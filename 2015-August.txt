From backus at genepi.med.utah.edu  Sat Aug  1 01:22:01 2015
From: backus at genepi.med.utah.edu (Steven Backus)
Date: Fri, 31 Jul 2015 17:22:01 -0600 (MDT)
Subject: [R] x11() hangs in 3.2.1
In-Reply-To: <02D24771-4BA5-4825-9B35-88A800A77739@me.com>
References: <201507311922.t6VJMiOl010572@whimsy.med.utah.edu>
	<02D24771-4BA5-4825-9B35-88A800A77739@me.com>
Message-ID: <201507312322.t6VNM1t7016401@genepi.med.utah.edu>

marc_schwartz at me.com writes:

> First, just an FYI, that this would be better posted to R-SIG-Fedora:

>   https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Thanks, I'll give it a try.

> Can you run:
>   capabilities()
> in a terminal session and see what it shows for X11:

Yes, here is the output:

       jpeg         png        tiff       tcltk         X11        aqua 
       TRUE        TRUE        TRUE       FALSE        TRUE       FALSE 
   http/ftp     sockets      libxml        fifo      cledit       iconv 
       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE 
        NLS     profmem       cairo         ICU long.double     libcurl 
       TRUE       FALSE        TRUE       FALSE        TRUE       FALSE 

> Did you install R via local compilation?

Yes, local compilation.

> Presuming local compilation, I would check your configure and build
> logs for warnings/errors. It is possible that you are missing an
> X11 header or lib someplace.

The config.log file has lots of errors but nothing obviously
related to this problem.

Thanks for your help,
  Steve
-- 
Steven J. Backus                        Computer Systems Manager
University of Utah                      E-Mail:  steven.backus at utah.edu
Genetic Epidemiology                    Alternate:  backus at math.utah.edu
391 Chipeta Way -- Suite D              Office:  801.587.9308
Salt Lake City, UT 84108-1266           http://www.math.utah.edu/~backus


From chris_kelvin2001 at yahoo.com  Sat Aug  1 03:36:12 2015
From: chris_kelvin2001 at yahoo.com (Christopher Kelvin)
Date: Sat, 1 Aug 2015 01:36:12 +0000 (UTC)
Subject: [R] Clarification on Simulation and Iteration
Message-ID: <1441173417.5041893.1438392972445.JavaMail.yahoo@mail.yahoo.com>

Dear All,
I am performing some simulations for a new model. I run about 10,000 iterations with a sample of 50 datasets and this returns one set of 50 simulated data. 

Now, what I need to obtain is 10 sets of the 50 simulated data out of the 10,000 iterations and not just only 1 set.  The model is the Copas selection model for publication bias in Mete-analysis. Any one who knows this model has any suggestion for the improvement of my code is most welcome.

Below is my code. 


Kind regards


Chris Guure
University of Ghana




install.packages("msm") 
library(msm) 


rho1=-0.3; tua=0.020; n=50; d=-0.2; rr=10000; a=-1.3; b=0.06 
si<-rtnorm(n, mean=0, sd=1, lower=0, upper=0.2)# I used this to generate standard errors for each study 
set.seed(21111)   ## I have stored the data and the output in this seed 

for( i in 1:rr){ 

mu<-rnorm(n,d,tua^2)              # prob. of each effect estimate 
rho<-si*rho1/sqrt(tua^2 + si^2) # estimate of the correlation coefficient 
mu0<- a + b/si       # mean of the truncated normal model (Copas selection model) 
y1<-rnorm(mu,si^2)            # observed effects zise 
z<-rnorm(mu0,1)               # selection model 
rho2<-cor(y1, z) 

select<-pnorm((mu0 + rho*(y1-mu)/sqrt(tua^2 + si^2))/sqrt(1-rho^2)) 
probselect<-ifelse(select<z, y1, NA)# the prob that the study is selected 

probselect 
data<-data.frame(probselect,si)    # this contains both include and exclude data 
data 
data1<-data[complete.cases(data),] # Contains only the included data for analysis 
data1 


}


From dwinsemius at comcast.net  Sat Aug  1 05:32:32 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 31 Jul 2015 20:32:32 -0700
Subject: [R] Clarification on Simulation and Iteration
In-Reply-To: <1441173417.5041893.1438392972445.JavaMail.yahoo@mail.yahoo.com>
References: <1441173417.5041893.1438392972445.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <7D84FB90-661F-4257-8F63-C0054F26817D@comcast.net>


On Jul 31, 2015, at 6:36 PM, Christopher Kelvin via R-help wrote:

> Dear All,
> I am performing some simulations for a new model. I run about 10,000 iterations with a sample of 50 datasets and this returns one set of 50 simulated data. 
> 
> Now, what I need to obtain is 10 sets of the 50 simulated data out of the 10,000 iterations and not just only 1 set.  The model is the Copas selection model for publication bias in Mete-analysis. Any one who knows this model has any suggestion for the improvement of my code is most welcome.
> 
> Below is my code. 
> 
> 
> Kind regards
> 
> 
> Chris Guure
> University of Ghana
> 
> 
> 
> 
> install.packages("msm") 
> library(msm) 
> 
> 
> rho1=-0.3; tua=0.020; n=50; d=-0.2; rr=10000; a=-1.3; b=0.06 
> si<-rtnorm(n, mean=0, sd=1, lower=0, upper=0.2)# I used this to generate standard errors for each study 
> set.seed(21111)   ## I have stored the data and the output in this seed 
> 
> for( i in 1:rr){ 
> 
> mu<-rnorm(n,d,tua^2)              # prob. of each effect estimate 
> rho<-si*rho1/sqrt(tua^2 + si^2) # estimate of the correlation coefficient 
> mu0<- a + b/si       # mean of the truncated normal model (Copas selection model) 
> y1<-rnorm(mu,si^2)            # observed effects zise 
> z<-rnorm(mu0,1)               # selection model 
> rho2<-cor(y1, z) 
> 
> select<-pnorm((mu0 + rho*(y1-mu)/sqrt(tua^2 + si^2))/sqrt(1-rho^2)) 
> probselect<-ifelse(select<z, y1, NA)# the prob that the study is selected 
> 
> probselect 
> data<-data.frame(probselect,si)    # this contains both include and exclude data 
> data 
> data1<-data[complete.cases(data),] # Contains only the included data for analysis 
> data1 
> 
> 
> }
> 

OK. The code runs without error. So .... what exactly is the problem? (I have no experience with the Copas selection model if in fact that is what is being exemplified.)

-- 

David Winsemius
Alameda, CA, USA


From chris_kelvin2001 at yahoo.com  Sat Aug  1 05:41:04 2015
From: chris_kelvin2001 at yahoo.com (Christopher Kelvin)
Date: Sat, 1 Aug 2015 03:41:04 +0000 (UTC)
Subject: [R] Clarification on Simulation and Iteration
In-Reply-To: <7D84FB90-661F-4257-8F63-C0054F26817D@comcast.net>
References: <7D84FB90-661F-4257-8F63-C0054F26817D@comcast.net>
Message-ID: <1106762682.7041.1438400464554.JavaMail.yahoo@mail.yahoo.com>

Thanks Dave.

What I actually want is to obtain say 10, different sets of (n=50) data for every 10,000 iterations I run. You will realise that the current code produces one set of data (n=50). I want 10 different sets of 50 observations at one run. I hope this makes sense.

Chris Guure 



On Saturday, August 1, 2015 3:32 AM, David Winsemius <dwinsemius at comcast.net> wrote:


On Jul 31, 2015, at 6:36 PM, Christopher Kelvin via R-help wrote:

> Dear All,
> I am performing some simulations for a new model. I run about 10,000 iterations with a sample of 50 datasets and this returns one set of 50 simulated data. 
> 
> Now, what I need to obtain is 10 sets of the 50 simulated data out of the 10,000 iterations and not just only 1 set.  The model is the Copas selection model for publication bias in Mete-analysis. Any one who knows this model has any suggestion for the improvement of my code is most welcome.
> 
> Below is my code. 
> 
> 
> Kind regards
> 
> 
> Chris Guure
> University of Ghana
> 
> 
> 
> 
> install.packages("msm") 
> library(msm) 
> 
> 
> rho1=-0.3; tua=0.020; n=50; d=-0.2; rr=10000; a=-1.3; b=0.06 
> si<-rtnorm(n, mean=0, sd=1, lower=0, upper=0.2)# I used this to generate standard errors for each study 
> set.seed(21111)   ## I have stored the data and the output in this seed 
> 
> for( i in 1:rr){ 
> 
> mu<-rnorm(n,d,tua^2)              # prob. of each effect estimate 
> rho<-si*rho1/sqrt(tua^2 + si^2) # estimate of the correlation coefficient 
> mu0<- a + b/si       # mean of the truncated normal model (Copas selection model) 
> y1<-rnorm(mu,si^2)            # observed effects zise 
> z<-rnorm(mu0,1)               # selection model 
> rho2<-cor(y1, z) 
> 
> select<-pnorm((mu0 + rho*(y1-mu)/sqrt(tua^2 + si^2))/sqrt(1-rho^2)) 
> probselect<-ifelse(select<z, y1, NA)# the prob that the study is selected 
> 
> probselect 
> data<-data.frame(probselect,si)    # this contains both include and exclude data 
> data 
> data1<-data[complete.cases(data),] # Contains only the included data for analysis 
> data1 
> 
> 
> }
> 

OK. The code runs without error. So .... what exactly is the problem? (I have no experience with the Copas selection model if in fact that is what is being exemplified.)

-- 

David Winsemius
Alameda, CA, USA


From adam.michael.erickson at gmail.com  Sat Aug  1 07:20:01 2015
From: adam.michael.erickson at gmail.com (Adam Erickson)
Date: Fri, 31 Jul 2015 22:20:01 -0700
Subject: [R] vectorized sub, gsub, grep, etc.
In-Reply-To: <1438315757.49661.YahooMailAndroidMobile@web185401.mail.gq1.yahoo.com>
References: <1438315757.49661.YahooMailAndroidMobile@web185401.mail.gq1.yahoo.com>
Message-ID: <4C611C07-2EC7-4F9D-AD5D-99C124BF0BFB@gmail.com>

I'm not sure I understand your question. Both functions return "" "CD" "" because they perform exact string matching. The first demonstrates how string or character replacements can be vectorized, while the second merely demonstrates how Rcpp can accelerate this type of operation.

Cheers,

Adam

> On Jul 30, 2015, at 21:09, John Thaden <jjthaden at flash.net> wrote:
> 
> 
> Can you show what is its solution for the original sample data? Why that discrepancy for you original sub2() function?
> 
> From:"Adam Erickson" <adam.michael.erickson at gmail.com>
> Date:Thu, Jul 30, 2015 at 6:11 pm
> Subject:Re: [R] vectorized sub, gsub, grep, etc.
> 
> Here is a Rcpp version for exact character matching (for example) written in C++ that is substantially faster. Hence, I think this is the way to go where loops may be unavoidable. However, the input vector length has to match the length of the pattern and replacement vectors, as your original code did. That can be changed though.
> 
> #include <Rcpp.h>
> using namespace Rcpp;
> 
> // [[Rcpp::export]]
> CharacterVector subCPP(CharacterVector pattern, CharacterVector replacement, CharacterVector x) {
>   int len = x.size();
>   CharacterVector y(len);
>   int patlen = pattern.size();
>   int replen = replacement.size();
>   if (patlen != replen)
>     Rcout<<"Error: Pattern and replacement length do not match";
>   for(int i = 0; i < patlen; ++i) {
>     if (*(char*)x[i] == *(char*)pattern[i])
>       y[x[i] == pattern[i]] = replacement[i];
>   }
>   return y;
> }
> 
> ""   "CD" ""  
> 
> system.time(for(i in 1:50000) subCPP(patt, repl, X))
>    user  system elapsed 
>    0.16    0.00    0.16 
> 
> Cheers,
> 
> Adam
> 
>> On Wednesday, July 29, 2015 at 2:42:23 PM UTC-7, Adam Erickson wrote:
>> Further refining the vectorized (within a loop) exact string match function, I get times below 0.9 seconds while maintaining error checking. This is accomplished by removing which() and replacing 1:length() with seq_along().
>> 
>> sub2 <- function(pattern, replacement, x) {
>>    len    <- length(x)
>>    y      <- character(length=len)
>>    patlen <- length(pattern)
>>    replen <- length(replacement)
>>    if(patlen != replen) stop('Error: Pattern and replacement length do not match')
>>    for(i in seq_along(pattern)) {
>>      y[x==pattern[i]] <- replacement[i]
>>    }
>>    return(y)
>>  }
>> 
>> system.time(for(i in 1:50000) sub2(patt, repl, X))
>>    user  system elapsed 
>>    0.86    0.00    0.86 
>> 
>> Since the ordered vectors are perfectly aligned, might as well do an exact string match. Hence, I think this is not off-topic.
>> 
>> Cheers,
>> 
>> Adam
>> 
>>> On Wednesday, July 29, 2015 at 8:15:52 AM UTC-7, Bert Gunter wrote:
>>> There is confusion here. apply() family functions are **NOT** 
>>> vectorization -- they ARE loops (at the interpreter level), just done 
>>> in "functionalized" form. Please read background material (John 
>>> Chambers's books, MASS, or numerous others) to improve your 
>>> understanding and avoid posting erroneous comments. 
>>> 
>>> Cheers, 
>>> Bert 
>>> 
>>> 
>>> Bert Gunter 
>>> 
>>> "Data is not information. Information is not knowledge. And knowledge 
>>> is certainly not wisdom." 
>>>    -- Clifford Stoll 
>>> 
>>> 
>>> On Tue, Jul 28, 2015 at 3:00 PM, John Thaden <jjth... at flash.net> wrote: 
>>> > Adam,    The method you propose gives a different result than the prior methods for these example vectors 
>>> > X <- c("ab", "cd", "ef") 
>>> > patt <- c("b", "cd", "a") 
>>> > repl <- c("B", "CD", "A") 
>>> > 
>>> > Old method 1 
>>> > 
>>> > mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X) 
>>> > gives 
>>> >   b   cd    a 
>>> > "aB" "CD" "ef" 
>>> > 
>>> > Old method 2 
>>> > 
>>> > sub2 <- function(pattern, replacement, x) { 
>>> >     len <- length(x) 
>>> >     if (length(pattern) == 1) 
>>> >         pattern <- rep(pattern, len) 
>>> >     if (length(replacement) == 1) 
>>> >         replacement <- rep(replacement, len) 
>>> >     FUN <- function(i, ...) { 
>>> >         sub(pattern[i], replacement[i], x[i], fixed = TRUE) 
>>> >     } 
>>> >     idx <- 1:length(x) 
>>> >     sapply(idx, FUN) 
>>> > } 
>>> > sub2(patt, repl, X) 
>>> >  gives 
>>> > [1] "aB" "CD" "ef" 
>>> > 
>>> > Your method (I gave it the unique name "sub3") 
>>> >  sub3 <- function(pattern, replacement, x) {   len    <- length(x)  y      <- character(length=len)  patlen <- length(pattern)  replen <- length(replacement)  if(patlen != replen) stop('Error: Pattern and replacement length do not match')  for(i in 1:replen) {    y[which(x==pattern[i])] <- replacement[i]  }  return(y)}sub3(patt, repl, X) 
>>> > gives[1] ""   "CD" "" 
>>> > 
>>> > Granted, whatever it does, it does it faster 
>>> > #Old method 1 
>>> > system.time(for(i in 1:50000) 
>>> > mapply(function(p,r,x) sub(p,r,x, fixed = TRUE),p=patt,r=repl,x=X)) 
>>> >    user  system elapsed 
>>> >    2.53    0.00    2.52 
>>> > 
>>> > #Old method 2 
>>> > system.time(for(i in 1:50000)sub2(patt, repl, X))   user  system elapsed 
>>> >    2.32    0.00    2.32 
>>> > 
>>> > #Your proposed method 
>>> > system.time(for(i in 1:50000) sub3(patt, repl, X)) 
>>> >    user  system elapsed 
>>> >    1.02    0.00    1.01 
>>> >  but would it still be faster if it actually solved the same problem? 
>>> > 
>>> > -John Thaden 
>>> > 
>>> > 
>>> > 
>>> > 
>>> >      On Monday, July 27, 2015 11:40 PM, Adam Erickson <adam.micha... at gmail.com> wrote: 
>>> > 
>>> > I know this is an old thread, but I wrote a simple FOR loop with vectorized pattern replacement that is much faster than either of those (it can also accept outputs differing in length from the patterns): 
>>> >   sub2  <- function(pattern, replacement, x) {     len   <- length(x)    y      <- character(length=len)    patlen <- length(pattern)    replen <- length(replacement)    if(patlen != replen) stop('Error: Pattern and replacement length do not match')    for(i in 1:replen) {      y[which(x==pattern[i])] <- replacement[i]    }    return(y)  } 
>>> > system.time(test <- sub2(patt, repl, XX))   user  system elapsed       0       0       0 
>>> > Cheers, 
>>> > Adam 
>>> > On Wednesday, October 8, 2008 at 9:38:01 PM UTC-7, john wrote: 
>>> > Hello Christos, 
>>> >   To my surprise, vectorization actually hurt processing speed!#Example 
>>> > X <- c("ab", "cd", "ef") 
>>> > patt <- c("b", "cd", "a") 
>>> > repl <- c("B", "CD", "A")sub2 <- function(pattern, replacement, x) { 
>>> >     len <- length(x) 
>>> >     if (length(pattern) == 1) 
>>> >         pattern <- rep(pattern, len) 
>>> >     if (length(replacement) == 1) 
>>> >         replacement <- rep(replacement, len) 
>>> >     FUN <- function(i, ...) { 
>>> >         sub(pattern[i], replacement[i], x[i], fixed = TRUE) 
>>> >     } 
>>> >     idx <- 1:length(x) 
>>> >     sapply(idx, FUN) 
>>> > } 
>>> > 
>>> > system.time(  for(i in 1:10000)  sub2(patt, repl, X)  ) 
>>> >    user  system elapsed 
>>> >    1.18    0.07    1.26 system.time(  for(i in 1:10000)  mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X)  ) 
>>> >    user  system elapsed 
>>> >    1.42    0.05    1.47 
>>> > 
>>> > So much for avoiding loops. 
>>> > John Thaden======= At 2008-10-07, 14:58:10 Christos wrote: =======>John, 
>>> >>Try the following: 
>>> >> 
>>> >> mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X) 
>>> >>   b   cd    a 
>>> >>"aB" "CD" "ef" 
>>> >> 
>>> >>-Christos>> -----My Original Message----- 
>>> >>> R pattern-matching and replacement functions are 
>>> >>> vectorized: they can operate on vectors of targets. 
>>> >>> However, they can only use one pattern and replacement. 
>>> >>> Here is code to apply a different pattern and replacement for 
>>> >>> every target.  My question: can it be done better? 
>>> >>> 
>>> >>> sub2 <- function(pattern, replacement, x) { 
>>> >>>     len <- length(x) 
>>> >>>     if (length(pattern) == 1) 
>>> >>>         pattern <- rep(pattern, len) 
>>> >>>     if (length(replacement) == 1) 
>>> >>>         replacement <- rep(replacement, len) 
>>> >>>     FUN <- function(i, ...) { 
>>> >>>         sub(pattern[i], replacement[i], x[i], fixed = TRUE) 
>>> >>>     } 
>>> >>>     idx <- 1:length(x) 
>>> >>>     sapply(idx, FUN) 
>>> >>> } 
>>> >>> 
>>> >>> #Example 
>>> >>> X <- c("ab", "cd", "ef") 
>>> >>> patt <- c("b", "cd", "a") 
>>> >>> repl <- c("B", "CD", "A") 
>>> >>> sub2(patt, repl, X) 
>>> >>> 
>>> >>> -John_________________________ _____________________ 
>>> > R-h... at r-project.org mailing list 
>>> > https://stat.ethz.ch/mailman/ listinfo/r-help 
>>> > PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html 
>>> > and provide commented, minimal, self-contained, reproducible code. 
>>> > 
>>> > 
>>> > 
>>> > 
>>> >         [[alternative HTML version deleted]] 
>>> > 
>>> > ______________________________ ________________ 
>>> > R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> > https://stat.ethz.ch/mailman/ listinfo/r-help 
>>> > PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html 
>>> > and provide commented, minimal, self-contained, reproducible code. 
>>> 
>>> ______________________________ ________________ 
>>> R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/ listinfo/r-help 
>>> PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html 
>>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Aug  1 08:45:14 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 31 Jul 2015 23:45:14 -0700
Subject: [R] Clarification on Simulation and Iteration
In-Reply-To: <1106762682.7041.1438400464554.JavaMail.yahoo@mail.yahoo.com>
References: <7D84FB90-661F-4257-8F63-C0054F26817D@comcast.net>
	<1106762682.7041.1438400464554.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <968E872D-8F15-4178-B94C-D8A8064E9AEC@comcast.net>


On Jul 31, 2015, at 8:41 PM, Christopher Kelvin wrote:

> Thanks Dave.
> 
> What I actually want is to obtain say 10, different sets of (n=50) data for every 10,000 iterations I run. You will realise that the current code produces one set of data (n=50). I want 10 different sets of 50 observations at one run. I hope this makes sense.

I would think that either `replicate(50, ...)` or `for(i in 1:50) {...}` would suffice. Unless of course the phrase "want 10 different sets of 50 observations at one run` means something different than it appears to request.


> 
> Chris Guure 
> 
> 
> 
> On Saturday, August 1, 2015 3:32 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On Jul 31, 2015, at 6:36 PM, Christopher Kelvin via R-help wrote:
> 
>> Dear All,
>> I am performing some simulations for a new model. I run about 10,000 iterations with a sample of 50 datasets and this returns one set of 50 simulated data. 
>> 
>> Now, what I need to obtain is 10 sets of the 50 simulated data out of the 10,000 iterations and not just only 1 set.  The model is the Copas selection model for publication bias in Mete-analysis. Any one who knows this model has any suggestion for the improvement of my code is most welcome.
>> 
>> Below is my code. 
>> 
>> 
>> Kind regards
>> 
>> 
>> Chris Guure
>> University of Ghana
>> 
>> 
>> 
>> 
>> install.packages("msm") 
>> library(msm) 
>> 
>> 
>> rho1=-0.3; tua=0.020; n=50; d=-0.2; rr=10000; a=-1.3; b=0.06 
>> si<-rtnorm(n, mean=0, sd=1, lower=0, upper=0.2)# I used this to generate standard errors for each study 
>> set.seed(21111)   ## I have stored the data and the output in this seed 
>> 
>> for( i in 1:rr){ 
>> 
>> mu<-rnorm(n,d,tua^2)              # prob. of each effect estimate 
>> rho<-si*rho1/sqrt(tua^2 + si^2) # estimate of the correlation coefficient 
>> mu0<- a + b/si       # mean of the truncated normal model (Copas selection model) 
>> y1<-rnorm(mu,si^2)            # observed effects zise 
>> z<-rnorm(mu0,1)               # selection model 
>> rho2<-cor(y1, z) 
>> 
>> select<-pnorm((mu0 + rho*(y1-mu)/sqrt(tua^2 + si^2))/sqrt(1-rho^2)) 
>> probselect<-ifelse(select<z, y1, NA)# the prob that the study is selected 
>> 
>> probselect 
>> data<-data.frame(probselect,si)    # this contains both include and exclude data 
>> data 
>> data1<-data[complete.cases(data),] # Contains only the included data for analysis 
>> data1 
>> 
>> 
>> }
>> 
> 
> OK. The code runs without error. So .... what exactly is the problem? (I have no experience with the Copas selection model if in fact that is what is being exemplified.)
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA

David Winsemius
Alameda, CA, USA


From joerg.kirschner at gmail.com  Sat Aug  1 07:48:13 2015
From: joerg.kirschner at gmail.com (Joerg Kirschner)
Date: Sat, 1 Aug 2015 07:48:13 +0200
Subject: [R] Error when compiling R-2.5.1 / *** [d-p-q-r-tests.Rout] Fehler 1
Message-ID: <CAFEfSPcjkfmGdzsG-6HJxFKSuKzCg_djBO12VVPD23UFrRFkAw@mail.gmail.com>

Hi everyone,
I am new to Linux and R - but I managed to build R-2.5.1 from source to use
it in Genepattern. Genepattern does only support R-2.5.1 which I could not
find anywhere for installation via apt-get or in the Ubuntu Software-Centre
(I am using Ubuntu 14.04 (Trusty Tahr) 32-bit)

But after doing

make check


I get

comparing 'method-dispatch.Rout' to './method-dispatch.Rout.save' ... OK
running code in 'd-p-q-r-tests.R' ...make[3]: *** [d-p-q-r-tests.Rout]
Fehler 1
make[3]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
make[2]: *** [test-Specific] Fehler 2
make[2]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
make[1]: *** [test-all-basics] Fehler 1
make[1]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
make: *** [check] Fehler 2


but I can make install and use R for simple plots etc. afterwards - still I
am worried something is wrong, can you give some advice.

A closer look at the error gives

> ## PR#7099 : pf() with large df1 or df2:
> nu <- 2^seq(25,34, 0.5)
> y <- 1e9*(pf(1,1,nu) - 0.68268949)
> stopifnot(All.eq(pf(1,1,Inf), 0.68268949213708596),
+           diff(y) > 0, # i.e. pf(1,1, *) is monotone increasing
+           All.eq(y [1], -5.07420372386491),
+           All.eq(y[19],  2.12300110824515))
Error: All.eq(y[1], -5.07420372386491) is not TRUE
Execution halted


As I understand so far some errors are critical some are not - can you
please give some advice on the error above? Can I still use R installed
with that error? What do I need to solve the error?

Thanks, Joerg

	[[alternative HTML version deleted]]


From jjthaden at flash.net  Sat Aug  1 08:15:42 2015
From: jjthaden at flash.net (John Thaden)
Date: Sat, 1 Aug 2015 06:15:42 +0000 (UTC)
Subject: [R] vectorized sub, gsub, grep, etc.
In-Reply-To: <4C611C07-2EC7-4F9D-AD5D-99C124BF0BFB@gmail.com>
References: <4C611C07-2EC7-4F9D-AD5D-99C124BF0BFB@gmail.com>
Message-ID: <430905393.29629.1438409742712.JavaMail.yahoo@mail.yahoo.com>

Adam,?? 
You reopened an old thread noting its age, but did you begin at its beginning?
> Subject: vectorized sub, gsub, grep, etc.> Date: Oct 7, 2008
> R pattern-matching and replacement functions are
> vectorized: they can operate on vectors of targets.
> However, they can only use one pattern and replacement.
> Here is code to apply a different pattern and replacement
> for every target.  My question: can it be done better?

    sub2 <- function(pattern, replacement, x) {
        len <- length(x)
        if (length(pattern) == 1) 
            pattern <- rep(pattern, len)
        if (length(replacement) == 1) 
            replacement <- rep(replacement, len)
        FUN <- function(i, ...) {
            sub(pattern[i], replacement[i], x[i], fixed = TRUE)
        }
        idx <- 1:length(x)
        sapply(idx, FUN)    
    }

    #Example
    X <- c("ab", "cd", "ef")
    patt <- c("b", "cd", "a")
    repl <- c("B", "CD", "A")
    sub2(patt, repl, X)
?
If you run that code, you'll see the correct answer is not "" "CD" "", it is

[1] "aB" "CD" "ef"

And the same answer is given by the shorter (but slower) code suggested later that day by Christos

    mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X)

  b ? cd ? ?a
"aB" "CD" "ef"

By talking instead about simple string matching, I'm afraid you've rather hijacked the thread.

-John
?-John 

Adam wrote


  
 > I'm not sure I understand your question. Both functions return "" "CD" "" because they 
> perform exact string matching. The first demonstrates how string or character replacements 
> can be vectorized, while the second merely demonstrates how Rcpp can accelerate this type of operation.

On Jul 30, 2015, at 21:09, John Thaden <jjthaden at flash.net> wrote:



| Can you show what is its solution for the original sample data? Why that discrepancy for you original sub2() function? 
|  From:"Adam Erickson" <adam.michael.erickson at gmail.com>
Date:Thu, Jul 30, 2015 at 6:11 pm
Subject:Re: [R] vectorized sub, gsub, grep, etc.

 Here is a Rcpp version for exact character matching (for example) written in C++ that is substantially faster. Hence, I think this is the way to go where loops may be unavoidable. However, the input vector length has to match the length of the pattern and replacement vectors, as your original code did. That can be changed though.
#include <Rcpp.h>using namespace Rcpp;
// [[Rcpp::export]]CharacterVector subCPP(CharacterVector pattern, CharacterVector replacement, CharacterVector x) {? int len = x.size();? CharacterVector y(len);? int patlen = pattern.size();? int replen = replacement.size();? if (patlen != replen)? ? Rcout<<"Error: Pattern and replacement length do not match";? for(int i = 0; i < patlen; ++i) {? ? if (*(char*)x[i] == *(char*)pattern[i])? ? ? y[x[i] == pattern[i]] = replacement[i];? }? return y;}
"" ? "CD" "" ?

system.time(for(i in 1:50000) subCPP(patt, repl, X))? ?user ?system elapsed?? ?0.16 ? ?0.00 ? ?0.16?
Cheers,
Adam
On Wednesday, July 29, 2015 at 2:42:23 PM UTC-7, Adam Erickson wrote:
Further refining the vectorized (within a loop) exact string match function,?I get times below 0.9 seconds while maintaining error checking. This is accomplished by?removing which() and replacing?1:length()?with seq_along().
sub2 <- function(pattern, replacement, x) {? ?len ? ?<- length(x)? ?y ? ? ?<- character(length=len)? ?patlen <- length(pattern)? ?replen <- length(replacement)? ?if(patlen != replen) stop('Error: Pattern and replacement length do not match')? ?for(i in seq_along(pattern)) {? ? ?y[x==pattern[i]] <- replacement[i]? ?}? ?return(y)?}
system.time(for(i in 1:50000) sub2(patt, repl, X))? ?user ?system elapsed?? ?0.86 ? ?0.00 ? ?0.86?
Since the ordered vectors are perfectly aligned, might as well do an exact string match. Hence, I think this is not off-topic.
Cheers,
Adam
On Wednesday, July 29, 2015 at 8:15:52 AM UTC-7, Bert Gunter wrote:
There is confusion here. apply() family functions are **NOT**
vectorization -- they ARE loops (at the interpreter level), just done
in "functionalized" form. Please read background material (John
Chambers's books, MASS, or numerous others) to improve your
understanding and avoid posting erroneous comments.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
? ?-- Clifford Stoll


On Tue, Jul 28, 2015 at 3:00 PM, John Thaden <jjth... at flash.net> wrote:
> Adam, ? ?The method you propose gives a different result than the prior methods for these example vectors
> X <- c("ab", "cd", "ef")
> patt <- c("b", "cd", "a")
> repl <- c("B", "CD", "A")
>
> Old method 1
>
> mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X)
> gives
> ? b ? cd ? ?a
> "aB" "CD" "ef"
>
> Old method 2
>
> sub2 <- function(pattern, replacement, x) {
> ? ? len <- length(x)
> ? ? if (length(pattern) == 1)
> ? ? ? ? pattern <- rep(pattern, len)
> ? ? if (length(replacement) == 1)
> ? ? ? ? replacement <- rep(replacement, len)
> ? ? FUN <- function(i, ...) {
> ? ? ? ? sub(pattern[i], replacement[i], x[i], fixed = TRUE)
> ? ? }
> ? ? idx <- 1:length(x)
> ? ? sapply(idx, FUN)
> }
> sub2(patt, repl, X)
> ?gives
> [1] "aB" "CD" "ef"
>
> Your method (I gave it the unique name "sub3")
> ?sub3 <- function(pattern, replacement, x) { ? len ? ?<- length(x) ?y ? ? ?<- character(length=len) ?patlen <- length(pattern) ?replen <- length(replacement) ?if(patlen != replen) stop('Error: Pattern and replacement length do not match') ?for(i in 1:replen) { ? ?y[which(x==pattern[i])] <- replacement[i] ?} ?return(y)}sub3(patt, repl, X)
> gives[1] "" ? "CD" ""
>
> Granted, whatever it does, it does it faster
> #Old method 1
> system.time(for(i in 1:50000)
> mapply(function(p,r,x) sub(p,r,x, fixed = TRUE),p=patt,r=repl,x=X))
> ? ?user ?system elapsed
> ? ?2.53 ? ?0.00 ? ?2.52
>
> #Old method 2
> system.time(for(i in 1:50000)sub2(patt, repl, X)) ? user ?system elapsed
> ? ?2.32 ? ?0.00 ? ?2.32
>
> #Your proposed method
> system.time(for(i in 1:50000) sub3(patt, repl, X))
> ? ?user ?system elapsed
> ? ?1.02 ? ?0.00 ? ?1.01
> ?but would it still be faster if it actually solved the same problem?
>
> -John Thaden
>
>
>
>
> ? ? ?On Monday, July 27, 2015 11:40 PM, Adam Erickson <adam.micha... at gmail.com> wrote:
>
> I know this is an old thread, but I wrote a simple FOR loop with vectorized pattern replacement that is much faster than either of those (it can also accept outputs differing in length from the patterns):
> ? sub2 ?<- function(pattern, replacement, x) { ? ? len ? <- length(x) ? ?y ? ? ?<- character(length=len) ? ?patlen <- length(pattern) ? ?replen <- length(replacement) ? ?if(patlen != replen) stop('Error: Pattern and replacement length do not match') ? ?for(i in 1:replen) { ? ? ?y[which(x==pattern[i])] <- replacement[i] ? ?} ? ?return(y) ?}
> system.time(test <- sub2(patt, repl, XX)) ? user ?system elapsed ? ? ? 0 ? ? ? 0 ? ? ? 0
> Cheers,
> Adam
> On Wednesday, October 8, 2008 at 9:38:01 PM UTC-7, john wrote:
> Hello Christos,
> ? To my surprise, vectorization actually hurt processing speed!#Example
> X <- c("ab", "cd", "ef")
> patt <- c("b", "cd", "a")
> repl <- c("B", "CD", "A")sub2 <- function(pattern, replacement, x) {
> ? ? len <- length(x)
> ? ? if (length(pattern) == 1)
> ? ? ? ? pattern <- rep(pattern, len)
> ? ? if (length(replacement) == 1)
> ? ? ? ? replacement <- rep(replacement, len)
> ? ? FUN <- function(i, ...) {
> ? ? ? ? sub(pattern[i], replacement[i], x[i], fixed = TRUE)
> ? ? }
> ? ? idx <- 1:length(x)
> ? ? sapply(idx, FUN)
> }
>
> system.time( ?for(i in 1:10000) ?sub2(patt, repl, X) ?)
> ? ?user ?system elapsed
> ? ?1.18 ? ?0.07 ? ?1.26 system.time( ?for(i in 1:10000) ?mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X) ?)
> ? ?user ?system elapsed
> ? ?1.42 ? ?0.05 ? ?1.47
>
> So much for avoiding loops.
> John Thaden======= At 2008-10-07, 14:58:10 Christos wrote: =======>John,
>>Try the following:
>>
>> mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X)
>> ? b ? cd ? ?a
>>"aB" "CD" "ef"
>>
>>-Christos>> -----My Original Message-----
>>> R pattern-matching and replacement functions are
>>> vectorized: they can operate on vectors of targets.
>>> However, they can only use one pattern and replacement.
>>> Here is code to apply a different pattern and replacement for
>>> every target. ?My question: can it be done better?
>>>
>>> sub2 <- function(pattern, replacement, x) {
>>> ? ? len <- length(x)
>>> ? ? if (length(pattern) == 1)
>>> ? ? ? ? pattern <- rep(pattern, len)
>>> ? ? if (length(replacement) == 1)
>>> ? ? ? ? replacement <- rep(replacement, len)
>>> ? ? FUN <- function(i, ...) {
>>> ? ? ? ? sub(pattern[i], replacement[i], x[i], fixed = TRUE)
>>> ? ? }
>>> ? ? idx <- 1:length(x)
>>> ? ? sapply(idx, FUN)
>>> }
>>>
>>> #Example
>>> X <- c("ab", "cd", "ef")
>>> patt <- c("b", "cd", "a")
>>> repl <- c("B", "CD", "A")
>>> sub2(patt, repl, X)
>>>
>>> -John_________________________ _____________________
> R-h... at r-project.org mailing list
> https://stat.ethz.ch/mailman/ listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________ ________________
> R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________ ________________
R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/ listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


 |

 |




  
	[[alternative HTML version deleted]]


From a.aycaozdemir at hotmail.com  Sat Aug  1 14:21:40 2015
From: a.aycaozdemir at hotmail.com (=?windows-1254?B?YXNlbmEgYXnnYSD2emRlbWly?=)
Date: Sat, 1 Aug 2015 15:21:40 +0300
Subject: [R] missing data in R
Message-ID: <DUB129-W855BD620889AFC41CA328EF8890@phx.gbl>

Hello Mr. FeldesmanI am a master student in biostatistic
my thesis about missing values in microarray data, but ? can't create any values.
? want to create %10, %20,...%90 missing values for all colums in microarray data set .
Can you help me any code?

thank you for your attention.


Asena Ay?a ?zdemirMersin University Biostatistics 		 	   		  
	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sat Aug  1 18:16:10 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 01 Aug 2015 17:16:10 +0100
Subject: [R] Clarification on Simulation and Iteration
In-Reply-To: <1441173417.5041893.1438392972445.JavaMail.yahoo@mail.yahoo.com>
References: <1441173417.5041893.1438392972445.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55BCF0CA.9070702@dewey.myzen.co.uk>

I am not sure how you are doing this but there is a package on CRAN 
which implements the Copas model (metasens). I am not sure whether that 
would help in your modelling.

On 01/08/2015 02:36, Christopher Kelvin via R-help wrote:
> Dear All,
> I am performing some simulations for a new model. I run about 10,000 iterations with a sample of 50 datasets and this returns one set of 50 simulated data.
>
> Now, what I need to obtain is 10 sets of the 50 simulated data out of the 10,000 iterations and not just only 1 set.  The model is the Copas selection model for publication bias in Mete-analysis. Any one who knows this model has any suggestion for the improvement of my code is most welcome.
>
> Below is my code.
>
>
> Kind regards
>
>
> Chris Guure
> University of Ghana
>
>
>
>
> install.packages("msm")
> library(msm)
>
>
> rho1=-0.3; tua=0.020; n=50; d=-0.2; rr=10000; a=-1.3; b=0.06
> si<-rtnorm(n, mean=0, sd=1, lower=0, upper=0.2)# I used this to generate standard errors for each study
> set.seed(21111)   ## I have stored the data and the output in this seed
>
> for( i in 1:rr){
>
> mu<-rnorm(n,d,tua^2)              # prob. of each effect estimate
> rho<-si*rho1/sqrt(tua^2 + si^2) # estimate of the correlation coefficient
> mu0<- a + b/si       # mean of the truncated normal model (Copas selection model)
> y1<-rnorm(mu,si^2)            # observed effects zise
> z<-rnorm(mu0,1)               # selection model
> rho2<-cor(y1, z)
>
> select<-pnorm((mu0 + rho*(y1-mu)/sqrt(tua^2 + si^2))/sqrt(1-rho^2))
> probselect<-ifelse(select<z, y1, NA)# the prob that the study is selected
>
> probselect
> data<-data.frame(probselect,si)    # this contains both include and exclude data
> data
> data1<-data[complete.cases(data),] # Contains only the included data for analysis
> data1
>
>
> }
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tal.galili at gmail.com  Sat Aug  1 19:08:31 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Sat, 1 Aug 2015 20:08:31 +0300
Subject: [R] R and AWS
In-Reply-To: <CAFpdVnxFRyX5VhzinqzKEbNKtRQRD0bsNCfFjr+BHz9jzJdMyA@mail.gmail.com>
References: <CAFpdVnxFRyX5VhzinqzKEbNKtRQRD0bsNCfFjr+BHz9jzJdMyA@mail.gmail.com>
Message-ID: <CANdJ3dWKYVnDg0hutjt4aL-_DGjpqOxkOH3omzaHDv0haOQCxA@mail.gmail.com>

How about this:
"Setting Rstudio server using Amazon Web Services (AWS) ? a step by step
(screenshots) tutorial"
<http://www.r-statistics.com/2015/06/setting-rstudio-server-using-amazon-web-services-aws-a-step-by-step-screenshots-tutorial/>




----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------


On Thu, Jul 30, 2015 at 3:41 PM, My List <mylisttech at gmail.com> wrote:

> Hello All,
>
> I wanted to know if there is a quick tutorial which I could be pointed to,
> for the understanding of setting R and R studio on Amazon web services.
>
> Thanks in Advance,
> Harmeet
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From adam.michael.erickson at gmail.com  Sat Aug  1 19:28:01 2015
From: adam.michael.erickson at gmail.com (Adam Erickson)
Date: Sat, 1 Aug 2015 10:28:01 -0700
Subject: [R] vectorized sub, gsub, grep, etc.
In-Reply-To: <430905393.29629.1438409742712.JavaMail.yahoo@mail.yahoo.com>
References: <4C611C07-2EC7-4F9D-AD5D-99C124BF0BFB@gmail.com>
	<430905393.29629.1438409742712.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAHEemWY3BunEfAeXFvtNmDRtgWZ7FkHMdAOEsUG+X9saZngJow@mail.gmail.com>

Hi John,

So, you think looping over the sub() function with regular expressions
disabled is somehow more nuanced? Perhaps you should have specified that
you were only interested in sub() function results. Regardless, the
original function failed to match the 'a' in 'ab,' which should have
returned 'AB' at that vector position. Hence, the 'correct' results are not
really correct. It only returned the first match. The qdap library provides
a function for this:

library(qdap)
mgsub(patt,repl,X)
[1] "AB" "CD" "ef"

Based on my previous pattern matching and replacement code, there is
clearly an opportunity to accelerate these function with Rcpp. I think that
is the main takeaway from all of this. Unfortunately, I cannot dedicade my
own time to this at the moment. Until then, exact string matching provides
an elegant and efficient solution. A little data preparation, which is also
quite fast, is all that is needed.

Cheers,

Adam

On Fri, Jul 31, 2015 at 11:15 PM, John Thaden <jjthaden at flash.net> wrote:

> Adam,
>
> You reopened an old thread noting its age, but did you begin at its
> beginning?
>
> > Subject: vectorized sub, gsub, grep, etc.
> > Date: Oct 7, 2008
>
> > R pattern-matching and replacement functions are
> > vectorized: they can operate on vectors of targets.
> > However, they can only use one pattern and replacement.
> > Here is code to apply a different pattern and replacement
> > for every target.  My question: can it be done better?
>
>     sub2 <- function(pattern, replacement, x) {
>         len <- length(x)
>         if (length(pattern) == 1)
>             pattern <- rep(pattern, len)
>         if (length(replacement) == 1)
>             replacement <- rep(replacement, len)
>         FUN <- function(i, ...) {
>             sub(pattern[i], replacement[i], x[i], fixed = TRUE)
>         }
>         idx <- 1:length(x)
>         sapply(idx, FUN)
>     }
>
>     #Example
>     X <- c("ab", "cd", "ef")
>     patt <- c("b", "cd", "a")
>     repl <- c("B", "CD", "A")
>     sub2(patt, repl, X)
>
> If you run that code, you'll see the correct answer is not "" "CD" "", it is
>
> [1] "aB" "CD" "ef"
> And the same answer is given by the shorter (but slower) code suggested later that day by Christos
>
>     mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X)
>   b   cd    a
> "aB" "CD" "ef"
>
> By talking instead about simple string matching, I'm afraid you've rather hijacked the thread.
>
> -John
>
>
> -John
>
>
> Adam wrote
>
>
>
>
> > I'm not sure I understand your question. Both functions return "" "CD"
> "" because they
> > perform exact string matching. The first demonstrates how string or
> character replacements
> > can be vectorized, while the second merely demonstrates how Rcpp can
> accelerate this type of operation.
>
>
> On Jul 30, 2015, at 21:09, John Thaden <jjthaden at flash.net> wrote:
>
> Can you show what is its solution for the original sample data? Why that
> discrepancy for you original sub2() function?
> From:"Adam Erickson" <adam.michael.erickson at gmail.com>
> Date:Thu, Jul 30, 2015 at 6:11 pm
> Subject:Re: [R] vectorized sub, gsub, grep, etc.
>
> Here is a Rcpp version for exact character matching (for example) written
> in C++ that is substantially faster. Hence, I think this is the way to go
> where loops may be unavoidable. However, the input vector length has to
> match the length of the pattern and replacement vectors, as your original
> code did. That can be changed though.
>
> #include <Rcpp.h>
> using namespace Rcpp;
>
> // [[Rcpp::export]]
> CharacterVector subCPP(CharacterVector pattern, CharacterVector
> replacement, CharacterVector x) {
>   int len = x.size();
>   CharacterVector y(len);
>   int patlen = pattern.size();
>   int replen = replacement.size();
>   if (patlen != replen)
>     Rcout<<"Error: Pattern and replacement length do not match";
>   for(int i = 0; i < patlen; ++i) {
>     if (*(char*)x[i] == *(char*)pattern[i])
>       y[x[i] == pattern[i]] = replacement[i];
>   }
>   return y;
> }
>
> ""   "CD" ""
>
> system.time(for(i in 1:50000) subCPP(patt, repl, X))
>    user  system elapsed
>    0.16    0.00    0.16
>
> Cheers,
>
> Adam
>
> On Wednesday, July 29, 2015 at 2:42:23 PM UTC-7, Adam Erickson wrote:
>
> Further refining the vectorized (within a loop) exact string match
> function, I get times below 0.9 seconds while maintaining error checking.
> This is accomplished by removing which() and replacing 1:length() with
> seq_along().
>
> sub2 <- function(pattern, replacement, x) {
>    len    <- length(x)
>    y      <- character(length=len)
>    patlen <- length(pattern)
>    replen <- length(replacement)
>    if(patlen != replen) stop('Error: Pattern and replacement length do not
> match')
>    for(i in seq_along(pattern)) {
>      y[x==pattern[i]] <- replacement[i]
>    }
>    return(y)
>  }
>
> system.time(for(i in 1:50000) sub2(patt, repl, X))
>    user  system elapsed
>    0.86    0.00    0.86
>
> Since the ordered vectors are perfectly aligned, might as well do an exact
> string match. Hence, I think this is not off-topic.
>
> Cheers,
>
> Adam
>
> On Wednesday, July 29, 2015 at 8:15:52 AM UTC-7, Bert Gunter wrote:
>
> There is confusion here. apply() family functions are **NOT**
> vectorization -- they ARE loops (at the interpreter level), just done
> in "functionalized" form. Please read background material (John
> Chambers's books, MASS, or numerous others) to improve your
> understanding and avoid posting erroneous comments.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Tue, Jul 28, 2015 at 3:00 PM, John Thaden <jjth... at flash.net> wrote:
> > Adam,    The method you propose gives a different result than the prior
> methods for these example vectors
> > X <- c("ab", "cd", "ef")
> > patt <- c("b", "cd", "a")
> > repl <- c("B", "CD", "A")
> >
> > Old method 1
> >
> > mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl,
> x=X)
> > gives
> >   b   cd    a
> > "aB" "CD" "ef"
> >
> > Old method 2
> >
> > sub2 <- function(pattern, replacement, x) {
> >     len <- length(x)
> >     if (length(pattern) == 1)
> >         pattern <- rep(pattern, len)
> >     if (length(replacement) == 1)
> >         replacement <- rep(replacement, len)
> >     FUN <- function(i, ...) {
> >         sub(pattern[i], replacement[i], x[i], fixed = TRUE)
> >     }
> >     idx <- 1:length(x)
> >     sapply(idx, FUN)
> > }
> > sub2(patt, repl, X)
> >  gives
> > [1] "aB" "CD" "ef"
> >
> > Your method (I gave it the unique name "sub3")
> >  sub3 <- function(pattern, replacement, x) {   len    <- length(x)  y
>    <- character(length=len)  patlen <- length(pattern)  replen <-
> length(replacement)  if(patlen != replen) stop('Error: Pattern and
> replacement length do not match')  for(i in 1:replen) {
>  y[which(x==pattern[i])] <- replacement[i]  }  return(y)}sub3(patt, repl,
> X)
> > gives[1] ""   "CD" ""
> >
> > Granted, whatever it does, it does it faster
> > #Old method 1
> > system.time(for(i in 1:50000)
> > mapply(function(p,r,x) sub(p,r,x, fixed = TRUE),p=patt,r=repl,x=X))
> >    user  system elapsed
> >    2.53    0.00    2.52
> >
> > #Old method 2
> > system.time(for(i in 1:50000)sub2(patt, repl, X))   user  system elapsed
> >    2.32    0.00    2.32
> >
> > #Your proposed method
> > system.time(for(i in 1:50000) sub3(patt, repl, X))
> >    user  system elapsed
> >    1.02    0.00    1.01
> >  but would it still be faster if it actually solved the same problem?
> >
> > -John Thaden
> >
> >
> >
> >
> >      On Monday, July 27, 2015 11:40 PM, Adam Erickson <
> adam.micha... at gmail.com> wrote:
> >
> > I know this is an old thread, but I wrote a simple FOR loop with
> vectorized pattern replacement that is much faster than either of those (it
> can also accept outputs differing in length from the patterns):
> >   sub2  <- function(pattern, replacement, x) {     len   <- length(x)
>  y      <- character(length=len)    patlen <- length(pattern)    replen <-
> length(replacement)    if(patlen != replen) stop('Error: Pattern and
> replacement length do not match')    for(i in 1:replen) {
>  y[which(x==pattern[i])] <- replacement[i]    }    return(y)  }
> > system.time(test <- sub2(patt, repl, XX))   user  system elapsed       0
>       0       0
> > Cheers,
> > Adam
> > On Wednesday, October 8, 2008 at 9:38:01 PM UTC-7, john wrote:
> > Hello Christos,
> >   To my surprise, vectorization actually hurt processing speed!#Example
> > X <- c("ab", "cd", "ef")
> > patt <- c("b", "cd", "a")
> > repl <- c("B", "CD", "A")sub2 <- function(pattern, replacement, x) {
> >     len <- length(x)
> >     if (length(pattern) == 1)
> >         pattern <- rep(pattern, len)
> >     if (length(replacement) == 1)
> >         replacement <- rep(replacement, len)
> >     FUN <- function(i, ...) {
> >         sub(pattern[i], replacement[i], x[i], fixed = TRUE)
> >     }
> >     idx <- 1:length(x)
> >     sapply(idx, FUN)
> > }
> >
> > system.time(  for(i in 1:10000)  sub2(patt, repl, X)  )
> >    user  system elapsed
> >    1.18    0.07    1.26 system.time(  for(i in 1:10000)
>  mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl, x=X)
>  )
> >    user  system elapsed
> >    1.42    0.05    1.47
> >
> > So much for avoiding loops.
> > John Thaden======= At 2008-10-07, 14:58:10 Christos wrote: =======>John,
> >>Try the following:
> >>
> >> mapply(function(p, r, x) sub(p, r, x, fixed = TRUE), p=patt, r=repl,
> x=X)
> >>   b   cd    a
> >>"aB" "CD" "ef"
> >>
> >>-Christos>> -----My Original Message-----
> >>> R pattern-matching and replacement functions are
> >>> vectorized: they can operate on vectors of targets.
> >>> However, they can only use one pattern and replacement.
> >>> Here is code to apply a different pattern and replacement for
> >>> every target.  My question: can it be done better?
> >>>
> >>> sub2 <- function(pattern, replacement, x) {
> >>>     len <- length(x)
> >>>     if (length(pattern) == 1)
> >>>         pattern <- rep(pattern, len)
> >>>     if (length(replacement) == 1)
> >>>         replacement <- rep(replacement, len)
> >>>     FUN <- function(i, ...) {
> >>>         sub(pattern[i], replacement[i], x[i], fixed = TRUE)
> >>>     }
> >>>     idx <- 1:length(x)
> >>>     sapply(idx, FUN)
> >>> }
> >>>
> >>> #Example
> >>> X <- c("ab", "cd", "ef")
> >>> patt <- c("b", "cd", "a")
> >>> repl <- c("B", "CD", "A")
> >>> sub2(patt, repl, X)
> >>>
> >>> -John_________________________ _____________________
> > R-h... at r-project.org mailing list
> > https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________ ________________
> > R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________ ________________
> R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From michael.eisenring at gmx.ch  Sat Aug  1 17:17:22 2015
From: michael.eisenring at gmx.ch (Michael Eisenring)
Date: Sat, 1 Aug 2015 08:17:22 -0700
Subject: [R] Using R to fit a curve to a dataset using a specific equation
Message-ID: <000101d0cc6d$2b3e0210$81ba0630$@gmx.ch>

Hi there

 

	
I would like to use a specific equation to fit a curve to one of my data
sets (attached)

> dput(data)

structure(list(Gossypol = c(1036.331811, 4171.427741, 6039.995102,
5909.068158, 4140.242559, 4854.985845, 6982.035521, 6132.876396,
948.2418407, 3618.448997, 3130.376482, 5113.942098, 1180.171957,
1500.863038, 4576.787021, 5629.979049, 3378.151945, 3589.187889,
2508.417927, 1989.576826, 5972.926124, 2867.610671, 450.7205451, 1120.955,
3470.09352, 3575.043632, 2952.931863, 349.0864019, 1013.807628, 910.8879471,
3743.331903, 3350.203452, 592.3403778, 1517.045807, 1504.491931,
3736.144027, 2818.419785, 723.885643, 1782.864308, 1414.161257, 3723.629772,
3747.076592, 2005.919344, 4198.569251, 2228.522959, 3322.115942,
4274.324792, 720.9785449, 2874.651764, 2287.228752, 5654.858696,
1247.806111, 1247.806111, 2547.326207, 2608.716056, 1079.846532), Treatment
= structure(c(2L, 3L, 4L, 5L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 5L, 1L, 2L, 3L,
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
2L, 3L, 1L), .Label = c("C", "1c_2d", "3c_2d", "9c_2d", "1c_7d"), class =
"factor"), Damage_cm = c(0.4955, 1.516, 4.409, 3.2665, 0.491, 2.3035, 3.51,
1.8115, 0, 0.4435, 1.573, 1.8595, 0, 0.142, 2.171, 4.023, 4.9835, 0, 0.6925,
1.989, 5.683, 3.547, 0, 0.756, 2.129, 9.437, 3.211, 0, 0.578, 2.966, 4.7245,
1.8185, 0, 1.0475, 1.62, 5.568, 9.7455, 0, 0.8295, 2.411, 7.272, 4.516, 0,
0.4035, 2.974, 8.043, 4.809, 0, 0.6965, 1.313, 5.681, 3.474, 0, 0.5895,
2.559, 0)), .Names = c("Gossypol", "Treatment", "Damage_cm"), row.names =
c(NA, -56L), class = "data.frame")

The equation is: y~yo+a*(1-b^x) Where: y =Gossypol (from my data set) x=
Damage_cm (from my data set)

The other 3 parameters are unknown: yo=Intercept, a= assymptote ans b=slope 

In the end I would like to use the equation to plot a curve (with SE
interval, I usually use ggplot2)

Furthermore, I would like to know the R2 and p value. I would also be
interested in the parameters yo , a and b

I have never done this before and would be extremely grateful if anyone
could help me? I suppose I have to use a non linear approach (glm(...)). I
found out that the mosaic package might be helpful.

thanks a lot, Mike

 


	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Sat Aug  1 20:16:02 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sat, 01 Aug 2015 11:16:02 -0700
Subject: [R] Error when compiling R-2.5.1 / *** [d-p-q-r-tests.Rout]
 Fehler 1
In-Reply-To: <CAFEfSPcjkfmGdzsG-6HJxFKSuKzCg_djBO12VVPD23UFrRFkAw@mail.gmail.com>
References: <CAFEfSPcjkfmGdzsG-6HJxFKSuKzCg_djBO12VVPD23UFrRFkAw@mail.gmail.com>
Message-ID: <55BD0CE2.6080606@fredhutch.org>

On 07/31/2015 10:48 PM, Joerg Kirschner wrote:
> Hi everyone,
> I am new to Linux and R - but I managed to build R-2.5.1 from source to use
> it in Genepattern. Genepattern does only support R-2.5.1 which I could not
> find anywhere for installation via apt-get or in the Ubuntu Software-Centre
> (I am using Ubuntu 14.04 (Trusty Tahr) 32-bit)

Are you sure you want to do this? R 2.5.1 is from 2007, which is a very long 
time ago. It seems like GenePattern is not restricted to R-2.5.1,

 
http://www.broadinstitute.org/cancer/software/genepattern/administrators-guide#using-different-versions-of-r

and if their default distribution uses it, then I'm not sure I'd recommend using 
GenePattern for new analysis! (Maybe you're trying to re-do a previous analysis?)

Since GenePattern modules that use R typically wrap individual CRAN or 
Bioconductor (http://bioconductor.org) packages, maybe you can take out the 
middleman ?

Martin Morgan

>
> But after doing
>
> make check
>
>
> I get
>
> comparing 'method-dispatch.Rout' to './method-dispatch.Rout.save' ... OK
> running code in 'd-p-q-r-tests.R' ...make[3]: *** [d-p-q-r-tests.Rout]
> Fehler 1
> make[3]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
> make[2]: *** [test-Specific] Fehler 2
> make[2]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
> make[1]: *** [test-all-basics] Fehler 1
> make[1]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
> make: *** [check] Fehler 2
>
>
> but I can make install and use R for simple plots etc. afterwards - still I
> am worried something is wrong, can you give some advice.
>
> A closer look at the error gives
>
>> ## PR#7099 : pf() with large df1 or df2:
>> nu <- 2^seq(25,34, 0.5)
>> y <- 1e9*(pf(1,1,nu) - 0.68268949)
>> stopifnot(All.eq(pf(1,1,Inf), 0.68268949213708596),
> +           diff(y) > 0, # i.e. pf(1,1, *) is monotone increasing
> +           All.eq(y [1], -5.07420372386491),
> +           All.eq(y[19],  2.12300110824515))
> Error: All.eq(y[1], -5.07420372386491) is not TRUE
> Execution halted
>
>
> As I understand so far some errors are critical some are not - can you
> please give some advice on the error above? Can I still use R installed
> with that error? What do I need to solve the error?
>
> Thanks, Joerg
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From Martin.Spindler at gmx.de  Sat Aug  1 21:19:26 2015
From: Martin.Spindler at gmx.de (Martin Spindler)
Date: Sat, 1 Aug 2015 21:19:26 +0200
Subject: [R] R parallel / foreach - aggregation of results
In-Reply-To: <CAAxdm-7d80ZptONLfdvpfQQqY7TvrgYzgaA4xsgZD6t94TD5HA@mail.gmail.com>
References: <trinity-0f1e8231-2016-4c21-b2a6-c52882ecf380-1438346340329@3capp-gmx-bs44>,
	<CAAxdm-7d80ZptONLfdvpfQQqY7TvrgYzgaA4xsgZD6t94TD5HA@mail.gmail.com>
Message-ID: <trinity-ddf0d182-5f63-4827-a39a-e8ad192b917c-1438456766157@3capp-gmx-bs16>

Dear Jim,

Thank you very much for your response. It seems to work now, but the return value is not the required matrix but a list of matrices (one for each repition j).
Any idea how it is possible to return only the last matrix and not all?

Thanks and best,

Martin
?
?

Gesendet:?Freitag, 31. Juli 2015 um 18:22 Uhr
Von:?"jim holtman" <jholtman at gmail.com>
An:?"Martin Spindler" <Martin.Spindler at gmx.de>
Cc:?"r-help at r-project.org" <r-help at r-project.org>
Betreff:?Re: [R] R parallel / foreach - aggregation of results

Try this chance to actually return values:
?
?
library(doParallel)
Simpar3 <- function(n1) {
?? L2distance <- matrix(NA, ncol=n1, nrow=n1)
?? data <- rnorm(n1)
?? diag(L2distance)=0
?? cl <- makeCluster(4)
?? registerDoParallel(cl)
?? x <- foreach(j=1:n1)? %dopar% {
???? library(np)
???? datj <- data[j]
???? for(k in j:n1) {
?????? L2distance[j,k] <- k*datj
???? }
???? L2distance? # return the value
?? }
?? stopCluster(cl)
?? return(x)
?}
?Res <- Simpar3(100)
?

Jim Holtman
Data Munger Guru
?
What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.?
On Fri, Jul 31, 2015 at 8:39 AM, Martin Spindler <Martin.Spindler at gmx.de> wrote:Dear all,

when I am running the code attached below, it seems that no results are returned, only the predefined NAs. What mistake do I make?
Any comments and help is highly appreciated.

Thanks and best,

Martin


Simpar3 <- function(n1) {
? L2distance <- matrix(NA, ncol=n1, nrow=n1)
? data <- rnorm(n1)
? diag(L2distance)=0
? cl <- makeCluster(4)
? registerDoParallel(cl)
? foreach(j=1:n1)? %dopar% {
? ? library(np)
? ? datj <- data[j]
? ? for(k in j:n1) {
? ? ? L2distance[j,k] <- k*datj
? ? }
? }
? stopCluster(cl)
? return(L2distance)
}

Res <- Simpar3(100)

______________________________________________
R-help at r-project.org[R-help at r-project.org] mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sat Aug  1 22:49:43 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 1 Aug 2015 20:49:43 +0000
Subject: [R] Using R to fit a curve to a dataset using a specific
 equation
In-Reply-To: <000101d0cc6d$2b3e0210$81ba0630$@gmx.ch>
References: <000101d0cc6d$2b3e0210$81ba0630$@gmx.ch>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6AFEDB@mb02.ads.tamu.edu>

I can get you started, but you should really read up on non-linear least squares. Calling your data frame dta (since data is a function):

plot(Gossypol~Damage_cm, dta)
# Looking at the plot, 0 is a plausible estimate for y0:
# a+y0 is the asymptote, so estimate about 4000;
# b is between 0 and 1, so estimate .5
dta.nls <- nls(Gossypol~y0+a*(1-b^Damage_cm), dta, 
	start=list(y0=0, a=4000, b=.5))
xval <- seq(0, 10, length.out=200)
lines(xval, predict(dta.nls, data.frame(Damage_cm=xval)))
profile(dta.nls, alpha= .05)
===========================================
Number of iterations to convergence: 3 
Achieved convergence tolerance: 1.750586e-06
attr(,"summary")

Formula: Gossypol ~ y0 + a * (1 - b^Damage_cm)

Parameters:
       Estimate   Std. Error t value   Pr(>|t|)    
y0 1303.4529432  386.1515684 3.37550  0.0013853 ** 
a  2796.0464520  530.4140959 5.27144 2.5359e-06 ***
b     0.4939111    0.1809687 2.72926  0.0085950 ** 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1394.375 on 53 degrees of freedom

Number of iterations to convergence: 3 
Achieved convergence tolerance: 1.750586e-06


David Carlson
Dept of Anthropology
Texas A&M
College Station, TX  77843
________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Michael Eisenring [michael.eisenring at gmx.ch]
Sent: Saturday, August 01, 2015 10:17 AM
To: r-help at r-project.org
Subject: [R] Using R to fit a curve to a dataset using a specific equation

Hi there




I would like to use a specific equation to fit a curve to one of my data
sets (attached)

> dput(data)

structure(list(Gossypol = c(1036.331811, 4171.427741, 6039.995102,
5909.068158, 4140.242559, 4854.985845, 6982.035521, 6132.876396,
948.2418407, 3618.448997, 3130.376482, 5113.942098, 1180.171957,
1500.863038, 4576.787021, 5629.979049, 3378.151945, 3589.187889,
2508.417927, 1989.576826, 5972.926124, 2867.610671, 450.7205451, 1120.955,
3470.09352, 3575.043632, 2952.931863, 349.0864019, 1013.807628, 910.8879471,
3743.331903, 3350.203452, 592.3403778, 1517.045807, 1504.491931,
3736.144027, 2818.419785, 723.885643, 1782.864308, 1414.161257, 3723.629772,
3747.076592, 2005.919344, 4198.569251, 2228.522959, 3322.115942,
4274.324792, 720.9785449, 2874.651764, 2287.228752, 5654.858696,
1247.806111, 1247.806111, 2547.326207, 2608.716056, 1079.846532), Treatment
= structure(c(2L, 3L, 4L, 5L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 5L, 1L, 2L, 3L,
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
2L, 3L, 1L), .Label = c("C", "1c_2d", "3c_2d", "9c_2d", "1c_7d"), class =
"factor"), Damage_cm = c(0.4955, 1.516, 4.409, 3.2665, 0.491, 2.3035, 3.51,
1.8115, 0, 0.4435, 1.573, 1.8595, 0, 0.142, 2.171, 4.023, 4.9835, 0, 0.6925,
1.989, 5.683, 3.547, 0, 0.756, 2.129, 9.437, 3.211, 0, 0.578, 2.966, 4.7245,
1.8185, 0, 1.0475, 1.62, 5.568, 9.7455, 0, 0.8295, 2.411, 7.272, 4.516, 0,
0.4035, 2.974, 8.043, 4.809, 0, 0.6965, 1.313, 5.681, 3.474, 0, 0.5895,
2.559, 0)), .Names = c("Gossypol", "Treatment", "Damage_cm"), row.names =
c(NA, -56L), class = "data.frame")

The equation is: y~yo+a*(1-b^x) Where: y =Gossypol (from my data set) x=
Damage_cm (from my data set)

The other 3 parameters are unknown: yo=Intercept, a= assymptote ans b=slope

In the end I would like to use the equation to plot a curve (with SE
interval, I usually use ggplot2)

Furthermore, I would like to know the R2 and p value. I would also be
interested in the parameters yo , a and b

I have never done this before and would be extremely grateful if anyone
could help me? I suppose I have to use a non linear approach (glm(...)). I
found out that the mosaic package might be helpful.

thanks a lot, Mike




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sat Aug  1 23:15:36 2015
From: jholtman at gmail.com (jim holtman)
Date: Sat, 1 Aug 2015 17:15:36 -0400
Subject: [R] R parallel / foreach - aggregation of results
In-Reply-To: <trinity-ddf0d182-5f63-4827-a39a-e8ad192b917c-1438456766157@3capp-gmx-bs16>
References: <trinity-0f1e8231-2016-4c21-b2a6-c52882ecf380-1438346340329@3capp-gmx-bs44>
	<CAAxdm-7d80ZptONLfdvpfQQqY7TvrgYzgaA4xsgZD6t94TD5HA@mail.gmail.com>
	<trinity-ddf0d182-5f63-4827-a39a-e8ad192b917c-1438456766157@3capp-gmx-bs16>
Message-ID: <CAAxdm-5RdX1G5HwHg15S7-HCco_eQJA5sLhDwpSoa7yE1mMfzg@mail.gmail.com>

You can always just pull the last one off the list.  When running things in
parallel, what does the "last one" mean?  Do you want the last from each of
the parallel threads, or just the last one on the list?  You might want to
put some flag on the data being returned so you can determine which one you
want to process.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Aug 1, 2015 at 3:19 PM, Martin Spindler <Martin.Spindler at gmx.de>
wrote:

> Dear Jim,
>
> Thank you very much for your response. It seems to work now, but the
> return value is not the required matrix but a list of matrices (one for
> each repition j).
> Any idea how it is possible to return only the last matrix and not all?
>
> Thanks and best,
>
> Martin
>
>
>
> Gesendet: Freitag, 31. Juli 2015 um 18:22 Uhr
> Von: "jim holtman" <jholtman at gmail.com>
> An: "Martin Spindler" <Martin.Spindler at gmx.de>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Betreff: Re: [R] R parallel / foreach - aggregation of results
>
> Try this chance to actually return values:
>
>
> library(doParallel)
> Simpar3 <- function(n1) {
>    L2distance <- matrix(NA, ncol=n1, nrow=n1)
>    data <- rnorm(n1)
>    diag(L2distance)=0
>    cl <- makeCluster(4)
>    registerDoParallel(cl)
>    x <- foreach(j=1:n1)  %dopar% {
>      library(np)
>      datj <- data[j]
>      for(k in j:n1) {
>        L2distance[j,k] <- k*datj
>      }
>      L2distance  # return the value
>    }
>    stopCluster(cl)
>    return(x)
>  }
>  Res <- Simpar3(100)
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> On Fri, Jul 31, 2015 at 8:39 AM, Martin Spindler <Martin.Spindler at gmx.de>
> wrote:Dear all,
>
> when I am running the code attached below, it seems that no results are
> returned, only the predefined NAs. What mistake do I make?
> Any comments and help is highly appreciated.
>
> Thanks and best,
>
> Martin
>
>
> Simpar3 <- function(n1) {
>   L2distance <- matrix(NA, ncol=n1, nrow=n1)
>   data <- rnorm(n1)
>   diag(L2distance)=0
>   cl <- makeCluster(4)
>   registerDoParallel(cl)
>   foreach(j=1:n1)  %dopar% {
>     library(np)
>     datj <- data[j]
>     for(k in j:n1) {
>       L2distance[j,k] <- k*datj
>     }
>   }
>   stopCluster(cl)
>   return(L2distance)
> }
>
> Res <- Simpar3(100)
>
> ______________________________________________
> R-help at r-project.org[R-help at r-project.org] mailing list -- To UNSUBSCRIBE
> and more, see
>
> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Aug  1 23:17:15 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 1 Aug 2015 14:17:15 -0700
Subject: [R] R parallel / foreach - aggregation of results
In-Reply-To: <trinity-ddf0d182-5f63-4827-a39a-e8ad192b917c-1438456766157@3capp-gmx-bs16>
References: <trinity-0f1e8231-2016-4c21-b2a6-c52882ecf380-1438346340329@3capp-gmx-bs44>
	<CAAxdm-7d80ZptONLfdvpfQQqY7TvrgYzgaA4xsgZD6t94TD5HA@mail.gmail.com>
	<trinity-ddf0d182-5f63-4827-a39a-e8ad192b917c-1438456766157@3capp-gmx-bs16>
Message-ID: <CAF8bMcb9AP3h=bYpWD_oZL=GuZVm3HQh_nsobgc8RmTSDT4-+A@mail.gmail.com>

If you return just the row that the foreach procedure produces instead of
the entire matrix containing that row and use .combine=rbind then you will
end up with the matrix of interest.  E.g.,

Simpar3a <- function (n1)
{
    L2distance <- matrix(NA, ncol = n1, nrow = n1)
    data <- rnorm(n1)
    diag(L2distance) = 0
    cl <- makeCluster(4)
    registerDoParallel(cl)
    x <- foreach(j = 1:n1, .combine = rbind) %dopar% {
        library(np)
        datj <- data[j]
        rowJ <- numeric(n1)
        for (k in j:n1) {
            rowJ[k] <- k * datj
        }
        rowJ
    }
    stopCluster(cl)
    x
}


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Aug 1, 2015 at 12:19 PM, Martin Spindler <Martin.Spindler at gmx.de>
wrote:

> Dear Jim,
>
> Thank you very much for your response. It seems to work now, but the
> return value is not the required matrix but a list of matrices (one for
> each repition j).
> Any idea how it is possible to return only the last matrix and not all?
>
> Thanks and best,
>
> Martin
>
>
>
> Gesendet: Freitag, 31. Juli 2015 um 18:22 Uhr
> Von: "jim holtman" <jholtman at gmail.com>
> An: "Martin Spindler" <Martin.Spindler at gmx.de>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Betreff: Re: [R] R parallel / foreach - aggregation of results
>
> Try this chance to actually return values:
>
>
> library(doParallel)
> Simpar3 <- function(n1) {
>    L2distance <- matrix(NA, ncol=n1, nrow=n1)
>    data <- rnorm(n1)
>    diag(L2distance)=0
>    cl <- makeCluster(4)
>    registerDoParallel(cl)
>    x <- foreach(j=1:n1)  %dopar% {
>      library(np)
>      datj <- data[j]
>      for(k in j:n1) {
>        L2distance[j,k] <- k*datj
>      }
>      L2distance  # return the value
>    }
>    stopCluster(cl)
>    return(x)
>  }
>  Res <- Simpar3(100)
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> On Fri, Jul 31, 2015 at 8:39 AM, Martin Spindler <Martin.Spindler at gmx.de>
> wrote:Dear all,
>
> when I am running the code attached below, it seems that no results are
> returned, only the predefined NAs. What mistake do I make?
> Any comments and help is highly appreciated.
>
> Thanks and best,
>
> Martin
>
>
> Simpar3 <- function(n1) {
>   L2distance <- matrix(NA, ncol=n1, nrow=n1)
>   data <- rnorm(n1)
>   diag(L2distance)=0
>   cl <- makeCluster(4)
>   registerDoParallel(cl)
>   foreach(j=1:n1)  %dopar% {
>     library(np)
>     datj <- data[j]
>     for(k in j:n1) {
>       L2distance[j,k] <- k*datj
>     }
>   }
>   stopCluster(cl)
>   return(L2distance)
> }
>
> Res <- Simpar3(100)
>
> ______________________________________________
> R-help at r-project.org[R-help at r-project.org] mailing list -- To UNSUBSCRIBE
> and more, see
>
> https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Aug  2 01:16:58 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 2 Aug 2015 09:16:58 +1000
Subject: [R] missing data in R
In-Reply-To: <DUB129-W855BD620889AFC41CA328EF8890@phx.gbl>
References: <DUB129-W855BD620889AFC41CA328EF8890@phx.gbl>
Message-ID: <CA+8X3fWhsLfX8Rgk3B_AdFhSO3Ni3rXHo9OpYmEa2d9n53OOjA@mail.gmail.com>

Hi Asena,
If you already have microarray data, you can simply change some of the
existing values to NA (datum Not Available). Say you have a toy 10x10
array containing absolute (initial) values:

array_values<-matrix(sample(0:400,100,TRUE),nrow=10)
# create a 10% missing array
array_values_10<-array_values
array_values_10[sample(1:100,10)]<-NA
# next a 20% missing array
array_values_20<-array_values
array_values_20[sample(1:100,20)]<-NA
# and so on

This is possible because a matrix can be indexed as though it was a vector.

Jim


On Sat, Aug 1, 2015 at 10:21 PM, asena ay?a ?zdemir
<a.aycaozdemir at hotmail.com> wrote:
> Hello Mr. FeldesmanI am a master student in biostatistic
> my thesis about missing values in microarray data, but ? can't create any values.
> ? want to create %10, %20,...%90 missing values for all colums in microarray data set .
> Can you help me any code?
>
> thank you for your attention.
>
>
> Asena Ay?a ?zdemirMersin University Biostatistics
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cflynch at ncsu.edu  Sun Aug  2 04:51:56 2015
From: cflynch at ncsu.edu (Collin Lynch)
Date: Sat, 1 Aug 2015 22:51:56 -0400
Subject: [R] PythonInR. Python script in R with parameters required.
 Download satellite images from NASA
In-Reply-To: <CAJn2PbX8ahfRui_5d1O=XUNOur8A6fZROY68gu2u9dPWV3A-mg@mail.gmail.com>
References: <CAJn2PbX8ahfRui_5d1O=XUNOur8A6fZROY68gu2u9dPWV3A-mg@mail.gmail.com>
Message-ID: <CAE=6FXbC3zq9NsvWkRmzeS7eSuqVwdDPaL6E5USSosPaWV5hKg@mail.gmail.com>

Magi, is there a reason that you need to run the script via R? If your
plan is to download the data via python than then process with R, you
might consider using the Rpy2 package to link them.  This would allow
you to call the downloading code from python and then have python feed
the data to R.

    Collin.

On Wed, Jul 29, 2015 at 12:29 PM, Magi Franquesa
<magifranquesa at gmail.com> wrote:
> Hello,
>
> I'm trying to execute a python script within R (3.2.1 x 64) with the
> PythonInR package. I would like to download an order of satellite images
> from Nasa using a python script (
> http://landsat.usgs.gov/documents/espa_bulk_downloader_v1.0.0.zip) but I
> have no success. I first run the pyExecfile command with the *feedparser.py*
> script and then the *download_espa_order.py* giving the required parameters
> (my mail acount and the order number), here is the code:
>
> setwd("C:/Python27")
> install.packages("PythonInR")
> library(PythonInR)
> pyConnect(pythonExePath="C:/Python27/python.exe")
> pyIsConnected()
> # autodetectPython("C:/Python27/python.exe")
>
> pyExecfile("C:/Landsat/feedparser.py")
> pyExecfile("C:/Landsat/download_espa_order.py" -e "magifranquesa at gmail.com"
> -o "magifranquesa at gmail.com-07222015-120911" -d "C:/Landsat/ESPA")
>
> and I get this error:
>
> Error: unexpected string constant in
> "pyExecfile("C:/Landsat/download_espa_order.py" -e
> "magifranquesa at gmail.com""
>
> The code "C:/Landsat/download_espa_order.py" -e
> "magifranquesa at gmail.com" -o "magifranquesa at gmail.com-07222015-120911"
> -d "C:/Landsat/ESPA" runs ok when I use it within
> system console.
>
> I appreciate if someone could help me to solve this problem.
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From joerg.kirschner at gmail.com  Sun Aug  2 11:44:08 2015
From: joerg.kirschner at gmail.com (Joerg Kirschner)
Date: Sun, 2 Aug 2015 11:44:08 +0200
Subject: [R] Error when compiling R-2.5.1 / *** [d-p-q-r-tests.Rout]
 Fehler 1
In-Reply-To: <55BD0CE2.6080606@fredhutch.org>
References: <CAFEfSPcjkfmGdzsG-6HJxFKSuKzCg_djBO12VVPD23UFrRFkAw@mail.gmail.com>
	<55BD0CE2.6080606@fredhutch.org>
Message-ID: <CAFEfSPc2SrPV_V01j2GVTUa1vH9oxoSJLMJ0uaka7HiqsWXUOQ@mail.gmail.com>

Dear Martin,
thanks for the advice, I'll check out Bioconductor.

Meanwhile I reinstalled Ubuntu, this time as 64-bit and the error is gone :
)

Rgds, Joerg

On Sat, Aug 1, 2015 at 8:16 PM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 07/31/2015 10:48 PM, Joerg Kirschner wrote:
>
>> Hi everyone,
>> I am new to Linux and R - but I managed to build R-2.5.1 from source to
>> use
>> it in Genepattern. Genepattern does only support R-2.5.1 which I could not
>> find anywhere for installation via apt-get or in the Ubuntu
>> Software-Centre
>> (I am using Ubuntu 14.04 (Trusty Tahr) 32-bit)
>>
>
> Are you sure you want to do this? R 2.5.1 is from 2007, which is a very
> long time ago. It seems like GenePattern is not restricted to R-2.5.1,
>
>
>
> http://www.broadinstitute.org/cancer/software/genepattern/administrators-guide#using-different-versions-of-r
>
> and if their default distribution uses it, then I'm not sure I'd recommend
> using GenePattern for new analysis! (Maybe you're trying to re-do a
> previous analysis?)
>
> Since GenePattern modules that use R typically wrap individual CRAN or
> Bioconductor (http://bioconductor.org) packages, maybe you can take out
> the middleman ?
>
> Martin Morgan
>
>
>> But after doing
>>
>> make check
>>
>>
>> I get
>>
>> comparing 'method-dispatch.Rout' to './method-dispatch.Rout.save' ... OK
>> running code in 'd-p-q-r-tests.R' ...make[3]: *** [d-p-q-r-tests.Rout]
>> Fehler 1
>> make[3]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
>> make[2]: *** [test-Specific] Fehler 2
>> make[2]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
>> make[1]: *** [test-all-basics] Fehler 1
>> make[1]: Verzeichnis ?/home/karin/Downloads/R-2.5.1/tests? wird verlassen
>> make: *** [check] Fehler 2
>>
>>
>> but I can make install and use R for simple plots etc. afterwards - still
>> I
>> am worried something is wrong, can you give some advice.
>>
>> A closer look at the error gives
>>
>> ## PR#7099 : pf() with large df1 or df2:
>>> nu <- 2^seq(25,34, 0.5)
>>> y <- 1e9*(pf(1,1,nu) - 0.68268949)
>>> stopifnot(All.eq(pf(1,1,Inf), 0.68268949213708596),
>>>
>> +           diff(y) > 0, # i.e. pf(1,1, *) is monotone increasing
>> +           All.eq(y [1], -5.07420372386491),
>> +           All.eq(y[19],  2.12300110824515))
>> Error: All.eq(y[1], -5.07420372386491) is not TRUE
>> Execution halted
>>
>>
>> As I understand so far some errors are critical some are not - can you
>> please give some advice on the error above? Can I still use R installed
>> with that error? What do I need to solve the error?
>>
>> Thanks, Joerg
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>

	[[alternative HTML version deleted]]


From marcgg.lamblin at gmail.com  Sun Aug  2 17:10:52 2015
From: marcgg.lamblin at gmail.com (Marc Lamblin)
Date: Sun, 2 Aug 2015 17:10:52 +0200
Subject: [R] NATURAL Smoothing B-splines
Message-ID: <CABYYu7vTU1DaZ+UC7eFoQsog6NQ3ssk5RqVY4VV+s7OjvrBXJQ@mail.gmail.com>

Hi all,

I'm an engineering student from Politecnico di Milano.
I want to perform Smoothing using Smoothing B-splines on syntethic
data. The splines must be NATURAL (at the edges the second and third
order derivates are zero).
How can I impose this constraint?
I have searched in R documentation. For Smoothing I use the fda
package. From the description of the function smooth.basis() it seems
that it is not possible to use natural B-splines. I have found only
the function ns() from splines package but in this way you can obtain
only the basis and I have seen that this function is used in models
expressed in symbolic notation.

Thanks in advance!!

mggl


From Florian_Schwendinger at gmx.at  Sun Aug  2 13:01:42 2015
From: Florian_Schwendinger at gmx.at (Florian Schwendinger)
Date: Sun, 02 Aug 2015 13:01:42 +0200
Subject: [R] PythonInR. Python script in R with parameters required.
 Download satellite images from NASA
In-Reply-To: <CAJn2PbX8ahfRui_5d1O=XUNOur8A6fZROY68gu2u9dPWV3A-mg@mail.gmail.com>
References: <CAJn2PbX8ahfRui_5d1O=XUNOur8A6fZROY68gu2u9dPWV3A-mg@mail.gmail.com>
Message-ID: <55BDF896.10609@gmx.at>

I believe the Problem is that you trying to give command line arguments
pyExecfile("myPythonScript.py") and pyExecfile only expects to get a 
filename.


In Pyhton27 pyExecfile only runs the Python command execfile on the 
given filename. So the Problem is that in

pyExecfile("C:/Landsat/download_espa_order.py" -e "magifranquesa at gmail.com"
-o "magifranquesa at gmail.com-07222015-120911" -d "C:/Landsat/ESPA")

your not only providing a file name but also command line arguments.


It is maybe easier for you to use the command line. Something like the 
following should work

python <- "C:/Python27/python.exe"
pyScript <- "C:/Landsat/download_espa_order.py"
email <- "youremail at gmail.com"
order <- "youremail at gmail.com-order-number"
targetDirectory <- "C:/Landsat/ESPA"
pyArgs <- sprintf("--email %s --order %s --target_directory %s",
                   email, order, targetDirectory)
pyArgs
cmd <- sprintf("%s %s %s", python, pyScript, pyArgs)
cmd
system(cmd ,wait=FALSE)

or

system("C:/Python27/python.exe C:/Landsat/download_espa_order.py --email 
magifranquesa at gmail.com --order magifranquesa at gmail.com-07222015-120911 
--target_directory C:/Landsat/ESPA", wait=FALSE)


If you want to use PythonInR you could something like the following.
pyConnect(pythonExePath=python)
setwd("C:/Landsat/")
pyExec("import download_espa_order")
pySet("email", email)
pySet("order", order)
pyGet("[scene for scene in SceneFeed(email).get_items(order)]")


Florian


On 07/29/2015 06:29 PM, Magi Franquesa wrote:
> Hello,
>
> I'm trying to execute a python script within R (3.2.1 x 64) with the
> PythonInR package. I would like to download an order of satellite images
> from Nasa using a python script (
> http://landsat.usgs.gov/documents/espa_bulk_downloader_v1.0.0.zip) but I
> have no success. I first run the pyExecfile command with the *feedparser.py*
> script and then the *download_espa_order.py* giving the required parameters
> (my mail acount and the order number), here is the code:
>
> setwd("C:/Python27")
> install.packages("PythonInR")
> library(PythonInR)
> pyConnect(pythonExePath="C:/Python27/python.exe")
> pyIsConnected()
> # autodetectPython("C:/Python27/python.exe")
>
> pyExecfile("C:/Landsat/feedparser.py")
> pyExecfile("C:/Landsat/download_espa_order.py" -e "magifranquesa at gmail.com"
> -o "magifranquesa at gmail.com-07222015-120911" -d "C:/Landsat/ESPA")
>
> and I get this error:
>
> Error: unexpected string constant in
> "pyExecfile("C:/Landsat/download_espa_order.py" -e
> "magifranquesa at gmail.com""
>
> The code "C:/Landsat/download_espa_order.py" -e
> "magifranquesa at gmail.com" -o "magifranquesa at gmail.com-07222015-120911"
> -d "C:/Landsat/ESPA" runs ok when I use it within
> system console.
>
> I appreciate if someone could help me to solve this problem.
>
> Thank you
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From spencer.graves at effectivedefense.org  Sun Aug  2 17:21:58 2015
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sun, 2 Aug 2015 10:21:58 -0500
Subject: [R] NATURAL Smoothing B-splines
In-Reply-To: <CABYYu7vTU1DaZ+UC7eFoQsog6NQ3ssk5RqVY4VV+s7OjvrBXJQ@mail.gmail.com>
References: <CABYYu7vTU1DaZ+UC7eFoQsog6NQ3ssk5RqVY4VV+s7OjvrBXJQ@mail.gmail.com>
Message-ID: <55BE3596.6060808@effectivedefense.org>

 > library(sos)
 > ns. <- findFn('natural spline')
found 191 matches;  retrieving 10 pages
2 3 4 5 6 7 8 9 10
Downloaded 113 links in 70 packages.
 > ns2 <- findFn('natural splines')
found 145 matches;  retrieving 8 pages
2 3 4 5 6 7 8
Downloaded 70 links in 42 packages.
 > ns2. <- ns.|ns2
 > ns2.

# This displayed a table of 137 different help pages sorted to place the 
package with the most matches first.

 > findFn2xls(ns2.) # writes a file with a name like "nls2..xls" to the 
working directory [getwd()]
# with a sheet giving a summary by package.


       Hope this helps.
       Spencer


On 8/2/2015 10:10 AM, Marc Lamblin wrote:
> Hi all,
>
> I'm an engineering student from Politecnico di Milano.
> I want to perform Smoothing using Smoothing B-splines on syntethic
> data. The splines must be NATURAL (at the edges the second and third
> order derivates are zero).
> How can I impose this constraint?
> I have searched in R documentation. For Smoothing I use the fda
> package. From the description of the function smooth.basis() it seems
> that it is not possible to use natural B-splines. I have found only
> the function ns() from splines package but in this way you can obtain
> only the basis and I have seen that this function is used in models
> expressed in symbolic notation.
>
> Thanks in advance!!
>
> mggl
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Mon Aug  3 06:05:24 2015
From: syen04 at gmail.com (Steven Yen)
Date: Mon, 3 Aug 2015 00:05:24 -0400
Subject: [R] Splitting lines in R script
Message-ID: <CAKTtY6QVtaCb5_LxuuXThH2LE3KCJw81+8JAUvHcZmpL5spdag@mail.gmail.com>

I have a line containing summation of four components.

# This works OK:
  p<-pbivnorm(bb,dd,tau)+pbivnorm(aa,cc,tau)-
    -pbivnorm(aa,dd,tau)-pbivnorm(bb,cc,tau)

# This produces unpredicted results without warning:
  p<-pbivnorm(bb,dd,tau)+pbivnorm(aa,cc,tau)
    -pbivnorm(aa,dd,tau)-pbivnorm(bb,cc,tau)

Is there a general rule of thumb for line breaks? Thanks you.

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Mon Aug  3 06:26:07 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Sun, 2 Aug 2015 21:26:07 -0700
Subject: [R] Splitting lines in R script
In-Reply-To: <CAKTtY6QVtaCb5_LxuuXThH2LE3KCJw81+8JAUvHcZmpL5spdag@mail.gmail.com>
References: <CAKTtY6QVtaCb5_LxuuXThH2LE3KCJw81+8JAUvHcZmpL5spdag@mail.gmail.com>
Message-ID: <CA+hbrhUGzuCiA=7M=3cART4h-+BeqN0fv16NVwJe=wDVwPVc8g@mail.gmail.com>

R does not need a semicolon or other character to terminate a command;
if a line can be interpreted as a complete command, it will (first
line in your second example).

Also note that the first example may not produce what you want (if
your second example is any indication) - the result of
pbivnorm(aa,dd,tau) is added to the sum of the first two terms,
because the two minuses give a plus:

> 1- -1
[1] 2

Peter

On Sun, Aug 2, 2015 at 9:05 PM, Steven Yen <syen04 at gmail.com> wrote:
> I have a line containing summation of four components.
>
> # This works OK:
>   p<-pbivnorm(bb,dd,tau)+pbivnorm(aa,cc,tau)-
>     -pbivnorm(aa,dd,tau)-pbivnorm(bb,cc,tau)
>
> # This produces unpredicted results without warning:
>   p<-pbivnorm(bb,dd,tau)+pbivnorm(aa,cc,tau)
>     -pbivnorm(aa,dd,tau)-pbivnorm(bb,cc,tau)
>
> Is there a general rule of thumb for line breaks? Thanks you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jjthaden at flash.net  Mon Aug  3 06:42:16 2015
From: jjthaden at flash.net (John Thaden)
Date: Mon, 3 Aug 2015 04:42:16 +0000 (UTC)
Subject: [R] vectorized sub, gsub, grep, etc.
In-Reply-To: <CAHEemWY3BunEfAeXFvtNmDRtgWZ7FkHMdAOEsUG+X9saZngJow@mail.gmail.com>
References: <CAHEemWY3BunEfAeXFvtNmDRtgWZ7FkHMdAOEsUG+X9saZngJow@mail.gmail.com>
Message-ID: <2112067897.405511.1438576936391.JavaMail.yahoo@mail.yahoo.com>

Adam,
The original posting gave a function sub2 whose aim differs both from your functions' aim and from the intent of mgsub() in the qdap package:
> Here is code to apply a different 
> pattern and replacement for every target.    #Example
    X <- c("ab", "cd", "ef")
    patt <- c("b", "cd", "a")
    repl <- c("B", "CD", "A")
The first pattern ('b') and the first replacement ('B') therefore apply only to the first target ('ab'), the second to the second, etc. The function achieves its aim, giving the correct answer 'aB', 'CD', 'ef'.

mgsub() satisfies a different need, testing all targets for matches with any pattern in the vector of patterns and, if a match is found, replacing the matched target with the replacement value corresponding to the matched pattern. It, too, achieves its aim, giving a different (but also correct) answer 'AB', 'CD', 'ef'.
Regards,-John
    #Example
    X <- c("ab", "cd", "ef")
    patt <- c("b", "cd", "a")
    repl <- c("B", "CD", "A")

	[[alternative HTML version deleted]]


From sibylle.stoeckli at gmx.ch  Mon Aug  3 10:24:15 2015
From: sibylle.stoeckli at gmx.ch (=?iso-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Mon, 3 Aug 2015 10:24:15 +0200
Subject: [R] NCDF_arrays
Message-ID: <5593B006-FAC7-45F0-9746-7796625C7AFF@gmx.ch>

Dear R-users

I am working with ncdf data using the variables time (1-365), lon (longitude), lat (latitude) and the Temperature variable  daily). After setting the parameters for the model, I am able to calculate the output for each lon-lat grid point. The model works well including one ncdf file (TabsD29) (1). Now I want to include more than one ncdf file (2). Alls the ncdf files have the same variables with exception of the temperature variable. However, I get the output "wrong arrays".  I think may suggestion to calculate the mean is wrong? 

Many thanks
Sibylle


 nlon <- length(lon)
 nlat <- length(lat)
 nday <- length(TabsD29[1,1,])

 Tmin     <- 10.
 GDDmax   <- 145
 DOYstart <- 1
 
 (1)
 Teffs   <- pmax(TabsD29 - Tmin, array(0., dim=c(nlon, nlat, nday))) 

(2)

 
 Teff   <- pmax(mean(as.numeric(TabsD80+TabsD81+TabsD82+TabsD83+TabsD84+TabsD85+TabsD86+TabsD87+TabsD88+TabsD89+TabsD90+TabsD91+TabsD92+TabsD93+TabsD94+TabsD95+TabsD96+TabsD97+TabsD98+TabsD99+TabsD20+TabsD21+TabsD22+TabsD23+TabsD24+TabsD25+TabsD26+TabsD27+TabsD28+TabsD29)) - Tmin, array(0., dim=c(nlon, nlat, nday)), na.rm=TRUE) 
	[[alternative HTML version deleted]]


From adam.michael.erickson at gmail.com  Mon Aug  3 10:30:22 2015
From: adam.michael.erickson at gmail.com (Adam Erickson)
Date: Mon, 3 Aug 2015 01:30:22 -0700
Subject: [R] vectorized sub, gsub, grep, etc.
In-Reply-To: <2112067897.405511.1438576936391.JavaMail.yahoo@mail.yahoo.com>
References: <CAHEemWY3BunEfAeXFvtNmDRtgWZ7FkHMdAOEsUG+X9saZngJow@mail.gmail.com>
	<2112067897.405511.1438576936391.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAHEemWYwQMES0_MXYpe=L2eGgN3vfPZdDXwJX+vRXs0sQ2jYDw@mail.gmail.com>

Interesting. I know of no practical use for such a function. If the first
position were 'abb,' sub() would return 'aBb,' failing to replace the
second 'b.' I find it hard to believe that's the desired functionality.
Writing a looped regex function in Rcpp makes the most sense for speed.
Using Boost C++ library regex (link
<http://gallery.rcpp.org/articles/boost-regular-expressions/>) or a C++
wrapper for PCRE (link <https://gist.github.com/abicky/58ea79b01d9e394d5076>)
are two solutions, but pure Rcpp would be ideal to avoid external software
dependencies.

Cheers,

Adam

On Sun, Aug 2, 2015 at 9:42 PM, John Thaden <jjthaden at flash.net> wrote:

> Adam,
>
> The original posting gave a function sub2 whose aim differs both from your
> functions' aim and from the intent of mgsub() in the qdap package:
>
> > Here is code to apply a different
> > pattern and replacement for every target.
>
>     #Example
>     X <- c("ab", "cd", "ef")
>     patt <- c("b", "cd", "a")
>     repl <- c("B", "CD", "A")
>
> The first pattern ('b') and the first replacement ('B') therefore apply
> only to the first target ('ab'), the second to the second, etc. The
> function achieves its aim, giving the correct answer 'aB', 'CD', 'ef'.
>
> mgsub() satisfies a different need, testing all targets for matches with
> any pattern in the vector of patterns and, if a match is found, replacing
> the matched target with the replacement value corresponding to the matched
> pattern. It, too, achieves its aim, giving a different (but also correct)
> answer 'AB', 'CD', 'ef'.
>
> Regards,
> -John
>
>     #Example
>     X <- c("ab", "cd", "ef")
>     patt <- c("b", "cd", "a")
>     repl <- c("B", "CD", "A")
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Aug  3 11:11:07 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 3 Aug 2015 19:11:07 +1000
Subject: [R] Splitting lines in R script
In-Reply-To: <CA+hbrhUGzuCiA=7M=3cART4h-+BeqN0fv16NVwJe=wDVwPVc8g@mail.gmail.com>
References: <CAKTtY6QVtaCb5_LxuuXThH2LE3KCJw81+8JAUvHcZmpL5spdag@mail.gmail.com>
	<CA+hbrhUGzuCiA=7M=3cART4h-+BeqN0fv16NVwJe=wDVwPVc8g@mail.gmail.com>
Message-ID: <CA+8X3fXfDtOYJLmY4rjmFY4wFmS7Wg7k-sqKGUf3ju=3JrTOPg@mail.gmail.com>

Hi Steven,
In general, the command line must be incomplete (in your case, a
trailing hyphen) for the interpreter to take the next line as a
continuation.

Jim


 On Sun, Aug 2, 2015 at 9:05 PM, Steven Yen <syen04 at gmail.com> wrote:
> I have a line containing summation of four components.
>
> # This works OK:
>   p<-pbivnorm(bb,dd,tau)+pbivnorm(aa,cc,tau)-
>     -pbivnorm(aa,dd,tau)-pbivnorm(bb,cc,tau)
>
> # This produces unpredicted results without warning:
>   p<-pbivnorm(bb,dd,tau)+pbivnorm(aa,cc,tau)
>     -pbivnorm(aa,dd,tau)-pbivnorm(bb,cc,tau)
>
> Is there a general rule of thumb for line breaks? Thanks you.
>


From wewolski at gmail.com  Mon Aug  3 11:25:23 2015
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 3 Aug 2015 11:25:23 +0200
Subject: [R] Faster text search in document database than with grep?
Message-ID: <CAAjnpdjTGQia4FR+Qiamgj0XkCrMSr68r7ZSAYmSn8Y9g_S42w@mail.gmail.com>

I have a database of text documents (letter sequences). Several thousands
of documents with approx. 1000-2000 letters each.

I need to find exact matches of short 3-15 letters sequences in those
documents.

Without any regexp patterns the search of one 3-15 letter "words" takes in
the order of 1s.

So for a database with several thousand documents it's an the order of
hours.
The naive approach would be to use mcmapply, but than on a standard
hardware I am still in the same order and since R is an interactive
programming environment this isn't a solution I would go for.

But aren't there faster algorithmic solutions? Can anyone point me please
to an implementation  available in R.

Thank you
Witold




-- 
Witold Eryk Wolski

	[[alternative HTML version deleted]]


From marcgg.lamblin at gmail.com  Mon Aug  3 12:54:57 2015
From: marcgg.lamblin at gmail.com (Marc Lamblin)
Date: Mon, 3 Aug 2015 12:54:57 +0200
Subject: [R] Natural Smoothing B-splines
Message-ID: <CABYYu7s5UeJPFaLaS6X9Unrs2ddXkz6isr0b1rN3g=5UtOk5oQ@mail.gmail.com>

More effective search with respect to browsing or digging manually
into the documentation. Almost surely I'll find what I need!

Thanks very much

mggl


From murdoch.duncan at gmail.com  Mon Aug  3 15:13:37 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 03 Aug 2015 09:13:37 -0400
Subject: [R] Faster text search in document database than with grep?
In-Reply-To: <CAAjnpdjTGQia4FR+Qiamgj0XkCrMSr68r7ZSAYmSn8Y9g_S42w@mail.gmail.com>
References: <CAAjnpdjTGQia4FR+Qiamgj0XkCrMSr68r7ZSAYmSn8Y9g_S42w@mail.gmail.com>
Message-ID: <55BF6901.7010402@gmail.com>

On 03/08/2015 5:25 AM, Witold E Wolski wrote:
> I have a database of text documents (letter sequences). Several thousands
> of documents with approx. 1000-2000 letters each.
> 
> I need to find exact matches of short 3-15 letters sequences in those
> documents.
> 
> Without any regexp patterns the search of one 3-15 letter "words" takes in
> the order of 1s.
> 
> So for a database with several thousand documents it's an the order of
> hours.
> The naive approach would be to use mcmapply, but than on a standard
> hardware I am still in the same order and since R is an interactive
> programming environment this isn't a solution I would go for.
> 
> But aren't there faster algorithmic solutions? Can anyone point me please
> to an implementation  available in R.

You haven't shown us what you did, but it sounds far slower than I'd
expect.  I just used the code below to set up a database of 10000
documents of 2000 letters each, and searching those documents for "abc"
takes about 70 milliseconds:

database <- replicate(10000, paste(sample(letters, 2000, rep=TRUE),
collapse=""))

grep("abc", database, fixed=TRUE)

Duncan Murdoch


From petr.pikal at precheza.cz  Mon Aug  3 15:04:42 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 3 Aug 2015 13:04:42 +0000
Subject: [R] About nls.
In-Reply-To: <CAJ7mryKbrDA_H2gdX1=qHa3Qumzh-0b+chQpqy-GYh11VPzf6A@mail.gmail.com>
References: <CAJ7mryJzSkM6NpP2J5dO3wZZ1--VEO-w4CZsrujFKWFyEs29jQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C38602@SRVEXCHMBX.precheza.cz>
	<CAJ7mryKbrDA_H2gdX1=qHa3Qumzh-0b+chQpqy-GYh11VPzf6A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C389A0@SRVEXCHMBX.precheza.cz>

Hi

Please keep conversation on list somebody can have better idea. Other see in line.


> -----Original Message-----
> From: Jianling Fan [mailto:fanjianling at gmail.com]
> Sent: Friday, July 31, 2015 4:46 PM
> To: PIKAL Petr
> Subject: Re: [R] About nls.
>
> Hello, Petr,
>
> Thanks for your help.
> That works but it change my model. And I think that's not the main
> problem.
> from my data, (den1/R1+den2+den3+den4+den5/R5) always <1, which makes
> (1/(den1/R1+den2+den3+den4+den5/R5)-1)>0.

It is not true unless I have different data from yours.

> with(dat,(den1/0.9+den2+den3+den4+den5/23))
 [1]  0.4655556  0.7472222  0.9755556  1.0733333  1.1100000  0.3800000
 [7]  0.4800000  0.8500000  0.8800000  1.0000000  0.4800000  0.8900000
[13]  0.9800000  0.9900000  1.0000000  0.2000000  0.3900000  0.6900000
[19]  0.9900000  1.0000000  6.0652174  9.9065217 13.3434783 16.5782609
[25] 18.8021739 19.8130435

> with(dat,(1/(den1/.9+den2+den3+den4+den5/23)-1)>0)
 [1]  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE
[13]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
[25] FALSE FALSE
>

> str(dat)
'data.frame':   26 obs. of  7 variables:
 $ Depth: int  20 40 60 80 100 15 30 45 60 120 ...
 $ lnd  : num  3 3.69 4.09 4.38 4.61 ...
 $ den1 : num  0.419 0.672 0.878 0.966 0.999 ...
 $ den2 : num  0 0 0 0 0 0.38 0.48 0.85 0.88 1 ...
 $ den3 : num  0 0 0 0 0 0 0 0 0 0 ...
 $ den4 : num  0 0 0 0 0 0 0 0 0 0 ...
 $ den5 : num  0 0 0 0 0 0 0 0 0 0 ...
>

> dput(dat)
structure(list(Depth = c(20L, 40L, 60L, 80L, 100L, 15L, 30L,
45L, 60L, 120L, 15L, 30L, 45L, 60L, 120L, 15L, 30L, 45L, 60L,
120L, 10L, 30L, 50L, 70L, 90L, 110L), lnd = c(2.995732, 3.688879,
4.094345, 4.382027, 4.60517, 2.70805, 3.401197, 3.806662, 4.094345,
4.787492, 2.70805, 3.401197, 3.806662, 4.094345, 4.787492, 2.70805,
3.401197, 3.806662, 4.094345, 4.787492, 2.302585, 3.401197, 3.912023,
4.248495, 4.49981, 4.70048), den1 = c(0.419, 0.6725, 0.878, 0.966,
0.999, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0), den2 = c(0, 0, 0, 0, 0, 0.38, 0.48, 0.85, 0.88, 1,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), den3 = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0.48, 0.89, 0.98, 0.99, 1, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0), den4 = c(0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0.2, 0.39, 0.69, 0.99, 1, 0, 0, 0, 0, 0, 0),
    den5 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 139.5, 227.85, 306.9, 381.3, 432.45, 455.7)), .Names = c("Depth",
"lnd", "den1", "den2", "den3", "den4", "den5"), class = "data.frame", row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
"14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
"25", "26"))
>

You can check if this is the same as you have. That is why it is preferable to use dput for sending data.

Cheers
Petr


> So, the nls should work in this case. But I don't know why it does not.
>
> Thanks!
>
>  Regards,
>
> Julian
>
>
>
> On 31 July 2015 at 00:54, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > Hi
> >
> > I am not an expert but the problem seems to me that
> >
> > (den1/R1+den2+den3+den4+den5/R5)-1
> >
> > gives you sometimes value 0 and sometimes negative. In these cases
> the value of log(1/result) is NA or Inf and nls can not handle this.
> >
> > I do not search vhere is nls2 from so I used nls and removed -1 form
> your formula, which resulted to some final values.
> >
> >> fit1<-nls(lnd~log(1/(den1/R1+den2+den3+den4+den5/R5))/c+log(d50),
> > + start=c(R1=0.9, R5=23, c=-1.1, d50=10), data=test)
> >>
> >> coef(fit)
> >          A          B
> >  6.9720965 -0.0272203
> >> coef(fit1)
> >          R1          R5           c         d50
> >   0.9622249 416.1272498  -0.7178156  73.6017161
> >>
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> Jianling Fan
> >> Sent: Thursday, July 30, 2015 9:51 PM
> >> To: r-help at r-project.org
> >> Subject: [R] About nls.
> >>
> >> Hello,
> >>
> >> I am trying to do a nls regression with R.  but I always get a error
> >> as "Error in numericDeriv(form[[3L]], names(ind), env) :  Missing
> >> value or an infinity produced when evaluating the model".  I googled
> >> it and found someone said it is because of the improper start value.
> >> I tried many times but can not solve it. Does anyone can help me?
> >>
> >> thanks a lot !
> >>
> >> my code is:
> >>
> >> fit1<-nls2(lnd~log(1/(den1/R1+den2+den3+den4+den5/R5)-1)/c+log(d50),
> >>               start=c(R1=0.9, R5=23, c=-1.1, d50=10), data=SWrt)
> >>
> >> data (SWrt) is:
> >>
> >>   Depth      lnd   den1 den2 den3 den4   den5
> >> 1     20 2.995732 0.4190 0.00 0.00 0.00   0.00
> >> 2     40 3.688879 0.6725 0.00 0.00 0.00   0.00
> >> 3     60 4.094345 0.8780 0.00 0.00 0.00   0.00
> >> 4     80 4.382027 0.9660 0.00 0.00 0.00   0.00
> >> 5    100 4.605170 0.9990 0.00 0.00 0.00   0.00
> >> 6     15 2.708050 0.0000 0.38 0.00 0.00   0.00
> >> 7     30 3.401197 0.0000 0.48 0.00 0.00   0.00
> >> 8     45 3.806662 0.0000 0.85 0.00 0.00   0.00
> >> 9     60 4.094345 0.0000 0.88 0.00 0.00   0.00
> >> 10   120 4.787492 0.0000 1.00 0.00 0.00   0.00
> >> 11    15 2.708050 0.0000 0.00 0.48 0.00   0.00
> >> 12    30 3.401197 0.0000 0.00 0.89 0.00   0.00
> >> 13    45 3.806662 0.0000 0.00 0.98 0.00   0.00
> >> 14    60 4.094345 0.0000 0.00 0.99 0.00   0.00
> >> 15   120 4.787492 0.0000 0.00 1.00 0.00   0.00
> >> 16    15 2.708050 0.0000 0.00 0.00 0.20   0.00
> >> 17    30 3.401197 0.0000 0.00 0.00 0.39   0.00
> >> 18    45 3.806662 0.0000 0.00 0.00 0.69   0.00
> >> 19    60 4.094345 0.0000 0.00 0.00 0.99   0.00
> >> 20   120 4.787492 0.0000 0.00 0.00 1.00   0.00
> >> 21    10 2.302585 0.0000 0.00 0.00 0.00 139.50
> >> 22    30 3.401197 0.0000 0.00 0.00 0.00 227.85
> >> 23    50 3.912023 0.0000 0.00 0.00 0.00 306.90
> >> 24    70 4.248495 0.0000 0.00 0.00 0.00 381.30
> >> 25    90 4.499810 0.0000 0.00 0.00 0.00 432.45
> >> 26   110 4.700480 0.0000 0.00 0.00 0.00 455.70
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From wewolski at gmail.com  Mon Aug  3 15:45:30 2015
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 3 Aug 2015 15:45:30 +0200
Subject: [R] Faster text search in document database than with grep?
In-Reply-To: <55BF6901.7010402@gmail.com>
References: <CAAjnpdjTGQia4FR+Qiamgj0XkCrMSr68r7ZSAYmSn8Y9g_S42w@mail.gmail.com>
	<55BF6901.7010402@gmail.com>
Message-ID: <CAAjnpdjPxhrf4iM2XO89OHnyLSf0iw=0abs0xb0ghW3SD5wCvA@mail.gmail.com>

Dear Duncan,

This is a model of the data I work with.

database <- replicate(50000, paste(sample(letters,rexp(1,1/500), rep=TRUE),
                                   collapse=""))

words <- replicate(10000,paste(sample(letters,rexp(1,1/70), rep=TRUE),
                                       collapse=""))

NumberOfWords <- 10
system.time(lapply(words[1: NumberOfWords], grep, database))
   user  system elapsed
  5.002   0.003   5.005

 The model reproduces the running times I have to cope with.

To use grep in this context is rather naive and I am wondering if there are
better solutions availabe in R.



On 3 August 2015 at 15:13, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 03/08/2015 5:25 AM, Witold E Wolski wrote:
> > I have a database of text documents (letter sequences). Several thousands
> > of documents with approx. 1000-2000 letters each.
> >
> > I need to find exact matches of short 3-15 letters sequences in those
> > documents.
> >
> > Without any regexp patterns the search of one 3-15 letter "words" takes
> in
> > the order of 1s.
> >
> > So for a database with several thousand documents it's an the order of
> > hours.
> > The naive approach would be to use mcmapply, but than on a standard
> > hardware I am still in the same order and since R is an interactive
> > programming environment this isn't a solution I would go for.
> >
> > But aren't there faster algorithmic solutions? Can anyone point me please
> > to an implementation  available in R.
>
> You haven't shown us what you did, but it sounds far slower than I'd
> expect.  I just used the code below to set up a database of 10000
> documents of 2000 letters each, and searching those documents for "abc"
> takes about 70 milliseconds:
>
> database <- replicate(10000, paste(sample(letters, 2000, rep=TRUE),
> collapse=""))
>
> grep("abc", database, fixed=TRUE)
>
> Duncan Murdoch
>



-- 
Witold Eryk Wolski

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Aug  3 16:40:59 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 3 Aug 2015 14:40:59 +0000
Subject: [R] Using R to fit a curve to a dataset using a specific
 equation
In-Reply-To: <trinity-eb49071f-0879-4466-b2a7-d932b8c82d52-1438468354416@3capp-gmx-bs63>
References: <000101d0cc6d$2b3e0210$81ba0630$@gmx.ch>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6AFEDB@mb02.ads.tamu.edu>
	<trinity-eb49071f-0879-4466-b2a7-d932b8c82d52-1438468354416@3capp-gmx-bs63>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B0B32@mb02.ads.tamu.edu>

Use Reply-All to keep the discussion on the list.

I suggested reading about nls (not just how to do it in R) because you requested R2. It was not clear that you were aware that there are strong reasons to suspect that R2 is misleading when applied nls results. That is why nls() does not provide it automatically.

But R2 is easily computed from the model results:

GossSS <- sum((dta$Gossypol - mean(dta$Gossypol))^2)
R2 <- deviance(dta.nls)/GossSS
R2
[1] 0.6318866

As for ggplot, just add the line we created before to the points plot:

library(ggplot)
xval <- seq(0, 10, length.out=200)
yval <- predict(dta.nls, data.frame(Damage_cm=xval))
ggplot() + geom_point(data=dta, aes(x=Damage_cm, y=Gossypol)) + 
	geom_line(aes(x=xval, y=yval))


David Carlson

From: Michael Eisenring [mailto:Michael.Eisenring at gmx.ch] 
Sent: Saturday, August 1, 2015 5:33 PM
To: David L Carlson
Subject: Aw: RE: [R] Using R to fit a curve to a dataset using a specific equation

Hello and thank you very much for your help!
I just started to read up on non-linear least squares in The RBook. (I am totally new to the topic so i dindt even know where to look in the book ).
I have three last questions:
?
In the Rbook they say how to describe a model. In my case it would be something like:
?The model y ~ y0 + a * (1 - b^x)
had y0= 1303.45 ( 386.15 standard error), a=.... and b=....
The model explained ??% of the total variation in y
?
My question is were do I find the %age of total variation the model explains. it does not say that in the book.
Is there something similar as a R^2 value or a p-value?
?
My last question: is it possible to use ggplot2 for plotting the whole model?
?
Thanks a lot.
Mike
?
? 
Gesendet:?Samstag, 01. August 2015 um 13:49 Uhr
Von:?"David L Carlson" <dcarlson at tamu.edu>
An:?"Michael Eisenring" <michael.eisenring at gmx.ch>, "r-help at r-project.org" <r-help at r-project.org>
Betreff:?RE: [R] Using R to fit a curve to a dataset using a specific equation
I can get you started, but you should really read up on non-linear least squares. Calling your data frame dta (since data is a function):

plot(Gossypol~Damage_cm, dta)
# Looking at the plot, 0 is a plausible estimate for y0:
# a+y0 is the asymptote, so estimate about 4000;
# b is between 0 and 1, so estimate .5
dta.nls <- nls(Gossypol~y0+a*(1-b^Damage_cm), dta,
start=list(y0=0, a=4000, b=.5))
xval <- seq(0, 10, length.out=200)
lines(xval, predict(dta.nls, data.frame(Damage_cm=xval)))
profile(dta.nls, alpha= .05)
===========================================
Number of iterations to convergence: 3
Achieved convergence tolerance: 1.750586e-06
attr(,"summary")

Formula: Gossypol ~ y0 + a * (1 - b^Damage_cm)

Parameters:
Estimate Std. Error t value Pr(>|t|)
y0 1303.4529432 386.1515684 3.37550 0.0013853 **
a 2796.0464520 530.4140959 5.27144 2.5359e-06 ***
b 0.4939111 0.1809687 2.72926 0.0085950 **
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1394.375 on 53 degrees of freedom

Number of iterations to convergence: 3
Achieved convergence tolerance: 1.750586e-06


David Carlson
Dept of Anthropology
Texas A&M
College Station, TX 77843
________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Michael Eisenring [michael.eisenring at gmx.ch]
Sent: Saturday, August 01, 2015 10:17 AM
To: r-help at r-project.org
Subject: [R] Using R to fit a curve to a dataset using a specific equation

Hi there




I would like to use a specific equation to fit a curve to one of my data
sets (attached)

> dput(data)

structure(list(Gossypol = c(1036.331811, 4171.427741, 6039.995102,
5909.068158, 4140.242559, 4854.985845, 6982.035521, 6132.876396,
948.2418407, 3618.448997, 3130.376482, 5113.942098, 1180.171957,
1500.863038, 4576.787021, 5629.979049, 3378.151945, 3589.187889,
2508.417927, 1989.576826, 5972.926124, 2867.610671, 450.7205451, 1120.955,
3470.09352, 3575.043632, 2952.931863, 349.0864019, 1013.807628, 910.8879471,
3743.331903, 3350.203452, 592.3403778, 1517.045807, 1504.491931,
3736.144027, 2818.419785, 723.885643, 1782.864308, 1414.161257, 3723.629772,
3747.076592, 2005.919344, 4198.569251, 2228.522959, 3322.115942,
4274.324792, 720.9785449, 2874.651764, 2287.228752, 5654.858696,
1247.806111, 1247.806111, 2547.326207, 2608.716056, 1079.846532), Treatment
= structure(c(2L, 3L, 4L, 5L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 5L, 1L, 2L, 3L,
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
2L, 3L, 1L), .Label = c("C", "1c_2d", "3c_2d", "9c_2d", "1c_7d"), class =
"factor"), Damage_cm = c(0.4955, 1.516, 4.409, 3.2665, 0.491, 2.3035, 3.51,
1.8115, 0, 0.4435, 1.573, 1.8595, 0, 0.142, 2.171, 4.023, 4.9835, 0, 0.6925,
1.989, 5.683, 3.547, 0, 0.756, 2.129, 9.437, 3.211, 0, 0.578, 2.966, 4.7245,
1.8185, 0, 1.0475, 1.62, 5.568, 9.7455, 0, 0.8295, 2.411, 7.272, 4.516, 0,
0.4035, 2.974, 8.043, 4.809, 0, 0.6965, 1.313, 5.681, 3.474, 0, 0.5895,
2.559, 0)), .Names = c("Gossypol", "Treatment", "Damage_cm"), row.names =
c(NA, -56L), class = "data.frame")

The equation is: y~yo+a*(1-b^x) Where: y =Gossypol (from my data set) x=
Damage_cm (from my data set)

The other 3 parameters are unknown: yo=Intercept, a= assymptote ans b=slope

In the end I would like to use the equation to plot a curve (with SE
interval, I usually use ggplot2)

Furthermore, I would like to know the R2 and p value. I would also be
interested in the parameters yo , a and b

I have never done this before and would be extremely grateful if anyone
could help me? I suppose I have to use a non linear approach (glm(...)). I
found out that the mosaic package might be helpful.

thanks a lot, Mike




[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jgrn at illinois.edu  Mon Aug  3 17:19:32 2015
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Mon, 03 Aug 2015 15:19:32 +0000
Subject: [R] R command to open a file "browser" on Windows and Mac?
Message-ID: <CABG0rfsiYfnw8yHGuZRQY69O8We+qaPQ3tfOjtN-2dY0=qu8cg@mail.gmail.com>

Folks:

Is there an easy function to open a finder window (on mac) or windows
explorer window (on windows) given an input folder?  A lot of times I want
to be able to see via a file browser my working directory.  Is there a good
R hack to do this?

--j

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Aug  3 17:27:25 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 03 Aug 2015 11:27:25 -0400
Subject: [R] R command to open a file "browser" on Windows and Mac?
In-Reply-To: <CABG0rfsiYfnw8yHGuZRQY69O8We+qaPQ3tfOjtN-2dY0=qu8cg@mail.gmail.com>
References: <CABG0rfsiYfnw8yHGuZRQY69O8We+qaPQ3tfOjtN-2dY0=qu8cg@mail.gmail.com>
Message-ID: <55BF885D.9070206@gmail.com>

On 03/08/2015 11:19 AM, Jonathan Greenberg wrote:
> Folks:
> 
> Is there an easy function to open a finder window (on mac) or windows
> explorer window (on windows) given an input folder?  A lot of times I want
> to be able to see via a file browser my working directory.  Is there a good
> R hack to do this?

On Windows, shell.exec(dir) will open Explorer at that directory.
(It'll do something else if dir isn't a directory name, or has spaces in
it without quotes, so you need to be a little careful.)

On OSX, system2("open", dir) should do the same.

Duncan Murdoch


From msharp at txbiomed.org  Mon Aug  3 17:29:16 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 3 Aug 2015 15:29:16 +0000
Subject: [R] R command to open a file "browser" on Windows and Mac?
In-Reply-To: <CABG0rfsiYfnw8yHGuZRQY69O8We+qaPQ3tfOjtN-2dY0=qu8cg@mail.gmail.com>
References: <CABG0rfsiYfnw8yHGuZRQY69O8We+qaPQ3tfOjtN-2dY0=qu8cg@mail.gmail.com>
Message-ID: <FB2A5ED4-A456-4902-9DAE-3A63239C2707@txbiomed.org>

Set your path with setwd(?my_path?) and then use file.choose().

You could have gotten this information sooner with a simple online search.

Mark
R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Aug 3, 2015, at 10:19 AM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> 
> Folks:
> 
> Is there an easy function to open a finder window (on mac) or windows
> explorer window (on windows) given an input folder?  A lot of times I want
> to be able to see via a file browser my working directory.  Is there a good
> R hack to do this?
> 
> --j
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw1958 at gmail.com  Mon Aug  3 17:55:07 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Mon, 3 Aug 2015 11:55:07 -0400
Subject: [R] Households per Census block
Message-ID: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>

Folks,

I am using the UScensus2010 package and I am trying to figure out the number of households per census block.

There are a number of possible data downloads in the package but apparently I am not smart enough to figure out which data-set is appropriate and what functions to use.

Any help or pointers or links would be greatly appreciated.

Thanks for your time,
Best,
KW


From b.rowlingson at lancaster.ac.uk  Mon Aug  3 17:59:43 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 3 Aug 2015 16:59:43 +0100
Subject: [R] R command to open a file "browser" on Windows and Mac?
In-Reply-To: <4cddfa9aacea4691b208f2d69b0ab356@EX-0-HT0.lancs.local>
References: <4cddfa9aacea4691b208f2d69b0ab356@EX-0-HT0.lancs.local>
Message-ID: <CANVKczNJ=Fg3s++DJY2jkqpTztVvdrvyHa_+5sfLB0uvBkLi2g@mail.gmail.com>

And for completeness, on linux:

system(paste0("xdg-open ",getwd()))

there's a function in a package somewhere that hides the system
dependencies of opening things with the appropriate application, and
if you pass a folder/directory to it I reckon it will open it in the
Explorer/Finder/Nautilus//xfm//This Month's Linux File Browser// as
appropriate.

But I can't remember the name of the function or the package.

Barry



On Mon, Aug 3, 2015 at 4:19 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> Folks:
>
> Is there an easy function to open a finder window (on mac) or windows
> explorer window (on windows) given an input folder?  A lot of times I want
> to be able to see via a file browser my working directory.  Is there a good
> R hack to do this?
>
> --j
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Aug  3 18:23:45 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 3 Aug 2015 16:23:45 +0000
Subject: [R] Using R to fit a curve to a dataset using a specific
 equation
In-Reply-To: <trinity-44f091a1-4fc7-4aae-a7ba-d83d63fff774-1438616235772@3capp-gmx-bs10>
References: <000101d0cc6d$2b3e0210$81ba0630$@gmx.ch>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6AFEDB@mb02.ads.tamu.edu>
	<trinity-eb49071f-0879-4466-b2a7-d932b8c82d52-1438468354416@3capp-gmx-bs63>,
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6B0B32@mb02.ads.tamu.edu>
	<trinity-44f091a1-4fc7-4aae-a7ba-d83d63fff774-1438616235772@3capp-gmx-bs10>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B0DA5@mb02.ads.tamu.edu>

Your question is more statistics than R and I?m not qualified to offer an opinion. You should be able to find someone locally to help you. The Cross Validated website is also a useful resource.

David

From: Michael Eisenring [mailto:Michael.Eisenring at gmx.ch]
Sent: Monday, August 3, 2015 10:37 AM
To: David L Carlson
Cc: r-help
Subject: Aw: RE: RE: [R] Using R to fit a curve to a dataset using a specific equation

Hi David,
thank you for your help.
It makes sense to me that the R2 is very misleading in an non-linear regression. the same is true for the p-values.
My question then is: how can I present the results of my curve and quantify its goodness if R2 and p-values are misleading?
thanks a lot,
Mike



Gesendet: Montag, 03. August 2015 um 07:40 Uhr
Von: "David L Carlson" <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>>
An: "Michael Eisenring" <Michael.Eisenring at gmx.ch<mailto:Michael.Eisenring at gmx.ch>>, r-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Betreff: RE: RE: [R] Using R to fit a curve to a dataset using a specific equation
Use Reply-All to keep the discussion on the list.

I suggested reading about nls (not just how to do it in R) because you requested R2. It was not clear that you were aware that there are strong reasons to suspect that R2 is misleading when applied nls results. That is why nls() does not provide it automatically.

But R2 is easily computed from the model results:

GossSS <- sum((dta$Gossypol - mean(dta$Gossypol))^2)
R2 <- deviance(dta.nls)/GossSS
R2
[1] 0.6318866

As for ggplot, just add the line we created before to the points plot:

library(ggplot)
xval <- seq(0, 10, length.out=200)
yval <- predict(dta.nls, data.frame(Damage_cm=xval))
ggplot() + geom_point(data=dta, aes(x=Damage_cm, y=Gossypol)) +
geom_line(aes(x=xval, y=yval))


David Carlson

From: Michael Eisenring [mailto:Michael.Eisenring at gmx.ch]
Sent: Saturday, August 1, 2015 5:33 PM
To: David L Carlson
Subject: Aw: RE: [R] Using R to fit a curve to a dataset using a specific equation

Hello and thank you very much for your help!
I just started to read up on non-linear least squares in The RBook. (I am totally new to the topic so i dindt even know where to look in the book ).
I have three last questions:

In the Rbook they say how to describe a model. In my case it would be something like:
?The model y ~ y0 + a * (1 - b^x)
had y0= 1303.45 ( 386.15 standard error), a=.... and b=....
The model explained ??% of the total variation in y

My question is were do I find the %age of total variation the model explains. it does not say that in the book.
Is there something similar as a R^2 value or a p-value?

My last question: is it possible to use ggplot2 for plotting the whole model?

Thanks a lot.
Mike


Gesendet: Samstag, 01. August 2015 um 13:49 Uhr
Von: "David L Carlson" <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>>
An: "Michael Eisenring" <michael.eisenring at gmx.ch<mailto:michael.eisenring at gmx.ch>>, "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>
Betreff: RE: [R] Using R to fit a curve to a dataset using a specific equation
I can get you started, but you should really read up on non-linear least squares. Calling your data frame dta (since data is a function):

plot(Gossypol~Damage_cm, dta)
# Looking at the plot, 0 is a plausible estimate for y0:
# a+y0 is the asymptote, so estimate about 4000;
# b is between 0 and 1, so estimate .5
dta.nls <- nls(Gossypol~y0+a*(1-b^Damage_cm), dta,
start=list(y0=0, a=4000, b=.5))
xval <- seq(0, 10, length.out=200)
lines(xval, predict(dta.nls, data.frame(Damage_cm=xval)))
profile(dta.nls, alpha= .05)
===========================================
Number of iterations to convergence: 3
Achieved convergence tolerance: 1.750586e-06
attr(,"summary")

Formula: Gossypol ~ y0 + a * (1 - b^Damage_cm)

Parameters:
Estimate Std. Error t value Pr(>|t|)
y0 1303.4529432 386.1515684 3.37550 0.0013853 **
a 2796.0464520 530.4140959 5.27144 2.5359e-06 ***
b 0.4939111 0.1809687 2.72926 0.0085950 **
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1394.375 on 53 degrees of freedom

Number of iterations to convergence: 3
Achieved convergence tolerance: 1.750586e-06


David Carlson
Dept of Anthropology
Texas A&M
College Station, TX 77843
________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Michael Eisenring [michael.eisenring at gmx.ch]
Sent: Saturday, August 01, 2015 10:17 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Using R to fit a curve to a dataset using a specific equation

Hi there




I would like to use a specific equation to fit a curve to one of my data
sets (attached)

> dput(data)

structure(list(Gossypol = c(1036.331811, 4171.427741, 6039.995102,
5909.068158, 4140.242559, 4854.985845, 6982.035521, 6132.876396,
948.2418407, 3618.448997, 3130.376482, 5113.942098, 1180.171957,
1500.863038, 4576.787021, 5629.979049, 3378.151945, 3589.187889,
2508.417927, 1989.576826, 5972.926124, 2867.610671, 450.7205451, 1120.955,
3470.09352, 3575.043632, 2952.931863, 349.0864019, 1013.807628, 910.8879471,
3743.331903, 3350.203452, 592.3403778, 1517.045807, 1504.491931,
3736.144027, 2818.419785, 723.885643, 1782.864308, 1414.161257, 3723.629772,
3747.076592, 2005.919344, 4198.569251, 2228.522959, 3322.115942,
4274.324792, 720.9785449, 2874.651764, 2287.228752, 5654.858696,
1247.806111, 1247.806111, 2547.326207, 2608.716056, 1079.846532), Treatment
= structure(c(2L, 3L, 4L, 5L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 5L, 1L, 2L, 3L,
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
2L, 3L, 1L), .Label = c("C", "1c_2d", "3c_2d", "9c_2d", "1c_7d"), class =
"factor"), Damage_cm = c(0.4955, 1.516, 4.409, 3.2665, 0.491, 2.3035, 3.51,
1.8115, 0, 0.4435, 1.573, 1.8595, 0, 0.142, 2.171, 4.023, 4.9835, 0, 0.6925,
1.989, 5.683, 3.547, 0, 0.756, 2.129, 9.437, 3.211, 0, 0.578, 2.966, 4.7245,
1.8185, 0, 1.0475, 1.62, 5.568, 9.7455, 0, 0.8295, 2.411, 7.272, 4.516, 0,
0.4035, 2.974, 8.043, 4.809, 0, 0.6965, 1.313, 5.681, 3.474, 0, 0.5895,
2.559, 0)), .Names = c("Gossypol", "Treatment", "Damage_cm"), row.names =
c(NA, -56L), class = "data.frame")

The equation is: y~yo+a*(1-b^x) Where: y =Gossypol (from my data set) x=
Damage_cm (from my data set)

The other 3 parameters are unknown: yo=Intercept, a= assymptote ans b=slope

In the end I would like to use the equation to plot a curve (with SE
interval, I usually use ggplot2)

Furthermore, I would like to know the R2 and p value. I would also be
interested in the parameters yo , a and b

I have never done this before and would be extremely grateful if anyone
could help me? I suppose I have to use a non linear approach (glm(...)). I
found out that the mosaic package might be helpful.

thanks a lot, Mike




[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ri.williamson at outlook.com  Mon Aug  3 17:12:07 2015
From: ri.williamson at outlook.com (Robert in SA)
Date: Mon, 3 Aug 2015 08:12:07 -0700 (PDT)
Subject: [R] Environmental Data Connector v1.3
Message-ID: <1438614727977-4710686.post@n4.nabble.com>

Hello. I have "successfully" installed EDC v1.3 on linux ubuntu 14.04. I am
running a 64bit machine with R 3.2.1 via Rstudio. I have tried "> example1
<- EDC.get(1)" after loading the ncdf and EDCR libraries, from both the R
terminal and Rstudio and get the following result:

Error in setwd(paste(Sys.getenv("EDC_HOME"), sep = "")) : 
  cannot change working directory

During installation EDC_HOME was set to /home/robert/EDC and the directory
definitely exists. Does anyone have any suggestions?




--
View this message in context: http://r.789695.n4.nabble.com/Environmental-Data-Connector-v1-3-tp4710686.html
Sent from the R help mailing list archive at Nabble.com.


From yeo8 at cdc.gov  Mon Aug  3 18:00:57 2015
From: yeo8 at cdc.gov (Hood, Kyle (CDC/OCOO/OCIO/ITSO) (CTR))
Date: Mon, 3 Aug 2015 16:00:57 +0000
Subject: [R] R error
In-Reply-To: <4BBC5036C559974396A34EE0FD74CA110C1A0613@EMBX-CHAM3.cdc.gov>
References: <4BBC5036C559974396A34EE0FD74CA110C1A0613@EMBX-CHAM3.cdc.gov>
Message-ID: <AD29844AFE86BF46B27E9FCD752022C821AB0430@EMBX-CHAM2.cdc.gov>

Good afternoon,

I recently received a ticket from a customer to upgrade from 3.1.1. to 3.2.1.  After the upgrade, when he tries to install a package he receives the error below.  Could you please advise as to what is wrong?  Thank you.

Kyle

--- Please select a CRAN mirror for use in this session ---
Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA, type = type) :
  'lib = "C:/Program Files/R/R-3.2.1/library"' is not writable
Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type = type) :
  unable to create '\\cdc.gov\private\M328\ygv7/R/win-library/3.2'
In addition: Warning message:
In dir.create(userdir, recursive = TRUE) :
  cannot create dir '\\cdc.gov\private', reason 'Permission denied'

	[[alternative HTML version deleted]]


From rdevries85 at gmail.com  Mon Aug  3 18:11:10 2015
From: rdevries85 at gmail.com (Rob de Vries)
Date: Mon, 3 Aug 2015 17:11:10 +0100
Subject: [R] Matching posterior probabilities from poLCA
Message-ID: <CAFCf80g75QCjSw-U9gGM0jtZMF9vCUny8P7v9_dSnc9r0mBkwA@mail.gmail.com>

Hi all,

I'm a newbie to R with a question about poLCA. When you run a latent class
analysis in poLCA it generates a value for each respondent giving their
posterior probability of 'belonging' to each latent class. These are stored
as a matrix in the element 'posterior'.

I would like to create a dataframe which contains each respondent's unique
ID number (which is stored as a variable in the dataframe used for poLCA)
and their *matched* posterior probability from the 'posterior' matrix. I
would then like to write this dataframe to a csv file for use in another
program.

I know this is possible, but I just can't seem to get it right (blame my
incompetence with R). Any help would be very warmly appreciated.

Best wishes.
Robert de Vries

	[[alternative HTML version deleted]]


From jjthaden at flash.net  Mon Aug  3 18:51:55 2015
From: jjthaden at flash.net (John Thaden)
Date: Mon, 3 Aug 2015 09:51:55 -0700
Subject: [R] vectorized sub, gsub, grep, etc.
In-Reply-To: <CAHEemWYwQMES0_MXYpe=L2eGgN3vfPZdDXwJX+vRXs0sQ2jYDw@mail.gmail.com>
Message-ID: <1438620715.41118.YahooMailAndroidMobile@web185406.mail.gq1.yahoo.com>

sub() has practical uses though gsub() may have more. This function was what I needed at the time. Of course the gsub() version is also possible.

Sent from Yahoo Mail on Android


	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Mon Aug  3 19:43:05 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Mon, 3 Aug 2015 13:43:05 -0400
Subject: [R] Households per Census block
In-Reply-To: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
Message-ID: <CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>

hi, ccing the package maintainer.  one alternative is to pull the HU100
variable directly from the census bureau's summary files: that variable
starts at position 328 and ends at 336.  just modify this loop and you'll
get a table with one-record-per-census-block in every state.

https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104

(1) line 134 change the very last -9 to 9
(2) line 137 between "pop100" and "intptlat" add an "hu100"


summary file docs-

http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18



On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:

> Folks,
>
> I am using the UScensus2010 package and I am trying to figure out the
> number of households per census block.
>
> There are a number of possible data downloads in the package but
> apparently I am not smart enough to figure out which data-set is
> appropriate and what functions to use.
>
> Any help or pointers or links would be greatly appreciated.
>
> Thanks for your time,
> Best,
> KW
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Mon Aug  3 19:44:48 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Mon, 3 Aug 2015 17:44:48 +0000
Subject: [R] Environmental Data Connector v1.3
In-Reply-To: <1438614727977-4710686.post@n4.nabble.com>
References: <1438614727977-4710686.post@n4.nabble.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED7366C@WAXMXOLYMB025.WAX.wa.lcl>

Why are you using paste() ?  Why not just


setwd(Sys.getenv("EDC_HOME"))


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert in SA
Sent: Monday, August 03, 2015 8:12 AM
To: r-help at r-project.org
Subject: [R] Environmental Data Connector v1.3

Hello. I have "successfully" installed EDC v1.3 on linux ubuntu 14.04. I am running a 64bit machine with R 3.2.1 via Rstudio. I have tried "> example1
<- EDC.get(1)" after loading the ncdf and EDCR libraries, from both the R terminal and Rstudio and get the following result:

Error in setwd(paste(Sys.getenv("EDC_HOME"), sep = "")) : 
  cannot change working directory

During installation EDC_HOME was set to /home/robert/EDC and the directory definitely exists. Does anyone have any suggestions?




--
View this message in context: http://r.789695.n4.nabble.com/Environmental-Data-Connector-v1-3-tp4710686.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Aug  3 20:18:43 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 3 Aug 2015 20:18:43 +0200
Subject: [R] R error
In-Reply-To: <AD29844AFE86BF46B27E9FCD752022C821AB0430@EMBX-CHAM2.cdc.gov>
References: <4BBC5036C559974396A34EE0FD74CA110C1A0613@EMBX-CHAM3.cdc.gov>
	<AD29844AFE86BF46B27E9FCD752022C821AB0430@EMBX-CHAM2.cdc.gov>
Message-ID: <685FA0CB-4B07-4846-ABDF-62907B1259D5@gmail.com>


> On 03 Aug 2015, at 18:00 , Hood, Kyle (CDC/OCOO/OCIO/ITSO) (CTR) <yeo8 at cdc.gov> wrote:
> 
> Good afternoon,
> 
> I recently received a ticket from a customer to upgrade from 3.1.1. to 3.2.1.  After the upgrade, when he tries to install a package he receives the error below.  Could you please advise as to what is wrong?  Thank you.

It's not too easy to tell given the number of ways large networked installs can be configured, but the logic is that if the R installation directory is write protected (which is usually a good thing), the packages go into a subdirectory of the user's home dir. The output suggests that R believes that this is \\cdc.gov\private\M328\ygv7, but apparently that doesn't exist since it tries to create \\cdc.gov\private which it can't.

Apart from that, try digging around in 

https://cran.r-project.org/bin/windows/base/rw-FAQ.html

-pd

> 
> Kyle
> 
> --- Please select a CRAN mirror for use in this session ---
> Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA, type = type) :
>  'lib = "C:/Program Files/R/R-3.2.1/library"' is not writable
> Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type = type) :
>  unable to create '\\cdc.gov\private\M328\ygv7/R/win-library/3.2'
> In addition: Warning message:
> In dir.create(userdir, recursive = TRUE) :
>  cannot create dir '\\cdc.gov\private', reason 'Permission denied'
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ri.williamson at outlook.com  Mon Aug  3 20:36:57 2015
From: ri.williamson at outlook.com (Robert in SA)
Date: Mon, 3 Aug 2015 11:36:57 -0700 (PDT)
Subject: [R] Environmental Data Connector v1.3
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA27662ED7366C@WAXMXOLYMB025.WAX.wa.lcl>
References: <1438614727977-4710686.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27662ED7366C@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <1438627017816-4710701.post@n4.nabble.com>

Hi Dan, thanks for your response. 

The setwd is coded somewhere in the EDC.get function. I guess I could try
alter the code but I assume this package should work as is.



--
View this message in context: http://r.789695.n4.nabble.com/Environmental-Data-Connector-v1-3-tp4710686p4710701.html
Sent from the R help mailing list archive at Nabble.com.


From almquist at umn.edu  Mon Aug  3 20:12:42 2015
From: almquist at umn.edu (Zack Almquist)
Date: Mon, 3 Aug 2015 13:12:42 -0500
Subject: [R] Households per Census block
In-Reply-To: <CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
	<CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
Message-ID: <CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>

Hi Anthony and Keith Weintraub,

Here is a way to do what you are asking using the UScensus2010 packages:

## latest version of the package, not yet on CRAN
install.packages("UScensus2010", repos="http://R-Forge.R-project.org")
library(UScensus2010)
install.blk()
library(UScensus2010blk)
### You will want the H0010001 variable (see help(alabama.blk10))
### Other variables are also available
### You can use the new api function in UScensus2010 to get arbitrary
variables from SF1 and acs

data(states.names)
head(states.names)
state.blk.housing<-vector("list",length(states.names))
## notice this could be greatly spead up using the library(parallel)
## with mclapply
## This will be somewhat slow b/c of so much spatial data
for(i in 1:length(states.names)){
data(list=paste(states.names[i],"blk10",sep="."))
temp<-get(paste(states.names[i],"blk10",sep="."))
#unique b/c more shapefiles than fips
state.blk.housing[[i]]<-unique(temp at data[,c("fips","H0010001")])
print(i)
rm(paste(states.names,"blk10",sep="."))
}

###########
# alternatively Using the US Census API function in the new UScensus2010
package
###########

## Get all states fips code
data(countyfips)
state.fips<-unique(substr(countyfips$fips,1,2))
head(state.fips)
length(state.fips) ## will be 51=50 (states)+ 1(DC)
## You will need a census key
key<-"YOUR KEY HERE"
housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level =
c("block"), key, summaryfile = c("sf1"))

Best,

-- Zack
---------------------------------------------------------
Zack W.  Almquist
Assistant Professor
Department of Sociology and School of Statistics
Affiliate, Minnesota Population Center
University of Minnesota


On Mon, Aug 3, 2015 at 12:43 PM, Anthony Damico <ajdamico at gmail.com> wrote:

> hi, ccing the package maintainer.  one alternative is to pull the HU100
> variable directly from the census bureau's summary files: that variable
> starts at position 328 and ends at 336.  just modify this loop and you'll
> get a table with one-record-per-census-block in every state.
>
>
> https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104
>
> (1) line 134 change the very last -9 to 9
> (2) line 137 between "pop100" and "intptlat" add an "hu100"
>
>
> summary file docs-
>
> http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18
>
>
>
> On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com>
> wrote:
>
>> Folks,
>>
>> I am using the UScensus2010 package and I am trying to figure out the
>> number of households per census block.
>>
>> There are a number of possible data downloads in the package but
>> apparently I am not smart enough to figure out which data-set is
>> appropriate and what functions to use.
>>
>> Any help or pointers or links would be greatly appreciated.
>>
>> Thanks for your time,
>> Best,
>> KW
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From rawi2903 at colorado.edu  Mon Aug  3 20:42:01 2015
From: rawi2903 at colorado.edu (Ram09)
Date: Mon, 3 Aug 2015 11:42:01 -0700 (PDT)
Subject: [R] scaling variables consecutively and independently
Message-ID: <1438627321815-4710702.post@n4.nabble.com>

Hello Everyone,

So I am very new to R and I'm having some trouble.  I basically have around
110 datasets each one made up of around 100 variables.  I am trying to
z-score the scores in each column but independently of each other ( each
column independent of the other).  The problem is that there are just too
many variables in each dataset to compute individually.  I figured there
should be some type of loop that I can do in which it would scale the scores
in each column and then move on to the next but I haven't been able to find
anything about this.  Can anyone help?  Thanks so much!

-RW



--
View this message in context: http://r.789695.n4.nabble.com/scaling-variables-consecutively-and-independently-tp4710702.html
Sent from the R help mailing list archive at Nabble.com.


From roy.mendelssohn at noaa.gov  Mon Aug  3 20:58:42 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 3 Aug 2015 11:58:42 -0700
Subject: [R] Environmental Data Connector v1.3
In-Reply-To: <1438627017816-4710701.post@n4.nabble.com>
References: <1438614727977-4710686.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27662ED7366C@WAXMXOLYMB025.WAX.wa.lcl>
	<1438627017816-4710701.post@n4.nabble.com>
Message-ID: <8F9FD4E4-9801-4077-91B2-9B66CC3C5DAD@noaa.gov>

Hi Robert:

I didn?t see this until Dan sent me something offline.  I apologize for the problem. Yes the function should work as is, and a lot of the EDC is Java.  I have forwarded your email to the people who did the coding.  But in the meantime can you do two things for me to help us in the debugging:

1.  Can you send me  the result of  the command:

     Sys.getenv(?EDC_HOME?)

2.  Can you send  the result 

ls -l

on that directory?

I suggest that at this point do it offline, as I doubt these details would be of interest to the list as a whole.  If we find a solution I will post that.  I will add that we don?t have the resources to test on all versions of all OS, and that at times changes in R have required us to change our code, and this can also be one such instance.  But yes, the error message suggests that the code can?t write the necessary temp files to whatever directory it is trying.

Thanks,

-Roy



> On Aug 3, 2015, at 11:36 AM, Robert in SA <ri.williamson at outlook.com> wrote:
> 
> Hi Dan, thanks for your response. 
> 
> The setwd is coded somewhere in the EDC.get function. I guess I could try
> alter the code but I assume this package should work as is.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Environmental-Data-Connector-v1-3-tp4710686p4710701.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From wdunlap at tibco.com  Mon Aug  3 21:01:41 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 3 Aug 2015 12:01:41 -0700
Subject: [R] Environmental Data Connector v1.3
In-Reply-To: <1438614727977-4710686.post@n4.nabble.com>
References: <1438614727977-4710686.post@n4.nabble.com>
Message-ID: <CAF8bMcZD-coJaUmuqDQruaMH40wVP3QSuMUN-CR10c6BCPPT5A@mail.gmail.com>

> During installation EDC_HOME was set to /home/robert/EDC
> and the directory definitely exists.

Are you sure that EDC_HOME is set now?  What do you get from the following
command?
   Sys.getenv("EDC_HOME")
If that is set to something other than "", what do you get from
   getwd()
   setwd(Sys.getenv("EDC_HOME"))
   getwd()
If it is was not set, do things work better if you first do
   Sys.setenv(EDC_HOME="/home/robert/EDC")



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 3, 2015 at 8:12 AM, Robert in SA <ri.williamson at outlook.com>
wrote:

> Hello. I have "successfully" installed EDC v1.3 on linux ubuntu 14.04. I am
> running a 64bit machine with R 3.2.1 via Rstudio. I have tried "> example1
> <- EDC.get(1)" after loading the ncdf and EDCR libraries, from both the R
> terminal and Rstudio and get the following result:
>
> Error in setwd(paste(Sys.getenv("EDC_HOME"), sep = "")) :
>   cannot change working directory
>
> During installation EDC_HOME was set to /home/robert/EDC and the directory
> definitely exists. Does anyone have any suggestions?
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Environmental-Data-Connector-v1-3-tp4710686.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Aug  3 21:42:10 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 3 Aug 2015 12:42:10 -0700
Subject: [R] scaling variables consecutively and independently
In-Reply-To: <1438627321815-4710702.post@n4.nabble.com>
References: <1438627321815-4710702.post@n4.nabble.com>
Message-ID: <DCC396A4-420A-435D-B72A-E195413D67BB@comcast.net>


On Aug 3, 2015, at 11:42 AM, Ram09 wrote:

> Hello Everyone,
> 
> So I am very new to R and I'm having some trouble.  I basically have around
> 110 datasets each one made up of around 100 variables.  I am trying to
> z-score the scores in each column but independently of each other ( each
> column independent of the other).  The problem is that there are just too
> many variables in each dataset to compute individually.  I figured there
> should be some type of loop that I can do in which it would scale the scores
> in each column and then move on to the next but I haven't been able to find
> anything about this.  Can anyone help?  Thanks so much!

Perhaps you are looking for the 'scale'-function?

<deleted Nabble link>

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 
David Winsemius
Alameda, CA, USA


From rawi2903 at colorado.edu  Mon Aug  3 22:06:48 2015
From: rawi2903 at colorado.edu (Ram09)
Date: Mon, 3 Aug 2015 13:06:48 -0700 (PDT)
Subject: [R] scaling variables consecutively and independently
In-Reply-To: <DCC396A4-420A-435D-B72A-E195413D67BB@comcast.net>
References: <1438627321815-4710702.post@n4.nabble.com>
	<DCC396A4-420A-435D-B72A-E195413D67BB@comcast.net>
Message-ID: <1438632408771-4710709.post@n4.nabble.com>

Yes, I've been using the scale function but I don't know how to write a line
of code that will scale the scores in each variable independently of each
other instead of as a whole.  In other words, how can I get the scale
function to standardize all the scores in one variable (column) then move on
to the the next, so on and so forth for the whole dataset without having to
tediously type out the same line of code for each variable? 

-RW



--
View this message in context: http://r.789695.n4.nabble.com/scaling-variables-consecutively-and-independently-tp4710702p4710709.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Mon Aug  3 22:29:26 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 3 Aug 2015 13:29:26 -0700
Subject: [R] scaling variables consecutively and independently
In-Reply-To: <1438632408771-4710709.post@n4.nabble.com>
References: <1438627321815-4710702.post@n4.nabble.com>
	<DCC396A4-420A-435D-B72A-E195413D67BB@comcast.net>
	<1438632408771-4710709.post@n4.nabble.com>
Message-ID: <3EDF8E80-86B6-4DE2-9242-A247CAD1FB55@comcast.net>


On Aug 3, 2015, at 1:06 PM, Ram09 wrote:

> Yes, I've been using the scale function but I don't know how to write a line
> of code that will scale the scores in each variable independently of each
> other instead of as a whole.

You do not appear to be reading the help page for `scale`.

>  In other words, how can I get the scale
> function to standardize all the scores in one variable (column) then move on
> to the the next, so on and so forth for the whole dataset without having to
> tediously type out the same line of code for each variable? 

This is the first Line of text in the help page:

"'scale' is generic function whose default method centers and/or scales the columns of a numeric matrix."

If you do not want the result as a matrix then you can use lapply on a dataframe.

-- 
David.

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From roy.mendelssohn at noaa.gov  Mon Aug  3 22:38:57 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 3 Aug 2015 13:38:57 -0700
Subject: [R] Environmental Data Connector v1.3
In-Reply-To: <1438614727977-4710686.post@n4.nabble.com>
References: <1438614727977-4710686.post@n4.nabble.com>
Message-ID: <F5C824AB-5B8D-4FA1-AFB9-5EB282C6E1C8@noaa.gov>


> On Aug 3, 2015, at 8:12 AM, Robert in SA <ri.williamson at outlook.com> wrote:
> 
> Hello. I have "successfully" installed EDC v1.3 on linux ubuntu 14.04. I am
> running a 64bit machine with R 3.2.1 via Rstudio. I have tried "> example1
> <- EDC.get(1)" after loading the ncdf and EDCR libraries, from both the R
> terminal and Rstudio and get the following result:
> 
> Error in setwd(paste(Sys.getenv("EDC_HOME"), sep = "")) : 
>  cannot change working directory
> 
> During installation EDC_HOME was set to /home/robert/EDC and the directory
> definitely exists. Does anyone have any suggestions?
> 
> 

Bringing this back on list so that the solution is on record , the problem is that EDC_HOME was not set when the install was done.  We are looking into whether this is a problem with the installer.

In the meantime, if this problem pops-up again, use:

 Sys.setenv(EDC_HOME="/your/EDC/home/directory?)

Many thanks to Bill Dunlop of Tibco for help on solving this.  He also notes:

> Yes.  You can set EDC_HOME on your .Rprofile or Renviron (sp?) files.
> See help(Startup) for details.
> 


-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dpmeddings at gmail.com  Mon Aug  3 22:49:54 2015
From: dpmeddings at gmail.com (Daniel Meddings)
Date: Mon, 3 Aug 2015 21:49:54 +0100
Subject: [R] How to simulate informative censoring in a Cox PH model?
In-Reply-To: <CAFEqCdyVFU7z-Eiwrnq3oQ2TeZZif5rRGi2S-T_6eaaQsnM1Vg@mail.gmail.com>
References: <CABrUXPWBEe_TovEoTK+wY6UWeQtNTM_j1WnOic5wG1qAJi1seg@mail.gmail.com>
	<CAFEqCdzk8cSwed-VdBrob1bzLQtx7rknK9UkNEU_bwt8auoD7A@mail.gmail.com>
	<CABrUXPVi2=GnEg14xZQ19XjJOnuW=61NVZc+Vkbfo2HDN08L8g@mail.gmail.com>
	<CAFEqCdxb9_Lv-_DoYVM26F=wOW_cJnn-FRtYubQhkbL8gWpjbw@mail.gmail.com>
	<CABrUXPWCVc_vJYqPBCkmL-30KQKAP_Hp+=2K5M0SeARU5eq+=w@mail.gmail.com>
	<CAFEqCdyVFU7z-Eiwrnq3oQ2TeZZif5rRGi2S-T_6eaaQsnM1Vg@mail.gmail.com>
Message-ID: <CABrUXPW+-1ZRbEQ+9_SJtDfvHgsr-3Hf+GH51SJ_a7Xv3znYgA@mail.gmail.com>

Hi Greg

The copulas concept seems a nicely simple way of simulating event times
that are subject to informative censoring (in contrast to the double cox
model approach I use). The correlation between the marginal uniform random
variables you speak of reminded me that my approach should also induce this
correlation, just in a different way. Similarly I should also observe zero
correlation between my event times from my outcome model and the censoring
times. Unfortunately this was not the case - to cut a long story short I
was inadvertently generating my independent censoring times from a model
that depended on covariates in the outcome model. This now explains the
mixed results I rather laboriously attempted to describe previously.

Re-running some scenarios with my new error-free code I can now clearly
observe the points you have been making, that is informative censoring only
leads to bias if the covariates in the censoring model are not in the
outcome model. Indeed I can choose the common (to both models) treatment
effect to be vastly different (with all other effects the same) and have no
bias, yet small differences in the censoring Z effect (not in the outcome
model) effect lead to moderate biases.

I am still somewhat confused at the other approach to this problem where I
have seen in various journal articles authors assuming an outcome model for
the censored subjects - i.e. an outcome model for the unobserved event
times. Using this approach the definition of informative censoring appears
to be where the observed and un-observed outcome models are different. This
approach also makes sense to me - censoring merely loses precision of the
parameter estimators due to reduced events, but does not lead to bias.
However the concept of correlated event and censoring times does not even
present itself here?

Thanks

Dan



On Fri, Jul 31, 2015 at 5:06 PM, Greg Snow <538280 at gmail.com> wrote:

> Daniel,
>
> Basically just responding to your last paragraph (the others are
> interesting, but I think that you are learning as much as anyone and I
> don't currently have any other suggestions).
>
> I am not an expert on copulas, so this is a basic understanding, you
> should learn more about them if you choose to use them.  The main idea
> of a copula is that it is a bivariate or multivariate distribution
> where all the variables have uniform marginal distributions but the
> variables are not independent from each other.  How I would suggest
> using them is to choose a copula and generate random points from a
> bivariate copula, then put those (uniform) values into the inverse pdf
> function for the Weibull (or other distribution), one of which is the
> event time, the other the censoring time.  This will give you times
> that (marginally) come from the distributions of interest, but are not
> independent (so would be considered informative censoring).  Repeat
> this with different levels of relationship in the copula to see how
> much difference it makes in your simulations.
>
> On Thu, Jul 30, 2015 at 2:02 PM, Daniel Meddings <dpmeddings at gmail.com>
> wrote:
> > Thanks Greg once more for taking the time to reply. I certainly agree
> that
> > this is not a simple set-up, although it is realistic I think. In short
> you
> > are correct about model mis-specification being the key to producing more
> > biased estimates under informative than under non-informative censoring.
> > After looking again at my code and trying various things I realize that
> the
> > key factor that leads to the informative and non-informative censoring
> data
> > giving rise to the same biased estimates is how I generate my Z_i
> variable,
> > and also the magnitude of the Z_i coefficient in both of the event and
> > informative censoring models.
> >
> > In the example I gave I generated Z_i (I think of this as a "poor
> prognosis"
> > variable) from a beta distribution so that it ranged from 0-1. The biased
> > estimates for "beta_t_1" (I think of this as the effect of a treatment on
> > survival) were approximately 1.56 when the true value was -1. What I
> forgot
> > to mention was that estimating a cox model with 1,000,000 subjects to the
> > full data (i.e. no censoring at all) arguably gives the best treatment
> > effect estimate possible given that the effects of Z_i and Z_i*Treat_i
> are
> > not in the model. This "best possible" estimate turns out to be 1.55 -
> i.e.
> > the example I gave just so happens to be such that even with 25-27%
> > censoring, the estimates obtained are almost the best that can be
> attained.
> >
> > My guess is that the informative censoring does not bias the estimate
> more
> > than non-informative censoring because the only variable not accounted
> for
> > in the model is Z_i which does not have a large enough effect "beta_t_2",
> > and/or "beta_c_2", or perhaps because Z_i only has a narrow range which
> does
> > not permit the current "beta_t_2" value to do any damage?
> >
> > To investigate the "beta_t_2", and/or "beta_c_2" issue I changed
> "beta_c_2"
> > from 2 to 7 and "beta_c_0" from 0.2 to -1.2, and "beta_d_0" from -0.7 to
> > -0.4 to keep the censoring %'s equal at about 30%. This time the "best
> > possible" estimate of "beta_t_1" was -1.53 which was similar to that
> > obtained previously. The informative censoring gave an estimate for
> > "beta_t_1" of -1.49 whereas the non-informative censoring gave -1.53 -
> this
> > time the non-informative censoring attains the "best possible" but the
> > non-informative censoring does not.
> >
> >
> >
> > I then instead changed "beta_t_2" from 1 to 7 and "beta_c_0" from 0.2 to
> 2,
> > and "beta_d_0" from -0.7 to -1.9 again to keep the censoring %'s equal at
> > about 30%. This time the "best possible" estimate of "beta_t_1" was
> -0.999
> > which is pretty much equal to the true value of -1. The informative
> > censoring gave an estimate for "beta_t_1" of -1.09 whereas the
> > non-informative censoring gave -0.87 ? surprisingly this time the
> > informative censoring is slightly closer to the ?best possible? than the
> > non-informative censoring.
> >
> >
> >
> > To investigate the Z_i issue I generated it from a normal distribution
> with
> > mean 1 and variance 1. I changed "beta_c_0 " from 0.2 to -0.5 to keep the
> > censoring levels equal (this time about 30% for both). This time the
> "best
> > possible" estimate was -1.98 which was further from -1 than previous
> > examples. The informative censoring gave an estimate for "beta_t_1" of
> -1.81
> > whereas the non-informative censoring gave -1.84. So again the
> informative
> > censoring gives an estimate closer to the "best possible" when compared
> with
> > the informative censoring, but this time it does not attain the "best
> > possible".
> >
> > In conclusion it is clear to me that a stronger Z_i effect in the
> censoring
> > model causes the informative censoring to be worse than the
> non-informative
> > one (as expected), but a stronger Z_i effect in the event model does not
> > have this effect and even causes the independent censoring to be worse ?
> > this in general may not hold but I nonetheless see it here. I am
> wondering
> > if this is because altering the treatment effect in the event model also
> > affects the independent censoring process and so it ?muddies the waters?
> > whereas altering the treatment effect in the informative censoring model
> > obviously confines the changes to just the informative censoring process.
> > For a fixed treatment effect size in both the event and informative
> > censoring models the effect of Z_i having a wider range than is possible
> > under the beta distribution also appears to produce informative censoring
> > that is worse than the non-informative one. This makes sense I think
> because
> > the Z_i-response relationship must be more informative?
> >
> >
> >
> > Thanks for your suggestion of copulas ? I have not come across these. Is
> > this similar to assuming a event model for censored subjects (this is
> > unobserved) ? i.e. if the event model is different conditional on
> censoring
> > then if we could observe the events beyond censoring then clearly the
> > parameter estimates would be different compared to those obtained when
> > modelling only non-censored times?
> >
> >
> >
> >
> > On Wed, Jul 29, 2015 at 5:37 PM, Greg Snow <538280 at gmail.com> wrote:
> >>
> >> As models become more complex it becomes harder to distinguish
> >> different parts and their effects.  Even for a straight forward linear
> >> regression model if X1 and X2 are correlated with each other then it
> >> becomes difficult to distinguish between the effects of X1^2, X2^2,
> >> and X1*X2.  In your case the informative censoring and model
> >> misspecification are becoming hard to distinguish (and it could be
> >> argued that having informative censoring is really just a form of
> >> model misspecification).  So I don't think so much that you are doing
> >> things wrong, just that you are learning that the models are complex.
> >>
> >> Another approach to simulation that you could try is to simulate the
> >> event time and censoring time using copulas (and therefore they can be
> >> correlated to give informative censoring, but without relying on a
> >> term that you could have included in the model) then consider the
> >> event censored if the censoring time is shorter.
> >>
> >> On Fri, Jul 24, 2015 at 10:14 AM, Daniel Meddings <dpmeddings at gmail.com
> >
> >> wrote:
> >> > Hi Greg
> >> >
> >> > Many thanks for taking the time to respond to my query. You are right
> >> > about
> >> > pointing out the distinction between what variables are and are not
> >> > included
> >> > in the event times process and in the censoring process. I clearly
> >> > forgot
> >> > this important aspect. I amended my code to do as you advise and now I
> >> > am
> >> > indeed getting biased estimates when using the informatively censored
> >> > responses. The problem is now that the estimates from the
> independently
> >> > censored responses are the same - i.e. they are just as biased. Thus
> the
> >> > bias seems to be due entirely to model mis-specification and not the
> >> > informative censoring.
> >> >
> >> >
> >> > To give a concrete example I simulate event times T_i and censoring
> >> > times
> >> > C_i from the following models;
> >> >
> >> >
> >> > T_i~ Weibull(lambda_t(x),v_t),    lambda_t(x)=lambda_t*exp( beta_t_0 +
> >> > (beta_t_1*Treat_i) + (beta_t_2*Z_i) + (beta_t_3*Treat_i*Z_i)  )
> >> >
> >> > C_i~ Weibull(lambda_c(x),v_c),    lambda_c(x)=lambda_c*exp( beta_c_0 +
> >> > (beta_c_1*Treat_i) + (beta_c_2*Z_i) + (beta_c_3*Treat_i*Z_i)  )
> >> >
> >> > D_i~Weibull(lambda_d(x),v_D), lambda_d(x)=lamda_d*exp( beta_d_0)
> >> >
> >> > where ;
> >> >
> >> > beta_t_0 = 1,  beta_t_1 = -1,   beta_t_2 = 1,  beta_t_3 = -2,
> >> > lambda_t=0.5
> >> >
> >> > beta_c_0 = 0.2,  beta_c_1 = -2,   beta_c_2 = 2,  beta_c_3 = -2,
> >> > lambda_c=0.5
> >> >
> >> > beta_d_0 = -0.7,  lambda_d=0.1
> >> >
> >> > When I fit the cox model to both the informatively censored responses
> >> > and
> >> > the independent censored responses I include only the Treatment
> >> > covariate in
> >> > the model.
> >> >
> >> > I simulate Treatment from a Bernoulli distribution with p=0.5 and Z_i
> >> > from a
> >> > beta distribution so that Z ranges from 0 to 1 (I like to think of Z
> as
> >> > a
> >> > "poor" prognosis probability where Z_i=1 means a subject is 100%
> certain
> >> > to
> >> > have a poor prognosis and Z_i=0 means zero chance). These parameter
> >> > choices
> >> > give approximately 27% and 25% censoring for the informatively
> censored
> >> > responses (using C_i) and the independent censored responses (using
> D_i)
> >> > respectively. I use N=2000 subjects and 2000 simulation replications.
> >> >
> >> > The above simulation I get estimates of beta_t_2 of -1.526 and -1.537
> >> > for
> >> > the informatively censored responses and the independent censored
> >> > responses
> >> > respectively.
> >> >
> >> > Furthermore when I fit a cox model to the full responses (no censoring
> >> > at
> >> > all) I get an estimate of beta_t_2 of -1.542. This represents the best
> >> > that
> >> > can possibly be done given that Z and Treat*Z are not in the model.
> >> > Clearly
> >> > censoring is not making much of a difference here - model
> >> > mis-specification
> >> > dominates.
> >> >
> >> > I still must be doing something wrong but I cannot figure this one
> out.
> >> >
> >> > Thanks
> >> >
> >> > Dan
> >> >
> >> >
> >> >
> >> > On Thu, Jul 23, 2015 at 12:33 AM, Greg Snow <538280 at gmail.com> wrote:
> >> >>
> >> >> I think that the Cox model still works well when the only information
> >> >> in the censoring is conditional on variables in the model.  What you
> >> >> describe could be called non-informative conditional on x.
> >> >>
> >> >> To really see the difference you need informative censoring that
> >> >> depends on something not included in the model.  One option would be
> >> >> to use copulas to generate dependent data and then transform the
> >> >> values using your Weibul.  Or you could generate your event times and
> >> >> censoring times based on x1 and x2, but then only include x1 in the
> >> >> model.
> >> >>
> >> >> On Wed, Jul 22, 2015 at 2:20 AM, Daniel Meddings <
> dpmeddings at gmail.com>
> >> >> wrote:
> >> >> > I wish to simulate event times where the censoring is informative,
> >> >> > and
> >> >> > to
> >> >> > compare parameter estimator quality from a Cox PH model with
> >> >> > estimates
> >> >> > obtained from event times generated with non-informative censoring.
> >> >> > However
> >> >> > I am struggling to do this, and I conclude rather than a technical
> >> >> > flaw
> >> >> > in
> >> >> > my code I instead do not understand what is meant by informative
> and
> >> >> > un-informative censoring.
> >> >> >
> >> >> > My approach is to simulate an event time T dependent on a vector of
> >> >> > covariates x having hazard function
> >> >> > h(t|x)=lambda*exp(beta'*x)v*t^{v-1}.
> >> >> > This corresponds to T~ Weibull(lambda(x),v), where the scale
> >> >> > parameter
> >> >> > lambda(x)=lambda*exp(beta'*x) depends on x and the shape parameter
> v
> >> >> > is
> >> >> > fixed. I have N subjects where T_{i}~ Weibull(lambda(x_{i}),v_{T}),
> >> >> > lambda(x_{i})=lambda_{T}*exp(beta_{T}'*x_{i}), for i=1,...,N. Here
> I
> >> >> > assume
> >> >> > the regression coefficients are p-dimensional.
> >> >> >
> >> >> > I generate informative censoring times C_i~
> Weibull(lambda(x_i),v_C),
> >> >> > lambda(x_i)=lambda_C*exp(beta_C'*x_i) and compute
> >> >> > Y_inf_i=min(T_i,C_i)
> >> >> > and
> >> >> > a censored flag delta_inf_i=1 if Y_inf_i <= C_i (an observed
> event),
> >> >> > and
> >> >> > delta_inf_i=0 if Y_inf_i > C_i (informatively censored: event not
> >> >> > observed). I am convinced this is informative censoring because as
> >> >> > long
> >> >> > as
> >> >> > beta_T~=0 and beta_C~=0 then for each subject the data generating
> >> >> > process
> >> >> > for T and C both depend on x.
> >> >> >
> >> >> > In contrast I generate non-informative censoring times
> >> >> > D_i~Weibull(lambda_D*exp(beta_D),v_D), and compute
> >> >> > Y_ninf_i=min(T_i,D_i)
> >> >> > and a censored flag delta_ninf_i=1 if Y_ninf_i <= D_i (an observed
> >> >> > event),
> >> >> > and delta_ninf_i=0 if Y_ninf_i > D_i (non-informatively censored:
> >> >> > event
> >> >> > not
> >> >> > observed). Here beta_D is a scalar. I "scale" the simulation by
> >> >> > choosing
> >> >> > the lambda_T, lambda_C and lambda_D parameters such that on average
> >> >> > T_i<C_i
> >> >> > and T_i<D_i to achieve X% of censored subjects for both Y_inf_i and
> >> >> > Y_ninf_i.
> >> >> >
> >> >> > The problem is that even for say 30% censoring (which I think is
> >> >> > high),
> >> >> > the
> >> >> > Cox PH parameter estimates using both Y_inf and Y_ninf are unbiased
> >> >> > when
> >> >> > I
> >> >> > expected the estimates using Y_inf to be biased, and I think I see
> >> >> > why:
> >> >> > however different beta_C is from beta_T, a censored subject can
> >> >> > presumably
> >> >> > influence the estimation of beta_T only by affecting the set of
> >> >> > subjects
> >> >> > at
> >> >> > risk at any time t, but this does not change the fact that every
> >> >> > single
> >> >> > Y_inf_i with delta_inf_i=1 will have been generated using beta_T
> >> >> > only.
> >> >> > Thus
> >> >> > I do not see how my simulation can possibly produce biased
> estimates
> >> >> > for
> >> >> > beta_T using Y_inf.
> >> >> >
> >> >> > But then what is informative censoring if not based on this
> approach?
> >> >> >
> >> >> > Any help would be greatly appreciated.
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Gregory (Greg) L. Snow Ph.D.
> >> >> 538280 at gmail.com
> >> >
> >> >
> >>
> >>
> >>
> >> --
> >> Gregory (Greg) L. Snow Ph.D.
> >> 538280 at gmail.com
> >
> >
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From dpmeddings at gmail.com  Mon Aug  3 22:49:54 2015
From: dpmeddings at gmail.com (Daniel Meddings)
Date: Mon, 3 Aug 2015 21:49:54 +0100
Subject: [R] How to simulate informative censoring in a Cox PH model?
In-Reply-To: <CAFEqCdyVFU7z-Eiwrnq3oQ2TeZZif5rRGi2S-T_6eaaQsnM1Vg@mail.gmail.com>
References: <CABrUXPWBEe_TovEoTK+wY6UWeQtNTM_j1WnOic5wG1qAJi1seg@mail.gmail.com>
	<CAFEqCdzk8cSwed-VdBrob1bzLQtx7rknK9UkNEU_bwt8auoD7A@mail.gmail.com>
	<CABrUXPVi2=GnEg14xZQ19XjJOnuW=61NVZc+Vkbfo2HDN08L8g@mail.gmail.com>
	<CAFEqCdxb9_Lv-_DoYVM26F=wOW_cJnn-FRtYubQhkbL8gWpjbw@mail.gmail.com>
	<CABrUXPWCVc_vJYqPBCkmL-30KQKAP_Hp+=2K5M0SeARU5eq+=w@mail.gmail.com>
	<CAFEqCdyVFU7z-Eiwrnq3oQ2TeZZif5rRGi2S-T_6eaaQsnM1Vg@mail.gmail.com>
Message-ID: <CABrUXPW+-1ZRbEQ+9_SJtDfvHgsr-3Hf+GH51SJ_a7Xv3znYgA@mail.gmail.com>

Hi Greg

The copulas concept seems a nicely simple way of simulating event times
that are subject to informative censoring (in contrast to the double cox
model approach I use). The correlation between the marginal uniform random
variables you speak of reminded me that my approach should also induce this
correlation, just in a different way. Similarly I should also observe zero
correlation between my event times from my outcome model and the censoring
times. Unfortunately this was not the case - to cut a long story short I
was inadvertently generating my independent censoring times from a model
that depended on covariates in the outcome model. This now explains the
mixed results I rather laboriously attempted to describe previously.

Re-running some scenarios with my new error-free code I can now clearly
observe the points you have been making, that is informative censoring only
leads to bias if the covariates in the censoring model are not in the
outcome model. Indeed I can choose the common (to both models) treatment
effect to be vastly different (with all other effects the same) and have no
bias, yet small differences in the censoring Z effect (not in the outcome
model) effect lead to moderate biases.

I am still somewhat confused at the other approach to this problem where I
have seen in various journal articles authors assuming an outcome model for
the censored subjects - i.e. an outcome model for the unobserved event
times. Using this approach the definition of informative censoring appears
to be where the observed and un-observed outcome models are different. This
approach also makes sense to me - censoring merely loses precision of the
parameter estimators due to reduced events, but does not lead to bias.
However the concept of correlated event and censoring times does not even
present itself here?

Thanks

Dan



On Fri, Jul 31, 2015 at 5:06 PM, Greg Snow <538280 at gmail.com> wrote:

> Daniel,
>
> Basically just responding to your last paragraph (the others are
> interesting, but I think that you are learning as much as anyone and I
> don't currently have any other suggestions).
>
> I am not an expert on copulas, so this is a basic understanding, you
> should learn more about them if you choose to use them.  The main idea
> of a copula is that it is a bivariate or multivariate distribution
> where all the variables have uniform marginal distributions but the
> variables are not independent from each other.  How I would suggest
> using them is to choose a copula and generate random points from a
> bivariate copula, then put those (uniform) values into the inverse pdf
> function for the Weibull (or other distribution), one of which is the
> event time, the other the censoring time.  This will give you times
> that (marginally) come from the distributions of interest, but are not
> independent (so would be considered informative censoring).  Repeat
> this with different levels of relationship in the copula to see how
> much difference it makes in your simulations.
>
> On Thu, Jul 30, 2015 at 2:02 PM, Daniel Meddings <dpmeddings at gmail.com>
> wrote:
> > Thanks Greg once more for taking the time to reply. I certainly agree
> that
> > this is not a simple set-up, although it is realistic I think. In short
> you
> > are correct about model mis-specification being the key to producing more
> > biased estimates under informative than under non-informative censoring.
> > After looking again at my code and trying various things I realize that
> the
> > key factor that leads to the informative and non-informative censoring
> data
> > giving rise to the same biased estimates is how I generate my Z_i
> variable,
> > and also the magnitude of the Z_i coefficient in both of the event and
> > informative censoring models.
> >
> > In the example I gave I generated Z_i (I think of this as a "poor
> prognosis"
> > variable) from a beta distribution so that it ranged from 0-1. The biased
> > estimates for "beta_t_1" (I think of this as the effect of a treatment on
> > survival) were approximately 1.56 when the true value was -1. What I
> forgot
> > to mention was that estimating a cox model with 1,000,000 subjects to the
> > full data (i.e. no censoring at all) arguably gives the best treatment
> > effect estimate possible given that the effects of Z_i and Z_i*Treat_i
> are
> > not in the model. This "best possible" estimate turns out to be 1.55 -
> i.e.
> > the example I gave just so happens to be such that even with 25-27%
> > censoring, the estimates obtained are almost the best that can be
> attained.
> >
> > My guess is that the informative censoring does not bias the estimate
> more
> > than non-informative censoring because the only variable not accounted
> for
> > in the model is Z_i which does not have a large enough effect "beta_t_2",
> > and/or "beta_c_2", or perhaps because Z_i only has a narrow range which
> does
> > not permit the current "beta_t_2" value to do any damage?
> >
> > To investigate the "beta_t_2", and/or "beta_c_2" issue I changed
> "beta_c_2"
> > from 2 to 7 and "beta_c_0" from 0.2 to -1.2, and "beta_d_0" from -0.7 to
> > -0.4 to keep the censoring %'s equal at about 30%. This time the "best
> > possible" estimate of "beta_t_1" was -1.53 which was similar to that
> > obtained previously. The informative censoring gave an estimate for
> > "beta_t_1" of -1.49 whereas the non-informative censoring gave -1.53 -
> this
> > time the non-informative censoring attains the "best possible" but the
> > non-informative censoring does not.
> >
> >
> >
> > I then instead changed "beta_t_2" from 1 to 7 and "beta_c_0" from 0.2 to
> 2,
> > and "beta_d_0" from -0.7 to -1.9 again to keep the censoring %'s equal at
> > about 30%. This time the "best possible" estimate of "beta_t_1" was
> -0.999
> > which is pretty much equal to the true value of -1. The informative
> > censoring gave an estimate for "beta_t_1" of -1.09 whereas the
> > non-informative censoring gave -0.87 ? surprisingly this time the
> > informative censoring is slightly closer to the ?best possible? than the
> > non-informative censoring.
> >
> >
> >
> > To investigate the Z_i issue I generated it from a normal distribution
> with
> > mean 1 and variance 1. I changed "beta_c_0 " from 0.2 to -0.5 to keep the
> > censoring levels equal (this time about 30% for both). This time the
> "best
> > possible" estimate was -1.98 which was further from -1 than previous
> > examples. The informative censoring gave an estimate for "beta_t_1" of
> -1.81
> > whereas the non-informative censoring gave -1.84. So again the
> informative
> > censoring gives an estimate closer to the "best possible" when compared
> with
> > the informative censoring, but this time it does not attain the "best
> > possible".
> >
> > In conclusion it is clear to me that a stronger Z_i effect in the
> censoring
> > model causes the informative censoring to be worse than the
> non-informative
> > one (as expected), but a stronger Z_i effect in the event model does not
> > have this effect and even causes the independent censoring to be worse ?
> > this in general may not hold but I nonetheless see it here. I am
> wondering
> > if this is because altering the treatment effect in the event model also
> > affects the independent censoring process and so it ?muddies the waters?
> > whereas altering the treatment effect in the informative censoring model
> > obviously confines the changes to just the informative censoring process.
> > For a fixed treatment effect size in both the event and informative
> > censoring models the effect of Z_i having a wider range than is possible
> > under the beta distribution also appears to produce informative censoring
> > that is worse than the non-informative one. This makes sense I think
> because
> > the Z_i-response relationship must be more informative?
> >
> >
> >
> > Thanks for your suggestion of copulas ? I have not come across these. Is
> > this similar to assuming a event model for censored subjects (this is
> > unobserved) ? i.e. if the event model is different conditional on
> censoring
> > then if we could observe the events beyond censoring then clearly the
> > parameter estimates would be different compared to those obtained when
> > modelling only non-censored times?
> >
> >
> >
> >
> > On Wed, Jul 29, 2015 at 5:37 PM, Greg Snow <538280 at gmail.com> wrote:
> >>
> >> As models become more complex it becomes harder to distinguish
> >> different parts and their effects.  Even for a straight forward linear
> >> regression model if X1 and X2 are correlated with each other then it
> >> becomes difficult to distinguish between the effects of X1^2, X2^2,
> >> and X1*X2.  In your case the informative censoring and model
> >> misspecification are becoming hard to distinguish (and it could be
> >> argued that having informative censoring is really just a form of
> >> model misspecification).  So I don't think so much that you are doing
> >> things wrong, just that you are learning that the models are complex.
> >>
> >> Another approach to simulation that you could try is to simulate the
> >> event time and censoring time using copulas (and therefore they can be
> >> correlated to give informative censoring, but without relying on a
> >> term that you could have included in the model) then consider the
> >> event censored if the censoring time is shorter.
> >>
> >> On Fri, Jul 24, 2015 at 10:14 AM, Daniel Meddings <dpmeddings at gmail.com
> >
> >> wrote:
> >> > Hi Greg
> >> >
> >> > Many thanks for taking the time to respond to my query. You are right
> >> > about
> >> > pointing out the distinction between what variables are and are not
> >> > included
> >> > in the event times process and in the censoring process. I clearly
> >> > forgot
> >> > this important aspect. I amended my code to do as you advise and now I
> >> > am
> >> > indeed getting biased estimates when using the informatively censored
> >> > responses. The problem is now that the estimates from the
> independently
> >> > censored responses are the same - i.e. they are just as biased. Thus
> the
> >> > bias seems to be due entirely to model mis-specification and not the
> >> > informative censoring.
> >> >
> >> >
> >> > To give a concrete example I simulate event times T_i and censoring
> >> > times
> >> > C_i from the following models;
> >> >
> >> >
> >> > T_i~ Weibull(lambda_t(x),v_t),    lambda_t(x)=lambda_t*exp( beta_t_0 +
> >> > (beta_t_1*Treat_i) + (beta_t_2*Z_i) + (beta_t_3*Treat_i*Z_i)  )
> >> >
> >> > C_i~ Weibull(lambda_c(x),v_c),    lambda_c(x)=lambda_c*exp( beta_c_0 +
> >> > (beta_c_1*Treat_i) + (beta_c_2*Z_i) + (beta_c_3*Treat_i*Z_i)  )
> >> >
> >> > D_i~Weibull(lambda_d(x),v_D), lambda_d(x)=lamda_d*exp( beta_d_0)
> >> >
> >> > where ;
> >> >
> >> > beta_t_0 = 1,  beta_t_1 = -1,   beta_t_2 = 1,  beta_t_3 = -2,
> >> > lambda_t=0.5
> >> >
> >> > beta_c_0 = 0.2,  beta_c_1 = -2,   beta_c_2 = 2,  beta_c_3 = -2,
> >> > lambda_c=0.5
> >> >
> >> > beta_d_0 = -0.7,  lambda_d=0.1
> >> >
> >> > When I fit the cox model to both the informatively censored responses
> >> > and
> >> > the independent censored responses I include only the Treatment
> >> > covariate in
> >> > the model.
> >> >
> >> > I simulate Treatment from a Bernoulli distribution with p=0.5 and Z_i
> >> > from a
> >> > beta distribution so that Z ranges from 0 to 1 (I like to think of Z
> as
> >> > a
> >> > "poor" prognosis probability where Z_i=1 means a subject is 100%
> certain
> >> > to
> >> > have a poor prognosis and Z_i=0 means zero chance). These parameter
> >> > choices
> >> > give approximately 27% and 25% censoring for the informatively
> censored
> >> > responses (using C_i) and the independent censored responses (using
> D_i)
> >> > respectively. I use N=2000 subjects and 2000 simulation replications.
> >> >
> >> > The above simulation I get estimates of beta_t_2 of -1.526 and -1.537
> >> > for
> >> > the informatively censored responses and the independent censored
> >> > responses
> >> > respectively.
> >> >
> >> > Furthermore when I fit a cox model to the full responses (no censoring
> >> > at
> >> > all) I get an estimate of beta_t_2 of -1.542. This represents the best
> >> > that
> >> > can possibly be done given that Z and Treat*Z are not in the model.
> >> > Clearly
> >> > censoring is not making much of a difference here - model
> >> > mis-specification
> >> > dominates.
> >> >
> >> > I still must be doing something wrong but I cannot figure this one
> out.
> >> >
> >> > Thanks
> >> >
> >> > Dan
> >> >
> >> >
> >> >
> >> > On Thu, Jul 23, 2015 at 12:33 AM, Greg Snow <538280 at gmail.com> wrote:
> >> >>
> >> >> I think that the Cox model still works well when the only information
> >> >> in the censoring is conditional on variables in the model.  What you
> >> >> describe could be called non-informative conditional on x.
> >> >>
> >> >> To really see the difference you need informative censoring that
> >> >> depends on something not included in the model.  One option would be
> >> >> to use copulas to generate dependent data and then transform the
> >> >> values using your Weibul.  Or you could generate your event times and
> >> >> censoring times based on x1 and x2, but then only include x1 in the
> >> >> model.
> >> >>
> >> >> On Wed, Jul 22, 2015 at 2:20 AM, Daniel Meddings <
> dpmeddings at gmail.com>
> >> >> wrote:
> >> >> > I wish to simulate event times where the censoring is informative,
> >> >> > and
> >> >> > to
> >> >> > compare parameter estimator quality from a Cox PH model with
> >> >> > estimates
> >> >> > obtained from event times generated with non-informative censoring.
> >> >> > However
> >> >> > I am struggling to do this, and I conclude rather than a technical
> >> >> > flaw
> >> >> > in
> >> >> > my code I instead do not understand what is meant by informative
> and
> >> >> > un-informative censoring.
> >> >> >
> >> >> > My approach is to simulate an event time T dependent on a vector of
> >> >> > covariates x having hazard function
> >> >> > h(t|x)=lambda*exp(beta'*x)v*t^{v-1}.
> >> >> > This corresponds to T~ Weibull(lambda(x),v), where the scale
> >> >> > parameter
> >> >> > lambda(x)=lambda*exp(beta'*x) depends on x and the shape parameter
> v
> >> >> > is
> >> >> > fixed. I have N subjects where T_{i}~ Weibull(lambda(x_{i}),v_{T}),
> >> >> > lambda(x_{i})=lambda_{T}*exp(beta_{T}'*x_{i}), for i=1,...,N. Here
> I
> >> >> > assume
> >> >> > the regression coefficients are p-dimensional.
> >> >> >
> >> >> > I generate informative censoring times C_i~
> Weibull(lambda(x_i),v_C),
> >> >> > lambda(x_i)=lambda_C*exp(beta_C'*x_i) and compute
> >> >> > Y_inf_i=min(T_i,C_i)
> >> >> > and
> >> >> > a censored flag delta_inf_i=1 if Y_inf_i <= C_i (an observed
> event),
> >> >> > and
> >> >> > delta_inf_i=0 if Y_inf_i > C_i (informatively censored: event not
> >> >> > observed). I am convinced this is informative censoring because as
> >> >> > long
> >> >> > as
> >> >> > beta_T~=0 and beta_C~=0 then for each subject the data generating
> >> >> > process
> >> >> > for T and C both depend on x.
> >> >> >
> >> >> > In contrast I generate non-informative censoring times
> >> >> > D_i~Weibull(lambda_D*exp(beta_D),v_D), and compute
> >> >> > Y_ninf_i=min(T_i,D_i)
> >> >> > and a censored flag delta_ninf_i=1 if Y_ninf_i <= D_i (an observed
> >> >> > event),
> >> >> > and delta_ninf_i=0 if Y_ninf_i > D_i (non-informatively censored:
> >> >> > event
> >> >> > not
> >> >> > observed). Here beta_D is a scalar. I "scale" the simulation by
> >> >> > choosing
> >> >> > the lambda_T, lambda_C and lambda_D parameters such that on average
> >> >> > T_i<C_i
> >> >> > and T_i<D_i to achieve X% of censored subjects for both Y_inf_i and
> >> >> > Y_ninf_i.
> >> >> >
> >> >> > The problem is that even for say 30% censoring (which I think is
> >> >> > high),
> >> >> > the
> >> >> > Cox PH parameter estimates using both Y_inf and Y_ninf are unbiased
> >> >> > when
> >> >> > I
> >> >> > expected the estimates using Y_inf to be biased, and I think I see
> >> >> > why:
> >> >> > however different beta_C is from beta_T, a censored subject can
> >> >> > presumably
> >> >> > influence the estimation of beta_T only by affecting the set of
> >> >> > subjects
> >> >> > at
> >> >> > risk at any time t, but this does not change the fact that every
> >> >> > single
> >> >> > Y_inf_i with delta_inf_i=1 will have been generated using beta_T
> >> >> > only.
> >> >> > Thus
> >> >> > I do not see how my simulation can possibly produce biased
> estimates
> >> >> > for
> >> >> > beta_T using Y_inf.
> >> >> >
> >> >> > But then what is informative censoring if not based on this
> approach?
> >> >> >
> >> >> > Any help would be greatly appreciated.
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Gregory (Greg) L. Snow Ph.D.
> >> >> 538280 at gmail.com
> >> >
> >> >
> >>
> >>
> >>
> >> --
> >> Gregory (Greg) L. Snow Ph.D.
> >> 538280 at gmail.com
> >
> >
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From karl.schilling at uni-bonn.de  Tue Aug  4 10:50:07 2015
From: karl.schilling at uni-bonn.de (Karl Schilling)
Date: Tue, 4 Aug 2015 10:50:07 +0200
Subject: [R] dplyr and function length()
Message-ID: <55C07CBF.2080505@uni-bonn.de>

Dear All,

I have an observation / question about how the function length() works 
once package dplyr is loaded.

Say we have a data.frame  df with n rows and m columns. Then a way to 
get the number of rows is to use

length(df$m1)  (m1 here stand is as the header of the first column)

or, alternatively

length(df[,1]).

Both commands will return n.

However, once dplyr is loaded,

length(df[,1]) will return a value of 1.

length(df$m1) and also length(df[[1]]) will correctly return n.

I know that using length() may not be the most elegant or efficient way 
to get the value of n. However, what puzzles (and somewhat disturbs) me 
is that loading of dplyr affects how length() works, without there being 
a warning or masking message upon loading it.

Any clarification or comment would be welcome.

Thank you so much,

Karl


-- 
Karl Schilling


From pdalgd at gmail.com  Tue Aug  4 11:06:44 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 4 Aug 2015 11:06:44 +0200
Subject: [R] dplyr and function length()
In-Reply-To: <55C07CBF.2080505@uni-bonn.de>
References: <55C07CBF.2080505@uni-bonn.de>
Message-ID: <27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>


On 04 Aug 2015, at 10:50 , Karl Schilling <karl.schilling at uni-bonn.de> wrote:

> Dear All,
> 
> I have an observation / question about how the function length() works once package dplyr is loaded.
> 
> Say we have a data.frame  df with n rows and m columns. Then a way to get the number of rows is to use
> 
> length(df$m1)  (m1 here stand is as the header of the first column)
> 
> or, alternatively
> 
> length(df[,1]).
> 
> Both commands will return n.
> 
> However, once dplyr is loaded,
> 
> length(df[,1]) will return a value of 1.
> 
> length(df$m1) and also length(df[[1]]) will correctly return n.
> 
> I know that using length() may not be the most elegant or efficient way to get the value of n. However, what puzzles (and somewhat disturbs) me is that loading of dplyr affects how length() works, without there being a warning or masking message upon loading it.
> 
> Any clarification or comment would be welcome.

Presumably, dplyr changes how [.data.frame works (by altering the default for drop=, I expect) so that df[,1] is a data frame with 1 variable and not a vector. And yes, that _is_ somewhat disturbing.

-pd 

> 
> Thank you so much,
> 
> Karl
> 
> 
> -- 
> Karl Schilling
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Tue Aug  4 12:20:36 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 04 Aug 2015 06:20:36 -0400
Subject: [R] dplyr and function length()
In-Reply-To: <27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>
References: <55C07CBF.2080505@uni-bonn.de>
	<27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>
Message-ID: <AFDDC9AC-7E8C-4322-9F29-515ADCF34922@dcn.davis.CA.us>

I can confirm that the drop default is different, but keep in mind that it is only changed for a tbl_df so just convert back to data.frame at the end of your dplr operations to get back to your familiar data.frame behavior.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 4, 2015 5:06:44 AM EDT, peter dalgaard <pdalgd at gmail.com> wrote:
>
>On 04 Aug 2015, at 10:50 , Karl Schilling <karl.schilling at uni-bonn.de>
>wrote:
>
>> Dear All,
>> 
>> I have an observation / question about how the function length()
>works once package dplyr is loaded.
>> 
>> Say we have a data.frame  df with n rows and m columns. Then a way to
>get the number of rows is to use
>> 
>> length(df$m1)  (m1 here stand is as the header of the first column)
>> 
>> or, alternatively
>> 
>> length(df[,1]).
>> 
>> Both commands will return n.
>> 
>> However, once dplyr is loaded,
>> 
>> length(df[,1]) will return a value of 1.
>> 
>> length(df$m1) and also length(df[[1]]) will correctly return n.
>> 
>> I know that using length() may not be the most elegant or efficient
>way to get the value of n. However, what puzzles (and somewhat
>disturbs) me is that loading of dplyr affects how length() works,
>without there being a warning or masking message upon loading it.
>> 
>> Any clarification or comment would be welcome.
>
>Presumably, dplyr changes how [.data.frame works (by altering the
>default for drop=, I expect) so that df[,1] is a data frame with 1
>variable and not a vector. And yes, that _is_ somewhat disturbing.
>
>-pd 
>
>> 
>> Thank you so much,
>> 
>> Karl
>> 
>> 
>> -- 
>> Karl Schilling
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From karl.schilling at uni-bonn.de  Tue Aug  4 12:51:30 2015
From: karl.schilling at uni-bonn.de (Karl Schilling)
Date: Tue, 4 Aug 2015 12:51:30 +0200
Subject: [R] dplyr and function length()
In-Reply-To: <AFDDC9AC-7E8C-4322-9F29-515ADCF34922@dcn.davis.CA.us>
References: <55C07CBF.2080505@uni-bonn.de>
	<27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>
	<AFDDC9AC-7E8C-4322-9F29-515ADCF34922@dcn.davis.CA.us>
Message-ID: <55C09932.7060305@uni-bonn.de>

Dear Jeff:

No, the effect I described has nothing to do wit USING dplyr. It occurs 
with any (preexisting) data.frame once dplyr is LOADED (require(dplyr). 
It is this silent, sort of "backward acting" effect that disturbs me.

Best,

Karl Schilling

On 04.08.2015 12:20, Jeff Newmiller wrote:
> I can confirm that the drop default is different, but keep in mind that it is only changed for a tbl_df so just convert back to data.frame at the end of your dplr operations to get back to your familiar data.frame behavior.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>         Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 4, 2015 5:06:44 AM EDT, peter dalgaard<pdalgd at gmail.com>  wrote:
>> >
>> >On 04 Aug 2015, at 10:50 , Karl Schilling<karl.schilling at uni-bonn.de>
>> >wrote:
>> >
>>> >>Dear All,
>>> >>
>>> >>I have an observation / question about how the function length()
>> >works once package dplyr is loaded.
>>> >>
>>> >>Say we have a data.frame  df with n rows and m columns. Then a way to
>> >get the number of rows is to use
>>> >>
>>> >>length(df$m1)  (m1 here stand is as the header of the first column)
>>> >>
>>> >>or, alternatively
>>> >>
>>> >>length(df[,1]).
>>> >>
>>> >>Both commands will return n.
>>> >>
>>> >>However, once dplyr is loaded,
>>> >>
>>> >>length(df[,1]) will return a value of 1.
>>> >>
>>> >>length(df$m1) and also length(df[[1]]) will correctly return n.
>>> >>
>>> >>I know that using length() may not be the most elegant or efficient
>> >way to get the value of n. However, what puzzles (and somewhat
>> >disturbs) me is that loading of dplyr affects how length() works,
>> >without there being a warning or masking message upon loading it.
>>> >>
>>> >>Any clarification or comment would be welcome.
>> >
>> >Presumably, dplyr changes how [.data.frame works (by altering the
>> >default for drop=, I expect) so that df[,1] is a data frame with 1
>> >variable and not a vector. And yes, that_is_  somewhat disturbing.
>> >
>> >-pd
>> >
>>> >>
>>> >>Thank you so much,
>>> >>
>>> >>Karl
>>> >>
>>> >>
>>> >>--
>>> >>Karl Schilling
>>> >>

-- 
Karl Schilling


From h.wickham at gmail.com  Tue Aug  4 13:14:19 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 4 Aug 2015 06:14:19 -0500
Subject: [R] dplyr and function length()
In-Reply-To: <55C09932.7060305@uni-bonn.de>
References: <55C07CBF.2080505@uni-bonn.de>
	<27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>
	<AFDDC9AC-7E8C-4322-9F29-515ADCF34922@dcn.davis.CA.us>
	<55C09932.7060305@uni-bonn.de>
Message-ID: <CABdHhvFgRDNNyT769FyjjdAWS3+o_WAD1fiijvaUq2QOAXmUuA@mail.gmail.com>

> No, the effect I described has nothing to do wit USING dplyr. It occurs with
> any (preexisting) data.frame once dplyr is LOADED (require(dplyr). It is
> this silent, sort of "backward acting" effect that disturbs me.

You're going to need to provide some evidence for that charge: dplyr
does not affect the behaviour of data.frames (only tbl_dfs)

Hadley

-- 
http://had.co.nz/


From h.wickham at gmail.com  Tue Aug  4 13:16:02 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 4 Aug 2015 06:16:02 -0500
Subject: [R] dplyr and function length()
In-Reply-To: <27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>
References: <55C07CBF.2080505@uni-bonn.de>
	<27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>
Message-ID: <CABdHhvHt=Sb85FoHjU5rHK9MuBrz6U-3VVdx4CZ88bDxiqZzYw@mail.gmail.com>

>> length(df[,1]).
>>
>> Both commands will return n.
>>
>> However, once dplyr is loaded,
>>
>> length(df[,1]) will return a value of 1.
>>
>> length(df$m1) and also length(df[[1]]) will correctly return n.
>>
>> I know that using length() may not be the most elegant or efficient way to get the value of n. However, what puzzles (and somewhat disturbs) me is that loading of dplyr affects how length() works, without there being a warning or masking message upon loading it.
>>
>> Any clarification or comment would be welcome.
>
> Presumably, dplyr changes how [.data.frame works (by altering the default for drop=, I expect) so that df[,1] is a data frame with 1 variable and not a vector. And yes, that _is_ somewhat disturbing.

It changes the behaviour for [.tbl_df (tbl_df is a very minor
extension of data frame with custom [ and print methods).  This is
partly an experiment to see what happens when you make [ more
consistent - [.tbl_df always returns a data frame, so if you want a
vector you have to use [[.

Hadley

-- 
http://had.co.nz/


From highstat at highstat.com  Tue Aug  4 14:05:24 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 04 Aug 2015 21:35:24 +0930
Subject: [R] Course: Introduction to zero inflated models
Message-ID: <55C0AA84.7060101@highstat.com>

Apologies for cross-posting

We would like to announce the following statistics course:

Course: Introduction to zero inflated models
Where:  Elche (close to Alicante), Spain
When:   2-6 November 2015

Course website: http://www.highstat.com/statscourse.htm
Flyer: http://www.highstat.com/Courses/Flyers/Flyer2015_11Elche.pdf


Kind regards,

Alain Zuur







-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From john.archie.mckown at gmail.com  Tue Aug  4 14:14:57 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 4 Aug 2015 07:14:57 -0500
Subject: [R] Course: Introduction to zero inflated models
In-Reply-To: <55C0AA84.7060101@highstat.com>
References: <55C0AA84.7060101@highstat.com>
Message-ID: <CAAJSdjgeTAOYfzsgmmHrFzMNDrDRHD-hABcMwXAbAbJJXchq0g@mail.gmail.com>

On Tue, Aug 4, 2015 at 7:05 AM, Highland Statistics Ltd <
highstat at highstat.com> wrote:

> Apologies for cross-posting
>

?Apologies for UCE does not make it any less objectionable.? But I would
love a "working" vacation in the U.K.

-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From karl.schilling at uni-bonn.de  Tue Aug  4 14:55:55 2015
From: karl.schilling at uni-bonn.de (Karl Schilling)
Date: Tue, 4 Aug 2015 14:55:55 +0200
Subject: [R] dplyr and function length() and some apologies
In-Reply-To: <CABdHhvFgRDNNyT769FyjjdAWS3+o_WAD1fiijvaUq2QOAXmUuA@mail.gmail.com>
References: <55C07CBF.2080505@uni-bonn.de>
	<27BD3A8C-C77E-47BF-93CB-9ED891C83A78@gmail.com>
	<AFDDC9AC-7E8C-4322-9F29-515ADCF34922@dcn.davis.CA.us>
	<55C09932.7060305@uni-bonn.de>
	<CABdHhvFgRDNNyT769FyjjdAWS3+o_WAD1fiijvaUq2QOAXmUuA@mail.gmail.com>
Message-ID: <55C0B65B.8020104@uni-bonn.de>

Dear Hadley:

your request for evidence for my observation seems to have paved the way 
to solve this issue. As it turns out, the effect I described only occurs 
with "data.frames" read in with readxl. Clearly, I missed that these are 
tbl_df. And that explains the differential behavior depending on whether 
dplyr is loaded or not. Also, I realize that this latter effect can be 
avoided by explicitly converting objects read in with readxl to a 
data.frame.

Well, I should have known that if i had carefully read the README stuff 
for readxl. But then, readxl is so much of an every-day tool for me that 
I didn't even think of its involvement in my problem, all the more as 
the reference manual does not mention the format/class of objects read 
in with readxl.

So my apologies for any confusion I may have caused - and I certainly 
did not mean my observation as a charge against dplyr or its authors. 
Quite to the contrary, i appreciate thees tools, and as you may see, 
tray to understand and use them.

Thank you so much again

Karl

On 04.08.2015 13:14, Hadley Wickham wrote:
>> No, the effect I described has nothing to do wit USING dplyr. It occurs with
>> >any (preexisting) data.frame once dplyr is LOADED (require(dplyr). It is
>> >this silent, sort of "backward acting" effect that disturbs me.
> You're going to need to provide some evidence for that charge: dplyr
> does not affect the behaviour of data.frames (only tbl_dfs)
>
> Hadley

-- 
Karl Schilling


From rhelpmaillist at 163.com  Tue Aug  4 09:30:45 2015
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 4 Aug 2015 15:30:45 +0800 (CST)
Subject: [R]  how to use nlme  package to analysis mixed effect model
Message-ID: <383a7045.2c88d.14ef79ea2e9.Coremail.rhelpmaillist@163.com>


Dear experts,
? ?i want to use nlme or plm to?analysis mixed effect model, my data has the format :


? city ?year ?area ? ?y ? x ??
? ?1 ? ?2010 ? A ? ? 1.2 ? 2
? ?1 ? ?2011 ? A ? ? 3 ? ?3
? ? 2 ? 2010 ? A ? ? 5 ? ?4
? ? 2 ? 2011 ? A ? ?2.1 ? 1.8? ? 3 ?2010 ?B ? ? ?1.7 ? ?2
? ? ? ........


I want to know does y has relationsheep with x? how to use nlme or plm to do the ?task? ?the two packages seems does not have viggnette to guide me ? Does anyone happen to know ?


--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From Mike.Conklin at gfk.com  Tue Aug  4 16:40:46 2015
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Tue, 4 Aug 2015 16:40:46 +0200
Subject: [R] attributes in dplyr and haven
Message-ID: <FB454C9C2759D64BA12708C3073C30BB81F782B7F4@NUEW-EXMBCRB1.gfk.com>

I read in spss files using haven's read_spss. Each column then gets attributes assigned named
label - a long description of the variable
class -" labelled"
labels --- answer labels i.e. 1=Male, 2=Female
 example -
> attributes(KPTV[[3]])
$label
[1] "DERIVED: Survey language"

$class
[1] "labelled"

$labels
English Spanish 
      1       2 

However, if I subset the data.frame  e.g. MassTV<-KPTV[row selection logic,] the label attribute disappears

attributes(MassTV[[3]])
$labels
English Spanish 
      1       2 

$class
[1] "labelled"

If I use dplyr to filter the data I simply get an ERROR that the label attribute is not supported.

> MassTV<-filter(KPTV,KPTV$MNO %in% KPMass$`KPMain$mno`)
Error: column 'MNO' of type numeric has unsupported attributes: label

Any ideas on how I can preserve the label attribute (i.e. the long description of the variable name?)

Thanks for any help,

Mike

--
W. Michael Conklin
Executive Vice President
Marketing & Data Sciences - North America
GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
mike.conklin at gfk.com 
T +1 763 417 4545 | M +1 612 567 8287 
www.gfk.com 


From demmitba at gmail.com  Tue Aug  4 16:51:24 2015
From: demmitba at gmail.com (Brittany Demmitt)
Date: Tue, 4 Aug 2015 08:51:24 -0600
Subject: [R] write.csv file= question
Message-ID: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>

Hello,

I have a quick question about the ?file=? specification for the command write.csv.    When I run this command in Rstudio I do not need the ?file=? specified.  For example the below command works just fine.

write.csv(data,?/home/data.csv?)   

However when I am running an Rscript from the terminal and putting it in the background I need to specify ?file=?.  So for the example above I need to instead have

write.csv(data,file=?/home/data.csv?)   

Any ideas why this is the case?  Writing file= isn?t a problem, just trying to get an idea of how R works better.

Thanks!


From jrkrideau at inbox.com  Tue Aug  4 17:04:42 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 4 Aug 2015 07:04:42 -0800
Subject: [R] write.csv file= question
In-Reply-To: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
Message-ID: <C9AF90CFBE3.000001DBjrkrideau@inbox.com>

You probably need to ask this on a RStudio forum but my guess is it is just a little 'refinement' that the RStudio people added. Similar in concept o the the matching "".  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: demmitba at gmail.com
> Sent: Tue, 4 Aug 2015 08:51:24 -0600
> To: r-help at r-project.org
> Subject: [R] write.csv file= question
> 
> Hello,
> 
> I have a quick question about the ?file=? specification for the command
> write.csv.    When I run this command in Rstudio I do not need the
> ?file=? specified.  For example the below command works just fine.
> 
> write.csv(data,?/home/data.csv?)
> 
> However when I am running an Rscript from the terminal and putting it in
> the background I need to specify ?file=?.  So for the example above I
> need to instead have
> 
> write.csv(data,file=?/home/data.csv?)
> 
> Any ideas why this is the case?  Writing file= isn?t a problem, just
> trying to get an idea of how R works better.
> 
> Thanks!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From demmitba at gmail.com  Tue Aug  4 17:05:34 2015
From: demmitba at gmail.com (Brittany Demmitt)
Date: Tue, 4 Aug 2015 09:05:34 -0600
Subject: [R] write.csv file= question
In-Reply-To: <C9AF90CFBE3.000001DBjrkrideau@inbox.com>
References: <C9AF90CFBE3.000001DBjrkrideau@inbox.com>
Message-ID: <9D7344BB-B47F-4FA4-B931-97D5B3054A58@gmail.com>

Thanks!

> On Aug 4, 2015, at 9:04 AM, John Kane <jrkrideau at inbox.com> wrote:
> 
> You probably need to ask this on a RStudio forum but my guess is it is just a little 'refinement' that the RStudio people added. Similar in concept o the the matching "".  
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: demmitba at gmail.com
>> Sent: Tue, 4 Aug 2015 08:51:24 -0600
>> To: r-help at r-project.org
>> Subject: [R] write.csv file= question
>> 
>> Hello,
>> 
>> I have a quick question about the ?file=? specification for the command
>> write.csv.    When I run this command in Rstudio I do not need the
>> ?file=? specified.  For example the below command works just fine.
>> 
>> write.csv(data,?/home/data.csv?)
>> 
>> However when I am running an Rscript from the terminal and putting it in
>> the background I need to specify ?file=?.  So for the example above I
>> need to instead have
>> 
>> write.csv(data,file=?/home/data.csv?)
>> 
>> Any ideas why this is the case?  Writing file= isn?t a problem, just
>> trying to get an idea of how R works better.
>> 
>> Thanks!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
> Check it out at http://mysecurelogon.com/password-manager
> 
> 


From istazahn at gmail.com  Tue Aug  4 17:12:20 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 4 Aug 2015 11:12:20 -0400
Subject: [R] write.csv file= question
In-Reply-To: <C9AF90CFBE3.000001DBjrkrideau@inbox.com>
References: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
	<C9AF90CFBE3.000001DBjrkrideau@inbox.com>
Message-ID: <CA+vqiLEcfn--F1hZXO5rz5vQ1L_U6ZRDrPbekOBvD_XhWW6Lqw@mail.gmail.com>

On Tue, Aug 4, 2015 at 11:04 AM, John Kane <jrkrideau at inbox.com> wrote:
> You probably need to ask this on a RStudio forum but my guess is it is just a little 'refinement' that the RStudio people added. Similar in concept o the the matching "".

Really? write.csv(data,?/home/data.csv?) works for me in Rstudio, ESS,
Terminal, Rscript etc.

>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: demmitba at gmail.com
>> Sent: Tue, 4 Aug 2015 08:51:24 -0600
>> To: r-help at r-project.org
>> Subject: [R] write.csv file= question
>>
>> Hello,
>>
>> I have a quick question about the ?file=? specification for the command
>> write.csv.    When I run this command in Rstudio I do not need the
>> ?file=? specified.  For example the below command works just fine.
>>
>> write.csv(data,?/home/data.csv?)
>>
>> However when I am running an Rscript from the terminal and putting it in
>> the background I need to specify ?file=?.  So for the example above I
>> need to instead have
>>
>> write.csv(data,file=?/home/data.csv?)
>>
>> Any ideas why this is the case?  Writing file= isn?t a problem, just
>> trying to get an idea of how R works better.
>>
>> Thanks!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sergio.fonda99 at gmail.com  Tue Aug  4 17:13:18 2015
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Tue, 4 Aug 2015 17:13:18 +0200
Subject: [R] write.csv file= question
In-Reply-To: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
References: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
Message-ID: <CAJRuHoot7mX-2B0fvstvhR=VvaWeQg_jmJFw_pcDgwkCFM7+Qg@mail.gmail.com>

Call getwd() in both terminal and your RStudio environments and compare
results
Il 04/ago/2015 16:53, "Brittany Demmitt" <demmitba at gmail.com> ha scritto:

> Hello,
>
> I have a quick question about the ?file=? specification for the command
> write.csv.    When I run this command in Rstudio I do not need the ?file=?
> specified.  For example the below command works just fine.
>
> write.csv(data,?/home/data.csv?)
>
> However when I am running an Rscript from the terminal and putting it in
> the background I need to specify ?file=?.  So for the example above I need
> to instead have
>
> write.csv(data,file=?/home/data.csv?)
>
> Any ideas why this is the case?  Writing file= isn?t a problem, just
> trying to get an idea of how R works better.
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Aug  4 17:15:16 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 4 Aug 2015 15:15:16 +0000
Subject: [R] write.csv file= question
In-Reply-To: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
References: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B1385@mb02.ads.tamu.edu>

I cannot reproduce your problem on a Windows 8 machine with R version 3.2.1. It is working fine for me without "file=" when I source() a script file from the console. 

Open a script file and add the following commands:

test <- data.frame(x=rnorm(15, 10, 2), y=rnorm(15, 15, 3))
write.csv(test, "test.csv")
file.info("Test.csv")

Save it as test.R and then source it:
> source("Test.R", echo=TRUE)

> test <- data.frame(x=rnorm(15, 10, 2), y=rnorm(15, 15, 3))

> write.csv(test, "test.csv")

> file.info("Test.csv")
         size isdir mode               mtime               ctime
Test.csv  600 FALSE  666 2015-08-04 10:13:23 2015-08-04 10:11:56
                       atime exe
Test.csv 2015-08-04 10:11:56  no


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Brittany Demmitt
Sent: Tuesday, August 4, 2015 9:51 AM
To: r-help at r-project.org
Subject: [R] write.csv file= question

Hello,

I have a quick question about the ?file=? specification for the command write.csv.    When I run this command in Rstudio I do not need the ?file=? specified.  For example the below command works just fine.

write.csv(data,?/home/data.csv?)   

However when I am running an Rscript from the terminal and putting it in the background I need to specify ?file=?.  So for the example above I need to instead have

write.csv(data,file=?/home/data.csv?)   

Any ideas why this is the case?  Writing file= isn?t a problem, just trying to get an idea of how R works better.

Thanks!

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From istazahn at gmail.com  Tue Aug  4 17:20:36 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 4 Aug 2015 11:20:36 -0400
Subject: [R] write.csv file= question
In-Reply-To: <CA+vqiLEcfn--F1hZXO5rz5vQ1L_U6ZRDrPbekOBvD_XhWW6Lqw@mail.gmail.com>
References: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
	<C9AF90CFBE3.000001DBjrkrideau@inbox.com>
	<CA+vqiLEcfn--F1hZXO5rz5vQ1L_U6ZRDrPbekOBvD_XhWW6Lqw@mail.gmail.com>
Message-ID: <CA+vqiLGcj_4EbmdHW6KHN3qwj0N5C9VBANbNhPO5D03rkepqsg@mail.gmail.com>

On Tue, Aug 4, 2015 at 11:12 AM, Ista Zahn <istazahn at gmail.com> wrote:
> On Tue, Aug 4, 2015 at 11:04 AM, John Kane <jrkrideau at inbox.com> wrote:
>> You probably need to ask this on a RStudio forum but my guess is it is just a little 'refinement' that the RStudio people added. Similar in concept o the the matching "".
>
> Really? write.csv(data,?/home/data.csv?) works for me in Rstudio, ESS,
> Terminal, Rscript etc.

Well, actually I misspoke. I don't actually have permission to write
to "/home" on my system. But

write.csv(data, "~/data.csv")

works.

>
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>> -----Original Message-----
>>> From: demmitba at gmail.com
>>> Sent: Tue, 4 Aug 2015 08:51:24 -0600
>>> To: r-help at r-project.org
>>> Subject: [R] write.csv file= question
>>>
>>> Hello,
>>>
>>> I have a quick question about the ?file=? specification for the command
>>> write.csv.    When I run this command in Rstudio I do not need the
>>> ?file=? specified.  For example the below command works just fine.
>>>
>>> write.csv(data,?/home/data.csv?)
>>>
>>> However when I am running an Rscript from the terminal and putting it in
>>> the background I need to specify ?file=?.  So for the example above I
>>> need to instead have
>>>
>>> write.csv(data,file=?/home/data.csv?)
>>>
>>> Any ideas why this is the case?  Writing file= isn?t a problem, just
>>> trying to get an idea of how R works better.
>>>
>>> Thanks!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Tue Aug  4 18:24:08 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 4 Aug 2015 11:24:08 -0500
Subject: [R] attributes in dplyr and haven
In-Reply-To: <FB454C9C2759D64BA12708C3073C30BB81F782B7F4@NUEW-EXMBCRB1.gfk.com>
References: <FB454C9C2759D64BA12708C3073C30BB81F782B7F4@NUEW-EXMBCRB1.gfk.com>
Message-ID: <CABdHhvGKj1xqCqK4=TxY_EuTRnHgSx6JAq9NGKCFfTUEkU3hMw@mail.gmail.com>

Install the latest version of dplyr? Should be fixed there.
Hadley

On Tue, Aug 4, 2015 at 9:40 AM, Conklin, Mike (GfK)
<Mike.Conklin at gfk.com> wrote:
> I read in spss files using haven's read_spss. Each column then gets attributes assigned named
> label - a long description of the variable
> class -" labelled"
> labels --- answer labels i.e. 1=Male, 2=Female
>  example -
>> attributes(KPTV[[3]])
> $label
> [1] "DERIVED: Survey language"
>
> $class
> [1] "labelled"
>
> $labels
> English Spanish
>       1       2
>
> However, if I subset the data.frame  e.g. MassTV<-KPTV[row selection logic,] the label attribute disappears
>
> attributes(MassTV[[3]])
> $labels
> English Spanish
>       1       2
>
> $class
> [1] "labelled"
>
> If I use dplyr to filter the data I simply get an ERROR that the label attribute is not supported.
>
>> MassTV<-filter(KPTV,KPTV$MNO %in% KPMass$`KPMain$mno`)
> Error: column 'MNO' of type numeric has unsupported attributes: label
>
> Any ideas on how I can preserve the label attribute (i.e. the long description of the variable name?)
>
> Thanks for any help,
>
> Mike
>
> --
> W. Michael Conklin
> Executive Vice President
> Marketing & Data Sciences - North America
> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
> mike.conklin at gfk.com
> T +1 763 417 4545 | M +1 612 567 8287
> www.gfk.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From barbara.rogo at uniroma1.it  Tue Aug  4 19:25:20 2015
From: barbara.rogo at uniroma1.it (Barbara Rogo)
Date: Tue, 4 Aug 2015 19:25:20 +0200
Subject: [R] GARCH model estimation
Message-ID: <CAL+pVGi9VNReMuzZSt67O4gZqKg-DO0pT0YCfLz2=CaG_c8K3g@mail.gmail.com>

I have to estimate the volatility of FTSE/MIB index with a GARCH model from
2012-06-21 to 2015-04-30, in every day. I use garchFit function, but I
don't understand the meaning of se.coef output. Does this function estimate
the volatility in every day of the time series (in input)? So does it
estimate three parameters (for example if the model is GARCH(1,1)) in every
day?

Thanks for your help.

Barbara

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Tue Aug  4 19:43:32 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 4 Aug 2015 13:43:32 -0400
Subject: [R] Households per Census block
In-Reply-To: <CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
	<CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
	<CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>
Message-ID: <3F75011A-C6CB-4AAB-BC1E-4D9C6472F465@gmail.com>

I had to download a bunch of stuff but I got it mostly working.

Unfortunately using the alternative method I get the following:

> housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
Error in file(con, "r") : cannot open the connection
In addition: Warning message:
In file(con, "r") : cannot open: HTTP status was '400 Bad Request?

I have a feeling that this is not a problem with the API.

Thanks for your help,
KW







> On Aug 3, 2015, at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
> 
> Hi Anthony and Keith Weintraub,
> 
> Here is a way to do what you are asking using the UScensus2010 packages:
> 
> ## latest version of the package, not yet on CRAN
> install.packages("UScensus2010", repos="http://R-Forge.R-project.org")
> library(UScensus2010)
> install.blk()
> library(UScensus2010blk)
> ### You will want the H0010001 variable (see help(alabama.blk10))
> ### Other variables are also available
> ### You can use the new api function in UScensus2010 to get arbitrary variables from SF1 and acs
> 
> data(states.names)
> head(states.names)
> state.blk.housing<-vector("list",length(states.names))
> ## notice this could be greatly spead up using the library(parallel) 
> ## with mclapply
> ## This will be somewhat slow b/c of so much spatial data
> for(i in 1:length(states.names)){
> 	data(list=paste(states.names[i],"blk10",sep="."))
> 	temp<-get(paste(states.names[i],"blk10",sep="."))
> 	 #unique b/c more shapefiles than fips
> 	state.blk.housing[[i]]<-unique(temp at data[,c("fips","H0010001")])
> 	print(i)
> 	rm(paste(states.names,"blk10",sep="."))
> }
> 
> ###########
> # alternatively Using the US Census API function in the new UScensus2010 package
> ###########
> 
> ## Get all states fips code
> data(countyfips)
> state.fips<-unique(substr(countyfips$fips,1,2))
> head(state.fips)
> length(state.fips) ## will be 51=50 (states)+ 1(DC)
> ## You will need a census key
> key<-"YOUR KEY HERE"
> housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
> 
> Best,
> 
> -- Zack
> ---------------------------------------------------------
> Zack W.  Almquist
> Assistant Professor
> Department of Sociology and School of Statistics
> Affiliate, Minnesota Population Center
> University of Minnesota
> 
> 
> On Mon, Aug 3, 2015 at 12:43 PM, Anthony Damico <ajdamico at gmail.com> wrote:
> hi, ccing the package maintainer.  one alternative is to pull the HU100 variable directly from the census bureau's summary files: that variable starts at position 328 and ends at 336.  just modify this loop and you'll get a table with one-record-per-census-block in every state.
> 
> https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104
> 
> (1) line 134 change the very last -9 to 9
> (2) line 137 between "pop100" and "intptlat" add an "hu100"
> 
> 
> summary file docs-
> 
> http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18
> 
> 
> 
> On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:
> Folks,
> 
> I am using the UScensus2010 package and I am trying to figure out the number of households per census block.
> 
> There are a number of possible data downloads in the package but apparently I am not smart enough to figure out which data-set is appropriate and what functions to use.
> 
> Any help or pointers or links would be greatly appreciated.
> 
> Thanks for your time,
> Best,
> KW
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 


From aprilgracesmith at gmail.com  Tue Aug  4 19:58:19 2015
From: aprilgracesmith at gmail.com (April Smith)
Date: Tue, 4 Aug 2015 10:58:19 -0700
Subject: [R] Help with Plot
Message-ID: <CAKcEf9C6WuWMzyG=M4m5BDbp4rz42+K6BzLQDxs81YShoCTsSQ@mail.gmail.com>

Let me just preface that everything I know about writing code for R is self
taught so this may be really basic but I can't figure it out!

I am using someone else code to create plots.  I would like to change the
automatically generated colors to the same colors for every plot.  The
current code makes the highest line in the graph black, the second highest
line red, 3rd blue, etc, regardless of what the line represents.  I need to
create 10 of these plots and it gets confusing when the black line means a
different thing in each plot!   Here is the line I need to adjust, I just
don't know how.

lines(1:orders, x[i,], col=i)

Here is the code in entirety:
plot.hill <- function(x, scales = c(0, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64,
   Inf), ...) {
   require(vegan)
   nsites <- if(is.null(ncol(x))) 1 else ncol(x)
   x <- renyi(t(x), scales=scales, hill=TRUE)
   orders <- length(scales)
   if(nsites > 1) {
      x <- x[order(x[,1], decreasing=TRUE),]
      OP <- matrix(".   ", nsites,nsites)
      colnames(OP) <- rownames(OP) <- rownames(x)
      for(i in 1:(nsites-1))
         for(j in (i+1):nsites)
            if(all(x[i,] > x[j,])) {
               OP[i,j] <- "<   "
               OP[j,i] <- "^   "
            }
      diag(OP) <- " "
      OP <- as.data.frame(OP)
      cat("The arrow < or ^ points to the more diverse site:\n")
      print(OP, na.print=" ")
   } else
      OP <- NULL
   plot(1:4,1:4,type="n",xlim=c(0.9,orders+0.1),ylim=range(0,x),axes=FALSE,
      ylab="Hill Diversity Numbers",xlab="Order", ...)
   axis(2)
   axis(1, at=1:orders, labels=scales)
   if(nsites > 1) {
      for(i in 1:nsites)
         lines(1:orders, x[i,], col=i)
      legend("topright", legend=row.names(x), col=1:nsites, lty=1, cex=0.7)
   } else
      lines(1:orders, x)
   invisible(OP)
}

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Tue Aug  4 20:09:40 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 4 Aug 2015 11:09:40 -0700
Subject: [R] Help with Plot
In-Reply-To: <CAKcEf9C6WuWMzyG=M4m5BDbp4rz42+K6BzLQDxs81YShoCTsSQ@mail.gmail.com>
References: <CAKcEf9C6WuWMzyG=M4m5BDbp4rz42+K6BzLQDxs81YShoCTsSQ@mail.gmail.com>
Message-ID: <CA+hbrhWJk0qngOuxywOrfkd7MoFbb5Le_m4HEkmGLQ4S-CJbww@mail.gmail.com>

Try removing the line

x <- x[order(x[,1], decreasing=TRUE),]


Peter

On Tue, Aug 4, 2015 at 10:58 AM, April Smith <aprilgracesmith at gmail.com> wrote:
> Let me just preface that everything I know about writing code for R is self
> taught so this may be really basic but I can't figure it out!
>
> I am using someone else code to create plots.  I would like to change the
> automatically generated colors to the same colors for every plot.  The
> current code makes the highest line in the graph black, the second highest
> line red, 3rd blue, etc, regardless of what the line represents.  I need to
> create 10 of these plots and it gets confusing when the black line means a
> different thing in each plot!   Here is the line I need to adjust, I just
> don't know how.
>
> lines(1:orders, x[i,], col=i)
>
> Here is the code in entirety:
> plot.hill <- function(x, scales = c(0, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64,
>    Inf), ...) {
>    require(vegan)
>    nsites <- if(is.null(ncol(x))) 1 else ncol(x)
>    x <- renyi(t(x), scales=scales, hill=TRUE)
>    orders <- length(scales)
>    if(nsites > 1) {
>       x <- x[order(x[,1], decreasing=TRUE),]
>       OP <- matrix(".   ", nsites,nsites)
>       colnames(OP) <- rownames(OP) <- rownames(x)
>       for(i in 1:(nsites-1))
>          for(j in (i+1):nsites)
>             if(all(x[i,] > x[j,])) {
>                OP[i,j] <- "<   "
>                OP[j,i] <- "^   "
>             }
>       diag(OP) <- " "
>       OP <- as.data.frame(OP)
>       cat("The arrow < or ^ points to the more diverse site:\n")
>       print(OP, na.print=" ")
>    } else
>       OP <- NULL
>    plot(1:4,1:4,type="n",xlim=c(0.9,orders+0.1),ylim=range(0,x),axes=FALSE,
>       ylab="Hill Diversity Numbers",xlab="Order", ...)
>    axis(2)
>    axis(1, at=1:orders, labels=scales)
>    if(nsites > 1) {
>       for(i in 1:nsites)
>          lines(1:orders, x[i,], col=i)
>       legend("topright", legend=row.names(x), col=1:nsites, lty=1, cex=0.7)
>    } else
>       lines(1:orders, x)
>    invisible(OP)
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw1958 at gmail.com  Tue Aug  4 21:31:17 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 4 Aug 2015 15:31:17 -0400
Subject: [R] Households per Census block
In-Reply-To: <CAMjQ9QP6ang9kH2105jPgU3NORBikQaiESTo0JfOtxAav4Jq_g@mail.gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
	<CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
	<CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>
	<3F75011A-C6CB-4AAB-BC1E-4D9C6472F465@gmail.com>
	<CAMjQ9QMRW8SQzGTKSoT0Rwt_gxPH+qNfDRGAYeOrNXT6oWFr9w@mail.gmail.com>
	<CAMjQ9QP6ang9kH2105jPgU3NORBikQaiESTo0JfOtxAav4Jq_g@mail.gmail.com>
Message-ID: <D92D96C5-6303-4214-AAA1-606411F25E76@gmail.com>

Can you give me a for-instance of ?populations?? Is there a table or chart or list or?

Also I guess that I should leave my R session on for as long as possible as ?install.blk? takes a really long time to re-upload if that is what it is doing.

Does install.blk go to the source every time?

Thanks again.
---
KW







> On Aug 4, 2015, at 3:22 PM, Zack Almquist <almquist at umn.edu> wrote:
> 
> P.S. The US census has different "populations" (or worlds) so make sure the housing variable you use is accessing the correct "world."
> 
> Best,
> 
> -- Zack
> ---------------------------------------------------------
> Zack W.  Almquist
> Assistant Professor
> Department of Sociology and School of Statistics
> Affiliate, Minnesota Population Center
> University of Minnesota
> 
> On Tue, Aug 4, 2015 at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
> Hi Keith,
> 
> 
> On Tue, Aug 4, 2015 at 12:43 PM, Keith S Weintraub <kw1958 at gmail.com> wrote:
> I had to download a bunch of stuff but I got it mostly working.
> 
> Unfortunately using the alternative method I get the following:
> 
> > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
> Error in file(con, "r") : cannot open the connection
> In addition: Warning message:
> In file(con, "r") : cannot open: HTTP status was '400 Bad Request?
> 
> Sorry that is my bad, I didn't verify the variable name at (http://api.census.gov/data/2010/sf1/variables.html). This seems to work for me, as a quick test:
> 
> housing<-CensusAPI2010(variables="H0060001", state.fips="06", level = c("tract"), key, summaryfile = c("sf1"))
> 
> So the larger example:
> 
>  ## Get all states fips code
> data(countyfips)
> state.fips<-unique(substr(countyfips$fips,1,2))
> head(state.fips)
> length(state.fips) ## will be 51=50 (states)+ 1(DC)
> ## You will need a census key
> key<-"YOUR KEY HERE"
> housing<-CensusAPI2010(c("H0060001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
> 
> should work just fine.
> 
> Best,
> 
> -- Zack
> ---------------------------------------------------------
> Zack W.  Almquist
> Assistant Professor
> Department of Sociology and School of Statistics
> Affiliate, Minnesota Population Center
> University of Minnesota
>  
> I have a feeling that this is not a problem with the API.
> 
> Thanks for your help,
> KW
> 
> 
> 
> 
> 
> 
> 
> > On Aug 3, 2015, at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
> >
> > Hi Anthony and Keith Weintraub,
> >
> > Here is a way to do what you are asking using the UScensus2010 packages:
> >
> > ## latest version of the package, not yet on CRAN
> > install.packages("UScensus2010", repos="http://R-Forge.R-project.org")
> > library(UScensus2010)
> > install.blk()
> > library(UScensus2010blk)
> > ### You will want the H0010001 variable (see help(alabama.blk10))
> > ### Other variables are also available
> > ### You can use the new api function in UScensus2010 to get arbitrary variables from SF1 and acs
> >
> > data(states.names)
> > head(states.names)
> > state.blk.housing<-vector("list",length(states.names))
> > ## notice this could be greatly spead up using the library(parallel)
> > ## with mclapply
> > ## This will be somewhat slow b/c of so much spatial data
> > for(i in 1:length(states.names)){
> >       data(list=paste(states.names[i],"blk10",sep="."))
> >       temp<-get(paste(states.names[i],"blk10",sep="."))
> >        #unique b/c more shapefiles than fips
> >       state.blk.housing[[i]]<-unique(temp at data[,c("fips","H0010001")])
> >       print(i)
> >       rm(paste(states.names,"blk10",sep="."))
> > }
> >
> > ###########
> > # alternatively Using the US Census API function in the new UScensus2010 package
> > ###########
> >
> > ## Get all states fips code
> > data(countyfips)
> > state.fips<-unique(substr(countyfips$fips,1,2))
> > head(state.fips)
> > length(state.fips) ## will be 51=50 (states)+ 1(DC)
> > ## You will need a census key
> > key<-"YOUR KEY HERE"
> > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
> >
> > Best,
> >
> > -- Zack
> > ---------------------------------------------------------
> > Zack W.  Almquist
> > Assistant Professor
> > Department of Sociology and School of Statistics
> > Affiliate, Minnesota Population Center
> > University of Minnesota
> >
> >
> > On Mon, Aug 3, 2015 at 12:43 PM, Anthony Damico <ajdamico at gmail.com> wrote:
> > hi, ccing the package maintainer.  one alternative is to pull the HU100 variable directly from the census bureau's summary files: that variable starts at position 328 and ends at 336.  just modify this loop and you'll get a table with one-record-per-census-block in every state.
> >
> > https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104
> >
> > (1) line 134 change the very last -9 to 9
> > (2) line 137 between "pop100" and "intptlat" add an "hu100"
> >
> >
> > summary file docs-
> >
> > http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18
> >
> >
> >
> > On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:
> > Folks,
> >
> > I am using the UScensus2010 package and I am trying to figure out the number of households per census block.
> >
> > There are a number of possible data downloads in the package but apparently I am not smart enough to figure out which data-set is appropriate and what functions to use.
> >
> > Any help or pointers or links would be greatly appreciated.
> >
> > Thanks for your time,
> > Best,
> > KW
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> 
> 


From almquist at umn.edu  Tue Aug  4 21:12:19 2015
From: almquist at umn.edu (Zack Almquist)
Date: Tue, 4 Aug 2015 14:12:19 -0500
Subject: [R] Households per Census block
In-Reply-To: <3F75011A-C6CB-4AAB-BC1E-4D9C6472F465@gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
	<CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
	<CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>
	<3F75011A-C6CB-4AAB-BC1E-4D9C6472F465@gmail.com>
Message-ID: <CAMjQ9QMRW8SQzGTKSoT0Rwt_gxPH+qNfDRGAYeOrNXT6oWFr9w@mail.gmail.com>

Hi Keith,


On Tue, Aug 4, 2015 at 12:43 PM, Keith S Weintraub <kw1958 at gmail.com> wrote:

> I had to download a bunch of stuff but I got it mostly working.
>
> Unfortunately using the alternative method I get the following:
>
> > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level =
> c("block"), key, summaryfile = c("sf1"))
> Error in file(con, "r") : cannot open the connection
> In addition: Warning message:
> In file(con, "r") : cannot open: HTTP status was '400 Bad Request?
>

Sorry that is my bad, I didn't verify the variable name at (
http://api.census.gov/data/2010/sf1/variables.html). This seems to work for
me, as a quick test:

housing<-CensusAPI2010(variables="H0060001", state.fips="06", level =
c("tract"), key, summaryfile = c("sf1"))

So the larger example:

 ## Get all states fips code
data(countyfips)
state.fips<-unique(substr(countyfips$fips,1,2))
head(state.fips)
length(state.fips) ## will be 51=50 (states)+ 1(DC)
## You will need a census key
key<-"YOUR KEY HERE"
housing<-CensusAPI2010(c("H0060001"), state.fips=state.fips, level =
c("block"), key, summaryfile = c("sf1"))

should work just fine.

Best,

-- Zack
---------------------------------------------------------
Zack W.  Almquist
Assistant Professor
Department of Sociology and School of Statistics
Affiliate, Minnesota Population Center
University of Minnesota


> I have a feeling that this is not a problem with the API.
>
> Thanks for your help,
> KW
>
>
>
>
>
>
>
> > On Aug 3, 2015, at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
> >
> > Hi Anthony and Keith Weintraub,
> >
> > Here is a way to do what you are asking using the UScensus2010 packages:
> >
> > ## latest version of the package, not yet on CRAN
> > install.packages("UScensus2010", repos="http://R-Forge.R-project.org")
> > library(UScensus2010)
> > install.blk()
> > library(UScensus2010blk)
> > ### You will want the H0010001 variable (see help(alabama.blk10))
> > ### Other variables are also available
> > ### You can use the new api function in UScensus2010 to get arbitrary
> variables from SF1 and acs
> >
> > data(states.names)
> > head(states.names)
> > state.blk.housing<-vector("list",length(states.names))
> > ## notice this could be greatly spead up using the library(parallel)
> > ## with mclapply
> > ## This will be somewhat slow b/c of so much spatial data
> > for(i in 1:length(states.names)){
> >       data(list=paste(states.names[i],"blk10",sep="."))
> >       temp<-get(paste(states.names[i],"blk10",sep="."))
> >        #unique b/c more shapefiles than fips
> >       state.blk.housing[[i]]<-unique(temp at data[,c("fips","H0010001")])
> >       print(i)
> >       rm(paste(states.names,"blk10",sep="."))
> > }
> >
> > ###########
> > # alternatively Using the US Census API function in the new UScensus2010
> package
> > ###########
> >
> > ## Get all states fips code
> > data(countyfips)
> > state.fips<-unique(substr(countyfips$fips,1,2))
> > head(state.fips)
> > length(state.fips) ## will be 51=50 (states)+ 1(DC)
> > ## You will need a census key
> > key<-"YOUR KEY HERE"
> > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level =
> c("block"), key, summaryfile = c("sf1"))
> >
> > Best,
> >
> > -- Zack
> > ---------------------------------------------------------
> > Zack W.  Almquist
> > Assistant Professor
> > Department of Sociology and School of Statistics
> > Affiliate, Minnesota Population Center
> > University of Minnesota
> >
> >
> > On Mon, Aug 3, 2015 at 12:43 PM, Anthony Damico <ajdamico at gmail.com>
> wrote:
> > hi, ccing the package maintainer.  one alternative is to pull the HU100
> variable directly from the census bureau's summary files: that variable
> starts at position 328 and ends at 336.  just modify this loop and you'll
> get a table with one-record-per-census-block in every state.
> >
> >
> https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104
> >
> > (1) line 134 change the very last -9 to 9
> > (2) line 137 between "pop100" and "intptlat" add an "hu100"
> >
> >
> > summary file docs-
> >
> > http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18
> >
> >
> >
> > On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com>
> wrote:
> > Folks,
> >
> > I am using the UScensus2010 package and I am trying to figure out the
> number of households per census block.
> >
> > There are a number of possible data downloads in the package but
> apparently I am not smart enough to figure out which data-set is
> appropriate and what functions to use.
> >
> > Any help or pointers or links would be greatly appreciated.
> >
> > Thanks for your time,
> > Best,
> > KW
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>

	[[alternative HTML version deleted]]


From almquist at umn.edu  Tue Aug  4 21:22:53 2015
From: almquist at umn.edu (Zack Almquist)
Date: Tue, 4 Aug 2015 14:22:53 -0500
Subject: [R] Households per Census block
In-Reply-To: <CAMjQ9QMRW8SQzGTKSoT0Rwt_gxPH+qNfDRGAYeOrNXT6oWFr9w@mail.gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
	<CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
	<CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>
	<3F75011A-C6CB-4AAB-BC1E-4D9C6472F465@gmail.com>
	<CAMjQ9QMRW8SQzGTKSoT0Rwt_gxPH+qNfDRGAYeOrNXT6oWFr9w@mail.gmail.com>
Message-ID: <CAMjQ9QP6ang9kH2105jPgU3NORBikQaiESTo0JfOtxAav4Jq_g@mail.gmail.com>

P.S. The US census has different "populations" (or worlds) so make sure the
housing variable you use is accessing the correct "world."

Best,

-- Zack
---------------------------------------------------------
Zack W.  Almquist
Assistant Professor
Department of Sociology and School of Statistics
Affiliate, Minnesota Population Center
University of Minnesota

On Tue, Aug 4, 2015 at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:

> Hi Keith,
>
>
> On Tue, Aug 4, 2015 at 12:43 PM, Keith S Weintraub <kw1958 at gmail.com>
> wrote:
>
>> I had to download a bunch of stuff but I got it mostly working.
>>
>> Unfortunately using the alternative method I get the following:
>>
>> > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level =
>> c("block"), key, summaryfile = c("sf1"))
>> Error in file(con, "r") : cannot open the connection
>> In addition: Warning message:
>> In file(con, "r") : cannot open: HTTP status was '400 Bad Request?
>>
>
> Sorry that is my bad, I didn't verify the variable name at (
> http://api.census.gov/data/2010/sf1/variables.html). This seems to work
> for me, as a quick test:
>
> housing<-CensusAPI2010(variables="H0060001", state.fips="06", level =
> c("tract"), key, summaryfile = c("sf1"))
>
> So the larger example:
>
>  ## Get all states fips code
> data(countyfips)
> state.fips<-unique(substr(countyfips$fips,1,2))
> head(state.fips)
> length(state.fips) ## will be 51=50 (states)+ 1(DC)
> ## You will need a census key
> key<-"YOUR KEY HERE"
> housing<-CensusAPI2010(c("H0060001"), state.fips=state.fips, level =
> c("block"), key, summaryfile = c("sf1"))
>
> should work just fine.
>
> Best,
>
> -- Zack
> ---------------------------------------------------------
> Zack W.  Almquist
> Assistant Professor
> Department of Sociology and School of Statistics
> Affiliate, Minnesota Population Center
> University of Minnesota
>
>
>> I have a feeling that this is not a problem with the API.
>>
>> Thanks for your help,
>> KW
>>
>>
>>
>>
>>
>>
>>
>> > On Aug 3, 2015, at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
>> >
>> > Hi Anthony and Keith Weintraub,
>> >
>> > Here is a way to do what you are asking using the UScensus2010 packages:
>> >
>> > ## latest version of the package, not yet on CRAN
>> > install.packages("UScensus2010", repos="http://R-Forge.R-project.org")
>> > library(UScensus2010)
>> > install.blk()
>> > library(UScensus2010blk)
>> > ### You will want the H0010001 variable (see help(alabama.blk10))
>> > ### Other variables are also available
>> > ### You can use the new api function in UScensus2010 to get arbitrary
>> variables from SF1 and acs
>> >
>> > data(states.names)
>> > head(states.names)
>> > state.blk.housing<-vector("list",length(states.names))
>> > ## notice this could be greatly spead up using the library(parallel)
>> > ## with mclapply
>> > ## This will be somewhat slow b/c of so much spatial data
>> > for(i in 1:length(states.names)){
>> >       data(list=paste(states.names[i],"blk10",sep="."))
>> >       temp<-get(paste(states.names[i],"blk10",sep="."))
>> >        #unique b/c more shapefiles than fips
>> >       state.blk.housing[[i]]<-unique(temp at data[,c("fips","H0010001")])
>> >       print(i)
>> >       rm(paste(states.names,"blk10",sep="."))
>> > }
>> >
>> > ###########
>> > # alternatively Using the US Census API function in the new
>> UScensus2010 package
>> > ###########
>> >
>> > ## Get all states fips code
>> > data(countyfips)
>> > state.fips<-unique(substr(countyfips$fips,1,2))
>> > head(state.fips)
>> > length(state.fips) ## will be 51=50 (states)+ 1(DC)
>> > ## You will need a census key
>> > key<-"YOUR KEY HERE"
>> > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level =
>> c("block"), key, summaryfile = c("sf1"))
>> >
>> > Best,
>> >
>> > -- Zack
>> > ---------------------------------------------------------
>> > Zack W.  Almquist
>> > Assistant Professor
>> > Department of Sociology and School of Statistics
>> > Affiliate, Minnesota Population Center
>> > University of Minnesota
>> >
>> >
>> > On Mon, Aug 3, 2015 at 12:43 PM, Anthony Damico <ajdamico at gmail.com>
>> wrote:
>> > hi, ccing the package maintainer.  one alternative is to pull the HU100
>> variable directly from the census bureau's summary files: that variable
>> starts at position 328 and ends at 336.  just modify this loop and you'll
>> get a table with one-record-per-census-block in every state.
>> >
>> >
>> https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104
>> >
>> > (1) line 134 change the very last -9 to 9
>> > (2) line 137 between "pop100" and "intptlat" add an "hu100"
>> >
>> >
>> > summary file docs-
>> >
>> > http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18
>> >
>> >
>> >
>> > On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com>
>> wrote:
>> > Folks,
>> >
>> > I am using the UScensus2010 package and I am trying to figure out the
>> number of households per census block.
>> >
>> > There are a number of possible data downloads in the package but
>> apparently I am not smart enough to figure out which data-set is
>> appropriate and what functions to use.
>> >
>> > Any help or pointers or links would be greatly appreciated.
>> >
>> > Thanks for your time,
>> > Best,
>> > KW
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>>
>

	[[alternative HTML version deleted]]


From almquist at umn.edu  Tue Aug  4 21:45:49 2015
From: almquist at umn.edu (Zack Almquist)
Date: Tue, 4 Aug 2015 14:45:49 -0500
Subject: [R] Households per Census block
In-Reply-To: <D92D96C5-6303-4214-AAA1-606411F25E76@gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
	<CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
	<CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>
	<3F75011A-C6CB-4AAB-BC1E-4D9C6472F465@gmail.com>
	<CAMjQ9QMRW8SQzGTKSoT0Rwt_gxPH+qNfDRGAYeOrNXT6oWFr9w@mail.gmail.com>
	<CAMjQ9QP6ang9kH2105jPgU3NORBikQaiESTo0JfOtxAav4Jq_g@mail.gmail.com>
	<D92D96C5-6303-4214-AAA1-606411F25E76@gmail.com>
Message-ID: <CAMjQ9QNOtaS8uC-L+UJPD=-bLxMh2mbkDo1RVdZFg+WMwWF3Jw@mail.gmail.com>

Hi Keith,

I would only use install.blk() once. Then just load the
library(UScensus2010blk) like normal on your machine (this should be
relatively fast), redownloading and re-installing each time will be very
expensive (both on download and time).

The SF1 file manual produced by the US Census goes over all the details of
the various variables (http://www.census.gov/prod/cen2010/doc/sf1.pdf) in
glorious detail; however a lot of the issues arise depending on if you are
interested in individual counts versus household counts and assumptions
thereof.

Best,

-- Zack
---------------------------------------------------------
Zack W.  Almquist
Assistant Professor
Department of Sociology and School of Statistics
Affiliate, Minnesota Population Center
University of Minnesota

On Tue, Aug 4, 2015 at 2:31 PM, Keith S Weintraub <kw1958 at gmail.com> wrote:

> Can you give me a for-instance of ?populations?? Is there a table or chart
> or list or?
>
> Also I guess that I should leave my R session on for as long as possible
> as ?install.blk? takes a really long time to re-upload if that is what it
> is doing.
>
> Does install.blk go to the source every time?
>
> Thanks again.
> ---
> KW
>
>
>
>
>
>
>
> > On Aug 4, 2015, at 3:22 PM, Zack Almquist <almquist at umn.edu> wrote:
> >
> > P.S. The US census has different "populations" (or worlds) so make sure
> the housing variable you use is accessing the correct "world."
> >
> > Best,
> >
> > -- Zack
> > ---------------------------------------------------------
> > Zack W.  Almquist
> > Assistant Professor
> > Department of Sociology and School of Statistics
> > Affiliate, Minnesota Population Center
> > University of Minnesota
> >
> > On Tue, Aug 4, 2015 at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
> > Hi Keith,
> >
> >
> > On Tue, Aug 4, 2015 at 12:43 PM, Keith S Weintraub <kw1958 at gmail.com>
> wrote:
> > I had to download a bunch of stuff but I got it mostly working.
> >
> > Unfortunately using the alternative method I get the following:
> >
> > > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level =
> c("block"), key, summaryfile = c("sf1"))
> > Error in file(con, "r") : cannot open the connection
> > In addition: Warning message:
> > In file(con, "r") : cannot open: HTTP status was '400 Bad Request?
> >
> > Sorry that is my bad, I didn't verify the variable name at (
> http://api.census.gov/data/2010/sf1/variables.html). This seems to work
> for me, as a quick test:
> >
> > housing<-CensusAPI2010(variables="H0060001", state.fips="06", level =
> c("tract"), key, summaryfile = c("sf1"))
> >
> > So the larger example:
> >
> >  ## Get all states fips code
> > data(countyfips)
> > state.fips<-unique(substr(countyfips$fips,1,2))
> > head(state.fips)
> > length(state.fips) ## will be 51=50 (states)+ 1(DC)
> > ## You will need a census key
> > key<-"YOUR KEY HERE"
> > housing<-CensusAPI2010(c("H0060001"), state.fips=state.fips, level =
> c("block"), key, summaryfile = c("sf1"))
> >
> > should work just fine.
> >
> > Best,
> >
> > -- Zack
> > ---------------------------------------------------------
> > Zack W.  Almquist
> > Assistant Professor
> > Department of Sociology and School of Statistics
> > Affiliate, Minnesota Population Center
> > University of Minnesota
> >
> > I have a feeling that this is not a problem with the API.
> >
> > Thanks for your help,
> > KW
> >
> >
> >
> >
> >
> >
> >
> > > On Aug 3, 2015, at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
> > >
> > > Hi Anthony and Keith Weintraub,
> > >
> > > Here is a way to do what you are asking using the UScensus2010
> packages:
> > >
> > > ## latest version of the package, not yet on CRAN
> > > install.packages("UScensus2010", repos="http://R-Forge.R-project.org")
> > > library(UScensus2010)
> > > install.blk()
> > > library(UScensus2010blk)
> > > ### You will want the H0010001 variable (see help(alabama.blk10))
> > > ### Other variables are also available
> > > ### You can use the new api function in UScensus2010 to get arbitrary
> variables from SF1 and acs
> > >
> > > data(states.names)
> > > head(states.names)
> > > state.blk.housing<-vector("list",length(states.names))
> > > ## notice this could be greatly spead up using the library(parallel)
> > > ## with mclapply
> > > ## This will be somewhat slow b/c of so much spatial data
> > > for(i in 1:length(states.names)){
> > >       data(list=paste(states.names[i],"blk10",sep="."))
> > >       temp<-get(paste(states.names[i],"blk10",sep="."))
> > >        #unique b/c more shapefiles than fips
> > >       state.blk.housing[[i]]<-unique(temp at data[,c("fips","H0010001")])
> > >       print(i)
> > >       rm(paste(states.names,"blk10",sep="."))
> > > }
> > >
> > > ###########
> > > # alternatively Using the US Census API function in the new
> UScensus2010 package
> > > ###########
> > >
> > > ## Get all states fips code
> > > data(countyfips)
> > > state.fips<-unique(substr(countyfips$fips,1,2))
> > > head(state.fips)
> > > length(state.fips) ## will be 51=50 (states)+ 1(DC)
> > > ## You will need a census key
> > > key<-"YOUR KEY HERE"
> > > housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level =
> c("block"), key, summaryfile = c("sf1"))
> > >
> > > Best,
> > >
> > > -- Zack
> > > ---------------------------------------------------------
> > > Zack W.  Almquist
> > > Assistant Professor
> > > Department of Sociology and School of Statistics
> > > Affiliate, Minnesota Population Center
> > > University of Minnesota
> > >
> > >
> > > On Mon, Aug 3, 2015 at 12:43 PM, Anthony Damico <ajdamico at gmail.com>
> wrote:
> > > hi, ccing the package maintainer.  one alternative is to pull the
> HU100 variable directly from the census bureau's summary files: that
> variable starts at position 328 and ends at 336.  just modify this loop and
> you'll get a table with one-record-per-census-block in every state.
> > >
> > >
> https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104
> > >
> > > (1) line 134 change the very last -9 to 9
> > > (2) line 137 between "pop100" and "intptlat" add an "hu100"
> > >
> > >
> > > summary file docs-
> > >
> > > http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18
> > >
> > >
> > >
> > > On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com>
> wrote:
> > > Folks,
> > >
> > > I am using the UScensus2010 package and I am trying to figure out the
> number of households per census block.
> > >
> > > There are a number of possible data downloads in the package but
> apparently I am not smart enough to figure out which data-set is
> appropriate and what functions to use.
> > >
> > > Any help or pointers or links would be greatly appreciated.
> > >
> > > Thanks for your time,
> > > Best,
> > > KW
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> >
> >
> >
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Aug  4 22:30:03 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Aug 2015 13:30:03 -0700
Subject: [R] Households per Census block
In-Reply-To: <D92D96C5-6303-4214-AAA1-606411F25E76@gmail.com>
References: <9F90D303-4326-4C8C-A9D8-AA755BDEAEB0@gmail.com>
	<CAOwvMDzPWA3ufNouNhL7bEbushVd-4WjdV+0eaBHaxSaGod6qw@mail.gmail.com>
	<CAMjQ9QPeGAEaji1wG+eNm6wyBoGZepqne4gm+hrkWwgwNV73gA@mail.gmail.com>
	<3F75011A-C6CB-4AAB-BC1E-4D9C6472F465@gmail.com>
	<CAMjQ9QMRW8SQzGTKSoT0Rwt_gxPH+qNfDRGAYeOrNXT6oWFr9w@mail.gmail.com>
	<CAMjQ9QP6ang9kH2105jPgU3NORBikQaiESTo0JfOtxAav4Jq_g@mail.gmail.com>
	<D92D96C5-6303-4214-AAA1-606411F25E76@gmail.com>
Message-ID: <59FE31ED-6BCB-4F6E-9804-6B45A0DD2134@comcast.net>


On Aug 4, 2015, at 12:31 PM, Keith S Weintraub wrote:

> Can you give me a for-instance of ?populations?? Is there a table or chart or list or?
> 
> Also I guess that I should leave my R session on for as long as possible as ?install.blk? takes a really long time to re-upload if that is what it is doing.
> 
> Does install.blk go to the source every time?

I have no experience with that package, but the help page says:
======:
Warning:

This is an extremely large file (around 2 gigs) and should only be installed if you have a very good connection. Also it is worth noting that for all systems the install is from source and can take quite a bit of time to install.
======:

It also says you need to provide an argument to the function: one of "osx", "linux" or "windows".

I would have guessed that you only need to run it once, and after reading its source continue to think that there should have been a package installed, which would then persist and not need to be repeatedly installed.

-- 
David

> 
> Thanks again.
> ---
> KW
> 
> 
> 
> 
> 
> 
> 
>> On Aug 4, 2015, at 3:22 PM, Zack Almquist <almquist at umn.edu> wrote:
>> 
>> P.S. The US census has different "populations" (or worlds) so make sure the housing variable you use is accessing the correct "world."
>> 
>> Best,
>> 
>> -- Zack
>> ---------------------------------------------------------
>> Zack W.  Almquist
>> Assistant Professor
>> Department of Sociology and School of Statistics
>> Affiliate, Minnesota Population Center
>> University of Minnesota
>> 
>> On Tue, Aug 4, 2015 at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
>> Hi Keith,
>> 
>> 
>> On Tue, Aug 4, 2015 at 12:43 PM, Keith S Weintraub <kw1958 at gmail.com> wrote:
>> I had to download a bunch of stuff but I got it mostly working.
>> 
>> Unfortunately using the alternative method I get the following:
>> 
>>> housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
>> Error in file(con, "r") : cannot open the connection
>> In addition: Warning message:
>> In file(con, "r") : cannot open: HTTP status was '400 Bad Request?
>> 
>> Sorry that is my bad, I didn't verify the variable name at (http://api.census.gov/data/2010/sf1/variables.html). This seems to work for me, as a quick test:
>> 
>> housing<-CensusAPI2010(variables="H0060001", state.fips="06", level = c("tract"), key, summaryfile = c("sf1"))
>> 
>> So the larger example:
>> 
>> ## Get all states fips code
>> data(countyfips)
>> state.fips<-unique(substr(countyfips$fips,1,2))
>> head(state.fips)
>> length(state.fips) ## will be 51=50 (states)+ 1(DC)
>> ## You will need a census key
>> key<-"YOUR KEY HERE"
>> housing<-CensusAPI2010(c("H0060001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
>> 
>> should work just fine.
>> 
>> Best,
>> 
>> -- Zack
>> ---------------------------------------------------------
>> Zack W.  Almquist
>> Assistant Professor
>> Department of Sociology and School of Statistics
>> Affiliate, Minnesota Population Center
>> University of Minnesota
>> 
>> I have a feeling that this is not a problem with the API.
>> 
>> Thanks for your help,
>> KW
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>> On Aug 3, 2015, at 2:12 PM, Zack Almquist <almquist at umn.edu> wrote:
>>> 
>>> Hi Anthony and Keith Weintraub,
>>> 
>>> Here is a way to do what you are asking using the UScensus2010 packages:
>>> 
>>> ## latest version of the package, not yet on CRAN
>>> install.packages("UScensus2010", repos="http://R-Forge.R-project.org")
>>> library(UScensus2010)
>>> install.blk()
>>> library(UScensus2010blk)
>>> ### You will want the H0010001 variable (see help(alabama.blk10))
>>> ### Other variables are also available
>>> ### You can use the new api function in UScensus2010 to get arbitrary variables from SF1 and acs
>>> 
>>> data(states.names)
>>> head(states.names)
>>> state.blk.housing<-vector("list",length(states.names))
>>> ## notice this could be greatly spead up using the library(parallel)
>>> ## with mclapply
>>> ## This will be somewhat slow b/c of so much spatial data
>>> for(i in 1:length(states.names)){
>>>      data(list=paste(states.names[i],"blk10",sep="."))
>>>      temp<-get(paste(states.names[i],"blk10",sep="."))
>>>       #unique b/c more shapefiles than fips
>>>      state.blk.housing[[i]]<-unique(temp at data[,c("fips","H0010001")])
>>>      print(i)
>>>      rm(paste(states.names,"blk10",sep="."))
>>> }
>>> 
>>> ###########
>>> # alternatively Using the US Census API function in the new UScensus2010 package
>>> ###########
>>> 
>>> ## Get all states fips code
>>> data(countyfips)
>>> state.fips<-unique(substr(countyfips$fips,1,2))
>>> head(state.fips)
>>> length(state.fips) ## will be 51=50 (states)+ 1(DC)
>>> ## You will need a census key
>>> key<-"YOUR KEY HERE"
>>> housing<-CensusAPI2010(c("H0010001"), state.fips=state.fips, level = c("block"), key, summaryfile = c("sf1"))
>>> 
>>> Best,
>>> 
>>> -- Zack
>>> ---------------------------------------------------------
>>> Zack W.  Almquist
>>> Assistant Professor
>>> Department of Sociology and School of Statistics
>>> Affiliate, Minnesota Population Center
>>> University of Minnesota
>>> 
>>> 
>>> On Mon, Aug 3, 2015 at 12:43 PM, Anthony Damico <ajdamico at gmail.com> wrote:
>>> hi, ccing the package maintainer.  one alternative is to pull the HU100 variable directly from the census bureau's summary files: that variable starts at position 328 and ends at 336.  just modify this loop and you'll get a table with one-record-per-census-block in every state.
>>> 
>>> https://github.com/davidbrae/swmap/blob/master/how%20to%20map%20the%20consumer%20expenditure%20survey.R#L104
>>> 
>>> (1) line 134 change the very last -9 to 9
>>> (2) line 137 between "pop100" and "intptlat" add an "hu100"
>>> 
>>> 
>>> summary file docs-
>>> 
>>> http://www.census.gov/prod/cen2010/doc/sf1.pdf#page=18
>>> 
>>> 
>>> 
>>> On Mon, Aug 3, 2015 at 11:55 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:
>>> Folks,
>>> 
>>> I am using the UScensus2010 package and I am trying to figure out the number of households per census block.
>>> 
>>> There are a number of possible data downloads in the package but apparently I am not smart enough to figure out which data-set is appropriate and what functions to use.
>>> 
>>> Any help or pointers or links would be greatly appreciated.
>>> 
>>> Thanks for your time,
>>> Best,
>>> KW
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rodlupanow at hotmail.com  Tue Aug  4 22:50:01 2015
From: rodlupanow at hotmail.com (=?iso-8859-1?B?Um9kcmlnbyBE7WF6?=)
Date: Tue, 4 Aug 2015 16:50:01 -0400
Subject: [R] Two conditions selection
Message-ID: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>

Hi. I have a matrix like this: 
cycle=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))col=c(rep("blue",2),rep("green",2),rep("blue",2),rep("green",2),rep("blue",2),rep("green",2))values=c(1:12)data.frame(cycle,col,values)
#  cycle   col values#1      1  blue      1#2      1  blue      2#3      1 green      3#4      2 green      4#5      2  blue      5#6      2  blue      6#7      3 green      7#8      3 green      8#9      3  blue      9#10     4  blue     10#11     4 green     11#12     4 green     12
I want to select or extract values matching 2 conditions. For example: values from col "blue" and cycle "1". If I use : values[col==blue] I get all blue values. I tried using values[c(col==blue,cycle==1)] but is not working. Please help. I have a very big data matrix and I do not wanna go to excel and start cutting the data. Thanks. 

 		 	   		  
	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Wed Aug  5 01:58:30 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 4 Aug 2015 23:58:30 +0000
Subject: [R] Two conditions selection
In-Reply-To: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>
References: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED73AC0@WAXMXOLYMB025.WAX.wa.lcl>

You need to read up on indexing in R.  What you want is logical indexing.  You can use just the vectors you created (since you didn't save the data frame that you created) like this

> cycle=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))
> col=c(rep("blue",2),rep("green",2),rep("blue",2),rep("green",2),rep("blue",2),rep("green",2))
> values=c(1:12)
> values[col==blue & cycle==1]

Or save the data frame and return the rows that you want like this

> df <- data.frame(cycle,col,values)
> df[df$col==blue & df$cycle==1, ]

Hope this is helpful,

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rodrigo D?az
Sent: Tuesday, August 04, 2015 1:50 PM
To: r-help at r-project.org
Subject: [R] Two conditions selection

Hi. I have a matrix like this: 
cycle=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))col=c(rep("blue",2),rep("green",2),rep("blue",2),rep("green",2),rep("blue",2),rep("green",2))values=c(1:12)data.frame(cycle,col,values)
#  cycle   col values#1      1  blue      1#2      1  blue      2#3      1 green      3#4      2 green      4#5      2  blue      5#6      2  blue      6#7      3 green      7#8      3 green      8#9      3  blue      9#10     4  blue     10#11     4 green     11#12     4 green     12
I want to select or extract values matching 2 conditions. For example: values from col "blue" and cycle "1". If I use : values[col==blue] I get all blue values. I tried using values[c(col==blue,cycle==1)] but is not working. Please help. I have a very big data matrix and I do not wanna go to excel and start cutting the data. Thanks. 

 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Peter.Brecknock at bp.com  Wed Aug  5 01:57:48 2015
From: Peter.Brecknock at bp.com (Pete Brecknock)
Date: Tue, 4 Aug 2015 16:57:48 -0700 (PDT)
Subject: [R] Two conditions selection
In-Reply-To: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>
References: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>
Message-ID: <1438732668564-4710763.post@n4.nabble.com>

Rodrigo D?az wrote
> Hi. I have a matrix like this: 
> cycle=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))col=c(rep("blue",2),rep("green",2),rep("blue",2),rep("green",2),rep("blue",2),rep("green",2))values=c(1:12)data.frame(cycle,col,values)
> #  cycle   col values#1      1  blue      1#2      1  blue      2#3      1
> green      3#4      2 green      4#5      2  blue      5#6      2  blue     
> 6#7      3 green      7#8      3 green      8#9      3  blue      9#10    
> 4  blue     10#11     4 green     11#12     4 green     12
> I want to select or extract values matching 2 conditions. For example:
> values from col "blue" and cycle "1". If I use : values[col==blue] I get
> all blue values. I tried using values[c(col==blue,cycle==1)] but is not
> working. Please help. I have a very big data matrix and I do not wanna go
> to excel and start cutting the data. Thanks. 
> 
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________

> R-help@

>  mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


How about 

# Your Code 
cycle=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))
col=c(rep("blue",2),rep("green",2),rep("blue",2),rep("green",2),rep("blue",2),rep("green",2))
values=c(1:12)
df <- data.frame(cycle,col,values)

# Subset data frame df
df[cycle==1 & col=="blue",]

HTH

Pete



--
View this message in context: http://r.789695.n4.nabble.com/Two-conditions-selection-tp4710762p4710763.html
Sent from the R help mailing list archive at Nabble.com.


From jhedges3 at gmail.com  Wed Aug  5 01:54:37 2015
From: jhedges3 at gmail.com (James Hedges)
Date: Tue, 04 Aug 2015 23:54:37 +0000
Subject: [R] Two conditions selection
In-Reply-To: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>
References: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>
Message-ID: <CAC04xV7cty=us10tfv2QJABi2Kbyj8_a7jp9iGsru6ij=8TauQ@mail.gmail.com>

cycle %>% filter(col == "blue", cycle == 1)
On Tue, Aug 4, 2015 at 18:59 Rodrigo D?az <rodlupanow at hotmail.com> wrote:

> Hi. I have a matrix like this:
>
> cycle=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))col=c(rep("blue",2),rep("green",2),rep("blue",2),rep("green",2),rep("blue",2),rep("green",2))values=c(1:12)data.frame(cycle,col,values)
> #  cycle   col values#1      1  blue      1#2      1  blue      2#3      1
> green      3#4      2 green      4#5      2  blue      5#6      2  blue
>   6#7      3 green      7#8      3 green      8#9      3  blue      9#10
>  4  blue     10#11     4 green     11#12     4 green     12
> I want to select or extract values matching 2 conditions. For example:
> values from col "blue" and cycle "1". If I use : values[col==blue] I get
> all blue values. I tried using values[c(col==blue,cycle==1)] but is not
> working. Please help. I have a very big data matrix and I do not wanna go
> to excel and start cutting the data. Thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jhedges3 at gmail.com  Wed Aug  5 01:57:49 2015
From: jhedges3 at gmail.com (James Hedges)
Date: Tue, 04 Aug 2015 23:57:49 +0000
Subject: [R] Two conditions selection
In-Reply-To: <CAC04xV7cty=us10tfv2QJABi2Kbyj8_a7jp9iGsru6ij=8TauQ@mail.gmail.com>
References: <BAY176-W45B4708ABF6C3BEC2FDE6C8760@phx.gbl>
	<CAC04xV7cty=us10tfv2QJABi2Kbyj8_a7jp9iGsru6ij=8TauQ@mail.gmail.com>
Message-ID: <CAC04xV6L+ygkgNwTDJfWGu62TUatKk2Ra0xuafh6qzdOC332nA@mail.gmail.com>

Sorry. In dplyr:
data %>% filter(col == "blue", cycle ==1) %>% select(values)

On Tue, Aug 4, 2015 at 19:54 James Hedges <jhedges3 at gmail.com> wrote:

> cycle %>% filter(col == "blue", cycle == 1)
> On Tue, Aug 4, 2015 at 18:59 Rodrigo D?az <rodlupanow at hotmail.com> wrote:
>
>> Hi. I have a matrix like this:
>>
>> cycle=c(rep(1,3),rep(2,3),rep(3,3),rep(4,3))col=c(rep("blue",2),rep("green",2),rep("blue",2),rep("green",2),rep("blue",2),rep("green",2))values=c(1:12)data.frame(cycle,col,values)
>> #  cycle   col values#1      1  blue      1#2      1  blue      2#3
>> 1 green      3#4      2 green      4#5      2  blue      5#6      2  blue
>>     6#7      3 green      7#8      3 green      8#9      3  blue      9#10
>>    4  blue     10#11     4 green     11#12     4 green     12
>> I want to select or extract values matching 2 conditions. For example:
>> values from col "blue" and cycle "1". If I use : values[col==blue] I get
>> all blue values. I tried using values[c(col==blue,cycle==1)] but is not
>> working. Please help. I have a very big data matrix and I do not wanna go
>> to excel and start cutting the data. Thanks.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From trentyarwood at gmail.com  Wed Aug  5 08:30:13 2015
From: trentyarwood at gmail.com (Trent Yarwood)
Date: Wed, 5 Aug 2015 16:30:13 +1000
Subject: [R] Advice on data format
Message-ID: <CAPavXd3qw=E795E_+y+bNXxTvHoD+ZQuwes692mzrqVb9WJPBw@mail.gmail.com>

Hi all,

I'm responsible for collating data on antibiotic use at my local group of
hospitals.  I have data for five different hospitals, about 40 different
antibiotics and monthly data going back to 2006.

At the moment, I have this stored in 5 datafiles, one for each hospital,
formatted as follows:

date, antibiotic1, antibiotic2, antibiotic3....
1-mmm-yy, ab11, ab21, ab31....
1-mmm-yy, ab12, ab22, ab32...

This works most of the time for me, because the most common thing I need to
do is to track a particular hospital's antibiotic use over time (sum of
columns, as a time series by row).

What I would like to do is to amalgamate the data so instead of analysing
an individual hospital (ie a datasheet in the current format) is to be able
to look at a particular antibiotic across the five hospitals.

The best way I can visualise this is having the data in a data cube, with
each hospital as a single plane. Currently, my hospitals are (x,y,1),
(x,y,2) etc. What I'd like to do is look at (2,y,z) - for example, the sum
of antibiotic1 in all hospitals.

I imagine one way of doing this is having a hospital column in the data:

date, hospital, antibiotic1, antibiotic2, antibiotic3...
1-mmm-yy, hospital1, a11, a21, a31...
1-mmm-yy, hospital2, a11, a21, a31... etc

Two questions:

1) Is there a better way of storing the data than this?
2) Is there an easy way to turn what I have into what I want?

I know that once I have the data sorted, I'll be able to dpyl it into the
categories I currently use - it's the getting from here to there I need
help with, please.

Cheers,

Trent.






-- 
-- 
Trent Yarwood
trentyarwood at gmail.com

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Aug  5 12:05:33 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 5 Aug 2015 20:05:33 +1000
Subject: [R] Advice on data format
In-Reply-To: <CAPavXd3qw=E795E_+y+bNXxTvHoD+ZQuwes692mzrqVb9WJPBw@mail.gmail.com>
References: <CAPavXd3qw=E795E_+y+bNXxTvHoD+ZQuwes692mzrqVb9WJPBw@mail.gmail.com>
Message-ID: <CA+8X3fW8ayGUOQmtXhuaY-U05JWUjaiYr0_w6dyAVdEZ-Lz_0Q@mail.gmail.com>

Hi Trent,
I may be missing something, but I think that if you simply add your
column with the hospital code to each of the five data frames:

hospital1.df$hospital<-"hospital1"
hospital2.df$hospital<-"hospital2"
...

and then concatenate (rbind) them you can get what you want without
going to a 3D array.

Jim


On Wed, Aug 5, 2015 at 4:30 PM, Trent Yarwood <trentyarwood at gmail.com> wrote:
> Hi all,
>
> I'm responsible for collating data on antibiotic use at my local group of
> hospitals.  I have data for five different hospitals, about 40 different
> antibiotics and monthly data going back to 2006.
>
> At the moment, I have this stored in 5 datafiles, one for each hospital,
> formatted as follows:
>
> date, antibiotic1, antibiotic2, antibiotic3....
> 1-mmm-yy, ab11, ab21, ab31....
> 1-mmm-yy, ab12, ab22, ab32...
>
> This works most of the time for me, because the most common thing I need to
> do is to track a particular hospital's antibiotic use over time (sum of
> columns, as a time series by row).
>
> What I would like to do is to amalgamate the data so instead of analysing
> an individual hospital (ie a datasheet in the current format) is to be able
> to look at a particular antibiotic across the five hospitals.
>
> The best way I can visualise this is having the data in a data cube, with
> each hospital as a single plane. Currently, my hospitals are (x,y,1),
> (x,y,2) etc. What I'd like to do is look at (2,y,z) - for example, the sum
> of antibiotic1 in all hospitals.
>
> I imagine one way of doing this is having a hospital column in the data:
>
> date, hospital, antibiotic1, antibiotic2, antibiotic3...
> 1-mmm-yy, hospital1, a11, a21, a31...
> 1-mmm-yy, hospital2, a11, a21, a31... etc
>
> Two questions:
>
> 1) Is there a better way of storing the data than this?
> 2) Is there an easy way to turn what I have into what I want?
>
> I know that once I have the data sorted, I'll be able to dpyl it into the
> categories I currently use - it's the getting from here to there I need
> help with, please.
>
> Cheers,
>
> Trent.
>
>
>
>
>
>
> --
> --
> Trent Yarwood
> trentyarwood at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Wed Aug  5 14:50:17 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 05 Aug 2015 13:50:17 +0100
Subject: [R] Advice on data format
In-Reply-To: <CAPavXd3qw=E795E_+y+bNXxTvHoD+ZQuwes692mzrqVb9WJPBw@mail.gmail.com>
References: <CAPavXd3qw=E795E_+y+bNXxTvHoD+ZQuwes692mzrqVb9WJPBw@mail.gmail.com>
Message-ID: <55C20689.2020509@dewey.myzen.co.uk>

Dear Trent

If you want them side-by-side in one data frame then you could use merge 
making sure it only merges by date. I would use sub to change all the 
anitbiotic names by adding "h1" "h2" and so on. Then you can sum 
antibiotic over hospital by using grep to select all the columns 
containing antibiotic1. The side-by-side solution has some advantages 
over stacking them vertically and some disadvantages. You may need to do 
both for different purposes.

You would need to learn about regular expressions if they are not 
already familiar to you to get the best out of sub and grep.

On 05/08/2015 07:30, Trent Yarwood wrote:
> Hi all,
>
> I'm responsible for collating data on antibiotic use at my local group of
> hospitals.  I have data for five different hospitals, about 40 different
> antibiotics and monthly data going back to 2006.
>
> At the moment, I have this stored in 5 datafiles, one for each hospital,
> formatted as follows:
>
> date, antibiotic1, antibiotic2, antibiotic3....
> 1-mmm-yy, ab11, ab21, ab31....
> 1-mmm-yy, ab12, ab22, ab32...
>
> This works most of the time for me, because the most common thing I need to
> do is to track a particular hospital's antibiotic use over time (sum of
> columns, as a time series by row).
>
> What I would like to do is to amalgamate the data so instead of analysing
> an individual hospital (ie a datasheet in the current format) is to be able
> to look at a particular antibiotic across the five hospitals.
>
> The best way I can visualise this is having the data in a data cube, with
> each hospital as a single plane. Currently, my hospitals are (x,y,1),
> (x,y,2) etc. What I'd like to do is look at (2,y,z) - for example, the sum
> of antibiotic1 in all hospitals.
>
> I imagine one way of doing this is having a hospital column in the data:
>
> date, hospital, antibiotic1, antibiotic2, antibiotic3...
> 1-mmm-yy, hospital1, a11, a21, a31...
> 1-mmm-yy, hospital2, a11, a21, a31... etc
>
> Two questions:
>
> 1) Is there a better way of storing the data than this?
> 2) Is there an easy way to turn what I have into what I want?
>
> I know that once I have the data sorted, I'll be able to dpyl it into the
> categories I currently use - it's the getting from here to there I need
> help with, please.
>
> Cheers,
>
> Trent.
>
>
>
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dialvac-r at yahoo.de  Wed Aug  5 15:18:26 2015
From: dialvac-r at yahoo.de (Alain D.)
Date: Wed, 5 Aug 2015 15:18:26 +0200 (CEST)
Subject: [R] GmeanRel vs. mult.icc - differential meaning of icc2 results?
Message-ID: <12125612.1250682.1438780707069.JavaMail.open-xchange@omgreatgod.store>

Dear R-list,

let us say I want to report the reliability of group means for "HRS" (ICC2):

library(multilevel)

data("bh1996")
mult.icc(bh1996[,c("HRS","LEAD","COHES")],grpid=bh1996$GRP)

Variable     ICC1    ICC2
1      HRS 0.129237 0.91713
2     LEAD 0.147462 0.92804
3    COHES 0.048049 0.79008

the result is 0.91713. 

However, if I use GmeanRel I get a different result:

tmod<-lme(HRS~1,random=~1|GRP,data=bh1996)
mean((GmeanRel(tmod))$MeanRel)
[1] 0.89586

What is the difference between both estimates?

Thanks for helping me!

Best wishes

Alain 
 
	[[alternative HTML version deleted]]


From demmitba at gmail.com  Wed Aug  5 16:06:19 2015
From: demmitba at gmail.com (Brittany Demmitt)
Date: Wed, 5 Aug 2015 08:06:19 -0600
Subject: [R] write.csv file= question
In-Reply-To: <CA+vqiLGcj_4EbmdHW6KHN3qwj0N5C9VBANbNhPO5D03rkepqsg@mail.gmail.com>
References: <5E866410-3B86-4757-BD46-488DE03278B6@gmail.com>
	<C9AF90CFBE3.000001DBjrkrideau@inbox.com>
	<CA+vqiLEcfn--F1hZXO5rz5vQ1L_U6ZRDrPbekOBvD_XhWW6Lqw@mail.gmail.com>
	<CA+vqiLGcj_4EbmdHW6KHN3qwj0N5C9VBANbNhPO5D03rkepqsg@mail.gmail.com>
Message-ID: <6E2C9FF6-1E9F-4550-9B64-106AEE75790E@gmail.com>


The trial ?test? script worked, as well as adding getwd() to my current script also fixed the problem. So it seems ?file=? isn?t necessary after all to run from the terminal.

Thanks everyone for your help! :-)





> On Aug 4, 2015, at 9:20 AM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> On Tue, Aug 4, 2015 at 11:12 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> On Tue, Aug 4, 2015 at 11:04 AM, John Kane <jrkrideau at inbox.com> wrote:
>>> You probably need to ask this on a RStudio forum but my guess is it is just a little 'refinement' that the RStudio people added. Similar in concept o the the matching "".
>> 
>> Really? write.csv(data,?/home/data.csv?) works for me in Rstudio, ESS,
>> Terminal, Rscript etc.
> 
> Well, actually I misspoke. I don't actually have permission to write
> to "/home" on my system. But
> 
> write.csv(data, "~/data.csv")
> 
> works.
> 
>> 
>>> 
>>> John Kane
>>> Kingston ON Canada
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: demmitba at gmail.com
>>>> Sent: Tue, 4 Aug 2015 08:51:24 -0600
>>>> To: r-help at r-project.org
>>>> Subject: [R] write.csv file= question
>>>> 
>>>> Hello,
>>>> 
>>>> I have a quick question about the ?file=? specification for the command
>>>> write.csv.    When I run this command in Rstudio I do not need the
>>>> ?file=? specified.  For example the below command works just fine.
>>>> 
>>>> write.csv(data,?/home/data.csv?)
>>>> 
>>>> However when I am running an Rscript from the terminal and putting it in
>>>> the background I need to specify ?file=?.  So for the example above I
>>>> need to instead have
>>>> 
>>>> write.csv(data,file=?/home/data.csv?)
>>>> 
>>>> Any ideas why this is the case?  Writing file= isn?t a problem, just
>>>> trying to get an idea of how R works better.
>>>> 
>>>> Thanks!
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ____________________________________________________________
>>> Can't remember your password? Do you need a strong and secure password?
>>> Use Password manager! It stores your passwords & protects your account.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From evan.kransdorf at gmail.com  Wed Aug  5 16:25:17 2015
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Wed, 5 Aug 2015 07:25:17 -0700
Subject: [R] Question about survival::survfit
Message-ID: <CAKZWb7fzkpG3cCPD2DY6X9ZWCTMPhnRbNPoab4H7LU6G-MT13w@mail.gmail.com>

I am wanting to do a KM curve of two groups using survival. For some
reason, the summary(survfit) gives me the following output:



           records n.max n.start events median 0.95LCL 0.95UCL

VAR=N   10931 10931   10931   1646     NA      NA      NA

VAR=Y    3452  3452    3452    906     NA      NA      NA



I am not sure why it won?t give me median survival for each group?  There
are no NA in my data.



Thanks very much

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Wed Aug  5 16:32:02 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Aug 2015 09:32:02 -0500
Subject: [R] Question about survival::survfit
In-Reply-To: <CAKZWb7fzkpG3cCPD2DY6X9ZWCTMPhnRbNPoab4H7LU6G-MT13w@mail.gmail.com>
References: <CAKZWb7fzkpG3cCPD2DY6X9ZWCTMPhnRbNPoab4H7LU6G-MT13w@mail.gmail.com>
Message-ID: <14D85EEE-F3FB-4CE8-B228-9D3FFB218B9B@me.com>


> On Aug 5, 2015, at 9:25 AM, Evan Kransdorf <evan.kransdorf at gmail.com> wrote:
> 
> I am wanting to do a KM curve of two groups using survival. For some
> reason, the summary(survfit) gives me the following output:
> 
> 
> 
>           records n.max n.start events median 0.95LCL 0.95UCL
> 
> VAR=N   10931 10931   10931   1646     NA      NA      NA
> 
> VAR=Y    3452  3452    3452    906     NA      NA      NA
> 
> 
> 
> I am not sure why it won?t give me median survival for each group?  There
> are no NA in my data.
> 
> 
> 
> Thanks very much


Presumably, because the survivorship function never crosses below 0.5. You may need to refresh yourself on the definition of median survival.

Plot the curves to visually confirm.

Regards,

Marc Schwartz


From fanch.collin at gmail.com  Wed Aug  5 14:24:01 2015
From: fanch.collin at gmail.com (=?UTF-8?Q?Fran=C3=A7ois_Collin?=)
Date: Wed, 5 Aug 2015 12:24:01 +0000
Subject: [R] Lattice: raw data and prediction of a non linear fitted function
Message-ID: <CAOH82u2mJx5C84rJ3Sx9a4AcDma0kprd6=P5aQPAtNFVKzqaEw@mail.gmail.com>

Dear all,

I have a question about lattice use. I would like to use it to represent:
- my raw data as points,
- and the results of a non linear fit as a line,
- having 2 groups data (and so 2 colors).

However, as I have few raw data, I would like to increase the number of
points to smooth the line which correspond to the fit.

So my questions are:
- How can I use the group argument to make new predictions inside panel
argument ?
- How can I use this prediction inside the panel argument to draw the fit
per group?

Hereafter a minimal example:

#==================================================
library(lattice)
set.seed(2)

# Dummy dataframe
foo <- data.frame(
  time = seq(0, 60, 5),
  char = sample(c("A", "B"), size = 13, replace = TRUE)
  );

# Simulated response vector according a Gompertz function + rnorn(0, 5)
foo$y <- SSgompertz(foo$time, Asym = 100, b2 = ifelse(foo$char == 'A', 6,
10),
  b3 = ifelse(foo$char == "A", .91, .8)) +
  rnorm(nrow(foo), mean=0, sd = 5);

# Non-linear fit on simulation data
res_nls <-  nls(
  y ~ SSgompertz(time, Asym = 100, b2[char], b3[char]), data = foo,
  start = list( b2 = c(7,7), b3 = c(0.9, 0.9)));

# My problem
xyplot(y ~ time, groups = char, data = foo,
  panel = function(x, y, groups=groups, model = model, ...){
    panel.xyplot(x,y, groups = groups, ...);

    newdata <- data.frame(time = x, char = groups);
    newdata$y <- predict(model, newdata = newdata);

    panel.superpose(x = newdata$time, y=newdata$y,  groups = groups, ...,
      panel.groups = function(x,y, col, col.symbol, ...){
        panel.lines(x,y, col.line = col.symbol)
      })

  }, model = res_nls);
#==================================================


Many thanks,
Francois

	[[alternative HTML version deleted]]


From sithlord1 at gmx.net  Wed Aug  5 16:40:22 2015
From: sithlord1 at gmx.net (a_wohl)
Date: Wed, 5 Aug 2015 07:40:22 -0700 (PDT)
Subject: [R] nested model and post hoc?
Message-ID: <1438785622177-4710784.post@n4.nabble.com>

Hi :-) i am really looking forward to get some help... Since I am a
R-beginner I need it.

I have a model consisting of the factors: dpi, infection, dissection day and
plate. My reskponse variable is cells/mg. dpi is nested in dissection day.
They are all fixed variables. 
I produced this nested model (best AIC index)
glm.3<-cm.2~infect.f+dpi.f+dpi.f/diss.f, na.action=na.omit)

summary(glm.3)
Call:
glm(formula = cm.2 ~ infect.f + dpi.f + dpi.f %in% diss.f, family =
gaussian, 
    na.action = na.omit)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.7746  -0.3625   0.0080   0.3628   1.9031  

Coefficients: (18 not defined because of singularities)
                Estimate Std. Error t value Pr(>|t|)    
(Intercept)      7.01887    0.15278  45.941  < 2e-16 ***
infect.finf      0.05544    0.08107   0.684   0.4946    
infect.fsha     -0.15563    0.08831  -1.762   0.0791 .  
dpi.f2           0.08924    0.20459   0.436   0.6630    
dpi.f4          -0.40167    0.21082  -1.905   0.0577 .  
dpi.f8           0.01961    0.20789   0.094   0.9249    
dpi.f16          0.82210    0.20469   4.016 7.54e-05 ***
dpi.f32          0.99639    0.21435   4.648 5.09e-06 ***
dpi.f1:diss.f2   0.13276    0.21077   0.630   0.5293    
dpi.f2:diss.f2        NA         NA      NA       NA    
dpi.f4:diss.f2   0.46749    0.20784   2.249   0.0253 *  
dpi.f8:diss.f2  -0.06555    0.20205  -0.324   0.7459    
dpi.f16:diss.f2       NA         NA      NA       NA    
dpi.f32:diss.f2       NA         NA      NA       NA    
dpi.f1:diss.f3        NA         NA      NA       NA    
dpi.f2:diss.f3  -0.15794    0.20186  -0.782   0.4346    
dpi.f4:diss.f3   0.20921    0.21081   0.992   0.3218    
dpi.f8:diss.f3        NA         NA      NA       NA    
dpi.f16:diss.f3 -0.03611    0.20178  -0.179   0.8581    
dpi.f32:diss.f3       NA         NA      NA       NA    
dpi.f1:diss.f4   0.14040    0.20459   0.686   0.4931    
dpi.f2:diss.f4  -0.01701    0.21152  -0.080   0.9360    
dpi.f4:diss.f4        NA         NA      NA       NA    
dpi.f8:diss.f4        NA         NA      NA       NA    
dpi.f16:diss.f4 -0.19082    0.20168  -0.946   0.3449    
dpi.f32:diss.f4       NA         NA      NA       NA    
dpi.f1:diss.f5        NA         NA      NA       NA    
dpi.f2:diss.f5        NA         NA      NA       NA    

........and so forth. 
Since i decided for a nested modul, I wonder where the NAs are coming from? 
Since I want to perform a post hoc test, I was trysing the glht fuinction
form the multcomp package. 
I always get this error 
Error in modelparm.default(model, ...) : 
  dimensions of coefficients and covariance matrix don't match

I think this is due to my NAs in the summary(glm.3).
Can anyone help me, how I can perform a post hoc test (Bonferroni) on my
data?

thank you 
a_wohl



--
View this message in context: http://r.789695.n4.nabble.com/nested-model-and-post-hoc-tp4710784.html
Sent from the R help mailing list archive at Nabble.com.


From djosseparfait at gmail.com  Wed Aug  5 11:55:21 2015
From: djosseparfait at gmail.com (=?UTF-8?Q?Djoss=C3=A8_Parfait?=)
Date: Wed, 5 Aug 2015 11:55:21 +0200
Subject: [R] (no subject)
Message-ID: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>

Good morning,

I would like to know how often per year is a new full version release of R.



Thanks

-- 
Djoss? Parfait BODJRENOU
Chef de la Division Centralisation et Analyse des Donn?es
Statistiques /DPP/MESFTPRIJ

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Aug  5 19:08:16 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 05 Aug 2015 13:08:16 -0400
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
Message-ID: <26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>

New versions are released when they are ready. This is volunteer-driven software.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait" <djosseparfait at gmail.com> wrote:
>Good morning,
>
>I would like to know how often per year is a new full version release
>of R.
>
>
>
>Thanks
>
>-- 
>Djoss? Parfait BODJRENOU
>Chef de la Division Centralisation et Analyse des Donn?es
>Statistiques /DPP/MESFTPRIJ
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mtmorgan at fredhutch.org  Wed Aug  5 19:19:42 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Wed, 05 Aug 2015 10:19:42 -0700
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
Message-ID: <55C245AE.8030808@fredhutch.org>

On 08/05/2015 10:08 AM, Jeff Newmiller wrote:
> New versions are released when they are ready. This is volunteer-driven software.

 From https://developer.r-project.org/ :

The overall release schedule is to have annual x.y.0 releases in Spring, with 
patch releases happening on an as-needed basis. It is intended to have a final 
patch release of the previous version shortly before the next major release.

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait" <djosseparfait at gmail.com> wrote:
>> Good morning,
>>
>> I would like to know how often per year is a new full version release
>> of R.
>>
>>
>>
>> Thanks
>>
>> --
>> Djoss? Parfait BODJRENOU
>> Chef de la Division Centralisation et Analyse des Donn?es
>> Statistiques /DPP/MESFTPRIJ
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From marc_schwartz at me.com  Wed Aug  5 19:31:22 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Aug 2015 12:31:22 -0500
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <55C245AE.8030808@fredhutch.org>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
	<55C245AE.8030808@fredhutch.org>
Message-ID: <962F29AF-17C4-4B2D-BDE9-5B20424D5BC7@me.com>


In addition, there are documents here:

  https://www.r-project.org/certification.html

that cover R?s SDLC (Software Development Life Cycle) that may be helpful.

Regards,

Marc Schwartz


> On Aug 5, 2015, at 12:19 PM, Martin Morgan <mtmorgan at fredhutch.org> wrote:
> 
> On 08/05/2015 10:08 AM, Jeff Newmiller wrote:
>> New versions are released when they are ready. This is volunteer-driven software.
> 
> From https://developer.r-project.org/ :
> 
> The overall release schedule is to have annual x.y.0 releases in Spring, with patch releases happening on an as-needed basis. It is intended to have a final patch release of the previous version shortly before the next major release.
> 
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait" <djosseparfait at gmail.com> wrote:
>>> Good morning,
>>> 
>>> I would like to know how often per year is a new full version release
>>> of R.
>>> 
>>> 
>>> 
>>> Thanks


From ligges at statistik.tu-dortmund.de  Wed Aug  5 20:12:35 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 5 Aug 2015 20:12:35 +0200
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
Message-ID: <55C25213.1070102@statistik.tu-dortmund.de>



On 05.08.2015 19:08, Jeff Newmiller wrote:
> New versions are released when they are ready. This is volunteer-driven software.

Actually the plans are a bit more formal:

http://developer.r-project.org/

Best,
Uwe Ligges


> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait" <djosseparfait at gmail.com> wrote:
>> Good morning,
>>
>> I would like to know how often per year is a new full version release
>> of R.
>>
>>
>>
>> Thanks
>>
>> --
>> Djoss? Parfait BODJRENOU
>> Chef de la Division Centralisation et Analyse des Donn?es
>> Statistiques /DPP/MESFTPRIJ
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Wed Aug  5 20:15:26 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 05 Aug 2015 14:15:26 -0400
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <55C245AE.8030808@fredhutch.org>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
	<55C245AE.8030808@fredhutch.org>
Message-ID: <98A0381D-817F-4883-9889-417B54475ECF@dcn.davis.CA.us>

So 3.1.3 to 3.2.0 was a major release?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 5, 2015 1:19:42 PM EDT, Martin Morgan <mtmorgan at fredhutch.org> wrote:
>On 08/05/2015 10:08 AM, Jeff Newmiller wrote:
>> New versions are released when they are ready. This is
>volunteer-driven software.
>
> From https://developer.r-project.org/ :
>
>The overall release schedule is to have annual x.y.0 releases in
>Spring, with 
>patch releases happening on an as-needed basis. It is intended to have
>a final 
>patch release of the previous version shortly before the next major
>release.
>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                        Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait"
><djosseparfait at gmail.com> wrote:
>>> Good morning,
>>>
>>> I would like to know how often per year is a new full version
>release
>>> of R.
>>>
>>>
>>>
>>> Thanks
>>>
>>> --
>>> Djoss? Parfait BODJRENOU
>>> Chef de la Division Centralisation et Analyse des Donn?es
>>> Statistiques /DPP/MESFTPRIJ
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From murdoch.duncan at gmail.com  Wed Aug  5 20:32:34 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 05 Aug 2015 14:32:34 -0400
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <98A0381D-817F-4883-9889-417B54475ECF@dcn.davis.CA.us>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>	<55C245AE.8030808@fredhutch.org>
	<98A0381D-817F-4883-9889-417B54475ECF@dcn.davis.CA.us>
Message-ID: <55C256C2.70306@gmail.com>

On 05/08/2015 2:15 PM, Jeff Newmiller wrote:
> So 3.1.3 to 3.2.0 was a major release?

Yes.  We do have the oddity (see ?version) that 3 is the major version
number and 2.0 is the minor version number including 0 as the
patchlevel, but we still call it a major release when the number in the
middle changes (e.g. 1 changed to 2 in the 3.2.0 release).  It's a patch
release when only the patchlevel changes.

Duncan Murdoch


> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On August 5, 2015 1:19:42 PM EDT, Martin Morgan <mtmorgan at fredhutch.org> wrote:
>> On 08/05/2015 10:08 AM, Jeff Newmiller wrote:
>>> New versions are released when they are ready. This is
>> volunteer-driven software.
>>
>> From https://developer.r-project.org/ :
>>
>> The overall release schedule is to have annual x.y.0 releases in
>> Spring, with 
>> patch releases happening on an as-needed basis. It is intended to have
>> a final 
>> patch release of the previous version shortly before the next major
>> release.
>>
>>>
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>>                                        Live:   OO#.. Dead: OO#.. 
>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>> rocks...1k
>>>
>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait"
>> <djosseparfait at gmail.com> wrote:
>>>> Good morning,
>>>>
>>>> I would like to know how often per year is a new full version
>> release
>>>> of R.
>>>>
>>>>
>>>>
>>>> Thanks
>>>>
>>>> --
>>>> Djoss? Parfait BODJRENOU
>>>> Chef de la Division Centralisation et Analyse des Donn?es
>>>> Statistiques /DPP/MESFTPRIJ
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Wed Aug  5 21:19:07 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 5 Aug 2015 12:19:07 -0700
Subject: [R] nested model and post hoc?
In-Reply-To: <1438785622177-4710784.post@n4.nabble.com>
References: <1438785622177-4710784.post@n4.nabble.com>
Message-ID: <CAGxFJbSzwhpABGAHghKDeSuX1KtPGPj8T0N_PV7ZFdCBDG9y6Q@mail.gmail.com>

I rather suspect the problem is primarily statistical, not R related. If at
all possible, try to get some local statistical advice. Most probably, you
have empty cells in some of the dpi.f by diss.f table.

Also, using a Gaussian family and the cells/mg response may be
inappropriate: 1 cell  in 5 mg is different than 100 cells in 500 mg. This
obviously depends on your data, which is why local help might be important.

Cheers,
Bert


On Wednesday, August 5, 2015, a_wohl <sithlord1 at gmx.net> wrote:

> Hi :-) i am really looking forward to get some help... Since I am a
> R-beginner I need it.
>
> I have a model consisting of the factors: dpi, infection, dissection day
> and
> plate. My reskponse variable is cells/mg. dpi is nested in dissection day.
> They are all fixed variables.
> I produced this nested model (best AIC index)
> glm.3<-cm.2~infect.f+dpi.f+dpi.f/diss.f, na.action=na.omit)
>
> summary(glm.3)
> Call:
> glm(formula = cm.2 ~ infect.f + dpi.f + dpi.f %in% diss.f, family =
> gaussian,
>     na.action = na.omit)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -2.7746  -0.3625   0.0080   0.3628   1.9031
>
> Coefficients: (18 not defined because of singularities)
>                 Estimate Std. Error t value Pr(>|t|)
> (Intercept)      7.01887    0.15278  45.941  < 2e-16 ***
> infect.finf      0.05544    0.08107   0.684   0.4946
> infect.fsha     -0.15563    0.08831  -1.762   0.0791 .
> dpi.f2           0.08924    0.20459   0.436   0.6630
> dpi.f4          -0.40167    0.21082  -1.905   0.0577 .
> dpi.f8           0.01961    0.20789   0.094   0.9249
> dpi.f16          0.82210    0.20469   4.016 7.54e-05 ***
> dpi.f32          0.99639    0.21435   4.648 5.09e-06 ***
> dpi.f1:diss.f2   0.13276    0.21077   0.630   0.5293
> dpi.f2:diss.f2        NA         NA      NA       NA
> dpi.f4:diss.f2   0.46749    0.20784   2.249   0.0253 *
> dpi.f8:diss.f2  -0.06555    0.20205  -0.324   0.7459
> dpi.f16:diss.f2       NA         NA      NA       NA
> dpi.f32:diss.f2       NA         NA      NA       NA
> dpi.f1:diss.f3        NA         NA      NA       NA
> dpi.f2:diss.f3  -0.15794    0.20186  -0.782   0.4346
> dpi.f4:diss.f3   0.20921    0.21081   0.992   0.3218
> dpi.f8:diss.f3        NA         NA      NA       NA
> dpi.f16:diss.f3 -0.03611    0.20178  -0.179   0.8581
> dpi.f32:diss.f3       NA         NA      NA       NA
> dpi.f1:diss.f4   0.14040    0.20459   0.686   0.4931
> dpi.f2:diss.f4  -0.01701    0.21152  -0.080   0.9360
> dpi.f4:diss.f4        NA         NA      NA       NA
> dpi.f8:diss.f4        NA         NA      NA       NA
> dpi.f16:diss.f4 -0.19082    0.20168  -0.946   0.3449
> dpi.f32:diss.f4       NA         NA      NA       NA
> dpi.f1:diss.f5        NA         NA      NA       NA
> dpi.f2:diss.f5        NA         NA      NA       NA
>
> ........and so forth.
> Since i decided for a nested modul, I wonder where the NAs are coming from?
> Since I want to perform a post hoc test, I was trysing the glht fuinction
> form the multcomp package.
> I always get this error
> Error in modelparm.default(model, ...) :
>   dimensions of coefficients and covariance matrix don't match
>
> I think this is due to my NAs in the summary(glm.3).
> Can anyone help me, how I can perform a post hoc test (Bonferroni) on my
> data?
>
> thank you
> a_wohl
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/nested-model-and-post-hoc-tp4710784.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Aug  5 22:36:15 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 5 Aug 2015 22:36:15 +0200
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <55C256C2.70306@gmail.com>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
	<55C245AE.8030808@fredhutch.org>
	<98A0381D-817F-4883-9889-417B54475ECF@dcn.davis.CA.us>
	<55C256C2.70306@gmail.com>
Message-ID: <27D92B17-CBB5-4E76-A9A0-E1371A8B13F9@gmail.com>


> On 05 Aug 2015, at 20:32 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/08/2015 2:15 PM, Jeff Newmiller wrote:
>> So 3.1.3 to 3.2.0 was a major release?
> 
> Yes.  We do have the oddity (see ?version) that 3 is the major version
> number and 2.0 is the minor version number including 0 as the
> patchlevel, but we still call it a major release when the number in the
> middle changes (e.g. 1 changed to 2 in the 3.2.0 release).  It's a patch
> release when only the patchlevel changes.
> 

Actually the wording on the developer site rather carefully avoids calling minor releases major... 

The dynamics of actual major releases, i.e. x.0.0, are less predictable than the x.y.0 ones; up till now there has been one in each of 2000, 2004, 2013. They usually signify some degree of accomplishment and possibly discontinuity in the API.

-pd 

> Duncan Murdoch
> 
> 
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> --------------------------------------------------------------------------- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On August 5, 2015 1:19:42 PM EDT, Martin Morgan <mtmorgan at fredhutch.org> wrote:
>>> On 08/05/2015 10:08 AM, Jeff Newmiller wrote:
>>>> New versions are released when they are ready. This is
>>> volunteer-driven software.
>>> 
>>> From https://developer.r-project.org/ :
>>> 
>>> The overall release schedule is to have annual x.y.0 releases in
>>> Spring, with 
>>> patch releases happening on an as-needed basis. It is intended to have
>>> a final 
>>> patch release of the previous version shortly before the next major
>>> release.
>>> 
>>>> 
>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>>                                       Live:   OO#.. Dead: OO#.. 
>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>> rocks...1k
>>>> 
>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait"
>>> <djosseparfait at gmail.com> wrote:
>>>>> Good morning,
>>>>> 
>>>>> I would like to know how often per year is a new full version
>>> release
>>>>> of R.
>>>>> 
>>>>> 
>>>>> 
>>>>> Thanks
>>>>> 
>>>>> --
>>>>> Djoss? Parfait BODJRENOU
>>>>> Chef de la Division Centralisation et Analyse des Donn?es
>>>>> Statistiques /DPP/MESFTPRIJ
>>>>> 
>>>>> 	[[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Wed Aug  5 22:47:52 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 05 Aug 2015 16:47:52 -0400
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <27D92B17-CBB5-4E76-A9A0-E1371A8B13F9@gmail.com>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
	<55C245AE.8030808@fredhutch.org>
	<98A0381D-817F-4883-9889-417B54475ECF@dcn.davis.CA.us>
	<55C256C2.70306@gmail.com>
	<27D92B17-CBB5-4E76-A9A0-E1371A8B13F9@gmail.com>
Message-ID: <55C27678.8040004@gmail.com>

On 05/08/2015 4:36 PM, peter dalgaard wrote:
> 
>> On 05 Aug 2015, at 20:32 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 05/08/2015 2:15 PM, Jeff Newmiller wrote:
>>> So 3.1.3 to 3.2.0 was a major release?
>>
>> Yes.  We do have the oddity (see ?version) that 3 is the major version
>> number and 2.0 is the minor version number including 0 as the
>> patchlevel, but we still call it a major release when the number in the
>> middle changes (e.g. 1 changed to 2 in the 3.2.0 release).  It's a patch
>> release when only the patchlevel changes.
>>
> 
> Actually the wording on the developer site rather carefully avoids calling minor releases major... 

Except when it doesn't:  "It is intended to have a final patch release
of the previous version shortly before the next major release."

Duncan

> 
> The dynamics of actual major releases, i.e. x.0.0, are less predictable than the x.y.0 ones; up till now there has been one in each of 2000, 2004, 2013. They usually signify some degree of accomplishment and possibly discontinuity in the API.
> 
> -pd 
> 
>> Duncan Murdoch
>>
>>
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                      Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> --------------------------------------------------------------------------- 
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On August 5, 2015 1:19:42 PM EDT, Martin Morgan <mtmorgan at fredhutch.org> wrote:
>>>> On 08/05/2015 10:08 AM, Jeff Newmiller wrote:
>>>>> New versions are released when they are ready. This is
>>>> volunteer-driven software.
>>>>
>>>> From https://developer.r-project.org/ :
>>>>
>>>> The overall release schedule is to have annual x.y.0 releases in
>>>> Spring, with 
>>>> patch releases happening on an as-needed basis. It is intended to have
>>>> a final 
>>>> patch release of the previous version shortly before the next major
>>>> release.
>>>>
>>>>>
>>>> ---------------------------------------------------------------------------
>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>>                                       Live:   OO#.. Dead: OO#.. 
>>>> Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>>> rocks...1k
>>>>>
>>>> ---------------------------------------------------------------------------
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait"
>>>> <djosseparfait at gmail.com> wrote:
>>>>>> Good morning,
>>>>>>
>>>>>> I would like to know how often per year is a new full version
>>>> release
>>>>>> of R.
>>>>>>
>>>>>>
>>>>>>
>>>>>> Thanks
>>>>>>
>>>>>> --
>>>>>> Djoss? Parfait BODJRENOU
>>>>>> Chef de la Division Centralisation et Analyse des Donn?es
>>>>>> Statistiques /DPP/MESFTPRIJ
>>>>>>
>>>>>> 	[[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jsorkin at grecc.umaryland.edu  Wed Aug  5 22:54:40 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 05 Aug 2015 16:54:40 -0400
Subject: [R] Simulate skewed data if 2.5, 25th 50th and 75 centile are known
Message-ID: <55C23FD0020000CB0013527D@smtp.medicine.umaryland.edu>

Colleagues,
I need to simulate skewed data so I can run a sample size calculation.
 
I know the 2.5th, 25th, 50th, and 75th centiles of the data (32, 43, 48, 250).
 
data <- matrix(c(75,250,50,48,25,43,2.5,32),nrow=4,ncol=2,byrow=TRUE)
dimnames(data) <- list(NULL,c("x","y"))
data

Is there a way I can use these values to generate simulations of the original data? Of course if the data were normally distributed this would be a piece of cake, but given the skewness, I don't know how to go about the generating the values that would be expected from a distribution having the observed values at the four centiles.
Thank you,
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From sithlord1 at gmx.net  Wed Aug  5 19:18:36 2015
From: sithlord1 at gmx.net (a_wohl)
Date: Wed, 5 Aug 2015 10:18:36 -0700 (PDT)
Subject: [R] nested model and post hoc?
In-Reply-To: <1438785622177-4710784.post@n4.nabble.com>
References: <1438785622177-4710784.post@n4.nabble.com>
Message-ID: <1438795116140-4710789.post@n4.nabble.com>

maybe i have to make my data more clear to you ?smile?-Emoticon
I am working with stickleback and a parasite. for my experiments I infected
the fish, so I have 3 groups in my infected factor (infected, exposed but
not infected and naive controll)
To get some information about different time points I dissected them
1,2,4,8,16,32 days post exposure (=dpi). I had 6 dissection days on which I
dissected samples of three different dpi (for example: one day one I
dissected 1,8 and 16 dpi, on day 2 8,4,32 dpi ...)
I am sure, that my problems with the post hoc come fromthe fact, that I
didn't dissect every dpi on every dissection day. But I don't know to
account for that, besides nesting



--
View this message in context: http://r.789695.n4.nabble.com/nested-model-and-post-hoc-tp4710784p4710789.html
Sent from the R help mailing list archive at Nabble.com.


From gordonjo at post.bgu.ac.il  Wed Aug  5 19:39:08 2015
From: gordonjo at post.bgu.ac.il (Gordonjo)
Date: Wed, 5 Aug 2015 10:39:08 -0700 (PDT)
Subject: [R] Installing package caret on a remote server
Message-ID: <1438796348650-4710792.post@n4.nabble.com>

I'm trying to install package caret on a remote server. At first, it told me
that I didn't have the necessary dependencies (ggplot2, nplotr, ...,
BradleyTerry2). I played with the repositories and the mirrors until I was
able to install all of the dependency packages except for BradleyTerry 2.
Now, when I run install.packages('caret', dependencies=TRUE), I get the
following warning message, and the installation fails:

1: In install.packages("caret", dependencies = TRUE) :
  installation of package ?BradleyTerry2? had non-zero exit status
2: In install.packages("caret", dependencies = TRUE) :
  installation of package ?caret? had non-zero exit status

I read up a bit on the web and I saw that the problem may be that I have
package brglm version 0.6-1, which is incompatible with BradleyTerry2. My
questions are:

1. Could this be the reason why I'm failing to install BradleyTerry2 (and
caret as a consequence)? If not, do you have any idea what else could be the
problem?
2. If so, how can I install brglm version 0.5-9? I can only seem to install
the newest version.

Thanks a lot for the help



--
View this message in context: http://r.789695.n4.nabble.com/Installing-package-caret-on-a-remote-server-tp4710792.html
Sent from the R help mailing list archive at Nabble.com.


From javajimburke at gmail.com  Wed Aug  5 19:45:50 2015
From: javajimburke at gmail.com (Jim Burke)
Date: Wed, 5 Aug 2015 12:45:50 -0500
Subject: [R] aggravating aggregate
Message-ID: <CALkjiFSJOjV5vSmpDaBKpXwvKidm9jNNdB=VwgfoeKZZUF2MJg@mail.gmail.com>

Greetings R mavens (and that's YOU). Given the following how on earth do I
aggregate and sum duplicate PCT rows into one combined row per PCT?

Data types
> str(xxx)
'data.frame':   9 obs. of  3 variables:
 $ Registered: int  1327 2129 10 433 5 166 1784 17 787 700
 $ GA_Total  : int  127 150 0 32 1 76 153 7 31 23
 $ PCT       : chr  "1120" "1121" "1121" "1122" ...

Data desired to be summarized
Registered GA_Total  PCT
1327       127      1120
2129       150      1121
  10         0      1121
 433        32      1122
   5         1      1124
 166        76      1125
1784       153      1125
  17         7      1125
 787        31      1126

Desired summary
Registered GA_Total  PCT
1327       127      1120
2139       150      1121
 433        32      1122
   5         1      1124
1967       236      1125
 787        31      1126

When answered this please make the reply suitable as a tutorial for many
other puzzled "R" "aggregate" people. Scarce useful examples on the
web. "Aggregate"
is a basic for statistical programming. Yet even ISBN 978-1461471370 An
Introduction to Statistical Learning with "R" does not appear to delve into
"aggerate". Basic simple and useful fully explained answers. If you have to
use "apply" then explain why.

Thanks
Jim Burke

	[[alternative HTML version deleted]]


From gdonald at gmail.com  Wed Aug  5 20:52:52 2015
From: gdonald at gmail.com (Greg Donald)
Date: Wed, 5 Aug 2015 13:52:52 -0500
Subject: [R] writing binary data from RCurl and postForm
Message-ID: <CAO+WgCYppHxo_9YQD67hJQkrSK=BJFABSE9tRT=4Qppa7mL8yA@mail.gmail.com>

I'm using RCurl with postForm() to post to a URL that responds with a
PDF.  I cannot figure out how to write the resulting PDF data to a
file without corruption.

result = postForm(url, binary=TRUE)

Both this:

capture.output(result, file='/tmp/export.pdf')

and this:

f = file('/tmp/export.pdf', 'wb')
write(result, f)
close(f)

result in a corrupted PDF.

I also tried postForm without binary=TRUE but that halts execution
with an "embedded nul in string" error.

I also tried writeBin() but that complains about my result not being a vector.

I can use curl on the command line and this works fine, but I need to
get this working in R.  Any help would be greatly appreciated.

Thanks.

--
Greg Donald


From bgunter.4567 at gmail.com  Wed Aug  5 23:21:09 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 5 Aug 2015 14:21:09 -0700
Subject: [R] Simulate skewed data if 2.5,
	25th 50th and 75 centile are known
In-Reply-To: <55C23FD0020000CB0013527D@smtp.medicine.umaryland.edu>
References: <55C23FD0020000CB0013527D@smtp.medicine.umaryland.edu>
Message-ID: <CAGxFJbREMkzw40aqKOhXqcJiAXrzWGAn4L92oCW-Prv6D2fg6g@mail.gmail.com>

Hint: See below.

On Wednesday, August 5, 2015, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> Colleagues,
> I need to simulate skewed data so I can run a sample size calculation.
>
> I know the 2.5th, 25th, 50th, and 75th centiles of the data (32, 43, 48,
> 250).
>
> data <- matrix(c(75,250,50,48,25,43,2.5,32),nrow=4,ncol=2,byrow=TRUE)
> dimnames(data) <- list(NULL,c("x","y"))
> data
>
> Is there a way I can use these values to generate simulations of the
> original data? Of course if the data were normally distributed this would
> be a piece of cake,


Oh -- how? ( a normal distribution is defined by 2 parameters. You appear
to have 4. ) If you can answer this question, you can probably answer the
same question for skew data. See also things like Johnson distributions,
Pearson distributions, and other flexible distribution families. You should
also probably move to stackexchange, as this is definitely a statistical
matter. Once you decide what to do, R will have a package to do it.

Others may be able to offer better advice, so wait a bit before proceeding,
though.

-- Bert

but given the skewness, I don't know how to go about the generating the
> values that would be expected from a distribution having the observed
> values at the four centiles.
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:25}}


From marc_schwartz at me.com  Wed Aug  5 23:44:14 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 05 Aug 2015 16:44:14 -0500
Subject: [R] Simulate skewed data if 2.5,
	25th 50th and 75 centile are known
In-Reply-To: <CAGxFJbREMkzw40aqKOhXqcJiAXrzWGAn4L92oCW-Prv6D2fg6g@mail.gmail.com>
References: <55C23FD0020000CB0013527D@smtp.medicine.umaryland.edu>
	<CAGxFJbREMkzw40aqKOhXqcJiAXrzWGAn4L92oCW-Prv6D2fg6g@mail.gmail.com>
Message-ID: <B110DE37-F345-495E-B87B-8F62324F4989@me.com>


> On Aug 5, 2015, at 4:21 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Hint: See below.
> 
> On Wednesday, August 5, 2015, John Sorkin <jsorkin at grecc.umaryland.edu>
> wrote:
> 
>> Colleagues,
>> I need to simulate skewed data so I can run a sample size calculation.
>> 
>> I know the 2.5th, 25th, 50th, and 75th centiles of the data (32, 43, 48,
>> 250).
>> 
>> data <- matrix(c(75,250,50,48,25,43,2.5,32),nrow=4,ncol=2,byrow=TRUE)
>> dimnames(data) <- list(NULL,c("x","y"))
>> data
>> 
>> Is there a way I can use these values to generate simulations of the
>> original data? Of course if the data were normally distributed this would
>> be a piece of cake,
> 
> 
> Oh -- how? ( a normal distribution is defined by 2 parameters. You appear
> to have 4. ) If you can answer this question, you can probably answer the
> same question for skew data. See also things like Johnson distributions,
> Pearson distributions, and other flexible distribution families. You should
> also probably move to stackexchange, as this is definitely a statistical
> matter. Once you decide what to do, R will have a package to do it.
> 
> Others may be able to offer better advice, so wait a bit before proceeding,
> though.
> 
> -- Bert
> 
> but given the skewness, I don't know how to go about the generating the
>> values that would be expected from a distribution having the observed
>> values at the four centiles.
>> Thank you,
>> John


John,

Just to pick up on Bert?s suggestion, there are some threads over on SE that discuss similar subject matter, one of which, due to my own curiosity, led me to:

  https://cran.r-project.org/web/packages/rriskDistributions/index.html

which you may find of value.

Regards,

Marc Schwartz


From mtmorgan at fredhutch.org  Wed Aug  5 23:49:42 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Wed, 05 Aug 2015 14:49:42 -0700
Subject: [R] writing binary data from RCurl and postForm
In-Reply-To: <CAO+WgCYppHxo_9YQD67hJQkrSK=BJFABSE9tRT=4Qppa7mL8yA@mail.gmail.com>
References: <CAO+WgCYppHxo_9YQD67hJQkrSK=BJFABSE9tRT=4Qppa7mL8yA@mail.gmail.com>
Message-ID: <55C284F6.5090404@fredhutch.org>

On 08/05/2015 11:52 AM, Greg Donald wrote:
> I'm using RCurl with postForm() to post to a URL that responds with a
> PDF.  I cannot figure out how to write the resulting PDF data to a
> file without corruption.
>
> result = postForm(url, binary=TRUE)
>
> Both this:
>
> capture.output(result, file='/tmp/export.pdf')
>
> and this:
>
> f = file('/tmp/export.pdf', 'wb')
> write(result, f)
> close(f)
>
> result in a corrupted PDF.
>
> I also tried postForm without binary=TRUE but that halts execution
> with an "embedded nul in string" error.
>
> I also tried writeBin() but that complains about my result not being a vector.

I think that is because the value returned from postForm has an attribute; 
remove it by casting the return to a vector

   fl <- tempfile(fileext=".pdf")
   writeBin(as.vector(postForm(url, binary=TRUE)), fl)


The httr package might also be a good bet

   writeBin(content(POST(url)), fl)

>
> I can use curl on the command line and this works fine, but I need to
> get this working in R.  Any help would be greatly appreciated.
>
> Thanks.
>
> --
> Greg Donald
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From wdunlap at tibco.com  Wed Aug  5 23:49:46 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 5 Aug 2015 14:49:46 -0700
Subject: [R] aggravating aggregate
In-Reply-To: <CALkjiFSJOjV5vSmpDaBKpXwvKidm9jNNdB=VwgfoeKZZUF2MJg@mail.gmail.com>
References: <CALkjiFSJOjV5vSmpDaBKpXwvKidm9jNNdB=VwgfoeKZZUF2MJg@mail.gmail.com>
Message-ID: <CAF8bMcaaUTt0BXSbu1rQ=CAGrgy4nW_NNGY1heA34rwDjqkCKw@mail.gmail.com>

# your data, from dump("xxx", file=stdout())
xxx <-
structure(list(Registered = c(1327, 2129, 10, 433, 5, 166, 1784,
17, 787), GA_Total = c(127, 150, 0, 32, 1, 76, 153, 7, 31), PCT = c("1120",
"1121", "1121", "1122", "1124", "1125", "1125", "1125", "1126"
)), .Names = c("Registered", "GA_Total", "PCT"), class = "data.frame",
row.names = c(NA,
-9L))
axxx <- aggregate(. ~ PCT, data=xxx, FUN=sum)
axxx
#   PCT Registered GA_Total
#1 1120       1327      127
#2 1121       2139      150
#3 1122        433       32
#4 1124          5        1
#5 1125       1967      236
#6 1126        787       31
# or
aggregate(xxx[, c("Registered", "GA_Total")], by=xxx[,"PCT",drop=FALSE],
sum)
#   PCT Registered GA_Total
#1 1120       1327      127
#2 1121       2139      150
#3 1122        433       32
#4 1124          5        1
#5 1125       1967      236
#6 1126        787       31

Use subscripting to rearrange the columns: axxx2 <- axxx[, c(2,3,1)].

Many people find the functions in the dplyr package easier to use.  E.g.,
library(dplyr)
group_by(xxx, PCT) %>% summarize(Registered=sum(Registered),
GA_Total=sum(GA_Total))
#Source: local data frame [6 x 3]
#
#   PCT Registered GA_Total
#1 1120       1327      127
#2 1121       2139      150
#3 1122        433       32
#4 1124          5        1
#5 1125       1967      236
#6 1126        787       31



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Aug 5, 2015 at 10:45 AM, Jim Burke <javajimburke at gmail.com> wrote:

> Greetings R mavens (and that's YOU). Given the following how on earth do I
> aggregate and sum duplicate PCT rows into one combined row per PCT?
>
> Data types
> > str(xxx)
> 'data.frame':   9 obs. of  3 variables:
>  $ Registered: int  1327 2129 10 433 5 166 1784 17 787 700
>  $ GA_Total  : int  127 150 0 32 1 76 153 7 31 23
>  $ PCT       : chr  "1120" "1121" "1121" "1122" ...
>
> Data desired to be summarized
> Registered GA_Total  PCT
> 1327       127      1120
> 2129       150      1121
>   10         0      1121
>  433        32      1122
>    5         1      1124
>  166        76      1125
> 1784       153      1125
>   17         7      1125
>  787        31      1126
>
> Desired summary
> Registered GA_Total  PCT
> 1327       127      1120
> 2139       150      1121
>  433        32      1122
>    5         1      1124
> 1967       236      1125
>  787        31      1126
>
> When answered this please make the reply suitable as a tutorial for many
> other puzzled "R" "aggregate" people. Scarce useful examples on the
> web. "Aggregate"
> is a basic for statistical programming. Yet even ISBN 978-1461471370 An
> Introduction to Statistical Learning with "R" does not appear to delve into
> "aggerate". Basic simple and useful fully explained answers. If you have to
> use "apply" then explain why.
>
> Thanks
> Jim Burke
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu Aug  6 00:47:38 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 5 Aug 2015 17:47:38 -0500
Subject: [R] writing binary data from RCurl and postForm
In-Reply-To: <55C284F6.5090404@fredhutch.org>
References: <CAO+WgCYppHxo_9YQD67hJQkrSK=BJFABSE9tRT=4Qppa7mL8yA@mail.gmail.com>
	<55C284F6.5090404@fredhutch.org>
Message-ID: <CABdHhvF4Eg+Lu0A7QDbQK7rJHAeBh9DKDPuiHay34Yf_HmfckA@mail.gmail.com>

> I think that is because the value returned from postForm has an attribute;
> remove it by casting the return to a vector
>
>   fl <- tempfile(fileext=".pdf")
>   writeBin(as.vector(postForm(url, binary=TRUE)), fl)
>
>
> The httr package might also be a good bet
>
>   writeBin(content(POST(url)), fl)

Or write response directly to disk with

POST(url, write_disk(fl))

Hadley

-- 
http://had.co.nz/


From canamika at gmail.com  Thu Aug  6 02:25:21 2015
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Wed, 5 Aug 2015 20:25:21 -0400
Subject: [R] Need help with kde2d function in R
Message-ID: <CALv--dZgA8vDq2xtDaJr8-zthYG65qWVzErgAMGo4JNB=34+xw@mail.gmail.com>

Hi,
I am trying to create a bivariate ellipse to see if the true values fall
within the 95% confidence ellipse. I am getting subscript out of bounds
error in R with following code. Not sure what is causing it. When I use the
kde2d function with n>=30 I get the error but not for n=25 and below.

    library(MASS)
    set.seed(1234)

    #Set working directory
    setwd("C://Tina/USB_Backup_042213/Paper II/MLN
Automation/csvs_equal_20s")
    p1<- .136
    p2<- .069
    nn<-60
     Y<-NULL
    >     Y <- read.csv(file=paste0("MVN",i,".csv"), header=T)
    >
    > Y<-as.matrix(Y)
    > xx <- ifelse(Y==0,Y+.5,Y)
    > nnn <- ifelse(Y==0,nn+.5,nn)
    >
    > xx<-as.matrix(xx)
    > Y1<-xx/nnn # estimates of p
    >
    >
    > #print(Y1)
    >
    > sigma2<-
matrix(c(var(Y1[,1]),cov(Y1[,1],Y1[,2]),cov(Y1[,1],Y1[,2]),var(Y1[,2])),2,2)
    > print(sigma2)
               [,1]        [,2]
    [1,] 0.02142909 0.010810225
    [2,] 0.01081023 0.008138709
    >
    > rho<-sigma2[1,2]/sqrt(sigma2[1,1]*sigma2[2,2])
    >
    > rate<-Y1[2,] # change for each site
    > print(rate)
            Y1         Y2
    0.13333333 0.06666667
    >
    > rate1<-rate/(1-rate)
    >
    > #print(rate1)
    >
    > rate2<-log(rate1)
    >
    > Sigma11<-(1/(rate[1]*(1-rate[1]))^2)*sigma2[1,1]
    > Sigma22<-(1/(rate[2]*(1-rate[2]))^2)*sigma2[2,2]
    > Sigma12<-(1/((rate[1]*(1-rate[1]))*(rate[2]*(1-rate[2]))))*sigma2[1,2]
    >
    > Sigma2<-matrix(c(Sigma11,Sigma12,Sigma12,Sigma22),2,2)
    >
    > #print(Sigma2)
    >
    > rate3<-mvrnorm(1000, mu=c(rate2[1],rate2[2]), Sigma2)
    >
    > #print(rate3)
    >
    > x<-exp(rate3[,1])/(1+exp(rate3[,1]))
    > y<-exp(rate3[,2])/(1+exp(rate3[,2]))
    >
    > ## Points within polygons
    > library(MASS)
    > dens <- kde2d(x, y, n=25)
    > image(dens)
    >
    >
    >
#filled.contour(dens,color.palette=colorRampPalette(c('white','blue','yellow','red','darkred')))
    >
    >
    > prob <- c(0.975, 0.025)
    > dx <- diff(dens$x[1:2])
    > dy <- diff(dens$y[1:2])
    > sz <- sort(dens$z)
    >
    > c1 <- cumsum(sz) * dx * dy
    > levels <- sapply(prob, function(x) {
    +     approx(c1, sz, xout = 1 - x)$y
    + })
    > #plot(p1,p2)
    > #contour(dens, levels=levels, labels=prob, add=T)
    > ls <- contourLines(dens, level=levels)
    > print(ls)
    [[1]]
    [[1]]$level
    [1] 0.2149866

    [[1]]$x
     [1] 0.004397130 0.004568786 0.020836478 0.032862816 0.040885850
0.049303040
     [7] 0.077374571 0.095771788 0.113863291 0.139211514 0.127080458
0.139599553
    [13] 0.150352011 0.186840732 0.201445193 0.223329452 0.239170012
0.245315258
    [19] 0.259818172 0.296306893 0.332795613 0.369284333 0.405773053
0.415153288
    [25] 0.442261774 0.472911758 0.478750494 0.515239214 0.536208449
0.551727935
    [31] 0.588216655 0.624705375 0.646392119 0.624705375 0.618407028
0.607497171
    [37] 0.624705375 0.661194096 0.697682816 0.734171536 0.750443060
0.770660257
    [43] 0.780548310 0.807148977 0.823897778 0.815766169 0.807148977
0.770660257
    [49] 0.745293482 0.750888227 0.734171536 0.733822194 0.734171536
0.770660257
    [55] 0.780165097 0.807148977 0.821208006 0.807148977 0.770975720
0.770660257
    [61] 0.734171536 0.712245087 0.697682816 0.693122349 0.693977032
0.697682816
    [67] 0.704425811 0.719174523 0.700076998 0.706464923 0.711329752
0.697682816
    [73] 0.661194096 0.624705375 0.588216655 0.577866122 0.588216655
0.589258511
    [79] 0.588216655 0.551727935 0.515239214 0.478750494 0.469648285
0.442261774
    [85] 0.405773053 0.395062033

    [[1]]$y
     [1] 0.1783278616 0.1786369552 0.2142104572 0.2497839592 0.2640206283
     [6] 0.2853574612 0.3109011130 0.3209309632 0.3351406407 0.3565044651
    [11] 0.3920779671 0.4276514691 0.4342808892 0.4573891723 0.4632249711
    [16] 0.4823023723 0.4987984731 0.5343719750 0.5402153675 0.5529088973
    [21] 0.5541833087 0.5511966122 0.5658454057 0.5699454770 0.5780502406
    [26] 0.5699454770 0.5677285953 0.5582423238 0.5699454770 0.5766348870
    [31] 0.5899083535 0.6007347908 0.6055189790 0.6249103884 0.6410924810
    [36] 0.6766659830 0.6936330128 0.7051209093 0.7052210613 0.7104009871
    [41] 0.7122394849 0.7175712767 0.7122394849 0.7002511608 0.6766659830
    [46] 0.6410924810 0.6338424511 0.6130127829 0.6055189790 0.5699454770
    [51] 0.5348306032 0.5343719750 0.5340918150 0.5053232008 0.4987984731
    [56] 0.4728407406 0.4632249711 0.4535094747 0.4276514691 0.4274565392
    [61] 0.4021096213 0.3920779671 0.3724826039 0.3565044651 0.3209309632
    [66] 0.3068930025 0.2853574612 0.2497839592 0.2142104572 0.1786369552
    [71] 0.1430634533 0.1356917738 0.1315167472 0.1273426210 0.1140927079
    [76] 0.1074899513 0.0744396356 0.0719164493 0.0703319222 0.0509793010
    [81] 0.0542138537 0.0417716905 0.0363429473 0.0207462171 0.0047801760
    [86] 0.0007694453


    [[2]]
    [[2]]$level
    [1] 0.2149866

    [[2]]$x
    [1] 0.2963069 0.2847163 0.2802502 0.2963069 0.3327956 0.3517197
0.3563875
    [8] 0.3327956 0.2963069

    [[2]]$y
    [1] 0.5929265 0.6055190 0.6410925 0.6510478 0.6520754 0.6410925
0.6055190
    [8] 0.5877331 0.5929265


    [[3]]
    [[3]]$level
    [1] 0.2149866

    [[3]]$x
    [1] 0.8059980 0.8071490 0.8436377 0.8449198 0.8436377 0.8071490
0.7848487
    [8] 0.7706603 0.7584362

    [[3]]$y
    [1] 0.8545335 0.8530500 0.8207634 0.8189600 0.8169512 0.8104161
0.8189600
    [8] 0.8304354 0.8545335


    > library(sp)
    > inner <- point.in.polygon(p1, p2, ls[[2]]$x, ls[[2]]$y) # whether
points in inner ellipse
    > out <- point.in.polygon(p1, p2, ls[[1]]$x, ls[[1]]$y) # whether
points in outter ellipse
    >
    > within<-(inner+out)
    >
    > print(within)
    [1] 0

Thanks
Anamika

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Thu Aug  6 03:03:35 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Thu, 06 Aug 2015 01:03:35 +0000 (GMT)
Subject: [R] Knit R and Book Publishing
Message-ID: <feb0b8d7-f27a-4669-bbd8-b1f69050e1c1@me.com>

Hello All,

I have finished my first R package, BondLab, and it will be available in Feb 2016. ? I wrote the book and R package concurrently. ?Prior, I had very little programming experience other than VBA and using others R packages. ?

http://www.amazon.com/Investing-Mortgage-Backed-Securities-Website/dp/1118944003/ref=sr_1_1?ie=UTF8&qid=1438822386&sr=8-1&keywords=glenn+m+schultz

During the learning process I came to know literate programming and reproducible research. ?Now, ?I have a viable package and I would like re-write the book in R Studio with knitr. ?I have had some success with LYX but I think I can do the whole thing in R studio. ?The first edition was done in TexMaker.

I really want to set the next project up in R Studio, I would really like to open source the next edition like Hadley's recent books but I really don't know how it was all done. ?Any starting points to set this up are appreciated.

-Glenn

From dulcalma at bigpond.com  Thu Aug  6 06:23:55 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 6 Aug 2015 14:23:55 +1000
Subject: [R] Lattice: raw data and prediction of a non linear fitted
	function
In-Reply-To: <CAOH82u2mJx5C84rJ3Sx9a4AcDma0kprd6=P5aQPAtNFVKzqaEw@mail.gmail.com>
References: <CAOH82u2mJx5C84rJ3Sx9a4AcDma0kprd6=P5aQPAtNFVKzqaEw@mail.gmail.com>
Message-ID: <000c01d0cfff$b5290980$1f7b1c80$@bigpond.com>

Sending again as I pressed the wrong button

Hi

Your model is overfitted for the number of points - the fitted values bear
no resemblance to a line fitting the data - ?too many x values to properly
predict
? splines etc
 library(locfit)
?locfit
If you want coefs of sort.

You have to do a nls on each group to get the values. 
You have 2 ways to do this 
1 do nls and predict y values separately as below an plot them in a panel
function
2 do nls and predict within the panel function 

> res_nlsA <-
+ nls(y ~ SSgompertz(time, Asym = 100, b2, b3), data = subset(foo, char ==
"A"),
+     start = list( b2 = c(7,7), b3 = c(0.9, 0.9)))
There were 50 or more warnings (use warnings() to see the first 50)
> res_nlsA
Nonlinear regression model
  model: y ~ SSgompertz(time, Asym = 100, b2, b3)
   data: subset(foo, char == "A")
   b21    b22    b31    b32 
4.6761 7.6280 0.9111 0.9000 
 residual sum-of-squares: 10.59

Number of iterations to convergence: 32 
Achieved convergence tolerance: 8.001e-06
> res_nlsB <-
+ nls(y ~ SSgompertz(time, Asym = 100, b2, b3), data = subset(foo, char ==
"B"),
+     start = list( b2 = c(7,7), b3 = c(0.9, 0.9)))
> res_nlsB
Nonlinear regression model
  model: y ~ SSgompertz(time, Asym = 100, b2, b3)
   data: subset(foo, char == "B")
    b21     b22     b31     b32 
 9.5231 86.6421  0.8164  0.6582 
 residual sum-of-squares: 36.26

Number of iterations to convergence: 10 
Achieved convergence tolerance: 1.37e-06
> 
> predict(res_nlsB, newdata = list(time = seq(5,60,2.5)))
 [1]   3.162527   2.321040  28.575719  62.814774  63.489626  94.416582
84.809570  99.292612  94.199502  99.912322  97.856129  99.989162  99.217093
99.998661  99.715346
[16]  99.999835  99.896669  99.999980  99.962512  99.999997  99.986402
100.000000  99.995068
Warning messages:
1: In b3^x :
  longer object length is not a multiple of shorter object length
2: In -b2 * .expr2 :
  longer object length is not a multiple of shorter object length
> predict(res_nlsB, newdata = list(time = seq(5,60,5)))
 [1]   3.162527  26.638924  63.489626  98.000694  94.199502  99.969171
99.217093  99.999529  99.896669  99.999993  99.986402 100.000000
> predict(res_nlsA, newdata = list(time = seq(0,55,5)))
 [1]  0.9314904  1.1062577 15.8281748 20.7951276 48.3512870 57.8358643
75.0914782 82.6202586 89.3216331 93.5601696 95.6459638 97.7058236

xyplot(y ~ time, data = foo,
       groups = char,
       panel = panel.superpose,
       panel.groups = function(x, y, ...,group.number){
       
                 panel.xyplot(x,y, ...);

                 xy.nls <-
                 nls(y ~ SSgompertz(x, Asym = 100, b2, b3),
                     start = list( b2 =7, b3 =  0.9))

                 #print(summary(xy.nls))
                 
                 if (group.number == 1){
                   xy.pre <- predict(xy.nls, newdata = list(time =
seq(0,55,5)))
                   print(xy.pre)
                   llines( seq(5,60,5), xy.pre, col = "blue")
                 } else {
                   xy.pre <- predict(xy.nls, newdata = list(time =
seq(5,60,5)))
                   print(xy.pre)
                   llines( seq(5,60,5), xy.pre, col = "magenta")
                 }
                   
       })

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fran?ois
Collin
Sent: Wednesday, 5 August 2015 22:24
To: r-help at r-project.org
Subject: [R] Lattice: raw data and prediction of a non linear fitted
function

Dear all,

I have a question about lattice use. I would like to use it to represent:
- my raw data as points,
- and the results of a non linear fit as a line,
- having 2 groups data (and so 2 colors).

However, as I have few raw data, I would like to increase the number of
points to smooth the line which correspond to the fit.

So my questions are:
- How can I use the group argument to make new predictions inside panel
argument ?
- How can I use this prediction inside the panel argument to draw the fit
per group?

Hereafter a minimal example:

#==================================================
library(lattice)
set.seed(2)

# Dummy dataframe
foo <- data.frame(
  time = seq(0, 60, 5),
  char = sample(c("A", "B"), size = 13, replace = TRUE)
  );

# Simulated response vector according a Gompertz function + rnorn(0, 5)
foo$y <- SSgompertz(foo$time, Asym = 100, b2 = ifelse(foo$char == 'A', 6,
10),
  b3 = ifelse(foo$char == "A", .91, .8)) +
  rnorm(nrow(foo), mean=0, sd = 5);

# Non-linear fit on simulation data
res_nls <-  nls(
  y ~ SSgompertz(time, Asym = 100, b2[char], b3[char]), data = foo,
  start = list( b2 = c(7,7), b3 = c(0.9, 0.9)));

# My problem
xyplot(y ~ time, groups = char, data = foo,
  panel = function(x, y, groups=groups, model = model, ...){
    panel.xyplot(x,y, groups = groups, ...);

    newdata <- data.frame(time = x, char = groups);
    newdata$y <- predict(model, newdata = newdata);

    panel.superpose(x = newdata$time, y=newdata$y,  groups = groups, ...,
      panel.groups = function(x,y, col, col.symbol, ...){
        panel.lines(x,y, col.line = col.symbol)
      })

  }, model = res_nls);
#==================================================


Many thanks,
Francois

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From anshuk.p at motivitylabs.com  Thu Aug  6 09:42:26 2015
From: anshuk.p at motivitylabs.com (Anshuk Pal Chaudhuri)
Date: Thu, 6 Aug 2015 07:42:26 +0000
Subject: [R] Supervised Learning for Text Classification
Message-ID: <HKXPR02MB06329A4F5932833550BE85C6F0740@HKXPR02MB0632.apcprd02.prod.outlook.com>

Hi All,

The current process which I am doing:


1.       Reading Unstructured data, Understand what text means what. e.g. a phrase like "JOHN SMITH" this is a customer name. or a phrase like "CLAIM DURATION" is a reason type field. Currently, doing this manually (no issue over here).

2.       Creating a data frame with fields - Reason, Name, Category, Sub-Reason, Description. There is no boolean or numeric field (Do I need to create any? based on #5 need).

3.       Manually feeding the data frame with values as read from the unstructured data text. This would have approximate be having 50 rows. and this is my training set. (no issue over here)

4.       Dataframe #3 would be nothing but a supervised train data set.



Following #5, this is what I need to achieve (and need help here)-


5.       Now when I receive another file (test data),lets say to start - just a phrase "******************", can I predict that text based on the trained model, it is a Reason related phrase (based on the probability, lets say more than 70%), create a new data frame (PredcitedDF) and add a column (e.g. Reason) add a row for this text under Reason field. Again receive on more text phrase, which seems like "Name", add a column "Name" in the PredictedDF and add this value under Name column as second row...and hence further.

I was reading about RTextTools (http://www.rtexttools.com/), well in that case it has be told that this value is for this text and hence further...

Any help would be appreciated.

Regards,
Anshuk Pal Chaudhuri


	[[alternative HTML version deleted]]


From federico.calboli at helsinki.fi  Thu Aug  6 12:25:56 2015
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Thu, 6 Aug 2015 13:25:56 +0300
Subject: [R] testing whether two character vectors contain (the same) items
	in the same order
Message-ID: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>

Hi All,

let?s assume I have a vector of letters drawn only once from the alphabet:

x = sample(letters, 15, replace = F)
x
 [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"

y = x[c(1:7,9:8, 10:12, 14, 15, 13)]

I would now like to test how good a match y is for x.  Obviously I can transform the letters in numbers and use a rank test, but I was left wondering whether this is the only solution and whether there are more appropriate solutions that are already implemented in R (I am not going to reinvent the wheel if I can avoid it).

BW

F


--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From bgunter.4567 at gmail.com  Thu Aug  6 14:33:27 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 6 Aug 2015 05:33:27 -0700
Subject: [R] Knit R and Book Publishing
In-Reply-To: <feb0b8d7-f27a-4669-bbd8-b1f69050e1c1@me.com>
References: <feb0b8d7-f27a-4669-bbd8-b1f69050e1c1@me.com>
Message-ID: <CAGxFJbTEEFhwORdf3Eaxjzj1PAQGtwcrmN=kHqenyCqvJJWwSA@mail.gmail.com>

I would have thought that the first place to look was R Studio support
site. You will find a lot of (Imo well done) docs there as well as links to
Hadley's and Yihui's books and online docs.

Bert

On Wednesday, August 5, 2015, Glenn Schultz <glennmschultz at me.com> wrote:

> Hello All,
>
> I have finished my first R package, BondLab, and it will be available in
> Feb 2016.   I wrote the book and R package concurrently.  Prior, I had very
> little programming experience other than VBA and using others R packages.
>
>
> http://www.amazon.com/Investing-Mortgage-Backed-Securities-Website/dp/1118944003/ref=sr_1_1?ie=UTF8&qid=1438822386&sr=8-1&keywords=glenn+m+schultz
>
> During the learning process I came to know literate programming and
> reproducible research.  Now,  I have a viable package and I would like
> re-write the book in R Studio with knitr.  I have had some success with LYX
> but I think I can do the whole thing in R studio.  The first edition was
> done in TexMaker.
>
> I really want to set the next project up in R Studio, I would really like
> to open source the next edition like Hadley's recent books but I really
> don't know how it was all done.  Any starting points to set this up are
> appreciated.
>
> -Glenn
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Aug  6 14:40:12 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 6 Aug 2015 05:40:12 -0700
Subject: [R] testing whether two character vectors contain (the same)
 items in the same order
In-Reply-To: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
Message-ID: <CAGxFJbRj7Wsas6przfnrtw4uqM-MVU0=HO+kA_28zt8bQ70zUw@mail.gmail.com>

Define "goodness of match" .  For exact matches, see ?"==" , all.equal, etc.

Bert

On Thursday, August 6, 2015, Federico Calboli <federico.calboli at helsinki.fi>
wrote:

> Hi All,
>
> let?s assume I have a vector of letters drawn only once from the alphabet:
>
> x = sample(letters, 15, replace = F)
> x
>  [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
>
> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
>
> I would now like to test how good a match y is for x.  Obviously I can
> transform the letters in numbers and use a rank test, but I was left
> wondering whether this is the only solution and whether there are more
> appropriate solutions that are already implemented in R (I am not going to
> reinvent the wheel if I can avoid it).
>
> BW
>
> F
>
>
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
>
> federico.calboli at helsinki.fi <javascript:;>
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From federico.calboli at helsinki.fi  Thu Aug  6 15:51:22 2015
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Thu, 6 Aug 2015 16:51:22 +0300
Subject: [R] testing whether two character vectors contain (the same)
	items in the same order
In-Reply-To: <CAGxFJbRj7Wsas6przfnrtw4uqM-MVU0=HO+kA_28zt8bQ70zUw@mail.gmail.com>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
	<CAGxFJbRj7Wsas6przfnrtw4uqM-MVU0=HO+kA_28zt8bQ70zUw@mail.gmail.com>
Message-ID: <84FC2562-CE0F-4187-A742-02FAB2E98BA4@helsinki.fi>


> On 6 Aug 2015, at 15:40, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Define "goodness of match" .  For exact matches, see ?"==" , all.equal, etc.

Fair point.  I would define it as a number that tells me how likely it is that the same (noisy) process produced both lists.

BW

F




> 
> Bert
> 
> On Thursday, August 6, 2015, Federico Calboli <federico.calboli at helsinki.fi> wrote:
> Hi All,
> 
> let?s assume I have a vector of letters drawn only once from the alphabet:
> 
> x = sample(letters, 15, replace = F)
> x
>  [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
> 
> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
> 
> I would now like to test how good a match y is for x.  Obviously I can transform the letters in numbers and use a rank test, but I was left wondering whether this is the only solution and whether there are more appropriate solutions that are already implemented in R (I am not going to reinvent the wheel if I can avoid it).
> 
> BW
> 
> F
> 
> 
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
> 
> federico.calboli at helsinki.fi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> -- 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
>    -- Clifford Stoll
> 


--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From jvadams at usgs.gov  Thu Aug  6 17:37:04 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 6 Aug 2015 10:37:04 -0500
Subject: [R] (no subject)
In-Reply-To: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
Message-ID: <CAN5YmCGEhStrZZWOmbbTbjgSNvrwPRjzxJ-UtEUzbVF0sp9tRw@mail.gmail.com>

A quick internet search for
     R version history
yielded this page
     https://cran.r-project.org/bin/windows/base/old/

Jean

On Wed, Aug 5, 2015 at 4:55 AM, Djoss? Parfait <djosseparfait at gmail.com>
wrote:

> Good morning,
>
> I would like to know how often per year is a new full version release of R.
>
>
>
> Thanks
>
> --
> Djoss? Parfait BODJRENOU
> Chef de la Division Centralisation et Analyse des Donn?es
> Statistiques /DPP/MESFTPRIJ
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Aug  6 18:08:02 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 6 Aug 2015 18:08:02 +0200
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <55C27678.8040004@gmail.com>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
	<55C245AE.8030808@fredhutch.org>
	<98A0381D-817F-4883-9889-417B54475ECF@dcn.davis.CA.us>
	<55C256C2.70306@gmail.com>
	<27D92B17-CBB5-4E76-A9A0-E1371A8B13F9@gmail.com>
	<55C27678.8040004@gmail.com>
Message-ID: <8C2E5099-C8B1-4301-9663-7338958C4DD7@gmail.com>


> On 05 Aug 2015, at 22:47 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/08/2015 4:36 PM, peter dalgaard wrote:
>> 
>>> On 05 Aug 2015, at 20:32 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> 
>>> On 05/08/2015 2:15 PM, Jeff Newmiller wrote:
>>>> So 3.1.3 to 3.2.0 was a major release?
>>> 
>>> Yes.  We do have the oddity (see ?version) that 3 is the major version
>>> number and 2.0 is the minor version number including 0 as the
>>> patchlevel, but we still call it a major release when the number in the
>>> middle changes (e.g. 1 changed to 2 in the 3.2.0 release).  It's a patch
>>> release when only the patchlevel changes.
>>> 
>> 
>> Actually the wording on the developer site rather carefully avoids calling minor releases major... 
> 
> Except when it doesn't:  "It is intended to have a final patch release
> of the previous version shortly before the next major release."

Argh. Needs fixing... :-p

-pd

> 
> Duncan
> 
>> 
>> The dynamics of actual major releases, i.e. x.0.0, are less predictable than the x.y.0 ones; up till now there has been one in each of 2000, 2004, 2013. They usually signify some degree of accomplishment and possibly discontinuity in the API.
>> 
>> -pd 
>> 
>>> Duncan Murdoch
>>> 
>>> 
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>>                                     Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#. rocks...1k
>>>> --------------------------------------------------------------------------- 
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On August 5, 2015 1:19:42 PM EDT, Martin Morgan <mtmorgan at fredhutch.org> wrote:
>>>>> On 08/05/2015 10:08 AM, Jeff Newmiller wrote:
>>>>>> New versions are released when they are ready. This is
>>>>> volunteer-driven software.
>>>>> 
>>>>> From https://developer.r-project.org/ :
>>>>> 
>>>>> The overall release schedule is to have annual x.y.0 releases in
>>>>> Spring, with 
>>>>> patch releases happening on an as-needed basis. It is intended to have
>>>>> a final 
>>>>> patch release of the previous version shortly before the next major
>>>>> release.
>>>>> 
>>>>>> 
>>>>> ---------------------------------------------------------------------------
>>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>> Live...
>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>> Go...
>>>>>>                                      Live:   OO#.. Dead: OO#.. 
>>>>> Playing
>>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>>>> rocks...1k
>>>>>> 
>>>>> ---------------------------------------------------------------------------
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>> 
>>>>>> On August 5, 2015 5:55:21 AM EDT, "Djoss? Parfait"
>>>>> <djosseparfait at gmail.com> wrote:
>>>>>>> Good morning,
>>>>>>> 
>>>>>>> I would like to know how often per year is a new full version
>>>>> release
>>>>>>> of R.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Thanks
>>>>>>> 
>>>>>>> --
>>>>>>> Djoss? Parfait BODJRENOU
>>>>>>> Chef de la Division Centralisation et Analyse des Donn?es
>>>>>>> Statistiques /DPP/MESFTPRIJ
>>>>>>> 
>>>>>>> 	[[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Thu Aug  6 18:29:42 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 6 Aug 2015 18:29:42 +0200
Subject: [R] Release schedule (was (no subject) )
In-Reply-To: <8C2E5099-C8B1-4301-9663-7338958C4DD7@gmail.com>
References: <CALr2Sx2b_QmQa=q9tn4SUuMQZURSnLjqLn9VMZTwt_cjc87LQA@mail.gmail.com>
	<26721663-65F0-419A-B0CF-FFB38AF92CDD@dcn.davis.CA.us>
	<55C245AE.8030808@fredhutch.org>
	<98A0381D-817F-4883-9889-417B54475ECF@dcn.davis.CA.us>
	<55C256C2.70306@gmail.com>
	<27D92B17-CBB5-4E76-A9A0-E1371A8B13F9@gmail.com>
	<55C27678.8040004@gmail.com>
	<8C2E5099-C8B1-4301-9663-7338958C4DD7@gmail.com>
Message-ID: <A8AB6185-302A-43CB-AB81-94E9DB98B280@gmail.com>


> On 06 Aug 2015, at 18:08 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> Except when it doesn't:  "It is intended to have a final patch release
>> of the previous version shortly before the next major release."
> 
> Argh. Needs fixing... :-p
> 

Done.

(Of course, by the canonical definition of "major", Macintosh hasn't had one for their OS since 2001, so it's all a bit silly.)

-p

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bob at rudis.net  Thu Aug  6 19:08:26 2015
From: bob at rudis.net (boB Rudis)
Date: Thu, 6 Aug 2015 13:08:26 -0400
Subject: [R] Knit R and Book Publishing
In-Reply-To: <CAGxFJbTEEFhwORdf3Eaxjzj1PAQGtwcrmN=kHqenyCqvJJWwSA@mail.gmail.com>
References: <feb0b8d7-f27a-4669-bbd8-b1f69050e1c1@me.com>
	<CAGxFJbTEEFhwORdf3Eaxjzj1PAQGtwcrmN=kHqenyCqvJJWwSA@mail.gmail.com>
Message-ID: <CAJ4QxaMPTiip6vd62rGB7RqM5VEzX2R8HpvyVxaptBCz8hQNsA@mail.gmail.com>

https://github.com/hadley/adv-r is how it was done.

On Thu, Aug 6, 2015 at 8:33 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> I would have thought that the first place to look was R Studio support
> site. You will find a lot of (Imo well done) docs there as well as links to
> Hadley's and Yihui's books and online docs.
>
> Bert
>
> On Wednesday, August 5, 2015, Glenn Schultz <glennmschultz at me.com> wrote:
>
>> Hello All,
>>
>> I have finished my first R package, BondLab, and it will be available in
>> Feb 2016.   I wrote the book and R package concurrently.  Prior, I had very
>> little programming experience other than VBA and using others R packages.
>>
>>
>> http://www.amazon.com/Investing-Mortgage-Backed-Securities-Website/dp/1118944003/ref=sr_1_1?ie=UTF8&qid=1438822386&sr=8-1&keywords=glenn+m+schultz
>>
>> During the learning process I came to know literate programming and
>> reproducible research.  Now,  I have a viable package and I would like
>> re-write the book in R Studio with knitr.  I have had some success with LYX
>> but I think I can do the whole thing in R studio.  The first edition was
>> done in TexMaker.
>>
>> I really want to set the next project up in R Studio, I would really like
>> to open source the next edition like Hadley's recent books but I really
>> don't know how it was all done.  Any starting points to set this up are
>> appreciated.
>>
>> -Glenn
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>    -- Clifford Stoll
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Thu Aug  6 19:17:34 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 6 Aug 2015 13:17:34 -0400
Subject: [R] testing whether two character vectors contain (the same)
	items in the same order
In-Reply-To: <84FC2562-CE0F-4187-A742-02FAB2E98BA4@helsinki.fi>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
	<CAGxFJbRj7Wsas6przfnrtw4uqM-MVU0=HO+kA_28zt8bQ70zUw@mail.gmail.com>
	<84FC2562-CE0F-4187-A742-02FAB2E98BA4@helsinki.fi>
Message-ID: <19927D40-C6F6-495E-9152-28855AE53841@utoronto.ca>

You are looking for what is known as the "Cayley distance" between vectors - an edit distance that allows only transpositions. RSeek mentions PerMallows (https://cran.r-project.org/web/packages/PerMallows/PerMallows.pdf) and Rankluster (https://cran.r-project.org/web/packages/Rankcluster/Rankcluster.pdf) as packages that support work with Cayley distances. It seems to me that distCayley() in Rankcluster does what you want. From the examples:

x=1:5
y=c(2,3,1,4,5)
distCayley(x,y)
8


Cheers,
Boris





On Aug 6, 2015, at 9:51 AM, Federico Calboli <federico.calboli at helsinki.fi> wrote:

>> 
>> On 6 Aug 2015, at 15:40, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> Define "goodness of match" .  For exact matches, see ?"==" , all.equal, etc.
> 
> Fair point.  I would define it as a number that tells me how likely it is that the same (noisy) process produced both lists.
> 
> BW
> 
> F
> 
> 
> 
> 
>> 
>> Bert
>> 
>> On Thursday, August 6, 2015, Federico Calboli <federico.calboli at helsinki.fi> wrote:
>> Hi All,
>> 
>> let?s assume I have a vector of letters drawn only once from the alphabet:
>> 
>> x = sample(letters, 15, replace = F)
>> x
>> [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
>> 
>> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
>> 
>> I would now like to test how good a match y is for x.  Obviously I can transform the letters in numbers and use a rank test, but I was left wondering whether this is the only solution and whether there are more appropriate solutions that are already implemented in R (I am not going to reinvent the wheel if I can avoid it).
>> 
>> BW
>> 
>> F
>> 
>> 
>> --
>> Federico Calboli
>> Ecological Genetics Research Unit
>> Department of Biosciences
>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>> FIN-00014 University of Helsinki
>> Finland
>> 
>> federico.calboli at helsinki.fi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> -- 
>> Bert Gunter
>> 
>> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
>>   -- Clifford Stoll
>> 
> 
> 
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
> 
> federico.calboli at helsinki.fi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Thu Aug  6 22:42:32 2015
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 6 Aug 2015 15:42:32 -0500
Subject: [R] Lattice: raw data and prediction of a non linear fitted
	function
In-Reply-To: <CAOH82u2mJx5C84rJ3Sx9a4AcDma0kprd6=P5aQPAtNFVKzqaEw@mail.gmail.com>
References: <CAOH82u2mJx5C84rJ3Sx9a4AcDma0kprd6=P5aQPAtNFVKzqaEw@mail.gmail.com>
Message-ID: <CAKFxdiShAZbNyODJK5RR556+GY4yy9UjECTsdsop3oOtymkP3g@mail.gmail.com>

I find this type of lattice graph to be much easier to create via the
use of layers in the latticeExtra package.  See the "carmer.density"
dataset example in the "agridat" package, which shows the use of
layers.  It doesn't have "groups", but it is not too hard to add a
groups argument to a layer and then use latticeExtra to combine
layers.

Kevin Wright


On Wed, Aug 5, 2015 at 7:24 AM, Fran?ois Collin <fanch.collin at gmail.com> wrote:
> Dear all,
>
> I have a question about lattice use. I would like to use it to represent:
> - my raw data as points,
> - and the results of a non linear fit as a line,
> - having 2 groups data (and so 2 colors).
>
> However, as I have few raw data, I would like to increase the number of
> points to smooth the line which correspond to the fit.
>
> So my questions are:
> - How can I use the group argument to make new predictions inside panel
> argument ?
> - How can I use this prediction inside the panel argument to draw the fit
> per group?
>
> Hereafter a minimal example:
>
> #==================================================
> library(lattice)
> set.seed(2)
>
> # Dummy dataframe
> foo <- data.frame(
>   time = seq(0, 60, 5),
>   char = sample(c("A", "B"), size = 13, replace = TRUE)
>   );
>
> # Simulated response vector according a Gompertz function + rnorn(0, 5)
> foo$y <- SSgompertz(foo$time, Asym = 100, b2 = ifelse(foo$char == 'A', 6,
> 10),
>   b3 = ifelse(foo$char == "A", .91, .8)) +
>   rnorm(nrow(foo), mean=0, sd = 5);
>
> # Non-linear fit on simulation data
> res_nls <-  nls(
>   y ~ SSgompertz(time, Asym = 100, b2[char], b3[char]), data = foo,
>   start = list( b2 = c(7,7), b3 = c(0.9, 0.9)));
>
> # My problem
> xyplot(y ~ time, groups = char, data = foo,
>   panel = function(x, y, groups=groups, model = model, ...){
>     panel.xyplot(x,y, groups = groups, ...);
>
>     newdata <- data.frame(time = x, char = groups);
>     newdata$y <- predict(model, newdata = newdata);
>
>     panel.superpose(x = newdata$time, y=newdata$y,  groups = groups, ...,
>       panel.groups = function(x,y, col, col.symbol, ...){
>         panel.lines(x,y, col.line = col.symbol)
>       })
>
>   }, model = res_nls);
> #==================================================
>
>
> Many thanks,
> Francois
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Kevin Wright


From bgunter.4567 at gmail.com  Fri Aug  7 00:59:23 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 6 Aug 2015 15:59:23 -0700
Subject: [R] testing whether two character vectors contain (the same)
 items in the same order
In-Reply-To: <19927D40-C6F6-495E-9152-28855AE53841@utoronto.ca>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
	<CAGxFJbRj7Wsas6przfnrtw4uqM-MVU0=HO+kA_28zt8bQ70zUw@mail.gmail.com>
	<84FC2562-CE0F-4187-A742-02FAB2E98BA4@helsinki.fi>
	<19927D40-C6F6-495E-9152-28855AE53841@utoronto.ca>
Message-ID: <CAGxFJbQBwdk7Dbe1fDGHSsZF-5ZkzzhDb_g0VBUJXw2uwTK+yg@mail.gmail.com>

Boris:

You may be right, but it seems like esp to me based on the op's
non-description of likelihood of coming from the same noisy process. My
response would be: seek local statistical help, as your replies indicate a
good deal of statistical confusion.

Cheers,
Bert



On Thursday, August 6, 2015, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> You are looking for what is known as the "Cayley distance" between vectors
> - an edit distance that allows only transpositions. RSeek mentions
> PerMallows (
> https://cran.r-project.org/web/packages/PerMallows/PerMallows.pdf) and
> Rankluster (
> https://cran.r-project.org/web/packages/Rankcluster/Rankcluster.pdf) as
> packages that support work with Cayley distances. It seems to me that
> distCayley() in Rankcluster does what you want. From the examples:
>
> x=1:5
> y=c(2,3,1,4,5)
> distCayley(x,y)
> 8
>
>
> Cheers,
> Boris
>
>
>
>
>
> On Aug 6, 2015, at 9:51 AM, Federico Calboli <federico.calboli at helsinki.fi
> <javascript:;>> wrote:
>
> >>
> >> On 6 Aug 2015, at 15:40, Bert Gunter <bgunter.4567 at gmail.com
> <javascript:;>> wrote:
> >>
> >> Define "goodness of match" .  For exact matches, see ?"==" , all.equal,
> etc.
> >
> > Fair point.  I would define it as a number that tells me how likely it
> is that the same (noisy) process produced both lists.
> >
> > BW
> >
> > F
> >
> >
> >
> >
> >>
> >> Bert
> >>
> >> On Thursday, August 6, 2015, Federico Calboli <
> federico.calboli at helsinki.fi <javascript:;>> wrote:
> >> Hi All,
> >>
> >> let?s assume I have a vector of letters drawn only once from the
> alphabet:
> >>
> >> x = sample(letters, 15, replace = F)
> >> x
> >> [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
> >>
> >> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
> >>
> >> I would now like to test how good a match y is for x.  Obviously I can
> transform the letters in numbers and use a rank test, but I was left
> wondering whether this is the only solution and whether there are more
> appropriate solutions that are already implemented in R (I am not going to
> reinvent the wheel if I can avoid it).
> >>
> >> BW
> >>
> >> F
> >>
> >>
> >> --
> >> Federico Calboli
> >> Ecological Genetics Research Unit
> >> Department of Biosciences
> >> PO Box 65 (Biocenter 3, Viikinkaari 1)
> >> FIN-00014 University of Helsinki
> >> Finland
> >>
> >> federico.calboli at helsinki.fi <javascript:;>
> >>
> >> ______________________________________________
> >> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >> --
> >> Bert Gunter
> >>
> >> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> >>   -- Clifford Stoll
> >>
> >
> >
> > --
> > Federico Calboli
> > Ecological Genetics Research Unit
> > Department of Biosciences
> > PO Box 65 (Biocenter 3, Viikinkaari 1)
> > FIN-00014 University of Helsinki
> > Finland
> >
> > federico.calboli at helsinki.fi <javascript:;>
> >
> > ______________________________________________
> > R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From dmorrison at seventhwave.org  Thu Aug  6 22:01:42 2015
From: dmorrison at seventhwave.org (Drew Morrison)
Date: Thu, 6 Aug 2015 13:01:42 -0700 (PDT)
Subject: [R] Piecewise (segmented) linear regression with center section
 slope constraint
Message-ID: <1438891302345-4710839.post@n4.nabble.com>

Hi,

I'm working on a way to predict the electricity consumption of electrically
heated buildings as a function of outdoor air temperature. I've identified a
three-segment linear model as a candidate for a good fit, with the slope of
the center section constrained to zero. I'm working with the segmented
package. I've searched some of the other posts on this forum and they've
been very helpful, but they don't address my big sticking point: how do I
constrain the slope of the center section of the model to 0, rather than the
left or right section?

Below is a script with simulated data and my first attempt at fitting the
model. You should be able to copy, paste, and run it. Thanks in advance.
Drew

# three-piece segmented regression
# center section constrained to slope of 0.


# simulate and plot data
T<- 1:100
energy<- 100+75*pmax(55-T,0)+25*pmax(T-70,0)+150*rnorm(50)
plot(T, energy)

# create a linear model
model <- lm(energy~T)
#print(summary(model))

# start segmented regression
library(segmented)
seg_model <- segmented(model, seg.Z = ~ T, psi = list(T = c(52, 71)))
print(summary(seg_model))
print(seg_model$psi)
print(slope(seg_model))

# plot regression lines
fitted_energy <- fitted(seg_model)
regression_model <- data.frame(Temperature = T, kWh = fitted_energy)
lines(x = T, y = fitted_energy, col = 1)

# try constrained regression
TT<- -T   # change signs of independent variable
model <- lm(energy~1)  # constrain slope
seg_model <- segmented(model, seg.Z = ~ TT, psi = list(TT = c(-71, -52)))
print(summary(seg_model))
print(seg_model$psi)
print(slope(seg_model))

# plot constrained regression 
fitted_energy <- fitted(seg_model)
regression_model <- data.frame(Temperature = T, kWh = fitted_energy)
lines(x = T, y = fitted_energy, col = 2)



--
View this message in context: http://r.789695.n4.nabble.com/Piecewise-segmented-linear-regression-with-center-section-slope-constraint-tp4710839.html
Sent from the R help mailing list archive at Nabble.com.


From sophie.ouillade at orange.fr  Thu Aug  6 11:06:03 2015
From: sophie.ouillade at orange.fr (SophieO)
Date: Thu, 6 Aug 2015 02:06:03 -0700 (PDT)
Subject: [R] APARCH models
Message-ID: <1438851963743-4710819.post@n4.nabble.com>

Dear all,

I need to estimate the coefficients of an APARCH that fits some dataset.
I have found to functions : 
* garchFit(formula=~aparch(1,1),...) from the fGarch package
* GSgarch.FitAIC(mMAX = 0, nMAX = 0, pMAX = 1, qMAX = 1, ...) from the
GEVStableGarch package

The problem is that they gave me different coefficients for the same
dataset. 
Does anyone know the difference between the two and which one should I use ?

Thanks in advance for your answer

Sophie O.

 




--
View this message in context: http://r.789695.n4.nabble.com/APARCH-models-tp4710819.html
Sent from the R help mailing list archive at Nabble.com.


From fanch.collin at gmail.com  Thu Aug  6 12:34:10 2015
From: fanch.collin at gmail.com (=?UTF-8?Q?Fran=C3=A7ois_Collin?=)
Date: Thu, 6 Aug 2015 10:34:10 +0000
Subject: [R] Lattice: raw data and prediction of a non linear fitted
	function
In-Reply-To: <000c01d0cfff$b5290980$1f7b1c80$@bigpond.com>
References: <CAOH82u2mJx5C84rJ3Sx9a4AcDma0kprd6=P5aQPAtNFVKzqaEw@mail.gmail.com>
	<000c01d0cfff$b5290980$1f7b1c80$@bigpond.com>
Message-ID: <CAOH82u1fr0FKS5eeVAAsXdRj==8PTG5hrDk9xcHfiv7fgJ6AMg@mail.gmail.com>

Hi,

Thank you for your answer. However, I think you misunderstood my problem.
The data and fit I provided are just here to illustrate 2 points:
- I have few raw data
- and a fitted model I want to represent.

It is a simulated dataset, no more, which match to my requirement: a non
linear response, which 2 unknown parameters b2 and b3 (?SSgompertz) have
values according to their group (char = { A, B }). The fit I proposed take
this into account as my formula is:
y ~ SSgompertz(time, Asym = 100, b2[char], b3[char]).

So I do not think two equations are relevant (or is out of the bounds of my
problem). But again, the quality of the fit is not my concern up to this
point, these are just required to illustrate my problem.

My question is about graphical representation using lattice. I look for the
efficient way to represent: my raw data and a curve which represents my
fitted function for two groups. But, as I want a curve, I have to increase
the number of points for the prediction to obtain a smooth representation.
The second part of your answer is more relevant for me:

================
xyplot(y ~ time, data = foo,
       groups = char,
       panel = panel.superpose,
       panel.groups = function(x, y, ...,group.number){
                 panel.xyplot(x,y, ...);
                 xy.nls <-
                 nls(y ~ SSgompertz(x, Asym = 100, b2, b3),
                     start = list( b2 =7, b3 =  0.9))

                 #print(summary(xy.nls))
                 if (group.number == 1){
                   xy.pre <- predict(xy.nls, newdata = list(time =
seq(0,55,5)))
                   print(xy.pre)
                   llines( seq(5,60,5), xy.pre, col = "blue")
                 } else {
                   xy.pre <- predict(xy.nls, newdata = list(time =
seq(5,60,5)))
                   print(xy.pre)
                   llines( seq(5,60,5), xy.pre, col = "magenta")
                 }

       })
==============

However, I tried it, and the results is very weird: instead of having a
smoother representation, I get a repetition of the initial pattern which
looks periodic, and draw according the number of points of the predict but
not using the predicted y.

Thus my problem is still unsolved:
- How can I use the group argument inside xyplot to make new predictions
inside panel
argument ?
- How can I use this prediction inside the panel argument to draw the fit
per group ?
- My constraints: on the same graph I want my raw data and my predictions
which have not the same dimensions.

# My initial problem
xyplot(y ~ time, groups = char, data = foo,
  panel = function(x, y, groups=groups, model = model, ...){
    panel.xyplot(x,y, groups = groups, ...);

    newdata <- data.frame(time = x, char = groups);
    newdata$y <- predict(model, newdata = newdata);

    # Here is an approximation of my results, which are good, except that
    # I would like to increase the number of points for the curves
representation
    # to obtain smooth representation.
    panel.superpose(x = newdata$time, y=newdata$y,  groups = groups, ...,
      panel.groups = function(x,y, col, col.symbol, ...){
        panel.lines(x,y, col.line = col.symbol)
      })

  }, model = res_nls);
#=============================

Many thanks,
Francois


2015-08-06 4:23 GMT+00:00 Duncan Mackay <dulcalma at bigpond.com>:

> Sending again as I pressed the wrong button
>
> Hi
>
> Your model is overfitted for the number of points - the fitted values bear
> no resemblance to a line fitting the data - ?too many x values to properly
> predict
> ? splines etc
>  library(locfit)
> ?locfit
> If you want coefs of sort.
>
> You have to do a nls on each group to get the values.
> You have 2 ways to do this
> 1 do nls and predict y values separately as below an plot them in a panel
> function
> 2 do nls and predict within the panel function
>
> > res_nlsA <-
> + nls(y ~ SSgompertz(time, Asym = 100, b2, b3), data = subset(foo, char ==
> "A"),
> +     start = list( b2 = c(7,7), b3 = c(0.9, 0.9)))
> There were 50 or more warnings (use warnings() to see the first 50)
> > res_nlsA
> Nonlinear regression model
>   model: y ~ SSgompertz(time, Asym = 100, b2, b3)
>    data: subset(foo, char == "A")
>    b21    b22    b31    b32
> 4.6761 7.6280 0.9111 0.9000
>  residual sum-of-squares: 10.59
>
> Number of iterations to convergence: 32
> Achieved convergence tolerance: 8.001e-06
> > res_nlsB <-
> + nls(y ~ SSgompertz(time, Asym = 100, b2, b3), data = subset(foo, char ==
> "B"),
> +     start = list( b2 = c(7,7), b3 = c(0.9, 0.9)))
> > res_nlsB
> Nonlinear regression model
>   model: y ~ SSgompertz(time, Asym = 100, b2, b3)
>    data: subset(foo, char == "B")
>     b21     b22     b31     b32
>  9.5231 86.6421  0.8164  0.6582
>  residual sum-of-squares: 36.26
>
> Number of iterations to convergence: 10
> Achieved convergence tolerance: 1.37e-06
> >
> > predict(res_nlsB, newdata = list(time = seq(5,60,2.5)))
>  [1]   3.162527   2.321040  28.575719  62.814774  63.489626  94.416582
> 84.809570  99.292612  94.199502  99.912322  97.856129  99.989162  99.217093
> 99.998661  99.715346
> [16]  99.999835  99.896669  99.999980  99.962512  99.999997  99.986402
> 100.000000  99.995068
> Warning messages:
> 1: In b3^x :
>   longer object length is not a multiple of shorter object length
> 2: In -b2 * .expr2 :
>   longer object length is not a multiple of shorter object length
> > predict(res_nlsB, newdata = list(time = seq(5,60,5)))
>  [1]   3.162527  26.638924  63.489626  98.000694  94.199502  99.969171
> 99.217093  99.999529  99.896669  99.999993  99.986402 100.000000
> > predict(res_nlsA, newdata = list(time = seq(0,55,5)))
>  [1]  0.9314904  1.1062577 15.8281748 20.7951276 48.3512870 57.8358643
> 75.0914782 82.6202586 89.3216331 93.5601696 95.6459638 97.7058236
>
> xyplot(y ~ time, data = foo,
>        groups = char,
>        panel = panel.superpose,
>        panel.groups = function(x, y, ...,group.number){
>
>                  panel.xyplot(x,y, ...);
>
>                  xy.nls <-
>                  nls(y ~ SSgompertz(x, Asym = 100, b2, b3),
>                      start = list( b2 =7, b3 =  0.9))
>
>                  #print(summary(xy.nls))
>
>                  if (group.number == 1){
>                    xy.pre <- predict(xy.nls, newdata = list(time =
> seq(0,55,5)))
>                    print(xy.pre)
>                    llines( seq(5,60,5), xy.pre, col = "blue")
>                  } else {
>                    xy.pre <- predict(xy.nls, newdata = list(time =
> seq(5,60,5)))
>                    print(xy.pre)
>                    llines( seq(5,60,5), xy.pre, col = "magenta")
>                  }
>
>        })
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fran?ois
> Collin
> Sent: Wednesday, 5 August 2015 22:24
> To: r-help at r-project.org
> Subject: [R] Lattice: raw data and prediction of a non linear fitted
> function
>
> Dear all,
>
> I have a question about lattice use. I would like to use it to represent:
> - my raw data as points,
> - and the results of a non linear fit as a line,
> - having 2 groups data (and so 2 colors).
>
> However, as I have few raw data, I would like to increase the number of
> points to smooth the line which correspond to the fit.
>
> So my questions are:
> - How can I use the group argument to make new predictions inside panel
> argument ?
> - How can I use this prediction inside the panel argument to draw the fit
> per group?
>
> Hereafter a minimal example:
>
> #==================================================
> library(lattice)
> set.seed(2)
>
> # Dummy dataframe
> foo <- data.frame(
>   time = seq(0, 60, 5),
>   char = sample(c("A", "B"), size = 13, replace = TRUE)
>   );
>
> # Simulated response vector according a Gompertz function + rnorn(0, 5)
> foo$y <- SSgompertz(foo$time, Asym = 100, b2 = ifelse(foo$char == 'A', 6,
> 10),
>   b3 = ifelse(foo$char == "A", .91, .8)) +
>   rnorm(nrow(foo), mean=0, sd = 5);
>
> # Non-linear fit on simulation data
> res_nls <-  nls(
>   y ~ SSgompertz(time, Asym = 100, b2[char], b3[char]), data = foo,
>   start = list( b2 = c(7,7), b3 = c(0.9, 0.9)));
>
> # My problem
> xyplot(y ~ time, groups = char, data = foo,
>   panel = function(x, y, groups=groups, model = model, ...){
>     panel.xyplot(x,y, groups = groups, ...);
>
>     newdata <- data.frame(time = x, char = groups);
>     newdata$y <- predict(model, newdata = newdata);
>
>     panel.superpose(x = newdata$time, y=newdata$y,  groups = groups, ...,
>       panel.groups = function(x,y, col, col.symbol, ...){
>         panel.lines(x,y, col.line = col.symbol)
>       })
>
>   }, model = res_nls);
> #==================================================
>
>
> Many thanks,
> Francois
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From hsansegundo at meteo.cat  Thu Aug  6 13:59:14 2015
From: hsansegundo at meteo.cat (hs)
Date: Thu, 6 Aug 2015 04:59:14 -0700 (PDT)
Subject: [R] adding a node in an existing xml file
Message-ID: <1438862354538-4710824.post@n4.nabble.com>

I have an xml file like this:
<?xml version="1.0" encoding="utf-8" ?>
<kml xmlns="http://www.opengis.net/kml/2.2">
<Document id="root_doc">
<Schema name="sql_statement" id="sql_statement">
	<SimpleField name="Name" type="string"></SimpleField>
	<SimpleField name="Description" type="string"></SimpleField>
</Schema>

<Folder>
  <name>sql_statement</name>
  <Placemark>
	<name>2013/11/16 00:02:16</name>
	<description>2013/11/16 00:02:16</description>
	<ExtendedData><SchemaData schemaUrl="#sql_statement">
		<SimpleData name="value1l">70.3</SimpleData>
		<SimpleData name="value2">65562</SimpleData>
	</SchemaData></ExtendedData>
     
<Point><coordinates>3.611564270451177,39.118047789677419</coordinates></Point>
  </Placemark>
 
</Folder>
</Document>
</kml>


I'm able to read the xml file with the xml package and navigate into the tag
values.

d = xmlParse("testkml.kml")
xmlfile<-d
xmltop = xmlRoot(xmlfile) #gives content of root
vxmlName<-xmlName(xmltop) #give name of nodt
vxmlNametop1<-xmlName(xmltop[[1]])         #<Document>
vxmlNametop11<-xmlName(xmltop[[1]][[1]]) #<Schema>
vxmlNametop12<-xmlName(xmltop[[1]][[2]]) #<Folder>


I need to create childs (

<Folder>
  <name>sql_statement</name>
  <Placemark>
	<name>2013/11/16 00:02:16</name>
	<description>2013/11/16 00:02:16</description>
	<ExtendedData><SchemaData schemaUrl="#sql_statement">
		<SimpleData name="value1l">70.3</SimpleData>
		<SimpleData name="value2">65562</SimpleData>
	</SchemaData></ExtendedData>
     
<Point><coordinates>3.611564270451177,39.118047789677419</coordinates></Point>
  </Placemark>
 
</Folder>
</Document>
</kml>

somebody can help me how to do it?
Thanks



--
View this message in context: http://r.789695.n4.nabble.com/adding-a-node-in-an-existing-xml-file-tp4710824.html
Sent from the R help mailing list archive at Nabble.com.


From sebp at k-d-w.org  Thu Aug  6 15:44:38 2015
From: sebp at k-d-w.org (=?UTF-8?Q?Sebastian_P=c3=b6lsterl?=)
Date: Thu, 6 Aug 2015 15:44:38 +0200
Subject: [R] Problem with survfit when model has interaction with strata
Message-ID: <55C364C6.8060900@k-d-w.org>

Dear all,

I encountered a problem when running survfit using a coxph model that 
contains an interaction with a strata variable (see the attached 
example). I hope this is the right place to report problems.

 > source("~/survfit-example.R")
Error in scale.default(x2, center = xcenter, scale = FALSE) :
   length of 'center' must equal the number of columns of 'x'

 > traceback()
9: stop("length of 'center' must equal the number of columns of 'x'")
8: scale.default(x2, center = xcenter, scale = FALSE)
7: scale(x2, center = xcenter, scale = FALSE)
6: survfit.coxph(fit, newdata = newd)
5: survfit(fit, newdata = newd) at survfit-example.R#10
4: eval(expr, envir, enclos)
3: eval(ei, envir)
2: withVisible(eval(ei, envir))
1: source("~/survfit-example.R")

 > sessionInfo()
R version 3.2.1 (2015-06-18)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: Fedora 22 (Twenty Two)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] survival_2.38-3 foreign_0.8-65

loaded via a namespace (and not attached):
[1] tools_3.2.1   splines_3.2.1


I believe the problem is occurring on line 263 of survfit.coxph.R, where 
a model.matrix from newdata is created. The values passed to scale look 
like:

 > x2
   RXplacebo RXtreatment:strata(SEX)male RXplacebo:strata(SEX)male
1         0                           1                         0
2         0                           0                         0

 > xcenter
                 RXplacebo strata(SEX)male:RXplacebo
                 0.5000000                 0.2380952


Clearly, model.matrix is adding an additional (redundant) column that 
was omitted when fitting the original model. Since interactions with 
strata variables are a special cases in coxph, I believe similar care 
should be taken when creating the model matrix for newdata.

Best regards,
Sebastian P?lsterl

-------------- next part --------------
library(foreign)
library(survival)
data <- data.frame(read.spss("http://web1.sph.emory.edu/dkleinb/allDatasets/surv2datasets/anderson.sav"))

S <- with(data, Surv(SURVT, I(STATUS == "relapse")))
fit <- coxph(S ~ strata(SEX)*RX, data=data)
newd <- data.frame(RX=c("treatment", "treatment"), SEX=c("male", "female"))
sfit <- survfit(fit, newdata=newd)

From karraspito at yahoo.es  Thu Aug  6 19:20:52 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Thu, 6 Aug 2015 17:20:52 +0000 (UTC)
Subject: [R] Potencial bug in R.adjust ("holm" method)
Message-ID: <704470060.364467.1438881652976.JavaMail.yahoo@mail.yahoo.com>

?? Hello all,
?? I am doing some Bonferroni correction analyses with R.adjust function. I have a spreadsheet with 24 columns, each with 5 values. When I use the "holm" method, it gives me adjusted figures for all the original values except from the ones in the 4th row of each column. I mean, the value on the 4th row for every column is exactly the same either in the original data or in the corrected one.?? I've tried using another algorithm just to see what happens ("bonferroni", for example) and everything is fine, I get corrected figures for all the values, even the ones on the 4th row.

?? Does anyone know whether this is any kind of known bug of the "holm" algorithm of P.adjust function. If so, should I worry about it? If so, can anybody suggest any possible solution?
?? Thank you very much.
?? Iker


__________________________________________________________________

?? Dr. Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations,?
?? School of Life Sciences, University of Lincoln,??? Riseholme Park Campus, Lincoln
?? LN2 2LG,
?? UK.

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


	[[alternative HTML version deleted]]


From klerer at sxmail.de  Thu Aug  6 23:31:58 2015
From: klerer at sxmail.de (klerer at sxmail.de)
Date: Thu, 6 Aug 2015 23:31:58 +0200
Subject: [R] function ndq()
Message-ID: <e12f5d1401aeb2ced7d195fc8909ee53@www.sxmail.de>

Hello everyone!I had to notice that it is better to be curious about packages and functions contained therein, as I (yet new to R) recognised that there is a number of 'convenient' R packages simplifying and possibilitating a lot. At the moment, I have 'retrofitted' (install packages not delivered with R's basic version) my R version (3.0.2); that number of packages already turned out to be more than helpful.Though, I have one problem lingering: It concerns a function that according to literature (Cohen & Cohen, ISBN-13 978-0-470-75805-2, 2008) is called "nqd()" and, as that reference put it, would enable the R user to print data (when working with matrices) without quotes and dimension names on the R console.I have but had difficulties getting to know to which package function "nqd()" belongs and would like to ask the R help community which package that was.Thanks a lot in advance yet!Best regards,Markus


	[[alternative HTML version deleted]]


From andymac at xtra.co.nz  Fri Aug  7 02:50:05 2015
From: andymac at xtra.co.nz (andymac)
Date: Thu, 6 Aug 2015 17:50:05 -0700 (PDT)
Subject: [R] R error
In-Reply-To: <AD29844AFE86BF46B27E9FCD752022C821AB0430@EMBX-CHAM2.cdc.gov>
References: <AD29844AFE86BF46B27E9FCD752022C821AB0430@EMBX-CHAM2.cdc.gov>
Message-ID: <1438908605259-4710847.post@n4.nabble.com>

Hi,

I had a similar problem running the 32-bit version of 3.2.0 on Windows 8.1.
For me the problem was user permissions. I re-ran the R program as an
administrator rather than a user and it now installs packages just fine. 

Cheers,
Andy




--
View this message in context: http://r.789695.n4.nabble.com/R-error-tp4710696p4710847.html
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Fri Aug  7 08:05:34 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 7 Aug 2015 08:05:34 +0200
Subject: [R] function ndq()
In-Reply-To: <e12f5d1401aeb2ced7d195fc8909ee53@www.sxmail.de>
References: <e12f5d1401aeb2ced7d195fc8909ee53@www.sxmail.de>
Message-ID: <55C44AAE.4080808@statistik.tu-dortmund.de>

Use an internet search engine.
The one I used told me that the book "Statistics and Data with R: An 
Applied Approach Through Examples" by Yosef Cohen, Jeremiah Y. Cohen 
contains a function definition of nqd in section 1.11.4.

Best,
Uwe Ligges




On 06.08.2015 23:31, klerer at sxmail.de wrote:
> Hello everyone!I had to notice that it is better to be curious about packages and functions contained therein, as I (yet new to R) recognised that there is a number of 'convenient' R packages simplifying and possibilitating a lot. At the moment, I have 'retrofitted' (install packages not delivered with R's basic version) my R version (3.0.2); that number of packages already turned out to be more than helpful.Though, I have one problem lingering: It concerns a function that according to literature (Cohen & Cohen, ISBN-13 978-0-470-75805-2, 2008) is called "nqd()" and, as that reference put it, would enable the R user to print data (when working with matrices) without quotes and dimension names on the R console.I have but had difficulties getting to know to which package function "nqd()" belongs and would like to ask the R help community which package that was.Thanks a lot in advance yet!Best regards,Markus
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From luysgarcia at gmail.com  Fri Aug  7 08:54:26 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Fri, 7 Aug 2015 03:54:26 -0300
Subject: [R] help plotting glmm values
Message-ID: <CANxP2S5ZgcPSUfGcgsFR0ht4TmpkauOqMOeOBtT35e17Zy0fxw@mail.gmail.com>

Dear Fellows,

I?m sorry if my question is very basic, but I'm still new in the field of R
and the GLMM.

I have made a following glmm, and I need to plot the predicted mean values
from the model and the CI, with this barplot +/- the CI, using the prey as
explanatory factor.

 Although I have been looking for it, I have not found a website which show
the way to do this, so  I'm unsure about the right procedure. If any of you
could help me with the correct procedure I would really apprreciate it!

Sorry for attaching the dataset, but it is too long.

##GLMM

Lac=read.table("loxoacc10.txt",header=T)
library(lme4)
glmm1 <- glmer(Acc ~ Prey + (1 | Sp), family=binomial)
summary(glmm1)
overdisp_fun <- function(model) {
  ## number of variance parameters in
  ##   an n-by-n variance-covariance matrix
  vpars <- function(m) {
    nrow(m)*(nrow(m)+1)/2
  }
overdisp_fun(glmm1)#Check for overdispersal
-------------- next part --------------
Sp	Acc	Prey
1	1	hormiga
1	1	termita
1	1	larva
1	0	cochinilla
2	0	hormiga
2	1	termita
2	0	larva
2	0	cochinilla
3	0	hormiga
3	1	termita
3	1	larva
3	1	cochinilla
4	1	hormiga
4	0	termita
4	0	larva
4	1	cochinilla
5	1	hormiga
5	0	termita
5	1	larva
5	0	cochinilla
6	1	hormiga
6	1	termita
6	1	larva
6	0	cochinilla
7	1	hormiga
7	1	termita
7	1	larva
7	1	cochinilla
8	1	hormiga
8	1	termita
8	1	larva
8	1	cochinilla
9	1	hormiga
9	1	termita
9	1	larva
9	0	cochinilla
10	1	hormiga
10	1	termita
10	0	larva
10	1	cochinilla
11	1	hormiga
11	1	termita
11	1	larva
11	0	cochinilla
12	1	hormiga
12	1	termita
12	1	larva
12	1	cochinilla
13	1	hormiga
13	1	termita
13	1	larva
13	1	cochinilla
14	1	hormiga
14	1	termita
14	1	larva
14	0	cochinilla
15	1	hormiga
15	1	termita
15	1	larva
15	0	cochinilla
16	1	hormiga
16	1	termita
16	1	larva
16	0	cochinilla
17	1	hormiga
17	0	termita
17	1	larva
17	0	cochinilla
18	1	hormiga
18	1	termita
18	1	larva
18	1	cochinilla
19	0	hormiga
19	1	termita
19	1	larva
19	0	cochinilla
20	0	hormiga
20	1	termita
20	1	larva
20	1	cochinilla

From federico.calboli at helsinki.fi  Fri Aug  7 09:22:23 2015
From: federico.calboli at helsinki.fi (Federico Calboli)
Date: Fri, 7 Aug 2015 10:22:23 +0300
Subject: [R] testing whether two character vectors contain (the same)
	items in the same order
In-Reply-To: <CAGxFJbQBwdk7Dbe1fDGHSsZF-5ZkzzhDb_g0VBUJXw2uwTK+yg@mail.gmail.com>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
	<CAGxFJbRj7Wsas6przfnrtw4uqM-MVU0=HO+kA_28zt8bQ70zUw@mail.gmail.com>
	<84FC2562-CE0F-4187-A742-02FAB2E98BA4@helsinki.fi>
	<19927D40-C6F6-495E-9152-28855AE53841@utoronto.ca>
	<CAGxFJbQBwdk7Dbe1fDGHSsZF-5ZkzzhDb_g0VBUJXw2uwTK+yg@mail.gmail.com>
Message-ID: <8CDF735C-3BE1-4E93-AA1F-ACDEC2C18E13@helsinki.fi>


> On 7 Aug 2015, at 01:59, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Boris:
> 
> You may be right, but it seems like esp to me based on the op's non-description of likelihood of coming from the same noisy process. My response would be: seek local statistical help, as your replies indicate a good deal of statistical confusion.
> 
> Cheers,
> Bert

Bert,

as this is R-help and not cross-validated I am looking for a precanned function that would test whether the order of characters in two character vectors comes from the same (noisy) process.  I would thus expect you to say something on the lines of:

function X uses method Y to do something like that
function W uses method Z to do something like that
?

look into those, figure out exactly what you are testing and use the most appropiate function.  

The whys and wherefores are for me to deal with, I just want to know whether someone has built a function that does, or seems to do, what I asked for.  As I said, this is R-help, and I seek help for R use.

I do concede that my original question might have left many wondering, but I guess my reply to Boris would have cleared any doubts.  I am therefore puzzled by the great deal of confusion on your part in understanding the purpose of my question and, in general, of this list.

Best wishes

F


> 
> 
> 
> On Thursday, August 6, 2015, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> You are looking for what is known as the "Cayley distance" between vectors - an edit distance that allows only transpositions. RSeek mentions PerMallows (https://cran.r-project.org/web/packages/PerMallows/PerMallows.pdf) and Rankluster (https://cran.r-project.org/web/packages/Rankcluster/Rankcluster.pdf) as packages that support work with Cayley distances. It seems to me that distCayley() in Rankcluster does what you want. From the examples:
> 
> x=1:5
> y=c(2,3,1,4,5)
> distCayley(x,y)
> 8
> 
> 
> Cheers,
> Boris
> 
> 
> 
> 
> 
> On Aug 6, 2015, at 9:51 AM, Federico Calboli <federico.calboli at helsinki.fi> wrote:
> 
> >>
> >> On 6 Aug 2015, at 15:40, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >>
> >> Define "goodness of match" .  For exact matches, see ?"==" , all.equal, etc.
> >
> > Fair point.  I would define it as a number that tells me how likely it is that the same (noisy) process produced both lists.
> >
> > BW
> >
> > F
> >
> >
> >
> >
> >>
> >> Bert
> >>
> >> On Thursday, August 6, 2015, Federico Calboli <federico.calboli at helsinki.fi> wrote:
> >> Hi All,
> >>
> >> let?s assume I have a vector of letters drawn only once from the alphabet:
> >>
> >> x = sample(letters, 15, replace = F)
> >> x
> >> [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
> >>
> >> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
> >>
> >> I would now like to test how good a match y is for x.  Obviously I can transform the letters in numbers and use a rank test, but I was left wondering whether this is the only solution and whether there are more appropriate solutions that are already implemented in R (I am not going to reinvent the wheel if I can avoid it).
> >>
> >> BW
> >>
> >> F
> >>
> >>
> >> --
> >> Federico Calboli
> >> Ecological Genetics Research Unit
> >> Department of Biosciences
> >> PO Box 65 (Biocenter 3, Viikinkaari 1)
> >> FIN-00014 University of Helsinki
> >> Finland
> >>
> >> federico.calboli at helsinki.fi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >> --
> >> Bert Gunter
> >>
> >> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
> >>   -- Clifford Stoll
> >>
> >
> >
> > --
> > Federico Calboli
> > Ecological Genetics Research Unit
> > Department of Biosciences
> > PO Box 65 (Biocenter 3, Viikinkaari 1)
> > FIN-00014 University of Helsinki
> > Finland
> >
> > federico.calboli at helsinki.fi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> -- 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
>    -- Clifford Stoll
> 


--
Federico Calboli
Ecological Genetics Research Unit
Department of Biosciences
PO Box 65 (Biocenter 3, Viikinkaari 1)
FIN-00014 University of Helsinki
Finland

federico.calboli at helsinki.fi


From ligges at statistik.tu-dortmund.de  Fri Aug  7 10:08:08 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 7 Aug 2015 10:08:08 +0200
Subject: [R] Potencial bug in R.adjust ("holm" method)
In-Reply-To: <704470060.364467.1438881652976.JavaMail.yahoo@mail.yahoo.com>
References: <704470060.364467.1438881652976.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55C46768.30105@statistik.tu-dortmund.de>

Please send a reproducible example.

Best,
Uwe Ligges


On 06.08.2015 19:20, Iker Vaquero Alba wrote:
>     Hello all,
>     I am doing some Bonferroni correction analyses with R.adjust function. I have a spreadsheet with 24 columns, each with 5 values. When I use the "holm" method, it gives me adjusted figures for all the original values except from the ones in the 4th row of each column. I mean, the value on the 4th row for every column is exactly the same either in the original data or in the corrected one.   I've tried using another algorithm just to see what happens ("bonferroni", for example) and everything is fine, I get corrected figures for all the values, even the ones on the 4th row.
>
>     Does anyone know whether this is any kind of known bug of the "holm" algorithm of P.adjust function. If so, should I worry about it? If so, can anybody suggest any possible solution?
>     Thank you very much.
>     Iker
>
>
> __________________________________________________________________
>
>     Dr. Iker Vaquero-Alba
>     Visiting Postdoctoral Research Associate
>     Laboratory of Evolutionary Ecology of Adaptations,
>     School of Life Sciences, University of Lincoln,    Riseholme Park Campus, Lincoln
>     LN2 2LG,
>     UK.
>
>     https://eric.exeter.ac.uk/repository/handle/10036/3381
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jvadams at usgs.gov  Fri Aug  7 14:54:48 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 7 Aug 2015 07:54:48 -0500
Subject: [R] Piecewise (segmented) linear regression with center section
 slope constraint
In-Reply-To: <1438891302345-4710839.post@n4.nabble.com>
References: <1438891302345-4710839.post@n4.nabble.com>
Message-ID: <CAN5YmCHaram3mr+n4tmbgfmKRq7sPxQ9QH6RRTfKxy+dQ4Ttgw@mail.gmail.com>

This posting on StackOverflow might be useful to you.
http://stackoverflow.com/questions/13810607/in-r-package-segmented-how-could-i-set-the-slope-of-one-of-lines-in-the-model

Jean

On Thu, Aug 6, 2015 at 3:01 PM, Drew Morrison <dmorrison at seventhwave.org>
wrote:

> Hi,
>
> I'm working on a way to predict the electricity consumption of electrically
> heated buildings as a function of outdoor air temperature. I've identified
> a
> three-segment linear model as a candidate for a good fit, with the slope of
> the center section constrained to zero. I'm working with the segmented
> package. I've searched some of the other posts on this forum and they've
> been very helpful, but they don't address my big sticking point: how do I
> constrain the slope of the center section of the model to 0, rather than
> the
> left or right section?
>
> Below is a script with simulated data and my first attempt at fitting the
> model. You should be able to copy, paste, and run it. Thanks in advance.
> Drew
>
> # three-piece segmented regression
> # center section constrained to slope of 0.
>
>
> # simulate and plot data
> T<- 1:100
> energy<- 100+75*pmax(55-T,0)+25*pmax(T-70,0)+150*rnorm(50)
> plot(T, energy)
>
> # create a linear model
> model <- lm(energy~T)
> #print(summary(model))
>
> # start segmented regression
> library(segmented)
> seg_model <- segmented(model, seg.Z = ~ T, psi = list(T = c(52, 71)))
> print(summary(seg_model))
> print(seg_model$psi)
> print(slope(seg_model))
>
> # plot regression lines
> fitted_energy <- fitted(seg_model)
> regression_model <- data.frame(Temperature = T, kWh = fitted_energy)
> lines(x = T, y = fitted_energy, col = 1)
>
> # try constrained regression
> TT<- -T   # change signs of independent variable
> model <- lm(energy~1)  # constrain slope
> seg_model <- segmented(model, seg.Z = ~ TT, psi = list(TT = c(-71, -52)))
> print(summary(seg_model))
> print(seg_model$psi)
> print(slope(seg_model))
>
> # plot constrained regression
> fitted_energy <- fitted(seg_model)
> regression_model <- data.frame(Temperature = T, kWh = fitted_energy)
> lines(x = T, y = fitted_energy, col = 2)
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Piecewise-segmented-linear-regression-with-center-section-slope-constraint-tp4710839.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Aug  7 15:40:27 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 7 Aug 2015 15:40:27 +0200
Subject: [R] Potencial bug in R.adjust ("holm" method)
In-Reply-To: <704470060.364467.1438881652976.JavaMail.yahoo@mail.yahoo.com>
References: <704470060.364467.1438881652976.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <9950EFAD-23BB-444D-8095-33A721BC6F28@gmail.com>


On 06 Aug 2015, at 19:20 , Iker Vaquero Alba <karraspito at yahoo.es> wrote:

>    Hello all,
>    I am doing some Bonferroni correction analyses with R.adjust function. I have a spreadsheet with 24 columns, each with 5 values. When I use the "holm" method, it gives me adjusted figures for all the original values except from the ones in the 4th row of each column. I mean, the value on the 4th row for every column is exactly the same either in the original data or in the corrected one.   I've tried using another algorithm just to see what happens ("bonferroni", for example) and everything is fine, I get corrected figures for all the values, even the ones on the 4th row.
> 
>    Does anyone know whether this is any kind of known bug of the "holm" algorithm of P.adjust function. If so, should I worry about it? If so, can anybody suggest any possible solution?
>    Thank you very much.
>    Iker

p.adjust(), I presume?

The Holm procedure is essentially to sort p-values in decreasing order and mutiplying by 1:n plus a little fiddling to keep the order and prevent p > 1. The logic is that if you reject the hypothesis corresponding to the smallest p after Bonferroni-correction by N, you only have N-1 simultaneous tests to consider, etc. The smallest multiplier will be 1, so it's not strange that one value appears uncorrected. It's curious that it is always in the 4th row, but it might be that the p-values in the 4 other rows are all considerably smaller.

You do realize that if you run p.adjust for each column, you are not actually adjusting for the total of 120 tests, only for 5 of them, effectively ignoring the 23 other columns every time?

-pd

> 
> 
> __________________________________________________________________
> 
>    Dr. Iker Vaquero-Alba
>    Visiting Postdoctoral Research Associate
>    Laboratory of Evolutionary Ecology of Adaptations, 
>    School of Life Sciences, University of Lincoln,    Riseholme Park Campus, Lincoln
>    LN2 2LG,
>    UK.
> 
>    https://eric.exeter.ac.uk/repository/handle/10036/3381
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From karraspito at yahoo.es  Fri Aug  7 16:20:08 2015
From: karraspito at yahoo.es (Iker Vaquero Alba)
Date: Fri, 7 Aug 2015 14:20:08 +0000 (UTC)
Subject: [R] Potencial bug in R.adjust ("holm" method)
In-Reply-To: <9950EFAD-23BB-444D-8095-33A721BC6F28@gmail.com>
References: <9950EFAD-23BB-444D-8095-33A721BC6F28@gmail.com>
Message-ID: <270025218.863338.1438957208627.JavaMail.yahoo@mail.yahoo.com>



?? Hello, Peter, and thank you for your clarifying reply. Actually, that was another doubt I had. As I take my data from different files (every "bunch of 5" values is taken from a different file), I assumed that, if I wanted to adjust for the error due to repeated measures, it should be enough to do it inside each file, right? I mean, the possible error due to repeated measures shouldn't go beyond each file. Once you close one file, open and attach a new one, the count, let's say, starts from scratch. 
Am I right? And if I'm not, what is the reason why should I pool all the p-values in a massive column and adjust them in bulk?
?? Thank you very much for your help.?? Iker?__________________________________________________________________

?? Dr. Iker Vaquero-Alba
?? Visiting Postdoctoral Research Associate
?? Laboratory of Evolutionary Ecology of Adaptations,?
?? School of Life Sciences, University of Lincoln,??? Riseholme Park Campus, Lincoln
?? LN2 2LG,
?? UK.

?? https://eric.exeter.ac.uk/repository/handle/10036/3381


      De: peter dalgaard <pdalgd at gmail.com>

CC: "r-help at r-project.org" <r-help at r-project.org> 
 Enviado: Viernes 7 de agosto de 2015 14:40
 Asunto: Re: [R] Potencial bug in R.adjust ("holm" method)
   



>? ? Hello all,
>? ? I am doing some Bonferroni correction analyses with R.adjust function. I have a spreadsheet with 24 columns, each with 5 values. When I use the "holm" method, it gives me adjusted figures for all the original values except from the ones in the 4th row of each column. I mean, the value on the 4th row for every column is exactly the same either in the original data or in the corrected one.? I've tried using another algorithm just to see what happens ("bonferroni", for example) and everything is fine, I get corrected figures for all the values, even the ones on the 4th row.
> 
>? ? Does anyone know whether this is any kind of known bug of the "holm" algorithm of P.adjust function. If so, should I worry about it? If so, can anybody suggest any possible solution?
>? ? Thank you very much.
>? ? Iker

p.adjust(), I presume?

The Holm procedure is essentially to sort p-values in decreasing order and mutiplying by 1:n plus a little fiddling to keep the order and prevent p > 1. The logic is that if you reject the hypothesis corresponding to the smallest p after Bonferroni-correction by N, you only have N-1 simultaneous tests to consider, etc. The smallest multiplier will be 1, so it's not strange that one value appears uncorrected. It's curious that it is always in the 4th row, but it might be that the p-values in the 4 other rows are all considerably smaller.

You do realize that if you run p.adjust for each column, you are not actually adjusting for the total of 120 tests, only for 5 of them, effectively ignoring the 23 other columns every time?

-pd



> 
> 
> __________________________________________________________________
> 
>? ? Dr. Iker Vaquero-Alba
>? ? Visiting Postdoctoral Research Associate
>? ? Laboratory of Evolutionary Ecology of Adaptations, 
>? ? School of Life Sciences, University of Lincoln,? ? Riseholme Park Campus, Lincoln
>? ? LN2 2LG,
>? ? UK.
> 
>? ? https://eric.exeter.ac.uk/repository/handle/10036/3381
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com










  
	[[alternative HTML version deleted]]


From ziqi.zhang at sheffield.ac.uk  Fri Aug  7 16:40:22 2015
From: ziqi.zhang at sheffield.ac.uk (Ziqi Zhang)
Date: Fri, 7 Aug 2015 15:40:22 +0100
Subject: [R] fpc package - computing silhouette value returns error
Message-ID: <55C4C356.9030205@sheffield.ac.uk>

Hi
I am using R to do clustering and compute a number of cluster 
statistics. Below are my code. I do not understand why I get the error:

"Error in summary(silhouette(clustering[ss[[i]]], dx)) : error in 
evaluating the argument 'object' in selecting a method for function 
'summary': Error in round(x) : non-numeric argument to mathematical 
function"

Any suggestsion highly appreciated!
Code:
--------------
library(fpc)
require(graphics)
distance <- dist(USArrests, "euclidean")
hc <-hclust(distance, "average")
distcritmulti(USArrests, hc, criterion="asw", fun="dist", 
metric="euclidean")
-------------



-- 
Ziqi Zhang
Research Associate
Department of Computer Science
University of Sheffield


---
This email has been checked for viruses by Avast antivirus software.


From pdalgd at gmail.com  Fri Aug  7 16:57:36 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 7 Aug 2015 16:57:36 +0200
Subject: [R] Potencial bug in R.adjust ("holm" method)
In-Reply-To: <270025218.863338.1438957208627.JavaMail.yahoo@mail.yahoo.com>
References: <9950EFAD-23BB-444D-8095-33A721BC6F28@gmail.com>
	<270025218.863338.1438957208627.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <861D6674-592C-4CCD-8A09-B8D426A5E87C@gmail.com>


On 07 Aug 2015, at 16:20 , Iker Vaquero Alba <karraspito at yahoo.es> wrote:

> 
> 
>    Hello, Peter, and thank you for your clarifying reply. Actually, that was another doubt I had. As I take my data from different files (every "bunch of 5" values is taken from a different file), I assumed that, if I wanted to adjust for the error due to repeated measures, it should be enough to do it inside each file, right? I mean, the possible error due to repeated measures shouldn't go beyond each file. Once you close one file, open and attach a new one, the count, let's say, starts from scratch. 
> Am I right? And if I'm not, what is the reason why should I pool all the p-values in a massive column and adjust them in bulk?
> 


There's no clear answer to that kind of question. It depends on which kind of error rate you want to control, but in principle multiple response variables are not different than multiple comparisons. If you test 20 response variables at level 5%, on average 1 will come out significant even if there are no actual effects (if the variables are highly correlated, this may mean that all 20 come out significant with 5% probability, though).



>    Thank you very much for your help.
>    Iker
>  
> __________________________________________________________________
> 
>    Dr. Iker Vaquero-Alba
>    Visiting Postdoctoral Research Associate
>    Laboratory of Evolutionary Ecology of Adaptations, 
>    School of Life Sciences, University of Lincoln, 
>    Riseholme Park Campus, Lincoln
>    LN2 2LG,
>    UK.
> 
>    https://eric.exeter.ac.uk/repository/handle/10036/3381
> 
> 
> De: peter dalgaard <pdalgd at gmail.com>
> Para: Iker Vaquero Alba <karraspito at yahoo.es> 
> CC: "r-help at r-project.org" <r-help at r-project.org> 
> Enviado: Viernes 7 de agosto de 2015 14:40
> Asunto: Re: [R] Potencial bug in R.adjust ("holm" method)
> 
> 
> On 06 Aug 2015, at 19:20 , Iker Vaquero Alba <karraspito at yahoo.es> wrote:
> 
> >    Hello all,
> >    I am doing some Bonferroni correction analyses with R.adjust function. I have a spreadsheet with 24 columns, each with 5 values. When I use the "holm" method, it gives me adjusted figures for all the original values except from the ones in the 4th row of each column. I mean, the value on the 4th row for every column is exactly the same either in the original data or in the corrected one.  I've tried using another algorithm just to see what happens ("bonferroni", for example) and everything is fine, I get corrected figures for all the values, even the ones on the 4th row.
> > 
> >    Does anyone know whether this is any kind of known bug of the "holm" algorithm of P.adjust function. If so, should I worry about it? If so, can anybody suggest any possible solution?
> >    Thank you very much.
> >    Iker
> 
> p.adjust(), I presume?
> 
> The Holm procedure is essentially to sort p-values in decreasing order and mutiplying by 1:n plus a little fiddling to keep the order and prevent p > 1. The logic is that if you reject the hypothesis corresponding to the smallest p after Bonferroni-correction by N, you only have N-1 simultaneous tests to consider, etc. The smallest multiplier will be 1, so it's not strange that one value appears uncorrected. It's curious that it is always in the 4th row, but it might be that the p-values in the 4 other rows are all considerably smaller.
> 
> You do realize that if you run p.adjust for each column, you are not actually adjusting for the total of 120 tests, only for 5 of them, effectively ignoring the 23 other columns every time?
> 
> -pd
> 
> 
> 
> 
> > 
> > 
> > __________________________________________________________________
> > 
> >    Dr. Iker Vaquero-Alba
> >    Visiting Postdoctoral Research Associate
> >    Laboratory of Evolutionary Ecology of Adaptations, 
> >    School of Life Sciences, University of Lincoln,    Riseholme Park Campus, Lincoln
> >    LN2 2LG,
> >    UK.
> > 
> >    https://eric.exeter.ac.uk/repository/handle/10036/3381
> 
> > 
> > 
> >     [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Fri Aug  7 17:40:25 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Aug 2015 08:40:25 -0700
Subject: [R] fpc package - computing silhouette value returns error
In-Reply-To: <55C4C356.9030205@sheffield.ac.uk>
References: <55C4C356.9030205@sheffield.ac.uk>
Message-ID: <CAF8bMcZQ8P8LK2e=TBPH=60t1TO1WGLj_NFEFj61+1SdSw1GKg@mail.gmail.com>

help(distcritmulti) says that its 2nd argument is
   "clustering: vector of integers indicating the clustering"
and you supplied the output of hclust, which is not a
vector of group identifiers.  You can make a group
identifier vector from hc with cutree(hc, k=4), where k is
the number of groups.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 7, 2015 at 7:40 AM, Ziqi Zhang <ziqi.zhang at sheffield.ac.uk>
wrote:

> Hi
> I am using R to do clustering and compute a number of cluster statistics.
> Below are my code. I do not understand why I get the error:
>
> "Error in summary(silhouette(clustering[ss[[i]]], dx)) : error in
> evaluating the argument 'object' in selecting a method for function
> 'summary': Error in round(x) : non-numeric argument to mathematical
> function"
>
> Any suggestsion highly appreciated!
> Code:
> --------------
> library(fpc)
> require(graphics)
> distance <- dist(USArrests, "euclidean")
> hc <-hclust(distance, "average")
> distcritmulti(USArrests, hc, criterion="asw", fun="dist",
> metric="euclidean")
> -------------
>
>
>
> --
> Ziqi Zhang
> Research Associate
> Department of Computer Science
> University of Sheffield
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mauriciocornejo at yahoo.com  Fri Aug  7 18:31:16 2015
From: mauriciocornejo at yahoo.com (Mauricio Cornejo)
Date: Fri, 7 Aug 2015 16:31:16 +0000 (UTC)
Subject: [R] Why does R start in wrong working directory despite R_USER
	setting?
Message-ID: <2105360340.462940.1438965076031.JavaMail.yahoo@mail.yahoo.com>

Hi
After launching newly-installed R 3.2.1 (on Windows 7), I run the following two commands:
> getwd()[1] "C:/ProgramData/Microsoft/Windows/Start Menu/Programs/R"
> Sys.getenv('R_USER')[1] "C:\\Users\\<my username>\\Documents"
I would like the startup working directory to be that pointed to by R_USER.
I don't have administrative access to the machine.
Many thanks for any insight anyone can provide.
Mauricio
	[[alternative HTML version deleted]]


From aurora.gonzalez2 at um.es  Fri Aug  7 19:09:31 2015
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Fri, 07 Aug 2015 19:09:31 +0200
Subject: [R] compare grupos dichotomus dependent variable
Message-ID: <20150807190931.Horde.E9zsJGoNGgJSbng5KmOujg1@webmail.um.es>

Hello everybody. I have a statistics question:

let's say that I want to compaire answers between men and women to a yes/no
question but I have so much more women than men, then, it looks like I
cannot use chi squared test. Would it be correct to use U test (or ranked
Wilcoxon test)?? What do you think?? The code is below, than you so much!!

men<-rep( 0,12 )
women <- c( 0,1,0,0,0,1,0,0,0,rep( 0,114 ),1,rep( 0,199 ) )
wilcox.test( men, women )
chisq.test( men, women )


------
Aurora Gonz?lez Vidal

Secci?n Apoyo Estad?stico.
Servicio de Apoyo a la Investigaci?n (SAI).
Vicerrectorado de Investigaci?n.
Universidad de Murcia
Edif. SACE . Campus de Espinardo.
30100 Murcia

@. aurora.gonzalez2 at um.es
T. 868 88 7315
F. 868 88 7302
www.um.es/sai
www.um.es/ae

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Aug  7 19:44:52 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 07 Aug 2015 18:44:52 +0100
Subject: [R] Why does R start in wrong working directory despite R_USER
 setting?
In-Reply-To: <2105360340.462940.1438965076031.JavaMail.yahoo@mail.yahoo.com>
References: <2105360340.462940.1438965076031.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55C4EE94.403@dewey.myzen.co.uk>

Assuming you are using the GUI you can use the Properties of the 
shortcut to tell R where to start.

On 07/08/2015 17:31, Mauricio Cornejo via R-help wrote:
> Hi
> After launching newly-installed R 3.2.1 (on Windows 7), I run the following two commands:
>> getwd()[1] "C:/ProgramData/Microsoft/Windows/Start Menu/Programs/R"
>> Sys.getenv('R_USER')[1] "C:\\Users\\<my username>\\Documents"
> I would like the startup working directory to be that pointed to by R_USER.
> I don't have administrative access to the machine.
> Many thanks for any insight anyone can provide.
> Mauricio
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From alicia.r.perezporro at gmail.com  Fri Aug  7 18:34:39 2015
From: alicia.r.perezporro at gmail.com (=?UTF-8?Q?Alicia_P=C3=A9rez=2DPorro?=)
Date: Fri, 07 Aug 2015 16:34:39 +0000
Subject: [R] Treemap error - missing value where TRUE/FALSE needed
Message-ID: <CAP49uECR=5KS32tycs=dRceaXBdAii1B5WpQtsFWOZu+7UsMHw@mail.gmail.com>

Dear R users,

I am trying to generate a treemap using the package Treemap on R and I'm
encountering the subsequent error:


*Error in if (rec[3] < rec[4]) { : missing value where TRUE/FALSE needed*

I did traceback() and I got:

*5: pivotSize(numeric(0), c(NA_real_, NA_real_, NA_real_, NA_real_*
*   ))*
*4: do.call(algorithm, list(value, rec))*
*3: subTM(datlist[datlist$l == 1])*
*2: tmGenerateRect(datlist, vps, indexList, algorithm)*
*1: treemap(stuff, index = c("representative", "description"), vSize =
"value", *
*       type = "categorical", vColor = "representative", title = "REVIGO
Gene Ontology treemap", *
*       inflate.labels = FALSE, lowerbound.cex.labels = 0, bg.labels =
"#CCCCCCAA", *
*       position.legend = "none")*

My script is attached.

I have no idea about how to fix it. Can anyone please help me?
Thanks in advance,

Alicia

From bbolker at gmail.com  Fri Aug  7 18:12:25 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 7 Aug 2015 16:12:25 +0000
Subject: [R] help plotting glmm values
References: <CANxP2S5ZgcPSUfGcgsFR0ht4TmpkauOqMOeOBtT35e17Zy0fxw@mail.gmail.com>
Message-ID: <loom.20150807T175716-247@post.gmane.org>

Luis Fernando Garc?a <luysgarcia <at> gmail.com> writes:

> 
> Dear Fellows,
> 
> I?m sorry if my question is very basic, but I'm still new in the field of R
> and the GLMM.

  In future, you might consider posting to r-sig-mixed-models at r-project.org
instead ...

> I have made a following glmm, and I need to plot the predicted mean values
> from the model and the CI, with this barplot +/- the CI, using the prey as
> explanatory factor.
> 
>  Although I have been looking for it, I have not found 
> a website which show
> the way to do this, so  I'm unsure about the right procedure. 
> If any of you
> could help me with the correct procedure I would really apprreciate it!

See:

http://glmm.wikidot.com/faq#predconf
http://ms.mcmaster.ca/~bolker/R/misc/foxchapter/  

Some modified analysis:

library(lme4)
glmm1 <- glmer(Acc ~ Prey + (1 | Sp), data=Lac, family=binomial)
summary(glmm1)
deviance(glmm1)/df.residual(glmm1)
glmm2 <- update(glmm1,nAGQ=10)

## aggregate
library(plyr)
Lac_agg <- ddply(Lac,c("Prey","Sp"),
                 summarise,
                 N=length(Acc),
                 p=mean(Acc))
Lac_agg <- aggregate(Acc~Prey*Sp,FUN=function(x) c(k=sum(x),N=length(x)),
                     data=Lac)
glmm3 <- glmer(p ~ Prey + (1 | Sp), weights=N,
               data=Lac_agg, family=binomial)
deviance(glmm3)/df.residual(glmm3)
## model with ind-level obs blows up: leave it alone ...

From jdnewmil at dcn.davis.CA.us  Fri Aug  7 20:02:03 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 07 Aug 2015 14:02:03 -0400
Subject: [R] Why does R start in wrong working directory despite
	R_USER	setting?
In-Reply-To: <2105360340.462940.1438965076031.JavaMail.yahoo@mail.yahoo.com>
References: <2105360340.462940.1438965076031.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <3C3BB32E-D210-4553-8E06-41BB438F91B1@dcn.davis.CA.us>

Not really a question about R, but you can make a Windows shortcut that sets the directory where you want it.

My preference is to start in different working directories depending on which project I am working on. R_USER is not a project directory. One way to do that is to double-click on an RData file located where you want to start. Another way is to create a new shortcut in each directory. Another way is to add a line to your script that sets the directory appropriately, though that makes sharing the scripts harder. Another way is to use RStudio projects.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 7, 2015 12:31:16 PM EDT, Mauricio Cornejo via R-help <r-help at r-project.org> wrote:
>Hi
>After launching newly-installed R 3.2.1 (on Windows 7), I run the
>following two commands:
>> getwd()[1] "C:/ProgramData/Microsoft/Windows/Start Menu/Programs/R"
>> Sys.getenv('R_USER')[1] "C:\\Users\\<my username>\\Documents"
>I would like the startup working directory to be that pointed to by
>R_USER.
>I don't have administrative access to the machine.
>Many thanks for any insight anyone can provide.
>Mauricio
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Aug  7 22:48:16 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 7 Aug 2015 13:48:16 -0700
Subject: [R] testing whether two character vectors contain (the same)
	items in the same order
In-Reply-To: <8CDF735C-3BE1-4E93-AA1F-ACDEC2C18E13@helsinki.fi>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
	<CAGxFJbRj7Wsas6przfnrtw4uqM-MVU0=HO+kA_28zt8bQ70zUw@mail.gmail.com>
	<84FC2562-CE0F-4187-A742-02FAB2E98BA4@helsinki.fi>
	<19927D40-C6F6-495E-9152-28855AE53841@utoronto.ca>
	<CAGxFJbQBwdk7Dbe1fDGHSsZF-5ZkzzhDb_g0VBUJXw2uwTK+yg@mail.gmail.com>
	<8CDF735C-3BE1-4E93-AA1F-ACDEC2C18E13@helsinki.fi>
Message-ID: <E74FDC57-0A5A-42D5-8E66-995BCD5394FB@comcast.net>


On Aug 7, 2015, at 12:22 AM, Federico Calboli wrote:

> 
>> On 7 Aug 2015, at 01:59, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> Boris:
>> 
>> You may be right, but it seems like esp to me based on the op's non-description of likelihood of coming from the same noisy process. My response would be: seek local statistical help, as your replies indicate a good deal of statistical confusion.
>> 
>> Cheers,
>> Bert
> 
> Bert,
> 
> as this is R-help and not cross-validated I am looking for a precanned function that would test whether the order of characters in two character vectors comes from the same (noisy) process.  I would thus expect you to say something on the lines of:
> 
> function X uses method Y to do something like that
> function W uses method Z to do something like that
> ?
> 
> look into those, figure out exactly what you are testing and use the most appropiate function.  
> 
> The whys and wherefores are for me to deal with, I just want to know whether someone has built a function that does, or seems to do, what I asked for.  As I said, this is R-help, and I seek help for R use.

> findFn("levenshtein")
found 57 matches;  retrieving 3 pages
2 3 
Downloaded 44 links in 17 packages.


 stringdist::stringdist( paste0(x, collapse=""), paste0(letters[y], collapse="") )
[1] 30

-- 
HTH;
David.

> 
> I do concede that my original question might have left many wondering, but I guess my reply to Boris would have cleared any doubts.  I am therefore puzzled by the great deal of confusion on your part in understanding the purpose of my question and, in general, of this list.
> 
> Best wishes
> 
> F
> 
> 
>> 
>> 
>> 
>> On Thursday, August 6, 2015, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> You are looking for what is known as the "Cayley distance" between vectors - an edit distance that allows only transpositions. RSeek mentions PerMallows (https://cran.r-project.org/web/packages/PerMallows/PerMallows.pdf) and Rankluster (https://cran.r-project.org/web/packages/Rankcluster/Rankcluster.pdf) as packages that support work with Cayley distances. It seems to me that distCayley() in Rankcluster does what you want. From the examples:
>> 
>> x=1:5
>> y=c(2,3,1,4,5)
>> distCayley(x,y)
>> 8
>> 
>> 
>> Cheers,
>> Boris
>> 
>> 
>> 
>> 
>> 
>> On Aug 6, 2015, at 9:51 AM, Federico Calboli <federico.calboli at helsinki.fi> wrote:
>> 
>>>> 
>>>> On 6 Aug 2015, at 15:40, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> 
>>>> Define "goodness of match" .  For exact matches, see ?"==" , all.equal, etc.
>>> 
>>> Fair point.  I would define it as a number that tells me how likely it is that the same (noisy) process produced both lists.
>>> 
>>> BW
>>> 
>>> F
>>> 
>>> 
>>> 
>>> 
>>>> 
>>>> Bert
>>>> 
>>>> On Thursday, August 6, 2015, Federico Calboli <federico.calboli at helsinki.fi> wrote:
>>>> Hi All,
>>>> 
>>>> let?s assume I have a vector of letters drawn only once from the alphabet:
>>>> 
>>>> x = sample(letters, 15, replace = F)
>>>> x
>>>> [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
>>>> 
>>>> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
>>>> 
>>>> I would now like to test how good a match y is for x.  Obviously I can transform the letters in numbers and use a rank test, but I was left wondering whether this is the only solution and whether there are more appropriate solutions that are already implemented in R (I am not going to reinvent the wheel if I can avoid it).
>>>> 
>>>> BW
>>>> 
>>>> F
>>>> 
>>>> 
>>>> --
>>>> Federico Calboli
>>>> Ecological Genetics Research Unit
>>>> Department of Biosciences
>>>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>>>> FIN-00014 University of Helsinki
>>>> Finland
>>>> 
>>>> federico.calboli at helsinki.fi
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> --
>>>> Bert Gunter
>>>> 
>>>> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
>>>>  -- Clifford Stoll
>>>> 
>>> 
>>> 
>>> --
>>> Federico Calboli
>>> Ecological Genetics Research Unit
>>> Department of Biosciences
>>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>>> FIN-00014 University of Helsinki
>>> Finland
>>> 
>>> federico.calboli at helsinki.fi
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> -- 
>> Bert Gunter
>> 
>> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
>>   -- Clifford Stoll
>> 
> 
> 
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
> 
> federico.calboli at helsinki.fi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat Aug  8 00:14:11 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 7 Aug 2015 15:14:11 -0700
Subject: [R] compare grupos dichotomus dependent variable
In-Reply-To: <20150807190931.Horde.E9zsJGoNGgJSbng5KmOujg1@webmail.um.es>
References: <20150807190931.Horde.E9zsJGoNGgJSbng5KmOujg1@webmail.um.es>
Message-ID: <CAGxFJbTVaYZaPQF1NDPeXpYr8puvWTfJ=3YBEZLdNonrx2kJug@mail.gmail.com>

What does this have to do with R programming?

Bert

On Friday, August 7, 2015, AURORA GONZALEZ VIDAL <aurora.gonzalez2 at um.es>
wrote:

> Hello everybody. I have a statistics question:
>
> let's say that I want to compaire answers between men and women to a yes/no
> question but I have so much more women than men, then, it looks like I
> cannot use chi squared test. Would it be correct to use U test (or ranked
> Wilcoxon test)?? What do you think?? The code is below, than you so much!!
>
> men<-rep( 0,12 )
> women <- c( 0,1,0,0,0,1,0,0,0,rep( 0,114 ),1,rep( 0,199 ) )
> wilcox.test( men, women )
> chisq.test( men, women )
>
>
> ------
> Aurora Gonz?lez Vidal
>
> Secci?n Apoyo Estad?stico.
> Servicio de Apoyo a la Investigaci?n (SAI).
> Vicerrectorado de Investigaci?n.
> Universidad de Murcia
> Edif. SACE . Campus de Espinardo.
> 30100 Murcia
>
> @. aurora.gonzalez2 at um.es <javascript:;>
> T. 868 88 7315
> F. 868 88 7302
> www.um.es/sai
> www.um.es/ae
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Aug  8 00:45:02 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 8 Aug 2015 08:45:02 +1000
Subject: [R] compare grupos dichotomus dependent variable
In-Reply-To: <20150807190931.Horde.E9zsJGoNGgJSbng5KmOujg1@webmail.um.es>
References: <20150807190931.Horde.E9zsJGoNGgJSbng5KmOujg1@webmail.um.es>
Message-ID: <CA+8X3fU-LQh2f9dtj9YJvsA+jhpFynfKcrJyjRHsTv+uvMMwbg@mail.gmail.com>

Hi Aurora,
Perhaps what you are seeking is a test of proportions.

prop.test(c(sum(men),sum(women)),c(length(men),length(women)))

        2-sample test for equality of proportions with continuity correction

data:  c(sum(men), sum(women)) out of c(length(men), length(women))
X-squared = 1.0378e-30, df = 1, p-value = 1
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.02903701  0.01046116
sample estimates:
     prop 1      prop 2
0.000000000 0.009287926

Warning message:
In prop.test(c(sum(men), sum(women)), c(length(men), length(women))) :
  Chi-squared approximation may be incorrect

If the question was "Have you had a baby in the past year?" the answer
is not too far off, but your sample is a bit small.

Jim


On Sat, Aug 8, 2015 at 3:09 AM, AURORA GONZALEZ VIDAL
<aurora.gonzalez2 at um.es> wrote:
> Hello everybody. I have a statistics question:
>
> let's say that I want to compaire answers between men and women to a yes/no
> question but I have so much more women than men, then, it looks like I
> cannot use chi squared test. Would it be correct to use U test (or ranked
> Wilcoxon test)?? What do you think?? The code is below, than you so much!!
>
> men<-rep( 0,12 )
> women <- c( 0,1,0,0,0,1,0,0,0,rep( 0,114 ),1,rep( 0,199 ) )
> wilcox.test( men, women )
> chisq.test( men, women )
>
>
> ------
> Aurora Gonz?lez Vidal
>
> Secci?n Apoyo Estad?stico.
> Servicio de Apoyo a la Investigaci?n (SAI).
> Vicerrectorado de Investigaci?n.
> Universidad de Murcia
> Edif. SACE . Campus de Espinardo.
> 30100 Murcia
>
> @. aurora.gonzalez2 at um.es
> T. 868 88 7315
> F. 868 88 7302
> www.um.es/sai
> www.um.es/ae
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Aug  8 00:56:43 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 8 Aug 2015 08:56:43 +1000
Subject: [R] Why does R start in wrong working directory despite R_USER
	setting?
In-Reply-To: <3C3BB32E-D210-4553-8E06-41BB438F91B1@dcn.davis.CA.us>
References: <2105360340.462940.1438965076031.JavaMail.yahoo@mail.yahoo.com>
	<3C3BB32E-D210-4553-8E06-41BB438F91B1@dcn.davis.CA.us>
Message-ID: <CA+8X3fVVf5qAGA-_jzk7PL5Rzx7_mvjwNxbnod4qwEOpy2Z9Bg@mail.gmail.com>

Hi Mauricio,
You can also run a directory selection file by including something like this:

source("SelectAnalysis.R")

in the .First function (see "An Introduction to R", section 10.8
Customizing the environment). Mine currently looks like this:

cat("(A)custudy\n(I)nterval analysis\n(O)mbo
mapping\nR\n(C)ourse\nStressaly(Z)er\n")
answer<-toupper(readline("Choose the project - "))
if(answer=="A") setwd("/home/jim/research/im/acustudy")
if(answer=="I") setwd("/home/jim/research/interval_analysis")
if(answer=="O") setwd("/home/jim/research/ombo/mapping")
if(answer=="R") setwd("/home/jim/R")
if(answer=="C") setwd("/home/jim/bitwrit/R_programming_course")
if(answer=="Z") setwd("/home/jim/research/stressalyser/naomi")
print(list.files(pattern="[.]R"))
options(browser="konqueror",editor="kwrite",show.signif.stars=FALSE)

This should work on any system, regardless of your privileges.

Jim


On Sat, Aug 8, 2015 at 4:02 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Not really a question about R, but you can make a Windows shortcut that sets the directory where you want it.
>
> My preference is to start in different working directories depending on which project I am working on. R_USER is not a project directory. One way to do that is to double-click on an RData file located where you want to start. Another way is to create a new shortcut in each directory. Another way is to add a line to your script that sets the directory appropriately, though that makes sharing the scripts harder. Another way is to use RStudio projects.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 7, 2015 12:31:16 PM EDT, Mauricio Cornejo via R-help <r-help at r-project.org> wrote:
>>Hi
>>After launching newly-installed R 3.2.1 (on Windows 7), I run the
>>following two commands:
>>> getwd()[1] "C:/ProgramData/Microsoft/Windows/Start Menu/Programs/R"
>>> Sys.getenv('R_USER')[1] "C:\\Users\\<my username>\\Documents"
>>I would like the startup working directory to be that pointed to by
>>R_USER.
>>I don't have administrative access to the machine.
>>Many thanks for any insight anyone can provide.
>>Mauricio
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.otojanov at qmul.ac.uk  Fri Aug  7 20:46:35 2015
From: r.otojanov at qmul.ac.uk (mrrox)
Date: Fri, 7 Aug 2015 11:46:35 -0700 (PDT)
Subject: [R] TVP-ECM modelling in R
Message-ID: <1438973195277-4710874.post@n4.nabble.com>

Hello,

I want to estimate a TVP-ECM model in R. Is there a specific package in R
that can handle TVP-ECM models?

Thank you



--
View this message in context: http://r.789695.n4.nabble.com/TVP-ECM-modelling-in-R-tp4710874.html
Sent from the R help mailing list archive at Nabble.com.


From dmorrison at seventhwave.org  Fri Aug  7 21:05:50 2015
From: dmorrison at seventhwave.org (Drew Morrison)
Date: Fri, 7 Aug 2015 12:05:50 -0700 (PDT)
Subject: [R] Piecewise (segmented) linear regression with center section
 slope constraint
In-Reply-To: <CAN5YmCHaram3mr+n4tmbgfmKRq7sPxQ9QH6RRTfKxy+dQ4Ttgw@mail.gmail.com>
References: <1438891302345-4710839.post@n4.nabble.com>
	<CAN5YmCHaram3mr+n4tmbgfmKRq7sPxQ9QH6RRTfKxy+dQ4Ttgw@mail.gmail.com>
Message-ID: <1438974350663-4710875.post@n4.nabble.com>

Thanks, Jean. I've actually looked at that source before. The issue is that I
can't constrain the slope of the /center/ section to be zero - in fact, I've
applied similar code to a three-segment regression and I can get a zero
slope either of the two sides, but not in the middle.

Here's a list of the main resources I've consulted so far:

https://climateecology.wordpress.com/2012/08/19/r-for-ecologists-putting-together-a-piecewise-regression/

http://www.stackoverflow.dluat.com/questions/30060278/creating-piecewise-linear-regression-with-flat-slope-in-r

https://rpubs.com/MarkusLoew/12164



--
View this message in context: http://r.789695.n4.nabble.com/Piecewise-segmented-linear-regression-with-center-section-slope-constraint-tp4710839p4710875.html
Sent from the R help mailing list archive at Nabble.com.


From kiradanielletaylor at gmail.com  Fri Aug  7 23:41:20 2015
From: kiradanielletaylor at gmail.com (kira taylor)
Date: Fri, 7 Aug 2015 15:41:20 -0600
Subject: [R] Error with predict and newdata
Message-ID: <CA+Y73W+oCq0BgUat1j7j8J=7HFeJLdA6Kvw=QbrEbbn0pDY5Jg@mail.gmail.com>

Hi!

I am trying to use predict to apply my model to data from one time period to
see what might be the values for another time period.  I did this
successfully for one dataset, and then tried on another with identical code
and got the following error:

Error in eval(predvars, data, env) :
  numeric 'envir' arg not of length one

The only difference between the two datasets was that my predictor model for
the first dataset had two predictor variables and my model for the second
dataset had only one.  Why would this make a difference?

My dougfir.csv contains just two columns with thirty numbers in each,
labeled height and dryshoot.

my lm is: fitdougfir <- lm(dryshoot~height,data=dougfir)

It gets a little complicated (and messy, sorry!  I am new to R) because I
then made a second .csv - the one I used to make my model contained values
from just June.  My new .csv (called alldatadougfir.csv) includes values
from October as well, and also contains a "date" column that labels the
values either "june" or "october."

I did the following to separate the height data by date:

alldatadougfir[alldatadougfir$date=="june",c("height")]->junedatadougfir
alldatadougfir[alldatadougfir$date=="october",c("height")]->
octoberdatadougfir

I then want to use my June model to predict my October dryshoots using
height as my variable and I did the following:

predict(fitdougfir, newdata=junedatadougfir)
predict(fitdougfir, newdata=octoberdatadougfir)

Again, I did this with an identical dataset successfully - the only
difference was that my model in the successful dataset had two predictor
variables instead of the one variable (height) I have in this dataset.

Sorry again for my messy code!

Thank you very much,

Kira

	[[alternative HTML version deleted]]


From betanster at gmail.com  Sat Aug  8 00:23:23 2015
From: betanster at gmail.com (Jose Betancourt B.)
Date: Sat, 8 Aug 2015 00:23:23 +0200
Subject: [R] creating a funct
Message-ID: <CANuuowPe_e2COTo1ob-VzMDHjyqeyDtx1m4730Mzt75RcaV0aQ@mail.gmail.com>

Dear

i am develeping a function, first  I attach r command and later r executer
script, the conection fails and I do not realize why

best regards
-------------- next part --------------
100	38	1
80	19	5
90	31	2
70	21	6
85	30	3
75	22	5
99	37	1
100	38	1
80	19	5
90	31	2
70	21	6
85	30	3
75	22	5
99	37	1

From jdnewmil at dcn.davis.CA.us  Sat Aug  8 05:22:28 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 07 Aug 2015 23:22:28 -0400
Subject: [R] creating a funct
In-Reply-To: <CANuuowPe_e2COTo1ob-VzMDHjyqeyDtx1m4730Mzt75RcaV0aQ@mail.gmail.com>
References: <CANuuowPe_e2COTo1ob-VzMDHjyqeyDtx1m4730Mzt75RcaV0aQ@mail.gmail.com>
Message-ID: <855BACFA-8396-41B6-BB64-F293BF4DB40F@dcn.davis.CA.us>

I think the readers of this mailing list would have to be psychic to know what went wrong given that description. This kind of situation usually requires in-person help, so I recommend looking for an educational environment that offers such assistance... a seminar, university class, tutor, or users group, for example.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 7, 2015 6:23:23 PM EDT, "Jose Betancourt B." <betanster at gmail.com> wrote:
>Dear
>
>i am develeping a function, first  I attach r command and later r
>executer
>script, the conection fails and I do not realize why
>
>best regards
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boredstoog at mailinator.com  Sat Aug  8 06:31:14 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Fri, 7 Aug 2015 21:31:14 -0700 (PDT)
Subject: [R] Cant upgrade R in ubuntu 14.04
Message-ID: <1439008274429-4710885.post@n4.nabble.com>


I am trying to install R programming language and able to install rbase
using this code without adding repository in *source.list*

sudo apt-get install r-base

After that i tried to upgrade it using this code

sudo add-apt-repository ?deb
http://star-www.st-andrews.ac.uk/cran/bin/linux/ubuntu/trusty/?
sudo apt-get update
sudo apt-get upgrade

But when i tried the first code

sudo add-apt-repository ?deb
http://star-www.st-andrews.ac.uk/cran/bin/linux/ubuntu/trusty/?

its giving this error

Error: need a single repository as argument





--
View this message in context: http://r.789695.n4.nabble.com/Cant-upgrade-R-in-ubuntu-14-04-tp4710885.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sat Aug  8 08:04:56 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 7 Aug 2015 23:04:56 -0700
Subject: [R] Piecewise (segmented) linear regression with center section
	slope constraint
In-Reply-To: <1438974350663-4710875.post@n4.nabble.com>
References: <1438891302345-4710839.post@n4.nabble.com>
	<CAN5YmCHaram3mr+n4tmbgfmKRq7sPxQ9QH6RRTfKxy+dQ4Ttgw@mail.gmail.com>
	<1438974350663-4710875.post@n4.nabble.com>
Message-ID: <036039B5-04C2-40F2-A0D4-8C93507F4C55@comcast.net>


On Aug 7, 2015, at 12:05 PM, Drew Morrison wrote:

> Thanks, Jean. I've actually looked at that source before. The issue is that I
> can't constrain the slope of the /center/ section to be zero - in fact, I've
> applied similar code to a three-segment regression and I can get a zero
> slope either of the two sides, but not in the middle.

If you replaced the values during the interval in question with their mean values during that interval, you should then get a zero slope.

-- 
David.
> 
> Here's a list of the main resources I've consulted so far:
> 
> https://climateecology.wordpress.com/2012/08/19/r-for-ecologists-putting-together-a-piecewise-regression/
> 
> http://www.stackoverflow.dluat.com/questions/30060278/creating-piecewise-linear-regression-with-flat-slope-in-r
> 
> https://rpubs.com/MarkusLoew/12164
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Piecewise-segmented-linear-regression-with-center-section-slope-constraint-tp4710839p4710875.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Aug  8 08:08:42 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 7 Aug 2015 23:08:42 -0700
Subject: [R] Error with predict and newdata
In-Reply-To: <CA+Y73W+oCq0BgUat1j7j8J=7HFeJLdA6Kvw=QbrEbbn0pDY5Jg@mail.gmail.com>
References: <CA+Y73W+oCq0BgUat1j7j8J=7HFeJLdA6Kvw=QbrEbbn0pDY5Jg@mail.gmail.com>
Message-ID: <BB06E206-D5BF-45E9-9DDA-2D9444158EDD@comcast.net>


On Aug 7, 2015, at 2:41 PM, kira taylor wrote:

> Hi!
> 
> I am trying to use predict to apply my model to data from one time period to
> see what might be the values for another time period.  I did this
> successfully for one dataset, and then tried on another with identical code
> and got the following error:
> 
> Error in eval(predvars, data, env) :
>  numeric 'envir' arg not of length one
> 
> The only difference between the two datasets was that my predictor model for
> the first dataset had two predictor variables and my model for the second
> dataset had only one.  Why would this make a difference?
> 
> My dougfir.csv contains just two columns with thirty numbers in each,
> labeled height and dryshoot.
> 
> my lm is: fitdougfir <- lm(dryshoot~height,data=dougfir)
> 
> It gets a little complicated (and messy, sorry!  I am new to R) because I
> then made a second .csv - the one I used to make my model contained values
> from just June.  My new .csv (called alldatadougfir.csv) includes values
> from October as well, and also contains a "date" column that labels the
> values either "june" or "october."
> 
> I did the following to separate the height data by date:
> 
> alldatadougfir[alldatadougfir$date=="june",c("height")]->junedatadougfir
> alldatadougfir[alldatadougfir$date=="october",c("height")]->
> octoberdatadougfir

Those are no longer lists or dataframe, which are the proper classes of object to pass to predict. 

-- 
David.
> 
> I then want to use my June model to predict my October dryshoots using
> height as my variable and I did the following:
> 
> predict(fitdougfir, newdata=junedatadougfir)
> predict(fitdougfir, newdata=octoberdatadougfir)
> 
> Again, I did this with an identical dataset successfully - the only
> difference was that my model in the successful dataset had two predictor
> variables instead of the one variable (height) I have in this dataset.
> 
> Sorry again for my messy code!
> 
> Thank you very much,
> 
> Kira
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Sat Aug  8 10:40:56 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 8 Aug 2015 10:40:56 +0200
Subject: [R] Cant upgrade R in ubuntu 14.04
In-Reply-To: <1439008274429-4710885.post@n4.nabble.com>
References: <1439008274429-4710885.post@n4.nabble.com>
Message-ID: <2CCC1846-CAE0-4010-BAB1-2DA6B6CAC7AB@gmail.com>

That is an Ubuntu issue, not an R one.

- Peter D.

> On 08 Aug 2015, at 06:31 , boredstoog via R-help <r-help at r-project.org> wrote:
> 
> 
> I am trying to install R programming language and able to install rbase
> using this code without adding repository in *source.list*
> 
> sudo apt-get install r-base
> 
> After that i tried to upgrade it using this code
> 
> sudo add-apt-repository ?deb
> http://star-www.st-andrews.ac.uk/cran/bin/linux/ubuntu/trusty/?
> sudo apt-get update
> sudo apt-get upgrade
> 
> But when i tried the first code
> 
> sudo add-apt-repository ?deb
> http://star-www.st-andrews.ac.uk/cran/bin/linux/ubuntu/trusty/?
> 
> its giving this error
> 
> Error: need a single repository as argument
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Cant-upgrade-R-in-ubuntu-14-04-tp4710885.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ziqi.zhang at sheffield.ac.uk  Sat Aug  8 13:15:50 2015
From: ziqi.zhang at sheffield.ac.uk (Ziqi Zhang)
Date: Sat, 8 Aug 2015 12:15:50 +0100
Subject: [R] parallel clustering, amap, hcluster
Message-ID: <55C5E4E6.604@sheffield.ac.uk>

Hi
I am looking for parallel implementation of hierarchical clustering, the 
equivalent to "hclust" in the "fpc" package.

I found "hcluster" from "amap" package:

hcluster(x, method = "euclidean", diag = FALSE, upper = FALSE,
          link = "complete", members = NULL, nbproc = 2,
          doubleprecision = TRUE)

It takes a data matrix, computes distance matrix then do clustering.
However in my application, /i have to compute the distance matrix and 
use it later anyway. So hcluster is re-computing the distance which is a 
waste of time, as my data is very large scale.

Is there anyway hcluster could just use a pre-computed distance object, 
or obtain the distance object from hcluster, so I can avoid 
double-computing the distane object?

Or more general question is, if there is a parallel implementation of 
hierarchical clustering that takes input a distance matrix, rather than 
the raw data matrix?
Many thanks!

---
This email has been checked for viruses by Avast antivirus software.


From jrkrideau at inbox.com  Sat Aug  8 16:04:46 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 8 Aug 2015 06:04:46 -0800
Subject: [R] creating a funct
In-Reply-To: <CANuuowPe_e2COTo1ob-VzMDHjyqeyDtx1m4730Mzt75RcaV0aQ@mail.gmail.com>
Message-ID: <FB7432CF5DF.000003D0jrkrideau@inbox.com>

You sent the data but forgot the code :)

It is better to use dput() to send data. Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html

John Kane
Kingston ON Canada


> -----Original Message-----
> From: betanster at gmail.com
> Sent: Sat, 8 Aug 2015 00:23:23 +0200
> To: r-help at r-project.org
> Subject: [R] creating a funct
> 
> Dear
> 
> i am develeping a function, first  I attach r command and later r
> executer
> script, the conection fails and I do not realize why
> 
> best regards

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From bbolker at gmail.com  Sat Aug  8 18:56:21 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 8 Aug 2015 16:56:21 +0000
Subject: [R] Error with predict and newdata
References: <CA+Y73W+oCq0BgUat1j7j8J=7HFeJLdA6Kvw=QbrEbbn0pDY5Jg@mail.gmail.com>
	<BB06E206-D5BF-45E9-9DDA-2D9444158EDD@comcast.net>
Message-ID: <loom.20150808T185408-567@post.gmane.org>

David Winsemius <dwinsemius <at> comcast.net> writes:

> 
> 
> On Aug 7, 2015, at 2:41 PM, kira taylor wrote:
> 
> > Hi!
> > 
> > I am trying to use predict to apply my model to data from
>  one time period to
> > see what might be the values for another time period.  I did this
> > successfully for one dataset, and then tried on another
>  with identical code
> > and got the following error:
> > 
> > Error in eval(predvars, data, env) :
> >  numeric 'envir' arg not of length one
> > 

  Please don't cross-post on StackOverflow and the r-help lists
(it will usually lead to duplicated/wasted effort).  If you must,
at least post a link/indicate in each venue that you have cross-posted
to the other: 

(line-broken link, reassemble to visit)

http://stackoverflow.com/questions/31887043/
error-with-predict-and-newdata-dependent-on-number-of-
predictor-variable-in-mod/31887398#31887398


From Scott.Waichler at pnnl.gov  Sat Aug  8 19:32:34 2015
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Sat, 8 Aug 2015 17:32:34 +0000
Subject: [R] Can't install rgl:  installed package can't be loaded;
 'memory not mapped'
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881A05A5C1@EX10MBOX03.pnnl.gov>

Hi, I can't install package rgl.  The last lines from the install process  talking about the error are:

** testing if installed package can be loaded
sh: line 1: 11949 Segmentation fault      '/files3/R/R-3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 < '/tmp/RtmpQCpp6N/file2b115f4f8e1d'

 *** caught segfault ***
address (nil), cause 'memory not mapped'
aborting ...
ERROR: loading failed

I realize this is probably not an R problem, but a Google search turns up nothing that helps, and I'm hoping someone here can help anyway.  Below are my sessionInfo() output and the contents of the first file generated with "R CMD check rgl_0.95.1247.tar.gz".

> sessionInfo()
R version 3.2.1 (2015-06-18)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.2.1


# R CMD check rgl_0.95.1247.tar.gz
* installing *source* package 'rgl' ...
** package 'rgl' successfully unpacked and MD5 sums checked
checking for gcc... gcc -std=gnu99
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for gcc... (cached) gcc -std=gnu99
checking whether we are using the GNU C compiler... (cached) yes
checking whether gcc -std=gnu99 accepts -g... (cached) yes
checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed
checking whether __attribute__((visibility())) is supported... yes
checking whether gcc -std=gnu99 accepts -fvisibility... yes
checking whether  accepts -fvisibility... no
checking for libpng-config... yes
configure: using libpng-config
configure: using libpng dynamic linkage
checking for X... libraries , headers 
checking GL/gl.h usability... yes
checking GL/gl.h presence... yes
checking for GL/gl.h... yes
checking GL/glu.h usability... yes
checking GL/glu.h presence... yes
checking for GL/glu.h... yes
checking for glEnd in -lGL... yes
checking for gluProject in -lGLU... yes
checking for freetype-config... yes
configure: using Freetype and FTGL
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c ABCLineSet.cpp -o ABCLineSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c BBoxDeco.cpp -o BBoxDeco.o
BBoxDeco.cpp: In member function 'int rgl::AxisInfo::getNticks(float, float)':
BBoxDeco.cpp:239: warning: converting to 'int' from 'float'
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Background.cpp -o Background.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c ClipPlane.cpp -o ClipPlane.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Color.cpp -o Color.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Disposable.cpp -o Disposable.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Light.cpp -o Light.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c LineSet.cpp -o LineSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c LineStripSet.cpp -o LineStripSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Material.cpp -o Material.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c NULLgui.cpp -o NULLgui.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c PlaneSet.cpp -o PlaneSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c PointSet.cpp -o PointSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c PrimitiveSet.cpp -o PrimitiveSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c RenderContext.cpp -o RenderContext.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Shape.cpp -o Shape.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c SphereMesh.cpp -o SphereMesh.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c SphereSet.cpp -o SphereSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c SpriteSet.cpp -o SpriteSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c String.cpp -o String.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Surface.cpp -o Surface.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c TextSet.cpp -o TextSet.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Texture.cpp -o Texture.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Viewpoint.cpp -o Viewpoint.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c api.cpp -o api.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c assert.cpp -o assert.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c callbacks.cpp -o callbacks.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c device.cpp -o device.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c devicemanager.cpp -o devicemanager.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c fps.cpp -o fps.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c ftgl.cpp -o ftgl.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c geom.cpp -o geom.o
gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -g -O2  -c gl2ps.c -o gl2ps.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c glErrors.cpp -o glErrors.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c glgui.cpp -o glgui.o
glgui.cpp: In member function 'virtual void rgl::GLBitmapFont::draw(const char*, int, double, double, const rgl::RenderContext&)':
glgui.cpp:115: warning: passing 'double' for argument 3 to 'GLint gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
glgui.cpp: In constructor 'rgl::GLFTFont::GLFTFont(const char*, int, double, const char*)':
glgui.cpp:144: warning: converting to 'unsigned int' from 'double'
glgui.cpp: In member function 'virtual void rgl::GLFTFont::draw(const char*, int, double, double, const rgl::RenderContext&)':
glgui.cpp:182: warning: passing 'double' for argument 3 to 'GLint gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c gui.cpp -o gui.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c init.cpp -o init.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c par3d.cpp -o par3d.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c pixmap.cpp -o pixmap.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c platform.cpp -o platform.o
gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -g -O2  -c pretty.c -o pretty.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c render.cpp -o render.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c rglmath.cpp -o rglmath.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c rglview.cpp -o rglview.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c scene.cpp -o scene.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c select.cpp -o select.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c subscene.cpp -o subscene.o
subscene.cpp: In member function 'void rgl::Subscene::setupViewport(rgl::RenderContext*)':
subscene.cpp:736: warning: converting to 'int' from 'double'
subscene.cpp:737: warning: converting to 'int' from 'double'
subscene.cpp:738: warning: converting to 'int' from 'double'
subscene.cpp:739: warning: converting to 'int' from 'double'
subscene.cpp:741: warning: converting to 'int' from 'double'
subscene.cpp:742: warning: converting to 'int' from 'double'
subscene.cpp:743: warning: converting to 'int' from 'double'
subscene.cpp:744: warning: converting to 'int' from 'double'
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c win32gui.cpp -o win32gui.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c win32lib.cpp -o win32lib.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c x11gui.cpp -o x11gui.o
g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c x11lib.cpp -o x11lib.o
g++ -shared -L/files3/R/R-3.2.1_install/lib64/R/lib -L/usr/local/lib64 -o rgl.so ABCLineSet.o BBoxDeco.o Background.o ClipPlane.o Color.o Disposable.o Light.o LineSet.o LineStripSet.o Material.o NULLgui.o PlaneSet.o PointSet.o PrimitiveSet.o RenderContext.o Shape.o SphereMesh.o SphereSet.o SpriteSet.o String.o Surface.o TextSet.o Texture.o Viewpoint.o api.o assert.o callbacks.o device.o devicemanager.o fps.o ftgl.o geom.o gl2ps.o glErrors.o glgui.o gui.o init.o par3d.o pixmap.o platform.o pretty.o render.o rglmath.o rglview.o scene.o select.o subscene.o win32gui.o win32lib.o x11gui.o x11lib.o -lGLU -lGL -L/usr/lib64 -lpng12 -lX11 -lfreetype -L/files3/R/R-3.2.1_install/lib64/R/lib -lR
installing to /files3/R/R-3.2.1_install/rgl.Rcheck/rgl/libs
** R
** demo
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
sh: line 1: 11949 Segmentation fault      '/files3/R/R-3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 < '/tmp/RtmpQCpp6N/file2b115f4f8e1d'

 *** caught segfault ***
address (nil), cause 'memory not mapped'
aborting ...
ERROR: loading failed
* removing '/files3/R/R-3.2.1_install/rgl.Rcheck/rgl'

Scott Waichler
Pacific Northwest National Laboratory
Richland, WA  USA


From rbaer at atsu.edu  Sat Aug  8 19:50:43 2015
From: rbaer at atsu.edu (Robert Baer)
Date: Sat, 8 Aug 2015 12:50:43 -0500
Subject: [R] testing whether two character vectors contain (the same)
 items in the same order
In-Reply-To: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
Message-ID: <55C64173.9000507@atsu.edu>



On 8/6/2015 5:25 AM, Federico Calboli wrote:
> Hi All,
>
> let?s assume I have a vector of letters drawn only once from the alphabet:
>
> x = sample(letters, 15, replace = F)
> x
>   [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
>
> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
>
> I would now like to test how good a match y is for x.  Obviously I can transform the letters in numbers and use a rank test, but I was left wondering whether this is the only solution and whether there are more appropriate solutions that are already implemented in R (I am not going to reinvent the wheel if I can avoid it).
>
> BW
>
> F
Perhaps
install.packages("stringdist")
help(package = 'stringdist')





>
> --
> Federico Calboli
> Ecological Genetics Research Unit
> Department of Biosciences
> PO Box 65 (Biocenter 3, Viikinkaari 1)
> FIN-00014 University of Helsinki
> Finland
>
> federico.calboli at helsinki.fi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rbaer at atsu.edu  Sat Aug  8 20:21:49 2015
From: rbaer at atsu.edu (Robert Baer)
Date: Sat, 8 Aug 2015 13:21:49 -0500
Subject: [R] testing whether two character vectors contain (the same)
 items in the same order
In-Reply-To: <55C64173.9000507@atsu.edu>
References: <2DD6DFB9-3108-4E78-B849-CE15AA3B4A61@helsinki.fi>
	<55C64173.9000507@atsu.edu>
Message-ID: <55C648BD.1050400@atsu.edu>

And I probably should have included this link:
http://journal.r-project.org/archive/2014-1/loo.pdf

On 8/8/2015 12:50 PM, Robert Baer wrote:
>
>
> On 8/6/2015 5:25 AM, Federico Calboli wrote:
>> Hi All,
>>
>> let?s assume I have a vector of letters drawn only once from the 
>> alphabet:
>>
>> x = sample(letters, 15, replace = F)
>> x
>>   [1] "z" "t" "g" "l" "u" "d" "w" "x" "a" "q" "k" "j" "f" "n" ?v"
>>
>> y = x[c(1:7,9:8, 10:12, 14, 15, 13)]
>>
>> I would now like to test how good a match y is for x.  Obviously I 
>> can transform the letters in numbers and use a rank test, but I was 
>> left wondering whether this is the only solution and whether there 
>> are more appropriate solutions that are already implemented in R (I 
>> am not going to reinvent the wheel if I can avoid it).
>>
>> BW
>>
>> F
> Perhaps
> install.packages("stringdist")
> help(package = 'stringdist')
>
>
>
>
>
>>
>> -- 
>> Federico Calboli
>> Ecological Genetics Research Unit
>> Department of Biosciences
>> PO Box 65 (Biocenter 3, Viikinkaari 1)
>> FIN-00014 University of Helsinki
>> Finland
>>
>> federico.calboli at helsinki.fi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From axel.urbiz at gmail.com  Sat Aug  8 21:01:41 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sat, 8 Aug 2015 15:01:41 -0400
Subject: [R] H2O Package - Error Messages
Message-ID: <CAAyVsXL_tU0X-aEYcdUfA7SvBsWj16rLvG7oP5Rjt3v+6WTQmg@mail.gmail.com>

Hello,

I've been experimenting with the H2O package, which seems to be a very
interesting and promising project.

I'm getting a few error messages through using "h2o.deeplearning" (which I
guess it must be something I'm doing wrong). Here is a reproducible example
of errors using the "n_folds" argument to this function and also when
supplying a list to the argument "hidden" in an attempt to perform
parameter search.

BTW - I'm running H20 on my local host (Mac/OS).

library(h2o)
localH2O <- h2o.init()
iris.hex <- as.h2o(iris)
iris.dl <- h2o.deeplearning(x = 1:4, y = 5, training_frame = iris.hex)

#n_folds issue
iris.dl2 <- h2o.deeplearning(x = 1:4, y = 5, n_folds = 5, training_frame =
iris.hex)
Error in .h2o.doSafeREST(conn = conn, h2oRestApiVersion =
h2oRestApiVersion,  :
  Unknown parameter: n_folds
>

#Parameter search issue
iris.dl3 <- h2o.deeplearning(x = 1:4, y = 5, hidden=list(c(5,5), c(10,10)),
                            training_frame = iris.hex)
Error in which(params[[i$name]] == Inf | params[[i$name]] == -Inf) :
  (list) object cannot be coerced to type 'double'

Any pointers would be much appreciated.

Thanks,
Axel.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Aug  8 21:51:59 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 08 Aug 2015 15:51:59 -0400
Subject: [R] Can't install rgl:  installed package can't be loaded;
 'memory not mapped'
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881A05A5C1@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881A05A5C1@EX10MBOX03.pnnl.gov>
Message-ID: <55C65DDF.8080309@gmail.com>

On 08/08/2015 1:32 PM, Waichler, Scott R wrote:
> Hi, I can't install package rgl.  The last lines from the install process  talking about the error are:

I'd guess you have an OpenGL problem.  Does glxgears run?

Duncan Murdoch

> 
> ** testing if installed package can be loaded
> sh: line 1: 11949 Segmentation fault      '/files3/R/R-3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 < '/tmp/RtmpQCpp6N/file2b115f4f8e1d'
> 
>  *** caught segfault ***
> address (nil), cause 'memory not mapped'
> aborting ...
> ERROR: loading failed
> 
> I realize this is probably not an R problem, but a Google search turns up nothing that helps, and I'm hoping someone here can help anyway.  Below are my sessionInfo() output and the contents of the first file generated with "R CMD check rgl_0.95.1247.tar.gz".
> 
>> sessionInfo()
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] tools_3.2.1
> 
> 
> # R CMD check rgl_0.95.1247.tar.gz
> * installing *source* package 'rgl' ...
> ** package 'rgl' successfully unpacked and MD5 sums checked
> checking for gcc... gcc -std=gnu99
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables... 
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for gcc... (cached) gcc -std=gnu99
> checking whether we are using the GNU C compiler... (cached) yes
> checking whether gcc -std=gnu99 accepts -g... (cached) yes
> checking for gcc -std=gnu99 option to accept ISO C89... (cached) none needed
> checking whether __attribute__((visibility())) is supported... yes
> checking whether gcc -std=gnu99 accepts -fvisibility... yes
> checking whether  accepts -fvisibility... no
> checking for libpng-config... yes
> configure: using libpng-config
> configure: using libpng dynamic linkage
> checking for X... libraries , headers 
> checking GL/gl.h usability... yes
> checking GL/gl.h presence... yes
> checking for GL/gl.h... yes
> checking GL/glu.h usability... yes
> checking GL/glu.h presence... yes
> checking for GL/glu.h... yes
> checking for glEnd in -lGL... yes
> checking for gluProject in -lGLU... yes
> checking for freetype-config... yes
> configure: using Freetype and FTGL
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c ABCLineSet.cpp -o ABCLineSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c BBoxDeco.cpp -o BBoxDeco.o
> BBoxDeco.cpp: In member function 'int rgl::AxisInfo::getNticks(float, float)':
> BBoxDeco.cpp:239: warning: converting to 'int' from 'float'
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Background.cpp -o Background.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c ClipPlane.cpp -o ClipPlane.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Color.cpp -o Color.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Disposable.cpp -o Disposable.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Light.cpp -o Light.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c LineSet.cpp -o LineSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c LineStripSet.cpp -o LineStripSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Material.cpp -o Material.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c NULLgui.cpp -o NULLgui.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c PlaneSet.cpp -o PlaneSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c PointSet.cpp -o PointSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c PrimitiveSet.cpp -o PrimitiveSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c RenderContext.cpp -o RenderContext.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Shape.cpp -o Shape.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c SphereMesh.cpp -o SphereMesh.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c SphereSet.cpp -o SphereSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c SpriteSet.cpp -o SpriteSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c String.cpp -o String.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Surface.cpp -o Surface.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c TextSet.cpp -o TextSet.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Texture.cpp -o Texture.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c Viewpoint.cpp -o Viewpoint.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c api.cpp -o api.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c assert.cpp -o assert.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c callbacks.cpp -o callbacks.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c device.cpp -o device.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c devicemanager.cpp -o devicemanager.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c fps.cpp -o fps.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c ftgl.cpp -o ftgl.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c geom.cpp -o geom.o
> gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -g -O2  -c gl2ps.c -o gl2ps.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c glErrors.cpp -o glErrors.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c glgui.cpp -o glgui.o
> glgui.cpp: In member function 'virtual void rgl::GLBitmapFont::draw(const char*, int, double, double, const rgl::RenderContext&)':
> glgui.cpp:115: warning: passing 'double' for argument 3 to 'GLint gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
> glgui.cpp: In constructor 'rgl::GLFTFont::GLFTFont(const char*, int, double, const char*)':
> glgui.cpp:144: warning: converting to 'unsigned int' from 'double'
> glgui.cpp: In member function 'virtual void rgl::GLFTFont::draw(const char*, int, double, double, const rgl::RenderContext&)':
> glgui.cpp:182: warning: passing 'double' for argument 3 to 'GLint gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c gui.cpp -o gui.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c init.cpp -o init.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c par3d.cpp -o par3d.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c pixmap.cpp -o pixmap.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c platform.cpp -o platform.o
> gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -g -O2  -c pretty.c -o pretty.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c render.cpp -o render.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c rglmath.cpp -o rglmath.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c rglview.cpp -o rglview.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c scene.cpp -o scene.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c select.cpp -o select.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c subscene.cpp -o subscene.o
> subscene.cpp: In member function 'void rgl::Subscene::setupViewport(rgl::RenderContext*)':
> subscene.cpp:736: warning: converting to 'int' from 'double'
> subscene.cpp:737: warning: converting to 'int' from 'double'
> subscene.cpp:738: warning: converting to 'int' from 'double'
> subscene.cpp:739: warning: converting to 'int' from 'double'
> subscene.cpp:741: warning: converting to 'int' from 'double'
> subscene.cpp:742: warning: converting to 'int' from 'double'
> subscene.cpp:743: warning: converting to 'int' from 'double'
> subscene.cpp:744: warning: converting to 'int' from 'double'
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c win32gui.cpp -o win32gui.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c win32lib.cpp -o win32lib.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c x11gui.cpp -o x11gui.o
> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden -fpic  -g -O2  -c x11lib.cpp -o x11lib.o
> g++ -shared -L/files3/R/R-3.2.1_install/lib64/R/lib -L/usr/local/lib64 -o rgl.so ABCLineSet.o BBoxDeco.o Background.o ClipPlane.o Color.o Disposable.o Light.o LineSet.o LineStripSet.o Material.o NULLgui.o PlaneSet.o PointSet.o PrimitiveSet.o RenderContext.o Shape.o SphereMesh.o SphereSet.o SpriteSet.o String.o Surface.o TextSet.o Texture.o Viewpoint.o api.o assert.o callbacks.o device.o devicemanager.o fps.o ftgl.o geom.o gl2ps.o glErrors.o glgui.o gui.o init.o par3d.o pixmap.o platform.o pretty.o render.o rglmath.o rglview.o scene.o select.o subscene.o win32gui.o win32lib.o x11gui.o x11lib.o -lGLU -lGL -L/usr/lib64 -lpng12 -lX11 -lfreetype -L/files3/R/R-3.2.1_install/lib64/R/lib -lR
> installing to /files3/R/R-3.2.1_install/rgl.Rcheck/rgl/libs
> ** R
> ** demo
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> sh: line 1: 11949 Segmentation fault      '/files3/R/R-3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 < '/tmp/RtmpQCpp6N/file2b115f4f8e1d'
> 
>  *** caught segfault ***
> address (nil), cause 'memory not mapped'
> aborting ...
> ERROR: loading failed
> * removing '/files3/R/R-3.2.1_install/rgl.Rcheck/rgl'
> 
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA  USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From evansochiaga at aims.ac.za  Sat Aug  8 20:14:00 2015
From: evansochiaga at aims.ac.za (Evans)
Date: Sat, 8 Aug 2015 11:14:00 -0700 (PDT)
Subject: [R] Recursive looping of a list in R
Message-ID: <1439057640651-4710898.post@n4.nabble.com>

I am trying to creat a list from a loop such that once you loop the value
obtained is appended onto the list, then you loop through that value to give
the next elemet of the list and the system continues recusively. To be clear
I am creating a list to contain elements of the following tree
probabilities;
<http://r.789695.n4.nabble.com/file/n4710898/help.png> . The elements of the
diagram should be presented in a list such that each level of the tree
represents elements in the list (only the coefficients are of interest). I
have this code to start with

j <- 0

while(j >= 0){
  
  j <- j+1
  
  occlist <- list(1)
  
  for(i in occlist[[j]]){
    
    occ_cell <- seq(i, i+1, by = 1)
    
    occllist <- list(occ_cell)
    
    occunlist <- as.vector(unlist(occllist, recursive = TRUE))
    
    occlist[[j]] <- occunlist
    
    print(occlist)
    
  }
}

Any assistance will be highly appreciated. Thanks.



--
View this message in context: http://r.789695.n4.nabble.com/Recursive-looping-of-a-list-in-R-tp4710898.html
Sent from the R help mailing list archive at Nabble.com.


From dingernikita at gmail.com  Sat Aug  8 22:19:51 2015
From: dingernikita at gmail.com (Nikita Dinger)
Date: Sun, 9 Aug 2015 01:49:51 +0530
Subject: [R] Errors --> Windows 8- R version 3.2.1
Message-ID: <CAN6BBTTzLaQ6SEf6a7QQSfXAACmQeZuu-31g1g29A_hfwj1zqQ@mail.gmail.com>

Have saved text files in the same working directory as well as in the
desktop.
I am still unable to read url or files in R.

Screenshot of the commands given by me in R are attached herewith.

The version of R I am using is 3.2.1 on a Windows 8 laptop.

Thanks for the help.

Regards,
Nikita Dinger
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot 2015-08-09 01.36.30.png
Type: image/png
Size: 118849 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150809/3a6a4c04/attachment.png>

From shouro at gmail.com  Sat Aug  8 22:59:35 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Sat, 8 Aug 2015 22:59:35 +0200
Subject: [R] Installing RGDAL on CentOS v.6.2
Message-ID: <CAMx+UYc-FsJxsBCBX8+nMrrKXV2qYZLP5yRPLn7WByf6ZPK3rA@mail.gmail.com>

Dear all,

I have access to an IBM IDataplex Cluster with CentOS v.6.2. R 3.2.1 is
currently installed. I was wondering if there was any way to install RGDAL
on it? Thanks!

Sincerely,

Shouro

	[[alternative HTML version deleted]]


From dingernikita at gmail.com  Sat Aug  8 22:44:55 2015
From: dingernikita at gmail.com (Nikita Dinger)
Date: Sun, 9 Aug 2015 02:14:55 +0530
Subject: [R] Error in rep in matrix - Windows 8- R 3.2.1
Message-ID: <CAN6BBTQCW2R+mQuK_ajMxwprbwhUK_312nSwSpNnKEPsvMo6zw@mail.gmail.com>

 y <- matrix(rep(10,4),2,2)
> y
     [,1] [,2]
[1,]   10   10
[2,]   10   10



I expected an output of
> y
     [,1] [,2]
[1,]   10   4
[2,]   10   4



Thanks and Regards.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Aug  8 23:17:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 8 Aug 2015 14:17:18 -0700
Subject: [R] Error in rep in matrix - Windows 8- R 3.2.1
In-Reply-To: <CAN6BBTQCW2R+mQuK_ajMxwprbwhUK_312nSwSpNnKEPsvMo6zw@mail.gmail.com>
References: <CAN6BBTQCW2R+mQuK_ajMxwprbwhUK_312nSwSpNnKEPsvMo6zw@mail.gmail.com>
Message-ID: <93456FAE-DD56-4F8A-A98B-83F74966E1A9@comcast.net>


On Aug 8, 2015, at 1:44 PM, Nikita Dinger wrote:

> y <- matrix(rep(10,4),2,2)
>> y
>     [,1] [,2]
> [1,]   10   10
> [2,]   10   10
> 
> 
> 
> I expected an output of
>> y
>     [,1] [,2]
> [1,]   10   4
> [2,]   10   4
> 

When you get something you don't expect, you should start by examining the arguments. Type this at your console:

rep(10,4)

It should then be obvious that you need to read the help page for `rep`.

-- 
David.
> 
> 
> Thanks and Regards.
> 
> 	[[alternative HTML version deleted]]

And do read the Posting guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Scott.Waichler at pnnl.gov  Sat Aug  8 23:19:40 2015
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Sat, 8 Aug 2015 21:19:40 +0000
Subject: [R] Can't install rgl:  installed package can't be loaded;
 'memory not mapped'
In-Reply-To: <55C65DDF.8080309@gmail.com>
References: <074C83DAD4825242A20B2D83FDBCB8881A05A5C1@EX10MBOX03.pnnl.gov>
	<55C65DDF.8080309@gmail.com>
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881A05A616@EX10MBOX03.pnnl.gov>

> > Hi, I can't install package rgl.  The last lines from the install process  talking
> about the error are:
> 
> I'd guess you have an OpenGL problem.  Does glxgears run?

Yes, it does.  I wasn't aware of the program before you mentioned it, but a display opens with 3 gears and here is some output:
[root at hokulea R-3.2.1_install]# glxgears -info
GL_RENDERER   = Mesa GLX Indirect
GL_VERSION    = 1.2 (1.5 Mesa 6.5.1)
GL_VENDOR     = Mesa project: www.mesa3d.org
GL_EXTENSIONS = GL_ARB_depth_texture GL_ARB_imaging GL_ARB_multitexture GL_ARB_point_parameters GL_ARB_point_sprite GL_ARB_shadow GL_ARB_texture_border_clamp GL_ARB_texture_cube_map GL_ARB_texture_env_add GL_ARB_texture_env_combine GL_ARB_texture_env_crossbar GL_ARB_texture_env_dot3 GL_ARB_texture_mirrored_repeat GL_ARB_texture_non_power_of_two GL_ARB_window_pos GL_EXT_abgr GL_EXT_bgra GL_EXT_blend_color GL_EXT_blend_func_separate GL_EXT_blend_minmax GL_EXT_blend_subtract GL_EXT_draw_range_elements GL_EXT_framebuffer_object GL_EXT_fog_coord GL_EXT_multi_draw_arrays GL_EXT_packed_pixels GL_EXT_rescale_normal GL_EXT_secondary_color GL_EXT_separate_specular_color GL_EXT_shadow_funcs GL_EXT_stencil_wrap GL_EXT_texture3D GL_EXT_texture_edge_clamp GL_EXT_texture_env_add GL_EXT_texture_env_combine GL_EXT_texture_env_dot3 GL_EXT_texture_lod_bias GL_EXT_texture_object GL_EXT_vertex_array GL_ATI_texture_mirror_once GL_IBM_texture_mirrored_repeat GL_NV_blend_square GL_NV_texture_rectangle GL_NV_texgen_reflection GL_SGIS_generate_mipmap GL_SGIS_texture_lod GL_SGIX_depth_texture GL_SGIX_shadow
24839 frames in 6.0 seconds = 4153.389 FPS
7152 frames in 6.0 seconds = 1192.594 FPS
. . . 

Scott


> > ** testing if installed package can be loaded
> > sh: line 1: 11949 Segmentation fault      '/files3/R/R-
> 3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 <
> '/tmp/RtmpQCpp6N/file2b115f4f8e1d'
> >
> >  *** caught segfault ***
> > address (nil), cause 'memory not mapped'
> > aborting ...
> > ERROR: loading failed
> >
> > I realize this is probably not an R problem, but a Google search turns up
> nothing that helps, and I'm hoping someone here can help anyway.  Below
> are my sessionInfo() output and the contents of the first file generated with
> "R CMD check rgl_0.95.1247.tar.gz".
> >
> >> sessionInfo()
> > R version 3.2.1 (2015-06-18)
> > Platform: x86_64-unknown-linux-gnu (64-bit)
> >
> > locale:
> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.1
> >
> >
> > # R CMD check rgl_0.95.1247.tar.gz
> > * installing *source* package 'rgl' ...
> > ** package 'rgl' successfully unpacked and MD5 sums checked checking
> > for gcc... gcc -std=gnu99 checking whether the C compiler works... yes
> > checking for C compiler default output file name... a.out checking for
> > suffix of executables...
> > checking whether we are cross compiling... no checking for suffix of
> > object files... o checking whether we are using the GNU C compiler...
> > yes checking whether gcc -std=gnu99 accepts -g... yes checking for gcc
> > -std=gnu99 option to accept ISO C89... none needed checking how to run
> > the C preprocessor... gcc -std=gnu99 -E checking for gcc... (cached)
> > gcc -std=gnu99 checking whether we are using the GNU C compiler...
> > (cached) yes checking whether gcc -std=gnu99 accepts -g... (cached)
> > yes checking for gcc -std=gnu99 option to accept ISO C89... (cached)
> > none needed checking whether __attribute__((visibility())) is
> > supported... yes checking whether gcc -std=gnu99 accepts
> > -fvisibility... yes checking whether  accepts -fvisibility... no
> > checking for libpng-config... yes
> > configure: using libpng-config
> > configure: using libpng dynamic linkage checking for X... libraries ,
> > headers checking GL/gl.h usability... yes checking GL/gl.h presence...
> > yes checking for GL/gl.h... yes checking GL/glu.h usability... yes
> > checking GL/glu.h presence... yes checking for GL/glu.h... yes
> > checking for glEnd in -lGL... yes checking for gluProject in -lGLU...
> > yes checking for freetype-config... yes
> > configure: using Freetype and FTGL
> > configure: creating ./config.status
> > config.status: creating src/Makevars
> > ** libs
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c ABCLineSet.cpp -o ABCLineSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c BBoxDeco.cpp -o BBoxDeco.o
> > BBoxDeco.cpp: In member function 'int rgl::AxisInfo::getNticks(float,
> float)':
> > BBoxDeco.cpp:239: warning: converting to 'int' from 'float'
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Background.cpp -o Background.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c ClipPlane.cpp -o ClipPlane.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Color.cpp -o Color.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Disposable.cpp -o Disposable.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Light.cpp -o Light.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c LineSet.cpp -o LineSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c LineStripSet.cpp -o LineStripSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Material.cpp -o Material.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c NULLgui.cpp -o NULLgui.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c PlaneSet.cpp -o PlaneSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c PointSet.cpp -o PointSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c PrimitiveSet.cpp -o PrimitiveSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c RenderContext.cpp -o RenderContext.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Shape.cpp -o Shape.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c SphereMesh.cpp -o SphereMesh.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c SphereSet.cpp -o SphereSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c SpriteSet.cpp -o SpriteSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c String.cpp -o String.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Surface.cpp -o Surface.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c TextSet.cpp -o TextSet.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Texture.cpp -o Texture.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c Viewpoint.cpp -o Viewpoint.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c api.cpp -o api.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c assert.cpp -o assert.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c callbacks.cpp -o callbacks.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c device.cpp -o device.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c devicemanager.cpp -o devicemanager.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c fps.cpp -o fps.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c ftgl.cpp -o ftgl.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c geom.cpp -o geom.o
> > gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -
> DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -
> g -O2  -c gl2ps.c -o gl2ps.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c glErrors.cpp -o glErrors.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c glgui.cpp -o glgui.o
> > glgui.cpp: In member function 'virtual void rgl::GLBitmapFont::draw(const
> char*, int, double, double, const rgl::RenderContext&)':
> > glgui.cpp:115: warning: passing 'double' for argument 3 to 'GLint
> gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
> > glgui.cpp: In constructor 'rgl::GLFTFont::GLFTFont(const char*, int, double,
> const char*)':
> > glgui.cpp:144: warning: converting to 'unsigned int' from 'double'
> > glgui.cpp: In member function 'virtual void rgl::GLFTFont::draw(const
> char*, int, double, double, const rgl::RenderContext&)':
> > glgui.cpp:182: warning: passing 'double' for argument 3 to 'GLint
> gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c gui.cpp -o gui.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c init.cpp -o init.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c par3d.cpp -o par3d.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c pixmap.cpp -o pixmap.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c platform.cpp -o platform.o
> > gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -
> DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -
> g -O2  -c pretty.c -o pretty.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c render.cpp -o render.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c rglmath.cpp -o rglmath.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c rglview.cpp -o rglview.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c scene.cpp -o scene.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c select.cpp -o select.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c subscene.cpp -o subscene.o
> > subscene.cpp: In member function 'void
> rgl::Subscene::setupViewport(rgl::RenderContext*)':
> > subscene.cpp:736: warning: converting to 'int' from 'double'
> > subscene.cpp:737: warning: converting to 'int' from 'double'
> > subscene.cpp:738: warning: converting to 'int' from 'double'
> > subscene.cpp:739: warning: converting to 'int' from 'double'
> > subscene.cpp:741: warning: converting to 'int' from 'double'
> > subscene.cpp:742: warning: converting to 'int' from 'double'
> > subscene.cpp:743: warning: converting to 'int' from 'double'
> > subscene.cpp:744: warning: converting to 'int' from 'double'
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c win32gui.cpp -o win32gui.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c win32lib.cpp -o win32lib.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c x11gui.cpp -o x11gui.o
> > g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
> -fpic  -g -O2  -c x11lib.cpp -o x11lib.o
> > g++ -shared -L/files3/R/R-3.2.1_install/lib64/R/lib -L/usr/local/lib64
> > g++ -o rgl.so ABCLineSet.o BBoxDeco.o Background.o ClipPlane.o Color.o
> > g++ Disposable.o Light.o LineSet.o LineStripSet.o Material.o NULLgui.o
> > g++ PlaneSet.o PointSet.o PrimitiveSet.o RenderContext.o Shape.o
> > g++ SphereMesh.o SphereSet.o SpriteSet.o String.o Surface.o TextSet.o
> > g++ Texture.o Viewpoint.o api.o assert.o callbacks.o device.o
> > g++ devicemanager.o fps.o ftgl.o geom.o gl2ps.o glErrors.o glgui.o
> > g++ gui.o init.o par3d.o pixmap.o platform.o pretty.o render.o
> > g++ rglmath.o rglview.o scene.o select.o subscene.o win32gui.o
> > g++ win32lib.o x11gui.o x11lib.o -lGLU -lGL -L/usr/lib64 -lpng12 -lX11
> > g++ -lfreetype -L/files3/R/R-3.2.1_install/lib64/R/lib -lR
> > installing to /files3/R/R-3.2.1_install/rgl.Rcheck/rgl/libs
> > ** R
> > ** demo
> > ** inst
> > ** preparing package for lazy loading
> > ** help
> > *** installing help indices
> > ** building package indices
> > ** installing vignettes
> > ** testing if installed package can be loaded
> > sh: line 1: 11949 Segmentation fault      '/files3/R/R-
> 3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 <
> '/tmp/RtmpQCpp6N/file2b115f4f8e1d'
> >
> >  *** caught segfault ***
> > address (nil), cause 'memory not mapped'
> > aborting ...
> > ERROR: loading failed
> > * removing '/files3/R/R-3.2.1_install/rgl.Rcheck/rgl'
> >
> > Scott Waichler
> > Pacific Northwest National Laboratory
> > Richland, WA  USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From ligges at statistik.tu-dortmund.de  Sat Aug  8 23:35:06 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 8 Aug 2015 23:35:06 +0200
Subject: [R] Errors --> Windows 8- R version 3.2.1
In-Reply-To: <CAN6BBTTzLaQ6SEf6a7QQSfXAACmQeZuu-31g1g29A_hfwj1zqQ@mail.gmail.com>
References: <CAN6BBTTzLaQ6SEf6a7QQSfXAACmQeZuu-31g1g29A_hfwj1zqQ@mail.gmail.com>
Message-ID: <55C6760A.5090907@statistik.tu-dortmund.de>

Errrr,

1. urls need to be ull qualified including the protocol such as
"http://www.facebook.com"
2. filenames are relative to the current working directory, if they are 
not in the current working directory, secify the full path.

3. read.csv() cannot read docx files....

Best,
Uwe Ligges


On 08.08.2015 22:19, Nikita Dinger wrote:
> Have saved text files in the same working directory as well as in the
> desktop.
> I am still unable to read url or files in R.
>
> Screenshot of the commands given by me in R are attached herewith.
>
> The version of R I am using is 3.2.1 on a Windows 8 laptop.
>
> Thanks for the help.
>
> Regards,
> Nikita Dinger
>
>
> Screenshot 2015-08-09 01.36.30.png
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From frainj at gmail.com  Sat Aug  8 23:35:43 2015
From: frainj at gmail.com (John C Frain)
Date: Sat, 8 Aug 2015 22:35:43 +0100
Subject: [R] Errors --> Windows 8- R version 3.2.1
In-Reply-To: <CAN6BBTTzLaQ6SEf6a7QQSfXAACmQeZuu-31g1g29A_hfwj1zqQ@mail.gmail.com>
References: <CAN6BBTTzLaQ6SEf6a7QQSfXAACmQeZuu-31g1g29A_hfwj1zqQ@mail.gmail.com>
Message-ID: <CAHrK516dEyMu0y8iDJrVZyk3it13C4jazYGApE+J_7OZ5N=viA@mail.gmail.com>

To check what your actual working directory is try

getwd()

To look a list of files in your actual working directory try

dir()

If your working directory is not what you expected change it with

setwd("path to directory")

There are several ways in Windows to ensure that R starts in the required
directory (eg double clicking on a file which starts in R in the working
directory or setting up a short cut on your desktop which starts R in that
directory, use projects in RStudio).  I usually use the setwd()  method  or
PStudio projects.

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 8 August 2015 at 21:19, Nikita Dinger <dingernikita at gmail.com> wrote:

> Have saved text files in the same working directory as well as in the
> desktop.
> I am still unable to read url or files in R.
>
> Screenshot of the commands given by me in R are attached herewith.
>
> The version of R I am using is 3.2.1 on a Windows 8 laptop.
>
> Thanks for the help.
>
> Regards,
> Nikita Dinger
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Aug  8 23:54:09 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 08 Aug 2015 17:54:09 -0400
Subject: [R] Can't install rgl:  installed package can't be loaded;
 'memory not mapped'
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB8881A05A616@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB8881A05A5C1@EX10MBOX03.pnnl.gov>
	<55C65DDF.8080309@gmail.com>
	<074C83DAD4825242A20B2D83FDBCB8881A05A616@EX10MBOX03.pnnl.gov>
Message-ID: <55C67A81.2020909@gmail.com>

On 08/08/2015 5:19 PM, Waichler, Scott R wrote:
>>> Hi, I can't install package rgl.  The last lines from the install process  talking
>> about the error are:
>>
>> I'd guess you have an OpenGL problem.  Does glxgears run?
> 
> Yes, it does.  I wasn't aware of the program before you mentioned it, but a display opens with 3 gears and here is some output:
> [root at hokulea R-3.2.1_install]# glxgears -info
> GL_RENDERER   = Mesa GLX Indirect
> GL_VERSION    = 1.2 (1.5 Mesa 6.5.1)
> GL_VENDOR     = Mesa project: www.mesa3d.org
> GL_EXTENSIONS = GL_ARB_depth_texture GL_ARB_imaging GL_ARB_multitexture GL_ARB_point_parameters GL_ARB_point_sprite GL_ARB_shadow GL_ARB_texture_border_clamp GL_ARB_texture_cube_map GL_ARB_texture_env_add GL_ARB_texture_env_combine GL_ARB_texture_env_crossbar GL_ARB_texture_env_dot3 GL_ARB_texture_mirrored_repeat GL_ARB_texture_non_power_of_two GL_ARB_window_pos GL_EXT_abgr GL_EXT_bgra GL_EXT_blend_color GL_EXT_blend_func_separate GL_EXT_blend_minmax GL_EXT_blend_subtract GL_EXT_draw_range_elements GL_EXT_framebuffer_object GL_EXT_fog_coord GL_EXT_multi_draw_arrays GL_EXT_packed_pixels GL_EXT_rescale_normal GL_EXT_secondary_color GL_EXT_separate_specular_color GL_EXT_shadow_funcs GL_EXT_stencil_wrap GL_EXT_texture3D GL_EXT_texture_edge_clamp GL_EXT_texture_env_add GL_EXT_texture_env_combine GL_EXT_texture_env_dot3 GL_EXT_texture_lod_bias GL_EXT_texture_object GL_EXT_vertex_array GL_ATI_texture_mirror_once GL_IBM_texture_mirrored_repeat GL_NV_blend_square GL_NV_texture_rectangle GL_N
V_texgen_reflection GL_SGIS_generate_mipmap GL_SGIS_texture_lod GL_SGIX_depth_texture GL_SGIX_shadow
> 24839 frames in 6.0 seconds = 4153.389 FPS
> 7152 frames in 6.0 seconds = 1192.594 FPS
> . . . 
> 

So it looks as though OpenGL is working.  I really have no idea what is
causing the error you're seeing.  rgl works for me, but I don't have a
64 bit Linux to try it on.  (It does work in 32 bit Ubuntu.)

Duncan Murdoch

> 
> 
>>> ** testing if installed package can be loaded
>>> sh: line 1: 11949 Segmentation fault      '/files3/R/R-
>> 3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 <
>> '/tmp/RtmpQCpp6N/file2b115f4f8e1d'
>>>
>>>  *** caught segfault ***
>>> address (nil), cause 'memory not mapped'
>>> aborting ...
>>> ERROR: loading failed
>>>
>>> I realize this is probably not an R problem, but a Google search turns up
>> nothing that helps, and I'm hoping someone here can help anyway.  Below
>> are my sessionInfo() output and the contents of the first file generated with
>> "R CMD check rgl_0.95.1247.tar.gz".
>>>
>>>> sessionInfo()
>>> R version 3.2.1 (2015-06-18)
>>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.2.1
>>>
>>>
>>> # R CMD check rgl_0.95.1247.tar.gz
>>> * installing *source* package 'rgl' ...
>>> ** package 'rgl' successfully unpacked and MD5 sums checked checking
>>> for gcc... gcc -std=gnu99 checking whether the C compiler works... yes
>>> checking for C compiler default output file name... a.out checking for
>>> suffix of executables...
>>> checking whether we are cross compiling... no checking for suffix of
>>> object files... o checking whether we are using the GNU C compiler...
>>> yes checking whether gcc -std=gnu99 accepts -g... yes checking for gcc
>>> -std=gnu99 option to accept ISO C89... none needed checking how to run
>>> the C preprocessor... gcc -std=gnu99 -E checking for gcc... (cached)
>>> gcc -std=gnu99 checking whether we are using the GNU C compiler...
>>> (cached) yes checking whether gcc -std=gnu99 accepts -g... (cached)
>>> yes checking for gcc -std=gnu99 option to accept ISO C89... (cached)
>>> none needed checking whether __attribute__((visibility())) is
>>> supported... yes checking whether gcc -std=gnu99 accepts
>>> -fvisibility... yes checking whether  accepts -fvisibility... no
>>> checking for libpng-config... yes
>>> configure: using libpng-config
>>> configure: using libpng dynamic linkage checking for X... libraries ,
>>> headers checking GL/gl.h usability... yes checking GL/gl.h presence...
>>> yes checking for GL/gl.h... yes checking GL/glu.h usability... yes
>>> checking GL/glu.h presence... yes checking for GL/glu.h... yes
>>> checking for glEnd in -lGL... yes checking for gluProject in -lGLU...
>>> yes checking for freetype-config... yes
>>> configure: using Freetype and FTGL
>>> configure: creating ./config.status
>>> config.status: creating src/Makevars
>>> ** libs
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c ABCLineSet.cpp -o ABCLineSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c BBoxDeco.cpp -o BBoxDeco.o
>>> BBoxDeco.cpp: In member function 'int rgl::AxisInfo::getNticks(float,
>> float)':
>>> BBoxDeco.cpp:239: warning: converting to 'int' from 'float'
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Background.cpp -o Background.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c ClipPlane.cpp -o ClipPlane.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Color.cpp -o Color.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Disposable.cpp -o Disposable.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Light.cpp -o Light.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c LineSet.cpp -o LineSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c LineStripSet.cpp -o LineStripSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Material.cpp -o Material.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c NULLgui.cpp -o NULLgui.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c PlaneSet.cpp -o PlaneSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c PointSet.cpp -o PointSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c PrimitiveSet.cpp -o PrimitiveSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c RenderContext.cpp -o RenderContext.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Shape.cpp -o Shape.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c SphereMesh.cpp -o SphereMesh.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c SphereSet.cpp -o SphereSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c SpriteSet.cpp -o SpriteSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c String.cpp -o String.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Surface.cpp -o Surface.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c TextSet.cpp -o TextSet.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Texture.cpp -o Texture.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c Viewpoint.cpp -o Viewpoint.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c api.cpp -o api.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c assert.cpp -o assert.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c callbacks.cpp -o callbacks.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c device.cpp -o device.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c devicemanager.cpp -o devicemanager.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c fps.cpp -o fps.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c ftgl.cpp -o ftgl.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c geom.cpp -o geom.o
>>> gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -
>> DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -
>> g -O2  -c gl2ps.c -o gl2ps.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c glErrors.cpp -o glErrors.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c glgui.cpp -o glgui.o
>>> glgui.cpp: In member function 'virtual void rgl::GLBitmapFont::draw(const
>> char*, int, double, double, const rgl::RenderContext&)':
>>> glgui.cpp:115: warning: passing 'double' for argument 3 to 'GLint
>> gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
>>> glgui.cpp: In constructor 'rgl::GLFTFont::GLFTFont(const char*, int, double,
>> const char*)':
>>> glgui.cpp:144: warning: converting to 'unsigned int' from 'double'
>>> glgui.cpp: In member function 'virtual void rgl::GLFTFont::draw(const
>> char*, int, double, double, const rgl::RenderContext&)':
>>> glgui.cpp:182: warning: passing 'double' for argument 3 to 'GLint
>> gl2psTextOpt(const char*, const char*, GLshort, GLint, GLfloat)'
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c gui.cpp -o gui.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c init.cpp -o init.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c par3d.cpp -o par3d.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c pixmap.cpp -o pixmap.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c platform.cpp -o platform.o
>>> gcc -std=gnu99 -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -
>> DHAVE_PNG_H -I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -fvisibility=hidden -fpic  -
>> g -O2  -c pretty.c -o pretty.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c render.cpp -o render.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c rglmath.cpp -o rglmath.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c rglview.cpp -o rglview.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c scene.cpp -o scene.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c select.cpp -o select.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c subscene.cpp -o subscene.o
>>> subscene.cpp: In member function 'void
>> rgl::Subscene::setupViewport(rgl::RenderContext*)':
>>> subscene.cpp:736: warning: converting to 'int' from 'double'
>>> subscene.cpp:737: warning: converting to 'int' from 'double'
>>> subscene.cpp:738: warning: converting to 'int' from 'double'
>>> subscene.cpp:739: warning: converting to 'int' from 'double'
>>> subscene.cpp:741: warning: converting to 'int' from 'double'
>>> subscene.cpp:742: warning: converting to 'int' from 'double'
>>> subscene.cpp:743: warning: converting to 'int' from 'double'
>>> subscene.cpp:744: warning: converting to 'int' from 'double'
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c win32gui.cpp -o win32gui.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c win32lib.cpp -o win32lib.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c x11gui.cpp -o x11gui.o
>>> g++ -I/files3/R/R-3.2.1_install/lib64/R/include -DNDEBUG -DHAVE_PNG_H -
>> I/usr/include/libpng12 -DHAVE_FREETYPE -Iext/ftgl -
>> I/usr/include/freetype2 -Iext -I/usr/local/include   -g -O2 -fvisibility=hidden
>> -fpic  -g -O2  -c x11lib.cpp -o x11lib.o
>>> g++ -shared -L/files3/R/R-3.2.1_install/lib64/R/lib -L/usr/local/lib64
>>> g++ -o rgl.so ABCLineSet.o BBoxDeco.o Background.o ClipPlane.o Color.o
>>> g++ Disposable.o Light.o LineSet.o LineStripSet.o Material.o NULLgui.o
>>> g++ PlaneSet.o PointSet.o PrimitiveSet.o RenderContext.o Shape.o
>>> g++ SphereMesh.o SphereSet.o SpriteSet.o String.o Surface.o TextSet.o
>>> g++ Texture.o Viewpoint.o api.o assert.o callbacks.o device.o
>>> g++ devicemanager.o fps.o ftgl.o geom.o gl2ps.o glErrors.o glgui.o
>>> g++ gui.o init.o par3d.o pixmap.o platform.o pretty.o render.o
>>> g++ rglmath.o rglview.o scene.o select.o subscene.o win32gui.o
>>> g++ win32lib.o x11gui.o x11lib.o -lGLU -lGL -L/usr/lib64 -lpng12 -lX11
>>> g++ -lfreetype -L/files3/R/R-3.2.1_install/lib64/R/lib -lR
>>> installing to /files3/R/R-3.2.1_install/rgl.Rcheck/rgl/libs
>>> ** R
>>> ** demo
>>> ** inst
>>> ** preparing package for lazy loading
>>> ** help
>>> *** installing help indices
>>> ** building package indices
>>> ** installing vignettes
>>> ** testing if installed package can be loaded
>>> sh: line 1: 11949 Segmentation fault      '/files3/R/R-
>> 3.2.1_install/lib64/R/bin/R' --no-save --slave 2>&1 <
>> '/tmp/RtmpQCpp6N/file2b115f4f8e1d'
>>>
>>>  *** caught segfault ***
>>> address (nil), cause 'memory not mapped'
>>> aborting ...
>>> ERROR: loading failed
>>> * removing '/files3/R/R-3.2.1_install/rgl.Rcheck/rgl'
>>>
>>> Scott Waichler
>>> Pacific Northwest National Laboratory
>>> Richland, WA  USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>


From drjimlemon at gmail.com  Sun Aug  9 00:33:54 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 9 Aug 2015 08:33:54 +1000
Subject: [R] Recursive looping of a list in R
In-Reply-To: <1439057640651-4710898.post@n4.nabble.com>
References: <1439057640651-4710898.post@n4.nabble.com>
Message-ID: <CA+8X3fWrhYFtYrckbx4Q_9bVfTFt5jNRWsV8y6=O=hPqAgMT6Q@mail.gmail.com>

Hi Evans,
I'm not sure whether this is what you want, but look at the code in
the listBuilder and listCrawler functions in the crank package.

Jim


On Sun, Aug 9, 2015 at 4:14 AM, Evans <evansochiaga at aims.ac.za> wrote:
> I am trying to creat a list from a loop such that once you loop the value
> obtained is appended onto the list, then you loop through that value to give
> the next elemet of the list and the system continues recusively. To be clear
> I am creating a list to contain elements of the following tree
> probabilities;
> <http://r.789695.n4.nabble.com/file/n4710898/help.png> . The elements of the
> diagram should be presented in a list such that each level of the tree
> represents elements in the list (only the coefficients are of interest). I
> have this code to start with
>
> j <- 0
>
> while(j >= 0){
>
>   j <- j+1
>
>   occlist <- list(1)
>
>   for(i in occlist[[j]]){
>
>     occ_cell <- seq(i, i+1, by = 1)
>
>     occllist <- list(occ_cell)
>
>     occunlist <- as.vector(unlist(occllist, recursive = TRUE))
>
>     occlist[[j]] <- occunlist
>
>     print(occlist)
>
>   }
> }
>
> Any assistance will be highly appreciated. Thanks.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Recursive-looping-of-a-list-in-R-tp4710898.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Aug  9 03:22:19 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 9 Aug 2015 11:22:19 +1000
Subject: [R] creating a funct
In-Reply-To: <FB7432CF5DF.000003D0jrkrideau@inbox.com>
References: <CANuuowPe_e2COTo1ob-VzMDHjyqeyDtx1m4730Mzt75RcaV0aQ@mail.gmail.com>
	<FB7432CF5DF.000003D0jrkrideau@inbox.com>
Message-ID: <CA+8X3fU4UUcvUfqf-HBp3G_5=LnCBOwvx2VxH0mFeAu2mUp72g@mail.gmail.com>

Hi Jose,
It looks like it is time for a bit of guessing. For one thing, if you
try to "attach" an R script you will get an error. I will assume that
you really used "source" as you seem to have gotten past that step.
You later mention a connection error when you try to execute the
command. As you sent what looks like a TAB separated data file,
perhaps you didn't specify where the data file is correctly. So, if
your data file is stored like this:

/home/jose/data/mydata.tab

your R session is in this directory:

getwd()
 /home/jose/R

and you have a command line like this:

mydata.df<-read.table("mydata.tab",sep="\t")

you will get a connection error because R is trying to find:

/home/jose/R/mydata.tab

and it is not there. Finally, it is really helpful if you copy the
error messages that you get into your email, even if they are in
Spanish. Seguir intentando y buena suerte

On Sun, Aug 9, 2015 at 12:04 AM, John Kane <jrkrideau at inbox.com> wrote:
> You sent the data but forgot the code :)
>
> It is better to use dput() to send data. Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: betanster at gmail.com
>> Sent: Sat, 8 Aug 2015 00:23:23 +0200
>> To: r-help at r-project.org
>> Subject: [R] creating a funct
>>
>> Dear
>>
>> i am develeping a function, first  I attach r command and later r
>> executer
>> script, the conection fails and I do not realize why
>>
>> best regards
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alexgade at utexas.edu  Sun Aug  9 01:32:36 2015
From: alexgade at utexas.edu (RUkidding)
Date: Sat, 8 Aug 2015 16:32:36 -0700 (PDT)
Subject: [R] regularized dfa rda (Klar): problems with predictions
In-Reply-To: <20110227215928.3C3CF4FD31@c-in3ws--03-06.sv2.lotuslive.com>
References: <20110227215928.3C3CF4FD31@c-in3ws--03-06.sv2.lotuslive.com>
Message-ID: <1439076756417-4710913.post@n4.nabble.com>

Daniel Stahl-2 wrote
> Error in predict.rda(z, data = test[testset, ]) : 
>   A new data to predict must be supplied.

For anyone encountering this problem, it stems from having both the klaR and
rda libraries loaded. rda gives this error message because its predict.rda
is defined:

function (object, x, y, xnew, prior, alpha, delta, type = c("class",
"posterior", "nonzero"), trace = FALSE, ...) 

and 

if (missing(xnew)) { 
stop("A new data to predict must be supplied.") 
}

unload the rda package:
detach("package:rda", unload=TRUE)



--
View this message in context: http://r.789695.n4.nabble.com/regularized-dfa-rda-Klar-problems-with-predictions-tp3327188p4710913.html
Sent from the R help mailing list archive at Nabble.com.


From brown at fastmail.com  Sun Aug  9 04:31:20 2015
From: brown at fastmail.com (Eric Brown)
Date: Sat, 08 Aug 2015 21:31:20 -0500
Subject: [R] Installing RGDAL on CentOS v.6.2
In-Reply-To: <CAMx+UYc-FsJxsBCBX8+nMrrKXV2qYZLP5yRPLn7WByf6ZPK3rA@mail.gmail.com>
	(Shouro Dasgupta's message of "Sat, 8 Aug 2015 22:59:35 +0200")
References: <CAMx+UYc-FsJxsBCBX8+nMrrKXV2qYZLP5yRPLn7WByf6ZPK3rA@mail.gmail.com>
Message-ID: <m2tws9ry4n.fsf@fastmail.com>

Dear Shouro,

I can confirm that I have installed GDAL (and RGDAL) on CentOS 
6.4, 6.5,
and 6.6.

But quite frankly, these systems have such old versions of 
software that
I spent a fair amount of time compiling everything up from tar.gz.

This is exhausting, so I spent some time learning NetBSD's 
pkgsrc--and
now recommend this wonderful package manager to anyone caught in a
situation where they don't have root privileges, but need to bring 
an
old CentOS to have modern versions of software and all its 
dependencies.

Best regards,
Eric

Shouro Dasgupta <shouro at gmail.com> writes:

> Dear all,
>
> I have access to an IBM IDataplex Cluster with CentOS v.6.2. R 
> 3.2.1 is
> currently installed. I was wondering if there was any way to 
> install RGDAL
> on it? Thanks!
>
> Sincerely,
>
> Shouro
>
> 	[[alternative HTML version deleted]]


From shouro at gmail.com  Sun Aug  9 11:30:28 2015
From: shouro at gmail.com (Shouro Dasgupta)
Date: Sun, 9 Aug 2015 11:30:28 +0200
Subject: [R] Installing RGDAL on CentOS v.6.2
In-Reply-To: <m2tws9ry4n.fsf@fastmail.com>
References: <CAMx+UYc-FsJxsBCBX8+nMrrKXV2qYZLP5yRPLn7WByf6ZPK3rA@mail.gmail.com>
	<m2tws9ry4n.fsf@fastmail.com>
Message-ID: <CAMx+UYdLB_jGbxZQhVUB0NaDj3sCKeVq+N33wtKevW+OF0WQfA@mail.gmail.com>

Dear Eric,

Thank you for your reply. Unfortunately, I don't have NetBSD on the cluster
and considering the size of my dataset, I can't utilise my local machine.

Does it make a difference that the R installed on the cluster is up-to-date
if I do want to compile everything from tar.gz? Thanks again.

Sincerely,

Shouro

On Sun, Aug 9, 2015 at 4:31 AM, Eric Brown <brown at fastmail.com> wrote:

> Dear Shouro,
>
> I can confirm that I have installed GDAL (and RGDAL) on CentOS 6.4, 6.5,
> and 6.6.
>
> But quite frankly, these systems have such old versions of software that
> I spent a fair amount of time compiling everything up from tar.gz.
>
> This is exhausting, so I spent some time learning NetBSD's pkgsrc--and
> now recommend this wonderful package manager to anyone caught in a
> situation where they don't have root privileges, but need to bring an
> old CentOS to have modern versions of software and all its dependencies.
>
> Best regards,
> Eric
>
> Shouro Dasgupta <shouro at gmail.com> writes:
>
> Dear all,
>>
>> I have access to an IBM IDataplex Cluster with CentOS v.6.2. R 3.2.1 is
>> currently installed. I was wondering if there was any way to install RGDAL
>> on it? Thanks!
>>
>> Sincerely,
>>
>> Shouro
>>
>>         [[alternative HTML version deleted]]
>>
>


-- 

*Shouro Dasgupta*
PhD Candidate
Science and Management of Climate Change
Department of Economics | Ca' Foscari University of Venice
-------------------------------------------------------------------------------------------------------
Junior Researcher
Fondazione Eni Enrico Mattei (FEEM) | Centro Euro-Mediterraneo per i
Cambiamenti Climatici (CMCC)
Isola di San Giorgio Maggiore, 8
30124 Venezia
Phone: +39 041 2700 436

	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Sun Aug  9 11:49:52 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Sun, 9 Aug 2015 11:49:52 +0200 (MEST)
Subject: [R] Recursive looping of a list in R
In-Reply-To: <1439057640651-4710898.post@n4.nabble.com>
References: <1439057640651-4710898.post@n4.nabble.com>
Message-ID: <Pine.SOC.4.64.1508091134400.7259@solcom.hrz.uni-giessen.de>

Hi Evans,

not many people (incl. me) are going to guess the building law for your 
recursive structure from the -- in fact at first sight not so clear -- 
picture, but I have some comments inline below.

  Hth  --  Gerrit

> I am trying to creat a list from a loop such that once you loop the 
> value obtained is appended onto the list, then you loop through that 
> value to give the next elemet of the list and the system continues 
> recusively. To be clear I am creating a list to contain elements of the 
> following tree probabilities; 
> <http://r.789695.n4.nabble.com/file/n4710898/help.png> .
> The elements of the diagram should be presented in a list such that each 
> level of the tree represents elements in the list (only the coefficients 
> are of interest). I have this code to start with


If you use a while-loop without a termination criterion and, e.g., a call 
to break, in its body it would run forever (if the code in its body were 
correct). Start coding with a (finite) for-loop. (Or even better start 
setting j and i "by hand" and let your code be evaluated step by step.)

> j <- 0
>
> while(j >= 0){
>
>  j <- j+1


Here you create in each loop the same starting list (which I guess is not 
what you want/should):

>  occlist <- list(1)


So, as a consequence an error occurs for j >= 2 in the following for-loop, 
because occlist has always only 1 component:

>  for(i in occlist[[j]]){
>
>    occ_cell <- seq(i, i+1, by = 1)


The following two lines of code compensate each other, so seem to be 
superfluous:

>    occllist <- list(occ_cell)
>
>    occunlist <- as.vector(unlist(occllist, recursive = TRUE))



>    occlist[[j]] <- occunlist
>
>    print(occlist)
>
>  }
> }
>
> Any assistance will be highly appreciated. Thanks.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Recursive-looping-of-a-list-in-R-tp4710898.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From brown at fastmail.com  Sun Aug  9 19:54:39 2015
From: brown at fastmail.com (Eric Brown)
Date: Sun, 09 Aug 2015 12:54:39 -0500
Subject: [R] Installing RGDAL on CentOS v.6.2
In-Reply-To: <CAMx+UYdLB_jGbxZQhVUB0NaDj3sCKeVq+N33wtKevW+OF0WQfA@mail.gmail.com>
	(Shouro Dasgupta's message of "Sun, 9 Aug 2015 11:30:28 +0200")
References: <CAMx+UYc-FsJxsBCBX8+nMrrKXV2qYZLP5yRPLn7WByf6ZPK3rA@mail.gmail.com>
	<m2tws9ry4n.fsf@fastmail.com>
	<CAMx+UYdLB_jGbxZQhVUB0NaDj3sCKeVq+N33wtKevW+OF0WQfA@mail.gmail.com>
Message-ID: <m2k2t49wkg.fsf@air.T-mobile.com>

Dear Shouro,

I should have mentioned that pkgsrc is cross-platform, and not
restricted to the NetBSD OS.  I use pkgsrc on my CentOS machines 
to
provide up-to-date software.  Since sysadmins tend to be 
conservative
about what they will install on computers, I end up installing my 
own
software into my own personal directory.

I don't think that the version of R is indicative of whether proj4 
and
gdal will compile. IIRC, I had to install a number of dependencies 
to be
able to build these from source.

It might be worthwhile to see if your sysadmin will install gdal 
and
proj4 from the CentOS distro.  These will probably be quite "old" 
--
though they may be enough for your needs.  Alternatively, there 
are some
third-party repositories for up-to-date software for CentOS, 
including
EPEL and ELGIS, the latter especially targeted toward geospatial
modeling.

Best regards,
Eric

Shouro Dasgupta <shouro at gmail.com> writes:

> Dear Eric,
>
> Thank you for your reply. Unfortunately, I don't have NetBSD on 
> the cluster
> and considering the size of my dataset, I can't utilise my local 
> machine.
>
> Does it make a difference that the R installed on the cluster is 
> up-to-date
> if I do want to compile everything from tar.gz? Thanks again.
>
> Sincerely,
>
> Shouro
>


From boredstoog at mailinator.com  Sun Aug  9 10:46:48 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Sun, 9 Aug 2015 01:46:48 -0700 (PDT)
Subject: [R] inbuilt crossover function for backtesting
Message-ID: <1439110008152-4710918.post@n4.nabble.com>

I am trying to built a simple moving average cross over strategy for
backtesting. I have installed TTR and quantmod, quantstrat for that purpose.
>From TTR package we can get functions for sma,bolinger band and other
indicators. I want to know whether any inbuilt crossover function (not
greater '>' or lesser '<') is available for R.

Example

sma10<-SMA(close,10)
sma30<-SMA(close,30)

buy<-Crossover(sma10,sma30)
sell<-Crossover(sma30,sma10)






--
View this message in context: http://r.789695.n4.nabble.com/inbuilt-crossover-function-for-backtesting-tp4710918.html
Sent from the R help mailing list archive at Nabble.com.


From boredstoog at mailinator.com  Sun Aug  9 10:53:05 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Sun, 9 Aug 2015 01:53:05 -0700 (PDT)
Subject: [R] Automatically updating a WordPress blog from R
In-Reply-To: <1439080529295-4710914.post@n4.nabble.com>
References: <1439080529295-4710914.post@n4.nabble.com>
Message-ID: <1439110385199-4710919.post@n4.nabble.com>

I dont know whether this will help you because even I am also pretty new to R
but have some experience in web development. I would recommend you to read
about "cron jobs" . cron jobs automate your request and execute according to
your execution parameters (1 minute, 3.5 days etc)



--
View this message in context: http://r.789695.n4.nabble.com/Automatically-updating-a-WordPress-blog-from-R-tp4710914p4710919.html
Sent from the R help mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Mon Aug 10 03:13:15 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 9 Aug 2015 20:13:15 -0500
Subject: [R] inbuilt crossover function for backtesting
In-Reply-To: <1439110008152-4710918.post@n4.nabble.com>
References: <1439110008152-4710918.post@n4.nabble.com>
Message-ID: <CAPPM_gSgAgvhTDVUwYBtMv+u8XBn3S5uUwh-LsoopU_2wWVzhA@mail.gmail.com>

On Sun, Aug 9, 2015 at 3:46 AM, boredstoog via R-help
<r-help at r-project.org> wrote:
> I am trying to built a simple moving average cross over strategy for
> backtesting. I have installed TTR and quantmod, quantstrat for that purpose.
> >From TTR package we can get functions for sma,bolinger band and other
> indicators. I want to know whether any inbuilt crossover function (not
> greater '>' or lesser '<') is available for R.
>
help.search("crossover") would have lead you to quantstrat::sigCrossover.

require(quantstrat)
getSymbols("SPY")
SPY$sma10 <- SMA(Cl(SPY),10)
SPY$sma30 <- SMA(Cl(SPY),30)
buy <- sigCrossover("buy", SPY, c("sma10","sma30"), "gt")
sell <- sigCrossover("sell", SPY, c("sma30","sma10"), "lt")

> Example
>
> sma10<-SMA(close,10)
> sma30<-SMA(close,30)
>
> buy<-Crossover(sma10,sma30)
> sell<-Crossover(sma30,sma10)
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/inbuilt-crossover-function-for-backtesting-tp4710918.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From ragia11 at hotmail.com  Mon Aug 10 05:45:59 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 10 Aug 2015 06:45:59 +0300
Subject: [R] result NA , but expected True or False
In-Reply-To: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>
References: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>
Message-ID: <DUB125-W91C972100E24493CABA989B3700@phx.gbl>

Dear Group,
Kindly,

I have those two lines
if(  (z_nebla==0) ||  (z_nebla_dash==0) )
           CM <- 0         else             
            
               CM <-  0.5 *(1/a)  +   0.5*(1/b)  

when running it

I got this

z_nebla==0)
logical(0)
> (z_nebla_dash==0)
logical(0)
> (z_nebla==0) ||  (z_nebla_dash==0)
[1] NA


why  (z_nebla==0) ||  (z_nebla_dash==0)
gives me NA ?

thanks in advance
Ragia

 		 	   		  
	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Mon Aug 10 06:42:15 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 10 Aug 2015 07:42:15 +0300
Subject: [R] Data frame Q
In-Reply-To: <DUB125-W91C972100E24493CABA989B3700@phx.gbl>
References: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>,
	<DUB125-W91C972100E24493CABA989B3700@phx.gbl>
Message-ID: <DUB125-W49BC987BD7C478DCA7220FB3700@phx.gbl>

 



Dear Group,
Kindly,
 I have the following 

Common_Friends <- intersect(node_neighbours_i_out,node_neighbours_j_out)
         class(Common_Friends)
         print(Common_Friends)
         #4 = Common_Friends
       newline<-c(i,   Common_Friends  )
 df<- rbind(df,newline)

I created a data frame to add the new line

when   Common_Friends  =0 nothing add ?, how to force it to write the value into the data frame


Common_Friends <- intersect(node_neighbours_i_out,node_neighbours_j_out)
>          class(Common_Friends)
[1] "numeric"
>          print(Common_Friends)
numeric(0)

>        newline<-c(i,   Common_Friends  )
> newline
[1] 5
thanks in advance
Ragia

 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From anshuk.p at motivitylabs.com  Mon Aug 10 07:24:29 2015
From: anshuk.p at motivitylabs.com (Anshuk Pal Chaudhuri)
Date: Mon, 10 Aug 2015 05:24:29 +0000
Subject: [R] Parsing all rows & columns of a Dataframe into one column
Message-ID: <HKXPR02MB06321FDA97E5C1E23E4D2601F0700@HKXPR02MB0632.apcprd02.prod.outlook.com>

Hi All,


I am using R for reading certain values in a dataset.

I have values in a data frame all scattered in different columns & rows, some values might be NA as well.

e.g. below three columns V1, V2,V3, and their respective values.
V1

    V2

    V2

NA

    NA

90

abc

89.09

$50

76799

NA

    NA

02:15

def

1




What I would like to do is parse this data frame, create a new data frame, omit all NA values. The new data frame would have one column, lets say Value column. (order of the samples coming is not an issue)

New Data Frame (Output Required):


Value

abc

76799

02:15

89.09

def

90

$50

1




Any help would be appreciated.

Regards,
Anshuk Pal Chaudhuri


	[[alternative HTML version deleted]]


From rhelp10 at gmail.com  Mon Aug 10 06:05:27 2015
From: rhelp10 at gmail.com (DJ L)
Date: Mon, 10 Aug 2015 00:05:27 -0400
Subject: [R] Plotting wind direction as arrows with precipitation
Message-ID: <CAGphrqrBe91PrqXw2e3SaPybs_FP4ZOVxixY7yStbmg-Cje5-A@mail.gmail.com>

Hello R users!

I am trying to create a time series in R with two variables, precipitation
and wind direction vs Date/Time.

I am looking for suggestions and maybe even sample code.

My workbook is called "Sandy" and has columns with Date/Time, Raindall_cm,
Wind Direction in both degree format (0-359) and in character form (N, NW,
S, SW, SE, E, NE, NW).

I have done some reading for it on stackoverflow and other sites but not
making head way.

I will be graphing with ggplot most likely and am a beginner in R, self
taught from books and online resources.

This is the code I have and a small peak into the data.

Sandy<-read.csv("Sandy.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
> head(Sandy)
      Deal1     Rainfall_cm    Wind_Direction1 Wind_Direction2
1 10/22/2012 0:00           0        296         W
2 10/22/2012 0:15           0        317        NW
3 10/22/2012 0:30           0        323        NW
4 10/22/2012 0:45           0        323        NW
5 10/22/2012 1:00           0        326        NW
6 10/22/2012 1:15           0        326        NW

> class(Sandy)
[1] "data.frame"

> str(Sandy)
'data.frame':   1832 obs. of  4 variables:
 $ Deal1         : chr  "10/22/2012 0:00" "10/22/2012 0:15" "10/22/2012
0:30" "10/22/2012 0:45" ...
 $ Rainfall_cm   : num  0 0 0 0 0 0 0 0 0 0 ...

 $ Wind_Direction: num 296 317  323   323  326  326

 $ Wind_Direction: chr  "W" "NW" "NW" "NW" ...

> require(ggplot2)
Loading required package: ggplot2

# this graph does the precipitation vs time graph, but not the wind

> ggplot(Sandy, aes(x = Deal1, y = Rainfall_cm, group = 1)) +
geom_line(stat = "identity")


Ideally I want it to have the precipitation graph vs time, then wind vs
time on the same graph. I would like the wind direction to be arrows
pointing in the designated direction (i.e. North points north).

Thank you!

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Aug 10 08:32:00 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 9 Aug 2015 23:32:00 -0700
Subject: [R] result NA , but expected True or False
In-Reply-To: <DUB125-W91C972100E24493CABA989B3700@phx.gbl>
References: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>
	<DUB125-W91C972100E24493CABA989B3700@phx.gbl>
Message-ID: <A898B599-25E3-4C5B-9959-283459BB3A0C@comcast.net>


On Aug 9, 2015, at 8:45 PM, Ragia Ibrahim wrote:

> Dear Group,
> Kindly,
> 
> I have those two lines
> if(  (z_nebla==0) ||  (z_nebla_dash==0) )
>           CM <- 0         else             
> 
>               CM <-  0.5 *(1/a)  +   0.5*(1/b)  
> 
> when running it
> 
> I got this
> 
> z_nebla==0)
> logical(0)
>> (z_nebla_dash==0)
> logical(0)
>> (z_nebla==0) ||  (z_nebla_dash==0)
> [1] NA
> 
> 
> why  (z_nebla==0) ||  (z_nebla_dash==0)
> gives me NA ?

We should instead ask you: why should a logical-OR give anything other than NA when given two length-zero vectors as arguments?

 What value do you expect?

> 
> thanks in advance
> Ragia
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Mon Aug 10 08:50:35 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 10 Aug 2015 06:50:35 +0000
Subject: [R] Parsing all rows & columns of a Dataframe into one column
In-Reply-To: <HKXPR02MB06321FDA97E5C1E23E4D2601F0700@HKXPR02MB0632.apcprd02.prod.outlook.com>
References: <HKXPR02MB06321FDA97E5C1E23E4D2601F0700@HKXPR02MB0632.apcprd02.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C393FC@SRVEXCHMBX.precheza.cz>

Hi

Your HTML posting scrammbled your question a bit. If I understand correctly and as you want values of various type in one column, probably the easiest way would be.

mat<-as.matrix(yourdata)
mat<-na.omit(mat)
dim(mat) <- NULL
newdata <- data.frame(mat, stringsAsFactors=FALSE)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Anshuk
> Pal Chaudhuri
> Sent: Monday, August 10, 2015 7:24 AM
> To: r-help at r-project.org
> Subject: [R] Parsing all rows & columns of a Dataframe into one column
>
> Hi All,
>
>
> I am using R for reading certain values in a dataset.
>
> I have values in a data frame all scattered in different columns &
> rows, some values might be NA as well.
>
> e.g. below three columns V1, V2,V3, and their respective values.
> V1
>
>     V2
>
>     V2
>
> NA
>
>     NA
>
> 90
>
> abc
>
> 89.09
>
> $50
>
> 76799
>
> NA
>
>     NA
>
> 02:15
>
> def
>
> 1
>
>
>
>
> What I would like to do is parse this data frame, create a new data
> frame, omit all NA values. The new data frame would have one column,
> lets say Value column. (order of the samples coming is not an issue)
>
> New Data Frame (Output Required):
>
>
> Value
>
> abc
>
> 76799
>
> 02:15
>
> 89.09
>
> def
>
> 90
>
> $50
>
> 1
>
>
>
>
> Any help would be appreciated.
>
> Regards,
> Anshuk Pal Chaudhuri
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Mon Aug 10 09:10:01 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 10 Aug 2015 07:10:01 +0000
Subject: [R] Data frame Q
In-Reply-To: <DUB125-W49BC987BD7C478DCA7220FB3700@phx.gbl>
References: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>,
	<DUB125-W91C972100E24493CABA989B3700@phx.gbl>
	<DUB125-W49BC987BD7C478DCA7220FB3700@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39417@SRVEXCHMBX.precheza.cz>

Hi

Your question is without reproducible example and I find it a bit cryptic. You do not uncover what is i. If it is a number I wonder why your atempts fail.

Find answer in line below.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ragia
> Ibrahim
> Sent: Monday, August 10, 2015 6:42 AM
> To: r-help at r-project.org
> Subject: [R] Data frame Q
>
> Dear Group,
> Kindly,
>  I have the following
>
> Common_Friends <-
> intersect(node_neighbours_i_out,node_neighbours_j_out)
>          class(Common_Friends)
>          print(Common_Friends)
>          #4 = Common_Friends
>        newline<-c(i,   Common_Friends  )
>  df<- rbind(df,newline)
>
> I created a data frame to add the new line
>
> when   Common_Friends  =0 nothing add ?, how to force it to write the
> value into the data frame
>
>
> Common_Friends <-
> intersect(node_neighbours_i_out,node_neighbours_j_out)
> >          class(Common_Friends)
> [1] "numeric"
> >          print(Common_Friends)
> numeric(0)

Common_Friends is not 0 but an empty vector.


>
> >        newline<-c(i,   Common_Friends  )
> > newline

> dat<-data.frame(a=1:4, b=rnorm(4))
> b<-numeric(length = 0)

> length(c(5,b))
[1] 1

> rbind(dat, c(5,b))
  a          b
1 1 -0.7346253
2 2  0.2063677
3 3  0.8580852
4 4 -0.4844313
5 5  5.0000000
>
so there is 5th line added but as b is empty vector the length of newline is one and recycling rule applies. If you want add zero you have to declare it as a zero (or NA) and not as an empty vector e.g.

> if(length(cf)==0) cf<-0
> cf
[1] 0

Cheers
Petr

> [1] 5
> thanks in advance
> Ragia
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From janka.vanschoenwinkel at uhasselt.be  Mon Aug 10 11:25:26 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka Vanschoenwinkel)
Date: Mon, 10 Aug 2015 11:25:26 +0200
Subject: [R] simultaneous equation model with endogenous interaction terms
Message-ID: <CAHymutJHcUTA2atcn4E0FB0T-n=Big_JgLKuCL5Us8UXr=kM1A@mail.gmail.com>

Dear list members,

I am building a model such as:

Y1 = Y2*X1 + X2
Y2 = Y1*X1 + X2

X2 is the exogenous variable
Z1 is the instrument of Y1
Z2 is the instrument of Y2

This is a simultaneous equation model. I know how to build a simultaneous
equation model without interaction terms:

library(systemfit)
eq1 <- Y1~Y2+X2+Z2
eq2 <- Y2~Y1+X2+Z1
inst <- ~X2+Z1+Z2
system <- list(eq1=eq1, eq2=eq2)
reg2SLS <-systemfit(system, "2SLS", inst=inst, data=mydata)
summary(reg2SLS)



I also know how to do a normal 2SLS with interaction terms:
library(systemfit)
ivreg(Y1~Y2*X1 | Z2*X1, data= Alldata)



However, I don't know how to deal with the interaction terms in the
simultaneous equation model.

I am experimenting both with R and STATA to see which formulation gives the
same result in both softwares, but until know without success.

Could somebody help me with this?

Thank you very much!

Janka

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Aug 10 13:11:32 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 10 Aug 2015 12:11:32 +0100
Subject: [R] Why does R start in wrong working directory
	despite	R_USER	setting?
In-Reply-To: <3C3BB32E-D210-4553-8E06-41BB438F91B1@dcn.davis.CA.us>
References: <2105360340.462940.1438965076031.JavaMail.yahoo@mail.yahoo.com>
	<3C3BB32E-D210-4553-8E06-41BB438F91B1@dcn.davis.CA.us>
Message-ID: <1A8C1289955EF649A09086A153E2672403B4430FD4@GBTEDVPEXCMB04.corp.lgc-group.com>

> >I would like the startup working directory to be that pointed to by
> >R_USER.
In Windows, right click on your R desktop shortcut (or create a new one pointing to Rgui.exe) and on the properties tab, change "Start in:" to 
%R_USER%

R will then start 'in' the R_USER directory if R_USER exists (that is, the working directory will be set to R_USER's contents).

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Mon Aug 10 13:20:16 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 10 Aug 2015 12:20:16 +0100
Subject: [R] Setting R working directories on Windows - was RE: Why does R
 start in wrong working directory ...
Message-ID: <1A8C1289955EF649A09086A153E2672403B4430FDC@GBTEDVPEXCMB04.corp.lgc-group.com>

> My preference is to start in different working directories depending on which
> project I am working on. R_USER is not a project directory. One way to do that
> is to double-click on an RData file located where you want to start. 
Saving an empty 'empty.RData' image in my project directories when I start a project is my preferred tactic. Always works independent of the physical location.

> Another way is to create a new shortcut in each directory. 
Did you mean 'shortcut _to_'?  That is, set up a shortcut somewhere like the desktop that points to Rgui.exe but with different 'Start in:' values for each project? Or literally a shortcut (probably with blank 'Start in:') in each project directory? (Both should work)

> Another way is to add a line to
> your script that sets the directory appropriately, though that makes sharing the
> scripts harder. 
This is indeed my most-hated way of doing this. It is very awkward when I move to a different machine - which I do a lot when shifting between working at work, working at home and working offsite on a laptop.


> Another way is to use RStudio projects.




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jdnewmil at dcn.davis.CA.us  Mon Aug 10 14:01:31 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 10 Aug 2015 08:01:31 -0400
Subject: [R] Plotting wind direction as arrows with precipitation
In-Reply-To: <CAGphrqrBe91PrqXw2e3SaPybs_FP4ZOVxixY7yStbmg-Cje5-A@mail.gmail.com>
References: <CAGphrqrBe91PrqXw2e3SaPybs_FP4ZOVxixY7yStbmg-Cje5-A@mail.gmail.com>
Message-ID: <261F2DA0-D55D-46CD-8DAC-B668A4301163@dcn.davis.CA.us>

I don't see any conversion of your time data from character to a time type, so it is probably converting to factor within the ggplot function. Something like

Sys.setenv(TZ="Etc/GMT+5") # you need to study time types, including ?strptime

Sandy$Deal1 <- as.POSIXct( Sandy$Deal1, format="%m/%d/%Y %H:%M")

The other problem I see is that you probably need to have your data in long form to get the results you want, so you should look at the vignettes for the reshape2 or tidyr packages.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 10, 2015 12:05:27 AM EDT, DJ L <rhelp10 at gmail.com> wrote:
>Hello R users!
>
>I am trying to create a time series in R with two variables,
>precipitation
>and wind direction vs Date/Time.
>
>I am looking for suggestions and maybe even sample code.
>
>My workbook is called "Sandy" and has columns with Date/Time,
>Raindall_cm,
>Wind Direction in both degree format (0-359) and in character form (N,
>NW,
>S, SW, SE, E, NE, NW).
>
>I have done some reading for it on stackoverflow and other sites but
>not
>making head way.
>
>I will be graphing with ggplot most likely and am a beginner in R, self
>taught from books and online resources.
>
>This is the code I have and a small peak into the data.
>
>Sandy<-read.csv("Sandy.csv", header=TRUE,
>sep=",",stringsAsFactors=FALSE)
>> head(Sandy)
>      Deal1     Rainfall_cm    Wind_Direction1 Wind_Direction2
>1 10/22/2012 0:00           0        296         W
>2 10/22/2012 0:15           0        317        NW
>3 10/22/2012 0:30           0        323        NW
>4 10/22/2012 0:45           0        323        NW
>5 10/22/2012 1:00           0        326        NW
>6 10/22/2012 1:15           0        326        NW
>
>> class(Sandy)
>[1] "data.frame"
>
>> str(Sandy)
>'data.frame':   1832 obs. of  4 variables:
> $ Deal1         : chr  "10/22/2012 0:00" "10/22/2012 0:15" "10/22/2012
>0:30" "10/22/2012 0:45" ...
> $ Rainfall_cm   : num  0 0 0 0 0 0 0 0 0 0 ...
>
> $ Wind_Direction: num 296 317  323   323  326  326
>
> $ Wind_Direction: chr  "W" "NW" "NW" "NW" ...
>
>> require(ggplot2)
>Loading required package: ggplot2
>
># this graph does the precipitation vs time graph, but not the wind
>
>> ggplot(Sandy, aes(x = Deal1, y = Rainfall_cm, group = 1)) +
>geom_line(stat = "identity")
>
>
>Ideally I want it to have the precipitation graph vs time, then wind vs
>time on the same graph. I would like the wind direction to be arrows
>pointing in the designated direction (i.e. North points north).
>
>Thank you!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From alc at sanger.ac.uk  Mon Aug 10 10:20:40 2015
From: alc at sanger.ac.uk (alc)
Date: Mon, 10 Aug 2015 09:20:40 +0100
Subject: [R] accessing confidence interval values from the 'predict' function
Message-ID: <a334c8948115e0d094aa45942d7bccc5@sanger.ac.uk>

 

Dear all, 

I'm wondering how can I access the confidence interval values ('upr' and
'lwr' values) produced by the 'predict' function. For example, I fitted
a linear regression line using: 

 fit <- lm(y ~ x) 

I then wanted to calculate a 95% confidence interval for the line, and
did this using: 

 ci <- predict(fit, data.frame(x), interval="confidence") 

I see that the 'ci' object has 'upr' and 'lwr' variables stored in it,
but am not sure how to access them properly. 

I find I can do it using: 

 upper <- as.data.frame(ci)$upr
 lower <- as.data.frame(ci)$lwr 

However, I'm wondering is there a more 'proper' way to do it in R? I
find that things like ci$upr don't seem to work, but am not sure what's
the right way? 

Kind Regards, 

Avril 

 


-- 
 The Wellcome Trust Sanger Institute is operated by Genome Research 
 Limited, a charity registered in England with number 1021457 and a 
 company registered in England with number 2742969, whose registered 
 office is 215 Euston Road, London, NW1 2BE. 
	[[alternative HTML version deleted]]


From h_a_patience at hotmail.com  Mon Aug 10 12:26:35 2015
From: h_a_patience at hotmail.com (Bazman76)
Date: Mon, 10 Aug 2015 03:26:35 -0700 (PDT)
Subject: [R] Unable to pass Object Arguments to UniRoot()
Message-ID: <1439202395517-4710938.post@n4.nabble.com>

Hi there,

I'd like to be able to pass an entire object to uniroot() as one of the
arguments. Unfortunately to recreate my precise error would be rather
involved. So I present a simplified version below:

To create a structured object let the output from the lm() function use this
simple code: 

    year <- c(2000 ,   2001  ,  2002  ,  2003 ,   2004)
    rate <- c(9.34 ,   8.50  ,  7.62  ,  6.93  ,  6.60)
    fit <- lm(rate ~ year)


    When I try to pass this to uniroot:

    OptLam<-uniroot(f=LamOpt, interval=c(0.0001,120),
tol=0.0000000000000001, MLEObj=fit )

I get the following error

Error in f(lower, ...) : 
  unused argument(s) (MLEObj = list(coefficients = c(1419.2079999999,
-0.704999999999952), residuals =

This seems to be specific to uniroot I have tested my own functions and they
happily accept objects like fit. The function LamOpt is not supposed to work
with a object created by lm() I've just used lm() as a simple example so
don't worry about the results that LamOpt produces, if I can pass one object
like fit to uniroot then I assume I can pass any object.

It seems that uniroot must be expecting an object of a certain size, would
it therefore be possible to use something analogous to pointers in c/c++ and
pass the object by reference so only a pointer to the object is passed
rather than the object itself?



    LamOpt<-function(lambda,MLEobj){

    x <- c(3,6,9,12,15,18,21,24,30,36,48,60,72,84,96,108,120)

    #MLEObj<-kemfit
    ## Cross-sectional model (Nelson and Siegel)
    #lambda <- 0.0609
    h2 <- function(x){(1-exp(-lambda*x))/(lambda*x)}
    h3 <- function(x){((1-exp(-lambda*x))/(lambda*x)) - exp(-lambda*x)}
    X=cbind(rep(1,m), h2(x), h3(x)) #obs

    Z <- matrix(as.list(X), ncol = 3)

    MLEObj$par$Z=Z

    kf_iter = MARSSkf(MLEobj)

    return(-kf_iter$logLik)
    }

Thanks

Baz
   




--
View this message in context: http://r.789695.n4.nabble.com/Unable-to-pass-Object-Arguments-to-UniRoot-tp4710938.html
Sent from the R help mailing list archive at Nabble.com.


From h_a_patience at hotmail.com  Mon Aug 10 14:45:38 2015
From: h_a_patience at hotmail.com (Bazman76)
Date: Mon, 10 Aug 2015 05:45:38 -0700 (PDT)
Subject: [R] Unable to pass Object Arguments to UniRoot()
In-Reply-To: <1439209612430-4710942.post@n4.nabble.com>
References: <1439202395517-4710938.post@n4.nabble.com>
	<1439209612430-4710942.post@n4.nabble.com>
Message-ID: <1439210738734-4710943.post@n4.nabble.com>

Thanks Krishna!


You are correct, but even when I manually add m<-17 just after x I still get
the same error?

Uniroot falls over when it tries to take in the argument MLEobj=fit, thus I
think the error is occurring before LamOpt() gets called by uniroot().

Which is why the error you mentioned didn't show up before and thus
unfortunately the original error still persists.

Baz







--
View this message in context: http://r.789695.n4.nabble.com/Unable-to-pass-Object-Arguments-to-UniRoot-tp4710938p4710943.html
Sent from the R help mailing list archive at Nabble.com.


From lists at dewey.myzen.co.uk  Mon Aug 10 15:48:03 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 10 Aug 2015 14:48:03 +0100
Subject: [R] accessing confidence interval values from the 'predict'
	function
In-Reply-To: <a334c8948115e0d094aa45942d7bccc5@sanger.ac.uk>
References: <a334c8948115e0d094aa45942d7bccc5@sanger.ac.uk>
Message-ID: <55C8AB93.2080705@dewey.myzen.co.uk>

Dear Avril

I think you will find that predict.lm returns a matrix not a data frame. 
I find str() useful when R does things I did not expect or quite understand.

Michael

On 10/08/2015 09:20, alc wrote:
>
>
> Dear all,
>
> I'm wondering how can I access the confidence interval values ('upr' and
> 'lwr' values) produced by the 'predict' function. For example, I fitted
> a linear regression line using:
>
>   fit <- lm(y ~ x)
>
> I then wanted to calculate a 95% confidence interval for the line, and
> did this using:
>
>   ci <- predict(fit, data.frame(x), interval="confidence")
>
> I see that the 'ci' object has 'upr' and 'lwr' variables stored in it,
> but am not sure how to access them properly.
>
> I find I can do it using:
>
>   upper <- as.data.frame(ci)$upr
>   lower <- as.data.frame(ci)$lwr
>
> However, I'm wondering is there a more 'proper' way to do it in R? I
> find that things like ci$upr don't seem to work, but am not sure what's
> the right way?
>
> Kind Regards,
>
> Avril
>
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From varinsacha at yahoo.fr  Mon Aug 10 16:15:03 2015
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 10 Aug 2015 14:15:03 +0000 (UTC)
Subject: [R] Bootstrapped CIs of R-squared for ordinal regression
Message-ID: <1640774558.2148857.1439216103222.JavaMail.yahoo@mail.yahoo.com>

Dear R-Experts,

I am trying to get the bootstrapped confidence intervals of R-squared (Nagelkerke) for an ordinal logistic regression. Something is going wrong at the end of my script. Many thanks for your help.

Here is my reproducible example.

install.packages("rms") 
library(rms)
x=c(1,2,3,2,3,1,2,3,3,3,2,2,1,2,1,2,3,2,1,2) 
y=c("math","eco","eco","lit","lit","eco","eco","math","math","lit","lit","math","eco","eco","math","lit","lit","math","eco","math") 
Dataset<-data.frame(x,y) 
h <- orm(x ~ y) 
h 
# Bootstrap 95% CI for R-Squared 
library(boot) 
# function to obtain R-Squared from the data 
rsq <- function(formula, data, indices) { 
d <- data[indices,] # allows boot to select sample 
fit <- orm(x ~ y, data=data[indices,]) 
return((fit)$r.square) 
} 
# bootstrapping with 1000 replications 
results <- boot(data=Dataset, statistic=rsq, R=1000, formula=x ~ y) 
# view results 
results 
plot(results) 
# get 95% confidence interval 
boot.ci(results, type="bca")


From davidsmi at microsoft.com  Mon Aug 10 16:40:30 2015
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 10 Aug 2015 14:40:30 +0000
Subject: [R] Revolutions blog roundup: July 2015
Message-ID: <BN3PR0301MB0835BF6ED448A5CD2AA28D4FC8700@BN3PR0301MB0835.namprd03.prod.outlook.com>

Since 2008, Revolution Analytics (and now Microsoft) staff and guests have written about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help. 

In case you missed them, here are some articles related to R from the month of June:

An alternative to stacked bar charts with the streamgraphs package: http://blog.revolutionanalytics.com/2015/07/streamgraphs-in-r.html

Joseph Rickert shares his process for creating the monthly new and updated packages "spotlight" feature on MRAN: http://blog.revolutionanalytics.com/2015/07/mranspackages-spotlight.html

An analysis of StackOverflow's data API using R reveals R to be the 8th most popular language by activity on that site: http://blog.revolutionanalytics.com/2015/07/the-most-popular-programming-languages-on-stackoverflow.html

On accumulating results in R using looping operations: http://blog.revolutionanalytics.com/2015/07/efficient-accumulation-in-r.html

In an in-depth profile, Hadley Wickham shares his motivations for creating his many useful R packages: http://blog.revolutionanalytics.com/2015/07/hadley-profile.html

The latest programming language rankings by IEEE Spectrum puts R in the #6 spot, rising 3 since 2014: http://blog.revolutionanalytics.com/2015/07/ieee-2015-rankings.html
	
Revolution R Open 3.2.1 is now available, bringing multi-threaded performance and new platforms to the latest R engine: http://blog.revolutionanalytics.com/2015/07/revolution-r-open-321-now-available.html

A look at trends of questions on StackOverflow for Python and R: http://blog.revolutionanalytics.com/2015/07/in-celebration-of-100000-r-questions-on-stackoverflow.html 

Setting up a Linux VM on Azure, and importing data into R from MySQL and mariaDB: http://blog.revolutionanalytics.com/2015/07/using-azure-as-an-r-datasource-part-2-pulling-data-from-mysqlmariadb-to-linux.html 

The winners of the 2015 KDD Cup, and how you can analyze the data with R in Azure ML Studio: http://blog.revolutionanalytics.com/2015/07/kdd-cup-2015-winners-announced.html 

The chair of the local committee shares some statistics from the useR! 2015 conference: http://blog.revolutionanalytics.com/2015/07/planning-of-and-some-stats-from-user-2015-aalborg.html 

A review of R packages for extreme value statistics: http://blog.revolutionanalytics.com/2015/07/r-extreme-value-statistics-and-missing-data.html 

Using the igraph package to create interactive (and embeddable) network graphs from data in R: http://blog.revolutionanalytics.com/2015/07/creating-network-graphs-using-javascript-directly-from-r.html 

Package author Ari Lamstein shares his tips for creating an email-based R course: http://blog.revolutionanalytics.com/2015/07/5-steps-to-create-an-r-package-email-course.html 

In an EMC-sponsored competition to analyze data generated by a motorcycle racer, both winners used R: http://blog.revolutionanalytics.com/2015/07/morecambe-missile.html 

A new visualization of the network structure of CRAN packages finds connected communities including one centered on "MASS": http://blog.revolutionanalytics.com/2015/07/the-network-structure-of-cran.html

Using R and A/B testing to evaluate the performance of advertising: http://blog.revolutionanalytics.com/2015/07/ab-testing-advertisements-with-r.html 

A roundup of press generated by the announcement of the R Consortium: http://blog.revolutionanalytics.com/2015/07/r-consortium-news-roundup.html 

My reflections on the successful 2015 useR! Conference in Denmark: http://blog.revolutionanalytics.com/2015/07/user-2015-its-a-wrap.html 

Experiences using R Markdown and Github for teaching: http://blog.revolutionanalytics.com/2015/06/get-your-r-education-going-with-github.html

Resources from the tutorial on using R with Hadoop and the RHadoop packages: http://blog.revolutionanalytics.com/2015/07/news-from-user2015-the-rhadoop-tutorial.html 

General interest stories (not related to R) in the past month included: a short film about impossible business meetings (http://blog.revolutionanalytics.com/2015/07/because-its-friday-seven-red-lines.html), filming the motion of guitar strings with just an iPhone (http://blog.revolutionanalytics.com/2015/07/because-its-friday-good-vibrations.html), an anthem for R users (http://blog.revolutionanalytics.com/2015/07/because-its-friday-doin-it-with-the-r.html), a short documentary on the mission to Pluto (http://blog.revolutionanalytics.com/2015/07/because-its-friday.html), a review of "Statistics Done Wrong" (http://blog.revolutionanalytics.com/2015/07/book-review-statistics-done-wrong.html), and a clever illustration of personal bias (http://blog.revolutionanalytics.com/2015/07/because-its-friday-youre-biased.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries from previous months at http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like blogtrottr.com, or join the Revolution Analytics mailing list at http://revolutionanalytics.com/newsletter to be alerted to new articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Revolution Analytics (a Microsoft company)? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com
We are hiring engineers for Revolution R and Azure Machine Learning: http://azuremljobs.github.io/ 


From msharp at txbiomed.org  Mon Aug 10 17:46:19 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 10 Aug 2015 15:46:19 +0000
Subject: [R] Reading Json data
In-Reply-To: <B3593265-661A-4E0E-BC63-88EC39E35BD5@txbiomed.org>
References: <CAHWpsEFi_15m4jbw5A=3NQchF9kFC3GnU9LRY-QfH771DXeJgA@mail.gmail.com>
	<B3593265-661A-4E0E-BC63-88EC39E35BD5@txbiomed.org>
Message-ID: <6952105E-60F5-4D22-8505-F9FB34627E0D@txbiomed.org>

Mayukh,

I apologize for taking so long to get back to your problem. I expect you may have found the solution. If so I would be interested. I have developed a hack to solve the problem, but I expect if someone knew how to handle JSON objects or even text parsing better they could develop a more elegant solution. 

As I understand the problem, your text file has more than one JSON object in text form. There are three. The first two are very similar and the last is a trailer indication what was done, when it was done and the number of JSON objects sent. The problem is that fromJSON() only pulls off the first of the JSON objects. 

I have defined three helper functions to separate the JSON objects, read them in, and store them in a list.

library(RJSONIO)
library(stringi, quietly = TRUE)
#library(jsonlite) # also works

#' Returns dataframe with ordered locations of the matching braces.
#'
#' There is almost certainly a better function to do this. 
#' @param txt character vector of length one having 0 or more matching braces.
#' @import stringi
#' @examples 
#' library(rmsutilityr)
#' match_braces("{123{456{78}9}10}")
#' @export
match_braces <- function(txt) {
  txt <- txt[1] # just in the case of having more than one element
  left <- stri_locate_all_regex(txt, "\\{")[[1]][ , 1]
  right <- stri_locate_all_regex(txt, "\\}")[[1]][ , 2]
  len <- length(left)
  braces <- data.frame(left = rep(0, len), right = rep(0, len))
  for (i in seq_along(right)) {
    for (j in rev(seq_along(left))) {
      if (left[j] < right[i] & left[j] != 0) {
        braces$left[i] <- left[j]
        braces$right[i] <- right[i]
        left[j] <- 0
        break
      }
    }
  }
  braces[order(braces$left), ]
}

#' Returns a list containing two objects in the text of a character vector 
#' of length one: (1) object = the first json object found and (2) remainder = 
#' the remaining text.
#' 
#'  Properly formed messages are assumed. Error checking is non-existent.
#' @param json_txt character vector of length one having one or more JSON
#' objects in character form.
#' @import stringi
#' @export
get_first_json_message <- function(json_txt) {
  len <- stri_length(json_txt)
  braces <- match_braces(json_txt)
  if (braces$right[1] + 1 > len) {
    remainder <- ""
  } else {
    remainder <- stri_trim_both(stri_sub(json_txt, braces$right[1] + 1))
  }
  list(object = stri_sub(json_txt, braces$left[1], to = braces$right[1]),
       remainder = remainder)
}
#' Returns list of lists made by call to fromJSON()

#' @param json_txt character vector of length 1 having one or more
#' JSON objects in text form.
#' @import stringi
#' @export
get_json_list <- function (json_txt) {
  t_json_txt <- json_txt
  i <- 0
  json_list <- list()
  repeat{
    i <- i + 1
    message_remainder <- get_first_json_message(t_json_txt)
    json_list[i] <- list(fromJSON(message_remainder$object))
    if (message_remainder$remainder == "")
      break
    t_json_txt <- message_remainder$remainder
  }
  json_list
}

json_file <- "../data/json_file.txt"
json_txt <- stri_trim_both(stri_c(readLines(json_file), collapse = " "))
json_list <- get_json_list(json_txt)
length(json_list)


R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Jul 27, 2015, at 5:16 PM, Mark Sharp <msharp at TxBiomed.org> wrote:
> 
> Mayukh,
> 
> I think you are missing an argument to paste() and a right parenthesis character.
> 
> Try 
> json_data <- fromJSON(paste(readLines(json_file), collapse = " "))
> 
> Mark
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
> 
> 
> 
> 
> 
>> On Jul 27, 2015, at 3:41 PM, Mayukh Dass <mayukh.dass at gmail.com> wrote:
>> 
>> Hello,
>> 
>> I am trying to read a set of json files containing tweets using the
>> following code:
>> 
>> json_data <- fromJSON(paste(readLines(json_file))
>> 
>> Unfortunately, it only reads the first record on the file. For example, in
>> the file below, it only reads the first record starting with "id":"tag:
>> search.twitter.com,2005:3318539389". What is the best way to retrieve these
>> records? I have 20 such json files with varying number of tweets in it.
>> Thank you in advance.
>> 
>> Best,
>> Mayukh
>> 
>> {"id":"tag:search.twitter.com
>> ,2005:3318539389","objectType":"activity","actor":{"objectType":"person","id":"id:
>> twitter.com:2859421","link":"http://www.twitter.com/meetjenn","displayName":"Jenn","postedTime":"2007-01-29T17:06:00.000Z","image":"06-19-07_2010.jpg","summary":"I
>> say 'like' a lot. I fall down a lot. I walk into everything. Love Pgh Pens,
>> NE Pats, Fundraising, Dogs & History. Craft Beer & Running
>> Novice.","links":[{"href":"http://meetjenn.tumblr.com","rel":"me"}],"friendsCount":0,"followersCount":0,"listedCount":0,"statusesCount":0,"twitterTimeZone":"Eastern
>> Time (US &
>> Canada)","verified":false,"utcOffset":"0","preferredUsername":"meetjenn","languages":["en"],"location":{"objectType":"place","displayName":"Pgh/Philajersey"},"favoritesCount":0},"verb":"post","postedTime":"2009-08-15T00:00:12.000Z","generator":{"displayName":"tweetdeck","link":"
>> http://twitter.com
>> "},"provider":{"objectType":"service","displayName":"Twitter","link":"
>> http://www.twitter.com"},"link":"
>> http://twitter.com/meetjenn/statuses/3318539389","body":"Cool story about
>> the man who created the @Starbucks logo. Additional link at the bottom on
>> how it came to be:  http://bit.ly/16bOJk
>> ","object":{"objectType":"note","id":"object:search.twitter.com,2005:3318539389","summary":"Cool
>> story about the man who created the @Starbucks logo. Additional link at the
>> bottom on how it came to be:  http://bit.ly/16bOJk","link":"
>> http://twitter.com/meetjenn/statuses/3318539389
>> ","postedTime":"2009-08-15T00:00:12.000Z"},"twitter_entities":{"urls":[{"expanded_url":null,"indices":[111,131],"url":"
>> http://bit.ly/16bOJk
>> "}],"hashtags":[],"user_mentions":[{"id":null,"name":null,"indices":[41,51],"screen_name":"@Starbucks","id_str":null}]},"retweetCount":0,"gnip":{"matching_rules":[{"value":"Starbucks","tag":null}]}}
>> {"id":"tag:search.twitter.com
>> ,2005:3318543260","objectType":"activity","actor":{"objectType":"person","id":"id:
>> twitter.com:61595468","link":"http://www.twitter.com/FastestFood","displayName":"FastFood
>> Bob","postedTime":"2009-01-30T20:51:10.000Z","image":"","summary":"Just A
>> little food for
>> thought","links":[{"href":"http://www.TeamSantilli.com","rel":"me"}],"friendsCount":0,"followersCount":0,"listedCount":0,"statusesCount":0,"twitterTimeZone":"Pacific
>> Time (US &
>> Canada)","verified":false,"utcOffset":"0","preferredUsername":"FastestFood","languages":["en"],"location":{"objectType":"place","displayName":"eating
>> some
>> thoughts"},"favoritesCount":0},"verb":"post","postedTime":"2009-08-15T00:00:23.000Z","generator":{"displayName":"oauth:17","link":"
>> http://twitter.com
>> "},"provider":{"objectType":"service","displayName":"Twitter","link":"
>> http://www.twitter.com"},"link":"
>> http://twitter.com/FastestFood/statuses/3318543260","body":"Oregon Biz
>> Report ? How Starbucks saved millions. Oregon closures ...
>> http://u.mavrev.com/02bdj","object":{"objectType":"note","id":"object:
>> search.twitter.com,2005:3318543260","summary":"Oregon Biz Report ? How
>> Starbucks saved millions. Oregon closures ... http://u.mavrev.com/02bdj
>> ","link":"http://twitter.com/FastestFood/statuses/3318543260
>> ","postedTime":"2009-08-15T00:00:23.000Z"},"twitter_entities":{"urls":[{"expanded_url":null,"indices":[70,95],"url":"
>> http://u.mavrev.com/02bdj
>> "}],"hashtags":[],"user_mentions":[]},"retweetCount":0,"gnip":{"matching_rules":[{"value":"Starbucks","tag":null}]}}
>> {"info":{"message":"Replay Request
>> Completed","sent":"2015-02-18T00:05:15+00:00","activity_count":2}}
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From wdunlap at tibco.com  Mon Aug 10 18:26:47 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 10 Aug 2015 09:26:47 -0700
Subject: [R] result NA , but expected True or False
In-Reply-To: <DUB125-W91C972100E24493CABA989B3700@phx.gbl>
References: <DUB125-W10C5D212C9BD3CF6775318B3A00@phx.gbl>
	<DUB125-W91C972100E24493CABA989B3700@phx.gbl>
Message-ID: <CAF8bMcbsTQ+_nZF8ZGnGH6dx-mu8wP00rFPtHmr0ieeLPDToQQ@mail.gmail.com>

The || operator will always return a result of type 'logical' and length 1.
You gave it two operands of length 0, so it returned the logical value NA,
meaning it had no idea what the result should be.  If you give it operands
of length > 1, it will use the only the first elements of them.  (S and S+
considered length 0 operands to || and && an error and warned about
length>1 operands, but R makes no comment about either case).

Perhaps you want to use the | operator, which acts like == and +, returning
a result as long as the longer of its operands, unless one operand has zero
elements, in which case it returns a length 0 result.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Aug 9, 2015 at 8:45 PM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:

> Dear Group,
> Kindly,
>
> I have those two lines
> if(  (z_nebla==0) ||  (z_nebla_dash==0) )
>            CM <- 0         else
>
>                CM <-  0.5 *(1/a)  +   0.5*(1/b)
>
> when running it
>
> I got this
>
> z_nebla==0)
> logical(0)
> > (z_nebla_dash==0)
> logical(0)
> > (z_nebla==0) ||  (z_nebla_dash==0)
> [1] NA
>
>
> why  (z_nebla==0) ||  (z_nebla_dash==0)
> gives me NA ?
>
> thanks in advance
> Ragia
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boredstoog at mailinator.com  Mon Aug 10 18:02:24 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Mon, 10 Aug 2015 09:02:24 -0700 (PDT)
Subject: [R] inbuilt crossover function for backtesting
In-Reply-To: <CAPPM_gSgAgvhTDVUwYBtMv+u8XBn3S5uUwh-LsoopU_2wWVzhA@mail.gmail.com>
References: <1439110008152-4710918.post@n4.nabble.com>
	<CAPPM_gSgAgvhTDVUwYBtMv+u8XBn3S5uUwh-LsoopU_2wWVzhA@mail.gmail.com>
Message-ID: <1439222544733-4710949.post@n4.nabble.com>

Thanks Joshua for the quick reply to the mail and once more sorry for
bothering with another doubt. So i have modified your code :) for
backtesting and this is the code

*
library(quantmod)
library(tseries)
require(quantstrat)
library(PerformanceAnalytics)
sym <- get(getSymbols('SPY'))["2013::"]
sym$sma10 <- SMA(Cl(sym),10) 
sym$sma30 <- SMA(Cl(sym),30)
buy <- sigCrossover("buy", SPY, c("sma10","sma30"), "gt") 
sell <- sigCrossover("sell", SPY, c("sma30","sma10"), "lt") 
if (buy==TRUE){
    sym$pos<-1
} else if (sell==TRUE){
   sym$pos<--1
} 
myReturn <- lag(sym$pos) * dailyReturn(sym)
charts.PerformanceSummary(cbind(dailyReturn(sym),myReturn))*


But the above code is returing this error

*Error in if (buy == TRUE) { : missing value where TRUE/FALSE needed
In addition: Warning message:
In if (buy == TRUE) { :
  the condition has length > 1 and only the first element will be used
> myReturn <- lag(sym$pos) * dailyReturn(sym)
Error in hasTsp(x) : attempt to set an attribute on NULL
> charts.PerformanceSummary(cbind(dailyReturn(sym),myReturn))
Warning message:
In to_period(xx, period = on.opts[[period]], ...) :
  missing values removed from data*

Any idea what is hapennning



--
View this message in context: http://r.789695.n4.nabble.com/inbuilt-crossover-function-for-backtesting-tp4710918p4710949.html
Sent from the R help mailing list archive at Nabble.com.


From josh.m.ulrich at gmail.com  Mon Aug 10 20:17:28 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 10 Aug 2015 13:17:28 -0500
Subject: [R] inbuilt crossover function for backtesting
In-Reply-To: <1439222544733-4710949.post@n4.nabble.com>
References: <1439110008152-4710918.post@n4.nabble.com>
	<CAPPM_gSgAgvhTDVUwYBtMv+u8XBn3S5uUwh-LsoopU_2wWVzhA@mail.gmail.com>
	<1439222544733-4710949.post@n4.nabble.com>
Message-ID: <CAPPM_gTKKS21-=X5mEyT8FggJcOcepAnvE7O_6XB0MuOhvGO6A@mail.gmail.com>

On Mon, Aug 10, 2015 at 11:02 AM, boredstoog via R-help
<r-help at r-project.org> wrote:
> Thanks Joshua for the quick reply to the mail and once more sorry for
> bothering with another doubt. So i have modified your code :) for
> backtesting and this is the code
>
> *
> library(quantmod)
> library(tseries)
> require(quantstrat)
> library(PerformanceAnalytics)
> sym <- get(getSymbols('SPY'))["2013::"]
> sym$sma10 <- SMA(Cl(sym),10)
> sym$sma30 <- SMA(Cl(sym),30)
> buy <- sigCrossover("buy", SPY, c("sma10","sma30"), "gt")
> sell <- sigCrossover("sell", SPY, c("sma30","sma10"), "lt")
> if (buy==TRUE){
>     sym$pos<-1
> } else if (sell==TRUE){
>    sym$pos<--1
> }
> myReturn <- lag(sym$pos) * dailyReturn(sym)
> charts.PerformanceSummary(cbind(dailyReturn(sym),myReturn))*
>
>
> But the above code is returing this error
>
> *Error in if (buy == TRUE) { : missing value where TRUE/FALSE needed
> In addition: Warning message:
> In if (buy == TRUE) { :
>   the condition has length > 1 and only the first element will be used
>> myReturn <- lag(sym$pos) * dailyReturn(sym)
> Error in hasTsp(x) : attempt to set an attribute on NULL
>> charts.PerformanceSummary(cbind(dailyReturn(sym),myReturn))
> Warning message:
> In to_period(xx, period = on.opts[[period]], ...) :
>   missing values removed from data*
>
> Any idea what is hapennning
>
There are several errors in your code.  Rather than enumerate them and
show you how to fix each one; I suggest you simply use quantstrat as
it was intended, rather than attempt to circumvent/re-invent it.

See demo('macd') and modify the demo source code to suit your purposes.

>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/inbuilt-crossover-function-for-backtesting-tp4710918p4710949.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From jvadams at usgs.gov  Mon Aug 10 20:43:23 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 10 Aug 2015 13:43:23 -0500
Subject: [R] accessing confidence interval values from the 'predict'
	function
In-Reply-To: <a334c8948115e0d094aa45942d7bccc5@sanger.ac.uk>
References: <a334c8948115e0d094aa45942d7bccc5@sanger.ac.uk>
Message-ID: <CAN5YmCFYgwsH9xiufcOBNqYCQiWuOYnXAZAQJnfz6mq94Zarfg@mail.gmail.com>

Avril,

The more direct way to access these columns from the matrix is:

ci[, "lwr"]
ci[, "upr"]

Jean

On Mon, Aug 10, 2015 at 3:20 AM, alc <alc at sanger.ac.uk> wrote:

>
>
> Dear all,
>
> I'm wondering how can I access the confidence interval values ('upr' and
> 'lwr' values) produced by the 'predict' function. For example, I fitted
> a linear regression line using:
>
>  fit <- lm(y ~ x)
>
> I then wanted to calculate a 95% confidence interval for the line, and
> did this using:
>
>  ci <- predict(fit, data.frame(x), interval="confidence")
>
> I see that the 'ci' object has 'upr' and 'lwr' variables stored in it,
> but am not sure how to access them properly.
>
> I find I can do it using:
>
>  upper <- as.data.frame(ci)$upr
>  lower <- as.data.frame(ci)$lwr
>
> However, I'm wondering is there a more 'proper' way to do it in R? I
> find that things like ci$upr don't seem to work, but am not sure what's
> the right way?
>
> Kind Regards,
>
> Avril
>
>
>
>
> --
>  The Wellcome Trust Sanger Institute is operated by Genome Research
>  Limited, a charity registered in England with number 1021457 and a
>  company registered in England with number 2742969, whose registered
>  office is 215 Euston Road, London, NW1 2BE.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Scott.Waichler at pnnl.gov  Mon Aug 10 21:32:05 2015
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Mon, 10 Aug 2015 19:32:05 +0000
Subject: [R] How to 2d cross sections from a 3d finite element mesh
Message-ID: <074C83DAD4825242A20B2D83FDBCB8881A05B733@EX10MBOX03.pnnl.gov>

Hi, I have a 3D finite element mesh where each element (cell) is defined by 8 vertices.  Each element is a regular polyhedron.  The overall domain is a block in shape, but its horizontal principal axes are not coincident with x and y (i.e. the domain is rotated about the z-axis).  

I want to plot 2D cross sections of discrete and continuous values assigned to the elements.  I can think of two ways to go about providing the values to plot:  1) Use the cross section plane intersection with the elements to define a 2D polygon for each intersected element, and plot each as a polygon, with the final product being a mosaic of polygons within the plane of intersection; 2) interpolate to a regular grid and then plot that.  

Method 1 seems preferable to plotting discrete variables, while the second would be better for contouring a continuous variable.  I know how to do a 3D interpolation using Delaunay triangulation, but I wonder if there is a package out there to simplify things.  I don't know at all how to go about doing it the first way.  Can anyone suggest or point me to existing methods?

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA  USA


From lid.zigh at gmail.com  Mon Aug 10 22:11:10 2015
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Mon, 10 Aug 2015 15:11:10 -0500
Subject: [R] add an idx column to the matrix
Message-ID: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>

Hi there,

I have a matrix contain 0,1,2, NA elements.
I want to add a column to this matrix with name of "idx" . then for each
row, I should put 1 in this column (idx) if there is at least one 2 in that
row otherwise I should put 0 in this column!

for example  mydata:

       125   255   558   2366   177    255
aa    0        1       0         NA    0         0
bb    1        1       0         NA    0         1
cs     2        1       2         1       0         0
de    0        1       0         NA    0         0
gh    2       0       0         0        0         0


my output should be:


       125   255   558   2366   177    255    idx
aa    0        1       0         NA    0         0      0
bb    1        1       0         NA    0         1      0
cs     2        1       2         1       0         0     1
de    0        1       0         NA    0         0      0
gh    2       0       0        2        0         2       1

Thank you for your help.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Aug 10 22:27:04 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 10 Aug 2015 16:27:04 -0400
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
Message-ID: <CAM_vju=uQwUxes9vm5VGxvVHjKkn9BbY0-LHAv9nM_E26_Oeog@mail.gmail.com>

Easy enough (note that your column names are problematic, though)

> mydata <- structure(list(X125 = c(0L, 1L, 2L, 0L, 2L), X255 = c(1L, 1L,
+ 1L, 1L, 0L), X558 = c(0L, 0L, 2L, 0L, 0L), X2366 = c(NA, NA,
+ 1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
+ 0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
+ "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
+ "de", "gh"))
> mydata$idx <- apply(mydata, 1, function(x)as.numeric(any(x == 2 & !is.na
(x))))
> mydata
   X125 X255 X558 X2366 X177 X255.1 idx
aa    0    1    0    NA    0      0   0
bb    1    1    0    NA    0      1   0
cs    2    1    2     1      0      0   1
de    0    1    0    NA    0      0   0
gh    2    0    0     0      0      0   1

Sarah

On Mon, Aug 10, 2015 at 4:11 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:

> Hi there,
>
> I have a matrix contain 0,1,2, NA elements.
> I want to add a column to this matrix with name of "idx" . then for each
> row, I should put 1 in this column (idx) if there is at least one 2 in that
> row otherwise I should put 0 in this column!
>
> for example  mydata:
>
>        125   255   558   2366   177    255
> aa    0        1       0         NA    0         0
> bb    1        1       0         NA    0         1
> cs     2        1       2         1       0         0
> de    0        1       0         NA    0         0
> gh    2       0       0         0        0         0
>
>
> my output should be:
>
>
>        125   255   558   2366   177    255    idx
> aa    0        1       0         NA    0         0      0
> bb    1        1       0         NA    0         1      0
> cs     2        1       2         1       0         0     1
> de    0        1       0         NA    0         0      0
> gh    2       0       0        2        0         2       1
>
> Thank you for your help.
>
-- 
Sarah Goslee
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Aug 10 22:28:50 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 10 Aug 2015 22:28:50 +0200
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
Message-ID: <CAJuCY5w+jgXX_BupPMRpTY2zPXBv_zUZ_uW48jzej9ecdLM_Sw@mail.gmail.com>

Dear Lida,

Here is a solution. Please don't post in HTML. And provide an easy to use
example of the data. E.g. the output of dput(mydata)

set.seed(1234)
mydata <- matrix(
  sample(
    c(0, 1, 2, NA),
    size = 30,
    replace = TRUE,
    prob = c(2, 1, 1, 1)
  ),
  ncol = 6
)

idx <- apply(mydata, 1, function(x){any(x == 2)})
idx[is.na(idx)] <- FALSE
cbind(mydata, idx)



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-08-10 22:11 GMT+02:00 Lida Zeighami <lid.zigh at gmail.com>:

> Hi there,
>
> I have a matrix contain 0,1,2, NA elements.
> I want to add a column to this matrix with name of "idx" . then for each
> row, I should put 1 in this column (idx) if there is at least one 2 in that
> row otherwise I should put 0 in this column!
>
> for example  mydata:
>
>        125   255   558   2366   177    255
> aa    0        1       0         NA    0         0
> bb    1        1       0         NA    0         1
> cs     2        1       2         1       0         0
> de    0        1       0         NA    0         0
> gh    2       0       0         0        0         0
>
>
> my output should be:
>
>
>        125   255   558   2366   177    255    idx
> aa    0        1       0         NA    0         0      0
> bb    1        1       0         NA    0         1      0
> cs     2        1       2         1       0         0     1
> de    0        1       0         NA    0         0      0
> gh    2       0       0        2        0         2       1
>
> Thank you for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tommac at nova.edu  Tue Aug 11 01:26:16 2015
From: tommac at nova.edu (Dr. Thomas W. MacFarland)
Date: Mon, 10 Aug 2015 23:26:16 +0000
Subject: [R] Is there a R function for the nonparametric Walsh Test?
Message-ID: <0A977721602DFC40B5D7608CD47E987E5304BD7B@DAGOBAH.oit.nova.edu>

Everyone:

I am currently trying to reproduce the nonparametric Walsh Test, as presented in Siegel (1956, pp. 83-87), and unfortunately I cannot find a R function for this test.

I would certainly appreciate any pointers for the Walsh Test using R, or perhaps a reasonable substitute if there is simply no package::function that specifically addresses this test.

Thank you and best wishes.

Tom MacFarland

----------
Thomas W. MacFarland, Ed.D.
Senior Research Associate; Institutional Effectiveness and Associate Professor
Nova Southeastern University
Voice 954-262-5395 tommac at nova.edu


From r.turner at auckland.ac.nz  Tue Aug 11 01:48:58 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 11 Aug 2015 11:48:58 +1200
Subject: [R] Is there a R function for the nonparametric Walsh Test?
In-Reply-To: <0A977721602DFC40B5D7608CD47E987E5304BD7B@DAGOBAH.oit.nova.edu>
References: <0A977721602DFC40B5D7608CD47E987E5304BD7B@DAGOBAH.oit.nova.edu>
Message-ID: <55C9386A.4050509@auckland.ac.nz>

On 11/08/15 11:26, Dr. Thomas W. MacFarland wrote:
> Everyone:
>
> I am currently trying to reproduce the nonparametric Walsh Test, as
> presented in Siegel (1956, pp. 83-87), and unfortunately I cannot
> find a R function for this test.
>
> I would certainly appreciate any pointers for the Walsh Test using R,
> or perhaps a reasonable substitute if there is simply no
> package::function that specifically addresses this test.

I don't know of any extant function to effect the Walsh Test, but having 
had a look at the recipe given in

   http://www.statistics4u.com/fundstat_eng/ee_walsh_outliertest.html

I would say that anyone with even a modest knowledge of R could write 
such a function in under 5 minutes.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Tue Aug 11 05:20:46 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 10 Aug 2015 20:20:46 -0700
Subject: [R] Unable to pass Object Arguments to UniRoot()
In-Reply-To: <1439202395517-4710938.post@n4.nabble.com>
References: <1439202395517-4710938.post@n4.nabble.com>
Message-ID: <CAGxFJbQA1J8GTbPWoEzF=iLyiuw-b5vgOQQm-9tjtiMqgiySFA@mail.gmail.com>

??

?uniroot tells you exactly what uniroot() expects as arguments. Unless
I misunderstand, your query seems totally unrelated to the way
uniroot() works.

Also, stop posting to Nabble and post to this (plain text) list. We
have no idea of what the Nabble contexts are, and many of us won't
even bother to read such posts for that reason.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Aug 10, 2015 at 3:26 AM, Bazman76 <h_a_patience at hotmail.com> wrote:
> Hi there,
>
> I'd like to be able to pass an entire object to uniroot() as one of the
> arguments. Unfortunately to recreate my precise error would be rather
> involved. So I present a simplified version below:
>
> To create a structured object let the output from the lm() function use this
> simple code:
>
>     year <- c(2000 ,   2001  ,  2002  ,  2003 ,   2004)
>     rate <- c(9.34 ,   8.50  ,  7.62  ,  6.93  ,  6.60)
>     fit <- lm(rate ~ year)
>
>
>     When I try to pass this to uniroot:
>
>     OptLam<-uniroot(f=LamOpt, interval=c(0.0001,120),
> tol=0.0000000000000001, MLEObj=fit )
>
> I get the following error
>
> Error in f(lower, ...) :
>   unused argument(s) (MLEObj = list(coefficients = c(1419.2079999999,
> -0.704999999999952), residuals =
>
> This seems to be specific to uniroot I have tested my own functions and they
> happily accept objects like fit. The function LamOpt is not supposed to work
> with a object created by lm() I've just used lm() as a simple example so
> don't worry about the results that LamOpt produces, if I can pass one object
> like fit to uniroot then I assume I can pass any object.
>
> It seems that uniroot must be expecting an object of a certain size, would
> it therefore be possible to use something analogous to pointers in c/c++ and
> pass the object by reference so only a pointer to the object is passed
> rather than the object itself?
>
>
>
>     LamOpt<-function(lambda,MLEobj){
>
>     x <- c(3,6,9,12,15,18,21,24,30,36,48,60,72,84,96,108,120)
>
>     #MLEObj<-kemfit
>     ## Cross-sectional model (Nelson and Siegel)
>     #lambda <- 0.0609
>     h2 <- function(x){(1-exp(-lambda*x))/(lambda*x)}
>     h3 <- function(x){((1-exp(-lambda*x))/(lambda*x)) - exp(-lambda*x)}
>     X=cbind(rep(1,m), h2(x), h3(x)) #obs
>
>     Z <- matrix(as.list(X), ncol = 3)
>
>     MLEObj$par$Z=Z
>
>     kf_iter = MARSSkf(MLEobj)
>
>     return(-kf_iter$logLik)
>     }
>
> Thanks
>
> Baz
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Unable-to-pass-Object-Arguments-to-UniRoot-tp4710938.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rosita21 at gmail.com  Tue Aug 11 01:44:22 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Tue, 11 Aug 2015 00:44:22 +0100
Subject: [R] LMER - generate data and define model (2 fixed effects and 1
	random effect or 1 fixed effect and 2 random effects)
Message-ID: <9D94908A-2EB3-4F66-B492-1AE187B7489E@gmail.com>

 

###############################################################################

# Clear memory and set the working directory and the seed

###############################################################################

rm(list = ls())

setwd("/Dropbox/LMER/R ")

set.seed(7010)

###############################################################################

# Load up needed packages and do a require

###############################################################################

# install.packages("gdata")



library(nlme)

library(lme4)



nsample                                       = 1000                    # Number of subjects

n.longitudinal.observations  = 5                                  # number of observations per subject



###############################################################################

# Set the other parameters

###############################################################################

id.pat                       = rep(seq(1:nsample), each =n.longitudinal.observations)

time                         = rep(seq(1:n.longitudinal.observations)-1, nsample)

age                          = rnorm(nsample, mean = 36, sd = .8)
id.age                      = rep(seq(1: n.longitudinal.observations), each =age)





############################################################################### MODEL WITHOUT AGE

boldBeta_individual_blup = coef(lmer(yy~1+time+(time|id.pat)   ))$id.pat   #mixed model





############################################################################### MODEL WITH AGE

boldBeta_individual_blup = coef(lmer(yy~1+age+time+(time|id.pat)   ))$id.pat   #mixed model



Dear all,





I?m trying to use LMER in my simulation problem, and I?m having problems ate the very begging L I?m new in LMER. Can you please help me?





1st problem:

how do I generate age so I can use it as a fixed factor?

2nd problem:

how do I insert age as a fixed factor?

3rd problem:

 what if I wanted to insert a 2nd random effect based on age?



Best,

RO



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates


From XWei at sugarresearch.com.au  Tue Aug 11 03:05:05 2015
From: XWei at sugarresearch.com.au (Xianming Wei)
Date: Tue, 11 Aug 2015 01:05:05 +0000
Subject: [R] replacing then summing by values from another dataframe
Message-ID: <326b356b0ac44179ac3b87f204d6f5a8@bneexchsvr.sugarresearch.local>

[I might have sent  the following request to a wrong email address - 'r-help-request at r-project.org']

Hi,



I have two data frame dat1 and dat2.



dat1 <- data.frame(pid = paste('C', 1:5, sep = ''),

                                    m1 = c(2, 2, 1, -1, 0),

                                     m2 = c(1, 0, 1, -1, 1),

                                     m3 = c(0, 1, 1, -1, 0))

dat2 <- data.frame(mid = paste('m', 1:3, sep = ''),

                                    '0' = c(-19.5482, -.512, -.492),

                                     '1' = c(.007, 3.241, -2.256),

                                     '2' =c(1.223, -4.490, 1.779)) names(dat2)[-1] <- c('0', '1', '2')



dat1 contains individuals with scores of three measurements (-1 represents missing) and dat2 with the effect of the different levels of the three measurements. What I'd like to do is to summise the effects of three measurements based on the level effects. So C1 I want to get the values of dat2 for m1 at level 2 = 1.223, m2 at level 1 = 3.241 and m3 at level 0 = -0.4920 and sum them up as 3.972.



I can only think of a loop to do that at the moment. Because of much higher dimensions of actual two datasets, I need help to come up with an efficient / elegant approach.



Any help is much appreciated.





Regards,

Xianming



Regards,
Xianming


-------------------- Internet e-Mail Disclaimer -------------------- 

PRIVILEGED - PRIVATE AND CONFIDENTIAL: This email and any files transmitted with it are intended solely for the use of the addressee(s) and may contain information, which is confidential or privileged. If you are not the intended recipient, be aware that any disclosure, copying, distribution, or use of the contents of this information is prohibited. In such case, you should destroy this message and kindly notify the sender by reply e-mail. The views and opinions expressed in this e-mail are those of the sender and do not necessarily reflect the views of the company. 

VIRUSES:  Email transmission cannot be guaranteed to be secure or error free, as information may be intercepted, corrupted, lost, destroyed, arrive late or incomplete or contain viruses. This email and any files attached to it have been checked with virus detection software before transmission. You should nonetheless carry out your own virus check before opening any attachment. Sugar Research Australia Limited does not represent or warrant that files attached to this email are free from computer viruses or other defects and accepts no liability for any loss or damage that may be caused by software viruses

	[[alternative HTML version deleted]]


From boredstoog at mailinator.com  Tue Aug 11 04:41:04 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Mon, 10 Aug 2015 19:41:04 -0700 (PDT)
Subject: [R] inbuilt crossover function for backtesting
In-Reply-To: <CAPPM_gTKKS21-=X5mEyT8FggJcOcepAnvE7O_6XB0MuOhvGO6A@mail.gmail.com>
References: <1439110008152-4710918.post@n4.nabble.com>
	<CAPPM_gSgAgvhTDVUwYBtMv+u8XBn3S5uUwh-LsoopU_2wWVzhA@mail.gmail.com>
	<1439222544733-4710949.post@n4.nabble.com>
	<CAPPM_gTKKS21-=X5mEyT8FggJcOcepAnvE7O_6XB0MuOhvGO6A@mail.gmail.com>
Message-ID: <1439260864267-4710961.post@n4.nabble.com>

Hey thanks josh,
I was looking for such a demo programme can you point to some more such demo
programmes if available




--
View this message in context: http://r.789695.n4.nabble.com/inbuilt-crossover-function-for-backtesting-tp4710918p4710961.html
Sent from the R help mailing list archive at Nabble.com.


From boredstoog at mailinator.com  Tue Aug 11 04:49:06 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Mon, 10 Aug 2015 19:49:06 -0700 (PDT)
Subject: [R] inbuilt crossover function for backtesting
In-Reply-To: <1439260864267-4710961.post@n4.nabble.com>
References: <1439110008152-4710918.post@n4.nabble.com>
	<CAPPM_gSgAgvhTDVUwYBtMv+u8XBn3S5uUwh-LsoopU_2wWVzhA@mail.gmail.com>
	<1439222544733-4710949.post@n4.nabble.com>
	<CAPPM_gTKKS21-=X5mEyT8FggJcOcepAnvE7O_6XB0MuOhvGO6A@mail.gmail.com>
	<1439260864267-4710961.post@n4.nabble.com>
Message-ID: <1439261346838-4710962.post@n4.nabble.com>

Josh,
I have found other demos on demo().. any way thanks for the help and for
supporting this project :)

boredstog



--
View this message in context: http://r.789695.n4.nabble.com/inbuilt-crossover-function-for-backtesting-tp4710918p4710962.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Tue Aug 11 08:24:26 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 11 Aug 2015 06:24:26 +0000
Subject: [R] replacing then summing by values from another dataframe
In-Reply-To: <326b356b0ac44179ac3b87f204d6f5a8@bneexchsvr.sugarresearch.local>
References: <326b356b0ac44179ac3b87f204d6f5a8@bneexchsvr.sugarresearch.local>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39608@SRVEXCHMBX.precheza.cz>

Hi

Not sure about elegancy/efficiency.

library(reshape2)

dat3 <- melt(dat2)

dat3
  mid variable    value
1  m1        0 -19.5482
2  m2        0  -0.5120
3  m3        0  -0.4920
4  m1        1   0.0070
5  m2        1   3.2410
6  m3        1  -2.2560
7  m1        2   1.2230
8  m2        2  -4.4900
9  m3        2   1.7790

dat4<-melt(dat1)
Using pid as id variables

dat4$value[dat4$value== -1] <- NA
names(dat4)[2:3] <- c("mid","variable")

dat4
   pid mid variable
1   C1  m1        2
2   C2  m1        2
3   C3  m1        1
4   C4  m1       NA
5   C5  m1        0
6   C1  m2        1
7   C2  m2        0
8   C3  m2        1
9   C4  m2       NA
10  C5  m2        1
11  C1  m3        0
12  C2  m3        1
13  C3  m3        1
14  C4  m3       NA
15  C5  m3        0

dat5 <- merge(dat4, dat3, all.x=T)

aggregate(dat5$value, list(dat5$pid), sum, na.rm=T)
  Group.1        x
1      C1   3.9720
2      C2  -1.5450
3      C3   0.9920
4      C4   0.0000
5      C5 -16.7992

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Xianming Wei
> Sent: Tuesday, August 11, 2015 3:05 AM
> To: R-help at r-project.org
> Subject: [R] replacing then summing by values from another dataframe
>
> [I might have sent  the following request to a wrong email address -
> 'r-help-request at r-project.org']
>
> Hi,
>
>
>
> I have two data frame dat1 and dat2.
>
>
>
> dat1 <- data.frame(pid = paste('C', 1:5, sep = ''),
>
>                                     m1 = c(2, 2, 1, -1, 0),
>
>                                      m2 = c(1, 0, 1, -1, 1),
>
>                                      m3 = c(0, 1, 1, -1, 0))
>
> dat2 <- data.frame(mid = paste('m', 1:3, sep = ''),
>
>                                     '0' = c(-19.5482, -.512, -.492),
>
>                                      '1' = c(.007, 3.241, -2.256),
>
>                                      '2' =c(1.223, -4.490, 1.779))
> names(dat2)[-1] <- c('0', '1', '2')
>
>
>
> dat1 contains individuals with scores of three measurements (-1
> represents missing) and dat2 with the effect of the different levels of
> the three measurements. What I'd like to do is to summise the effects
> of three measurements based on the level effects. So C1 I want to get
> the values of dat2 for m1 at level 2 = 1.223, m2 at level 1 = 3.241 and
> m3 at level 0 = -0.4920 and sum them up as 3.972.
>
>
>
> I can only think of a loop to do that at the moment. Because of much
> higher dimensions of actual two datasets, I need help to come up with
> an efficient / elegant approach.
>
>
>
> Any help is much appreciated.
>
>
>
>
>
> Regards,
>
> Xianming
>
>
>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Aug 11 08:40:06 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 11 Aug 2015 06:40:06 +0000
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAJuCY5w+jgXX_BupPMRpTY2zPXBv_zUZ_uW48jzej9ecdLM_Sw@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAJuCY5w+jgXX_BupPMRpTY2zPXBv_zUZ_uW48jzej9ecdLM_Sw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39627@SRVEXCHMBX.precheza.cz>

Hi

here is another approach.

> cbind(mydata, idx=(rowSums(mydata==2, na.rm=T)>0)*1)
   X125 X255 X558 X2366 X177 X255.1 idx
aa    0    1    0    NA    0      0   0
bb    1    1    0    NA    0      1   0
cs    2    1    2     1    0      0   1
de    0    1    0    NA    0      0   0
gh    2    0    0     0    0      0   1

It shall be faster if this is an issue.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thierry
> Onkelinx
> Sent: Monday, August 10, 2015 10:29 PM
> To: Lida Zeighami
> Cc: r-help at r-project.org
> Subject: Re: [R] add an idx column to the matrix
>
> Dear Lida,
>
> Here is a solution. Please don't post in HTML. And provide an easy to
> use
> example of the data. E.g. the output of dput(mydata)
>
> set.seed(1234)
> mydata <- matrix(
>   sample(
>     c(0, 1, 2, NA),
>     size = 30,
>     replace = TRUE,
>     prob = c(2, 1, 1, 1)
>   ),
>   ncol = 6
> )
>
> idx <- apply(mydata, 1, function(x){any(x == 2)})
> idx[is.na(idx)] <- FALSE
> cbind(mydata, idx)
>
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> 2015-08-10 22:11 GMT+02:00 Lida Zeighami <lid.zigh at gmail.com>:
>
> > Hi there,
> >
> > I have a matrix contain 0,1,2, NA elements.
> > I want to add a column to this matrix with name of "idx" . then for
> each
> > row, I should put 1 in this column (idx) if there is at least one 2
> in that
> > row otherwise I should put 0 in this column!
> >
> > for example  mydata:
> >
> >        125   255   558   2366   177    255
> > aa    0        1       0         NA    0         0
> > bb    1        1       0         NA    0         1
> > cs     2        1       2         1       0         0
> > de    0        1       0         NA    0         0
> > gh    2       0       0         0        0         0
> >
> >
> > my output should be:
> >
> >
> >        125   255   558   2366   177    255    idx
> > aa    0        1       0         NA    0         0      0
> > bb    1        1       0         NA    0         1      0
> > cs     2        1       2         1       0         0     1
> > de    0        1       0         NA    0         0      0
> > gh    2       0       0        2        0         2       1
> >
> > Thank you for your help.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Gerrit.Eichner at math.uni-giessen.de  Tue Aug 11 09:05:47 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 11 Aug 2015 09:05:47 +0200 (MEST)
Subject: [R] replacing then summing by values from another dataframe
In-Reply-To: <326b356b0ac44179ac3b87f204d6f5a8@bneexchsvr.sugarresearch.local>
References: <326b356b0ac44179ac3b87f204d6f5a8@bneexchsvr.sugarresearch.local>
Message-ID: <Pine.SOC.4.64.1508110855410.26151@solcom.hrz.uni-giessen.de>

Hello, Xianming,

I have changed your (particular) data structure: use matrices because you 
have only numeric scores and effects, use NA instead of -1 as missing 
value (as usual), don't use columns for ids or row/column names (except 
for the easy of reading the data structures), increase your score values 
in dat1 by 1 to obtain valid column indices for dat2. Finally, loop (!) 
rowwise through your matrix dat1 and construct an index-matrix (!) to 
index dat2 (and sum up the indexed elements). Hope this does what you 
want. (See below.)

The same remark regarding elegancy/efficiency applies as in Petr's 
solution (but w/o an additional package ;-)).


dat1 <- cbind( c(2, 2, 1, NA, 0),
                c(1, 0, 1, NA, 1),
                c(0, 1, 1, NA, 0))
# dimnames( dat1) <- list( paste0( 'C', 1:5), paste0( "m", 1:3))

dat2 <- cbind( c(-19.5482, -.512, -.492),
                c(.007, 3.241, -2.256),
                c(1.223, -4.490, 1.779))
# rownames( dat2) <- paste0 ('m', 1:3)

apply( dat1 + 1, 1,
        function( idx, d2)
         sum( d2[ cbind( seq( nrow( d2)), idx)]),
        d2 = dat2
       )


  Hth  --  Gerrit



On Tue, 11 Aug 2015, Xianming Wei wrote:

> [I might have sent  the following request to a wrong email address - 'r-help-request at r-project.org']
>
> Hi,
>
>
>
> I have two data frame dat1 and dat2.
>
>
>
> dat1 <- data.frame(pid = paste('C', 1:5, sep = ''),
>
>                                    m1 = c(2, 2, 1, -1, 0),
>
>                                     m2 = c(1, 0, 1, -1, 1),
>
>                                     m3 = c(0, 1, 1, -1, 0))
>
> dat2 <- data.frame(mid = paste('m', 1:3, sep = ''),
>
>                                    '0' = c(-19.5482, -.512, -.492),
>
>                                     '1' = c(.007, 3.241, -2.256),
>
>                                     '2' =c(1.223, -4.490, 1.779)) names(dat2)[-1] <- c('0', '1', '2')
>
>
>
> dat1 contains individuals with scores of three measurements (-1 represents missing) and dat2 with the effect of the different levels of the three measurements. What I'd like to do is to summise the effects of three measurements based on the level effects. So C1 I want to get the values of dat2 for m1 at level 2 = 1.223, m2 at level 1 = 3.241 and m3 at level 0 = -0.4920 and sum them up as 3.972.
>
>
>
> I can only think of a loop to do that at the moment. Because of much higher dimensions of actual two datasets, I need help to come up with an efficient / elegant approach.
>
>
>
> Any help is much appreciated.
>
>
>
>
>
> Regards,
> Xianming
>
>
> -------------------- Internet e-Mail Disclaimer --------------------
>
> PRIVILEGED - PRIVATE AND CONFIDENTIAL: This email and any files transmitted with it are intended solely for the use of the addressee(s) and may contain information, which is confidential or privileged. If you are not the intended recipient, be aware that any disclosure, copying, distribution, or use of the contents of this information is prohibited. In such case, you should destroy this message and kindly notify the sender by reply e-mail. The views and opinions expressed in this e-mail are those of the sender and do not necessarily reflect the views of the company.
>
> VIRUSES:  Email transmission cannot be guaranteed to be secure or error free, as information may be intercepted, corrupted, lost, destroyed, arrive late or incomplete or contain viruses. This email and any files attached to it have been checked with virus detection software before transmission. You should nonetheless carry out your own virus check before opening any attachment. Sugar Research Australia Limited does not represent or warrant that files attached to this email are free from computer viruses or other defects and accepts no liability for any loss or damage that may be caused by software viruses
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Tue Aug 11 10:00:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 11 Aug 2015 10:00:28 +0200
Subject: [R] LMER - generate data and define model (2 fixed effects and
 1 random effect or 1 fixed effect and 2 random effects)
In-Reply-To: <9D94908A-2EB3-4F66-B492-1AE187B7489E@gmail.com>
References: <9D94908A-2EB3-4F66-B492-1AE187B7489E@gmail.com>
Message-ID: <CAJuCY5wn2HZ9H+MDWP2st2q2DCt9QDE552Xe3u_NTRLGTvdp+g@mail.gmail.com>

Dear Rosa,

1) use cut() to convert a continuous variable into a factor. See ?cut for
the details.
2) The syntax for factors is the same as for continuous variables. Just add
the name of the factor variable to the formula
fAge <- cut(age)
yy~1+fAge+time+(time|id.pat)
3) Add + (1|fAge) to the formula. Note that adding fAge to both the fixed
and the random effect doesn't make sense.
yy~1+time+(time|id.pat) + (1|fAge)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-08-11 1:44 GMT+02:00 Rosa Oliveira <rosita21 at gmail.com>:

>
>
>
> ###############################################################################
>
> # Clear memory and set the working directory and the seed
>
>
> ###############################################################################
>
> rm(list = ls())
>
> setwd("/Dropbox/LMER/R ")
>
> set.seed(7010)
>
>
> ###############################################################################
>
> # Load up needed packages and do a require
>
>
> ###############################################################################
>
> # install.packages("gdata")
>
>
>
> library(nlme)
>
> library(lme4)
>
>
>
> nsample                                       = 1000                    #
> Number of subjects
>
> n.longitudinal.observations  = 5                                  # number
> of observations per subject
>
>
>
>
> ###############################################################################
>
> # Set the other parameters
>
>
> ###############################################################################
>
> id.pat                       = rep(seq(1:nsample), each
> =n.longitudinal.observations)
>
> time                         = rep(seq(1:n.longitudinal.observations)-1,
> nsample)
>
> age                          = rnorm(nsample, mean = 36, sd = .8)
> id.age                      = rep(seq(1: n.longitudinal.observations),
> each =age)
>
>
>
>
>
> ###############################################################################
> MODEL WITHOUT AGE
>
> boldBeta_individual_blup = coef(lmer(yy~1+time+(time|id.pat)   ))$id.pat
>  #mixed model
>
>
>
>
>
> ###############################################################################
> MODEL WITH AGE
>
> boldBeta_individual_blup = coef(lmer(yy~1+age+time+(time|id.pat)
>  ))$id.pat   #mixed model
>
>
>
> Dear all,
>
>
>
>
>
> I?m trying to use LMER in my simulation problem, and I?m having problems
> ate the very begging L I?m new in LMER. Can you please help me?
>
>
>
>
>
> 1st problem:
>
> how do I generate age so I can use it as a fixed factor?
>
> 2nd problem:
>
> how do I insert age as a fixed factor?
>
> 3rd problem:
>
>  what if I wanted to insert a 2nd random effect based on age?
>
>
>
> Best,
>
> RO
>
>
>
> Atenciosamente,
> Rosa Oliveira
>
> --
>
> ____________________________________________________________________________
>
>
> Rosa Celeste dos Santos Oliveira,
>
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From janka.vanschoenwinkel at uhasselt.be  Tue Aug 11 14:38:49 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka Vanschoenwinkel)
Date: Tue, 11 Aug 2015 14:38:49 +0200
Subject: [R] cut variable within a loop
Message-ID: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>

Dear list members,

I have a loop where I want to do several calculations for different samples
and save the results for each sample. These samples are for each loop
different. I want to use the "i" in the loop to cut the samples.

So for instance:

   - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
   - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
   - In loop 99 (i=99), I have a sample from 0-99 and a sample from 99-100.

I built the following function, but there is *a problem with the cut2
function* since it doesn't recognize the "i". Outside the lapply loop it
works, but not inside the loop.

Could somebody please help me with this problem? Thanks a lot!


d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))



    o<-lapply(0:100, function(i){



        Alldata$irri=cut2(Alldata$irrigation,i)

        levels(Alldata$irri)<-c("0","1")



       Alldata_Rainfed<-subset(Alldata, irri == 0)

       Alldata_Irrigation<-subset(Alldata, irri == 1)



    #calculations per sample, then store all the values per i and per
variable in a dataframe: (the calculations are not shown in this example)



     d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)



   })



   out<-as.data.frame(do.call(rbind, o))


-- 
P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Aug 11 14:52:58 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 11 Aug 2015 14:52:58 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
Message-ID: <CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>

Dear Janka,

You loop goes for 0 to 100. It should probably go from 1:99

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
janka.vanschoenwinkel at uhasselt.be>:

> Dear list members,
>
> I have a loop where I want to do several calculations for different samples
> and save the results for each sample. These samples are for each loop
> different. I want to use the "i" in the loop to cut the samples.
>
> So for instance:
>
>    - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>    - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>    - In loop 99 (i=99), I have a sample from 0-99 and a sample from 99-100.
>
> I built the following function, but there is *a problem with the cut2
> function* since it doesn't recognize the "i". Outside the lapply loop it
> works, but not inside the loop.
>
> Could somebody please help me with this problem? Thanks a lot!
>
>
>
> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>
>
>
>     o<-lapply(0:100, function(i){
>
>
>
>         Alldata$irri=cut2(Alldata$irrigation,i)
>
>         levels(Alldata$irri)<-c("0","1")
>
>
>
>        Alldata_Rainfed<-subset(Alldata, irri == 0)
>
>        Alldata_Irrigation<-subset(Alldata, irri == 1)
>
>
>
>     #calculations per sample, then store all the values per i and per
> variable in a dataframe: (the calculations are not shown in this example)
>
>
>
>      d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>
>
>
>    })
>
>
>
>    out<-as.data.frame(do.call(rbind, o))
>
>
> --
> P Please consider the environment before printing this e-mail
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From janka.vanschoenwinkel at uhasselt.be  Tue Aug 11 14:57:55 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka Vanschoenwinkel)
Date: Tue, 11 Aug 2015 14:57:55 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
Message-ID: <CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>

Hi Thierry!

Thanks for your answer. I tried this, but I get this error:

"Error in cut.default(x, k2) : invalid number of intervals"

Which is strange because I am not specifying intervals, but the number at
where the sample has to be cut?

Greetings from Belgium! :-)

2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Janka,
>
> You loop goes for 0 to 100. It should probably go from 1:99
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
> janka.vanschoenwinkel at uhasselt.be>:
>
>> Dear list members,
>>
>> I have a loop where I want to do several calculations for different
>> samples
>> and save the results for each sample. These samples are for each loop
>> different. I want to use the "i" in the loop to cut the samples.
>>
>> So for instance:
>>
>>    - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>>    - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>>    - In loop 99 (i=99), I have a sample from 0-99 and a sample from
>> 99-100.
>>
>> I built the following function, but there is *a problem with the cut2
>> function* since it doesn't recognize the "i". Outside the lapply loop it
>> works, but not inside the loop.
>>
>> Could somebody please help me with this problem? Thanks a lot!
>>
>>
>>
>> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>>
>>
>>
>>     o<-lapply(0:100, function(i){
>>
>>
>>
>>         Alldata$irri=cut2(Alldata$irrigation,i)
>>
>>         levels(Alldata$irri)<-c("0","1")
>>
>>
>>
>>        Alldata_Rainfed<-subset(Alldata, irri == 0)
>>
>>        Alldata_Irrigation<-subset(Alldata, irri == 1)
>>
>>
>>
>>     #calculations per sample, then store all the values per i and per
>> variable in a dataframe: (the calculations are not shown in this example)
>>
>>
>>
>>      d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>>
>>
>>
>>    })
>>
>>
>>
>>    out<-as.data.frame(do.call(rbind, o))
>>
>>
>> --
>> P Please consider the environment before printing this e-mail
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 

[image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel
*Doctoraatsbursaal - PhD *
Milieueconomie - Environmental economics

T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt

P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Aug 11 15:10:08 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 11 Aug 2015 15:10:08 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
Message-ID: <CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>

You'll need to send a reproducible example of the code. We can't run the
code that you send. Hence it is hard to help you. See e.g.
http://adv-r.had.co.nz/Reproducibility.html

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-08-11 14:57 GMT+02:00 Janka Vanschoenwinkel <
janka.vanschoenwinkel at uhasselt.be>:

> Hi Thierry!
>
> Thanks for your answer. I tried this, but I get this error:
>
> "Error in cut.default(x, k2) : invalid number of intervals"
>
> Which is strange because I am not specifying intervals, but the number at
> where the sample has to be cut?
>
> Greetings from Belgium! :-)
>
> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Janka,
>>
>> You loop goes for 0 to 100. It should probably go from 1:99
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
>> janka.vanschoenwinkel at uhasselt.be>:
>>
>>> Dear list members,
>>>
>>> I have a loop where I want to do several calculations for different
>>> samples
>>> and save the results for each sample. These samples are for each loop
>>> different. I want to use the "i" in the loop to cut the samples.
>>>
>>> So for instance:
>>>
>>>    - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>>>    - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>>>    - In loop 99 (i=99), I have a sample from 0-99 and a sample from
>>> 99-100.
>>>
>>> I built the following function, but there is *a problem with the cut2
>>> function* since it doesn't recognize the "i". Outside the lapply loop it
>>> works, but not inside the loop.
>>>
>>> Could somebody please help me with this problem? Thanks a lot!
>>>
>>>
>>>
>>> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>>>
>>>
>>>
>>>     o<-lapply(0:100, function(i){
>>>
>>>
>>>
>>>         Alldata$irri=cut2(Alldata$irrigation,i)
>>>
>>>         levels(Alldata$irri)<-c("0","1")
>>>
>>>
>>>
>>>        Alldata_Rainfed<-subset(Alldata, irri == 0)
>>>
>>>        Alldata_Irrigation<-subset(Alldata, irri == 1)
>>>
>>>
>>>
>>>     #calculations per sample, then store all the values per i and per
>>> variable in a dataframe: (the calculations are not shown in this example)
>>>
>>>
>>>
>>>      d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>>>
>>>
>>>
>>>    })
>>>
>>>
>>>
>>>    out<-as.data.frame(do.call(rbind, o))
>>>
>>>
>>> --
>>> P Please consider the environment before printing this e-mail
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
>
> [image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel
> *Doctoraatsbursaal - PhD *
> Milieueconomie - Environmental economics
>
> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
>
> www.uhasselt.be/eec
>
> Universiteit Hasselt | Campus Diepenbeek
> Agoralaan Gebouw D | B-3590 Diepenbeek
> Kantoor F11
>
> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>
> P Please consider the environment before printing this e-mail
>
>

	[[alternative HTML version deleted]]


From ramiro at precisionbioassay.com  Tue Aug 11 15:32:06 2015
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Tue, 11 Aug 2015 13:32:06 +0000
Subject: [R] Error in .External2(C_X11, paste("png::", filename, sep = ""),
 g$width, :   unable to start device PNG
Message-ID: <C7338A7EFF31BB4D831BB06C00887789B2FA3E4A@MBX023-W1-CA-2.exch023.domain.local>

Hello,

I have the following reproducible knitr document:

\documentclass{article}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}

\begin{document}

<<test,dev="png",echo=FALSE>>=
library(lattice)
xyplot(1:2~1:2)
@

\end{document}


but knitr is giving me an error:

Quitting from lines 9-11 (test.Rnw)
Error in .External2(C_X11, paste("png::", filename, sep = ""), g$width,  :
  unable to start device PNG
In addition: Warning message:
In (function (filename = "Rplot%03d.png", width = 480, height = 480,  :
  unable to open connection to X11 display ''

I don't have X11 installed in this machine and I was hoping not to have to.  I am guessing that this is the problem right?

Any suggestions??

Thanks,
Ramiro


	[[alternative HTML version deleted]]


From xie at yihui.name  Tue Aug 11 15:59:49 2015
From: xie at yihui.name (Yihui Xie)
Date: Tue, 11 Aug 2015 08:59:49 -0500
Subject: [R] Error in .External2(C_X11, paste("png::", filename,
 sep = ""), g$width, : unable to start device PNG
In-Reply-To: <C7338A7EFF31BB4D831BB06C00887789B2FA3E4A@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C00887789B2FA3E4A@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <CANROs4dxgdeQukQNCPsjrVFzBpVr+8Du_hzoZauSgurA7iDihw@mail.gmail.com>

>From my experience, that is often an indication that you built R from
source but didn't pay attention to the cairo/pango dependencies. You
can either install R from a repository, or make sure you have all the
dependencies installed before you build R from source (e.g. for
Ubuntu, use apt-get build-dep r-base-dev).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Tue, Aug 11, 2015 at 8:32 AM, Ramiro Barrantes
<ramiro at precisionbioassay.com> wrote:
> Hello,
>
> I have the following reproducible knitr document:
>
> \documentclass{article}
> \usepackage[sc]{mathpazo}
> \usepackage[T1]{fontenc}
> \usepackage{geometry}
>
> \begin{document}
>
> <<test,dev="png",echo=FALSE>>=
> library(lattice)
> xyplot(1:2~1:2)
> @
>
> \end{document}
>
>
> but knitr is giving me an error:
>
> Quitting from lines 9-11 (test.Rnw)
> Error in .External2(C_X11, paste("png::", filename, sep = ""), g$width,  :
>   unable to start device PNG
> In addition: Warning message:
> In (function (filename = "Rplot%03d.png", width = 480, height = 480,  :
>   unable to open connection to X11 display ''
>
> I don't have X11 installed in this machine and I was hoping not to have to.  I am guessing that this is the problem right?
>
> Any suggestions??
>
> Thanks,
> Ramiro


From jrkrideau at inbox.com  Tue Aug 11 16:16:30 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 11 Aug 2015 06:16:30 -0800
Subject: [R] Plotting wind direction as arrows with precipitation
In-Reply-To: <CAGphrqrBe91PrqXw2e3SaPybs_FP4ZOVxixY7yStbmg-Cje5-A@mail.gmail.com>
Message-ID: <2146629A792.000000E5jrkrideau@inbox.com>

Hi, 
Good example and data.  Thanks.

Here are a couple of approaches that may help. 
I tend to use a lot of what I tend to think of as the ggplot family of associated so you may need to install a couple packages. I used lubridate to transform your character dates to  POSIXct. Jeff N's code does exatly the same in base R. so you don't really need the lubridate package.

 I changed the data set name to dat1 and transformed the column names to lower case just for my convenience.  Data is now in dput() form. See ?dput() for more information. It is the preferred way to share data on R-help

Given what appears to be vastly different y-scales for rainfall and wind direction it struck me that it might be better to have the data in two plots so I included that option.

I am not really sure how to get the arrows you want. You may be able to do it using scale_shape_manual  but I am not sure if the required symbols are available.

You may have to manually draw them. See http://stackoverflow.com/questions/3421331/example-needed-using-arrow-with-ggplot2 for how to draw an arrow.  

John Kane
Kingston ON Canada
##============Start code==============
library(ggplot2)
library(reshape2)
library(lubridate)
library(gridExtra)

dat1  <-  structure(list(deal1 = c("10/22/2012 0:00", "10/22/2012 0:15", 
"10/22/2012 0:30", "10/22/2012 0:45", "10/22/2012 1:00", "10/22/2012 1:15"
), rainfall_cm = c(0L, 0L, 0L, 0L, 0L, 0L), wind_direction1 = c(296L, 
317L, 323L, 323L, 326L, 326L), wind_direction2 = c("W", "NW", 
"NW", "NW", "NW", "NW")), .Names = c("deal1", "rainfall_cm", 
"wind_direction1", "wind_direction2"), class = "data.frame", row.names = c(NA, 
-6L))


dat1$deal1 <- mdy_hm(dat1$deal1) # Lazy man's equivalent of Jeff N's Sandy$Deal1 <- as.POSIXct( Sandy$Deal1, format="%m/%d/%Y %H:%M")

dat2  <-  melt(dat1[ , 1:3], id.var = "deal1")  # use reshape to rearrange data.
p  <-  ggplot(dat2, aes(deal1, value, colour = variable) )+ geom_point()
p

## possible option
g1  <-  ggplot(dat1, aes(deal1,  wind_direction1)) + geom_point() + theme(axis.title.x=element_blank())
g2  <-  ggplot(dat1, aes(deal1, rainfall_cm ) )+ geom_point()

grid.arrange( g1, g2, ncol=1)

##===========end code==================


> -----Original Message-----
> From: rhelp10 at gmail.com
> Sent: Mon, 10 Aug 2015 00:05:27 -0400
> To: r-help at r-project.org
> Subject: [R] Plotting wind direction as arrows with precipitation
> 
> Hello R users!
> 
> I am trying to create a time series in R with two variables,
> precipitation
> and wind direction vs Date/Time.
> 
> I am looking for suggestions and maybe even sample code.
> 
> My workbook is called "Sandy" and has columns with Date/Time,
> Raindall_cm,
> Wind Direction in both degree format (0-359) and in character form (N,
> NW,
> S, SW, SE, E, NE, NW).
> 
> I have done some reading for it on stackoverflow and other sites but not
> making head way.
> 
> I will be graphing with ggplot most likely and am a beginner in R, self
> taught from books and online resources.
> 
> This is the code I have and a small peak into the data.
> 
> Sandy<-read.csv("Sandy.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
>> head(Sandy)
>       Deal1     Rainfall_cm    Wind_Direction1 Wind_Direction2
> 1 10/22/2012 0:00           0        296         W
> 2 10/22/2012 0:15           0        317        NW
> 3 10/22/2012 0:30           0        323        NW
> 4 10/22/2012 0:45           0        323        NW
> 5 10/22/2012 1:00           0        326        NW
> 6 10/22/2012 1:15           0        326        NW
> 
>> class(Sandy)
> [1] "data.frame"
> 
>> str(Sandy)
> 'data.frame':   1832 obs. of  4 variables:
>  $ Deal1         : chr  "10/22/2012 0:00" "10/22/2012 0:15" "10/22/2012
> 0:30" "10/22/2012 0:45" ...
>  $ Rainfall_cm   : num  0 0 0 0 0 0 0 0 0 0 ...
> 
>  $ Wind_Direction: num 296 317  323   323  326  326
> 
>  $ Wind_Direction: chr  "W" "NW" "NW" "NW" ...
> 
>> require(ggplot2)
> Loading required package: ggplot2
> 
> # this graph does the precipitation vs time graph, but not the wind
> 
>> ggplot(Sandy, aes(x = Deal1, y = Rainfall_cm, group = 1)) +
> geom_line(stat = "identity")
> 
> 
> Ideally I want it to have the precipitation graph vs time, then wind vs
> time on the same graph. I would like the wind direction to be arrows
> pointing in the designated direction (i.e. North points north).
> 
> Thank you!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From thierry.onkelinx at inbo.be  Tue Aug 11 16:41:12 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 11 Aug 2015 16:41:12 +0200
Subject: [R] Problem with path.expand("~")
Message-ID: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>

Dear all,

I'm puzzled by the behaviour of path.expand("~")

In the RStudio IDE the output is
> path.expand("~")
[1] "C:/Users/thierry_onkelinx/Documents"

In the R GUI the output is
> path.expand("~")
[1] "~"

But I'm expecting the same result as in the RStudio IDE. The "Start in"
parameter of shortcut to the R GUI has the value
"C:\Users\thierry_onkelinx\Documents"

The problem is that I use normalizePath("~/analysis"). This
yield "C:\\Users\\thierry_onkelinx\\Documents\\analysis" in RStudio

It throws an error in the R GUI
"C:\\Users\\thierry_onkelinx\\Documents\\~\\analysis"
Warning message:
In normalizePath(path.expand(path), winslash, mustWork) :
  path[1]="~/analysis": Het systeem kan het opgegeven pad niet vinden

# sessionInfo() in RStudio
R version 3.2.1 (2015-06-18)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
 LC_MONETARY=Dutch_Belgium.1252
[4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.2.1    fortunes_1.5-2

# sessionInfo() from R GUI
R version 3.2.1 (2015-06-18)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
[3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
[5] LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.2.1    fortunes_1.5-2


Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Aug 11 16:51:28 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 11 Aug 2015 10:51:28 -0400
Subject: [R] Problem with path.expand("~")
In-Reply-To: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>
References: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>
Message-ID: <CAM_vjumy7ZUXRbVt3D0UEJg3p8YO90JbDRqmKkf20MFXu3dBoA@mail.gmail.com>

Hm.

On my linux system:

> path.expand("~")
[1] "/home/sarahg"

The help file says:
     Expand a path name, for example by replacing a leading tilde by
     the user's home directory (if defined on that platform).

Does Windows 7 define ~?

Just because RStudio defines it for you, doesn't mean that R shares that
same setup; if R is checking with the operating system, then it depends on
the Windows setup. You could, I assume, define ~ in Windows yourself, or
write your own path.expand() to do so. I have no idea which option the
RStudio designers took.

Could you use getwd() to get the output you're looking for? I would expect
~ to properly be "C:/Users/thierry_onkelinx" and getwd() to be what you've
set Start in as, suggesting that not only did RStudio define ~ for Windows,
they did it in a non-standard way. (Unless your home directory on Windows
should be Documents?)

Sarah

On Tue, Aug 11, 2015 at 10:41 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear all,
>
> I'm puzzled by the behaviour of path.expand("~")
>
> In the RStudio IDE the output is
> > path.expand("~")
> [1] "C:/Users/thierry_onkelinx/Documents"
>
> In the R GUI the output is
> > path.expand("~")
> [1] "~"
>
> But I'm expecting the same result as in the RStudio IDE. The "Start in"
> parameter of shortcut to the R GUI has the value
> "C:\Users\thierry_onkelinx\Documents"
>
> The problem is that I use normalizePath("~/analysis"). This
> yield "C:\\Users\\thierry_onkelinx\\Documents\\analysis" in RStudio
>
> It throws an error in the R GUI
> "C:\\Users\\thierry_onkelinx\\Documents\\~\\analysis"
> Warning message:
> In normalizePath(path.expand(path), winslash, mustWork) :
>   path[1]="~/analysis": Het systeem kan het opgegeven pad niet vinden
>
> # sessionInfo() in RStudio
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
>  LC_MONETARY=Dutch_Belgium.1252
> [4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.1    fortunes_1.5-2
>
> # sessionInfo() from R GUI
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> [5] LC_TIME=Dutch_Belgium.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.1    fortunes_1.5-2
>
>
> Best regards,
>
-- 
Sarah Goslee
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Aug 11 16:55:55 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 11 Aug 2015 07:55:55 -0700
Subject: [R] Plotting wind direction as arrows with precipitation
In-Reply-To: <2146629A792.000000E5jrkrideau@inbox.com>
References: <CAGphrqrBe91PrqXw2e3SaPybs_FP4ZOVxixY7yStbmg-Cje5-A@mail.gmail.com>
	<2146629A792.000000E5jrkrideau@inbox.com>
Message-ID: <CAGxFJbTSdjCjeLnzYTrCbYwQhcC6zbH9iVYc38foHmdvrY5ywA@mail.gmail.com>

... don't know if this will help, but grid graphics, which is the
graphics engine for both trellis and ggplot, has a basic arrow()
function. Trellis's provides an interface to it with the
panel.arrows() panel function. I suspect ggplot has something similar,
but as I don't use it, I don't know for sure.

There is also an arrows() function in the basic (non-grid) graphics
engine, but this is probably irrelevant for your needs.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Aug 11, 2015 at 7:16 AM, John Kane <jrkrideau at inbox.com> wrote:
> Hi,
> Good example and data.  Thanks.
>
> Here are a couple of approaches that may help.
> I tend to use a lot of what I tend to think of as the ggplot family of associated so you may need to install a couple packages. I used lubridate to transform your character dates to  POSIXct. Jeff N's code does exatly the same in base R. so you don't really need the lubridate package.
>
>  I changed the data set name to dat1 and transformed the column names to lower case just for my convenience.  Data is now in dput() form. See ?dput() for more information. It is the preferred way to share data on R-help
>
> Given what appears to be vastly different y-scales for rainfall and wind direction it struck me that it might be better to have the data in two plots so I included that option.
>
> I am not really sure how to get the arrows you want. You may be able to do it using scale_shape_manual  but I am not sure if the required symbols are available.
>
> You may have to manually draw them. See http://stackoverflow.com/questions/3421331/example-needed-using-arrow-with-ggplot2 for how to draw an arrow.
>
> John Kane
> Kingston ON Canada
> ##============Start code==============
> library(ggplot2)
> library(reshape2)
> library(lubridate)
> library(gridExtra)
>
> dat1  <-  structure(list(deal1 = c("10/22/2012 0:00", "10/22/2012 0:15",
> "10/22/2012 0:30", "10/22/2012 0:45", "10/22/2012 1:00", "10/22/2012 1:15"
> ), rainfall_cm = c(0L, 0L, 0L, 0L, 0L, 0L), wind_direction1 = c(296L,
> 317L, 323L, 323L, 326L, 326L), wind_direction2 = c("W", "NW",
> "NW", "NW", "NW", "NW")), .Names = c("deal1", "rainfall_cm",
> "wind_direction1", "wind_direction2"), class = "data.frame", row.names = c(NA,
> -6L))
>
>
> dat1$deal1 <- mdy_hm(dat1$deal1) # Lazy man's equivalent of Jeff N's Sandy$Deal1 <- as.POSIXct( Sandy$Deal1, format="%m/%d/%Y %H:%M")
>
> dat2  <-  melt(dat1[ , 1:3], id.var = "deal1")  # use reshape to rearrange data.
> p  <-  ggplot(dat2, aes(deal1, value, colour = variable) )+ geom_point()
> p
>
> ## possible option
> g1  <-  ggplot(dat1, aes(deal1,  wind_direction1)) + geom_point() + theme(axis.title.x=element_blank())
> g2  <-  ggplot(dat1, aes(deal1, rainfall_cm ) )+ geom_point()
>
> grid.arrange( g1, g2, ncol=1)
>
> ##===========end code==================
>
>
>> -----Original Message-----
>> From: rhelp10 at gmail.com
>> Sent: Mon, 10 Aug 2015 00:05:27 -0400
>> To: r-help at r-project.org
>> Subject: [R] Plotting wind direction as arrows with precipitation
>>
>> Hello R users!
>>
>> I am trying to create a time series in R with two variables,
>> precipitation
>> and wind direction vs Date/Time.
>>
>> I am looking for suggestions and maybe even sample code.
>>
>> My workbook is called "Sandy" and has columns with Date/Time,
>> Raindall_cm,
>> Wind Direction in both degree format (0-359) and in character form (N,
>> NW,
>> S, SW, SE, E, NE, NW).
>>
>> I have done some reading for it on stackoverflow and other sites but not
>> making head way.
>>
>> I will be graphing with ggplot most likely and am a beginner in R, self
>> taught from books and online resources.
>>
>> This is the code I have and a small peak into the data.
>>
>> Sandy<-read.csv("Sandy.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
>>> head(Sandy)
>>       Deal1     Rainfall_cm    Wind_Direction1 Wind_Direction2
>> 1 10/22/2012 0:00           0        296         W
>> 2 10/22/2012 0:15           0        317        NW
>> 3 10/22/2012 0:30           0        323        NW
>> 4 10/22/2012 0:45           0        323        NW
>> 5 10/22/2012 1:00           0        326        NW
>> 6 10/22/2012 1:15           0        326        NW
>>
>>> class(Sandy)
>> [1] "data.frame"
>>
>>> str(Sandy)
>> 'data.frame':   1832 obs. of  4 variables:
>>  $ Deal1         : chr  "10/22/2012 0:00" "10/22/2012 0:15" "10/22/2012
>> 0:30" "10/22/2012 0:45" ...
>>  $ Rainfall_cm   : num  0 0 0 0 0 0 0 0 0 0 ...
>>
>>  $ Wind_Direction: num 296 317  323   323  326  326
>>
>>  $ Wind_Direction: chr  "W" "NW" "NW" "NW" ...
>>
>>> require(ggplot2)
>> Loading required package: ggplot2
>>
>> # this graph does the precipitation vs time graph, but not the wind
>>
>>> ggplot(Sandy, aes(x = Deal1, y = Rainfall_cm, group = 1)) +
>> geom_line(stat = "identity")
>>
>>
>> Ideally I want it to have the precipitation graph vs time, then wind vs
>> time on the same graph. I would like the wind direction to be arrows
>> pointing in the designated direction (i.e. North points north).
>>
>> Thank you!
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Tue Aug 11 17:01:07 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 11 Aug 2015 10:01:07 -0500
Subject: [R] Problem with path.expand("~")
In-Reply-To: <CAM_vjumy7ZUXRbVt3D0UEJg3p8YO90JbDRqmKkf20MFXu3dBoA@mail.gmail.com>
References: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>
	<CAM_vjumy7ZUXRbVt3D0UEJg3p8YO90JbDRqmKkf20MFXu3dBoA@mail.gmail.com>
Message-ID: <CAAJSdjiGbhva3BO8KntoS7pcXEAc09hBoY48m9P-_wSwef_LbA@mail.gmail.com>

Works correctly on 3.1.1 under Windows . You may have found a problem in
the Windows port. The Linux version of R 3.2.1 works correctly, for me.

R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i386-w64-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> path.expand("~")
[1] "C:\\Users\\john.mckown\\Documents"
>

===

R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> path.expand("~")
[1] "C:\\Users\\john.mckown\\Documents"
>


On Tue, Aug 11, 2015 at 9:51 AM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hm.
>
> On my linux system:
>
> > path.expand("~")
> [1] "/home/sarahg"
>
> The help file says:
>      Expand a path name, for example by replacing a leading tilde by
>      the user's home directory (if defined on that platform).
>
> Does Windows 7 define ~?
>
> Just because RStudio defines it for you, doesn't mean that R shares that
> same setup; if R is checking with the operating system, then it depends on
> the Windows setup. You could, I assume, define ~ in Windows yourself, or
> write your own path.expand() to do so. I have no idea which option the
> RStudio designers took.
>
> Could you use getwd() to get the output you're looking for? I would expect
> ~ to properly be "C:/Users/thierry_onkelinx" and getwd() to be what you've
> set Start in as, suggesting that not only did RStudio define ~ for Windows,
> they did it in a non-standard way. (Unless your home directory on Windows
> should be Documents?)
>
> Sarah
>
> On Tue, Aug 11, 2015 at 10:41 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be
> > wrote:
>
> > Dear all,
> >
> > I'm puzzled by the behaviour of path.expand("~")
> >
> > In the RStudio IDE the output is
> > > path.expand("~")
> > [1] "C:/Users/thierry_onkelinx/Documents"
> >
> > In the R GUI the output is
> > > path.expand("~")
> > [1] "~"
> >
> > But I'm expecting the same result as in the RStudio IDE. The "Start in"
> > parameter of shortcut to the R GUI has the value
> > "C:\Users\thierry_onkelinx\Documents"
> >
> > The problem is that I use normalizePath("~/analysis"). This
> > yield "C:\\Users\\thierry_onkelinx\\Documents\\analysis" in RStudio
> >
> > It throws an error in the R GUI
> > "C:\\Users\\thierry_onkelinx\\Documents\\~\\analysis"
> > Warning message:
> > In normalizePath(path.expand(path), winslash, mustWork) :
> >   path[1]="~/analysis": Het systeem kan het opgegeven pad niet vinden
> >
> > # sessionInfo() in RStudio
> > R version 3.2.1 (2015-06-18)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> >  LC_MONETARY=Dutch_Belgium.1252
> > [4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.1    fortunes_1.5-2
> >
> > # sessionInfo() from R GUI
> > R version 3.2.1 (2015-06-18)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> > [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> > [5] LC_TIME=Dutch_Belgium.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.1    fortunes_1.5-2
> >
> >
> > Best regards,
> >
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Aug 11 17:03:16 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 11 Aug 2015 11:03:16 -0400
Subject: [R] Problem with path.expand("~")
In-Reply-To: <CAM_vjumy7ZUXRbVt3D0UEJg3p8YO90JbDRqmKkf20MFXu3dBoA@mail.gmail.com>
References: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>
	<CAM_vjumy7ZUXRbVt3D0UEJg3p8YO90JbDRqmKkf20MFXu3dBoA@mail.gmail.com>
Message-ID: <55CA0EB4.7090901@gmail.com>

On 11/08/2015 10:51 AM, Sarah Goslee wrote:
> Hm.
> 
> On my linux system:
> 
>> path.expand("~")
> [1] "/home/sarahg"
> 
> The help file says:
>      Expand a path name, for example by replacing a leading tilde by
>      the user's home directory (if defined on that platform).
> 
> Does Windows 7 define ~?
> 
> Just because RStudio defines it for you, doesn't mean that R shares that
> same setup; if R is checking with the operating system, then it depends on
> the Windows setup. You could, I assume, define ~ in Windows yourself, or
> write your own path.expand() to do so. I have no idea which option the
> RStudio designers took.
> 
> Could you use getwd() to get the output you're looking for? I would expect
> ~ to properly be "C:/Users/thierry_onkelinx" and getwd() to be what you've
> set Start in as, suggesting that not only did RStudio define ~ for Windows,
> they did it in a non-standard way. (Unless your home directory on Windows
> should be Documents?)

The tilde meaning "home" is not a concept in Windows, but R fakes it.
This is described in ?path.expand and the R for Windows FAQ.  Thierry
should set the R_USER environment variable to whatever home dir he
wants.  RStudio is probably doing that for him.

Duncan Murdoch

> 
> Sarah
> 
> On Tue, Aug 11, 2015 at 10:41 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
>> wrote:
> 
>> Dear all,
>>
>> I'm puzzled by the behaviour of path.expand("~")
>>
>> In the RStudio IDE the output is
>>> path.expand("~")
>> [1] "C:/Users/thierry_onkelinx/Documents"
>>
>> In the R GUI the output is
>>> path.expand("~")
>> [1] "~"
>>
>> But I'm expecting the same result as in the RStudio IDE. The "Start in"
>> parameter of shortcut to the R GUI has the value
>> "C:\Users\thierry_onkelinx\Documents"
>>
>> The problem is that I use normalizePath("~/analysis"). This
>> yield "C:\\Users\\thierry_onkelinx\\Documents\\analysis" in RStudio
>>
>> It throws an error in the R GUI
>> "C:\\Users\\thierry_onkelinx\\Documents\\~\\analysis"
>> Warning message:
>> In normalizePath(path.expand(path), winslash, mustWork) :
>>   path[1]="~/analysis": Het systeem kan het opgegeven pad niet vinden
>>
>> # sessionInfo() in RStudio
>> R version 3.2.1 (2015-06-18)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
>>  LC_MONETARY=Dutch_Belgium.1252
>> [4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.1    fortunes_1.5-2
>>
>> # sessionInfo() from R GUI
>> R version 3.2.1 (2015-06-18)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
>> [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
>> [5] LC_TIME=Dutch_Belgium.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.1    fortunes_1.5-2
>>
>>
>> Best regards,
>>


From lists at dewey.myzen.co.uk  Tue Aug 11 17:25:04 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 11 Aug 2015 16:25:04 +0100
Subject: [R] cut variable within a loop
In-Reply-To: <CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
Message-ID: <55CA13D0.3020200@dewey.myzen.co.uk>

Dear Janka
If you supply a single number to the breaks parameter of cut I think it 
is the number of intervals.

On 11/08/2015 13:57, Janka Vanschoenwinkel wrote:
> Hi Thierry!
>
> Thanks for your answer. I tried this, but I get this error:
>
> "Error in cut.default(x, k2) : invalid number of intervals"
>
> Which is strange because I am not specifying intervals, but the number at
> where the sample has to be cut?
>
> Greetings from Belgium! :-)
>
> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Janka,
>>
>> You loop goes for 0 to 100. It should probably go from 1:99
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
>> janka.vanschoenwinkel at uhasselt.be>:
>>
>>> Dear list members,
>>>
>>> I have a loop where I want to do several calculations for different
>>> samples
>>> and save the results for each sample. These samples are for each loop
>>> different. I want to use the "i" in the loop to cut the samples.
>>>
>>> So for instance:
>>>
>>>     - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>>>     - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>>>     - In loop 99 (i=99), I have a sample from 0-99 and a sample from
>>> 99-100.
>>>
>>> I built the following function, but there is *a problem with the cut2
>>> function* since it doesn't recognize the "i". Outside the lapply loop it
>>> works, but not inside the loop.
>>>
>>> Could somebody please help me with this problem? Thanks a lot!
>>>
>>>
>>>
>>> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>>>
>>>
>>>
>>>      o<-lapply(0:100, function(i){
>>>
>>>
>>>
>>>          Alldata$irri=cut2(Alldata$irrigation,i)
>>>
>>>          levels(Alldata$irri)<-c("0","1")
>>>
>>>
>>>
>>>         Alldata_Rainfed<-subset(Alldata, irri == 0)
>>>
>>>         Alldata_Irrigation<-subset(Alldata, irri == 1)
>>>
>>>
>>>
>>>      #calculations per sample, then store all the values per i and per
>>> variable in a dataframe: (the calculations are not shown in this example)
>>>
>>>
>>>
>>>       d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>>>
>>>
>>>
>>>     })
>>>
>>>
>>>
>>>     out<-as.data.frame(do.call(rbind, o))
>>>
>>>
>>> --
>>> P Please consider the environment before printing this e-mail
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From wdunlap at tibco.com  Tue Aug 11 17:39:35 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 11 Aug 2015 08:39:35 -0700
Subject: [R] Problem with path.expand("~")
In-Reply-To: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>
References: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>
Message-ID: <CAF8bMcYG=eqH__RzBV79wjkD-SLCxab937cRgfFV2J-s_ktzxg@mail.gmail.com>

    In the R GUI the output is
    > path.expand("~")
    [1] "~"

Did you set the environment variable R_USER to something odd like "~"?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Aug 11, 2015 at 7:41 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear all,
>
> I'm puzzled by the behaviour of path.expand("~")
>
> In the RStudio IDE the output is
> > path.expand("~")
> [1] "C:/Users/thierry_onkelinx/Documents"
>
> In the R GUI the output is
> > path.expand("~")
> [1] "~"
>
> But I'm expecting the same result as in the RStudio IDE. The "Start in"
> parameter of shortcut to the R GUI has the value
> "C:\Users\thierry_onkelinx\Documents"
>
> The problem is that I use normalizePath("~/analysis"). This
> yield "C:\\Users\\thierry_onkelinx\\Documents\\analysis" in RStudio
>
> It throws an error in the R GUI
> "C:\\Users\\thierry_onkelinx\\Documents\\~\\analysis"
> Warning message:
> In normalizePath(path.expand(path), winslash, mustWork) :
>   path[1]="~/analysis": Het systeem kan het opgegeven pad niet vinden
>
> # sessionInfo() in RStudio
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
>  LC_MONETARY=Dutch_Belgium.1252
> [4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.1    fortunes_1.5-2
>
> # sessionInfo() from R GUI
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> [5] LC_TIME=Dutch_Belgium.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.1    fortunes_1.5-2
>
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Aug 11 18:52:30 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 11 Aug 2015 08:52:30 -0800
Subject: [R] Plotting wind direction as arrows with precipitation
In-Reply-To: <CAGxFJbTSdjCjeLnzYTrCbYwQhcC6zbH9iVYc38foHmdvrY5ywA@mail.gmail.com>
References: <cagphrqrbe91prqxw2e3sapybs_fp4zovxixy7ystbmg-cje5-a@mail.gmail.com>
	<2146629a792.000000e5jrkrideau@inbox.com>
Message-ID: <22A30A0E92F.00000328jrkrideau@inbox.com>

Thanks Bert,
I think that arrow()  would do what the OP needs. The main problem would be calculating the angles properly if I understand the issue. Still there cannot be "that" many points on a compass, can there?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: bgunter.4567 at gmail.com
> Sent: Tue, 11 Aug 2015 07:55:55 -0700
> To: jrkrideau at inbox.com
> Subject: Re: [R] Plotting wind direction as arrows with precipitation
> 
> ... don't know if this will help, but grid graphics, which is the
> graphics engine for both trellis and ggplot, has a basic arrow()
> function. Trellis's provides an interface to it with the
> panel.arrows() panel function. I suspect ggplot has something similar,
> but as I don't use it, I don't know for sure.
> 
> There is also an arrows() function in the basic (non-grid) graphics
> engine, but this is probably irrelevant for your needs.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
> 
> 
> On Tue, Aug 11, 2015 at 7:16 AM, John Kane <jrkrideau at inbox.com> wrote:
>> Hi,
>> Good example and data.  Thanks.
>> 
>> Here are a couple of approaches that may help.
>> I tend to use a lot of what I tend to think of as the ggplot family of
>> associated so you may need to install a couple packages. I used
>> lubridate to transform your character dates to  POSIXct. Jeff N's code
>> does exatly the same in base R. so you don't really need the lubridate
>> package.
>> 
>>  I changed the data set name to dat1 and transformed the column names to
>> lower case just for my convenience.  Data is now in dput() form. See
>> ?dput() for more information. It is the preferred way to share data on
>> R-help
>> 
>> Given what appears to be vastly different y-scales for rainfall and wind
>> direction it struck me that it might be better to have the data in two
>> plots so I included that option.
>> 
>> I am not really sure how to get the arrows you want. You may be able to
>> do it using scale_shape_manual  but I am not sure if the required
>> symbols are available.
>> 
>> You may have to manually draw them. See
http://stackoverflow.com/questions/3421331/example-needed-using-arrow-with-ggplot2
>> for how to draw an arrow.
>> 
>> John Kane
>> Kingston ON Canada
>> ##============Start code==============
>> library(ggplot2)
>> library(reshape2)
>> library(lubridate)
>> library(gridExtra)
>> 
>> dat1  <-  structure(list(deal1 = c("10/22/2012 0:00", "10/22/2012 0:15",
>> "10/22/2012 0:30", "10/22/2012 0:45", "10/22/2012 1:00", "10/22/2012
>> 1:15"
>> ), rainfall_cm = c(0L, 0L, 0L, 0L, 0L, 0L), wind_direction1 = c(296L,
>> 317L, 323L, 323L, 326L, 326L), wind_direction2 = c("W", "NW",
>> "NW", "NW", "NW", "NW")), .Names = c("deal1", "rainfall_cm",
>> "wind_direction1", "wind_direction2"), class = "data.frame", row.names =
>> c(NA,
>> -6L))
>> 
>> 
>> dat1$deal1 <- mdy_hm(dat1$deal1) # Lazy man's equivalent of Jeff N's
>> Sandy$Deal1 <- as.POSIXct( Sandy$Deal1, format="%m/%d/%Y %H:%M")
>> 
>> dat2  <-  melt(dat1[ , 1:3], id.var = "deal1")  # use reshape to
>> rearrange data.
>> p  <-  ggplot(dat2, aes(deal1, value, colour = variable) )+ geom_point()
>> p
>> 
>> ## possible option
>> g1  <-  ggplot(dat1, aes(deal1,  wind_direction1)) + geom_point() +
>> theme(axis.title.x=element_blank())
>> g2  <-  ggplot(dat1, aes(deal1, rainfall_cm ) )+ geom_point()
>> 
>> grid.arrange( g1, g2, ncol=1)
>> 
>> ##===========end code==================
>> 
>> 
>>> -----Original Message-----
>>> From: rhelp10 at gmail.com
>>> Sent: Mon, 10 Aug 2015 00:05:27 -0400
>>> To: r-help at r-project.org
>>> Subject: [R] Plotting wind direction as arrows with precipitation
>>> 
>>> Hello R users!
>>> 
>>> I am trying to create a time series in R with two variables,
>>> precipitation
>>> and wind direction vs Date/Time.
>>> 
>>> I am looking for suggestions and maybe even sample code.
>>> 
>>> My workbook is called "Sandy" and has columns with Date/Time,
>>> Raindall_cm,
>>> Wind Direction in both degree format (0-359) and in character form (N,
>>> NW,
>>> S, SW, SE, E, NE, NW).
>>> 
>>> I have done some reading for it on stackoverflow and other sites but
>>> not
>>> making head way.
>>> 
>>> I will be graphing with ggplot most likely and am a beginner in R, self
>>> taught from books and online resources.
>>> 
>>> This is the code I have and a small peak into the data.
>>> 
>>> Sandy<-read.csv("Sandy.csv", header=TRUE,
>>> sep=",",stringsAsFactors=FALSE)
>>>> head(Sandy)
>>>       Deal1     Rainfall_cm    Wind_Direction1 Wind_Direction2
>>> 1 10/22/2012 0:00           0        296         W
>>> 2 10/22/2012 0:15           0        317        NW
>>> 3 10/22/2012 0:30           0        323        NW
>>> 4 10/22/2012 0:45           0        323        NW
>>> 5 10/22/2012 1:00           0        326        NW
>>> 6 10/22/2012 1:15           0        326        NW
>>> 
>>>> class(Sandy)
>>> [1] "data.frame"
>>> 
>>>> str(Sandy)
>>> 'data.frame':   1832 obs. of  4 variables:
>>>  $ Deal1         : chr  "10/22/2012 0:00" "10/22/2012 0:15" "10/22/2012
>>> 0:30" "10/22/2012 0:45" ...
>>>  $ Rainfall_cm   : num  0 0 0 0 0 0 0 0 0 0 ...
>>> 
>>>  $ Wind_Direction: num 296 317  323   323  326  326
>>> 
>>>  $ Wind_Direction: chr  "W" "NW" "NW" "NW" ...
>>> 
>>>> require(ggplot2)
>>> Loading required package: ggplot2
>>> 
>>> # this graph does the precipitation vs time graph, but not the wind
>>> 
>>>> ggplot(Sandy, aes(x = Deal1, y = Rainfall_cm, group = 1)) +
>>> geom_line(stat = "identity")
>>> 
>>> 
>>> Ideally I want it to have the precipitation graph vs time, then wind vs
>>> time on the same graph. I would like the wind direction to be arrows
>>> pointing in the designated direction (i.e. North points north).
>>> 
>>> Thank you!
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Tue Aug 11 18:52:32 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 11 Aug 2015 08:52:32 -0800
Subject: [R] Plotting wind direction as arrows with precipitation
In-Reply-To: <CAGxFJbTSdjCjeLnzYTrCbYwQhcC6zbH9iVYc38foHmdvrY5ywA@mail.gmail.com>
References: <cagphrqrbe91prqxw2e3sapybs_fp4zovxixy7ystbmg-cje5-a@mail.gmail.com>
	<2146629a792.000000e5jrkrideau@inbox.com>
Message-ID: <22A322A4C8C.00000329jrkrideau@inbox.com>

Thanks Bert,
I think that arrow()  would do what the OP needs. The main problem would be calculating the angles properly if I understand the issue. Still there cannot be "that" many points on a compass, can there?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: bgunter.4567 at gmail.com
> Sent: Tue, 11 Aug 2015 07:55:55 -0700
> To: jrkrideau at inbox.com
> Subject: Re: [R] Plotting wind direction as arrows with precipitation
> 
> ... don't know if this will help, but grid graphics, which is the
> graphics engine for both trellis and ggplot, has a basic arrow()
> function. Trellis's provides an interface to it with the
> panel.arrows() panel function. I suspect ggplot has something similar,
> but as I don't use it, I don't know for sure.
> 
> There is also an arrows() function in the basic (non-grid) graphics
> engine, but this is probably irrelevant for your needs.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
> 
> 
> On Tue, Aug 11, 2015 at 7:16 AM, John Kane <jrkrideau at inbox.com> wrote:
>> Hi,
>> Good example and data.  Thanks.
>> 
>> Here are a couple of approaches that may help.
>> I tend to use a lot of what I tend to think of as the ggplot family of
>> associated so you may need to install a couple packages. I used
>> lubridate to transform your character dates to  POSIXct. Jeff N's code
>> does exatly the same in base R. so you don't really need the lubridate
>> package.
>> 
>>  I changed the data set name to dat1 and transformed the column names to
>> lower case just for my convenience.  Data is now in dput() form. See
>> ?dput() for more information. It is the preferred way to share data on
>> R-help
>> 
>> Given what appears to be vastly different y-scales for rainfall and wind
>> direction it struck me that it might be better to have the data in two
>> plots so I included that option.
>> 
>> I am not really sure how to get the arrows you want. You may be able to
>> do it using scale_shape_manual  but I am not sure if the required
>> symbols are available.
>> 
>> You may have to manually draw them. See
http://stackoverflow.com/questions/3421331/example-needed-using-arrow-with-ggplot2
>> for how to draw an arrow.
>> 
>> John Kane
>> Kingston ON Canada
>> ##============Start code==============
>> library(ggplot2)
>> library(reshape2)
>> library(lubridate)
>> library(gridExtra)
>> 
>> dat1  <-  structure(list(deal1 = c("10/22/2012 0:00", "10/22/2012 0:15",
>> "10/22/2012 0:30", "10/22/2012 0:45", "10/22/2012 1:00", "10/22/2012
>> 1:15"
>> ), rainfall_cm = c(0L, 0L, 0L, 0L, 0L, 0L), wind_direction1 = c(296L,
>> 317L, 323L, 323L, 326L, 326L), wind_direction2 = c("W", "NW",
>> "NW", "NW", "NW", "NW")), .Names = c("deal1", "rainfall_cm",
>> "wind_direction1", "wind_direction2"), class = "data.frame", row.names =
>> c(NA,
>> -6L))
>> 
>> 
>> dat1$deal1 <- mdy_hm(dat1$deal1) # Lazy man's equivalent of Jeff N's
>> Sandy$Deal1 <- as.POSIXct( Sandy$Deal1, format="%m/%d/%Y %H:%M")
>> 
>> dat2  <-  melt(dat1[ , 1:3], id.var = "deal1")  # use reshape to
>> rearrange data.
>> p  <-  ggplot(dat2, aes(deal1, value, colour = variable) )+ geom_point()
>> p
>> 
>> ## possible option
>> g1  <-  ggplot(dat1, aes(deal1,  wind_direction1)) + geom_point() +
>> theme(axis.title.x=element_blank())
>> g2  <-  ggplot(dat1, aes(deal1, rainfall_cm ) )+ geom_point()
>> 
>> grid.arrange( g1, g2, ncol=1)
>> 
>> ##===========end code==================
>> 
>> 
>>> -----Original Message-----
>>> From: rhelp10 at gmail.com
>>> Sent: Mon, 10 Aug 2015 00:05:27 -0400
>>> To: r-help at r-project.org
>>> Subject: [R] Plotting wind direction as arrows with precipitation
>>> 
>>> Hello R users!
>>> 
>>> I am trying to create a time series in R with two variables,
>>> precipitation
>>> and wind direction vs Date/Time.
>>> 
>>> I am looking for suggestions and maybe even sample code.
>>> 
>>> My workbook is called "Sandy" and has columns with Date/Time,
>>> Raindall_cm,
>>> Wind Direction in both degree format (0-359) and in character form (N,
>>> NW,
>>> S, SW, SE, E, NE, NW).
>>> 
>>> I have done some reading for it on stackoverflow and other sites but
>>> not
>>> making head way.
>>> 
>>> I will be graphing with ggplot most likely and am a beginner in R, self
>>> taught from books and online resources.
>>> 
>>> This is the code I have and a small peak into the data.
>>> 
>>> Sandy<-read.csv("Sandy.csv", header=TRUE,
>>> sep=",",stringsAsFactors=FALSE)
>>>> head(Sandy)
>>>       Deal1     Rainfall_cm    Wind_Direction1 Wind_Direction2
>>> 1 10/22/2012 0:00           0        296         W
>>> 2 10/22/2012 0:15           0        317        NW
>>> 3 10/22/2012 0:30           0        323        NW
>>> 4 10/22/2012 0:45           0        323        NW
>>> 5 10/22/2012 1:00           0        326        NW
>>> 6 10/22/2012 1:15           0        326        NW
>>> 
>>>> class(Sandy)
>>> [1] "data.frame"
>>> 
>>>> str(Sandy)
>>> 'data.frame':   1832 obs. of  4 variables:
>>>  $ Deal1         : chr  "10/22/2012 0:00" "10/22/2012 0:15" "10/22/2012
>>> 0:30" "10/22/2012 0:45" ...
>>>  $ Rainfall_cm   : num  0 0 0 0 0 0 0 0 0 0 ...
>>> 
>>>  $ Wind_Direction: num 296 317  323   323  326  326
>>> 
>>>  $ Wind_Direction: chr  "W" "NW" "NW" "NW" ...
>>> 
>>>> require(ggplot2)
>>> Loading required package: ggplot2
>>> 
>>> # this graph does the precipitation vs time graph, but not the wind
>>> 
>>>> ggplot(Sandy, aes(x = Deal1, y = Rainfall_cm, group = 1)) +
>>> geom_line(stat = "identity")
>>> 
>>> 
>>> Ideally I want it to have the precipitation graph vs time, then wind vs
>>> time on the same graph. I would like the wind direction to be arrows
>>> pointing in the designated direction (i.e. North points north).
>>> 
>>> Thank you!
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From boredstoog at mailinator.com  Tue Aug 11 14:27:34 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Tue, 11 Aug 2015 05:27:34 -0700 (PDT)
Subject: [R] Getting previous day data and implementing it for quantstrat
Message-ID: <1439296054968-4710978.post@n4.nabble.com>

I am a newbie and trying to create my own bactesting code after going through
demo(). I am using a *candle engulfing pattern* strategy and this is the
formula

buy=(close(1) < close) and (high(1) < high) and (low(1) < low)
sell=(close(1) > close) and (high(1) > high) and (low(1) > low)
**(1) represents previous day data*

How should i get previous day data for close,high and open for the previous
day?
How should i add indicators,rules and signals to this strategy.

This is my idea first create a signal using sig Formula and then add the
rules like this

BUYING
#adding signal
 strat1<-add.signal(strat1,
     name="sigFormula",
     arguments = list(columns=c("Close","High","Low"),
                      formula = "(close(1) < close) and (high(1) < high) and
(low(1) < low)",
                      label="trigger",
                      cross=TRUE),
     label="Bullish engulfing")
#adding rule
strat1 <- add.rule(strat1, name="ruleSignal",
arguments=list(sigcol="trigger", sigval=TRUE, orderqty=100,
ordertype="market", orderside="long", pricemethod="market"), type="enter")

is this correct!

The biggest problem is how i get previous day data for close, high and low





--
View this message in context: http://r.789695.n4.nabble.com/Getting-previous-day-data-and-implementing-it-for-quantstrat-tp4710978.html
Sent from the R help mailing list archive at Nabble.com.


From Paul.Parker at merck.com  Tue Aug 11 17:40:33 2015
From: Paul.Parker at merck.com (Parker, Paul)
Date: Tue, 11 Aug 2015 11:40:33 -0400
Subject: [R] install.package - CaTools
Message-ID: <49D7DBF8BEB8C9498B33FC625300313AE1549DB9F1@USCTMXP51007.merck.com>

How or where can I find the appropriate version of CaTools to install into R version 3.1.3 on Windows 7 platform  ?

I have tried to install manually, but with no success.

Paul Parker
IT Technical Analyst
AMS MS&O MMD Site Operations
West Point
WP62-7
a

Notice:  This e-mail message, together with any attachme...{{dropped:14}}


From stephaniecahill at hotmail.com  Tue Aug 11 16:16:43 2015
From: stephaniecahill at hotmail.com (mscheb)
Date: Tue, 11 Aug 2015 07:16:43 -0700 (PDT)
Subject: [R] plspm error: Error in solve.qr(qr(X[, blockinds == j]), Z[,
	j]) :
Message-ID: <1439302603894-4710987.post@n4.nabble.com>

Hello there,
I am performing a path analysis using plspm.

I successfully ran one analysis but then tried to rerun with some tweaks of
my data and now am getting this error message:
Error in solve.qr(qr(X[, blockinds == j]), Z[, j]) : 
  singular matrix 'a' in 'solve'

My code is:
> PNS = c(0, 0, 0, 0, 0)
> PND = c(1, 0, 0, 0, 0)
> mothering = c(1, 1, 0, 0, 0)
> controls = c(0, 0, 0, 0, 0)
> behav.diff.47 = c(1, 1, 1, 1, 0)
> second_path = rbind(PNS, PND, mothering, controls, behav.diff.47)
>  
> colnames(second_path) = rownames(second_path)
> innerplot(second_path)
> second_blocks = list(13, 14:17, 19, 2:12, 18)
> second_modes = c("B", "B", "B", "B", "B")
> second_plspm = plspm(steph.data.use.path2, second_path, second_blocks,
> modes = second_modes)

Can anyone help me? 
It seems strange it worked successfully before and now I can't run it when
all I did was omit a few rows.
Any help much appreciated :)



--
View this message in context: http://r.789695.n4.nabble.com/plspm-error-Error-in-solve-qr-qr-X-blockinds-j-Z-j-tp4710987.html
Sent from the R help mailing list archive at Nabble.com.


From rosita21 at gmail.com  Tue Aug 11 11:21:27 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Tue, 11 Aug 2015 10:21:27 +0100
Subject: [R] LMER - generate data and define model (2 fixed effects and
	1 random effect or 1 fixed effect and 2 random effects)
In-Reply-To: <CAJuCY5wn2HZ9H+MDWP2st2q2DCt9QDE552Xe3u_NTRLGTvdp+g@mail.gmail.com>
References: <9D94908A-2EB3-4F66-B492-1AE187B7489E@gmail.com>
	<CAJuCY5wn2HZ9H+MDWP2st2q2DCt9QDE552Xe3u_NTRLGTvdp+g@mail.gmail.com>
Message-ID: <2C15D293-04BD-4F83-88E9-0BCF7F098C2E@gmail.com>

Dear Thierry

id.pat                       = rep(seq(1:nsample), each =n.longitudinal.observations)

time                         = rep(seq(1:n.longitudinal.observations)-1, nsample)

age                          = rnorm(nsample, mean = 36, sd = .8)
f.age                        = table(cut(age, breaks = 8))
id.age                      = rep(f.age, each =5)
visit                         = rnorm(nsample, mean = 2, sd = .03)
f.visit                       = table(cut(visit, breaks = 3))
id.visit                     = rep(f.visit, each =5)


1.
I was able to solve the age problem and the number of visits problem. Now the problem is another:

yy~1+id.age+time+(time|id.pat)

or 

yy~1+id.age + time+(time|id.pat) + (1|id.visit)

there is no problem, but when I perform LMER, for example:

lmer(yy~1+id.age+time+(time|id.pat)), there are errors:

Error in model.frame.default(drop.unused.levels = TRUE, formula = yy ~  : 
  variable lengths differ (found for 'time?)

or 

Error in model.frame.default(drop.unused.levels = TRUE, formula = yy ~  : 
  variable lengths differ (found for 'id.age')



2. I wasn?t trying to add the same variable to both random and fixed effects. I?m simulating a model and I?m trying to figure if it makes sense to add some variables into the model.


Another doubt,

3. LMER only accepts categorical variables?


Best,
RO


Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 11 Aug 2015, at 09:00, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Rosa,
> 
> 1) use cut() to convert a continuous variable into a factor. See ?cut for the details.
> 2) The syntax for factors is the same as for continuous variables. Just add the name of the factor variable to the formula
> fAge <- cut(age)
> yy~1+fAge+time+(time|id.pat)
> 3) Add + (1|fAge) to the formula. Note that adding fAge to both the fixed and the random effect doesn't make sense.
> yy~1+time+(time|id.pat) + (1|fAge)
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2015-08-11 1:44 GMT+02:00 Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>:
> 
> 
> ###############################################################################
> 
> # Clear memory and set the working directory and the seed
> 
> ###############################################################################
> 
> rm(list = ls())
> 
> setwd("/Dropbox/LMER/R ")
> 
> set.seed(7010)
> 
> ###############################################################################
> 
> # Load up needed packages and do a require
> 
> ###############################################################################
> 
> # install.packages("gdata")
> 
> 
> 
> library(nlme)
> 
> library(lme4)
> 
> 
> 
> nsample                                       = 1000                    # Number of subjects
> 
> n.longitudinal.observations  = 5                                  # number of observations per subject
> 
> 
> 
> ###############################################################################
> 
> # Set the other parameters
> 
> ###############################################################################
> 
> id.pat                       = rep(seq(1:nsample), each =n.longitudinal.observations)
> 
> time                         = rep(seq(1:n.longitudinal.observations)-1, nsample)
> 
> age                          = rnorm(nsample, mean = 36, sd = .8)
> id.age                      = rep(seq(1: n.longitudinal.observations), each =age)
> 
> 
> 
> 
> 
> ############################################################################### MODEL WITHOUT AGE
> 
> boldBeta_individual_blup = coef(lmer(yy~1+time+(time|id.pat)   ))$id.pat   #mixed model
> 
> 
> 
> 
> 
> ############################################################################### MODEL WITH AGE
> 
> boldBeta_individual_blup = coef(lmer(yy~1+age+time+(time|id.pat)   ))$id.pat   #mixed model
> 
> 
> 
> Dear all,
> 
> 
> 
> 
> 
> I?m trying to use LMER in my simulation problem, and I?m having problems ate the very begging L I?m new in LMER. Can you please help me?
> 
> 
> 
> 
> 
> 1st problem:
> 
> how do I generate age so I can use it as a fixed factor?
> 
> 2nd problem:
> 
> how do I insert age as a fixed factor?
> 
> 3rd problem:
> 
>  what if I wanted to insert a 2nd random effect based on age?
> 
> 
> 
> Best,
> 
> RO
> 
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> --
> ____________________________________________________________________________
> 
> 
> Rosa Celeste dos Santos Oliveira,
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143 <tel:%2B351%20939355143>
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


From rosita21 at gmail.com  Tue Aug 11 11:35:48 2015
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Tue, 11 Aug 2015 10:35:48 +0100
Subject: [R] LMER - generate data and define model (2 fixed effects and
	1 random effect or 1 fixed effect and 2 random effects)
In-Reply-To: <CAJuCY5wn2HZ9H+MDWP2st2q2DCt9QDE552Xe3u_NTRLGTvdp+g@mail.gmail.com>
References: <9D94908A-2EB3-4F66-B492-1AE187B7489E@gmail.com>
	<CAJuCY5wn2HZ9H+MDWP2st2q2DCt9QDE552Xe3u_NTRLGTvdp+g@mail.gmail.com>
Message-ID: <FC9D7DEF-5587-49AD-9E73-6686ADDD6A75@gmail.com>

Dear Thierry,


even using the code:

id.pat                       = rep(seq(1:nsample), each =n.longitudinal.observations)

time                         = rep(seq(1:n.longitudinal.observations)-1, nsample)

age                          = rnorm(nsample, mean = 36, sd = .8)
f.age                        = cut(age, breaks = 8)
id.age                      = rep(f.age, each =5)
visit                         = rnorm(nsample, mean = 2, sd = .03)
f.visit                       = cut(visit, breaks = 3)
id.visit                     = rep(f.visit, each =5)

1st lmer(yy~1+id.age+time+(time|id.pat))

2nd lmer(yy~1+time+(time|id.pat)+(1|id.visit))

the problem remains:

variable lengths differ     - for the first fixed effect in the model id.age in the first or time in the second



Best,
RO




Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________


Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira
____________________________________________________________________________
"Many admire, few know"
Hippocrates

> On 11 Aug 2015, at 09:00, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Rosa,
> 
> 1) use cut() to convert a continuous variable into a factor. See ?cut for the details.
> 2) The syntax for factors is the same as for continuous variables. Just add the name of the factor variable to the formula
> fAge <- cut(age)
> yy~1+fAge+time+(time|id.pat)
> 3) Add + (1|fAge) to the formula. Note that adding fAge to both the fixed and the random effect doesn't make sense.
> yy~1+time+(time|id.pat) + (1|fAge)
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2015-08-11 1:44 GMT+02:00 Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>:
> 
> 
> ###############################################################################
> 
> # Clear memory and set the working directory and the seed
> 
> ###############################################################################
> 
> rm(list = ls())
> 
> setwd("/Dropbox/LMER/R ")
> 
> set.seed(7010)
> 
> ###############################################################################
> 
> # Load up needed packages and do a require
> 
> ###############################################################################
> 
> # install.packages("gdata")
> 
> 
> 
> library(nlme)
> 
> library(lme4)
> 
> 
> 
> nsample                                       = 1000                    # Number of subjects
> 
> n.longitudinal.observations  = 5                                  # number of observations per subject
> 
> 
> 
> ###############################################################################
> 
> # Set the other parameters
> 
> ###############################################################################
> 
> id.pat                       = rep(seq(1:nsample), each =n.longitudinal.observations)
> 
> time                         = rep(seq(1:n.longitudinal.observations)-1, nsample)
> 
> age                          = rnorm(nsample, mean = 36, sd = .8)
> id.age                      = rep(seq(1: n.longitudinal.observations), each =age)
> 
> 
> 
> 
> 
> ############################################################################### MODEL WITHOUT AGE
> 
> boldBeta_individual_blup = coef(lmer(yy~1+time+(time|id.pat)   ))$id.pat   #mixed model
> 
> 
> 
> 
> 
> ############################################################################### MODEL WITH AGE
> 
> boldBeta_individual_blup = coef(lmer(yy~1+age+time+(time|id.pat)   ))$id.pat   #mixed model
> 
> 
> 
> Dear all,
> 
> 
> 
> 
> 
> I?m trying to use LMER in my simulation problem, and I?m having problems ate the very begging L I?m new in LMER. Can you please help me?
> 
> 
> 
> 
> 
> 1st problem:
> 
> how do I generate age so I can use it as a fixed factor?
> 
> 2nd problem:
> 
> how do I insert age as a fixed factor?
> 
> 3rd problem:
> 
>  what if I wanted to insert a 2nd random effect based on age?
> 
> 
> 
> Best,
> 
> RO
> 
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> --
> ____________________________________________________________________________
> 
> 
> Rosa Celeste dos Santos Oliveira,
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143 <tel:%2B351%20939355143>
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewmil at dcn.davis.CA.us  Tue Aug 11 23:10:49 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 11 Aug 2015 14:10:49 -0700
Subject: [R] install.package - CaTools
In-Reply-To: <49D7DBF8BEB8C9498B33FC625300313AE1549DB9F1@USCTMXP51007.merck.com>
References: <49D7DBF8BEB8C9498B33FC625300313AE1549DB9F1@USCTMXP51007.merck.com>
Message-ID: <EF8F12A2-BE4E-4F35-8B8A-538F2E400172@dcn.davis.CA.us>

Have you tried the usual install.packages method from CRAN? I just installed it into 3.2.1 and 3.1.3 on Win7x64 just fine.

Note that this list does not officially support old versions of R, so if this is really specific to 3.1.1 then you should just upgrade.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 11, 2015 8:40:33 AM PDT, "Parker, Paul" <Paul.Parker at merck.com> wrote:
>How or where can I find the appropriate version of CaTools to install
>into R version 3.1.3 on Windows 7 platform  ?
>
>I have tried to install manually, but with no success.
>
>Paul Parker
>IT Technical Analyst
>AMS MS&O MMD Site Operations
>West Point
>WP62-7
>a
>
>Notice:  This e-mail message, together with any
>attachme...{{dropped:14}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Aug 11 23:53:03 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 11 Aug 2015 14:53:03 -0700
Subject: [R] LMER - generate data and define model (2 fixed effects and
 1 random effect or 1 fixed effect and 2 random effects)
In-Reply-To: <2C15D293-04BD-4F83-88E9-0BCF7F098C2E@gmail.com>
References: <9D94908A-2EB3-4F66-B492-1AE187B7489E@gmail.com>
	<CAJuCY5wn2HZ9H+MDWP2st2q2DCt9QDE552Xe3u_NTRLGTvdp+g@mail.gmail.com>
	<2C15D293-04BD-4F83-88E9-0BCF7F098C2E@gmail.com>
Message-ID: <CAGxFJbRgEz7iqkFw7e1MJRDwgBDYybMrCPxU4BJVggMiNCENxg@mail.gmail.com>

You need to:

1) Re-read ?seq. Your syntax is wrong. ("," not ":" )
2) Note that (n-1) x m  !=  n x m

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Aug 11, 2015 at 2:21 AM, Rosa Oliveira <rosita21 at gmail.com> wrote:
> Dear Thierry
>
> id.pat                       = rep(seq(1:nsample), each =n.longitudinal.observations)
>
> time                         = rep(seq(1:n.longitudinal.observations)-1, nsample)
>
> age                          = rnorm(nsample, mean = 36, sd = .8)
> f.age                        = table(cut(age, breaks = 8))
> id.age                      = rep(f.age, each =5)
> visit                         = rnorm(nsample, mean = 2, sd = .03)
> f.visit                       = table(cut(visit, breaks = 3))
> id.visit                     = rep(f.visit, each =5)
>
>
> 1.
> I was able to solve the age problem and the number of visits problem. Now the problem is another:
>
> yy~1+id.age+time+(time|id.pat)
>
> or
>
> yy~1+id.age + time+(time|id.pat) + (1|id.visit)
>
> there is no problem, but when I perform LMER, for example:
>
> lmer(yy~1+id.age+time+(time|id.pat)), there are errors:
>
> Error in model.frame.default(drop.unused.levels = TRUE, formula = yy ~  :
>   variable lengths differ (found for 'time?)
>
> or
>
> Error in model.frame.default(drop.unused.levels = TRUE, formula = yy ~  :
>   variable lengths differ (found for 'id.age')
>
>
>
> 2. I wasn?t trying to add the same variable to both random and fixed effects. I?m simulating a model and I?m trying to figure if it makes sense to add some variables into the model.
>
>
> Another doubt,
>
> 3. LMER only accepts categorical variables?
>
>
> Best,
> RO
>
>
> Atenciosamente,
> Rosa Oliveira
>
> --
> ____________________________________________________________________________
>
>
> Rosa Celeste dos Santos Oliveira,
>
> E-mail: rosita21 at gmail.com
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
>
>> On 11 Aug 2015, at 09:00, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>>
>> Dear Rosa,
>>
>> 1) use cut() to convert a continuous variable into a factor. See ?cut for the details.
>> 2) The syntax for factors is the same as for continuous variables. Just add the name of the factor variable to the formula
>> fAge <- cut(age)
>> yy~1+fAge+time+(time|id.pat)
>> 3) Add + (1|fAge) to the formula. Note that adding fAge to both the fixed and the random effect doesn't make sense.
>> yy~1+time+(time|id.pat) + (1|fAge)
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>>
>> 2015-08-11 1:44 GMT+02:00 Rosa Oliveira <rosita21 at gmail.com <mailto:rosita21 at gmail.com>>:
>>
>>
>> ###############################################################################
>>
>> # Clear memory and set the working directory and the seed
>>
>> ###############################################################################
>>
>> rm(list = ls())
>>
>> setwd("/Dropbox/LMER/R ")
>>
>> set.seed(7010)
>>
>> ###############################################################################
>>
>> # Load up needed packages and do a require
>>
>> ###############################################################################
>>
>> # install.packages("gdata")
>>
>>
>>
>> library(nlme)
>>
>> library(lme4)
>>
>>
>>
>> nsample                                       = 1000                    # Number of subjects
>>
>> n.longitudinal.observations  = 5                                  # number of observations per subject
>>
>>
>>
>> ###############################################################################
>>
>> # Set the other parameters
>>
>> ###############################################################################
>>
>> id.pat                       = rep(seq(1:nsample), each =n.longitudinal.observations)
>>
>> time                         = rep(seq(1:n.longitudinal.observations)-1, nsample)
>>
>> age                          = rnorm(nsample, mean = 36, sd = .8)
>> id.age                      = rep(seq(1: n.longitudinal.observations), each =age)
>>
>>
>>
>>
>>
>> ############################################################################### MODEL WITHOUT AGE
>>
>> boldBeta_individual_blup = coef(lmer(yy~1+time+(time|id.pat)   ))$id.pat   #mixed model
>>
>>
>>
>>
>>
>> ############################################################################### MODEL WITH AGE
>>
>> boldBeta_individual_blup = coef(lmer(yy~1+age+time+(time|id.pat)   ))$id.pat   #mixed model
>>
>>
>>
>> Dear all,
>>
>>
>>
>>
>>
>> I?m trying to use LMER in my simulation problem, and I?m having problems ate the very begging L I?m new in LMER. Can you please help me?
>>
>>
>>
>>
>>
>> 1st problem:
>>
>> how do I generate age so I can use it as a fixed factor?
>>
>> 2nd problem:
>>
>> how do I insert age as a fixed factor?
>>
>> 3rd problem:
>>
>>  what if I wanted to insert a 2nd random effect based on age?
>>
>>
>>
>> Best,
>>
>> RO
>>
>>
>>
>> Atenciosamente,
>> Rosa Oliveira
>>
>> --
>> ____________________________________________________________________________
>>
>>
>> Rosa Celeste dos Santos Oliveira,
>>
>> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
>> Tlm: +351 939355143 <tel:%2B351%20939355143>
>> Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
>> ____________________________________________________________________________
>> "Many admire, few know"
>> Hippocrates
>>
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From btyner at gmail.com  Wed Aug 12 02:41:21 2015
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 11 Aug 2015 20:41:21 -0400
Subject: [R] Rprof and system
Message-ID: <55CA9631.1060802@gmail.com>

Hi

I have an R script which invokes WriteXLS() (from the package of the
same name) which as you may know, calls perl via system(). I've noticed
that when I enable profiling using Rprof(), when the script gets to the
part where perl is called, it gets "stuck": it just sits there using
99-100% CPU and around 10% of the RAM, and the perl command does not
even show up as a running process under 'top'. While it is churning
away, new profiling results continue to be written to the profiling file
(at which point the entries are all "system" / "WriteXLS").  I have also
noticed this behavior with other system() calls; not just perl. I've
also tried pipe(cmd, open = "r") as an alternative to system(cmd) and
the result is the same. I have tried in interactive as well as
non-interactive mode, and the issue occurs in both modes although seems
to be more common in the latter.

So, I'm wondering if perhaps Rprof() + system() not a recommended
combination ? I did notice from ?Rprof that "the profiler interrupts R
asynchronously"; though I do not know what that means, perhaps that is
somehow relevant? This is running on R version 3.2.1 under linux (RHEL6).

Any suggestions would be greatly appreciated.

Regards
Ben


From anshuk.p at motivitylabs.com  Wed Aug 12 08:10:52 2015
From: anshuk.p at motivitylabs.com (Anshuk Pal Chaudhuri)
Date: Wed, 12 Aug 2015 06:10:52 +0000
Subject: [R] Parsing all rows & columns of a Dataframe into one column
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C393FC@SRVEXCHMBX.precheza.cz>
References: <HKXPR02MB06321FDA97E5C1E23E4D2601F0700@HKXPR02MB0632.apcprd02.prod.outlook.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C393FC@SRVEXCHMBX.precheza.cz>
Message-ID: <HKXPR02MB063226F3672FA3B28D9F42E2F07E0@HKXPR02MB0632.apcprd02.prod.outlook.com>

Thanks. Another way of handling is which I understood from other forum, thought to share here as well.

data.frame(Value=dat[!is.na(dat)])

Regards,
Anshuk Pal Chaudhuri

-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: 10 August 2015 12:21
To: Anshuk Pal Chaudhuri <anshuk.p at motivitylabs.com>; r-help at r-project.org
Subject: RE: Parsing all rows & columns of a Dataframe into one column

Hi

Your HTML posting scrammbled your question a bit. If I understand correctly and as you want values of various type in one column, probably the easiest way would be.

mat<-as.matrix(yourdata)
mat<-na.omit(mat)
dim(mat) <- NULL
newdata <- data.frame(mat, stringsAsFactors=FALSE)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Anshuk 
> Pal Chaudhuri
> Sent: Monday, August 10, 2015 7:24 AM
> To: r-help at r-project.org
> Subject: [R] Parsing all rows & columns of a Dataframe into one column
>
> Hi All,
>
>
> I am using R for reading certain values in a dataset.
>
> I have values in a data frame all scattered in different columns & 
> rows, some values might be NA as well.
>
> e.g. below three columns V1, V2,V3, and their respective values.
> V1
>
>     V2
>
>     V2
>
> NA
>
>     NA
>
> 90
>
> abc
>
> 89.09
>
> $50
>
> 76799
>
> NA
>
>     NA
>
> 02:15
>
> def
>
> 1
>
>
>
>
> What I would like to do is parse this data frame, create a new data 
> frame, omit all NA values. The new data frame would have one column, 
> lets say Value column. (order of the samples coming is not an issue)
>
> New Data Frame (Output Required):
>
>
> Value
>
> abc
>
> 76799
>
> 02:15
>
> 89.09
>
> def
>
> 90
>
> $50
>
> 1
>
>
>
>
> Any help would be appreciated.
>
> Regards,
> Anshuk Pal Chaudhuri
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html and provide commented, minimal, self-contained, 
> reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From thierry.onkelinx at inbo.be  Wed Aug 12 10:47:33 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 12 Aug 2015 10:47:33 +0200
Subject: [R] Problem with path.expand("~")
In-Reply-To: <CAF8bMcYG=eqH__RzBV79wjkD-SLCxab937cRgfFV2J-s_ktzxg@mail.gmail.com>
References: <CAJuCY5x8XmiVpe=6sd3MQRb2SRj5GkZrjfPxmibi=rUGMrcA0w@mail.gmail.com>
	<CAF8bMcYG=eqH__RzBV79wjkD-SLCxab937cRgfFV2J-s_ktzxg@mail.gmail.com>
Message-ID: <CAJuCY5x3qh7e_R4+u9TRuJnRU2CEvXJpdPb6iORzHr1e+eUqRg@mail.gmail.com>

Dear Bill,

The culprit was the environment variable HOME which was set to "~".
Changing it to "C:/Users/thierry_onkelinx/Documents" solved the problem.
Thanks for the hint.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-08-11 17:39 GMT+02:00 William Dunlap <wdunlap at tibco.com>:

>     In the R GUI the output is
>     > path.expand("~")
>     [1] "~"
>
> Did you set the environment variable R_USER to something odd like "~"?
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Aug 11, 2015 at 7:41 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear all,
>>
>> I'm puzzled by the behaviour of path.expand("~")
>>
>> In the RStudio IDE the output is
>> > path.expand("~")
>> [1] "C:/Users/thierry_onkelinx/Documents"
>>
>> In the R GUI the output is
>> > path.expand("~")
>> [1] "~"
>>
>> But I'm expecting the same result as in the RStudio IDE. The "Start in"
>> parameter of shortcut to the R GUI has the value
>> "C:\Users\thierry_onkelinx\Documents"
>>
>> The problem is that I use normalizePath("~/analysis"). This
>> yield "C:\\Users\\thierry_onkelinx\\Documents\\analysis" in RStudio
>>
>> It throws an error in the R GUI
>> "C:\\Users\\thierry_onkelinx\\Documents\\~\\analysis"
>> Warning message:
>> In normalizePath(path.expand(path), winslash, mustWork) :
>>   path[1]="~/analysis": Het systeem kan het opgegeven pad niet vinden
>>
>> # sessionInfo() in RStudio
>> R version 3.2.1 (2015-06-18)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
>>  LC_MONETARY=Dutch_Belgium.1252
>> [4] LC_NUMERIC=C                   LC_TIME=Dutch_Belgium.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.1    fortunes_1.5-2
>>
>> # sessionInfo() from R GUI
>> R version 3.2.1 (2015-06-18)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
>> [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
>> [5] LC_TIME=Dutch_Belgium.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.1    fortunes_1.5-2
>>
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From rguy at 123mail.org  Wed Aug 12 10:49:50 2015
From: rguy at 123mail.org (Rguy)
Date: Wed, 12 Aug 2015 09:49:50 +0100
Subject: [R] clusterMap: static vs dynamic scheduling
Message-ID: <CAEorq2NtkFXJfaV5ENxeZZrFn_fLSfeROUf4BV2ES5niFKwung@mail.gmail.com>

The clusterMap function provides the following argument
.scheduling = c("static", "dynamic")
The default is "static". When is it advisable to use "dynamic"?

	[[alternative HTML version deleted]]


From arne.henningsen at gmail.com  Wed Aug 12 12:11:42 2015
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Wed, 12 Aug 2015 12:11:42 +0200
Subject: [R] simultaneous equation model with endogenous interaction
	terms
In-Reply-To: <CAHymutJHcUTA2atcn4E0FB0T-n=Big_JgLKuCL5Us8UXr=kM1A@mail.gmail.com>
References: <CAHymutJHcUTA2atcn4E0FB0T-n=Big_JgLKuCL5Us8UXr=kM1A@mail.gmail.com>
Message-ID: <CAMTWbJisPyd7UC5gbFrGeqPMcO0-tuOUE4aa385PFm0AyGRDPA@mail.gmail.com>

Dear Janka

On 10 August 2015 at 11:25, Janka Vanschoenwinkel
<janka.vanschoenwinkel at uhasselt.be> wrote:
> Dear list members,
>
> I am building a model such as:
>
> Y1 = Y2*X1 + X2
> Y2 = Y1*X1 + X2

Do you mean the model:

Y1 = b10 + b11 * (Y2*X1) + b12 * X2 + e1

Y2 = b20 + b21 * (Y1*X1) + b22 * X2 + e2

where Y1 and Y2 are two (endogenous) dependent variables, X1 is a
potentially endogenous explanatory variable, X2 is an exogenous
explanatory variable, e1 and e2 are two potentially contemporaneously
correlated error terms, and b10, b11, b12, b20, b21, and b22 are
parameters to be estimated?

> X2 is the exogenous variable
> Z1 is the instrument of Y1
> Z2 is the instrument of Y2
>
> This is a simultaneous equation model. I know how to build a simultaneous
> equation model without interaction terms:
>
> library(systemfit)
> eq1 <- Y1~Y2+X2+Z2
> eq2 <- Y2~Y1+X2+Z1
> inst <- ~X2+Z1+Z2
> system <- list(eq1=eq1, eq2=eq2)
> reg2SLS <-systemfit(system, "2SLS", inst=inst, data=mydata)
> summary(reg2SLS)
>
> I also know how to do a normal 2SLS with interaction terms:
> library(systemfit)
> ivreg(Y1~Y2*X1 | Z2*X1, data= Alldata)
>
> However, I don't know how to deal with the interaction terms in the
> simultaneous equation model.
>
> I am experimenting both with R and STATA to see which formulation gives the
> same result in both softwares, but until know without success.
>
> Could somebody help me with this?

To estimate the above model specification, the following should work:

eq1 <- Y1 ~ I(Y2*X1) + X2
eq2 <- Y2 ~ I(Y1*X1) + X2
inst <- ~ X2 + Z1 + Z2
system <- list( eq1 = eq1, eq2 = eq2 )
reg2SLS <- systemfit( system, "2SLS", inst = inst, data = mydata )

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From josh.m.ulrich at gmail.com  Wed Aug 12 12:39:05 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 12 Aug 2015 05:39:05 -0500
Subject: [R] Getting previous day data and implementing it for quantstrat
In-Reply-To: <1439296054968-4710978.post@n4.nabble.com>
References: <1439296054968-4710978.post@n4.nabble.com>
Message-ID: <CAPPM_gSOnmfH315dX88qgpK4fwT4+2SH0PL6ib2wzu85BndJ0A@mail.gmail.com>

Please don't cross-post: http://stackoverflow.com/q/31955979/271616

At minimum, tell people that you're cross-posting, so they don't spend
time answering a question that was answered on another forum they do
not follow.

On Tue, Aug 11, 2015 at 7:27 AM, boredstoog via R-help
<r-help at r-project.org> wrote:
> I am a newbie and trying to create my own bactesting code after going through
> demo(). I am using a *candle engulfing pattern* strategy and this is the
> formula
>
> buy=(close(1) < close) and (high(1) < high) and (low(1) < low)
> sell=(close(1) > close) and (high(1) > high) and (low(1) > low)
> **(1) represents previous day data*
>
> How should i get previous day data for close,high and open for the previous
> day?
> How should i add indicators,rules and signals to this strategy.
>
> This is my idea first create a signal using sig Formula and then add the
> rules like this
>
> BUYING
> #adding signal
>  strat1<-add.signal(strat1,
>      name="sigFormula",
>      arguments = list(columns=c("Close","High","Low"),
>                       formula = "(close(1) < close) and (high(1) < high) and
> (low(1) < low)",
>                       label="trigger",
>                       cross=TRUE),
>      label="Bullish engulfing")
> #adding rule
> strat1 <- add.rule(strat1, name="ruleSignal",
> arguments=list(sigcol="trigger", sigval=TRUE, orderqty=100,
> ordertype="market", orderside="long", pricemethod="market"), type="enter")
>
> is this correct!
>
> The biggest problem is how i get previous day data for close, high and low
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Getting-previous-day-data-and-implementing-it-for-quantstrat-tp4710978.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From h_a_patience at hotmail.com  Wed Aug 12 13:28:57 2015
From: h_a_patience at hotmail.com (Bazman76)
Date: Wed, 12 Aug 2015 04:28:57 -0700 (PDT)
Subject: [R] Unable to pass Object Arguments to UniRoot()
In-Reply-To: <1439375091328-4711010.post@n4.nabble.com>
References: <1439202395517-4710938.post@n4.nabble.com>
	<1439209612430-4710942.post@n4.nabble.com>
	<1439210738734-4710943.post@n4.nabble.com>
	<1439375091328-4711010.post@n4.nabble.com>
Message-ID: <1439378937501-4711015.post@n4.nabble.com>

yeah I found the error pls feel free to delete post!



--
View this message in context: http://r.789695.n4.nabble.com/Unable-to-pass-Object-Arguments-to-UniRoot-tp4710938p4711015.html
Sent from the R help mailing list archive at Nabble.com.


From lid.zigh at gmail.com  Wed Aug 12 13:48:03 2015
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Wed, 12 Aug 2015 06:48:03 -0500
Subject: [R] add an idx column to the matrix
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39627@SRVEXCHMBX.precheza.cz>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAJuCY5w+jgXX_BupPMRpTY2zPXBv_zUZ_uW48jzej9ecdLM_Sw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39627@SRVEXCHMBX.precheza.cz>
Message-ID: <CAMqbV1DTmK0dbhXjh=O0Fi5vZ0YdM+ce6oVymsu7BZ494rXNjw@mail.gmail.com>

Dear all,
Thank you so much for your helps.
They all works! But I think the Petr solution is the best!

Thanks again.
On Aug 11, 2015 1:40 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:

> Hi
>
> here is another approach.
>
> > cbind(mydata, idx=(rowSums(mydata==2, na.rm=T)>0)*1)
>    X125 X255 X558 X2366 X177 X255.1 idx
> aa    0    1    0    NA    0      0   0
> bb    1    1    0    NA    0      1   0
> cs    2    1    2     1    0      0   1
> de    0    1    0    NA    0      0   0
> gh    2    0    0     0    0      0   1
>
> It shall be faster if this is an issue.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thierry
> > Onkelinx
> > Sent: Monday, August 10, 2015 10:29 PM
> > To: Lida Zeighami
> > Cc: r-help at r-project.org
> > Subject: Re: [R] add an idx column to the matrix
> >
> > Dear Lida,
> >
> > Here is a solution. Please don't post in HTML. And provide an easy to
> > use
> > example of the data. E.g. the output of dput(mydata)
> >
> > set.seed(1234)
> > mydata <- matrix(
> >   sample(
> >     c(0, 1, 2, NA),
> >     size = 30,
> >     replace = TRUE,
> >     prob = c(2, 1, 1, 1)
> >   ),
> >   ncol = 6
> > )
> >
> > idx <- apply(mydata, 1, function(x){any(x == 2)})
> > idx[is.na(idx)] <- FALSE
> > cbind(mydata, idx)
> >
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not
> > ensure that a reasonable answer can be extracted from a given body of
> > data.
> > ~ John Tukey
> >
> > 2015-08-10 22:11 GMT+02:00 Lida Zeighami <lid.zigh at gmail.com>:
> >
> > > Hi there,
> > >
> > > I have a matrix contain 0,1,2, NA elements.
> > > I want to add a column to this matrix with name of "idx" . then for
> > each
> > > row, I should put 1 in this column (idx) if there is at least one 2
> > in that
> > > row otherwise I should put 0 in this column!
> > >
> > > for example  mydata:
> > >
> > >        125   255   558   2366   177    255
> > > aa    0        1       0         NA    0         0
> > > bb    1        1       0         NA    0         1
> > > cs     2        1       2         1       0         0
> > > de    0        1       0         NA    0         0
> > > gh    2       0       0         0        0         0
> > >
> > >
> > > my output should be:
> > >
> > >
> > >        125   255   558   2366   177    255    idx
> > > aa    0        1       0         NA    0         0      0
> > > bb    1        1       0         NA    0         1      0
> > > cs     2        1       2         1       0         0     1
> > > de    0        1       0         NA    0         0      0
> > > gh    2       0       0        2        0         2       1
> > >
> > > Thank you for your help.
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From info at analyticsindiamag.com  Wed Aug 12 11:08:32 2015
From: info at analyticsindiamag.com (Imarticus Learning)
Date: Wed, 12 Aug 2015 09:08:32 +0000
Subject: [R] Prepare yourself for careers within Analytics - R & SAS
	(International Certification)
Message-ID: <39203741298401078631777@Lenovo-PC>

IMARTICUS: Are You Ready for a Career in Analytics - R?         Click here
to view in your browser
<http://imarticus.org/mailers/analytics-mailers/analytics1/analytics.html> 
LEARN R / SAS & BUILD A CAREER 
IN ANALYTICS WITHIN 60 DAYS        Imarticus Learning, a leading analytics
learning centre, offers industry endorsed Classroom & Online programs in
technologies such as R and SAS with global certifications.   

ONLINE & CLASSROOM AVAILABLE
<http://imarticus.org/programs/business-analytics-professional/>     
 = BENEFITS =

   - Global Certifications  - Industry Connect  - Comprehensive Coverage  -
Flexible-Learn Anytime, Anywhere  - Interactive Portal  - Self Paced  -
Curriculum includes: Predictive Analytics, Text Analytics, Data Modelling &
more.  - Experienced Industry Trainers 

         = TOP RECRUITERS =

Accenture   |   Ebay   |   Flipkart   |   MuSigma   |   Amazon   |  
Genpact   |   Infosys   |   HCL   |   IBM   |   Citi Bank Analytics   |  
and more   HOW IT WORKS?
<mailto:anurag.patil at imarticus.com?subject=Analytics Enquiry&body=Name
:%20%0d%0aMobile Number :%20%0d%0aPreferred Mode of Training : Classroom /
Online (Please Choose)%20%0d%0aCurrent Location :%20%0d%0aQuery : (If
Any)%20%0d%0a%20%0d%0a%20%0d%0aPlease Note : We will treat all of the
personal information you provide to us as confidential . We do not sell,
trade, share or transfer your personal data what so
ever.&cc=info at imarticus.org>     For More Details Call Our Training
Consultant  Mumbai   Bangalore  Chennai  022 424 22 016/17  080 451 29 914 
044 456 42 123        W: www.imarticus.org | E: info at imarticus.org
<https://www.facebook.com/ImarticusLearning>
<https://www.linkedin.com/company/imarticus?trk=nav_account_sub_nav_company_admin>
<https://twitter.com/imarticus>
<https://plus.google.com/108424183483217719355/posts>
<https://www.youtube.com/channel/UCGByJSZBR_kcr4Qid4_iB3Q>
<https://in.pinterest.com/imarticusl/>
<https://www.quora.com/Imarticus-Learning>





This email was sent to r-help at r-project.org (mailto:r-help at r-project.org)
unsubscribe from this list (http://mandrillapp.com/track/unsub.php?u=30323212&id=d6f44b007ba745d0930b5fb402764af1.EI9Berli75mp3b3oQvB6UtY8N0M%3D&r=https%3A%2F%2Fmandrillapp.com%2Funsub%3Fmd_email%3Dr-help%2540r-project.org)
	[[alternative HTML version deleted]]


From desak.ristia at yahoo.co.id  Wed Aug 12 12:37:54 2015
From: desak.ristia at yahoo.co.id (vidya)
Date: Wed, 12 Aug 2015 03:37:54 -0700 (PDT)
Subject: [R] nls in r
Message-ID: <1439375874384-4711012.post@n4.nabble.com>

I get this error 
Error in numericDeriv(form[[3L]], names(ind), env) : 
  Missing value or an infinity produced when evaluating the model
I was replace the starting value but still get error.

Here is my code:
library(stats)
x=c(30:110)
y=c(0.000760289, 0.000800320, 0.000830345, 0.000840353, 0.000860370,  
0.000910414, 0.000990490, 0.001090594, 0.001200721, 0.001350912, 
0.001531172, 0.001751533, 0.001961923, 0.002192402, 0.002463031, 
0.002793899, 0.003185067, 0.003636604, 0.004148594, 0.004721127, 
0.005394524, 0.006168989, 0.007014544, 0.007870894, 0.008758242, 
0.009656474, 0.010565620, 0.011485709, 0.012396520, 0.013308162, 
0.014271353, 0.015326859, 0.016525802, 0.017889059, 0.019447890, 
0.021223636, 0.023145810, 0.025174229, 0.027391752, 0.029645106, 
0.032337259, 0.035347424, 0.039375125, 0.043575783, 0.048003973, 
0.052926206, 0.058307309, 0.064581189, 0.071947231, 0.080494476, 
0.089891885, 0.100671526, 0.111971207, 0.124237571, 0.137975539, 
0.153629149, 0.171239194, 0.190712664, 0.212079979, 0.235026373,
0.259457493, 0.282867017, 0.307830359, 0.334773680, 0.364001719, 
0.395742526, 0.425596389, 0.458391314, 0.494558651, 0.534657357, 
0.579354317, 0.616075034, 0.656680256, 0.701804548, 0.752133146, 
0.808558032, 0.872226001, 0.944664487, 1.027837007, 1.124484096, 
1.238426232)

a=0.0189
b=0.14328
delta=0.0005

fit = nls(y ~
a*(exp(b*(x+0.5)))*((delta*b)/((delta*b)+(a*(exp(b*(x+0.5))-1))))^(0.5), 
start=list(a=a,b=b, delta=delta))
predict(fit)
plot(x,y,col="red", xlab="Usia",ylab=expression(paste(mu)))
lines(x,predict(fit), col="blue")
legend("topleft",
c(expression(paste(mu)),"Fit"),col=c("red","blue"),lty=1:1)


I really appreciate for the helps. Thank you.



--
View this message in context: http://r.789695.n4.nabble.com/nls-in-r-tp4711012.html
Sent from the R help mailing list archive at Nabble.com.


From boredstoog at mailinator.com  Wed Aug 12 13:04:02 2015
From: boredstoog at mailinator.com (boredstoog)
Date: Wed, 12 Aug 2015 04:04:02 -0700 (PDT)
Subject: [R] Getting previous day data and implementing it for quantstrat
In-Reply-To: <CAPPM_gSOnmfH315dX88qgpK4fwT4+2SH0PL6ib2wzu85BndJ0A@mail.gmail.com>
References: <1439296054968-4710978.post@n4.nabble.com>
	<CAPPM_gSOnmfH315dX88qgpK4fwT4+2SH0PL6ib2wzu85BndJ0A@mail.gmail.com>
Message-ID: <1439377442210-4711014.post@n4.nabble.com>

Sorry Joshua,
I just want diverse solutions for this answer. Sorry  for causing any
trouble or inconvenience for you. I am withdrawing my question from this
forum.



--
View this message in context: http://r.789695.n4.nabble.com/Getting-previous-day-data-and-implementing-it-for-quantstrat-tp4710978p4711014.html
Sent from the R help mailing list archive at Nabble.com.


From petretta at unina.it  Wed Aug 12 16:19:45 2015
From: petretta at unina.it (petretta at unina.it)
Date: Wed, 12 Aug 2015 14:19:45 +0000
Subject: [R] help with metasens
Message-ID: <20150812141945.Horde.mMVJAOJFce5OwW_oJpmzlw8@webmail-sso.unina.it>

Dear all,

I use R 3.1.1 for Windows (x 64).

I performed a meta-analysis of hazard ratio using the below reported  
Dataset and metagen function from package meta.

meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")

Thereafter, I try to use the copas function from package metasens.

cop1<-copas(meta1)


and I have these 3 warnings:

Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
NaN was produced
Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
NaN was produced
Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
NaN was produced

If I try:
plot (cop1)

  I have:
ERROR:
object "is.relative.effect" not found

Any suggestion is welcome.

The Dataset is:

    id Year      lnHR       seHR
1   1 2001 0.6881346 0.06940859
2   2 2001 1.4036430 0.60414338
3   3 2002 0.7419373 0.28897730
4   4 2003 1.5475625 0.45206678
5   5 2003 1.4816046 0.44859666
6   6 2005 0.9162908 0.17166950
7   7 2006 1.2697605 0.34205049
8   8 2009 0.8960880 0.24626434
9   9 2011 1.5040774 0.24683516
10 10 2012 0.4510756 0.17213355
11 11 2008 0.9895412 0.26590857
12 12 2009 2.8094027 0.61304092
13 13 2010 0.9162908 0.21362771
14 14 2011 0.5068176 0.15060408
15 15 2012 3.0027080 0.27239493
16 16 2013 1.9837563 0.55793673
17 17 2013 3.0492730 0.18798657
18 18 2014 1.2974632 0.44759619
19 19 2014 0.8241754 0.39551640
20 20 2014 2.2617631 0.56545281

The code used are:

meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")

> meta1
       HR             95%-CI %W(fixed) %W(random)
1   1.99 [ 1.7369;  2.2800]     42.92       5.99
2   4.07 [ 1.2455; 13.2997]      0.57       3.71
3   2.10 [ 1.1919;  3.7000]      2.48       5.28
4   4.70 [ 1.9378; 11.3998]      1.01       4.47
5   4.40 [ 1.8264; 10.5998]      1.03       4.49
6   2.50 [ 1.7857;  3.5000]      7.02       5.75
7   3.56 [ 1.8209;  6.9599]      1.77       5.03
8   2.45 [ 1.5120;  3.9700]      3.41       5.47
9   4.50 [ 2.7740;  7.2999]      3.39       5.47
10  1.57 [ 1.1204;  2.2000]      6.98       5.75
11  2.69 [ 1.5974;  4.5300]      2.92       5.38
12 16.60 [ 4.9921; 55.1988]      0.55       3.67
13  2.50 [ 1.6447;  3.8000]      4.53       5.60
14  1.66 [ 1.2357;  2.2300]      9.12       5.81
15 20.14 [11.8085; 34.3497]      2.79       5.36
16  7.27 [ 2.4357; 21.6996]      0.66       3.94
17 21.10 [14.5971; 30.4998]      5.85       5.69
18  3.66 [ 1.5223;  8.7999]      1.03       4.49
19  2.28 [ 1.0502;  4.9499]      1.32       4.76
20  9.60 [ 3.1693; 29.0794]      0.65       3.90

Number of studies combined: k=20

                          HR           95%-CI       z  p.value
Fixed effect model   2.7148 [2.4833; 2.9679] 21.9628 < 0.0001
Random effects model 3.9637 [2.7444; 5.7247]  7.3426 < 0.0001

Quantifying heterogeneity:
tau^2 = 0.5826; H = 3.56 [3.04; 4.16]; I^2 = 92.1% [89.2%; 94.2%]

Test of heterogeneity:
       Q d.f.  p.value
  240.64   19 < 0.0001

Details on meta-analytical method:
- Inverse variance method
- DerSimonian-Laird estimator for tau^2

> cop1<-copas(meta1)

Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
NaN was produced

> plot (cop1)

ERROR:
object "is.relative.effect" not found

-------------------------------------------------------
Mario Petretta
Associate Professor of Internal Medicine
Department of Translational Medical Sciences
Naples University Federico II Italy



----
5x1000 AI GIOVANI RICERCATORI
DELL'UNIVERSIT? DI NAPOLI
Codice Fiscale: 00876220633
www.unina.it/Vademecum5permille


From lists at dewey.myzen.co.uk  Wed Aug 12 18:19:28 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 12 Aug 2015 17:19:28 +0100
Subject: [R] help with metasens
In-Reply-To: <20150812141945.Horde.mMVJAOJFce5OwW_oJpmzlw8@webmail-sso.unina.it>
References: <20150812141945.Horde.mMVJAOJFce5OwW_oJpmzlw8@webmail-sso.unina.it>
Message-ID: <55CB7210.3030409@dewey.myzen.co.uk>

Dear Mario

I do not use metasens myself so cannot be of direct help but I have 
looked at your dataset and it does seem rather strange (as you perhaps 
know). You have two quite large studies with very large hazard ratios 
and if we ignore them all the rest of the studies fall on a diagonal 
bacn indicative of extreme small study bias.

One thing you could consider is to use metafor and within it use the hc 
function which uses a different approach due to Henmi and Copas (the 
same Copas).

On 12/08/2015 15:19, petretta at unina.it wrote:
> Dear all,
>
> I use R 3.1.1 for Windows (x 64).
>
> I performed a meta-analysis of hazard ratio using the below reported
> Dataset and metagen function from package meta.
>
> meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")
>
> Thereafter, I try to use the copas function from package metasens.
>
> cop1<-copas(meta1)
>
>
> and I have these 3 warnings:
>
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
>
> If I try:
> plot (cop1)
>
>   I have:
> ERROR:
> object "is.relative.effect" not found
>
> Any suggestion is welcome.
>
> The Dataset is:
>
>     id Year      lnHR       seHR
> 1   1 2001 0.6881346 0.06940859
> 2   2 2001 1.4036430 0.60414338
> 3   3 2002 0.7419373 0.28897730
> 4   4 2003 1.5475625 0.45206678
> 5   5 2003 1.4816046 0.44859666
> 6   6 2005 0.9162908 0.17166950
> 7   7 2006 1.2697605 0.34205049
> 8   8 2009 0.8960880 0.24626434
> 9   9 2011 1.5040774 0.24683516
> 10 10 2012 0.4510756 0.17213355
> 11 11 2008 0.9895412 0.26590857
> 12 12 2009 2.8094027 0.61304092
> 13 13 2010 0.9162908 0.21362771
> 14 14 2011 0.5068176 0.15060408
> 15 15 2012 3.0027080 0.27239493
> 16 16 2013 1.9837563 0.55793673
> 17 17 2013 3.0492730 0.18798657
> 18 18 2014 1.2974632 0.44759619
> 19 19 2014 0.8241754 0.39551640
> 20 20 2014 2.2617631 0.56545281
>
> The code used are:
>
> meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")
>
>> meta1
>        HR             95%-CI %W(fixed) %W(random)
> 1   1.99 [ 1.7369;  2.2800]     42.92       5.99
> 2   4.07 [ 1.2455; 13.2997]      0.57       3.71
> 3   2.10 [ 1.1919;  3.7000]      2.48       5.28
> 4   4.70 [ 1.9378; 11.3998]      1.01       4.47
> 5   4.40 [ 1.8264; 10.5998]      1.03       4.49
> 6   2.50 [ 1.7857;  3.5000]      7.02       5.75
> 7   3.56 [ 1.8209;  6.9599]      1.77       5.03
> 8   2.45 [ 1.5120;  3.9700]      3.41       5.47
> 9   4.50 [ 2.7740;  7.2999]      3.39       5.47
> 10  1.57 [ 1.1204;  2.2000]      6.98       5.75
> 11  2.69 [ 1.5974;  4.5300]      2.92       5.38
> 12 16.60 [ 4.9921; 55.1988]      0.55       3.67
> 13  2.50 [ 1.6447;  3.8000]      4.53       5.60
> 14  1.66 [ 1.2357;  2.2300]      9.12       5.81
> 15 20.14 [11.8085; 34.3497]      2.79       5.36
> 16  7.27 [ 2.4357; 21.6996]      0.66       3.94
> 17 21.10 [14.5971; 30.4998]      5.85       5.69
> 18  3.66 [ 1.5223;  8.7999]      1.03       4.49
> 19  2.28 [ 1.0502;  4.9499]      1.32       4.76
> 20  9.60 [ 3.1693; 29.0794]      0.65       3.90
>
> Number of studies combined: k=20
>
>                           HR           95%-CI       z  p.value
> Fixed effect model   2.7148 [2.4833; 2.9679] 21.9628 < 0.0001
> Random effects model 3.9637 [2.7444; 5.7247]  7.3426 < 0.0001
>
> Quantifying heterogeneity:
> tau^2 = 0.5826; H = 3.56 [3.04; 4.16]; I^2 = 92.1% [89.2%; 94.2%]
>
> Test of heterogeneity:
>        Q d.f.  p.value
>   240.64   19 < 0.0001
>
> Details on meta-analytical method:
> - Inverse variance method
> - DerSimonian-Laird estimator for tau^2
>
>> cop1<-copas(meta1)
>
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
>
>> plot (cop1)
>
> ERROR:
> object "is.relative.effect" not found
>
> -------------------------------------------------------
> Mario Petretta
> Associate Professor of Internal Medicine
> Department of Translational Medical Sciences
> Naples University Federico II Italy
>
>
>
> ----
> 5x1000 AI GIOVANI RICERCATORI
> DELL'UNIVERSIT? DI NAPOLI
> Codice Fiscale: 00876220633
> www.unina.it/Vademecum5permille
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From lid.zigh at gmail.com  Wed Aug 12 20:04:16 2015
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Wed, 12 Aug 2015 13:04:16 -0500
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAM_vju=uQwUxes9vm5VGxvVHjKkn9BbY0-LHAv9nM_E26_Oeog@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAM_vju=uQwUxes9vm5VGxvVHjKkn9BbY0-LHAv9nM_E26_Oeog@mail.gmail.com>
Message-ID: <CAMqbV1Av0D0tjVh0ENvyKBsAYVoBpCYRyVFTDYihCS0O0vzojA@mail.gmail.com>

I applied this code in a loop function but since in some matrices there
isn't any 2, so I got the below error:

idx<- apply(lofGT_met,1, function(x)as.numeric(any(x==2 & !is.na(x))))


Error in apply(lofGT_met, 1, function(x){(any(x == 2)}) :
  dim(X) must have a positive length

would you please let me know how to correct it?
Thanks

On Mon, Aug 10, 2015 at 3:27 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Easy enough (note that your column names are problematic, though)
>
> > mydata <- structure(list(X125 = c(0L, 1L, 2L, 0L, 2L), X255 = c(1L, 1L,
> + 1L, 1L, 0L), X558 = c(0L, 0L, 2L, 0L, 0L), X2366 = c(NA, NA,
> + 1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
> + 0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
> + "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
> + "de", "gh"))
> > mydata$idx <- apply(mydata, 1, function(x)as.numeric(any(x == 2 & !is.na
> (x))))
> > mydata
>    X125 X255 X558 X2366 X177 X255.1 idx
> aa    0    1    0    NA    0      0   0
> bb    1    1    0    NA    0      1   0
> cs    2    1    2     1      0      0   1
> de    0    1    0    NA    0      0   0
> gh    2    0    0     0      0      0   1
>
> Sarah
>
> On Mon, Aug 10, 2015 at 4:11 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
>
>> Hi there,
>>
>> I have a matrix contain 0,1,2, NA elements.
>> I want to add a column to this matrix with name of "idx" . then for each
>> row, I should put 1 in this column (idx) if there is at least one 2 in
>> that
>> row otherwise I should put 0 in this column!
>>
>> for example  mydata:
>>
>>        125   255   558   2366   177    255
>> aa    0        1       0         NA    0         0
>> bb    1        1       0         NA    0         1
>> cs     2        1       2         1       0         0
>> de    0        1       0         NA    0         0
>> gh    2       0       0         0        0         0
>>
>>
>> my output should be:
>>
>>
>>        125   255   558   2366   177    255    idx
>> aa    0        1       0         NA    0         0      0
>> bb    1        1       0         NA    0         1      0
>> cs     2        1       2         1       0         0     1
>> de    0        1       0         NA    0         0      0
>> gh    2       0       0        2        0         2       1
>>
>> Thank you for your help.
>>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Aug 12 20:12:48 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 12 Aug 2015 14:12:48 -0400
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAMqbV1Av0D0tjVh0ENvyKBsAYVoBpCYRyVFTDYihCS0O0vzojA@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAM_vju=uQwUxes9vm5VGxvVHjKkn9BbY0-LHAv9nM_E26_Oeog@mail.gmail.com>
	<CAMqbV1Av0D0tjVh0ENvyKBsAYVoBpCYRyVFTDYihCS0O0vzojA@mail.gmail.com>
Message-ID: <CAM_vjunnVnmSFRHBOsD=eaipuPjCZPar=h2ggndn0ve7octxLg@mail.gmail.com>

On Wed, Aug 12, 2015 at 2:04 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> I applied this code in a loop function but since in some matrices there
> isn't any 2, so I got the below error:
>
> idx<- apply(lofGT_met,1, function(x)as.numeric(any(x==2 & !is.na(x))))
>
>
> Error in apply(lofGT_met, 1, function(x){(any(x == 2)}) :
>   dim(X) must have a positive length

That has nothing to do with whether there are any values of 2 in the
data frame. The code I suggested can handle that:


no2 <- structure(list(X125 = c(0L, 1L, 1L, 0L, 1L), X255 = c(1L, 1L,
 1L, 1L, 0L), X558 = c(0L, 0L, 1L, 0L, 0L), X2366 = c(NA, NA,
 1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
 0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
 "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
 "de", "gh"))

no2
apply(no2, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))


> no2
   X125 X255 X558 X2366 X177 X255.1
aa    0    1    0    NA    0      0
bb    1    1    0    NA    0      1
cs    1    1    1     1    0      0
de    0    1    0    NA    0      0
gh    1    0    0     0    0      0
> apply(no2, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))
aa bb cs de gh
 0  0  0  0  0

It also works for rows that are entirely NA. Thus, I'm forced to
conclude that there's something odd about lofGT_met, and you'll need
to provide more information about that data frame, and a reproducible
example, for a solution to be offered.

Sarah


>
> would you please let me know how to correct it?
> Thanks
>
> On Mon, Aug 10, 2015 at 3:27 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Easy enough (note that your column names are problematic, though)
>>
>> > mydata <- structure(list(X125 = c(0L, 1L, 2L, 0L, 2L), X255 = c(1L, 1L,
>> + 1L, 1L, 0L), X558 = c(0L, 0L, 2L, 0L, 0L), X2366 = c(NA, NA,
>> + 1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
>> + 0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
>> + "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
>> + "de", "gh"))
>> > mydata$idx <- apply(mydata, 1, function(x)as.numeric(any(x == 2 &
>> > !is.na(x))))
>> > mydata
>>    X125 X255 X558 X2366 X177 X255.1 idx
>> aa    0    1    0    NA    0      0   0
>> bb    1    1    0    NA    0      1   0
>> cs    2    1    2     1      0      0   1
>> de    0    1    0    NA    0      0   0
>> gh    2    0    0     0      0      0   1
>>
>> Sarah
>>
>> On Mon, Aug 10, 2015 at 4:11 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
>>>
>>> Hi there,
>>>
>>> I have a matrix contain 0,1,2, NA elements.
>>> I want to add a column to this matrix with name of "idx" . then for each
>>> row, I should put 1 in this column (idx) if there is at least one 2 in
>>> that
>>> row otherwise I should put 0 in this column!
>>>
>>> for example  mydata:
>>>
>>>        125   255   558   2366   177    255
>>> aa    0        1       0         NA    0         0
>>> bb    1        1       0         NA    0         1
>>> cs     2        1       2         1       0         0
>>> de    0        1       0         NA    0         0
>>> gh    2       0       0         0        0         0
>>>
>>>
>>> my output should be:
>>>
>>>
>>>        125   255   558   2366   177    255    idx
>>> aa    0        1       0         NA    0         0      0
>>> bb    1        1       0         NA    0         1      0
>>> cs     2        1       2         1       0         0     1
>>> de    0        1       0         NA    0         0      0
>>> gh    2       0       0        2        0         2       1
>>>


From lid.zigh at gmail.com  Wed Aug 12 20:23:31 2015
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Wed, 12 Aug 2015 13:23:31 -0500
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAM_vjunnVnmSFRHBOsD=eaipuPjCZPar=h2ggndn0ve7octxLg@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAM_vju=uQwUxes9vm5VGxvVHjKkn9BbY0-LHAv9nM_E26_Oeog@mail.gmail.com>
	<CAMqbV1Av0D0tjVh0ENvyKBsAYVoBpCYRyVFTDYihCS0O0vzojA@mail.gmail.com>
	<CAM_vjunnVnmSFRHBOsD=eaipuPjCZPar=h2ggndn0ve7octxLg@mail.gmail.com>
Message-ID: <CAMqbV1C8uN7i+2Tn5P2-hs4+YgH1h--GQa1pEgMxJOxrtfbnTg@mail.gmail.com>

Thanks Sarah,

I use your code in a loop, so each time I have different matrix, means
lofGT_met changed each time!
some times I have just one column in matrix so my matrix will be n*1 (the
number of rows is the same =n)
do you think it cause the error?


On Wed, Aug 12, 2015 at 1:12 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> On Wed, Aug 12, 2015 at 2:04 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> > I applied this code in a loop function but since in some matrices there
> > isn't any 2, so I got the below error:
> >
> > idx<- apply(lofGT_met,1, function(x)as.numeric(any(x==2 & !is.na(x))))
> >
> >
> > Error in apply(lofGT_met, 1, function(x){(any(x == 2)}) :
> >   dim(X) must have a positive length
>
> That has nothing to do with whether there are any values of 2 in the
> data frame. The code I suggested can handle that:
>
>
> no2 <- structure(list(X125 = c(0L, 1L, 1L, 0L, 1L), X255 = c(1L, 1L,
>  1L, 1L, 0L), X558 = c(0L, 0L, 1L, 0L, 0L), X2366 = c(NA, NA,
>  1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
>  0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
>  "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
>  "de", "gh"))
>
> no2
> apply(no2, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))
>
>
> > no2
>    X125 X255 X558 X2366 X177 X255.1
> aa    0    1    0    NA    0      0
> bb    1    1    0    NA    0      1
> cs    1    1    1     1    0      0
> de    0    1    0    NA    0      0
> gh    1    0    0     0    0      0
> > apply(no2, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))
> aa bb cs de gh
>  0  0  0  0  0
>
> It also works for rows that are entirely NA. Thus, I'm forced to
> conclude that there's something odd about lofGT_met, and you'll need
> to provide more information about that data frame, and a reproducible
> example, for a solution to be offered.
>
> Sarah
>
>
> >
> > would you please let me know how to correct it?
> > Thanks
> >
> > On Mon, Aug 10, 2015 at 3:27 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> Easy enough (note that your column names are problematic, though)
> >>
> >> > mydata <- structure(list(X125 = c(0L, 1L, 2L, 0L, 2L), X255 = c(1L,
> 1L,
> >> + 1L, 1L, 0L), X558 = c(0L, 0L, 2L, 0L, 0L), X2366 = c(NA, NA,
> >> + 1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
> >> + 0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
> >> + "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
> >> + "de", "gh"))
> >> > mydata$idx <- apply(mydata, 1, function(x)as.numeric(any(x == 2 &
> >> > !is.na(x))))
> >> > mydata
> >>    X125 X255 X558 X2366 X177 X255.1 idx
> >> aa    0    1    0    NA    0      0   0
> >> bb    1    1    0    NA    0      1   0
> >> cs    2    1    2     1      0      0   1
> >> de    0    1    0    NA    0      0   0
> >> gh    2    0    0     0      0      0   1
> >>
> >> Sarah
> >>
> >> On Mon, Aug 10, 2015 at 4:11 PM, Lida Zeighami <lid.zigh at gmail.com>
> wrote:
> >>>
> >>> Hi there,
> >>>
> >>> I have a matrix contain 0,1,2, NA elements.
> >>> I want to add a column to this matrix with name of "idx" . then for
> each
> >>> row, I should put 1 in this column (idx) if there is at least one 2 in
> >>> that
> >>> row otherwise I should put 0 in this column!
> >>>
> >>> for example  mydata:
> >>>
> >>>        125   255   558   2366   177    255
> >>> aa    0        1       0         NA    0         0
> >>> bb    1        1       0         NA    0         1
> >>> cs     2        1       2         1       0         0
> >>> de    0        1       0         NA    0         0
> >>> gh    2       0       0         0        0         0
> >>>
> >>>
> >>> my output should be:
> >>>
> >>>
> >>>        125   255   558   2366   177    255    idx
> >>> aa    0        1       0         NA    0         0      0
> >>> bb    1        1       0         NA    0         1      0
> >>> cs     2        1       2         1       0         0     1
> >>> de    0        1       0         NA    0         0      0
> >>> gh    2       0       0        2        0         2       1
> >>>
>

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Wed Aug 12 20:25:47 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Wed, 12 Aug 2015 14:25:47 -0400
Subject: [R] nls in r
In-Reply-To: <1439375874384-4711012.post@n4.nabble.com>
References: <1439375874384-4711012.post@n4.nabble.com>
Message-ID: <55CB8FAB.9030909@gmail.com>

With package nlmrt, I get a solution, but the Jacobian is essentially
singular, so the model may not be appropriate. You'll need to read the
documentation to learn how to interpret the Jacobian singular values. Or
Chapter 6 of my book "Nonlinear parameter optimization with R tools."

Here's the script. Note nlxb is a little different from nls() and
requires a data frame for the data.

library(stats)
x=c(30:110)
y=c(0.000760289, 0.000800320, 0.000830345, 0.000840353, 0.000860370,
0.000910414, 0.000990490, 0.001090594, 0.001200721, 0.001350912,
0.001531172, 0.001751533, 0.001961923, 0.002192402, 0.002463031,
0.002793899, 0.003185067, 0.003636604, 0.004148594, 0.004721127,
0.005394524, 0.006168989, 0.007014544, 0.007870894, 0.008758242,
0.009656474, 0.010565620, 0.011485709, 0.012396520, 0.013308162,
0.014271353, 0.015326859, 0.016525802, 0.017889059, 0.019447890,
0.021223636, 0.023145810, 0.025174229, 0.027391752, 0.029645106,
0.032337259, 0.035347424, 0.039375125, 0.043575783, 0.048003973,
0.052926206, 0.058307309, 0.064581189, 0.071947231, 0.080494476,
0.089891885, 0.100671526, 0.111971207, 0.124237571, 0.137975539,
0.153629149, 0.171239194, 0.190712664, 0.212079979, 0.235026373,
0.259457493, 0.282867017, 0.307830359, 0.334773680, 0.364001719,
0.395742526, 0.425596389, 0.458391314, 0.494558651, 0.534657357,
0.579354317, 0.616075034, 0.656680256, 0.701804548, 0.752133146,
0.808558032, 0.872226001, 0.944664487, 1.027837007, 1.124484096,
1.238426232)

vdata<- data.frame(x=x, y=y)

a=0.0189
b=0.14328
delta=0.0005

# fit = nls(y ~
a*(exp(b*(x+0.5)))*((delta*b)/((delta*b)+(a*(exp(b*(x+0.5))-1))))^(0.5),
# start=list(a=a,b=b, delta=delta), trace=TRUE)
# predict(fit)
# plot(x,y,col="red", xlab="Usia",ylab=expression(paste(mu)))
# lines(x,predict(fit), col="blue")
# legend("topleft",
# c(expression(paste(mu)),"Fit"),col=c("red","blue"),lty=1:1)

library(nlmrt)

 vformula <- y ~
a*(exp(b*(x+0.5)))*((delta*b)/((delta*b)+a*(exp(b*(x+0.5))-1)))^(0.5)

fitjn = nlxb(formula= vformula, start=list(a=a,b=b,delta=delta),
trace=TRUE, data=vdata)
fitjn

Best, JN


On 15-08-12 06:37 AM, vidya wrote:
> I get this error 
> Error in numericDeriv(form[[3L]], names(ind), env) : 
>   Missing value or an infinity produced when evaluating the model
> I was replace the starting value but still get error.
> 
> Here is my code:
> library(stats)
> x=c(30:110)
> y=c(0.000760289, 0.000800320, 0.000830345, 0.000840353, 0.000860370,  
> 0.000910414, 0.000990490, 0.001090594, 0.001200721, 0.001350912, 
> 0.001531172, 0.001751533, 0.001961923, 0.002192402, 0.002463031, 
> 0.002793899, 0.003185067, 0.003636604, 0.004148594, 0.004721127, 
> 0.005394524, 0.006168989, 0.007014544, 0.007870894, 0.008758242, 
> 0.009656474, 0.010565620, 0.011485709, 0.012396520, 0.013308162, 
> 0.014271353, 0.015326859, 0.016525802, 0.017889059, 0.019447890, 
> 0.021223636, 0.023145810, 0.025174229, 0.027391752, 0.029645106, 
> 0.032337259, 0.035347424, 0.039375125, 0.043575783, 0.048003973, 
> 0.052926206, 0.058307309, 0.064581189, 0.071947231, 0.080494476, 
> 0.089891885, 0.100671526, 0.111971207, 0.124237571, 0.137975539, 
> 0.153629149, 0.171239194, 0.190712664, 0.212079979, 0.235026373,
> 0.259457493, 0.282867017, 0.307830359, 0.334773680, 0.364001719, 
> 0.395742526, 0.425596389, 0.458391314, 0.494558651, 0.534657357, 
> 0.579354317, 0.616075034, 0.656680256, 0.701804548, 0.752133146, 
> 0.808558032, 0.872226001, 0.944664487, 1.027837007, 1.124484096, 
> 1.238426232)
> 
> a=0.0189
> b=0.14328
> delta=0.0005
> 
> fit = nls(y ~
> a*(exp(b*(x+0.5)))*((delta*b)/((delta*b)+(a*(exp(b*(x+0.5))-1))))^(0.5), 
> start=list(a=a,b=b, delta=delta))
> predict(fit)
> plot(x,y,col="red", xlab="Usia",ylab=expression(paste(mu)))
> lines(x,predict(fit), col="blue")
> legend("topleft",
> c(expression(paste(mu)),"Fit"),col=c("red","blue"),lty=1:1)
> 
> 
> I really appreciate for the helps. Thank you.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/nls-in-r-tp4711012.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sarah.goslee at gmail.com  Wed Aug 12 20:37:18 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 12 Aug 2015 14:37:18 -0400
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAMqbV1C8uN7i+2Tn5P2-hs4+YgH1h--GQa1pEgMxJOxrtfbnTg@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAM_vju=uQwUxes9vm5VGxvVHjKkn9BbY0-LHAv9nM_E26_Oeog@mail.gmail.com>
	<CAMqbV1Av0D0tjVh0ENvyKBsAYVoBpCYRyVFTDYihCS0O0vzojA@mail.gmail.com>
	<CAM_vjunnVnmSFRHBOsD=eaipuPjCZPar=h2ggndn0ve7octxLg@mail.gmail.com>
	<CAMqbV1C8uN7i+2Tn5P2-hs4+YgH1h--GQa1pEgMxJOxrtfbnTg@mail.gmail.com>
Message-ID: <CAM_vju=XtAg1xVd7dpc9dWhxWB=sE_YWS3qBsj7v9Hq1sYeAoQ@mail.gmail.com>

On Wed, Aug 12, 2015 at 2:23 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
> Thanks Sarah,
>
> I use your code in a loop, so each time I have different matrix, means
> lofGT_met changed each time!
> some times I have just one column in matrix so my matrix will be n*1 (the
> number of rows is the same =n)
> do you think it cause the error?

Not if it is really a two-dimensional object. That's why I suggested
you provide a *reproducible example*.

> onecol <- data.frame(aa=c(1, 2, 3, NA))
> onecol
  aa
1  1
2  2
3  3
4 NA
> apply(onecol, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))
[1] 0 1 0 0

> onecol <- as.vector(onecol[,1])
> onecol
[1]  1  2  3 NA
> apply(onecol, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))
Error in apply(onecol, 1, function(x) as.numeric(any(x == 2 & !is.na(x)))) :
  dim(X) must have a positive length


>
> On Wed, Aug 12, 2015 at 1:12 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> On Wed, Aug 12, 2015 at 2:04 PM, Lida Zeighami <lid.zigh at gmail.com> wrote:
>> > I applied this code in a loop function but since in some matrices there
>> > isn't any 2, so I got the below error:
>> >
>> > idx<- apply(lofGT_met,1, function(x)as.numeric(any(x==2 & !is.na(x))))
>> >
>> >
>> > Error in apply(lofGT_met, 1, function(x){(any(x == 2)}) :
>> >   dim(X) must have a positive length
>>
>> That has nothing to do with whether there are any values of 2 in the
>> data frame. The code I suggested can handle that:
>>
>>
>> no2 <- structure(list(X125 = c(0L, 1L, 1L, 0L, 1L), X255 = c(1L, 1L,
>>  1L, 1L, 0L), X558 = c(0L, 0L, 1L, 0L, 0L), X2366 = c(NA, NA,
>>  1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
>>  0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
>>  "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
>>  "de", "gh"))
>>
>> no2
>> apply(no2, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))
>>
>>
>> > no2
>>    X125 X255 X558 X2366 X177 X255.1
>> aa    0    1    0    NA    0      0
>> bb    1    1    0    NA    0      1
>> cs    1    1    1     1    0      0
>> de    0    1    0    NA    0      0
>> gh    1    0    0     0    0      0
>> > apply(no2, 1, function(x)as.numeric(any(x == 2 & !is.na(x))))
>> aa bb cs de gh
>>  0  0  0  0  0
>>
>> It also works for rows that are entirely NA. Thus, I'm forced to
>> conclude that there's something odd about lofGT_met, and you'll need
>> to provide more information about that data frame, and a reproducible
>> example, for a solution to be offered.
>>
>> Sarah
>>
>>
>> >
>> > would you please let me know how to correct it?
>> > Thanks
>> >
>> > On Mon, Aug 10, 2015 at 3:27 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> > wrote:
>> >>
>> >> Easy enough (note that your column names are problematic, though)
>> >>
>> >> > mydata <- structure(list(X125 = c(0L, 1L, 2L, 0L, 2L), X255 = c(1L,
>> >> > 1L,
>> >> + 1L, 1L, 0L), X558 = c(0L, 0L, 2L, 0L, 0L), X2366 = c(NA, NA,
>> >> + 1L, NA, 0L), X177 = c(0L, 0L, 0L, 0L, 0L), X255.1 = c(0L, 1L,
>> >> + 0L, 0L, 0L)), .Names = c("X125", "X255", "X558", "X2366", "X177",
>> >> + "X255.1"), class = "data.frame", row.names = c("aa", "bb", "cs",
>> >> + "de", "gh"))
>> >> > mydata$idx <- apply(mydata, 1, function(x)as.numeric(any(x == 2 &
>> >> > !is.na(x))))
>> >> > mydata
>> >>    X125 X255 X558 X2366 X177 X255.1 idx
>> >> aa    0    1    0    NA    0      0   0
>> >> bb    1    1    0    NA    0      1   0
>> >> cs    2    1    2     1      0      0   1
>> >> de    0    1    0    NA    0      0   0
>> >> gh    2    0    0     0      0      0   1
>> >>
>> >> Sarah
>> >>
>> >> On Mon, Aug 10, 2015 at 4:11 PM, Lida Zeighami <lid.zigh at gmail.com>
>> >> wrote:
>> >>>
>> >>> Hi there,
>> >>>
>> >>> I have a matrix contain 0,1,2, NA elements.
>> >>> I want to add a column to this matrix with name of "idx" . then for
>> >>> each
>> >>> row, I should put 1 in this column (idx) if there is at least one 2 in
>> >>> that
>> >>> row otherwise I should put 0 in this column!
>> >>>
>> >>> for example  mydata:
>> >>>
>> >>>        125   255   558   2366   177    255
>> >>> aa    0        1       0         NA    0         0
>> >>> bb    1        1       0         NA    0         1
>> >>> cs     2        1       2         1       0         0
>> >>> de    0        1       0         NA    0         0
>> >>> gh    2       0       0         0        0         0
>> >>>
>> >>>
>> >>> my output should be:
>> >>>
>> >>>
>> >>>        125   255   558   2366   177    255    idx
>> >>> aa    0        1       0         NA    0         0      0
>> >>> bb    1        1       0         NA    0         1      0
>> >>> cs     2        1       2         1       0         0     1
>> >>> de    0        1       0         NA    0         0      0
>> >>> gh    2       0       0        2        0         2       1
>> >>>
>
>


From k.kowitski at icloud.com  Wed Aug 12 17:51:12 2015
From: k.kowitski at icloud.com (Kevin Kowitski)
Date: Wed, 12 Aug 2015 15:51:12 +0000 (GMT)
Subject: [R] String Matching
Message-ID: <5fabd36a-ed1d-4e66-a77f-05e24bc9b0e6@me.com>

Hey everyone,?

? I have been having an issue trying to find a specific string of text in a log of system messages. ?I have tried to use pmatch, match, and some regular expressions but all to no avail. ?

I have a matrix / data.frame (either one, the file outputs a tens of thousands of rows with a single column) of strings in the following format with different items after INFO:
?"09:11:57.259 - Assay File Processing Thread - INFO - SolenoidCycleMessage: Addr = 0x03 "

as an example I would like to match "SolenoidCycleMessage"
searchString<-"SolenoidCycleMessage"
matchString<-"09:11:57.259 - Assay File Processing Thread - INFO - SolenoidCycleMessage: Addr = 0x03"

> pmatch(searchString, matchString)
[1] NA

> match(searchString, matchString)
[1] NA
> match(matchString, searchString)
[1] NA
> grep(searchString, matchString, ignore.case=FALSE)
[1] 1
> df<-as.data.frame(c(matchString, string1, string2))
> df
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?c(matchString, string1, string2)
1 09:11:57.259 - Assay File Processing Thread - INFO - SolenoidCycleMessage: Addr = 0x03?
2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?23:12:43.22 - Test
3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?test
> grep(searchString, df, ignore.case=FALSE)
integer(0)

> grep(searchString, c(matchString, string1, string2), ignore.case=FALSE)
[1] 1

Doe anyone have some input that could help?

Thanks,?
Kevin

From trisgutt at hotmail.com  Wed Aug 12 19:35:13 2015
From: trisgutt at hotmail.com (trisgutt)
Date: Wed, 12 Aug 2015 10:35:13 -0700 (PDT)
Subject: [R] Predict Function use with GLM
Message-ID: <1439400913689-4711026.post@n4.nabble.com>

I am currently using a GLM with Gaussian family to model fish depth~length +
distance from shore: 

model1 <- glm(Depth ~ length + distance from shore,
family=gaussian(link="log"))

There are no zero depths. I would like to use the above model with the
predict function in R to generate three lines (with confidence intervals)
for the depth at size for three distances, say 100 m, 500 m and 1000m.
Problem is I am unable to figure out how to do this? 

Any advice / assistance would be gratefully received...

Thank you

Tris




--
View this message in context: http://r.789695.n4.nabble.com/Predict-Function-use-with-GLM-tp4711026.html
Sent from the R help mailing list archive at Nabble.com.


From istazahn at gmail.com  Wed Aug 12 21:40:03 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 12 Aug 2015 15:40:03 -0400
Subject: [R] String Matching
In-Reply-To: <5fabd36a-ed1d-4e66-a77f-05e24bc9b0e6@me.com>
References: <5fabd36a-ed1d-4e66-a77f-05e24bc9b0e6@me.com>
Message-ID: <CA+vqiLFTp+BNxL7kWX7zU-aeMDWMZDohbckMFG-TGdNbGsG_6Q@mail.gmail.com>

Hi Kevin,

It's not totally clear to me what the desired output is.

grep(searchString, matchString, ignore.case=FALSE)

told you that searchString is in the first element of matchString.
Isn't that what you want to know? If not, perhaps you can be more
specific about what the desired result is.

Best,
Ista

On Wed, Aug 12, 2015 at 11:51 AM, Kevin Kowitski <k.kowitski at icloud.com> wrote:
> Hey everyone,
>
>   I have been having an issue trying to find a specific string of text in a
> log of system messages.  I have tried to use pmatch, match, and some regular
> expressions but all to no avail.
>
> I have a matrix / data.frame (either one, the file outputs a tens of
> thousands of rows with a single column) of strings in the following format
> with different items after INFO:
>  "09:11:57.259 - Assay File Processing Thread - INFO - SolenoidCycleMessage:
> Addr = 0x03 "
>
> as an example I would like to match "SolenoidCycleMessage"
> searchString<-"SolenoidCycleMessage"
> matchString<-"09:11:57.259 - Assay File Processing Thread - INFO -
> SolenoidCycleMessage: Addr = 0x03"
>
>> pmatch(searchString, matchString)
>
> [1] NA
>
>> match(searchString, matchString)
>
> [1] NA
>>
>> match(matchString, searchString)
>
> [1] NA
>>
>> grep(searchString, matchString, ignore.case=FALSE)
>
> [1] 1
>>
>> df<-as.data.frame(c(matchString, string1, string2))
>> df
>
>                                                          c(matchString,
> string1, string2)
> 1 09:11:57.259 - Assay File Processing Thread - INFO - SolenoidCycleMessage:
> Addr = 0x03
> 2
> 23:12:43.22 - Test
> 3
> test
>>
>> grep(searchString, df, ignore.case=FALSE)
>
> integer(0)
>
>> grep(searchString, c(matchString, string1, string2), ignore.case=FALSE)
>
> [1] 1
>
> Doe anyone have some input that could help?
>
> Thanks,
> Kevin
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Wed Aug 12 22:03:00 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 12 Aug 2015 20:03:00 +0000
Subject: [R] Predict Function use with GLM
References: <1439400913689-4711026.post@n4.nabble.com>
Message-ID: <loom.20150812T220002-197@post.gmane.org>

trisgutt <trisgutt <at> hotmail.com> writes:

> 
> I am currently using a GLM with Gaussian family to model fish depth~length +
> distance from shore: 
> 
> model1 <- glm(Depth ~ length + distance from shore,
> family=gaussian(link="log"))
> 
> There are no zero depths. I would like to use the above model with the
> predict function in R to generate three lines (with confidence intervals)
> for the depth at size for three distances, say 100 m, 500 m and 1000m.
> Problem is I am unable to figure out how to do this? 
> 
> Any advice / assistance would be gratefully received...
> 
> Thank you
> 
> Tris
> 

Something like:

pp <- expand.grid(distance=c(100,500,1000),
                       length=seq(min_depth,max_depth,length.out=51))
## 51 is arbitrary -- you just need enough points to make the curve
## appear smooth

predvals <- predict(model1,newdata=newdata,se.fit=TRUE,type="link")
pp <- transform(pp,est=exp(predvals$fit),
            lwr=exp(predvals$fit-1.96*predvals$se),
            upr=exp(predvals$fit+1.96*predvals$se))


From davef at otter-rsch.com  Wed Aug 12 21:38:51 2015
From: davef at otter-rsch.com (dave fournier)
Date: Wed, 12 Aug 2015 12:38:51 -0700
Subject: [R] nls in r
In-Reply-To: <55CB8FAB.9030909@gmail.com>
References: <55CB8FAB.9030909@gmail.com>
Message-ID: <55CBA0CB.7060509@otter-rsch.com>


I believe that if your try these starting values the sum of squares is 
considerably smaller


a=1.0851e-06
b=1.4596e-01
delta=9.1375e-01

something like SS= 0.005236471 vs  SS= 0.01597071


From valkremk at gmail.com  Thu Aug 13 04:37:20 2015
From: valkremk at gmail.com (Val)
Date: Wed, 12 Aug 2015 22:37:20 -0400
Subject: [R] Reading multiple files from different folders
Message-ID: <CAJOiR6YHHDaoAjCC5m8kW68om3qESv85-Z4gBS1+bfBrWNS4DQ@mail.gmail.com>

Hi all,

I have several files in different folders or subdirectories.  Here is an
example of the data set.

c:\country\state\city.  There might be more than 500 cities.

**********************************
c:\country\state\city1
c:\country\state\city2
.
.
.
c:\country\state\city500

***************************
Cities may keep  the population record either in Excel file or  text file
 format ( *.xlsx or *.txt)

Each file contains :   first name, last name, address, zip code, etc

I want  to create one data set  from  all the cities  for analysis of in
interest.

Output should looks  like

country,  state, city, first name, last name, address, zip code,  etc.
 USA ,    NY ,  city1, Alex    ,    John  ,     102  st name ,   10004 ,
 USA   ,     NY ,     city1    Martin  ,         Leno  ,       284 street
name  ,  10003 ,
 .
 .
 USA,    NY ,  city500,  Ethan , Noah  ,   543  st name ,  10015 ,

Please note that variables  Country, state and city come from the
 " c:\country\state\city"

I would appreciate your  help me in reading and combing this data sets

Thank you in advance,

	[[alternative HTML version deleted]]


From desak.ristia at yahoo.co.id  Thu Aug 13 04:41:13 2015
From: desak.ristia at yahoo.co.id (vidya)
Date: Wed, 12 Aug 2015 19:41:13 -0700 (PDT)
Subject: [R] nls in r
In-Reply-To: <55CBA0CB.7060509@otter-rsch.com>
References: <1439375874384-4711012.post@n4.nabble.com>
	<55CB8FAB.9030909@gmail.com> <55CBA0CB.7060509@otter-rsch.com>
Message-ID: <1439433673154-4711043.post@n4.nabble.com>

How can you find that starting value ? is there a trick for that ?.

Really appreciate. Thank you very much. 


King Regards








--
View this message in context: http://r.789695.n4.nabble.com/nls-in-r-tp4711012p4711043.html
Sent from the R help mailing list archive at Nabble.com.


From desak.ristia at yahoo.co.id  Thu Aug 13 04:44:44 2015
From: desak.ristia at yahoo.co.id (vidya)
Date: Wed, 12 Aug 2015 19:44:44 -0700 (PDT)
Subject: [R] nls in r
In-Reply-To: <55CB8FAB.9030909@gmail.com>
References: <1439375874384-4711012.post@n4.nabble.com>
	<55CB8FAB.9030909@gmail.com>
Message-ID: <1439433884802-4711044.post@n4.nabble.com>

Thank you very much Prof.JC Nash

I am still don't understand about that Jacobian. why the model not
approprite. 

Really appreciate
King regards



--
View this message in context: http://r.789695.n4.nabble.com/nls-in-r-tp4711012p4711044.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Thu Aug 13 06:02:06 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 12 Aug 2015 21:02:06 -0700
Subject: [R] nls in r
In-Reply-To: <1439433673154-4711043.post@n4.nabble.com>
References: <1439375874384-4711012.post@n4.nabble.com>
	<55CB8FAB.9030909@gmail.com> <55CBA0CB.7060509@otter-rsch.com>
	<1439433673154-4711043.post@n4.nabble.com>
Message-ID: <A6DAFE40-993D-4BD2-8543-8803C925C27E@dcn.davis.CA.us>

This subject is introduced in multivariable calculus, and in more detail in some numerical analysis courses. Graphing is one common technique for identifying promising search ranges if the number of variables can be reduced to one or two. Analytical identification of asymptotes, extrema, and zeros can also be employed to set bounds/starting points for searching, but those topics are in general completely orthogonal to the topic of this mailing list... which is R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 12, 2015 7:41:13 PM PDT, vidya <desak.ristia at yahoo.co.id> wrote:
>How can you find that starting value ? is there a trick for that ?.
>
>Really appreciate. Thank you very much. 
>
>
>King Regards
>
>
>
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/nls-in-r-tp4711012p4711043.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From anshuk.p at motivitylabs.com  Thu Aug 13 07:05:19 2015
From: anshuk.p at motivitylabs.com (Anshuk Pal Chaudhuri)
Date: Thu, 13 Aug 2015 05:05:19 +0000
Subject: [R] Doing PDF OCR with R
Message-ID: <HKXPR02MB063267AA07F69CE7ACC5AC46F07D0@HKXPR02MB0632.apcprd02.prod.outlook.com>

Hi All,

I have been trying to do OCR within R (reading PDF data which data as scanned image). Have been reading about this @ http://electricarchaeology.ca/2014/07/15/doing-ocr-within-r/

This a very good post.

Effectively 3 steps:

convert pdf to ppm (an image format)
convert ppm to tif ready for tesseract (using ImageMagick for convert)
convert tif to text file
The effective code for the above 3 steps as per the link post:

lapply(myfiles, function(i){
  # convert pdf to ppm (an image format), just pages 1-10 of the PDF
  # but you can change that easily, just remove or edit the
  # -f 1 -l 10 bit in the line below
  shell(shQuote(paste0("F:/xpdf/bin64/pdftoppm.exe ", i, " -f 1 -l 10 -r 600 ocrbook")))
  # convert ppm to tif ready for tesseract
  shell(shQuote(paste0("F:/ImageMagick-6.9.1-Q16/convert.exe *.ppm ", i, ".tif")))
  # convert tif to text file
  shell(shQuote(paste0("F:/Tesseract-OCR/tesseract.exe ", i, ".tif ", i, " -l eng")))
  # delete tif file
  file.remove(paste0(i, ".tif" ))
  })
The first two steps are happening fine. (although taking good amount of time, for 4 pages of a pdf, but will look into the scalability part later, first trying if this works or not)

While running this, the first two steps work fine.

While runinng the 3rd step, i.e

**shell(shQuote(paste0("F:/Tesseract-OCR/tesseract.exe ", i, ".tif ", i, " -l eng")))**
I having this error:

Error: evaluation nested too deeply: infinite recursion / options(expressions=)?

Or

Tesseract is crashing.

Any workaround or root cause analysis would be appreciated.

Regards,
Anshuk Pal Chaudhuri


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Aug 13 07:29:47 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 12 Aug 2015 22:29:47 -0700
Subject: [R] Doing PDF OCR with R
In-Reply-To: <HKXPR02MB063267AA07F69CE7ACC5AC46F07D0@HKXPR02MB0632.apcprd02.prod.outlook.com>
References: <HKXPR02MB063267AA07F69CE7ACC5AC46F07D0@HKXPR02MB0632.apcprd02.prod.outlook.com>
Message-ID: <648411A2-3794-4FC4-8493-2D8911D7CC08@dcn.davis.CA.us>

This code is using R like a command shell... there really is not much chance that R is the problem, and this is not a "tesseract" support forum, so this seems quite off-topic. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 12, 2015 10:05:19 PM PDT, Anshuk Pal Chaudhuri <anshuk.p at motivitylabs.com> wrote:
>Hi All,
>
>I have been trying to do OCR within R (reading PDF data which data as
>scanned image). Have been reading about this @
>http://electricarchaeology.ca/2014/07/15/doing-ocr-within-r/
>
>This a very good post.
>
>Effectively 3 steps:
>
>convert pdf to ppm (an image format)
>convert ppm to tif ready for tesseract (using ImageMagick for convert)
>convert tif to text file
>The effective code for the above 3 steps as per the link post:
>
>lapply(myfiles, function(i){
>  # convert pdf to ppm (an image format), just pages 1-10 of the PDF
>  # but you can change that easily, just remove or edit the
>  # -f 1 -l 10 bit in the line below
>shell(shQuote(paste0("F:/xpdf/bin64/pdftoppm.exe ", i, " -f 1 -l 10 -r
>600 ocrbook")))
>  # convert ppm to tif ready for tesseract
>shell(shQuote(paste0("F:/ImageMagick-6.9.1-Q16/convert.exe *.ppm ", i,
>".tif")))
>  # convert tif to text file
>shell(shQuote(paste0("F:/Tesseract-OCR/tesseract.exe ", i, ".tif ", i,
>" -l eng")))
>  # delete tif file
>  file.remove(paste0(i, ".tif" ))
>  })
>The first two steps are happening fine. (although taking good amount of
>time, for 4 pages of a pdf, but will look into the scalability part
>later, first trying if this works or not)
>
>While running this, the first two steps work fine.
>
>While runinng the 3rd step, i.e
>
>**shell(shQuote(paste0("F:/Tesseract-OCR/tesseract.exe ", i, ".tif ",
>i, " -l eng")))**
>I having this error:
>
>Error: evaluation nested too deeply: infinite recursion /
>options(expressions=)?
>
>Or
>
>Tesseract is crashing.
>
>Any workaround or root cause analysis would be appreciated.
>
>Regards,
>Anshuk Pal Chaudhuri
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Aug 13 08:07:44 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 13 Aug 2015 06:07:44 +0000
Subject: [R] add an idx column to the matrix
In-Reply-To: <CAMqbV1BzS0J5GG5Mfde65SawRHBe2TGHcMmUFHx=KUNLVXk6NA@mail.gmail.com>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAJuCY5w+jgXX_BupPMRpTY2zPXBv_zUZ_uW48jzej9ecdLM_Sw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39627@SRVEXCHMBX.precheza.cz>
	<CAMqbV1BzS0J5GG5Mfde65SawRHBe2TGHcMmUFHx=KUNLVXk6NA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39B02@SRVEXCHMBX.precheza.cz>

Hi

the error is not caused by missing 2

> set.seed(333)
> x<-sample(0:1, 12, rep=T)
> dim(x)<-c(3,4)
> x[2,2]<-NA
> cbind(x, idx=(rowSums(x==2, na.rm=TRUE)>0)*1)
              idx
[1,] 0  1 1 0   0
[2,] 0 NA 0 0   0
[3,] 1  1 0 0   0

As Sarah pointed out, you are the only one observing such error. Without more information ? at least  structure of your data

see ?str

but preferably part of your data causing error and a code you hardly get any sensible advice.

Cheers
Petr
From: Lida Zeighami [mailto:lid.zigh at gmail.com]
Sent: Wednesday, August 12, 2015 6:23 PM
To: PIKAL Petr
Subject: Re: [R] add an idx column to the matrix

Dear Petr,

I use your code in a loop function, but in some matrix there isn't any 2 so I got the below error:

Error in rowSums(lofGT_met == 2, na.rm = T) :
  'x' must be an array of at least two dimensions

would you please let me know how to correct it?
Thanks,
Lida

On Tue, Aug 11, 2015 at 1:40 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

here is another approach.

> cbind(mydata, idx=(rowSums(mydata==2, na.rm=T)>0)*1)
   X125 X255 X558 X2366 X177 X255.1 idx
aa    0    1    0    NA    0      0   0
bb    1    1    0    NA    0      1   0
cs    2    1    2     1    0      0   1
de    0    1    0    NA    0      0   0
gh    2    0    0     0    0      0   1

It shall be faster if this is an issue.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Thierry
> Onkelinx
> Sent: Monday, August 10, 2015 10:29 PM
> To: Lida Zeighami
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] add an idx column to the matrix
>
> Dear Lida,
>
> Here is a solution. Please don't post in HTML. And provide an easy to
> use
> example of the data. E.g. the output of dput(mydata)
>
> set.seed(1234)
> mydata <- matrix(
>   sample(
>     c(0, 1, 2, NA),
>     size = 30,
>     replace = TRUE,
>     prob = c(2, 1, 1, 1)
>   ),
>   ncol = 6
> )
>
> idx <- apply(mydata, 1, function(x){any(x == 2)})
> idx[is.na<http://is.na>(idx)] <- FALSE
> cbind(mydata, idx)
>
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> 2015-08-10 22:11 GMT+02:00 Lida Zeighami <lid.zigh at gmail.com<mailto:lid.zigh at gmail.com>>:
>
> > Hi there,
> >
> > I have a matrix contain 0,1,2, NA elements.
> > I want to add a column to this matrix with name of "idx" . then for
> each
> > row, I should put 1 in this column (idx) if there is at least one 2
> in that
> > row otherwise I should put 0 in this column!
> >
> > for example  mydata:
> >
> >        125   255   558   2366   177    255
> > aa    0        1       0         NA    0         0
> > bb    1        1       0         NA    0         1
> > cs     2        1       2         1       0         0
> > de    0        1       0         NA    0         0
> > gh    2       0       0         0        0         0
> >
> >
> > my output should be:
> >
> >
> >        125   255   558   2366   177    255    idx
> > aa    0        1       0         NA    0         0      0
> > bb    1        1       0         NA    0         1      0
> > cs     2        1       2         1       0         0     1
> > de    0        1       0         NA    0         0      0
> > gh    2       0       0        2        0         2       1
> >
> > Thank you for your help.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Aug 13 08:22:20 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 13 Aug 2015 06:22:20 +0000
Subject: [R] Reading multiple files from different folders
In-Reply-To: <CAJOiR6YHHDaoAjCC5m8kW68om3qESv85-Z4gBS1+bfBrWNS4DQ@mail.gmail.com>
References: <CAJOiR6YHHDaoAjCC5m8kW68om3qESv85-Z4gBS1+bfBrWNS4DQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39B33@SRVEXCHMBX.precheza.cz>

Hi

First you shall move your folders to some other place than c:. Let say

c:\project\country\...

after that you can list folders by ?list.dirs and files by ?list.files.

you can then navigate directories by ?setwd, ?getwd and read files from them.

The exact code depends on what exactly you have and want to do and I wonder if anybody can give canned solution for you, especially when your files have various origin.

Here is a sample of code reading files from folders, calculating some values, plotting some graphs and writing final result.

wd<- getwd()
dirs<-list.dirs()
dirs<-dirs[-1]
n <- length(dirs)
pigm<-gsub("./([[:alnum:]])","\\1", dirs)
vysled <- data.frame(MinFeret=rep(NA, n), ECD = rep(NA, n),
aspect= rep(NA,n), pigment=rep("X", n), stringsAsFactors=F)

for (i in 1:length(dirs)) {

setwd(wd)
setwd(dirs[i])
if(file.exists("Results.xls")) {
velik<-read.delim("Results.xls")
zeros <- which(velik[,c(2,3,7)]<5, arr.ind=T)[,1]
if (length(zeros)>0) velik<-velik[-zeros,]
velik$ecd<-sqrt(4*velik$Area/pi)
velik$aspect<-velik$Feret/velik$MinFeret
velik <- velik[,-1]
maxx<-ceiling(max(velik$ecd)/100)*100

png(paste(pigm[i], "png", sep="."), 800,800)
plot(ecdf(velik$ecd), col=3, main=pigm[i], xlab="Particle size nm",
ylab="Cummulative percentage ECD", xlim=c(0,maxx))
plot(ecdf(velik$MinFeret), col=4, main=pigm[i], xlab="Particle size nm",
ylab="Cummulative percentage MinFeret", xlim=c(0,maxx), add=T)
abline(v=100, h=.5, col="pink", lwd=5)
legend(450, .2, legend=c("ECD", "MinFeret"), fill=3:4)
dev.off()

png(paste(paste(pigm[i], "ECD"), "png", sep="."), 800,800)
plot(ecdf(velik$ecd), col=3, main=pigm[i], xlab="Particle size nm",
ylab="Cummulative percentage ECD", xlim=c(0,maxx))
abline(v=100, h=.5, col="pink", lwd=5)
dev.off()

vysled[i,1:2]<- round(apply(velik[,6:7], 2, median),0)
vysled[i,3]<- round(median(velik[,8]),3)
vysled[i,4] <- pigm[i] } else {
vysled[i,4] <- pigm[i]}
setwd(wd)
write.table(vysled, "vysled.xls", sep="\t", row.names=F, na="")

}

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
> Sent: Thursday, August 13, 2015 4:37 AM
> To: r-help at r-project.org
> Subject: [R] Reading multiple files from different folders
>
> Hi all,
>
> I have several files in different folders or subdirectories.  Here is
> an example of the data set.
>
> c:\country\state\city.  There might be more than 500 cities.
>
> **********************************
> c:\country\state\city1
> c:\country\state\city2
> .
> .
> .
> c:\country\state\city500
>
> ***************************
> Cities may keep  the population record either in Excel file or  text
> file  format ( *.xlsx or *.txt)
>
> Each file contains :   first name, last name, address, zip code, etc
>
> I want  to create one data set  from  all the cities  for analysis of
> in interest.
>
> Output should looks  like
>
> country,  state, city, first name, last name, address, zip code,  etc.
>  USA ,    NY ,  city1, Alex    ,    John  ,     102  st name ,   10004
> ,
>  USA   ,     NY ,     city1    Martin  ,         Leno  ,       284
> street
> name  ,  10003 ,
>  .
>  .
>  USA,    NY ,  city500,  Ethan , Noah  ,   543  st name ,  10015 ,
>
> Please note that variables  Country, state and city come from the  "
> c:\country\state\city"
>
> I would appreciate your  help me in reading and combing this data sets
>
> Thank you in advance,
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From kristin.kaiser at web.de  Thu Aug 13 09:57:57 2015
From: kristin.kaiser at web.de (Krissey)
Date: Thu, 13 Aug 2015 00:57:57 -0700 (PDT)
Subject: [R] How to obtain the unique communities when plotting VENNs?
Message-ID: <1439452677012-4711056.post@n4.nabble.com>

Hey there guys.

I am having a question about Venn diagrams.
A colleague wrote a script based on the VennDiagram package a while ago,
that I was able to adapt for my data. I wanted a Venn for the soil bacterial
communities derived from forests of 4 different tree species.
It worked fine for me, however my question is: 

Is there a possibility to somehow obtain a list of the unique populations of
each of the for categories?
<http://r.789695.n4.nabble.com/file/n4711056/Venntrees.png> 

That's what the Venn looks like. Now I'd like to now the 426 community
members, that seem to be unique for beech forest, the 45 for pine, ect ect.
I feel like this is a tough call because of all the intersecting that had to
be done before. These are the Intersects:
N12 = InterSect(AKL_beech,AKL_oak)#(1,2)
N13 = InterSect(AKL_beech, AKL_pine)#(1,3)
N14 = InterSect(AKL_beech, AKL_spruce)#(1,4)
N23 = InterSect(AKL_oak,AKL_pine)#(2,3)
N24 = InterSect(AKL_oak,AKL_spruce)#(2,4)
N34 = InterSect(AKL_pine,AKL_spruce)#(3,4)
length(N234) - length(N1234)
N1234 = InterSect(N12,N34)
N123 = InterSect(N12,AKL_pine)
length(N123) - length(N1234)
N124 = InterSect(N12,AKL_spruce)
length(N124) - length(N1234)
N134 = InterSect(N13,AKL_spruce)
length(N134) - length(N1234)
N234 = InterSect(N23,AKL_spruce)

Does anyone has an idea how to do it? I'm completely at loss by now, since I
am also not a pro concerning R, or statistics.
I'd be happy to hear what you come up with.
Thanks so much in advance!

Best, Krissey




--
View this message in context: http://r.789695.n4.nabble.com/How-to-obtain-the-unique-communities-when-plotting-VENNs-tp4711056.html
Sent from the R help mailing list archive at Nabble.com.


From petretta at unina.it  Thu Aug 13 11:25:45 2015
From: petretta at unina.it (Mario Petretta)
Date: Thu, 13 Aug 2015 11:25:45 +0200
Subject: [R] R:  help with metasens
In-Reply-To: <55CB7210.3030409@dewey.myzen.co.uk>
References: <20150812141945.Horde.mMVJAOJFce5OwW_oJpmzlw8@webmail-sso.unina.it>
	<55CB7210.3030409@dewey.myzen.co.uk>
Message-ID: <002201d0d5aa$09042e90$1b0c8bb0$@unina.it>

Many thanks for your suggestion.

I will try a new database search and the hc metaphor function.

Mario

PS: what is diagonal bacn?

-----Messaggio originale-----
Da: Michael Dewey [mailto:lists at dewey.myzen.co.uk] 
Inviato: mercoled? 12 agosto 2015 18.19
A: petretta at unina.it; r-help at r-project.org
Oggetto: Re: [R] help with metasens

Dear Mario

I do not use metasens myself so cannot be of direct help but I have looked at your dataset and it does seem rather strange (as you perhaps know). You have two quite large studies with very large hazard ratios and if we ignore them all the rest of the studies fall on a diagonal bacn indicative of extreme small study bias.

One thing you could consider is to use metafor and within it use the hc function which uses a different approach due to Henmi and Copas (the same Copas).

On 12/08/2015 15:19, petretta at unina.it wrote:
> Dear all,
>
> I use R 3.1.1 for Windows (x 64).
>
> I performed a meta-analysis of hazard ratio using the below reported 
> Dataset and metagen function from package meta.
>
> meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")
>
> Thereafter, I try to use the copas function from package metasens.
>
> cop1<-copas(meta1)
>
>
> and I have these 3 warnings:
>
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
>
> If I try:
> plot (cop1)
>
>   I have:
> ERROR:
> object "is.relative.effect" not found
>
> Any suggestion is welcome.
>
> The Dataset is:
>
>     id Year      lnHR       seHR
> 1   1 2001 0.6881346 0.06940859
> 2   2 2001 1.4036430 0.60414338
> 3   3 2002 0.7419373 0.28897730
> 4   4 2003 1.5475625 0.45206678
> 5   5 2003 1.4816046 0.44859666
> 6   6 2005 0.9162908 0.17166950
> 7   7 2006 1.2697605 0.34205049
> 8   8 2009 0.8960880 0.24626434
> 9   9 2011 1.5040774 0.24683516
> 10 10 2012 0.4510756 0.17213355
> 11 11 2008 0.9895412 0.26590857
> 12 12 2009 2.8094027 0.61304092
> 13 13 2010 0.9162908 0.21362771
> 14 14 2011 0.5068176 0.15060408
> 15 15 2012 3.0027080 0.27239493
> 16 16 2013 1.9837563 0.55793673
> 17 17 2013 3.0492730 0.18798657
> 18 18 2014 1.2974632 0.44759619
> 19 19 2014 0.8241754 0.39551640
> 20 20 2014 2.2617631 0.56545281
>
> The code used are:
>
> meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")
>
>> meta1
>        HR             95%-CI %W(fixed) %W(random)
> 1   1.99 [ 1.7369;  2.2800]     42.92       5.99
> 2   4.07 [ 1.2455; 13.2997]      0.57       3.71
> 3   2.10 [ 1.1919;  3.7000]      2.48       5.28
> 4   4.70 [ 1.9378; 11.3998]      1.01       4.47
> 5   4.40 [ 1.8264; 10.5998]      1.03       4.49
> 6   2.50 [ 1.7857;  3.5000]      7.02       5.75
> 7   3.56 [ 1.8209;  6.9599]      1.77       5.03
> 8   2.45 [ 1.5120;  3.9700]      3.41       5.47
> 9   4.50 [ 2.7740;  7.2999]      3.39       5.47
> 10  1.57 [ 1.1204;  2.2000]      6.98       5.75
> 11  2.69 [ 1.5974;  4.5300]      2.92       5.38
> 12 16.60 [ 4.9921; 55.1988]      0.55       3.67
> 13  2.50 [ 1.6447;  3.8000]      4.53       5.60
> 14  1.66 [ 1.2357;  2.2300]      9.12       5.81
> 15 20.14 [11.8085; 34.3497]      2.79       5.36
> 16  7.27 [ 2.4357; 21.6996]      0.66       3.94
> 17 21.10 [14.5971; 30.4998]      5.85       5.69
> 18  3.66 [ 1.5223;  8.7999]      1.03       4.49
> 19  2.28 [ 1.0502;  4.9499]      1.32       4.76
> 20  9.60 [ 3.1693; 29.0794]      0.65       3.90
>
> Number of studies combined: k=20
>
>                           HR           95%-CI       z  p.value
> Fixed effect model   2.7148 [2.4833; 2.9679] 21.9628 < 0.0001
> Random effects model 3.9637 [2.7444; 5.7247]  7.3426 < 0.0001
>
> Quantifying heterogeneity:
> tau^2 = 0.5826; H = 3.56 [3.04; 4.16]; I^2 = 92.1% [89.2%; 94.2%]
>
> Test of heterogeneity:
>        Q d.f.  p.value
>   240.64   19 < 0.0001
>
> Details on meta-analytical method:
> - Inverse variance method
> - DerSimonian-Laird estimator for tau^2
>
>> cop1<-copas(meta1)
>
> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
> NaN was produced
>
>> plot (cop1)
>
> ERROR:
> object "is.relative.effect" not found
>
> -------------------------------------------------------
> Mario Petretta
> Associate Professor of Internal Medicine Department of Translational 
> Medical Sciences Naples University Federico II Italy
>
>
>
> ----
> 5x1000 AI GIOVANI RICERCATORI
> DELL'UNIVERSIT? DI NAPOLI
> Codice Fiscale: 00876220633
> www.unina.it/Vademecum5permille
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Michael
http://www.dewey.myzen.co.uk/home.html


From murdoch.duncan at gmail.com  Thu Aug 13 12:03:49 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Aug 2015 06:03:49 -0400
Subject: [R] Doing PDF OCR with R
In-Reply-To: <648411A2-3794-4FC4-8493-2D8911D7CC08@dcn.davis.CA.us>
References: <HKXPR02MB063267AA07F69CE7ACC5AC46F07D0@HKXPR02MB0632.apcprd02.prod.outlook.com>
	<648411A2-3794-4FC4-8493-2D8911D7CC08@dcn.davis.CA.us>
Message-ID: <55CC6B85.4020700@gmail.com>

On 13/08/2015 1:29 AM, Jeff Newmiller wrote:
> This code is using R like a command shell... there really is not much chance that R is the problem, and this is not a "tesseract" support forum, so this seems quite off-topic. 

I would have guessed the same, but the error message looks like an R
message.  But I can see anything very different in the 3rd step compared
to the first, so I don't know what would be going on.

The use of shQuote looks wrong:  Anshuk probably doesn't want to quote
the whole command expression, just parts of it that may cause problems.
 And the docs do recommend using system2() rather than shell().  But I
don't think either of those things should have caused that error.

Duncan Murdoch

> 
> On August 12, 2015 10:05:19 PM PDT, Anshuk Pal Chaudhuri <anshuk.p at motivitylabs.com> wrote:
>> Hi All,
>>
>> I have been trying to do OCR within R (reading PDF data which data as
>> scanned image). Have been reading about this @
>> http://electricarchaeology.ca/2014/07/15/doing-ocr-within-r/
>>
>> This a very good post.
>>
>> Effectively 3 steps:
>>
>> convert pdf to ppm (an image format)
>> convert ppm to tif ready for tesseract (using ImageMagick for convert)
>> convert tif to text file
>> The effective code for the above 3 steps as per the link post:
>>
>> lapply(myfiles, function(i){
>>  # convert pdf to ppm (an image format), just pages 1-10 of the PDF
>>  # but you can change that easily, just remove or edit the
>>  # -f 1 -l 10 bit in the line below
>> shell(shQuote(paste0("F:/xpdf/bin64/pdftoppm.exe ", i, " -f 1 -l 10 -r
>> 600 ocrbook")))
>>  # convert ppm to tif ready for tesseract
>> shell(shQuote(paste0("F:/ImageMagick-6.9.1-Q16/convert.exe *.ppm ", i,
>> ".tif")))
>>  # convert tif to text file
>> shell(shQuote(paste0("F:/Tesseract-OCR/tesseract.exe ", i, ".tif ", i,
>> " -l eng")))
>>  # delete tif file
>>  file.remove(paste0(i, ".tif" ))
>>  })
>> The first two steps are happening fine. (although taking good amount of
>> time, for 4 pages of a pdf, but will look into the scalability part
>> later, first trying if this works or not)
>>
>> While running this, the first two steps work fine.
>>
>> While runinng the 3rd step, i.e
>>
>> **shell(shQuote(paste0("F:/Tesseract-OCR/tesseract.exe ", i, ".tif ",
>> i, " -l eng")))**
>> I having this error:
>>
>> Error: evaluation nested too deeply: infinite recursion /
>> options(expressions=)?
>>
>> Or
>>
>> Tesseract is crashing.
>>
>> Any workaround or root cause analysis would be appreciated.
>>
>> Regards,
>> Anshuk Pal Chaudhuri
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petretta at unina.it  Thu Aug 13 12:38:55 2015
From: petretta at unina.it (Mario Petretta)
Date: Thu, 13 Aug 2015 12:38:55 +0200
Subject: [R] R:  help with metasens
Message-ID: <003201d0d5b4$41a36040$c4ea20c0$@unina.it>

Obviously metafor and not metaphor.

 

Sorry

 

Mario


	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Thu Aug 13 12:14:38 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 13 Aug 2015 03:14:38 -0700 (PDT)
Subject: [R] Finding top 25% observations in Dplyr
Message-ID: <1439460878216-4711061.post@n4.nabble.com>

Hi All, I am working on a dataset baseball where i am grouping based on one
var income in descending order. 
Now i need to find the top 25% of the observations from the income group for
which i used top_n (0.25) but it is not finding the desired. 

Can you please suggest.

Baseball%>%
  group_by(income)%>%  top_n(0.25,income)%>%
  arrange(desc(income))





--
View this message in context: http://r.789695.n4.nabble.com/Finding-top-25-observations-in-Dplyr-tp4711061.html
Sent from the R help mailing list archive at Nabble.com.


From tacsunday at yahoo.fr  Thu Aug 13 14:51:19 2015
From: tacsunday at yahoo.fr (Robert U)
Date: Thu, 13 Aug 2015 12:51:19 +0000 (UTC)
Subject: [R] Basic editing of XML file
Message-ID: <2134087124.4101855.1439470279356.JavaMail.yahoo@mail.yahoo.com>

Dear RUser,I?m tryingto operate some very slight editing to the values of an XML file. I looked abit everywhere and it appears that dealing with XML files is not that easy? besidemy XML files might be a bit weirdly structured. Anyway, let me give you an exampleof it :
Root(xmlfile)<BLABLA version="XXX">? <A1 X1="2" X2="0"X3="100">??? <A2 X1="133.708" X2="36.28558"/>???<A3 X1="0" X2="0" X3="0" X4="0"/>???<A4 mode="0"/>??? ?? ???? </ A1 ></ BLABLA >?I?d like to modify the value of say,X1 in A1 line, or X1 in A2 line. Unfortunately the structure of this datasetdoes not really look like the examples I?ve seen on the internet, where youhave something that look like that :?<A1> something to change </A1>?In my case as you noticed, thevalues I want to edit are inside de <>, which is pretty odd??Any tips? ?Regards
	[[alternative HTML version deleted]]


From web13site at yahoo.co.uk  Thu Aug 13 11:30:08 2015
From: web13site at yahoo.co.uk (Dean1)
Date: Thu, 13 Aug 2015 02:30:08 -0700 (PDT)
Subject: [R] Crosstabulation with a frequency variable
Message-ID: <1439458208284-4711058.post@n4.nabble.com>

Hi all,

I've had a few years experience with R, which is why this is so frustrating,
my problem seems so simple but I can't find a solution.

I have a data frame in the following form:

data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))

How do I create a crosstab with frequencies?
     0    1
0: 11  12
1: 13  14



--
View this message in context: http://r.789695.n4.nabble.com/Crosstabulation-with-a-frequency-variable-tp4711058.html
Sent from the R help mailing list archive at Nabble.com.


From jrkrideau at inbox.com  Thu Aug 13 15:38:27 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 13 Aug 2015 05:38:27 -0800
Subject: [R] Finding top 25% observations in Dplyr
In-Reply-To: <1439460878216-4711061.post@n4.nabble.com>
Message-ID: <3A169ACD12D.000001A6jrkrideau@inbox.com>

I don't know how to do it in plyr but 
xx  <-  seq(1:300)
nn  <- trunc( length(xx)/4)
yy  <-  xx[nn, ]

should come close.  Have a look at ?ceiling or ?floor as an alternative to trunc()

John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Thu, 13 Aug 2015 03:14:38 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] Finding top 25% observations in Dplyr
> 
> Hi All, I am working on a dataset baseball where i am grouping based on
> one
> var income in descending order.
> Now i need to find the top 25% of the observations from the income group
> for
> which i used top_n (0.25) but it is not finding the desired.
> 
> Can you please suggest.
> 
> Baseball%>%
>   group_by(income)%>%  top_n(0.25,income)%>%
>   arrange(desc(income))
> 
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Finding-top-25-observations-in-Dplyr-tp4711061.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From sarah.goslee at gmail.com  Thu Aug 13 15:39:34 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 13 Aug 2015 09:39:34 -0400
Subject: [R] Crosstabulation with a frequency variable
In-Reply-To: <1439458208284-4711058.post@n4.nabble.com>
References: <1439458208284-4711058.post@n4.nabble.com>
Message-ID: <CAM_vjukynQp8J4dHEERaxmoANZoVxqLsdRxd1fivrHb6+jsPKQ@mail.gmail.com>

Hi,

There are lots of ways to do it in base R, but a long time ago I got
frustrated and wrote a crosstab function that did exactly what I
wanted:

library(ecodist)
mydata <- data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
crosstab(var1, var2, freq, data=mydata)

   0  1
0 11 12
1 13 14

Sarah

On Thu, Aug 13, 2015 at 5:30 AM, Dean1 <web13site at yahoo.co.uk> wrote:
> Hi all,
>
> I've had a few years experience with R, which is why this is so frustrating,
> my problem seems so simple but I can't find a solution.
>
> I have a data frame in the following form:
>
> data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
>
> How do I create a crosstab with frequencies?
>      0    1
> 0: 11  12
> 1: 13  14
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jrkrideau at inbox.com  Thu Aug 13 16:06:55 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 13 Aug 2015 06:06:55 -0800
Subject: [R] How to obtain the unique communities when plotting VENNs?
In-Reply-To: <1439452677012-4711056.post@n4.nabble.com>
Message-ID: <3A5641AAEBF.000001F2jrkrideau@inbox.com>

Hi Krissey,

I don't have an answer for you but here are some hints on how to ask questions on R-help.
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html

In particular we probably need your actual code and some sample data.  Use dput() see ?dput or read about it in the above links.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: kristin.kaiser at web.de
> Sent: Thu, 13 Aug 2015 00:57:57 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] How to obtain the unique communities when plotting VENNs?
> 
> Hey there guys.
> 
> I am having a question about Venn diagrams.
> A colleague wrote a script based on the VennDiagram package a while ago,
> that I was able to adapt for my data. I wanted a Venn for the soil
> bacterial
> communities derived from forests of 4 different tree species.
> It worked fine for me, however my question is:
> 
> Is there a possibility to somehow obtain a list of the unique populations
> of
> each of the for categories?
> <http://r.789695.n4.nabble.com/file/n4711056/Venntrees.png>
> 
> That's what the Venn looks like. Now I'd like to now the 426 community
> members, that seem to be unique for beech forest, the 45 for pine, ect
> ect.
> I feel like this is a tough call because of all the intersecting that had
> to
> be done before. These are the Intersects:
> N12 = InterSect(AKL_beech,AKL_oak)#(1,2)
> N13 = InterSect(AKL_beech, AKL_pine)#(1,3)
> N14 = InterSect(AKL_beech, AKL_spruce)#(1,4)
> N23 = InterSect(AKL_oak,AKL_pine)#(2,3)
> N24 = InterSect(AKL_oak,AKL_spruce)#(2,4)
> N34 = InterSect(AKL_pine,AKL_spruce)#(3,4)
> length(N234) - length(N1234)
> N1234 = InterSect(N12,N34)
> N123 = InterSect(N12,AKL_pine)
> length(N123) - length(N1234)
> N124 = InterSect(N12,AKL_spruce)
> length(N124) - length(N1234)
> N134 = InterSect(N13,AKL_spruce)
> length(N134) - length(N1234)
> N234 = InterSect(N23,AKL_spruce)
> 
> Does anyone has an idea how to do it? I'm completely at loss by now,
> since I
> am also not a pro concerning R, or statistics.
> I'd be happy to hear what you come up with.
> Thanks so much in advance!
> 
> Best, Krissey
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/How-to-obtain-the-unique-communities-when-plotting-VENNs-tp4711056.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From btupper at bigelow.org  Thu Aug 13 16:08:35 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 13 Aug 2015 10:08:35 -0400
Subject: [R] Basic editing of XML file
In-Reply-To: <2134087124.4101855.1439470279356.JavaMail.yahoo@mail.yahoo.com>
References: <2134087124.4101855.1439470279356.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <11748CF1-F1F6-43D8-B809-CF03B35B0374@bigelow.org>

Hi,

Your email client is set to send in HTML format which has mangled your message.  Please set your client to send plain text to R-help.

You could use the XML package to modify the attributes of a given node.

> library(XML)

# make an reproducible example
> z <- newXMLNode("BLABLA",
+     attrs = c(version = "XXX"),
+     .children = list(
+         newXMLNode("A1", 
+             attrs = c(X1=2, X2="0", X3 = "100")),
+         newXMLNode("A2", 
+             attrs = c(X1=133.708, X2=36.28558)),
+         newXMLNode("A3",
+             attrs = c(X1=1, X2 = 2, X3 = 3, X4 = 4))
+         ))
> z
<BLABLA version="XXX">
  <A1 X1="2" X2="0" X3="100"/>
  <A2 X1="133.708" X2="36.28558"/>
  <A3 X1="1" X2="2" X3="3" X4="4"/>
</BLABLA> 

# XML child nodes can be access using like a list 
# z[['A1']] will extract the first node with that name
# then use the XML::xmlAttrs() function to get and set the attributes 
> a1_atts <- xmlAttrs(z[["A1"]])
> a1_atts
   X1    X2    X3 
  "2"   "0" "100" 
> a1_atts[['X3']] <- "boo"
> xmlAttrs(z[["A1"]]) <- a1_atts
> z
<BLABLA version="XXX">
  <A1 X1="2" X2="0" X3="boo"/>
  <A2 X1="133.708" X2="36.28558"/>
  <A3 X1="1" X2="2" X3="3" X4="4"/>
</BLABLA> 

Is that what you want to do?


Cheers,
Ben


On Aug 13, 2015, at 8:51 AM, Robert U <tacsunday at yahoo.fr> wrote:

> Dear RUser,I?m tryingto operate some very slight editing to the values of an XML file. I looked abit everywhere and it appears that dealing with XML files is not that easy? besidemy XML files might be a bit weirdly structured. Anyway, let me give you an exampleof it :
> Root(xmlfile)<BLABLA version="XXX">  <A1 X1="2" X2="0"X3="100">    <A2 X1="133.708" X2="36.28558"/>   <A3 X1="0" X2="0" X3="0" X4="0"/>   <A4 mode="0"/>    ?  ???  </ A1 ></ BLABLA > I?d like to modify the value of say,X1 in A1 line, or X1 in A2 line. Unfortunately the structure of this datasetdoes not really look like the examples I?ve seen on the internet, where youhave something that look like that : <A1> something to change </A1> In my case as you noticed, thevalues I want to edit are inside de <>, which is pretty odd? Any tips?  Regards
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From marc_schwartz at me.com  Thu Aug 13 16:15:33 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 13 Aug 2015 09:15:33 -0500
Subject: [R] Crosstabulation with a frequency variable
In-Reply-To: <CAM_vjukynQp8J4dHEERaxmoANZoVxqLsdRxd1fivrHb6+jsPKQ@mail.gmail.com>
References: <1439458208284-4711058.post@n4.nabble.com>
	<CAM_vjukynQp8J4dHEERaxmoANZoVxqLsdRxd1fivrHb6+jsPKQ@mail.gmail.com>
Message-ID: <1D8EC002-154C-48C1-BCD6-D91AD197CE7A@me.com>

Hi,

As Sarah noted, there are a variety of ways in R to accomplish this, such as:

DF <- data.frame(var1 = c(0, 0, 1, 1), var2 = c(0, 1, 0, 1), freq = c(11, 12, 13, 14))

> xtabs(freq ~ var1 + var2, data = DF)
    var2
var1  0  1
   0 11 12
   1 13 14

See ?xtabs 

Regards,

Marc Schwartz



> On Aug 13, 2015, at 8:39 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi,
> 
> There are lots of ways to do it in base R, but a long time ago I got
> frustrated and wrote a crosstab function that did exactly what I
> wanted:
> 
> library(ecodist)
> mydata <- data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
> crosstab(var1, var2, freq, data=mydata)
> 
>   0  1
> 0 11 12
> 1 13 14
> 
> Sarah
> 
> On Thu, Aug 13, 2015 at 5:30 AM, Dean1 <web13site at yahoo.co.uk> wrote:
>> Hi all,
>> 
>> I've had a few years experience with R, which is why this is so frustrating,
>> my problem seems so simple but I can't find a solution.
>> 
>> I have a data frame in the following form:
>> 
>> data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
>> 
>> How do I create a crosstab with frequencies?
>>     0    1
>> 0: 11  12
>> 1: 13  14
>> 
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org


From bgunter.4567 at gmail.com  Thu Aug 13 16:24:16 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 13 Aug 2015 07:24:16 -0700
Subject: [R] Crosstabulation with a frequency variable
In-Reply-To: <CAM_vjukynQp8J4dHEERaxmoANZoVxqLsdRxd1fivrHb6+jsPKQ@mail.gmail.com>
References: <1439458208284-4711058.post@n4.nabble.com>
	<CAM_vjukynQp8J4dHEERaxmoANZoVxqLsdRxd1fivrHb6+jsPKQ@mail.gmail.com>
Message-ID: <CAGxFJbR0SgeYMgFSGm6OOYxZRiUPR7Oj0LhWFRMmvm1nu1arng@mail.gmail.com>

Well, just using base R, ...

> with(mydata,tapply(freq,list(var1,var2),I))
   0  1
0 11 12
1 13 14


Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Aug 13, 2015 at 6:39 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Hi,
>
> There are lots of ways to do it in base R, but a long time ago I got
> frustrated and wrote a crosstab function that did exactly what I
> wanted:
>
> library(ecodist)
> mydata <- data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
> crosstab(var1, var2, freq, data=mydata)
>
>    0  1
> 0 11 12
> 1 13 14
>
> Sarah
>
> On Thu, Aug 13, 2015 at 5:30 AM, Dean1 <web13site at yahoo.co.uk> wrote:
>> Hi all,
>>
>> I've had a few years experience with R, which is why this is so frustrating,
>> my problem seems so simple but I can't find a solution.
>>
>> I have a data frame in the following form:
>>
>> data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
>>
>> How do I create a crosstab with frequencies?
>>      0    1
>> 0: 11  12
>> 1: 13  14
>>
>>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Thu Aug 13 16:35:19 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 13 Aug 2015 15:35:19 +0100
Subject: [R] R:  help with metasens
In-Reply-To: <002201d0d5aa$09042e90$1b0c8bb0$@unina.it>
References: <20150812141945.Horde.mMVJAOJFce5OwW_oJpmzlw8@webmail-sso.unina.it>
	<55CB7210.3030409@dewey.myzen.co.uk>
	<002201d0d5aa$09042e90$1b0c8bb0$@unina.it>
Message-ID: <55CCAB27.2010805@dewey.myzen.co.uk>

diagonal bacn is a typo, sorry for that. My brain meant to type diagonal 
band, ie going in this case from north west to south east but my fingers 
failed completely.

On 13/08/2015 10:25, Mario Petretta wrote:
> Many thanks for your suggestion.
>
> I will try a new database search and the hc metaphor function.
>
> Mario
>
> PS: what is diagonal bacn?
>
> -----Messaggio originale-----
> Da: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> Inviato: mercoled? 12 agosto 2015 18.19
> A: petretta at unina.it; r-help at r-project.org
> Oggetto: Re: [R] help with metasens
>
> Dear Mario
>
> I do not use metasens myself so cannot be of direct help but I have looked at your dataset and it does seem rather strange (as you perhaps know). You have two quite large studies with very large hazard ratios and if we ignore them all the rest of the studies fall on a diagonal bacn indicative of extreme small study bias.
>
> One thing you could consider is to use metafor and within it use the hc function which uses a different approach due to Henmi and Copas (the same Copas).
>
> On 12/08/2015 15:19, petretta at unina.it wrote:
>> Dear all,
>>
>> I use R 3.1.1 for Windows (x 64).
>>
>> I performed a meta-analysis of hazard ratio using the below reported
>> Dataset and metagen function from package meta.
>>
>> meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")
>>
>> Thereafter, I try to use the copas function from package metasens.
>>
>> cop1<-copas(meta1)
>>
>>
>> and I have these 3 warnings:
>>
>> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
>> NaN was produced
>> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
>> NaN was produced
>> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
>> NaN was produced
>>
>> If I try:
>> plot (cop1)
>>
>>    I have:
>> ERROR:
>> object "is.relative.effect" not found
>>
>> Any suggestion is welcome.
>>
>> The Dataset is:
>>
>>      id Year      lnHR       seHR
>> 1   1 2001 0.6881346 0.06940859
>> 2   2 2001 1.4036430 0.60414338
>> 3   3 2002 0.7419373 0.28897730
>> 4   4 2003 1.5475625 0.45206678
>> 5   5 2003 1.4816046 0.44859666
>> 6   6 2005 0.9162908 0.17166950
>> 7   7 2006 1.2697605 0.34205049
>> 8   8 2009 0.8960880 0.24626434
>> 9   9 2011 1.5040774 0.24683516
>> 10 10 2012 0.4510756 0.17213355
>> 11 11 2008 0.9895412 0.26590857
>> 12 12 2009 2.8094027 0.61304092
>> 13 13 2010 0.9162908 0.21362771
>> 14 14 2011 0.5068176 0.15060408
>> 15 15 2012 3.0027080 0.27239493
>> 16 16 2013 1.9837563 0.55793673
>> 17 17 2013 3.0492730 0.18798657
>> 18 18 2014 1.2974632 0.44759619
>> 19 19 2014 0.8241754 0.39551640
>> 20 20 2014 2.2617631 0.56545281
>>
>> The code used are:
>>
>> meta1<-metagen(Dataset$lnHR, Dataset$seHR, sm="HR")
>>
>>> meta1
>>         HR             95%-CI %W(fixed) %W(random)
>> 1   1.99 [ 1.7369;  2.2800]     42.92       5.99
>> 2   4.07 [ 1.2455; 13.2997]      0.57       3.71
>> 3   2.10 [ 1.1919;  3.7000]      2.48       5.28
>> 4   4.70 [ 1.9378; 11.3998]      1.01       4.47
>> 5   4.40 [ 1.8264; 10.5998]      1.03       4.49
>> 6   2.50 [ 1.7857;  3.5000]      7.02       5.75
>> 7   3.56 [ 1.8209;  6.9599]      1.77       5.03
>> 8   2.45 [ 1.5120;  3.9700]      3.41       5.47
>> 9   4.50 [ 2.7740;  7.2999]      3.39       5.47
>> 10  1.57 [ 1.1204;  2.2000]      6.98       5.75
>> 11  2.69 [ 1.5974;  4.5300]      2.92       5.38
>> 12 16.60 [ 4.9921; 55.1988]      0.55       3.67
>> 13  2.50 [ 1.6447;  3.8000]      4.53       5.60
>> 14  1.66 [ 1.2357;  2.2300]      9.12       5.81
>> 15 20.14 [11.8085; 34.3497]      2.79       5.36
>> 16  7.27 [ 2.4357; 21.6996]      0.66       3.94
>> 17 21.10 [14.5971; 30.4998]      5.85       5.69
>> 18  3.66 [ 1.5223;  8.7999]      1.03       4.49
>> 19  2.28 [ 1.0502;  4.9499]      1.32       4.76
>> 20  9.60 [ 3.1693; 29.0794]      0.65       3.90
>>
>> Number of studies combined: k=20
>>
>>                            HR           95%-CI       z  p.value
>> Fixed effect model   2.7148 [2.4833; 2.9679] 21.9628 < 0.0001
>> Random effects model 3.9637 [2.7444; 5.7247]  7.3426 < 0.0001
>>
>> Quantifying heterogeneity:
>> tau^2 = 0.5826; H = 3.56 [3.04; 4.16]; I^2 = 92.1% [89.2%; 94.2%]
>>
>> Test of heterogeneity:
>>         Q d.f.  p.value
>>    240.64   19 < 0.0001
>>
>> Details on meta-analytical method:
>> - Inverse variance method
>> - DerSimonian-Laird estimator for tau^2
>>
>>> cop1<-copas(meta1)
>>
>> Warning in sqrt(solve(junk2$hessian + 1e-08)[1, 1]) :
>> NaN was produced
>>
>>> plot (cop1)
>>
>> ERROR:
>> object "is.relative.effect" not found
>>
>> -------------------------------------------------------
>> Mario Petretta
>> Associate Professor of Internal Medicine Department of Translational
>> Medical Sciences Naples University Federico II Italy
>>
>>
>>
>> ----
>> 5x1000 AI GIOVANI RICERCATORI
>> DELL'UNIVERSIT? DI NAPOLI
>> Codice Fiscale: 00876220633
>> www.unina.it/Vademecum5permille
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From kittlein at mdp.edu.ar  Thu Aug 13 15:45:13 2015
From: kittlein at mdp.edu.ar (kittlein)
Date: Thu, 13 Aug 2015 06:45:13 -0700 (PDT)
Subject: [R] georeferencing image from scratch
Message-ID: <1439473513158-4711069.post@n4.nabble.com>

I want to change a MSS landsat image which has bad georeferencing. I have a
grid of points with correct georeferences and want to use them to reproject
the image to a correct reference system.

Is there some way to this with raster or other packages?

in idrisi I used to resample the image using a correspondence file (.cor)
with xold yold xnew ynew values. I wonder if there is something similar I
can do in R? 



--
View this message in context: http://r.789695.n4.nabble.com/georeferencing-image-from-scratch-tp4711069.html
Sent from the R help mailing list archive at Nabble.com.


From aurora.gonzalez at openmailbox.org  Thu Aug 13 16:13:32 2015
From: aurora.gonzalez at openmailbox.org (aurora.gonzalez at openmailbox.org)
Date: Thu, 13 Aug 2015 16:13:32 +0200
Subject: [R] lme4 package installation
Message-ID: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>

Hello

I've downloaded the tar.gz file of the package "lme4" and when I use the 
coomand:

install.packages("lme4_1.1-8.tar.gz", repos = NULL, type = "source")

appears an error that suspends the installation:


In file included from external.cpp:8:0:
predModule.h:12:23: fatal error: RcppEigen.h: No such file or directory
compilation terminated.
make: *** [external.o] Error 1
ERROR: compilation failed for package ?lme4?
* removing ?/home/aurora/R/x86_64-pc-linux-gnu-library/3.2/lme4?



Does anyone know how to fix it? Thank you very much!


My sessionInfo:


R version 3.2.1 (2015-06-18)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu precise (12.04.5 LTS)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base

loaded via a namespace (and not attached):
[1] tools_3.2.1


From kittlein at mdp.edu.ar  Thu Aug 13 13:15:13 2015
From: kittlein at mdp.edu.ar (Marcelo Kittlein)
Date: Thu, 13 Aug 2015 11:15:13 +0000
Subject: [R] georeferencing image from scratch
Message-ID: <55CC7C41.1090306@mdp.edu.ar>

Hi all

I want to change a MSS landsat image which has bad georeferencing. I 
have a grid of points with correct georeferences and want to use them to 
reproject the image to a correct reference system.

Is there some way to this with raster or other packages?

in idrisi I used to resample the image using a correspondence file 
(.cor) with xold yold xnew ynew values. I wonder if there is something 
similar I can do in R?

Thanks in advance

Marcelo Kittlein


From thierry.onkelinx at inbo.be  Thu Aug 13 17:09:21 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 13 Aug 2015 17:09:21 +0200
Subject: [R] lme4 package installation
In-Reply-To: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>
References: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>
Message-ID: <CAJuCY5yWc3uCVCkR1qwUgJUPuCrHi81848tEG1mjEhrzUwZrHw@mail.gmail.com>

Have you trying installing it directly from CRAN?

install.packages("lme4")

Do you have all dependencies installed? install.packages() from CRAN will
take care of that. You repos = NULL you have to install all dependencies
manually.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-08-13 16:13 GMT+02:00 <aurora.gonzalez at openmailbox.org>:

> Hello
>
> I've downloaded the tar.gz file of the package "lme4" and when I use the
> coomand:
>
> install.packages("lme4_1.1-8.tar.gz", repos = NULL, type = "source")
>
> appears an error that suspends the installation:
>
>
> In file included from external.cpp:8:0:
> predModule.h:12:23: fatal error: RcppEigen.h: No such file or directory
> compilation terminated.
> make: *** [external.o] Error 1
> ERROR: compilation failed for package ?lme4?
> * removing ?/home/aurora/R/x86_64-pc-linux-gnu-library/3.2/lme4?
>
>
>
> Does anyone know how to fix it? Thank you very much!
>
>
> My sessionInfo:
>
>
> R version 3.2.1 (2015-06-18)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu precise (12.04.5 LTS)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kristin.kaiser at web.de  Thu Aug 13 17:05:20 2015
From: kristin.kaiser at web.de (Krissey)
Date: Thu, 13 Aug 2015 08:05:20 -0700 (PDT)
Subject: [R] How to obtain the unique communities when plotting VENNs?
In-Reply-To: <3A5641AAEBF.000001F2jrkrideau@inbox.com>
References: <1439452677012-4711056.post@n4.nabble.com>
	<3A5641AAEBF.000001F2jrkrideau@inbox.com>
Message-ID: <1439478320854-4711081.post@n4.nabble.com>

Thanks a lot John - I will set up a new post and hopefully do better :)



--
View this message in context: http://r.789695.n4.nabble.com/How-to-obtain-the-unique-communities-when-plotting-VENNs-tp4711056p4711081.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Thu Aug 13 17:18:35 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 13 Aug 2015 17:18:35 +0200
Subject: [R] Crosstabulation with a frequency variable
In-Reply-To: <CAGxFJbR0SgeYMgFSGm6OOYxZRiUPR7Oj0LhWFRMmvm1nu1arng@mail.gmail.com>
References: <1439458208284-4711058.post@n4.nabble.com>
	<CAM_vjukynQp8J4dHEERaxmoANZoVxqLsdRxd1fivrHb6+jsPKQ@mail.gmail.com>
	<CAGxFJbR0SgeYMgFSGm6OOYxZRiUPR7Oj0LhWFRMmvm1nu1arng@mail.gmail.com>
Message-ID: <9DF50022-D615-41FE-B434-2A1DD5F8A74A@gmail.com>


> On 13 Aug 2015, at 16:24 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Well, just using base R, ...
> 
>> with(mydata,tapply(freq,list(var1,var2),I))
>   0  1
> 0 11 12
> 1 13 14

If you insist on avoiding the stats package...

However, I'd use sum() rather than I() to get an xtabs() workalike.

-pd

> 
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
> 
> 
> On Thu, Aug 13, 2015 at 6:39 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> Hi,
>> 
>> There are lots of ways to do it in base R, but a long time ago I got
>> frustrated and wrote a crosstab function that did exactly what I
>> wanted:
>> 
>> library(ecodist)
>> mydata <- data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
>> crosstab(var1, var2, freq, data=mydata)
>> 
>>   0  1
>> 0 11 12
>> 1 13 14
>> 
>> Sarah
>> 
>> On Thu, Aug 13, 2015 at 5:30 AM, Dean1 <web13site at yahoo.co.uk> wrote:
>>> Hi all,
>>> 
>>> I've had a few years experience with R, which is why this is so frustrating,
>>> my problem seems so simple but I can't find a solution.
>>> 
>>> I have a data frame in the following form:
>>> 
>>> data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
>>> 
>>> How do I create a crosstab with frequencies?
>>>     0    1
>>> 0: 11  12
>>> 1: 13  14
>>> 
>>> 
>> 
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter.4567 at gmail.com  Thu Aug 13 17:25:23 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 13 Aug 2015 08:25:23 -0700
Subject: [R] Crosstabulation with a frequency variable
In-Reply-To: <9DF50022-D615-41FE-B434-2A1DD5F8A74A@gmail.com>
References: <1439458208284-4711058.post@n4.nabble.com>
	<CAM_vjukynQp8J4dHEERaxmoANZoVxqLsdRxd1fivrHb6+jsPKQ@mail.gmail.com>
	<CAGxFJbR0SgeYMgFSGm6OOYxZRiUPR7Oj0LhWFRMmvm1nu1arng@mail.gmail.com>
	<9DF50022-D615-41FE-B434-2A1DD5F8A74A@gmail.com>
Message-ID: <CAGxFJbSuO=-LaTCFQrU5cL20JdYe4yn1tGiKYPC5KoLjdYf1+w@mail.gmail.com>

Yes and yes.

To be clear,

1. sum() is better.
2. xtabs is better (I just forgot about it and didn't bother to search).

Maybe the best answer is in fact,

??crosstabulation

which would have brought up xtabs(). So the moral is (to the OP),
learn how to search before posting.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Aug 13, 2015 at 8:18 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 13 Aug 2015, at 16:24 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Well, just using base R, ...
>>
>>> with(mydata,tapply(freq,list(var1,var2),I))
>>   0  1
>> 0 11 12
>> 1 13 14
>
> If you insist on avoiding the stats package...
>
> However, I'd use sum() rather than I() to get an xtabs() workalike.
>
> -pd
>
>>
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>>   -- Clifford Stoll
>>
>>
>> On Thu, Aug 13, 2015 at 6:39 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>> Hi,
>>>
>>> There are lots of ways to do it in base R, but a long time ago I got
>>> frustrated and wrote a crosstab function that did exactly what I
>>> wanted:
>>>
>>> library(ecodist)
>>> mydata <- data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
>>> crosstab(var1, var2, freq, data=mydata)
>>>
>>>   0  1
>>> 0 11 12
>>> 1 13 14
>>>
>>> Sarah
>>>
>>> On Thu, Aug 13, 2015 at 5:30 AM, Dean1 <web13site at yahoo.co.uk> wrote:
>>>> Hi all,
>>>>
>>>> I've had a few years experience with R, which is why this is so frustrating,
>>>> my problem seems so simple but I can't find a solution.
>>>>
>>>> I have a data frame in the following form:
>>>>
>>>> data.frame(var1=c(0,0,1,1),var2=c(0,1,0,1),freq=c(11,12,13,14))
>>>>
>>>> How do I create a crosstab with frequencies?
>>>>     0    1
>>>> 0: 11  12
>>>> 1: 13  14
>>>>
>>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>


From oluola2011 at yahoo.com  Thu Aug 13 19:20:35 2015
From: oluola2011 at yahoo.com (Olu Ola)
Date: Thu, 13 Aug 2015 10:20:35 -0700
Subject: [R] Error: Gradient function might be wrong - check it! OPTMX
Message-ID: <1439486435.87223.YahooMailBasic@web161602.mail.bf1.yahoo.com>

Hello,
I am trying to estimate a non-linear GMM in R using Optimx. However, when I do the start test to compare my analytical gradient with the numerical gradient, I get the following error message

Error: Gradient function might be wrong - check it!

Below are the print out of my analytical and numerical gradient. They are close to an extent and I want to use my analytical gradient. The first column is the analytical gradient while the second column is the numerical gradient

                     numgrad
 [1,]   -9862.118   -9862.103
 [2,]  -20855.001  -20854.985
 [3,]  -12277.764  -12277.767
 [4,]    3332.864    3332.865
 [5,]    3562.808    3562.804
 [6,]  -14971.913  -14971.915
 [7,]   27394.457   27394.451
 [8,]  -15634.531  -15634.532
 [9,]  -16893.399  -16893.402
[10,]   -1330.469   -1330.468
[11,]   16877.994   16877.991
[12,]   -9406.643   -9406.643
[13,]  -40451.881  -40451.881
[14,]  -48052.941  -48052.944
[15,]  -29997.114  -29997.116
[16,]   34546.011   34546.002
[17,]  -65540.191  -65540.200
[18,]  -24400.970  -24400.972
[19,]  -26655.760  -26655.760
[20,]  -59128.576  -59128.576
[21,]  -40026.926  -40026.931
[22,]  -34780.662  -34780.655
[23,] -119284.474 -119284.473
[24,]   22336.013   22336.025
[25,]  -40665.139  -40665.139
[26,]  -21596.959  -21596.959
[27,]  -33859.274  -33860.747
[28,]  -30536.938  -30539.807
[29,]  -95411.022  -95416.182
[30,]  -33016.450  -33018.690
[31,]  -90052.772  -90059.612
[32,]    8008.684    8009.342
[33,]  -45084.823  -45086.720
[34,]  -34071.584  -34074.802
[35,] -259960.860 -259990.135
[36,]  -69986.472  -69990.537
[37,]   24870.530   24874.012

The code for my optimization is as follows:


nlgmm = optimx(par=b0, fn=obj,gr=gra, method ="BFGS", itnmax=10000, control=list(follow.on = TRUE,usenumDeriv=FALSE,kkttol=10,starttests=TRUE, save.failures=TRUE, trace=0))

Is there a way to turn off the gradient check? this is because if I do not run the start test, it will still eventually display the error message. Any help to cross this bridge will be greatly appreciated.

Thank you


From lid.zigh at gmail.com  Thu Aug 13 19:31:42 2015
From: lid.zigh at gmail.com (Lida Zeighami)
Date: Thu, 13 Aug 2015 12:31:42 -0500
Subject: [R] add an idx column to the matrix
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39B02@SRVEXCHMBX.precheza.cz>
References: <CAMqbV1BHoUBaUhChMsOtoAsYqrzUu-WBiwTEv8SyUEQo321ZjQ@mail.gmail.com>
	<CAJuCY5w+jgXX_BupPMRpTY2zPXBv_zUZ_uW48jzej9ecdLM_Sw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39627@SRVEXCHMBX.precheza.cz>
	<CAMqbV1BzS0J5GG5Mfde65SawRHBe2TGHcMmUFHx=KUNLVXk6NA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39B02@SRVEXCHMBX.precheza.cz>
Message-ID: <CAMqbV1AajZBRzmqODBvEkp11Q4=Uc5X6=+SytXmfBCdCJCsQ2A@mail.gmail.com>

Hi dear all,

Yes, your solution all are correct! it was my mistake and I found it.

Thanks

On Thu, Aug 13, 2015 at 1:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> the error is not caused by missing 2
>
>
>
> > set.seed(333)
>
> > x<-sample(0:1, 12, rep=T)
>
> > dim(x)<-c(3,4)
>
> > x[2,2]<-NA
>
> > cbind(x, idx=(rowSums(x==2, na.rm=TRUE)>0)*1)
>
>               idx
>
> [1,] 0  1 1 0   0
>
> [2,] 0 NA 0 0   0
>
> [3,] 1  1 0 0   0
>
>
>
> As Sarah pointed out, you are the only one observing such error. Without
> more information ? at least  structure of your data
>
>
>
> see ?str
>
>
>
> but preferably part of your data causing error and a code you hardly get
> any sensible advice.
>
>
>
> Cheers
>
> Petr
>
> *From:* Lida Zeighami [mailto:lid.zigh at gmail.com]
> *Sent:* Wednesday, August 12, 2015 6:23 PM
> *To:* PIKAL Petr
>
> *Subject:* Re: [R] add an idx column to the matrix
>
>
>
> Dear Petr,
>
>
>
> I use your code in a loop function, but in some matrix there isn't any 2
> so I got the below error:
>
>
>
> Error in rowSums(lofGT_met == 2, na.rm = T) :
>   'x' must be an array of at least two dimensions
>
>
>
> would you please let me know how to correct it?
>
> Thanks,
>
> Lida
>
>
>
> On Tue, Aug 11, 2015 at 1:40 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Hi
>
> here is another approach.
>
> > cbind(mydata, idx=(rowSums(mydata==2, na.rm=T)>0)*1)
>    X125 X255 X558 X2366 X177 X255.1 idx
> aa    0    1    0    NA    0      0   0
> bb    1    1    0    NA    0      1   0
> cs    2    1    2     1    0      0   1
> de    0    1    0    NA    0      0   0
> gh    2    0    0     0    0      0   1
>
> It shall be faster if this is an issue.
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thierry
> > Onkelinx
> > Sent: Monday, August 10, 2015 10:29 PM
> > To: Lida Zeighami
> > Cc: r-help at r-project.org
> > Subject: Re: [R] add an idx column to the matrix
> >
> > Dear Lida,
> >
> > Here is a solution. Please don't post in HTML. And provide an easy to
> > use
> > example of the data. E.g. the output of dput(mydata)
> >
> > set.seed(1234)
> > mydata <- matrix(
> >   sample(
> >     c(0, 1, 2, NA),
> >     size = 30,
> >     replace = TRUE,
> >     prob = c(2, 1, 1, 1)
> >   ),
> >   ncol = 6
> > )
> >
> > idx <- apply(mydata, 1, function(x){any(x == 2)})
> > idx[is.na(idx)] <- FALSE
> > cbind(mydata, idx)
> >
> >
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> > and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not
> > ensure that a reasonable answer can be extracted from a given body of
> > data.
> > ~ John Tukey
> >
> > 2015-08-10 22:11 GMT+02:00 Lida Zeighami <lid.zigh at gmail.com>:
> >
> > > Hi there,
> > >
> > > I have a matrix contain 0,1,2, NA elements.
> > > I want to add a column to this matrix with name of "idx" . then for
> > each
> > > row, I should put 1 in this column (idx) if there is at least one 2
> > in that
> > > row otherwise I should put 0 in this column!
> > >
> > > for example  mydata:
> > >
> > >        125   255   558   2366   177    255
> > > aa    0        1       0         NA    0         0
> > > bb    1        1       0         NA    0         1
> > > cs     2        1       2         1       0         0
> > > de    0        1       0         NA    0         0
> > > gh    2       0       0         0        0         0
> > >
> > >
> > > my output should be:
> > >
> > >
> > >        125   255   558   2366   177    255    idx
> > > aa    0        1       0         NA    0         0      0
> > > bb    1        1       0         NA    0         1      0
> > > cs     2        1       2         1       0         0     1
> > > de    0        1       0         NA    0         0      0
> > > gh    2       0       0        2        0         2       1
> > >
> > > Thank you for your help.
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Thu Aug 13 19:42:22 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Thu, 13 Aug 2015 13:42:22 -0400
Subject: [R] Error: Gradient function might be wrong - check it! OPTMX
In-Reply-To: <1439486435.87223.YahooMailBasic@web161602.mail.bf1.yahoo.com>
References: <1439486435.87223.YahooMailBasic@web161602.mail.bf1.yahoo.com>
Message-ID: <55CCD6FE.1080106@gmail.com>

There are tolerances in the checks, and sometimes scaling of the problem
leads to false positives on the checks.

Try control = list(starttest=FALSE, etc.) to suppress the test.

JN

On 15-08-13 01:20 PM, Olu Ola via R-help wrote:
> Hello,
> I am trying to estimate a non-linear GMM in R using Optimx. However, when I do the start test to compare my analytical gradient with the numerical gradient, I get the following error message
> 
> Error: Gradient function might be wrong - check it!
> 
> Below are the print out of my analytical and numerical gradient. They are close to an extent and I want to use my analytical gradient. The first column is the analytical gradient while the second column is the numerical gradient
> 
>                      numgrad
>  [1,]   -9862.118   -9862.103
>  [2,]  -20855.001  -20854.985
>  [3,]  -12277.764  -12277.767
>  [4,]    3332.864    3332.865
>  [5,]    3562.808    3562.804
>  [6,]  -14971.913  -14971.915
>  [7,]   27394.457   27394.451
>  [8,]  -15634.531  -15634.532
>  [9,]  -16893.399  -16893.402
> [10,]   -1330.469   -1330.468
> [11,]   16877.994   16877.991
> [12,]   -9406.643   -9406.643
> [13,]  -40451.881  -40451.881
> [14,]  -48052.941  -48052.944
> [15,]  -29997.114  -29997.116
> [16,]   34546.011   34546.002
> [17,]  -65540.191  -65540.200
> [18,]  -24400.970  -24400.972
> [19,]  -26655.760  -26655.760
> [20,]  -59128.576  -59128.576
> [21,]  -40026.926  -40026.931
> [22,]  -34780.662  -34780.655
> [23,] -119284.474 -119284.473
> [24,]   22336.013   22336.025
> [25,]  -40665.139  -40665.139
> [26,]  -21596.959  -21596.959
> [27,]  -33859.274  -33860.747
> [28,]  -30536.938  -30539.807
> [29,]  -95411.022  -95416.182
> [30,]  -33016.450  -33018.690
> [31,]  -90052.772  -90059.612
> [32,]    8008.684    8009.342
> [33,]  -45084.823  -45086.720
> [34,]  -34071.584  -34074.802
> [35,] -259960.860 -259990.135
> [36,]  -69986.472  -69990.537
> [37,]   24870.530   24874.012
> 
> The code for my optimization is as follows:
> 
> 
> nlgmm = optimx(par=b0, fn=obj,gr=gra, method ="BFGS", itnmax=10000, control=list(follow.on = TRUE,usenumDeriv=FALSE,kkttol=10,starttests=TRUE, save.failures=TRUE, trace=0))
> 
> Is there a way to turn off the gradient check? this is because if I do not run the start test, it will still eventually display the error message. Any help to cross this bridge will be greatly appreciated.
> 
> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Thu Aug 13 21:42:00 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 13 Aug 2015 19:42:00 +0000
Subject: [R] String Matching
In-Reply-To: <5fabd36a-ed1d-4e66-a77f-05e24bc9b0e6@me.com>
References: <5fabd36a-ed1d-4e66-a77f-05e24bc9b0e6@me.com>
Message-ID: <D1F24055.1351BB%macqueen1@llnl.gov>

I haven't tested this, but what about:


df <- data.frame(mtch=c(matchString, string1, string2))

grep(searchString, df$mtch, ignore.case=FALSE)

Depending on what your next step is, you might prefer grepl.


Sometimes using fixed=TRUE in grep() helps.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/12/15, 8:51 AM, "R-help on behalf of Kevin Kowitski"
<r-help-bounces at r-project.org on behalf of k.kowitski at icloud.com> wrote:

>>df<-as.data.frame(c(matchString, string1, string2))
>>df
>                                                         c(matchString,
>string1, string2)
>1 09:11:57.259 - Assay File Processing Thread - INFO -
>SolenoidCycleMessage: Addr = 0x03
>2                 
>23:12:43.22 - Test
>3                 
>           test
>>grep(searchString, df, ignore.case=FALSE)
>i


From mauricioromerolondono at gmail.com  Thu Aug 13 20:55:36 2015
From: mauricioromerolondono at gmail.com (Mauricio Romero)
Date: Thu, 13 Aug 2015 14:55:36 -0400
Subject: [R] stringr package question
Message-ID: <CAPjE+LTd2rqUtHQBwJdufK9AMqNv=_mjLEdMvwpfAnR4G5TLkQ@mail.gmail.com>

Hi,

I'm running R 3.2.1 and im having an unexpected problem... when I run the
follwing code it returns an error

library(stringr)
str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs +ellps=WGS84
+towgs84=0,0,0", "+proj=[a-zA-Z0-9]*")

But I can't find whats wrong with my code.

Thanks

Mauricio

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Aug 13 22:33:12 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 13 Aug 2015 16:33:12 -0400
Subject: [R] stringr package question
In-Reply-To: <CAPjE+LTd2rqUtHQBwJdufK9AMqNv=_mjLEdMvwpfAnR4G5TLkQ@mail.gmail.com>
References: <CAPjE+LTd2rqUtHQBwJdufK9AMqNv=_mjLEdMvwpfAnR4G5TLkQ@mail.gmail.com>
Message-ID: <CAM_vju=CupnFtJMnEMUyFQj5pYDvHmfR9h1RJJz6nY501wxabQ@mail.gmail.com>

Hi,

The + is a special character in regular expressions. If you want to
match a literal + you need to escape it:

str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs
+ellps=WGS84 +towgs84=0,0,0", "\\+proj=[a-zA-Z0-9]*")

Sarah


On Thu, Aug 13, 2015 at 2:55 PM, Mauricio Romero
<mauricioromerolondono at gmail.com> wrote:
> Hi,
>
> I'm running R 3.2.1 and im having an unexpected problem... when I run the
> follwing code it returns an error
>
> library(stringr)
> str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs +ellps=WGS84
> +towgs84=0,0,0", "+proj=[a-zA-Z0-9]*")
>
> But I can't find whats wrong with my code.
>
> Thanks
>
> Mauricio
>


From mauricioromerolondono at gmail.com  Thu Aug 13 22:34:16 2015
From: mauricioromerolondono at gmail.com (Mauricio Romero)
Date: Thu, 13 Aug 2015 16:34:16 -0400
Subject: [R] stringr package question
In-Reply-To: <CAM_vju=CupnFtJMnEMUyFQj5pYDvHmfR9h1RJJz6nY501wxabQ@mail.gmail.com>
References: <CAPjE+LTd2rqUtHQBwJdufK9AMqNv=_mjLEdMvwpfAnR4G5TLkQ@mail.gmail.com>
	<CAM_vju=CupnFtJMnEMUyFQj5pYDvHmfR9h1RJJz6nY501wxabQ@mail.gmail.com>
Message-ID: <CAPjE+LR_UtiXHonFdU2R6opTRRzcRNn7p-aEMU-MjM5aQvWSbQ@mail.gmail.com>

thanks.... that makes sense... in the previous version of R it worked for
some reason.

On Thu, Aug 13, 2015 at 4:33 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi,
>
> The + is a special character in regular expressions. If you want to
> match a literal + you need to escape it:
>
> str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs
> +ellps=WGS84 +towgs84=0,0,0", "\\+proj=[a-zA-Z0-9]*")
>
> Sarah
>
>
> On Thu, Aug 13, 2015 at 2:55 PM, Mauricio Romero
> <mauricioromerolondono at gmail.com> wrote:
> > Hi,
> >
> > I'm running R 3.2.1 and im having an unexpected problem... when I run the
> > follwing code it returns an error
> >
> > library(stringr)
> > str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs
> +ellps=WGS84
> > +towgs84=0,0,0", "+proj=[a-zA-Z0-9]*")
> >
> > But I can't find whats wrong with my code.
> >
> > Thanks
> >
> > Mauricio
> >
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Aug 13 22:39:21 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 13 Aug 2015 13:39:21 -0700
Subject: [R] stringr package question
In-Reply-To: <CAPjE+LTd2rqUtHQBwJdufK9AMqNv=_mjLEdMvwpfAnR4G5TLkQ@mail.gmail.com>
References: <CAPjE+LTd2rqUtHQBwJdufK9AMqNv=_mjLEdMvwpfAnR4G5TLkQ@mail.gmail.com>
Message-ID: <39D0BBE7-6F3C-4259-8D52-15FDA86A17E6@dcn.davis.CA.us>

"+" is a special character in regular expressions that requires a preceding pattern to apply to. See ?base::regex.
You need to escape the special with a backslash to remove the special behavior, and escape the backslash so the R parser will be happy.

str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0", "\\+proj=[a-zA-Z0-9]*")

Please read and follow the Posting Guide, including sending your emails using plain text instead of HTML.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 13, 2015 11:55:36 AM PDT, Mauricio Romero <mauricioromerolondono at gmail.com> wrote:
>Hi,
>
>I'm running R 3.2.1 and im having an unexpected problem... when I run
>the
>follwing code it returns an error
>
>library(stringr)
>str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs
>+ellps=WGS84
>+towgs84=0,0,0", "+proj=[a-zA-Z0-9]*")
>
>But I can't find whats wrong with my code.
>
>Thanks
>
>Mauricio
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Aug 13 23:22:55 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 13 Aug 2015 14:22:55 -0700 (PDT)
Subject: [R] stringr package question
In-Reply-To: <CAPjE+LR_UtiXHonFdU2R6opTRRzcRNn7p-aEMU-MjM5aQvWSbQ@mail.gmail.com>
References: <CAPjE+LTd2rqUtHQBwJdufK9AMqNv=_mjLEdMvwpfAnR4G5TLkQ@mail.gmail.com>
	<CAM_vju=CupnFtJMnEMUyFQj5pYDvHmfR9h1RJJz6nY501wxabQ@mail.gmail.com>
	<CAPjE+LR_UtiXHonFdU2R6opTRRzcRNn7p-aEMU-MjM5aQvWSbQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1508131419050.26849@pedal.dcn.davis.ca.us>

Seems more likely to be related to changes in the options stringr uses 
when it invokes the regex code? See the different response coming from 
base R when told to use a different regex engine:

> grep( "+proj", "syz+project" )
[1] 1
> grep( "+proj", "syz+project", perl=TRUE )
Error in grep("+proj", "syz+project", perl = TRUE) :
   invalid regular expression '+proj'
In addition: Warning message:
In grep("+proj", "syz+project", perl = TRUE) :
   PCRE pattern compilation error
         'nothing to repeat'
         at '+proj'

On Thu, 13 Aug 2015, Mauricio Romero wrote:

> thanks.... that makes sense... in the previous version of R it worked for
> some reason.
>
> On Thu, Aug 13, 2015 at 4:33 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> Hi,
>>
>> The + is a special character in regular expressions. If you want to
>> match a literal + you need to escape it:
>>
>> str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs
>> +ellps=WGS84 +towgs84=0,0,0", "\\+proj=[a-zA-Z0-9]*")
>>
>> Sarah
>>
>>
>> On Thu, Aug 13, 2015 at 2:55 PM, Mauricio Romero
>> <mauricioromerolondono at gmail.com> wrote:
>>> Hi,
>>>
>>> I'm running R 3.2.1 and im having an unexpected problem... when I run the
>>> follwing code it returns an error
>>>
>>> library(stringr)
>>> str_extract("+proj=utm +zone=19 +datum=WGS84 +units=m +no_defs
>> +ellps=WGS84
>>> +towgs84=0,0,0", "+proj=[a-zA-Z0-9]*")
>>>
>>> But I can't find whats wrong with my code.
>>>
>>> Thanks
>>>
>>> Mauricio
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From pingpong.tktan at gmail.com  Thu Aug 13 22:52:35 2015
From: pingpong.tktan at gmail.com (Teck Kiang Tan)
Date: Fri, 14 Aug 2015 04:52:35 +0800
Subject: [R] lme4 package installation
In-Reply-To: <CAJuCY5yWc3uCVCkR1qwUgJUPuCrHi81848tEG1mjEhrzUwZrHw@mail.gmail.com>
References: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>
	<CAJuCY5yWc3uCVCkR1qwUgJUPuCrHi81848tEG1mjEhrzUwZrHw@mail.gmail.com>
Message-ID: <CAGetN7VCYb-OuQOjSGugdPxNrqhx68KrLA0OBKPTZQVbG9GMVA@mail.gmail.com>

Hi all

I have problem in installation lme4 and have tried over the past 2 days. It
failed to install from the various countries.

> install.packages("lme4")
Warning: unable to access index for repository
http://cran.stat.nus.edu.sg/src/contrib
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/src/contrib
Warning: unable to access index for repository
http://cran.stat.nus.edu.sg/bin/windows/contrib/3.2

Warning message:
package ?lme4? is not available (for R version 3.2.1)

Teck Kiang


On Thu, Aug 13, 2015 at 11:09 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Have you trying installing it directly from CRAN?
>
> install.packages("lme4")
>
> Do you have all dependencies installed? install.packages() from CRAN will
> take care of that. You repos = NULL you have to install all dependencies
> manually.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-08-13 16:13 GMT+02:00 <aurora.gonzalez at openmailbox.org>:
>
> > Hello
> >
> > I've downloaded the tar.gz file of the package "lme4" and when I use the
> > coomand:
> >
> > install.packages("lme4_1.1-8.tar.gz", repos = NULL, type = "source")
> >
> > appears an error that suspends the installation:
> >
> >
> > In file included from external.cpp:8:0:
> > predModule.h:12:23: fatal error: RcppEigen.h: No such file or directory
> > compilation terminated.
> > make: *** [external.o] Error 1
> > ERROR: compilation failed for package ?lme4?
> > * removing ?/home/aurora/R/x86_64-pc-linux-gnu-library/3.2/lme4?
> >
> >
> >
> > Does anyone know how to fix it? Thank you very much!
> >
> >
> > My sessionInfo:
> >
> >
> > R version 3.2.1 (2015-06-18)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> > Running under: Ubuntu precise (12.04.5 LTS)
> >
> > locale:
> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods
> > [7] base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.1
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From em8g14 at soton.ac.uk  Fri Aug 14 01:36:47 2015
From: em8g14 at soton.ac.uk (mcknight e. (em8g14))
Date: Thu, 13 Aug 2015 23:36:47 +0000
Subject: [R] Multi-line forestplots, how to in R
Message-ID: <DB5PR04MB08728012256D85A40A8D9049DD7D0@DB5PR04MB0872.eurprd04.prod.outlook.com>

Hello,


I am working on ecological data covering a meta-analysis on invasive species traits.


I am not very skilled in R and would love if someone could assist me in my production of multi-line forest plots.

The data I have is: random effects mixed model and is further divided into subsets, I have used metafor package and here is a breakdown of my code =

#this is my main data calculation into effect sizes

MA <- escalc (measure="SMD", m1i=Invasive..mean, sd1i=sd.invasive, n1i=N.invasive, m2i=Control.mean, sd2i=sd.control, n2i=N.control, data=dataset)

res.MA <- rma(yi,vi,data=MA,method="REML");res.MA  #random-effects models ; "HS" Viechtbauer (2005)


#separating data
lab <- subset (x=MA, Type.of.ex=="Lab")
field <- subset (x=MA, Type.of.ex=="Field")

res.MAlab <- rma(yi,vi,data=lab,method="REML");res.MAlab  #random-effects models ; "HS" Viechtbauer (2005)
res.MAfield <- rma(yi,vi,data=field,method="REML");res.MAfield  #random-effects models ; "HS" Viechtbauer (2005)

res.traitlab <- rma(yi,vi,mods= ~ factor(Trait)-1,data=lab);res.traitlab #model for traits

res.traitfield <- rma(yi,vi,mods= ~ factor(Trait)-1,data=field);res.traitfield

#model for each lab traits

res.labct <- rma(yi,vi,subset=Trait=="Consumption",data=lab);res.labct
res.labec <- rma(yi,vi,subset=Trait=="Exploitative competition",data=lab);res.labec
res.labgr <- rma(yi,vi,subset=Trait=="Growth",data=lab);res.labgr
res.labic <- rma(yi,vi,subset=Trait=="Interference competition",data=lab);res.labic
res.labpa <- rma(yi,vi,subset=Trait=="Predator avoidance",data=lab);res.labpa
res.labpe <- rma(yi,vi,subset=Trait=="Predator escape",data=lab);res.labpe

#model for each field traits

res.fieldct <- rma(yi,vi,subset=Trait=="Consumption",data=field);res.labct
res.fieldec <- rma(yi,vi,subset=Trait=="Exploitative competition",data=field);res.labec
res.fieldgr <- rma(yi,vi,subset=Trait=="Growth",data=field);res.labgr
res.fieldic <- rma(yi,vi,subset=Trait=="Interference competition",data=field);res.labic
res.fieldpa <- rma(yi,vi,subset=Trait=="Predator avoidance",data=field);res.labpa
res.fieldpe <- rma(yi,vi,subset=Trait=="Predator escape",data=field);res.labpe

#producing a graph for lab data

estimateslab <- c(coef(res.labct), coef(res.labec), coef(res.labgr), coef(res.labic), coef(res.labpa),coef(res.labpe))
varianceslab <- c(vcov(res.labct), vcov(res.labec), vcov(res.labgr), vcov(res.labic), vcov(res.labpa),vcov(res.labpe))
labelslab <- c("Consumption (109)","Exploitative competition (21)","Growth (33)","Interference competition (31)","Predator avoidance (4)","Predator escape (61)")
forest(estimateslab, varianceslab, slab=labelslab, digit=0, annotate=F, xlab="Mean effect size",ylim=c(0,11))

#producing a graph for field data

estimatesfield <- c(coef(res.fieldct),coef(res.fieldec), coef(res.fieldgr), coef(res.fieldic),coef(res.fieldpa),coef(res.fieldpe))
variancesfield <- c(vcov(res.fieldct),vcov(res.fieldec), vcov(res.fieldgr), vcov(res.fieldic), vcov(res.fieldpa),   vcov(res.fieldpe))
labelsfield <- c("Consumption (7)","Exploitative competition (19)","Growth (2)","Interference competition (34)","Predator avoidance (2)","Predator escape (15)")
forest(estimatesfield, variancesfield, slab=labelsfield,digit=0,annotate=F,xlab="Mean effect size",ylim=c(0,11)) # "psize=1" size of mean box on forest plot
addpoly(res.MAfield, row=0.2, cex=1, atransf=F, mlab="RE Model Field Studies (79)",annotate=F)


OK, so sorry for code overload... I hope you can understand what i have done.

What i need it to produce one graph with both data sets Lab and field showing effect sizes for each of the mentioned traits. Im not super up to scratch on R and some of the current code was shared through a colleague, however this person isnt great at plots.


Please please can someone help me. Im currently wasting heaps of my time and getting no where.

Sincerely grateful

Ella

	[[alternative HTML version deleted]]


From em8g14 at soton.ac.uk  Fri Aug 14 01:39:33 2015
From: em8g14 at soton.ac.uk (mcknight e. (em8g14))
Date: Thu, 13 Aug 2015 23:39:33 +0000
Subject: [R] Need help with Multi-line forestplots in R
In-Reply-To: <DB5PR04MB08728012256D85A40A8D9049DD7D0@DB5PR04MB0872.eurprd04.prod.outlook.com>
References: <DB5PR04MB08728012256D85A40A8D9049DD7D0@DB5PR04MB0872.eurprd04.prod.outlook.com>
Message-ID: <DB5PR04MB08729A97F2D964C3E0085D37DD7D0@DB5PR04MB0872.eurprd04.prod.outlook.com>

________________________________
 Hello,


I am working on ecological data covering a meta-analysis on invasive species traits.


I am not very skilled in R and would love if someone could assist me in my production of multi-line forest plots.

The data I have is: random effects mixed model and is further divided into subsets, I have used metafor package and here is a breakdown of my code =

#this is my main data calculation into effect sizes

MA <- escalc (measure="SMD", m1i=Invasive..mean, sd1i=sd.invasive, n1i=N.invasive, m2i=Control.mean, sd2i=sd.control, n2i=N.control, data=dataset)

res.MA <- rma(yi,vi,data=MA,method="REML");res.MA  #random-effects models ; "HS" Viechtbauer (2005)


#separating data
lab <- subset (x=MA, Type.of.ex=="Lab")
field <- subset (x=MA, Type.of.ex=="Field")

res.MAlab <- rma(yi,vi,data=lab,method="REML");res.MAlab  #random-effects models ; "HS" Viechtbauer (2005)
res.MAfield <- rma(yi,vi,data=field,method="REML");res.MAfield  #random-effects models ; "HS" Viechtbauer (2005)

res.traitlab <- rma(yi,vi,mods= ~ factor(Trait)-1,data=lab);res.traitlab #model for traits

res.traitfield <- rma(yi,vi,mods= ~ factor(Trait)-1,data=field);res.traitfield

#model for each lab traits

res.labct <- rma(yi,vi,subset=Trait=="Consumption",data=lab);res.labct
res.labec <- rma(yi,vi,subset=Trait=="Exploitative competition",data=lab);res.labec
res.labgr <- rma(yi,vi,subset=Trait=="Growth",data=lab);res.labgr
res.labic <- rma(yi,vi,subset=Trait=="Interference competition",data=lab);res.labic
res.labpa <- rma(yi,vi,subset=Trait=="Predator avoidance",data=lab);res.labpa
res.labpe <- rma(yi,vi,subset=Trait=="Predator escape",data=lab);res.labpe

#model for each field traits

res.fieldct <- rma(yi,vi,subset=Trait=="Consumption",data=field);res.labct
res.fieldec <- rma(yi,vi,subset=Trait=="Exploitative competition",data=field);res.labec
res.fieldgr <- rma(yi,vi,subset=Trait=="Growth",data=field);res.labgr
res.fieldic <- rma(yi,vi,subset=Trait=="Interference competition",data=field);res.labic
res.fieldpa <- rma(yi,vi,subset=Trait=="Predator avoidance",data=field);res.labpa
res.fieldpe <- rma(yi,vi,subset=Trait=="Predator escape",data=field);res.labpe

#producing a graph for lab data

estimateslab <- c(coef(res.labct), coef(res.labec), coef(res.labgr), coef(res.labic), coef(res.labpa),coef(res.labpe))
varianceslab <- c(vcov(res.labct), vcov(res.labec), vcov(res.labgr), vcov(res.labic), vcov(res.labpa),vcov(res.labpe))
labelslab <- c("Consumption (109)","Exploitative competition (21)","Growth (33)","Interference competition (31)","Predator avoidance (4)","Predator escape (61)")
forest(estimateslab, varianceslab, slab=labelslab, digit=0, annotate=F, xlab="Mean effect size",ylim=c(0,11))

#producing a graph for field data

estimatesfield <- c(coef(res.fieldct),coef(res.fieldec), coef(res.fieldgr), coef(res.fieldic),coef(res.fieldpa),coef(res.fieldpe))
variancesfield <- c(vcov(res.fieldct),vcov(res.fieldec), vcov(res.fieldgr), vcov(res.fieldic), vcov(res.fieldpa),   vcov(res.fieldpe))
labelsfield <- c("Consumption (7)","Exploitative competition (19)","Growth (2)","Interference competition (34)","Predator avoidance (2)","Predator escape (15)")
forest(estimatesfield, variancesfield, slab=labelsfield,digit=0,annotate=F,xlab="Mean effect size",ylim=c(0,11)) # "psize=1" size of mean box on forest plot
addpoly(res.MAfield, row=0.2, cex=1, atransf=F, mlab="RE Model Field Studies (79)",annotate=F)


OK, so sorry for code overload... I hope you can understand what i have done.

What i need it to produce one graph with both data sets Lab and field showing effect sizes for each of the mentioned traits. Im not super up to scratch on R and some of the current code was shared through a colleague, however this person isnt great at plots.


Please please can someone help me. Im currently wasting heaps of my time and getting no where.

Sincerely grateful

Ella

	[[alternative HTML version deleted]]


From jia.t.shen at gmail.com  Thu Aug 13 22:51:08 2015
From: jia.t.shen at gmail.com (Jia Shen)
Date: Thu, 13 Aug 2015 16:51:08 -0400
Subject: [R] having error of downloading multiple files from password
 protected ftp in R
Message-ID: <CAEXZgLcNJKbS3SjWZ9tORkmxfm8ZEdZppaPjpnqEvVAfrdFV7w@mail.gmail.com>

Hi all,

I'm trying to download a bunch of files from a credential needed ftp
address using R.* Below is my code:*
==========================
library(RCurl)
url <- "ftp://xxx.com"
userpwd <- "user:pwd"
filenames <- getURL(url, userpwd = userpwd, ftp.use.epsv =
FALSE,dirlistonly = TRUE)
fn <- unlist(strsplit(filenames, "\r\n"))
destdir <- "C:\\xxx\\destfolder"

lapply(fn, function(x) download.file(url=paste0(url,"/", x),
destfile=paste0(destdir,"/", x)),method="curl")


*The error message i got is below: *

trying URL 'ftp://FTP.weatherbank.com/CYTZ-FULL.XLSB'

 Error in download.file(url = paste0(url, "/", x), destfile =
paste0(destdir,  :
  cannot open URL 'ftp://xxx.com' In addition: Warning message:
In download.file(url = paste0(url, "/", x), destfile = paste0(destdir,  :
  InternetOpenUrl failed: 'The login request was denied


============================

Can anyone help? have been working on this issue for a couple of hours.

Thanks!

Tracy

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Fri Aug 14 03:39:27 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Fri, 14 Aug 2015 01:39:27 +0000 (GMT)
Subject: [R] Parallel Processing
Message-ID: <456cb3e0-30a3-4d84-8cc4-4027a94491c6@me.com>

Helllo All,

Need some help understanding parallel processing. ?I set-up DoParallel and worked perfectly. ?I tried to set-up using parallel package following the book Parallel R but I get the following error:
Error in checkForRemoteErrors(val) :?
? 4 nodes produced errors; first error: 'what' must be a character string or a function?

I have read some posts on the internet suggesting the issue may be related to S4 class and I have tried parse() to no avail. ?I have read Snow and Parallel documentation but I am not getting the issue.

Glenn ?

library(parallel)
library(foreach)
library(doParallel)

From Parallel R and Internet set up the following
============ DoParallel 4 seconds (perfect) took about 10 mins to set-up ==============
ptm <- proc.time()
Cluster <- makeCluster(detectCores())
registerDoParallel(Cluster)
clusterSetRNGStream(cl = Cluster, set.seed(100))
OAS <- foreach(i = 1:4, .packages = c("BondLab"), .combine = cbind) %dopar%?
? Mortgage.OAS(bond.id = "bondlabMBS4", trade.date = "01-10-2013", settlement.date = "01-13-2013",
? original.bal = 100000, price = 105.75, sigma = .23/sqrt(240), paths = 50)@OAS
mean(OAS)
proc.time() - ptm
hist(OAS * 100, breaks = 20)
stopCluster(Cluster)

============== followed the book example fails with the following message:
Error in checkForRemoteErrors(val) :?
? 4 nodes produced errors; first error: 'what' must be a character string or a function ============

ptm <- proc.time()
RNGkind("L'Ecuyer-CMRG")
cl <- makeCluster(detectCores())
clusterSetRNGStream(cl, set.seed(100))
clusterEvalQ(cl, library(BondLab))
OAS <- clusterApply(cl = cl, 1:4, Mortgage.OAS(bond.id = "bondlabMBS4",?
? ? ? ? ? trade.date = "01-10-2013", settlement.date = "01-13-2013",
? ? ? ? ? original.bal = 100000, price = 105.75, sigma = .23/sqrt(240), paths = 50)@OAS)?
proc.time() - ptm
mean(OAS)
hist(OAS * 100, breaks = 20)
stopCluster(cl)


From ligges at statistik.tu-dortmund.de  Fri Aug 14 07:29:21 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 14 Aug 2015 07:29:21 +0200
Subject: [R] lme4 package installation
In-Reply-To: <CAGetN7VCYb-OuQOjSGugdPxNrqhx68KrLA0OBKPTZQVbG9GMVA@mail.gmail.com>
References: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>
	<CAJuCY5yWc3uCVCkR1qwUgJUPuCrHi81848tEG1mjEhrzUwZrHw@mail.gmail.com>
	<CAGetN7VCYb-OuQOjSGugdPxNrqhx68KrLA0OBKPTZQVbG9GMVA@mail.gmail.com>
Message-ID: <55CD7CB1.1030306@statistik.tu-dortmund.de>



On 13.08.2015 22:52, Teck Kiang Tan wrote:
> Hi all
>
> I have problem in installation lme4 and have tried over the past 2 days. It
> failed to install from the various countries.
>
>> install.packages("lme4")
> Warning: unable to access index for repository
> http://cran.stat.nus.edu.sg/src/contrib


This mirror does not respond whn I just tried, choose another one.


> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/src/contrib

This one works for me (but does not contain lme4).
Perhaps also run setInternet2() before you try again in cae you need 
proxy settings.

Best,
Uwe Ligges



> Warning: unable to access index for repository
> http://cran.stat.nus.edu.sg/bin/windows/contrib/3.2
>
> Warning message:
> package ?lme4? is not available (for R version 3.2.1)
>
> Teck Kiang
>
>
> On Thu, Aug 13, 2015 at 11:09 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be
>> wrote:
>
>> Have you trying installing it directly from CRAN?
>>
>> install.packages("lme4")
>>
>> Do you have all dependencies installed? install.packages() from CRAN will
>> take care of that. You repos = NULL you have to install all dependencies
>> manually.
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2015-08-13 16:13 GMT+02:00 <aurora.gonzalez at openmailbox.org>:
>>
>>> Hello
>>>
>>> I've downloaded the tar.gz file of the package "lme4" and when I use the
>>> coomand:
>>>
>>> install.packages("lme4_1.1-8.tar.gz", repos = NULL, type = "source")
>>>
>>> appears an error that suspends the installation:
>>>
>>>
>>> In file included from external.cpp:8:0:
>>> predModule.h:12:23: fatal error: RcppEigen.h: No such file or directory
>>> compilation terminated.
>>> make: *** [external.o] Error 1
>>> ERROR: compilation failed for package ?lme4?
>>> * removing ?/home/aurora/R/x86_64-pc-linux-gnu-library/3.2/lme4?
>>>
>>>
>>>
>>> Does anyone know how to fix it? Thank you very much!
>>>
>>>
>>> My sessionInfo:
>>>
>>>
>>> R version 3.2.1 (2015-06-18)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu precise (12.04.5 LTS)
>>>
>>> locale:
>>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods
>>> [7] base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] tools_3.2.1
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From janka.vanschoenwinkel at uhasselt.be  Fri Aug 14 10:15:34 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka Vanschoenwinkel)
Date: Fri, 14 Aug 2015 10:15:34 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <55CA13D0.3020200@dewey.myzen.co.uk>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<55CA13D0.3020200@dewey.myzen.co.uk>
Message-ID: <CAHymutK2aVeiROW2feEhxJkJm6PqkauEYAQCnoDVXJYODzf8_A@mail.gmail.com>

Hey Michael,

Sorry for the late reply!

Thanks for your comment, but for the cut2 command, this is not the case. If
I enter for instance

Alldata$irri=cut2(irrigation,3)

Then I get 2 intervals from 0-3 and from 3-100.

Janka

2015-08-11 17:25 GMT+02:00 Michael Dewey <lists at dewey.myzen.co.uk>:

> Dear Janka
> If you supply a single number to the breaks parameter of cut I think it is
> the number of intervals.
>
>
> On 11/08/2015 13:57, Janka Vanschoenwinkel wrote:
>
>> Hi Thierry!
>>
>> Thanks for your answer. I tried this, but I get this error:
>>
>> "Error in cut.default(x, k2) : invalid number of intervals"
>>
>> Which is strange because I am not specifying intervals, but the number at
>> where the sample has to be cut?
>>
>> Greetings from Belgium! :-)
>>
>> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>> Dear Janka,
>>>
>>> You loop goes for 0 to 100. It should probably go from 1:99
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
>>> janka.vanschoenwinkel at uhasselt.be>:
>>>
>>> Dear list members,
>>>>
>>>> I have a loop where I want to do several calculations for different
>>>> samples
>>>> and save the results for each sample. These samples are for each loop
>>>> different. I want to use the "i" in the loop to cut the samples.
>>>>
>>>> So for instance:
>>>>
>>>>     - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>>>>     - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>>>>     - In loop 99 (i=99), I have a sample from 0-99 and a sample from
>>>> 99-100.
>>>>
>>>> I built the following function, but there is *a problem with the cut2
>>>> function* since it doesn't recognize the "i". Outside the lapply loop it
>>>> works, but not inside the loop.
>>>>
>>>> Could somebody please help me with this problem? Thanks a lot!
>>>>
>>>>
>>>>
>>>>
>>>> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>>>>
>>>>
>>>>
>>>>      o<-lapply(0:100, function(i){
>>>>
>>>>
>>>>
>>>>          Alldata$irri=cut2(Alldata$irrigation,i)
>>>>
>>>>          levels(Alldata$irri)<-c("0","1")
>>>>
>>>>
>>>>
>>>>         Alldata_Rainfed<-subset(Alldata, irri == 0)
>>>>
>>>>         Alldata_Irrigation<-subset(Alldata, irri == 1)
>>>>
>>>>
>>>>
>>>>      #calculations per sample, then store all the values per i and per
>>>> variable in a dataframe: (the calculations are not shown in this
>>>> example)
>>>>
>>>>
>>>>
>>>>       d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>>>>
>>>>
>>>>
>>>>     })
>>>>
>>>>
>>>>
>>>>     out<-as.data.frame(do.call(rbind, o))
>>>>
>>>>
>>>> --
>>>> P Please consider the environment before printing this e-mail
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>



-- 

[image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel
*Doctoraatsbursaal - PhD *
Milieueconomie - Environmental economics

T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt

P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Fri Aug 14 11:21:48 2015
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Fri, 14 Aug 2015 11:21:48 +0200
Subject: [R] R 3.2.2 is released
Message-ID: <14CDC0C4-DE12-4742-897C-C30D0E78976A@cbs.dk>

The build system rolled up  R-3.2.2.tar.gz (codename "Fire Safety") this morning.

The list below details the changes in this release. The main point of this release is to enable package installation via secure HTTP, since ordinary HTTP is increasingly being considered a security risk.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.2.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:


MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = e74e64dde0f92181957d46a0f8538e8b
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 5ff829377f0de5cdb0ad30bb42977611
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (R-latest.tar.gz) = 57cef5c2e210a5454da1979562a10e5b
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = ba00f6cc68a823e1741cfa6011f40ccb
MD5 (VERSION-INFO.dcf) = 55826f7f976cd9623577e5a9ac694c47
MD5 (R-3/R-3.2.2.tar.gz) = 57cef5c2e210a5454da1979562a10e5b

This is the relevant part of the NEWS file

CHANGES IN R 3.2.2:

  SIGNIFICANT USER-VISIBLE CHANGES:

    * It is now easier to use secure downloads from https:// URLs on
      builds which support them: no longer do non-default options need
      to be selected to do so.  In particular, packages can be
      installed from repositories which offer https:// URLs, and those
      listed by setRepositories() now do so (for some of their
      mirrors).

      Support for https:// URLs is available on Windows, and on other
      platforms if support for libcurl was compiled in and if that
      supports the https protocol (system installations can be expected
      to do).  So https:// support can be expected except on rather old
      OSes (an example being OS X 'Snow Leopard', where a non-system
      version of libcurl can be used).

      (Windows only) The default method for accessing URLs _via_
      download.file() and url() has been changed to be "wininet" using
      Windows API calls.  This changes the way proxies need to be set
      and security settings made: there have been some reports of sites
      being inaccessible under the new default method (but the previous
      methods remain available).

  NEW FEATURES:

    * cmdscale() gets new option list. for increased flexibility when a
      list should be returned.

    * configure now supports texinfo version 6.0, which (unlike the
      change from 4.x to 5.0) is a minor update.  (Wish of PR#16456.)

    * (Non-Windows only) download.file() with default method = "auto"
      now chooses "libcurl" if that is available and a https:// or
      ftps:// URL is used.

    * (Windows only) setInternet2(TRUE) is now the default.  The
      command-line option --internet2 and environment variable
      R_WIN_INTERNET2 are now ignored.

      Thus by default the "internal" method for download.file() and
      url() uses the "wininet" method: to revert to the previous
      default use setInternet2(FALSE).

      This means that https:// can be read by default by
      download.file() (they have been readable by file() and url()
      since R 3.2.0).

      There are implications for how proxies need to be set (see
      ?download.file): also, cacheOK = FALSE is not supported.

    * chooseCRANmirror() and chooseBioCmirror() now offer HTTPS mirrors
      in preference to HTTP mirrors.  This changes the interpretation
      of their ind arguments: see their help pages.

    * capture.output() gets optional arguments type and split to pass
      to sink(), and hence can be used to capture messages.

  C-LEVEL FACILITIES:

    * Header Rconfig.h now defines HAVE_ALLOCA_H if the platform has
      the alloca.h header (it is needed to define alloca on Solaris and
      AIX, at least: see 'Writing R Extensions' for how to use it).

  INSTALLATION and INCLUDED SOFTWARE:

    * The libtool script generated by configure has been modified to
      support FreeBSD >= 10 (PR#16410).

  BUG FIXES:

    * The HTML help page links to demo code failed due to a change in R
      3.2.0.  (PR#16432)

    * If the na.action argument was used in model.frame(), the original
      data could be modified. (PR#16436)

    * getGraphicsEvent() could cause a crash if a graphics window was
      closed while it was in use. (PR#16438)

    * matrix(x, nr, nc, byrow = TRUE) failed if x was an object of type
      "expression".

    * strptime() could overflow the allocated storage on the C stack
      when the timezone had a non-standard format much longer than the
      standard formats. (Part of PR#16328.)

    * options(OutDec = s) now signals a warning (which will become an
      error in the future) when s is not a string with exactly one
      character, as that has been a documented requirement.

    * prettyNum() gains a new option input.d.mark which together with
      other changes, e.g., the default for decimal.mark, fixes some
      format()ting variants with non-default getOption("OutDec") such
      as in PR#16411.

    * download.packages() failed for type equal to either "both" or
      "binary".  (Reported by Dan Tenenbaum.)

    * The dendrogram method of labels() is much more efficient for
      large dendrograms, now using rapply().  (Comment #15 of PR#15215)

    * The "port" algorithm of nls() could give spurious errors.
      (Reported by Radford Neal.)

    * Reference classes that inherited from reference classes in
      another package could invalidate methods of the inherited class.
      Fixing this requires adding the ability for methods to be
      "external", with the object supplied explicitly as the first
      argument, named .self. See "Inter-Package Superclasses" in the
      documentation.

    * readBin() could fail on the SPARC architecture due to alignment
      issues.  (Reported by Radford Neal.)

    * qt(*, df=Inf, ncp=.) now uses the natural qnorm() limit instead
      of returning NaN. (PR#16475)

    * Auto-printing of S3 and S4 values now searches for print() in the
      base namespace and show() in the methods namespace instead of
      searching the global environment.

    * polym() gains a coefs = NULL argument and returns class "poly"
      just like poly() which gets a new simple=FALSE option.  They now
      lead to correct predict()ions, e.g., on subsets of the original
      data.

    * rhyper(nn, <large>) now works correctly. (PR#16489)

    * ttkimage() did not (and could not) work so was removed. Ditto for
      tkimage.cget() and tkimage.configure(). Added two Ttk widgets and
      missing subcommands for Tk's image command: ttkscale(),
      ttkspinbox(), tkimage.delete(), tkimage.height(),
      tkimage.inuse(), tkimage.type(), tkimage.types(),
      tkimage.width(). (PR#15372, PR#16450)

    * getClass("foo") now also returns a class definition when it is
      found in the cache more than once.

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From petr.pikal at precheza.cz  Fri Aug 14 12:01:33 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 14 Aug 2015 10:01:33 +0000
Subject: [R] cut variable within a loop
In-Reply-To: <CAHymutK2aVeiROW2feEhxJkJm6PqkauEYAQCnoDVXJYODzf8_A@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<55CA13D0.3020200@dewey.myzen.co.uk>
	<CAHymutK2aVeiROW2feEhxJkJm6PqkauEYAQCnoDVXJYODzf8_A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39DB0@SRVEXCHMBX.precheza.cz>

Hi

Didn't you by chance use plain cut and k2 was NA?

> cut(1:300, NA)
Error in cut.default(1:300, NA) : invalid number of intervals

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Janka
> Vanschoenwinkel
> Sent: Friday, August 14, 2015 10:16 AM
> To: Michael Dewey
> Cc: r-help at r-project.org
> Subject: Re: [R] cut variable within a loop
>
> Hey Michael,
>
> Sorry for the late reply!
>
> Thanks for your comment, but for the cut2 command, this is not the
> case. If I enter for instance
>
> Alldata$irri=cut2(irrigation,3)
>
> Then I get 2 intervals from 0-3 and from 3-100.
>
> Janka
>
> 2015-08-11 17:25 GMT+02:00 Michael Dewey <lists at dewey.myzen.co.uk>:
>
> > Dear Janka
> > If you supply a single number to the breaks parameter of cut I think
> > it is the number of intervals.
> >
> >
> > On 11/08/2015 13:57, Janka Vanschoenwinkel wrote:
> >
> >> Hi Thierry!
> >>
> >> Thanks for your answer. I tried this, but I get this error:
> >>
> >> "Error in cut.default(x, k2) : invalid number of intervals"
> >>
> >> Which is strange because I am not specifying intervals, but the
> >> number at where the sample has to be cut?
> >>
> >> Greetings from Belgium! :-)
> >>
> >> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx
> <thierry.onkelinx at inbo.be>:
> >>
> >> Dear Janka,
> >>>
> >>> You loop goes for 0 to 100. It should probably go from 1:99
> >>>
> >>> Best regards,
> >>>
> >>> ir. Thierry Onkelinx
> >>> Instituut voor natuur- en bosonderzoek / Research Institute for
> >>> Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics
> >>> & Quality Assurance Kliniekstraat 25 1070 Anderlecht Belgium
> >>>
> >>> To call in the statistician after the experiment is done may be no
> >>> more than asking him to perform a post-mortem examination: he may
> be
> >>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>> The plural of anecdote is not data. ~ Roger Brinner The combination
> >>> of some data and an aching desire for an answer does not ensure
> that
> >>> a reasonable answer can be extracted from a given body of data.
> >>> ~ John Tukey
> >>>
> >>> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
> >>> janka.vanschoenwinkel at uhasselt.be>:
> >>>
> >>> Dear list members,
> >>>>
> >>>> I have a loop where I want to do several calculations for
> different
> >>>> samples and save the results for each sample. These samples are
> for
> >>>> each loop different. I want to use the "i" in the loop to cut the
> >>>> samples.
> >>>>
> >>>> So for instance:
> >>>>
> >>>>     - In loop 1 (i=1), I have a sample from 0-1 and a sample from
> 1-100.
> >>>>     - In loop 2 (i=2), I have a sample from 0-2 and a sample from
> 2-100.
> >>>>     - In loop 99 (i=99), I have a sample from 0-99 and a sample
> >>>> from 99-100.
> >>>>
> >>>> I built the following function, but there is *a problem with the
> >>>> cut2
> >>>> function* since it doesn't recognize the "i". Outside the lapply
> >>>> loop it works, but not inside the loop.
> >>>>
> >>>> Could somebody please help me with this problem? Thanks a lot!
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irri
> >>>> gation=rep(0,100),MEp_Irrigation=rep(0,100))
> >>>>
> >>>>
> >>>>
> >>>>      o<-lapply(0:100, function(i){
> >>>>
> >>>>
> >>>>
> >>>>          Alldata$irri=cut2(Alldata$irrigation,i)
> >>>>
> >>>>          levels(Alldata$irri)<-c("0","1")
> >>>>
> >>>>
> >>>>
> >>>>         Alldata_Rainfed<-subset(Alldata, irri == 0)
> >>>>
> >>>>         Alldata_Irrigation<-subset(Alldata, irri == 1)
> >>>>
> >>>>
> >>>>
> >>>>      #calculations per sample, then store all the values per i and
> >>>> per variable in a dataframe: (the calculations are not shown in
> >>>> this
> >>>> example)
> >>>>
> >>>>
> >>>>
> >>>>       d[i, ] =
> >>>> c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> >>>>
> >>>>
> >>>>
> >>>>     })
> >>>>
> >>>>
> >>>>
> >>>>     out<-as.data.frame(do.call(rbind, o))
> >>>>
> >>>>
> >>>> --
> >>>> P Please consider the environment before printing this e-mail
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>>
> >>>
> >>
> >>
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
> >
>
>
>
> --
>
> [image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel *Doctoraatsbursaal
> - PhD * Milieueconomie - Environmental economics
>
> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
>
> www.uhasselt.be/eec
>
> Universiteit Hasselt | Campus Diepenbeek Agoralaan Gebouw D | B-3590
> Diepenbeek Kantoor F11
>
> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>
> P Please consider the environment before printing this e-mail
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Fri Aug 14 12:55:31 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 14 Aug 2015 20:55:31 +1000
Subject: [R] How to obtain the unique communities when plotting VENNs?
In-Reply-To: <1439478320854-4711081.post@n4.nabble.com>
References: <1439452677012-4711056.post@n4.nabble.com>
	<3A5641AAEBF.000001F2jrkrideau@inbox.com>
	<1439478320854-4711081.post@n4.nabble.com>
Message-ID: <CA+8X3fWVQSuGo1DJ_kuejMutpTtO03SGBMrW1BCv5pk7jYS71g@mail.gmail.com>

Hi Krissey,
I think what you need is the object (probably a matrix or data frame)
that contains the present/absent codes for all of the species
recorded. It looks to me as though the venn.diagram function wants a
list with the indices of "present" codes for each set, and calculates
the intersections from that. If you have that list, you can work
backward to generate the initial present/absent matrix for all
species. You will have to know the order of the rows in the initial
matrix to identify which species is which.

Jim


On Fri, Aug 14, 2015 at 1:05 AM, Krissey <kristin.kaiser at web.de> wrote:
> Thanks a lot John - I will set up a new post and hopefully do better :)
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/How-to-obtain-the-unique-communities-when-plotting-VENNs-tp4711056p4711081.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Fri Aug 14 13:14:09 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 14 Aug 2015 12:14:09 +0100
Subject: [R] Multi-line forestplots, how to in R
In-Reply-To: <DB5PR04MB08728012256D85A40A8D9049DD7D0@DB5PR04MB0872.eurprd04.prod.outlook.com>
References: <DB5PR04MB08728012256D85A40A8D9049DD7D0@DB5PR04MB0872.eurprd04.prod.outlook.com>
Message-ID: <55CDCD81.7000202@dewey.myzen.co.uk>

Read Ella

Comments in-line below

On 14/08/2015 00:36, mcknight e. (em8g14) wrote:
> Hello,
>
>
> I am working on ecological data covering a meta-analysis on invasive species traits.
>
>
> I am not very skilled in R and would love if someone could assist me in my production of multi-line forest plots.
>
> The data I have is: random effects mixed model and is further divided into subsets, I have used metafor package and here is a breakdown of my code =
>
> #this is my main data calculation into effect sizes
>
> MA <- escalc (measure="SMD", m1i=Invasive..mean, sd1i=sd.invasive, n1i=N.invasive, m2i=Control.mean, sd2i=sd.control, n2i=N.control, data=dataset)
>
> res.MA <- rma(yi,vi,data=MA,method="REML");res.MA  #random-effects models ; "HS" Viechtbauer (2005)
>

Why does your comment say "HS" when you have in fact asked for it to 
estimate tau^2 using REML (which is the default)?
>
> #separating data
> lab <- subset (x=MA, Type.of.ex=="Lab")
> field <- subset (x=MA, Type.of.ex=="Field")
>

You do not need to do that since rma.uni has a subset parameter as you 
use later

> res.MAlab <- rma(yi,vi,data=lab,method="REML");res.MAlab  #random-effects models ; "HS" Viechtbauer (2005)
> res.MAfield <- rma(yi,vi,data=field,method="REML");res.MAfield  #random-effects models ; "HS" Viechtbauer (2005)
>

Could you not get the estimates you want by using Type.of.ex as a 
moderator here with the full dataset?

 From here on it is difficult to be sure what to say without more 
knowledge about your dataset and the underlying science but I wonder 
whether in fact you need to fit a multivariate model instead if you have 
(say) k studies each giving 6 trait estimates, and so on. If that is the 
way to go you need to read

?rma.mv

Please set your mailer to not send HTML as it mangles your messages and 
it is more readable if you (a) put each command on a separate line (b) 
use more spaces. Disk space is cheap.


> res.traitlab <- rma(yi,vi,mods= ~ factor(Trait)-1,data=lab);res.traitlab #model for traits
>
> res.traitfield <- rma(yi,vi,mods= ~ factor(Trait)-1,data=field);res.traitfield
>
> #model for each lab traits
>
> res.labct <- rma(yi,vi,subset=Trait=="Consumption",data=lab);res.labct
> res.labec <- rma(yi,vi,subset=Trait=="Exploitative competition",data=lab);res.labec
> res.labgr <- rma(yi,vi,subset=Trait=="Growth",data=lab);res.labgr
> res.labic <- rma(yi,vi,subset=Trait=="Interference competition",data=lab);res.labic
> res.labpa <- rma(yi,vi,subset=Trait=="Predator avoidance",data=lab);res.labpa
> res.labpe <- rma(yi,vi,subset=Trait=="Predator escape",data=lab);res.labpe
>
> #model for each field traits
>
> res.fieldct <- rma(yi,vi,subset=Trait=="Consumption",data=field);res.labct
> res.fieldec <- rma(yi,vi,subset=Trait=="Exploitative competition",data=field);res.labec
> res.fieldgr <- rma(yi,vi,subset=Trait=="Growth",data=field);res.labgr
> res.fieldic <- rma(yi,vi,subset=Trait=="Interference competition",data=field);res.labic
> res.fieldpa <- rma(yi,vi,subset=Trait=="Predator avoidance",data=field);res.labpa
> res.fieldpe <- rma(yi,vi,subset=Trait=="Predator escape",data=field);res.labpe
>
> #producing a graph for lab data
>
> estimateslab <- c(coef(res.labct), coef(res.labec), coef(res.labgr), coef(res.labic), coef(res.labpa),coef(res.labpe))
> varianceslab <- c(vcov(res.labct), vcov(res.labec), vcov(res.labgr), vcov(res.labic), vcov(res.labpa),vcov(res.labpe))
> labelslab <- c("Consumption (109)","Exploitative competition (21)","Growth (33)","Interference competition (31)","Predator avoidance (4)","Predator escape (61)")
> forest(estimateslab, varianceslab, slab=labelslab, digit=0, annotate=F, xlab="Mean effect size",ylim=c(0,11))
>
> #producing a graph for field data
>
> estimatesfield <- c(coef(res.fieldct),coef(res.fieldec), coef(res.fieldgr), coef(res.fieldic),coef(res.fieldpa),coef(res.fieldpe))
> variancesfield <- c(vcov(res.fieldct),vcov(res.fieldec), vcov(res.fieldgr), vcov(res.fieldic), vcov(res.fieldpa),   vcov(res.fieldpe))
> labelsfield <- c("Consumption (7)","Exploitative competition (19)","Growth (2)","Interference competition (34)","Predator avoidance (2)","Predator escape (15)")
> forest(estimatesfield, variancesfield, slab=labelsfield,digit=0,annotate=F,xlab="Mean effect size",ylim=c(0,11)) # "psize=1" size of mean box on forest plot
> addpoly(res.MAfield, row=0.2, cex=1, atransf=F, mlab="RE Model Field Studies (79)",annotate=F)
>
>
> OK, so sorry for code overload... I hope you can understand what i have done.
>
> What i need it to produce one graph with both data sets Lab and field showing effect sizes for each of the mentioned traits. Im not super up to scratch on R and some of the current code was shared through a colleague, however this person isnt great at plots.
>
>
> Please please can someone help me. Im currently wasting heaps of my time and getting no where.
>
> Sincerely grateful
>
> Ella
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From janka.vanschoenwinkel at uhasselt.be  Fri Aug 14 14:17:23 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka Vanschoenwinkel)
Date: Fri, 14 Aug 2015 14:17:23 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>
Message-ID: <CAHymutKPfSM-qfbp9dLQgUpErUKp0tHj476fCPP8_r5aFiUxyQ@mail.gmail.com>

Hi Thierry and Petr,

I really appreciate the comments you already gave. Thank you very much for
that.

Below you can find a link to the data and the code. Hopefully this helps in
spotting the error.

I still think the issue is that the cut2 function only accepts numbers, and
not an "i" that refers to the number at the start of the loop. To answer
Petr his question, yes, column 3 and 4 are NA (these are the columns of the
second interval). But I don't really understand your point so could you
clarify this please?

https://drive.google.com/folderview?id=0By9u5m3kxn9yfkxxeVNMdnRQQXhoT05CRlJlZVBCWWF2NURMMTNmVFVFeXJXXzhlMWE4SUk&usp=sharing

Thank you very much once again!

Janka



2015-08-11 15:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> You'll need to send a reproducible example of the code. We can't run the
> code that you send. Hence it is hard to help you. See e.g.
> http://adv-r.had.co.nz/Reproducibility.html
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-08-11 14:57 GMT+02:00 Janka Vanschoenwinkel <
> janka.vanschoenwinkel at uhasselt.be>:
>
>> Hi Thierry!
>>
>> Thanks for your answer. I tried this, but I get this error:
>>
>> "Error in cut.default(x, k2) : invalid number of intervals"
>>
>> Which is strange because I am not specifying intervals, but the number at
>> where the sample has to be cut?
>>
>> Greetings from Belgium! :-)
>>
>> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>>> Dear Janka,
>>>
>>> You loop goes for 0 to 100. It should probably go from 1:99
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
>>> janka.vanschoenwinkel at uhasselt.be>:
>>>
>>>> Dear list members,
>>>>
>>>> I have a loop where I want to do several calculations for different
>>>> samples
>>>> and save the results for each sample. These samples are for each loop
>>>> different. I want to use the "i" in the loop to cut the samples.
>>>>
>>>> So for instance:
>>>>
>>>>    - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>>>>    - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>>>>    - In loop 99 (i=99), I have a sample from 0-99 and a sample from
>>>> 99-100.
>>>>
>>>> I built the following function, but there is *a problem with the cut2
>>>> function* since it doesn't recognize the "i". Outside the lapply loop it
>>>> works, but not inside the loop.
>>>>
>>>> Could somebody please help me with this problem? Thanks a lot!
>>>>
>>>>
>>>>
>>>> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>>>>
>>>>
>>>>
>>>>     o<-lapply(0:100, function(i){
>>>>
>>>>
>>>>
>>>>         Alldata$irri=cut2(Alldata$irrigation,i)
>>>>
>>>>         levels(Alldata$irri)<-c("0","1")
>>>>
>>>>
>>>>
>>>>        Alldata_Rainfed<-subset(Alldata, irri == 0)
>>>>
>>>>        Alldata_Irrigation<-subset(Alldata, irri == 1)
>>>>
>>>>
>>>>
>>>>     #calculations per sample, then store all the values per i and per
>>>> variable in a dataframe: (the calculations are not shown in this
>>>> example)
>>>>
>>>>
>>>>
>>>>      d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>>>>
>>>>
>>>>
>>>>    })
>>>>
>>>>
>>>>
>>>>    out<-as.data.frame(do.call(rbind, o))
>>>>
>>>>
>>>> --
>>>> P Please consider the environment before printing this e-mail
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>>
>> --
>>
>> [image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel
>> *Doctoraatsbursaal - PhD *
>> Milieueconomie - Environmental economics
>>
>> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
>>
>> www.uhasselt.be/eec
>>
>> Universiteit Hasselt | Campus Diepenbeek
>> Agoralaan Gebouw D | B-3590 Diepenbeek
>> Kantoor F11
>>
>> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>>
>> P Please consider the environment before printing this e-mail
>>
>>
>


-- 

[image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel
*Doctoraatsbursaal - PhD *
Milieueconomie - Environmental economics

T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt

P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From janka.vanschoenwinkel at uhasselt.be  Fri Aug 14 15:40:59 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka Vanschoenwinkel)
Date: Fri, 14 Aug 2015 15:40:59 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39DE6@SRVEXCHMBX.precheza.cz>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>
	<CAHymutKPfSM-qfbp9dLQgUpErUKp0tHj476fCPP8_r5aFiUxyQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39DE6@SRVEXCHMBX.precheza.cz>
Message-ID: <CAHymutK__NMQFbWJsCk3aYw3Wz3S1gLmGFW=kFoxQ+yh+g3PqQ@mail.gmail.com>

Hi Petr,

Here the code below:

load("data.Rda") # or see data at the bottom of this email

##########################################################################################

####### Question cut2 intervals #######

# I have the variable irrigation which has a range from 0% to 100%.
# I now want to calculate the code below for different thresholds of irrigation.
# So for instance: starting from 10%, a farmer is defined as "irrigated farm".
# Then we would have 0-10 = Rainfed, 10-100 is Irrigated.

# In the code below I run a short code for only 50 observations and
# only for the interval 0-1,1-100 and 0-2, 2-100. If that works, it should also
# work for 1-99.

# As indicated, it goes wrong when I want to cut based on the "i"
specified at the start of the loop.

# Thanks a lot for your help!

# Janka


d= data.frame(MEt_Rainfed=rep(1,2),MEp_Rainfed=rep(1,2),MEt_Irrigation=rep(1,2),MEp_Irrigation=rep(1,2))

library(Hmisc)
o<-lapply(1:2, function(i){

  #cut sample in rainfed versus irrigation
  Alldata$irri=cut2(Alldata$irrigation,i)
  levels(Alldata$irri)<-c("0","1")

  Alldata_Rainfed<-subset(Alldata, irri == 0)
  Alldata_Irrigation<-subset(Alldata, irri == 1)

  Alldata_Rainfed$w<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
  Alldata_Irrigation$w<-Alldata_Irrigation$b48+Alldata_Irrigation$b50

  OLS_Rainfed <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
                      ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
                      pdnsty+portsML+cities500k+rentedland+subsidies1+
                      elevmean+elevrange+
                      t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
                      AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
                    weights=w,Alldata_Rainfed)

  attach(Alldata_Rainfed)

  CoefRainfed_ps1 <- OLS_Rainfed$coeff[2]
  CoefRainfed_ps2 <- OLS_Rainfed$coeff[3]
  CoefRainfed_ps3 <- OLS_Rainfed$coeff[4]
  CoefRainfed_ps4 <- OLS_Rainfed$coeff[5]
  CoefRainfed_ts1 <- OLS_Rainfed$coeff[6]
  CoefRainfed_ts2 <- OLS_Rainfed$coeff[7]
  CoefRainfed_ts3 <- OLS_Rainfed$coeff[8]
  CoefRainfed_ts4 <- OLS_Rainfed$coeff[9]
  CoefRainfed_ps1sq <- OLS_Rainfed$coeff[10]
  CoefRainfed_ps2sq <- OLS_Rainfed$coeff[11]
  CoefRainfed_ps3sq <- OLS_Rainfed$coeff[12]
  CoefRainfed_ps4sq <- OLS_Rainfed$coeff[13]
  CoefRainfed_ts1sq <- OLS_Rainfed$coeff[14]
  CoefRainfed_ts2sq <- OLS_Rainfed$coeff[15]
  CoefRainfed_ts3sq <- OLS_Rainfed$coeff[16]
  CoefRainfed_ts4sq <- OLS_Rainfed$coeff[17]

  attach(Alldata_Rainfed)


  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY level)
  # Maar dit is dus de marginale impact per LnALVperHA?

  Alldata_Rainfed$MEts1 =
CoefRainfed_ts1+2*CoefRainfed_ts1sq*Alldata_Rainfed$ts1
  Alldata_Rainfed$MEts2 =
CoefRainfed_ts2+2*CoefRainfed_ts2sq*Alldata_Rainfed$ts2
  Alldata_Rainfed$MEts3 =
CoefRainfed_ts3+2*CoefRainfed_ts3sq*Alldata_Rainfed$ts3
  Alldata_Rainfed$MEts4 =
CoefRainfed_ts4+2*CoefRainfed_ts4sq*Alldata_Rainfed$ts4
  Alldata_Rainfed$MEt   = Alldata_Rainfed$MEts1 +
Alldata_Rainfed$MEts2 + Alldata_Rainfed$MEts3 + Alldata_Rainfed$MEts4

  Alldata_Rainfed$MEps1 =
CoefRainfed_ps1+2*CoefRainfed_ps1sq*Alldata_Rainfed$ps1
  Alldata_Rainfed$MEps2 =
CoefRainfed_ps2+2*CoefRainfed_ps2sq*Alldata_Rainfed$ps2
  Alldata_Rainfed$MEps3 =
CoefRainfed_ps3+2*CoefRainfed_ps3sq*Alldata_Rainfed$ps3
  Alldata_Rainfed$MEps4 =
CoefRainfed_ps4+2*CoefRainfed_ps4sq*Alldata_Rainfed$ps4
  Alldata_Rainfed$MEp   = Alldata_Rainfed$MEps1 +
Alldata_Rainfed$MEps2 + Alldata_Rainfed$MEps3 + Alldata_Rainfed$MEps4


  Alldata_Rainfed$weight2<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
  attach(Alldata_Rainfed)
  library(stats)
  MEt_Rainfed<-weighted.mean(MEt,weight2)
  MEp_Rainfed<-weighted.mean(MEp,weight2)



  attach(Alldata_Irrigation)

  OLS_Irrigation <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
                         ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
                         pdnsty+portsML+cities500k+rentedland+subsidies1+
                         elevmean+elevrange+
                         t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
                         AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
                       weights=w,Alldata_Irrigation)



  CoefIrrigation_ps1 <- OLS_Irrigation$coeff[2]
  CoefIrrigation_ps2 <- OLS_Irrigation$coeff[3]
  CoefIrrigation_ps3 <- OLS_Irrigation$coeff[4]
  CoefIrrigation_ps4 <- OLS_Irrigation$coeff[5]
  CoefIrrigation_ts1 <- OLS_Irrigation$coeff[6]
  CoefIrrigation_ts2 <- OLS_Irrigation$coeff[7]
  CoefIrrigation_ts3 <- OLS_Irrigation$coeff[8]
  CoefIrrigation_ts4 <- OLS_Irrigation$coeff[9]
  CoefIrrigation_ps1sq <- OLS_Irrigation$coeff[10]
  CoefIrrigation_ps2sq <- OLS_Irrigation$coeff[11]
  CoefIrrigation_ps3sq <- OLS_Irrigation$coeff[12]
  CoefIrrigation_ps4sq <- OLS_Irrigation$coeff[13]
  CoefIrrigation_ts1sq <- OLS_Irrigation$coeff[14]
  CoefIrrigation_ts2sq <- OLS_Irrigation$coeff[15]
  CoefIrrigation_ts3sq <- OLS_Irrigation$coeff[16]
  CoefIrrigation_ts4sq <- OLS_Irrigation$coeff[17]

  attach(Alldata_Irrigation)
  # gives the residual errors in Y
  Alldata_Irrigation$residuals <-resid(OLS_Irrigation)

  # gives the predicted values for Ln_Y
  Alldata_Irrigation$Ln_y_hat <-fitted(OLS_Irrigation)

  # Zelf functie rmse maken
  rmse <- function(error)
  {
    sqrt(mean(error^2))
  }
  Alldata_Irrigation$y_hat <-
exp(Alldata_Irrigation$Ln_y_hat)*exp(0.5*(rmse(OLS_Irrigation$residuals))^2)

  # absolute impact (landwaarde current)
  Alldata_Irrigation$absolute.current<-Alldata_Irrigation$y_hat*Alldata_Irrigation$se025*Alldata_Irrigation$sys02


  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY level)
  # Maar dit is dus de marginale impact per LnALVperHA?

  Alldata_Irrigation$MEts1 =
CoefIrrigation_ts1+2*CoefIrrigation_ts1sq*Alldata_Irrigation$ts1
  Alldata_Irrigation$MEts2 =
CoefIrrigation_ts2+2*CoefIrrigation_ts2sq*Alldata_Irrigation$ts2
  Alldata_Irrigation$MEts3 =
CoefIrrigation_ts3+2*CoefIrrigation_ts3sq*Alldata_Irrigation$ts3
  Alldata_Irrigation$MEts4 =
CoefIrrigation_ts4+2*CoefIrrigation_ts4sq*Alldata_Irrigation$ts4
  Alldata_Irrigation$MEt   = Alldata_Irrigation$MEts1 +
Alldata_Irrigation$MEts2 + Alldata_Irrigation$MEts3 +
Alldata_Irrigation$MEts4

  Alldata_Irrigation$MEps1 =
CoefIrrigation_ps1+2*CoefIrrigation_ps1sq*Alldata_Irrigation$ps1
  Alldata_Irrigation$MEps2 =
CoefIrrigation_ps2+2*CoefIrrigation_ps2sq*Alldata_Irrigation$ps2
  Alldata_Irrigation$MEps3 =
CoefIrrigation_ps3+2*CoefIrrigation_ps3sq*Alldata_Irrigation$ps3
  Alldata_Irrigation$MEps4 =
CoefIrrigation_ps4+2*CoefIrrigation_ps4sq*Alldata_Irrigation$ps4
  Alldata_Irrigation$MEp   = Alldata_Irrigation$MEps1 +
Alldata_Irrigation$MEps2 + Alldata_Irrigation$MEps3 +
Alldata_Irrigation$MEps4


  Alldata_Irrigation$weight2<-Alldata_Irrigation$sys02*Alldata_Irrigation$se025
  Alldata_Irrigation$weight2<-Alldata_Irrigation$b48+Alldata_Irrigation$b50

  attach(Alldata_Irrigation)
  library(stats)
  MEt_Irrigation<-weighted.mean(MEt,weight2)
  MEp_Irrigation<-weighted.mean(MEp,weight2)

  c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)

  attach(Alldata)


  # And in the loop (index i):

  d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)


})
out<-as.data.frame(do.call(rbind, o))




And the data are:

structure(list(LnALVperHA = c(8.09964942932129, 9.53274631500244,
7.42697763442993, 8.25370121002197, 8.42619132995605, 8.0093936920166,
8.09785747528076, 8.49044704437256, 9.08215141296387, 8.38935947418213,
8.67814350128174, 8.38935947418213, 10.4056901931763, 8.48210144042969,
8.30281829833984, 8.92265796661377, 8.33178997039795, 4.54404163360596,
10.662184715271, 9.62167072296143, 7.98790407180786, 7.58244323730469,
7.23262739181519, 9.47037124633789, 8.93403625488281, 7.54256629943848,
9.40302467346191, 10.6290521621704, 8.59830188751221, 8.59585666656494,
9.10000514984131, 9.99381542205811, 9.54681301116943, 9.53055191040039,
8.67971229553223, 7.19780731201172, 8.90067958831787, 6.0509786605835,
6.55788946151733, 8.22567272186279, 9.05618953704834, 6.81858921051025,
8.46410751342773, 7.81292057037354, 8.38989448547363, 10.4709157943726,
8.06132888793945, 8.43629264831543, 10.3087100982666, 10.3218297958374
), ps1 = c(5.14855766296387, 4.71904611587524, 7.9462103843689,
10.6017990112305, 11.233078956604, 9.12952136993408, 12.6536712646484,
11.233078956604, 11.233078956604, 11.233078956604, 11.233078956604,
11.233078956604, 5.93759632110596, 10.6017990112305, 11.233078956604,
10.6017990112305, 7.95780467987061, 9.07744884490967, 4.29865598678589,
8.27481746673584, 3.25137901306152, 4.51061344146729, 6.34518480300903,
6.66202449798584, 6.66202449798584, 4.75249433517456, 6.28858852386475,
6.33270215988159, 10.3600759506226, 10.3600759506226, 18.7164611816406,
5.73318386077881, 7.92949104309082, 9.09823608398438, 11.233078956604,
10.4455404281616, 11.233078956604, 10.4455404281616, 10.4455404281616,
10.6017990112305, 9.19112777709961, 10.4455404281616, 11.233078956604,
11.064302444458, 11.233078956604, 5.93759632110596, 11.233078956604,
10.6017990112305, 6.05948448181152, 9.5645227432251), ps2 = c(5.23111915588379,
4.86784505844116, 7.7175760269165, 4.34898376464844, 4.48626232147217,
9.57159423828125, 8.38174915313721, 4.48626232147217, 4.48626232147217,
4.48626232147217, 4.48626232147217, 4.48626232147217, 6.87198734283447,
4.34898376464844, 4.48626232147217, 4.34898376464844, 6.2098217010498,
7.5497522354126, 5.62545442581177, 5.57168531417847, 3.08954334259033,
6.6683931350708, 4.41767883300781, 6.11901044845581, 6.11901044845581,
4.06884765625, 6.35917854309082, 5.7121729850769, 8.55229663848877,
8.55229663848877, 11.8981914520264, 5.49351119995117, 5.34777498245239,
6.12420177459717, 4.48626232147217, 5.2967677116394, 4.48626232147217,
5.2967677116394, 5.2967677116394, 4.34898376464844, 4.51386308670044,
5.2967677116394, 4.48626232147217, 5.98725175857544, 4.48626232147217,
6.87198734283447, 4.48626232147217, 4.34898376464844, 5.58411026000977,
4.42436075210571), ps3 = c(4.95634937286377, 3.50353670120239,
6.01129817962646, 0.851324141025543, 0.816295921802521, 8.03804397583008,
5.56230783462524, 0.816295921802521, 0.816295921802521, 0.816295921802521,
0.816295921802521, 0.816295921802521, 6.01666784286499, 0.851324141025543,
0.816295921802521, 0.851324141025543, 3.45424580574036, 5.31899690628052,
7.45753812789917, 3.34133338928223, 6.61472988128662, 11.244439125061,
2.19617891311646, 5.29748106002808, 5.29748106002808, 1.63307499885559,
5.51272773742676, 6.78562116622925, 4.5334997177124, 4.5334997177124,
4.31791353225708, 7.10963106155396, 2.32198905944824, 2.74845194816589,
0.816295921802521, 1.47570741176605, 0.816295921802521, 1.47570741176605,
1.47570741176605, 0.851324141025543, 1.39068424701691, 1.47570741176605,
0.816295921802521, 1.85064959526062, 0.816295921802521, 6.01666784286499,
0.816295921802521, 0.851324141025543, 6.78009986877441, 1.21070051193237
), ps4 = c(5.66667366027832, 4.82342433929443, 7.40090322494507,
6.59299898147583, 7.33758926391602, 9.98004341125488, 10.3958940505981,
7.33758926391602, 7.33758926391602, 7.33758926391602, 7.33758926391602,
7.33758926391602, 8.31999015808105, 6.59299898147583, 7.33758926391602,
6.59299898147583, 7.05771064758301, 8.38344383239746, 4.75349426269531,
9.00399303436279, 5.48189449310303, 5.9071044921875, 5.30881881713867,
8.68398857116699, 8.68398857116699, 4.32339859008789, 8.57950687408447,
6.78787326812744, 8.68624305725098, 8.68624305725098, 12.9021902084351,
6.14854049682617, 6.71301507949829, 7.50605535507202, 7.33758926391602,
8.11069011688232, 7.33758926391602, 8.11069011688232, 8.11069011688232,
6.59299898147583, 5.92181205749512, 8.11069011688232, 7.33758926391602,
9.29954528808594, 7.33758926391602, 8.31999015808105, 7.33758926391602,
6.59299898147583, 6.16447877883911, 5.83903217315674), ts1 = c(4.19949150085449,
2.46556353569031, 3.96805644035339, 9.05560302734375, 9.5199556350708,
1.18671488761902, 6.60286664962769, 9.5199556350708, 9.5199556350708,
9.5199556350708, 9.5199556350708, 9.5199556350708, 2.12847352027893,
9.05560302734375, 9.5199556350708, 9.05560302734375, 2.11432313919067,
6.49393510818481, -0.165110915899277, 7.78503036499023, -7.71160411834717,
-0.979450941085815, 4.96369075775146, 4.28496122360229, 4.28496122360229,
6.35976600646973, 3.02656149864197, 2.80754446983337, 5.94739389419556,
5.94739389419556, 8.70161914825439, 1.57025468349457, 5.08782005310059,
4.27688789367676, 9.5199556350708, 8.49832916259766, 9.5199556350708,
8.49832916259766, 8.49832916259766, 9.05560302734375, 6.33359289169312,
8.49832916259766, 9.5199556350708, 7.99740839004517, 9.5199556350708,
2.12847352027893, 9.5199556350708, 9.05560302734375, 2.67069268226624,
7.33829879760742), ts2 = c(9.89923763275146, 10.9084701538086,
9.61682415008545, 13.6253662109375, 13.8121919631958, 6.19518041610718,
9.40560817718506, 13.8121919631958, 13.8121919631958, 13.8121919631958,
13.8121919631958, 13.8121919631958, 10.3912172317505, 13.6253662109375,
13.8121919631958, 13.6253662109375, 9.77112770080566, 11.5460777282715,
8.18180465698242, 12.9412984848022, 2.54625177383423, 8.29829216003418,
10.6650953292847, 10.1770324707031, 10.1770324707031, 12.4333782196045,
8.98324680328369, 8.45312309265137, 9.23384857177734, 9.23384857177734,
11.371600151062, 8.09108352661133, 12.0714511871338, 11.385799407959,
13.8121919631958, 13.912787437439, 13.8121919631958, 13.912787437439,
13.912787437439, 13.6253662109375, 12.0018119812012, 13.912787437439,
13.8121919631958, 14.0190010070801, 13.8121919631958, 10.3912172317505,
13.8121919631958, 13.6253662109375, 8.53981018066406, 12.7294788360596
), ts3 = c(17.718994140625, 21.1172523498535, 17.8669090270996,
23.1215572357178, 22.9536685943604, 15.3891229629517, 15.7000684738159,
22.9536685943604, 22.9536685943604, 22.9536685943604, 22.9536685943604,
22.9536685943604, 20.1229286193848, 23.1215572357178, 22.9536685943604,
23.1215572357178, 19.8251171112061, 19.3250198364258, 16.8351039886475,
22.2966594696045, 14.6743259429932, 17.1554985046387, 20.1656894683838,
20.0012702941895, 20.0012702941895, 23.2738876342773, 18.6255321502686,
16.2553405761719, 16.551155090332, 16.551155090332, 17.6266174316406,
16.1711521148682, 22.280725479126, 21.450382232666, 22.9536685943604,
23.5616970062256, 22.9536685943604, 23.5616970062256, 23.5616970062256,
23.1215572357178, 22.1113948822021, 23.5616970062256, 22.9536685943604,
23.5085678100586, 22.9536685943604, 20.1229286193848, 22.9536685943604,
23.1215572357178, 16.3595314025879, 22.7737102508545), ts4 = c(11.661883354187,
12.7669324874878, 11.6320190429688, 17.2357921600342, 17.4911460876465,
9.09537506103516, 12.179615020752, 17.4911460876465, 17.4911460876465,
17.4911460876465, 17.4911460876465, 17.4911460876465, 12.0781927108765,
17.2357921600342, 17.4911460876465, 17.2357921600342, 11.9486837387085,
13.7441387176514, 8.9575023651123, 15.9984045028687, 4.02816677093506,
9.12790489196777, 13.0505475997925, 12.842321395874, 12.842321395874,
14.8937959671021, 11.5566177368164, 10.0515727996826, 12.2921047210693,
12.2921047210693, 14.2251281738281, 9.64802074432373, 14.6072359085083,
13.7993869781494, 17.4911460876465, 17.0232067108154, 17.4911460876465,
17.0232067108154, 17.0232067108154, 17.2357921600342, 15.045259475708,
17.0232067108154, 17.4911460876465, 16.7633666992188, 17.4911460876465,
12.0781927108765, 17.4911460876465, 17.2357921600342, 10.0954942703247,
15.9187803268433), ps1sq = c(26.5076465606689, 22.2693958282471,
63.1422576904297, 112.398139953613, 126.182060241699, 83.3481597900391,
160.11540222168, 126.182060241699, 126.182060241699, 126.182060241699,
126.182060241699, 126.182060241699, 35.2550506591797, 112.398139953613,
126.182060241699, 112.398139953613, 63.3266563415527, 82.4000778198242,
18.478443145752, 68.4726028442383, 10.5714654922485, 20.3456344604492,
40.2613716125488, 44.3825721740723, 44.3825721740723, 22.58620262146,
39.5463447570801, 40.1031150817871, 107.331176757812, 107.331176757812,
350.305908203125, 32.8693962097168, 62.8768272399902, 82.7779006958008,
126.182060241699, 109.109313964844, 126.182060241699, 109.109313964844,
109.109313964844, 112.398139953613, 84.4768295288086, 109.109313964844,
126.182060241699, 122.418785095215, 126.182060241699, 35.2550506591797,
126.182060241699, 112.398139953613, 36.7173538208008, 91.480094909668
), ps2sq = c(27.3646068572998, 23.695915222168, 59.560977935791,
18.9136600494385, 20.1265487670898, 91.6154174804688, 70.2537155151367,
20.1265487670898, 20.1265487670898, 20.1265487670898, 20.1265487670898,
20.1265487670898, 47.2242088317871, 18.9136600494385, 20.1265487670898,
18.9136600494385, 38.5618858337402, 56.9987602233887, 31.6457366943359,
31.0436763763428, 9.54527759552002, 44.4674682617188, 19.5158863067627,
37.4422874450684, 37.4422874450684, 16.5555210113525, 40.439151763916,
32.6289215087891, 73.1417770385742, 73.1417770385742, 141.566955566406,
30.1786651611328, 28.5986976623535, 37.5058479309082, 20.1265487670898,
28.0557479858398, 20.1265487670898, 28.0557479858398, 28.0557479858398,
18.9136600494385, 20.3749599456787, 28.0557479858398, 20.1265487670898,
35.8471832275391, 20.1265487670898, 47.2242088317871, 20.1265487670898,
18.9136600494385, 31.1822872161865, 19.5749683380127), ps3sq =
c(24.5653991699219,
12.27476978302, 36.1357040405273, 0.72475278377533, 0.666339039802551,
64.6101531982422, 30.9392681121826, 0.666339039802551, 0.666339039802551,
0.666339039802551, 0.666339039802551, 0.666339039802551, 36.2002906799316,
0.72475278377533, 0.666339039802551, 0.72475278377533, 11.9318141937256,
28.2917289733887, 55.614875793457, 11.1645088195801, 43.7546501159668,
126.437408447266, 4.82320165634155, 28.063304901123, 28.063304901123,
2.6669340133667, 30.3901672363281, 46.0446548461914, 20.552619934082,
20.552619934082, 18.6443767547607, 50.5468521118164, 5.39163303375244,
7.55398797988892, 0.666339039802551, 2.17771244049072, 0.666339039802551,
2.17771244049072, 2.17771244049072, 0.72475278377533, 1.93400263786316,
2.17771244049072, 0.666339039802551, 3.42490386962891, 0.666339039802551,
36.2002906799316, 0.666339039802551, 0.72475278377533, 45.9697532653809,
1.46579575538635), ps4sq = c(32.1111907958984, 23.2654228210449,
54.7733688354492, 43.4676361083984, 53.840217590332, 99.6012649536133,
108.074615478516, 53.840217590332, 53.840217590332, 53.840217590332,
53.840217590332, 53.840217590332, 69.2222366333008, 43.4676361083984,
53.840217590332, 43.4676361083984, 49.811279296875, 70.2821273803711,
22.5957069396973, 81.071891784668, 30.0511665344238, 34.8938827514648,
28.183557510376, 75.4116592407227, 75.4116592407227, 18.6917762756348,
73.6079406738281, 46.0752220153809, 75.4508209228516, 75.4508209228516,
166.466506958008, 37.8045501708984, 45.0645713806152, 56.3408660888672,
53.840217590332, 65.7832946777344, 53.840217590332, 65.7832946777344,
65.7832946777344, 43.4676361083984, 35.0678596496582, 65.7832946777344,
53.840217590332, 86.4815444946289, 53.840217590332, 69.2222366333008,
53.840217590332, 43.4676361083984, 38.0007972717285, 34.094295501709
), ts1sq = c(17.6357288360596, 6.07900333404541, 15.7454719543457,
82.0039443969727, 90.6295547485352, 1.40829217433929, 43.5978469848633,
90.6295547485352, 90.6295547485352, 90.6295547485352, 90.6295547485352,
90.6295547485352, 4.53039932250977, 82.0039443969727, 90.6295547485352,
82.0039443969727, 4.47036218643188, 42.1711921691895, 0.0272616147994995,
60.6066970825195, 59.4688377380371, 0.95932412147522, 24.6382255554199,
18.3608932495117, 18.3608932495117, 40.4466247558594, 9.16007423400879,
7.88230609893799, 35.3714942932129, 35.3714942932129, 75.7181777954102,
2.46569967269897, 25.8859119415283, 18.2917709350586, 90.6295547485352,
72.2215957641602, 90.6295547485352, 72.2215957641602, 72.2215957641602,
82.0039443969727, 40.1143989562988, 72.2215957641602, 90.6295547485352,
63.9585418701172, 90.6295547485352, 4.53039932250977, 90.6295547485352,
82.0039443969727, 7.13259935379028, 53.8506278991699), ts2sq =
c(97.9949035644531,
118.994720458984, 92.4833068847656, 185.650604248047, 190.776641845703,
38.3802604675293, 88.465461730957, 190.776641845703, 190.776641845703,
190.776641845703, 190.776641845703, 190.776641845703, 107.977394104004,
185.650604248047, 190.776641845703, 185.650604248047, 95.4749374389648,
133.311904907227, 66.9419250488281, 167.477203369141, 6.48339796066284,
68.8616561889648, 113.744255065918, 103.571990966797, 103.571990966797,
154.588897705078, 80.6987228393555, 71.4552917480469, 85.2639617919922,
85.2639617919922, 129.313293457031, 65.4656295776367, 145.719940185547,
129.636428833008, 190.776641845703, 193.565658569336, 190.776641845703,
193.565658569336, 193.565658569336, 185.650604248047, 144.043487548828,
193.565658569336, 190.776641845703, 196.53239440918, 190.776641845703,
107.977394104004, 190.776641845703, 185.650604248047, 72.9283599853516,
162.039627075195), ts3sq = c(313.962768554688, 445.938354492188,
319.226440429688, 534.606384277344, 526.870910644531, 236.825103759766,
246.492156982422, 526.870910644531, 526.870910644531, 526.870910644531,
526.870910644531, 526.870910644531, 404.932250976562, 534.606384277344,
526.870910644531, 534.606384277344, 393.035278320312, 373.456390380859,
283.420715332031, 497.141021728516, 215.335845947266, 294.311126708984,
406.655029296875, 400.050811767578, 400.050811767578, 541.673828125,
346.910461425781, 264.236083984375, 273.940734863281, 273.940734863281,
310.697631835938, 261.506164550781, 496.430725097656, 460.118896484375,
526.870910644531, 555.153564453125, 526.870910644531, 555.153564453125,
555.153564453125, 534.606384277344, 488.913787841797, 555.153564453125,
526.870910644531, 552.652770996094, 526.870910644531, 404.932250976562,
526.870910644531, 534.606384277344, 267.63427734375, 518.641906738281
), ts4sq = c(135.999526977539, 162.994567871094, 135.303863525391,
297.072540283203, 305.940185546875, 82.7258453369141, 148.343017578125,
305.940185546875, 305.940185546875, 305.940185546875, 305.940185546875,
305.940185546875, 145.882736206055, 297.072540283203, 305.940185546875,
297.072540283203, 142.771041870117, 188.901351928711, 80.2368469238281,
255.948944091797, 16.2261276245117, 83.3186492919922, 170.316787719727,
164.925216674805, 164.925216674805, 221.825164794922, 133.555419921875,
101.034118652344, 151.095840454102, 151.095840454102, 202.354278564453,
93.0843048095703, 213.371337890625, 190.423080444336, 305.940185546875,
289.789581298828, 305.940185546875, 289.789581298828, 289.789581298828,
297.072540283203, 226.359832763672, 289.789581298828, 305.940185546875,
281.010467529297, 305.940185546875, 145.882736206055, 305.940185546875,
297.072540283203, 101.919006347656, 253.407562255859), pdnsty =
c(0.616999983787537,
0.0850000008940697, 0.068000003695488, 0.025000000372529, 0.0549999997019768,
0.0230000000447035, 0.133000001311302, 0.0549999997019768, 0.0549999997019768,
0.0549999997019768, 0.0549999997019768, 0.0549999997019768, 0.25900000333786,
0.025000000372529, 0.0549999997019768, 0.025000000372529, 0.0140000004321337,
0.14300000667572, 0.140000000596046, 0.777999997138977, 0.0329999998211861,
0.316000014543533, 0.0179999992251396, 0.105999998748302, 0.105999998748302,
0.046000000089407, 0.108000002801418, 0.310999989509583, 0.101000003516674,
0.101000003516674, 0.14300000667572, 0.168999999761581, 0.0439999997615814,
0.0379999987781048, 0.0549999997019768, 0.063000001013279, 0.0549999997019768,
0.063000001013279, 0.063000001013279, 0.025000000372529, 0.0640000030398369,
0.063000001013279, 0.0549999997019768, 0.209000006318092, 0.0549999997019768,
0.25900000333786, 0.0549999997019768, 0.025000000372529, 0.257999986410141,
0.0469999983906746), portsML = c(0.0900330692529678, 0.0604440234601498,
0.168490216135979, 0.275995850563049, 0.269018620252609, 0.175392478704453,
0.0350189469754696, 0.269018620252609, 0.269018620252609, 0.269018620252609,
0.269018620252609, 0.269018620252609, 0.11026918143034, 0.275995850563049,
0.269018620252609, 0.275995850563049, 0.145082741975784, 0.00440915673971176,
0.426146239042282, 0.0686663240194321, 0.103511147201061, 0.289726078510284,
0.234196603298187, 0.123688526451588, 0.123688526451588, 0.315173029899597,
0.112561739981174, 0.0461684986948967, 0.179993003606796, 0.179993003606796,
0.0438785217702389, 0.096462681889534, 0.0934395045042038, 0.121217466890812,
0.269018620252609, 0.212490051984787, 0.269018620252609, 0.212490051984787,
0.212490051984787, 0.275995850563049, 0.162760972976685, 0.212490051984787,
0.269018620252609, 0.270619571208954, 0.269018620252609, 0.11026918143034,
0.269018620252609, 0.275995850563049, 0.108705826103687, 0.196496397256851
), cities500k = c(0.0360943526029587, 0.0577861145138741, 0.183606043457985,
0.150749072432518, 0.185974538326263, 0.0923599153757095, 0.353672504425049,
0.185974538326263, 0.185974538326263, 0.185974538326263, 0.185974538326263,
0.185974538326263, 0.0887016654014587, 0.150749072432518, 0.185974538326263,
0.150749072432518, 0.144800990819931, 0.00326321297325194, 0.0622526630759239,
0.00816718116402626, 0.181859150528908, 0.163181975483894, 0.204970955848694,
0.129742562770844, 0.129742562770844, 0.0783679932355881, 0.0559677332639694,
0.0293320622295141, 0.248573184013367, 0.248573184013367, 0.174525216221809,
0.092569001019001, 0.176346719264984, 0.16088992357254, 0.185974538326263,
0.280431807041168, 0.185974538326263, 0.280431807041168, 0.280431807041168,
0.150749072432518, 0.088722825050354, 0.280431807041168, 0.185974538326263,
0.189705356955528, 0.185974538326263, 0.0887016654014587, 0.185974538326263,
0.150749072432518, 0.0712414756417274, 0.0842432081699371), rentedland
= c(0.571943998336792,
0, 0.5929936170578, 0, 0, 0.755691230297089, 0.440930217504501,
0, 0, 0, 0.229885056614876, 0, 0, 0, 0, 0, 0.890581607818604,
0.212423488497734, 0.386227518320084, 0, 0.11130790412426, 0.483032256364822,
0.444395005702972, 0, 0, 0.253378361463547, 0, 0.10909091681242,
0.181818187236786, 0.666666686534882, 0, 0.94951194524765, 0.846153855323792,
0.403846144676208, 0, 0, 0.155963316559792, 0, 0, 0.408163279294968,
0.699570834636688, 0, 0, 0, 0, 0, 0.0476190522313118, 0, 0, 0
), subsidies1 = c(361.835754394531, 0, 368.242034912109, 345.636352539062,
701.746032714844, 488.922821044922, 344.918609619141, 790.392150878906,
795.3125, 631.666687011719, 193.563217163086, 565.75, 0, 577.586181640625,
395.681823730469, 192, 371.963653564453, 9.9977331161499, 310.838317871094,
905.764709472656, 1745.76293945312, 359.003814697266, 163.204330444336,
427.94970703125, 204.842727661133, 52.2592887878418, 0, 0, 3022.24243164062,
80.2666702270508, 445.366577148438, 925.681640625, 824.769226074219,
625.192321777344, 850.441162109375, 280.891723632812, 619.266052246094,
333.962249755859, 376.304351806641, 317.551025390625, 166.652359008789,
171.224487304688, 526.119445800781, 253.191497802734, 334.470581054688,
107.277839660645, 431.428588867188, 0, 107.245544433594, 339.701507568359
), elevmean = c(0.121736958622932, 0.46412268280983, 0.344255149364471,
0.466430068016052, 0.43000802397728, 1.15364873409271, 0.0955904126167297,
0.43000802397728, 0.43000802397728, 0.43000802397728, 0.43000802397728,
0.43000802397728, 0.370405077934265, 0.466430068016052, 0.43000802397728,
0.466430068016052, 0.849120080471039, 0.0433186627924442, 0.335433751344681,
0.271958351135254, 0.125564843416214, 0.376024007797241, 0.815701544284821,
0.525435268878937, 0.525435268878937, 0.62959760427475, 0.518330037593842,
0.00362438289448619, 0.628515422344208, 0.628515422344208, 0.274942100048065,
0.0728112533688545, 0.496583759784698, 0.739268243312836, 0.43000802397728,
0.321640431880951, 0.43000802397728, 0.321640431880951, 0.321640431880951,
0.466430068016052, 0.585907399654388, 0.321640431880951, 0.43000802397728,
0.147326037287712, 0.43000802397728, 0.370405077934265, 0.43000802397728,
0.466430068016052, 0.0183117985725403, 0.414920538663864), elevrange =
c(0.180000007152557,
1.99300003051758, 0.611000001430511, 2.35199999809265, 2.29999995231628,
2.94199991226196, 0.354999989271164, 2.29999995231628, 2.29999995231628,
2.29999995231628, 2.29999995231628, 2.29999995231628, 2.01799988746643,
2.35199999809265, 2.29999995231628, 2.35199999809265, 1.7389999628067,
0.160999998450279, 0.314000010490417, 1.76300001144409, 0.17399999499321,
0.653999984264374, 1.63399994373322, 2.19099998474121, 2.19099998474121,
1.14100003242493, 1.34800004959106, 0.00899999961256981, 2.41300010681152,
2.41300010681152, 0.787999987602234, 0.26800000667572, 1.92200005054474,
2.02600002288818, 2.29999995231628, 1.05099999904633, 2.29999995231628,
1.05099999904633, 1.05099999904633, 2.35199999809265, 2.35999989509583,
1.05099999904633, 2.29999995231628, 0.772000014781952, 2.29999995231628,
2.01799988746643, 2.29999995231628, 2.35199999809265, 0.0649999976158142,
1.75399994850159), t_gravel = c(4.58953237533569, 13.3146963119507,
10.0136280059814, 13.8894920349121, 13.9366893768311, 13.5653190612793,
7.71220588684082, 13.9366893768311, 13.9366893768311, 13.9366893768311,
13.9366893768311, 13.9366893768311, 11.4818019866943, 13.8894920349121,
13.9366893768311, 13.8894920349121, 13.4321727752686, 5.71388387680054,
8.03888702392578, 9.01077747344971, 4.58924961090088, 8.14134693145752,
11.8983144760132, 9.96716785430908, 9.96716785430908, 11.1739711761475,
10.4019403457642, 5.16821479797363, 10.7357034683228, 10.7357034683228,
9.23897457122803, 4.3336238861084, 10.9520101547241, 12.9722995758057,
13.9366893768311, 13.1780118942261, 13.9366893768311, 13.1780118942261,
13.1780118942261, 13.8894920349121, 12.7335777282715, 13.1780118942261,
13.9366893768311, 12.315260887146, 13.9366893768311, 11.4818019866943,
13.9366893768311, 13.8894920349121, 6.68424606323242, 14.101095199585
), t_ph_h2o = c(6.07352828979492, 6.72695684432983, 5.60523176193237,
6.13967752456665, 6.86059141159058, 7.40929126739502, 5.68151950836182,
6.86059141159058, 6.86059141159058, 6.86059141159058, 6.86059141159058,
6.86059141159058, 6.51894521713257, 6.13967752456665, 6.86059141159058,
6.13967752456665, 6.98909568786621, 5.5628228187561, 6.68793487548828,
6.57724285125732, 4.67033195495605, 6.32772016525269, 6.4612717628479,
6.73934555053711, 6.73934555053711, 6.80293703079224, 6.17414236068726,
7.03696584701538, 5.93052577972412, 5.93052577972412, 5.43228578567505,
5.5989408493042, 6.86088180541992, 6.68706750869751, 6.86059141159058,
6.00043678283691, 6.86059141159058, 6.00043678283691, 6.00043678283691,
6.13967752456665, 6.89467239379883, 6.00043678283691, 6.86059141159058,
6.81896543502808, 6.86059141159058, 6.51894521713257, 6.86059141159058,
6.13967752456665, 5.63159275054932, 6.13170003890991), t_silt =
c(34.2329025268555,
33.4969100952148, 34.4774589538574, 27.8914813995361, 31.9258117675781,
39.6254501342773, 34.7939414978027, 31.9258117675781, 31.9258117675781,
31.9258117675781, 31.9258117675781, 31.9258117675781, 26.6626663208008,
27.8914813995361, 31.9258117675781, 27.8914813995361, 29.7444763183594,
21.3432540893555, 37.4038734436035, 28.1513748168945, 19.4936828613281,
33.5968360900879, 32.8024406433105, 33.313850402832, 33.313850402832,
28.3197917938232, 33.3154563903809, 38.103458404541, 36.0389099121094,
36.0389099121094, 34.9229164123535, 26.5577545166016, 30.9245643615723,
31.1334323883057, 31.9258117675781, 27.1493148803711, 31.9258117675781,
27.1493148803711, 27.1493148803711, 27.8914813995361, 31.3038387298584,
27.1493148803711, 31.9258117675781, 31.6541061401367, 31.9258117675781,
26.6626663208008, 31.9258117675781, 27.8914813995361, 15.6523361206055,
27.803352355957), t_sand = c(47.0063323974609, 37.0355186462402,
45.8286781311035, 36.0810203552246, 39.9931793212891, 39.3664970397949,
46.2948226928711, 39.9931793212891, 39.9931793212891, 39.9931793212891,
39.9931793212891, 39.9931793212891, 49.3508529663086, 36.0810203552246,
39.9931793212891, 36.0810203552246, 39.2436943054199, 65.7813262939453,
35.8039131164551, 51.2884674072266, 66.2952728271484, 46.6789817810059,
41.4505424499512, 44.4590721130371, 44.4590721130371, 48.7276763916016,
43.3654098510742, 33.999683380127, 43.040699005127, 43.040699005127,
43.2519073486328, 59.4827156066895, 43.8675765991211, 41.7124671936035,
39.9931793212891, 34.94921875, 39.9931793212891, 34.94921875,
34.94921875, 36.0810203552246, 39.1853942871094, 34.94921875,
39.9931793212891, 39.8589019775391, 39.9931793212891, 49.3508529663086,
39.9931793212891, 36.0810203552246, 75.7048721313477, 33.5687866210938
), AT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), BE = c(0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0), DE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), DK = c(0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0), ES = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), FI = c(0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0), FR = c(1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), GR = c(0, 1, 0,
1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
0, 1, 1, 0, 1), IE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), IT = c(0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 1, 0, 0, 0, 0), LU = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), NL = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 1, 0), PT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SE = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), WDE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), EDE = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), UK = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CY = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), BG = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CZ = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), EE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), HU = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), LT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), LV = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), PL = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), RO = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), SI = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SK = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), b48 = c(70, 2.70000004768372, 63.9000015258789,
5.5, 6.30000019073486, 8.80000019073486, 48.0800018310547, 5.09999990463257,
6.40000009536743, 6, 6.69999980926514, 4, 6.30000019073486, 5.80000019073486,
8.80000019073486, 2, 13, 0.5, 10.25, 34, 65.2300033569336, 37.7799987792969,
74.9400024414062, 31.0200004577637, 20.0300006866455, 70.7200012207031,
40, 4.90000009536743, 13.5, 5, 26.8700008392334, 3, 2, 3.09999990463257,
6.80000019073486, 15.6999998092651, 9.19999980926514, 5.30000019073486,
4.59999990463257, 17.3999996185303, 7, 4.90000009536743, 13.3999996185303,
2.34999990463257, 8.5, 24.8700008392334, 4, 1.39999997615814,
34.7799987792969, 6.69999980926514), b50 = c(0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34.2400016784668, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), irrigation = c(0, 100, 0, 5.45454584062099,
7.9365074634552, 89.3392562866211, 0, 17.6470592617989, 0, 0,
65.5172407627106, 0, 61.904764175415, 34.4827562570572, 7.95454531908035,
75, 0, 0, 0, 0, 0, 0, 5.26393800973892, 0, 0, 0, 0, 0, 0, 0,
0, 0, 74.6153831481934, 84.6153914928436, 0, 5.09554147720337,
0, 0, 0, 21.0884347558022, 18.4549376368523, 6.1224490404129,
25.3731369972229, 2.12765969336033, 0, 84.3988716602325, 0, 0,
0, 100), awc_class = c(106.228088378906, 78.2306137084961, 80.9311141967773,
32.4921531677246, 54.8475151062012, 80.6665878295898, 116.331588745117,
54.8475151062012, 54.8475151062012, 54.8475151062012, 54.8475151062012,
54.8475151062012, 56.3101806640625, 32.4921531677246, 54.8475151062012,
32.4921531677246, 59.3034172058105, 101.193893432617, 96.5840377807617,
54.2786560058594, 87.1388244628906, 66.1907730102539, 57.205738067627,
55.4114303588867, 55.4114303588867, 80.9288787841797, 63.6008758544922,
150, 30.3404140472412, 30.3404140472412, 19.8318557739258, 104.236854553223,
79.2445755004883, 57.0045547485352, 54.8475151062012, 34.320426940918,
54.8475151062012, 34.320426940918, 34.320426940918, 32.4921531677246,
65.1337509155273, 34.320426940918, 54.8475151062012, 73.6748657226562,
54.8475151062012, 56.3101806640625, 54.8475151062012, 32.4921531677246,
127.726959228516, 27.9528160095215), sys02 = c(18.8571434020996,
303.529418945312, 30.2469139099121, 104.305557250977, 86.4935073852539,
51.25, 83.0927810668945, 453.118286132812, 42.5, 104.305557250977,
48.461540222168, 86.4935073852539, 55.1851844787598, 104.305557250977,
104.305557250977, 185.277770996094, 17.9775276184082, 25.2777786254883,
64, 21.6666660308838, 30, 24.2372875213623, 47.0285720825195,
16.1904754638672, 33.75, 22.5423736572266, 10.2857141494751,
39.230770111084, 6.06741571426392, 1, 28.3255805969238, 21.6000003814697,
69.2592620849609, 86.6666641235352, 48.5185203552246, 44.4186058044434,
48.6538467407227, 437.105255126953, 437.105255126953, 19.1666660308838,
48.461540222168, 437.105255126953, 48.6538467407227, 453.118286132812,
48.6538467407227, 14.2857141494751, 453.118286132812, 453.118286132812,
95.2380981445312, 63), se025 = c(163.529998779297, 2.70000004768372,
157, 5.5, 6.30000019073486, 36.0200004577637, 86, 5.09999990463257,
6.40000009536743, 6, 8.69999980926514, 4, 6.30000019073486, 5.80000019073486,
8.80000019073486, 2, 118.809997558594, 44.1100006103516, 16.7000007629395,
34, 73.4000015258789, 73.0800018310547, 134.880004882812, 31.0200004577637,
20.0300006866455, 94.7200012207031, 40, 5.5, 16.5, 15, 26.8700008392334,
59.4199981689453, 13, 5.19999980926514, 6.80000019073486, 15.6999998092651,
10.8999996185303, 5.30000019073486, 4.59999990463257, 29.3999996185303,
23.2999992370605, 4.90000009536743, 13.3999996185303, 2.34999990463257,
8.5, 24.8700008392334, 4.19999980926514, 1.39999997615814, 34.7799987792969,
6.69999980926514)), .Names = c("LnALVperHA", "ps1", "ps2", "ps3",
"ps4", "ts1", "ts2", "ts3", "ts4", "ps1sq", "ps2sq", "ps3sq",
"ps4sq", "ts1sq", "ts2sq", "ts3sq", "ts4sq", "pdnsty", "portsML",
"cities500k", "rentedland", "subsidies1", "elevmean", "elevrange",
"t_gravel", "t_ph_h2o", "t_silt", "t_sand", "AT", "BE", "DE",
"DK", "ES", "FI", "FR", "GR", "IE", "IT", "LU", "NL", "PT", "SE",
"WDE", "EDE", "UK", "CY", "BG", "CZ", "EE", "HU", "LT", "LV",
"PL", "RO", "SI", "SK", "b48", "b50", "irrigation", "awc_class",
"sys02", "se025"), row.names = c("2", "3", "4", "5", "6", "7",
"8", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
"21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31",
"32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
"43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53"
), class = "data.frame")



























2015-08-14 14:58 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz>:
>
> Hi Janka
>
>
>
> Sorry, but we are limited in connecting to web services so I am not able to restore your data and see your code. Result of dput(somedata) coppied to email is preferable for sharing data and code can be copied to email too. But do not use HTML as it usually scrambles  text.
>
>
>
> Answer in line
>
>
>
> From: Janka Vanschoenwinkel [mailto:janka.vanschoenwinkel at uhasselt.be]
> Sent: Friday, August 14, 2015 2:17 PM
> To: Thierry Onkelinx; PIKAL Petr
> Cc: r-help at r-project.org
> Subject: Re: [R] cut variable within a loop
>
>
>
> Hi Thierry and Petr,
>
>
>
> I really appreciate the comments you already gave. Thank you very much for that.
>
>
>
> Below you can find a link to the data and the code. Hopefully this helps in spotting the error.
>
>
>
> I still think the issue is that the cut2 function only accepts numbers, and not an "i" that refers to the number at the start of the loop. To answer Petr his question, yes, column 3 and 4 are NA (these are the columns of the second interval). But I don't really understand your point so could you clarify this please?
>
>
>
> If you use NA as a number of intervals you will get such errors
>
>
>
> k<-c(2,4,NA,5)
>
> ii<-vector(4, mode="list")
>
> for (i in 1:4) {
>
> ii[[i]] <- cut2(iris[,i], k[i])
>
> }
>
> Error in if (r[1] < cuts[1]) cuts <- c(r[1], cuts) :
>
>   missing value where TRUE/FALSE needed
>
> for (i in 1:4) {
>
> ii[[i]] <- cut(iris[,i], k[i])
>
> }
>
> Error in cut.default(iris[, i], k[i]) : invalid number of intervals
>
>
>
> If you remove NA from k definition error is gone.
>
> k<-c(2,4,3,5)
>
> ii<-vector(4, mode="list")
>
>
>
> for (i in 1:4) {
>
> ii[[i]] <- cut(iris[,i], k[i])
>
> }
>
>
>
> You can try it yourself. The error is not related to cycle; whenever number of intervals in cut call is NA you always get an error.
>
>
>
> Cheers
>
> Petr
>
>
>
> https://drive.google.com/folderview?id=0By9u5m3kxn9yfkxxeVNMdnRQQXhoT05CRlJlZVBCWWF2NURMMTNmVFVFeXJXXzhlMWE4SUk&usp=sharing
>
>
>
> Thank you very much once again!
>
>
>
> Janka
>
>
>
>
>
>
>
> 2015-08-11 15:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
> You'll need to send a reproducible example of the code. We can't run the code that you send. Hence it is hard to help you. See e.g. http://adv-r.had.co.nz/Reproducibility.html
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>
>
>
> 2015-08-11 14:57 GMT+02:00 Janka Vanschoenwinkel <janka.vanschoenwinkel at uhasselt.be>:
>
> Hi Thierry!
>
>
>
> Thanks for your answer. I tried this, but I get this error:
>
>
>
> "Error in cut.default(x, k2) : invalid number of intervals"
>
>
>
> Which is strange because I am not specifying intervals, but the number at where the sample has to be cut?
>
>
>
> Greetings from Belgium! :-)
>
>
>
> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
> Dear Janka,
>
>
>
> You loop goes for 0 to 100. It should probably go from 1:99
>
>
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>
>
>
> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <janka.vanschoenwinkel at uhasselt.be>:
>
> Dear list members,
>
> I have a loop where I want to do several calculations for different samples
> and save the results for each sample. These samples are for each loop
> different. I want to use the "i" in the loop to cut the samples.
>
> So for instance:
>
>    - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>    - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>    - In loop 99 (i=99), I have a sample from 0-99 and a sample from 99-100.
>
> I built the following function, but there is *a problem with the cut2
> function* since it doesn't recognize the "i". Outside the lapply loop it
> works, but not inside the loop.
>
> Could somebody please help me with this problem? Thanks a lot!
>
>
> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>
>
>
>     o<-lapply(0:100, function(i){
>
>
>
>         Alldata$irri=cut2(Alldata$irrigation,i)
>
>         levels(Alldata$irri)<-c("0","1")
>
>
>
>        Alldata_Rainfed<-subset(Alldata, irri == 0)
>
>        Alldata_Irrigation<-subset(Alldata, irri == 1)
>
>
>
>     #calculations per sample, then store all the values per i and per
> variable in a dataframe: (the calculations are not shown in this example)
>
>
>
>      d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>
>
>
>    })
>
>
>
>    out<-as.data.frame(do.call(rbind, o))
>
>
> --
> P Please consider the environment before printing this e-mail
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
> --
>
>
>
> Mevrouw Janka Vanschoenwinkel
> Doctoraatsbursaal - PhD
> Milieueconomie - Environmental economics
>
> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
>
> www.uhasselt.be/eec
>
> Universiteit Hasselt | Campus Diepenbeek
> Agoralaan Gebouw D | B-3590 Diepenbeek
> Kantoor F11
>
> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>
> P Please consider the environment before printing this e-mail
>
>
>
>
>
>
>
>
>
> --
>
>
>
> Mevrouw Janka Vanschoenwinkel
> Doctoraatsbursaal - PhD
> Milieueconomie - Environmental economics
>
> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
>
> www.uhasselt.be/eec
>
> Universiteit Hasselt | Campus Diepenbeek
> Agoralaan Gebouw D | B-3590 Diepenbeek
> Kantoor F11
>
> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>
> P Please consider the environment before printing this e-mail
>
>
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.




--

Mevrouw Janka Vanschoenwinkel
Doctoraatsbursaal - PhD
Milieueconomie - Environmental economics

T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt

P Please consider the environment before printing this e-mail


From pingpong.tktan at gmail.com  Fri Aug 14 11:20:40 2015
From: pingpong.tktan at gmail.com (Teck Kiang Tan)
Date: Fri, 14 Aug 2015 17:20:40 +0800
Subject: [R] lme4 package installation
In-Reply-To: <55CD7CB1.1030306@statistik.tu-dortmund.de>
References: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>
	<CAJuCY5yWc3uCVCkR1qwUgJUPuCrHi81848tEG1mjEhrzUwZrHw@mail.gmail.com>
	<CAGetN7VCYb-OuQOjSGugdPxNrqhx68KrLA0OBKPTZQVbG9GMVA@mail.gmail.com>
	<55CD7CB1.1030306@statistik.tu-dortmund.de>
Message-ID: <CAGetN7UC43++ipv1CAKje48pxpF+JMS0v7z1oQ4AUBaGzsqrTQ@mail.gmail.com>

Thanks Uwe Ligges for the suggestion.
I tried using setInternet2() but also failed.
I tried for several other countries but also failed.
Any other suggestion to overcome it.
Thanks.


Warning: unable to access index for repository
http://cran.utstat.utoronto.ca/src/contrib
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/src/contrib
Warning: unable to access index for repository
http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2


On Fri, Aug 14, 2015 at 1:29 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 13.08.2015 22:52, Teck Kiang Tan wrote:
>
>> Hi all
>>
>> I have problem in installation lme4 and have tried over the past 2 days.
>> It
>> failed to install from the various countries.
>>
>> install.packages("lme4")
>>>
>> Warning: unable to access index for repository
>> http://cran.stat.nus.edu.sg/src/contrib
>>
>
>
> This mirror does not respond whn I just tried, choose another one.
>
>
> Warning: unable to access index for repository
>> http://www.stats.ox.ac.uk/pub/RWin/src/contrib
>>
>
> This one works for me (but does not contain lme4).
> Perhaps also run setInternet2() before you try again in cae you need proxy
> settings.
>
> Best,
> Uwe Ligges
>
>
>
>
> Warning: unable to access index for repository
>> http://cran.stat.nus.edu.sg/bin/windows/contrib/3.2
>>
>> Warning message:
>> package ?lme4? is not available (for R version 3.2.1)
>>
>> Teck Kiang
>>
>>
>> On Thu, Aug 13, 2015 at 11:09 PM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be
>>
>>> wrote:
>>>
>>
>> Have you trying installing it directly from CRAN?
>>>
>>> install.packages("lme4")
>>>
>>> Do you have all dependencies installed? install.packages() from CRAN will
>>> take care of that. You repos = NULL you have to install all dependencies
>>> manually.
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and
>>> Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> 2015-08-13 16:13 GMT+02:00 <aurora.gonzalez at openmailbox.org>:
>>>
>>> Hello
>>>>
>>>> I've downloaded the tar.gz file of the package "lme4" and when I use the
>>>> coomand:
>>>>
>>>> install.packages("lme4_1.1-8.tar.gz", repos = NULL, type = "source")
>>>>
>>>> appears an error that suspends the installation:
>>>>
>>>>
>>>> In file included from external.cpp:8:0:
>>>> predModule.h:12:23: fatal error: RcppEigen.h: No such file or directory
>>>> compilation terminated.
>>>> make: *** [external.o] Error 1
>>>> ERROR: compilation failed for package ?lme4?
>>>> * removing ?/home/aurora/R/x86_64-pc-linux-gnu-library/3.2/lme4?
>>>>
>>>>
>>>>
>>>> Does anyone know how to fix it? Thank you very much!
>>>>
>>>>
>>>> My sessionInfo:
>>>>
>>>>
>>>> R version 3.2.1 (2015-06-18)
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>> Running under: Ubuntu precise (12.04.5 LTS)
>>>>
>>>> locale:
>>>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods
>>>> [7] base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] tools_3.2.1
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From sreenath.rajur at macfast.ac.in  Fri Aug 14 11:51:14 2015
From: sreenath.rajur at macfast.ac.in (sreenath)
Date: Fri, 14 Aug 2015 02:51:14 -0700 (PDT)
Subject: [R] Jaccard index
Message-ID: <1439545874063-4711111.post@n4.nabble.com>

sim(file_name,method="jaccard")
this command is giving the raw wise similarity matrix
how can i find column wise similarity matrix?
what is the command?
please help me



--
View this message in context: http://r.789695.n4.nabble.com/Jaccard-index-tp4711111.html
Sent from the R help mailing list archive at Nabble.com.


From sreenath.rajur at macfast.ac.in  Fri Aug 14 11:53:47 2015
From: sreenath.rajur at macfast.ac.in (sreenath)
Date: Fri, 14 Aug 2015 02:53:47 -0700 (PDT)
Subject: [R] Notched boxplot using R
In-Reply-To: <1439183108469-4710930.post@n4.nabble.com>
References: <1439183108469-4710930.post@n4.nabble.com>
Message-ID: <1439546027268-4711112.post@n4.nabble.com>

Instead of boxes use boxplot () then these values will be disappear 



--
View this message in context: http://r.789695.n4.nabble.com/Notched-boxplot-using-R-tp4710930p4711112.html
Sent from the R help mailing list archive at Nabble.com.


From luca.gaglia at gmail.com  Fri Aug 14 14:13:41 2015
From: luca.gaglia at gmail.com (Luca Gagliardone)
Date: Fri, 14 Aug 2015 14:13:41 +0200
Subject: [R] System exactly singular with pgmm (package plm)
Message-ID: <CAJW7ayP+jNXkrVRKDkJFuzx+Nn45TwtHpuCJcJ3h58FRj4YNAQ@mail.gmail.com>

his is my first post, I'll do my best to be clear and complete.

I am trying to run a pgmm regression (Arellano Bond estimator) following
the example online with the EmplUK dataset.

My dataset is unbalanced, with some missing values (that I also removed,
without any difference). This is the paste from R' dataframe.

 row.names ID   Year    p       I
    1   23  1   1992    NA      NA
    2   22  1   1993    17.01   NA
    3   21  1   1994    15.86   NA
    4   20  1   1995    17.02   7.512347
    5   19  1   1996    20.64   7.685104
    6   18  1   1997    19.11   12.730282
    7   17  1   1998    12.76   12.633871
    8   16  1   1999    17.90   7.416381
    9   15  1   2000    28.66   6.396114
    10  14  1   2001    24.46   9.213729
    11  13  1   2002    24.99   20.117159
    12  12  1   2003    28.85   11.117816
    13  11  1   2004    38.26   11.242638
    14  10  1   2005    54.57   13.015168
    15  9   1   2006    65.16   18.507212
    16  8   1   2007    72.44   18.875281
    17  7   1   2008    96.94   24.459170
    18  6   1   2009    61.74   21.332035
    19  5   1   2010    79.61   17.119038
    20  4   1   2011    111.26  16.941914
    21  3   1   2012    111.63  19.964875
    22  2   1   2013    108.56  28.863894
    23  1   1   2014    99.03   15.182615
    24  45  2   1993    17.01   NA
    25  44  2   1994    15.86   NA
    26  43  2   1995    17.02   NA
    27  42  2   1996    20.64   NA
    28  41  2   1997    19.11   NA
    29  40  2   1998    12.76   NA
    30  39  2   1999    17.90   11.428262
    31  38  2   2000    28.66   20.232613
    32  37  2   2001    24.46   25.811754
    33  36  2   2002    24.99   18.959958
    34  35  2   2003    28.85   20.767074
    35  34  2   2004    38.26   29.260406
    36  33  2   2005    54.57   25.837434
    37  32  2   2006    65.16   32.675618
    38  31  2   2007    72.44   48.415190
    39  30  2   2008    96.94   42.444435
    40  29  2   2009    61.74   40.047462
    41  28  2   2010    79.61   49.090816
    42  27  2   2011    111.26  53.828050
    43  26  2   2012    111.63  61.684020
    44  25  2   2013    108.56  68.394140
    45  24  2   2014    99.03   55.738584
    46  76  3   1984    NA      NA
    47  75  3   1985    NA      NA
    48  74  3   1986    NA      NA
    49  73  3   1987    18.53   NA
    50  72  3   1988    14.91   NA
    51  71  3   1989    18.23   NA
    52  70  3   1990    23.76   17.046268
    53  69  3   1991    20.04   30.191128
    54  68  3   1992    19.32   30.414108
    55  67  3   1993    17.01   27.916000
    56  66  3   1994    15.86   26.437651
    57  65  3   1995    17.02   25.895513
    58  64  3   1996    20.64   26.791996
    59  63  3   1997    19.11   30.074375
    60  62  3   1998    12.76   42.636103
    61  61  3   1999    17.90   46.862510
    62  60  3   2000    28.66   30.154079
    63  59  3   2001    24.46   30.297644
    64  58  3   2002    24.99   34.851205
    65  57  3   2003    28.85   38.854943
    66  56  3   2004    38.26   37.542447
    67  55  3   2005    54.57   38.456399
    68  54  3   2006    65.16   43.465535
    69  53  3   2007    72.44   41.749414
    70  52  3   2008    96.94   48.371262
    71  51  3   2009    61.74   54.914470
    72  50  3   2010    79.61   65.444964
    73  49  3   2011    111.26  76.888119
    74  48  3   2012    111.63  81.833602
    75  47  3   2013    108.56  83.800483
    76  46  3   2014    99.03   79.713947

my codes are the following:

data <- plm.data(Autoregression,index=c("ID","Year"))


Panel <- subset(data, !is.na(I) )

Are <- pgmm( I~p+lag( I , 0:1)
            | lag(I, 2:99),
            data = Panel, effect = "twoways", model = "onestep")

I have tried also many other versions, including every possible number of
the lags, shorter or longer.

The error is the following :

Errore in solve.default(crossprod(WX, t(crossprod(WX, A1)))) :
  Lapack routine dgesv: system is exactly singular: U[3,3] = 0
Inoltre: Warning message:
In pgmm(I ~ lag(I, 1) + p | lag(I, 2:10), Panel, effect = "twoways",  :
  the first-step matrix is singular, a general inverse is used

Can you please help me? Thanks for the attention, i'll wait for an answer

Regards, Luca.

	[[alternative HTML version deleted]]


From j.guilbert at auckland.ac.nz  Fri Aug 14 18:45:02 2015
From: j.guilbert at auckland.ac.nz (jgui001)
Date: Fri, 14 Aug 2015 09:45:02 -0700 (PDT)
Subject: [R] R map data for South Africa
Message-ID: <1439570702911-4711123.post@n4.nabble.com>

I am looking for some elevation data to map in R for Cape Town, South Africa.
Can it be found in any packages or R data bases? 

Cheers




-----
Josh
--
View this message in context: http://r.789695.n4.nabble.com/R-map-data-for-South-Africa-tp4711123.html
Sent from the R help mailing list archive at Nabble.com.


From bbolker at gmail.com  Fri Aug 14 18:56:53 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 14 Aug 2015 16:56:53 +0000
Subject: [R] Jaccard index
References: <1439545874063-4711111.post@n4.nabble.com>
Message-ID: <loom.20150814T185331-567@post.gmane.org>

sreenath <sreenath.rajur <at> macfast.ac.in> writes:

> 
> sim(file_name,method="jaccard")
> this command is giving the raw wise similarity matrix
> how can i find column wise similarity matrix?
> what is the command?
> please help me
> 

  Based on a search 

library("sos"); findFn("jaccard sim")

I'm guessing that you're using the simba package (which you really
should have said in your message ...).  In general transposing the
matrix  

  sim(t(file_name),method="jaccard")

should work.

If you have ecology-related questions you might want to check out
the r-sig-ecology at r-project.org mailing list ...


From dwinsemius at comcast.net  Fri Aug 14 20:39:11 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Aug 2015 11:39:11 -0700
Subject: [R] R map data for South Africa
In-Reply-To: <1439570702911-4711123.post@n4.nabble.com>
References: <1439570702911-4711123.post@n4.nabble.com>
Message-ID: <66AA2842-AA09-4330-BC33-02C7589EADF1@comcast.net>


On Aug 14, 2015, at 9:45 AM, jgui001 wrote:

> I am looking for some elevation data to map in R for Cape Town, South Africa.
> Can it be found in any packages or R data bases? 

R has a well developed set of packages for geospatial analysis as well as an active mailing list, R-SIG-GEO. I suggest that you first do a google-search with terms:

 shape file elevation map cape town south africa

After you have put some search time into this, you will be in a better position to ask for help on the correct mailing list. I do not know if that mailing list is mirrored on Nabble. Generally it is recommended that you subscribe to R support mailing lists rather than use Nabble.

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Aug 14 20:10:32 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Aug 2015 11:10:32 -0700
Subject: [R] cut variable within a loop
In-Reply-To: <CAHymutK__NMQFbWJsCk3aYw3Wz3S1gLmGFW=kFoxQ+yh+g3PqQ@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>
	<CAHymutKPfSM-qfbp9dLQgUpErUKp0tHj476fCPP8_r5aFiUxyQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39DE6@SRVEXCHMBX.precheza.cz>
	<CAHymutK__NMQFbWJsCk3aYw3Wz3S1gLmGFW=kFoxQ+yh+g3PqQ@mail.gmail.com>
Message-ID: <154AA9FB-F7B6-4212-9373-761F475CA59B@comcast.net>


On Aug 14, 2015, at 6:40 AM, Janka Vanschoenwinkel wrote:

> Hi Petr,
> 
> Here the code below:
> 
> load("data.Rda") # or see data at the bottom of this email
> 
> ##########################################################################################
> 
> ####### Question cut2 intervals #######
> 
> # I have the variable irrigation which has a range from 0% to 100%.
> # I now want to calculate the code below for different thresholds of irrigation.
> # So for instance: starting from 10%, a farmer is defined as "irrigated farm".
> # Then we would have 0-10 = Rainfed, 10-100 is Irrigated.
> 
> # In the code below I run a short code for only 50 observations and
> # only for the interval 0-1,1-100 and 0-2, 2-100. If that works, it should also
> # work for 1-99.
> 
> # As indicated, it goes wrong when I want to cut based on the "i"
> specified at the start of the loop.
> 
> # Thanks a lot for your help!
> 
> # Janka
> 
> 
> d= data.frame(MEt_Rainfed=rep(1,2),MEp_Rainfed=rep(1,2),MEt_Irrigation=rep(1,2),MEp_Irrigation=rep(1,2))
> 
> library(Hmisc)
> o<-lapply(1:2, function(i){
> 
>  #cut sample in rainfed versus irrigation
>  Alldata$irri=cut2(Alldata$irrigation,i)

When using a function in R you may need to supply an argument name. Are you expecting this to be the number of groups. I cannot decipher the intent here with such sparse commentary, but this call to `cut2` does not make sense to me. Perhaps you meant the number of groups? .... in which case you need  cut2( Alldata$irrigation, g=i ), since the arguments to cut2 are not that same as the arguments to cut.

At the moment you are implicitly sending on the first pass a 1 and then on the second pass a 2 to the second argument of cut2 which is the `breaks` argument. So you wold be getting two different factors each with different cut-point levels. I looked at your data and in point of fact there would be no difference since you have 29 zero values and no values between 0 and 1.

> table(cut2(dat$irrigation, 1))

        0 [  1,100] 
       29        21 
> table(cut2(dat$irrigation, 2))

        0 [  2,100] 
       29        21 




>  levels(Alldata$irri)<-c("0","1")
> 
>  Alldata_Rainfed<-subset(Alldata, irri == 0)
>  Alldata_Irrigation<-subset(Alldata, irri == 1)
> 
>  Alldata_Rainfed$w<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
>  Alldata_Irrigation$w<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> 
>  OLS_Rainfed <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
>                      ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
>                      pdnsty+portsML+cities500k+rentedland+subsidies1+
>                      elevmean+elevrange+
>                      t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
>                      AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
>                    weights=w,Alldata_Rainfed)
> 
>  attach(Alldata_Rainfed)
> 
>  CoefRainfed_ps1 <- OLS_Rainfed$coeff[2]
>  CoefRainfed_ps2 <- OLS_Rainfed$coeff[3]
>  CoefRainfed_ps3 <- OLS_Rainfed$coeff[4]
>  CoefRainfed_ps4 <- OLS_Rainfed$coeff[5]
>  CoefRainfed_ts1 <- OLS_Rainfed$coeff[6]
>  CoefRainfed_ts2 <- OLS_Rainfed$coeff[7]
>  CoefRainfed_ts3 <- OLS_Rainfed$coeff[8]
>  CoefRainfed_ts4 <- OLS_Rainfed$coeff[9]
>  CoefRainfed_ps1sq <- OLS_Rainfed$coeff[10]
>  CoefRainfed_ps2sq <- OLS_Rainfed$coeff[11]
>  CoefRainfed_ps3sq <- OLS_Rainfed$coeff[12]
>  CoefRainfed_ps4sq <- OLS_Rainfed$coeff[13]
>  CoefRainfed_ts1sq <- OLS_Rainfed$coeff[14]
>  CoefRainfed_ts2sq <- OLS_Rainfed$coeff[15]
>  CoefRainfed_ts3sq <- OLS_Rainfed$coeff[16]
>  CoefRainfed_ts4sq <- OLS_Rainfed$coeff[17]
> 
>  attach(Alldata_Rainfed)
> 
> 
>  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY level)
>  # Maar dit is dus de marginale impact per LnALVperHA?
> 
>  Alldata_Rainfed$MEts1 =
> CoefRainfed_ts1+2*CoefRainfed_ts1sq*Alldata_Rainfed$ts1
>  Alldata_Rainfed$MEts2 =
> CoefRainfed_ts2+2*CoefRainfed_ts2sq*Alldata_Rainfed$ts2
>  Alldata_Rainfed$MEts3 =
> CoefRainfed_ts3+2*CoefRainfed_ts3sq*Alldata_Rainfed$ts3
>  Alldata_Rainfed$MEts4 =
> CoefRainfed_ts4+2*CoefRainfed_ts4sq*Alldata_Rainfed$ts4
>  Alldata_Rainfed$MEt   = Alldata_Rainfed$MEts1 +
> Alldata_Rainfed$MEts2 + Alldata_Rainfed$MEts3 + Alldata_Rainfed$MEts4
> 
>  Alldata_Rainfed$MEps1 =
> CoefRainfed_ps1+2*CoefRainfed_ps1sq*Alldata_Rainfed$ps1
>  Alldata_Rainfed$MEps2 =
> CoefRainfed_ps2+2*CoefRainfed_ps2sq*Alldata_Rainfed$ps2
>  Alldata_Rainfed$MEps3 =
> CoefRainfed_ps3+2*CoefRainfed_ps3sq*Alldata_Rainfed$ps3
>  Alldata_Rainfed$MEps4 =
> CoefRainfed_ps4+2*CoefRainfed_ps4sq*Alldata_Rainfed$ps4
>  Alldata_Rainfed$MEp   = Alldata_Rainfed$MEps1 +
> Alldata_Rainfed$MEps2 + Alldata_Rainfed$MEps3 + Alldata_Rainfed$MEps4
> 
> 
>  Alldata_Rainfed$weight2<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
>  attach(Alldata_Rainfed)
>  library(stats)
>  MEt_Rainfed<-weighted.mean(MEt,weight2)
>  MEp_Rainfed<-weighted.mean(MEp,weight2)
> 
> 
> 
>  attach(Alldata_Irrigation)
> 
>  OLS_Irrigation <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
>                         ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
>                         pdnsty+portsML+cities500k+rentedland+subsidies1+
>                         elevmean+elevrange+
>                         t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
>                         AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
>                       weights=w,Alldata_Irrigation)
> 
> 
> 
>  CoefIrrigation_ps1 <- OLS_Irrigation$coeff[2]
>  CoefIrrigation_ps2 <- OLS_Irrigation$coeff[3]
>  CoefIrrigation_ps3 <- OLS_Irrigation$coeff[4]
>  CoefIrrigation_ps4 <- OLS_Irrigation$coeff[5]
>  CoefIrrigation_ts1 <- OLS_Irrigation$coeff[6]
>  CoefIrrigation_ts2 <- OLS_Irrigation$coeff[7]
>  CoefIrrigation_ts3 <- OLS_Irrigation$coeff[8]
>  CoefIrrigation_ts4 <- OLS_Irrigation$coeff[9]
>  CoefIrrigation_ps1sq <- OLS_Irrigation$coeff[10]
>  CoefIrrigation_ps2sq <- OLS_Irrigation$coeff[11]
>  CoefIrrigation_ps3sq <- OLS_Irrigation$coeff[12]
>  CoefIrrigation_ps4sq <- OLS_Irrigation$coeff[13]
>  CoefIrrigation_ts1sq <- OLS_Irrigation$coeff[14]
>  CoefIrrigation_ts2sq <- OLS_Irrigation$coeff[15]
>  CoefIrrigation_ts3sq <- OLS_Irrigation$coeff[16]
>  CoefIrrigation_ts4sq <- OLS_Irrigation$coeff[17]
> 
>  attach(Alldata_Irrigation)
>  # gives the residual errors in Y
>  Alldata_Irrigation$residuals <-resid(OLS_Irrigation)
> 
>  # gives the predicted values for Ln_Y
>  Alldata_Irrigation$Ln_y_hat <-fitted(OLS_Irrigation)
> 
>  # Zelf functie rmse maken
>  rmse <- function(error)
>  {
>    sqrt(mean(error^2))
>  }
>  Alldata_Irrigation$y_hat <-
> exp(Alldata_Irrigation$Ln_y_hat)*exp(0.5*(rmse(OLS_Irrigation$residuals))^2)
> 
>  # absolute impact (landwaarde current)
>  Alldata_Irrigation$absolute.current<-Alldata_Irrigation$y_hat*Alldata_Irrigation$se025*Alldata_Irrigation$sys02
> 
> 
>  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY level)
>  # Maar dit is dus de marginale impact per LnALVperHA?
> 
>  Alldata_Irrigation$MEts1 =
> CoefIrrigation_ts1+2*CoefIrrigation_ts1sq*Alldata_Irrigation$ts1
>  Alldata_Irrigation$MEts2 =
> CoefIrrigation_ts2+2*CoefIrrigation_ts2sq*Alldata_Irrigation$ts2
>  Alldata_Irrigation$MEts3 =
> CoefIrrigation_ts3+2*CoefIrrigation_ts3sq*Alldata_Irrigation$ts3
>  Alldata_Irrigation$MEts4 =
> CoefIrrigation_ts4+2*CoefIrrigation_ts4sq*Alldata_Irrigation$ts4
>  Alldata_Irrigation$MEt   = Alldata_Irrigation$MEts1 +
> Alldata_Irrigation$MEts2 + Alldata_Irrigation$MEts3 +
> Alldata_Irrigation$MEts4
> 
>  Alldata_Irrigation$MEps1 =
> CoefIrrigation_ps1+2*CoefIrrigation_ps1sq*Alldata_Irrigation$ps1
>  Alldata_Irrigation$MEps2 =
> CoefIrrigation_ps2+2*CoefIrrigation_ps2sq*Alldata_Irrigation$ps2
>  Alldata_Irrigation$MEps3 =
> CoefIrrigation_ps3+2*CoefIrrigation_ps3sq*Alldata_Irrigation$ps3
>  Alldata_Irrigation$MEps4 =
> CoefIrrigation_ps4+2*CoefIrrigation_ps4sq*Alldata_Irrigation$ps4
>  Alldata_Irrigation$MEp   = Alldata_Irrigation$MEps1 +
> Alldata_Irrigation$MEps2 + Alldata_Irrigation$MEps3 +
> Alldata_Irrigation$MEps4
> 
> 
>  Alldata_Irrigation$weight2<-Alldata_Irrigation$sys02*Alldata_Irrigation$se025
>  Alldata_Irrigation$weight2<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> 
>  attach(Alldata_Irrigation)
>  library(stats)
>  MEt_Irrigation<-weighted.mean(MEt,weight2)
>  MEp_Irrigation<-weighted.mean(MEp,weight2)
> 
>  c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> 
>  attach(Alldata)
> 
> 
>  # And in the loop (index i):
> 
>  d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> 
> 
> })
> out<-as.data.frame(do.call(rbind, o))
> 
> 
> 
> 
> And the data are:
> 
> structure(list(LnALVperHA = c(8.09964942932129, 9.53274631500244,
> 7.42697763442993, 8.25370121002197, 8.42619132995605, 8.0093936920166,
> 8.09785747528076, 8.49044704437256, 9.08215141296387, 8.38935947418213,
> 8.67814350128174, 8.38935947418213, 10.4056901931763, 8.48210144042969,
> 8.30281829833984, 8.92265796661377, 8.33178997039795, 4.54404163360596,
> 10.662184715271, 9.62167072296143, 7.98790407180786, 7.58244323730469,
> 7.23262739181519, 9.47037124633789, 8.93403625488281, 7.54256629943848,
> 9.40302467346191, 10.6290521621704, 8.59830188751221, 8.59585666656494,
> 9.10000514984131, 9.99381542205811, 9.54681301116943, 9.53055191040039,
> 8.67971229553223, 7.19780731201172, 8.90067958831787, 6.0509786605835,
> 6.55788946151733, 8.22567272186279, 9.05618953704834, 6.81858921051025,
> 8.46410751342773, 7.81292057037354, 8.38989448547363, 10.4709157943726,
> 8.06132888793945, 8.43629264831543, 10.3087100982666, 10.3218297958374
> ), ps1 = c(5.14855766296387, 4.71904611587524, 7.9462103843689,
> 10.6017990112305, 11.233078956604, 9.12952136993408, 12.6536712646484,
> 11.233078956604, 11.233078956604, 11.233078956604, 11.233078956604,
> 11.233078956604, 5.93759632110596, 10.6017990112305, 11.233078956604,
> 10.6017990112305, 7.95780467987061, 9.07744884490967, 4.29865598678589,
> 8.27481746673584, 3.25137901306152, 4.51061344146729, 6.34518480300903,
> 6.66202449798584, 6.66202449798584, 4.75249433517456, 6.28858852386475,
> 6.33270215988159, 10.3600759506226, 10.3600759506226, 18.7164611816406,
> 5.73318386077881, 7.92949104309082, 9.09823608398438, 11.233078956604,
> 10.4455404281616, 11.233078956604, 10.4455404281616, 10.4455404281616,
> 10.6017990112305, 9.19112777709961, 10.4455404281616, 11.233078956604,
> 11.064302444458, 11.233078956604, 5.93759632110596, 11.233078956604,
> 10.6017990112305, 6.05948448181152, 9.5645227432251), ps2 = c(5.23111915588379,
> 4.86784505844116, 7.7175760269165, 4.34898376464844, 4.48626232147217,
> 9.57159423828125, 8.38174915313721, 4.48626232147217, 4.48626232147217,
> 4.48626232147217, 4.48626232147217, 4.48626232147217, 6.87198734283447,
> 4.34898376464844, 4.48626232147217, 4.34898376464844, 6.2098217010498,
> 7.5497522354126, 5.62545442581177, 5.57168531417847, 3.08954334259033,
> 6.6683931350708, 4.41767883300781, 6.11901044845581, 6.11901044845581,
> 4.06884765625, 6.35917854309082, 5.7121729850769, 8.55229663848877,
> 8.55229663848877, 11.8981914520264, 5.49351119995117, 5.34777498245239,
> 6.12420177459717, 4.48626232147217, 5.2967677116394, 4.48626232147217,
> 5.2967677116394, 5.2967677116394, 4.34898376464844, 4.51386308670044,
> 5.2967677116394, 4.48626232147217, 5.98725175857544, 4.48626232147217,
> 6.87198734283447, 4.48626232147217, 4.34898376464844, 5.58411026000977,
> 4.42436075210571), ps3 = c(4.95634937286377, 3.50353670120239,
> 6.01129817962646, 0.851324141025543, 0.816295921802521, 8.03804397583008,
> 5.56230783462524, 0.816295921802521, 0.816295921802521, 0.816295921802521,
> 0.816295921802521, 0.816295921802521, 6.01666784286499, 0.851324141025543,
> 0.816295921802521, 0.851324141025543, 3.45424580574036, 5.31899690628052,
> 7.45753812789917, 3.34133338928223, 6.61472988128662, 11.244439125061,
> 2.19617891311646, 5.29748106002808, 5.29748106002808, 1.63307499885559,
> 5.51272773742676, 6.78562116622925, 4.5334997177124, 4.5334997177124,
> 4.31791353225708, 7.10963106155396, 2.32198905944824, 2.74845194816589,
> 0.816295921802521, 1.47570741176605, 0.816295921802521, 1.47570741176605,
> 1.47570741176605, 0.851324141025543, 1.39068424701691, 1.47570741176605,
> 0.816295921802521, 1.85064959526062, 0.816295921802521, 6.01666784286499,
> 0.816295921802521, 0.851324141025543, 6.78009986877441, 1.21070051193237
> ), ps4 = c(5.66667366027832, 4.82342433929443, 7.40090322494507,
> 6.59299898147583, 7.33758926391602, 9.98004341125488, 10.3958940505981,
> 7.33758926391602, 7.33758926391602, 7.33758926391602, 7.33758926391602,
> 7.33758926391602, 8.31999015808105, 6.59299898147583, 7.33758926391602,
> 6.59299898147583, 7.05771064758301, 8.38344383239746, 4.75349426269531,
> 9.00399303436279, 5.48189449310303, 5.9071044921875, 5.30881881713867,
> 8.68398857116699, 8.68398857116699, 4.32339859008789, 8.57950687408447,
> 6.78787326812744, 8.68624305725098, 8.68624305725098, 12.9021902084351,
> 6.14854049682617, 6.71301507949829, 7.50605535507202, 7.33758926391602,
> 8.11069011688232, 7.33758926391602, 8.11069011688232, 8.11069011688232,
> 6.59299898147583, 5.92181205749512, 8.11069011688232, 7.33758926391602,
> 9.29954528808594, 7.33758926391602, 8.31999015808105, 7.33758926391602,
> 6.59299898147583, 6.16447877883911, 5.83903217315674), ts1 = c(4.19949150085449,
> 2.46556353569031, 3.96805644035339, 9.05560302734375, 9.5199556350708,
> 1.18671488761902, 6.60286664962769, 9.5199556350708, 9.5199556350708,
> 9.5199556350708, 9.5199556350708, 9.5199556350708, 2.12847352027893,
> 9.05560302734375, 9.5199556350708, 9.05560302734375, 2.11432313919067,
> 6.49393510818481, -0.165110915899277, 7.78503036499023, -7.71160411834717,
> -0.979450941085815, 4.96369075775146, 4.28496122360229, 4.28496122360229,
> 6.35976600646973, 3.02656149864197, 2.80754446983337, 5.94739389419556,
> 5.94739389419556, 8.70161914825439, 1.57025468349457, 5.08782005310059,
> 4.27688789367676, 9.5199556350708, 8.49832916259766, 9.5199556350708,
> 8.49832916259766, 8.49832916259766, 9.05560302734375, 6.33359289169312,
> 8.49832916259766, 9.5199556350708, 7.99740839004517, 9.5199556350708,
> 2.12847352027893, 9.5199556350708, 9.05560302734375, 2.67069268226624,
> 7.33829879760742), ts2 = c(9.89923763275146, 10.9084701538086,
> 9.61682415008545, 13.6253662109375, 13.8121919631958, 6.19518041610718,
> 9.40560817718506, 13.8121919631958, 13.8121919631958, 13.8121919631958,
> 13.8121919631958, 13.8121919631958, 10.3912172317505, 13.6253662109375,
> 13.8121919631958, 13.6253662109375, 9.77112770080566, 11.5460777282715,
> 8.18180465698242, 12.9412984848022, 2.54625177383423, 8.29829216003418,
> 10.6650953292847, 10.1770324707031, 10.1770324707031, 12.4333782196045,
> 8.98324680328369, 8.45312309265137, 9.23384857177734, 9.23384857177734,
> 11.371600151062, 8.09108352661133, 12.0714511871338, 11.385799407959,
> 13.8121919631958, 13.912787437439, 13.8121919631958, 13.912787437439,
> 13.912787437439, 13.6253662109375, 12.0018119812012, 13.912787437439,
> 13.8121919631958, 14.0190010070801, 13.8121919631958, 10.3912172317505,
> 13.8121919631958, 13.6253662109375, 8.53981018066406, 12.7294788360596
> ), ts3 = c(17.718994140625, 21.1172523498535, 17.8669090270996,
> 23.1215572357178, 22.9536685943604, 15.3891229629517, 15.7000684738159,
> 22.9536685943604, 22.9536685943604, 22.9536685943604, 22.9536685943604,
> 22.9536685943604, 20.1229286193848, 23.1215572357178, 22.9536685943604,
> 23.1215572357178, 19.8251171112061, 19.3250198364258, 16.8351039886475,
> 22.2966594696045, 14.6743259429932, 17.1554985046387, 20.1656894683838,
> 20.0012702941895, 20.0012702941895, 23.2738876342773, 18.6255321502686,
> 16.2553405761719, 16.551155090332, 16.551155090332, 17.6266174316406,
> 16.1711521148682, 22.280725479126, 21.450382232666, 22.9536685943604,
> 23.5616970062256, 22.9536685943604, 23.5616970062256, 23.5616970062256,
> 23.1215572357178, 22.1113948822021, 23.5616970062256, 22.9536685943604,
> 23.5085678100586, 22.9536685943604, 20.1229286193848, 22.9536685943604,
> 23.1215572357178, 16.3595314025879, 22.7737102508545), ts4 = c(11.661883354187,
> 12.7669324874878, 11.6320190429688, 17.2357921600342, 17.4911460876465,
> 9.09537506103516, 12.179615020752, 17.4911460876465, 17.4911460876465,
> 17.4911460876465, 17.4911460876465, 17.4911460876465, 12.0781927108765,
> 17.2357921600342, 17.4911460876465, 17.2357921600342, 11.9486837387085,
> 13.7441387176514, 8.9575023651123, 15.9984045028687, 4.02816677093506,
> 9.12790489196777, 13.0505475997925, 12.842321395874, 12.842321395874,
> 14.8937959671021, 11.5566177368164, 10.0515727996826, 12.2921047210693,
> 12.2921047210693, 14.2251281738281, 9.64802074432373, 14.6072359085083,
> 13.7993869781494, 17.4911460876465, 17.0232067108154, 17.4911460876465,
> 17.0232067108154, 17.0232067108154, 17.2357921600342, 15.045259475708,
> 17.0232067108154, 17.4911460876465, 16.7633666992188, 17.4911460876465,
> 12.0781927108765, 17.4911460876465, 17.2357921600342, 10.0954942703247,
> 15.9187803268433), ps1sq = c(26.5076465606689, 22.2693958282471,
> 63.1422576904297, 112.398139953613, 126.182060241699, 83.3481597900391,
> 160.11540222168, 126.182060241699, 126.182060241699, 126.182060241699,
> 126.182060241699, 126.182060241699, 35.2550506591797, 112.398139953613,
> 126.182060241699, 112.398139953613, 63.3266563415527, 82.4000778198242,
> 18.478443145752, 68.4726028442383, 10.5714654922485, 20.3456344604492,
> 40.2613716125488, 44.3825721740723, 44.3825721740723, 22.58620262146,
> 39.5463447570801, 40.1031150817871, 107.331176757812, 107.331176757812,
> 350.305908203125, 32.8693962097168, 62.8768272399902, 82.7779006958008,
> 126.182060241699, 109.109313964844, 126.182060241699, 109.109313964844,
> 109.109313964844, 112.398139953613, 84.4768295288086, 109.109313964844,
> 126.182060241699, 122.418785095215, 126.182060241699, 35.2550506591797,
> 126.182060241699, 112.398139953613, 36.7173538208008, 91.480094909668
> ), ps2sq = c(27.3646068572998, 23.695915222168, 59.560977935791,
> 18.9136600494385, 20.1265487670898, 91.6154174804688, 70.2537155151367,
> 20.1265487670898, 20.1265487670898, 20.1265487670898, 20.1265487670898,
> 20.1265487670898, 47.2242088317871, 18.9136600494385, 20.1265487670898,
> 18.9136600494385, 38.5618858337402, 56.9987602233887, 31.6457366943359,
> 31.0436763763428, 9.54527759552002, 44.4674682617188, 19.5158863067627,
> 37.4422874450684, 37.4422874450684, 16.5555210113525, 40.439151763916,
> 32.6289215087891, 73.1417770385742, 73.1417770385742, 141.566955566406,
> 30.1786651611328, 28.5986976623535, 37.5058479309082, 20.1265487670898,
> 28.0557479858398, 20.1265487670898, 28.0557479858398, 28.0557479858398,
> 18.9136600494385, 20.3749599456787, 28.0557479858398, 20.1265487670898,
> 35.8471832275391, 20.1265487670898, 47.2242088317871, 20.1265487670898,
> 18.9136600494385, 31.1822872161865, 19.5749683380127), ps3sq =
> c(24.5653991699219,
> 12.27476978302, 36.1357040405273, 0.72475278377533, 0.666339039802551,
> 64.6101531982422, 30.9392681121826, 0.666339039802551, 0.666339039802551,
> 0.666339039802551, 0.666339039802551, 0.666339039802551, 36.2002906799316,
> 0.72475278377533, 0.666339039802551, 0.72475278377533, 11.9318141937256,
> 28.2917289733887, 55.614875793457, 11.1645088195801, 43.7546501159668,
> 126.437408447266, 4.82320165634155, 28.063304901123, 28.063304901123,
> 2.6669340133667, 30.3901672363281, 46.0446548461914, 20.552619934082,
> 20.552619934082, 18.6443767547607, 50.5468521118164, 5.39163303375244,
> 7.55398797988892, 0.666339039802551, 2.17771244049072, 0.666339039802551,
> 2.17771244049072, 2.17771244049072, 0.72475278377533, 1.93400263786316,
> 2.17771244049072, 0.666339039802551, 3.42490386962891, 0.666339039802551,
> 36.2002906799316, 0.666339039802551, 0.72475278377533, 45.9697532653809,
> 1.46579575538635), ps4sq = c(32.1111907958984, 23.2654228210449,
> 54.7733688354492, 43.4676361083984, 53.840217590332, 99.6012649536133,
> 108.074615478516, 53.840217590332, 53.840217590332, 53.840217590332,
> 53.840217590332, 53.840217590332, 69.2222366333008, 43.4676361083984,
> 53.840217590332, 43.4676361083984, 49.811279296875, 70.2821273803711,
> 22.5957069396973, 81.071891784668, 30.0511665344238, 34.8938827514648,
> 28.183557510376, 75.4116592407227, 75.4116592407227, 18.6917762756348,
> 73.6079406738281, 46.0752220153809, 75.4508209228516, 75.4508209228516,
> 166.466506958008, 37.8045501708984, 45.0645713806152, 56.3408660888672,
> 53.840217590332, 65.7832946777344, 53.840217590332, 65.7832946777344,
> 65.7832946777344, 43.4676361083984, 35.0678596496582, 65.7832946777344,
> 53.840217590332, 86.4815444946289, 53.840217590332, 69.2222366333008,
> 53.840217590332, 43.4676361083984, 38.0007972717285, 34.094295501709
> ), ts1sq = c(17.6357288360596, 6.07900333404541, 15.7454719543457,
> 82.0039443969727, 90.6295547485352, 1.40829217433929, 43.5978469848633,
> 90.6295547485352, 90.6295547485352, 90.6295547485352, 90.6295547485352,
> 90.6295547485352, 4.53039932250977, 82.0039443969727, 90.6295547485352,
> 82.0039443969727, 4.47036218643188, 42.1711921691895, 0.0272616147994995,
> 60.6066970825195, 59.4688377380371, 0.95932412147522, 24.6382255554199,
> 18.3608932495117, 18.3608932495117, 40.4466247558594, 9.16007423400879,
> 7.88230609893799, 35.3714942932129, 35.3714942932129, 75.7181777954102,
> 2.46569967269897, 25.8859119415283, 18.2917709350586, 90.6295547485352,
> 72.2215957641602, 90.6295547485352, 72.2215957641602, 72.2215957641602,
> 82.0039443969727, 40.1143989562988, 72.2215957641602, 90.6295547485352,
> 63.9585418701172, 90.6295547485352, 4.53039932250977, 90.6295547485352,
> 82.0039443969727, 7.13259935379028, 53.8506278991699), ts2sq =
> c(97.9949035644531,
> 118.994720458984, 92.4833068847656, 185.650604248047, 190.776641845703,
> 38.3802604675293, 88.465461730957, 190.776641845703, 190.776641845703,
> 190.776641845703, 190.776641845703, 190.776641845703, 107.977394104004,
> 185.650604248047, 190.776641845703, 185.650604248047, 95.4749374389648,
> 133.311904907227, 66.9419250488281, 167.477203369141, 6.48339796066284,
> 68.8616561889648, 113.744255065918, 103.571990966797, 103.571990966797,
> 154.588897705078, 80.6987228393555, 71.4552917480469, 85.2639617919922,
> 85.2639617919922, 129.313293457031, 65.4656295776367, 145.719940185547,
> 129.636428833008, 190.776641845703, 193.565658569336, 190.776641845703,
> 193.565658569336, 193.565658569336, 185.650604248047, 144.043487548828,
> 193.565658569336, 190.776641845703, 196.53239440918, 190.776641845703,
> 107.977394104004, 190.776641845703, 185.650604248047, 72.9283599853516,
> 162.039627075195), ts3sq = c(313.962768554688, 445.938354492188,
> 319.226440429688, 534.606384277344, 526.870910644531, 236.825103759766,
> 246.492156982422, 526.870910644531, 526.870910644531, 526.870910644531,
> 526.870910644531, 526.870910644531, 404.932250976562, 534.606384277344,
> 526.870910644531, 534.606384277344, 393.035278320312, 373.456390380859,
> 283.420715332031, 497.141021728516, 215.335845947266, 294.311126708984,
> 406.655029296875, 400.050811767578, 400.050811767578, 541.673828125,
> 346.910461425781, 264.236083984375, 273.940734863281, 273.940734863281,
> 310.697631835938, 261.506164550781, 496.430725097656, 460.118896484375,
> 526.870910644531, 555.153564453125, 526.870910644531, 555.153564453125,
> 555.153564453125, 534.606384277344, 488.913787841797, 555.153564453125,
> 526.870910644531, 552.652770996094, 526.870910644531, 404.932250976562,
> 526.870910644531, 534.606384277344, 267.63427734375, 518.641906738281
> ), ts4sq = c(135.999526977539, 162.994567871094, 135.303863525391,
> 297.072540283203, 305.940185546875, 82.7258453369141, 148.343017578125,
> 305.940185546875, 305.940185546875, 305.940185546875, 305.940185546875,
> 305.940185546875, 145.882736206055, 297.072540283203, 305.940185546875,
> 297.072540283203, 142.771041870117, 188.901351928711, 80.2368469238281,
> 255.948944091797, 16.2261276245117, 83.3186492919922, 170.316787719727,
> 164.925216674805, 164.925216674805, 221.825164794922, 133.555419921875,
> 101.034118652344, 151.095840454102, 151.095840454102, 202.354278564453,
> 93.0843048095703, 213.371337890625, 190.423080444336, 305.940185546875,
> 289.789581298828, 305.940185546875, 289.789581298828, 289.789581298828,
> 297.072540283203, 226.359832763672, 289.789581298828, 305.940185546875,
> 281.010467529297, 305.940185546875, 145.882736206055, 305.940185546875,
> 297.072540283203, 101.919006347656, 253.407562255859), pdnsty =
> c(0.616999983787537,
> 0.0850000008940697, 0.068000003695488, 0.025000000372529, 0.0549999997019768,
> 0.0230000000447035, 0.133000001311302, 0.0549999997019768, 0.0549999997019768,
> 0.0549999997019768, 0.0549999997019768, 0.0549999997019768, 0.25900000333786,
> 0.025000000372529, 0.0549999997019768, 0.025000000372529, 0.0140000004321337,
> 0.14300000667572, 0.140000000596046, 0.777999997138977, 0.0329999998211861,
> 0.316000014543533, 0.0179999992251396, 0.105999998748302, 0.105999998748302,
> 0.046000000089407, 0.108000002801418, 0.310999989509583, 0.101000003516674,
> 0.101000003516674, 0.14300000667572, 0.168999999761581, 0.0439999997615814,
> 0.0379999987781048, 0.0549999997019768, 0.063000001013279, 0.0549999997019768,
> 0.063000001013279, 0.063000001013279, 0.025000000372529, 0.0640000030398369,
> 0.063000001013279, 0.0549999997019768, 0.209000006318092, 0.0549999997019768,
> 0.25900000333786, 0.0549999997019768, 0.025000000372529, 0.257999986410141,
> 0.0469999983906746), portsML = c(0.0900330692529678, 0.0604440234601498,
> 0.168490216135979, 0.275995850563049, 0.269018620252609, 0.175392478704453,
> 0.0350189469754696, 0.269018620252609, 0.269018620252609, 0.269018620252609,
> 0.269018620252609, 0.269018620252609, 0.11026918143034, 0.275995850563049,
> 0.269018620252609, 0.275995850563049, 0.145082741975784, 0.00440915673971176,
> 0.426146239042282, 0.0686663240194321, 0.103511147201061, 0.289726078510284,
> 0.234196603298187, 0.123688526451588, 0.123688526451588, 0.315173029899597,
> 0.112561739981174, 0.0461684986948967, 0.179993003606796, 0.179993003606796,
> 0.0438785217702389, 0.096462681889534, 0.0934395045042038, 0.121217466890812,
> 0.269018620252609, 0.212490051984787, 0.269018620252609, 0.212490051984787,
> 0.212490051984787, 0.275995850563049, 0.162760972976685, 0.212490051984787,
> 0.269018620252609, 0.270619571208954, 0.269018620252609, 0.11026918143034,
> 0.269018620252609, 0.275995850563049, 0.108705826103687, 0.196496397256851
> ), cities500k = c(0.0360943526029587, 0.0577861145138741, 0.183606043457985,
> 0.150749072432518, 0.185974538326263, 0.0923599153757095, 0.353672504425049,
> 0.185974538326263, 0.185974538326263, 0.185974538326263, 0.185974538326263,
> 0.185974538326263, 0.0887016654014587, 0.150749072432518, 0.185974538326263,
> 0.150749072432518, 0.144800990819931, 0.00326321297325194, 0.0622526630759239,
> 0.00816718116402626, 0.181859150528908, 0.163181975483894, 0.204970955848694,
> 0.129742562770844, 0.129742562770844, 0.0783679932355881, 0.0559677332639694,
> 0.0293320622295141, 0.248573184013367, 0.248573184013367, 0.174525216221809,
> 0.092569001019001, 0.176346719264984, 0.16088992357254, 0.185974538326263,
> 0.280431807041168, 0.185974538326263, 0.280431807041168, 0.280431807041168,
> 0.150749072432518, 0.088722825050354, 0.280431807041168, 0.185974538326263,
> 0.189705356955528, 0.185974538326263, 0.0887016654014587, 0.185974538326263,
> 0.150749072432518, 0.0712414756417274, 0.0842432081699371), rentedland
> = c(0.571943998336792,
> 0, 0.5929936170578, 0, 0, 0.755691230297089, 0.440930217504501,
> 0, 0, 0, 0.229885056614876, 0, 0, 0, 0, 0, 0.890581607818604,
> 0.212423488497734, 0.386227518320084, 0, 0.11130790412426, 0.483032256364822,
> 0.444395005702972, 0, 0, 0.253378361463547, 0, 0.10909091681242,
> 0.181818187236786, 0.666666686534882, 0, 0.94951194524765, 0.846153855323792,
> 0.403846144676208, 0, 0, 0.155963316559792, 0, 0, 0.408163279294968,
> 0.699570834636688, 0, 0, 0, 0, 0, 0.0476190522313118, 0, 0, 0
> ), subsidies1 = c(361.835754394531, 0, 368.242034912109, 345.636352539062,
> 701.746032714844, 488.922821044922, 344.918609619141, 790.392150878906,
> 795.3125, 631.666687011719, 193.563217163086, 565.75, 0, 577.586181640625,
> 395.681823730469, 192, 371.963653564453, 9.9977331161499, 310.838317871094,
> 905.764709472656, 1745.76293945312, 359.003814697266, 163.204330444336,
> 427.94970703125, 204.842727661133, 52.2592887878418, 0, 0, 3022.24243164062,
> 80.2666702270508, 445.366577148438, 925.681640625, 824.769226074219,
> 625.192321777344, 850.441162109375, 280.891723632812, 619.266052246094,
> 333.962249755859, 376.304351806641, 317.551025390625, 166.652359008789,
> 171.224487304688, 526.119445800781, 253.191497802734, 334.470581054688,
> 107.277839660645, 431.428588867188, 0, 107.245544433594, 339.701507568359
> ), elevmean = c(0.121736958622932, 0.46412268280983, 0.344255149364471,
> 0.466430068016052, 0.43000802397728, 1.15364873409271, 0.0955904126167297,
> 0.43000802397728, 0.43000802397728, 0.43000802397728, 0.43000802397728,
> 0.43000802397728, 0.370405077934265, 0.466430068016052, 0.43000802397728,
> 0.466430068016052, 0.849120080471039, 0.0433186627924442, 0.335433751344681,
> 0.271958351135254, 0.125564843416214, 0.376024007797241, 0.815701544284821,
> 0.525435268878937, 0.525435268878937, 0.62959760427475, 0.518330037593842,
> 0.00362438289448619, 0.628515422344208, 0.628515422344208, 0.274942100048065,
> 0.0728112533688545, 0.496583759784698, 0.739268243312836, 0.43000802397728,
> 0.321640431880951, 0.43000802397728, 0.321640431880951, 0.321640431880951,
> 0.466430068016052, 0.585907399654388, 0.321640431880951, 0.43000802397728,
> 0.147326037287712, 0.43000802397728, 0.370405077934265, 0.43000802397728,
> 0.466430068016052, 0.0183117985725403, 0.414920538663864), elevrange =
> c(0.180000007152557,
> 1.99300003051758, 0.611000001430511, 2.35199999809265, 2.29999995231628,
> 2.94199991226196, 0.354999989271164, 2.29999995231628, 2.29999995231628,
> 2.29999995231628, 2.29999995231628, 2.29999995231628, 2.01799988746643,
> 2.35199999809265, 2.29999995231628, 2.35199999809265, 1.7389999628067,
> 0.160999998450279, 0.314000010490417, 1.76300001144409, 0.17399999499321,
> 0.653999984264374, 1.63399994373322, 2.19099998474121, 2.19099998474121,
> 1.14100003242493, 1.34800004959106, 0.00899999961256981, 2.41300010681152,
> 2.41300010681152, 0.787999987602234, 0.26800000667572, 1.92200005054474,
> 2.02600002288818, 2.29999995231628, 1.05099999904633, 2.29999995231628,
> 1.05099999904633, 1.05099999904633, 2.35199999809265, 2.35999989509583,
> 1.05099999904633, 2.29999995231628, 0.772000014781952, 2.29999995231628,
> 2.01799988746643, 2.29999995231628, 2.35199999809265, 0.0649999976158142,
> 1.75399994850159), t_gravel = c(4.58953237533569, 13.3146963119507,
> 10.0136280059814, 13.8894920349121, 13.9366893768311, 13.5653190612793,
> 7.71220588684082, 13.9366893768311, 13.9366893768311, 13.9366893768311,
> 13.9366893768311, 13.9366893768311, 11.4818019866943, 13.8894920349121,
> 13.9366893768311, 13.8894920349121, 13.4321727752686, 5.71388387680054,
> 8.03888702392578, 9.01077747344971, 4.58924961090088, 8.14134693145752,
> 11.8983144760132, 9.96716785430908, 9.96716785430908, 11.1739711761475,
> 10.4019403457642, 5.16821479797363, 10.7357034683228, 10.7357034683228,
> 9.23897457122803, 4.3336238861084, 10.9520101547241, 12.9722995758057,
> 13.9366893768311, 13.1780118942261, 13.9366893768311, 13.1780118942261,
> 13.1780118942261, 13.8894920349121, 12.7335777282715, 13.1780118942261,
> 13.9366893768311, 12.315260887146, 13.9366893768311, 11.4818019866943,
> 13.9366893768311, 13.8894920349121, 6.68424606323242, 14.101095199585
> ), t_ph_h2o = c(6.07352828979492, 6.72695684432983, 5.60523176193237,
> 6.13967752456665, 6.86059141159058, 7.40929126739502, 5.68151950836182,
> 6.86059141159058, 6.86059141159058, 6.86059141159058, 6.86059141159058,
> 6.86059141159058, 6.51894521713257, 6.13967752456665, 6.86059141159058,
> 6.13967752456665, 6.98909568786621, 5.5628228187561, 6.68793487548828,
> 6.57724285125732, 4.67033195495605, 6.32772016525269, 6.4612717628479,
> 6.73934555053711, 6.73934555053711, 6.80293703079224, 6.17414236068726,
> 7.03696584701538, 5.93052577972412, 5.93052577972412, 5.43228578567505,
> 5.5989408493042, 6.86088180541992, 6.68706750869751, 6.86059141159058,
> 6.00043678283691, 6.86059141159058, 6.00043678283691, 6.00043678283691,
> 6.13967752456665, 6.89467239379883, 6.00043678283691, 6.86059141159058,
> 6.81896543502808, 6.86059141159058, 6.51894521713257, 6.86059141159058,
> 6.13967752456665, 5.63159275054932, 6.13170003890991), t_silt =
> c(34.2329025268555,
> 33.4969100952148, 34.4774589538574, 27.8914813995361, 31.9258117675781,
> 39.6254501342773, 34.7939414978027, 31.9258117675781, 31.9258117675781,
> 31.9258117675781, 31.9258117675781, 31.9258117675781, 26.6626663208008,
> 27.8914813995361, 31.9258117675781, 27.8914813995361, 29.7444763183594,
> 21.3432540893555, 37.4038734436035, 28.1513748168945, 19.4936828613281,
> 33.5968360900879, 32.8024406433105, 33.313850402832, 33.313850402832,
> 28.3197917938232, 33.3154563903809, 38.103458404541, 36.0389099121094,
> 36.0389099121094, 34.9229164123535, 26.5577545166016, 30.9245643615723,
> 31.1334323883057, 31.9258117675781, 27.1493148803711, 31.9258117675781,
> 27.1493148803711, 27.1493148803711, 27.8914813995361, 31.3038387298584,
> 27.1493148803711, 31.9258117675781, 31.6541061401367, 31.9258117675781,
> 26.6626663208008, 31.9258117675781, 27.8914813995361, 15.6523361206055,
> 27.803352355957), t_sand = c(47.0063323974609, 37.0355186462402,
> 45.8286781311035, 36.0810203552246, 39.9931793212891, 39.3664970397949,
> 46.2948226928711, 39.9931793212891, 39.9931793212891, 39.9931793212891,
> 39.9931793212891, 39.9931793212891, 49.3508529663086, 36.0810203552246,
> 39.9931793212891, 36.0810203552246, 39.2436943054199, 65.7813262939453,
> 35.8039131164551, 51.2884674072266, 66.2952728271484, 46.6789817810059,
> 41.4505424499512, 44.4590721130371, 44.4590721130371, 48.7276763916016,
> 43.3654098510742, 33.999683380127, 43.040699005127, 43.040699005127,
> 43.2519073486328, 59.4827156066895, 43.8675765991211, 41.7124671936035,
> 39.9931793212891, 34.94921875, 39.9931793212891, 34.94921875,
> 34.94921875, 36.0810203552246, 39.1853942871094, 34.94921875,
> 39.9931793212891, 39.8589019775391, 39.9931793212891, 49.3508529663086,
> 39.9931793212891, 36.0810203552246, 75.7048721313477, 33.5687866210938
> ), AT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), BE = c(0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0), DE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), DK = c(0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0), ES = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), FI = c(0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0), FR = c(1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), GR = c(0, 1, 0,
> 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 0, 1, 1, 0, 1), IE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), IT = c(0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
> 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 1, 0, 0, 0, 0), LU = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), NL = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 1, 0), PT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SE = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), WDE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), EDE = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), UK = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CY = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), BG = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CZ = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), EE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), HU = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), LT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), LV = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), PL = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), RO = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), SI = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SK = c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), b48 = c(70, 2.70000004768372, 63.9000015258789,
> 5.5, 6.30000019073486, 8.80000019073486, 48.0800018310547, 5.09999990463257,
> 6.40000009536743, 6, 6.69999980926514, 4, 6.30000019073486, 5.80000019073486,
> 8.80000019073486, 2, 13, 0.5, 10.25, 34, 65.2300033569336, 37.7799987792969,
> 74.9400024414062, 31.0200004577637, 20.0300006866455, 70.7200012207031,
> 40, 4.90000009536743, 13.5, 5, 26.8700008392334, 3, 2, 3.09999990463257,
> 6.80000019073486, 15.6999998092651, 9.19999980926514, 5.30000019073486,
> 4.59999990463257, 17.3999996185303, 7, 4.90000009536743, 13.3999996185303,
> 2.34999990463257, 8.5, 24.8700008392334, 4, 1.39999997615814,
> 34.7799987792969, 6.69999980926514), b50 = c(0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34.2400016784668, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0), irrigation = c(0, 100, 0, 5.45454584062099,
> 7.9365074634552, 89.3392562866211, 0, 17.6470592617989, 0, 0,
> 65.5172407627106, 0, 61.904764175415, 34.4827562570572, 7.95454531908035,
> 75, 0, 0, 0, 0, 0, 0, 5.26393800973892, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 74.6153831481934, 84.6153914928436, 0, 5.09554147720337,
> 0, 0, 0, 21.0884347558022, 18.4549376368523, 6.1224490404129,
> 25.3731369972229, 2.12765969336033, 0, 84.3988716602325, 0, 0,
> 0, 100), awc_class = c(106.228088378906, 78.2306137084961, 80.9311141967773,
> 32.4921531677246, 54.8475151062012, 80.6665878295898, 116.331588745117,
> 54.8475151062012, 54.8475151062012, 54.8475151062012, 54.8475151062012,
> 54.8475151062012, 56.3101806640625, 32.4921531677246, 54.8475151062012,
> 32.4921531677246, 59.3034172058105, 101.193893432617, 96.5840377807617,
> 54.2786560058594, 87.1388244628906, 66.1907730102539, 57.205738067627,
> 55.4114303588867, 55.4114303588867, 80.9288787841797, 63.6008758544922,
> 150, 30.3404140472412, 30.3404140472412, 19.8318557739258, 104.236854553223,
> 79.2445755004883, 57.0045547485352, 54.8475151062012, 34.320426940918,
> 54.8475151062012, 34.320426940918, 34.320426940918, 32.4921531677246,
> 65.1337509155273, 34.320426940918, 54.8475151062012, 73.6748657226562,
> 54.8475151062012, 56.3101806640625, 54.8475151062012, 32.4921531677246,
> 127.726959228516, 27.9528160095215), sys02 = c(18.8571434020996,
> 303.529418945312, 30.2469139099121, 104.305557250977, 86.4935073852539,
> 51.25, 83.0927810668945, 453.118286132812, 42.5, 104.305557250977,
> 48.461540222168, 86.4935073852539, 55.1851844787598, 104.305557250977,
> 104.305557250977, 185.277770996094, 17.9775276184082, 25.2777786254883,
> 64, 21.6666660308838, 30, 24.2372875213623, 47.0285720825195,
> 16.1904754638672, 33.75, 22.5423736572266, 10.2857141494751,
> 39.230770111084, 6.06741571426392, 1, 28.3255805969238, 21.6000003814697,
> 69.2592620849609, 86.6666641235352, 48.5185203552246, 44.4186058044434,
> 48.6538467407227, 437.105255126953, 437.105255126953, 19.1666660308838,
> 48.461540222168, 437.105255126953, 48.6538467407227, 453.118286132812,
> 48.6538467407227, 14.2857141494751, 453.118286132812, 453.118286132812,
> 95.2380981445312, 63), se025 = c(163.529998779297, 2.70000004768372,
> 157, 5.5, 6.30000019073486, 36.0200004577637, 86, 5.09999990463257,
> 6.40000009536743, 6, 8.69999980926514, 4, 6.30000019073486, 5.80000019073486,
> 8.80000019073486, 2, 118.809997558594, 44.1100006103516, 16.7000007629395,
> 34, 73.4000015258789, 73.0800018310547, 134.880004882812, 31.0200004577637,
> 20.0300006866455, 94.7200012207031, 40, 5.5, 16.5, 15, 26.8700008392334,
> 59.4199981689453, 13, 5.19999980926514, 6.80000019073486, 15.6999998092651,
> 10.8999996185303, 5.30000019073486, 4.59999990463257, 29.3999996185303,
> 23.2999992370605, 4.90000009536743, 13.3999996185303, 2.34999990463257,
> 8.5, 24.8700008392334, 4.19999980926514, 1.39999997615814, 34.7799987792969,
> 6.69999980926514)), .Names = c("LnALVperHA", "ps1", "ps2", "ps3",
> "ps4", "ts1", "ts2", "ts3", "ts4", "ps1sq", "ps2sq", "ps3sq",
> "ps4sq", "ts1sq", "ts2sq", "ts3sq", "ts4sq", "pdnsty", "portsML",
> "cities500k", "rentedland", "subsidies1", "elevmean", "elevrange",
> "t_gravel", "t_ph_h2o", "t_silt", "t_sand", "AT", "BE", "DE",
> "DK", "ES", "FI", "FR", "GR", "IE", "IT", "LU", "NL", "PT", "SE",
> "WDE", "EDE", "UK", "CY", "BG", "CZ", "EE", "HU", "LT", "LV",
> "PL", "RO", "SI", "SK", "b48", "b50", "irrigation", "awc_class",
> "sys02", "se025"), row.names = c("2", "3", "4", "5", "6", "7",
> "8", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
> "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31",
> "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
> "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53"
> ), class = "data.frame")
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 2015-08-14 14:58 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz>:
>> 
>> Hi Janka
>> 
>> 
>> 
>> Sorry, but we are limited in connecting to web services so I am not able to restore your data and see your code. Result of dput(somedata) coppied to email is preferable for sharing data and code can be copied to email too. But do not use HTML as it usually scrambles  text.
>> 
>> 
>> 
>> Answer in line
>> 
>> 
>> 
>> From: Janka Vanschoenwinkel [mailto:janka.vanschoenwinkel at uhasselt.be]
>> Sent: Friday, August 14, 2015 2:17 PM
>> To: Thierry Onkelinx; PIKAL Petr
>> Cc: r-help at r-project.org
>> Subject: Re: [R] cut variable within a loop
>> 
>> 
>> 
>> Hi Thierry and Petr,
>> 
>> 
>> 
>> I really appreciate the comments you already gave. Thank you very much for that.
>> 
>> 
>> 
>> Below you can find a link to the data and the code. Hopefully this helps in spotting the error.
>> 
>> 
>> 
>> I still think the issue is that the cut2 function only accepts numbers, and not an "i" that refers to the number at the start of the loop. To answer Petr his question, yes, column 3 and 4 are NA (these are the columns of the second interval). But I don't really understand your point so could you clarify this please?
>> 
>> 
>> 
>> If you use NA as a number of intervals you will get such errors
>> 
>> 
>> 
>> k<-c(2,4,NA,5)
>> 
>> ii<-vector(4, mode="list")
>> 
>> for (i in 1:4) {
>> 
>> ii[[i]] <- cut2(iris[,i], k[i])
>> 
>> }
>> 
>> Error in if (r[1] < cuts[1]) cuts <- c(r[1], cuts) :
>> 
>>  missing value where TRUE/FALSE needed
>> 
>> for (i in 1:4) {
>> 
>> ii[[i]] <- cut(iris[,i], k[i])
>> 
>> }
>> 
>> Error in cut.default(iris[, i], k[i]) : invalid number of intervals
>> 
>> 
>> 
>> If you remove NA from k definition error is gone.
>> 
>> k<-c(2,4,3,5)
>> 
>> ii<-vector(4, mode="list")
>> 
>> 
>> 
>> for (i in 1:4) {
>> 
>> ii[[i]] <- cut(iris[,i], k[i])
>> 
>> }
>> 
>> 
>> 
>> You can try it yourself. The error is not related to cycle; whenever number of intervals in cut call is NA you always get an error.
>> 
>> 
>> 
>> Cheers
>> 
>> Petr
>> 
>> 
>> 
>> https://drive.google.com/folderview?id=0By9u5m3kxn9yfkxxeVNMdnRQQXhoT05CRlJlZVBCWWF2NURMMTNmVFVFeXJXXzhlMWE4SUk&usp=sharing
>> 
>> 
>> 
>> Thank you very much once again!
>> 
>> 
>> 
>> Janka
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 2015-08-11 15:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>> 
>> You'll need to send a reproducible example of the code. We can't run the code that you send. Hence it is hard to help you. See e.g. http://adv-r.had.co.nz/Reproducibility.html
>> 
>> 
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> 
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> 
>> 
>> 
>> 2015-08-11 14:57 GMT+02:00 Janka Vanschoenwinkel <janka.vanschoenwinkel at uhasselt.be>:
>> 
>> Hi Thierry!
>> 
>> 
>> 
>> Thanks for your answer. I tried this, but I get this error:
>> 
>> 
>> 
>> "Error in cut.default(x, k2) : invalid number of intervals"
>> 
>> 
>> 
>> Which is strange because I am not specifying intervals, but the number at where the sample has to be cut?
>> 
>> 
>> 
>> Greetings from Belgium! :-)
>> 
>> 
>> 
>> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>> 
>> Dear Janka,
>> 
>> 
>> 
>> You loop goes for 0 to 100. It should probably go from 1:99
>> 
>> 
>> 
>> Best regards,
>> 
>> 
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> 
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
>> 
>> 
>> 
>> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <janka.vanschoenwinkel at uhasselt.be>:
>> 
>> Dear list members,
>> 
>> I have a loop where I want to do several calculations for different samples
>> and save the results for each sample. These samples are for each loop
>> different. I want to use the "i" in the loop to cut the samples.
>> 
>> So for instance:
>> 
>>   - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
>>   - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
>>   - In loop 99 (i=99), I have a sample from 0-99 and a sample from 99-100.
>> 
>> I built the following function, but there is *a problem with the cut2
>> function* since it doesn't recognize the "i". Outside the lapply loop it
>> works, but not inside the loop.
>> 
>> Could somebody please help me with this problem? Thanks a lot!
>> 
>> 
>> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
>> 
>> 
>> 
>>    o<-lapply(0:100, function(i){
>> 
>> 
>> 
>>        Alldata$irri=cut2(Alldata$irrigation,i)
>> 
>>        levels(Alldata$irri)<-c("0","1")
>> 
>> 
>> 
>>       Alldata_Rainfed<-subset(Alldata, irri == 0)
>> 
>>       Alldata_Irrigation<-subset(Alldata, irri == 1)
>> 
>> 
>> 
>>    #calculations per sample, then store all the values per i and per
>> variable in a dataframe: (the calculations are not shown in this example)
>> 
>> 
>> 
>>     d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
>> 
>> 
>> 
>>   })
>> 
>> 
>> 
>>   out<-as.data.frame(do.call(rbind, o))
>> 
>> 
>> --
>> P Please consider the environment before printing this e-mail
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> 
>> 
>> 
>> Mevrouw Janka Vanschoenwinkel
>> Doctoraatsbursaal - PhD
>> Milieueconomie - Environmental economics
>> 
>> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
>> 
>> www.uhasselt.be/eec
>> 
>> Universiteit Hasselt | Campus Diepenbeek
>> Agoralaan Gebouw D | B-3590 Diepenbeek
>> Kantoor F11
>> 
>> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>> 
>> P Please consider the environment before printing this e-mail
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> 
>> 
>> 
>> Mevrouw Janka Vanschoenwinkel
>> Doctoraatsbursaal - PhD
>> Milieueconomie - Environmental economics
>> 
>> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
>> 
>> www.uhasselt.be/eec
>> 
>> Universiteit Hasselt | Campus Diepenbeek
>> Agoralaan Gebouw D | B-3590 Diepenbeek
>> Kantoor F11
>> 
>> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
>> 
>> P Please consider the environment before printing this e-mail
>> 
>> 
>> 
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> 
> 
> 
> 
> --
> 
> Mevrouw Janka Vanschoenwinkel
> Doctoraatsbursaal - PhD
> Milieueconomie - Environmental economics
> 
> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> 
> www.uhasselt.be/eec
> 
> Universiteit Hasselt | Campus Diepenbeek
> Agoralaan Gebouw D | B-3590 Diepenbeek
> Kantoor F11
> 
> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> 
> P Please consider the environment before printing this e-mail
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mdsumner at gmail.com  Fri Aug 14 23:26:44 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 15 Aug 2015 07:26:44 +1000
Subject: [R] R map data for South Africa
In-Reply-To: <1439570702911-4711123.post@n4.nabble.com>
References: <1439570702911-4711123.post@n4.nabble.com>
Message-ID: <CAAcGz9_drrVWWELNPsFoASgLDdjHOS0g_rKxUqTpGNoJJOoRbg@mail.gmail.com>

See ?raster::getData for the SRTM  option.

Hth

On Saturday, August 15, 2015, jgui001 <j.guilbert at auckland.ac.nz> wrote:
> I am looking for some elevation data to map in R for Cape Town, South
Africa.
> Can it be found in any packages or R data bases?
>
> Cheers
>
>
>
>
> -----
> Josh
> --
> View this message in context:
http://r.789695.n4.nabble.com/R-map-data-for-South-Africa-tp4711123.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com

	[[alternative HTML version deleted]]


From andrluis at ualberta.ca  Fri Aug 14 21:46:38 2015
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Fri, 14 Aug 2015 13:46:38 -0600
Subject: [R] Help
Message-ID: <CAHxKz8aYpYmoy+TvbghdHdSbAuBKctKY=zH2LSL0BzcD1gA72w@mail.gmail.com>

Dear everyone,

Would like to know how to add asterisks and arcs that indicate a subgroup
comparison above box plots to denote statistical diference.

Thank you.

Andre

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Aug 15 10:20:20 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 15 Aug 2015 18:20:20 +1000
Subject: [R] Help
In-Reply-To: <CAHxKz8aYpYmoy+TvbghdHdSbAuBKctKY=zH2LSL0BzcD1gA72w@mail.gmail.com>
References: <CAHxKz8aYpYmoy+TvbghdHdSbAuBKctKY=zH2LSL0BzcD1gA72w@mail.gmail.com>
Message-ID: <CA+8X3fXH2D_kVCkoxd8yL+_syEqYFNQPTLLvqJ6uf6n99+wODw@mail.gmail.com>

Hi Andre,
You can do it manually like this:

testmat<-matrix(rnorm(90),ncol=3)
boxplot(testmat,ylim=c(-3,4))
library(plotrix)
draw.arc(1.5,2,0.5,0,pi,col=1)
draw.arc(2.5,2,0.5,0,pi,col=1)
boxed.labels(c(1.5,2.5),c(3.3,3.3),c("**","***"),border=NA)

Obviously you would have to nudge the arcs and labels around to match
your plot. I don't know of a function that does this automatically.
Also if your aspect ratio is far from 1, the arcs won't be circular.
It is possible to write a function that will use the return values
from boxplot to display rectangular brackets above the boxplots and
then put the asterisks or whatever else you want on the top lines.

Jim


On Sat, Aug 15, 2015 at 5:46 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Dear everyone,
>
> Would like to know how to add asterisks and arcs that indicate a subgroup
> comparison above box plots to denote statistical diference.
>
> Thank you.
>
> Andre
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Aug 15 14:59:31 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 15 Aug 2015 04:59:31 -0800
Subject: [R] Help
In-Reply-To: <CAHxKz8aYpYmoy+TvbghdHdSbAuBKctKY=zH2LSL0BzcD1gA72w@mail.gmail.com>
Message-ID: <52E4E2B6280.0000093Djrkrideau@inbox.com>

Hi Andr?,
 You have not told us how you are creating the boxplots. See http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and http://adv-r.had.co.nz/Reproducibility.html for some suggestions on how to ask a question for the R-help list.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: andrluis at ualberta.ca
> Sent: Fri, 14 Aug 2015 13:46:38 -0600
> To: r-help at r-project.org
> Subject: [R] Help
> 
> Dear everyone,
> 
> Would like to know how to add asterisks and arcs that indicate a subgroup
> comparison above box plots to denote statistical diference.
> 
> Thank you.
> 
> Andre
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From ajdamico at gmail.com  Sat Aug 15 18:44:44 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 15 Aug 2015 12:44:44 -0400
Subject: [R] minimal reproducible read.fwf() example that crashes the
 console on windows 8 with 32-bit R
Message-ID: <CAOwvMDwx6ahGy+V9=ej5z5iskkzviZ370Ce_kZCiZWbZnWYRVw@mail.gmail.com>

hi, if i copy and paste this (pretty straightforward) code into R 3.2.2's
32-bit console, the program dies.  if i use 64-bit R, the console doesn't
die, but the process ends with a weird line-ending warning.  i'm under the
impression that if the console crashes, it's a bug?  but i wanted to check
with r-help that i'm not doing something silly before filing a formal bug
report..

i get the same crash using 3.2.1 but do not need setInternet2( FALSE )

if i use 3.2.22 with setInternet2( TRUE ) then the download throws an
internet connectivity error (but the console does not crash)

thanks!






sessionInfo()
# R version 3.2.2 (2015-08-14)
# Platform: i386-w64-mingw32/i386 (32-bit)
# Running under: Windows 8 x64 (build 9200)

# locale:
# [1] LC_COLLATE=English_United States.1252
# [2] LC_CTYPE=English_United States.1252
# [3] LC_MONETARY=English_United States.1252
# [4] LC_NUMERIC=C
# [5] LC_TIME=English_United States.1252

# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods   base

setInternet2( FALSE )

widths <- c(5, 2, -3, 2, 2, 1, 1, 1, 1, 1, 1, 5, -2, 2, 1, 1, 1, 2, 2,
1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,
2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, -1, 1, 2, 1, 2, 1, 2,
2, 1, 1, 1, 5, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1,
2, 1, 2, 2, 1, 1, 1, 5, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2,
2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 5, 1, 1, 2, 2, 1, 1, 1, 5, 5, 5,
5, 5, 5, 1, 3, 5, 5, 3, 5, 5, 3, 5, 5, 3, 5, 5, 5, 1, 1, 1, 1,
1, 1, 1, 3, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1,
2, 2, 2, 2, 2, 7, 7, 7, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, -2369, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8)

varnames <- c("SEQNUM", "RECTYPE", "PREG_NUM", "PREGTYPE", "NUMBIRTH",
"OUTCOME1",
"OUTCOME2", "OUTCOME3", "DELIVERY", "NEWFLAG", "B14MO", "B_15",
"B_16", "BOX7", "B_17", "B_18", "B_19", "B_20", "B_21", "B_22",
"B_23", "B_24", "B25A", "B25B", "B25C", "B25D", "B25E", "B25F",
"B_26", "B_27", "B_28", "B29A", "B29B", "B29C", "B29D", "B29E",
"B29F", "B29G", "B_30", "BOX8", "BLIVEBIR", "LASTPREG", "B12_1",
"B31LB_1", "B31OZ_1", "B32_1", "BOX10_1", "B33A_1", "B33B_1",
"B33C_1", "B33D_1", "B33E_1", "B33F_1", "B34_1", "B35_1", "B36_1",
"B37_1", "B38_1", "BOX11_1", "B39_1", "B40_1", "B41MO_1", "BOX12_1",
"B42_1", "B43_1", "B44_1", "B12_2", "B31LB_2", "B31OZ_2", "B32_2",
"BOX10_2", "B33A_2", "B33B_2", "B33C_2", "B33D_2", "B33E_2",
"B33F_2", "B34_2", "B35_2", "B36_2", "B37_2", "B38_2", "BOX11_2",
"B39_2", "B40_2", "B41MO_2", "BOX12_2", "B42_2", "B43_2", "B44_2",
"B12_3", "B31LB_3", "B31OZ_3", "B32_3", "BOX10_3", "B33A_3",
"B33B_3", "B33C_3", "B33D_3", "B33E_3", "B33F_3", "B34_3", "B35_3",
"B36_3", "B37_3", "B38_3", "BOX11_3", "B39_3", "B40_3", "B41MO_3",
"BOX12_3", "B42_3", "B43_3", "B44_3", "B_45", "B_46", "C12A",
"C13F1MO", "C13T1MO", "C13F2MO", "C13T2MO", "C13F3MO", "C13T3MO",
"C_14", "C15M1", "C16M1MO", "C17M1MO", "C15M2", "C16M2MO", "C17M2MO",
"C15M3", "C16M3MO", "C17M3MO", "C15M4", "C16M4MO", "C17M4MO",
"C18MO", "C_19", "C_20", "C_21", "C_22", "C_23", "C_24", "C_25",
"PRGLNGTH", "AGEPREG", "WANTWIFE", "WANTMAN", "OUTCOME", "YRPREG",
"FMAROUT", "LIVBABY1", "LIVBABY2", "LIVBABY3", "LOW1", "LOW2",
"LOW3", "PREGTEST", "PNCAREWK", "PNCARENO", "RACE", "CEND84",
"BIRTH071", "BIRTH072", "BIRTH073", "PREGNUM7", "PREGNUM8", "W_1",
"W_2", "W_3", "W_4", "W_5", "FLAG341", "FLAG372", "FLAG373",
"FLAG374", "FLAG375", "FLAG376", "FLAG426", "FLAG427", "FLAG614",
"FLAG621", "FLAG991", "FLAG992", "REPWGT1", "REPWGT2", "REPWGT3",
"REPWGT4", "REPWGT5", "REPWGT6", "REPWGT7", "REPWGT8", "REPWGT9",
"REPWGT10", "REPWGT11", "REPWGT12", "REPWGT13", "REPWGT14", "REPWGT15",
"REPWGT16", "REPWGT17", "REPWGT18", "REPWGT19", "REPWGT20", "REPWGT21",
"REPWGT22", "REPWGT23", "REPWGT24", "REPWGT25", "REPWGT26", "REPWGT27",
"REPWGT28", "REPWGT29", "REPWGT30", "REPWGT31", "REPWGT32", "REPWGT33",
"REPWGT34", "REPWGT35", "REPWGT36", "REPWGT37", "REPWGT38", "REPWGT39",
"REPWGT40", "REPWGT41", "REPWGT42", "REPWGT43", "REPWGT44", "REPWGT45",
"REPWGT46", "REPWGT47", "REPWGT48", "REPWGT49", "REPWGT50", "REPWGT51",
"REPWGT52", "REPWGT53", "REPWGT54", "REPWGT55", "REPWGT56", "REPWGT57",
"REPWGT58", "REPWGT59", "REPWGT60", "REPWGT61", "REPWGT62", "REPWGT63",
"REPWGT64", "REPWGT65", "REPWGT66", "REPWGT67", "REPWGT68", "REPWGT69",
"REPWGT70", "REPWGT71", "REPWGT72", "REPWGT73", "REPWGT74", "REPWGT75",
"REPWGT76", "REPWGT77", "REPWGT78", "REPWGT79", "REPWGT80", "REPWGT81",
"REPWGT82", "REPWGT83", "REPWGT84", "REPWGT85", "REPWGT86", "REPWGT87",
"REPWGT88", "REPWGT89", "REPWGT90", "REPWGT91", "REPWGT92", "REPWGT93",
"REPWGT94", "REPWGT95", "REPWGT96", "REPWGT97", "REPWGT98", "REPWGT99",
"REPWGT100")

x <-
    read.fwf(
        file = "
ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Datasets/NSFG/1988PregData.dat"
,
        widths = widths ,
        col.names = varnames ,
        comment.char = "" ,
        colClasses = "character" ,
        buffersize = 50 ,
        n = 1000 ,
        skip = 0
    )

	[[alternative HTML version deleted]]


From r.otojanov at qmul.ac.uk  Sat Aug 15 18:04:58 2015
From: r.otojanov at qmul.ac.uk (mrrox)
Date: Sat, 15 Aug 2015 09:04:58 -0700 (PDT)
Subject: [R] Cumulative vs. non-cumulative IRFs in R
Message-ID: <1439654698666-4711138.post@n4.nabble.com>

I am using irf function from vars package. I am trying to derive cumulative
IRFs.

The following code describes the case of deriving cumulative IRFs:

irf(vecm.l, impulse = c("g","p","h","l","s"), response = "g",  cumulative =
TRUE,n.ahead = 20, ortho=TRUE)

I got the output and plotted it, it looked like cumulative values of
estimated MA coefficients. But then I ran the code with cumulative switched
to FALSE as below:

irf(vecm.l, impulse = c("g","p","h","l","s"), response = "g",  cumulative =
FALSE,n.ahead = 20, ortho=TRUE)

Output from these two codes is identical. Including cumulative = TRUEin the
irf function does not produce the cumulative responses??

Please note that I converted a vecm model to var using vec2var, hence the
input model is called vecm.l here. Though, I doubt it plays any significance
in deriving cumulative IRFs.

I would appreciate your comment, am I specifying the function incorrectly?
Thanks,



--
View this message in context: http://r.789695.n4.nabble.com/Cumulative-vs-non-cumulative-IRFs-in-R-tp4711138.html
Sent from the R help mailing list archive at Nabble.com.


From dingernikita at gmail.com  Sat Aug 15 19:06:44 2015
From: dingernikita at gmail.com (Nikita Dinger)
Date: Sat, 15 Aug 2015 22:36:44 +0530
Subject: [R] Error -> cannot open file 'specdata/001.csv': No such file or
 directory; Windows 8, R Version 3.2.1
Message-ID: <CAN6BBTQ2zR9Ec-CxF9eZgPJZecsYP1=RFETEfcCeogo4oX9htQ@mail.gmail.com>

I am having a problem in opening the excel files in specdata folder.

I have completed coding the R program for the assignment but when I run the
following commands in the R console,

*source("pollutantmean.R")*
*> pollutantmean("specdata", "nitrate", 23)*

I get an error message stating

*Error in file(file, "rt") : cannot open the connection*
*In addition: Warning message:*
*In file(file, "rt") :*
*  cannot open file 'specdata/023.csv': No such file or directory*

I tried everything and reset my Working Directory to


*C:/Users/acer/My Documents/specdata/rprog-data-specdata/specdata*

After the last specdata folder are all the excel sheets numbered 001 to 332.

I searched the internet and all other options available, and got a solution
to open it using the following command:

*df <- read.csv("specdata/001.csv")*


This generated the following error message

*Error in file(file, "rt") : cannot open the connection*
*In addition: Warning message:*
*In file(file, "rt") :*
*  cannot open file 'specdata/001.csv': No such file or directory*

I have tried various other commands also such as


*path <- c(paste("./",directory, "/",formatC(id[i], width=3,
flag=0),".csv",sep=""))*

However, all the commands show some error.

What shall I do?
I am using the 3.2.1 version of R on a Windows 8 laptop.

Regards,
Nikita Dinger

	[[alternative HTML version deleted]]


From jeffrey.slagle at gmail.com  Sat Aug 15 19:59:44 2015
From: jeffrey.slagle at gmail.com (Jeff Slagle)
Date: Sat, 15 Aug 2015 13:59:44 -0400
Subject: [R] Bayesian data analysis recommendations
Message-ID: <01AE019A-4C74-4758-A0A6-628E76658F79@gmail.com>

I have a question about AtelieR out on stackoverflow.com.  Perhaps you could forward the link to:

Yvonnick Noel
University of Brittany
Department of Psychology
Rennes, France

Here is the link:

AtelieR GTK GUI
http://stackoverflow.com/q/32023277/5229811?sem=2

Thank you,
Jeff
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Aug 15 21:03:16 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Aug 2015 12:03:16 -0700
Subject: [R] Error -> cannot open file 'specdata/001.csv': No such file
	or directory; Windows 8, R Version 3.2.1
In-Reply-To: <CAN6BBTQ2zR9Ec-CxF9eZgPJZecsYP1=RFETEfcCeogo4oX9htQ@mail.gmail.com>
References: <CAN6BBTQ2zR9Ec-CxF9eZgPJZecsYP1=RFETEfcCeogo4oX9htQ@mail.gmail.com>
Message-ID: <6B5E174F-3038-4E05-A528-BD7ABDAB1456@comcast.net>



This is pretty obviously difficulty in completing an assignment for a Coursera task. You are asked by the Course Director of the entry-level R course to post your questions to a website established for the purpose of requesting assistance. Rhelp is a text-only mailing list (although you might have been duped into thinking that it was a website by the Nabble mirror.) Rhelp has a "no homework" policy.

-- 
David.


On Aug 15, 2015, at 10:06 AM, Nikita Dinger wrote:

> I am having a problem in opening the excel files in specdata folder.
> 
> I have completed coding the R program for the assignment but when I run the
> following commands in the R console,
> 
> *source("pollutantmean.R")*
> *> pollutantmean("specdata", "nitrate", 23)*
> 
> I get an error message stating
> 
> *Error in file(file, "rt") : cannot open the connection*
> *In addition: Warning message:*
> *In file(file, "rt") :*
> *  cannot open file 'specdata/023.csv': No such file or directory*
> 
> I tried everything and reset my Working Directory to
> 
> 
> *C:/Users/acer/My Documents/specdata/rprog-data-specdata/specdata*
> 
> After the last specdata folder are all the excel sheets numbered 001 to 332.
> 
> I searched the internet and all other options available, and got a solution
> to open it using the following command:
> 
> *df <- read.csv("specdata/001.csv")*
> 
> 
> This generated the following error message
> 
> *Error in file(file, "rt") : cannot open the connection*
> *In addition: Warning message:*
> *In file(file, "rt") :*
> *  cannot open file 'specdata/001.csv': No such file or directory*
> 
> I have tried various other commands also such as
> 
> 
> *path <- c(paste("./",directory, "/",formatC(id[i], width=3,
> flag=0),".csv",sep=""))*
> 
> However, all the commands show some error.
> 
> What shall I do?
> I am using the 3.2.1 version of R on a Windows 8 laptop.
> 
> Regards,
> Nikita Dinger
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Aug 15 23:01:47 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Aug 2015 14:01:47 -0700
Subject: [R] Is there "orphan code" in seq.default?
Message-ID: <28540248-CE88-4E16-900D-B0AD5B280E55@comcast.net>

I was looking at the code in seq.default and saw code that I think would throw an error if it were ever executed, although it will not because there is first a test to see if one of its arguments is missing. Near the end of the function body is this code:

    else if (missing(by)) {
        if (missing(to)) 
            to <- from + length.out - 1L
        if (missing(from)) 
            from <- to - length.out + 1L
        if (length.out > 2L) 
            if (from == to) 
                rep.int(from, length.out)
            else as.vector(c(from, from + seq_len(length.out - 
                2L) * by, to))

Notice that the last call to `else` would be returning a value calculated with 'by' which was already established as missing.

-- 

David Winsemius
Alameda, CA, USA


From mtmorgan at fredhutch.org  Sat Aug 15 23:21:57 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sat, 15 Aug 2015 14:21:57 -0700
Subject: [R] Is there "orphan code" in seq.default?
In-Reply-To: <28540248-CE88-4E16-900D-B0AD5B280E55@comcast.net>
References: <28540248-CE88-4E16-900D-B0AD5B280E55@comcast.net>
Message-ID: <55CFAD75.8060201@fredhutch.org>

On 08/15/2015 02:01 PM, David Winsemius wrote:
> I was looking at the code in seq.default and saw code that I think would throw an error if it were ever executed, although it will not because there is first a test to see if one of its arguments is missing. Near the end of the function body is this code:
>
>      else if (missing(by)) {
>          if (missing(to))
>              to <- from + length.out - 1L
>          if (missing(from))
>              from <- to - length.out + 1L
>          if (length.out > 2L)
>              if (from == to)
>                  rep.int(from, length.out)
>              else as.vector(c(from, from + seq_len(length.out -
>                  2L) * by, to))
>
> Notice that the last call to `else` would be returning a value calculated with 'by' which was already established as missing.
>

missing arguments can have default values

 > f = function(by="sea") if (missing(by)) by
 > f()
[1] "sea"

which is the case for seq.default

 > args(seq.default)
function (from = 1, to = 1, by = ((to - from)/(length.out - 1)),
     length.out = NULL, along.with = NULL, ...)


Martin Morgan
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From searl at vt.edu  Sun Aug 16 02:09:43 2015
From: searl at vt.edu (Steve E.)
Date: Sat, 15 Aug 2015 17:09:43 -0700 (PDT)
Subject: [R] apply with multiple references and database interactivity
Message-ID: <1439683783295-4711148.post@n4.nabble.com>

Hi R Colleagues,

I have a small R script that relies on two for-loops to pull data from a
database, make some edits to the data returned from the query, then inserts
the updated data back into the database. The script works just fine, no
problems, except that I am striving to get away from loops, and to focus on
the apply family of tools. In this case, though, I did not know quite where
to start with apply. I wonder if someone more adept with apply would not
mind taking a look at this, and suggesting some tips as to how this could
have been accomplished with apply instead of nested loops. More details on
what the script is accomplishing are included below.

Thanks in advance for your help and consideration.


Steve

Here, I have a df that includes a list of keywords that need to be edited,
and the corresponding edit. The script goes through a database of people,
identifies whether any of the keywords associated with each person are in
the list of keywords to edit, and, if so, pulls in the list of keywords and
the person details, swaps the new keyword for the old keyword, then inserts
the updated keywords back into the database for that person (many keywords
are associated with each person, and they are in an array, hence the
somewhat complicated procedure). The if-statement provides a list of
keywords in the df that were not found in the database, and 'm' is just a
counter to help me know how many keywords the script changed.

for(i in 1:nrow(keywords)) {
  pull <- dbGetQuery(conn = con, statement = paste0("SELECT person_id,
expertise FROM people WHERE expertise RLIKE '; ", keywords[i, 2], ";'"))
  pull$expertise <- gsub(keywords[i, 2], keywords[i, 3], pull$expertise)
  if (nrow(pull)==0) {
    sink('~/Desktop/r1', append = TRUE)
    print(keywords[i, ]$keyword)
    sink() } else
    {
    for (j in 1:nrow(pull)) {
    dbSendQuery(conn = con, statement = paste0("UPDATE people SET expertise
= '", pull[j, ]$expertise, "' WHERE person_id = ", pull[j, ]$person_id)) }
      m=m+1
    } }




--
View this message in context: http://r.789695.n4.nabble.com/apply-with-multiple-references-and-database-interactivity-tp4711148.html
Sent from the R help mailing list archive at Nabble.com.


From jmtruppia at gmail.com  Sun Aug 16 06:06:39 2015
From: jmtruppia at gmail.com (Juan Manuel Truppia)
Date: Sun, 16 Aug 2015 04:06:39 +0000
Subject: [R] reikon: A package to interact with Thomson Reuters Eikon from R
Message-ID: <CAO2XSvdGtGQ4tJn5B=Rh-y+nY6zcPGayq01ctSzf1zRLzbWxwA@mail.gmail.com>

Hi, I'm developing a package to interact from R with Eikon, the Thomson
Reuters financial data platform (a la Rblpapi).
You can find the package in Bitbucket at
https://bitbucket.org/juancentro/reikon.
The package is fully functional, but requires testing and usage in other
environments than mine.
It has documentation and a vignette.
Please report any bugs directly in Bitbucket, and I would gladly accept
help with the development.

Regards

Juan

	[[alternative HTML version deleted]]


From hazel_knipe at hotmail.co.uk  Sun Aug 16 11:10:51 2015
From: hazel_knipe at hotmail.co.uk (Aureus)
Date: Sun, 16 Aug 2015 02:10:51 -0700 (PDT)
Subject: [R] All results not showing in console (very large dataset)
Message-ID: <1439716251103-4711150.post@n4.nabble.com>

Hi, 

I have a very large dataset, and have run a simper test on it. However, the
output is so large that I cannot see the first sets of results in the
console. How can I view them? I have tried saving to text, but it only saves
what's in the console. 

Or is there a way to report the first X number of results from each
contrasting test? Or summarise each test result individually?

Thanks!





--
View this message in context: http://r.789695.n4.nabble.com/All-results-not-showing-in-console-very-large-dataset-tp4711150.html
Sent from the R help mailing list archive at Nabble.com.


From dingernikita at gmail.com  Sun Aug 16 11:01:00 2015
From: dingernikita at gmail.com (Nikita Dinger)
Date: Sun, 16 Aug 2015 14:31:00 +0530
Subject: [R] Error
Message-ID: <CAN6BBTSHwwBM7hKK7Bh0RHwChhdzeZ00aTbEptdKAYyL9=FPuQ@mail.gmail.com>

Dear Sir,

I am getting this error

Error in rep(xi, length.out = nvar) :
  attempt to replicate an object of type 'closure'

I have read through the websites but cant really comprehend what this means?
Need your help.

This is my code

complete <- function(directory, idvec = 1:332) {
        df <- data.frame(id = integer(), nobs = integer())
    for (id in idvec) {
        filename <- paste(directory, "/",
                          sprintf("%03d", as.integer(id)),
                          ".csv", sep = "")
filename <- list.files()
        data <- rbind(data, read.csv(filename[id]))
}
str(data)
for (id in idvec)
        {nd <- data.frame(id = id,
                         nobs = nrow(na.omit(data)))
        df <- rbind(df, nd)
    }
    return(df)

}

	[[alternative HTML version deleted]]


From swagato1987 at gmail.com  Sun Aug 16 10:17:02 2015
From: swagato1987 at gmail.com (Swagato Chatterjee)
Date: Sun, 16 Aug 2015 13:47:02 +0530
Subject: [R] Running R in Server
Message-ID: <CACruXeuAZustY5QBM7X9jnhotzMAq=-u8h2vsi1Qn4XHveb0=g@mail.gmail.com>

Hello,

I have written a R script which runs a regression of a dataset and saves
the result in a csv file.

Now this dataset has to be edited periodically which is done in a server. I
need to run the R script in a server so that the results can also be shared
in a server and used in a web application.

I have coded in R and have used R in windows. I have never used
Ubuntu/Linux. Is there a step by step guide on how to run a R code in
server?

Thanks and Regards,

-- 
Swagato Chatterjee

	[[alternative HTML version deleted]]


From swagato1987 at gmail.com  Sun Aug 16 10:27:56 2015
From: swagato1987 at gmail.com (Swagato Chatterjee)
Date: Sun, 16 Aug 2015 13:57:56 +0530
Subject: [R]  Running R in Server
Message-ID: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>

Hello,

I have written a R script which runs a regression of a dataset and saves
the result in a csv file.

Now this dataset has to be edited periodically which is done in a server. I
need to run the R script in a server so that the results can also be shared
in a server and used in a web application.

I have coded in R and have used R in windows. I have never used
Ubuntu/Linux. Is there a step by step guide on how to run a R code in
server?

Thanks and Regards,

Swagato

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sun Aug 16 14:51:35 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 16 Aug 2015 04:51:35 -0800
Subject: [R] All results not showing in console (very large dataset)
In-Reply-To: <1439716251103-4711150.post@n4.nabble.com>
Message-ID: <5F65CDB4647.00000663jrkrideau@inbox.com>


Write the results into an object and use head()?

Quick example
dat1  <-  data.frame(aa = sample(x, 500, replace = TRUE),
bb  = sample(x, 500, replace = TRUE),
cc  = sample(x, 500, replace = TRUE),
dd =sample(x, 500, replace = TRUE)
)

head(dat1)

see ?head for more details

John Kane
Kingston ON Canada


> -----Original Message-----
> From: hazel_knipe at hotmail.co.uk
> Sent: Sun, 16 Aug 2015 02:10:51 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] All results not showing in console (very large dataset)
> 
> Hi,
> 
> I have a very large dataset, and have run a simper test on it. However,
> the
> output is so large that I cannot see the first sets of results in the
> console. How can I view them? I have tried saving to text, but it only
> saves
> what's in the console.
> 
> Or is there a way to report the first X number of results from each
> contrasting test? Or summarise each test result individually?
> 
> Thanks!
> 
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/All-results-not-showing-in-console-very-large-dataset-tp4711150.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From bgunter.4567 at gmail.com  Sun Aug 16 16:17:05 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 16 Aug 2015 07:17:05 -0700
Subject: [R] Error
In-Reply-To: <CAN6BBTSHwwBM7hKK7Bh0RHwChhdzeZ00aTbEptdKAYyL9=FPuQ@mail.gmail.com>
References: <CAN6BBTSHwwBM7hKK7Bh0RHwChhdzeZ00aTbEptdKAYyL9=FPuQ@mail.gmail.com>
Message-ID: <CAGxFJbQge-r6KP6RPrH+29tHabCk+ppxBGwJXVSfS++mWzNEfA@mail.gmail.com>

What do you think "data" is in:

rbind(data, read.csv(filename[id]))

str(data) ## before running your function

will show you that it is probably the built in function data() which
is probably the source of your error.


Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sun, Aug 16, 2015 at 2:01 AM, Nikita Dinger <dingernikita at gmail.com> wrote:
> Dear Sir,
>
> I am getting this error
>
> Error in rep(xi, length.out = nvar) :
>   attempt to replicate an object of type 'closure'
>
> I have read through the websites but cant really comprehend what this means?
> Need your help.
>
> This is my code
>
> complete <- function(directory, idvec = 1:332) {
>         df <- data.frame(id = integer(), nobs = integer())
>     for (id in idvec) {
>         filename <- paste(directory, "/",
>                           sprintf("%03d", as.integer(id)),
>                           ".csv", sep = "")
> filename <- list.files()
>         data <- rbind(data, read.csv(filename[id]))
> }
> str(data)
> for (id in idvec)
>         {nd <- data.frame(id = id,
>                          nobs = nrow(na.omit(data)))
>         df <- rbind(df, nd)
>     }
>     return(df)
>
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jszhao at yeah.net  Sun Aug 16 16:38:42 2015
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sun, 16 Aug 2015 22:38:42 +0800
Subject: [R] difference between write.csv(...) and write.table(..., sep=", ")
Message-ID: <55D0A072.2060605@yeah.net>

Hi there,

I notice that write.csv is a wrap of write.table. However, I can't get 
the same results using both functions. Here is a reproducible example:

 > x <- matrix(1:6, nrow =2)
 > rownames(x) <- letters[1:2]
 > colnames(x) <- LETTERS[1:3]
 > write.csv(x, "")
"","A","B","C"
"a",1,3,5
"b",2,4,6
 > write.table(x, "", sep = ",")
"A","B","C"
"a",1,3,5
"b",2,4,6

The difference of outputs from both functions is clear.

Is it possible to get the same results of write.csv using write.table?

Any suggestions will be really appreciated. Thanks in advance.

Best,
Jinsong


From lists at dewey.myzen.co.uk  Sun Aug 16 16:53:09 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 16 Aug 2015 15:53:09 +0100
Subject: [R] difference between write.csv(...) and write.table(..., sep=",
 ")
In-Reply-To: <55D0A072.2060605@yeah.net>
References: <55D0A072.2060605@yeah.net>
Message-ID: <55D0A3D5.1040209@dewey.myzen.co.uk>

I think that if you do ?write.csv and then page down to the section
entitled CSV files the mystery will be solved for you in the first few 
paragraphs.

On 16/08/2015 15:38, Jinsong Zhao wrote:
> Hi there,
>
> I notice that write.csv is a wrap of write.table. However, I can't get
> the same results using both functions. Here is a reproducible example:
>
>  > x <- matrix(1:6, nrow =2)
>  > rownames(x) <- letters[1:2]
>  > colnames(x) <- LETTERS[1:3]
>  > write.csv(x, "")
> "","A","B","C"
> "a",1,3,5
> "b",2,4,6
>  > write.table(x, "", sep = ",")
> "A","B","C"
> "a",1,3,5
> "b",2,4,6
>
> The difference of outputs from both functions is clear.
>
> Is it possible to get the same results of write.csv using write.table?
>
> Any suggestions will be really appreciated. Thanks in advance.
>
> Best,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bhh at xs4all.nl  Sun Aug 16 16:57:07 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 16 Aug 2015 16:57:07 +0200
Subject: [R] difference between write.csv(...) and write.table(..., sep=",
	")
In-Reply-To: <55D0A072.2060605@yeah.net>
References: <55D0A072.2060605@yeah.net>
Message-ID: <D134485A-60BB-4136-AC73-C7A76C5F7CF3@xs4all.nl>


> On 16-08-2015, at 16:38, Jinsong Zhao <jszhao at yeah.net> wrote:
> 
> Hi there,
> 
> I notice that write.csv is a wrap of write.table. However, I can't get the same results using both functions. Here is a reproducible example:
> 
> > x <- matrix(1:6, nrow =2)
> > rownames(x) <- letters[1:2]
> > colnames(x) <- LETTERS[1:3]
> > write.csv(x, "")
> "","A","B","C"
> "a",1,3,5
> "b",2,4,6
> > write.table(x, "", sep = ",")
> "A","B","C"
> "a",1,3,5
> "b",2,4,6
> 
> The difference of outputs from both functions is clear.
> 
> Is it possible to get the same results of write.csv using write.table?
> 

Yes. Read  the item col.names in the help for write.table and go to the section ?CSV files?..

Use  write.table(x, "", sep = ",", col.names=NA)

Learn to use R?s help.

Berend

> Any suggestions will be really appreciated. Thanks in advance.
> 
> Best,
> Jinsong
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Sun Aug 16 16:59:50 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sun, 16 Aug 2015 09:59:50 -0500
Subject: [R] difference between write.csv(...) and write.table(..., sep=",
 ")
In-Reply-To: <55D0A072.2060605@yeah.net>
References: <55D0A072.2060605@yeah.net>
Message-ID: <96130151-F1A6-44A0-9C43-7E4079495FF3@me.com>


> On Aug 16, 2015, at 9:38 AM, Jinsong Zhao <jszhao at yeah.net> wrote:
> 
> Hi there,
> 
> I notice that write.csv is a wrap of write.table. However, I can't get the same results using both functions. Here is a reproducible example:
> 
> > x <- matrix(1:6, nrow =2)
> > rownames(x) <- letters[1:2]
> > colnames(x) <- LETTERS[1:3]
> > write.csv(x, "")
> "","A","B","C"
> "a",1,3,5
> "b",2,4,6
> > write.table(x, "", sep = ",")
> "A","B","C"
> "a",1,3,5
> "b",2,4,6
> 
> The difference of outputs from both functions is clear.
> 
> Is it possible to get the same results of write.csv using write.table?
> 
> Any suggestions will be really appreciated. Thanks in advance.
> 
> Best,
> Jinsong


> write.csv(x)
"","A","B","C"
"a",1,3,5
"b?,2,4,6


> write.table(x, sep = ",", qmethod = "double", col.names = NA)
"","A","B","C"
"a",1,3,5
"b?,2,4,6


Read the section on CSV files in ?write.table

Regards,

Marc Schwartz


From janka.vanschoenwinkel at uhasselt.be  Sun Aug 16 17:57:15 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Sun, 16 Aug 2015 17:57:15 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <154AA9FB-F7B6-4212-9373-761F475CA59B@comcast.net>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>
	<CAHymutKPfSM-qfbp9dLQgUpErUKp0tHj476fCPP8_r5aFiUxyQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39DE6@SRVEXCHMBX.precheza.cz>
	<CAHymutK__NMQFbWJsCk3aYw3Wz3S1gLmGFW=kFoxQ+yh+g3PqQ@mail.gmail.com>
	<154AA9FB-F7B6-4212-9373-761F475CA59B@comcast.net>
Message-ID: <CAHymutKOx3yMR_Es0db7UhBEmJa8WCGi=gkNfXJuavX+vm7q_A@mail.gmail.com>

Hi David,

Thanks for your comment. I'll explain what I want to do. I explained it
already earlier but the explanation might have gone lost in some of the
emails.

The variable irrigation ranges from 0 to 100. (maybe not in de small sample
I gave, but in reality I have over 60000 observations and there the
variable ranges from 0 to 100). I want to make (and use) 100 different
samples. The sample is based each time on the "i" that I put at the
beginning of the loop.

So:

i = 1: this means there are 2 subsets. One from 0-1, another from 1-100
i = 2: this means there are 2 subsets. One from 0-2, another from 2-100
i = 3: this means there are 2 subsets. One from 0-3, another from 3-100
i = 4: this means there are 2 subsets. One from 0-4, another from 4-100
...
i = 96: this means there are 2 subsets. One from 0-96, another from 96-100
i = 97: this means there are 2 subsets. One from 0-97, another from 97-100
i = 98: this means there are 2 subsets. One from 0-98, another from 98-100
i = 99: this means there are 2 subsets. One from 0-99, another from 99-100

It might be possible that i = 1 and i = 2 give the same results in the
small dataset. But in the full dataset all numbers are represented.

The cut2 function is capable of "cutting" a sample based on a number
supplied. Yet, when I tell him this number is "i", then it doesn't work. If
instead I write that the number is 10, then it does work and it gives me 2
subsets from 0-10 and from 10-100.

Hope this is more clear!

Janka


2015-08-14 20:10 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> When using a function in R you may need to supply an argument name. Are
> you expecting this to be the number of groups. I cannot decipher the intent
> here with such sparse commentary, but this call to `cut2` does not make
> sense to me. Perhaps you meant the number of groups? .... in which case you
> need  cut2( Alldata$irrigation, g=i ), since the arguments to cut2 are not
> that same as the arguments to cut.
>
> At the moment you are implicitly sending on the first pass a 1 and then on
> the second pass a 2 to the second argument of cut2 which is the `breaks`
> argument. So you wold be getting two different factors each with different
> cut-point levels. I looked at your data and in point of fact there would be
> no difference since you have 29 zero values and no values between 0 and 1.
>
> > table(cut2(dat$irrigation, 1))
>
>         0 [  1,100]
>        29        21
> > table(cut2(dat$irrigation, 2))
>
>         0 [  2,100]
>        29        21
>
>
>
>
> >  levels(Alldata$irri)<-c("0","1")
> >
> >  Alldata_Rainfed<-subset(Alldata, irri == 0)
> >  Alldata_Irrigation<-subset(Alldata, irri == 1)
> >
> >  Alldata_Rainfed$w<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
> >  Alldata_Irrigation$w<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> >
> >  OLS_Rainfed <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
> >                      ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
> >                      pdnsty+portsML+cities500k+rentedland+subsidies1+
> >                      elevmean+elevrange+
> >                      t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
> >                      AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
> >                    weights=w,Alldata_Rainfed)
> >
> >  attach(Alldata_Rainfed)
> >
> >  CoefRainfed_ps1 <- OLS_Rainfed$coeff[2]
> >  CoefRainfed_ps2 <- OLS_Rainfed$coeff[3]
> >  CoefRainfed_ps3 <- OLS_Rainfed$coeff[4]
> >  CoefRainfed_ps4 <- OLS_Rainfed$coeff[5]
> >  CoefRainfed_ts1 <- OLS_Rainfed$coeff[6]
> >  CoefRainfed_ts2 <- OLS_Rainfed$coeff[7]
> >  CoefRainfed_ts3 <- OLS_Rainfed$coeff[8]
> >  CoefRainfed_ts4 <- OLS_Rainfed$coeff[9]
> >  CoefRainfed_ps1sq <- OLS_Rainfed$coeff[10]
> >  CoefRainfed_ps2sq <- OLS_Rainfed$coeff[11]
> >  CoefRainfed_ps3sq <- OLS_Rainfed$coeff[12]
> >  CoefRainfed_ps4sq <- OLS_Rainfed$coeff[13]
> >  CoefRainfed_ts1sq <- OLS_Rainfed$coeff[14]
> >  CoefRainfed_ts2sq <- OLS_Rainfed$coeff[15]
> >  CoefRainfed_ts3sq <- OLS_Rainfed$coeff[16]
> >  CoefRainfed_ts4sq <- OLS_Rainfed$coeff[17]
> >
> >  attach(Alldata_Rainfed)
> >
> >
> >  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY
> level)
> >  # Maar dit is dus de marginale impact per LnALVperHA?
> >
> >  Alldata_Rainfed$MEts1 =
> > CoefRainfed_ts1+2*CoefRainfed_ts1sq*Alldata_Rainfed$ts1
> >  Alldata_Rainfed$MEts2 =
> > CoefRainfed_ts2+2*CoefRainfed_ts2sq*Alldata_Rainfed$ts2
> >  Alldata_Rainfed$MEts3 =
> > CoefRainfed_ts3+2*CoefRainfed_ts3sq*Alldata_Rainfed$ts3
> >  Alldata_Rainfed$MEts4 =
> > CoefRainfed_ts4+2*CoefRainfed_ts4sq*Alldata_Rainfed$ts4
> >  Alldata_Rainfed$MEt   = Alldata_Rainfed$MEts1 +
> > Alldata_Rainfed$MEts2 + Alldata_Rainfed$MEts3 + Alldata_Rainfed$MEts4
> >
> >  Alldata_Rainfed$MEps1 =
> > CoefRainfed_ps1+2*CoefRainfed_ps1sq*Alldata_Rainfed$ps1
> >  Alldata_Rainfed$MEps2 =
> > CoefRainfed_ps2+2*CoefRainfed_ps2sq*Alldata_Rainfed$ps2
> >  Alldata_Rainfed$MEps3 =
> > CoefRainfed_ps3+2*CoefRainfed_ps3sq*Alldata_Rainfed$ps3
> >  Alldata_Rainfed$MEps4 =
> > CoefRainfed_ps4+2*CoefRainfed_ps4sq*Alldata_Rainfed$ps4
> >  Alldata_Rainfed$MEp   = Alldata_Rainfed$MEps1 +
> > Alldata_Rainfed$MEps2 + Alldata_Rainfed$MEps3 + Alldata_Rainfed$MEps4
> >
> >
> >  Alldata_Rainfed$weight2<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
> >  attach(Alldata_Rainfed)
> >  library(stats)
> >  MEt_Rainfed<-weighted.mean(MEt,weight2)
> >  MEp_Rainfed<-weighted.mean(MEp,weight2)
> >
> >
> >
> >  attach(Alldata_Irrigation)
> >
> >  OLS_Irrigation <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
> >                         ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
> >                         pdnsty+portsML+cities500k+rentedland+subsidies1+
> >                         elevmean+elevrange+
> >                         t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
> >
>  AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
> >                       weights=w,Alldata_Irrigation)
> >
> >
> >
> >  CoefIrrigation_ps1 <- OLS_Irrigation$coeff[2]
> >  CoefIrrigation_ps2 <- OLS_Irrigation$coeff[3]
> >  CoefIrrigation_ps3 <- OLS_Irrigation$coeff[4]
> >  CoefIrrigation_ps4 <- OLS_Irrigation$coeff[5]
> >  CoefIrrigation_ts1 <- OLS_Irrigation$coeff[6]
> >  CoefIrrigation_ts2 <- OLS_Irrigation$coeff[7]
> >  CoefIrrigation_ts3 <- OLS_Irrigation$coeff[8]
> >  CoefIrrigation_ts4 <- OLS_Irrigation$coeff[9]
> >  CoefIrrigation_ps1sq <- OLS_Irrigation$coeff[10]
> >  CoefIrrigation_ps2sq <- OLS_Irrigation$coeff[11]
> >  CoefIrrigation_ps3sq <- OLS_Irrigation$coeff[12]
> >  CoefIrrigation_ps4sq <- OLS_Irrigation$coeff[13]
> >  CoefIrrigation_ts1sq <- OLS_Irrigation$coeff[14]
> >  CoefIrrigation_ts2sq <- OLS_Irrigation$coeff[15]
> >  CoefIrrigation_ts3sq <- OLS_Irrigation$coeff[16]
> >  CoefIrrigation_ts4sq <- OLS_Irrigation$coeff[17]
> >
> >  attach(Alldata_Irrigation)
> >  # gives the residual errors in Y
> >  Alldata_Irrigation$residuals <-resid(OLS_Irrigation)
> >
> >  # gives the predicted values for Ln_Y
> >  Alldata_Irrigation$Ln_y_hat <-fitted(OLS_Irrigation)
> >
> >  # Zelf functie rmse maken
> >  rmse <- function(error)
> >  {
> >    sqrt(mean(error^2))
> >  }
> >  Alldata_Irrigation$y_hat <-
> >
> exp(Alldata_Irrigation$Ln_y_hat)*exp(0.5*(rmse(OLS_Irrigation$residuals))^2)
> >
> >  # absolute impact (landwaarde current)
> >
> Alldata_Irrigation$absolute.current<-Alldata_Irrigation$y_hat*Alldata_Irrigation$se025*Alldata_Irrigation$sys02
> >
> >
> >  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY
> level)
> >  # Maar dit is dus de marginale impact per LnALVperHA?
> >
> >  Alldata_Irrigation$MEts1 =
> > CoefIrrigation_ts1+2*CoefIrrigation_ts1sq*Alldata_Irrigation$ts1
> >  Alldata_Irrigation$MEts2 =
> > CoefIrrigation_ts2+2*CoefIrrigation_ts2sq*Alldata_Irrigation$ts2
> >  Alldata_Irrigation$MEts3 =
> > CoefIrrigation_ts3+2*CoefIrrigation_ts3sq*Alldata_Irrigation$ts3
> >  Alldata_Irrigation$MEts4 =
> > CoefIrrigation_ts4+2*CoefIrrigation_ts4sq*Alldata_Irrigation$ts4
> >  Alldata_Irrigation$MEt   = Alldata_Irrigation$MEts1 +
> > Alldata_Irrigation$MEts2 + Alldata_Irrigation$MEts3 +
> > Alldata_Irrigation$MEts4
> >
> >  Alldata_Irrigation$MEps1 =
> > CoefIrrigation_ps1+2*CoefIrrigation_ps1sq*Alldata_Irrigation$ps1
> >  Alldata_Irrigation$MEps2 =
> > CoefIrrigation_ps2+2*CoefIrrigation_ps2sq*Alldata_Irrigation$ps2
> >  Alldata_Irrigation$MEps3 =
> > CoefIrrigation_ps3+2*CoefIrrigation_ps3sq*Alldata_Irrigation$ps3
> >  Alldata_Irrigation$MEps4 =
> > CoefIrrigation_ps4+2*CoefIrrigation_ps4sq*Alldata_Irrigation$ps4
> >  Alldata_Irrigation$MEp   = Alldata_Irrigation$MEps1 +
> > Alldata_Irrigation$MEps2 + Alldata_Irrigation$MEps3 +
> > Alldata_Irrigation$MEps4
> >
> >
> >
> Alldata_Irrigation$weight2<-Alldata_Irrigation$sys02*Alldata_Irrigation$se025
> >
> Alldata_Irrigation$weight2<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> >
> >  attach(Alldata_Irrigation)
> >  library(stats)
> >  MEt_Irrigation<-weighted.mean(MEt,weight2)
> >  MEp_Irrigation<-weighted.mean(MEp,weight2)
> >
> >  c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> >
> >  attach(Alldata)
> >
> >
> >  # And in the loop (index i):
> >
> >  d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> >
> >
> > })
> > out<-as.data.frame(do.call(rbind, o))
> >
> >
> >
> >
> > And the data are:
> >
> > structure(list(LnALVperHA = c(8.09964942932129, 9.53274631500244,
> > 7.42697763442993, 8.25370121002197, 8.42619132995605, 8.0093936920166,
> > 8.09785747528076, 8.49044704437256, 9.08215141296387, 8.38935947418213,
> > 8.67814350128174, 8.38935947418213, 10.4056901931763, 8.48210144042969,
> > 8.30281829833984, 8.92265796661377, 8.33178997039795, 4.54404163360596,
> > 10.662184715271, 9.62167072296143, 7.98790407180786, 7.58244323730469,
> > 7.23262739181519, 9.47037124633789, 8.93403625488281, 7.54256629943848,
> > 9.40302467346191, 10.6290521621704, 8.59830188751221, 8.59585666656494,
> > 9.10000514984131, 9.99381542205811, 9.54681301116943, 9.53055191040039,
> > 8.67971229553223, 7.19780731201172, 8.90067958831787, 6.0509786605835,
> > 6.55788946151733, 8.22567272186279, 9.05618953704834, 6.81858921051025,
> > 8.46410751342773, 7.81292057037354, 8.38989448547363, 10.4709157943726,
> > 8.06132888793945, 8.43629264831543, 10.3087100982666, 10.3218297958374
> > ), ps1 = c(5.14855766296387, 4.71904611587524, 7.9462103843689,
> > 10.6017990112305, 11.233078956604, 9.12952136993408, 12.6536712646484,
> > 11.233078956604, 11.233078956604, 11.233078956604, 11.233078956604,
> > 11.233078956604, 5.93759632110596, 10.6017990112305, 11.233078956604,
> > 10.6017990112305, 7.95780467987061, 9.07744884490967, 4.29865598678589,
> > 8.27481746673584, 3.25137901306152, 4.51061344146729, 6.34518480300903,
> > 6.66202449798584, 6.66202449798584, 4.75249433517456, 6.28858852386475,
> > 6.33270215988159, 10.3600759506226, 10.3600759506226, 18.7164611816406,
> > 5.73318386077881, 7.92949104309082, 9.09823608398438, 11.233078956604,
> > 10.4455404281616, 11.233078956604, 10.4455404281616, 10.4455404281616,
> > 10.6017990112305, 9.19112777709961, 10.4455404281616, 11.233078956604,
> > 11.064302444458, 11.233078956604, 5.93759632110596, 11.233078956604,
> > 10.6017990112305, 6.05948448181152, 9.5645227432251), ps2 =
> c(5.23111915588379,
> > 4.86784505844116, 7.7175760269165, 4.34898376464844, 4.48626232147217,
> > 9.57159423828125, 8.38174915313721, 4.48626232147217, 4.48626232147217,
> > 4.48626232147217, 4.48626232147217, 4.48626232147217, 6.87198734283447,
> > 4.34898376464844, 4.48626232147217, 4.34898376464844, 6.2098217010498,
> > 7.5497522354126, 5.62545442581177, 5.57168531417847, 3.08954334259033,
> > 6.6683931350708, 4.41767883300781, 6.11901044845581, 6.11901044845581,
> > 4.06884765625, 6.35917854309082, 5.7121729850769, 8.55229663848877,
> > 8.55229663848877, 11.8981914520264, 5.49351119995117, 5.34777498245239,
> > 6.12420177459717, 4.48626232147217, 5.2967677116394, 4.48626232147217,
> > 5.2967677116394, 5.2967677116394, 4.34898376464844, 4.51386308670044,
> > 5.2967677116394, 4.48626232147217, 5.98725175857544, 4.48626232147217,
> > 6.87198734283447, 4.48626232147217, 4.34898376464844, 5.58411026000977,
> > 4.42436075210571), ps3 = c(4.95634937286377, 3.50353670120239,
> > 6.01129817962646, 0.851324141025543, 0.816295921802521, 8.03804397583008,
> > 5.56230783462524, 0.816295921802521, 0.816295921802521,
> 0.816295921802521,
> > 0.816295921802521, 0.816295921802521, 6.01666784286499,
> 0.851324141025543,
> > 0.816295921802521, 0.851324141025543, 3.45424580574036, 5.31899690628052,
> > 7.45753812789917, 3.34133338928223, 6.61472988128662, 11.244439125061,
> > 2.19617891311646, 5.29748106002808, 5.29748106002808, 1.63307499885559,
> > 5.51272773742676, 6.78562116622925, 4.5334997177124, 4.5334997177124,
> > 4.31791353225708, 7.10963106155396, 2.32198905944824, 2.74845194816589,
> > 0.816295921802521, 1.47570741176605, 0.816295921802521, 1.47570741176605,
> > 1.47570741176605, 0.851324141025543, 1.39068424701691, 1.47570741176605,
> > 0.816295921802521, 1.85064959526062, 0.816295921802521, 6.01666784286499,
> > 0.816295921802521, 0.851324141025543, 6.78009986877441, 1.21070051193237
> > ), ps4 = c(5.66667366027832, 4.82342433929443, 7.40090322494507,
> > 6.59299898147583, 7.33758926391602, 9.98004341125488, 10.3958940505981,
> > 7.33758926391602, 7.33758926391602, 7.33758926391602, 7.33758926391602,
> > 7.33758926391602, 8.31999015808105, 6.59299898147583, 7.33758926391602,
> > 6.59299898147583, 7.05771064758301, 8.38344383239746, 4.75349426269531,
> > 9.00399303436279, 5.48189449310303, 5.9071044921875, 5.30881881713867,
> > 8.68398857116699, 8.68398857116699, 4.32339859008789, 8.57950687408447,
> > 6.78787326812744, 8.68624305725098, 8.68624305725098, 12.9021902084351,
> > 6.14854049682617, 6.71301507949829, 7.50605535507202, 7.33758926391602,
> > 8.11069011688232, 7.33758926391602, 8.11069011688232, 8.11069011688232,
> > 6.59299898147583, 5.92181205749512, 8.11069011688232, 7.33758926391602,
> > 9.29954528808594, 7.33758926391602, 8.31999015808105, 7.33758926391602,
> > 6.59299898147583, 6.16447877883911, 5.83903217315674), ts1 =
> c(4.19949150085449,
> > 2.46556353569031, 3.96805644035339, 9.05560302734375, 9.5199556350708,
> > 1.18671488761902, 6.60286664962769, 9.5199556350708, 9.5199556350708,
> > 9.5199556350708, 9.5199556350708, 9.5199556350708, 2.12847352027893,
> > 9.05560302734375, 9.5199556350708, 9.05560302734375, 2.11432313919067,
> > 6.49393510818481, -0.165110915899277, 7.78503036499023,
> -7.71160411834717,
> > -0.979450941085815, 4.96369075775146, 4.28496122360229, 4.28496122360229,
> > 6.35976600646973, 3.02656149864197, 2.80754446983337, 5.94739389419556,
> > 5.94739389419556, 8.70161914825439, 1.57025468349457, 5.08782005310059,
> > 4.27688789367676, 9.5199556350708, 8.49832916259766, 9.5199556350708,
> > 8.49832916259766, 8.49832916259766, 9.05560302734375, 6.33359289169312,
> > 8.49832916259766, 9.5199556350708, 7.99740839004517, 9.5199556350708,
> > 2.12847352027893, 9.5199556350708, 9.05560302734375, 2.67069268226624,
> > 7.33829879760742), ts2 = c(9.89923763275146, 10.9084701538086,
> > 9.61682415008545, 13.6253662109375, 13.8121919631958, 6.19518041610718,
> > 9.40560817718506, 13.8121919631958, 13.8121919631958, 13.8121919631958,
> > 13.8121919631958, 13.8121919631958, 10.3912172317505, 13.6253662109375,
> > 13.8121919631958, 13.6253662109375, 9.77112770080566, 11.5460777282715,
> > 8.18180465698242, 12.9412984848022, 2.54625177383423, 8.29829216003418,
> > 10.6650953292847, 10.1770324707031, 10.1770324707031, 12.4333782196045,
> > 8.98324680328369, 8.45312309265137, 9.23384857177734, 9.23384857177734,
> > 11.371600151062, 8.09108352661133, 12.0714511871338, 11.385799407959,
> > 13.8121919631958, 13.912787437439, 13.8121919631958, 13.912787437439,
> > 13.912787437439, 13.6253662109375, 12.0018119812012, 13.912787437439,
> > 13.8121919631958, 14.0190010070801, 13.8121919631958, 10.3912172317505,
> > 13.8121919631958, 13.6253662109375, 8.53981018066406, 12.7294788360596
> > ), ts3 = c(17.718994140625, 21.1172523498535, 17.8669090270996,
> > 23.1215572357178, 22.9536685943604, 15.3891229629517, 15.7000684738159,
> > 22.9536685943604, 22.9536685943604, 22.9536685943604, 22.9536685943604,
> > 22.9536685943604, 20.1229286193848, 23.1215572357178, 22.9536685943604,
> > 23.1215572357178, 19.8251171112061, 19.3250198364258, 16.8351039886475,
> > 22.2966594696045, 14.6743259429932, 17.1554985046387, 20.1656894683838,
> > 20.0012702941895, 20.0012702941895, 23.2738876342773, 18.6255321502686,
> > 16.2553405761719, 16.551155090332, 16.551155090332, 17.6266174316406,
> > 16.1711521148682, 22.280725479126, 21.450382232666, 22.9536685943604,
> > 23.5616970062256, 22.9536685943604, 23.5616970062256, 23.5616970062256,
> > 23.1215572357178, 22.1113948822021, 23.5616970062256, 22.9536685943604,
> > 23.5085678100586, 22.9536685943604, 20.1229286193848, 22.9536685943604,
> > 23.1215572357178, 16.3595314025879, 22.7737102508545), ts4 =
> c(11.661883354187,
> > 12.7669324874878, 11.6320190429688, 17.2357921600342, 17.4911460876465,
> > 9.09537506103516, 12.179615020752, 17.4911460876465, 17.4911460876465,
> > 17.4911460876465, 17.4911460876465, 17.4911460876465, 12.0781927108765,
> > 17.2357921600342, 17.4911460876465, 17.2357921600342, 11.9486837387085,
> > 13.7441387176514, 8.9575023651123, 15.9984045028687, 4.02816677093506,
> > 9.12790489196777, 13.0505475997925, 12.842321395874, 12.842321395874,
> > 14.8937959671021, 11.5566177368164, 10.0515727996826, 12.2921047210693,
> > 12.2921047210693, 14.2251281738281, 9.64802074432373, 14.6072359085083,
> > 13.7993869781494, 17.4911460876465, 17.0232067108154, 17.4911460876465,
> > 17.0232067108154, 17.0232067108154, 17.2357921600342, 15.045259475708,
> > 17.0232067108154, 17.4911460876465, 16.7633666992188, 17.4911460876465,
> > 12.0781927108765, 17.4911460876465, 17.2357921600342, 10.0954942703247,
> > 15.9187803268433), ps1sq = c(26.5076465606689, 22.2693958282471,
> > 63.1422576904297, 112.398139953613, 126.182060241699, 83.3481597900391,
> > 160.11540222168, 126.182060241699, 126.182060241699, 126.182060241699,
> > 126.182060241699, 126.182060241699, 35.2550506591797, 112.398139953613,
> > 126.182060241699, 112.398139953613, 63.3266563415527, 82.4000778198242,
> > 18.478443145752, 68.4726028442383, 10.5714654922485, 20.3456344604492,
> > 40.2613716125488, 44.3825721740723, 44.3825721740723, 22.58620262146,
> > 39.5463447570801, 40.1031150817871, 107.331176757812, 107.331176757812,
> > 350.305908203125, 32.8693962097168, 62.8768272399902, 82.7779006958008,
> > 126.182060241699, 109.109313964844, 126.182060241699, 109.109313964844,
> > 109.109313964844, 112.398139953613, 84.4768295288086, 109.109313964844,
> > 126.182060241699, 122.418785095215, 126.182060241699, 35.2550506591797,
> > 126.182060241699, 112.398139953613, 36.7173538208008, 91.480094909668
> > ), ps2sq = c(27.3646068572998, 23.695915222168, 59.560977935791,
> > 18.9136600494385, 20.1265487670898, 91.6154174804688, 70.2537155151367,
> > 20.1265487670898, 20.1265487670898, 20.1265487670898, 20.1265487670898,
> > 20.1265487670898, 47.2242088317871, 18.9136600494385, 20.1265487670898,
> > 18.9136600494385, 38.5618858337402, 56.9987602233887, 31.6457366943359,
> > 31.0436763763428, 9.54527759552002, 44.4674682617188, 19.5158863067627,
> > 37.4422874450684, 37.4422874450684, 16.5555210113525, 40.439151763916,
> > 32.6289215087891, 73.1417770385742, 73.1417770385742, 141.566955566406,
> > 30.1786651611328, 28.5986976623535, 37.5058479309082, 20.1265487670898,
> > 28.0557479858398, 20.1265487670898, 28.0557479858398, 28.0557479858398,
> > 18.9136600494385, 20.3749599456787, 28.0557479858398, 20.1265487670898,
> > 35.8471832275391, 20.1265487670898, 47.2242088317871, 20.1265487670898,
> > 18.9136600494385, 31.1822872161865, 19.5749683380127), ps3sq =
> > c(24.5653991699219,
> > 12.27476978302, 36.1357040405273, 0.72475278377533, 0.666339039802551,
> > 64.6101531982422, 30.9392681121826, 0.666339039802551, 0.666339039802551,
> > 0.666339039802551, 0.666339039802551, 0.666339039802551,
> 36.2002906799316,
> > 0.72475278377533, 0.666339039802551, 0.72475278377533, 11.9318141937256,
> > 28.2917289733887, 55.614875793457, 11.1645088195801, 43.7546501159668,
> > 126.437408447266, 4.82320165634155, 28.063304901123, 28.063304901123,
> > 2.6669340133667, 30.3901672363281, 46.0446548461914, 20.552619934082,
> > 20.552619934082, 18.6443767547607, 50.5468521118164, 5.39163303375244,
> > 7.55398797988892, 0.666339039802551, 2.17771244049072, 0.666339039802551,
> > 2.17771244049072, 2.17771244049072, 0.72475278377533, 1.93400263786316,
> > 2.17771244049072, 0.666339039802551, 3.42490386962891, 0.666339039802551,
> > 36.2002906799316, 0.666339039802551, 0.72475278377533, 45.9697532653809,
> > 1.46579575538635), ps4sq = c(32.1111907958984, 23.2654228210449,
> > 54.7733688354492, 43.4676361083984, 53.840217590332, 99.6012649536133,
> > 108.074615478516, 53.840217590332, 53.840217590332, 53.840217590332,
> > 53.840217590332, 53.840217590332, 69.2222366333008, 43.4676361083984,
> > 53.840217590332, 43.4676361083984, 49.811279296875, 70.2821273803711,
> > 22.5957069396973, 81.071891784668, 30.0511665344238, 34.8938827514648,
> > 28.183557510376, 75.4116592407227, 75.4116592407227, 18.6917762756348,
> > 73.6079406738281, 46.0752220153809, 75.4508209228516, 75.4508209228516,
> > 166.466506958008, 37.8045501708984, 45.0645713806152, 56.3408660888672,
> > 53.840217590332, 65.7832946777344, 53.840217590332, 65.7832946777344,
> > 65.7832946777344, 43.4676361083984, 35.0678596496582, 65.7832946777344,
> > 53.840217590332, 86.4815444946289, 53.840217590332, 69.2222366333008,
> > 53.840217590332, 43.4676361083984, 38.0007972717285, 34.094295501709
> > ), ts1sq = c(17.6357288360596, 6.07900333404541, 15.7454719543457,
> > 82.0039443969727, 90.6295547485352, 1.40829217433929, 43.5978469848633,
> > 90.6295547485352, 90.6295547485352, 90.6295547485352, 90.6295547485352,
> > 90.6295547485352, 4.53039932250977, 82.0039443969727, 90.6295547485352,
> > 82.0039443969727, 4.47036218643188, 42.1711921691895, 0.0272616147994995,
> > 60.6066970825195, 59.4688377380371, 0.95932412147522, 24.6382255554199,
> > 18.3608932495117, 18.3608932495117, 40.4466247558594, 9.16007423400879,
> > 7.88230609893799, 35.3714942932129, 35.3714942932129, 75.7181777954102,
> > 2.46569967269897, 25.8859119415283, 18.2917709350586, 90.6295547485352,
> > 72.2215957641602, 90.6295547485352, 72.2215957641602, 72.2215957641602,
> > 82.0039443969727, 40.1143989562988, 72.2215957641602, 90.6295547485352,
> > 63.9585418701172, 90.6295547485352, 4.53039932250977, 90.6295547485352,
> > 82.0039443969727, 7.13259935379028, 53.8506278991699), ts2sq =
> > c(97.9949035644531,
> > 118.994720458984, 92.4833068847656, 185.650604248047, 190.776641845703,
> > 38.3802604675293, 88.465461730957, 190.776641845703, 190.776641845703,
> > 190.776641845703, 190.776641845703, 190.776641845703, 107.977394104004,
> > 185.650604248047, 190.776641845703, 185.650604248047, 95.4749374389648,
> > 133.311904907227, 66.9419250488281, 167.477203369141, 6.48339796066284,
> > 68.8616561889648, 113.744255065918, 103.571990966797, 103.571990966797,
> > 154.588897705078, 80.6987228393555, 71.4552917480469, 85.2639617919922,
> > 85.2639617919922, 129.313293457031, 65.4656295776367, 145.719940185547,
> > 129.636428833008, 190.776641845703, 193.565658569336, 190.776641845703,
> > 193.565658569336, 193.565658569336, 185.650604248047, 144.043487548828,
> > 193.565658569336, 190.776641845703, 196.53239440918, 190.776641845703,
> > 107.977394104004, 190.776641845703, 185.650604248047, 72.9283599853516,
> > 162.039627075195), ts3sq = c(313.962768554688, 445.938354492188,
> > 319.226440429688, 534.606384277344, 526.870910644531, 236.825103759766,
> > 246.492156982422, 526.870910644531, 526.870910644531, 526.870910644531,
> > 526.870910644531, 526.870910644531, 404.932250976562, 534.606384277344,
> > 526.870910644531, 534.606384277344, 393.035278320312, 373.456390380859,
> > 283.420715332031, 497.141021728516, 215.335845947266, 294.311126708984,
> > 406.655029296875, 400.050811767578, 400.050811767578, 541.673828125,
> > 346.910461425781, 264.236083984375, 273.940734863281, 273.940734863281,
> > 310.697631835938, 261.506164550781, 496.430725097656, 460.118896484375,
> > 526.870910644531, 555.153564453125, 526.870910644531, 555.153564453125,
> > 555.153564453125, 534.606384277344, 488.913787841797, 555.153564453125,
> > 526.870910644531, 552.652770996094, 526.870910644531, 404.932250976562,
> > 526.870910644531, 534.606384277344, 267.63427734375, 518.641906738281
> > ), ts4sq = c(135.999526977539, 162.994567871094, 135.303863525391,
> > 297.072540283203, 305.940185546875, 82.7258453369141, 148.343017578125,
> > 305.940185546875, 305.940185546875, 305.940185546875, 305.940185546875,
> > 305.940185546875, 145.882736206055, 297.072540283203, 305.940185546875,
> > 297.072540283203, 142.771041870117, 188.901351928711, 80.2368469238281,
> > 255.948944091797, 16.2261276245117, 83.3186492919922, 170.316787719727,
> > 164.925216674805, 164.925216674805, 221.825164794922, 133.555419921875,
> > 101.034118652344, 151.095840454102, 151.095840454102, 202.354278564453,
> > 93.0843048095703, 213.371337890625, 190.423080444336, 305.940185546875,
> > 289.789581298828, 305.940185546875, 289.789581298828, 289.789581298828,
> > 297.072540283203, 226.359832763672, 289.789581298828, 305.940185546875,
> > 281.010467529297, 305.940185546875, 145.882736206055, 305.940185546875,
> > 297.072540283203, 101.919006347656, 253.407562255859), pdnsty =
> > c(0.616999983787537,
> > 0.0850000008940697, 0.068000003695488, 0.025000000372529,
> 0.0549999997019768,
> > 0.0230000000447035, 0.133000001311302, 0.0549999997019768,
> 0.0549999997019768,
> > 0.0549999997019768, 0.0549999997019768, 0.0549999997019768,
> 0.25900000333786,
> > 0.025000000372529, 0.0549999997019768, 0.025000000372529,
> 0.0140000004321337,
> > 0.14300000667572, 0.140000000596046, 0.777999997138977,
> 0.0329999998211861,
> > 0.316000014543533, 0.0179999992251396, 0.105999998748302,
> 0.105999998748302,
> > 0.046000000089407, 0.108000002801418, 0.310999989509583,
> 0.101000003516674,
> > 0.101000003516674, 0.14300000667572, 0.168999999761581,
> 0.0439999997615814,
> > 0.0379999987781048, 0.0549999997019768, 0.063000001013279,
> 0.0549999997019768,
> > 0.063000001013279, 0.063000001013279, 0.025000000372529,
> 0.0640000030398369,
> > 0.063000001013279, 0.0549999997019768, 0.209000006318092,
> 0.0549999997019768,
> > 0.25900000333786, 0.0549999997019768, 0.025000000372529,
> 0.257999986410141,
> > 0.0469999983906746), portsML = c(0.0900330692529678, 0.0604440234601498,
> > 0.168490216135979, 0.275995850563049, 0.269018620252609,
> 0.175392478704453,
> > 0.0350189469754696, 0.269018620252609, 0.269018620252609,
> 0.269018620252609,
> > 0.269018620252609, 0.269018620252609, 0.11026918143034,
> 0.275995850563049,
> > 0.269018620252609, 0.275995850563049, 0.145082741975784,
> 0.00440915673971176,
> > 0.426146239042282, 0.0686663240194321, 0.103511147201061,
> 0.289726078510284,
> > 0.234196603298187, 0.123688526451588, 0.123688526451588,
> 0.315173029899597,
> > 0.112561739981174, 0.0461684986948967, 0.179993003606796,
> 0.179993003606796,
> > 0.0438785217702389, 0.096462681889534, 0.0934395045042038,
> 0.121217466890812,
> > 0.269018620252609, 0.212490051984787, 0.269018620252609,
> 0.212490051984787,
> > 0.212490051984787, 0.275995850563049, 0.162760972976685,
> 0.212490051984787,
> > 0.269018620252609, 0.270619571208954, 0.269018620252609,
> 0.11026918143034,
> > 0.269018620252609, 0.275995850563049, 0.108705826103687,
> 0.196496397256851
> > ), cities500k = c(0.0360943526029587, 0.0577861145138741,
> 0.183606043457985,
> > 0.150749072432518, 0.185974538326263, 0.0923599153757095,
> 0.353672504425049,
> > 0.185974538326263, 0.185974538326263, 0.185974538326263,
> 0.185974538326263,
> > 0.185974538326263, 0.0887016654014587, 0.150749072432518,
> 0.185974538326263,
> > 0.150749072432518, 0.144800990819931, 0.00326321297325194,
> 0.0622526630759239,
> > 0.00816718116402626, 0.181859150528908, 0.163181975483894,
> 0.204970955848694,
> > 0.129742562770844, 0.129742562770844, 0.0783679932355881,
> 0.0559677332639694,
> > 0.0293320622295141, 0.248573184013367, 0.248573184013367,
> 0.174525216221809,
> > 0.092569001019001, 0.176346719264984, 0.16088992357254,
> 0.185974538326263,
> > 0.280431807041168, 0.185974538326263, 0.280431807041168,
> 0.280431807041168,
> > 0.150749072432518, 0.088722825050354, 0.280431807041168,
> 0.185974538326263,
> > 0.189705356955528, 0.185974538326263, 0.0887016654014587,
> 0.185974538326263,
> > 0.150749072432518, 0.0712414756417274, 0.0842432081699371), rentedland
> > = c(0.571943998336792,
> > 0, 0.5929936170578, 0, 0, 0.755691230297089, 0.440930217504501,
> > 0, 0, 0, 0.229885056614876, 0, 0, 0, 0, 0, 0.890581607818604,
> > 0.212423488497734, 0.386227518320084, 0, 0.11130790412426,
> 0.483032256364822,
> > 0.444395005702972, 0, 0, 0.253378361463547, 0, 0.10909091681242,
> > 0.181818187236786, 0.666666686534882, 0, 0.94951194524765,
> 0.846153855323792,
> > 0.403846144676208, 0, 0, 0.155963316559792, 0, 0, 0.408163279294968,
> > 0.699570834636688, 0, 0, 0, 0, 0, 0.0476190522313118, 0, 0, 0
> > ), subsidies1 = c(361.835754394531, 0, 368.242034912109,
> 345.636352539062,
> > 701.746032714844, 488.922821044922, 344.918609619141, 790.392150878906,
> > 795.3125, 631.666687011719, 193.563217163086, 565.75, 0,
> 577.586181640625,
> > 395.681823730469, 192, 371.963653564453, 9.9977331161499,
> 310.838317871094,
> > 905.764709472656, 1745.76293945312, 359.003814697266, 163.204330444336,
> > 427.94970703125, 204.842727661133, 52.2592887878418, 0, 0,
> 3022.24243164062,
> > 80.2666702270508, 445.366577148438, 925.681640625, 824.769226074219,
> > 625.192321777344, 850.441162109375, 280.891723632812, 619.266052246094,
> > 333.962249755859, 376.304351806641, 317.551025390625, 166.652359008789,
> > 171.224487304688, 526.119445800781, 253.191497802734, 334.470581054688,
> > 107.277839660645, 431.428588867188, 0, 107.245544433594, 339.701507568359
> > ), elevmean = c(0.121736958622932, 0.46412268280983, 0.344255149364471,
> > 0.466430068016052, 0.43000802397728, 1.15364873409271,
> 0.0955904126167297,
> > 0.43000802397728, 0.43000802397728, 0.43000802397728, 0.43000802397728,
> > 0.43000802397728, 0.370405077934265, 0.466430068016052, 0.43000802397728,
> > 0.466430068016052, 0.849120080471039, 0.0433186627924442,
> 0.335433751344681,
> > 0.271958351135254, 0.125564843416214, 0.376024007797241,
> 0.815701544284821,
> > 0.525435268878937, 0.525435268878937, 0.62959760427475,
> 0.518330037593842,
> > 0.00362438289448619, 0.628515422344208, 0.628515422344208,
> 0.274942100048065,
> > 0.0728112533688545, 0.496583759784698, 0.739268243312836,
> 0.43000802397728,
> > 0.321640431880951, 0.43000802397728, 0.321640431880951,
> 0.321640431880951,
> > 0.466430068016052, 0.585907399654388, 0.321640431880951,
> 0.43000802397728,
> > 0.147326037287712, 0.43000802397728, 0.370405077934265, 0.43000802397728,
> > 0.466430068016052, 0.0183117985725403, 0.414920538663864), elevrange =
> > c(0.180000007152557,
> > 1.99300003051758, 0.611000001430511, 2.35199999809265, 2.29999995231628,
> > 2.94199991226196, 0.354999989271164, 2.29999995231628, 2.29999995231628,
> > 2.29999995231628, 2.29999995231628, 2.29999995231628, 2.01799988746643,
> > 2.35199999809265, 2.29999995231628, 2.35199999809265, 1.7389999628067,
> > 0.160999998450279, 0.314000010490417, 1.76300001144409, 0.17399999499321,
> > 0.653999984264374, 1.63399994373322, 2.19099998474121, 2.19099998474121,
> > 1.14100003242493, 1.34800004959106, 0.00899999961256981,
> 2.41300010681152,
> > 2.41300010681152, 0.787999987602234, 0.26800000667572, 1.92200005054474,
> > 2.02600002288818, 2.29999995231628, 1.05099999904633, 2.29999995231628,
> > 1.05099999904633, 1.05099999904633, 2.35199999809265, 2.35999989509583,
> > 1.05099999904633, 2.29999995231628, 0.772000014781952, 2.29999995231628,
> > 2.01799988746643, 2.29999995231628, 2.35199999809265, 0.0649999976158142,
> > 1.75399994850159), t_gravel = c(4.58953237533569, 13.3146963119507,
> > 10.0136280059814, 13.8894920349121, 13.9366893768311, 13.5653190612793,
> > 7.71220588684082, 13.9366893768311, 13.9366893768311, 13.9366893768311,
> > 13.9366893768311, 13.9366893768311, 11.4818019866943, 13.8894920349121,
> > 13.9366893768311, 13.8894920349121, 13.4321727752686, 5.71388387680054,
> > 8.03888702392578, 9.01077747344971, 4.58924961090088, 8.14134693145752,
> > 11.8983144760132, 9.96716785430908, 9.96716785430908, 11.1739711761475,
> > 10.4019403457642, 5.16821479797363, 10.7357034683228, 10.7357034683228,
> > 9.23897457122803, 4.3336238861084, 10.9520101547241, 12.9722995758057,
> > 13.9366893768311, 13.1780118942261, 13.9366893768311, 13.1780118942261,
> > 13.1780118942261, 13.8894920349121, 12.7335777282715, 13.1780118942261,
> > 13.9366893768311, 12.315260887146, 13.9366893768311, 11.4818019866943,
> > 13.9366893768311, 13.8894920349121, 6.68424606323242, 14.101095199585
> > ), t_ph_h2o = c(6.07352828979492, 6.72695684432983, 5.60523176193237,
> > 6.13967752456665, 6.86059141159058, 7.40929126739502, 5.68151950836182,
> > 6.86059141159058, 6.86059141159058, 6.86059141159058, 6.86059141159058,
> > 6.86059141159058, 6.51894521713257, 6.13967752456665, 6.86059141159058,
> > 6.13967752456665, 6.98909568786621, 5.5628228187561, 6.68793487548828,
> > 6.57724285125732, 4.67033195495605, 6.32772016525269, 6.4612717628479,
> > 6.73934555053711, 6.73934555053711, 6.80293703079224, 6.17414236068726,
> > 7.03696584701538, 5.93052577972412, 5.93052577972412, 5.43228578567505,
> > 5.5989408493042, 6.86088180541992, 6.68706750869751, 6.86059141159058,
> > 6.00043678283691, 6.86059141159058, 6.00043678283691, 6.00043678283691,
> > 6.13967752456665, 6.89467239379883, 6.00043678283691, 6.86059141159058,
> > 6.81896543502808, 6.86059141159058, 6.51894521713257, 6.86059141159058,
> > 6.13967752456665, 5.63159275054932, 6.13170003890991), t_silt =
> > c(34.2329025268555,
> > 33.4969100952148, 34.4774589538574, 27.8914813995361, 31.9258117675781,
> > 39.6254501342773, 34.7939414978027, 31.9258117675781, 31.9258117675781,
> > 31.9258117675781, 31.9258117675781, 31.9258117675781, 26.6626663208008,
> > 27.8914813995361, 31.9258117675781, 27.8914813995361, 29.7444763183594,
> > 21.3432540893555, 37.4038734436035, 28.1513748168945, 19.4936828613281,
> > 33.5968360900879, 32.8024406433105, 33.313850402832, 33.313850402832,
> > 28.3197917938232, 33.3154563903809, 38.103458404541, 36.0389099121094,
> > 36.0389099121094, 34.9229164123535, 26.5577545166016, 30.9245643615723,
> > 31.1334323883057, 31.9258117675781, 27.1493148803711, 31.9258117675781,
> > 27.1493148803711, 27.1493148803711, 27.8914813995361, 31.3038387298584,
> > 27.1493148803711, 31.9258117675781, 31.6541061401367, 31.9258117675781,
> > 26.6626663208008, 31.9258117675781, 27.8914813995361, 15.6523361206055,
> > 27.803352355957), t_sand = c(47.0063323974609, 37.0355186462402,
> > 45.8286781311035, 36.0810203552246, 39.9931793212891, 39.3664970397949,
> > 46.2948226928711, 39.9931793212891, 39.9931793212891, 39.9931793212891,
> > 39.9931793212891, 39.9931793212891, 49.3508529663086, 36.0810203552246,
> > 39.9931793212891, 36.0810203552246, 39.2436943054199, 65.7813262939453,
> > 35.8039131164551, 51.2884674072266, 66.2952728271484, 46.6789817810059,
> > 41.4505424499512, 44.4590721130371, 44.4590721130371, 48.7276763916016,
> > 43.3654098510742, 33.999683380127, 43.040699005127, 43.040699005127,
> > 43.2519073486328, 59.4827156066895, 43.8675765991211, 41.7124671936035,
> > 39.9931793212891, 34.94921875, 39.9931793212891, 34.94921875,
> > 34.94921875, 36.0810203552246, 39.1853942871094, 34.94921875,
> > 39.9931793212891, 39.8589019775391, 39.9931793212891, 49.3508529663086,
> > 39.9931793212891, 36.0810203552246, 75.7048721313477, 33.5687866210938
> > ), AT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), BE = c(0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0), DE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), DK = c(0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0), ES = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), FI = c(0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0), FR = c(1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), GR = c(0, 1, 0,
> > 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> > 0, 1, 1, 0, 1), IE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), IT = c(0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
> > 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 1, 0, 0, 0, 0), LU = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), NL = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 1, 0), PT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SE = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), WDE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), EDE = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), UK = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CY = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), BG = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CZ = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), EE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), HU = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), LT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), LV = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), PL = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), RO = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), SI = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SK = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), b48 = c(70, 2.70000004768372, 63.9000015258789,
> > 5.5, 6.30000019073486, 8.80000019073486, 48.0800018310547,
> 5.09999990463257,
> > 6.40000009536743, 6, 6.69999980926514, 4, 6.30000019073486,
> 5.80000019073486,
> > 8.80000019073486, 2, 13, 0.5, 10.25, 34, 65.2300033569336,
> 37.7799987792969,
> > 74.9400024414062, 31.0200004577637, 20.0300006866455, 70.7200012207031,
> > 40, 4.90000009536743, 13.5, 5, 26.8700008392334, 3, 2, 3.09999990463257,
> > 6.80000019073486, 15.6999998092651, 9.19999980926514, 5.30000019073486,
> > 4.59999990463257, 17.3999996185303, 7, 4.90000009536743,
> 13.3999996185303,
> > 2.34999990463257, 8.5, 24.8700008392334, 4, 1.39999997615814,
> > 34.7799987792969, 6.69999980926514), b50 = c(0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34.2400016784668, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), irrigation = c(0, 100, 0, 5.45454584062099,
> > 7.9365074634552, 89.3392562866211, 0, 17.6470592617989, 0, 0,
> > 65.5172407627106, 0, 61.904764175415, 34.4827562570572, 7.95454531908035,
> > 75, 0, 0, 0, 0, 0, 0, 5.26393800973892, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 74.6153831481934, 84.6153914928436, 0, 5.09554147720337,
> > 0, 0, 0, 21.0884347558022, 18.4549376368523, 6.1224490404129,
> > 25.3731369972229, 2.12765969336033, 0, 84.3988716602325, 0, 0,
> > 0, 100), awc_class = c(106.228088378906, 78.2306137084961,
> 80.9311141967773,
> > 32.4921531677246, 54.8475151062012, 80.6665878295898, 116.331588745117,
> > 54.8475151062012, 54.8475151062012, 54.8475151062012, 54.8475151062012,
> > 54.8475151062012, 56.3101806640625, 32.4921531677246, 54.8475151062012,
> > 32.4921531677246, 59.3034172058105, 101.193893432617, 96.5840377807617,
> > 54.2786560058594, 87.1388244628906, 66.1907730102539, 57.205738067627,
> > 55.4114303588867, 55.4114303588867, 80.9288787841797, 63.6008758544922,
> > 150, 30.3404140472412, 30.3404140472412, 19.8318557739258,
> 104.236854553223,
> > 79.2445755004883, 57.0045547485352, 54.8475151062012, 34.320426940918,
> > 54.8475151062012, 34.320426940918, 34.320426940918, 32.4921531677246,
> > 65.1337509155273, 34.320426940918, 54.8475151062012, 73.6748657226562,
> > 54.8475151062012, 56.3101806640625, 54.8475151062012, 32.4921531677246,
> > 127.726959228516, 27.9528160095215), sys02 = c(18.8571434020996,
> > 303.529418945312, 30.2469139099121, 104.305557250977, 86.4935073852539,
> > 51.25, 83.0927810668945, 453.118286132812, 42.5, 104.305557250977,
> > 48.461540222168, 86.4935073852539, 55.1851844787598, 104.305557250977,
> > 104.305557250977, 185.277770996094, 17.9775276184082, 25.2777786254883,
> > 64, 21.6666660308838, 30, 24.2372875213623, 47.0285720825195,
> > 16.1904754638672, 33.75, 22.5423736572266, 10.2857141494751,
> > 39.230770111084, 6.06741571426392, 1, 28.3255805969238, 21.6000003814697,
> > 69.2592620849609, 86.6666641235352, 48.5185203552246, 44.4186058044434,
> > 48.6538467407227, 437.105255126953, 437.105255126953, 19.1666660308838,
> > 48.461540222168, 437.105255126953, 48.6538467407227, 453.118286132812,
> > 48.6538467407227, 14.2857141494751, 453.118286132812, 453.118286132812,
> > 95.2380981445312, 63), se025 = c(163.529998779297, 2.70000004768372,
> > 157, 5.5, 6.30000019073486, 36.0200004577637, 86, 5.09999990463257,
> > 6.40000009536743, 6, 8.69999980926514, 4, 6.30000019073486,
> 5.80000019073486,
> > 8.80000019073486, 2, 118.809997558594, 44.1100006103516,
> 16.7000007629395,
> > 34, 73.4000015258789, 73.0800018310547, 134.880004882812,
> 31.0200004577637,
> > 20.0300006866455, 94.7200012207031, 40, 5.5, 16.5, 15, 26.8700008392334,
> > 59.4199981689453, 13, 5.19999980926514, 6.80000019073486,
> 15.6999998092651,
> > 10.8999996185303, 5.30000019073486, 4.59999990463257, 29.3999996185303,
> > 23.2999992370605, 4.90000009536743, 13.3999996185303, 2.34999990463257,
> > 8.5, 24.8700008392334, 4.19999980926514, 1.39999997615814,
> 34.7799987792969,
> > 6.69999980926514)), .Names = c("LnALVperHA", "ps1", "ps2", "ps3",
> > "ps4", "ts1", "ts2", "ts3", "ts4", "ps1sq", "ps2sq", "ps3sq",
> > "ps4sq", "ts1sq", "ts2sq", "ts3sq", "ts4sq", "pdnsty", "portsML",
> > "cities500k", "rentedland", "subsidies1", "elevmean", "elevrange",
> > "t_gravel", "t_ph_h2o", "t_silt", "t_sand", "AT", "BE", "DE",
> > "DK", "ES", "FI", "FR", "GR", "IE", "IT", "LU", "NL", "PT", "SE",
> > "WDE", "EDE", "UK", "CY", "BG", "CZ", "EE", "HU", "LT", "LV",
> > "PL", "RO", "SI", "SK", "b48", "b50", "irrigation", "awc_class",
> > "sys02", "se025"), row.names = c("2", "3", "4", "5", "6", "7",
> > "8", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
> > "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31",
> > "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
> > "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53"
> > ), class = "data.frame")
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > 2015-08-14 14:58 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz>:
> >>
> >> Hi Janka
> >>
> >>
> >>
> >> Sorry, but we are limited in connecting to web services so I am not
> able to restore your data and see your code. Result of dput(somedata)
> coppied to email is preferable for sharing data and code can be copied to
> email too. But do not use HTML as it usually scrambles  text.
> >>
> >>
> >>
> >> Answer in line
> >>
> >>
> >>
> >> From: Janka Vanschoenwinkel [mailto:janka.vanschoenwinkel at uhasselt.be]
> >> Sent: Friday, August 14, 2015 2:17 PM
> >> To: Thierry Onkelinx; PIKAL Petr
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] cut variable within a loop
> >>
> >>
> >>
> >> Hi Thierry and Petr,
> >>
> >>
> >>
> >> I really appreciate the comments you already gave. Thank you very much
> for that.
> >>
> >>
> >>
> >> Below you can find a link to the data and the code. Hopefully this
> helps in spotting the error.
> >>
> >>
> >>
> >> I still think the issue is that the cut2 function only accepts numbers,
> and not an "i" that refers to the number at the start of the loop. To
> answer Petr his question, yes, column 3 and 4 are NA (these are the columns
> of the second interval). But I don't really understand your point so could
> you clarify this please?
> >>
> >>
> >>
> >> If you use NA as a number of intervals you will get such errors
> >>
> >>
> >>
> >> k<-c(2,4,NA,5)
> >>
> >> ii<-vector(4, mode="list")
> >>
> >> for (i in 1:4) {
> >>
> >> ii[[i]] <- cut2(iris[,i], k[i])
> >>
> >> }
> >>
> >> Error in if (r[1] < cuts[1]) cuts <- c(r[1], cuts) :
> >>
> >>  missing value where TRUE/FALSE needed
> >>
> >> for (i in 1:4) {
> >>
> >> ii[[i]] <- cut(iris[,i], k[i])
> >>
> >> }
> >>
> >> Error in cut.default(iris[, i], k[i]) : invalid number of intervals
> >>
> >>
> >>
> >> If you remove NA from k definition error is gone.
> >>
> >> k<-c(2,4,3,5)
> >>
> >> ii<-vector(4, mode="list")
> >>
> >>
> >>
> >> for (i in 1:4) {
> >>
> >> ii[[i]] <- cut(iris[,i], k[i])
> >>
> >> }
> >>
> >>
> >>
> >> You can try it yourself. The error is not related to cycle; whenever
> number of intervals in cut call is NA you always get an error.
> >>
> >>
> >>
> >> Cheers
> >>
> >> Petr
> >>
> >>
> >>
> >>
> https://drive.google.com/folderview?id=0By9u5m3kxn9yfkxxeVNMdnRQQXhoT05CRlJlZVBCWWF2NURMMTNmVFVFeXJXXzhlMWE4SUk&usp=sharing
> >>
> >>
> >>
> >> Thank you very much once again!
> >>
> >>
> >>
> >> Janka
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> 2015-08-11 15:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> >>
> >> You'll need to send a reproducible example of the code. We can't run
> the code that you send. Hence it is hard to help you. See e.g.
> http://adv-r.had.co.nz/Reproducibility.html
> >>
> >>
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
> >>
> >>
> >>
> >> 2015-08-11 14:57 GMT+02:00 Janka Vanschoenwinkel <
> janka.vanschoenwinkel at uhasselt.be>:
> >>
> >> Hi Thierry!
> >>
> >>
> >>
> >> Thanks for your answer. I tried this, but I get this error:
> >>
> >>
> >>
> >> "Error in cut.default(x, k2) : invalid number of intervals"
> >>
> >>
> >>
> >> Which is strange because I am not specifying intervals, but the number
> at where the sample has to be cut?
> >>
> >>
> >>
> >> Greetings from Belgium! :-)
> >>
> >>
> >>
> >> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> >>
> >> Dear Janka,
> >>
> >>
> >>
> >> You loop goes for 0 to 100. It should probably go from 1:99
> >>
> >>
> >>
> >> Best regards,
> >>
> >>
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
> >>
> >>
> >>
> >> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
> janka.vanschoenwinkel at uhasselt.be>:
> >>
> >> Dear list members,
> >>
> >> I have a loop where I want to do several calculations for different
> samples
> >> and save the results for each sample. These samples are for each loop
> >> different. I want to use the "i" in the loop to cut the samples.
> >>
> >> So for instance:
> >>
> >>   - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
> >>   - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
> >>   - In loop 99 (i=99), I have a sample from 0-99 and a sample from
> 99-100.
> >>
> >> I built the following function, but there is *a problem with the cut2
> >> function* since it doesn't recognize the "i". Outside the lapply loop it
> >> works, but not inside the loop.
> >>
> >> Could somebody please help me with this problem? Thanks a lot!
> >>
> >>
> >>
> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
> >>
> >>
> >>
> >>    o<-lapply(0:100, function(i){
> >>
> >>
> >>
> >>        Alldata$irri=cut2(Alldata$irrigation,i)
> >>
> >>        levels(Alldata$irri)<-c("0","1")
> >>
> >>
> >>
> >>       Alldata_Rainfed<-subset(Alldata, irri == 0)
> >>
> >>       Alldata_Irrigation<-subset(Alldata, irri == 1)
> >>
> >>
> >>
> >>    #calculations per sample, then store all the values per i and per
> >> variable in a dataframe: (the calculations are not shown in this
> example)
> >>
> >>
> >>
> >>     d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> >>
> >>
> >>
> >>   })
> >>
> >>
> >>
> >>   out<-as.data.frame(do.call(rbind, o))
> >>
> >>
> >> --
> >> P Please consider the environment before printing this e-mail
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >>
> >>
> >> Mevrouw Janka Vanschoenwinkel
> >> Doctoraatsbursaal - PhD
> >> Milieueconomie - Environmental economics
> >>
> >> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> >>
> >> www.uhasselt.be/eec
> >>
> >> Universiteit Hasselt | Campus Diepenbeek
> >> Agoralaan Gebouw D | B-3590 Diepenbeek
> >> Kantoor F11
> >>
> >> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> >>
> >> P Please consider the environment before printing this e-mail
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >>
> >>
> >> Mevrouw Janka Vanschoenwinkel
> >> Doctoraatsbursaal - PhD
> >> Milieueconomie - Environmental economics
> >>
> >> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> >>
> >> www.uhasselt.be/eec
> >>
> >> Universiteit Hasselt | Campus Diepenbeek
> >> Agoralaan Gebouw D | B-3590 Diepenbeek
> >> Kantoor F11
> >>
> >> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> >>
> >> P Please consider the environment before printing this e-mail
> >>
> >>
> >>
> >>
> >> ________________________________
> >> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> >> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> >> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >>
> >> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> >> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >>
> >> This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> >> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> >> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> >> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >>
> >> In case that this e-mail forms part of business dealings:
> >> - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any reasoning.
> >> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> >> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> >> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> >
> >
> >
> >
> > --
> >
> > Mevrouw Janka Vanschoenwinkel
> > Doctoraatsbursaal - PhD
> > Milieueconomie - Environmental economics
> >
> > T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> >
> > www.uhasselt.be/eec
> >
> > Universiteit Hasselt | Campus Diepenbeek
> > Agoralaan Gebouw D | B-3590 Diepenbeek
> > Kantoor F11
> >
> > Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> >
> > P Please consider the environment before printing this e-mail
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 

[image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel
*Doctoraatsbursaal - PhD *
Milieueconomie - Environmental economics

T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt

P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From dingernikita at gmail.com  Sun Aug 16 18:39:28 2015
From: dingernikita at gmail.com (Nikita Dinger)
Date: Sun, 16 Aug 2015 22:09:28 +0530
Subject: [R] Error while submission
Message-ID: <CAN6BBTT8yo6_7qB1BdjEvZ3gAggDcOcmvqFy_fStqJBV5aAAJQ@mail.gmail.com>

I have completed part 2 of the assignment and am getting the desired output.
But on submitting the code, it shows as the answer is incorrect along with
this message:

function (..., list = character(), package = NULL, lib.loc = NULL, verbose
= getOption("verbose"),
    envir = .GlobalEnv)
Result:  Sorry, your answer was incorrect.

The following is my code for part 2:

complete <- function(directory, idvec = 1:332) {
        df <- data.frame(id = integer(), nobs = integer())
    for (id in idvec) {
        filename <- paste(directory, "/",
                          sprintf("%03d", as.integer(id)),
              5            ".csv", sep = "")
filename <- list.files()
        dat <- rbind(dat, read.csv(filename[id]))
}
str(data)
for (id in idvec)
        {nd <- data.frame(id = id,
                         nobs = nrow(na.omit(dat)))
        df <- rbind(df, nd)
    }
    return(df)

}

I am using R 3.2.1 on a Windows 8 laptop.

How shall I solve this?

Thanks and regards
Nikita

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sun Aug 16 22:06:32 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 16 Aug 2015 16:06:32 -0400
Subject: [R] Error while submission
In-Reply-To: <CAN6BBTT8yo6_7qB1BdjEvZ3gAggDcOcmvqFy_fStqJBV5aAAJQ@mail.gmail.com>
References: <CAN6BBTT8yo6_7qB1BdjEvZ3gAggDcOcmvqFy_fStqJBV5aAAJQ@mail.gmail.com>
Message-ID: <CAM_vjun+oBgXEMCaFRos050xxzaC2+8rxw=Xy2FFr6-BQRo_yA@mail.gmail.com>

On Sun, Aug 16, 2015 at 12:39 PM, Nikita Dinger <dingernikita at gmail.com> wrote:
> I have completed part 2 of the assignment and am getting the desired output.
> But on submitting the code, it shows as the answer is incorrect along with
> this message:

This list is not an appropriate place for you to ask for help with
your homework. Your course should have a way for you to get assistance
from instructor/TA/other students; this is not that way.

We on R-help can't do much for you, since none of us have any idea
what "part 2" might be, and the list has a no-homework policy anyway.

> function (..., list = character(), package = NULL, lib.loc = NULL, verbose
> = getOption("verbose"),
>     envir = .GlobalEnv)
> Result:  Sorry, your answer was incorrect.
>
> The following is my code for part 2:
>
> complete <- function(directory, idvec = 1:332) {
>         df <- data.frame(id = integer(), nobs = integer())
>     for (id in idvec) {
>         filename <- paste(directory, "/",
>                           sprintf("%03d", as.integer(id)),
>               5            ".csv", sep = "")
> filename <- list.files()
>         dat <- rbind(dat, read.csv(filename[id]))
> }
> str(data)
> for (id in idvec)
>         {nd <- data.frame(id = id,
>                          nobs = nrow(na.omit(dat)))
>         df <- rbind(df, nd)
>     }
>     return(df)
>
> }
>
> I am using R 3.2.1 on a Windows 8 laptop.
>
> How shall I solve this?
>
> Thanks and regards
> Nikita
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Sun Aug 16 22:11:56 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 16 Aug 2015 13:11:56 -0700
Subject: [R] Error while submission
In-Reply-To: <CAN6BBTT8yo6_7qB1BdjEvZ3gAggDcOcmvqFy_fStqJBV5aAAJQ@mail.gmail.com>
References: <CAN6BBTT8yo6_7qB1BdjEvZ3gAggDcOcmvqFy_fStqJBV5aAAJQ@mail.gmail.com>
Message-ID: <9B0EEE79-D434-4061-B2CB-21F933ADC3FC@dcn.davis.CA.us>

Go to where you were given this assignment and ask them for help.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 16, 2015 9:39:28 AM PDT, Nikita Dinger <dingernikita at gmail.com> wrote:
>I have completed part 2 of the assignment and am getting the desired
>output.
>But on submitting the code, it shows as the answer is incorrect along
>with
>this message:
>
>function (..., list = character(), package = NULL, lib.loc = NULL,
>verbose
>= getOption("verbose"),
>    envir = .GlobalEnv)
>Result:  Sorry, your answer was incorrect.
>
>The following is my code for part 2:
>
>complete <- function(directory, idvec = 1:332) {
>        df <- data.frame(id = integer(), nobs = integer())
>    for (id in idvec) {
>        filename <- paste(directory, "/",
>                          sprintf("%03d", as.integer(id)),
>              5            ".csv", sep = "")
>filename <- list.files()
>        dat <- rbind(dat, read.csv(filename[id]))
>}
>str(data)
>for (id in idvec)
>        {nd <- data.frame(id = id,
>                         nobs = nrow(na.omit(dat)))
>        df <- rbind(df, nd)
>    }
>    return(df)
>
>}
>
>I am using R 3.2.1 on a Windows 8 laptop.
>
>How shall I solve this?
>
>Thanks and regards
>Nikita
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Aug 16 22:31:56 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Aug 2015 13:31:56 -0700
Subject: [R] cut variable within a loop
In-Reply-To: <CAHymutKOx3yMR_Es0db7UhBEmJa8WCGi=gkNfXJuavX+vm7q_A@mail.gmail.com>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>
	<CAHymutKPfSM-qfbp9dLQgUpErUKp0tHj476fCPP8_r5aFiUxyQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39DE6@SRVEXCHMBX.precheza.cz>
	<CAHymutK__NMQFbWJsCk3aYw3Wz3S1gLmGFW=kFoxQ+yh+g3PqQ@mail.gmail.com>
	<154AA9FB-F7B6-4212-9373-761F475CA59B@comcast.net>
	<CAHymutKOx3yMR_Es0db7UhBEmJa8WCGi=gkNfXJuavX+vm7q_A@mail.gmail.com>
Message-ID: <ADB27316-C8E0-47CD-A852-4B9C1FB00BB7@comcast.net>


On Aug 16, 2015, at 8:57 AM, Janka VANSCHOENWINKEL wrote:

> Hi David,
> 
> Thanks for your comment. I'll explain what I want to do. I explained it already earlier but the explanation might have gone lost in some of the emails. 

I now see that you did explain that you wanted the positional matching in cut2 as a "break". The code runs without error on my machine, but delivers a lot of warnings about masking. You are repeatedly using attach on the same named objects. Using `attach` in programming is generally not a good idea. In interactive use it is safer to use `with`, although that is not generally considered safe in programming, either.

You need to do a better job of nailing down the source of the difficulty what ever it might be. While you say the cut2 function "doesn't work", you don't actually give evidence of "failure".

It's fairly simple to show that your theory about why your code fails in some way as being due to cut2 failing to accept an "i" value inside an lapply call is just wrong:

> o <- lapply(1:3, function(i) { cut2( 0:10, i) } )
> o
[[1]]
 [1]  0      [ 1,10] [ 1,10] [ 1,10] [ 1,10] [ 1,10] [ 1,10]
 [8] [ 1,10] [ 1,10] [ 1,10] [ 1,10]
Levels:  0 [ 1,10]

[[2]]
 [1] [ 0, 2) [ 0, 2) [ 2,10] [ 2,10] [ 2,10] [ 2,10] [ 2,10]
 [8] [ 2,10] [ 2,10] [ 2,10] [ 2,10]
Levels: [ 0, 2) [ 2,10]

[[3]]
 [1] [ 0, 3) [ 0, 3) [ 0, 3) [ 3,10] [ 3,10] [ 3,10] [ 3,10]
 [8] [ 3,10] [ 3,10] [ 3,10] [ 3,10]
Levels: [ 0, 3) [ 3,10]


You also have two different definitions of weight2 for your irrigation model:

Alldata_Irrigation$weight2<-Alldata_Irrigation$sys02*Alldata_Irrigation$se025
Alldata_Irrigation$weight2<-Alldata_Irrigation$b48+Alldata_Irrigation$b50

-- 
David
> 
> The variable irrigation ranges from 0 to 100. (maybe not in de small sample I gave, but in reality I have over 60000 observations and there the variable ranges from 0 to 100). I want to make (and use) 100 different samples. The sample is based each time on the "i" that I put at the beginning of the loop.
> 
> So:
> 
> i = 1: this means there are 2 subsets. One from 0-1, another from 1-100
> i = 2: this means there are 2 subsets. One from 0-2, another from 2-100
> i = 3: this means there are 2 subsets. One from 0-3, another from 3-100
> i = 4: this means there are 2 subsets. One from 0-4, another from 4-100
> ...
> i = 96: this means there are 2 subsets. One from 0-96, another from 96-100
> i = 97: this means there are 2 subsets. One from 0-97, another from 97-100
> i = 98: this means there are 2 subsets. One from 0-98, another from 98-100
> i = 99: this means there are 2 subsets. One from 0-99, another from 99-100
> 
> It might be possible that i = 1 and i = 2 give the same results in the small dataset. But in the full dataset all numbers are represented.
> 
> The cut2 function is capable of "cutting" a sample based on a number supplied. Yet, when I tell him this number is "i", then it doesn't work. If instead I write that the number is 10, then it does work and it gives me 2 subsets from 0-10 and from 10-100.
> 
> Hope this is more clear!
> 
> Janka
> 
> 
> 2015-08-14 20:10 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
> 
> When using a function in R you may need to supply an argument name. Are you expecting this to be the number of groups. I cannot decipher the intent here with such sparse commentary, but this call to `cut2` does not make sense to me. Perhaps you meant the number of groups? .... in which case you need  cut2( Alldata$irrigation, g=i ), since the arguments to cut2 are not that same as the arguments to cut.
> 
> At the moment you are implicitly sending on the first pass a 1 and then on the second pass a 2 to the second argument of cut2 which is the `breaks` argument. So you wold be getting two different factors each with different cut-point levels. I looked at your data and in point of fact there would be no difference since you have 29 zero values and no values between 0 and 1.
> 
> > table(cut2(dat$irrigation, 1))
> 
>         0 [  1,100]
>        29        21
> > table(cut2(dat$irrigation, 2))
> 
>         0 [  2,100]
>        29        21
> 
> 
> 
> 
> >  levels(Alldata$irri)<-c("0","1")
> >
> >  Alldata_Rainfed<-subset(Alldata, irri == 0)
> >  Alldata_Irrigation<-subset(Alldata, irri == 1)
> >
> >  Alldata_Rainfed$w<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
> >  Alldata_Irrigation$w<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> >
> >  OLS_Rainfed <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
> >                      ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
> >                      pdnsty+portsML+cities500k+rentedland+subsidies1+
> >                      elevmean+elevrange+
> >                      t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
> >                      AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
> >                    weights=w,Alldata_Rainfed)
> >
> >  attach(Alldata_Rainfed)
> >
> >  CoefRainfed_ps1 <- OLS_Rainfed$coeff[2]
> >  CoefRainfed_ps2 <- OLS_Rainfed$coeff[3]
> >  CoefRainfed_ps3 <- OLS_Rainfed$coeff[4]
> >  CoefRainfed_ps4 <- OLS_Rainfed$coeff[5]
> >  CoefRainfed_ts1 <- OLS_Rainfed$coeff[6]
> >  CoefRainfed_ts2 <- OLS_Rainfed$coeff[7]
> >  CoefRainfed_ts3 <- OLS_Rainfed$coeff[8]
> >  CoefRainfed_ts4 <- OLS_Rainfed$coeff[9]
> >  CoefRainfed_ps1sq <- OLS_Rainfed$coeff[10]
> >  CoefRainfed_ps2sq <- OLS_Rainfed$coeff[11]
> >  CoefRainfed_ps3sq <- OLS_Rainfed$coeff[12]
> >  CoefRainfed_ps4sq <- OLS_Rainfed$coeff[13]
> >  CoefRainfed_ts1sq <- OLS_Rainfed$coeff[14]
> >  CoefRainfed_ts2sq <- OLS_Rainfed$coeff[15]
> >  CoefRainfed_ts3sq <- OLS_Rainfed$coeff[16]
> >  CoefRainfed_ts4sq <- OLS_Rainfed$coeff[17]
> >
> >  attach(Alldata_Rainfed)
> >
> >
> >  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY level)
> >  # Maar dit is dus de marginale impact per LnALVperHA?
> >
> >  Alldata_Rainfed$MEts1 =
> > CoefRainfed_ts1+2*CoefRainfed_ts1sq*Alldata_Rainfed$ts1
> >  Alldata_Rainfed$MEts2 =
> > CoefRainfed_ts2+2*CoefRainfed_ts2sq*Alldata_Rainfed$ts2
> >  Alldata_Rainfed$MEts3 =
> > CoefRainfed_ts3+2*CoefRainfed_ts3sq*Alldata_Rainfed$ts3
> >  Alldata_Rainfed$MEts4 =
> > CoefRainfed_ts4+2*CoefRainfed_ts4sq*Alldata_Rainfed$ts4
> >  Alldata_Rainfed$MEt   = Alldata_Rainfed$MEts1 +
> > Alldata_Rainfed$MEts2 + Alldata_Rainfed$MEts3 + Alldata_Rainfed$MEts4
> >
> >  Alldata_Rainfed$MEps1 =
> > CoefRainfed_ps1+2*CoefRainfed_ps1sq*Alldata_Rainfed$ps1
> >  Alldata_Rainfed$MEps2 =
> > CoefRainfed_ps2+2*CoefRainfed_ps2sq*Alldata_Rainfed$ps2
> >  Alldata_Rainfed$MEps3 =
> > CoefRainfed_ps3+2*CoefRainfed_ps3sq*Alldata_Rainfed$ps3
> >  Alldata_Rainfed$MEps4 =
> > CoefRainfed_ps4+2*CoefRainfed_ps4sq*Alldata_Rainfed$ps4
> >  Alldata_Rainfed$MEp   = Alldata_Rainfed$MEps1 +
> > Alldata_Rainfed$MEps2 + Alldata_Rainfed$MEps3 + Alldata_Rainfed$MEps4
> >
> >
> >  Alldata_Rainfed$weight2<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
> >  attach(Alldata_Rainfed)
> >  library(stats)
> >  MEt_Rainfed<-weighted.mean(MEt,weight2)
> >  MEp_Rainfed<-weighted.mean(MEp,weight2)
> >
> >
> >
> >  attach(Alldata_Irrigation)
> >
> >  OLS_Irrigation <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
> >                         ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
> >                         pdnsty+portsML+cities500k+rentedland+subsidies1+
> >                         elevmean+elevrange+
> >                         t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
> >                         AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
> >                       weights=w,Alldata_Irrigation)
> >
> >
> >
> >  CoefIrrigation_ps1 <- OLS_Irrigation$coeff[2]
> >  CoefIrrigation_ps2 <- OLS_Irrigation$coeff[3]
> >  CoefIrrigation_ps3 <- OLS_Irrigation$coeff[4]
> >  CoefIrrigation_ps4 <- OLS_Irrigation$coeff[5]
> >  CoefIrrigation_ts1 <- OLS_Irrigation$coeff[6]
> >  CoefIrrigation_ts2 <- OLS_Irrigation$coeff[7]
> >  CoefIrrigation_ts3 <- OLS_Irrigation$coeff[8]
> >  CoefIrrigation_ts4 <- OLS_Irrigation$coeff[9]
> >  CoefIrrigation_ps1sq <- OLS_Irrigation$coeff[10]
> >  CoefIrrigation_ps2sq <- OLS_Irrigation$coeff[11]
> >  CoefIrrigation_ps3sq <- OLS_Irrigation$coeff[12]
> >  CoefIrrigation_ps4sq <- OLS_Irrigation$coeff[13]
> >  CoefIrrigation_ts1sq <- OLS_Irrigation$coeff[14]
> >  CoefIrrigation_ts2sq <- OLS_Irrigation$coeff[15]
> >  CoefIrrigation_ts3sq <- OLS_Irrigation$coeff[16]
> >  CoefIrrigation_ts4sq <- OLS_Irrigation$coeff[17]
> >
> >  attach(Alldata_Irrigation)
> >  # gives the residual errors in Y
> >  Alldata_Irrigation$residuals <-resid(OLS_Irrigation)
> >
> >  # gives the predicted values for Ln_Y
> >  Alldata_Irrigation$Ln_y_hat <-fitted(OLS_Irrigation)
> >
> >  # Zelf functie rmse maken
> >  rmse <- function(error)
> >  {
> >    sqrt(mean(error^2))
> >  }
> >  Alldata_Irrigation$y_hat <-
> > exp(Alldata_Irrigation$Ln_y_hat)*exp(0.5*(rmse(OLS_Irrigation$residuals))^2)
> >
> >  # absolute impact (landwaarde current)
> >  Alldata_Irrigation$absolute.current<-Alldata_Irrigation$y_hat*Alldata_Irrigation$se025*Alldata_Irrigation$sys02
> >
> >
> >  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or COUNTRY level)
> >  # Maar dit is dus de marginale impact per LnALVperHA?
> >
> >  Alldata_Irrigation$MEts1 =
> > CoefIrrigation_ts1+2*CoefIrrigation_ts1sq*Alldata_Irrigation$ts1
> >  Alldata_Irrigation$MEts2 =
> > CoefIrrigation_ts2+2*CoefIrrigation_ts2sq*Alldata_Irrigation$ts2
> >  Alldata_Irrigation$MEts3 =
> > CoefIrrigation_ts3+2*CoefIrrigation_ts3sq*Alldata_Irrigation$ts3
> >  Alldata_Irrigation$MEts4 =
> > CoefIrrigation_ts4+2*CoefIrrigation_ts4sq*Alldata_Irrigation$ts4
> >  Alldata_Irrigation$MEt   = Alldata_Irrigation$MEts1 +
> > Alldata_Irrigation$MEts2 + Alldata_Irrigation$MEts3 +
> > Alldata_Irrigation$MEts4
> >
> >  Alldata_Irrigation$MEps1 =
> > CoefIrrigation_ps1+2*CoefIrrigation_ps1sq*Alldata_Irrigation$ps1
> >  Alldata_Irrigation$MEps2 =
> > CoefIrrigation_ps2+2*CoefIrrigation_ps2sq*Alldata_Irrigation$ps2
> >  Alldata_Irrigation$MEps3 =
> > CoefIrrigation_ps3+2*CoefIrrigation_ps3sq*Alldata_Irrigation$ps3
> >  Alldata_Irrigation$MEps4 =
> > CoefIrrigation_ps4+2*CoefIrrigation_ps4sq*Alldata_Irrigation$ps4
> >  Alldata_Irrigation$MEp   = Alldata_Irrigation$MEps1 +
> > Alldata_Irrigation$MEps2 + Alldata_Irrigation$MEps3 +
> > Alldata_Irrigation$MEps4
> >
> >
> >  Alldata_Irrigation$weight2<-Alldata_Irrigation$sys02*Alldata_Irrigation$se025
> >  Alldata_Irrigation$weight2<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> >
> >  attach(Alldata_Irrigation)
> >  library(stats)
> >  MEt_Irrigation<-weighted.mean(MEt,weight2)
> >  MEp_Irrigation<-weighted.mean(MEp,weight2)
> >
> >  c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> >
> >  attach(Alldata)
> >
> >
> >  # And in the loop (index i):
> >
> >  d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> >
> >
> > })
> > out<-as.data.frame(do.call(rbind, o))
> >
> >
> >
> >
> > And the data are:
> >
> > structure(list(LnALVperHA = c(8.09964942932129, 9.53274631500244,
> > 7.42697763442993, 8.25370121002197, 8.42619132995605, 8.0093936920166,
> > 8.09785747528076, 8.49044704437256, 9.08215141296387, 8.38935947418213,
> > 8.67814350128174, 8.38935947418213, 10.4056901931763, 8.48210144042969,
> > 8.30281829833984, 8.92265796661377, 8.33178997039795, 4.54404163360596,
> > 10.662184715271, 9.62167072296143, 7.98790407180786, 7.58244323730469,
> > 7.23262739181519, 9.47037124633789, 8.93403625488281, 7.54256629943848,
> > 9.40302467346191, 10.6290521621704, 8.59830188751221, 8.59585666656494,
> > 9.10000514984131, 9.99381542205811, 9.54681301116943, 9.53055191040039,
> > 8.67971229553223, 7.19780731201172, 8.90067958831787, 6.0509786605835,
> > 6.55788946151733, 8.22567272186279, 9.05618953704834, 6.81858921051025,
> > 8.46410751342773, 7.81292057037354, 8.38989448547363, 10.4709157943726,
> > 8.06132888793945, 8.43629264831543, 10.3087100982666, 10.3218297958374
> > ), ps1 = c(5.14855766296387, 4.71904611587524, 7.9462103843689,
> > 10.6017990112305, 11.233078956604, 9.12952136993408, 12.6536712646484,
> > 11.233078956604, 11.233078956604, 11.233078956604, 11.233078956604,
> > 11.233078956604, 5.93759632110596, 10.6017990112305, 11.233078956604,
> > 10.6017990112305, 7.95780467987061, 9.07744884490967, 4.29865598678589,
> > 8.27481746673584, 3.25137901306152, 4.51061344146729, 6.34518480300903,
> > 6.66202449798584, 6.66202449798584, 4.75249433517456, 6.28858852386475,
> > 6.33270215988159, 10.3600759506226, 10.3600759506226, 18.7164611816406,
> > 5.73318386077881, 7.92949104309082, 9.09823608398438, 11.233078956604,
> > 10.4455404281616, 11.233078956604, 10.4455404281616, 10.4455404281616,
> > 10.6017990112305, 9.19112777709961, 10.4455404281616, 11.233078956604,
> > 11.064302444458, 11.233078956604, 5.93759632110596, 11.233078956604,
> > 10.6017990112305, 6.05948448181152, 9.5645227432251), ps2 = c(5.23111915588379,
> > 4.86784505844116, 7.7175760269165, 4.34898376464844, 4.48626232147217,
> > 9.57159423828125, 8.38174915313721, 4.48626232147217, 4.48626232147217,
> > 4.48626232147217, 4.48626232147217, 4.48626232147217, 6.87198734283447,
> > 4.34898376464844, 4.48626232147217, 4.34898376464844, 6.2098217010498,
> > 7.5497522354126, 5.62545442581177, 5.57168531417847, 3.08954334259033,
> > 6.6683931350708, 4.41767883300781, 6.11901044845581, 6.11901044845581,
> > 4.06884765625, 6.35917854309082, 5.7121729850769, 8.55229663848877,
> > 8.55229663848877, 11.8981914520264, 5.49351119995117, 5.34777498245239,
> > 6.12420177459717, 4.48626232147217, 5.2967677116394, 4.48626232147217,
> > 5.2967677116394, 5.2967677116394, 4.34898376464844, 4.51386308670044,
> > 5.2967677116394, 4.48626232147217, 5.98725175857544, 4.48626232147217,
> > 6.87198734283447, 4.48626232147217, 4.34898376464844, 5.58411026000977,
> > 4.42436075210571), ps3 = c(4.95634937286377, 3.50353670120239,
> > 6.01129817962646, 0.851324141025543, 0.816295921802521, 8.03804397583008,
> > 5.56230783462524, 0.816295921802521, 0.816295921802521, 0.816295921802521,
> > 0.816295921802521, 0.816295921802521, 6.01666784286499, 0.851324141025543,
> > 0.816295921802521, 0.851324141025543, 3.45424580574036, 5.31899690628052,
> > 7.45753812789917, 3.34133338928223, 6.61472988128662, 11.244439125061,
> > 2.19617891311646, 5.29748106002808, 5.29748106002808, 1.63307499885559,
> > 5.51272773742676, 6.78562116622925, 4.5334997177124, 4.5334997177124,
> > 4.31791353225708, 7.10963106155396, 2.32198905944824, 2.74845194816589,
> > 0.816295921802521, 1.47570741176605, 0.816295921802521, 1.47570741176605,
> > 1.47570741176605, 0.851324141025543, 1.39068424701691, 1.47570741176605,
> > 0.816295921802521, 1.85064959526062, 0.816295921802521, 6.01666784286499,
> > 0.816295921802521, 0.851324141025543, 6.78009986877441, 1.21070051193237
> > ), ps4 = c(5.66667366027832, 4.82342433929443, 7.40090322494507,
> > 6.59299898147583, 7.33758926391602, 9.98004341125488, 10.3958940505981,
> > 7.33758926391602, 7.33758926391602, 7.33758926391602, 7.33758926391602,
> > 7.33758926391602, 8.31999015808105, 6.59299898147583, 7.33758926391602,
> > 6.59299898147583, 7.05771064758301, 8.38344383239746, 4.75349426269531,
> > 9.00399303436279, 5.48189449310303, 5.9071044921875, 5.30881881713867,
> > 8.68398857116699, 8.68398857116699, 4.32339859008789, 8.57950687408447,
> > 6.78787326812744, 8.68624305725098, 8.68624305725098, 12.9021902084351,
> > 6.14854049682617, 6.71301507949829, 7.50605535507202, 7.33758926391602,
> > 8.11069011688232, 7.33758926391602, 8.11069011688232, 8.11069011688232,
> > 6.59299898147583, 5.92181205749512, 8.11069011688232, 7.33758926391602,
> > 9.29954528808594, 7.33758926391602, 8.31999015808105, 7.33758926391602,
> > 6.59299898147583, 6.16447877883911, 5.83903217315674), ts1 = c(4.19949150085449,
> > 2.46556353569031, 3.96805644035339, 9.05560302734375, 9.5199556350708,
> > 1.18671488761902, 6.60286664962769, 9.5199556350708, 9.5199556350708,
> > 9.5199556350708, 9.5199556350708, 9.5199556350708, 2.12847352027893,
> > 9.05560302734375, 9.5199556350708, 9.05560302734375, 2.11432313919067,
> > 6.49393510818481, -0.165110915899277, 7.78503036499023, -7.71160411834717,
> > -0.979450941085815, 4.96369075775146, 4.28496122360229, 4.28496122360229,
> > 6.35976600646973, 3.02656149864197, 2.80754446983337, 5.94739389419556,
> > 5.94739389419556, 8.70161914825439, 1.57025468349457, 5.08782005310059,
> > 4.27688789367676, 9.5199556350708, 8.49832916259766, 9.5199556350708,
> > 8.49832916259766, 8.49832916259766, 9.05560302734375, 6.33359289169312,
> > 8.49832916259766, 9.5199556350708, 7.99740839004517, 9.5199556350708,
> > 2.12847352027893, 9.5199556350708, 9.05560302734375, 2.67069268226624,
> > 7.33829879760742), ts2 = c(9.89923763275146, 10.9084701538086,
> > 9.61682415008545, 13.6253662109375, 13.8121919631958, 6.19518041610718,
> > 9.40560817718506, 13.8121919631958, 13.8121919631958, 13.8121919631958,
> > 13.8121919631958, 13.8121919631958, 10.3912172317505, 13.6253662109375,
> > 13.8121919631958, 13.6253662109375, 9.77112770080566, 11.5460777282715,
> > 8.18180465698242, 12.9412984848022, 2.54625177383423, 8.29829216003418,
> > 10.6650953292847, 10.1770324707031, 10.1770324707031, 12.4333782196045,
> > 8.98324680328369, 8.45312309265137, 9.23384857177734, 9.23384857177734,
> > 11.371600151062, 8.09108352661133, 12.0714511871338, 11.385799407959,
> > 13.8121919631958, 13.912787437439, 13.8121919631958, 13.912787437439,
> > 13.912787437439, 13.6253662109375, 12.0018119812012, 13.912787437439,
> > 13.8121919631958, 14.0190010070801, 13.8121919631958, 10.3912172317505,
> > 13.8121919631958, 13.6253662109375, 8.53981018066406, 12.7294788360596
> > ), ts3 = c(17.718994140625, 21.1172523498535, 17.8669090270996,
> > 23.1215572357178, 22.9536685943604, 15.3891229629517, 15.7000684738159,
> > 22.9536685943604, 22.9536685943604, 22.9536685943604, 22.9536685943604,
> > 22.9536685943604, 20.1229286193848, 23.1215572357178, 22.9536685943604,
> > 23.1215572357178, 19.8251171112061, 19.3250198364258, 16.8351039886475,
> > 22.2966594696045, 14.6743259429932, 17.1554985046387, 20.1656894683838,
> > 20.0012702941895, 20.0012702941895, 23.2738876342773, 18.6255321502686,
> > 16.2553405761719, 16.551155090332, 16.551155090332, 17.6266174316406,
> > 16.1711521148682, 22.280725479126, 21.450382232666, 22.9536685943604,
> > 23.5616970062256, 22.9536685943604, 23.5616970062256, 23.5616970062256,
> > 23.1215572357178, 22.1113948822021, 23.5616970062256, 22.9536685943604,
> > 23.5085678100586, 22.9536685943604, 20.1229286193848, 22.9536685943604,
> > 23.1215572357178, 16.3595314025879, 22.7737102508545), ts4 = c(11.661883354187,
> > 12.7669324874878, 11.6320190429688, 17.2357921600342, 17.4911460876465,
> > 9.09537506103516, 12.179615020752, 17.4911460876465, 17.4911460876465,
> > 17.4911460876465, 17.4911460876465, 17.4911460876465, 12.0781927108765,
> > 17.2357921600342, 17.4911460876465, 17.2357921600342, 11.9486837387085,
> > 13.7441387176514, 8.9575023651123, 15.9984045028687, 4.02816677093506,
> > 9.12790489196777, 13.0505475997925, 12.842321395874, 12.842321395874,
> > 14.8937959671021, 11.5566177368164, 10.0515727996826, 12.2921047210693,
> > 12.2921047210693, 14.2251281738281, 9.64802074432373, 14.6072359085083,
> > 13.7993869781494, 17.4911460876465, 17.0232067108154, 17.4911460876465,
> > 17.0232067108154, 17.0232067108154, 17.2357921600342, 15.045259475708,
> > 17.0232067108154, 17.4911460876465, 16.7633666992188, 17.4911460876465,
> > 12.0781927108765, 17.4911460876465, 17.2357921600342, 10.0954942703247,
> > 15.9187803268433), ps1sq = c(26.5076465606689, 22.2693958282471,
> > 63.1422576904297, 112.398139953613, 126.182060241699, 83.3481597900391,
> > 160.11540222168, 126.182060241699, 126.182060241699, 126.182060241699,
> > 126.182060241699, 126.182060241699, 35.2550506591797, 112.398139953613,
> > 126.182060241699, 112.398139953613, 63.3266563415527, 82.4000778198242,
> > 18.478443145752, 68.4726028442383, 10.5714654922485, 20.3456344604492,
> > 40.2613716125488, 44.3825721740723, 44.3825721740723, 22.58620262146,
> > 39.5463447570801, 40.1031150817871, 107.331176757812, 107.331176757812,
> > 350.305908203125, 32.8693962097168, 62.8768272399902, 82.7779006958008,
> > 126.182060241699, 109.109313964844, 126.182060241699, 109.109313964844,
> > 109.109313964844, 112.398139953613, 84.4768295288086, 109.109313964844,
> > 126.182060241699, 122.418785095215, 126.182060241699, 35.2550506591797,
> > 126.182060241699, 112.398139953613, 36.7173538208008, 91.480094909668
> > ), ps2sq = c(27.3646068572998, 23.695915222168, 59.560977935791,
> > 18.9136600494385, 20.1265487670898, 91.6154174804688, 70.2537155151367,
> > 20.1265487670898, 20.1265487670898, 20.1265487670898, 20.1265487670898,
> > 20.1265487670898, 47.2242088317871, 18.9136600494385, 20.1265487670898,
> > 18.9136600494385, 38.5618858337402, 56.9987602233887, 31.6457366943359,
> > 31.0436763763428, 9.54527759552002, 44.4674682617188, 19.5158863067627,
> > 37.4422874450684, 37.4422874450684, 16.5555210113525, 40.439151763916,
> > 32.6289215087891, 73.1417770385742, 73.1417770385742, 141.566955566406,
> > 30.1786651611328, 28.5986976623535, 37.5058479309082, 20.1265487670898,
> > 28.0557479858398, 20.1265487670898, 28.0557479858398, 28.0557479858398,
> > 18.9136600494385, 20.3749599456787, 28.0557479858398, 20.1265487670898,
> > 35.8471832275391, 20.1265487670898, 47.2242088317871, 20.1265487670898,
> > 18.9136600494385, 31.1822872161865, 19.5749683380127), ps3sq =
> > c(24.5653991699219,
> > 12.27476978302, 36.1357040405273, 0.72475278377533, 0.666339039802551,
> > 64.6101531982422, 30.9392681121826, 0.666339039802551, 0.666339039802551,
> > 0.666339039802551, 0.666339039802551, 0.666339039802551, 36.2002906799316,
> > 0.72475278377533, 0.666339039802551, 0.72475278377533, 11.9318141937256,
> > 28.2917289733887, 55.614875793457, 11.1645088195801, 43.7546501159668,
> > 126.437408447266, 4.82320165634155, 28.063304901123, 28.063304901123,
> > 2.6669340133667, 30.3901672363281, 46.0446548461914, 20.552619934082,
> > 20.552619934082, 18.6443767547607, 50.5468521118164, 5.39163303375244,
> > 7.55398797988892, 0.666339039802551, 2.17771244049072, 0.666339039802551,
> > 2.17771244049072, 2.17771244049072, 0.72475278377533, 1.93400263786316,
> > 2.17771244049072, 0.666339039802551, 3.42490386962891, 0.666339039802551,
> > 36.2002906799316, 0.666339039802551, 0.72475278377533, 45.9697532653809,
> > 1.46579575538635), ps4sq = c(32.1111907958984, 23.2654228210449,
> > 54.7733688354492, 43.4676361083984, 53.840217590332, 99.6012649536133,
> > 108.074615478516, 53.840217590332, 53.840217590332, 53.840217590332,
> > 53.840217590332, 53.840217590332, 69.2222366333008, 43.4676361083984,
> > 53.840217590332, 43.4676361083984, 49.811279296875, 70.2821273803711,
> > 22.5957069396973, 81.071891784668, 30.0511665344238, 34.8938827514648,
> > 28.183557510376, 75.4116592407227, 75.4116592407227, 18.6917762756348,
> > 73.6079406738281, 46.0752220153809, 75.4508209228516, 75.4508209228516,
> > 166.466506958008, 37.8045501708984, 45.0645713806152, 56.3408660888672,
> > 53.840217590332, 65.7832946777344, 53.840217590332, 65.7832946777344,
> > 65.7832946777344, 43.4676361083984, 35.0678596496582, 65.7832946777344,
> > 53.840217590332, 86.4815444946289, 53.840217590332, 69.2222366333008,
> > 53.840217590332, 43.4676361083984, 38.0007972717285, 34.094295501709
> > ), ts1sq = c(17.6357288360596, 6.07900333404541, 15.7454719543457,
> > 82.0039443969727, 90.6295547485352, 1.40829217433929, 43.5978469848633,
> > 90.6295547485352, 90.6295547485352, 90.6295547485352, 90.6295547485352,
> > 90.6295547485352, 4.53039932250977, 82.0039443969727, 90.6295547485352,
> > 82.0039443969727, 4.47036218643188, 42.1711921691895, 0.0272616147994995,
> > 60.6066970825195, 59.4688377380371, 0.95932412147522, 24.6382255554199,
> > 18.3608932495117, 18.3608932495117, 40.4466247558594, 9.16007423400879,
> > 7.88230609893799, 35.3714942932129, 35.3714942932129, 75.7181777954102,
> > 2.46569967269897, 25.8859119415283, 18.2917709350586, 90.6295547485352,
> > 72.2215957641602, 90.6295547485352, 72.2215957641602, 72.2215957641602,
> > 82.0039443969727, 40.1143989562988, 72.2215957641602, 90.6295547485352,
> > 63.9585418701172, 90.6295547485352, 4.53039932250977, 90.6295547485352,
> > 82.0039443969727, 7.13259935379028, 53.8506278991699), ts2sq =
> > c(97.9949035644531,
> > 118.994720458984, 92.4833068847656, 185.650604248047, 190.776641845703,
> > 38.3802604675293, 88.465461730957, 190.776641845703, 190.776641845703,
> > 190.776641845703, 190.776641845703, 190.776641845703, 107.977394104004,
> > 185.650604248047, 190.776641845703, 185.650604248047, 95.4749374389648,
> > 133.311904907227, 66.9419250488281, 167.477203369141, 6.48339796066284,
> > 68.8616561889648, 113.744255065918, 103.571990966797, 103.571990966797,
> > 154.588897705078, 80.6987228393555, 71.4552917480469, 85.2639617919922,
> > 85.2639617919922, 129.313293457031, 65.4656295776367, 145.719940185547,
> > 129.636428833008, 190.776641845703, 193.565658569336, 190.776641845703,
> > 193.565658569336, 193.565658569336, 185.650604248047, 144.043487548828,
> > 193.565658569336, 190.776641845703, 196.53239440918, 190.776641845703,
> > 107.977394104004, 190.776641845703, 185.650604248047, 72.9283599853516,
> > 162.039627075195), ts3sq = c(313.962768554688, 445.938354492188,
> > 319.226440429688, 534.606384277344, 526.870910644531, 236.825103759766,
> > 246.492156982422, 526.870910644531, 526.870910644531, 526.870910644531,
> > 526.870910644531, 526.870910644531, 404.932250976562, 534.606384277344,
> > 526.870910644531, 534.606384277344, 393.035278320312, 373.456390380859,
> > 283.420715332031, 497.141021728516, 215.335845947266, 294.311126708984,
> > 406.655029296875, 400.050811767578, 400.050811767578, 541.673828125,
> > 346.910461425781, 264.236083984375, 273.940734863281, 273.940734863281,
> > 310.697631835938, 261.506164550781, 496.430725097656, 460.118896484375,
> > 526.870910644531, 555.153564453125, 526.870910644531, 555.153564453125,
> > 555.153564453125, 534.606384277344, 488.913787841797, 555.153564453125,
> > 526.870910644531, 552.652770996094, 526.870910644531, 404.932250976562,
> > 526.870910644531, 534.606384277344, 267.63427734375, 518.641906738281
> > ), ts4sq = c(135.999526977539, 162.994567871094, 135.303863525391,
> > 297.072540283203, 305.940185546875, 82.7258453369141, 148.343017578125,
> > 305.940185546875, 305.940185546875, 305.940185546875, 305.940185546875,
> > 305.940185546875, 145.882736206055, 297.072540283203, 305.940185546875,
> > 297.072540283203, 142.771041870117, 188.901351928711, 80.2368469238281,
> > 255.948944091797, 16.2261276245117, 83.3186492919922, 170.316787719727,
> > 164.925216674805, 164.925216674805, 221.825164794922, 133.555419921875,
> > 101.034118652344, 151.095840454102, 151.095840454102, 202.354278564453,
> > 93.0843048095703, 213.371337890625, 190.423080444336, 305.940185546875,
> > 289.789581298828, 305.940185546875, 289.789581298828, 289.789581298828,
> > 297.072540283203, 226.359832763672, 289.789581298828, 305.940185546875,
> > 281.010467529297, 305.940185546875, 145.882736206055, 305.940185546875,
> > 297.072540283203, 101.919006347656, 253.407562255859), pdnsty =
> > c(0.616999983787537,
> > 0.0850000008940697, 0.068000003695488, 0.025000000372529, 0.0549999997019768,
> > 0.0230000000447035, 0.133000001311302, 0.0549999997019768, 0.0549999997019768,
> > 0.0549999997019768, 0.0549999997019768, 0.0549999997019768, 0.25900000333786,
> > 0.025000000372529, 0.0549999997019768, 0.025000000372529, 0.0140000004321337,
> > 0.14300000667572, 0.140000000596046, 0.777999997138977, 0.0329999998211861,
> > 0.316000014543533, 0.0179999992251396, 0.105999998748302, 0.105999998748302,
> > 0.046000000089407, 0.108000002801418, 0.310999989509583, 0.101000003516674,
> > 0.101000003516674, 0.14300000667572, 0.168999999761581, 0.0439999997615814,
> > 0.0379999987781048, 0.0549999997019768, 0.063000001013279, 0.0549999997019768,
> > 0.063000001013279, 0.063000001013279, 0.025000000372529, 0.0640000030398369,
> > 0.063000001013279, 0.0549999997019768, 0.209000006318092, 0.0549999997019768,
> > 0.25900000333786, 0.0549999997019768, 0.025000000372529, 0.257999986410141,
> > 0.0469999983906746), portsML = c(0.0900330692529678, 0.0604440234601498,
> > 0.168490216135979, 0.275995850563049, 0.269018620252609, 0.175392478704453,
> > 0.0350189469754696, 0.269018620252609, 0.269018620252609, 0.269018620252609,
> > 0.269018620252609, 0.269018620252609, 0.11026918143034, 0.275995850563049,
> > 0.269018620252609, 0.275995850563049, 0.145082741975784, 0.00440915673971176,
> > 0.426146239042282, 0.0686663240194321, 0.103511147201061, 0.289726078510284,
> > 0.234196603298187, 0.123688526451588, 0.123688526451588, 0.315173029899597,
> > 0.112561739981174, 0.0461684986948967, 0.179993003606796, 0.179993003606796,
> > 0.0438785217702389, 0.096462681889534, 0.0934395045042038, 0.121217466890812,
> > 0.269018620252609, 0.212490051984787, 0.269018620252609, 0.212490051984787,
> > 0.212490051984787, 0.275995850563049, 0.162760972976685, 0.212490051984787,
> > 0.269018620252609, 0.270619571208954, 0.269018620252609, 0.11026918143034,
> > 0.269018620252609, 0.275995850563049, 0.108705826103687, 0.196496397256851
> > ), cities500k = c(0.0360943526029587, 0.0577861145138741, 0.183606043457985,
> > 0.150749072432518, 0.185974538326263, 0.0923599153757095, 0.353672504425049,
> > 0.185974538326263, 0.185974538326263, 0.185974538326263, 0.185974538326263,
> > 0.185974538326263, 0.0887016654014587, 0.150749072432518, 0.185974538326263,
> > 0.150749072432518, 0.144800990819931, 0.00326321297325194, 0.0622526630759239,
> > 0.00816718116402626, 0.181859150528908, 0.163181975483894, 0.204970955848694,
> > 0.129742562770844, 0.129742562770844, 0.0783679932355881, 0.0559677332639694,
> > 0.0293320622295141, 0.248573184013367, 0.248573184013367, 0.174525216221809,
> > 0.092569001019001, 0.176346719264984, 0.16088992357254, 0.185974538326263,
> > 0.280431807041168, 0.185974538326263, 0.280431807041168, 0.280431807041168,
> > 0.150749072432518, 0.088722825050354, 0.280431807041168, 0.185974538326263,
> > 0.189705356955528, 0.185974538326263, 0.0887016654014587, 0.185974538326263,
> > 0.150749072432518, 0.0712414756417274, 0.0842432081699371), rentedland
> > = c(0.571943998336792,
> > 0, 0.5929936170578, 0, 0, 0.755691230297089, 0.440930217504501,
> > 0, 0, 0, 0.229885056614876, 0, 0, 0, 0, 0, 0.890581607818604,
> > 0.212423488497734, 0.386227518320084, 0, 0.11130790412426, 0.483032256364822,
> > 0.444395005702972, 0, 0, 0.253378361463547, 0, 0.10909091681242,
> > 0.181818187236786, 0.666666686534882, 0, 0.94951194524765, 0.846153855323792,
> > 0.403846144676208, 0, 0, 0.155963316559792, 0, 0, 0.408163279294968,
> > 0.699570834636688, 0, 0, 0, 0, 0, 0.0476190522313118, 0, 0, 0
> > ), subsidies1 = c(361.835754394531, 0, 368.242034912109, 345.636352539062,
> > 701.746032714844, 488.922821044922, 344.918609619141, 790.392150878906,
> > 795.3125, 631.666687011719, 193.563217163086, 565.75, 0, 577.586181640625,
> > 395.681823730469, 192, 371.963653564453, 9.9977331161499, 310.838317871094,
> > 905.764709472656, 1745.76293945312, 359.003814697266, 163.204330444336,
> > 427.94970703125, 204.842727661133, 52.2592887878418, 0, 0, 3022.24243164062,
> > 80.2666702270508, 445.366577148438, 925.681640625, 824.769226074219,
> > 625.192321777344, 850.441162109375, 280.891723632812, 619.266052246094,
> > 333.962249755859, 376.304351806641, 317.551025390625, 166.652359008789,
> > 171.224487304688, 526.119445800781, 253.191497802734, 334.470581054688,
> > 107.277839660645, 431.428588867188, 0, 107.245544433594, 339.701507568359
> > ), elevmean = c(0.121736958622932, 0.46412268280983, 0.344255149364471,
> > 0.466430068016052, 0.43000802397728, 1.15364873409271, 0.0955904126167297,
> > 0.43000802397728, 0.43000802397728, 0.43000802397728, 0.43000802397728,
> > 0.43000802397728, 0.370405077934265, 0.466430068016052, 0.43000802397728,
> > 0.466430068016052, 0.849120080471039, 0.0433186627924442, 0.335433751344681,
> > 0.271958351135254, 0.125564843416214, 0.376024007797241, 0.815701544284821,
> > 0.525435268878937, 0.525435268878937, 0.62959760427475, 0.518330037593842,
> > 0.00362438289448619, 0.628515422344208, 0.628515422344208, 0.274942100048065,
> > 0.0728112533688545, 0.496583759784698, 0.739268243312836, 0.43000802397728,
> > 0.321640431880951, 0.43000802397728, 0.321640431880951, 0.321640431880951,
> > 0.466430068016052, 0.585907399654388, 0.321640431880951, 0.43000802397728,
> > 0.147326037287712, 0.43000802397728, 0.370405077934265, 0.43000802397728,
> > 0.466430068016052, 0.0183117985725403, 0.414920538663864), elevrange =
> > c(0.180000007152557,
> > 1.99300003051758, 0.611000001430511, 2.35199999809265, 2.29999995231628,
> > 2.94199991226196, 0.354999989271164, 2.29999995231628, 2.29999995231628,
> > 2.29999995231628, 2.29999995231628, 2.29999995231628, 2.01799988746643,
> > 2.35199999809265, 2.29999995231628, 2.35199999809265, 1.7389999628067,
> > 0.160999998450279, 0.314000010490417, 1.76300001144409, 0.17399999499321,
> > 0.653999984264374, 1.63399994373322, 2.19099998474121, 2.19099998474121,
> > 1.14100003242493, 1.34800004959106, 0.00899999961256981, 2.41300010681152,
> > 2.41300010681152, 0.787999987602234, 0.26800000667572, 1.92200005054474,
> > 2.02600002288818, 2.29999995231628, 1.05099999904633, 2.29999995231628,
> > 1.05099999904633, 1.05099999904633, 2.35199999809265, 2.35999989509583,
> > 1.05099999904633, 2.29999995231628, 0.772000014781952, 2.29999995231628,
> > 2.01799988746643, 2.29999995231628, 2.35199999809265, 0.0649999976158142,
> > 1.75399994850159), t_gravel = c(4.58953237533569, 13.3146963119507,
> > 10.0136280059814, 13.8894920349121, 13.9366893768311, 13.5653190612793,
> > 7.71220588684082, 13.9366893768311, 13.9366893768311, 13.9366893768311,
> > 13.9366893768311, 13.9366893768311, 11.4818019866943, 13.8894920349121,
> > 13.9366893768311, 13.8894920349121, 13.4321727752686, 5.71388387680054,
> > 8.03888702392578, 9.01077747344971, 4.58924961090088, 8.14134693145752,
> > 11.8983144760132, 9.96716785430908, 9.96716785430908, 11.1739711761475,
> > 10.4019403457642, 5.16821479797363, 10.7357034683228, 10.7357034683228,
> > 9.23897457122803, 4.3336238861084, 10.9520101547241, 12.9722995758057,
> > 13.9366893768311, 13.1780118942261, 13.9366893768311, 13.1780118942261,
> > 13.1780118942261, 13.8894920349121, 12.7335777282715, 13.1780118942261,
> > 13.9366893768311, 12.315260887146, 13.9366893768311, 11.4818019866943,
> > 13.9366893768311, 13.8894920349121, 6.68424606323242, 14.101095199585
> > ), t_ph_h2o = c(6.07352828979492, 6.72695684432983, 5.60523176193237,
> > 6.13967752456665, 6.86059141159058, 7.40929126739502, 5.68151950836182,
> > 6.86059141159058, 6.86059141159058, 6.86059141159058, 6.86059141159058,
> > 6.86059141159058, 6.51894521713257, 6.13967752456665, 6.86059141159058,
> > 6.13967752456665, 6.98909568786621, 5.5628228187561, 6.68793487548828,
> > 6.57724285125732, 4.67033195495605, 6.32772016525269, 6.4612717628479,
> > 6.73934555053711, 6.73934555053711, 6.80293703079224, 6.17414236068726,
> > 7.03696584701538, 5.93052577972412, 5.93052577972412, 5.43228578567505,
> > 5.5989408493042, 6.86088180541992, 6.68706750869751, 6.86059141159058,
> > 6.00043678283691, 6.86059141159058, 6.00043678283691, 6.00043678283691,
> > 6.13967752456665, 6.89467239379883, 6.00043678283691, 6.86059141159058,
> > 6.81896543502808, 6.86059141159058, 6.51894521713257, 6.86059141159058,
> > 6.13967752456665, 5.63159275054932, 6.13170003890991), t_silt =
> > c(34.2329025268555,
> > 33.4969100952148, 34.4774589538574, 27.8914813995361, 31.9258117675781,
> > 39.6254501342773, 34.7939414978027, 31.9258117675781, 31.9258117675781,
> > 31.9258117675781, 31.9258117675781, 31.9258117675781, 26.6626663208008,
> > 27.8914813995361, 31.9258117675781, 27.8914813995361, 29.7444763183594,
> > 21.3432540893555, 37.4038734436035, 28.1513748168945, 19.4936828613281,
> > 33.5968360900879, 32.8024406433105, 33.313850402832, 33.313850402832,
> > 28.3197917938232, 33.3154563903809, 38.103458404541, 36.0389099121094,
> > 36.0389099121094, 34.9229164123535, 26.5577545166016, 30.9245643615723,
> > 31.1334323883057, 31.9258117675781, 27.1493148803711, 31.9258117675781,
> > 27.1493148803711, 27.1493148803711, 27.8914813995361, 31.3038387298584,
> > 27.1493148803711, 31.9258117675781, 31.6541061401367, 31.9258117675781,
> > 26.6626663208008, 31.9258117675781, 27.8914813995361, 15.6523361206055,
> > 27.803352355957), t_sand = c(47.0063323974609, 37.0355186462402,
> > 45.8286781311035, 36.0810203552246, 39.9931793212891, 39.3664970397949,
> > 46.2948226928711, 39.9931793212891, 39.9931793212891, 39.9931793212891,
> > 39.9931793212891, 39.9931793212891, 49.3508529663086, 36.0810203552246,
> > 39.9931793212891, 36.0810203552246, 39.2436943054199, 65.7813262939453,
> > 35.8039131164551, 51.2884674072266, 66.2952728271484, 46.6789817810059,
> > 41.4505424499512, 44.4590721130371, 44.4590721130371, 48.7276763916016,
> > 43.3654098510742, 33.999683380127, 43.040699005127, 43.040699005127,
> > 43.2519073486328, 59.4827156066895, 43.8675765991211, 41.7124671936035,
> > 39.9931793212891, 34.94921875, 39.9931793212891, 34.94921875,
> > 34.94921875, 36.0810203552246, 39.1853942871094, 34.94921875,
> > 39.9931793212891, 39.8589019775391, 39.9931793212891, 49.3508529663086,
> > 39.9931793212891, 36.0810203552246, 75.7048721313477, 33.5687866210938
> > ), AT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), BE = c(0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0), DE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), DK = c(0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0), ES = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), FI = c(0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0), FR = c(1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), GR = c(0, 1, 0,
> > 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> > 0, 1, 1, 0, 1), IE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), IT = c(0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
> > 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 1, 0, 0, 0, 0), LU = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), NL = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 1, 0), PT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SE = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), WDE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), EDE = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), UK = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CY = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), BG = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CZ = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), EE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), HU = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), LT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), LV = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), PL = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), RO = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), SI = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SK = c(0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), b48 = c(70, 2.70000004768372, 63.9000015258789,
> > 5.5, 6.30000019073486, 8.80000019073486, 48.0800018310547, 5.09999990463257,
> > 6.40000009536743, 6, 6.69999980926514, 4, 6.30000019073486, 5.80000019073486,
> > 8.80000019073486, 2, 13, 0.5, 10.25, 34, 65.2300033569336, 37.7799987792969,
> > 74.9400024414062, 31.0200004577637, 20.0300006866455, 70.7200012207031,
> > 40, 4.90000009536743, 13.5, 5, 26.8700008392334, 3, 2, 3.09999990463257,
> > 6.80000019073486, 15.6999998092651, 9.19999980926514, 5.30000019073486,
> > 4.59999990463257, 17.3999996185303, 7, 4.90000009536743, 13.3999996185303,
> > 2.34999990463257, 8.5, 24.8700008392334, 4, 1.39999997615814,
> > 34.7799987792969, 6.69999980926514), b50 = c(0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34.2400016784668, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 0, 0, 0, 0, 0), irrigation = c(0, 100, 0, 5.45454584062099,
> > 7.9365074634552, 89.3392562866211, 0, 17.6470592617989, 0, 0,
> > 65.5172407627106, 0, 61.904764175415, 34.4827562570572, 7.95454531908035,
> > 75, 0, 0, 0, 0, 0, 0, 5.26393800973892, 0, 0, 0, 0, 0, 0, 0,
> > 0, 0, 74.6153831481934, 84.6153914928436, 0, 5.09554147720337,
> > 0, 0, 0, 21.0884347558022, 18.4549376368523, 6.1224490404129,
> > 25.3731369972229, 2.12765969336033, 0, 84.3988716602325, 0, 0,
> > 0, 100), awc_class = c(106.228088378906, 78.2306137084961, 80.9311141967773,
> > 32.4921531677246, 54.8475151062012, 80.6665878295898, 116.331588745117,
> > 54.8475151062012, 54.8475151062012, 54.8475151062012, 54.8475151062012,
> > 54.8475151062012, 56.3101806640625, 32.4921531677246, 54.8475151062012,
> > 32.4921531677246, 59.3034172058105, 101.193893432617, 96.5840377807617,
> > 54.2786560058594, 87.1388244628906, 66.1907730102539, 57.205738067627,
> > 55.4114303588867, 55.4114303588867, 80.9288787841797, 63.6008758544922,
> > 150, 30.3404140472412, 30.3404140472412, 19.8318557739258, 104.236854553223,
> > 79.2445755004883, 57.0045547485352, 54.8475151062012, 34.320426940918,
> > 54.8475151062012, 34.320426940918, 34.320426940918, 32.4921531677246,
> > 65.1337509155273, 34.320426940918, 54.8475151062012, 73.6748657226562,
> > 54.8475151062012, 56.3101806640625, 54.8475151062012, 32.4921531677246,
> > 127.726959228516, 27.9528160095215), sys02 = c(18.8571434020996,
> > 303.529418945312, 30.2469139099121, 104.305557250977, 86.4935073852539,
> > 51.25, 83.0927810668945, 453.118286132812, 42.5, 104.305557250977,
> > 48.461540222168, 86.4935073852539, 55.1851844787598, 104.305557250977,
> > 104.305557250977, 185.277770996094, 17.9775276184082, 25.2777786254883,
> > 64, 21.6666660308838, 30, 24.2372875213623, 47.0285720825195,
> > 16.1904754638672, 33.75, 22.5423736572266, 10.2857141494751,
> > 39.230770111084, 6.06741571426392, 1, 28.3255805969238, 21.6000003814697,
> > 69.2592620849609, 86.6666641235352, 48.5185203552246, 44.4186058044434,
> > 48.6538467407227, 437.105255126953, 437.105255126953, 19.1666660308838,
> > 48.461540222168, 437.105255126953, 48.6538467407227, 453.118286132812,
> > 48.6538467407227, 14.2857141494751, 453.118286132812, 453.118286132812,
> > 95.2380981445312, 63), se025 = c(163.529998779297, 2.70000004768372,
> > 157, 5.5, 6.30000019073486, 36.0200004577637, 86, 5.09999990463257,
> > 6.40000009536743, 6, 8.69999980926514, 4, 6.30000019073486, 5.80000019073486,
> > 8.80000019073486, 2, 118.809997558594, 44.1100006103516, 16.7000007629395,
> > 34, 73.4000015258789, 73.0800018310547, 134.880004882812, 31.0200004577637,
> > 20.0300006866455, 94.7200012207031, 40, 5.5, 16.5, 15, 26.8700008392334,
> > 59.4199981689453, 13, 5.19999980926514, 6.80000019073486, 15.6999998092651,
> > 10.8999996185303, 5.30000019073486, 4.59999990463257, 29.3999996185303,
> > 23.2999992370605, 4.90000009536743, 13.3999996185303, 2.34999990463257,
> > 8.5, 24.8700008392334, 4.19999980926514, 1.39999997615814, 34.7799987792969,
> > 6.69999980926514)), .Names = c("LnALVperHA", "ps1", "ps2", "ps3",
> > "ps4", "ts1", "ts2", "ts3", "ts4", "ps1sq", "ps2sq", "ps3sq",
> > "ps4sq", "ts1sq", "ts2sq", "ts3sq", "ts4sq", "pdnsty", "portsML",
> > "cities500k", "rentedland", "subsidies1", "elevmean", "elevrange",
> > "t_gravel", "t_ph_h2o", "t_silt", "t_sand", "AT", "BE", "DE",
> > "DK", "ES", "FI", "FR", "GR", "IE", "IT", "LU", "NL", "PT", "SE",
> > "WDE", "EDE", "UK", "CY", "BG", "CZ", "EE", "HU", "LT", "LV",
> > "PL", "RO", "SI", "SK", "b48", "b50", "irrigation", "awc_class",
> > "sys02", "se025"), row.names = c("2", "3", "4", "5", "6", "7",
> > "8", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
> > "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31",
> > "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
> > "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53"
> > ), class = "data.frame")
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > 2015-08-14 14:58 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz>:
> >>
> >> Hi Janka
> >>
> >>
> >>
> >> Sorry, but we are limited in connecting to web services so I am not able to restore your data and see your code. Result of dput(somedata) coppied to email is preferable for sharing data and code can be copied to email too. But do not use HTML as it usually scrambles  text.
> >>
> >>
> >>
> >> Answer in line
> >>
> >>
> >>
> >> From: Janka Vanschoenwinkel [mailto:janka.vanschoenwinkel at uhasselt.be]
> >> Sent: Friday, August 14, 2015 2:17 PM
> >> To: Thierry Onkelinx; PIKAL Petr
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] cut variable within a loop
> >>
> >>
> >>
> >> Hi Thierry and Petr,
> >>
> >>
> >>
> >> I really appreciate the comments you already gave. Thank you very much for that.
> >>
> >>
> >>
> >> Below you can find a link to the data and the code. Hopefully this helps in spotting the error.
> >>
> >>
> >>
> >> I still think the issue is that the cut2 function only accepts numbers, and not an "i" that refers to the number at the start of the loop. To answer Petr his question, yes, column 3 and 4 are NA (these are the columns of the second interval). But I don't really understand your point so could you clarify this please?
> >>
> >>
> >>
> >> If you use NA as a number of intervals you will get such errors
> >>
> >>
> >>
> >> k<-c(2,4,NA,5)
> >>
> >> ii<-vector(4, mode="list")
> >>
> >> for (i in 1:4) {
> >>
> >> ii[[i]] <- cut2(iris[,i], k[i])
> >>
> >> }
> >>
> >> Error in if (r[1] < cuts[1]) cuts <- c(r[1], cuts) :
> >>
> >>  missing value where TRUE/FALSE needed
> >>
> >> for (i in 1:4) {
> >>
> >> ii[[i]] <- cut(iris[,i], k[i])
> >>
> >> }
> >>
> >> Error in cut.default(iris[, i], k[i]) : invalid number of intervals
> >>
> >>
> >>
> >> If you remove NA from k definition error is gone.
> >>
> >> k<-c(2,4,3,5)
> >>
> >> ii<-vector(4, mode="list")
> >>
> >>
> >>
> >> for (i in 1:4) {
> >>
> >> ii[[i]] <- cut(iris[,i], k[i])
> >>
> >> }
> >>
> >>
> >>
> >> You can try it yourself. The error is not related to cycle; whenever number of intervals in cut call is NA you always get an error.
> >>
> >>
> >>
> >> Cheers
> >>
> >> Petr
> >>
> >>
> >>
> >> https://drive.google.com/folderview?id=0By9u5m3kxn9yfkxxeVNMdnRQQXhoT05CRlJlZVBCWWF2NURMMTNmVFVFeXJXXzhlMWE4SUk&usp=sharing
> >>
> >>
> >>
> >> Thank you very much once again!
> >>
> >>
> >>
> >> Janka
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> 2015-08-11 15:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> >>
> >> You'll need to send a reproducible example of the code. We can't run the code that you send. Hence it is hard to help you. See e.g. http://adv-r.had.co.nz/Reproducibility.html
> >>
> >>
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> >>
> >>
> >>
> >> 2015-08-11 14:57 GMT+02:00 Janka Vanschoenwinkel <janka.vanschoenwinkel at uhasselt.be>:
> >>
> >> Hi Thierry!
> >>
> >>
> >>
> >> Thanks for your answer. I tried this, but I get this error:
> >>
> >>
> >>
> >> "Error in cut.default(x, k2) : invalid number of intervals"
> >>
> >>
> >>
> >> Which is strange because I am not specifying intervals, but the number at where the sample has to be cut?
> >>
> >>
> >>
> >> Greetings from Belgium! :-)
> >>
> >>
> >>
> >> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> >>
> >> Dear Janka,
> >>
> >>
> >>
> >> You loop goes for 0 to 100. It should probably go from 1:99
> >>
> >>
> >>
> >> Best regards,
> >>
> >>
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> >>
> >>
> >>
> >> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <janka.vanschoenwinkel at uhasselt.be>:
> >>
> >> Dear list members,
> >>
> >> I have a loop where I want to do several calculations for different samples
> >> and save the results for each sample. These samples are for each loop
> >> different. I want to use the "i" in the loop to cut the samples.
> >>
> >> So for instance:
> >>
> >>   - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
> >>   - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
> >>   - In loop 99 (i=99), I have a sample from 0-99 and a sample from 99-100.
> >>
> >> I built the following function, but there is *a problem with the cut2
> >> function* since it doesn't recognize the "i". Outside the lapply loop it
> >> works, but not inside the loop.
> >>
> >> Could somebody please help me with this problem? Thanks a lot!
> >>
> >>
> >> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
> >>
> >>
> >>
> >>    o<-lapply(0:100, function(i){
> >>
> >>
> >>
> >>        Alldata$irri=cut2(Alldata$irrigation,i)
> >>
> >>        levels(Alldata$irri)<-c("0","1")
> >>
> >>
> >>
> >>       Alldata_Rainfed<-subset(Alldata, irri == 0)
> >>
> >>       Alldata_Irrigation<-subset(Alldata, irri == 1)
> >>
> >>
> >>
> >>    #calculations per sample, then store all the values per i and per
> >> variable in a dataframe: (the calculations are not shown in this example)
> >>
> >>
> >>
> >>     d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> >>
> >>
> >>
> >>   })
> >>
> >>
> >>
> >>   out<-as.data.frame(do.call(rbind, o))
> >>
> >>
> >> --
> >> P Please consider the environment before printing this e-mail
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >>
> >>
> >> Mevrouw Janka Vanschoenwinkel
> >> Doctoraatsbursaal - PhD
> >> Milieueconomie - Environmental economics
> >>
> >> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> >>
> >> www.uhasselt.be/eec
> >>
> >> Universiteit Hasselt | Campus Diepenbeek
> >> Agoralaan Gebouw D | B-3590 Diepenbeek
> >> Kantoor F11
> >>
> >> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> >>
> >> P Please consider the environment before printing this e-mail
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >>
> >>
> >> Mevrouw Janka Vanschoenwinkel
> >> Doctoraatsbursaal - PhD
> >> Milieueconomie - Environmental economics
> >>
> >> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> >>
> >> www.uhasselt.be/eec
> >>
> >> Universiteit Hasselt | Campus Diepenbeek
> >> Agoralaan Gebouw D | B-3590 Diepenbeek
> >> Kantoor F11
> >>
> >> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> >>
> >> P Please consider the environment before printing this e-mail
> >>
> >>
> >>
> >>
> >> ________________________________
> >> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> >> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> >> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >>
> >> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> >> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >>
> >> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> >> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> >> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> >> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> >>
> >> In case that this e-mail forms part of business dealings:
> >> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> >> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> >> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> >> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> >
> >
> >
> >
> > --
> >
> > Mevrouw Janka Vanschoenwinkel
> > Doctoraatsbursaal - PhD
> > Milieueconomie - Environmental economics
> >
> > T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> >
> > www.uhasselt.be/eec
> >
> > Universiteit Hasselt | Campus Diepenbeek
> > Agoralaan Gebouw D | B-3590 Diepenbeek
> > Kantoor F11
> >
> > Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> >
> > P Please consider the environment before printing this e-mail
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> 
> -- 
> 
> 	Mevrouw Janka Vanschoenwinkel 
> Doctoraatsbursaal - PhD 
> Milieueconomie - Environmental economics
> 
> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> 
> www.uhasselt.be/eec
> 
> Universiteit Hasselt | Campus Diepenbeek
> Agoralaan Gebouw D | B-3590 Diepenbeek 
> Kantoor F11 
> 
> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt 
> 
> P Please consider the environment before printing this e-mail
> 

David Winsemius
Alameda, CA, USA


From peter.anthoni at kit.edu  Mon Aug 17 07:44:55 2015
From: peter.anthoni at kit.edu (Anthoni, Peter (IMK))
Date: Mon, 17 Aug 2015 05:44:55 +0000
Subject: [R] Error -> cannot open file 'specdata/001.csv': No such file
 or directory; Windows 8, R Version 3.2.1
In-Reply-To: <CAN6BBTQ2zR9Ec-CxF9eZgPJZecsYP1=RFETEfcCeogo4oX9htQ@mail.gmail.com>
References: <CAN6BBTQ2zR9Ec-CxF9eZgPJZecsYP1=RFETEfcCeogo4oX9htQ@mail.gmail.com>
Message-ID: <010B37B7-03D7-4ACE-AE58-B4AAA298E59C@kit.edu>

Hi Nikita,

To check whether the files are really there, run the following at the R prompt:

getwd()
list.files()

> *C:/Users/acer/My Documents/specdata/rprog-data-specdata/specdata*

Your working path looks like you either need to set it to:
  C:/Users/acer/My Documents/specdata/rprog-data-specdata
or change your read.csv to:
   df <- read.csv("001.csv")

cheers
Peter



> On 15 Aug 2015, at 19:06, Nikita Dinger <dingernikita at gmail.com> wrote:
> 
> I am having a problem in opening the excel files in specdata folder.
> 
> I have completed coding the R program for the assignment but when I run the
> following commands in the R console,
> 
> *source("pollutantmean.R")*
> *> pollutantmean("specdata", "nitrate", 23)*
> 
> I get an error message stating
> 
> *Error in file(file, "rt") : cannot open the connection*
> *In addition: Warning message:*
> *In file(file, "rt") :*
> *  cannot open file 'specdata/023.csv': No such file or directory*
> 
> I tried everything and reset my Working Directory to
> 
> 
> *C:/Users/acer/My Documents/specdata/rprog-data-specdata/specdata*
> 
> After the last specdata folder are all the excel sheets numbered 001 to 332.
> 
> I searched the internet and all other options available, and got a solution
> to open it using the following command:
> 
> *df <- read.csv("specdata/001.csv")*
> 
> 
> This generated the following error message
> 
> *Error in file(file, "rt") : cannot open the connection*
> *In addition: Warning message:*
> *In file(file, "rt") :*
> *  cannot open file 'specdata/001.csv': No such file or directory*
> 
> I have tried various other commands also such as
> 
> 
> *path <- c(paste("./",directory, "/",formatC(id[i], width=3,
> flag=0),".csv",sep=""))*
> 
> However, all the commands show some error.
> 
> What shall I do?
> I am using the 3.2.1 version of R on a Windows 8 laptop.
> 
> Regards,
> Nikita Dinger
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Aug 17 08:43:27 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 17 Aug 2015 06:43:27 +0000
Subject: [R] lme4 package installation
In-Reply-To: <CAGetN7UC43++ipv1CAKje48pxpF+JMS0v7z1oQ4AUBaGzsqrTQ@mail.gmail.com>
References: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>
	<CAJuCY5yWc3uCVCkR1qwUgJUPuCrHi81848tEG1mjEhrzUwZrHw@mail.gmail.com>
	<CAGetN7VCYb-OuQOjSGugdPxNrqhx68KrLA0OBKPTZQVbG9GMVA@mail.gmail.com>
	<55CD7CB1.1030306@statistik.tu-dortmund.de>
	<CAGetN7UC43++ipv1CAKje48pxpF+JMS0v7z1oQ4AUBaGzsqrTQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3A020@SRVEXCHMBX.precheza.cz>

Hi

try tu put line

setInternet2(TRUE)

into your Rprofile.site file (located in etc directory of R installation) and restart R.


Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Teck
> Kiang Tan
> Sent: Friday, August 14, 2015 11:21 AM
> To: Uwe Ligges
> Cc: r-help at r-project.org; aurora.gonzalez at openmailbox.org
> Subject: Re: [R] lme4 package installation
>
> Thanks Uwe Ligges for the suggestion.
> I tried using setInternet2() but also failed.
> I tried for several other countries but also failed.
> Any other suggestion to overcome it.
> Thanks.
>
>
> Warning: unable to access index for repository
> http://cran.utstat.utoronto.ca/src/contrib
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/src/contrib
> Warning: unable to access index for repository
> http://cran.utstat.utoronto.ca/bin/windows/contrib/3.2
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2
>
>
> On Fri, Aug 14, 2015 at 1:29 PM, Uwe Ligges <ligges at statistik.tu-
> dortmund.de
> > wrote:
>
> >
> >
> > On 13.08.2015 22:52, Teck Kiang Tan wrote:
> >
> >> Hi all
> >>
> >> I have problem in installation lme4 and have tried over the past 2
> days.
> >> It
> >> failed to install from the various countries.
> >>
> >> install.packages("lme4")
> >>>
> >> Warning: unable to access index for repository
> >> http://cran.stat.nus.edu.sg/src/contrib
> >>
> >
> >
> > This mirror does not respond whn I just tried, choose another one.
> >
> >
> > Warning: unable to access index for repository
> >> http://www.stats.ox.ac.uk/pub/RWin/src/contrib
> >>
> >
> > This one works for me (but does not contain lme4).
> > Perhaps also run setInternet2() before you try again in cae you need
> > proxy settings.
> >
> > Best,
> > Uwe Ligges
> >
> >
> >
> >
> > Warning: unable to access index for repository
> >> http://cran.stat.nus.edu.sg/bin/windows/contrib/3.2
> >>
> >> Warning message:
> >> package ?lme4? is not available (for R version 3.2.1)
> >>
> >> Teck Kiang
> >>
> >>
> >> On Thu, Aug 13, 2015 at 11:09 PM, Thierry Onkelinx <
> >> thierry.onkelinx at inbo.be
> >>
> >>> wrote:
> >>>
> >>
> >> Have you trying installing it directly from CRAN?
> >>>
> >>> install.packages("lme4")
> >>>
> >>> Do you have all dependencies installed? install.packages() from
> CRAN
> >>> will take care of that. You repos = NULL you have to install all
> >>> dependencies manually.
> >>>
> >>> ir. Thierry Onkelinx
> >>> Instituut voor natuur- en bosonderzoek / Research Institute for
> >>> Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics
> >>> & Quality Assurance Kliniekstraat 25 1070 Anderlecht Belgium
> >>>
> >>> To call in the statistician after the experiment is done may be no
> >>> more than asking him to perform a post-mortem examination: he may
> be
> >>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>> The plural of anecdote is not data. ~ Roger Brinner The combination
> >>> of some data and an aching desire for an answer does not ensure
> that
> >>> a reasonable answer can be extracted from a given body of data.
> >>> ~ John Tukey
> >>>
> >>> 2015-08-13 16:13 GMT+02:00 <aurora.gonzalez at openmailbox.org>:
> >>>
> >>> Hello
> >>>>
> >>>> I've downloaded the tar.gz file of the package "lme4" and when I
> >>>> use the
> >>>> coomand:
> >>>>
> >>>> install.packages("lme4_1.1-8.tar.gz", repos = NULL, type =
> >>>> "source")
> >>>>
> >>>> appears an error that suspends the installation:
> >>>>
> >>>>
> >>>> In file included from external.cpp:8:0:
> >>>> predModule.h:12:23: fatal error: RcppEigen.h: No such file or
> >>>> directory compilation terminated.
> >>>> make: *** [external.o] Error 1
> >>>> ERROR: compilation failed for package ?lme4?
> >>>> * removing ?/home/aurora/R/x86_64-pc-linux-gnu-library/3.2/lme4?
> >>>>
> >>>>
> >>>>
> >>>> Does anyone know how to fix it? Thank you very much!
> >>>>
> >>>>
> >>>> My sessionInfo:
> >>>>
> >>>>
> >>>> R version 3.2.1 (2015-06-18)
> >>>> Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu
> >>>> precise (12.04.5 LTS)
> >>>>
> >>>> locale:
> >>>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >>>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >>>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >>>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >>>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >>>>
> >>>> attached base packages:
> >>>> [1] stats     graphics  grDevices utils     datasets  methods
> >>>> [7] base
> >>>>
> >>>> loaded via a namespace (and not attached):
> >>>> [1] tools_3.2.1
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From barbara.rogo at uniroma1.it  Mon Aug 17 10:36:23 2015
From: barbara.rogo at uniroma1.it (Barbara Rogo)
Date: Mon, 17 Aug 2015 10:36:23 +0200
Subject: [R] GARCH model estimation
In-Reply-To: <CAL+pVGi9VNReMuzZSt67O4gZqKg-DO0pT0YCfLz2=CaG_c8K3g@mail.gmail.com>
References: <CAL+pVGi9VNReMuzZSt67O4gZqKg-DO0pT0YCfLz2=CaG_c8K3g@mail.gmail.com>
Message-ID: <CAL+pVGh3VQUDHe=PwaieAvzipYH3ZKD-F1qM=8-rE2Apk_WyPQ@mail.gmail.com>

I have to estimate the volatility of FTSE/MIB index with a GARCH model from
2012-06-21 to 2015-04-30, in every day. I use garchFit function, but I
don't understand the meaning of se.coef output. Does this function estimate
the volatility in every day of the time series (in input)? So does it
estimate three parameters (for example if the model is GARCH(1,1)) in every
day?

Thanks for your help.

2015-08-04 19:25 GMT+02:00 Barbara Rogo <barbara.rogo at uniroma1.it>:

> I have to estimate the volatility of FTSE/MIB index with a GARCH model
> from 2012-06-21 to 2015-04-30, in every day. I use garchFit function, but I
> don't understand the meaning of se.coef output. Does this function estimate
> the volatility in every day of the time series (in input)? So does it
> estimate three parameters (for example if the model is GARCH(1,1)) in every
> day?
>
> Thanks for your help.
>
> Barbara
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Aug 17 10:45:35 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 17 Aug 2015 18:45:35 +1000
Subject: [R] All results not showing in console (very large dataset)
In-Reply-To: <1439716251103-4711150.post@n4.nabble.com>
References: <1439716251103-4711150.post@n4.nabble.com>
Message-ID: <CA+8X3fXLkk_qRvpubUbRqq=xyafZBWHsC99EgQ4RsmfLV3ny_g@mail.gmail.com>

Hi Aureus,
I think you have cut and pasted the text in the console window when
you say "saving to text". One way to get the entire output of your
test is:

sink('"simper_test.txt")
# run your test code here
sink()

The output will be in the file "simper_test.txt"

Jim


On Sun, Aug 16, 2015 at 7:10 PM, Aureus <hazel_knipe at hotmail.co.uk> wrote:
> Hi,
>
> I have a very large dataset, and have run a simper test on it. However, the
> output is so large that I cannot see the first sets of results in the
> console. How can I view them? I have tried saving to text, but it only saves
> what's in the console.
>
> Or is there a way to report the first X number of results from each
> contrasting test? Or summarise each test result individually?
>
> Thanks!
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/All-results-not-showing-in-console-very-large-dataset-tp4711150.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Mon Aug 17 13:30:49 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 17 Aug 2015 12:30:49 +0100
Subject: [R] lme4 package installation
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3A020@SRVEXCHMBX.precheza.cz>
References: <1ca3339cedf4be76f916f016b84b3b51@openmailbox.org>
	<CAJuCY5yWc3uCVCkR1qwUgJUPuCrHi81848tEG1mjEhrzUwZrHw@mail.gmail.com>
	<CAGetN7VCYb-OuQOjSGugdPxNrqhx68KrLA0OBKPTZQVbG9GMVA@mail.gmail.com>
	<55CD7CB1.1030306@statistik.tu-dortmund.de>
	<CAGetN7UC43++ipv1CAKje48pxpF+JMS0v7z1oQ4AUBaGzsqrTQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3A020@SRVEXCHMBX.precheza.cz>
Message-ID: <1A8C1289955EF649A09086A153E2672403B4431ABA@GBTEDVPEXCMB04.corp.lgc-group.com>

> try tu put line
> 
> setInternet2(TRUE)
> 
> into your Rprofile.site file (located in etc directory of R installation) and restart
> R.

You may well need to specify the utils library, as follows, to make sure the setInternet2 function is found at run time: 

utils::setInternet2()



S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From anshuk.p at motivitylabs.com  Mon Aug 17 16:27:01 2015
From: anshuk.p at motivitylabs.com (Anshuk Pal Chaudhuri)
Date: Mon, 17 Aug 2015 14:27:01 +0000
Subject: [R] Text Pattern Recognition - Model
Message-ID: <SG2PR02MB063496A4D43CBB478903E5FBF0790@SG2PR02MB0634.apcprd02.prod.outlook.com>

Hi,

I have a training dataset which has two columns which has around 70 values.

1.       "PNRNo" whose values like UT768G, CXKA, 4IOI59, 4BV7TW...(typical PNR number patterns)

2.       I have created one more factor variable mentioning (IsPNR) - so all the values are 1 (true)

My first objective is to create a model on this training set which would recognize the text pattern.

Second objective: The  model would then be used to predict IsPNR with new set of test values like "Anshuk", "4EL58S"...as 0 and 1...

Which model would be best for recognizing such kind of pattern and having decent accuracy? I tried naiveBayes, but I don't think it is all doing a good job. Its predicting all the test values as true. I suppose bayes is not meant for this.


Regards,
Anshuk Pal Chaudhuri


	[[alternative HTML version deleted]]


From rakibalfahad at hotmail.com  Mon Aug 17 03:40:21 2015
From: rakibalfahad at hotmail.com (rakibalfahad)
Date: Sun, 16 Aug 2015 18:40:21 -0700 (PDT)
Subject: [R] SubgraphMining
In-Reply-To: <1402781202746-4692121.post@n4.nabble.com>
References: <1402781202746-4692121.post@n4.nabble.com>
Message-ID: <1439775621325-4711174.post@n4.nabble.com>

Follow the link 

download Frequent Subgraph Mining related R package from table and install
it to R

http://www.csc.ncsu.edu/faculty/samatova/practical-graph-mining-with-R/PracticalGraphMiningWithR.html




--
View this message in context: http://r.789695.n4.nabble.com/SubgraphMining-tp4692121p4711174.html
Sent from the R help mailing list archive at Nabble.com.


From matt at shark.co.za  Mon Aug 17 11:16:43 2015
From: matt at shark.co.za (Matt Dicken)
Date: Mon, 17 Aug 2015 09:16:43 +0000
Subject: [R] hurdle control and optim
Message-ID: <HE1PR04MB145213E683880955F4B386A282790@HE1PR04MB1452.eurprd04.prod.outlook.com>


I was hoping someone may be able to help with the following.

I fit the model below using the pscl package. I am modelling catch data (about 17,000 entry points) so lots of zero's

fit.hurdle.bin = hurdle(Catch ~ Beach + Region + Year+
                      Decade + Month + Season + Whale+ Sex + Size+ meantemp +
                      meanviz + offset(log(Length.nets..km.)),
                      dist="poisson",zero.dist="binomial",link="logit",trace=T)

The model output tells me that:
Warning message: In sqrt(diag(object$vcov)) : NaNs produced (against year)

I then use hurdle control with "L-BFGS-B" to set some parameter controls to solve this issue, but get the warning message:
L-BFGS-B needs finite values of 'fn'
In addition: Warning message:
In optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist ==  :
  method L-BFGS-B uses 'factr' (and 'pgtol') instead of 'reltol' and 'abstol'

How do I write the script for Hurdle control to solve these issues?
Any help would be really appreciated
All the best
Matt





Dr. Matt Dicken
Senior Scientist
Telephone: 0315660400 | Fax: 0315660493 | Email: matt at shark.co.za
Physical Address: 1a Herrwood Drive, Umhlanga Rocks, 4320 | www.shark.co.za

[http://www.shark.co.za/ImageHandler.ashx?fguid=2c107195-209c-4fb2-aae5-31e45ce5de1a]

Connect with us on social media: [KZNSB Facebook]  <https://www.facebook.com/kznsb> [KZNSB Twitter]  <https://twitter.com/KznSharks?lang=en>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Aug 17 18:20:30 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Aug 2015 09:20:30 -0700
Subject: [R] Text Pattern Recognition - Model
In-Reply-To: <SG2PR02MB063496A4D43CBB478903E5FBF0790@SG2PR02MB0634.apcprd02.prod.outlook.com>
References: <SG2PR02MB063496A4D43CBB478903E5FBF0790@SG2PR02MB0634.apcprd02.prod.outlook.com>
Message-ID: <CAGxFJbTHKsUdfSe6z4xwwm2SbY74Dp2vq4=etrUCSDfTk=4c5Q@mail.gmail.com>

Wrong list. This list is about R, not about statistics/statistical
learning. Post to a stats list like stats.stackexchange.com for
methods issues. Once you figure out what you want to do, R almost
certainly can do it -- search to find out what fuctions/packages to
use.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Aug 17, 2015 at 7:27 AM, Anshuk Pal Chaudhuri
<anshuk.p at motivitylabs.com> wrote:
> Hi,
>
> I have a training dataset which has two columns which has around 70 values.
>
> 1.       "PNRNo" whose values like UT768G, CXKA, 4IOI59, 4BV7TW...(typical PNR number patterns)
>
> 2.       I have created one more factor variable mentioning (IsPNR) - so all the values are 1 (true)
>
> My first objective is to create a model on this training set which would recognize the text pattern.
>
> Second objective: The  model would then be used to predict IsPNR with new set of test values like "Anshuk", "4EL58S"...as 0 and 1...
>
> Which model would be best for recognizing such kind of pattern and having decent accuracy? I tried naiveBayes, but I don't think it is all doing a good job. Its predicting all the test values as true. I suppose bayes is not meant for this.
>
>
> Regards,
> Anshuk Pal Chaudhuri
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sds at gnu.org  Mon Aug 17 18:48:55 2015
From: sds at gnu.org (Sam Steingold)
Date: Mon, 17 Aug 2015 12:48:55 -0400
Subject: [R] help with binom.power
Message-ID: <m2y4h9oo7c.fsf@gnu.org>

Hi,
I am confused by the binom.power - I cannot figure out how to use it.
E.g., I have "normal success rate" 0.1% (i.e., p=0.001).
How many successes do I need to observe per n=c(100,1000,10000,100000)
trials to reject the normalcy hypothesis with confidence 95%?
I think binom.power should be able to compute that but I cannot figure
out the meaning of its many parameters (as well as its return value).
Thanks.

PS. Would you prefer to answer this on SO or CV?

-- 
Sam Steingold (http://sds.podval.org/) on darwin Ns 10.3.1348
http://www.childpsy.net/ http://palestinefacts.org http://camera.org
http://truepeace.org http://americancensorship.org http://memri.org
One can find Holy Grail or Higgs boson, but not the second sock.


From bgunter.4567 at gmail.com  Mon Aug 17 19:27:58 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Aug 2015 10:27:58 -0700
Subject: [R] help with binom.power
In-Reply-To: <m2y4h9oo7c.fsf@gnu.org>
References: <m2y4h9oo7c.fsf@gnu.org>
Message-ID: <CAGxFJbRadEzjEWFwU-r+fSxqYnF1o=GUF6vtjBrJtnvw56Bvgw@mail.gmail.com>

(offline, since this is about statistics, not R)

1. The phrasing of your question ("reject hypothesis with 95%
confidence" instead of "at 5% level") indicates some statistical
confusion, so you may wish to consult a local statistician or SO for
clarification.

2. Note that using qbinom(in the stats package that is usually
automatically available)

> qbinom(.025,1000,.001,lower=FALSE)
[1] 3


i.e. a one sided test with size .025 rejects P <= .1% if the number of
successes out of 1000 is 4 or more -- i.e. if the observed rate in a
sample of 1000 is .4% or more (using the particular binomial
approximation referenced in ?qbinom, which is probably slightly
different than that used in the function/package you asked about).

If that is not enough to clarify, post on SO or consult locally. Do
not reply to me. (and, of course, feel free to completely disregard
this).

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Aug 17, 2015 at 9:48 AM, Sam Steingold <sds at gnu.org> wrote:
> Hi,
> I am confused by the binom.power - I cannot figure out how to use it.
> E.g., I have "normal success rate" 0.1% (i.e., p=0.001).
> How many successes do I need to observe per n=c(100,1000,10000,100000)
> trials to reject the normalcy hypothesis with confidence 95%?
> I think binom.power should be able to compute that but I cannot figure
> out the meaning of its many parameters (as well as its return value).
> Thanks.
>
> PS. Would you prefer to answer this on SO or CV?
>
> --
> Sam Steingold (http://sds.podval.org/) on darwin Ns 10.3.1348
> http://www.childpsy.net/ http://palestinefacts.org http://camera.org
> http://truepeace.org http://americancensorship.org http://memri.org
> One can find Holy Grail or Higgs boson, but not the second sock.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sds at gnu.org  Mon Aug 17 21:05:42 2015
From: sds at gnu.org (Sam Steingold)
Date: Mon, 17 Aug 2015 15:05:42 -0400
Subject: [R] help with binom.power
In-Reply-To: <CAGxFJbRadEzjEWFwU-r+fSxqYnF1o=GUF6vtjBrJtnvw56Bvgw@mail.gmail.com>
	(Bert Gunter's message of "Mon, 17 Aug 2015 10:27:58 -0700")
References: <m2y4h9oo7c.fsf@gnu.org>
	<CAGxFJbRadEzjEWFwU-r+fSxqYnF1o=GUF6vtjBrJtnvw56Bvgw@mail.gmail.com>
Message-ID: <m2pp2lohvd.fsf@gnu.org>

> * Bert Gunter <othagre.4567 at tznvy.pbz> [2015-08-17 10:27:58 -0700]:
>
>> qbinom(.025,1000,.001,lower=FALSE)

I don't think this is what I need.
I am looking for an inverse of binom.confint.

Sorry that my question was not clear.

-- 
Sam Steingold (http://sds.podval.org/) on darwin Ns 10.3.1348
http://www.childpsy.net/ http://islamexposedonline.com http://jihadwatch.org
http://iris.org.il http://dhimmi.org http://americancensorship.org
Genius is immortal, but morons live longer.


From mcferrae at mskcc.org  Mon Aug 17 21:07:18 2015
From: mcferrae at mskcc.org (mcferrae at mskcc.org)
Date: Mon, 17 Aug 2015 19:07:18 +0000
Subject: [R] bind function
Message-ID: <BC58FB70031B564BAB625FC99DD5C0EE0100C8D9@SMSKPEX10MBX1.MSKCC.ROOT.MSKCC.ORG>

HI there
I'm very new to R, as in 3 days new, so apologies if I'm not framing my question correctly
I am working through the Johns' Hopkins coursera course, I'm following, just about!

I am trying to have R read multiple .csv files together as one dataframe - I can't figure how to ask the program to do so, despite multiple attempts, and googles' and re-reading the course materials.

Please can you advise what a code might read like?


bws
ethna


Ethna McFerran ?NCI Health Economics Fellow
________________________________________________________________________
Dr. Ann Graham Zauber, PhD ?Department of Epidemiology & Biostatistics?Memorial Sloan-Kettering Cancer Center
485 Lexington Avenue, New York, NY 10017
________________________________________________________________________________________________
E-mail: mcferrae at mskcc.org<mailto:zaubera at mskcc.org>
Skype ID: ethna.mcferran
Tel: +1646 888 8121

-------------- next part --------------
=====================================================================

     Please note that this e-mail and any files transmitted from
     Memorial Sloan Kettering Cancer Center may be privileged, confidential,
     and protected from disclosure under applicable law. If the reader of
     this message is not the intended recipient, or an employee or agent
     responsible for delivering this message to the intended recipient,
     you are hereby notified that any reading, dissemination, distribution,
     copying, or other use of this communication or any of its attachments
     is strictly prohibited.  If you have received this communication in
     error, please notify the sender immediately by replying to this message
     and deleting this message, any attachments, and all copies and backups
     from your computer.

From tufanomichele at hotmail.it  Mon Aug 17 21:10:52 2015
From: tufanomichele at hotmail.it (survivalUser)
Date: Mon, 17 Aug 2015 12:10:52 -0700 (PDT)
Subject: [R] Survival Analysis and Predict time-to-death
Message-ID: <1439838652501-4711198.post@n4.nabble.com>

Dear All,

I would like to build a model, based on survival analysis on some data, that
is able to predict the /*expected time until death*/ for a new data
instance.

Data
For each individual in the population I have the, for each unit of time, the
status information and several continuous covariates for that particular
time. The data is right censored since at the end of the time interval
analyzed, instances could be still alive and die later.

Model
I created the model using R and the survreg function:

lfit <- survreg(Surv(time, status) ~ X) 

where:
- time is the time vector
- status is the status vector (0 alive, 1 death)
- X is a bind of multiple vectors of covariates

Predict time to death
Given a new individual with some covariates values, I would like to predict
the estimated time to death. In other words, the number of time units for
which the individual will be still alive till his death.

I think I can use this:

ptime <- predict(lfit, newdata=data.frame(X=NEWDATA), type='response')

Is that correct? Am I going to get the expected-time-to-death that I would
like to have?

In theory, I could provide also the time information (the time when the
individual has those covariates values), should I simply add that in the
newdata:

ptime <- predict(lfit, newdata=data.frame(time=TIME, X=NEWDATA),
type='response')

Is that correct? Is this going to improve the prediction? (for my data, the
time already passed should be an important variable).

Any other suggestions or comments?

Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/Survival-Analysis-and-Predict-time-to-death-tp4711198.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Mon Aug 17 21:36:38 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 17 Aug 2015 12:36:38 -0700
Subject: [R] help with binom.power
In-Reply-To: <m2y4h9oo7c.fsf@gnu.org>
References: <m2y4h9oo7c.fsf@gnu.org>
Message-ID: <058CADFA-C09C-47F7-99F6-FA6B524415F4@comcast.net>


On Aug 17, 2015, at 9:48 AM, Sam Steingold wrote:

> Hi,
> I am confused by the binom.power - I cannot figure out how to use it.
> E.g., I have "normal success rate" 0.1% (i.e., p=0.001).
> How many successes do I need to observe per n=c(100,1000,10000,100000)
> trials to reject the normalcy hypothesis with confidence 95%?

> I think binom.power should be able to compute that but I cannot figure
> out the meaning of its many parameters (as well as its return value).
> Thanks.
> 
> PS. Would you prefer to answer this on SO or CV?

This would be a better fit with the on-topic criteria for CV, since it appears the problem is at the very least a lack of understanding of the principles of power analysis rather than primarily a coding difficulty. You might mention that you hoped to use a function by the name of `binom.power` in some non-base package (which you should offer).

-- 

David Winsemius
Alameda, CA, USA


From dtenenba at fredhutch.org  Mon Aug 17 22:15:05 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Mon, 17 Aug 2015 13:15:05 -0700 (PDT)
Subject: [R] Windows: URL associations do not work in scheduled tasks
In-Reply-To: <476563325.1002915.1439842134708.JavaMail.root@fredhutch.org>
Message-ID: <195939695.1003394.1439842505116.JavaMail.root@fredhutch.org>

Hi,

I have a script called test.R which contains:

browseURL("http://r-project.org")

It works fine when I run it interactively or with "R -f test.R" when logged in as the user 'biocbuild'.

However, if I set up a Scheduled Task to run the script as that same user (with the XML definition below) it outputs the following:

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> browseURL("http://r-project.org")
Error in shell.exec(url) :
  file association for 'http://r-project.org' not available or invalid
Calls: browseURL -> shell.exec
Execution halted

I tried granting the user that the task runs as (biocbuild) the Log On As A Service right (per https://technet.microsoft.com/en-us/library/Cc739424(v=WS.10).aspx) but that did not make a difference.


This is on 

> sessionInfo()
R version 3.2.2 RC (2015-08-06 r68871)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows Server 2012 x64 (build 9200)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
>


I note that I do not have the same issue with Windows Server 2008; I am seeing it now in Windows Server 2012.


Here is the task definition:

<?xml version="1.0" encoding="UTF-16"?>
<Task version="1.2" xmlns="http://schemas.microsoft.com/windows/2004/02/mit/task">
  <RegistrationInfo>
    <Date>2015-08-17T14:03:12.3440388</Date>
    <Author>WINDOWS1\Administrator</Author>
  </RegistrationInfo>
  <Triggers />
  <Principals>
    <Principal id="Author">
      <UserId>WINDOWS1\biocbuild</UserId>
      <LogonType>Password</LogonType>
      <RunLevel>LeastPrivilege</RunLevel>
    </Principal>
  </Principals>
  <Settings>
    <MultipleInstancesPolicy>IgnoreNew</MultipleInstancesPolicy>
    <DisallowStartIfOnBatteries>true</DisallowStartIfOnBatteries>
    <StopIfGoingOnBatteries>true</StopIfGoingOnBatteries>
    <AllowHardTerminate>true</AllowHardTerminate>
    <StartWhenAvailable>false</StartWhenAvailable>
    <RunOnlyIfNetworkAvailable>false</RunOnlyIfNetworkAvailable>
    <IdleSettings>
      <StopOnIdleEnd>true</StopOnIdleEnd>
      <RestartOnIdle>false</RestartOnIdle>
    </IdleSettings>
    <AllowStartOnDemand>true</AllowStartOnDemand>
    <Enabled>true</Enabled>
    <Hidden>false</Hidden>
    <RunOnlyIfIdle>false</RunOnlyIfIdle>
    <WakeToRun>false</WakeToRun>
    <ExecutionTimeLimit>P3D</ExecutionTimeLimit>
    <Priority>7</Priority>
  </Settings>
  <Actions Context="Author">
    <Exec>
      <Command>C:\biocbld\bbs-3.2-bioc\R\bin\R.exe</Command>
      <Arguments>-f test.R &gt; out 2&gt;&amp;1</Arguments>
      <WorkingDirectory>c:\biocbld\bbs-3.2-bioc\meat</WorkingDirectory>
    </Exec>
  </Actions>
</Task>

Thanks in advance for any help,
Dan


From Achim.Zeileis at R-project.org  Mon Aug 17 22:06:04 2015
From: Achim.Zeileis at R-project.org (Achim Zeileis)
Date: Mon, 17 Aug 2015 22:06:04 +0200 (CEST)
Subject: [R] hurdle control and optim
In-Reply-To: <HE1PR04MB145213E683880955F4B386A282790@HE1PR04MB1452.eurprd04.prod.outlook.com>
References: <HE1PR04MB145213E683880955F4B386A282790@HE1PR04MB1452.eurprd04.prod.outlook.com>
Message-ID: <alpine.DEB.2.11.1508172203030.27330@paninaro.uibk.ac.at>

Please refrain from cross-posting. The same request was sent to the author 
of hurdle(), R-help, and StackOverflow (where it was already answered). 
Also, do provide self-contained and reproducible code as would be 
appropriate in any of the three cases.

On Mon, 17 Aug 2015, Matt Dicken wrote:

>
> I was hoping someone may be able to help with the following.
>
> I fit the model below using the pscl package. I am modelling catch data (about 17,000 entry points) so lots of zero's
>
> fit.hurdle.bin = hurdle(Catch ~ Beach + Region + Year+
>                      Decade + Month + Season + Whale+ Sex + Size+ meantemp +
>                      meanviz + offset(log(Length.nets..km.)),
>                      dist="poisson",zero.dist="binomial",link="logit",trace=T)
>
> The model output tells me that:
> Warning message: In sqrt(diag(object$vcov)) : NaNs produced (against year)
>
> I then use hurdle control with "L-BFGS-B" to set some parameter controls to solve this issue, but get the warning message:
> L-BFGS-B needs finite values of 'fn'
> In addition: Warning message:
> In optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist ==  :
>  method L-BFGS-B uses 'factr' (and 'pgtol') instead of 'reltol' and 'abstol'
>
> How do I write the script for Hurdle control to solve these issues?
> Any help would be really appreciated
> All the best
> Matt
>
>
>
>
>
> Dr. Matt Dicken
> Senior Scientist
> Telephone: 0315660400 | Fax: 0315660493 | Email: matt at shark.co.za
> Physical Address: 1a Herrwood Drive, Umhlanga Rocks, 4320 | www.shark.co.za
>
> [http://www.shark.co.za/ImageHandler.ashx?fguid=2c107195-209c-4fb2-aae5-31e45ce5de1a]
>
> Connect with us on social media: [KZNSB Facebook]  <https://www.facebook.com/kznsb> [KZNSB Twitter]  <https://twitter.com/KznSharks?lang=en>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From matt at shark.co.za  Mon Aug 17 22:09:07 2015
From: matt at shark.co.za (Matt Dicken)
Date: Mon, 17 Aug 2015 20:09:07 +0000
Subject: [R] hurdle control and optim
In-Reply-To: <alpine.DEB.2.11.1508172203030.27330@paninaro.uibk.ac.at>
References: <HE1PR04MB145213E683880955F4B386A282790@HE1PR04MB1452.eurprd04.prod.outlook.com>
	<alpine.DEB.2.11.1508172203030.27330@paninaro.uibk.ac.at>
Message-ID: <HE1PR04MB14526215027526EFED10660382790@HE1PR04MB1452.eurprd04.prod.outlook.com>

Dear Achim,

Apologies for the cross posting and confusion. I really appreciate the help

All the best

Matt

-----Original Message-----
From: Achim Zeileis [mailto:Achim.Zeileis at R-project.org] 
Sent: 17 August, 2015 10:06 PM
To: Matt Dicken <matt at shark.co.za>
Cc: r-help at r-project.org
Subject: Re: [R] hurdle control and optim

Please refrain from cross-posting. The same request was sent to the author of hurdle(), R-help, and StackOverflow (where it was already answered). 
Also, do provide self-contained and reproducible code as would be appropriate in any of the three cases.

On Mon, 17 Aug 2015, Matt Dicken wrote:

>
> I was hoping someone may be able to help with the following.
>
> I fit the model below using the pscl package. I am modelling catch 
> data (about 17,000 entry points) so lots of zero's
>
> fit.hurdle.bin = hurdle(Catch ~ Beach + Region + Year+
>                      Decade + Month + Season + Whale+ Sex + Size+ meantemp +
>                      meanviz + offset(log(Length.nets..km.)),
>                      
> dist="poisson",zero.dist="binomial",link="logit",trace=T)
>
> The model output tells me that:
> Warning message: In sqrt(diag(object$vcov)) : NaNs produced (against 
> year)
>
> I then use hurdle control with "L-BFGS-B" to set some parameter controls to solve this issue, but get the warning message:
> L-BFGS-B needs finite values of 'fn'
> In addition: Warning message:
> In optim(fn = countDist, gr = countGrad, par = c(start$count, if (dist ==  :
>  method L-BFGS-B uses 'factr' (and 'pgtol') instead of 'reltol' and 'abstol'
>
> How do I write the script for Hurdle control to solve these issues?
> Any help would be really appreciated
> All the best
> Matt
>
>
>
>
>
> Dr. Matt Dicken
> Senior Scientist
> Telephone: 0315660400 | Fax: 0315660493 | Email: matt at shark.co.za 
> Physical Address: 1a Herrwood Drive, Umhlanga Rocks, 4320 | 
> www.shark.co.za
>
> [http://www.shark.co.za/ImageHandler.ashx?fguid=2c107195-209c-4fb2-aae
> 5-31e45ce5de1a]
>
> Connect with us on social media: [KZNSB Facebook]  
> <https://www.facebook.com/kznsb> [KZNSB Twitter]  
> <https://twitter.com/KznSharks?lang=en>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Mon Aug 17 22:51:41 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 17 Aug 2015 13:51:41 -0700
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <1439838652501-4711198.post@n4.nabble.com>
References: <1439838652501-4711198.post@n4.nabble.com>
Message-ID: <F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>


On Aug 17, 2015, at 12:10 PM, survivalUser wrote:

> Dear All,
> 
> I would like to build a model, based on survival analysis on some data, that
> is able to predict the /*expected time until death*/ for a new data
> instance.

Are you sure you want to use life expectancy as the outcome? In order to establish a mathematical expectation  you need to have know the risk at all time in the future, which as pointed out in the print.survfit help page is undefined unless the last observation is a death. Very few datasets support such an estimate. If on the other hand you have sufficient events in the future, then you may be able to more readily justify an estimate of a median survival. 

The print.survfit function does give choices of a "restricted mean survival" or time-to-median-survival as estimate options. See that function's help page.

> Data
> For each individual in the population I have the, for each unit of time, the
> status information and several continuous covariates for that particular
> time. The data is right censored since at the end of the time interval
> analyzed, instances could be still alive and die later.
> 
> Model
> I created the model using R and the survreg function:
> 
> lfit <- survreg(Surv(time, status) ~ X) 
> 
> where:
> - time is the time vector
> - status is the status vector (0 alive, 1 death)
> - X is a bind of multiple vectors of covariates
> 
> Predict time to death
> Given a new individual with some covariates values, I would like to predict
> the estimated time to death. In other words, the number of time units for
> which the individual will be still alive till his death.
> 
> I think I can use this:
> 
> ptime <- predict(lfit, newdata=data.frame(X=NEWDATA), type='response')

I don't see type="response" as a documented option in the `?predict.survreg` help page. Were you suggesting that code on the basis of some tutorial?

> Is that correct? Am I going to get the expected-time-to-death that I would
> like to have?

Most people would be using `survfit` to construct survival estimates.

> 
> In theory, I could provide also the time information (the time when the
> individual has those covariates values), should I simply add that in the
> newdata:
> 
> ptime <- predict(lfit, newdata=data.frame(time=TIME, X=NEWDATA),
> type='response')
> 
> Is that correct?

This sounds like you are considering time-varying predictors. Adding them as a 'newdata' argument is most definitely not the correct method. As such I would ask if you really wanted to use a parametric survival model in the first place? The coxph function has facilities for time-varying covariates.


> Is this going to improve the prediction?

It would most likely severely complicate prediction. Survival estimates may be more problematic in that case on theoretical grounds.

> (for my data, the
> time already passed should be an important variable).
> 
> Any other suggestions or comments?
> 
> Thank you!
> 

R-help at r-project.org

The real Rhelp mailing list  ....   not the impostor Rhelp at Nabble

-- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Mon Aug 17 23:15:59 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 18 Aug 2015 09:15:59 +1200
Subject: [R] bind function
In-Reply-To: <BC58FB70031B564BAB625FC99DD5C0EE0100C8D9@SMSKPEX10MBX1.MSKCC.ROOT.MSKCC.ORG>
References: <BC58FB70031B564BAB625FC99DD5C0EE0100C8D9@SMSKPEX10MBX1.MSKCC.ROOT.MSKCC.ORG>
Message-ID: <55D24F0F.1060500@auckland.ac.nz>


On 18/08/15 07:07, mcferrae at mskcc.org wrote:

> HI there I'm very new to R, as in 3 days new, so apologies if I'm not
> framing my question correctly I am working through the Johns' Hopkins
> coursera course, I'm following, just about!
>
> I am trying to have R read multiple .csv files together as one
> dataframe - I can't figure how to ask the program to do so, despite
> multiple attempts, and googles' and re-reading the course materials.
>
> Please can you advise what a code might read like?


Well, I guess (???) this isn't *really* homework .....

Something like:

clyde  <- list.files(pattern="*.csv")
melvin <- lapply(clyde,read.csv)
irving <- do.call(rbind,melvin)

Note that the data frames read in by read.csv() must have identical 
column names.

Your question is very vague and indicative of a lack of focus.  (As in 
"Focus?  They don't even know us!)

Have you read (thoroughly and diligently) some basic introduction to R, 
such as "An Introduction to R" (!!!) available from the R web page?  Do so!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Tue Aug 18 00:39:07 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 17 Aug 2015 15:39:07 -0700
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
References: <1439838652501-4711198.post@n4.nabble.com>
	<F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
Message-ID: <CAGxFJbSNqZS6H=uJq0-o60TJx9aoaHgXE6re3Xctz44ytfimkg@mail.gmail.com>

David:

I may have misunderstood you here, specifically:

"As such I would ask if you really wanted to use a parametric survival
model in the first place? "

The K-M curve is , of course, a **non-parametric** fit, and that is
why there can be no mean survival time unless the last point is a
death.

If you use the sample data to estimate a **parametric** model, then,
of course, you can estimate mean survival time (at any covariate
value) as the mean of the predicted parameter estimates (e.g. through
a link function).

I would certainly agree that the OP seems pretty confused about all
this. And apologies if I have misunderstood.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Aug 17, 2015 at 1:51 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 17, 2015, at 12:10 PM, survivalUser wrote:
>
>> Dear All,
>>
>> I would like to build a model, based on survival analysis on some data, that
>> is able to predict the /*expected time until death*/ for a new data
>> instance.
>
> Are you sure you want to use life expectancy as the outcome? In order to establish a mathematical expectation  you need to have know the risk at all time in the future, which as pointed out in the print.survfit help page is undefined unless the last observation is a death. Very few datasets support such an estimate. If on the other hand you have sufficient events in the future, then you may be able to more readily justify an estimate of a median survival.
>
> The print.survfit function does give choices of a "restricted mean survival" or time-to-median-survival as estimate options. See that function's help page.
>
>> Data
>> For each individual in the population I have the, for each unit of time, the
>> status information and several continuous covariates for that particular
>> time. The data is right censored since at the end of the time interval
>> analyzed, instances could be still alive and die later.
>>
>> Model
>> I created the model using R and the survreg function:
>>
>> lfit <- survreg(Surv(time, status) ~ X)
>>
>> where:
>> - time is the time vector
>> - status is the status vector (0 alive, 1 death)
>> - X is a bind of multiple vectors of covariates
>>
>> Predict time to death
>> Given a new individual with some covariates values, I would like to predict
>> the estimated time to death. In other words, the number of time units for
>> which the individual will be still alive till his death.
>>
>> I think I can use this:
>>
>> ptime <- predict(lfit, newdata=data.frame(X=NEWDATA), type='response')
>
> I don't see type="response" as a documented option in the `?predict.survreg` help page. Were you suggesting that code on the basis of some tutorial?
>
>> Is that correct? Am I going to get the expected-time-to-death that I would
>> like to have?
>
> Most people would be using `survfit` to construct survival estimates.
>
>>
>> In theory, I could provide also the time information (the time when the
>> individual has those covariates values), should I simply add that in the
>> newdata:
>>
>> ptime <- predict(lfit, newdata=data.frame(time=TIME, X=NEWDATA),
>> type='response')
>>
>> Is that correct?
>
> This sounds like you are considering time-varying predictors. Adding them as a 'newdata' argument is most definitely not the correct method. As such I would ask if you really wanted to use a parametric survival model in the first place? The coxph function has facilities for time-varying covariates.
>
>
>> Is this going to improve the prediction?
>
> It would most likely severely complicate prediction. Survival estimates may be more problematic in that case on theoretical grounds.
>
>> (for my data, the
>> time already passed should be an important variable).
>>
>> Any other suggestions or comments?
>>
>> Thank you!
>>
>
> R-help at r-project.org
>
> The real Rhelp mailing list  ....   not the impostor Rhelp at Nabble
>
> -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Aug 18 01:33:02 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 17 Aug 2015 16:33:02 -0700
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <CAGxFJbSNqZS6H=uJq0-o60TJx9aoaHgXE6re3Xctz44ytfimkg@mail.gmail.com>
References: <1439838652501-4711198.post@n4.nabble.com>
	<F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
	<CAGxFJbSNqZS6H=uJq0-o60TJx9aoaHgXE6re3Xctz44ytfimkg@mail.gmail.com>
Message-ID: <BB96E50E-A6DA-4C64-A89D-645F2270A411@comcast.net>


On Aug 17, 2015, at 3:39 PM, Bert Gunter wrote:

> David:
> 
> I may have misunderstood you here, specifically:
> 
> "As such I would ask if you really wanted to use a parametric survival
> model in the first place? "
> 
> The K-M curve is , of course, a **non-parametric** fit, and that is
> why there can be no mean survival time unless the last point is a
> death.
> 
> If you use the sample data to estimate a **parametric** model, then,
> of course, you can estimate mean survival time (at any covariate
> value) as the mean of the predicted parameter estimates (e.g. through
> a link function).
> 
> I would certainly agree that the OP seems pretty confused about all
> this. And apologies if I have misunderstood.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
> 
> 
> On Mon, Aug 17, 2015 at 1:51 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Aug 17, 2015, at 12:10 PM, survivalUser wrote:
>> 
>>> Dear All,
>>> 
>>> I would like to build a model, based on survival analysis on some data, that
>>> is able to predict the /*expected time until death*/ for a new data
>>> instance.
>> 
>> Are you sure you want to use life expectancy as the outcome? In order to establish a mathematical expectation  you need to have know the risk at all time in the future, which as pointed out in the print.survfit help page is undefined unless the last observation is a death. Very few datasets support such an estimate. If on the other hand you have sufficient events in the future, then you may be able to more readily justify an estimate of a median survival.
>> 
>> The print.survfit function does give choices of a "restricted mean survival" or time-to-median-survival as estimate options. See that function's help page.
>> 
>>> Data
>>> For each individual in the population I have the, for each unit of time, the
>>> status information and several continuous covariates for that particular
>>> time. The data is right censored since at the end of the time interval
>>> analyzed, instances could be still alive and die later.
>>> 
>>> Model
>>> I created the model using R and the survreg function:
>>> 
>>> lfit <- survreg(Surv(time, status) ~ X)
>>> 
>>> where:
>>> - time is the time vector
>>> - status is the status vector (0 alive, 1 death)
>>> - X is a bind of multiple vectors of covariates
>>> 
>>> Predict time to death
>>> Given a new individual with some covariates values, I would like to predict
>>> the estimated time to death. In other words, the number of time units for
>>> which the individual will be still alive till his death.
>>> 
>>> I think I can use this:
>>> 
>>> ptime <- predict(lfit, newdata=data.frame(X=NEWDATA), type='response')
>> 
>> I don't see type="response" as a documented option in the `?predict.survreg` help page. Were you suggesting that code on the basis of some tutorial?
>> 
>>> Is that correct? Am I going to get the expected-time-to-death that I would
>>> like to have?
>> 
>> Most people would be using `survfit` to construct survival estimates.
>> 
>>> 
>>> In theory, I could provide also the time information (the time when the
>>> individual has those covariates values), should I simply add that in the
>>> newdata:
>>> 
>>> ptime <- predict(lfit, newdata=data.frame(time=TIME, X=NEWDATA),
>>> type='response')
>>> 
>>> Is that correct?
>> 
>> This sounds like you are considering time-varying predictors. Adding them as a 'newdata' argument is most definitely not the correct method. As such I would ask if you really wanted to use a parametric survival model in the first place? The coxph function has facilities for time-varying covariates.
>> 
>> 
>>> Is this going to improve the prediction?
>> 
>> It would most likely severely complicate prediction. Survival estimates may be more problematic in that case on theoretical grounds.
>> 
>>> (for my data, the
>>> time already passed should be an important variable).
>>> 
>>> Any other suggestions or comments?
>>> 
>>> Thank you!
>>> 
>> 
>> R-help at r-project.org
>> 
>> The real Rhelp mailing list  ....   not the impostor Rhelp at Nabble
>> 
>> -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Aug 18 01:44:15 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 17 Aug 2015 16:44:15 -0700
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
References: <1439838652501-4711198.post@n4.nabble.com>
	<F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
Message-ID: <F016873F-282C-450E-8C0A-5744F36206AA@comcast.net>


On Aug 17, 2015, at 1:51 PM, David Winsemius wrote:

> 
> On Aug 17, 2015, at 12:10 PM, survivalUser wrote:
> 
>> Dear All,
>> 
>> I would like to build a model, based on survival analysis on some data, that
>> is able to predict the /*expected time until death*/ for a new data
>> instance.
> 
> Are you sure you want to use life expectancy as the outcome? In order to establish a mathematical expectation  you need to have know the risk at all time in the future, which as pointed out in the print.survfit help page is undefined unless the last observation is a death. Very few datasets support such an estimate. If on the other hand you have sufficient events in the future, then you may be able to more readily justify an estimate of a median survival. 

Dear survivalUser;

I've been reminded that you later asked for a parametric model built with survreg. The above commentary applies to the coxph models and objects and not to survreg objects. If you do have a parametric model, even with incomplete observation then calculating life expectancy should be a simple matter of plugging the parameters for the distribution's mean value, since life-expectancy is the statistical mean. So maybe you do want such a modle. The default survreg  distribution is "weibull" so just go to your mathematical statistics text and look up the formula for the mean of a Weibull distribution with the estimated parameters.

-- 
David.

> 
> The print.survfit function does give choices of a "restricted mean survival" or time-to-median-survival as estimate options. See that function's help page.
> 
>> Data
>> For each individual in the population I have the, for each unit of time, the
>> status information and several continuous covariates for that particular
>> time. The data is right censored since at the end of the time interval
>> analyzed, instances could be still alive and die later.
>> 
>> Model
>> I created the model using R and the survreg function:
>> 
>> lfit <- survreg(Surv(time, status) ~ X) 
>> 
>> where:
>> - time is the time vector
>> - status is the status vector (0 alive, 1 death)
>> - X is a bind of multiple vectors of covariates
>> 
>> Predict time to death
>> Given a new individual with some covariates values, I would like to predict
>> the estimated time to death. In other words, the number of time units for
>> which the individual will be still alive till his death.
>> 
>> I think I can use this:
>> 
>> ptime <- predict(lfit, newdata=data.frame(X=NEWDATA), type='response')
> 
> I don't see type="response" as a documented option in the `?predict.survreg` help page. Were you suggesting that code on the basis of some tutorial?
> 
>> Is that correct? Am I going to get the expected-time-to-death that I would
>> like to have?
> 
> Most people would be using `survfit` to construct survival estimates.
> 
>> 
>> In theory, I could provide also the time information (the time when the
>> individual has those covariates values), should I simply add that in the
>> newdata:
>> 
>> ptime <- predict(lfit, newdata=data.frame(time=TIME, X=NEWDATA),
>> type='response')
>> 
>> Is that correct?
> 
> This sounds like you are considering time-varying predictors. Adding them as a 'newdata' argument is most definitely not the correct method. As such I would ask if you really wanted to use a parametric survival model in the first place? The coxph function has facilities for time-varying covariates.
> 
> 
>> Is this going to improve the prediction?
> 
> It would most likely severely complicate prediction. Survival estimates may be more problematic in that case on theoretical grounds.
> 
>> (for my data, the
>> time already passed should be an important variable).
>> 
>> Any other suggestions or comments?
>> 
>> Thank you!
>> 
> 
> R-help at r-project.org
> 
> The real Rhelp mailing list  ....   not the impostor Rhelp at Nabble
> 
> -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Aug 18 01:45:34 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 17 Aug 2015 16:45:34 -0700
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <CAGxFJbSNqZS6H=uJq0-o60TJx9aoaHgXE6re3Xctz44ytfimkg@mail.gmail.com>
References: <1439838652501-4711198.post@n4.nabble.com>
	<F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
	<CAGxFJbSNqZS6H=uJq0-o60TJx9aoaHgXE6re3Xctz44ytfimkg@mail.gmail.com>
Message-ID: <971E0172-93A1-4EE5-81BF-FDF38D7D8C01@comcast.net>

Ooops. I meant to drop that other message but hit the send icon instead.


On Aug 17, 2015, at 3:39 PM, Bert Gunter wrote:

> David:
> 
> I may have misunderstood you here, specifically:
> 
> "As such I would ask if you really wanted to use a parametric survival
> model in the first place? "

> 
> The K-M curve is , of course, a **non-parametric** fit, and that is
> why there can be no mean survival time unless the last point is a
> death.
> 
> If you use the sample data to estimate a **parametric** model, then,
> of course, you can estimate mean survival time (at any covariate
> value) as the mean of the predicted parameter estimates (e.g. through
> a link function).

Agree. I should have thought about that. I can post a clarification since this also mean my earlier comments about getting mean and median were off-target.

Best;
David.
> 
> I would certainly agree that the OP seems pretty confused about all
> this. And apologies if I have misunderstood.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
> 
> 
> On Mon, Aug 17, 2015 at 1:51 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Aug 17, 2015, at 12:10 PM, survivalUser wrote:
>> 
>>> Dear All,
>>> 
>>> I would like to build a model, based on survival analysis on some data, that
>>> is able to predict the /*expected time until death*/ for a new data
>>> instance.
>> 
>> Are you sure you want to use life expectancy as the outcome? In order to establish a mathematical expectation  you need to have know the risk at all time in the future, which as pointed out in the print.survfit help page is undefined unless the last observation is a death. Very few datasets support such an estimate. If on the other hand you have sufficient events in the future, then you may be able to more readily justify an estimate of a median survival.
>> 
>> The print.survfit function does give choices of a "restricted mean survival" or time-to-median-survival as estimate options. See that function's help page.
>> 
>>> Data
>>> For each individual in the population I have the, for each unit of time, the
>>> status information and several continuous covariates for that particular
>>> time. The data is right censored since at the end of the time interval
>>> analyzed, instances could be still alive and die later.
>>> 
>>> Model
>>> I created the model using R and the survreg function:
>>> 
>>> lfit <- survreg(Surv(time, status) ~ X)
>>> 
>>> where:
>>> - time is the time vector
>>> - status is the status vector (0 alive, 1 death)
>>> - X is a bind of multiple vectors of covariates
>>> 
>>> Predict time to death
>>> Given a new individual with some covariates values, I would like to predict
>>> the estimated time to death. In other words, the number of time units for
>>> which the individual will be still alive till his death.
>>> 
>>> I think I can use this:
>>> 
>>> ptime <- predict(lfit, newdata=data.frame(X=NEWDATA), type='response')
>> 
>> I don't see type="response" as a documented option in the `?predict.survreg` help page. Were you suggesting that code on the basis of some tutorial?
>> 
>>> Is that correct? Am I going to get the expected-time-to-death that I would
>>> like to have?
>> 
>> Most people would be using `survfit` to construct survival estimates.
>> 
>>> 
>>> In theory, I could provide also the time information (the time when the
>>> individual has those covariates values), should I simply add that in the
>>> newdata:
>>> 
>>> ptime <- predict(lfit, newdata=data.frame(time=TIME, X=NEWDATA),
>>> type='response')
>>> 
>>> Is that correct?
>> 
>> This sounds like you are considering time-varying predictors. Adding them as a 'newdata' argument is most definitely not the correct method. As such I would ask if you really wanted to use a parametric survival model in the first place? The coxph function has facilities for time-varying covariates.
>> 
>> 
>>> Is this going to improve the prediction?
>> 
>> It would most likely severely complicate prediction. Survival estimates may be more problematic in that case on theoretical grounds.
>> 
>>> (for my data, the
>>> time already passed should be an important variable).
>>> 
>>> Any other suggestions or comments?
>>> 
>>> Thank you!
>>> 
>> 
>> R-help at r-project.org
>> 
>> The real Rhelp mailing list  ....   not the impostor Rhelp at Nabble
>> 
>> -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From leptostracan at yahoo.com  Tue Aug 18 06:15:39 2015
From: leptostracan at yahoo.com (Christine Lee)
Date: Mon, 17 Aug 2015 21:15:39 -0700
Subject: [R] date format in xyplot
Message-ID: <1439871339.80066.YahooMailBasic@web120805.mail.ne1.yahoo.com>

To whom it may concern,

I have tried to plot some numbers against time with the time on the X-axis shown as "Jan", "Feb", etc.

I used the following commands:
Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L, 
2L, 4L, 12L), .Label = c("1/10", "1/11", "11/11", "12/11", "13/10", 
"19/9", "2/10", "2/11", "20/9", "26/11", "29/10", "29/11", "30/11", 
"31/10", "4/10", "6/10"), class = "factor"), Year = c(2002L, 
2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
), Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L), .Label = c("E", "F", "H", "I"), class = "factor"), Abun = c(3.42, 
1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67, 6.33, 0.67), Date1 = structure(c(16697, 
16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768
), class = "Date")), .Names = c("Date", "Year", "Station", "Abun", 
"Date1"), row.names = c(NA, 10L), class = "data.frame")

Raw$Date1<-as.Date(Raw$Date,"%d/%m")
xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),ylab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Black"),strip=strip.custom(bg='white'),format="%B-%d")

The date format shown on X-axis was just "10-1", "10-15"

I should be grateful if any one could help indicating what has gone wrong?

Regards,
Christine


From andrluis at ualberta.ca  Mon Aug 17 23:38:38 2015
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Mon, 17 Aug 2015 15:38:38 -0600
Subject: [R] Statistic_help
Message-ID: <CAHxKz8ZPfsvpPbKr42F2_vr9F4wy=o+LJXNg23Gq6OYtvEHeNg@mail.gmail.com>

Hi Everyone,

I have an experimental design that I'm confused about what model/approach I
should use to do the data analysis, and I would like to ask you for help as
there are many excellent statisticians and scientists in this group that
could help me to solve this problem.

The design is like this: I have 18 calves in the experiment, and all these
calves were divided into 3 groups with 6 calves in each group. The 6 calves
in group 1 were euthanized at the end of the first week (week 1) of birth,
the 6 calves in group 2 were euthanized after 3 weeks, and the other 6
calves in group 3 were euthanized after 6 weeks of birth. After the
euthanization, samples (different types of samples: digesta and content)
were collected from different gut regions (cecum, colon and rectum).
I should say that the calves in group 1 were only fed on whole milk, the
calves in group 2 were fed on whole milk during the first week after birth,
and after this, they were fed on whole milk and starter until the 3th week.
Finally, the calves in group 3 were also fed on whole milk during the first
week after birth, and then fed on milk and starter from the 2nd week to the
6th week after birth. After euthanizing the animals, I collected the
tissues and contents samples from each calf in the different groups, and
measured the quantity of four different species of bacteria to see the
establishment of these communities during the first weeks of life in calves.
The purpose of this study is to investigate the differences of the four
species of bacteria (in terms of quantity) among cecum, colon and rectum,
and also to see if the types of samples (content or tissue) are involved
in. Finally, I would like to know if the bacteria species found in the
different regions of the gut (cecum, colon and rectum) and in the sample
types (content or tissue)  are affected by the age (weeks after birth) and
by the type of food (as described before) that the calves received during
their life.

I should also say that this experiment was approved by the local animal
committee.

Thank you very much.

Andre

	[[alternative HTML version deleted]]


From tufanomichele at hotmail.it  Mon Aug 17 23:18:11 2015
From: tufanomichele at hotmail.it (survivalUser)
Date: Mon, 17 Aug 2015 14:18:11 -0700 (PDT)
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
References: <1439838652501-4711198.post@n4.nabble.com>
	<F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
Message-ID: <1439846291684-4711207.post@n4.nabble.com>

Thank you David for your answer.

Some follow-up questions:

- So, do you think that try to estimate the life expectancy would be risky
and probably not justifiable? Is there some sort of 'confidence' that the
model could give me for a prediction?

- type=response - I found it here: 
https://stat.ethz.ch/R-manual/R-devel/library/survival/html/predict.survreg.html

I have not tried it yet, but I was planning to use that because it says that
predict the "original scale of the data".

- Yes, I think they are time-varying predictors. Would you suggest other
models? (coxph?)

Overall, do you think this analysis is feasible/correct? Predicting how much
time a new individual (with those covariates) will be alive till death, is a
reasonable thing to predict with survival model?

Thank you again!




--
View this message in context: http://r.789695.n4.nabble.com/Survival-Analysis-and-Predict-time-to-death-tp4711198p4711207.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Tue Aug 18 07:18:04 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 17 Aug 2015 22:18:04 -0700
Subject: [R] Statistic_help
In-Reply-To: <CAHxKz8ZPfsvpPbKr42F2_vr9F4wy=o+LJXNg23Gq6OYtvEHeNg@mail.gmail.com>
References: <CAHxKz8ZPfsvpPbKr42F2_vr9F4wy=o+LJXNg23Gq6OYtvEHeNg@mail.gmail.com>
Message-ID: <21644645-E755-4459-900F-D2FC1E2A2786@dcn.davis.CA.us>

This is completely off-topic on R-help, so unless someone feels like corresponding off-list (unlikely) your attempt to derail the list (from the topic of R) is unwelcome regardless of the readers' qualifications.

There are forums where statistical experiment design is on topic (e.g. stats.stackexchange.com) but I have a feeling you would be better served to take a course on the topic or hire an expert.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 17, 2015 2:38:38 PM PDT, "Andr? Luis Neves" <andrluis at ualberta.ca> wrote:
>Hi Everyone,
>
>I have an experimental design that I'm confused about what
>model/approach I
>should use to do the data analysis, and I would like to ask you for
>help as
>there are many excellent statisticians and scientists in this group
>that
>could help me to solve this problem.
>
>The design is like this: I have 18 calves in the experiment, and all
>these
>calves were divided into 3 groups with 6 calves in each group. The 6
>calves
>in group 1 were euthanized at the end of the first week (week 1) of
>birth,
>the 6 calves in group 2 were euthanized after 3 weeks, and the other 6
>calves in group 3 were euthanized after 6 weeks of birth. After the
>euthanization, samples (different types of samples: digesta and
>content)
>were collected from different gut regions (cecum, colon and rectum).
>I should say that the calves in group 1 were only fed on whole milk,
>the
>calves in group 2 were fed on whole milk during the first week after
>birth,
>and after this, they were fed on whole milk and starter until the 3th
>week.
>Finally, the calves in group 3 were also fed on whole milk during the
>first
>week after birth, and then fed on milk and starter from the 2nd week to
>the
>6th week after birth. After euthanizing the animals, I collected the
>tissues and contents samples from each calf in the different groups,
>and
>measured the quantity of four different species of bacteria to see the
>establishment of these communities during the first weeks of life in
>calves.
>The purpose of this study is to investigate the differences of the four
>species of bacteria (in terms of quantity) among cecum, colon and
>rectum,
>and also to see if the types of samples (content or tissue) are
>involved
>in. Finally, I would like to know if the bacteria species found in the
>different regions of the gut (cecum, colon and rectum) and in the
>sample
>types (content or tissue)  are affected by the age (weeks after birth)
>and
>by the type of food (as described before) that the calves received
>during
>their life.
>
>I should also say that this experiment was approved by the local animal
>committee.
>
>Thank you very much.
>
>Andre
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Aug 18 08:02:47 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 18 Aug 2015 18:02:47 +1200
Subject: [R] [FORGED]  date format in xyplot
In-Reply-To: <1439871339.80066.YahooMailBasic@web120805.mail.ne1.yahoo.com>
References: <1439871339.80066.YahooMailBasic@web120805.mail.ne1.yahoo.com>
Message-ID: <55D2CA87.7010106@auckland.ac.nz>


See inline below.

On 18/08/15 16:15, Christine Lee via R-help wrote:
> To whom it may concern,
>
> I have tried to plot some numbers against time with the time on the X-axis
> shown as "Jan", "Feb", etc.
>
> I used the following commands:
> Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L,
> 2L, 4L, 12L), .Label = c("1/10", "1/11", "11/11", "12/11", "13/10",
> "19/9", "2/10", "2/11", "20/9", "26/11", "29/10", "29/11", "30/11",
> "31/10", "4/10", "6/10"), class = "factor"), Year = c(2002L,
> 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
> ), Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L), .Label = c("E", "F", "H", "I"), class = "factor"), Abun = c(3.42,
> 1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67, 6.33, 0.67), Date1 = structure(c(16697,
> 16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768
> ), class = "Date")), .Names = c("Date", "Year", "Station", "Abun",
> "Date1"), row.names = c(NA, 10L), class = "data.frame")
>
> Raw$Date1<-as.Date(Raw$Date,"%d/%m")

What does this accomplish?  As far as I can tell Raw$Date1 is the same 
after doing this replacement as it was before.

> xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),
> lab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Black"),
> strip=strip.custom(bg='white'),format="%B-%d")
>
> The date format shown on X-axis was just "10-1", "10-15"

Not what I get.

> I should be grateful if any one could help indicating what has gone wrong?

No idea.  When I try your code, the x-axis labels that I get are
"Oct 01", "Oct 15", ..., "Dec 01", which looks pretty much as it should.

General advice --- when you are getting unexpected results, try the 
example in a stripped down "keep it simple" form --- i.e. eliminate most 
of the bells and whistles in your very complicated call to xyplot(). 
That might give you a better chance at discerning what is causing things 
to go wrong for you.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From leptostracan at yahoo.com  Tue Aug 18 08:15:28 2015
From: leptostracan at yahoo.com (Christine Lee)
Date: Tue, 18 Aug 2015 06:15:28 +0000 (UTC)
Subject: [R] =?utf-8?b?5Zue6KaG77iwIFtGT1JHRURdICBkYXRlIGZvcm1hdCBpbiB4?=
	=?utf-8?q?yplot?=
In-Reply-To: <55D2CA87.7010106@auckland.ac.nz>
References: <55D2CA87.7010106@auckland.ac.nz>
Message-ID: <1949525937.6436519.1439878528511.JavaMail.yahoo@mail.yahoo.com>

Thanks Mr. Turner,?This puzzles me.? Why do we come out with different axis labels with the same command?? Is this because of my R version or my computer??Regards,Christine 


     Rolf Turner <r.turner at auckland.ac.nz> ? 2015?08?18? (??) 2:02 PM ???
   

 
See inline below.

On 18/08/15 16:15, Christine Lee via R-help wrote:
> To whom it may concern,
>
> I have tried to plot some numbers against time with the time on the X-axis
> shown as "Jan", "Feb", etc.
>
> I used the following commands:
> Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L,
> 2L, 4L, 12L), .Label = c("1/10", "1/11", "11/11", "12/11", "13/10",
> "19/9", "2/10", "2/11", "20/9", "26/11", "29/10", "29/11", "30/11",
> "31/10", "4/10", "6/10"), class = "factor"), Year = c(2002L,
> 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
> ), Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L), .Label = c("E", "F", "H", "I"), class = "factor"), Abun = c(3.42,
> 1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67, 6.33, 0.67), Date1 = structure(c(16697,
> 16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768
> ), class = "Date")), .Names = c("Date", "Year", "Station", "Abun",
> "Date1"), row.names = c(NA, 10L), class = "data.frame")
>
> Raw$Date1<-as.Date(Raw$Date,"%d/%m")

What does this accomplish?? As far as I can tell Raw$Date1 is the same 
after doing this replacement as it was before.

> xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),
> lab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Black"),
> strip=strip.custom(bg='white'),format="%B-%d")
>
> The date format shown on X-axis was just "10-1", "10-15"

Not what I get.

> I should be grateful if any one could help indicating what has gone wrong?

No idea.? When I try your code, the x-axis labels that I get are
"Oct 01", "Oct 15", ..., "Dec 01", which looks pretty much as it should.

General advice --- when you are getting unexpected results, try the 
example in a stripped down "keep it simple" form --- i.e. eliminate most 
of the bells and whistles in your very complicated call to xyplot(). 
That might give you a better chance at discerning what is causing things 
to go wrong for you.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


  
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Aug 18 10:07:14 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 18 Aug 2015 20:07:14 +1200
Subject: [R] =?utf-8?b?5Zue6KaG77iwIFtGT1JHRURdICBkYXRlIGZvcm1hdCBpbiB4?=
 =?utf-8?q?yplot?=
In-Reply-To: <1949525937.6436519.1439878528511.JavaMail.yahoo@mail.yahoo.com>
References: <55D2CA87.7010106@auckland.ac.nz>
	<1949525937.6436519.1439878528511.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55D2E7B2.7060801@auckland.ac.nz>


On 18/08/15 18:15, Christine Lee wrote:

> Thanks Mr. Turner,

Please!!! Either "Rolf" or (if you insist on formality)
*Dr.* Turner. :-)

> This puzzles me.  Why do we come out with different axis labels with the
> same command?  Is this because of my R version or my computer?

<SNIP>

It is most likely a *version* issue; in your version the default format 
is "%m-%e" whereas in mine it's "%b %d".  Or something like that.

Or it just might be a Windoze thing.  (If Micro$oft can find a way to 
mess things up, they will.)  I run *Linux*, as do all right-thinking people.

Be that as it may, I have now looked at the help for xyplot() a little 
more carefully (when in doubt try reading TFM!!!) and saw that "format" 
must be supplied as part of the *scales* argument, which is a *list*.

So try:

xyplot(Abun ~ Date1 | ... etc. etc ..., scales=list(format="%B=%d"))

and I think you'll get what you want.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dulcalma at bigpond.com  Tue Aug 18 10:08:56 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 18 Aug 2015 18:08:56 +1000
Subject: [R] date format in xyplot
In-Reply-To: <1439871339.80066.YahooMailBasic@web120805.mail.ne1.yahoo.com>
References: <1439871339.80066.YahooMailBasic@web120805.mail.ne1.yahoo.com>
Message-ID: <000901d0d98d$2207d860$66178920$@bigpond.com>

Hi Christine

If somethings go wrong:
1 first check your data

str(Raw)
'data.frame':   10 obs. of  5 variables:
 $ Date   : Factor w/ 16 levels "1/10","1/11",..: 6 7 2 4 12 9 7 2 4 12
 $ Year   : int  2002 2002 2002 2002 2002 2002 2002 2002 2002 2002
 $ Station: Factor w/ 4 levels "E","F","H","I": 1 1 1 1 1 2 2 2 2 2
 $ Abun   : num  3.42 1.33 3.67 3.67 3.92 2.17 2.5 1.67 6.33 0.67
 $ Date1  : Date, format: "2015-09-19" "2015-10-02" "2015-11-01"
"2015-11-12" ...

Raw$Date2 <- as.character(Raw$Date1)
Raw$Date2
[1] "2015-09-19" "2015-10-02" "2015-11-01" "2015-11-12" "2015-11-29"
"2015-09-20" "2015-10-02" "2015-11-01" "2015-11-12" "2015-11-29"
Raw$Date2 <- as.Date(Raw$Date2, "%Y-%m-%d")

2 read the help guide again if not done recently ?lattice::xyplot or ?xyplot
3 start with a minimum number of arguments

xyplot(Abun~Date2|as.factor(Year), Raw)
or 
xyplot(Abun~Date2, Raw)
if you are still having problems

Dates are hard work in any language as they are not consistent so:
a.  use  default
b.  use your own 

This works

xyplot(Abun~Date2|as.factor(Year), Raw,
       par.settings = list(stripbackground = "transparent"), # background
colour controlled here
       type="p",
       scales = list(x = list(at = sort(c(seq(as.Date(Raw$Date2[1]-4), by =
"months", length = 4),
                                           seq(as.Date(Raw$Date2[1]+12), by
= "months", length = 3))),
                               labels =
format(sort(c(seq(as.Date(Raw$Date2[1]-4), by = "months", length = 4),
 
seq(as.Date(Raw$Date2[1]+12), by = "months", length = 3))), "%m-%d") ) ),
       xlab=list("Month",cex=1.5),
       ylab=list("Abundance",cex=1.5),
       cex=2,
       pch=c(16,16,21),
       col=c("Black","Grey","Black")
)

par.settings is confining the parameters set by trellis.par.set()  to the
function
to get them

names(trellis.par.get() )
and going further
trellis.par.get()$superpose.symbol
will give you the values for superpose.symbol

Beware: Do not make the labels etc so big that the axis labels are hard to
read. Think of final size

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christine
Lee via R-help
Sent: Tuesday, 18 August 2015 14:16
To: r-help at r-project.org
Subject: [R] date format in xyplot

To whom it may concern,

I have tried to plot some numbers against time with the time on the X-axis
shown as "Jan", "Feb", etc.

I used the following commands:
Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L, 
2L, 4L, 12L), .Label = c("1/10", "1/11", "11/11", "12/11", "13/10", 
"19/9", "2/10", "2/11", "20/9", "26/11", "29/10", "29/11", "30/11", 
"31/10", "4/10", "6/10"), class = "factor"), Year = c(2002L, 
2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
), Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L), .Label = c("E", "F", "H", "I"), class = "factor"), Abun = c(3.42, 
1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67, 6.33, 0.67), Date1 =
structure(c(16697, 
16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768
), class = "Date")), .Names = c("Date", "Year", "Station", "Abun", 
"Date1"), row.names = c(NA, 10L), class = "data.frame")

Raw$Date1<-as.Date(Raw$Date,"%d/%m")
xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),yl
ab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Bla
ck"),strip=strip.custom(bg='white'),format="%B-%d")

The date format shown on X-axis was just "10-1", "10-15"

I should be grateful if any one could help indicating what has gone wrong?

Regards,
Christine

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From prgosek at gmail.com  Tue Aug 18 10:43:20 2015
From: prgosek at gmail.com (=?UTF-8?Q?Michal_Kvasni=C4=8Dka?=)
Date: Tue, 18 Aug 2015 10:43:20 +0200
Subject: [R] How are packages installed with install_github() updated in
	RStudio?
Message-ID: <CALs_GZVgiwiwr27Aco-Kf83rT7H-Dax1aNmPugX9mEmLAbV3bQ@mail.gmail.com>

Hallo.

I use RStudio. Because of a bug in the latest CRAN version of dplyr, I
installed the GitHub version with install_github(). Now I wonder what
happens when there is a new version. Does RStudio update the packages
installed from GitHub? If so, does it replace it with the new CRAN version,
or a new GitHub version?

Many thanks for you answer,
Michal Kvasnicka

	[[alternative HTML version deleted]]


From gpierard86 at gmail.com  Tue Aug 18 10:37:03 2015
From: gpierard86 at gmail.com (Gauthier Pierard)
Date: Tue, 18 Aug 2015 15:37:03 +0700
Subject: [R] R: forecasting a binary time series using the VLMC package
Message-ID: <CAFW4SqWCSAj=cZu3aRhPgLA20Qpc0Y+rQM9DQ1XuTidT3f61ZA@mail.gmail.com>

I would like to ask some clarifications on the method:

predict.vlmc

My problem is to forecast a binary time series one period ahead. I have a
time series bin2 of length 2000. When using

m2<-vlmc(bin2)
fc2<-predict(m2)


   1. fc2[i] is a prediction for i, not for i+1, is that correct? I am
   aware that the documentation stipulates "Compute predictions on a fitted
   VLMC object for each (but the first) element of another discrete time
   series.", but am still asking to make it 100% clear.
   2.

   I guess that the predictions fc2 are based on the full range [1:2000] of
   bin2, because I fitted a VLMC to the full timeseries on the first line
   above. Therefore, I am actually forecasting each period by already "knowing
   the future", is that correct?
   3.

   In order to forecast while "not knowing the future", can I do the
   following:

   for(i in 1000:1999) {
   retFull2 <- window(retFull, start=1, end=i)
   bin2<- window(bin, start=1, end=i)
   dummy<-ts(c(bin2,0))  #Adding a dummy zero at the end of each window
                     #so that a prediction will be made for i+1 as well
                     #without using i+1 while fitting the model
   m2<-vlmc(bin2) # bin2 granges from 1 to i
   fct2<-predict(m2, dummy)[i+1,1]  #forecasting on an "
artificially-added" i+1 index.}

   I am adding a "dummy" zero at the end of each windowed ts, and
   predicting for i+1 as well. Is it relevant at all? Any suggestions? Any
   practical suggestions on how to best forecast these binary time series?

Many thanks in advance, cheers!!!!!!!!

	[[alternative HTML version deleted]]


From mbowej at nm-aist.ac.tz  Tue Aug 18 09:49:22 2015
From: mbowej at nm-aist.ac.tz (Joseph Mbowe)
Date: Tue, 18 Aug 2015 10:49:22 +0300
Subject: [R] Please Help how to execute R via php script
Message-ID: <CAJrDUO-A2_suiRJWLL0FwJ6h_xMKf8bphVUkObm4AQ4nS4G0gw@mail.gmail.com>

Dear R members, I want to call my R script thorough php but no I am not
getting output
When I call my r script by bat file works fines also when run by Rstudio it
works fines
but when i cant call via php
here is the php code:
<?php
exec('C:/"Program Files"/R/R-3.2.0/bin/i386/Rscript.exe
C:/xampp/htdocs/postam/DrawGraph.R"')

echo '<img src="C:/xampp/htdocs/postam/radargplot100.png?t='.time().'"
style="height:600px;width:auto;" />' ;

?>

here is R script
args=(commandArgs(TRUE))
  library(ggplot2)
  library(readxl)
  #library(RMySQL)
  #library(readxl,lib.loc ="C:\Program Files\R\R-3.2.0\bin\i386")
  library(RMySQL,lib.loc ="C:/Users/Mbowe/Documents/R/win-library/3.2")
  library(arulesViz, quietly=TRUE)
  drv_postam = dbDriver("MySQL")
  con = dbConnect(drv_postam, user="root",
dbname="evtlogr",host="localhost")
  tbl_data2<-dbGetQuery(con,"select * from `tblsevtlogs` where datetime
BETWEEN '5/20/2015' AND '5/28/2015';")
  closeAllConnections()
  head( tbl_data2)
  tail( tbl_data2)

  #summary(data)
  w1 =
table(tbl_data2$evtcategory,tbl_data2$evttype,tbl_data2$evt_usr_source)
  t1 = as.data.frame(w1)
  t1
  LogonType<-t1$Var1
  LogonTypeCount<-t1$Freq
  Yaxis<-paste(paste("Frequency Count"))
  user_obj<-paste("User: ",tbl_data2$evt_usr_source)

  myplot <- ggplot(t1, aes(y = LogonTypeCount, x = reorder(t1$Var2,
t1$Freq),
                 group = LogonType, colour =   LogonType)) + coord_polar()
+ geom_point(size=3) + geom_path(size=1) +
    labs(x = paste("Data Mined From (",user_obj,")", "Event Logs"),y=Yaxis)
    ggsave(file="C:/xampp/htdocs/postam/radargplot100.png")
      dev.off()

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Tue Aug 18 13:47:49 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 18 Aug 2015 13:47:49 +0200
Subject: [R] Please Help how to execute R via php script
References: <CAJrDUO-A2_suiRJWLL0FwJ6h_xMKf8bphVUkObm4AQ4nS4G0gw@mail.gmail.com>
Message-ID: <87a8to3jiy.fsf@hornfels.zedat.fu-berlin.de>

Joseph Mbowe <mbowej at nm-aist.ac.tz> writes:

> Dear R members, I want to call my R script thorough php but no I am not
> getting output
> When I call my r script by bat file works fines also when run by Rstudio it
> works fines
> but when i cant call via php
> here is the php code:
> <?php
> exec('C:/"Program Files"/R/R-3.2.0/bin/i386/Rscript.exe
> C:/xampp/htdocs/postam/DrawGraph.R"')
>
> echo '<img src="C:/xampp/htdocs/postam/radargplot100.png?t='.time().'"
> style="height:600px;width:auto;" />' ;
>
> ?>

I know nothing about PHP, but you seem to have a missing double quote in
your call to 'exec'.

Cheers,

Loris

> here is R script
> args=(commandArgs(TRUE))
>   library(ggplot2)
>   library(readxl)
>   #library(RMySQL)
>   #library(readxl,lib.loc ="C:\Program Files\R\R-3.2.0\bin\i386")
>   library(RMySQL,lib.loc ="C:/Users/Mbowe/Documents/R/win-library/3.2")
>   library(arulesViz, quietly=TRUE)
>   drv_postam = dbDriver("MySQL")
>   con = dbConnect(drv_postam, user="root",
> dbname="evtlogr",host="localhost")
>   tbl_data2<-dbGetQuery(con,"select * from `tblsevtlogs` where datetime
> BETWEEN '5/20/2015' AND '5/28/2015';")
>   closeAllConnections()
>   head( tbl_data2)
>   tail( tbl_data2)
>
>   #summary(data)
>   w1 =
> table(tbl_data2$evtcategory,tbl_data2$evttype,tbl_data2$evt_usr_source)
>   t1 = as.data.frame(w1)
>   t1
>   LogonType<-t1$Var1
>   LogonTypeCount<-t1$Freq
>   Yaxis<-paste(paste("Frequency Count"))
>   user_obj<-paste("User: ",tbl_data2$evt_usr_source)
>
>   myplot <- ggplot(t1, aes(y = LogonTypeCount, x = reorder(t1$Var2,
> t1$Freq),
>                  group = LogonType, colour =   LogonType)) + coord_polar()
> + geom_point(size=3) + geom_path(size=1) +
>     labs(x = paste("Data Mined From (",user_obj,")", "Event Logs"),y=Yaxis)
>     ggsave(file="C:/xampp/htdocs/postam/radargplot100.png")
>       dev.off()
>
> 	[[alternative HTML version deleted]]
>

-- 
This signature is currently under construction.


From jrkrideau at inbox.com  Tue Aug 18 15:07:09 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 18 Aug 2015 05:07:09 -0800
Subject: [R] date format in xyplot
In-Reply-To: <1439871339.80066.YahooMailBasic@web120805.mail.ne1.yahoo.com>
Message-ID: <78ADEB1F78C.00000218jrkrideau@inbox.com>

Hi Christine,
I am afraid I cannot help as it 'appears' fine here 

I get an x-axis witih 
Oct 01 Oct 15 Nov 15 Dec 01

I don't normally use lattice but the dates seem reasonable to me

Do a str(Raw) and check if Date1 is actually a date in your orginal data. It is one here but who knows with R :)
John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Mon, 17 Aug 2015 21:15:39 -0700
> To: r-help at r-project.org
> Subject: [R] date format in xyplot
> 
> To whom it may concern,
> 
> I have tried to plot some numbers against time with the time on the
> X-axis shown as "Jan", "Feb", etc.
> 
> I used the following commands:
> Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L,
> 2L, 4L, 12L), .Label = c("1/10", "1/11", "11/11", "12/11", "13/10",
> "19/9", "2/10", "2/11", "20/9", "26/11", "29/10", "29/11", "30/11",
> "31/10", "4/10", "6/10"), class = "factor"), Year = c(2002L,
> 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
> ), Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L), .Label = c("E", "F", "H", "I"), class = "factor"), Abun = c(3.42,
> 1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67, 6.33, 0.67), Date1 =
> structure(c(16697,
> 16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768
> ), class = "Date")), .Names = c("Date", "Year", "Station", "Abun",
> "Date1"), row.names = c(NA, 10L), class = "data.frame")
> 
> Raw$Date1<-as.Date(Raw$Date,"%d/%m")
> xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),ylab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Black"),strip=strip.custom(bg='white'),format="%B-%d")
> 
> The date format shown on X-axis was just "10-1", "10-15"
> 
> I should be grateful if any one could help indicating what has gone
> wrong?
> 
> Regards,
> Christine
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Tue Aug 18 15:09:12 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 18 Aug 2015 05:09:12 -0800
Subject: [R] date format in xyplot
In-Reply-To: <1439871339.80066.YahooMailBasic@web120805.mail.ne1.yahoo.com>
Message-ID: <78B27C68D9B.00000223jrkrideau@inbox.com>

Sorry, quick follow-up: is there any chance you used Date rather than Date1 in the original plot?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Mon, 17 Aug 2015 21:15:39 -0700
> To: r-help at r-project.org
> Subject: [R] date format in xyplot
> 
> To whom it may concern,
> 
> I have tried to plot some numbers against time with the time on the
> X-axis shown as "Jan", "Feb", etc.
> 
> I used the following commands:
> Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L,
> 2L, 4L, 12L), .Label = c("1/10", "1/11", "11/11", "12/11", "13/10",
> "19/9", "2/10", "2/11", "20/9", "26/11", "29/10", "29/11", "30/11",
> "31/10", "4/10", "6/10"), class = "factor"), Year = c(2002L,
> 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
> ), Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L), .Label = c("E", "F", "H", "I"), class = "factor"), Abun = c(3.42,
> 1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67, 6.33, 0.67), Date1 =
> structure(c(16697,
> 16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768
> ), class = "Date")), .Names = c("Date", "Year", "Station", "Abun",
> "Date1"), row.names = c(NA, 10L), class = "data.frame")
> 
> Raw$Date1<-as.Date(Raw$Date,"%d/%m")
> xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),ylab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Black"),strip=strip.custom(bg='white'),format="%B-%d")
> 
> The date format shown on X-axis was just "10-1", "10-15"
> 
> I should be grateful if any one could help indicating what has gone
> wrong?
> 
> Regards,
> Christine
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Tue Aug 18 15:14:35 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 18 Aug 2015 05:14:35 -0800
Subject: [R] How are packages installed with install_github() updated in
 RStudio?
In-Reply-To: <CALs_GZVgiwiwr27Aco-Kf83rT7H-Dax1aNmPugX9mEmLAbV3bQ@mail.gmail.com>
Message-ID: <78BE8667825.00000239jrkrideau@inbox.com>

Hi Michal,

Because RStudio seems to use its own method of updating you might be better off asking in their forum. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: prgosek at gmail.com
> Sent: Tue, 18 Aug 2015 10:43:20 +0200
> To: r-help at r-project.org
> Subject: [R] How are packages installed with install_github() updated in
> RStudio?
> 
> Hallo.
> 
> I use RStudio. Because of a bug in the latest CRAN version of dplyr, I
> installed the GitHub version with install_github(). Now I wonder what
> happens when there is a new version. Does RStudio update the packages
> installed from GitHub? If so, does it replace it with the new CRAN
> version,
> or a new GitHub version?
> 
> Many thanks for you answer,
> Michal Kvasnicka
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From therneau at mayo.edu  Tue Aug 18 15:19:29 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 18 Aug 2015 08:19:29 -0500
Subject: [R] Survival analysis and predict time-to-death
In-Reply-To: <mailman.5.1439892002.13784.r-help@r-project.org>
References: <mailman.5.1439892002.13784.r-help@r-project.org>
Message-ID: <2f3a88$186eam@ironport10.mayo.edu>

I read this list a day late as a digest so my answers are rarely the first.  (Which is 
nice as David W answers most of the survival questions for me!)

What you are asking is reasonable, and in fact is common practice in the realm of 
industrial reliability, e.g., Meeker and Escobar, Statistical Methods for Reliability 
Analysis.  Extrapolation of the survival curve to obtain the mean and percentiles of the 
lifetime distribution for some device (e.g. a washing machine) is their bread and butter, 
used for instance to determine the right size for an inventory of spare parts.  For most 
of us on this list who do medical statistics and live in the Kaplan-Meier/ Cox model world 
the ideas are uncommon.  I was lucky enough to sit through one of Bill Meeker's short 
courses and retain some (minimal) memory of it.

   1. You are correct that parametric models are essential.  If the extrapolation is 
substantial (30% or more censored, say), then the choice of distribution can be critical. 
  If failure is due to repeated insult, e.g., the multi-hit model, then Weibull tends to 
be preferred; if it is from degradation, e.g., flexing of a diaphram, then the log-normal. 
  Beyond this you need more guidance than mine.

   2. The survreg routine assumes that log(y) ~ covariates + error.  For a log-normal 
distribion the error is Gaussian and thus the predict(fit, type='response') will be 
exp(predicted mean of log time), which is not the predicted mean time.  For Weibull the 
error dist is asymmetric so things are more muddy.  Each is the MLE prediction for the 
subject, just not interpretable as a mean.  To get the actual mean you need to look up the 
formulas for Weibull and/or lognormal in a textbook, and map from the survreg 
parameterization to whatever one the textbook uses.  The two parameterizations are never 
the same.

   3. Another option is predicted quantiles.  ?predict.survreg shows how to get the entire 
survival curve.  The mean can be obtained as the area under the survival curve.  Relevant 
to your question, the expected time remaining for a subject still alive at time =10, say, 
is  integral(S(t), from 10 to infin) / S(10), where S is the survival curve.  You can also 
read off quantiles of the expected remaining life.

Terry Therneau
(author of the survival package)

On 08/18/2015 05:00 AM, r-help-request at r-project.org wrote:
> Dear All,
>
> I would like to build a model, based on survival analysis on some data, that
> is able to predict the /*expected time until death*/ for a new data
> instance.
>
> Data
> For each individual in the population I have the, for each unit of time, the
> status information and several continuous covariates for that particular
> time. The data is right censored since at the end of the time interval
> analyzed, instances could be still alive and die later.
>
> Model
> I created the model using R and the survreg function:
>
> lfit <- survreg(Surv(time, status) ~ X)
>
> where:
> - time is the time vector
> - status is the status vector (0 alive, 1 death)
> - X is a bind of multiple vectors of covariates
>
> Predict time to death
> Given a new individual with some covariates values, I would like to predict
> the estimated time to death. In other words, the number of time units for
> which the individual will be still alive till his death.
>
> I think I can use this:
>
> ptime <- predict(lfit, newdata=data.frame(X=NEWDATA), type='response')
>
> Is that correct? Am I going to get the expected-time-to-death that I would
> like to have?
>
> In theory, I could provide also the time information (the time when the
> individual has those covariates values), should I simply add that in the
> newdata:
>
> ptime <- predict(lfit, newdata=data.frame(time=TIME, X=NEWDATA),
> type='response')
>
> Is that correct? Is this going to improve the prediction? (for my data, the
> time already passed should be an important variable).
>
> Any other suggestions or comments?
>
> Thank you!


From roger.bos at rothschild.com  Tue Aug 18 15:37:51 2015
From: roger.bos at rothschild.com (Bos, Roger)
Date: Tue, 18 Aug 2015 13:37:51 +0000
Subject: [R] Running R in Server
In-Reply-To: <CACruXeuAZustY5QBM7X9jnhotzMAq=-u8h2vsi1Qn4XHveb0=g@mail.gmail.com>
References: <CACruXeuAZustY5QBM7X9jnhotzMAq=-u8h2vsi1Qn4XHveb0=g@mail.gmail.com>
Message-ID: <0765308CD028654885F30322557308D81EF38FB2@NYCSM0208.rth.ad.rothschild.com>

There is probably nothing that can give you a step by step guide.  You are touching on a couple of different subjects.  If you just want to run code automatically on a windows server you can use task scheduler to call Rscript filename.R.  If you want to create Web application, that's a bit harder.  I still use Rpad, which works on windows, but development of it stopped a long time so I wouldn't suggest using it.  All the other web application approaches such as RApache only work on Linux.

If I understand correctly what you want to do, you might be able to create a HTML report using RMarkdown and host that on the website.  If you really need a web app, I suggest looking into Shiny.  You can make a shiny app, host it for free on the cloud.  You will have a lot to learn, but it will be time well spent.  https://www.rstudio.com/

Thanks,

Roger



***************************************************************
This message and any attachments are for the intended recipient's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies.  You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Swagato Chatterjee
Sent: Sunday, August 16, 2015 4:17 AM
To: r-help at r-project.org
Subject: [R] Running R in Server

Hello,

I have written a R script which runs a regression of a dataset and saves the result in a csv file.

Now this dataset has to be edited periodically which is done in a server. I need to run the R script in a server so that the results can also be shared in a server and used in a web application.

I have coded in R and have used R in windows. I have never used Ubuntu/Linux. Is there a step by step guide on how to run a R code in server?

Thanks and Regards,

--
Swagato Chatterjee

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From h.wickham at gmail.com  Tue Aug 18 16:01:09 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 18 Aug 2015 09:01:09 -0500
Subject: [R] How are packages installed with install_github() updated in
	RStudio?
In-Reply-To: <78BE8667825.00000239jrkrideau@inbox.com>
References: <CALs_GZVgiwiwr27Aco-Kf83rT7H-Dax1aNmPugX9mEmLAbV3bQ@mail.gmail.com>
	<78BE8667825.00000239jrkrideau@inbox.com>
Message-ID: <CABdHhvEy8GXUGTYu0Ww28=E4vpjCYVhWAKep8kbt=35fozbgOQ@mail.gmail.com>

RStudio just calls the same underlying R functions, so it doesn't make
any difference that you're using RStudio.  Currently, there's no
automatic way to update packages installed from github.

Hadley

On Tue, Aug 18, 2015 at 8:14 AM, John Kane <jrkrideau at inbox.com> wrote:
> Hi Michal,
>
> Because RStudio seems to use its own method of updating you might be better off asking in their forum.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: prgosek at gmail.com
>> Sent: Tue, 18 Aug 2015 10:43:20 +0200
>> To: r-help at r-project.org
>> Subject: [R] How are packages installed with install_github() updated in
>> RStudio?
>>
>> Hallo.
>>
>> I use RStudio. Because of a bug in the latest CRAN version of dplyr, I
>> installed the GitHub version with install_github(). Now I wonder what
>> happens when there is a new version. Does RStudio update the packages
>> installed from GitHub? If so, does it replace it with the new CRAN
>> version,
>> or a new GitHub version?
>>
>> Many thanks for you answer,
>> Michal Kvasnicka
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From john.archie.mckown at gmail.com  Tue Aug 18 16:08:39 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 18 Aug 2015 09:08:39 -0500
Subject: [R] Running R in Server
In-Reply-To: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>
References: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>
Message-ID: <CAAJSdjggXvR13Crh-tnsgfwg_yF=5H5RB6P9-JPey4FSoMzjcg@mail.gmail.com>

On Sun, Aug 16, 2015 at 3:27 AM, Swagato Chatterjee <swagato1987 at gmail.com>
wrote:

> Hello,
>
> I have written a R script which runs a regression of a dataset and saves
> the result in a csv file.
>
> Now this dataset has to be edited periodically which is done in a server. I
> need to run the R script in a server so that the results can also be shared
> in a server and used in a web application.
>
> I have coded in R and have used R in windows. I have never used
> Ubuntu/Linux. Is there a step by step guide on how to run a R code in
> server?
>
> Thanks and Regards,
>
> Swagato
>
>
I
? was going to answer yesterday, but work went insane. Also, I was hoping
someone else had something, because I don't have any "step by step"
instructions.

This is a rather complicated question. So I'm going to ask a number of
questions and make some statement for you to correct, if necessary.?

?Statement: You have a Windows desktop and have used R on it, so you are
familiar with R in a Windows environment.?
Statement: You are not Linux (Ubuntu) trained.
Statement: You wrote an R script on Windows, which works, but you need to
run it on Ubuntu.

The above is my starting point. Now I have some questions.

Can you connect to the Ubuntu server from your Windows desktop? If so, how?
If not, I'm confused about how you could get anything to run on the Ubuntu
server.

Where does this "dataset" reside? On you desktop? On a Windows shared
folder? On the Ubuntu server? Other?

Who or what edits the "dataset"? That is, is it always yourself? Some one
in your group? Some other human? Some automated process?

Why can't you run the R script as you do now, then deploy the results to
the Ubuntu server? Since I don't know the environment that the Ubuntu
server runs in, I can't address how to deploy an updated file into it. I
assume you have some sort of deployment software. It could be as easy as
being able to ftp the results from your desktop to the proper places on the
Ubuntu server.

?===

Now, whatever the answers are to the above, you'll likely need some help
from your Ubuntu server people. My first approach, given my ignorance,
would be that I would have something set up so that you could edit this
"dataset" on your desktop (assuming that's what you do). I would then have
you ftp it ?to a special directory on the Ubuntu server set up especially
for this function. Now, what remains would be running the R script, likely
in a "shell script" (like a PowerShell command file), whenever you do the
ftp. There is a function in Ubuntu (any Linux) called "icrond". This is a
daemon (Windows service equivalent) which can "monitor" a file or directory
for changes. When a change is detected it can take an action. In this case
it would be to schedule the execution of the previously mentioned "shell
script". The "shell script" would then take the actions necessary to do the
R script ("R CMD script-name parameters ..." for instance) and then deploy
the results to the web server (however you normally do this).  Setting up
the icrond environment is going to take some work by your Ubuntu
administrator.

===

I hope this was at least the start of some help to you.




-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From leptostracan at yahoo.com  Tue Aug 18 16:25:35 2015
From: leptostracan at yahoo.com (Christine Lee)
Date: Tue, 18 Aug 2015 07:25:35 -0700
Subject: [R] date format in xyplot
In-Reply-To: <000901d0d98d$2207d860$66178920$@bigpond.com>
Message-ID: <1439907935.89748.YahooMailBasic@web120801.mail.ne1.yahoo.com>

Thank you Duncan,

I have tried the scales function.  It ends up with 2015-09-15, which is acceptable. It is far much better than "09 15" shown on the axis.  The problem is the data were obtained in different years.  This makes "2015" shown in lattice plots of different years.  I have tried to put in the year in the raw data (such as "1/10/2013"), but the plot is really bizzard, with the 2002 plots have all the points on the left of the plot whereas 2013 plots have all the data points on the right of the plots because the x-axis shows data from 2001 to 2013.  I feel like hopeless to insist to have the axis label shown as "Sep 15" because it seems to be the problem of my computer setting.  Is there a way to shows graphs in different years, but with the same scale beginning from September to December?

Regards,
Christine


--------------------------------------------
2015?8?18? ????Duncan Mackay <dulcalma at bigpond.com> ???

 ??: RE: [R] date format in xyplot
 ???: "R" <r-help at r-project.org>

 ??: 2015?8?18?,???,??4:08

 Hi Christine

 If somethings go wrong:
 1 first check your data

 str(Raw)
 'data.frame':???10 obs. of?
 5 variables:
  $ Date???: Factor
 w/ 16 levels "1/10","1/11",..: 6 7 2 4
 12 9 7 2 4 12
  $ Year???: int?
 2002 2002 2002 2002 2002 2002 2002 2002 2002 2002
  $ Station: Factor w/ 4 levels
 "E","F","H","I": 1 1
 1 1 1 2 2 2 2 2
  $ Abun???: num?
 3.42 1.33 3.67 3.67 3.92 2.17 2.5 1.67 6.33 0.67
  $ Date1? : Date, format:
 "2015-09-19" "2015-10-02"
 "2015-11-01"
 "2015-11-12" ...

 Raw$Date2 <- as.character(Raw$Date1)
 Raw$Date2
 [1]
 "2015-09-19" "2015-10-02"
 "2015-11-01" "2015-11-12"
 "2015-11-29"
 "2015-09-20" "2015-10-02"
 "2015-11-01" "2015-11-12"
 "2015-11-29"
 Raw$Date2 <-
 as.Date(Raw$Date2, "%Y-%m-%d")

 2 read the help guide again if not done
 recently ?lattice::xyplot or ?xyplot
 3 start
 with a minimum number of arguments

 xyplot(Abun~Date2|as.factor(Year), Raw)
 or 
 xyplot(Abun~Date2, Raw)
 if you are still having problems

 Dates are hard work in any
 language as they are not consistent so:
 a.?
 use? default
 b.? use your own 

 This works

 xyplot(Abun~Date2|as.factor(Year), Raw,
 ? ? ???par.settings =
 list(stripbackground = "transparent"), #
 background
 colour controlled here
 ? ? ???type="p",
 ? ? ???scales = list(x = list(at =
 sort(c(seq(as.Date(Raw$Date2[1]-4), by =
 "months", length = 4),
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ? ? ? ? ???seq(as.Date(Raw$Date2[1]+12),
 by
 = "months", length = 3))),
 ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???labels =
 format(sort(c(seq(as.Date(Raw$Date2[1]-4), by =
 "months", length = 4),
  
 seq(as.Date(Raw$Date2[1]+12), by =
 "months", length = 3))), "%m-%d") )
 ),
 ? ?
 ???xlab=list("Month",cex=1.5),
 ? ?
 ???ylab=list("Abundance",cex=1.5),
 ? ? ???cex=2,
 ?
 ? ???pch=c(16,16,21),
 ? ?
 ???col=c("Black","Grey","Black")
 )

 par.settings
 is confining the parameters set by trellis.par.set()? to
 the
 function
 to get them

 names(trellis.par.get() )
 and going further
 trellis.par.get()$superpose.symbol
 will give you the values for
 superpose.symbol

 Beware: Do
 not make the labels etc so big that the axis labels are hard
 to
 read. Think of final size

 Regards

 Duncan

 Duncan
 Mackay
 Department of Agronomy and Soil
 Science
 University of New England
 Armidale NSW 2351
 Email: home:
 mackay at northnet.com.au

 -----Original Message-----
 From: R-help [mailto:r-help-bounces at r-project.org]
 On Behalf Of Christine
 Lee via R-help
 Sent: Tuesday, 18 August 2015 14:16
 To: r-help at r-project.org
 Subject: [R] date format in xyplot

 To whom it may concern,

 I have tried to plot some
 numbers against time with the time on the X-axis
 shown as "Jan", "Feb",
 etc.

 I used the following
 commands:
 Raw<-structure(list(Date =
 structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L, 
 2L, 4L, 12L), .Label = c("1/10",
 "1/11", "11/11", "12/11",
 "13/10", 
 "19/9",
 "2/10", "2/11", "20/9",
 "26/11", "29/10", "29/11",
 "30/11", 
 "31/10",
 "4/10", "6/10"), class =
 "factor"), Year = c(2002L, 
 2002L,
 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
 ), Station = structure(c(1L, 1L, 1L, 1L, 1L,
 2L, 2L, 2L, 2L, 
 2L), .Label =
 c("E", "F", "H",
 "I"), class = "factor"), Abun = c(3.42,

 1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67,
 6.33, 0.67), Date1 =
 structure(c(16697, 
 16710, 16740, 16751, 16768, 16698, 16710,
 16740, 16751, 16768
 ), class =
 "Date")), .Names = c("Date",
 "Year", "Station", "Abun", 
 "Date1"), row.names = c(NA, 10L),
 class = "data.frame")

 Raw$Date1<-as.Date(Raw$Date,"%d/%m")
 xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),yl
 ab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Bla
 ck"),strip=strip.custom(bg='white'),format="%B-%d")

 The date format shown on
 X-axis was just "10-1", "10-15"

 I should be grateful if any
 one could help indicating what has gone wrong?

 Regards,
 Christine

 ______________________________________________
 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained,
 reproducible code.


From loris.bennett at fu-berlin.de  Tue Aug 18 16:28:19 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 18 Aug 2015 16:28:19 +0200
Subject: [R] Running R in Server
References: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>
Message-ID: <87614c3c3g.fsf@hornfels.zedat.fu-berlin.de>

Swagato Chatterjee <swagato1987 at gmail.com> writes:

> Hello,
>
> I have written a R script which runs a regression of a dataset and saves
> the result in a csv file.
>
> Now this dataset has to be edited periodically which is done in a server. I
> need to run the R script in a server so that the results can also be shared
> in a server and used in a web application.
>
> I have coded in R and have used R in windows. I have never used
> Ubuntu/Linux. Is there a step by step guide on how to run a R code in
> server?
>
> Thanks and Regards,
>
> Swagato

If you are lucky, you can just copy your script to the server and call

Rscript /path/to/your/r/script

on the linux command line.

However, you'll probably have to make sure that all the packages you
need are installed on the server.

HTH

Loris

-- 
This signature is currently under construction.


From shivibhatia at ymail.com  Tue Aug 18 14:41:21 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Tue, 18 Aug 2015 05:41:21 -0700 (PDT)
Subject: [R] Output In R
Message-ID: <1439901681930-4711227.post@n4.nabble.com>

Hello All, 

 As i am a newbie in R so most of you would have seen this question zillion
times. I searched for the answer on this forum as well on other various
forums however could not find the answer i am looking for.

 I am dplyr package and used a very basic code:
 select(june,city,state,mod)

 The data sheet i am using has more than 3 million observations but the
console does not print all of them and show only few options and give a
message:
[ reached getOption("max.print") -- omitted 376341 rows ]


 What is the option that i need to add to see all values in the output.
Similarly once i scroll down and then if i scroll up i am not able to see
the values starting from row #1. Please suggest



--
View this message in context: http://r.789695.n4.nabble.com/Output-In-R-tp4711227.html
Sent from the R help mailing list archive at Nabble.com.


From serpilaltunay at gmail.com  Tue Aug 18 15:00:06 2015
From: serpilaltunay at gmail.com (=?UTF-8?Q?Serpil_Akta=C5=9F_Altunay?=)
Date: Tue, 18 Aug 2015 16:00:06 +0300
Subject: [R] NB-L Regression
Message-ID: <CACnA_fOHjbZSWGUXjmAXrgVvnS6ddNMyb1MFQM_jJe3oLqzmvw@mail.gmail.com>

Hi All,

I am trying to run "Negative Binomial Lindley" regression under glm. But
NB-L is not defined in the family group. I will perform a simulation. The
model has only one covariate generated from uniform distribution, the count
response variable follows the NB distribution.

the model should be  glm(count~x, family=nbl)

I would greatly appreciate any help.

Serpil

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Tue Aug 18 16:56:35 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 19 Aug 2015 00:56:35 +1000
Subject: [R] date format in xyplot
In-Reply-To: <1439907935.89748.YahooMailBasic@web120801.mail.ne1.yahoo.com>
References: <000901d0d98d$2207d860$66178920$@bigpond.com>
	<1439907935.89748.YahooMailBasic@web120801.mail.ne1.yahoo.com>
Message-ID: <000001d0d9c6$1402bc60$3c083520$@bigpond.com>

Hi

I forgot to change the format and put the panel back in - I was trying to get the data right

see ? strptime for a list of all the combinations for dates.

Have a look at 
http://lmdvr.r-forge.r-project.org/figures/figures.html
which may give you some ideas.

If you want  to restrict data to a certain period you will have to put limits on the x axis and you do that in the scales argument ie x =list(limits = c(min date, max date) )  NB date format
For one panel it is easy but for 2+ it can be tricky as you will be working with a list. 
Then the code would be something like

xyplot(Abun~Date2|Year, Raw, 
            scales = list(x = list(limits = list(c(min y1, max y1), c(min y2, max y2))) 
..
)
where y[1...] is the applicable year 
have a look at aspect which may improve things for the final plot if desired.

If you want to space groups of years-- see between 
 
Regards

Duncan

-----Original Message-----
From: Christine Lee [mailto:leptostracan at yahoo.com] 
Sent: Wednesday, 19 August 2015 00:26
To: R; Duncan Mackay
Subject: RE: [R] date format in xyplot

Thank you Duncan,

I have tried the scales function.  It ends up with 2015-09-15, which is acceptable. It is far much better than "09 15" shown on the axis.  The problem is the data were obtained in different years.  This makes "2015" shown in lattice plots of different years.  I have tried to put in the year in the raw data (such as "1/10/2013"), but the plot is really bizzard, with the 2002 plots have all the points on the left of the plot whereas 2013 plots have all the data points on the right of the plots because the x-axis shows data from 2001 to 2013.  I feel like hopeless to insist to have the axis label shown as "Sep 15" because it seems to be the problem of my computer setting.  Is there a way to shows graphs in different years, but with the same scale beginning from September to December?

Regards,
Christine


--------------------------------------------
2015?8?18? ????Duncan Mackay <dulcalma at bigpond.com> ???

 ??: RE: [R] date format in xyplot
 ???: "R" <r-help at r-project.org>
 ??(CC): "'Christine Lee'" <leptostracan at yahoo.com>
 ??: 2015?8?18?,???,??4:08

 Hi Christine

 If somethings go wrong:
 1 first check your data

 str(Raw)
 'data.frame':   10 obs. of 
 5 variables:
  $ Date   : Factor
 w/ 16 levels "1/10","1/11",..: 6 7 2 4
 12 9 7 2 4 12
  $ Year   : int 
 2002 2002 2002 2002 2002 2002 2002 2002 2002 2002
  $ Station: Factor w/ 4 levels
 "E","F","H","I": 1 1
 1 1 1 2 2 2 2 2
  $ Abun   : num 
 3.42 1.33 3.67 3.67 3.92 2.17 2.5 1.67 6.33 0.67
  $ Date1  : Date, format:
 "2015-09-19" "2015-10-02"
 "2015-11-01"
 "2015-11-12" ...

 Raw$Date2 <- as.character(Raw$Date1)
 Raw$Date2
 [1]
 "2015-09-19" "2015-10-02"
 "2015-11-01" "2015-11-12"
 "2015-11-29"
 "2015-09-20" "2015-10-02"
 "2015-11-01" "2015-11-12"
 "2015-11-29"
 Raw$Date2 <-
 as.Date(Raw$Date2, "%Y-%m-%d")

 2 read the help guide again if not done
 recently ?lattice::xyplot or ?xyplot
 3 start
 with a minimum number of arguments

 xyplot(Abun~Date2|as.factor(Year), Raw)
 or 
 xyplot(Abun~Date2, Raw)
 if you are still having problems

 Dates are hard work in any
 language as they are not consistent so:
 a. 
 use  default
 b.  use your own 

 This works

 xyplot(Abun~Date2|as.factor(Year), Raw,
        par.settings =
 list(stripbackground = "transparent"), #
 background
 colour controlled here
        type="p",
        scales = list(x = list(at =
 sort(c(seq(as.Date(Raw$Date2[1]-4), by =
 "months", length = 4),
                                
            seq(as.Date(Raw$Date2[1]+12),
 by
 = "months", length = 3))),
                            
    labels =
 format(sort(c(seq(as.Date(Raw$Date2[1]-4), by =
 "months", length = 4),
  
 seq(as.Date(Raw$Date2[1]+12), by =
 "months", length = 3))), "%m-%d") )
 ),
    
    xlab=list("Month",cex=1.5),
    
    ylab=list("Abundance",cex=1.5),
        cex=2,
  
      pch=c(16,16,21),
    
    col=c("Black","Grey","Black")
 )

 par.settings
 is confining the parameters set by trellis.par.set()  to
 the
 function
 to get them

 names(trellis.par.get() )
 and going further
 trellis.par.get()$superpose.symbol
 will give you the values for
 superpose.symbol

 Beware: Do
 not make the labels etc so big that the axis labels are hard
 to
 read. Think of final size

 Regards

 Duncan

 Duncan
 Mackay
 Department of Agronomy and Soil
 Science
 University of New England
 Armidale NSW 2351
 Email: home:
 mackay at northnet.com.au

 -----Original Message-----
 From: R-help [mailto:r-help-bounces at r-project.org]
 On Behalf Of Christine
 Lee via R-help
 Sent: Tuesday, 18 August 2015 14:16
 To: r-help at r-project.org
 Subject: [R] date format in xyplot

 To whom it may concern,

 I have tried to plot some
 numbers against time with the time on the X-axis
 shown as "Jan", "Feb",
 etc.

 I used the following
 commands:
 Raw<-structure(list(Date =
 structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L, 
 2L, 4L, 12L), .Label = c("1/10",
 "1/11", "11/11", "12/11",
 "13/10", 
 "19/9",
 "2/10", "2/11", "20/9",
 "26/11", "29/10", "29/11",
 "30/11", 
 "31/10",
 "4/10", "6/10"), class =
 "factor"), Year = c(2002L, 
 2002L,
 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L, 2002L
 ), Station = structure(c(1L, 1L, 1L, 1L, 1L,
 2L, 2L, 2L, 2L, 
 2L), .Label =
 c("E", "F", "H",
 "I"), class = "factor"), Abun = c(3.42,

 1.33, 3.67, 3.67, 3.92, 2.17, 2.5, 1.67,
 6.33, 0.67), Date1 =
 structure(c(16697, 
 16710, 16740, 16751, 16768, 16698, 16710,
 16740, 16751, 16768
 ), class =
 "Date")), .Names = c("Date",
 "Year", "Station", "Abun", 
 "Date1"), row.names = c(NA, 10L),
 class = "data.frame")

 Raw$Date1<-as.Date(Raw$Date,"%d/%m")
 xyplot(Abun~Date1|as.factor(Year),Raw,type="p",xlab=list("Month",cex=1.5),yl
 ab=list("Abundance",cex=1.5),cex=2,pch=c(16,16,21),col=c("Black","Grey","Bla
 ck"),strip=strip.custom(bg='white'),format="%B-%d")

 The date format shown on
 X-axis was just "10-1", "10-15"

 I should be grateful if any
 one could help indicating what has gone wrong?

 Regards,
 Christine

 ______________________________________________
 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained,
 reproducible code.


From boris.steipe at utoronto.ca  Tue Aug 18 17:24:08 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 18 Aug 2015 11:24:08 -0400
Subject: [R] Output In R
In-Reply-To: <1439901681930-4711227.post@n4.nabble.com>
References: <1439901681930-4711227.post@n4.nabble.com>
Message-ID: <A3F4CC15-F8CD-4327-88CE-740F78DCC6DF@utoronto.ca>

That's a very odd request: surely you would not want to visually inspect 3 million rows in the console?

Typically one would assign the (large) results of a function to a variable for further processing. If you need to inspect the beginning and end of your dataset, use head() and tail().

Try getOption("max.print") to see what it is set to: it's a large and reasonable value, remember your console uses memory and at some point it needs to truncate the values you store in the console, to stay within its allotted memory. You can change the "max.print" option, but I can't see how that would be reasonable.

Cheers,
Boris




On Aug 18, 2015, at 8:41 AM, Shivi82 <shivibhatia at ymail.com> wrote:

> Hello All, 
> 
> As i am a newbie in R so most of you would have seen this question zillion
> times. I searched for the answer on this forum as well on other various
> forums however could not find the answer i am looking for.
> 
> I am dplyr package and used a very basic code:
> select(june,city,state,mod)
> 
> The data sheet i am using has more than 3 million observations but the
> console does not print all of them and show only few options and give a
> message:
> [ reached getOption("max.print") -- omitted 376341 rows ]
> 
> 
> What is the option that i need to add to see all values in the output.
> Similarly once i scroll down and then if i scroll up i am not able to see
> the values starting from row #1. Please suggest
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Output-In-R-tp4711227.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Tue Aug 18 17:25:18 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 18 Aug 2015 17:25:18 +0200
Subject: [R] Output In R
References: <1439901681930-4711227.post@n4.nabble.com>
Message-ID: <871tf039gh.fsf@hornfels.zedat.fu-berlin.de>

Shivi82 <shivibhatia at ymail.com> writes:

> Hello All, 
>
>  As i am a newbie in R so most of you would have seen this question zillion
> times. I searched for the answer on this forum as well on other various
> forums however could not find the answer i am looking for.
>
>  I am dplyr package and used a very basic code:
>  select(june,city,state,mod)
>
>  The data sheet i am using has more than 3 million observations but the
> console does not print all of them and show only few options and give a
> message:
> [ reached getOption("max.print") -- omitted 376341 rows ]
>
>
>  What is the option that i need to add to see all values in the output.
> Similarly once i scroll down and then if i scroll up i am not able to see
> the values starting from row #1. Please suggest

You need to sharpen your searching skills.  The first result of
looking  for

r max.print

via a well-known search engine is a question on StackOverflow.  One of
the answers given there is to set the value of max.print in the
following manner:

options(max.print=999999)

I'll leave finding the appropriate value as an exercise for the reader.

Cheers,

Loris

-- 
This signature is currently under construction.


From scotttetrick at gmail.com  Tue Aug 18 17:02:31 2015
From: scotttetrick at gmail.com (Scott Tetrick)
Date: Tue, 18 Aug 2015 09:02:31 -0600
Subject: [R] Output In R
In-Reply-To: <1439901681930-4711227.post@n4.nabble.com>
References: <1439901681930-4711227.post@n4.nabble.com>
Message-ID: <CAD5dwaQ-CmZEqPVzPCOr8GJ4Li3QQ08js6G1b0XvMdGgTuiDSw@mail.gmail.com>

?write.csv and look at with the editor of choice.



On Tue, Aug 18, 2015 at 6:41 AM, Shivi82 <shivibhatia at ymail.com> wrote:

> Hello All,
>
>  As i am a newbie in R so most of you would have seen this question zillion
> times. I searched for the answer on this forum as well on other various
> forums however could not find the answer i am looking for.
>
>  I am dplyr package and used a very basic code:
>  select(june,city,state,mod)
>
>  The data sheet i am using has more than 3 million observations but the
> console does not print all of them and show only few options and give a
> message:
> [ reached getOption("max.print") -- omitted 376341 rows ]
>
>
>  What is the option that i need to add to see all values in the output.
> Similarly once i scroll down and then if i scroll up i am not able to see
> the values starting from row #1. Please suggest
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Output-In-R-tp4711227.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Xochitl.Cormon at ifremer.fr  Tue Aug 18 18:08:30 2015
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Tue, 18 Aug 2015 18:08:30 +0200
Subject: [R] Non linear regression - Von Bertalanffy Growth Function -
 "singular gradient matrix at initial parameter estimates"
Message-ID: <55D3587E.7020509@ifremer.fr>

Dear all,

I am trying to estimate VBGF parameters K and Linf using non linear 
regression and nls(). First I used a classic approach where I estimate 
both parameters together as below with "alkdyr" being a subset per year 
of my age-length-key database and running in a loop.

vbgf.par <- nls(Lgtcm ~  Linf *(1 - exp(-K * (Age - tzero))), start = 
c(K= 0.07, Linf = 177.1), data=alkdyr)

I obtain an estimation of both parameters that are strongly correlated. 
Indeed after plotting Linf ~ K and fitting a linear regression I obtain 
a function (Linf = a + b*K) with R2= 0.8 and a = 215, b = -763.

In this context, to take into account explicitly correlation between 
parameters, I decided to fit a new non linear regression derivate from 
VBGF but where Linf is expressed depending on K (I am most interested in 
K). To do so, I tried this model:
vbgf.par <- nls(Lgtcm ~  (a + (b*k)) *(1 - exp(-k * (Age - tzero))), 
start = c(k= 0.07, a= 215, b=-763), data=alkdyr)

Unfortunately at this point I cannot go further as I get the error 
message "singular gradient matrix at initial parameter estimates".

I tried to use alg= plinear (which I am not sure I understand properly 
yet). If I give a starting value for a and b only, I have an error 
message stating "step factor below minFactor" (even when minFactor is 
set to 100000000000).

Any help will be more than welcome as this is quite urgent....

Best,

Xochitl C.




-- 

<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en ?cologie marine et science halieutique
PhD student in marine ecology and fishery science

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><


From arnaud.gaboury at gmail.com  Tue Aug 18 18:15:08 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Tue, 18 Aug 2015 16:15:08 +0000
Subject: [R] Running R in Server
In-Reply-To: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>
References: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>
Message-ID: <CAK1hC9tNgn9Tpc-rus2RYmzaRhLsaMe01rHb1XX4wNyoHiM-qQ@mail.gmail.com>

On Sun, Aug 16, 2015, 2:29 PM Swagato Chatterjee <swagato1987 at gmail.com>
wrote:

Hello,

I have written a R script which runs a regression of a dataset and saves
the result in a csv file.

Now this dataset has to be edited periodically which is done in a server. I
need to run the R script in a server so that the results can also be shared
in a server and used in a web application.

Have a look at deployR on Revolutioanalytic website. There is a free
open-source solution for windows.

I have coded in R and have used R in windows. I have never used
Ubuntu/Linux. Is there a step by step guide on how to run a R code in
server?

Thanks and Regards,

Swagato

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Aug 18 18:20:02 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 18 Aug 2015 09:20:02 -0700
Subject: [R] Non linear regression - Von Bertalanffy Growth Function -
 "singular gradient matrix at initial parameter estimates"
In-Reply-To: <55D3587E.7020509@ifremer.fr>
References: <55D3587E.7020509@ifremer.fr>
Message-ID: <CAGxFJbR3u_QSF=eR6itOxujhg0L_HdT=aPoNg6L90RX5x4+Eeg@mail.gmail.com>

These appear to be primarily statistics/nonlinear optimization issues
that are off topic here, which is about R programming. Post on a
statistics list like stats.stackexchange.com instead.


Cheers,
Bert




Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Aug 18, 2015 at 9:08 AM, Xochitl CORMON
<Xochitl.Cormon at ifremer.fr> wrote:
> Dear all,
>
> I am trying to estimate VBGF parameters K and Linf using non linear
> regression and nls(). First I used a classic approach where I estimate both
> parameters together as below with "alkdyr" being a subset per year of my
> age-length-key database and running in a loop.
>
> vbgf.par <- nls(Lgtcm ~  Linf *(1 - exp(-K * (Age - tzero))), start = c(K=
> 0.07, Linf = 177.1), data=alkdyr)
>
> I obtain an estimation of both parameters that are strongly correlated.
> Indeed after plotting Linf ~ K and fitting a linear regression I obtain a
> function (Linf = a + b*K) with R2= 0.8 and a = 215, b = -763.
>
> In this context, to take into account explicitly correlation between
> parameters, I decided to fit a new non linear regression derivate from VBGF
> but where Linf is expressed depending on K (I am most interested in K). To
> do so, I tried this model:
> vbgf.par <- nls(Lgtcm ~  (a + (b*k)) *(1 - exp(-k * (Age - tzero))), start =
> c(k= 0.07, a= 215, b=-763), data=alkdyr)
>
> Unfortunately at this point I cannot go further as I get the error message
> "singular gradient matrix at initial parameter estimates".
>
> I tried to use alg= plinear (which I am not sure I understand properly yet).
> If I give a starting value for a and b only, I have an error message stating
> "step factor below minFactor" (even when minFactor is set to 100000000000).
>
> Any help will be more than welcome as this is quite urgent....
>
> Best,
>
> Xochitl C.
>
>
>
>
> --
>
> <>< <>< <>< <><
>
> Xochitl CORMON
> +33 (0)3 21 99 56 84
>
> Doctorante en ?cologie marine et science halieutique
> PhD student in marine ecology and fishery science
>
> <>< <>< <>< <><
>
> IFREMER
> Centre Manche Mer du Nord
> 150 quai Gambetta
> 62200 Boulogne-sur-Mer
>
> <>< <>< <>< <><
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Aug 18 18:43:00 2015
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 18 Aug 2015 10:43:00 -0600
Subject: [R] Output In R
In-Reply-To: <1439901681930-4711227.post@n4.nabble.com>
References: <1439901681930-4711227.post@n4.nabble.com>
Message-ID: <CAFEqCdyOhsj_3tJifUX-iiRzdatDB-rHXpXZQ=rJ4V4kKxtWhw@mail.gmail.com>

I would suggest that instead of trying to view all the results in the
console that you save the result into a object then use the View (note
the capitol V) function to be able to scroll through the results.  The
head and tail functions have already been mentioned and I second their
use for a quick view.  Since you are already using dplyr you should
look at the slice (and possibly filter) function for another way to
display pieces of the resulting object.

On Tue, Aug 18, 2015 at 6:41 AM, Shivi82 <shivibhatia at ymail.com> wrote:
> Hello All,
>
>  As i am a newbie in R so most of you would have seen this question zillion
> times. I searched for the answer on this forum as well on other various
> forums however could not find the answer i am looking for.
>
>  I am dplyr package and used a very basic code:
>  select(june,city,state,mod)
>
>  The data sheet i am using has more than 3 million observations but the
> console does not print all of them and show only few options and give a
> message:
> [ reached getOption("max.print") -- omitted 376341 rows ]
>
>
>  What is the option that i need to add to see all values in the output.
> Similarly once i scroll down and then if i scroll up i am not able to see
> the values starting from row #1. Please suggest
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Output-In-R-tp4711227.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jrkrideau at inbox.com  Tue Aug 18 19:07:51 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 18 Aug 2015 09:07:51 -0800
Subject: [R] How are packages installed with install_github() updated in
 RStudio?
In-Reply-To: <CABdHhvEy8GXUGTYu0Ww28=E4vpjCYVhWAKep8kbt=35fozbgOQ@mail.gmail.com>
References: <78be8667825.00000239jrkrideau@inbox.com>
	<cals_gzvgiwiwr27aco-kf83rt7h-dax1anmpugx9memlabv3bq@mail.gmail.com>
Message-ID: <7AC7E82C45E.000005C4jrkrideau@inbox.com>


Thanks Hadley

I had some vague impression that RStudio was maintaining a slightly diffferent repository thought I am not sure why I thought that.
John Kane
Kingston ON Canada


> -----Original Message-----
> From: h.wickham at gmail.com
> Sent: Tue, 18 Aug 2015 09:01:09 -0500
> To: jrkrideau at inbox.com
> Subject: Re: [R] How are packages installed with install_github() updated
> in RStudio?
> 
> RStudio just calls the same underlying R functions, so it doesn't make
> any difference that you're using RStudio.  Currently, there's no
> automatic way to update packages installed from github.
> 
> Hadley
> 
> On Tue, Aug 18, 2015 at 8:14 AM, John Kane <jrkrideau at inbox.com> wrote:
>> Hi Michal,
>> 
>> Because RStudio seems to use its own method of updating you might be
>> better off asking in their forum.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: prgosek at gmail.com
>>> Sent: Tue, 18 Aug 2015 10:43:20 +0200
>>> To: r-help at r-project.org
>>> Subject: [R] How are packages installed with install_github() updated
>>> in
>>> RStudio?
>>> 
>>> Hallo.
>>> 
>>> I use RStudio. Because of a bug in the latest CRAN version of dplyr, I
>>> installed the GitHub version with install_github(). Now I wonder what
>>> happens when there is a new version. Does RStudio update the packages
>>> installed from GitHub? If so, does it replace it with the new CRAN
>>> version,
>>> or a new GitHub version?
>>> 
>>> Many thanks for you answer,
>>> Michal Kvasnicka
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> http://had.co.nz/

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From murdoch.duncan at gmail.com  Tue Aug 18 19:56:10 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 18 Aug 2015 13:56:10 -0400
Subject: [R] How are packages installed with install_github() updated in
 RStudio?
In-Reply-To: <CABdHhvEy8GXUGTYu0Ww28=E4vpjCYVhWAKep8kbt=35fozbgOQ@mail.gmail.com>
References: <CALs_GZVgiwiwr27Aco-Kf83rT7H-Dax1aNmPugX9mEmLAbV3bQ@mail.gmail.com>	<78BE8667825.00000239jrkrideau@inbox.com>
	<CABdHhvEy8GXUGTYu0Ww28=E4vpjCYVhWAKep8kbt=35fozbgOQ@mail.gmail.com>
Message-ID: <55D371BA.7030008@gmail.com>

On 18/08/2015 10:01 AM, Hadley Wickham wrote:
> RStudio just calls the same underlying R functions, so it doesn't make
> any difference that you're using RStudio.  Currently, there's no
> automatic way to update packages installed from github.

And to clarify a bit more:  this means if you install a patched version
of something from github that is newer than what is on CRAN, then call
update.packages(), you'll keep the new one as long as the version number
is higher than the one on CRAN.

On the other hand, if you run install.packages("foo"), then you'll
install the CRAN version of foo even if you already have a newer one
from github.

Duncan Murdoch

> 
> Hadley
> 
> On Tue, Aug 18, 2015 at 8:14 AM, John Kane <jrkrideau at inbox.com> wrote:
>> Hi Michal,
>>
>> Because RStudio seems to use its own method of updating you might be better off asking in their forum.
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>> -----Original Message-----
>>> From: prgosek at gmail.com
>>> Sent: Tue, 18 Aug 2015 10:43:20 +0200
>>> To: r-help at r-project.org
>>> Subject: [R] How are packages installed with install_github() updated in
>>> RStudio?
>>>
>>> Hallo.
>>>
>>> I use RStudio. Because of a bug in the latest CRAN version of dplyr, I
>>> installed the GitHub version with install_github(). Now I wonder what
>>> happens when there is a new version. Does RStudio update the packages
>>> installed from GitHub? If so, does it replace it with the new CRAN
>>> version,
>>> or a new GitHub version?
>>>
>>> Many thanks for you answer,
>>> Michal Kvasnicka
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> Can't remember your password? Do you need a strong and secure password?
>> Use Password manager! It stores your passwords & protects your account.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From jonsleepy at gmail.com  Tue Aug 18 21:06:36 2015
From: jonsleepy at gmail.com (Jon BR)
Date: Tue, 18 Aug 2015 15:06:36 -0400
Subject: [R] data frame formatting
Message-ID: <CA+d7zeQCQ3XqZj7xbUye=K=8wKqZrUVSamO_1+uEdgweSUftxg@mail.gmail.com>

Hello all,
    I would like to take a data frame such as the following one:

> df <-
data.frame(id=c("A","A","B","B"),first=c("BX",NA,NA,"LF"),second=c(NA,"TD","BZ",NA),third=c(NA,NA,"RB","BT"),fourth=c("LG","QR",NA,NA))
> df
  id first second third fourth
1  A    BX   <NA>  <NA>     LG
2  A  <NA>     TD  <NA>     QR
3  B  <NA>     BZ    RB   <NA>
4  B    LF   <NA>    BT   <NA>

and merge rows based on the id, such that the value in the column will be
one of four possibilities: if both values in the original df are <NA>, the
new value should also be <NA>.  If there are two non-NA values, then the
new value should read "clash".  Otherwise, the new value should be
whichever value was not <NA>.

An example output from the command would read in df and read out:


  id first second third fourth
1  A    BX   TD  <NA>     clash
2  B    LF   BZ    clash   <NA>


I'd be grateful if someone could point me in the right direction.

Thanks,
Jonathan

	[[alternative HTML version deleted]]


From bob at rudis.net  Tue Aug 18 21:27:08 2015
From: bob at rudis.net (boB Rudis)
Date: Tue, 18 Aug 2015 15:27:08 -0400
Subject: [R] data frame formatting
In-Reply-To: <CA+d7zeQCQ3XqZj7xbUye=K=8wKqZrUVSamO_1+uEdgweSUftxg@mail.gmail.com>
References: <CA+d7zeQCQ3XqZj7xbUye=K=8wKqZrUVSamO_1+uEdgweSUftxg@mail.gmail.com>
Message-ID: <CAJ4QxaPSGxUOD48C1GDH-TE5tMg=wTTg+b-eTRK9osF2_WVrpg@mail.gmail.com>

Here's one way in base R:

df <- data.frame(id=c("A","A","B","B"),
                 first=c("BX",NA,NA,"LF"),
                 second=c(NA,"TD","BZ",NA),
                 third=c(NA,NA,"RB","BT"),
                 fourth=c("LG","QR",NA,NA))


new_df <- data.frame(do.call(rbind, by(df, df$id, function(x) {
  sapply(x[,-1], function(y) {
    if (all(is.na(y))) return(NA)
    if (all(!is.na(y))) return("clash")
    return(as.character(y[which(!is.na(y))]))
  })
})))

new_df$id <- rownames(new_df)
rownames(new_df) <- NULL

new_df

##   first second third fourth id
## 1    BX     TD  <NA>  clash  A
## 2    LF     BZ clash   <NA>  B


On Tue, Aug 18, 2015 at 3:06 PM, Jon BR <jonsleepy at gmail.com> wrote:
> df <-
> data.frame(id=c("A","A","B","B"),first=c("BX",NA,NA,"LF"),second=c(NA,"TD","BZ",NA),third=c(NA,NA,"RB","BT"),fourth=c("LG","QR",NA,NA))
>> df


From brian at bmorrishome.org  Tue Aug 18 21:05:38 2015
From: brian at bmorrishome.org (brian at bmorrishome.org)
Date: Tue, 18 Aug 2015 12:05:38 -0700
Subject: [R] Unable to get the 64-bit version of R (3.2.1 Terminal or GUI)
 to start on a Windows 7 machine
Message-ID: <20150818120538.6fb0b48f2107a62aaa51106d9f22d240.2251cd4905.wbe@email09.secureserver.net>

I am unable to get the 64-bit version of R (3.2.1 Terminal or GUI) to
start on a Windows 7 machine.  I can get the 32-bit to start, just not
the 64-bit.

I am receiving a dialog box box that points me to four files but nothing
seems usable when examining them.

Installed to C:\Dev\R\R-3.2.1.  I have set my R_HOME environment
variable to "C:\Dev\R\R-3.2.1" and added "C:\Dev\R\R-3.2.1\bin\x64" to
my Windows PATH environment variable.

I have also checked the Windows Registry to make sure everything is
pointing to the x64 directory and one example is given below:

    Registry Key: ?HKEY_CLASSES_ROOT\RWorkspace\shell\open\command?
    Registry Key Value:"C:\Dev\R\R-3.2.1\bin\x64\RGui.exe" "%1"

I have searched and have tried for some time to resolve this based on
what I have found but am not having any success.  Any help you can
provide would be greatly appreciated.

I have embedded three of the four troubleshooting files as text below in
the hope that it might be helpful.  

The WER8836.tmp.wmi.txt file looks like Windows is using a 32-Bit
processor but it is a 64-bit install of the OS.  I have embedded below:
instance of Win32_Processor
{
    Family = 198;
};

instance of Win32_OperatingSystem
{
    BuildNumber = "7601";
    OSLanguage = 1033;
    ProductType = 1;
    ServicePackMajorVersion = 1;
    ServicePackMinorVersion = 0;
    SuiteMask = 272;
    Version = "6.1.7601";
};

instance of Win32_ComputerSystem
{
    Domain = "chkenergy.net";
    Manufacturer = "Dell Inc.";
    Model = "Latitude E6420";
    Name = "CHK4WL6DS1";
    PartOfDomain = TRUE;
    UserName = "CHKENERGY\\bmorris2";
};

The WER8798.tmp.apcompat.txt is another file given for troubleshooting
in the error message.  I have embedded it below as well:
<?xml version="1.0" encoding="UTF-16"?>
<DATABASE>
<EXE NAME="Rgui.exe" FILTER="CMI_FILTER_PRIVACY">
    <MATCHING_FILE NAME="open.exe" SIZE="16384" CHECKSUM="0xB287F521"
MODULE_TYPE="WIN32" PE_CHECKSUM="0x6F3E" LINKER_VERSION="0x0"
LINK_DATE="06/18/2015 17:20:02" UPTO_LINK_DATE="06/18/2015 17:20:02"
EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="R.dll" SIZE="25820672" CHECKSUM="0x6850795A"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows DLL" FILE_VERSION="3.2.1  (2015-06-18)"
LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0" VERDATELO="0x0"
VERFILEOS="0x4" VERFILETYPE="0x2" MODULE_TYPE="WIN32"
PE_CHECKSUM="0x18A30E0" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:19:42" UPTO_LINK_DATE="06/18/2015 17:19:42"
EXPORT_NAME="R.dll" VER_LANGUAGE="English (United States) [0x409]"
EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="R.exe" SIZE="39936" CHECKSUM="0x8919B6FD"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows front-end" FILE_VERSION="3.2.1 
(2015-06-18)" LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0"
VERDATELO="0x0" VERFILEOS="0x4" VERFILETYPE="0x1" MODULE_TYPE="WIN32"
PE_CHECKSUM="0x15CE3" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:20:00" UPTO_LINK_DATE="06/18/2015 17:20:00"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rblas.dll" SIZE="343623" CHECKSUM="0x3B624D2B"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows DLL" FILE_VERSION="3.2.1  (2015-06-18)"
LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0" VERDATELO="0x0"
VERFILEOS="0x4" VERFILETYPE="0x2" MODULE_TYPE="WIN32"
PE_CHECKSUM="0x5F357" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:19:54" UPTO_LINK_DATE="06/18/2015 17:19:54"
EXPORT_NAME="Rblas.dll" VER_LANGUAGE="English (United States) [0x409]"
EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rcmd.exe" SIZE="39936" CHECKSUM="0x8F60F12D"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows front-end" FILE_VERSION="3.2.1 
(2015-06-18)" LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0"
VERDATELO="0x0" VERFILEOS="0x4" VERFILETYPE="0x1" MODULE_TYPE="WIN32"
PE_CHECKSUM="0x13E5C" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:19:59" UPTO_LINK_DATE="06/18/2015 17:19:59"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rfe.exe" SIZE="23040" CHECKSUM="0x8D69D4D8"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows front-end" FILE_VERSION="3.2.1 
(2015-06-18)" LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0"
VERDATELO="0x0" VERFILEOS="0x4" VERFILETYPE="0x1" MODULE_TYPE="WIN32"
PE_CHECKSUM="0x13155" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:20:03" UPTO_LINK_DATE="06/18/2015 17:20:03"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rgraphapp.dll" SIZE="377702"
CHECKSUM="0xC8C6CA6E" BIN_FILE_VERSION="3.21.2995.0"
BIN_PRODUCT_VERSION="3.0.0.0" FILE_DESCRIPTION="Graphapp DLL for R"
FILE_VERSION="3.2.1  (2015-06-18)" LEGAL_COPYRIGHT="R Core Team
1995-2015" VERDATEHI="0x0" VERDATELO="0x0" VERFILEOS="0x4"
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x643D2"
LINKER_VERSION="0x0" UPTO_BIN_FILE_VERSION="3.21.2995.0"
UPTO_BIN_PRODUCT_VERSION="3.0.0.0" LINK_DATE="06/18/2015 17:19:09"
UPTO_LINK_DATE="06/18/2015 17:19:09" EXPORT_NAME="Rgraphapp.dll"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rgui.exe" SIZE="22016" CHECKSUM="0x8513A33F"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows GUI front-end" FILE_VERSION="3.2.1 
(2015-06-18)" LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0"
VERDATELO="0x0" VERFILEOS="0x4" VERFILETYPE="0x1" MODULE_TYPE="WIN32"
PE_CHECKSUM="0xC1F7" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:19:57" UPTO_LINK_DATE="06/18/2015 17:19:57"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Riconv.dll" SIZE="131391" CHECKSUM="0xAAC7D582"
MODULE_TYPE="WIN32" PE_CHECKSUM="0x2F812" LINKER_VERSION="0x0"
LINK_DATE="06/18/2015 17:19:24" UPTO_LINK_DATE="06/18/2015 17:19:24"
EXPORT_NAME="Riconv.dll" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rlapack.dll" SIZE="2186240"
CHECKSUM="0xBE287D58" BIN_FILE_VERSION="3.21.2995.0"
BIN_PRODUCT_VERSION="3.0.0.0" FILE_DESCRIPTION="R DLL for lapack"
FILE_VERSION="3.2.1    (2015-06-18)" LEGAL_COPYRIGHT="R Core Team
2002-2015" VERDATEHI="0x0" VERDATELO="0x0" VERFILEOS="0x4"
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x21B6B2"
LINKER_VERSION="0x0" UPTO_BIN_FILE_VERSION="3.21.2995.0"
UPTO_BIN_PRODUCT_VERSION="3.0.0.0" LINK_DATE="06/18/2015 17:21:20"
UPTO_LINK_DATE="06/18/2015 17:21:20" EXPORT_NAME="Rlapack.dll"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rscript.exe" SIZE="26112" CHECKSUM="0x4D5FB8B7"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows front-end" FILE_VERSION="3.2.1 
(2015-06-18)" LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0"
VERDATELO="0x0" VERFILEOS="0x4" VERFILETYPE="0x1" MODULE_TYPE="WIN32"
PE_CHECKSUM="0x99D0" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:20:01" UPTO_LINK_DATE="06/18/2015 17:20:01"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="RSetReg.exe" SIZE="24064" CHECKSUM="0x1F2EF25"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows front-end" FILE_VERSION="3.2.1 
(2015-06-18)" LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0"
VERDATELO="0x0" VERFILEOS="0x4" VERFILETYPE="0x1" MODULE_TYPE="WIN32"
PE_CHECKSUM="0xEDE1" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:20:00" UPTO_LINK_DATE="06/18/2015 17:20:00"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
    <MATCHING_FILE NAME="Rterm.exe" SIZE="22528" CHECKSUM="0x56EBC9D0"
BIN_FILE_VERSION="3.21.2995.0" BIN_PRODUCT_VERSION="3.0.0.0"
FILE_DESCRIPTION="R for Windows terminal front-end" FILE_VERSION="3.2.1 
(2015-06-18)" LEGAL_COPYRIGHT="R Core Team 1995-2015" VERDATEHI="0x0"
VERDATELO="0x0" VERFILEOS="0x4" VERFILETYPE="0x1" MODULE_TYPE="WIN32"
PE_CHECKSUM="0xA8B2" LINKER_VERSION="0x0"
UPTO_BIN_FILE_VERSION="3.21.2995.0" UPTO_BIN_PRODUCT_VERSION="3.0.0.0"
LINK_DATE="06/18/2015 17:19:58" UPTO_LINK_DATE="06/18/2015 17:19:58"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
</EXE>
<EXE NAME="ntdll.dll" FILTER="CMI_FILTER_THISFILEONLY">
    <MATCHING_FILE NAME="ntdll.dll" SIZE="1728960" CHECKSUM="0x3302D03F"
BIN_FILE_VERSION="6.1.7601.23072" BIN_PRODUCT_VERSION="6.1.7601.23072"
PRODUCT_VERSION="6.1.7600.16385" FILE_DESCRIPTION="NT Layer DLL"
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows?
Operating System" FILE_VERSION="6.1.7600.16385 (win7_rtm.090713-1255)"
ORIGINAL_FILENAME="ntdll.dll.mui" INTERNAL_NAME="ntdll.dll"
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved."
VERDATEHI="0x0" VERDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2"
MODULE_TYPE="WIN32" PE_CHECKSUM="0x1AECCF" LINKER_VERSION="0x60001"
UPTO_BIN_FILE_VERSION="6.1.7601.23072"
UPTO_BIN_PRODUCT_VERSION="6.1.7601.23072" LINK_DATE="05/25/2015
18:19:15" UPTO_LINK_DATE="05/25/2015 18:19:15" EXPORT_NAME="ntdll.dll"
VER_LANGUAGE="English (United States) [0x409]" EXE_WRAPPER="0x0" />
</EXE>
<EXE NAME="kernel32.dll" FILTER="CMI_FILTER_THISFILEONLY">
    <MATCHING_FILE NAME="kernel32.dll" SIZE="1163776"
CHECKSUM="0xBA3F403C" BIN_FILE_VERSION="6.1.7601.23072"
BIN_PRODUCT_VERSION="6.1.7601.23072" PRODUCT_VERSION="6.1.7601.18015"
FILE_DESCRIPTION="Windows NT BASE API Client DLL"
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows?
Operating System" FILE_VERSION="6.1.7601.18015
(win7sp1_gdr.121129-1432)" ORIGINAL_FILENAME="kernel32"
INTERNAL_NAME="kernel32" LEGAL_COPYRIGHT="? Microsoft Corporation. All
rights reserved." VERDATEHI="0x0" VERDATELO="0x0" VERFILEOS="0x40004"
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x12A681"
LINKER_VERSION="0x60001" UPTO_BIN_FILE_VERSION="6.1.7601.23072"
UPTO_BIN_PRODUCT_VERSION="6.1.7601.23072" LINK_DATE="05/25/2015
18:19:33" UPTO_LINK_DATE="05/25/2015 18:19:33"
EXPORT_NAME="KERNEL32.dll" VER_LANGUAGE="English (United States)
[0x409]" EXE_WRAPPER="0x0" />
</EXE>
</DATABASE>


Last but not least I have embedded the
WER8767.tmp.WERInternalMetadata.xml below:
<?xml version="1.0" encoding="UTF-16"?>
<WERReportMetadata><OSVersionInformation><WindowsNTVersion>6.1</WindowsNTVersion><Build>7601
Service Pack 1</Build><Product>(0x4): Windows 7
Enterprise</Product><Edition>Enterprise</Edition><BuildString>7601.23072.amd64fre.win7sp1_ldr.150525-0604</BuildString><Revision>1130</Revision><Flavor>Multiprocessor
Free</Flavor><Architecture>X64</Architecture><LCID>1033</LCID></OSVersionInformation><ParentProcessInformation><ParentProcessId>4276</ParentProcessId><ParentProcessPath>C:\Windows\explorer.exe</ParentProcessPath><ParentProcessCmdLine>C:\WINDOWS\Explorer.EXE</ParentProcessCmdLine></ParentProcessInformation><ProblemSignatures><EventType>APPCRASH</EventType><Parameter0>Rgui.exe</Parameter0><Parameter1>3.21.2995.0</Parameter1><Parameter2>5582fdbd</Parameter2><Parameter3>ntdll.dll</Parameter3><Parameter4>6.1.7601.23072</Parameter4><Parameter5>556367a3</Parameter5><Parameter6>c0000005</Parameter6><Parameter7>0000000000038a9d</Parameter7></ProblemSignatures><DynamicSignatures><Parameter1>6.1.7601.2.1.0.256.4</Parameter1><Parameter2>1033</Parameter2><Parameter22>6aa4</Parameter22><Parameter23>6aa45dc75f59da5f5623d283480dc6ba</Parameter23><Parameter24>6aa4</Parameter24><Parameter25>6aa45dc75f59da5f5623d283480dc6ba</Parameter25></DynamicSignatures><SystemInformation><MID>75162641-17AE-44E9-83A2-34DF9A0F75D0</MID><SystemManufacturer>Dell
Inc.</SystemManufacturer><SystemProductName>Latitude
E6420</SystemProductName><BIOSVersion>A08</BIOSVersion></SystemInformation></WERReportMetadata>




From goran.brostrom at umu.se  Tue Aug 18 22:46:55 2015
From: goran.brostrom at umu.se (=?windows-1252?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 18 Aug 2015 22:46:55 +0200
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <F016873F-282C-450E-8C0A-5744F36206AA@comcast.net>
References: <1439838652501-4711198.post@n4.nabble.com>	<F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
	<F016873F-282C-450E-8C0A-5744F36206AA@comcast.net>
Message-ID: <55D399BF.7020502@umu.se>



On 2015-08-18 01:44, David Winsemius wrote:
>
> On Aug 17, 2015, at 1:51 PM, David Winsemius wrote:
>
>>
>> On Aug 17, 2015, at 12:10 PM, survivalUser wrote:
>>
>>> Dear All,
>>>
>>> I would like to build a model, based on survival analysis on some
>>> data, that is able to predict the /*expected time until death*/
>>> for a new data instance.
>>
>> Are you sure you want to use life expectancy as the outcome? In
>> order to establish a mathematical expectation  you need to have
>> know the risk at all time in the future, which as pointed out in
>> the print.survfit help page is undefined unless the last
>> observation is a death. Very few datasets support such an estimate.
>> If on the other hand you have sufficient events in the future, then
>> you may be able to more readily justify an estimate of a median
>> survival.
>
> Dear survivalUser;
>
> I've been reminded that you later asked for a parametric model built
> with survreg. The above commentary applies to the coxph models and
> objects and not to survreg objects. If you do have a parametric
> model, even with incomplete observation then calculating life
> expectancy should be a simple matter of plugging the parameters for
> the distribution's mean value, since life-expectancy is the
> statistical mean. So maybe you do want such a modle. The default
> survreg  distribution is "weibull" so just go to your mathematical
> statistics text and look up the formula for the mean of a Weibull
> distribution with the estimated parameters.
>
No need for 'the mathematical statistics text': The necessary 
information is found on the help page for the Weibull distribution: E(T) 
=  b Gamma(1 + 1/a), where 'b' is scale (really!) and 'a' is shape. You 
must however take into account the special parametrization that is used 
by 'survreg'; see its help page for how to do it.

Alternatively, use 'aftreg' in the package 'eha' and get the same 
parametrization as in base  R.

After getting the baseline expectation by the formula above, simply 
multiply that value by exp(-lp) to get the expected life for an 
individual with linear predictor lp.

A useful alternative is simulation (use 'rweibull') or numerical 
integration, especially for estimating remaining expected life 'later in 
life'. And for other distributions than the Weibull.


G?ran Brostr?m
(author of the eha package)


From dwinsemius at comcast.net  Tue Aug 18 22:58:09 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 18 Aug 2015 13:58:09 -0700
Subject: [R] Survival Analysis and Predict time-to-death
In-Reply-To: <1439846291684-4711207.post@n4.nabble.com>
References: <1439838652501-4711198.post@n4.nabble.com>
	<F99EC9F0-BEE7-45F2-8C3C-42848268E223@comcast.net>
	<1439846291684-4711207.post@n4.nabble.com>
Message-ID: <86B9CDE2-4480-48D8-A5C5-F45FCB68CD2C@comcast.net>

It depends on several factors. You need answers to all these questions:  How many events occurred, ... and was the period of observation long enough to cover a significant fraction of the life expectancy, ?. and is there external evidence or theory that will help establish that this process should follow Weibull statistics?

? 
David.

> On Aug 17, 2015, at 2:18 PM, survivalUser <tufanomichele at hotmail.it> wrote:
> 
> Thank you David for your answer.
> 
> Some follow-up questions:
> 
> - So, do you think that try to estimate the life expectancy would be risky
> and probably not justifiable? Is there some sort of 'confidence' that the
> model could give me for a prediction?
> 
> - type=response - I found it here: 
> https://stat.ethz.ch/R-manual/R-devel/library/survival/html/predict.survreg.html
> 
> I have not tried it yet, but I was planning to use that because it says that
> predict the "original scale of the data".
> 
> - Yes, I think they are time-varying predictors. Would you suggest other
> models? (coxph?)
> 
> Overall, do you think this analysis is feasible/correct? Predicting how much
> time a new individual (with those covariates) will be alive till death, is a
> reasonable thing to predict with survival model?
> 
> Thank you again!
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Survival-Analysis-and-Predict-time-to-death-tp4711198p4711207.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j.para.fernandez at hotmail.com  Wed Aug 19 11:08:46 2015
From: j.para.fernandez at hotmail.com (jpara3)
Date: Wed, 19 Aug 2015 02:08:46 -0700 (PDT)
Subject: [R] Confussion matrix in tree clasiffication
Message-ID: <1439975326557-4711269.post@n4.nabble.com>

Hi there!

I want to create a confussion matrix after using the tree package to create
a clasiffication tree, but I?m not sure of how to create this matrix.

Can anyone please help me?

Thanks
Jes?s



-----

Guided Tours Basque Country 

Guided tours in the three capitals of the Basque Country: Bilbao, Vitoria-Gasteiz and San Sebastian, as well as in their provinces. Available languages.

Travel planners for groups and design of tourist routes across the Basque Country.
--
View this message in context: http://r.789695.n4.nabble.com/Confussion-matrix-in-tree-clasiffication-tp4711269.html
Sent from the R help mailing list archive at Nabble.com.


From profjcnash at gmail.com  Wed Aug 19 15:11:25 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Wed, 19 Aug 2015 09:11:25 -0400
Subject: [R] Non linear regression - Von Bertalanffy Growth Function -
 "singular gradient matrix at initial parameter estimates"
In-Reply-To: <55D3587E.7020509@ifremer.fr>
References: <55D3587E.7020509@ifremer.fr>
Message-ID: <55D4807D.4080707@gmail.com>

Packages nlmrt or minpack.lm use a Marquardt method. minpack.lm won't 
proceed if the Jacobian singularity is at the starting point as far as 
I'm aware, but nlxb in nlmrt can sometimes get going. It has a policy 
that is aggressive in trying to improve the sum of squares, so will use 
more effort than nls when both work.

JN

On 15-08-18 12:08 PM, Xochitl CORMON wrote:
> Dear all,
>
> I am trying to estimate VBGF parameters K and Linf using non linear
> regression and nls(). First I used a classic approach where I estimate
> both parameters together as below with "alkdyr" being a subset per year
> of my age-length-key database and running in a loop.
>
> vbgf.par <- nls(Lgtcm ~  Linf *(1 - exp(-K * (Age - tzero))), start =
> c(K= 0.07, Linf = 177.1), data=alkdyr)
>
> I obtain an estimation of both parameters that are strongly correlated.
> Indeed after plotting Linf ~ K and fitting a linear regression I obtain
> a function (Linf = a + b*K) with R2= 0.8 and a = 215, b = -763.
>
> In this context, to take into account explicitly correlation between
> parameters, I decided to fit a new non linear regression derivate from
> VBGF but where Linf is expressed depending on K (I am most interested in
> K). To do so, I tried this model:
> vbgf.par <- nls(Lgtcm ~  (a + (b*k)) *(1 - exp(-k * (Age - tzero))),
> start = c(k= 0.07, a= 215, b=-763), data=alkdyr)
>
> Unfortunately at this point I cannot go further as I get the error
> message "singular gradient matrix at initial parameter estimates".
>
> I tried to use alg= plinear (which I am not sure I understand properly
> yet). If I give a starting value for a and b only, I have an error
> message stating "step factor below minFactor" (even when minFactor is
> set to 100000000000).
>
> Any help will be more than welcome as this is quite urgent....
>
> Best,
>
> Xochitl C.
>
>
>
>


From dcarlson at tamu.edu  Wed Aug 19 15:28:41 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 19 Aug 2015 13:28:41 +0000
Subject: [R] Confussion matrix in tree clasiffication
In-Reply-To: <1439975326557-4711269.post@n4.nabble.com>
References: <1439975326557-4711269.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B7991@mb02.ads.tamu.edu>

Use predict.tree() with type="class" on the object returned by tree(). Then use that to construct a cross tabulation against the original data. If you provide a reproducible example with data, I could be more specific.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of jpara3
Sent: Wednesday, August 19, 2015 4:09 AM
To: r-help at r-project.org
Subject: [R] Confussion matrix in tree clasiffication

Hi there!

I want to create a confussion matrix after using the tree package to create
a clasiffication tree, but I?m not sure of how to create this matrix.

Can anyone please help me?

Thanks
Jes?s



-----

Guided Tours Basque Country 

Guided tours in the three capitals of the Basque Country: Bilbao, Vitoria-Gasteiz and San Sebastian, as well as in their provinces. Available languages.

Travel planners for groups and design of tourist routes across the Basque Country.
--
View this message in context: http://r.789695.n4.nabble.com/Confussion-matrix-in-tree-clasiffication-tp4711269.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From yfong at fhcrc.org  Wed Aug 19 02:42:29 2015
From: yfong at fhcrc.org (Youyi Fong)
Date: Tue, 18 Aug 2015 17:42:29 -0700
Subject: [R] match.arg: how to prevent users from not specifying a value
Message-ID: <CAA4m0GYRHqWC1hp7FQi4JoYKfg3dk_E+RuW_2KRzFZAC+=ZdcQ@mail.gmail.com>

Hello, I have a function that looks like

f=function( type=c("dummy,"A","B,"C"), ... ) {
    type<-match.arg(type)
    if (type=="dummy") stop("Please choose a type that is not dummy.")
    ...
}

I put a "dummy" in the list of choices as a mechanism to prevent users
from not specifying a value for "type" when calling the function. My
question is whether there is a better way to achieve it that does not
need "dummy".

Thanks,
Youyi


From aruna.sudarshan at gmail.com  Wed Aug 19 07:29:54 2015
From: aruna.sudarshan at gmail.com (aruna sudarshan)
Date: Wed, 19 Aug 2015 01:29:54 -0400
Subject: [R] repeated measures anova equivalent using lmer
Message-ID: <CAGA5bS_1eu0httLr9Sdpb5M3aypfUcmxD3tGrd1U7MVECkjHhA@mail.gmail.com>

I am trying to run a linear mixed effects model similar to the 2*2*2 anova
design. My DV is reaction time and fixed factors are time (pre vs.
post:within-subject), condition (congruent vs. incongruent: within subject)
and stimulation (vertex vs. DLPFC: between subject)
My concerns are:
a)I have very few participants: 7 in the vertex condition and 7 in the
DLPFC condition.
b)2 out of the 7 participants participated in both vertex and DLPFC
condition.
 How do I compute a nested lmer model with reaction time as DV and time,
condition and stimulation as factors? and how do i account for random
intercepts and slopes with few number of participants?
Thanks for all the help

	[[alternative HTML version deleted]]


From aruna.sudarshan at gmail.com  Wed Aug 19 07:30:13 2015
From: aruna.sudarshan at gmail.com (asudar)
Date: Tue, 18 Aug 2015 22:30:13 -0700 (PDT)
Subject: [R] equivalent of repeated measures anova using lmer
Message-ID: <CAGA5bS9UXhr3RbkXpcyYJg81gHOvT8y7FTtyJytoO9fD1y=w+w@mail.gmail.com>

I am trying to run a linear mixed effects model similar to the 2*2*2 anova
design. My DV is reaction time and fixed factors are time (pre vs.
post:within-subject), condition (congruent vs. incongruent: within subject)
and stimulation (vertex vs. DLPFC: between subject)
My concerns are:
a)I have very few participants: 7 in the vertex condition and 7 in the
DLPFC condition.
b)2 out of the 7 participants participated in both vertex and DLPFC
condition.
 How do I compute a nested lmer model with reaction time as DV and time,
condition and stimulation as factors? and how do i account for random
intercepts and slopes with few number of participants?
Thanks for all the help




--
View this message in context: http://r.789695.n4.nabble.com/equivalent-of-repeated-measures-anova-using-lmer-tp4711265.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From valentin.cojocaru at hotmail.com  Wed Aug 19 09:23:42 2015
From: valentin.cojocaru at hotmail.com (Valentin Cojocaru)
Date: Wed, 19 Aug 2015 10:23:42 +0300
Subject: [R] html posts tags remove home page
Message-ID: <DUB131-W50C15818A6F780AC78A954EE670@phx.gbl>

In html,
How to remove posts from one category displaying on the home page by using tags.
Thanks,Valentin 		 	   		  
	[[alternative HTML version deleted]]


From consultant at logiccorp.com  Wed Aug 19 13:47:36 2015
From: consultant at logiccorp.com (chappo007)
Date: Wed, 19 Aug 2015 04:47:36 -0700 (PDT)
Subject: [R] Plot z=f(x,y) analytically
Message-ID: <1439984856689-4711272.post@n4.nabble.com>

Hi,

I've been led to believe that in R  it is possible to produce a 3d
analytical plot of a function.  I've been pointed in the direction of
plot3d(), so the command is something like
plot3d(x^2+y^2,(x,-3,3),(y,-3,3)).  And a smart person out there is going to
tell me where this syntax comes from (or belongs to), there is also a R
package called MapleSoft ( I believe) which is commercial, and there is
always Mathematica.  So is there a R function to plot z=f(x,y) without
obtain or generating data.

Cheers,
Mike



--
View this message in context: http://r.789695.n4.nabble.com/Plot-z-f-x-y-analytically-tp4711272.html
Sent from the R help mailing list archive at Nabble.com.


From Luis.Diaz at tecnocom.es  Wed Aug 19 14:11:14 2015
From: Luis.Diaz at tecnocom.es (Diaz Garcia, Luis Carlos)
Date: Wed, 19 Aug 2015 12:11:14 +0000
Subject: [R] Rodbc retrieve data
Message-ID: <DB5PR03MB125372CBEB9D39074BFC89A5EB670@DB5PR03MB1253.eurprd03.prod.outlook.com>

Hi every one
first I would like to introduce myself, as I'm new here.
I'm Luis from Barcelona, I'm Oracle dba and I need to create some nice
graphs.
So, I was looking for a solution and I saw R...

I think it's a good tool to make the task I need.

So here is the task: I need to get all the dblink from one database and draw
the result of the query.
The dblink will have the origin database name, the destination, the name of
the link the type too.
So I look into the R doc and I saw the way to get the data from my database:

library("RODBC")
con <- odbcConnect("DPL03", uid="myuser", pwd="mypass",believeNRows=FALSE )
dbName <- sqlQuery(con, "SELECT instance_name from v$instance",errors=FALSE)

Now I have dbName with one value, the name of my instance, but I don't know
how to insert this data into this:

plot.new()
title (main ="Map of the dbLinks of the database",sub="Luis Diaz -
Emergencies & improvments")


As you see, I create a screen to plot where I'll draw shapes and lines but
the first issue is to insert here the name of my instance, but I can't.
I try to concatenate like this:

title (main ="Mapa de los dblinks del entorno: " + dbName ,sub="Luis Diaz -
Emergencies & improvments")


But I have an error, and if I use print(dbName) the value is printed but
outside of the plot.new() screen.
Some one can help ?
Thanks in advance !

Cheers


From swagato1987 at gmail.com  Wed Aug 19 00:12:45 2015
From: swagato1987 at gmail.com (Swagato Chatterjee)
Date: Wed, 19 Aug 2015 03:42:45 +0530
Subject: [R] Running R in Server
In-Reply-To: <CAK1hC9tNgn9Tpc-rus2RYmzaRhLsaMe01rHb1XX4wNyoHiM-qQ@mail.gmail.com>
References: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>
	<CAK1hC9tNgn9Tpc-rus2RYmzaRhLsaMe01rHb1XX4wNyoHiM-qQ@mail.gmail.com>
Message-ID: <CACruXesG4yPqrW9WhbzL_V9v8uiRUwA9Qhnx+DQUjwtMj-DChw@mail.gmail.com>

Dear all,

Thenks for replying to my query.

*@Amaud: If I understand correctly what you want to do, you might be able
to create a HTML report using RMarkdown and host that on the website.  If
you really need a web app, I suggest looking into Shiny.  You can make a
shiny app, host it for free on the cloud.  You will have a lot to learn,
but it will be time well spent.  https://www.rstudio.com/
<https://www.rstudio.com/>*

Obviously I have shiny as an option.But I was thinking PHP based GUI is a
better fit for me as I have very limited resources in my team who can
create a Shiny app and implement it with the all the functionalities of a
PHP based GUI.

*Have a look at deployR on Revolutioanalytic website. There is a free
open-source solution for windows.*

I'll check this.

*@John: Statement: You have a Windows desktop and have used R on it, so you
are familiar with R in a Windows environment.?*
*Statement: You are not Linux (Ubuntu) trained.*
*Statement: You wrote an R script on Windows, which works, but you need to
run it on Ubuntu.*

*The above is my starting point. Now I have some questions.*

*Can you connect to the Ubuntu server from your Windows desktop? If so,
how? If not, I'm confused about how you could get anything to run on the
Ubuntu server.*

My developer has given me an username and password which I can use to
connect the server using Putty. The GUI is being developed in Ubuntu server
only using PHP and my the results of my RScript (figures and tables) will
be the input of the GUI. Having said that, I have limited knowledge how to
implement the R and run the script in server after loggin in to the server.

*Where does this "dataset" reside? On you desktop? On a Windows shared
folder? On the Ubuntu server? Other?*

Right now, on my desktop. But soon the dataset will be residing on a server.

*Who or what edits the "dataset"? That is, is it always yourself? Some one
in your group? Some other human? Some automated process?*

The input data of my Rscript again comes from another app and the database
is also residing on the same server. The update of the dataset is being
done by the app automatically.

*Why can't you run the R script as you do now, then deploy the results to
the Ubuntu server? Since I don't know the environment that the Ubuntu
server runs in, I can't address how to deploy an updated file into it. I
assume you have some sort of deployment software. It could be as easy as
being able to ftp the results from your desktop to the proper places on the
Ubuntu server.*

I cannot run the R script as I do now because the Rscript will also be
called for automatically so that the results of the Rscript go as an input
to the end app. PFA the architecture picture.

*@Loris: However, you'll probably have to make sure that all the packages
you*
*need are installed on the server.*

This is where I need a help.?

Thanks and Regards,

Swagato

From robertzimbardo at gmail.com  Wed Aug 19 02:49:43 2015
From: robertzimbardo at gmail.com (Robert Zimbardo)
Date: Tue, 18 Aug 2015 17:49:43 -0700
Subject: [R] =?utf-8?q?Error_message_from_allEffects=28model=29_/_effect?=
	=?utf-8?b?KG1vZGVsKSIg4oCYcmFuZ2XigJkgbm90IG1lYW5pbmdmdWwgZm9yIGZh?=
	=?utf-8?q?ctors=22?=
Message-ID: <CAGJyvhGGPXBCs2rkab+RZDAOxRE30srDcUo-bdPM4mLH6bOyyQ@mail.gmail.com>

Hi

I cannot figure out why the effects package throws me error messages
with the following simple code:


rm(list=ls(all=TRUE)); set.seed(1); library(effects)
# set up data
x <- factor(rep(letters[1:3], each=100))
y <- c(rnorm(100, 3, 3), rnorm(100, 4, 3), rnorm(100, 5, 3))


# fit linear model
m <- summary(lm(y~x)) # no problem

# now the problem
plot(allEffects(m))
# Error in Summary.factor(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,  :
#   ?range? not meaningful for factors
plot(effect("x", m))
# Error in Summary.factor(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,  :
#   ?range? not meaningful for factors


Any ideas? It's go to be something superobvious, but I don't get it. Thanks,
RZ


From shivibhatia at ymail.com  Wed Aug 19 07:10:52 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Tue, 18 Aug 2015 22:10:52 -0700 (PDT)
Subject: [R] Output In R
In-Reply-To: <A3F4CC15-F8CD-4327-88CE-740F78DCC6DF@utoronto.ca>
References: <1439901681930-4711227.post@n4.nabble.com>
	<A3F4CC15-F8CD-4327-88CE-740F78DCC6DF@utoronto.ca>
Message-ID: <1439961052449-4711263.post@n4.nabble.com>

HI Boris,

The reason i want to see or show 3 million rows in console is that i need to
present it to a business user. 

So here my end objective is to present the final output to the business
user. So lets say when i write a code:
select(june,waybill:type,contains("sfxcode")) so here there could be
multiple instances where sfx code could appear which will not accommodate in
console. I tried using max print option and increased to (max.print=999999)
but still only shows few rows of data. 

What other option to i have. Thanks. 



--
View this message in context: http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711263.html
Sent from the R help mailing list archive at Nabble.com.


From shivibhatia at ymail.com  Wed Aug 19 07:20:25 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Tue, 18 Aug 2015 22:20:25 -0700 (PDT)
Subject: [R] Output In R
In-Reply-To: <871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
References: <1439901681930-4711227.post@n4.nabble.com>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <1439961625598-4711264.post@n4.nabble.com>

Hi Loris,

I have already tried options(max.print=999999) but does not show the desired
result. 
As posted above it want to share the outcome with the business owner where
there could be multiple entries. 





--
View this message in context: http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711264.html
Sent from the R help mailing list archive at Nabble.com.


From minikg at cmfri.org.in  Wed Aug 19 16:29:17 2015
From: minikg at cmfri.org.in (minikg)
Date: Wed, 19 Aug 2015 07:29:17 -0700 (PDT)
Subject: [R] data format
Message-ID: <1439994557446-4711278.post@n4.nabble.com>

Hi,

I have a dataset consisting of landmarks of each sample's  coordinates as
given below. 

landmark	X	Y	X	Y	X	Y
P1	       5	34	7	26	7	32
P2	     46	45	48	42	44	48
P3	     73	45	72	44	71	46
P4	     92	43	90	43	89	42


please help me to change my data format to

sample	p1x1	p1y1	p2x2	p2y2	p3x3	p3y3	p4x4	p4y4
1	       5	34	46	45	73	45	92	43
2	       7	26	48	42	72	44	90	43
3	       7	32	44	48	71	46	89	42

Thanks 




--
View this message in context: http://r.789695.n4.nabble.com/data-format-tp4711278.html
Sent from the R help mailing list archive at Nabble.com.


From erich.neuwirth at univie.ac.at  Wed Aug 19 17:52:07 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Wed, 19 Aug 2015 17:52:07 +0200
Subject: [R] data format
In-Reply-To: <1439994557446-4711278.post@n4.nabble.com>
References: <1439994557446-4711278.post@n4.nabble.com>
Message-ID: <BB014847-3D13-4C79-A3B8-E2E1F5F33C26@univie.ac.at>

This is the kind of problem the package tidyR has been designed for.

> On 19 Aug 2015, at 16:29, minikg <minikg at cmfri.org.in> wrote:
> 
> Hi,
> 
> I have a dataset consisting of landmarks of each sample's  coordinates as
> given below.
> 
> landmark	X	Y	X	Y	X	Y
> P1	       5	34	7	26	7	32
> P2	     46	45	48	42	44	48
> P3	     73	45	72	44	71	46
> P4	     92	43	90	43	89	42
> 
> 
> please help me to change my data format to
> 
> sample	p1x1	p1y1	p2x2	p2y2	p3x3	p3y3	p4x4	p4y4
> 1	       5	34	46	45	73	45	92	43
> 2	       7	26	48	42	72	44	90	43
> 3	       7	32	44	48	71	46	89	42
> 
> Thanks
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/data-format-tp4711278.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150819/a816581f/attachment.bin>

From jfox at mcmaster.ca  Wed Aug 19 17:55:10 2015
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 19 Aug 2015 11:55:10 -0400
Subject: [R]
	=?utf-8?q?Error_message_from_allEffects=28model=29_/_effect?=
	=?utf-8?b?KG1vZGVsKSIg4oCYcmFuZ2XigJkgbm90IG1lYW5pbmdmdWwgZm9yIGZh?=
	=?utf-8?q?ctors=22?=
In-Reply-To: <CAGJyvhGGPXBCs2rkab+RZDAOxRE30srDcUo-bdPM4mLH6bOyyQ@mail.gmail.com>
References: <CAGJyvhGGPXBCs2rkab+RZDAOxRE30srDcUo-bdPM4mLH6bOyyQ@mail.gmail.com>
Message-ID: <002f01d0da97$6dddbe70$49993b50$@mcmaster.ca>

Hi,

> m <- lm(y~x) # no problem

> allEffects(m)# also no problem
 model: y ~ x

 x effect
x
       a        b        c 
3.322448 3.830997 4.969154

> effect("x", m) # ditto

 x effect
x
       a        b        c 
3.322448 3.830997 4.969154 

> Effect("x", m) # ditto

 x effect
x
       a        b        c 
3.322448 3.830997 4.969154

Best,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert
> Zimbardo
> Sent: Tuesday, August 18, 2015 8:50 PM
> To: r-help at r-project.org
> Subject: [R] Error message from allEffects(model) / effect(model)"
> ?range? not meaningful for factors"
> 
> Hi
> 
> I cannot figure out why the effects package throws me error messages
> with the following simple code:
> 
> 
> rm(list=ls(all=TRUE)); set.seed(1); library(effects)
> # set up data
> x <- factor(rep(letters[1:3], each=100))
> y <- c(rnorm(100, 3, 3), rnorm(100, 4, 3), rnorm(100, 5, 3))
> 
> 
> # fit linear model
> m <- summary(lm(y~x)) # no problem
> 
> # now the problem
> plot(allEffects(m))
> # Error in Summary.factor(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> :
> #   ?range? not meaningful for factors
> plot(effect("x", m))
> # Error in Summary.factor(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> :
> #   ?range? not meaningful for factors
> 
> 
> Any ideas? It's go to be something superobvious, but I don't get it.
> Thanks,
> RZ
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Wed Aug 19 17:54:53 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Wed, 19 Aug 2015 15:54:53 +0000
Subject: [R] Rodbc retrieve data
In-Reply-To: <DB5PR03MB125372CBEB9D39074BFC89A5EB670@DB5PR03MB1253.eurprd03.prod.outlook.com>
References: <DB5PR03MB125372CBEB9D39074BFC89A5EB670@DB5PR03MB1253.eurprd03.prod.outlook.com>
Message-ID: <49691A5A-A1DB-4CD9-8D26-86C5ECE17DA2@txbiomed.org>

Diaz,

paste() and paste0() will work here. paste0() defaults to "" between character vector elements and paste() defaults to " " (single blank character) between character vector elements. See ?paste.

I do not recall, but you may have to escape the "&" symbol, but that is another topic.

Try this.

title (main = paste0("Mapa de los dblinks del entorno: ", dbName),sub="Luis Diaz -
Emergencies & improvments")

Mark
P.S. Spelling correction - "improvements"

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Aug 19, 2015, at 7:11 AM, Diaz Garcia, Luis Carlos <Luis.Diaz at tecnocom.es> wrote:
> 
> Hi every one
> first I would like to introduce myself, as I'm new here.
> I'm Luis from Barcelona, I'm Oracle dba and I need to create some nice
> graphs.
> So, I was looking for a solution and I saw R...
> 
> I think it's a good tool to make the task I need.
> 
> So here is the task: I need to get all the dblink from one database and draw
> the result of the query.
> The dblink will have the origin database name, the destination, the name of
> the link the type too.
> So I look into the R doc and I saw the way to get the data from my database:
> 
> library("RODBC")
> con <- odbcConnect("DPL03", uid="myuser", pwd="mypass",believeNRows=FALSE )
> dbName <- sqlQuery(con, "SELECT instance_name from v$instance",errors=FALSE)
> 
> Now I have dbName with one value, the name of my instance, but I don't know
> how to insert this data into this:
> 
> plot.new()
> title (main ="Map of the dbLinks of the database",sub="Luis Diaz -
> Emergencies & improvments")
> 
> 
> As you see, I create a screen to plot where I'll draw shapes and lines but
> the first issue is to insert here the name of my instance, but I can't.
> I try to concatenate like this:
> 
> title (main ="Mapa de los dblinks del entorno: " + dbName ,sub="Luis Diaz -
> Emergencies & improvments")
> 
> 
> But I have an error, and if I use print(dbName) the value is printed but
> outside of the plot.new() screen.
> Some one can help ?
> Thanks in advance !
> 
> Cheers
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Wed Aug 19 17:57:30 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 19 Aug 2015 16:57:30 +0100
Subject: [R]
 =?utf-8?q?Error_message_from_allEffects=28model=29_/_effect?=
 =?utf-8?b?KG1vZGVsKSIg4oCYcmFuZ2XigJkgbm90IG1lYW5pbmdmdWwgZm9yIGZhY3Rv?=
 =?utf-8?b?cnMi?=
In-Reply-To: <CAGJyvhGGPXBCs2rkab+RZDAOxRE30srDcUo-bdPM4mLH6bOyyQ@mail.gmail.com>
References: <CAGJyvhGGPXBCs2rkab+RZDAOxRE30srDcUo-bdPM4mLH6bOyyQ@mail.gmail.com>
Message-ID: <55D4A76A.1060306@dewey.myzen.co.uk>

You rm is of class summary.lm
Is that what allEffects is expecting?

On 19/08/2015 01:49, Robert Zimbardo wrote:
> Hi
>
> I cannot figure out why the effects package throws me error messages
> with the following simple code:
>
>
> rm(list=ls(all=TRUE)); set.seed(1); library(effects)
> # set up data
> x <- factor(rep(letters[1:3], each=100))
> y <- c(rnorm(100, 3, 3), rnorm(100, 4, 3), rnorm(100, 5, 3))
>
>
> # fit linear model
> m <- summary(lm(y~x)) # no problem
>
> # now the problem
> plot(allEffects(m))
> # Error in Summary.factor(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,  :
> #   ?range? not meaningful for factors
> plot(effect("x", m))
> # Error in Summary.factor(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,  :
> #   ?range? not meaningful for factors
>
>
> Any ideas? It's go to be something superobvious, but I don't get it. Thanks,
> RZ
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From wdunlap at tibco.com  Wed Aug 19 18:19:00 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 19 Aug 2015 09:19:00 -0700
Subject: [R] match.arg: how to prevent users from not specifying a value
In-Reply-To: <CAA4m0GYRHqWC1hp7FQi4JoYKfg3dk_E+RuW_2KRzFZAC+=ZdcQ@mail.gmail.com>
References: <CAA4m0GYRHqWC1hp7FQi4JoYKfg3dk_E+RuW_2KRzFZAC+=ZdcQ@mail.gmail.com>
Message-ID: <CAF8bMca_4h2xkU5vtVUBN8CrwLZJ4OtZ54rafmcp-VgHdG_qXw@mail.gmail.com>

If you want to force the user to enter the 'type' argument,
move the vector of choices out of the argument list
and into the call to match.arg():

   f1 <- function(type, ...) {
       match.arg(type, c("A", "B", "C"))
   }
   f1()
   #Error in match.arg(type, c("A", "B", "C")) :
   #  argument "type" is missing, with no default
   f1("X")
   #Error in match.arg(type, c("A", "B", "C")) :
   #  'arg' should be one of ?A?, ?B?, ?C?
   f1("B")
   #[1] "B"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Aug 18, 2015 at 5:42 PM, Youyi Fong <yfong at fhcrc.org> wrote:

> Hello, I have a function that looks like
>
> f=function( type=c("dummy,"A","B,"C"), ... ) {
>     type<-match.arg(type)
>     if (type=="dummy") stop("Please choose a type that is not dummy.")
>     ...
> }
>
> I put a "dummy" in the list of choices as a mechanism to prevent users
> from not specifying a value for "type" when calling the function. My
> question is whether there is a better way to achieve it that does not
> need "dummy".
>
> Thanks,
> Youyi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Aug 19 18:19:56 2015
From: jholtman at gmail.com (jim holtman)
Date: Wed, 19 Aug 2015 12:19:56 -0400
Subject: [R] Output In R
In-Reply-To: <1439961625598-4711264.post@n4.nabble.com>
References: <1439901681930-4711227.post@n4.nabble.com>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
Message-ID: <CAAxdm-4p1Vpz-6LuiCMtTRfv_Z7213juH7kxX8Z-2ZuqKpF0Tw@mail.gmail.com>

At least provide a sample of the data and then the desired output.  All we
get from your email is that it "does not show the desired result" and we
are at a lost to understand what that is.  I know it was suggested that you
write it out as a CSV file and then you can use EXCEL to page through the
data.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Aug 19, 2015 at 1:20 AM, Shivi82 <shivibhatia at ymail.com> wrote:

> Hi Loris,
>
> I have already tried options(max.print=999999) but does not show the
> desired
> result.
> As posted above it want to share the outcome with the business owner where
> there could be multiple entries.
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711264.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Aug 19 18:35:15 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 19 Aug 2015 09:35:15 -0700
Subject: [R] match.arg: how to prevent users from not specifying a value
In-Reply-To: <CAF8bMca_4h2xkU5vtVUBN8CrwLZJ4OtZ54rafmcp-VgHdG_qXw@mail.gmail.com>
References: <CAA4m0GYRHqWC1hp7FQi4JoYKfg3dk_E+RuW_2KRzFZAC+=ZdcQ@mail.gmail.com>
	<CAF8bMca_4h2xkU5vtVUBN8CrwLZJ4OtZ54rafmcp-VgHdG_qXw@mail.gmail.com>
Message-ID: <CAGxFJbSnu10s+6NiCtNQTV6e9Htn40HSopTKK2YShrYCCZTGmg@mail.gmail.com>

... and you could also use missing() (?missing for details) if you
wanted to give the user more verbose instructions, e.g.

   f1 <- function(type, ...) {
       if(missing(type)){
       cat("You must enter a 'type' argument that is one of etc....\n")
       return(invisible())
       }
       match.arg(type, c("A", "B", "C"))
   }
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Wed, Aug 19, 2015 at 9:19 AM, William Dunlap <wdunlap at tibco.com> wrote:
> If you want to force the user to enter the 'type' argument,
> move the vector of choices out of the argument list
> and into the call to match.arg():
>
>    f1 <- function(type, ...) {
>        match.arg(type, c("A", "B", "C"))
>    }
>    f1()
>    #Error in match.arg(type, c("A", "B", "C")) :
>    #  argument "type" is missing, with no default
>    f1("X")
>    #Error in match.arg(type, c("A", "B", "C")) :
>    #  'arg' should be one of ?A?, ?B?, ?C?
>    f1("B")
>    #[1] "B"
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Aug 18, 2015 at 5:42 PM, Youyi Fong <yfong at fhcrc.org> wrote:
>
>> Hello, I have a function that looks like
>>
>> f=function( type=c("dummy,"A","B,"C"), ... ) {
>>     type<-match.arg(type)
>>     if (type=="dummy") stop("Please choose a type that is not dummy.")
>>     ...
>> }
>>
>> I put a "dummy" in the list of choices as a mechanism to prevent users
>> from not specifying a value for "type" when calling the function. My
>> question is whether there is a better way to achieve it that does not
>> need "dummy".
>>
>> Thanks,
>> Youyi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Aug 19 18:54:43 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 19 Aug 2015 09:54:43 -0700
Subject: [R] html posts tags remove home page
In-Reply-To: <DUB131-W50C15818A6F780AC78A954EE670@phx.gbl>
References: <DUB131-W50C15818A6F780AC78A954EE670@phx.gbl>
Message-ID: <3929501E-69EB-4440-A6BD-0BC2F9493560@dcn.davis.CA.us>

This is a mailing list on the topic of R. Your email does not appear to be related to that topic, so either look for a different mailing list/web forum where your question would be on topic, or provide a concrete example of your problem. If you do post here again, please use plain text format since the HTML formatting produced by default from your email program corrupts most examples.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 19, 2015 12:23:42 AM PDT, Valentin Cojocaru <valentin.cojocaru at hotmail.com> wrote:
>In html,
>How to remove posts from one category displaying on the home page by
>using tags.
>Thanks,Valentin 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From joaquin.aldabe at gmail.com  Wed Aug 19 17:54:10 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Wed, 19 Aug 2015 12:54:10 -0300
Subject: [R] glm help
Message-ID: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>

Dear All, I?m running a glm with poisson errors and have a doubt when
ploting the predicted values. One of my variables has a positive slope in
the summary output, but when I plot the predicted values on the original
plot it draws a line with negative slope. I appreciate your comments on
this and any other aspect of the analysis.

Attached is the script and data in different formats just in case.

Thanks in advanced,

Joaqu?n.


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
-------------- next part --------------
my4<-read.table(file.choose(), header=T, dec=",")
my4s<-as.data.frame(scale(my4[,c(6,10,12,13,16)], center=T, scale=T))
my4S<-cbind(BBSA=my4$BBSA, Field_name=my4$Field_name,Grassland_type=my4$Grassland_type, Flood=my4$Flood, Year=my4$Year,my4s)

m2.glm=glm(BBSA~AMGP+Distance_to_lagoon+Grass_height, family="quasipoisson", data=my4S
summary(m2.glm)
#residuales
par(mfrow=c(2,2))
plot(m2.glm)#pretty good

#predict
amgp=seq(-0.51, 5.44, length.out=100)
grass=seq(-0.85,2.83, length.out=100)
dist=seq(-1.59,1.53, length.out=100)
newdata=data.frame(AMGP=amgp, Distance_to_lagoon=dist,Grass_height=grass)
pred.m2.glm=exp(predict(m2.glm,newdata))
plot(BBSA~Grass_height, data=my4S)
lines(newdata$Grass_height,pred.m2.glm)
plot(BBSA~AMGP, data=my4S)
lines(newdata$AMGP,pred.m2.glm)#why negative slope if summary output is positive
plot(BBSA~Distance_to_lagoon, data=my4S)
lines(newdata$Distance_to_lagoon, pred.m2.glm)

From yfong at fhcrc.org  Wed Aug 19 18:54:39 2015
From: yfong at fhcrc.org (Youyi Fong)
Date: Wed, 19 Aug 2015 09:54:39 -0700
Subject: [R] match.arg: how to prevent users from not specifying a value
In-Reply-To: <CAGxFJbSnu10s+6NiCtNQTV6e9Htn40HSopTKK2YShrYCCZTGmg@mail.gmail.com>
References: <CAA4m0GYRHqWC1hp7FQi4JoYKfg3dk_E+RuW_2KRzFZAC+=ZdcQ@mail.gmail.com>
	<CAF8bMca_4h2xkU5vtVUBN8CrwLZJ4OtZ54rafmcp-VgHdG_qXw@mail.gmail.com>
	<CAGxFJbSnu10s+6NiCtNQTV6e9Htn40HSopTKK2YShrYCCZTGmg@mail.gmail.com>
Message-ID: <CAA4m0Gbn3TK0BPhNpByoRHkpz8WwuWDaRZrNH4uSAKJWO3cA5w@mail.gmail.com>

Great. missing is what I was looking for, and it seems to also work
with interfaces like

f=function( type=c("A","B,"C"), ... ) {
}

Thanks!
Youyi



On Wed, Aug 19, 2015 at 9:35 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ... and you could also use missing() (?missing for details) if you
> wanted to give the user more verbose instructions, e.g.
>
>    f1 <- function(type, ...) {
>        if(missing(type)){
>        cat("You must enter a 'type' argument that is one of etc....\n")
>        return(invisible())
>        }
>        match.arg(type, c("A", "B", "C"))
>    }
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Wed, Aug 19, 2015 at 9:19 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> If you want to force the user to enter the 'type' argument,
>> move the vector of choices out of the argument list
>> and into the call to match.arg():
>>
>>    f1 <- function(type, ...) {
>>        match.arg(type, c("A", "B", "C"))
>>    }
>>    f1()
>>    #Error in match.arg(type, c("A", "B", "C")) :
>>    #  argument "type" is missing, with no default
>>    f1("X")
>>    #Error in match.arg(type, c("A", "B", "C")) :
>>    #  'arg' should be one of ?A?, ?B?, ?C?
>>    f1("B")
>>    #[1] "B"
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Tue, Aug 18, 2015 at 5:42 PM, Youyi Fong <yfong at fhcrc.org> wrote:
>>
>>> Hello, I have a function that looks like
>>>
>>> f=function( type=c("dummy,"A","B,"C"), ... ) {
>>>     type<-match.arg(type)
>>>     if (type=="dummy") stop("Please choose a type that is not dummy.")
>>>     ...
>>> }
>>>
>>> I put a "dummy" in the list of choices as a mechanism to prevent users
>>> from not specifying a value for "type" when calling the function. My
>>> question is whether there is a better way to achieve it that does not
>>> need "dummy".
>>>
>>> Thanks,
>>> Youyi
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Wed Aug 19 19:26:55 2015
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 19 Aug 2015 11:26:55 -0600
Subject: [R] Plot z=f(x,y) analytically
In-Reply-To: <1439984856689-4711272.post@n4.nabble.com>
References: <1439984856689-4711272.post@n4.nabble.com>
Message-ID: <CAFEqCdwcpq1vh_8Qad7XYKwV7LXeDEPJNRcyhso4grZOqxNcBg@mail.gmail.com>

R has several options for projecting a 3 dimensional plot onto a 2
dimensional plane and plotting the result.  Which is best depends on
what you want.

You mention a function "plot3d" but not which package it comes from.
You are more likely to receive prompt and useful help when you do your
part of the homework and tell us which package it is from (it is not
in the default packages).  In fact, with a name like that, there could
easily be more than one package with a function of that name and if we
tell you how to use the function from a different package than you are
using then the "help" will probably be more confusing than helpful.

In base R you can use functions like persp, image, and contour (after
using a function like outer), the help pages have examples.

If you load the lattice package then you can use wireframe, levelplot,
or contourplot, again the help pages have examples.

The TeachingDemos package has functions rotate.persp and
rotate.wireframe that create an interactive interface to the
corresponding plots.

The help page for the plot3d function in the RGL package (one likely
candidate for the function you mentioned) points to the
plot3d.function function in the "See Also" section which has examples
that you could plug your function into.

On Wed, Aug 19, 2015 at 5:47 AM, chappo007 <consultant at logiccorp.com> wrote:
> Hi,
>
> I've been led to believe that in R  it is possible to produce a 3d
> analytical plot of a function.  I've been pointed in the direction of
> plot3d(), so the command is something like
> plot3d(x^2+y^2,(x,-3,3),(y,-3,3)).  And a smart person out there is going to
> tell me where this syntax comes from (or belongs to), there is also a R
> package called MapleSoft ( I believe) which is commercial, and there is
> always Mathematica.  So is there a R function to plot z=f(x,y) without
> obtain or generating data.
>
> Cheers,
> Mike
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Plot-z-f-x-y-analytically-tp4711272.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dcarlson at tamu.edu  Wed Aug 19 19:58:26 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 19 Aug 2015 17:58:26 +0000
Subject: [R] data format
In-Reply-To: <1439994557446-4711278.post@n4.nabble.com>
References: <1439994557446-4711278.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B7B7F@mb02.ads.tamu.edu>

This looks like data for a morphometrics analysis so you should know about package geomorph. Data like yours is often stored as a three dimensional array so we switch to that format and then use the two.d.array() function in package geomorph:

Assuming your dataset is called dat: 

> arr <- array(as.matrix(dat[, -1]), dim=c(4, 2, 3))
> library(geomorph)
> mat <- two.d.array(arr)
> colnames(mat) <- paste0("p", rep(1:4, each=2), 
+      rep(c("x", "y"), 4), rep(1:4, each=2))
> mat
     p1x1 p1y1 p2x2 p2y2 p3x3 p3y3 p4x4 p4y4
[1,]    5   34   46   45   73   45   92   43
[2,]    7   26   48   42   72   44   90   43
[3,]    7   32   44   48   71   46   89   42
> dat2 <- data.frame(sample=1:3, mat)
> dat2
  sample p1x1 p1y1 p2x2 p2y2 p3x3 p3y3 p4x4 p4y4
1      1    5   34   46   45   73   45   92   43
2      2    7   26   48   42   72   44   90   43
3      3    7   32   44   48   71   46   89   42


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of minikg
Sent: Wednesday, August 19, 2015 9:29 AM
To: r-help at r-project.org
Subject: [R] data format

Hi,

I have a dataset consisting of landmarks of each sample's  coordinates as
given below. 

landmark	X	Y	X	Y	X	Y
P1	       5	34	7	26	7	32
P2	     46	45	48	42	44	48
P3	     73	45	72	44	71	46
P4	     92	43	90	43	89	42


please help me to change my data format to

sample	p1x1	p1y1	p2x2	p2y2	p3x3	p3y3	p4x4	p4y4
1	       5	34	46	45	73	45	92	43
2	       7	26	48	42	72	44	90	43
3	       7	32	44	48	71	46	89	42

Thanks 




--
View this message in context: http://r.789695.n4.nabble.com/data-format-tp4711278.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Aug 19 20:16:35 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 19 Aug 2015 18:16:35 +0000
Subject: [R] Plot z=f(x,y) analytically
In-Reply-To: <1439984856689-4711272.post@n4.nabble.com>
References: <1439984856689-4711272.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B7BD3@mb02.ads.tamu.edu>

You probably want function persp3d() in package rgl. You have to define the formula as a function and specify the limits correctly, but you were close:

> library(rgl)
> persp3d(function(x, y) x^2+y^2, xlim=c(-3, 3), ylim=c(-3, 3))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of chappo007
Sent: Wednesday, August 19, 2015 6:48 AM
To: r-help at r-project.org
Subject: [R] Plot z=f(x,y) analytically

Hi,

I've been led to believe that in R  it is possible to produce a 3d
analytical plot of a function.  I've been pointed in the direction of
plot3d(), so the command is something like
plot3d(x^2+y^2,(x,-3,3),(y,-3,3)).  And a smart person out there is going to
tell me where this syntax comes from (or belongs to), there is also a R
package called MapleSoft ( I believe) which is commercial, and there is
always Mathematica.  So is there a R function to plot z=f(x,y) without
obtain or generating data.

Cheers,
Mike



--
View this message in context: http://r.789695.n4.nabble.com/Plot-z-f-x-y-analytically-tp4711272.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Aug 20 00:38:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Aug 2015 15:38:40 -0700
Subject: [R] Bayesian data analysis recommendations
In-Reply-To: <01AE019A-4C74-4758-A0A6-628E76658F79@gmail.com>
References: <01AE019A-4C74-4758-A0A6-628E76658F79@gmail.com>
Message-ID: <9D21C0F4-5FBF-47F1-A8ED-882292517472@comcast.net>

If you need the link to the latest email address of a package maintainer just use the maintainer function:

?maintainer


> On Aug 15, 2015, at 10:59 AM, Jeff Slagle <jeffrey.slagle at gmail.com> wrote:
> 
> I have a question about AtelieR out on stackoverflow.com.  Perhaps you could forward the link to:
> 
> Yvonnick Noel
> University of Brittany
> Department of Psychology
> Rennes, France
> 
> Here is the link:
> 
> AtelieR GTK GUI
> http://stackoverflow.com/q/32023277/5229811?sem=2
> 
> Thank you,
> Jeff
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mathewanalytics at gmail.com  Wed Aug 19 23:43:01 2015
From: mathewanalytics at gmail.com (Abraham Mathew)
Date: Wed, 19 Aug 2015 16:43:01 -0500
Subject: [R] Response Variable Coding
Message-ID: <CABbYstdUxMvkiOj5DvQk1KHPG2gk+UNq1M8xR-i5UNDOop=3=w@mail.gmail.com>

Very simple question that I want confirm.

Let's say that I have a response variable. What are the appropriate ways
that it can be coded for a logistic regression model?

1. It can be 0/1 and a factor
2. It can be 1/2 and a factor
3. It can be characters and a factor, where the second letter takes on the
1. (bad/good becomes 0/1).
4. ?
5. ?


My question is....are 1, 2, and 3 all correct, and are there other coding
schemes that glm can take.



Thanks!

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Aug 20 06:11:07 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 20 Aug 2015 16:11:07 +1200
Subject: [R] [FORGED]  Response Variable Coding
In-Reply-To: <CABbYstdUxMvkiOj5DvQk1KHPG2gk+UNq1M8xR-i5UNDOop=3=w@mail.gmail.com>
References: <CABbYstdUxMvkiOj5DvQk1KHPG2gk+UNq1M8xR-i5UNDOop=3=w@mail.gmail.com>
Message-ID: <55D5535B.9020906@auckland.ac.nz>

On 20/08/15 09:43, Abraham Mathew wrote:
> Very simple question that I want confirm.
>
> Let's say that I have a response variable. What are the appropriate ways
> that it can be coded for a logistic regression model?
>
> 1. It can be 0/1 and a factor
> 2. It can be 1/2 and a factor
> 3. It can be characters and a factor, where the second letter takes on the
> 1. (bad/good becomes 0/1).
> 4. ?
> 5. ?
>
>
> My question is....are 1, 2, and 3 all correct, and are there other coding
> schemes that glm can take.

When in doubt, RTFM! :-)

 From ?binomial:

> For the binomial and quasibinomial families the response can be
> specified in one of three ways:
>
> As a factor: ?success? is interpreted as the factor not having the first
> level (and hence usually of having the second level).
>
> As a numerical vector with values between 0 and 1, interpreted as the
> proportion of successful cases (with the total number of cases given by
> the weights).
>
> As a two-column integer matrix: the first column gives the number of
> successes and the second the number of failures.

That pretty well says it all.  One thing to note:  If the response is a 
*numeric* vector of 0's and 1's it will produce the same result as it 
would if it were converted to a factor.  (This is because the default 
weights are all 1.)

HTH

cheers,

Rolf Turner


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pjwicher at gmail.com  Thu Aug 20 06:13:45 2015
From: pjwicher at gmail.com (Peter Wicher)
Date: Wed, 19 Aug 2015 21:13:45 -0700
Subject: [R] Newbie question: error message with install.packages
Message-ID: <E8EB6700-50FE-4F42-9B99-FA2852700CDB@gmail.com>

Hi,

I?m starting to work my way through ?Machine Learning With R? by Brett Lantz.  

Running on Mac OS X 10.10.4

I?ve downloaded and installed R and the R Console comes up fine.  

Whenever I use the install.packages command, regardless of the package I get the same error message:

> install.packages ("RWeka")
Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!

Any idea of what is wrong and how to solve it?  

Thanks!

Peter Wicher
pjwicher at gmail.com


From dwinsemius at comcast.net  Thu Aug 20 08:17:40 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Aug 2015 23:17:40 -0700
Subject: [R] Newbie question: error message with install.packages
In-Reply-To: <E8EB6700-50FE-4F42-9B99-FA2852700CDB@gmail.com>
References: <E8EB6700-50FE-4F42-9B99-FA2852700CDB@gmail.com>
Message-ID: <EFDA3078-2E38-4ECE-BA1E-8EE4A0C4522A@comcast.net>


> On Aug 19, 2015, at 9:13 PM, Peter Wicher <pjwicher at gmail.com> wrote:
> 
> Hi,
> 
> I?m starting to work my way through ?Machine Learning With R? by Brett Lantz.  
> 
> Running on Mac OS X 10.10.4
> 
> I?ve downloaded and installed R and the R Console comes up fine.  
> 
> Whenever I use the install.packages command, regardless of the package I get the same error message:
> 
>> install.packages ("RWeka")
> Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!
> 
> Any idea of what is wrong and how to solve it?  

Not sure. Have never gotten that error message, and I do use OS X 10.10.3 as well as having very recently updated to R 3.2.2.

Are you using the R.app GUI?

If so ? What do you see when you look at Preference/Startup for the default CRAN repository?

If not ? What do you see when you run:

getOption("repos?)

I get:

                          CRAN 
"http://cran.cnr.Berkeley.edu" 


> 
> Thanks!
> 
> Peter Wicher
> pjwicher at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Thu Aug 20 08:50:27 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 20 Aug 2015 08:50:27 +0200
Subject: [R] Running R in Server
References: <CACruXetXNCNZ7FnR5fMbJpP4q5b2xe-fdTzQFZRgA9bhsdF2Hw@mail.gmail.com>
	<CAK1hC9tNgn9Tpc-rus2RYmzaRhLsaMe01rHb1XX4wNyoHiM-qQ@mail.gmail.com>
	<CACruXesG4yPqrW9WhbzL_V9v8uiRUwA9Qhnx+DQUjwtMj-DChw@mail.gmail.com>
Message-ID: <874mju8nd8.fsf@hornfels.zedat.fu-berlin.de>

Swagato Chatterjee <swagato1987 at gmail.com> writes:

> *@Loris: However, you'll probably have to make sure that all the packages
> you*
> *need are installed on the server.*
>
> This is where I need a help.?

Presumably the program 'cron' will be used to run your script.  If the
program is run as root, you will have to ask the admin of the server to
install the packages you need.  If you have a cron entry for your user
on the server, you can simply start R and install the packages in your
home directory with

install.packages(c("pkg1", "pkg2"))

Note that this could fail if your server is behind a firewall and unable
to access a CRAN mirror.

HTH

Loris
-- 
This signature is currently under construction.


From bbolker at gmail.com  Thu Aug 20 09:27:51 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 20 Aug 2015 07:27:51 +0000
Subject: [R] equivalent of repeated measures anova using lmer
References: <CAGA5bS9UXhr3RbkXpcyYJg81gHOvT8y7FTtyJytoO9fD1y=w+w@mail.gmail.com>
Message-ID: <loom.20150820T083549-763@post.gmane.org>

asudar <aruna.sudarshan <at> gmail.com> writes:

> 
> I am trying to run a linear mixed effects model similar to the 2*2*2 anova
> design. My DV is reaction time and fixed factors are time (pre vs.
> post:within-subject), condition (congruent vs. incongruent: within subject)
> and stimulation (vertex vs. DLPFC: between subject)
> My concerns are:
> a)I have very few participants: 7 in the vertex condition and 7 in the
> DLPFC condition.
> b)2 out of the 7 participants participated in both vertex and DLPFC
> condition.
>  How do I compute a nested lmer model with reaction time as DV and time,
> condition and stimulation as factors? and how do i account for random
> intercepts and slopes with few number of participants?
> Thanks for all the help

  You'll probably get more useful answers to this question on
the r-sig-mixed-models at r-project.org mailing list.

   7 participants is small but doesn't seem horribly small
(but it might preclude estimating a full random-slopes model).
You'll get more information on r-sig-mixed-models ...


From S.Ellison at LGCGroup.com  Thu Aug 20 17:00:28 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 20 Aug 2015 16:00:28 +0100
Subject: [R] Output In R
In-Reply-To: <1439961625598-4711264.post@n4.nabble.com>
References: <1439901681930-4711227.post@n4.nabble.com>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403B44C0DA9@GBTEDVPEXCMB04.corp.lgc-group.com>

> I have already tried options(max.print=999999) but does not show the desired
> result.
> As posted above it want to share the outcome with the business owner where
> there could be multiple entries.

Then just print the multiple entries. See ?duplicated for finding them

Otherwise, use things like 
> head(tail(d, 90000), 30) 
or
> d[10000:100030, ]
to print 30 lines at a time.







*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From eva.fritzsche at tum.de  Thu Aug 20 17:12:08 2015
From: eva.fritzsche at tum.de (Fritzsche, Eva)
Date: Thu, 20 Aug 2015 15:12:08 +0000
Subject: [R] CFI fit measure for EFA in semTools
Message-ID: <2d0d5fca4e7443ef9d29e3a2dc02818b@BADWLRZ-SW13MB5.ads.mwn.de>

Hi @ all,

i am trying to get fitMeasures (CFI) for an Exploratory Factor Analysis using R and I am still not able for the rotated version.
I applied the package semTools
My code is as follows:

unrot01 <- efaUnrotate(rszK2[ , 73:93], nf=3, start=F)
summary(unrot01)
fitMeasures(unrot01)  # for the unrotated solution I get all fit measures

rot01 <- oblqRotate(unrot01, method= "oblimin")
summary(rot01, fit.measures=T)
# returns "Error in .local(object, ...) : unused argument (fit.measures = TRUE)"

I guess the problem might be that oblqRotate doesn't return something like lavaan-Output, but something "Formal class EFA".
Right?
I would be very happy about any suggestions!
Thank you very much!

Eva



-------
Dr. Eva S. Fritzsche
Postanschrift:
Technische Universit?t M?nchen
TUM School of Education | Lehrstuhl f?r Schulp?dagogik
Arcisstr. 21 | 80333 M?nchen
Besucheranschrift:
TUM School of Education | Marsstr. 20 - 22 | 80335 M?nchen
Raumnr. 274 | Tel. +49.89.289.25106
eva.fritzsche at tum.de<mailto:eva.fritzsche at tum.de> | www.schulpaed.edu.tum.de<http://www.edu.tum.de/>


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Aug 20 17:29:56 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 20 Aug 2015 08:29:56 -0700
Subject: [R] CFI fit measure for EFA in semTools
In-Reply-To: <2d0d5fca4e7443ef9d29e3a2dc02818b@BADWLRZ-SW13MB5.ads.mwn.de>
References: <2d0d5fca4e7443ef9d29e3a2dc02818b@BADWLRZ-SW13MB5.ads.mwn.de>
Message-ID: <CAGxFJbSKytVGGscj6Az8rCsprcM=rCA6Z-mooughsiLbvEOubw@mail.gmail.com>

ummm.... Have you tried reading the documentation for the summary
method for the object returned by oblqRotate? It will tell you what
its arguments should be.

If you don't know what this means, then you need to go through an R
tutorial to learn about (S3 or S4, don't know which) methods in R.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Aug 20, 2015 at 8:12 AM, Fritzsche, Eva <eva.fritzsche at tum.de> wrote:
> Hi @ all,
>
> i am trying to get fitMeasures (CFI) for an Exploratory Factor Analysis using R and I am still not able for the rotated version.
> I applied the package semTools
> My code is as follows:
>
> unrot01 <- efaUnrotate(rszK2[ , 73:93], nf=3, start=F)
> summary(unrot01)
> fitMeasures(unrot01)  # for the unrotated solution I get all fit measures
>
> rot01 <- oblqRotate(unrot01, method= "oblimin")
> summary(rot01, fit.measures=T)
> # returns "Error in .local(object, ...) : unused argument (fit.measures = TRUE)"
>
> I guess the problem might be that oblqRotate doesn't return something like lavaan-Output, but something "Formal class EFA".
> Right?
> I would be very happy about any suggestions!
> Thank you very much!
>
> Eva
>
>
>
> -------
> Dr. Eva S. Fritzsche
> Postanschrift:
> Technische Universit?t M?nchen
> TUM School of Education | Lehrstuhl f?r Schulp?dagogik
> Arcisstr. 21 | 80333 M?nchen
> Besucheranschrift:
> TUM School of Education | Marsstr. 20 - 22 | 80335 M?nchen
> Raumnr. 274 | Tel. +49.89.289.25106
> eva.fritzsche at tum.de<mailto:eva.fritzsche at tum.de> | www.schulpaed.edu.tum.de<http://www.edu.tum.de/>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From akhst7 at gmail.com  Thu Aug 20 23:20:18 2015
From: akhst7 at gmail.com (Aki Hoji)
Date: Thu, 20 Aug 2015 17:20:18 -0400
Subject: [R] how to create contour lines on a 3D surface plot by persp3d
	from rgl package
Message-ID: <52A66ED9-35C4-4B66-962B-C496BBE7C30C@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

HI, 

I created a 3D surface plot of 2D surface data (generated by kde2d)  by using persp3d from rlg as follows;


	persp3d(dens3d, theta=50, phi=25, expand=0.75, col=color[zcol], ticktype="detailed",axes=TRUE)

 I would like to add contour lines to this 3D surface plot and I?d appreciate if any help on this.  

Thanks in advance.  

AH


-----BEGIN PGP SIGNATURE-----
Comment: GPGTools - https://gpgtools.org

iF4EAREKAAYFAlXWRJMACgkQOpsV3h2pS5ooEgEAkqV5YhvJtT7k3ieSToWGEQLu
5YJw4myWd854/gY9/EIBAIGDCITrrrUj2HX4ztUtykNmxodyeZRqHcwLp53L59a9
=G6Sx
-----END PGP SIGNATURE-----


From pjwicher at gmail.com  Thu Aug 20 19:09:00 2015
From: pjwicher at gmail.com (Peter Wicher)
Date: Thu, 20 Aug 2015 10:09:00 -0700
Subject: [R] Newbie question: error message with install.packages
In-Reply-To: <EFDA3078-2E38-4ECE-BA1E-8EE4A0C4522A@comcast.net>
References: <E8EB6700-50FE-4F42-9B99-FA2852700CDB@gmail.com>
	<EFDA3078-2E38-4ECE-BA1E-8EE4A0C4522A@comcast.net>
Message-ID: <CAA5iXLeTL_3K46ohCNFUzp7N3O_9yGgwuW7Y2ds+SNe8EALnLg@mail.gmail.com>

Many thanks.

Yes, I am using the R.app GUI:
[R.app GUI 1.66 (6996) x86_64-apple-darwin13.4.0]


At startup,

> getOption("repos")
    CRAN
"@CRAN@"

Then when attempting again to install RWeka I'm able to select the mirror,
and after that the result is the same as yours:

> getOption("repos")
                           CRAN
"https://cran.cnr.Berkeley.edu"

Unfortunately the same error message happens with install.packages, for
example:
> install.packages("err")
Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!

I've confirmed that Java 8 update 60 is correctly loaded.

Interestingly I've loaded R on my Windows machine and this error message
doesn't happen, the packages load properly.

Peter

On Wed, Aug 19, 2015 at 11:17 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Aug 19, 2015, at 9:13 PM, Peter Wicher <pjwicher at gmail.com> wrote:
> >
> > Hi,
> >
> > I?m starting to work my way through ?Machine Learning With R? by Brett
> Lantz.
> >
> > Running on Mac OS X 10.10.4
> >
> > I?ve downloaded and installed R and the R Console comes up fine.
> >
> > Whenever I use the install.packages command, regardless of the package I
> get the same error message:
> >
> >> install.packages ("RWeka")
> > Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!
> >
> > Any idea of what is wrong and how to solve it?
>
> Not sure. Have never gotten that error message, and I do use OS X 10.10.3
> as well as having very recently updated to R 3.2.2.
>
> Are you using the R.app GUI?
>
> If so ? What do you see when you look at Preference/Startup for the
> default CRAN repository?
>
> If not ? What do you see when you run:
>
> getOption("repos?)
>
> I get:
>
>                           CRAN
> "http://cran.cnr.Berkeley.edu"
>
>
> >
> > Thanks!
> >
> > Peter Wicher
> > pjwicher at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Fri Aug 21 00:06:15 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 20 Aug 2015 15:06:15 -0700
Subject: [R] Newbie question: error message with install.packages
In-Reply-To: <CAA5iXLeTL_3K46ohCNFUzp7N3O_9yGgwuW7Y2ds+SNe8EALnLg@mail.gmail.com>
References: <E8EB6700-50FE-4F42-9B99-FA2852700CDB@gmail.com>
	<EFDA3078-2E38-4ECE-BA1E-8EE4A0C4522A@comcast.net>
	<CAA5iXLeTL_3K46ohCNFUzp7N3O_9yGgwuW7Y2ds+SNe8EALnLg@mail.gmail.com>
Message-ID: <CA+hbrhX731rVrRYLPkFnVqTyyDg1ZF6V5mb4k-qQxS54ubX6ag@mail.gmail.com>

>From an older post by Uwe Ligges:

Anyway: R tried to download the package but got an html page, obviously,
hence either the mirror you are using is corrupted or someone in between
(like some proxy?) delivers html pages rather than packages...


In other words, check your proxy/internet settings, or perhaps try a
different mirror.

Peter


On Thu, Aug 20, 2015 at 10:09 AM, Peter Wicher <pjwicher at gmail.com> wrote:
> Many thanks.
>
> Yes, I am using the R.app GUI:
> [R.app GUI 1.66 (6996) x86_64-apple-darwin13.4.0]
>
>
> At startup,
>
>> getOption("repos")
>     CRAN
> "@CRAN@"
>
> Then when attempting again to install RWeka I'm able to select the mirror,
> and after that the result is the same as yours:
>
>> getOption("repos")
>                            CRAN
> "https://cran.cnr.Berkeley.edu"
>
> Unfortunately the same error message happens with install.packages, for
> example:
>> install.packages("err")
> Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!
>
> I've confirmed that Java 8 update 60 is correctly loaded.
>
> Interestingly I've loaded R on my Windows machine and this error message
> doesn't happen, the packages load properly.
>
> Peter
>
> On Wed, Aug 19, 2015 at 11:17 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> > On Aug 19, 2015, at 9:13 PM, Peter Wicher <pjwicher at gmail.com> wrote:
>> >
>> > Hi,
>> >
>> > I?m starting to work my way through ?Machine Learning With R? by Brett
>> Lantz.
>> >
>> > Running on Mac OS X 10.10.4
>> >
>> > I?ve downloaded and installed R and the R Console comes up fine.
>> >
>> > Whenever I use the install.packages command, regardless of the package I
>> get the same error message:
>> >
>> >> install.packages ("RWeka")
>> > Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!
>> >
>> > Any idea of what is wrong and how to solve it?
>>
>> Not sure. Have never gotten that error message, and I do use OS X 10.10.3
>> as well as having very recently updated to R 3.2.2.
>>
>> Are you using the R.app GUI?
>>
>> If so ? What do you see when you look at Preference/Startup for the
>> default CRAN repository?
>>
>> If not ? What do you see when you run:
>>
>> getOption("repos?)
>>
>> I get:
>>
>>                           CRAN
>> "http://cran.cnr.Berkeley.edu"
>>
>>
>> >
>> > Thanks!
>> >
>> > Peter Wicher
>> > pjwicher at gmail.com
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Aug 21 00:30:44 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 20 Aug 2015 18:30:44 -0400
Subject: [R] how to create contour lines on a 3D surface plot by persp3d
 from rgl package
In-Reply-To: <52A66ED9-35C4-4B66-962B-C496BBE7C30C@gmail.com>
References: <52A66ED9-35C4-4B66-962B-C496BBE7C30C@gmail.com>
Message-ID: <55D65514.4030000@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 20/08/2015 5:20 PM, Aki Hoji wrote:
> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA512
> 
> HI,
> 
> I created a 3D surface plot of 2D surface data (generated by kde2d)
> by using persp3d from rlg as follows;
> 
> 
> persp3d(dens3d, theta=50, phi=25, expand=0.75, col=color[zcol],
> ticktype="detailed",axes=TRUE)
> 
> I would like to add contour lines to this 3D surface plot and I?d
> appreciate if any help on this.
> 
> Thanks in advance.

Use the contourLines() function to compute them, then plot them using
lines3d.

The difficulty is that they may be hidden by the surface.  The
simplest way around that is to make the surface have partial
transparency.  If you don't want to do that, plotting the lines first
will

For example:

f <- function(x, y) x^2 + y^2
x <- seq(-2, 2, len=50)
y <- seq(-2, 2, len=50)
z <- outer(x,y,f)
persp3d(x,y,z, col="red",alpha=0.5)
lines <- contourLines(x, y, z)
for (i in seq_along(lines)) {
  x <- lines[[i]]$x
  y <- lines[[i]]$y
  z <- rep(lines[[i]]$level, length(x))
  lines3d(x, y, z)
}


Duncan Murdoch
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2
Comment: GPGTools - https://gpgtools.org

iQEcBAEBCgAGBQJV1lUUAAoJEHE2Kz23YMZyVxUH/jmOwREkGy045EcbnkXCfARE
bSS7H2/kzbU5jY+vavrIDRveCQo2eYJr7yigF8HMiiRZqRqF7nEg+tt5yuQHwc4L
fYYldU4ZHohS+AQg/u21qD8Skln7+1d1D5yZj6DQqY8hU5duWdcErdNgoDt268+i
u0hsBAZDhDEBNh6+5IIGI5CF3utqS7ufJb8aEKrSDfZV5fDqSYGxRpNlYcI1Ou+n
SRoQi5jJ2FOBlSlYC3wg5ZjT5FiV7QqoymKFiUMKYz0eUWqoPkPiQDVKi054Qlim
xRyHUsaGN31Jc2817+kmjWnL7K5MFFbg/BLlLtijg5bmM9dZo/wYJ0MU6Pu8CVA=
=Sn3R
-----END PGP SIGNATURE-----


From dwinsemius at comcast.net  Fri Aug 21 06:06:19 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 20 Aug 2015 21:06:19 -0700
Subject: [R] glm help
In-Reply-To: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
Message-ID: <8B38BCEE-F8A2-4D0B-81EC-21D7A3CB0139@comcast.net>


> On Aug 19, 2015, at 8:54 AM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:
> 
> Dear All, I?m running a glm with poisson errors and have a doubt when
> ploting the predicted values. One of my variables has a positive slope in
> the summary output, but when I plot the predicted values on the original
> plot it draws a line with negative slope. I appreciate your comments on
> this and any other aspect of the analysis.
> 
> Attached is the script and data in different formats just in case.

The script in .txt format was accepted by the server. The data was apparently not in a .txt format, so it was rejected.

You made three plots, so when you reply with data using the correct format (which is plain text and generally need to have an extension .txt so that mail client will lable as MIME-text) , you should be more specific about which plots are not exhibiting the expected features. 

I noticed you made two data-frames, ?my4s' and ?my4S'. The `my4S` was built with `cbind` which would create a matrix (probably a character matrix) rather than a data frame. I?m wondering you you inadvertently constructed a data-object whose structure was different than you imagined? It might have gotten coerced back to a dataframe with undesirable concsequences.

? 
David.

> 
> Thanks in advanced,
> 
> Joaqu?n.
> 
> 
> -- 
> *Joaqu?n Aldabe*
> 
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> 
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
> 
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> <glm forum consult.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Aug 21 07:04:01 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 20 Aug 2015 22:04:01 -0700
Subject: [R] glm help
In-Reply-To: <8B38BCEE-F8A2-4D0B-81EC-21D7A3CB0139@comcast.net>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
	<8B38BCEE-F8A2-4D0B-81EC-21D7A3CB0139@comcast.net>
Message-ID: <CAGxFJbR1raq9RCZeP7v9x2DCm8F3u-BfYr4FL6+dM++79CRsGw@mail.gmail.com>

Inline.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Aug 20, 2015 at 9:06 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Aug 19, 2015, at 8:54 AM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> wrote:
>>
>> Dear All, I?m running a glm with poisson errors and have a doubt when
>> ploting the predicted values. One of my variables has a positive slope in
>> the summary output, but when I plot the predicted values on the original
>> plot it draws a line with negative slope. I appreciate your comments on
>> this and any other aspect of the analysis.
>>
>> Attached is the script and data in different formats just in case.
>
> The script in .txt format was accepted by the server. The data was apparently not in a .txt format, so it was rejected.
>
> You made three plots, so when you reply with data using the correct format (which is plain text and generally need to have an extension .txt so that mail client will lable as MIME-text) , you should be more specific about which plots are not exhibiting the expected features.
>
> I noticed you made two data-frames, ?my4s' and ?my4S'. The `my4S` was built with `cbind` which would create a matrix (probably a character matrix) rather than a data frame.

False. There is a data.frame method for cbind that returns a data
frame. Don't know the specifics here, though.

Cheers,
Bert


 I?m wondering you you inadvertently constructed a data-object whose
structure was different than you imagined? It might have gotten
coerced back to a dataframe with undesirable concsequences.
>
> ?
> David.
>
>>
>> Thanks in advanced,
>>
>> Joaqu?n.
>>
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> *Grupo Biodiversidad, Ambiente y Sociedad*
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *Departamento de Conservaci?n*
>> Aves Uruguay
>> BirdLife International
>> Canelones 1164, Montevideo
>>
>> https://sites.google.com/site/joaquin.aldabe
>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>> <glm forum consult.txt>______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter.langfelder at gmail.com  Fri Aug 21 07:47:44 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 20 Aug 2015 22:47:44 -0700
Subject: [R] glm help
In-Reply-To: <CAGxFJbR1raq9RCZeP7v9x2DCm8F3u-BfYr4FL6+dM++79CRsGw@mail.gmail.com>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
	<8B38BCEE-F8A2-4D0B-81EC-21D7A3CB0139@comcast.net>
	<CAGxFJbR1raq9RCZeP7v9x2DCm8F3u-BfYr4FL6+dM++79CRsGw@mail.gmail.com>
Message-ID: <CA+hbrhVtvDneEzx5ni=MXOdjJeaVFsO3HnXwmsuTZ=d1Qte4YA@mail.gmail.com>

On Thu, Aug 20, 2015 at 10:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

>> I noticed you made two data-frames, ?my4s' and ?my4S'. The `my4S` was built with `cbind` which would create a matrix (probably a character matrix) rather than a data frame.
>
> False. There is a data.frame method for cbind that returns a data
> frame. Don't know the specifics here, though.
>

True, but does not apply here, i.e., David is correct. cbind will
return a data frame if the first argument is a data frame. In the OP
case, the first argument was a vector and hence cbind gives a matrix,
of mode "character" if any of the inputs were character. Here's a
short demo:

> a = data.frame(a1 = 1:10)
# First argument a data frame, so the results is also a data frame  :
> class(cbind(a, b = 11:20))
[1] "data.frame"
# First argument is a vector, so the result is a matrix:
> class(cbind(a$a1, b = 11:20))
[1] "matrix"
> mode(cbind(a$a1, b = 11:20))
[1] "numeric"
> mode(cbind(a$a1, b = letters[11:20]))
[1] "character"

Peter


From oma.gonzales at gmail.com  Fri Aug 21 15:38:26 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 21 Aug 2015 08:38:26 -0500
Subject: [R] [Rmarkdown] html_document - custom CSS for code snippets
Message-ID: <CAM-xyZi0r9S1EdaRCQuyewmh1bEskGZzV5dsVAXejmakkNdz_w@mail.gmail.com>

Hi Community,

I'm using custom CSS to modify my html_document, genereted using knirt.

According to this page:

http://rmarkdown.rstudio.com/html_document_format.html

I have to turn off: 1) theme: null  and 2) highlight: null. And use:
3) css: my_styles.css (my css document).

I've achieved to use some html tags, like <main></main> to give some
left margin to the document. But i cannot apply correctly html tags to
the code snipets, and convert it's background to gray.

So my code snipets show the code, but the background is white, and has
no difference with the white background of the page.

What can i do?

*Extra: Now i'm displaying some R code, but i would like to display
also some javascript code. Is this possible?


From rv15i at yahoo.se  Fri Aug 21 16:30:32 2015
From: rv15i at yahoo.se (ravi)
Date: Fri, 21 Aug 2015 14:30:32 +0000 (UTC)
Subject: [R] plotting over a raster image with control over location and
 orientation
Message-ID: <2048639744.8977490.1440167432929.JavaMail.yahoo@mail.yahoo.com>

Hi,I would like to get some help in plotting over an image. I have a png image over which I would like to have a plot. I would like to be able to control the location, area and orientation of the plot on the image.
I have taken help from the following references :http://journal.r-project.org/archive/2011-1/RJournal_2011-1_Murrell.pdfhttp://stackoverflow.com/questions/12918367/in-r-how-to-plot-with-a-png-as-background
In order to give a reproducible example, I set up my image with the help of some code from the the first reference above.

#Setting up the initial example raster image
x <- y <- seq(-4*pi, 4*pi, len=27)
r <- sqrt(outer(x^2, y^2, "+"))
z <- cos(r^2)*exp(-r/6)
image <- (z - min(z))/diff(range(z))
step <- diff(x)[1]
xrange <- range(x) + c(-step/2, step/2)
yrange <- range(y) + c(-step/2, step/2)
plot(x, y, ann=FALSE,xlim=xrange, ylim=yrange,xaxs="i", yaxs="i")
rasterImage(image,xrange[1], yrange[1],xrange[2], yrange[2],interpolate=FALSE)

# the explanation of my problem starts here
# First, I want to mark out a particular line
lines(c(10,10.5),c(-10.5,10),col="red",lwd=2)
#In my problem, I have to locate these points graphically from the image
calpoints <- locator(n=2,type='p',pch=4,col='blue',lwd=2)
# this gives the line corresponding to the x-axis for my overlay plot
# I don't want the red line on my plot
#the red line plotted earlier is just to show the example location
newOrigin<-calpoints[1]
xLimit<-calpoints[2]#xlimit marks the limit of the x-axis on the image# on this new line as the x-axis, I want to make a new plot# the y-axis should be perpendicular to the x-axis. I would like to be able to specify the width of coverage over the image#example
xx<-1:10
yy<-xx^2
plot(xx,yy,xlim=range(xx),ylim=range(yy),col="blue",type="b",xlab="x",ylab="square of x")
# I would prefer to have the image more transparent just under the x and y labels and axis labelsThanks, Ravi


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Aug 21 16:32:22 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 21 Aug 2015 07:32:22 -0700
Subject: [R] glm help
In-Reply-To: <CA+hbrhVtvDneEzx5ni=MXOdjJeaVFsO3HnXwmsuTZ=d1Qte4YA@mail.gmail.com>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
	<8B38BCEE-F8A2-4D0B-81EC-21D7A3CB0139@comcast.net>
	<CAGxFJbR1raq9RCZeP7v9x2DCm8F3u-BfYr4FL6+dM++79CRsGw@mail.gmail.com>
	<CA+hbrhVtvDneEzx5ni=MXOdjJeaVFsO3HnXwmsuTZ=d1Qte4YA@mail.gmail.com>
Message-ID: <CAGxFJbTya=hVwOoA0k041tqPvGFfdVAmos9g6ZR0Zxp-UcUPVw@mail.gmail.com>

Inline.

-- Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Aug 20, 2015 at 10:47 PM, Peter Langfelder
<peter.langfelder at gmail.com> wrote:
> On Thu, Aug 20, 2015 at 10:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>>> I noticed you made two data-frames, ?my4s' and ?my4S'. The `my4S` was built with `cbind` which would create a matrix (probably a character matrix) rather than a data frame.
>>
>> False. There is a data.frame method for cbind that returns a data
>> frame. Don't know the specifics here, though.
>>
>
> True, but does not apply here, i.e., David is correct. cbind will
> return a data frame if the first argument is a data frame. In the OP
> case, the first argument was a vector and hence cbind gives a matrix,

False again.

class(cbind(a=1:5,b=data.frame(a=letters[1:5],b=3:7)))

[1] "data.frame"

##First argument a vector, but data frame is returned. Please consult
?cbind -- especially the data frame section -- for details.

Again, I don't know the specifics here, and you and David may still
well be right for what the OP did. I am only trying to correct what
appear to me to be incorrect statements about the data.frame method of
cbind (or rbind). Apologies if I have misinterpreted.

Cheers,
Bert



> of mode "character" if any of the inputs were character. Here's a
> short demo:
>
>> a = data.frame(a1 = 1:10)
> # First argument a data frame, so the results is also a data frame  :
>> class(cbind(a, b = 11:20))
> [1] "data.frame"
> # First argument is a vector, so the result is a matrix:
>> class(cbind(a$a1, b = 11:20))
> [1] "matrix"
>> mode(cbind(a$a1, b = 11:20))
> [1] "numeric"
>> mode(cbind(a$a1, b = letters[11:20]))
> [1] "character"
>
> Peter


From eladlazar22 at gmail.com  Fri Aug 21 13:10:23 2015
From: eladlazar22 at gmail.com (Elad Lazar)
Date: Fri, 21 Aug 2015 14:10:23 +0300
Subject: [R] fill color in boxplot and change number in scale
Message-ID: <CAANc9U3kn1Vz4irs=YG=ONqP39ZWbqPF5CO69ND2ss25FMG=jw@mail.gmail.com>

hello,
I want to change the line color and/or fill of each boxplot and  change
number in scale
what I need to do?


ylim<-c(-3,0.5)
data.for.plot<-data.frame(accelaration=data_2$lag1min_accelaration,
                          lag=1,
                          alert='red')
data.for.plot<-rbind(data.for.plot,
                      data.frame(accelaration=data_2$min_accelaration,
                          lag=0,
                          alert='red'))

data.for.plot<-rbind(data.for.plot,
                      data.frame(accelaration=data_1$lag1min_accelaration,
                          lag=1,
                          alert='yellow'))
data.for.plot<-rbind(data.for.plot,
                     data.frame(accelaration=data_1$min_accelaration,
                                lag=0,
                                alert='yellow'))

data.for.plot<-rbind(data.for.plot,
  data.frame(accelaration=data_0$lag1min_accelaration,
             lag=1,
             alert='no alert'))
data.for.plot<-rbind(data.for.plot,
                     data.frame(accelaration=data_0$min_accelaration,
                                lag=0,
                                alert='no alert'))
library('ggplot2')
ggplot(data.for.plot,aes(fill=factor(alert),
                         y=accelaration,x=factor(lag)))+
  geom_boxplot()
-------------- next part --------------
A non-text attachment was scrubbed...
Name: color.PNG
Type: image/png
Size: 15347 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150821/df2540db/attachment.png>

From joaquin.aldabe at gmail.com  Fri Aug 21 13:45:21 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Fri, 21 Aug 2015 08:45:21 -0300
Subject: [R] glm help
In-Reply-To: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
Message-ID: <CAMM93=Lq4m-zgvqgF1GD-M9-c1j3sruRsBPOCv1moVj=RyE1Jg@mail.gmail.com>

Thankyou all by the comments and sorry for not sending in the adequate
format. I don't have the chance to make txt archives as open office doesn't
do it. I'm attaching the data in excel. Please let me know if this is ok.

The graph that is wierd to me is the BBSA vs AMGP. It is supposed that AMGP
has a positive effect on BBSA, but the model fit shows a negative slope. In
other forum I was told to plot each variable with fixed values of the other
two variables, and make different curves for each variable.

Thanks again for your interest and help.

All the best,
Joaqu?n

2015-08-19 12:54 GMT-03:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:

> Dear All, I?m running a glm with poisson errors and have a doubt when
> ploting the predicted values. One of my variables has a positive slope in
> the summary output, but when I plot the predicted values on the original
> plot it draws a line with negative slope. I appreciate your comments on
> this and any other aspect of the analysis.
>
> Attached is the script and data in different formats just in case.
>
> Thanks in advanced,
>
> Joaqu?n.
>
>
> --
> *Joaqu?n Aldabe*
>
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
>
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>
>


-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

From callyak4real at yahoo.com  Fri Aug 21 14:22:04 2015
From: callyak4real at yahoo.com (Babatunde Yakub)
Date: Fri, 21 Aug 2015 12:22:04 +0000 (UTC)
Subject: [R] Generalised poisson regression
Message-ID: <39823553.5046111.1440159724900.JavaMail.yahoo@mail.yahoo.com>

I want to know how to extract or obtain the deviance for a fitted generalised poisson regression model. Thanks in advance


	[[alternative HTML version deleted]]


From callyak4real at yahoo.com  Fri Aug 21 14:47:04 2015
From: callyak4real at yahoo.com (Babatunde Yakub)
Date: Fri, 21 Aug 2015 12:47:04 +0000 (UTC)
Subject: [R] Conway Maxwell Poisson
Message-ID: <1036900256.5442259.1440161224555.JavaMail.yahoo@mail.yahoo.com>

I want to know how to extract or compute the AIC and BIC measures of a conway maxwell poisson regression model.Thanks

	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Fri Aug 21 07:25:18 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Thu, 20 Aug 2015 22:25:18 -0700 (PDT)
Subject: [R] Output In R
In-Reply-To: <CAAxdm-4p1Vpz-6LuiCMtTRfv_Z7213juH7kxX8Z-2ZuqKpF0Tw@mail.gmail.com>
References: <1439901681930-4711227.post@n4.nabble.com>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
	<CAAxdm-4p1Vpz-6LuiCMtTRfv_Z7213juH7kxX8Z-2ZuqKpF0Tw@mail.gmail.com>
Message-ID: <1440134718677-4711335.post@n4.nabble.com>

Hi Jim,

Please see the sample code:
ak<-read.csv("June.csv", header = TRUE)
ak%>%select(sfxcode,mod,chargedweight)%>%filter(mod=='AIR')

what i am trying to find is selecting the required var and then selecting
only AIR as a mode of transportation from mod.
I am getting the output but the total rows which fulfil this condition is
10500 where console shows only 3300. 
I want to share the output i.e. 10500 rows to my business. So want to see
the possible options to share the results with the business. R Markdown & R
Sweave might help - please suggest. 



--
View this message in context: http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711335.html
Sent from the R help mailing list archive at Nabble.com.


From pjwicher at gmail.com  Fri Aug 21 08:22:24 2015
From: pjwicher at gmail.com (Peter Wicher)
Date: Thu, 20 Aug 2015 23:22:24 -0700
Subject: [R] Newbie question: error message with install.packages
In-Reply-To: <CA+hbrhX731rVrRYLPkFnVqTyyDg1ZF6V5mb4k-qQxS54ubX6ag@mail.gmail.com>
References: <E8EB6700-50FE-4F42-9B99-FA2852700CDB@gmail.com>
	<EFDA3078-2E38-4ECE-BA1E-8EE4A0C4522A@comcast.net>
	<CAA5iXLeTL_3K46ohCNFUzp7N3O_9yGgwuW7Y2ds+SNe8EALnLg@mail.gmail.com>
	<CA+hbrhX731rVrRYLPkFnVqTyyDg1ZF6V5mb4k-qQxS54ubX6ag@mail.gmail.com>
Message-ID: <3E2EBBFB-E250-4DC5-A5CD-8CFBD7C6E16E@gmail.com>

Peter,

Thank you.  I tried a different mirror (in TX) and install.packages(?RWeka?) worked.  I really appreciate your help.

Best,

Peter

> On Aug 20, 2015, at 3:06 PM, Peter Langfelder <peter.langfelder at gmail.com> wrote:
> 
> From an older post by Uwe Ligges:
> 
> Anyway: R tried to download the package but got an html page, obviously,
> hence either the mirror you are using is corrupted or someone in between
> (like some proxy?) delivers html pages rather than packages...
> 
> 
> In other words, check your proxy/internet settings, or perhaps try a
> different mirror.
> 
> Peter
> 
> 
> On Thu, Aug 20, 2015 at 10:09 AM, Peter Wicher <pjwicher at gmail.com> wrote:
>> Many thanks.
>> 
>> Yes, I am using the R.app GUI:
>> [R.app GUI 1.66 (6996) x86_64-apple-darwin13.4.0]
>> 
>> 
>> At startup,
>> 
>>> getOption("repos")
>>    CRAN
>> "@CRAN@"
>> 
>> Then when attempting again to install RWeka I'm able to select the mirror,
>> and after that the result is the same as yours:
>> 
>>> getOption("repos")
>>                           CRAN
>> "https://cran.cnr.Berkeley.edu"
>> 
>> Unfortunately the same error message happens with install.packages, for
>> example:
>>> install.packages("err")
>> Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!
>> 
>> I've confirmed that Java 8 update 60 is correctly loaded.
>> 
>> Interestingly I've loaded R on my Windows machine and this error message
>> doesn't happen, the packages load properly.
>> 
>> Peter
>> 
>> On Wed, Aug 19, 2015 at 11:17 PM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>> 
>>> 
>>>> On Aug 19, 2015, at 9:13 PM, Peter Wicher <pjwicher at gmail.com> wrote:
>>>> 
>>>> Hi,
>>>> 
>>>> I?m starting to work my way through ?Machine Learning With R? by Brett
>>> Lantz.
>>>> 
>>>> Running on Mac OS X 10.10.4
>>>> 
>>>> I?ve downloaded and installed R and the R Console comes up fine.
>>>> 
>>>> Whenever I use the install.packages command, regardless of the package I
>>> get the same error message:
>>>> 
>>>>> install.packages ("RWeka")
>>>> Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!
>>>> 
>>>> Any idea of what is wrong and how to solve it?
>>> 
>>> Not sure. Have never gotten that error message, and I do use OS X 10.10.3
>>> as well as having very recently updated to R 3.2.2.
>>> 
>>> Are you using the R.app GUI?
>>> 
>>> If so ? What do you see when you look at Preference/Startup for the
>>> default CRAN repository?
>>> 
>>> If not ? What do you see when you run:
>>> 
>>> getOption("repos?)
>>> 
>>> I get:
>>> 
>>>                          CRAN
>>> "http://cran.cnr.Berkeley.edu"
>>> 
>>> 
>>>> 
>>>> Thanks!
>>>> 
>>>> Peter Wicher
>>>> pjwicher at gmail.com
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Aug 21 17:29:13 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 21 Aug 2015 11:29:13 -0400
Subject: [R] [Rmarkdown] html_document - custom CSS for code snippets
In-Reply-To: <CAM-xyZi0r9S1EdaRCQuyewmh1bEskGZzV5dsVAXejmakkNdz_w@mail.gmail.com>
References: <CAM-xyZi0r9S1EdaRCQuyewmh1bEskGZzV5dsVAXejmakkNdz_w@mail.gmail.com>
Message-ID: <55D743C9.2020703@gmail.com>

On 21/08/2015 9:38 AM, Omar Andr? Gonz?les D?az wrote:
> Hi Community,
> 
> I'm using custom CSS to modify my html_document, genereted using knirt.
> 
> According to this page:
> 
> http://rmarkdown.rstudio.com/html_document_format.html
> 
> I have to turn off: 1) theme: null  and 2) highlight: null. And use:
> 3) css: my_styles.css (my css document).
>
> I've achieved to use some html tags, like <main></main> to give some
> left margin to the document. But i cannot apply correctly html tags to
> the code snipets, and convert it's background to gray.
> 
> So my code snipets show the code, but the background is white, and has
> no difference with the white background of the page.
> 
> What can i do?
> 
> *Extra: Now i'm displaying some R code, but i would like to display
> also some javascript code. Is this possible?

Sure, just enter it as

```
x = 1;
for (var i=0; i<2; i++)
```

You won't get syntax highlighting; if you want that, you'll need to
create a "Javascript engine"; see ?knitr::knit_engines, or use a
different one (the "coffee" engine is probably fine):

```{coffee, eval=FALSE}
x = 1;
for (var i=0; i<2; i++)
```

Duncan Murdoch


From jrkrideau at inbox.com  Fri Aug 21 17:31:11 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 21 Aug 2015 07:31:11 -0800
Subject: [R] fill color in boxplot and change number in scale
In-Reply-To: <CAANc9U3kn1Vz4irs=YG=ONqP39ZWbqPF5CO69ND2ss25FMG=jw@mail.gmail.com>
Message-ID: <9FA7CE3DEA9.000009CEjrkrideau@inbox.com>

Would this help on colour?
http://stackoverflow.com/questions/8320462/ggplot2-how-to-adjust-fill-colour-in-a-boxplot-and-change-legend-text

You don't say what you want to with the numbers in scale (what scale?)
You might want to try something like ?scale_manual and then do some googling.

Note almost all the code you provided is redundent for the problem. We probably should have the data however . See ?dput or read ttp://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or  http://adv-r.had.co.nz/Reproducibility.html for some hints on how to frame the question and supply data.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: eladlazar22 at gmail.com
> Sent: Fri, 21 Aug 2015 14:10:23 +0300
> To: r-help at r-project.org
> Subject: [R] fill color in boxplot and change number in scale
> 
> hello,
> I want to change the line color and/or fill of each boxplot and  change
> number in scale
> what I need to do?
> 
> 
> ylim<-c(-3,0.5)
> data.for.plot<-data.frame(accelaration=data_2$lag1min_accelaration,
>                           lag=1,
>                           alert='red')
> data.for.plot<-rbind(data.for.plot,
>                       data.frame(accelaration=data_2$min_accelaration,
>                           lag=0,
>                           alert='red'))
> 
> data.for.plot<-rbind(data.for.plot,
> 
> data.frame(accelaration=data_1$lag1min_accelaration,
>                           lag=1,
>                           alert='yellow'))
> data.for.plot<-rbind(data.for.plot,
>                      data.frame(accelaration=data_1$min_accelaration,
>                                 lag=0,
>                                 alert='yellow'))
> 
> data.for.plot<-rbind(data.for.plot,
>   data.frame(accelaration=data_0$lag1min_accelaration,
>              lag=1,
>              alert='no alert'))
> data.for.plot<-rbind(data.for.plot,
>                      data.frame(accelaration=data_0$min_accelaration,
>                                 lag=0,
>                                 alert='no alert'))
> library('ggplot2')
> ggplot(data.for.plot,aes(fill=factor(alert),
>                          y=accelaration,x=factor(lag)))+
>   geom_boxplot()
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From bgunter.4567 at gmail.com  Fri Aug 21 17:31:59 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 21 Aug 2015 08:31:59 -0700
Subject: [R] Conway Maxwell Poisson
In-Reply-To: <1036900256.5442259.1440161224555.JavaMail.yahoo@mail.yahoo.com>
References: <1036900256.5442259.1440161224555.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbRmegmcmT5N1TGsg=KAEb7iQzCBNE1eM0--mZ04A0Vp_A@mail.gmail.com>

?AIC

-- Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Fri, Aug 21, 2015 at 5:47 AM, Babatunde Yakub via R-help
<r-help at r-project.org> wrote:
> I want to know how to extract or compute the AIC and BIC measures of a conway maxwell poisson regression model.Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter.langfelder at gmail.com  Fri Aug 21 18:09:12 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 21 Aug 2015 09:09:12 -0700
Subject: [R] glm help
In-Reply-To: <CAGxFJbTya=hVwOoA0k041tqPvGFfdVAmos9g6ZR0Zxp-UcUPVw@mail.gmail.com>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
	<8B38BCEE-F8A2-4D0B-81EC-21D7A3CB0139@comcast.net>
	<CAGxFJbR1raq9RCZeP7v9x2DCm8F3u-BfYr4FL6+dM++79CRsGw@mail.gmail.com>
	<CA+hbrhVtvDneEzx5ni=MXOdjJeaVFsO3HnXwmsuTZ=d1Qte4YA@mail.gmail.com>
	<CAGxFJbTya=hVwOoA0k041tqPvGFfdVAmos9g6ZR0Zxp-UcUPVw@mail.gmail.com>
Message-ID: <CA+hbrhWKMJ08fbw3BLRiMKVfCXkyx+sgXqJFV7ZTu7VhBL2xTw@mail.gmail.com>

Thanks for the correction, I learned something new.

Peter

On Fri, Aug 21, 2015 at 7:32 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Inline.
>
> -- Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Thu, Aug 20, 2015 at 10:47 PM, Peter Langfelder
> <peter.langfelder at gmail.com> wrote:
>> On Thu, Aug 20, 2015 at 10:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>>>> I noticed you made two data-frames, ?my4s' and ?my4S'. The `my4S` was built with `cbind` which would create a matrix (probably a character matrix) rather than a data frame.
>>>
>>> False. There is a data.frame method for cbind that returns a data
>>> frame. Don't know the specifics here, though.
>>>
>>
>> True, but does not apply here, i.e., David is correct. cbind will
>> return a data frame if the first argument is a data frame. In the OP
>> case, the first argument was a vector and hence cbind gives a matrix,
>
> False again.
>
> class(cbind(a=1:5,b=data.frame(a=letters[1:5],b=3:7)))
>
> [1] "data.frame"
>
> ##First argument a vector, but data frame is returned. Please consult
> ?cbind -- especially the data frame section -- for details.
>
> Again, I don't know the specifics here, and you and David may still
> well be right for what the OP did. I am only trying to correct what
> appear to me to be incorrect statements about the data.frame method of
> cbind (or rbind). Apologies if I have misinterpreted.
>
> Cheers,
> Bert
>
>
>
>> of mode "character" if any of the inputs were character. Here's a
>> short demo:
>>
>>> a = data.frame(a1 = 1:10)
>> # First argument a data frame, so the results is also a data frame  :
>>> class(cbind(a, b = 11:20))
>> [1] "data.frame"
>> # First argument is a vector, so the result is a matrix:
>>> class(cbind(a$a1, b = 11:20))
>> [1] "matrix"
>>> mode(cbind(a$a1, b = 11:20))
>> [1] "numeric"
>>> mode(cbind(a$a1, b = letters[11:20]))
>> [1] "character"
>>
>> Peter


From jdnewmil at dcn.davis.CA.us  Fri Aug 21 18:52:52 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 21 Aug 2015 09:52:52 -0700
Subject: [R] Output In R
In-Reply-To: <1440134718677-4711335.post@n4.nabble.com>
References: <1439901681930-4711227.post@n4.nabble.com>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
	<CAAxdm-4p1Vpz-6LuiCMtTRfv_Z7213juH7kxX8Z-2ZuqKpF0Tw@mail.gmail.com>
	<1440134718677-4711335.post@n4.nabble.com>
Message-ID: <62971056-D9D2-47CF-8FB0-CDFE99865E27@dcn.davis.CA.us>

You really should not be using the console as a way to transfer large amounts of data. CSV files are much better, because sane people don't spend their time looking through thousands of rows of data. You should be giving the data to users in a form where they can filter it down for their needs, or better yet you should be filtering it for them to obtain more focused results. 

If you won't be dissuaded from dumping this data on people then Sweave and rmarkdown can be used for making large tables. The nuts and bolts of those tools are not really on topic here because they involve only a very little R but mostly need skills in LaTeX or HTML/CSS respectively.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 20, 2015 10:25:18 PM PDT, Shivi82 <shivibhatia at ymail.com> wrote:
>Hi Jim,
>
>Please see the sample code:
>ak<-read.csv("June.csv", header = TRUE)
>ak%>%select(sfxcode,mod,chargedweight)%>%filter(mod=='AIR')
>
>what i am trying to find is selecting the required var and then
>selecting
>only AIR as a mode of transportation from mod.
>I am getting the output but the total rows which fulfil this condition
>is
>10500 where console shows only 3300. 
>I want to share the output i.e. 10500 rows to my business. So want to
>see
>the possible options to share the results with the business. R Markdown
>& R
>Sweave might help - please suggest. 
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711335.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Fri Aug 21 19:00:38 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 21 Aug 2015 13:00:38 -0400
Subject: [R] accessing CRAN through a proxy on 3.2.2
Message-ID: <CAAxdm-72CjKQthjnOCjyNrEPA0ZFGQyNeKCeYgqbppExt9ocNA@mail.gmail.com>

With the previous versions of R (my latest is 3.2.1) I have had no problem
getting through the proxy for the firewall at work.  I installed the latest
version (3.2.2) and now cannot get through the firewall.  There is the
session:

R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)
R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.
  Natural language support but running in an English locale
R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
> Sys.setenv(http_proxy = "http://10.254.16.12:3128/", http_proxy_user =
"ask")
> utils:::menuInstallPkgs()
--- Please select a CRAN mirror for use in this session ---
Error in download.file(url, destfile = f, quiet = TRUE) :
  cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
In addition: Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
  cannot open: HTTP status was '407 Proxy Authentication Required'
Warning: unable to access index for repository
https://rweb.crmda.ku.edu/cran/src/contrib
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/src/contrib
Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
type) :
  no packages were specified
> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1
locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
[3] LC_MONETARY=English_United States.1252
LC_NUMERIC=C
[5] LC_TIME=English_United States.1252
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
loaded via a namespace (and not attached):
[1] tools_3.2.2
>

I was running with "--vanilla" on the RGUI.  I have seen that there were
some other people having issues with 3.2.2 and proxies.  Is there a fix out
there, or are there some other options I need to setup for 3.2.2 to access
through a proxy?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

	[[alternative HTML version deleted]]


From joaquin.aldabe at gmail.com  Fri Aug 21 19:06:27 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Fri, 21 Aug 2015 14:06:27 -0300
Subject: [R] glm help
In-Reply-To: <20E8DC1B-2F9E-4CF9-9C34-D6DD65D6496D@uw.edu>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
	<CAMM93=Lq4m-zgvqgF1GD-M9-c1j3sruRsBPOCv1moVj=RyE1Jg@mail.gmail.com>
	<20E8DC1B-2F9E-4CF9-9C34-D6DD65D6496D@uw.edu>
Message-ID: <CAMM93=LC0qm1fNNnaEpaX37pw1+bGHxZDMPj2w3xYJQY0FUUcQ@mail.gmail.com>

Thanks. Here is in csv format.
Cheers,
Joaqu?n.

2015-08-21 12:49 GMT-03:00 Don McKenzie <dmck at uw.edu>:

> You can save to .csv from OpenOffice.
>
> Sent from my iPad
>
> > On Aug 21, 2015, at 4:45 AM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
> wrote:
> >
> > Thankyou all by the comments and sorry for not sending in the adequate
> > format. I don't have the chance to make txt archives as open office
> doesn't
> > do it. I'm attaching the data in excel. Please let me know if this is ok.
> >
> > The graph that is wierd to me is the BBSA vs AMGP. It is supposed that
> AMGP
> > has a positive effect on BBSA, but the model fit shows a negative slope.
> In
> > other forum I was told to plot each variable with fixed values of the
> other
> > two variables, and make different curves for each variable.
> >
> > Thanks again for your interest and help.
> >
> > All the best,
> > Joaqu?n
> >
> > 2015-08-19 12:54 GMT-03:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
> >
> >> Dear All, I?m running a glm with poisson errors and have a doubt when
> >> ploting the predicted values. One of my variables has a positive slope
> in
> >> the summary output, but when I plot the predicted values on the original
> >> plot it draws a line with negative slope. I appreciate your comments on
> >> this and any other aspect of the analysis.
> >>
> >> Attached is the script and data in different formats just in case.
> >>
> >> Thanks in advanced,
> >>
> >> Joaqu?n.
> >>
> >>
> >> --
> >> *Joaqu?n Aldabe*
> >>
> >> *Grupo Biodiversidad, Ambiente y Sociedad*
> >> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> >> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >>
> >> *Departamento de Conservaci?n*
> >> Aves Uruguay
> >> BirdLife International
> >> Canelones 1164, Montevideo
> >>
> >> https://sites.google.com/site/joaquin.aldabe
> >> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> >>
> >>
> >
> >
> > --
> > *Joaqu?n Aldabe*
> >
> > *Grupo Biodiversidad, Ambiente y Sociedad*
> > Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> > Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> >
> > *Departamento de Conservaci?n*
> > Aves Uruguay
> > BirdLife International
> > Canelones 1164, Montevideo
> >
> > https://sites.google.com/site/joaquin.aldabe
> > <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

From dwinsemius at comcast.net  Fri Aug 21 19:39:59 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Aug 2015 10:39:59 -0700
Subject: [R] glm help
In-Reply-To: <CAMM93=LC0qm1fNNnaEpaX37pw1+bGHxZDMPj2w3xYJQY0FUUcQ@mail.gmail.com>
References: <CAMM93=KBhW=4h-Mi9bJp2cDA7TkQ_FkPwGB_TOw=GRA1QiBoWg@mail.gmail.com>
	<CAMM93=Lq4m-zgvqgF1GD-M9-c1j3sruRsBPOCv1moVj=RyE1Jg@mail.gmail.com>
	<20E8DC1B-2F9E-4CF9-9C34-D6DD65D6496D@uw.edu>
	<CAMM93=LC0qm1fNNnaEpaX37pw1+bGHxZDMPj2w3xYJQY0FUUcQ@mail.gmail.com>
Message-ID: <A43B195E-ABFF-48AF-A736-C0180FB3E825@comcast.net>

.csv format is still not accepted by the server. When I say it needs to be a .txt file  .... I mean it it needs to be a .txt file. You need to change its extension to .txt to prevent your mail client from labeling it as csv which is a different type even though I, too, would have thought they should both be accepted.

I do now see that the last argument to cbind was a dataframe and Bert's comments there were correct. I did not see that tiny little `my4s` way out at at the end of all those other arguments. 
-- 
David.

On Aug 21, 2015, at 10:06 AM, Joaqu?n Aldabe wrote:

> Thanks. Here is in csv format.
> Cheers,
> Joaqu?n.
> 
> 2015-08-21 12:49 GMT-03:00 Don McKenzie <dmck at uw.edu>:
> 
>> You can save to .csv from OpenOffice.
>> 
>> Sent from my iPad
>> 
>>> On Aug 21, 2015, at 4:45 AM, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
>> wrote:
>>> 
>>> Thankyou all by the comments and sorry for not sending in the adequate
>>> format. I don't have the chance to make txt archives as open office
>> doesn't
>>> do it. I'm attaching the data in excel. Please let me know if this is ok.
>>> 
>>> The graph that is wierd to me is the BBSA vs AMGP. It is supposed that
>> AMGP
>>> has a positive effect on BBSA, but the model fit shows a negative slope.
>> In
>>> other forum I was told to plot each variable with fixed values of the
>> other
>>> two variables, and make different curves for each variable.
>>> 
>>> Thanks again for your interest and help.
>>> 
>>> All the best,
>>> Joaqu?n
>>> 
>>> 2015-08-19 12:54 GMT-03:00 Joaqu?n Aldabe <joaquin.aldabe at gmail.com>:
>>> 
>>>> Dear All, I?m running a glm with poisson errors and have a doubt when
>>>> ploting the predicted values. One of my variables has a positive slope
>> in
>>>> the summary output, but when I plot the predicted values on the original
>>>> plot it draws a line with negative slope. I appreciate your comments on
>>>> this and any other aspect of the analysis.
>>>> 
>>>> Attached is the script and data in different formats just in case.
>>>> 
>>>> Thanks in advanced,
>>>> 
>>>> Joaqu?n.
>>>> 
>>>> 
>>>> --
>>>> *Joaqu?n Aldabe*
>>>> 
>>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>>> 
>>>> *Departamento de Conservaci?n*
>>>> Aves Uruguay
>>>> BirdLife International
>>>> Canelones 1164, Montevideo
>>>> 
>>>> https://sites.google.com/site/joaquin.aldabe
>>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>>> 
>>>> 
>>> 
>>> 
>>> --
>>> *Joaqu?n Aldabe*
>>> 
>>> *Grupo Biodiversidad, Ambiente y Sociedad*
>>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
>>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>> 
>>> *Departamento de Conservaci?n*
>>> Aves Uruguay
>>> BirdLife International
>>> Canelones 1164, Montevideo
>>> 
>>> https://sites.google.com/site/joaquin.aldabe
>>> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> *Joaqu?n Aldabe*
> 
> *Grupo Biodiversidad, Ambiente y Sociedad*
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
> 
> *Departamento de Conservaci?n*
> Aves Uruguay
> BirdLife International
> Canelones 1164, Montevideo
> 
> https://sites.google.com/site/joaquin.aldabe
> <https://sites.google.com/site/perfilprofesionaljoaquinaldabe>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Aug 21 20:40:52 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Aug 2015 11:40:52 -0700
Subject: [R] Generalised poisson regression
In-Reply-To: <39823553.5046111.1440159724900.JavaMail.yahoo@mail.yahoo.com>
References: <39823553.5046111.1440159724900.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D7E55C73-C455-4F3B-B2D9-F513B9DCB834@comcast.net>


On Aug 21, 2015, at 5:22 AM, Babatunde Yakub via R-help wrote:

> I want to know how to extract or obtain the deviance for a fitted generalised poisson regression model. Thanks in advance

If you post the code and some sample data, for building such a model, I'm sure someone can help you extract the deviance. If you simply mean what is returned by an ordinary glm-call with family="poisson" then deviance should be one of the elements of the glm-object.


object$deviance

> 	[[alternative HTML version deleted]]

When you do reply (if needed) please send in plain text rather than HTML.

-- 
David Winsemius
Alameda, CA, USA


From michael.weylandt at gmail.com  Fri Aug 21 20:55:21 2015
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Fri, 21 Aug 2015 13:55:21 -0500
Subject: [R] accessing CRAN through a proxy on 3.2.2
In-Reply-To: <CAAxdm-72CjKQthjnOCjyNrEPA0ZFGQyNeKCeYgqbppExt9ocNA@mail.gmail.com>
References: <CAAxdm-72CjKQthjnOCjyNrEPA0ZFGQyNeKCeYgqbppExt9ocNA@mail.gmail.com>
Message-ID: <CAAmySGMKrLf6GV2VMXBVy1YpgioDTvATHKXEkp0GATQLD9YCQQ@mail.gmail.com>

On Fri, Aug 21, 2015 at 12:00 PM, jim holtman <jholtman at gmail.com> wrote:
> With the previous versions of R (my latest is 3.2.1) I have had no problem
> getting through the proxy for the firewall at work.  I installed the latest
> version (3.2.2) and now cannot get through the firewall.  There is the
> session:
>
> R version 3.2.2 (2015-08-14) -- "Fire Safety"
> Copyright (C) 2015 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>   Natural language support but running in an English locale
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>> Sys.setenv(http_proxy = "http://10.254.16.12:3128/", http_proxy_user =
> "ask")
>> utils:::menuInstallPkgs()
> --- Please select a CRAN mirror for use in this session ---
> Error in download.file(url, destfile = f, quiet = TRUE) :
>   cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
> In addition: Warning message:
> In download.file(url, destfile = f, quiet = TRUE) :
>   cannot open: HTTP status was '407 Proxy Authentication Required'
> Warning: unable to access index for repository
> https://rweb.crmda.ku.edu/cran/src/contrib
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/src/contrib
> Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
> type) :
>   no packages were specified
>> sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252
> LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> loaded via a namespace (and not attached):
> [1] tools_3.2.2
>>
>
> I was running with "--vanilla" on the RGUI.  I have seen that there were
> some other people having issues with 3.2.2 and proxies.  Is there a fix out
> there, or are there some other options I need to setup for 3.2.2 to access
> through a proxy?

Try setInternet2() (or the equivalent command line flag).

Michael


From jholtman at gmail.com  Fri Aug 21 22:17:01 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 21 Aug 2015 16:17:01 -0400
Subject: [R] accessing CRAN through a proxy on 3.2.2
In-Reply-To: <CAAmySGMKrLf6GV2VMXBVy1YpgioDTvATHKXEkp0GATQLD9YCQQ@mail.gmail.com>
References: <CAAxdm-72CjKQthjnOCjyNrEPA0ZFGQyNeKCeYgqbppExt9ocNA@mail.gmail.com>
	<CAAmySGMKrLf6GV2VMXBVy1YpgioDTvATHKXEkp0GATQLD9YCQQ@mail.gmail.com>
Message-ID: <CAAxdm-5t7U-Qd9akN_N===m-BTGfoGoe79U94cA+feNkk4EMrg@mail.gmail.com>

Thanks.  I did find out that for my work environment if I use

setInternet(FALSE)

then everything seems to work again.  They changed the default to TRUE in
3.2.2 and that must have been causing the problem.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Aug 21, 2015 at 2:55 PM, Michael Weylandt <
michael.weylandt at gmail.com> wrote:

> On Fri, Aug 21, 2015 at 12:00 PM, jim holtman <jholtman at gmail.com> wrote:
> > With the previous versions of R (my latest is 3.2.1) I have had no
> problem
> > getting through the proxy for the firewall at work.  I installed the
> latest
> > version (3.2.2) and now cannot get through the firewall.  There is the
> > session:
> >
> > R version 3.2.2 (2015-08-14) -- "Fire Safety"
> > Copyright (C) 2015 The R Foundation for Statistical Computing
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > You are welcome to redistribute it under certain conditions.
> > Type 'license()' or 'licence()' for distribution details.
> >   Natural language support but running in an English locale
> > R is a collaborative project with many contributors.
> > Type 'contributors()' for more information and
> > 'citation()' on how to cite R or R packages in publications.
> > Type 'demo()' for some demos, 'help()' for on-line help, or
> > 'help.start()' for an HTML browser interface to help.
> > Type 'q()' to quit R.
> >> Sys.setenv(http_proxy = "http://10.254.16.12:3128/", http_proxy_user =
> > "ask")
> >> utils:::menuInstallPkgs()
> > --- Please select a CRAN mirror for use in this session ---
> > Error in download.file(url, destfile = f, quiet = TRUE) :
> >   cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv'
> > In addition: Warning message:
> > In download.file(url, destfile = f, quiet = TRUE) :
> >   cannot open: HTTP status was '407 Proxy Authentication Required'
> > Warning: unable to access index for repository
> > https://rweb.crmda.ku.edu/cran/src/contrib
> > Warning: unable to access index for repository
> > http://www.stats.ox.ac.uk/pub/RWin/src/contrib
> > Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
> =
> > type) :
> >   no packages were specified
> >> sessionInfo()
> > R version 3.2.2 (2015-08-14)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> > locale:
> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> > States.1252
> > [3] LC_MONETARY=English_United States.1252
> > LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> > loaded via a namespace (and not attached):
> > [1] tools_3.2.2
> >>
> >
> > I was running with "--vanilla" on the RGUI.  I have seen that there were
> > some other people having issues with 3.2.2 and proxies.  Is there a fix
> out
> > there, or are there some other options I need to setup for 3.2.2 to
> access
> > through a proxy?
>
> Try setInternet2() (or the equivalent command line flag).
>
> Michael
>

	[[alternative HTML version deleted]]


From eladlazar22 at gmail.com  Fri Aug 21 20:52:52 2015
From: eladlazar22 at gmail.com (ELAD LAZAR)
Date: Fri, 21 Aug 2015 11:52:52 -0700 (PDT)
Subject: [R] fill color in boxplot and change number in scale
In-Reply-To: <9FA7CE3DEA9.000009CEjrkrideau@inbox.com>
References: <CAANc9U3kn1Vz4irs=YG=ONqP39ZWbqPF5CO69ND2ss25FMG=jw@mail.gmail.com>
	<9FA7CE3DEA9.000009CEjrkrideau@inbox.com>
Message-ID: <CAANc9U22K4N-ovhdWHK-Wg_4PyvOPsW0Ecdwm4oV9n9hzLE6GQ@mail.gmail.com>

I want to change the numbers in scale Y to c(0,-2.5) from (0,-10) only.

and I want to change the color green to yellow and blue to green in the
boxplot.

Thank you

On Fri, Aug 21, 2015 at 6:28 PM, John Kane [via R] <
ml-node+s789695n4711353h9 at n4.nabble.com> wrote:

> Would this help on colour?
>
> http://stackoverflow.com/questions/8320462/ggplot2-how-to-adjust-fill-colour-in-a-boxplot-and-change-legend-text
>
> You don't say what you want to with the numbers in scale (what scale?)
> You might want to try something like ?scale_manual and then do some
> googling.
>
> Note almost all the code you provided is redundent for the problem. We
> probably should have the data however . See ?dput or read ttp://
> stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> and/or  http://adv-r.had.co.nz/Reproducibility.html for some hints on how
> to frame the question and supply data.
>
>
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: [hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711353&i=0>
> > Sent: Fri, 21 Aug 2015 14:10:23 +0300
> > To: [hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711353&i=1>
> > Subject: [R] fill color in boxplot and change number in scale
> >
> > hello,
> > I want to change the line color and/or fill of each boxplot and  change
> > number in scale
> > what I need to do?
> >
> >
> > ylim<-c(-3,0.5)
> > data.for.plot<-data.frame(accelaration=data_2$lag1min_accelaration,
> >                           lag=1,
> >                           alert='red')
> > data.for.plot<-rbind(data.for.plot,
> >                       data.frame(accelaration=data_2$min_accelaration,
> >                           lag=0,
> >                           alert='red'))
> >
> > data.for.plot<-rbind(data.for.plot,
> >
> > data.frame(accelaration=data_1$lag1min_accelaration,
> >                           lag=1,
> >                           alert='yellow'))
> > data.for.plot<-rbind(data.for.plot,
> >                      data.frame(accelaration=data_1$min_accelaration,
> >                                 lag=0,
> >                                 alert='yellow'))
> >
> > data.for.plot<-rbind(data.for.plot,
> >   data.frame(accelaration=data_0$lag1min_accelaration,
> >              lag=1,
> >              alert='no alert'))
> > data.for.plot<-rbind(data.for.plot,
> >                      data.frame(accelaration=data_0$min_accelaration,
> >                                 lag=0,
> >                                 alert='no alert'))
> > library('ggplot2')
> > ggplot(data.for.plot,aes(fill=factor(alert),
> >                          y=accelaration,x=factor(lag)))+
> >   geom_boxplot()
> > ______________________________________________
> > [hidden email] <http:///user/SendEmail.jtp?type=node&node=4711353&i=2>
> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> [hidden email] <http:///user/SendEmail.jtp?type=node&node=4711353&i=3>
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ------------------------------
> If you reply to this email, your message will be added to the discussion
> below:
>
> http://r.789695.n4.nabble.com/fill-color-in-boxplot-and-change-number-in-scale-tp4711348p4711353.html
> To start a new topic under R help, email
> ml-node+s789695n789696h42 at n4.nabble.com
> To unsubscribe from R help, click here
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=789696&code=ZWxhZGxhemFyMjJAZ21haWwuY29tfDc4OTY5NnwtMTc0ODMyNzg0MQ==>
> .
> NAML
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/fill-color-in-boxplot-and-change-number-in-scale-tp4711348p4711364.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From andrew_park at airpost.net  Fri Aug 21 20:59:42 2015
From: andrew_park at airpost.net (Andrew Park)
Date: Fri, 21 Aug 2015 11:59:42 -0700 (PDT)
Subject: [R] Error in dis[sppInSample,
	sppInSample]:subscript out of bounds
In-Reply-To: <SNT150-W66B7B542645583FD0BEE7CF0F30@phx.gbl>
References: <SNT150-W66B7B542645583FD0BEE7CF0F30@phx.gbl>
Message-ID: <1440183582771-4711366.post@n4.nabble.com>

I'm pretty sure you are using the package Picante. When I received the error
you described in my own project, it was due to the naming of species in the
community matrix and the phylogenetic tree being slightly different (one
separated latin binomials with a space, the other with an underscore). When
I corrected one set of names (using gsub) to be identical to the other then
the error went away. I hope this helps.



--
View this message in context: http://r.789695.n4.nabble.com/Error-in-dis-sppInSample-sppInSample-subscript-out-of-bounds-tp4705418p4711366.html
Sent from the R help mailing list archive at Nabble.com.


From shivibhatia at ymail.com  Fri Aug 21 21:26:50 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Fri, 21 Aug 2015 12:26:50 -0700 (PDT)
Subject: [R] Output In R
In-Reply-To: <62971056-D9D2-47CF-8FB0-CDFE99865E27@dcn.davis.CA.us>
References: <1439901681930-4711227.post@n4.nabble.com>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
	<CAAxdm-4p1Vpz-6LuiCMtTRfv_Z7213juH7kxX8Z-2ZuqKpF0Tw@mail.gmail.com>
	<1440134718677-4711335.post@n4.nabble.com>
	<62971056-D9D2-47CF-8FB0-CDFE99865E27@dcn.davis.CA.us>
Message-ID: <1440185210948-4711368.post@n4.nabble.com>

Thanks Jeff, this is helpful. 
The reason i am curious to know this is because I have worked for a long
duration in SAS where in it gives us the flexibility to create a data set of
our analysis and then we can easily detail out the same to the end user.

In R seems like View or Sweave  or Shiny are the alternative.




--
View this message in context: http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711368.html
Sent from the R help mailing list archive at Nabble.com.


From rv15i at yahoo.se  Sat Aug 22 10:50:00 2015
From: rv15i at yahoo.se (ravi)
Date: Sat, 22 Aug 2015 08:50:00 +0000 (UTC)
Subject: [R] plotting over a raster image with control over location and
 orientation
In-Reply-To: <2048639744.8977490.1440167432929.JavaMail.yahoo@mail.yahoo.com>
References: <2048639744.8977490.1440167432929.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1591601188.65252.1440233400745.JavaMail.yahoo@mail.yahoo.com>

Hi,I havetried to find a simple way for my overlay plot. A simple summary of myapproach would to first plot the raster image and then overlay the second pot with :
par(new=TRUE,plt=c(x1,x2,y1,y2)) # not sure if the plt or usr argument should be used# have some difficulty in knowing the units for x1,x2,y1 and y2
plot(1:10,1:10)#justan example plot
But my problem is that I do not understand the unit conversions for graphics. What exactly are "npc" and "native"?Let me explain by starting with the code again:#Setting up the initial example raster image
library(grid)
x <- y <- c(-15,seq(-4*pi, 4*pi, len=27),15)
r <- sqrt(outer(x^2, y^2, "+"))
z <- cos(r^2)*exp(-r/6)
image <- (z - min(z))/diff(range(z))
plot(x, y, ann=FALSE,xaxs="i", yaxs="i")
rasterImage(image,xrange[1], yrange[1],xrange[2], yrange[2],interpolate=FALSE)# let's say that I want to draw an overlay plot with the follwing line as x-axis
lines(c(-10,10),c(-12,-12),col="red",lwd=2)

lim<-par("usr")
lim
limplt<-par("plt")
limplt

#convertX(unit(0:1,"npc"),"native")
convertX(unit(-10,"native"),"npc")
convertX(unit(10,"native"),"npc")
convertY(unit(-12,"native"),"npc")
> lim<-par("usr")
> lim
[1] -15  15 -15  15
> limplt<-par("plt")
> limplt
[1] 0.09132251 0.95322506 0.18000000 0.85529412
> 
> #convertX(unit(0:1,"npc"),"native")
> convertX(unit(-10,"native"),"npc")
[1] -0.0116009280742459npc
> convertX(unit(10,"native"),"npc")
[1] 0.0116009280742459npc
> convertY(unit(-12,"native"),"npc")
[1] 1.02205882352941npc


These converted values and the values for the limplt variable do not seem to be in agreement. How do I convert, for example, the point (10,-12) to "npc" units?

I hope that I have explained my problem sufficiently well. If I can get help with an approach involving viewports also, I would be grateful for any help that I can get.
Thanks,
Ravi

      From: ravi <rv15i at yahoo.se>
 To: R-help <r-help at r-project.org> 
 Sent: Friday, 21 August 2015, 16:30
 Subject: plotting over a raster image with control over location and orientation
   
Hi,I would like to get some help in plotting over an image. I have a png image over which I would like to have a plot. I would like to be able to control the location, area and orientation of the plot on the image.
I have taken help from the following references :http://journal.r-project.org/archive/2011-1/RJournal_2011-1_Murrell.pdfhttp://stackoverflow.com/questions/12918367/in-r-how-to-plot-with-a-png-as-background
In order to give a reproducible example, I set up my image with the help of some code from the the first reference above.

#Setting up the initial example raster image
x <- y <- seq(-4*pi, 4*pi, len=27)
r <- sqrt(outer(x^2, y^2, "+"))
z <- cos(r^2)*exp(-r/6)
image <- (z - min(z))/diff(range(z))
step <- diff(x)[1]
xrange <- range(x) + c(-step/2, step/2)
yrange <- range(y) + c(-step/2, step/2)
plot(x, y, ann=FALSE,xlim=xrange, ylim=yrange,xaxs="i", yaxs="i")
rasterImage(image,xrange[1], yrange[1],xrange[2], yrange[2],interpolate=FALSE)

# the explanation of my problem starts here
# First, I want to mark out a particular line
lines(c(10,10.5),c(-10.5,10),col="red",lwd=2)
#In my problem, I have to locate these points graphically from the image
calpoints <- locator(n=2,type='p',pch=4,col='blue',lwd=2)
# this gives the line corresponding to the x-axis for my overlay plot
# I don't want the red line on my plot
#the red line plotted earlier is just to show the example location
newOrigin<-calpoints[1]
xLimit<-calpoints[2]#xlimit marks the limit of the x-axis on the image# on this new line as the x-axis, I want to make a new plot# the y-axis should be perpendicular to the x-axis. I would like to be able to specify the width of coverage over the image#example
xx<-1:10
yy<-xx^2
plot(xx,yy,xlim=range(xx),ylim=range(yy),col="blue",type="b",xlab="x",ylab="square of x")
# I would prefer to have the image more transparent just under the x and y labels and axis labelsThanks, Ravi



   
	[[alternative HTML version deleted]]


From rv15i at yahoo.se  Sat Aug 22 14:32:03 2015
From: rv15i at yahoo.se (ravi)
Date: Sat, 22 Aug 2015 12:32:03 +0000 (UTC)
Subject: [R] plotting over a raster image with control over location and
 orientation
In-Reply-To: <1591601188.65252.1440233400745.JavaMail.yahoo@mail.yahoo.com>
References: <2048639744.8977490.1440167432929.JavaMail.yahoo@mail.yahoo.com>
	<1591601188.65252.1440233400745.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1208388625.140155.1440246723749.JavaMail.yahoo@mail.yahoo.com>

Hi,I am sorry for not having control checked the code before posting (in my earlier mail). I have done this now. 
I just have a simple question now. Why is the overlay plot (the final plot ) not falling into the intended position (as defined by the viewport vp2)?#Setting up the initial example raster image
library(grid)
x <- y <- c(-15,seq(-4*pi, 4*pi, len=27),15)
r <- sqrt(outer(x^2, y^2, "+"))
z <- cos(r^2)*exp(-r/6)
image <- (z - min(z))/diff(range(z))
xrange <- range(x)
yrange <- range(y)

vp1<-viewport(x = unit(0.5, "npc"), y = unit(0.5, "npc"),
???????? width = unit(1, "npc"), height = unit(1, "npc"),
???????? default.units = "npc", just = c("left","bottom"),name="vp1")
pushViewport(vp1)
plot(x, y, ann=FALSE,xlim=xrange, ylim=yrange,xaxs="i", yaxs="i")
rasterImage(image,xrange[1], yrange[1],xrange[2], yrange[2],interpolate=FALSE)
lines(c(-10,4),c(-12,-12),col="red",lwd=2)

lim<-par("usr")
lim
limplt<-par("plt")
limplt
#par(new=TRUE,plt=c(limplt[1],limplt[2],limplt[3]))

#convertX(unit(0:1,"npc"),"native")
x1<-convertX(unit(-10,"native"),"npc")
x2<-convertX(unit(5,"native"),"npc")
y1<-convertY(unit(-12,"native"),"npc")
y2<-convertY(unit(3,"native"),"npc")

wx<-(5-(-10))/(15-(-15))
wy<-(3-(-12))/(15-(-15))

xw<-convertWidth(unit(wx,"native"),"npc")
yw<-convertHeight(unit(wy,"native"),"npc")


vp2<-viewport(x = unit(x1, "npc"), y = unit(y1, "npc"),
????????????? width = unit(xw, "npc"), height = unit(yw, "npc"),
????????????? default.units = "npc", name="vp2")
pushViewport(vp2)
#data with a different scale
xs<-seq(0.01,0.1,0.01)ys<-xs^2
#points(xs,ys,type='b',col='red',newpage=FALSE)

plot(xs,ys,type='b',col='red') #fills the whole screen instead of just the intended viewport


Thanks,Ravi


   

  
	[[alternative HTML version deleted]]


From shivibhatia at ymail.com  Sat Aug 22 09:43:05 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Sat, 22 Aug 2015 00:43:05 -0700 (PDT)
Subject: [R] Date as Integer
Message-ID: <1440229385099-4711377.post@n4.nabble.com>

Hi All,

I am using dplyr package and need to find total bills booked grouped on a
date level however my date is integer. 
In the code below i was trying to change date format from integer. However
it is throwing an error:

"no applicable method for 'group_by_' applied to an object of class
"c('integer', 'numeric')"

ak%>%
  group_by(as.Date(pickdate),"%y%m%d")%>%
  summarise(Total=count(waybill))

Do i need to create a new var first changing the date and then group it or
as.Date will work as i added in dplyr.





--
View this message in context: http://r.789695.n4.nabble.com/Date-as-Integer-tp4711377.html
Sent from the R help mailing list archive at Nabble.com.


From jrkrideau at inbox.com  Sat Aug 22 14:44:35 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 22 Aug 2015 04:44:35 -0800
Subject: [R] fill color in boxplot and change number in scale
In-Reply-To: <CAANc9U22K4N-ovhdWHK-Wg_4PyvOPsW0Ecdwm4oV9n9hzLE6GQ@mail.gmail.com>
References: <caanc9u3kn1vz4irs=yg=onqp39zwbqpf5co69nd2ss25fmg=jw@mail.gmail.com>
	<9fa7ce3dea9.000009cejrkrideau@inbox.com>
Message-ID: <AAC61215E12.00000370jrkrideau@inbox.com>

Data? Please use dput() 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: eladlazar22 at gmail.com
> Sent: Fri, 21 Aug 2015 11:52:52 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] fill color in boxplot and change number in scale
> 
> I want to change the numbers in scale Y to c(0,-2.5) from (0,-10) only.
> 
> and I want to change the color green to yellow and blue to green in the
> boxplot.
> 
> Thank you
> 
> On Fri, Aug 21, 2015 at 6:28 PM, John Kane [via R] <
> ml-node+s789695n4711353h9 at n4.nabble.com> wrote:
> 
>> Would this help on colour?
>> 
>> http://stackoverflow.com/questions/8320462/ggplot2-how-to-adjust-fill-colour-in-a-boxplot-and-change-legend-text
>> 
>> You don't say what you want to with the numbers in scale (what scale?)
>> You might want to try something like ?scale_manual and then do some
>> googling.
>> 
>> Note almost all the code you provided is redundent for the problem. We
>> probably should have the data however . See ?dput or read ttp://
>> stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and/or  http://adv-r.had.co.nz/Reproducibility.html for some hints on
>> how
>> to frame the question and supply data.
>> 
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: [hidden email]
>> <http:///user/SendEmail.jtp?type=node&node=4711353&i=0>
>>> Sent: Fri, 21 Aug 2015 14:10:23 +0300
>>> To: [hidden email]
>> <http:///user/SendEmail.jtp?type=node&node=4711353&i=1>
>>> Subject: [R] fill color in boxplot and change number in scale
>>> 
>>> hello,
>>> I want to change the line color and/or fill of each boxplot and  change
>>> number in scale
>>> what I need to do?
>>> 
>>> 
>>> ylim<-c(-3,0.5)
>>> data.for.plot<-data.frame(accelaration=data_2$lag1min_accelaration,
>>>                           lag=1,
>>>                           alert='red')
>>> data.for.plot<-rbind(data.for.plot,
>>>                       data.frame(accelaration=data_2$min_accelaration,
>>>                           lag=0,
>>>                           alert='red'))
>>> 
>>> data.for.plot<-rbind(data.for.plot,
>>> 
>>> data.frame(accelaration=data_1$lag1min_accelaration,
>>>                           lag=1,
>>>                           alert='yellow'))
>>> data.for.plot<-rbind(data.for.plot,
>>>                      data.frame(accelaration=data_1$min_accelaration,
>>>                                 lag=0,
>>>                                 alert='yellow'))
>>> 
>>> data.for.plot<-rbind(data.for.plot,
>>>   data.frame(accelaration=data_0$lag1min_accelaration,
>>>              lag=1,
>>>              alert='no alert'))
>>> data.for.plot<-rbind(data.for.plot,
>>>                      data.frame(accelaration=data_0$min_accelaration,
>>>                                 lag=0,
>>>                                 alert='no alert'))
>>> library('ggplot2')
>>> ggplot(data.for.plot,aes(fill=factor(alert),
>>>                          y=accelaration,x=factor(lag)))+
>>>   geom_boxplot()
>>> ______________________________________________
>>> [hidden email] <http:///user/SendEmail.jtp?type=node&node=4711353&i=2>
>> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and
>> family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>> ______________________________________________
>> [hidden email] <http:///user/SendEmail.jtp?type=node&node=4711353&i=3>
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> ------------------------------
>> If you reply to this email, your message will be added to the discussion
>> below:
>> 
>> http://r.789695.n4.nabble.com/fill-color-in-boxplot-and-change-number-in-scale-tp4711348p4711353.html
>> To start a new topic under R help, email
>> ml-node+s789695n789696h42 at n4.nabble.com
>> To unsubscribe from R help, click here
>> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=789696&code=ZWxhZGxhemFyMjJAZ21haWwuY29tfDc4OTY5NnwtMTc0ODMyNzg0MQ==>
>> .
>> NAML
>> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>> 
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/fill-color-in-boxplot-and-change-number-in-scale-tp4711348p4711364.html
> Sent from the R help mailing list archive at Nabble.com.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jdnewmil at dcn.davis.CA.us  Sat Aug 22 15:28:36 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 22 Aug 2015 06:28:36 -0700
Subject: [R] Date as Integer
In-Reply-To: <1440229385099-4711377.post@n4.nabble.com>
References: <1440229385099-4711377.post@n4.nabble.com>
Message-ID: <1C31E8B7-F2A9-42BC-85F1-F113B69A3BB0@dcn.davis.CA.us>

Use mutate to change the date before you use group_by.

Posting incomplete fragments in your questions is usually not enough to get useful help with R on the internet. Please add the extra few lines of code that would make it reproducible [1] from now on.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 22, 2015 12:43:05 AM PDT, Shivi82 <shivibhatia at ymail.com> wrote:
>Hi All,
>
>I am using dplyr package and need to find total bills booked grouped on
>a
>date level however my date is integer. 
>In the code below i was trying to change date format from integer.
>However
>it is throwing an error:
>
>"no applicable method for 'group_by_' applied to an object of class
>"c('integer', 'numeric')"
>
>ak%>%
>  group_by(as.Date(pickdate),"%y%m%d")%>%
>  summarise(Total=count(waybill))
>
>Do i need to create a new var first changing the date and then group it
>or
>as.Date will work as i added in dplyr.
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Date-as-Integer-tp4711377.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Sat Aug 22 15:43:54 2015
From: syen04 at gmail.com (Steven Yen)
Date: Sat, 22 Aug 2015 09:43:54 -0400
Subject: [R] Multrix-vector multiplication
Message-ID: <CAKTtY6SvyHDrGxC7a5KV4KPWVv8-Y41SvoKwJ90W3LPhJKpvsA@mail.gmail.com>

I had trouble with matrix multiplication when a matrix reduces to a
vector.  In the following, lines 1 and 2 work when matrices u and a are
both of order 2.
Lines 3 and 5 do not work (message is matrix not conformable) when u is (T
x 1) and a is (1 x 2) and This causes a problem for users of other matrix
languages such as Gauss and MATLAB.
Inserting line 4 makes it work, which is annoying. But, is it proper/safe
to make it work by inserting line 4? Other approaches?
Thank you!

1 a<-solve(s22)%*%s21 # (2 x 2) <- (2 x 2) %*% (2 x 2)
2 uc<-u%*%v$a         # (T x 2) <- (T x 2) %*% (2 x 2)

3 a<-solve(s22)%*%s21 # (1 x 2) <- (1 x 1) %*% (1 x 2)
4 a<-as.matrix(a)     # This line makes it work. OK? Other approaches?
5 uc<-u%*%v$a         # (T x 1) %*% (1 x 2)

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat Aug 22 15:49:32 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 22 Aug 2015 05:49:32 -0800
Subject: [R] Output In R
In-Reply-To: <1440185210948-4711368.post@n4.nabble.com>
References: <62971056-d9d2-47cf-8fb0-cdfe99865e27@dcn.davis.ca.us>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
	<1439901681930-4711227.post@n4.nabble.com>
	<caaxdm-4p1vpz-6luicmttrfv_z7213juh7kxx8z-2zuqkpf0tw@mail.gmail.com>
	<1440134718677-4711335.post@n4.nabble.com>
Message-ID: <AB57401CE2A.000003DCjrkrideau@inbox.com>

We are talking at cross-purposes here because SAS and R are radically different beasts. Just about everything you did in SAS does not work / is wrong /i s illegal/ is immoral / and possibly fattening.

If you have not seen it, you may find Bob?Muenchen's pdf and/or the expanded book R FOR SAS AND SPSS USERS ( https://science.nature.nps.gov/im/datamgmt/statistics/R/documents/R_for_SAS_SPSS_users.pdf ) useful.

It is very easy to create the data set you want. You just need to think in R's somewhat twisted way.  Well if twisted my mind for the first 6 weeks that I used it. 

Let's say you are doing some analysis. Don't send the data to the console. Instead save it in a R object (not sure if this is the correct term--I am sure the purists will correct me.) 


I am going to create a data.frame called dat1 (pretend it is your data).


#create make-believe data
dat1  <-  data.frame(matrix( rnorm(100), ncol = 5))

#Save dat1 as an R file. Handy for your work not great as a way 
#to pass around data unless the client knows R and has R installed

save( dat1, file = "~/Rjunk/ mydata.RData")

#Save as a .csv file. Fast easy and can be opened in any 
#text editor, spreadsheet or even a word processor. 

write.csv(dat1, file = "~/Rjunk/ mydata.csv")



To produce a Latex file and get a pdf.

One starts with a  .Rnw (i.e. plain text with a .Rnw suffix)  file and then compiles it.
I used the command  Rscript -e "library(knitr); knit('./Shiv1.Rnw')" where Shiv.Rnw was my LaTeX / knitr file.  It is easier and faster to use RStudio for  this.

You will probably need to install the xtable package and depending in your LaTeX version you may need to install booktabs. 

########Start Latex file###################
\documentclass[12pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\title{Magnum Opus Meum}
\author{jrkrideau }
\begin{document}

\maketitle

<<atable, echo=FALSE, results="asis">>=
library(xtable) 
dat1  <-  data.frame(matrix( rnorm(100), ncol = 5))
dat1.table  <-  xtable(dat1)
print(dat1.table,
include.rownames=FALSE,
booktabs = TRUE)
@

\end{document}

########End Latex file####################

John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Fri, 21 Aug 2015 12:26:50 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] Output In R
> 
> Thanks Jeff, this is helpful.
> The reason i am curious to know this is because I have worked for a long
> duration in SAS where in it gives us the flexibility to create a data set
> of
> our analysis and then we can easily detail out the same to the end user.
> 
> In R seems like View or Sweave  or Shiny are the alternative.
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711368.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From marc_schwartz at me.com  Sat Aug 22 15:59:37 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sat, 22 Aug 2015 08:59:37 -0500
Subject: [R] Output In R
In-Reply-To: <AB57401CE2A.000003DCjrkrideau@inbox.com>
References: <62971056-d9d2-47cf-8fb0-cdfe99865e27@dcn.davis.ca.us>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
	<1439901681930-4711227.post@n4.nabble.com>
	<caaxdm-4p1vpz-6luicmttrfv_z7213juh7kxx8z-2zuqkpf0tw@mail.gmail.com>
	<1440134718677-4711335.post@n4.nabble.com>
	<AB57401CE2A.000003DCjrkrideau@inbox.com>
Message-ID: <0477CA74-6BDB-4FA0-B5C1-95726A1E1697@me.com>


> On Aug 22, 2015, at 8:49 AM, John Kane <jrkrideau at inbox.com> wrote:
> 
> We are talking at cross-purposes here because SAS and R are radically different beasts. Just about everything you did in SAS does not work / is wrong / is illegal / is immoral / and possibly fattening.


Fortune candidate!

:-)

Regards,

Marc Schwartz


> 
> If you have not seen it, you may find Bob Muenchen's pdf and/or the expanded book R FOR SAS AND SPSS USERS ( https://science.nature.nps.gov/im/datamgmt/statistics/R/documents/R_for_SAS_SPSS_users.pdf ) useful.
> 
> It is very easy to create the data set you want. You just need to think in R's somewhat twisted way.  Well if twisted my mind for the first 6 weeks that I used it. 
> 
> Let's say you are doing some analysis. Don't send the data to the console. Instead save it in a R object (not sure if this is the correct term--I am sure the purists will correct me.) 
> 
> 
> I am going to create a data.frame called dat1 (pretend it is your data).
> 
> 
> #create make-believe data
> dat1  <-  data.frame(matrix( rnorm(100), ncol = 5))
> 
> #Save dat1 as an R file. Handy for your work not great as a way 
> #to pass around data unless the client knows R and has R installed
> 
> save( dat1, file = "~/Rjunk/ mydata.RData")
> 
> #Save as a .csv file. Fast easy and can be opened in any 
> #text editor, spreadsheet or even a word processor. 
> 
> write.csv(dat1, file = "~/Rjunk/ mydata.csv")
> 
> 
> 
> To produce a Latex file and get a pdf.
> 
> One starts with a  .Rnw (i.e. plain text with a .Rnw suffix)  file and then compiles it.
> I used the command  Rscript -e "library(knitr); knit('./Shiv1.Rnw')" where Shiv.Rnw was my LaTeX / knitr file.  It is easier and faster to use RStudio for  this.
> 
> You will probably need to install the xtable package and depending in your LaTeX version you may need to install booktabs. 
> 
> ########Start Latex file###################
> \documentclass[12pt,letterpaper]{article}
> \usepackage[utf8]{inputenc}
> \usepackage{booktabs}
> \title{Magnum Opus Meum}
> \author{jrkrideau }
> \begin{document}
> 
> \maketitle
> 
> <<atable, echo=FALSE, results="asis">>=
> library(xtable) 
> dat1  <-  data.frame(matrix( rnorm(100), ncol = 5))
> dat1.table  <-  xtable(dat1)
> print(dat1.table,
> include.rownames=FALSE,
> booktabs = TRUE)
> @
> 
> \end{document}
> 
> ########End Latex file####################
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: shivibhatia at ymail.com
>> Sent: Fri, 21 Aug 2015 12:26:50 -0700 (PDT)
>> To: r-help at r-project.org
>> Subject: Re: [R] Output In R
>> 
>> Thanks Jeff, this is helpful.
>> The reason i am curious to know this is because I have worked for a long
>> duration in SAS where in it gives us the flexibility to create a data set
>> of
>> our analysis and then we can easily detail out the same to the end user.
>> 
>> In R seems like View or Sweave  or Shiny are the alternative.
>> 
>> 
>> 
>> 
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711368.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Aug 22 16:03:23 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 22 Aug 2015 06:03:23 -0800
Subject: [R] Date as Integer
In-Reply-To: <1440229385099-4711377.post@n4.nabble.com>
Message-ID: <AB763649AB2.000003E8jrkrideau@inbox.com>

Do an str() on the data. It looks like your variable is an integer where you probably need a date or a factor.

Would you please include some sample data if possible. See ?dput which is the preferred way for sending sample data. It ensures that the reader is looking at the exact same data that you have on your machine.  

If the data set is large a small, representative sample is find. Something like dput(head(dat1, 100)) is probably fine. Fake data is okay if it is in the same format as the real.  Check with str() before sending.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: shivibhatia at ymail.com
> Sent: Sat, 22 Aug 2015 00:43:05 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] Date as Integer
> 
> Hi All,
> 
> I am using dplyr package and need to find total bills booked grouped on a
> date level however my date is integer.
> In the code below i was trying to change date format from integer.
> However
> it is throwing an error:
> 
> "no applicable method for 'group_by_' applied to an object of class
> "c('integer', 'numeric')"
> 
> ak%>%
>   group_by(as.Date(pickdate),"%y%m%d")%>%
>   summarise(Total=count(waybill))
> 
> Do i need to create a new var first changing the date and then group it
> or
> as.Date will work as i added in dplyr.
> 
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Date-as-Integer-tp4711377.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jdnewmil at dcn.davis.CA.us  Sat Aug 22 16:30:49 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 22 Aug 2015 07:30:49 -0700
Subject: [R] Multrix-vector multiplication
In-Reply-To: <CAKTtY6SvyHDrGxC7a5KV4KPWVv8-Y41SvoKwJ90W3LPhJKpvsA@mail.gmail.com>
References: <CAKTtY6SvyHDrGxC7a5KV4KPWVv8-Y41SvoKwJ90W3LPhJKpvsA@mail.gmail.com>
Message-ID: <683E2C77-6837-402D-BA96-99B99D911AA3@dcn.davis.CA.us>

The actual types of data you have are critical to understanding your problem, and you have not provided that information. [1] What looks like a matrix isn't always, and in R vectors do not have a "column" or "row" nature, so matrix multiplication is not necessarily well-defined. To get consistent results, make sure you actually are working with matrices rather than vectors, data frames or other data types. The str function is your friend.

Please clarify what data you are actually working with using the dput as described in the link [1]. Also use plain text, as the HTML formatting in your email usually corrupts what you think you see by the time we see it.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 22, 2015 6:43:54 AM PDT, Steven Yen <syen04 at gmail.com> wrote:
>I had trouble with matrix multiplication when a matrix reduces to a
>vector.  In the following, lines 1 and 2 work when matrices u and a are
>both of order 2.
>Lines 3 and 5 do not work (message is matrix not conformable) when u is
>(T
>x 1) and a is (1 x 2) and This causes a problem for users of other
>matrix
>languages such as Gauss and MATLAB.
>Inserting line 4 makes it work, which is annoying. But, is it
>proper/safe
>to make it work by inserting line 4? Other approaches?
>Thank you!
>
>1 a<-solve(s22)%*%s21 # (2 x 2) <- (2 x 2) %*% (2 x 2)
>2 uc<-u%*%v$a         # (T x 2) <- (T x 2) %*% (2 x 2)
>
>3 a<-solve(s22)%*%s21 # (1 x 2) <- (1 x 1) %*% (1 x 2)
>4 a<-as.matrix(a)     # This line makes it work. OK? Other approaches?
>5 uc<-u%*%v$a         # (T x 1) %*% (1 x 2)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Aug 22 16:33:16 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 22 Aug 2015 06:33:16 -0800
Subject: [R] Output In R
In-Reply-To: <AB57401CE2A.000003DCjrkrideau@inbox.com>
References: <62971056-d9d2-47cf-8fb0-cdfe99865e27@dcn.davis.ca.us>
	<871tf039gh.fsf@hornfels.zedat.fu-berlin.de>
	<1439961625598-4711264.post@n4.nabble.com>
	<1439901681930-4711227.post@n4.nabble.com>
	<caaxdm-4p1vpz-6luicmttrfv_z7213juh7kxx8z-2zuqkpf0tw@mail.gmail.com>
	<1440134718677-4711335.post@n4.nabble.com>
	<1440185210948-4711368.post@n4.nabble.com>
Message-ID: <ABB9036252A.0000041Bjrkrideau@inbox.com>

Hi Shivi,
A correction to my latex/knitr code.  I stupidly forgot the initial problem was the length of the data set.  To get it to print correctly we need to use the LaTeX package 'longtable'.  Clearly too many trees for me to see the forest.
Add \usepackage{longtable} to the Preamble.

#==========Revised code for knitr/R========
<<atable, echo=FALSE, results="asis">>=
library(xtable) 
dat1  <-  data.frame(matrix( rnorm(2000), ncol = 5))
dat1.table  <-  xtable(dat1)
print(dat1.table,tabular.environment='longtable',
floating = FALSE,
include.rownames=FALSE,
booktabs = TRUE)
@
#==============end===================

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jrkrideau at inbox.com
> Sent: Sat, 22 Aug 2015 05:49:32 -0800
> To: shivibhatia at ymail.com, r-help at r-project.org
> Subject: Re: [R] Output In R
> 
> We are talking at cross-purposes here because SAS and R are radically
> different beasts. Just about everything you did in SAS does not work / is
> wrong /i s illegal/ is immoral / and possibly fattening.
> 
> If you have not seen it, you may find Bob?Muenchen's pdf and/or the
> expanded book R FOR SAS AND SPSS USERS (
https://science.nature.nps.gov/im/datamgmt/statistics/R/documents/R_for_SAS_SPSS_users.pdf
> ) useful.
> 
> It is very easy to create the data set you want. You just need to think
> in R's somewhat twisted way.  Well if twisted my mind for the first 6
> weeks that I used it.
> 
> Let's say you are doing some analysis. Don't send the data to the
> console. Instead save it in a R object (not sure if this is the correct
> term--I am sure the purists will correct me.)
> 
> 
> I am going to create a data.frame called dat1 (pretend it is your data).
> 
> 
> #create make-believe data
> dat1  <-  data.frame(matrix( rnorm(100), ncol = 5))
> 
> #Save dat1 as an R file. Handy for your work not great as a way
> #to pass around data unless the client knows R and has R installed
> 
> save( dat1, file = "~/Rjunk/ mydata.RData")
> 
> #Save as a .csv file. Fast easy and can be opened in any
> #text editor, spreadsheet or even a word processor.
> 
> write.csv(dat1, file = "~/Rjunk/ mydata.csv")
> 
> 
> 
> To produce a Latex file and get a pdf.
> 
> One starts with a  .Rnw (i.e. plain text with a .Rnw suffix)  file and
> then compiles it.
> I used the command  Rscript -e "library(knitr); knit('./Shiv1.Rnw')"
> where Shiv.Rnw was my LaTeX / knitr file.  It is easier and faster to use
> RStudio for  this.
> 
> You will probably need to install the xtable package and depending in
> your LaTeX version you may need to install booktabs.
> 
> ########Start Latex file###################
> \documentclass[12pt,letterpaper]{article}
> \usepackage[utf8]{inputenc}
> \usepackage{booktabs}
> \title{Magnum Opus Meum}
> \author{jrkrideau }
> \begin{document}
> 
> \maketitle
> 
> <<atable, echo=FALSE, results="asis">>=
> library(xtable)
> dat1  <-  data.frame(matrix( rnorm(100), ncol = 5))
> dat1.table  <-  xtable(dat1)
> print(dat1.table,
> include.rownames=FALSE,
> booktabs = TRUE)
> @
> 
> \end{document}
> 
> ########End Latex file####################
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: shivibhatia at ymail.com
>> Sent: Fri, 21 Aug 2015 12:26:50 -0700 (PDT)
>> To: r-help at r-project.org
>> Subject: Re: [R] Output In R
>> 
>> Thanks Jeff, this is helpful.
>> The reason i am curious to know this is because I have worked for a long
>> duration in SAS where in it gives us the flexibility to create a data
>> set
>> of
>> our analysis and then we can easily detail out the same to the end user.
>> 
>> In R seems like View or Sweave  or Shiny are the alternative.
>> 
>> 
>> 
>> 
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Output-In-R-tp4711227p4711368.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> your desktop!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From arnaud.gaboury at gmail.com  Sat Aug 22 16:51:39 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Sat, 22 Aug 2015 16:51:39 +0200
Subject: [R] Build R with optimized BLAS library
Message-ID: <CAK1hC9tuAW=KnJqFYqnAk+o2MqrV4p_u-=tROopG12YqunZtFw@mail.gmail.com>

I want to build R with an optimized BLAS library.
My OS: Fedora 22
Hardware: CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian
CPU(s): 8 Thread(s) per core: 2 Vendor ID: GenuineIntel Model name:
Intel(R) Core(TM) i7-2600K CPU @ 3.40GHz

I am a little confused when it comes to choose a method and would like
to hear your experiences. If I am right, I have 3 possibilities:
- OpenBLAS: opensource and free, but I came across some posts
describing seg faults issues and bugs. These posts are 2 years old and
I wonder if it is still the case.
- ATLAS: can't see any reason to not use it
- Intel MKL: this is part of Intel Parallel Studio and is a paid
software. Now, there is the MKL package distributed by
Revolutionanalytics, but I am not certain how this can be distributed
for free. Is there any kind of difference? In case of use of this
package, do I need to install RRO or can I just build R from GNU
against these libraries?

Thank you for advices.

-- 

google.com/+arnaudgabourygabx


From jdnewmil at dcn.davis.CA.us  Sat Aug 22 17:12:32 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 22 Aug 2015 08:12:32 -0700
Subject: [R] Build R with optimized BLAS library
In-Reply-To: <CAK1hC9tuAW=KnJqFYqnAk+o2MqrV4p_u-=tROopG12YqunZtFw@mail.gmail.com>
References: <CAK1hC9tuAW=KnJqFYqnAk+o2MqrV4p_u-=tROopG12YqunZtFw@mail.gmail.com>
Message-ID: <77B9C452-1191-4ECC-8943-453CE83278EF@dcn.davis.CA.us>

Questions about compiling generally belong on R-devel.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 22, 2015 7:51:39 AM PDT, arnaud gaboury <arnaud.gaboury at gmail.com> wrote:
>I want to build R with an optimized BLAS library.
>My OS: Fedora 22
>Hardware: CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian
>CPU(s): 8 Thread(s) per core: 2 Vendor ID: GenuineIntel Model name:
>Intel(R) Core(TM) i7-2600K CPU @ 3.40GHz
>
>I am a little confused when it comes to choose a method and would like
>to hear your experiences. If I am right, I have 3 possibilities:
>- OpenBLAS: opensource and free, but I came across some posts
>describing seg faults issues and bugs. These posts are 2 years old and
>I wonder if it is still the case.
>- ATLAS: can't see any reason to not use it
>- Intel MKL: this is part of Intel Parallel Studio and is a paid
>software. Now, there is the MKL package distributed by
>Revolutionanalytics, but I am not certain how this can be distributed
>for free. Is there any kind of difference? In case of use of this
>package, do I need to install RRO or can I just build R from GNU
>against these libraries?
>
>Thank you for advices.


From arnaud.gaboury at gmail.com  Sat Aug 22 17:14:42 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Sat, 22 Aug 2015 15:14:42 +0000
Subject: [R] Build R with optimized BLAS library
In-Reply-To: <77B9C452-1191-4ECC-8943-453CE83278EF@dcn.davis.CA.us>
References: <CAK1hC9tuAW=KnJqFYqnAk+o2MqrV4p_u-=tROopG12YqunZtFw@mail.gmail.com>
	<77B9C452-1191-4ECC-8943-453CE83278EF@dcn.davis.CA.us>
Message-ID: <CAK1hC9u1D3K_ko5G+oJHm3FBjm0THpkcYZM8dmZAOuQcBC_4Yw@mail.gmail.com>

On Sat, Aug 22, 2015, 5:12 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

Questions about compiling generally belong on R-devel.

Ok. Sorrx fpr the noise


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On August 22, 2015 7:51:39 AM PDT, arnaud gaboury <arnaud.gaboury at gmail.com>
wrote:
>I want to build R with an optimized BLAS library.
>My OS: Fedora 22
>Hardware: CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian
>CPU(s): 8 Thread(s) per core: 2 Vendor ID: GenuineIntel Model name:
>Intel(R) Core(TM) i7-2600K CPU @ 3.40GHz
>
>I am a little confused when it comes to choose a method and would like
>to hear your experiences. If I am right, I have 3 possibilities:
>- OpenBLAS: opensource and free, but I came across some posts
>describing seg faults issues and bugs. These posts are 2 years old and
>I wonder if it is still the case.
>- ATLAS: can't see any reason to not use it
>- Intel MKL: this is part of Intel Parallel Studio and is a paid
>software. Now, there is the MKL package distributed by
>Revolutionanalytics, but I am not certain how this can be distributed
>for free. Is there any kind of difference? In case of use of this
>package, do I need to install RRO or can I just build R from GNU
>against these libraries?
>
>Thank you for advices.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Aug 22 18:47:40 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 22 Aug 2015 09:47:40 -0700
Subject: [R] Date as Integer
In-Reply-To: <1440229385099-4711377.post@n4.nabble.com>
References: <1440229385099-4711377.post@n4.nabble.com>
Message-ID: <CAF8bMcaRpY-Up2iEQzj6ieP8pDo6fNSe9PwBRdcHg4gGbVLuVg@mail.gmail.com>

It would help if you supplied a small dataset so we could
reproduce your problem problem.  Here is one that gives the same
error.  (I also moved some parentheses around so "%y-%m-%d"
is an argument to as.Date() instead of to group_by().)
  data.frame(pickdate=paste(sep="-",15,08,c(21,22,21,22,22)),
waybill=2^(0:4)) %>%
    group_by(as.Date(pickdate,"%y-%m-%d")) %>%
    summarize(Total=count(waybill))
  #Error: no applicable method for 'group_by_' applied to an object of
class "c('double', 'numeric')"

I think count() is a wrapper for summarize() (or summarise() outside the
US),
not something to call from within summarize(), but I may be wrong (the help
file is terse).  Try using n() instead:
  data.frame(pickdate=paste(sep="-",15,08,c(21,22,21,22,22)),
waybill=2^(0:4)) %>%
    group_by(as.Date(pickdate,"%y-%m-%d")) %>%
    summarize(N=n(), Sum=sum(waybill), Mean=mean(waybill))
  #Source: local data frame [2 x 4]
  #
  #  as.Date(pickdate, "%y-%m-%d") N Sum     Mean
  #1                    2015-08-21 2   5 2.500000
  #2                    2015-08-22 3  26 8.666667




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Aug 22, 2015 at 12:43 AM, Shivi82 <shivibhatia at ymail.com> wrote:

> Hi All,
>
> I am using dplyr package and need to find total bills booked grouped on a
> date level however my date is integer.
> In the code below i was trying to change date format from integer. However
> it is throwing an error:
>
> "no applicable method for 'group_by_' applied to an object of class
> "c('integer', 'numeric')"
>
> ak%>%
>   group_by(as.Date(pickdate),"%y%m%d")%>%
>   summarise(Total=count(waybill))
>
> Do i need to create a new var first changing the date and then group it or
> as.Date will work as i added in dplyr.
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Date-as-Integer-tp4711377.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pls at mevik.net  Sat Aug 22 16:00:49 2015
From: pls at mevik.net (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Sat, 22 Aug 2015 16:00:49 +0200
Subject: [R] [R-pkgs] pls 2.5-0 released
Message-ID: <m0a8tjctim.fsf@bar.nemo-project.org>

Version 2.5-0 of the pls package has been released.  The pls package
implements Partial Least Squares Regression, Principal Component
Regression and Canonical Powered PLS.

The major changes are:

- Cross-validation can now make sure that replicates are kept in the
  same segment, by the use of a new argument `nrep'.  See ?cvsegments
  for details.

- It now has a vignette.

- It now has a NEWS file that can be accessed by news().
 
-- 
Regards,
Bj?rn-Helge Mevik

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From dwinsemius at comcast.net  Sat Aug 22 22:17:02 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 22 Aug 2015 13:17:02 -0700
Subject: [R] Generalised poisson regression
In-Reply-To: <197368862.5746741.1440258051179.JavaMail.yahoo@mail.yahoo.com>
References: <D7E55C73-C455-4F3B-B2D9-F513B9DCB834@comcast.net>
	<197368862.5746741.1440258051179.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <C75AAE88-E32F-4DB1-8775-94E892B670D7@comcast.net>


On Aug 22, 2015, at 8:40 AM, Babatunde Yakub wrote:

> Using object$deviance for generalised poisson regression model gives NULL as response. Code attached. please check....thanks

I'm not attacking your manhood when I say that your attachments are a problem. The only person who can see that attachment besides yourself is me because you did not copy the list and used an extension of `.r`. The mailing list requires that attachments be MIME-text and most mailers will not construct an email that lists them as such unless you use an extension of .txt. So your attachment with an .r extension was scrubbed. I'm not a user of the VGAM package, but I do read help pages. First your code which will let the rest of the audience correct my errors:

#EQUI-DISPERSION POISSON COUNT
library(MASS)
library(GPseq)
library(VGAM)
library(COMPoissonReg)
x=rnorm(50)
link=0.2+0.4*x
rpois.od<-function (n,lambda,d) {
   if (d==1)
      rpois(n, lambda)
   else
      rnbinom(n, size=(lambda/(d-1)), mu=lambda)
}
y=rpois.od(50,lambda=exp(link),d=1)

# GENERALIZED POISSON
genp= vglm(y~x, genpoisson,trace = TRUE)
gen=summary(genp)


The need for 4 different packages was no at all clear. I installed pkg:VGAM and looked at `?genpoisson` after loading only that package. Since it was there then only pkg:COMPoissonReg might be modifying the behavior of htat code, so I left it uninstalled (and unloaded initially). The ?vglm page tells us that there is no deviance component to objects returned from it and states that the recommended method for doing LR-tests is to use `lrtest` and so my w

The 'gen' object was examined with `str`:

str(gen)

#--------output truncated at beginning and end
 ..@ family          :Formal class 'vglmff' [package "VGAM"] with 18 slots
 .. .. ..@ blurb             : chr [1:8] "Generalized Poisson distribution\n\n" "Links:    " "rhobit(lambda)" ", " ...
 .. .. ..@ constraints       :  expression({     M1 <- 2     dotzero <- -1     eval(negzero.expression.VGAM) })
 .. .. ..@ deviance          :function ()  
 .. .. ..@ fini              :  expression({ })
 .. .. ..@ first             :  expression({ })
 .. .. ..@ infos             :function (...)  

#-------

So that didn't look very promising, ..... seeing that empty `deviance` function. So I continued with my hacking efforts at following the manual and built a NULL model and ran an LRT:

?lrtest

> genpnull= vglm(y~1, genpoisson,trace = TRUE)
VGLM    linear loop  1 :  loglikelihood = -64.750744
VGLM    linear loop  2 :  loglikelihood = -64.696782
VGLM    linear loop  3 :  loglikelihood = -64.696568
VGLM    linear loop  4 :  loglikelihood = -64.696567
VGLM    linear loop  5 :  loglikelihood = -64.696567
> gen0=summary(genpnull)
> lrtest(genp,genpnull)
Likelihood ratio test

Model 1: y ~ x
Model 2: y ~ 1
 #Df  LogLik Df  Chisq Pr(>Chisq)    
1  97 -59.045                         
2  98 -64.697  1 11.304  0.0007735 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


The LogLik values would allow you to construct a "deviance"-value for each model although the `lrtest` function has already calculated the difference in 2*LL between the 2 models and labeled it 'Chisq'. The deviance is not of much meaning as a number applied to a single model because it can vary drastically for different data arrangements. Only differences in nested models is meaningful.

Turned out that the actions I just performed are already done automatically if a single model is given to lrtest. Exactly the same output results. You can look at the code:

lrtest_vglm

# and see where it does that
----snippet----
   if (nmodels < 2) {
       objects <- c(objects, . ~ 1)
       nmodels <- 2
   }
#-----and then see that it is using a function named LogLik------

logLlist <- lapply(objects, logLik)

#-----------

> logLik(genp)
[1] -59.04466

So if I had really known what I was doing, I might have just typed ?logLik, except when I do that it appears the package author doesn't really intend for us to do this, since that pulls up a page for "Undocumented and Internally Used Functions and Classes". Thus endeth today's meanderings among the help pages for pkg:VGAM.

Please read the Posting Guide and also go back and read the general information webpages. You seem to have missed some important details.

-- 
David.

> 
> 
> On Friday, August 21, 2015 7:40 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> On Aug 21, 2015, at 5:22 AM, Babatunde Yakub via R-help wrote:
> 
>> I want to know how to extract or obtain the deviance for a fitted generalised poisson regression model. Thanks in advance
> 
> 
> If you post the code and some sample data, for building such a model, I'm sure someone can help you extract the deviance. If you simply mean what is returned by an ordinary glm-call with family="poisson" then deviance should be one of the elements of the glm-object.
> 
> 
> object$deviance
> 
>>    [[alternative HTML version deleted]]
> 
> When you do reply (if needed) please send in plain text rather than HTML.
> 
> -- 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> <for mail.r>

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat Aug 22 22:28:03 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 22 Aug 2015 13:28:03 -0700
Subject: [R] Generalised poisson regression
In-Reply-To: <C75AAE88-E32F-4DB1-8775-94E892B670D7@comcast.net>
References: <D7E55C73-C455-4F3B-B2D9-F513B9DCB834@comcast.net>
	<197368862.5746741.1440258051179.JavaMail.yahoo@mail.yahoo.com>
	<C75AAE88-E32F-4DB1-8775-94E892B670D7@comcast.net>
Message-ID: <CAGxFJbTQPvTJZ2crWhnkFOYgUM2=e+dQyumEJYOALHyXFm08-w@mail.gmail.com>

Dare I say...



On Sat, Aug 22, 2015 at 1:17 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
....
> I'm not attacking your manhood when I say that your attachments are a problem.


Fortune Nomination!

Cheers,
Bert


From peterenos at ymail.com  Sun Aug 23 19:01:40 2015
From: peterenos at ymail.com (Peter Tuju)
Date: Sun, 23 Aug 2015 17:01:40 +0000 (UTC)
Subject: [R] Compute RowMeans from mulple files
Message-ID: <320737549.4622328.1440349300423.JavaMail.yahoo@mail.yahoo.com>

Dear R users,?I have fifty two (52) text files with the same dimensions (ie 31 by 13). Three sample of such data files are attached. I want to compute the rowMeans for each separate file for;(i) all the months 
(ii) For January and February 
(iii) For March, April and May 
(iv) For June, July and august? 
(v) For October, November and December 
(vi) Plot the single mass curve for each file and season ie. plot(Year, cumsum(rowMeans([])))
(vii) Plot Time series graphs for each file and per each season.
The code I was trying to use is given below, and I investigated it and find that it does just for one only one file.How can I loop through all files?
I kindly need your help.

Thanks in advance!!


rm(list = ls())
setwd("/run/media/nwp-tma/+255767090047/analysis/R/R_sessions/R_sessions_prec/Rain_stn_data")# Import text filesprec_files <- list.files(pattern="*.txt")# Reading my files
prec_files <- list.files(pattern = ".txt")
for (i in 1:length(prec_files)){ ?
? prec_data = read.delim(prec_files[i], sep="\t", 
header = TRUE)? }
#prec_data <- as.numeric(prec_data[, 2:13])
# All years assignments
all_yr <- prec_data[, 2:13]
# Season assignment
jf <- prec_data[, 2:3]
mam <- prec_data[, 4:6]
jja <- prec_data[, 7:9]
ond <- prec_data[, 11:13]
jf_means <- apply(jf, 1, mean)
mam_means <- apply(mam, 1, mean) 
jja_means <- apply(jja, 1, mean) 
ond_means <-apply(ond, 1, mean)
yr_mean <- apply(all_yr, 1, mean)


?_____________
Peter? E. Tuju
Dar es Salaam
T A N Z A N I A
----------------------
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Kibaha.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150823/71d21f94/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Songea.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150823/71d21f94/attachment-0001.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Kigoma.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150823/71d21f94/attachment-0002.txt>

From janka.vanschoenwinkel at uhasselt.be  Sun Aug 23 19:25:59 2015
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Sun, 23 Aug 2015 19:25:59 +0200
Subject: [R] cut variable within a loop
In-Reply-To: <ADB27316-C8E0-47CD-A852-4B9C1FB00BB7@comcast.net>
References: <CAHymut+y3XMUC0w0+07-EVE8Ob8HUSSL2-kRvAw7eeP=_Lepkg@mail.gmail.com>
	<CAJuCY5wOaZAaWMwTEQ9N3S9REpM7SBO5VHgMZG7w7x3Pj8WPug@mail.gmail.com>
	<CAHymut+SK61ap-dxH1P1OgqD-eXQYgiDB4xo-E=MpHqoJw9nxw@mail.gmail.com>
	<CAJuCY5y16YF7EtRAppmntq-9krMnw7y+7uk5PS4zFQNerQRf0w@mail.gmail.com>
	<CAHymutKPfSM-qfbp9dLQgUpErUKp0tHj476fCPP8_r5aFiUxyQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C39DE6@SRVEXCHMBX.precheza.cz>
	<CAHymutK__NMQFbWJsCk3aYw3Wz3S1gLmGFW=kFoxQ+yh+g3PqQ@mail.gmail.com>
	<154AA9FB-F7B6-4212-9373-761F475CA59B@comcast.net>
	<CAHymutKOx3yMR_Es0db7UhBEmJa8WCGi=gkNfXJuavX+vm7q_A@mail.gmail.com>
	<ADB27316-C8E0-47CD-A852-4B9C1FB00BB7@comcast.net>
Message-ID: <CAHymutKZDo94bjmJBUFFZv8E+jpeeizzW4Qej1cMCyACQR-O5g@mail.gmail.com>

Thank you all very much. A combination of the solutions suggested solved my
problem!

2015-08-16 22:31 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Aug 16, 2015, at 8:57 AM, Janka VANSCHOENWINKEL wrote:
>
> > Hi David,
> >
> > Thanks for your comment. I'll explain what I want to do. I explained it
> already earlier but the explanation might have gone lost in some of the
> emails.
>
> I now see that you did explain that you wanted the positional matching in
> cut2 as a "break". The code runs without error on my machine, but delivers
> a lot of warnings about masking. You are repeatedly using attach on the
> same named objects. Using `attach` in programming is generally not a good
> idea. In interactive use it is safer to use `with`, although that is not
> generally considered safe in programming, either.
>
> You need to do a better job of nailing down the source of the difficulty
> what ever it might be. While you say the cut2 function "doesn't work", you
> don't actually give evidence of "failure".
>
> It's fairly simple to show that your theory about why your code fails in
> some way as being due to cut2 failing to accept an "i" value inside an
> lapply call is just wrong:
>
> > o <- lapply(1:3, function(i) { cut2( 0:10, i) } )
> > o
> [[1]]
>  [1]  0      [ 1,10] [ 1,10] [ 1,10] [ 1,10] [ 1,10] [ 1,10]
>  [8] [ 1,10] [ 1,10] [ 1,10] [ 1,10]
> Levels:  0 [ 1,10]
>
> [[2]]
>  [1] [ 0, 2) [ 0, 2) [ 2,10] [ 2,10] [ 2,10] [ 2,10] [ 2,10]
>  [8] [ 2,10] [ 2,10] [ 2,10] [ 2,10]
> Levels: [ 0, 2) [ 2,10]
>
> [[3]]
>  [1] [ 0, 3) [ 0, 3) [ 0, 3) [ 3,10] [ 3,10] [ 3,10] [ 3,10]
>  [8] [ 3,10] [ 3,10] [ 3,10] [ 3,10]
> Levels: [ 0, 3) [ 3,10]
>
>
> You also have two different definitions of weight2 for your irrigation
> model:
>
>
> Alldata_Irrigation$weight2<-Alldata_Irrigation$sys02*Alldata_Irrigation$se025
> Alldata_Irrigation$weight2<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
>
> --
> David
> >
> > The variable irrigation ranges from 0 to 100. (maybe not in de small
> sample I gave, but in reality I have over 60000 observations and there the
> variable ranges from 0 to 100). I want to make (and use) 100 different
> samples. The sample is based each time on the "i" that I put at the
> beginning of the loop.
> >
> > So:
> >
> > i = 1: this means there are 2 subsets. One from 0-1, another from 1-100
> > i = 2: this means there are 2 subsets. One from 0-2, another from 2-100
> > i = 3: this means there are 2 subsets. One from 0-3, another from 3-100
> > i = 4: this means there are 2 subsets. One from 0-4, another from 4-100
> > ...
> > i = 96: this means there are 2 subsets. One from 0-96, another from
> 96-100
> > i = 97: this means there are 2 subsets. One from 0-97, another from
> 97-100
> > i = 98: this means there are 2 subsets. One from 0-98, another from
> 98-100
> > i = 99: this means there are 2 subsets. One from 0-99, another from
> 99-100
> >
> > It might be possible that i = 1 and i = 2 give the same results in the
> small dataset. But in the full dataset all numbers are represented.
> >
> > The cut2 function is capable of "cutting" a sample based on a number
> supplied. Yet, when I tell him this number is "i", then it doesn't work. If
> instead I write that the number is 10, then it does work and it gives me 2
> subsets from 0-10 and from 10-100.
> >
> > Hope this is more clear!
> >
> > Janka
> >
> >
> > 2015-08-14 20:10 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
> >
> > When using a function in R you may need to supply an argument name. Are
> you expecting this to be the number of groups. I cannot decipher the intent
> here with such sparse commentary, but this call to `cut2` does not make
> sense to me. Perhaps you meant the number of groups? .... in which case you
> need  cut2( Alldata$irrigation, g=i ), since the arguments to cut2 are not
> that same as the arguments to cut.
> >
> > At the moment you are implicitly sending on the first pass a 1 and then
> on the second pass a 2 to the second argument of cut2 which is the `breaks`
> argument. So you wold be getting two different factors each with different
> cut-point levels. I looked at your data and in point of fact there would be
> no difference since you have 29 zero values and no values between 0 and 1.
> >
> > > table(cut2(dat$irrigation, 1))
> >
> >         0 [  1,100]
> >        29        21
> > > table(cut2(dat$irrigation, 2))
> >
> >         0 [  2,100]
> >        29        21
> >
> >
> >
> >
> > >  levels(Alldata$irri)<-c("0","1")
> > >
> > >  Alldata_Rainfed<-subset(Alldata, irri == 0)
> > >  Alldata_Irrigation<-subset(Alldata, irri == 1)
> > >
> > >  Alldata_Rainfed$w<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
> > >  Alldata_Irrigation$w<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> > >
> > >  OLS_Rainfed <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
> > >                      ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
> > >                      pdnsty+portsML+cities500k+rentedland+subsidies1+
> > >                      elevmean+elevrange+
> > >                      t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
> > >                      AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
> > >                    weights=w,Alldata_Rainfed)
> > >
> > >  attach(Alldata_Rainfed)
> > >
> > >  CoefRainfed_ps1 <- OLS_Rainfed$coeff[2]
> > >  CoefRainfed_ps2 <- OLS_Rainfed$coeff[3]
> > >  CoefRainfed_ps3 <- OLS_Rainfed$coeff[4]
> > >  CoefRainfed_ps4 <- OLS_Rainfed$coeff[5]
> > >  CoefRainfed_ts1 <- OLS_Rainfed$coeff[6]
> > >  CoefRainfed_ts2 <- OLS_Rainfed$coeff[7]
> > >  CoefRainfed_ts3 <- OLS_Rainfed$coeff[8]
> > >  CoefRainfed_ts4 <- OLS_Rainfed$coeff[9]
> > >  CoefRainfed_ps1sq <- OLS_Rainfed$coeff[10]
> > >  CoefRainfed_ps2sq <- OLS_Rainfed$coeff[11]
> > >  CoefRainfed_ps3sq <- OLS_Rainfed$coeff[12]
> > >  CoefRainfed_ps4sq <- OLS_Rainfed$coeff[13]
> > >  CoefRainfed_ts1sq <- OLS_Rainfed$coeff[14]
> > >  CoefRainfed_ts2sq <- OLS_Rainfed$coeff[15]
> > >  CoefRainfed_ts3sq <- OLS_Rainfed$coeff[16]
> > >  CoefRainfed_ts4sq <- OLS_Rainfed$coeff[17]
> > >
> > >  attach(Alldata_Rainfed)
> > >
> > >
> > >  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or
> COUNTRY level)
> > >  # Maar dit is dus de marginale impact per LnALVperHA?
> > >
> > >  Alldata_Rainfed$MEts1 =
> > > CoefRainfed_ts1+2*CoefRainfed_ts1sq*Alldata_Rainfed$ts1
> > >  Alldata_Rainfed$MEts2 =
> > > CoefRainfed_ts2+2*CoefRainfed_ts2sq*Alldata_Rainfed$ts2
> > >  Alldata_Rainfed$MEts3 =
> > > CoefRainfed_ts3+2*CoefRainfed_ts3sq*Alldata_Rainfed$ts3
> > >  Alldata_Rainfed$MEts4 =
> > > CoefRainfed_ts4+2*CoefRainfed_ts4sq*Alldata_Rainfed$ts4
> > >  Alldata_Rainfed$MEt   = Alldata_Rainfed$MEts1 +
> > > Alldata_Rainfed$MEts2 + Alldata_Rainfed$MEts3 + Alldata_Rainfed$MEts4
> > >
> > >  Alldata_Rainfed$MEps1 =
> > > CoefRainfed_ps1+2*CoefRainfed_ps1sq*Alldata_Rainfed$ps1
> > >  Alldata_Rainfed$MEps2 =
> > > CoefRainfed_ps2+2*CoefRainfed_ps2sq*Alldata_Rainfed$ps2
> > >  Alldata_Rainfed$MEps3 =
> > > CoefRainfed_ps3+2*CoefRainfed_ps3sq*Alldata_Rainfed$ps3
> > >  Alldata_Rainfed$MEps4 =
> > > CoefRainfed_ps4+2*CoefRainfed_ps4sq*Alldata_Rainfed$ps4
> > >  Alldata_Rainfed$MEp   = Alldata_Rainfed$MEps1 +
> > > Alldata_Rainfed$MEps2 + Alldata_Rainfed$MEps3 + Alldata_Rainfed$MEps4
> > >
> > >
> > >  Alldata_Rainfed$weight2<-Alldata_Rainfed$b48+Alldata_Rainfed$b50
> > >  attach(Alldata_Rainfed)
> > >  library(stats)
> > >  MEt_Rainfed<-weighted.mean(MEt,weight2)
> > >  MEp_Rainfed<-weighted.mean(MEp,weight2)
> > >
> > >
> > >
> > >  attach(Alldata_Irrigation)
> > >
> > >  OLS_Irrigation <- lm(LnALVperHA~ps1+ps2+ps3+ps4+ts1+ts2+ts3+ts4+
> > >
>  ps1sq+ps2sq+ps3sq+ps4sq+ts1sq+ts2sq+ts3sq+ts4sq+
> > >
>  pdnsty+portsML+cities500k+rentedland+subsidies1+
> > >                         elevmean+elevrange+
> > >                         t_gravel+t_gravel+t_ph_h2o+t_silt+t_sand+
> > >
>  AT+BE+DK+ES+FI+FR+GR+IE+IT+LU+NL+PT+SE+WDE+EDE+UK,
> > >                       weights=w,Alldata_Irrigation)
> > >
> > >
> > >
> > >  CoefIrrigation_ps1 <- OLS_Irrigation$coeff[2]
> > >  CoefIrrigation_ps2 <- OLS_Irrigation$coeff[3]
> > >  CoefIrrigation_ps3 <- OLS_Irrigation$coeff[4]
> > >  CoefIrrigation_ps4 <- OLS_Irrigation$coeff[5]
> > >  CoefIrrigation_ts1 <- OLS_Irrigation$coeff[6]
> > >  CoefIrrigation_ts2 <- OLS_Irrigation$coeff[7]
> > >  CoefIrrigation_ts3 <- OLS_Irrigation$coeff[8]
> > >  CoefIrrigation_ts4 <- OLS_Irrigation$coeff[9]
> > >  CoefIrrigation_ps1sq <- OLS_Irrigation$coeff[10]
> > >  CoefIrrigation_ps2sq <- OLS_Irrigation$coeff[11]
> > >  CoefIrrigation_ps3sq <- OLS_Irrigation$coeff[12]
> > >  CoefIrrigation_ps4sq <- OLS_Irrigation$coeff[13]
> > >  CoefIrrigation_ts1sq <- OLS_Irrigation$coeff[14]
> > >  CoefIrrigation_ts2sq <- OLS_Irrigation$coeff[15]
> > >  CoefIrrigation_ts3sq <- OLS_Irrigation$coeff[16]
> > >  CoefIrrigation_ts4sq <- OLS_Irrigation$coeff[17]
> > >
> > >  attach(Alldata_Irrigation)
> > >  # gives the residual errors in Y
> > >  Alldata_Irrigation$residuals <-resid(OLS_Irrigation)
> > >
> > >  # gives the predicted values for Ln_Y
> > >  Alldata_Irrigation$Ln_y_hat <-fitted(OLS_Irrigation)
> > >
> > >  # Zelf functie rmse maken
> > >  rmse <- function(error)
> > >  {
> > >    sqrt(mean(error^2))
> > >  }
> > >  Alldata_Irrigation$y_hat <-
> > >
> exp(Alldata_Irrigation$Ln_y_hat)*exp(0.5*(rmse(OLS_Irrigation$residuals))^2)
> > >
> > >  # absolute impact (landwaarde current)
> > >
> Alldata_Irrigation$absolute.current<-Alldata_Irrigation$y_hat*Alldata_Irrigation$se025*Alldata_Irrigation$sys02
> > >
> > >
> > >  ###### MARGINAL EFFECTS SEASONAL and YEARLY and REGIONAL (EU or
> COUNTRY level)
> > >  # Maar dit is dus de marginale impact per LnALVperHA?
> > >
> > >  Alldata_Irrigation$MEts1 =
> > > CoefIrrigation_ts1+2*CoefIrrigation_ts1sq*Alldata_Irrigation$ts1
> > >  Alldata_Irrigation$MEts2 =
> > > CoefIrrigation_ts2+2*CoefIrrigation_ts2sq*Alldata_Irrigation$ts2
> > >  Alldata_Irrigation$MEts3 =
> > > CoefIrrigation_ts3+2*CoefIrrigation_ts3sq*Alldata_Irrigation$ts3
> > >  Alldata_Irrigation$MEts4 =
> > > CoefIrrigation_ts4+2*CoefIrrigation_ts4sq*Alldata_Irrigation$ts4
> > >  Alldata_Irrigation$MEt   = Alldata_Irrigation$MEts1 +
> > > Alldata_Irrigation$MEts2 + Alldata_Irrigation$MEts3 +
> > > Alldata_Irrigation$MEts4
> > >
> > >  Alldata_Irrigation$MEps1 =
> > > CoefIrrigation_ps1+2*CoefIrrigation_ps1sq*Alldata_Irrigation$ps1
> > >  Alldata_Irrigation$MEps2 =
> > > CoefIrrigation_ps2+2*CoefIrrigation_ps2sq*Alldata_Irrigation$ps2
> > >  Alldata_Irrigation$MEps3 =
> > > CoefIrrigation_ps3+2*CoefIrrigation_ps3sq*Alldata_Irrigation$ps3
> > >  Alldata_Irrigation$MEps4 =
> > > CoefIrrigation_ps4+2*CoefIrrigation_ps4sq*Alldata_Irrigation$ps4
> > >  Alldata_Irrigation$MEp   = Alldata_Irrigation$MEps1 +
> > > Alldata_Irrigation$MEps2 + Alldata_Irrigation$MEps3 +
> > > Alldata_Irrigation$MEps4
> > >
> > >
> > >
> Alldata_Irrigation$weight2<-Alldata_Irrigation$sys02*Alldata_Irrigation$se025
> > >
> Alldata_Irrigation$weight2<-Alldata_Irrigation$b48+Alldata_Irrigation$b50
> > >
> > >  attach(Alldata_Irrigation)
> > >  library(stats)
> > >  MEt_Irrigation<-weighted.mean(MEt,weight2)
> > >  MEp_Irrigation<-weighted.mean(MEp,weight2)
> > >
> > >  c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> > >
> > >  attach(Alldata)
> > >
> > >
> > >  # And in the loop (index i):
> > >
> > >  d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> > >
> > >
> > > })
> > > out<-as.data.frame(do.call(rbind, o))
> > >
> > >
> > >
> > >
> > > And the data are:
> > >
> > > structure(list(LnALVperHA = c(8.09964942932129, 9.53274631500244,
> > > 7.42697763442993, 8.25370121002197, 8.42619132995605, 8.0093936920166,
> > > 8.09785747528076, 8.49044704437256, 9.08215141296387, 8.38935947418213,
> > > 8.67814350128174, 8.38935947418213, 10.4056901931763, 8.48210144042969,
> > > 8.30281829833984, 8.92265796661377, 8.33178997039795, 4.54404163360596,
> > > 10.662184715271, 9.62167072296143, 7.98790407180786, 7.58244323730469,
> > > 7.23262739181519, 9.47037124633789, 8.93403625488281, 7.54256629943848,
> > > 9.40302467346191, 10.6290521621704, 8.59830188751221, 8.59585666656494,
> > > 9.10000514984131, 9.99381542205811, 9.54681301116943, 9.53055191040039,
> > > 8.67971229553223, 7.19780731201172, 8.90067958831787, 6.0509786605835,
> > > 6.55788946151733, 8.22567272186279, 9.05618953704834, 6.81858921051025,
> > > 8.46410751342773, 7.81292057037354, 8.38989448547363, 10.4709157943726,
> > > 8.06132888793945, 8.43629264831543, 10.3087100982666, 10.3218297958374
> > > ), ps1 = c(5.14855766296387, 4.71904611587524, 7.9462103843689,
> > > 10.6017990112305, 11.233078956604, 9.12952136993408, 12.6536712646484,
> > > 11.233078956604, 11.233078956604, 11.233078956604, 11.233078956604,
> > > 11.233078956604, 5.93759632110596, 10.6017990112305, 11.233078956604,
> > > 10.6017990112305, 7.95780467987061, 9.07744884490967, 4.29865598678589,
> > > 8.27481746673584, 3.25137901306152, 4.51061344146729, 6.34518480300903,
> > > 6.66202449798584, 6.66202449798584, 4.75249433517456, 6.28858852386475,
> > > 6.33270215988159, 10.3600759506226, 10.3600759506226, 18.7164611816406,
> > > 5.73318386077881, 7.92949104309082, 9.09823608398438, 11.233078956604,
> > > 10.4455404281616, 11.233078956604, 10.4455404281616, 10.4455404281616,
> > > 10.6017990112305, 9.19112777709961, 10.4455404281616, 11.233078956604,
> > > 11.064302444458, 11.233078956604, 5.93759632110596, 11.233078956604,
> > > 10.6017990112305, 6.05948448181152, 9.5645227432251), ps2 =
> c(5.23111915588379,
> > > 4.86784505844116, 7.7175760269165, 4.34898376464844, 4.48626232147217,
> > > 9.57159423828125, 8.38174915313721, 4.48626232147217, 4.48626232147217,
> > > 4.48626232147217, 4.48626232147217, 4.48626232147217, 6.87198734283447,
> > > 4.34898376464844, 4.48626232147217, 4.34898376464844, 6.2098217010498,
> > > 7.5497522354126, 5.62545442581177, 5.57168531417847, 3.08954334259033,
> > > 6.6683931350708, 4.41767883300781, 6.11901044845581, 6.11901044845581,
> > > 4.06884765625, 6.35917854309082, 5.7121729850769, 8.55229663848877,
> > > 8.55229663848877, 11.8981914520264, 5.49351119995117, 5.34777498245239,
> > > 6.12420177459717, 4.48626232147217, 5.2967677116394, 4.48626232147217,
> > > 5.2967677116394, 5.2967677116394, 4.34898376464844, 4.51386308670044,
> > > 5.2967677116394, 4.48626232147217, 5.98725175857544, 4.48626232147217,
> > > 6.87198734283447, 4.48626232147217, 4.34898376464844, 5.58411026000977,
> > > 4.42436075210571), ps3 = c(4.95634937286377, 3.50353670120239,
> > > 6.01129817962646, 0.851324141025543, 0.816295921802521,
> 8.03804397583008,
> > > 5.56230783462524, 0.816295921802521, 0.816295921802521,
> 0.816295921802521,
> > > 0.816295921802521, 0.816295921802521, 6.01666784286499,
> 0.851324141025543,
> > > 0.816295921802521, 0.851324141025543, 3.45424580574036,
> 5.31899690628052,
> > > 7.45753812789917, 3.34133338928223, 6.61472988128662, 11.244439125061,
> > > 2.19617891311646, 5.29748106002808, 5.29748106002808, 1.63307499885559,
> > > 5.51272773742676, 6.78562116622925, 4.5334997177124, 4.5334997177124,
> > > 4.31791353225708, 7.10963106155396, 2.32198905944824, 2.74845194816589,
> > > 0.816295921802521, 1.47570741176605, 0.816295921802521,
> 1.47570741176605,
> > > 1.47570741176605, 0.851324141025543, 1.39068424701691,
> 1.47570741176605,
> > > 0.816295921802521, 1.85064959526062, 0.816295921802521,
> 6.01666784286499,
> > > 0.816295921802521, 0.851324141025543, 6.78009986877441,
> 1.21070051193237
> > > ), ps4 = c(5.66667366027832, 4.82342433929443, 7.40090322494507,
> > > 6.59299898147583, 7.33758926391602, 9.98004341125488, 10.3958940505981,
> > > 7.33758926391602, 7.33758926391602, 7.33758926391602, 7.33758926391602,
> > > 7.33758926391602, 8.31999015808105, 6.59299898147583, 7.33758926391602,
> > > 6.59299898147583, 7.05771064758301, 8.38344383239746, 4.75349426269531,
> > > 9.00399303436279, 5.48189449310303, 5.9071044921875, 5.30881881713867,
> > > 8.68398857116699, 8.68398857116699, 4.32339859008789, 8.57950687408447,
> > > 6.78787326812744, 8.68624305725098, 8.68624305725098, 12.9021902084351,
> > > 6.14854049682617, 6.71301507949829, 7.50605535507202, 7.33758926391602,
> > > 8.11069011688232, 7.33758926391602, 8.11069011688232, 8.11069011688232,
> > > 6.59299898147583, 5.92181205749512, 8.11069011688232, 7.33758926391602,
> > > 9.29954528808594, 7.33758926391602, 8.31999015808105, 7.33758926391602,
> > > 6.59299898147583, 6.16447877883911, 5.83903217315674), ts1 =
> c(4.19949150085449,
> > > 2.46556353569031, 3.96805644035339, 9.05560302734375, 9.5199556350708,
> > > 1.18671488761902, 6.60286664962769, 9.5199556350708, 9.5199556350708,
> > > 9.5199556350708, 9.5199556350708, 9.5199556350708, 2.12847352027893,
> > > 9.05560302734375, 9.5199556350708, 9.05560302734375, 2.11432313919067,
> > > 6.49393510818481, -0.165110915899277, 7.78503036499023,
> -7.71160411834717,
> > > -0.979450941085815, 4.96369075775146, 4.28496122360229,
> 4.28496122360229,
> > > 6.35976600646973, 3.02656149864197, 2.80754446983337, 5.94739389419556,
> > > 5.94739389419556, 8.70161914825439, 1.57025468349457, 5.08782005310059,
> > > 4.27688789367676, 9.5199556350708, 8.49832916259766, 9.5199556350708,
> > > 8.49832916259766, 8.49832916259766, 9.05560302734375, 6.33359289169312,
> > > 8.49832916259766, 9.5199556350708, 7.99740839004517, 9.5199556350708,
> > > 2.12847352027893, 9.5199556350708, 9.05560302734375, 2.67069268226624,
> > > 7.33829879760742), ts2 = c(9.89923763275146, 10.9084701538086,
> > > 9.61682415008545, 13.6253662109375, 13.8121919631958, 6.19518041610718,
> > > 9.40560817718506, 13.8121919631958, 13.8121919631958, 13.8121919631958,
> > > 13.8121919631958, 13.8121919631958, 10.3912172317505, 13.6253662109375,
> > > 13.8121919631958, 13.6253662109375, 9.77112770080566, 11.5460777282715,
> > > 8.18180465698242, 12.9412984848022, 2.54625177383423, 8.29829216003418,
> > > 10.6650953292847, 10.1770324707031, 10.1770324707031, 12.4333782196045,
> > > 8.98324680328369, 8.45312309265137, 9.23384857177734, 9.23384857177734,
> > > 11.371600151062, 8.09108352661133, 12.0714511871338, 11.385799407959,
> > > 13.8121919631958, 13.912787437439, 13.8121919631958, 13.912787437439,
> > > 13.912787437439, 13.6253662109375, 12.0018119812012, 13.912787437439,
> > > 13.8121919631958, 14.0190010070801, 13.8121919631958, 10.3912172317505,
> > > 13.8121919631958, 13.6253662109375, 8.53981018066406, 12.7294788360596
> > > ), ts3 = c(17.718994140625, 21.1172523498535, 17.8669090270996,
> > > 23.1215572357178, 22.9536685943604, 15.3891229629517, 15.7000684738159,
> > > 22.9536685943604, 22.9536685943604, 22.9536685943604, 22.9536685943604,
> > > 22.9536685943604, 20.1229286193848, 23.1215572357178, 22.9536685943604,
> > > 23.1215572357178, 19.8251171112061, 19.3250198364258, 16.8351039886475,
> > > 22.2966594696045, 14.6743259429932, 17.1554985046387, 20.1656894683838,
> > > 20.0012702941895, 20.0012702941895, 23.2738876342773, 18.6255321502686,
> > > 16.2553405761719, 16.551155090332, 16.551155090332, 17.6266174316406,
> > > 16.1711521148682, 22.280725479126, 21.450382232666, 22.9536685943604,
> > > 23.5616970062256, 22.9536685943604, 23.5616970062256, 23.5616970062256,
> > > 23.1215572357178, 22.1113948822021, 23.5616970062256, 22.9536685943604,
> > > 23.5085678100586, 22.9536685943604, 20.1229286193848, 22.9536685943604,
> > > 23.1215572357178, 16.3595314025879, 22.7737102508545), ts4 =
> c(11.661883354187,
> > > 12.7669324874878, 11.6320190429688, 17.2357921600342, 17.4911460876465,
> > > 9.09537506103516, 12.179615020752, 17.4911460876465, 17.4911460876465,
> > > 17.4911460876465, 17.4911460876465, 17.4911460876465, 12.0781927108765,
> > > 17.2357921600342, 17.4911460876465, 17.2357921600342, 11.9486837387085,
> > > 13.7441387176514, 8.9575023651123, 15.9984045028687, 4.02816677093506,
> > > 9.12790489196777, 13.0505475997925, 12.842321395874, 12.842321395874,
> > > 14.8937959671021, 11.5566177368164, 10.0515727996826, 12.2921047210693,
> > > 12.2921047210693, 14.2251281738281, 9.64802074432373, 14.6072359085083,
> > > 13.7993869781494, 17.4911460876465, 17.0232067108154, 17.4911460876465,
> > > 17.0232067108154, 17.0232067108154, 17.2357921600342, 15.045259475708,
> > > 17.0232067108154, 17.4911460876465, 16.7633666992188, 17.4911460876465,
> > > 12.0781927108765, 17.4911460876465, 17.2357921600342, 10.0954942703247,
> > > 15.9187803268433), ps1sq = c(26.5076465606689, 22.2693958282471,
> > > 63.1422576904297, 112.398139953613, 126.182060241699, 83.3481597900391,
> > > 160.11540222168, 126.182060241699, 126.182060241699, 126.182060241699,
> > > 126.182060241699, 126.182060241699, 35.2550506591797, 112.398139953613,
> > > 126.182060241699, 112.398139953613, 63.3266563415527, 82.4000778198242,
> > > 18.478443145752, 68.4726028442383, 10.5714654922485, 20.3456344604492,
> > > 40.2613716125488, 44.3825721740723, 44.3825721740723, 22.58620262146,
> > > 39.5463447570801, 40.1031150817871, 107.331176757812, 107.331176757812,
> > > 350.305908203125, 32.8693962097168, 62.8768272399902, 82.7779006958008,
> > > 126.182060241699, 109.109313964844, 126.182060241699, 109.109313964844,
> > > 109.109313964844, 112.398139953613, 84.4768295288086, 109.109313964844,
> > > 126.182060241699, 122.418785095215, 126.182060241699, 35.2550506591797,
> > > 126.182060241699, 112.398139953613, 36.7173538208008, 91.480094909668
> > > ), ps2sq = c(27.3646068572998, 23.695915222168, 59.560977935791,
> > > 18.9136600494385, 20.1265487670898, 91.6154174804688, 70.2537155151367,
> > > 20.1265487670898, 20.1265487670898, 20.1265487670898, 20.1265487670898,
> > > 20.1265487670898, 47.2242088317871, 18.9136600494385, 20.1265487670898,
> > > 18.9136600494385, 38.5618858337402, 56.9987602233887, 31.6457366943359,
> > > 31.0436763763428, 9.54527759552002, 44.4674682617188, 19.5158863067627,
> > > 37.4422874450684, 37.4422874450684, 16.5555210113525, 40.439151763916,
> > > 32.6289215087891, 73.1417770385742, 73.1417770385742, 141.566955566406,
> > > 30.1786651611328, 28.5986976623535, 37.5058479309082, 20.1265487670898,
> > > 28.0557479858398, 20.1265487670898, 28.0557479858398, 28.0557479858398,
> > > 18.9136600494385, 20.3749599456787, 28.0557479858398, 20.1265487670898,
> > > 35.8471832275391, 20.1265487670898, 47.2242088317871, 20.1265487670898,
> > > 18.9136600494385, 31.1822872161865, 19.5749683380127), ps3sq =
> > > c(24.5653991699219,
> > > 12.27476978302, 36.1357040405273, 0.72475278377533, 0.666339039802551,
> > > 64.6101531982422, 30.9392681121826, 0.666339039802551,
> 0.666339039802551,
> > > 0.666339039802551, 0.666339039802551, 0.666339039802551,
> 36.2002906799316,
> > > 0.72475278377533, 0.666339039802551, 0.72475278377533,
> 11.9318141937256,
> > > 28.2917289733887, 55.614875793457, 11.1645088195801, 43.7546501159668,
> > > 126.437408447266, 4.82320165634155, 28.063304901123, 28.063304901123,
> > > 2.6669340133667, 30.3901672363281, 46.0446548461914, 20.552619934082,
> > > 20.552619934082, 18.6443767547607, 50.5468521118164, 5.39163303375244,
> > > 7.55398797988892, 0.666339039802551, 2.17771244049072,
> 0.666339039802551,
> > > 2.17771244049072, 2.17771244049072, 0.72475278377533, 1.93400263786316,
> > > 2.17771244049072, 0.666339039802551, 3.42490386962891,
> 0.666339039802551,
> > > 36.2002906799316, 0.666339039802551, 0.72475278377533,
> 45.9697532653809,
> > > 1.46579575538635), ps4sq = c(32.1111907958984, 23.2654228210449,
> > > 54.7733688354492, 43.4676361083984, 53.840217590332, 99.6012649536133,
> > > 108.074615478516, 53.840217590332, 53.840217590332, 53.840217590332,
> > > 53.840217590332, 53.840217590332, 69.2222366333008, 43.4676361083984,
> > > 53.840217590332, 43.4676361083984, 49.811279296875, 70.2821273803711,
> > > 22.5957069396973, 81.071891784668, 30.0511665344238, 34.8938827514648,
> > > 28.183557510376, 75.4116592407227, 75.4116592407227, 18.6917762756348,
> > > 73.6079406738281, 46.0752220153809, 75.4508209228516, 75.4508209228516,
> > > 166.466506958008, 37.8045501708984, 45.0645713806152, 56.3408660888672,
> > > 53.840217590332, 65.7832946777344, 53.840217590332, 65.7832946777344,
> > > 65.7832946777344, 43.4676361083984, 35.0678596496582, 65.7832946777344,
> > > 53.840217590332, 86.4815444946289, 53.840217590332, 69.2222366333008,
> > > 53.840217590332, 43.4676361083984, 38.0007972717285, 34.094295501709
> > > ), ts1sq = c(17.6357288360596, 6.07900333404541, 15.7454719543457,
> > > 82.0039443969727, 90.6295547485352, 1.40829217433929, 43.5978469848633,
> > > 90.6295547485352, 90.6295547485352, 90.6295547485352, 90.6295547485352,
> > > 90.6295547485352, 4.53039932250977, 82.0039443969727, 90.6295547485352,
> > > 82.0039443969727, 4.47036218643188, 42.1711921691895,
> 0.0272616147994995,
> > > 60.6066970825195, 59.4688377380371, 0.95932412147522, 24.6382255554199,
> > > 18.3608932495117, 18.3608932495117, 40.4466247558594, 9.16007423400879,
> > > 7.88230609893799, 35.3714942932129, 35.3714942932129, 75.7181777954102,
> > > 2.46569967269897, 25.8859119415283, 18.2917709350586, 90.6295547485352,
> > > 72.2215957641602, 90.6295547485352, 72.2215957641602, 72.2215957641602,
> > > 82.0039443969727, 40.1143989562988, 72.2215957641602, 90.6295547485352,
> > > 63.9585418701172, 90.6295547485352, 4.53039932250977, 90.6295547485352,
> > > 82.0039443969727, 7.13259935379028, 53.8506278991699), ts2sq =
> > > c(97.9949035644531,
> > > 118.994720458984, 92.4833068847656, 185.650604248047, 190.776641845703,
> > > 38.3802604675293, 88.465461730957, 190.776641845703, 190.776641845703,
> > > 190.776641845703, 190.776641845703, 190.776641845703, 107.977394104004,
> > > 185.650604248047, 190.776641845703, 185.650604248047, 95.4749374389648,
> > > 133.311904907227, 66.9419250488281, 167.477203369141, 6.48339796066284,
> > > 68.8616561889648, 113.744255065918, 103.571990966797, 103.571990966797,
> > > 154.588897705078, 80.6987228393555, 71.4552917480469, 85.2639617919922,
> > > 85.2639617919922, 129.313293457031, 65.4656295776367, 145.719940185547,
> > > 129.636428833008, 190.776641845703, 193.565658569336, 190.776641845703,
> > > 193.565658569336, 193.565658569336, 185.650604248047, 144.043487548828,
> > > 193.565658569336, 190.776641845703, 196.53239440918, 190.776641845703,
> > > 107.977394104004, 190.776641845703, 185.650604248047, 72.9283599853516,
> > > 162.039627075195), ts3sq = c(313.962768554688, 445.938354492188,
> > > 319.226440429688, 534.606384277344, 526.870910644531, 236.825103759766,
> > > 246.492156982422, 526.870910644531, 526.870910644531, 526.870910644531,
> > > 526.870910644531, 526.870910644531, 404.932250976562, 534.606384277344,
> > > 526.870910644531, 534.606384277344, 393.035278320312, 373.456390380859,
> > > 283.420715332031, 497.141021728516, 215.335845947266, 294.311126708984,
> > > 406.655029296875, 400.050811767578, 400.050811767578, 541.673828125,
> > > 346.910461425781, 264.236083984375, 273.940734863281, 273.940734863281,
> > > 310.697631835938, 261.506164550781, 496.430725097656, 460.118896484375,
> > > 526.870910644531, 555.153564453125, 526.870910644531, 555.153564453125,
> > > 555.153564453125, 534.606384277344, 488.913787841797, 555.153564453125,
> > > 526.870910644531, 552.652770996094, 526.870910644531, 404.932250976562,
> > > 526.870910644531, 534.606384277344, 267.63427734375, 518.641906738281
> > > ), ts4sq = c(135.999526977539, 162.994567871094, 135.303863525391,
> > > 297.072540283203, 305.940185546875, 82.7258453369141, 148.343017578125,
> > > 305.940185546875, 305.940185546875, 305.940185546875, 305.940185546875,
> > > 305.940185546875, 145.882736206055, 297.072540283203, 305.940185546875,
> > > 297.072540283203, 142.771041870117, 188.901351928711, 80.2368469238281,
> > > 255.948944091797, 16.2261276245117, 83.3186492919922, 170.316787719727,
> > > 164.925216674805, 164.925216674805, 221.825164794922, 133.555419921875,
> > > 101.034118652344, 151.095840454102, 151.095840454102, 202.354278564453,
> > > 93.0843048095703, 213.371337890625, 190.423080444336, 305.940185546875,
> > > 289.789581298828, 305.940185546875, 289.789581298828, 289.789581298828,
> > > 297.072540283203, 226.359832763672, 289.789581298828, 305.940185546875,
> > > 281.010467529297, 305.940185546875, 145.882736206055, 305.940185546875,
> > > 297.072540283203, 101.919006347656, 253.407562255859), pdnsty =
> > > c(0.616999983787537,
> > > 0.0850000008940697, 0.068000003695488, 0.025000000372529,
> 0.0549999997019768,
> > > 0.0230000000447035, 0.133000001311302, 0.0549999997019768,
> 0.0549999997019768,
> > > 0.0549999997019768, 0.0549999997019768, 0.0549999997019768,
> 0.25900000333786,
> > > 0.025000000372529, 0.0549999997019768, 0.025000000372529,
> 0.0140000004321337,
> > > 0.14300000667572, 0.140000000596046, 0.777999997138977,
> 0.0329999998211861,
> > > 0.316000014543533, 0.0179999992251396, 0.105999998748302,
> 0.105999998748302,
> > > 0.046000000089407, 0.108000002801418, 0.310999989509583,
> 0.101000003516674,
> > > 0.101000003516674, 0.14300000667572, 0.168999999761581,
> 0.0439999997615814,
> > > 0.0379999987781048, 0.0549999997019768, 0.063000001013279,
> 0.0549999997019768,
> > > 0.063000001013279, 0.063000001013279, 0.025000000372529,
> 0.0640000030398369,
> > > 0.063000001013279, 0.0549999997019768, 0.209000006318092,
> 0.0549999997019768,
> > > 0.25900000333786, 0.0549999997019768, 0.025000000372529,
> 0.257999986410141,
> > > 0.0469999983906746), portsML = c(0.0900330692529678,
> 0.0604440234601498,
> > > 0.168490216135979, 0.275995850563049, 0.269018620252609,
> 0.175392478704453,
> > > 0.0350189469754696, 0.269018620252609, 0.269018620252609,
> 0.269018620252609,
> > > 0.269018620252609, 0.269018620252609, 0.11026918143034,
> 0.275995850563049,
> > > 0.269018620252609, 0.275995850563049, 0.145082741975784,
> 0.00440915673971176,
> > > 0.426146239042282, 0.0686663240194321, 0.103511147201061,
> 0.289726078510284,
> > > 0.234196603298187, 0.123688526451588, 0.123688526451588,
> 0.315173029899597,
> > > 0.112561739981174, 0.0461684986948967, 0.179993003606796,
> 0.179993003606796,
> > > 0.0438785217702389, 0.096462681889534, 0.0934395045042038,
> 0.121217466890812,
> > > 0.269018620252609, 0.212490051984787, 0.269018620252609,
> 0.212490051984787,
> > > 0.212490051984787, 0.275995850563049, 0.162760972976685,
> 0.212490051984787,
> > > 0.269018620252609, 0.270619571208954, 0.269018620252609,
> 0.11026918143034,
> > > 0.269018620252609, 0.275995850563049, 0.108705826103687,
> 0.196496397256851
> > > ), cities500k = c(0.0360943526029587, 0.0577861145138741,
> 0.183606043457985,
> > > 0.150749072432518, 0.185974538326263, 0.0923599153757095,
> 0.353672504425049,
> > > 0.185974538326263, 0.185974538326263, 0.185974538326263,
> 0.185974538326263,
> > > 0.185974538326263, 0.0887016654014587, 0.150749072432518,
> 0.185974538326263,
> > > 0.150749072432518, 0.144800990819931, 0.00326321297325194,
> 0.0622526630759239,
> > > 0.00816718116402626, 0.181859150528908, 0.163181975483894,
> 0.204970955848694,
> > > 0.129742562770844, 0.129742562770844, 0.0783679932355881,
> 0.0559677332639694,
> > > 0.0293320622295141, 0.248573184013367, 0.248573184013367,
> 0.174525216221809,
> > > 0.092569001019001, 0.176346719264984, 0.16088992357254,
> 0.185974538326263,
> > > 0.280431807041168, 0.185974538326263, 0.280431807041168,
> 0.280431807041168,
> > > 0.150749072432518, 0.088722825050354, 0.280431807041168,
> 0.185974538326263,
> > > 0.189705356955528, 0.185974538326263, 0.0887016654014587,
> 0.185974538326263,
> > > 0.150749072432518, 0.0712414756417274, 0.0842432081699371), rentedland
> > > = c(0.571943998336792,
> > > 0, 0.5929936170578, 0, 0, 0.755691230297089, 0.440930217504501,
> > > 0, 0, 0, 0.229885056614876, 0, 0, 0, 0, 0, 0.890581607818604,
> > > 0.212423488497734, 0.386227518320084, 0, 0.11130790412426,
> 0.483032256364822,
> > > 0.444395005702972, 0, 0, 0.253378361463547, 0, 0.10909091681242,
> > > 0.181818187236786, 0.666666686534882, 0, 0.94951194524765,
> 0.846153855323792,
> > > 0.403846144676208, 0, 0, 0.155963316559792, 0, 0, 0.408163279294968,
> > > 0.699570834636688, 0, 0, 0, 0, 0, 0.0476190522313118, 0, 0, 0
> > > ), subsidies1 = c(361.835754394531, 0, 368.242034912109,
> 345.636352539062,
> > > 701.746032714844, 488.922821044922, 344.918609619141, 790.392150878906,
> > > 795.3125, 631.666687011719, 193.563217163086, 565.75, 0,
> 577.586181640625,
> > > 395.681823730469, 192, 371.963653564453, 9.9977331161499,
> 310.838317871094,
> > > 905.764709472656, 1745.76293945312, 359.003814697266, 163.204330444336,
> > > 427.94970703125, 204.842727661133, 52.2592887878418, 0, 0,
> 3022.24243164062,
> > > 80.2666702270508, 445.366577148438, 925.681640625, 824.769226074219,
> > > 625.192321777344, 850.441162109375, 280.891723632812, 619.266052246094,
> > > 333.962249755859, 376.304351806641, 317.551025390625, 166.652359008789,
> > > 171.224487304688, 526.119445800781, 253.191497802734, 334.470581054688,
> > > 107.277839660645, 431.428588867188, 0, 107.245544433594,
> 339.701507568359
> > > ), elevmean = c(0.121736958622932, 0.46412268280983, 0.344255149364471,
> > > 0.466430068016052, 0.43000802397728, 1.15364873409271,
> 0.0955904126167297,
> > > 0.43000802397728, 0.43000802397728, 0.43000802397728, 0.43000802397728,
> > > 0.43000802397728, 0.370405077934265, 0.466430068016052,
> 0.43000802397728,
> > > 0.466430068016052, 0.849120080471039, 0.0433186627924442,
> 0.335433751344681,
> > > 0.271958351135254, 0.125564843416214, 0.376024007797241,
> 0.815701544284821,
> > > 0.525435268878937, 0.525435268878937, 0.62959760427475,
> 0.518330037593842,
> > > 0.00362438289448619, 0.628515422344208, 0.628515422344208,
> 0.274942100048065,
> > > 0.0728112533688545, 0.496583759784698, 0.739268243312836,
> 0.43000802397728,
> > > 0.321640431880951, 0.43000802397728, 0.321640431880951,
> 0.321640431880951,
> > > 0.466430068016052, 0.585907399654388, 0.321640431880951,
> 0.43000802397728,
> > > 0.147326037287712, 0.43000802397728, 0.370405077934265,
> 0.43000802397728,
> > > 0.466430068016052, 0.0183117985725403, 0.414920538663864), elevrange =
> > > c(0.180000007152557,
> > > 1.99300003051758, 0.611000001430511, 2.35199999809265,
> 2.29999995231628,
> > > 2.94199991226196, 0.354999989271164, 2.29999995231628,
> 2.29999995231628,
> > > 2.29999995231628, 2.29999995231628, 2.29999995231628, 2.01799988746643,
> > > 2.35199999809265, 2.29999995231628, 2.35199999809265, 1.7389999628067,
> > > 0.160999998450279, 0.314000010490417, 1.76300001144409,
> 0.17399999499321,
> > > 0.653999984264374, 1.63399994373322, 2.19099998474121,
> 2.19099998474121,
> > > 1.14100003242493, 1.34800004959106, 0.00899999961256981,
> 2.41300010681152,
> > > 2.41300010681152, 0.787999987602234, 0.26800000667572,
> 1.92200005054474,
> > > 2.02600002288818, 2.29999995231628, 1.05099999904633, 2.29999995231628,
> > > 1.05099999904633, 1.05099999904633, 2.35199999809265, 2.35999989509583,
> > > 1.05099999904633, 2.29999995231628, 0.772000014781952,
> 2.29999995231628,
> > > 2.01799988746643, 2.29999995231628, 2.35199999809265,
> 0.0649999976158142,
> > > 1.75399994850159), t_gravel = c(4.58953237533569, 13.3146963119507,
> > > 10.0136280059814, 13.8894920349121, 13.9366893768311, 13.5653190612793,
> > > 7.71220588684082, 13.9366893768311, 13.9366893768311, 13.9366893768311,
> > > 13.9366893768311, 13.9366893768311, 11.4818019866943, 13.8894920349121,
> > > 13.9366893768311, 13.8894920349121, 13.4321727752686, 5.71388387680054,
> > > 8.03888702392578, 9.01077747344971, 4.58924961090088, 8.14134693145752,
> > > 11.8983144760132, 9.96716785430908, 9.96716785430908, 11.1739711761475,
> > > 10.4019403457642, 5.16821479797363, 10.7357034683228, 10.7357034683228,
> > > 9.23897457122803, 4.3336238861084, 10.9520101547241, 12.9722995758057,
> > > 13.9366893768311, 13.1780118942261, 13.9366893768311, 13.1780118942261,
> > > 13.1780118942261, 13.8894920349121, 12.7335777282715, 13.1780118942261,
> > > 13.9366893768311, 12.315260887146, 13.9366893768311, 11.4818019866943,
> > > 13.9366893768311, 13.8894920349121, 6.68424606323242, 14.101095199585
> > > ), t_ph_h2o = c(6.07352828979492, 6.72695684432983, 5.60523176193237,
> > > 6.13967752456665, 6.86059141159058, 7.40929126739502, 5.68151950836182,
> > > 6.86059141159058, 6.86059141159058, 6.86059141159058, 6.86059141159058,
> > > 6.86059141159058, 6.51894521713257, 6.13967752456665, 6.86059141159058,
> > > 6.13967752456665, 6.98909568786621, 5.5628228187561, 6.68793487548828,
> > > 6.57724285125732, 4.67033195495605, 6.32772016525269, 6.4612717628479,
> > > 6.73934555053711, 6.73934555053711, 6.80293703079224, 6.17414236068726,
> > > 7.03696584701538, 5.93052577972412, 5.93052577972412, 5.43228578567505,
> > > 5.5989408493042, 6.86088180541992, 6.68706750869751, 6.86059141159058,
> > > 6.00043678283691, 6.86059141159058, 6.00043678283691, 6.00043678283691,
> > > 6.13967752456665, 6.89467239379883, 6.00043678283691, 6.86059141159058,
> > > 6.81896543502808, 6.86059141159058, 6.51894521713257, 6.86059141159058,
> > > 6.13967752456665, 5.63159275054932, 6.13170003890991), t_silt =
> > > c(34.2329025268555,
> > > 33.4969100952148, 34.4774589538574, 27.8914813995361, 31.9258117675781,
> > > 39.6254501342773, 34.7939414978027, 31.9258117675781, 31.9258117675781,
> > > 31.9258117675781, 31.9258117675781, 31.9258117675781, 26.6626663208008,
> > > 27.8914813995361, 31.9258117675781, 27.8914813995361, 29.7444763183594,
> > > 21.3432540893555, 37.4038734436035, 28.1513748168945, 19.4936828613281,
> > > 33.5968360900879, 32.8024406433105, 33.313850402832, 33.313850402832,
> > > 28.3197917938232, 33.3154563903809, 38.103458404541, 36.0389099121094,
> > > 36.0389099121094, 34.9229164123535, 26.5577545166016, 30.9245643615723,
> > > 31.1334323883057, 31.9258117675781, 27.1493148803711, 31.9258117675781,
> > > 27.1493148803711, 27.1493148803711, 27.8914813995361, 31.3038387298584,
> > > 27.1493148803711, 31.9258117675781, 31.6541061401367, 31.9258117675781,
> > > 26.6626663208008, 31.9258117675781, 27.8914813995361, 15.6523361206055,
> > > 27.803352355957), t_sand = c(47.0063323974609, 37.0355186462402,
> > > 45.8286781311035, 36.0810203552246, 39.9931793212891, 39.3664970397949,
> > > 46.2948226928711, 39.9931793212891, 39.9931793212891, 39.9931793212891,
> > > 39.9931793212891, 39.9931793212891, 49.3508529663086, 36.0810203552246,
> > > 39.9931793212891, 36.0810203552246, 39.2436943054199, 65.7813262939453,
> > > 35.8039131164551, 51.2884674072266, 66.2952728271484, 46.6789817810059,
> > > 41.4505424499512, 44.4590721130371, 44.4590721130371, 48.7276763916016,
> > > 43.3654098510742, 33.999683380127, 43.040699005127, 43.040699005127,
> > > 43.2519073486328, 59.4827156066895, 43.8675765991211, 41.7124671936035,
> > > 39.9931793212891, 34.94921875, 39.9931793212891, 34.94921875,
> > > 34.94921875, 36.0810203552246, 39.1853942871094, 34.94921875,
> > > 39.9931793212891, 39.8589019775391, 39.9931793212891, 49.3508529663086,
> > > 39.9931793212891, 36.0810203552246, 75.7048721313477, 33.5687866210938
> > > ), AT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), BE = c(0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0), DE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), DK = c(0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0), ES = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), FI = c(0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0), FR = c(1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), GR = c(0, 1, 0,
> > > 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> > > 0, 1, 1, 0, 1), IE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), IT = c(0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,
> > > 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 1, 0, 0, 0, 0), LU = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), NL = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 1, 0), PT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SE = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), WDE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), EDE = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), UK = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CY = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), BG = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), CZ = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), EE = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), HU = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), LT = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), LV = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), PL = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), RO = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), SI = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), SK = c(0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), b48 = c(70, 2.70000004768372, 63.9000015258789,
> > > 5.5, 6.30000019073486, 8.80000019073486, 48.0800018310547,
> 5.09999990463257,
> > > 6.40000009536743, 6, 6.69999980926514, 4, 6.30000019073486,
> 5.80000019073486,
> > > 8.80000019073486, 2, 13, 0.5, 10.25, 34, 65.2300033569336,
> 37.7799987792969,
> > > 74.9400024414062, 31.0200004577637, 20.0300006866455, 70.7200012207031,
> > > 40, 4.90000009536743, 13.5, 5, 26.8700008392334, 3, 2,
> 3.09999990463257,
> > > 6.80000019073486, 15.6999998092651, 9.19999980926514, 5.30000019073486,
> > > 4.59999990463257, 17.3999996185303, 7, 4.90000009536743,
> 13.3999996185303,
> > > 2.34999990463257, 8.5, 24.8700008392334, 4, 1.39999997615814,
> > > 34.7799987792969, 6.69999980926514), b50 = c(0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34.2400016784668, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 0, 0, 0, 0, 0), irrigation = c(0, 100, 0, 5.45454584062099,
> > > 7.9365074634552, 89.3392562866211, 0, 17.6470592617989, 0, 0,
> > > 65.5172407627106, 0, 61.904764175415, 34.4827562570572,
> 7.95454531908035,
> > > 75, 0, 0, 0, 0, 0, 0, 5.26393800973892, 0, 0, 0, 0, 0, 0, 0,
> > > 0, 0, 74.6153831481934, 84.6153914928436, 0, 5.09554147720337,
> > > 0, 0, 0, 21.0884347558022, 18.4549376368523, 6.1224490404129,
> > > 25.3731369972229, 2.12765969336033, 0, 84.3988716602325, 0, 0,
> > > 0, 100), awc_class = c(106.228088378906, 78.2306137084961,
> 80.9311141967773,
> > > 32.4921531677246, 54.8475151062012, 80.6665878295898, 116.331588745117,
> > > 54.8475151062012, 54.8475151062012, 54.8475151062012, 54.8475151062012,
> > > 54.8475151062012, 56.3101806640625, 32.4921531677246, 54.8475151062012,
> > > 32.4921531677246, 59.3034172058105, 101.193893432617, 96.5840377807617,
> > > 54.2786560058594, 87.1388244628906, 66.1907730102539, 57.205738067627,
> > > 55.4114303588867, 55.4114303588867, 80.9288787841797, 63.6008758544922,
> > > 150, 30.3404140472412, 30.3404140472412, 19.8318557739258,
> 104.236854553223,
> > > 79.2445755004883, 57.0045547485352, 54.8475151062012, 34.320426940918,
> > > 54.8475151062012, 34.320426940918, 34.320426940918, 32.4921531677246,
> > > 65.1337509155273, 34.320426940918, 54.8475151062012, 73.6748657226562,
> > > 54.8475151062012, 56.3101806640625, 54.8475151062012, 32.4921531677246,
> > > 127.726959228516, 27.9528160095215), sys02 = c(18.8571434020996,
> > > 303.529418945312, 30.2469139099121, 104.305557250977, 86.4935073852539,
> > > 51.25, 83.0927810668945, 453.118286132812, 42.5, 104.305557250977,
> > > 48.461540222168, 86.4935073852539, 55.1851844787598, 104.305557250977,
> > > 104.305557250977, 185.277770996094, 17.9775276184082, 25.2777786254883,
> > > 64, 21.6666660308838, 30, 24.2372875213623, 47.0285720825195,
> > > 16.1904754638672, 33.75, 22.5423736572266, 10.2857141494751,
> > > 39.230770111084, 6.06741571426392, 1, 28.3255805969238,
> 21.6000003814697,
> > > 69.2592620849609, 86.6666641235352, 48.5185203552246, 44.4186058044434,
> > > 48.6538467407227, 437.105255126953, 437.105255126953, 19.1666660308838,
> > > 48.461540222168, 437.105255126953, 48.6538467407227, 453.118286132812,
> > > 48.6538467407227, 14.2857141494751, 453.118286132812, 453.118286132812,
> > > 95.2380981445312, 63), se025 = c(163.529998779297, 2.70000004768372,
> > > 157, 5.5, 6.30000019073486, 36.0200004577637, 86, 5.09999990463257,
> > > 6.40000009536743, 6, 8.69999980926514, 4, 6.30000019073486,
> 5.80000019073486,
> > > 8.80000019073486, 2, 118.809997558594, 44.1100006103516,
> 16.7000007629395,
> > > 34, 73.4000015258789, 73.0800018310547, 134.880004882812,
> 31.0200004577637,
> > > 20.0300006866455, 94.7200012207031, 40, 5.5, 16.5, 15,
> 26.8700008392334,
> > > 59.4199981689453, 13, 5.19999980926514, 6.80000019073486,
> 15.6999998092651,
> > > 10.8999996185303, 5.30000019073486, 4.59999990463257, 29.3999996185303,
> > > 23.2999992370605, 4.90000009536743, 13.3999996185303, 2.34999990463257,
> > > 8.5, 24.8700008392334, 4.19999980926514, 1.39999997615814,
> 34.7799987792969,
> > > 6.69999980926514)), .Names = c("LnALVperHA", "ps1", "ps2", "ps3",
> > > "ps4", "ts1", "ts2", "ts3", "ts4", "ps1sq", "ps2sq", "ps3sq",
> > > "ps4sq", "ts1sq", "ts2sq", "ts3sq", "ts4sq", "pdnsty", "portsML",
> > > "cities500k", "rentedland", "subsidies1", "elevmean", "elevrange",
> > > "t_gravel", "t_ph_h2o", "t_silt", "t_sand", "AT", "BE", "DE",
> > > "DK", "ES", "FI", "FR", "GR", "IE", "IT", "LU", "NL", "PT", "SE",
> > > "WDE", "EDE", "UK", "CY", "BG", "CZ", "EE", "HU", "LT", "LV",
> > > "PL", "RO", "SI", "SK", "b48", "b50", "irrigation", "awc_class",
> > > "sys02", "se025"), row.names = c("2", "3", "4", "5", "6", "7",
> > > "8", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20",
> > > "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31",
> > > "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
> > > "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53"
> > > ), class = "data.frame")
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > 2015-08-14 14:58 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz>:
> > >>
> > >> Hi Janka
> > >>
> > >>
> > >>
> > >> Sorry, but we are limited in connecting to web services so I am not
> able to restore your data and see your code. Result of dput(somedata)
> coppied to email is preferable for sharing data and code can be copied to
> email too. But do not use HTML as it usually scrambles  text.
> > >>
> > >>
> > >>
> > >> Answer in line
> > >>
> > >>
> > >>
> > >> From: Janka Vanschoenwinkel [mailto:janka.vanschoenwinkel at uhasselt.be
> ]
> > >> Sent: Friday, August 14, 2015 2:17 PM
> > >> To: Thierry Onkelinx; PIKAL Petr
> > >> Cc: r-help at r-project.org
> > >> Subject: Re: [R] cut variable within a loop
> > >>
> > >>
> > >>
> > >> Hi Thierry and Petr,
> > >>
> > >>
> > >>
> > >> I really appreciate the comments you already gave. Thank you very
> much for that.
> > >>
> > >>
> > >>
> > >> Below you can find a link to the data and the code. Hopefully this
> helps in spotting the error.
> > >>
> > >>
> > >>
> > >> I still think the issue is that the cut2 function only accepts
> numbers, and not an "i" that refers to the number at the start of the loop.
> To answer Petr his question, yes, column 3 and 4 are NA (these are the
> columns of the second interval). But I don't really understand your point
> so could you clarify this please?
> > >>
> > >>
> > >>
> > >> If you use NA as a number of intervals you will get such errors
> > >>
> > >>
> > >>
> > >> k<-c(2,4,NA,5)
> > >>
> > >> ii<-vector(4, mode="list")
> > >>
> > >> for (i in 1:4) {
> > >>
> > >> ii[[i]] <- cut2(iris[,i], k[i])
> > >>
> > >> }
> > >>
> > >> Error in if (r[1] < cuts[1]) cuts <- c(r[1], cuts) :
> > >>
> > >>  missing value where TRUE/FALSE needed
> > >>
> > >> for (i in 1:4) {
> > >>
> > >> ii[[i]] <- cut(iris[,i], k[i])
> > >>
> > >> }
> > >>
> > >> Error in cut.default(iris[, i], k[i]) : invalid number of intervals
> > >>
> > >>
> > >>
> > >> If you remove NA from k definition error is gone.
> > >>
> > >> k<-c(2,4,3,5)
> > >>
> > >> ii<-vector(4, mode="list")
> > >>
> > >>
> > >>
> > >> for (i in 1:4) {
> > >>
> > >> ii[[i]] <- cut(iris[,i], k[i])
> > >>
> > >> }
> > >>
> > >>
> > >>
> > >> You can try it yourself. The error is not related to cycle; whenever
> number of intervals in cut call is NA you always get an error.
> > >>
> > >>
> > >>
> > >> Cheers
> > >>
> > >> Petr
> > >>
> > >>
> > >>
> > >>
> https://drive.google.com/folderview?id=0By9u5m3kxn9yfkxxeVNMdnRQQXhoT05CRlJlZVBCWWF2NURMMTNmVFVFeXJXXzhlMWE4SUk&usp=sharing
> > >>
> > >>
> > >>
> > >> Thank you very much once again!
> > >>
> > >>
> > >>
> > >> Janka
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >> 2015-08-11 15:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be
> >:
> > >>
> > >> You'll need to send a reproducible example of the code. We can't run
> the code that you send. Hence it is hard to help you. See e.g.
> http://adv-r.had.co.nz/Reproducibility.html
> > >>
> > >>
> > >> ir. Thierry Onkelinx
> > >> Instituut voor natuur- en bosonderzoek / Research Institute for
> Nature and Forest
> > >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > >> Kliniekstraat 25
> > >> 1070 Anderlecht
> > >> Belgium
> > >>
> > >> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be able
> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > >> The plural of anecdote is not data. ~ Roger Brinner
> > >> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
> > >>
> > >>
> > >>
> > >> 2015-08-11 14:57 GMT+02:00 Janka Vanschoenwinkel <
> janka.vanschoenwinkel at uhasselt.be>:
> > >>
> > >> Hi Thierry!
> > >>
> > >>
> > >>
> > >> Thanks for your answer. I tried this, but I get this error:
> > >>
> > >>
> > >>
> > >> "Error in cut.default(x, k2) : invalid number of intervals"
> > >>
> > >>
> > >>
> > >> Which is strange because I am not specifying intervals, but the
> number at where the sample has to be cut?
> > >>
> > >>
> > >>
> > >> Greetings from Belgium! :-)
> > >>
> > >>
> > >>
> > >> 2015-08-11 14:52 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be
> >:
> > >>
> > >> Dear Janka,
> > >>
> > >>
> > >>
> > >> You loop goes for 0 to 100. It should probably go from 1:99
> > >>
> > >>
> > >>
> > >> Best regards,
> > >>
> > >>
> > >> ir. Thierry Onkelinx
> > >> Instituut voor natuur- en bosonderzoek / Research Institute for
> Nature and Forest
> > >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > >> Kliniekstraat 25
> > >> 1070 Anderlecht
> > >> Belgium
> > >>
> > >> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be able
> to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > >> The plural of anecdote is not data. ~ Roger Brinner
> > >> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body of
> data. ~ John Tukey
> > >>
> > >>
> > >>
> > >> 2015-08-11 14:38 GMT+02:00 Janka Vanschoenwinkel <
> janka.vanschoenwinkel at uhasselt.be>:
> > >>
> > >> Dear list members,
> > >>
> > >> I have a loop where I want to do several calculations for different
> samples
> > >> and save the results for each sample. These samples are for each loop
> > >> different. I want to use the "i" in the loop to cut the samples.
> > >>
> > >> So for instance:
> > >>
> > >>   - In loop 1 (i=1), I have a sample from 0-1 and a sample from 1-100.
> > >>   - In loop 2 (i=2), I have a sample from 0-2 and a sample from 2-100.
> > >>   - In loop 99 (i=99), I have a sample from 0-99 and a sample from
> 99-100.
> > >>
> > >> I built the following function, but there is *a problem with the cut2
> > >> function* since it doesn't recognize the "i". Outside the lapply loop
> it
> > >> works, but not inside the loop.
> > >>
> > >> Could somebody please help me with this problem? Thanks a lot!
> > >>
> > >>
> > >>
> d=data.frame(MEt_Rainfed=rep(0,100),MEp_Rainfed=rep(0,100),MEt_Irrigation=rep(0,100),MEp_Irrigation=rep(0,100))
> > >>
> > >>
> > >>
> > >>    o<-lapply(0:100, function(i){
> > >>
> > >>
> > >>
> > >>        Alldata$irri=cut2(Alldata$irrigation,i)
> > >>
> > >>        levels(Alldata$irri)<-c("0","1")
> > >>
> > >>
> > >>
> > >>       Alldata_Rainfed<-subset(Alldata, irri == 0)
> > >>
> > >>       Alldata_Irrigation<-subset(Alldata, irri == 1)
> > >>
> > >>
> > >>
> > >>    #calculations per sample, then store all the values per i and per
> > >> variable in a dataframe: (the calculations are not shown in this
> example)
> > >>
> > >>
> > >>
> > >>     d[i, ] = c(MEt_Rainfed,MEp_Rainfed,MEt_Irrigation,MEp_Irrigation)
> > >>
> > >>
> > >>
> > >>   })
> > >>
> > >>
> > >>
> > >>   out<-as.data.frame(do.call(rbind, o))
> > >>
> > >>
> > >> --
> > >> P Please consider the environment before printing this e-mail
> > >>
> > >>        [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >> --
> > >>
> > >>
> > >>
> > >> Mevrouw Janka Vanschoenwinkel
> > >> Doctoraatsbursaal - PhD
> > >> Milieueconomie - Environmental economics
> > >>
> > >> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> > >>
> > >> www.uhasselt.be/eec
> > >>
> > >> Universiteit Hasselt | Campus Diepenbeek
> > >> Agoralaan Gebouw D | B-3590 Diepenbeek
> > >> Kantoor F11
> > >>
> > >> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> > >>
> > >> P Please consider the environment before printing this e-mail
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >> --
> > >>
> > >>
> > >>
> > >> Mevrouw Janka Vanschoenwinkel
> > >> Doctoraatsbursaal - PhD
> > >> Milieueconomie - Environmental economics
> > >>
> > >> T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> > >>
> > >> www.uhasselt.be/eec
> > >>
> > >> Universiteit Hasselt | Campus Diepenbeek
> > >> Agoralaan Gebouw D | B-3590 Diepenbeek
> > >> Kantoor F11
> > >>
> > >> Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> > >>
> > >> P Please consider the environment before printing this e-mail
> > >>
> > >>
> > >>
> > >>
> > >> ________________________________
> > >> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> > >> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > >> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > >> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> > >>
> > >> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > >> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > >> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > >> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > >> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> > >>
> > >> This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> > >> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > >> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> > >> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> > >>
> > >> In case that this e-mail forms part of business dealings:
> > >> - the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> > >> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> > >> - the sender insists on that the respective contract is concluded
> only upon an express mutual agreement on all its aspects.
> > >> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> > >
> > >
> > >
> > >
> > > --
> > >
> > > Mevrouw Janka Vanschoenwinkel
> > > Doctoraatsbursaal - PhD
> > > Milieueconomie - Environmental economics
> > >
> > > T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> > >
> > > www.uhasselt.be/eec
> > >
> > > Universiteit Hasselt | Campus Diepenbeek
> > > Agoralaan Gebouw D | B-3590 Diepenbeek
> > > Kantoor F11
> > >
> > > Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> > >
> > > P Please consider the environment before printing this e-mail
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> >
> >
> > --
> >
> >       Mevrouw Janka Vanschoenwinkel
> > Doctoraatsbursaal - PhD
> > Milieueconomie - Environmental economics
> >
> > T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40
> >
> > www.uhasselt.be/eec
> >
> > Universiteit Hasselt | Campus Diepenbeek
> > Agoralaan Gebouw D | B-3590 Diepenbeek
> > Kantoor F11
> >
> > Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt
> >
> > P Please consider the environment before printing this e-mail
> >
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 

[image: Logo UHasselt]Mevrouw Janka Vanschoenwinkel
*Doctoraatsbursaal - PhD *
Milieueconomie - Environmental economics

T +32(0)11 26 87 42 | GSM +32(0)476 28 21 40

www.uhasselt.be/eec

Universiteit Hasselt | Campus Diepenbeek
Agoralaan Gebouw D | B-3590 Diepenbeek
Kantoor F11

Postadres: Universiteit Hasselt | Martelarenlaan 42 | B-3500 Hasselt

P Please consider the environment before printing this e-mail

	[[alternative HTML version deleted]]


From sdevendersingh91 at gmail.com  Sun Aug 23 19:08:10 2015
From: sdevendersingh91 at gmail.com (devender singh saini)
Date: Sun, 23 Aug 2015 22:38:10 +0530
Subject: [R] Error while running swirl package in R
Message-ID: <CAE_tb20cXXfE2St7A68ZBh=PyvZRVpD_OtOZFQwPuy=CwPWxSA@mail.gmail.com>

Hi,
     I am not able to work in swirl package in R. I am able to install the
package R. But while giving the library("swirl") command the error comes up.
This is the error message.

> install.packages("swirl")
Installing package into ?C:/Users/Devender/Documents/R/win-library/3.2?
(as ?lib? is unspecified)
trying URL
'https://cran.rstudio.com/bin/windows/contrib/3.2/swirl_2.2.21.zip'
Content type 'application/zip' length 132711 bytes (129 KB)
downloaded 129 KB

package ?swirl? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\Devender\AppData\Local\Temp\RtmpKuk1l0\downloaded_packages
> library("swirl")
Error in get(Info[i, 1], envir = env) :
  cannot open file
'C:/Users/Devender/Documents/R/win-library/3.2/httr/R/httr.rdb': No such
file or directory
Error: package or namespace load failed for ?swirl?


If anyone nows about this. Please help.
Thanks

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Aug 23 21:42:34 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Aug 2015 12:42:34 -0700
Subject: [R] Error while running swirl package in R
In-Reply-To: <CAE_tb20cXXfE2St7A68ZBh=PyvZRVpD_OtOZFQwPuy=CwPWxSA@mail.gmail.com>
References: <CAE_tb20cXXfE2St7A68ZBh=PyvZRVpD_OtOZFQwPuy=CwPWxSA@mail.gmail.com>
Message-ID: <34DE58D8-223B-4753-987B-9F8AFDEB3790@comcast.net>


On Aug 23, 2015, at 10:08 AM, devender singh saini wrote:

> Hi,
>     I am not able to work in swirl package in R. I am able to install the
> package R. But while giving the library("swirl") command the error comes up.
> This is the error message.
> 
>> install.packages("swirl")
> Installing package into ?C:/Users/Devender/Documents/R/win-library/3.2?
> (as ?lib? is unspecified)
> trying URL
> 'https://cran.rstudio.com/bin/windows/contrib/3.2/swirl_2.2.21.zip'
> Content type 'application/zip' length 132711 bytes (129 KB)
> downloaded 129 KB
> 
> package ?swirl? successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
>        C:\Users\Devender\AppData\Local\Temp\RtmpKuk1l0\downloaded_packages
>> library("swirl")
> Error in get(Info[i, 1], envir = env) :
>  cannot open file
> 'C:/Users/Devender/Documents/R/win-library/3.2/httr/R/httr.rdb': No such
> file or directory
> Error: package or namespace load failed for ?swirl?

It appears that the swirl package expects to have the httr package installed. You did not include the parameter dependencies=TRUE when you installed swirl.

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ligges at statistik.tu-dortmund.de  Sun Aug 23 22:18:30 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 23 Aug 2015 22:18:30 +0200
Subject: [R] Error while running swirl package in R
In-Reply-To: <34DE58D8-223B-4753-987B-9F8AFDEB3790@comcast.net>
References: <CAE_tb20cXXfE2St7A68ZBh=PyvZRVpD_OtOZFQwPuy=CwPWxSA@mail.gmail.com>
	<34DE58D8-223B-4753-987B-9F8AFDEB3790@comcast.net>
Message-ID: <55DA2A96.3060708@statistik.tu-dortmund.de>



On 23.08.2015 21:42, David Winsemius wrote:
>
> On Aug 23, 2015, at 10:08 AM, devender singh saini wrote:
>
>> Hi,
>>      I am not able to work in swirl package in R. I am able to install the
>> package R. But while giving the library("swirl") command the error comes up.
>> This is the error message.
>>
>>> install.packages("swirl")
>> Installing package into ?C:/Users/Devender/Documents/R/win-library/3.2?
>> (as ?lib? is unspecified)
>> trying URL
>> 'https://cran.rstudio.com/bin/windows/contrib/3.2/swirl_2.2.21.zip'
>> Content type 'application/zip' length 132711 bytes (129 KB)
>> downloaded 129 KB
>>
>> package ?swirl? successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>>         C:\Users\Devender\AppData\Local\Temp\RtmpKuk1l0\downloaded_packages
>>> library("swirl")
>> Error in get(Info[i, 1], envir = env) :
>>   cannot open file
>> 'C:/Users/Devender/Documents/R/win-library/3.2/httr/R/httr.rdb': No such
>> file or directory
>> Error: package or namespace load failed for ?swirl?
>
> It appears that the swirl package expects to have the httr package installed. You did not include the parameter dependencies=TRUE when you installed swirl.

The default should be fine, guess the httr installation is simply broken.

Best,
Uwe Ligges


>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From diegoalejandroospina at hotmail.com  Mon Aug 24 03:48:46 2015
From: diegoalejandroospina at hotmail.com (DiegoA_OspinaR)
Date: Sun, 23 Aug 2015 18:48:46 -0700 (PDT)
Subject: [R] Dealing with DAILY time series
Message-ID: <1440380926853-4711411.post@n4.nabble.com>

Good afternoon.

I have problems dealing with daily data time series.

I have this code as an example of monthly data, begining in January/1990:

              X=ts(x,frequency=12,start=c(1990,1))

How must I write my time series, to declare I have DAILY data begining in
October 3rd 2014?

Thanks a lot.

Regards,
Diego



--
View this message in context: http://r.789695.n4.nabble.com/Dealing-with-DAILY-time-series-tp4711411.html
Sent from the R help mailing list archive at Nabble.com.


From sdevendersingh91 at gmail.com  Mon Aug 24 06:34:37 2015
From: sdevendersingh91 at gmail.com (devender singh saini)
Date: Mon, 24 Aug 2015 10:04:37 +0530
Subject: [R] Error while running swirl package in R
In-Reply-To: <55DA2A96.3060708@statistik.tu-dortmund.de>
References: <CAE_tb20cXXfE2St7A68ZBh=PyvZRVpD_OtOZFQwPuy=CwPWxSA@mail.gmail.com>
	<34DE58D8-223B-4753-987B-9F8AFDEB3790@comcast.net>
	<55DA2A96.3060708@statistik.tu-dortmund.de>
Message-ID: <CAE_tb23MT83ttAHx8Wu3ELcUD+oU9VPTtYzAAfgani9rmVUwYg@mail.gmail.com>

ThankYou very much all of you. It is working now. Thanks alot! :)

On Mon, Aug 24, 2015 at 1:48 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 23.08.2015 21:42, David Winsemius wrote:
>
>>
>> On Aug 23, 2015, at 10:08 AM, devender singh saini wrote:
>>
>> Hi,
>>>      I am not able to work in swirl package in R. I am able to install
>>> the
>>> package R. But while giving the library("swirl") command the error comes
>>> up.
>>> This is the error message.
>>>
>>> install.packages("swirl")
>>>>
>>> Installing package into ?C:/Users/Devender/Documents/R/win-library/3.2?
>>> (as ?lib? is unspecified)
>>> trying URL
>>> 'https://cran.rstudio.com/bin/windows/contrib/3.2/swirl_2.2.21.zip'
>>> Content type 'application/zip' length 132711 bytes (129 KB)
>>> downloaded 129 KB
>>>
>>> package ?swirl? successfully unpacked and MD5 sums checked
>>>
>>> The downloaded binary packages are in
>>>
>>> C:\Users\Devender\AppData\Local\Temp\RtmpKuk1l0\downloaded_packages
>>>
>>>> library("swirl")
>>>>
>>> Error in get(Info[i, 1], envir = env) :
>>>   cannot open file
>>> 'C:/Users/Devender/Documents/R/win-library/3.2/httr/R/httr.rdb': No such
>>> file or directory
>>> Error: package or namespace load failed for ?swirl?
>>>
>>
>> It appears that the swirl package expects to have the httr package
>> installed. You did not include the parameter dependencies=TRUE when you
>> installed swirl.
>>
>
> The default should be fine, guess the httr installation is simply broken.
>
> Best,
> Uwe Ligges
>
>
>
>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From marceivissa at gmail.com  Mon Aug 24 10:43:07 2015
From: marceivissa at gmail.com (=?UTF-8?Q?Marc_Mar=C3=AD_Dell=27Olmo?=)
Date: Mon, 24 Aug 2015 10:43:07 +0200
Subject: [R] =?utf-8?q?problem_with_accents_and_Catalan_characters_=28for_?=
	=?utf-8?q?ex=2E_=C3=A7=29_using_geocode_function_=28ggmap=29?=
Message-ID: <CAAZSCQ5wFyWBxHLXaLqbArw90EgjZFAMs=BU9xexfsnJqcxDrw@mail.gmail.com>

Dear all,

I'm trying to geocode addresses (of Catalonia) with accents and
Catalan characters (as for example "?").  I'm using the "geocode"
function (package ggmap), but I obtain some Google "INVALID_REQUEST"
when the addresses have these characters. For example:

> geocode("Carrer Vene?uela, 10, 08019 Barcelona, Spain")
Information from URL :
http://maps.googleapis.com/maps/api/geocode/json?address=Carrer+Vene%E7uela,+10,+08019+Barcelona,+Spain&sensor=false
  lon lat
1  NA  NA
Warning message:
geocode failed with status INVALID_REQUEST, location =
"Carrer+Vene?uela,+10,+08019+Barcelona,+Spain"


> geocode("Carrer Mec?nica, 12, 08038 Barcelona, Spain")
Information from URL :
http://maps.googleapis.com/maps/api/geocode/json?address=Carrer+Mec%E0nica,+12,+08038+Barcelona,+Spain&sensor=false
  lon lat
1  NA  NA
Warning message:
geocode failed with status INVALID_REQUEST, location =
"Carrer+Mec?nica,+12,+08038+Barcelona,+Spain"

However, I can find these addresses directly on Google maps.

https://www.google.es/maps/place/Carrer+de+Vene%C3%A7uela,+10,+08019+Barcelona/@41.40873,2.2057253,17z/data=!3m1!4b1!4m2!3m1!1s0x12a4a347b9b9bb8d:0x41b696acd7b26e37

https://www.google.es/maps/place/Carrer+de+la+Mec%C3%A0nica,+12,+08038+Barcelona/@41.3591918,2.1379927,17z/data=!3m1!4b1!4m2!3m1!1s0x12a498a25156dc8b:0xc9ccfd74e54c503f


I think that there is a problem enconding the URL. I hope anyone can
help me! Thank you very much!


Marc


From drjimlemon at gmail.com  Mon Aug 24 11:20:15 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 24 Aug 2015 19:20:15 +1000
Subject: [R] Compute RowMeans from mulple files
In-Reply-To: <320737549.4622328.1440349300423.JavaMail.yahoo@mail.yahoo.com>
References: <320737549.4622328.1440349300423.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fV=0Kvp9dKa2KTtF_AuABwYLyRD496CHVwq9oUj5in92Q@mail.gmail.com>

Hi Peter,
I think your problem is that your calculations occur after the end of
the loop. What you probably want is something like this:

yr_means<-mam_means<-jf_means<-
 jja_means<-ond_means<-rep(NA,length(prec_files))
for (i in 1:length(prec_files)) {
 prec_data<-read.delim(prec_files[i], sep="\t",header = TRUE)
 # All years assignments
 all_yr <- prec_data[, 2:13]
 # Season assignment
 jf <- prec_data[, 2:3]
 mam <- prec_data[, 4:6]
 jja <- prec_data[, 7:9]
 ond <- prec_data[, 11:13]
 jf_means[i] <- apply(jf, 1, mean)
mam_means[i] <- apply(mam, 1, mean)
 jja_means[i] <- apply(jja, 1, mean)
 ond_means[i] <-apply(ond, 1, mean)
 yr_means[i] <- apply(all_yr, 1, mean)
}

Jim

On Mon, Aug 24, 2015 at 3:01 AM, Peter Tuju <peterenos at ymail.com> wrote:
> Dear R users, I have fifty two (52) text files with the same dimensions (ie 31 by 13). Three sample of such data files are attached. I want to compute the rowMeans for each separate file for;(i) all the months
> (ii) For January and February
> (iii) For March, April and May
> (iv) For June, July and august
> (v) For October, November and December
> (vi) Plot the single mass curve for each file and season ie. plot(Year, cumsum(rowMeans([])))
> (vii) Plot Time series graphs for each file and per each season.
> The code I was trying to use is given below, and I investigated it and find that it does just for one only one file.How can I loop through all files?
> I kindly need your help.
>
> Thanks in advance!!
>
>
> rm(list = ls())
> setwd("/run/media/nwp-tma/+255767090047/analysis/R/R_sessions/R_sessions_prec/Rain_stn_data")# Import text filesprec_files <- list.files(pattern="*.txt")# Reading my files
> prec_files <- list.files(pattern = ".txt")
> for (i in 1:length(prec_files)){
>   prec_data = read.delim(prec_files[i], sep="\t",
> header = TRUE)  }
> #prec_data <- as.numeric(prec_data[, 2:13])
> # All years assignments
> all_yr <- prec_data[, 2:13]
> # Season assignment
> jf <- prec_data[, 2:3]
> mam <- prec_data[, 4:6]
> jja <- prec_data[, 7:9]
> ond <- prec_data[, 11:13]
> jf_means <- apply(jf, 1, mean)
> mam_means <- apply(mam, 1, mean)
> jja_means <- apply(jja, 1, mean)
> ond_means <-apply(ond, 1, mean)
> yr_mean <- apply(all_yr, 1, mean)
>
>
>  _____________
> Peter  E. Tuju
> Dar es Salaam
> T A N Z A N I A
> ----------------------
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cahoff at gmx.de  Mon Aug 24 11:10:11 2015
From: cahoff at gmx.de (CarstenH)
Date: Mon, 24 Aug 2015 02:10:11 -0700 (PDT)
Subject: [R] Calculate the area under a curve
Message-ID: <1440407411144-4711418.post@n4.nabble.com>

Hi all

I need to calculate the area under a curve (integral) for the following data
pairs:

Depth SOC	
22.5	0.143
28.5 	0.165	
34.5	0.131	
37.5	0.134	
40.5	0.138	
43.5 	0.107	
46.5	0.132
49.5 	0.175 
52.5	0.087	
55.5 	0.117	
58.5	0.126	
61.5 	0.13	
64.5	0.122	
67.5 	0.161	
71.5	0.144	
76.5 	0.146	
82.5	0.156	
94.5	0.132	

(Table name is P)

After reading the data set I assiged the collumns by:

/x <- (P$Depth)
y <- (P$SOC)
/

and decided to make a ploynominal function (3rd order):

/fitP <- lm( y~poly(x,3,raw=TRUE) )/

At the next step I failed. I can plot point and function but am not able to
integrate the curve between e.g. depths 20 and 80.

If I try:
/
integrand <-function(fitP1)
  predict(y)
integrate(integrand, lower = 25, upper = 80)/

the "Conosle" opend with the message: "Source unavailable or out of sync"
and
/
function(fitP1)
predict(y)
/
)


Would be great if somebody could help!

Thanks

Carsten



--
View this message in context: http://r.789695.n4.nabble.com/Calculate-the-area-under-a-curve-tp4711418.html
Sent from the R help mailing list archive at Nabble.com.


From butt_its_me at hotmail.com  Mon Aug 24 13:00:31 2015
From: butt_its_me at hotmail.com (Jhon Grey)
Date: Mon, 24 Aug 2015 16:30:31 +0530
Subject: [R] Understand Rcode- subset
Message-ID: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>

Hi!
I am facing a problem in understanding the R-Code
Suppose I have a dataset named- transact with its values like following:

 
 
 
 
  customer_ID 
  shopping_pt
  record_type
 
 
  10000000
  1
  0
 
 
  10000000
  2
  0
 
 
  10000000
  3
  0
 
 
  10000000
  4
  0
 
 
  10000000
  5
  0
 
 
  10000000
  6
  0
 
 
  10000000
  7
  0
 
 
  10000000
  8
  0
 
 
  10000000
  9
  1
 
 
  10000005
  1
  0
 
 
  10000005
  2
  0
 
 
  10000005
  3
  0
 
 
  10000005
  4
  0
 
 
  10000005
  5
  0
 
 
  10000005
  6
  1
 
 
  10000007
  1
  0
 
 
  10000007
  2
  0
 
 
  10000007
  3
  0
 
 
  10000007
  4
  0
 
How does the following code work and the results of sub and id-
id<-transact$record_type==1sub<-train[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE) sub2<-train[id,]
Thanks in advance!
 		 	   		  
	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Aug 24 15:25:09 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 24 Aug 2015 15:25:09 +0200
Subject: [R] Understand Rcode- subset
In-Reply-To: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>
References: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>
Message-ID: <CAJuCY5xCQG28rXqz_PVqYUm6FHKi_zt8noAZcHefWpO6TXZfUA@mail.gmail.com>

Posting in HTML mangles up your code, making it hard to read. Please
resend your question in plain text and make the code reproducible. See
http://adv-r.had.co.nz/Reproducibility.html for more details on that.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-08-24 13:00 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
> Hi!
> I am facing a problem in understanding the R-Code
> Suppose I have a dataset named- transact with its values like following:
>
>
>
>
>
>   customer_ID
>   shopping_pt
>   record_type
>
>
>   10000000
>   1
>   0
>
>
>   10000000
>   2
>   0
>
>
>   10000000
>   3
>   0
>
>
>   10000000
>   4
>   0
>
>
>   10000000
>   5
>   0
>
>
>   10000000
>   6
>   0
>
>
>   10000000
>   7
>   0
>
>
>   10000000
>   8
>   0
>
>
>   10000000
>   9
>   1
>
>
>   10000005
>   1
>   0
>
>
>   10000005
>   2
>   0
>
>
>   10000005
>   3
>   0
>
>
>   10000005
>   4
>   0
>
>
>   10000005
>   5
>   0
>
>
>   10000005
>   6
>   1
>
>
>   10000007
>   1
>   0
>
>
>   10000007
>   2
>   0
>
>
>   10000007
>   3
>   0
>
>
>   10000007
>   4
>   0
>
> How does the following code work and the results of sub and id-
> id<-transact$record_type==1sub<-train[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE) sub2<-train[id,]
> Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Aug 24 16:05:38 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 24 Aug 2015 07:05:38 -0700
Subject: [R] Compute RowMeans from mulple files
In-Reply-To: <CA+8X3fV=0Kvp9dKa2KTtF_AuABwYLyRD496CHVwq9oUj5in92Q@mail.gmail.com>
References: <320737549.4622328.1440349300423.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fV=0Kvp9dKa2KTtF_AuABwYLyRD496CHVwq9oUj5in92Q@mail.gmail.com>
Message-ID: <CAGxFJbTVoUBvOD3EnSJegseYn2d971Tpi7qFpd8qUU-LC7_Vkg@mail.gmail.com>

Note that, in general,

rowMeans(x)

is preferable to

apply(x,1,mean)

Consult ?rowMeans  for details.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Aug 24, 2015 at 2:20 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Peter,
> I think your problem is that your calculations occur after the end of
> the loop. What you probably want is something like this:
>
> yr_means<-mam_means<-jf_means<-
>  jja_means<-ond_means<-rep(NA,length(prec_files))
> for (i in 1:length(prec_files)) {
>  prec_data<-read.delim(prec_files[i], sep="\t",header = TRUE)
>  # All years assignments
>  all_yr <- prec_data[, 2:13]
>  # Season assignment
>  jf <- prec_data[, 2:3]
>  mam <- prec_data[, 4:6]
>  jja <- prec_data[, 7:9]
>  ond <- prec_data[, 11:13]
>  jf_means[i] <- apply(jf, 1, mean)
> mam_means[i] <- apply(mam, 1, mean)
>  jja_means[i] <- apply(jja, 1, mean)
>  ond_means[i] <-apply(ond, 1, mean)
>  yr_means[i] <- apply(all_yr, 1, mean)
> }
>
> Jim
>
> On Mon, Aug 24, 2015 at 3:01 AM, Peter Tuju <peterenos at ymail.com> wrote:
>> Dear R users, I have fifty two (52) text files with the same dimensions (ie 31 by 13). Three sample of such data files are attached. I want to compute the rowMeans for each separate file for;(i) all the months
>> (ii) For January and February
>> (iii) For March, April and May
>> (iv) For June, July and august
>> (v) For October, November and December
>> (vi) Plot the single mass curve for each file and season ie. plot(Year, cumsum(rowMeans([])))
>> (vii) Plot Time series graphs for each file and per each season.
>> The code I was trying to use is given below, and I investigated it and find that it does just for one only one file.How can I loop through all files?
>> I kindly need your help.
>>
>> Thanks in advance!!
>>
>>
>> rm(list = ls())
>> setwd("/run/media/nwp-tma/+255767090047/analysis/R/R_sessions/R_sessions_prec/Rain_stn_data")# Import text filesprec_files <- list.files(pattern="*.txt")# Reading my files
>> prec_files <- list.files(pattern = ".txt")
>> for (i in 1:length(prec_files)){
>>   prec_data = read.delim(prec_files[i], sep="\t",
>> header = TRUE)  }
>> #prec_data <- as.numeric(prec_data[, 2:13])
>> # All years assignments
>> all_yr <- prec_data[, 2:13]
>> # Season assignment
>> jf <- prec_data[, 2:3]
>> mam <- prec_data[, 4:6]
>> jja <- prec_data[, 7:9]
>> ond <- prec_data[, 11:13]
>> jf_means <- apply(jf, 1, mean)
>> mam_means <- apply(mam, 1, mean)
>> jja_means <- apply(jja, 1, mean)
>> ond_means <-apply(ond, 1, mean)
>> yr_mean <- apply(all_yr, 1, mean)
>>
>>
>>  _____________
>> Peter  E. Tuju
>> Dar es Salaam
>> T A N Z A N I A
>> ----------------------
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cdetermanjr at gmail.com  Mon Aug 24 16:10:47 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Mon, 24 Aug 2015 09:10:47 -0500
Subject: [R] Calculate the area under a curve
In-Reply-To: <1440407411144-4711418.post@n4.nabble.com>
References: <1440407411144-4711418.post@n4.nabble.com>
Message-ID: <CAKxd1KOZrtGFSY7o8sS4yLqMA4egRMhzfwpsxrTr+e4UnRyX5Q@mail.gmail.com>

Hi Carsten,

This list is meant to help you solve specific coding problems.  What have
you tried?  A quick google search will provide several packages including
caTools, ROCR, AUC, pROC.  Look in to some of them, try them out and report
back if you have problems 'using' a function instead of just asking 'how
can I do this?'  As with everything in R, there are many different ways to
accomplish the same thing.

Regards,
Charles

On Mon, Aug 24, 2015 at 4:10 AM, CarstenH <cahoff at gmx.de> wrote:

> Hi all
>
> I need to calculate the area under a curve (integral) for the following
> data
> pairs:
>
> Depth SOC
> 22.5    0.143
> 28.5    0.165
> 34.5    0.131
> 37.5    0.134
> 40.5    0.138
> 43.5    0.107
> 46.5    0.132
> 49.5    0.175
> 52.5    0.087
> 55.5    0.117
> 58.5    0.126
> 61.5    0.13
> 64.5    0.122
> 67.5    0.161
> 71.5    0.144
> 76.5    0.146
> 82.5    0.156
> 94.5    0.132
>
> (Table name is P)
>
> After reading the data set I assiged the collumns by:
>
> /x <- (P$Depth)
> y <- (P$SOC)
> /
>
> and decided to make a ploynominal function (3rd order):
>
> /fitP <- lm( y~poly(x,3,raw=TRUE) )/
>
> At the next step I failed. I can plot point and function but am not able to
> integrate the curve between e.g. depths 20 and 80.
>
> If I try:
> /
> integrand <-function(fitP1)
>   predict(y)
> integrate(integrand, lower = 25, upper = 80)/
>
> the "Conosle" opend with the message: "Source unavailable or out of sync"
> and
> /
> function(fitP1)
> predict(y)
> /
> )
>
>
> Would be great if somebody could help!
>
> Thanks
>
> Carsten
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Calculate-the-area-under-a-curve-tp4711418.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Aug 24 16:23:25 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 24 Aug 2015 07:23:25 -0700
Subject: [R] Calculate the area under a curve
In-Reply-To: <1440407411144-4711418.post@n4.nabble.com>
References: <1440407411144-4711418.post@n4.nabble.com>
Message-ID: <9FE05A8E-B84F-4D12-913E-F7F4BBE0B0D6@dcn.davis.CA.us>

Read ?predict, paying particular attention to the newdata argument.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 24, 2015 2:10:11 AM PDT, CarstenH <cahoff at gmx.de> wrote:
>Hi all
>
>I need to calculate the area under a curve (integral) for the following
>data
>pairs:
>
>Depth SOC	
>22.5	0.143
>28.5 	0.165	
>34.5	0.131	
>37.5	0.134	
>40.5	0.138	
>43.5 	0.107	
>46.5	0.132
>49.5 	0.175 
>52.5	0.087	
>55.5 	0.117	
>58.5	0.126	
>61.5 	0.13	
>64.5	0.122	
>67.5 	0.161	
>71.5	0.144	
>76.5 	0.146	
>82.5	0.156	
>94.5	0.132	
>
>(Table name is P)
>
>After reading the data set I assiged the collumns by:
>
>/x <- (P$Depth)
>y <- (P$SOC)
>/
>
>and decided to make a ploynominal function (3rd order):
>
>/fitP <- lm( y~poly(x,3,raw=TRUE) )/
>
>At the next step I failed. I can plot point and function but am not
>able to
>integrate the curve between e.g. depths 20 and 80.
>
>If I try:
>/
>integrand <-function(fitP1)
>  predict(y)
>integrate(integrand, lower = 25, upper = 80)/
>
>the "Conosle" opend with the message: "Source unavailable or out of
>sync"
>and
>/
>function(fitP1)
>predict(y)
>/
>)
>
>
>Would be great if somebody could help!
>
>Thanks
>
>Carsten
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Calculate-the-area-under-a-curve-tp4711418.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Wang.Xue at mayo.edu  Mon Aug 24 15:48:28 2015
From: Wang.Xue at mayo.edu (Wang, Xue, Ph.D.)
Date: Mon, 24 Aug 2015 13:48:28 +0000
Subject: [R] lsqlin in R package pracma
Message-ID: <2f3a88$19bee5@ironport10.mayo.edu>

Hi R developers,
I am looking for a R version of Matlab function lsqlin. I came across R pracma package which has a lsqlin function. Compared with Matlab lsqlin, the R version does not allow inequality constraints.
I am wondering if this functionality will be available in future. And I would also like to get your opinion on which R package/function is the best for solving least square minimization problem with linear inequality constraints.
Thanks very much for your time and attention!


Xue









	[[alternative HTML version deleted]]


From marco.colagrossi at gmail.com  Mon Aug 24 16:03:43 2015
From: marco.colagrossi at gmail.com (Marco Colagrossi)
Date: Mon, 24 Aug 2015 16:03:43 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
Message-ID: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>

Hello folks,

I have a couple of issues with the metafor package, specifically with
the forest graphs.
I am currently conducting a Meta-Analysis in economics throughout the
metafor package.

My meta-analysis has the specific of having different cases from
single studies, and this proven to be challenging especially when
trying to plot graphically the results I'm obtaining.

Here's the code:

forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1, subset=(pub==1),
       ilab = cbind(ys, f_dim, SIMdv, SIMiv),
       ilab.xpos = c(-9.5, -8, -6, -4.5), cex = 0.75)
par(font=2)
      text(c(-9.5,-8,-6,-4.5), 26, c("Years", "Firm(s) Dimension", "DV", "IV"))
      text(-16,                26, "Author(s) and Year",     pos=4)
      text(6,                  26, "Observed Outcome [95% CI]", pos=2)
par(op)

'pc' is the 'effect size', 'var' the variance, 'ci95m & ci95p' the CI,
'pub' if the paper has been published or not. the pub subset was the
first idea I had in order to split my sample that otherwise would have
been to big. The issue with this solution is that forest() displays
only the slap argument and the forest with the confidence interval,
completely ignoring the lab argument and the text I'm trying to add.
Moreover, the graph is showed correctly only within the zoom in
Rstudio but if I save it it is showed as enclosed.

What I'm doing wrong? I tried both to look at the package
documentation and online but I can't figure it out.

Moreover, how would you suggest to handle (graphically) the
multiple-cases-per-study thing? It's a 'good' way to average the cases
among different studies in the graphs?
In my meta-analysis I'm using a multilevel model as shown in
Gelman-Hill but graphically (and in tables) I'm struggling.

Thanks for your help and patience


From lists at dewey.myzen.co.uk  Mon Aug 24 16:46:50 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 24 Aug 2015 15:46:50 +0100
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
Message-ID: <55DB2E5A.6000900@dewey.myzen.co.uk>

Dear Marco

Comments inline

On 24/08/2015 15:03, Marco Colagrossi wrote:
> Hello folks,
>
> I have a couple of issues with the metafor package, specifically with
> the forest graphs.
> I am currently conducting a Meta-Analysis in economics throughout the
> metafor package.
>
> My meta-analysis has the specific of having different cases from
> single studies, and this proven to be challenging especially when
> trying to plot graphically the results I'm obtaining.
>
> Here's the code:
>
> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1, subset=(pub==1),
>         ilab = cbind(ys, f_dim, SIMdv, SIMiv),
>         ilab.xpos = c(-9.5, -8, -6, -4.5), cex = 0.75)

At this point I think you meant to close the call to forest with another 
) as the subsequent calls to text are further commands and not internal 
to the call of forest.

> par(font=2)
>        text(c(-9.5,-8,-6,-4.5), 26, c("Years", "Firm(s) Dimension", "DV", "IV"))
>        text(-16,                26, "Author(s) and Year",     pos=4)
>        text(6,                  26, "Observed Outcome [95% CI]", pos=2)
> par(op)

For that to have worked you probably meant to go
op <- par() somewhere earlier

>
> 'pc' is the 'effect size', 'var' the variance, 'ci95m & ci95p' the CI,
> 'pub' if the paper has been published or not. the pub subset was the
> first idea I had in order to split my sample that otherwise would have
> been to big. The issue with this solution is that forest() displays
> only the slap argument and the forest with the confidence interval,
> completely ignoring the lab argument and the text I'm trying to add.
> Moreover, the graph is showed correctly only within the zoom in
> Rstudio but if I save it it is showed as enclosed.
>

Sorry, do not use Rstudio myself

> What I'm doing wrong? I tried both to look at the package
> documentation and online but I can't figure it out.
>
> Moreover, how would you suggest to handle (graphically) the
> multiple-cases-per-study thing? It's a 'good' way to average the cases
> among different studies in the graphs?

Are you looking for rma.mv perhaps?

> In my meta-analysis I'm using a multilevel model as shown in
> Gelman-Hill but graphically (and in tables) I'm struggling.
>
> Thanks for your help and patience
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Aug 24 16:50:48 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 24 Aug 2015 16:50:48 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>

I cannot reproduce the issue with 'ilab' not being shown when using 'subset'. My guess is that the values for 'ilab.xpos' specified are actually outside of the plotting region. After you have drawn the forest plot, try:

par("usr")[1:2]

to see what the default limits actually are. Then use 'xlim' to adjust the limits to your taste. And then use appropriate values for 'ilab.xpos', so they are inside those limits.

> Moreover, the graph is showed correctly only within the zoom in
> Rstudio but if I save it it is showed as enclosed.

Nothing was enclosed (or it was stripped).

> Moreover, how would you suggest to handle (graphically) the
> multiple-cases-per-study thing? It's a 'good' way to average the cases
> among different studies in the graphs?

Maybe add some space between groupings (i.e., studies). The example given here can provide some clues how one could go about this: http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups But drawing a plot like this requires a lot of hand-tweaking.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marco
> Colagrossi
> Sent: Monday, August 24, 2015 16:04
> To: r-help at r-project.org
> Subject: [R] Metafor and forest(); not showing 'ilab' and text
> 
> Hello folks,
> 
> I have a couple of issues with the metafor package, specifically with
> the forest graphs.
> I am currently conducting a Meta-Analysis in economics throughout the
> metafor package.
> 
> My meta-analysis has the specific of having different cases from
> single studies, and this proven to be challenging especially when
> trying to plot graphically the results I'm obtaining.
> 
> Here's the code:
> 
> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
> subset=(pub==1),
>        ilab = cbind(ys, f_dim, SIMdv, SIMiv),
>        ilab.xpos = c(-9.5, -8, -6, -4.5), cex = 0.75)
> par(font=2)
>       text(c(-9.5,-8,-6,-4.5), 26, c("Years", "Firm(s) Dimension", "DV",
> "IV"))
>       text(-16,                26, "Author(s) and Year",     pos=4)
>       text(6,                  26, "Observed Outcome [95% CI]", pos=2)
> par(op)
> 
> 'pc' is the 'effect size', 'var' the variance, 'ci95m & ci95p' the CI,
> 'pub' if the paper has been published or not. the pub subset was the
> first idea I had in order to split my sample that otherwise would have
> been to big. The issue with this solution is that forest() displays
> only the slap argument and the forest with the confidence interval,
> completely ignoring the lab argument and the text I'm trying to add.
> Moreover, the graph is showed correctly only within the zoom in
> Rstudio but if I save it it is showed as enclosed.
> 
> What I'm doing wrong? I tried both to look at the package
> documentation and online but I can't figure it out.
> 
> Moreover, how would you suggest to handle (graphically) the
> multiple-cases-per-study thing? It's a 'good' way to average the cases
> among different studies in the graphs?
> In my meta-analysis I'm using a multilevel model as shown in
> Gelman-Hill but graphically (and in tables) I'm struggling.
> 
> Thanks for your help and patience
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Aug 24 17:30:53 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 24 Aug 2015 15:30:53 +0000
Subject: [R] Multrix-vector multiplication
In-Reply-To: <CAKTtY6SvyHDrGxC7a5KV4KPWVv8-Y41SvoKwJ90W3LPhJKpvsA@mail.gmail.com>
References: <CAKTtY6SvyHDrGxC7a5KV4KPWVv8-Y41SvoKwJ90W3LPhJKpvsA@mail.gmail.com>
Message-ID: <D20084E0.136328%macqueen1@llnl.gov>

I would suggest you look into the Matrix package.

Here's an example that illustrates what I suspect is the root cause of
your issue:

> x <- matrix(1:4, ncol=2)
> class(x)
[1] "matrix"
> y1 <- x[,1]
> class(y1)
[1] "integer"
> y1
[1] 1 2
> y2 <- x[,1,drop=FALSE]
> class(y2)
[1] "matrix"
> y2
     [,1]
[1,]    1
[2,]    2


> as.matrix(y1)
     [,1]
[1,]    1
[2,]    2





If you assign your objects the "Matrix" class as defined in that package,
then perhaps your 'a' will be a matrix after your step 1. (I have not
tried to verify this)


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/22/15, 6:43 AM, "R-help on behalf of Steven Yen"
<r-help-bounces at r-project.org on behalf of syen04 at gmail.com> wrote:

>I had trouble with matrix multiplication when a matrix reduces to a
>vector.  In the following, lines 1 and 2 work when matrices u and a are
>both of order 2.
>Lines 3 and 5 do not work (message is matrix not conformable) when u is (T
>x 1) and a is (1 x 2) and This causes a problem for users of other matrix
>languages such as Gauss and MATLAB.
>Inserting line 4 makes it work, which is annoying. But, is it proper/safe
>to make it work by inserting line 4? Other approaches?
>Thank you!
>
>1 a<-solve(s22)%*%s21 # (2 x 2) <- (2 x 2) %*% (2 x 2)
>2 uc<-u%*%v$a         # (T x 2) <- (T x 2) %*% (2 x 2)
>
>3 a<-solve(s22)%*%s21 # (1 x 2) <- (1 x 1) %*% (1 x 2)
>4 a<-as.matrix(a)     # This line makes it work. OK? Other approaches?
>5 uc<-u%*%v$a         # (T x 1) %*% (1 x 2)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Mon Aug 24 17:55:28 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 24 Aug 2015 17:55:28 +0200
Subject: [R] Understand Rcode- subset
In-Reply-To: <BAY179-W44CE818EFF1B32A8D8E3AEBE620@phx.gbl>
References: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>
	<CAJuCY5xCQG28rXqz_PVqYUm6FHKi_zt8noAZcHefWpO6TXZfUA@mail.gmail.com>
	<BAY179-W44CE818EFF1B32A8D8E3AEBE620@phx.gbl>
Message-ID: <CAJuCY5xX_u1EmQyd8HwBbrztxnbQpfbOPp8HhT0NXEs2kfqXZw@mail.gmail.com>

# logical vector, TRUE when record_type equals 1
id <- transact$record_type == 1
# lagged vector of id. TRUE is shifted one position ahead
id.lag <- c(id[2:length(id)], FALSE)
sub <- transact[id.lag, ]
# have a look at the row numbers
transact[id, ]
sub

Best regards,
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-08-24 17:32 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
> Hi!
>
> Thanks for pointing out the mistake.
>
> I am resubmitting my question as follows:
>
> Hi!
> I am facing a problem in understanding the R-Code
> Suppose I have a transactional dataset named- "transact" with its values
> like following:
> customer_ID
> <-c(10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000005,10000005,10000005,10000005,10000005,10000005,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000013,10000013)
> shopping_pt <- c(1,2,2,3,4,5,6,7,8,9,1,2,3,4,5,6,1,2,3,4,5,6,7,8,1,2)
> record_type <- c(0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0)
> transact <- data.frame(customer_ID, shopping_pt, record_type)
>
> How does the following code work
> id<-transact$record_type==1
> sub<-transact[c(id[2:length(id)],FALSE),]
> id<-c(id[3:length(id)],FALSE,FALSE)
> sub2<-transact[id,]
> Thanks in advance!
>
>> Date: Mon, 24 Aug 2015 15:25:09 +0200
>> Subject: Re: [R] Understand Rcode- subset
>> From: thierry.onkelinx at inbo.be
>> To: butt_its_me at hotmail.com
>> CC: r-help at r-project.org
>
>>
>> Posting in HTML mangles up your code, making it hard to read. Please
>> resend your question in plain text and make the code reproducible. See
>> http://adv-r.had.co.nz/Reproducibility.html for more details on that.
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2015-08-24 13:00 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
>> > Hi!
>> > I am facing a problem in understanding the R-Code
>> > Suppose I have a dataset named- transact with its values like following:
>> >
>> >
>> >
>> >
>> >
>> > customer_ID
>> > shopping_pt
>> > record_type
>> >
>> >
>> > 10000000
>> > 1
>> > 0
>> >
>> >
>> > 10000000
>> > 2
>> > 0
>> >
>> >
>> > 10000000
>> > 3
>> > 0
>> >
>> >
>> > 10000000
>> > 4
>> > 0
>> >
>> >
>> > 10000000
>> > 5
>> > 0
>> >
>> >
>> > 10000000
>> > 6
>> > 0
>> >
>> >
>> > 10000000
>> > 7
>> > 0
>> >
>> >
>> > 10000000
>> > 8
>> > 0
>> >
>> >
>> > 10000000
>> > 9
>> > 1
>> >
>> >
>> > 10000005
>> > 1
>> > 0
>> >
>> >
>> > 10000005
>> > 2
>> > 0
>> >
>> >
>> > 10000005
>> > 3
>> > 0
>> >
>> >
>> > 10000005
>> > 4
>> > 0
>> >
>> >
>> > 10000005
>> > 5
>> > 0
>> >
>> >
>> > 10000005
>> > 6
>> > 1
>> >
>> >
>> > 10000007
>> > 1
>> > 0
>> >
>> >
>> > 10000007
>> > 2
>> > 0
>> >
>> >
>> > 10000007
>> > 3
>> > 0
>> >
>> >
>> > 10000007
>> > 4
>> > 0
>> >
>> > How does the following code work and the results of sub and id-
>> >
>> > id<-transact$record_type==1sub<-train[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE)
>> > sub2<-train[id,]
>> > Thanks in advance!
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Mon Aug 24 17:59:56 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 24 Aug 2015 07:59:56 -0800
Subject: [R] Understand Rcode- subset
In-Reply-To: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>
Message-ID: <C5A000640A8.000004DFjrkrideau@inbox.com>

Just to second Thierry's point, your HTML post is basically unreadable.

Please repost as plain text.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: butt_its_me at hotmail.com
> Sent: Mon, 24 Aug 2015 16:30:31 +0530
> To: r-help at r-project.org
> Subject: [R] Understand Rcode- subset
> 
> Hi!
> I am facing a problem in understanding the R-Code
> Suppose I have a dataset named- transact with its values like following:
> 
> 
> 
> 
> 
>   customer_ID
>   shopping_pt
>   record_type
> 
> 
>   10000000
>   1
>   0
> 
> 
>   10000000
>   2
>   0
> 
> 
>   10000000
>   3
>   0
> 
> 
>   10000000
>   4
>   0
> 
> 
>   10000000
>   5
>   0
> 
> 
>   10000000
>   6
>   0
> 
> 
>   10000000
>   7
>   0
> 
> 
>   10000000
>   8
>   0
> 
> 
>   10000000
>   9
>   1
> 
> 
>   10000005
>   1
>   0
> 
> 
>   10000005
>   2
>   0
> 
> 
>   10000005
>   3
>   0
> 
> 
>   10000005
>   4
>   0
> 
> 
>   10000005
>   5
>   0
> 
> 
>   10000005
>   6
>   1
> 
> 
>   10000007
>   1
>   0
> 
> 
>   10000007
>   2
>   0
> 
> 
>   10000007
>   3
>   0
> 
> 
>   10000007
>   4
>   0
> 
> How does the following code work and the results of sub and id-
id<-transact$record_type==1sub<-train[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE)
> sub2<-train[id,]
> Thanks in advance!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From dwinsemius at comcast.net  Mon Aug 24 18:10:54 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 24 Aug 2015 09:10:54 -0700
Subject: [R] Calculate the area under a curve
In-Reply-To: <9FE05A8E-B84F-4D12-913E-F7F4BBE0B0D6@dcn.davis.CA.us>
References: <1440407411144-4711418.post@n4.nabble.com>
	<9FE05A8E-B84F-4D12-913E-F7F4BBE0B0D6@dcn.davis.CA.us>
Message-ID: <5995636C-CD47-41DB-B840-73075F7C069A@comcast.net>


On Aug 24, 2015, at 7:23 AM, Jeff Newmiller wrote:

> Read ?predict, paying particular attention to the newdata argument.

I agree that reading help pages is needed but need both the ?predict page and the ?integrate page. I think proximate cause of the error is that `integrate` is not getting an integrand that is a function of "x" so that it can receive a sequence of x-values and return a sequence of y-values. The interpreter is complaining because it's not getting a proper function.

I suppose one could do that with predict, but you need to build that function to accept a single value as the newdata 'x'-argument. One would, of course, need to have the model name in the integrand function matching the name of the lm-object, which at the moment is also a further error waiting to be uncovered.

Decided to avoid creating extraneous objects and assume that the data is in the form of a dataframe named 'inp':

 fitP <- lm( SOC~poly(Depth,3), data=inp )   # It's better to use correct column names with a data-argument
 integrand <-function(x) predict(fitP, newdata= list(Depth=x))  # single value of x passed to correct name of column, see ?predict
 integrate(integrand, lower = 25, upper = 80)
# 7.43651 with absolute error < 8.3e-14


> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On August 24, 2015 2:10:11 AM PDT, CarstenH <cahoff at gmx.de> wrote:
>> Hi all
>> 
>> I need to calculate the area under a curve (integral) for the following
>> data
>> pairs:
>> 
>> Depth SOC	
>> 22.5	0.143
>> 28.5 	0.165	
>> 34.5	0.131	
>> 37.5	0.134	
>> 40.5	0.138	
>> 43.5 	0.107	
>> 46.5	0.132
>> 49.5 	0.175 
>> 52.5	0.087	
>> 55.5 	0.117	
>> 58.5	0.126	
>> 61.5 	0.13	
>> 64.5	0.122	
>> 67.5 	0.161	
>> 71.5	0.144	
>> 76.5 	0.146	
>> 82.5	0.156	
>> 94.5	0.132	
>> 
>> (Table name is P)
>> 
>> After reading the data set I assiged the collumns by:
>> 
>> /x <- (P$Depth)
>> y <- (P$SOC)
>> /
>> 
>> and decided to make a ploynominal function (3rd order):
>> 
>> /fitP <- lm( y~poly(x,3,raw=TRUE) )/
>> 
>> At the next step I failed. I can plot point and function but am not
>> able to
>> integrate the curve between e.g. depths 20 and 80.
>> 
>> If I try:
>> /
>> integrand <-function(fitP1)
>> predict(y)
>> integrate(integrand, lower = 25, upper = 80)/
>> 
>> the "Conosle" opend with the message: "Source unavailable or out of
>> sync"
>> and
>> /
>> function(fitP1)
>> predict(y)
>> /
>> )
>> 
>> 
>> Would be great if somebody could help!
>> 
>> Thanks
>> 
>> Carsten
>> 
>> 
>> 
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Calculate-the-area-under-a-curve-tp4711418.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From cahoff at gmx.de  Mon Aug 24 16:38:40 2015
From: cahoff at gmx.de (CarstenH)
Date: Mon, 24 Aug 2015 07:38:40 -0700 (PDT)
Subject: [R] Calculate the area under a curve
In-Reply-To: <CAKxd1KOZrtGFSY7o8sS4yLqMA4egRMhzfwpsxrTr+e4UnRyX5Q@mail.gmail.com>
References: <1440407411144-4711418.post@n4.nabble.com>
	<CAKxd1KOZrtGFSY7o8sS4yLqMA4egRMhzfwpsxrTr+e4UnRyX5Q@mail.gmail.com>
Message-ID: <1440427120427-4711434.post@n4.nabble.com>

Hi Charles

I am new in R and would like to learn/use it in the beginning for easy
operations. I already used google for houres and did not find a solution for
this in my eyes easy calculation process. I spent long time with reading
forums, package handbooks, and tried and error but always failed. But I
still believe that somebody could tell me something like: Load package XY
and than use that command Z... 

Sorry if I am naive or half-baked but I guess there shout be a very easy
command to calculate the area under a function.


E.g. If I use the package AUC: 

auc(fitP, min=20, max=100)
there is an error report which I do not understand: 
/Error in auc(fitP1, min = 20, max = 100) : object 'ans' not found.
/

My task in short: 

I have 20 x and associated 20 y values and created a function by

fitP <- lm( y~poly(x,3,raw=TRUE) )

the function looks like this: 

fitP

/Call:
lm(formula = y2 ~ poly(x2, 3, raw = TRUE))


Coefficients:
             (Intercept)  poly(x2, 3, raw = TRUE)1  
               1.125e+01                -5.262e-01  
poly(x2, 3, raw = TRUE)2  poly(x2, 3, raw = TRUE)3  
               9.156e-03                -4.771e-05  

/

The last step now is to integrate the function. If I put this data by hand
in any of many AUC-calculators in the web it works. But I still not find the
"easy" way within R.






--
View this message in context: http://r.789695.n4.nabble.com/Calculate-the-area-under-a-curve-tp4711418p4711434.html
Sent from the R help mailing list archive at Nabble.com.


From butt_its_me at hotmail.com  Mon Aug 24 17:32:58 2015
From: butt_its_me at hotmail.com (Jhon Grey)
Date: Mon, 24 Aug 2015 21:02:58 +0530
Subject: [R] Understand Rcode- subset
In-Reply-To: <CAJuCY5xCQG28rXqz_PVqYUm6FHKi_zt8noAZcHefWpO6TXZfUA@mail.gmail.com>
References: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>,
	<CAJuCY5xCQG28rXqz_PVqYUm6FHKi_zt8noAZcHefWpO6TXZfUA@mail.gmail.com>
Message-ID: <BAY179-W44CE818EFF1B32A8D8E3AEBE620@phx.gbl>

Hi!
Thanks for pointing out the mistake.
I am resubmitting my question as follows:
Hi!I am facing a problem in understanding the R-CodeSuppose I have a transactional dataset named- "transact" with its values like following:customer_ID <-c(10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000005,10000005,10000005,10000005,10000005,10000005,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000013,10000013)shopping_pt <- c(1,2,2,3,4,5,6,7,8,9,1,2,3,4,5,6,1,2,3,4,5,6,7,8,1,2)record_type <- c(0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0)transact <- data.frame(customer_ID, shopping_pt, record_type)
How does the following code work id<-transact$record_type==1sub<-transact[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE) sub2<-transact[id,]Thanks in advance!
> Date: Mon, 24 Aug 2015 15:25:09 +0200
> Subject: Re: [R] Understand Rcode- subset
> From: thierry.onkelinx at inbo.be
> To: butt_its_me at hotmail.com
> CC: r-help at r-project.org
> 
> Posting in HTML mangles up your code, making it hard to read. Please
> resend your question in plain text and make the code reproducible. See
> http://adv-r.had.co.nz/Reproducibility.html for more details on that.
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> 
> 
> 2015-08-24 13:00 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
> > Hi!
> > I am facing a problem in understanding the R-Code
> > Suppose I have a dataset named- transact with its values like following:
> >
> >
> >
> >
> >
> >   customer_ID
> >   shopping_pt
> >   record_type
> >
> >
> >   10000000
> >   1
> >   0
> >
> >
> >   10000000
> >   2
> >   0
> >
> >
> >   10000000
> >   3
> >   0
> >
> >
> >   10000000
> >   4
> >   0
> >
> >
> >   10000000
> >   5
> >   0
> >
> >
> >   10000000
> >   6
> >   0
> >
> >
> >   10000000
> >   7
> >   0
> >
> >
> >   10000000
> >   8
> >   0
> >
> >
> >   10000000
> >   9
> >   1
> >
> >
> >   10000005
> >   1
> >   0
> >
> >
> >   10000005
> >   2
> >   0
> >
> >
> >   10000005
> >   3
> >   0
> >
> >
> >   10000005
> >   4
> >   0
> >
> >
> >   10000005
> >   5
> >   0
> >
> >
> >   10000005
> >   6
> >   1
> >
> >
> >   10000007
> >   1
> >   0
> >
> >
> >   10000007
> >   2
> >   0
> >
> >
> >   10000007
> >   3
> >   0
> >
> >
> >   10000007
> >   4
> >   0
> >
> > How does the following code work and the results of sub and id-
> > id<-transact$record_type==1sub<-train[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE) sub2<-train[id,]
> > Thanks in advance!
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From butt_its_me at hotmail.com  Mon Aug 24 18:29:41 2015
From: butt_its_me at hotmail.com (Jhon Grey)
Date: Mon, 24 Aug 2015 21:59:41 +0530
Subject: [R] Understand Rcode- subset
In-Reply-To: <CAJuCY5xX_u1EmQyd8HwBbrztxnbQpfbOPp8HhT0NXEs2kfqXZw@mail.gmail.com>
References: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>,
	<CAJuCY5xCQG28rXqz_PVqYUm6FHKi_zt8noAZcHefWpO6TXZfUA@mail.gmail.com>,
	<BAY179-W44CE818EFF1B32A8D8E3AEBE620@phx.gbl>,
	<CAJuCY5xX_u1EmQyd8HwBbrztxnbQpfbOPp8HhT0NXEs2kfqXZw@mail.gmail.com>
Message-ID: <BAY179-W8519E1569279DA75C6ACDCBE620@phx.gbl>

Can you please explain elaborately! I understood that TRUE has been shifted ahead. But unfortunately did not understand the code- as how using logical vector it was shifted ? # lagged vector of id. TRUE is shifted one position aheadid.lag <- c(id[2:length(id)], FALSE)It shifted ahead twice using the code-id.lag <- c(id[3:length(id)], FALSE,FALSE)
Thanking you again for your prompt response!
> Date: Mon, 24 Aug 2015 17:55:28 +0200
> Subject: Re: [R] Understand Rcode- subset
> From: thierry.onkelinx at inbo.be
> To: butt_its_me at hotmail.com
> CC: r-help at r-project.org
> 
> # logical vector, TRUE when record_type equals 1
> id <- transact$record_type == 1
> # lagged vector of id. TRUE is shifted one position ahead
> id.lag <- c(id[2:length(id)], FALSE)
> sub <- transact[id.lag, ]
> # have a look at the row numbers
> transact[id, ]
> sub
> 
> Best regards,
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> 
> 
> 2015-08-24 17:32 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
> > Hi!
> >
> > Thanks for pointing out the mistake.
> >
> > I am resubmitting my question as follows:
> >
> > Hi!
> > I am facing a problem in understanding the R-Code
> > Suppose I have a transactional dataset named- "transact" with its values
> > like following:
> > customer_ID
> > <-c(10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000005,10000005,10000005,10000005,10000005,10000005,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000013,10000013)
> > shopping_pt <- c(1,2,2,3,4,5,6,7,8,9,1,2,3,4,5,6,1,2,3,4,5,6,7,8,1,2)
> > record_type <- c(0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0)
> > transact <- data.frame(customer_ID, shopping_pt, record_type)
> >
> > How does the following code work
> > id<-transact$record_type==1
> > sub<-transact[c(id[2:length(id)],FALSE),]
> > id<-c(id[3:length(id)],FALSE,FALSE)
> > sub2<-transact[id,]
> > Thanks in advance!
> >
> >> Date: Mon, 24 Aug 2015 15:25:09 +0200
> >> Subject: Re: [R] Understand Rcode- subset
> >> From: thierry.onkelinx at inbo.be
> >> To: butt_its_me at hotmail.com
> >> CC: r-help at r-project.org
> >
> >>
> >> Posting in HTML mangles up your code, making it hard to read. Please
> >> resend your question in plain text and make the code reproducible. See
> >> http://adv-r.had.co.nz/Reproducibility.html for more details on that.
> >> ir. Thierry Onkelinx
> >> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> >> and Forest
> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> >> Kliniekstraat 25
> >> 1070 Anderlecht
> >> Belgium
> >>
> >> To call in the statistician after the experiment is done may be no
> >> more than asking him to perform a post-mortem examination: he may be
> >> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does
> >> not ensure that a reasonable answer can be extracted from a given body
> >> of data. ~ John Tukey
> >>
> >>
> >> 2015-08-24 13:00 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
> >> > Hi!
> >> > I am facing a problem in understanding the R-Code
> >> > Suppose I have a dataset named- transact with its values like following:
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > customer_ID
> >> > shopping_pt
> >> > record_type
> >> >
> >> >
> >> > 10000000
> >> > 1
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 2
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 3
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 4
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 5
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 6
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 7
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 8
> >> > 0
> >> >
> >> >
> >> > 10000000
> >> > 9
> >> > 1
> >> >
> >> >
> >> > 10000005
> >> > 1
> >> > 0
> >> >
> >> >
> >> > 10000005
> >> > 2
> >> > 0
> >> >
> >> >
> >> > 10000005
> >> > 3
> >> > 0
> >> >
> >> >
> >> > 10000005
> >> > 4
> >> > 0
> >> >
> >> >
> >> > 10000005
> >> > 5
> >> > 0
> >> >
> >> >
> >> > 10000005
> >> > 6
> >> > 1
> >> >
> >> >
> >> > 10000007
> >> > 1
> >> > 0
> >> >
> >> >
> >> > 10000007
> >> > 2
> >> > 0
> >> >
> >> >
> >> > 10000007
> >> > 3
> >> > 0
> >> >
> >> >
> >> > 10000007
> >> > 4
> >> > 0
> >> >
> >> > How does the following code work and the results of sub and id-
> >> >
> >> > id<-transact$record_type==1sub<-train[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE)
> >> > sub2<-train[id,]
> >> > Thanks in advance!
> >> >
> >> > [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
 		 	   		  
	[[alternative HTML version deleted]]


From 538280 at gmail.com  Mon Aug 24 19:31:07 2015
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 24 Aug 2015 11:31:07 -0600
Subject: [R] plotting over a raster image with control over location and
	orientation
In-Reply-To: <2048639744.8977490.1440167432929.JavaMail.yahoo@mail.yahoo.com>
References: <2048639744.8977490.1440167432929.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAFEqCdzHQLZZ8kxpmSOVio-KweqkVxyR2bxng9Nowf9-omz=ow@mail.gmail.com>

For base plotting functions (not grid) then you may be interested in
the updateusr function in the TeachingDemos package.  If you can find
the current coordinates of 2 points on the 1st plot (the background
image) that are not in the same horizontal or vertical line (use the
locator function if nothing else) and you know what you would like the
coordinates of the 2 points to be, then you just call updateusr with
the current coordinates and the desired coordinates and it resets them
for you so that you can add to the current plot with lines or other
low level functions.

On Fri, Aug 21, 2015 at 8:30 AM, ravi <rv15i at yahoo.se> wrote:
> Hi,I would like to get some help in plotting over an image. I have a png image over which I would like to have a plot. I would like to be able to control the location, area and orientation of the plot on the image.
> I have taken help from the following references :http://journal.r-project.org/archive/2011-1/RJournal_2011-1_Murrell.pdfhttp://stackoverflow.com/questions/12918367/in-r-how-to-plot-with-a-png-as-background
> In order to give a reproducible example, I set up my image with the help of some code from the the first reference above.
>
> #Setting up the initial example raster image
> x <- y <- seq(-4*pi, 4*pi, len=27)
> r <- sqrt(outer(x^2, y^2, "+"))
> z <- cos(r^2)*exp(-r/6)
> image <- (z - min(z))/diff(range(z))
> step <- diff(x)[1]
> xrange <- range(x) + c(-step/2, step/2)
> yrange <- range(y) + c(-step/2, step/2)
> plot(x, y, ann=FALSE,xlim=xrange, ylim=yrange,xaxs="i", yaxs="i")
> rasterImage(image,xrange[1], yrange[1],xrange[2], yrange[2],interpolate=FALSE)
>
> # the explanation of my problem starts here
> # First, I want to mark out a particular line
> lines(c(10,10.5),c(-10.5,10),col="red",lwd=2)
> #In my problem, I have to locate these points graphically from the image
> calpoints <- locator(n=2,type='p',pch=4,col='blue',lwd=2)
> # this gives the line corresponding to the x-axis for my overlay plot
> # I don't want the red line on my plot
> #the red line plotted earlier is just to show the example location
> newOrigin<-calpoints[1]
> xLimit<-calpoints[2]#xlimit marks the limit of the x-axis on the image# on this new line as the x-axis, I want to make a new plot# the y-axis should be perpendicular to the x-axis. I would like to be able to specify the width of coverage over the image#example
> xx<-1:10
> yy<-xx^2
> plot(xx,yy,xlim=range(xx),ylim=range(yy),col="blue",type="b",xlab="x",ylab="square of x")
> # I would prefer to have the image more transparent just under the x and y labels and axis labelsThanks, Ravi
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From wdunlap at tibco.com  Mon Aug 24 19:32:38 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 24 Aug 2015 10:32:38 -0700
Subject: [R] Calculate the area under a curve
In-Reply-To: <1440427120427-4711434.post@n4.nabble.com>
References: <1440407411144-4711418.post@n4.nabble.com>
	<CAKxd1KOZrtGFSY7o8sS4yLqMA4egRMhzfwpsxrTr+e4UnRyX5Q@mail.gmail.com>
	<1440427120427-4711434.post@n4.nabble.com>
Message-ID: <CAF8bMcYWWadrZ+XZYTxbA7yOJ+cGUV4NY+9ep3sn-vdjaUwoag@mail.gmail.com>

This is partly a bug in the AUC package and partly a problem
with you not reading or understanding the the help file for the
auc function in that package.  help(auc) says

         auc(x, min = 0, max = 1)

  Arguments:

         x: an object produced by one of the functions ?sensitivity?,
            ?specificity?, ?accuracy?, or ?roc?

and you give the output of lm(), not the output of one of the
functions listed there.

The auc() function should give a clear error message when
class(x) is not one of the expected classes.

When you encounter a problem in a user-contributed package
you should report it to the 'maintainer' of the package so the package
may be improved
   > maintainer("AUC")
   [1] "Michel Ballings <Michel.Ballings at UGent.be>"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 24, 2015 at 7:38 AM, CarstenH <cahoff at gmx.de> wrote:

> Hi Charles
>
> I am new in R and would like to learn/use it in the beginning for easy
> operations. I already used google for houres and did not find a solution
> for
> this in my eyes easy calculation process. I spent long time with reading
> forums, package handbooks, and tried and error but always failed. But I
> still believe that somebody could tell me something like: Load package XY
> and than use that command Z...
>
> Sorry if I am naive or half-baked but I guess there shout be a very easy
> command to calculate the area under a function.
>
>
> E.g. If I use the package AUC:
>
> auc(fitP, min=20, max=100)
> there is an error report which I do not understand:
> /Error in auc(fitP1, min = 20, max = 100) : object 'ans' not found.
> /
>
> My task in short:
>
> I have 20 x and associated 20 y values and created a function by
>
> fitP <- lm( y~poly(x,3,raw=TRUE) )
>
> the function looks like this:
>
> fitP
>
> /Call:
> lm(formula = y2 ~ poly(x2, 3, raw = TRUE))
>
>
> Coefficients:
>              (Intercept)  poly(x2, 3, raw = TRUE)1
>                1.125e+01                -5.262e-01
> poly(x2, 3, raw = TRUE)2  poly(x2, 3, raw = TRUE)3
>                9.156e-03                -4.771e-05
>
> /
>
> The last step now is to integrate the function. If I put this data by hand
> in any of many AUC-calculators in the web it works. But I still not find
> the
> "easy" way within R.
>
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Calculate-the-area-under-a-curve-tp4711418p4711434.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Mon Aug 24 19:42:29 2015
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 24 Aug 2015 11:42:29 -0600
Subject: [R] Calculate the area under a curve
In-Reply-To: <1440407411144-4711418.post@n4.nabble.com>
References: <1440407411144-4711418.post@n4.nabble.com>
Message-ID: <CAFEqCdzq5df1guWdBqt1Uncz=VFSYmw_LSosG-THbDVwPQamEQ@mail.gmail.com>

An alternative to your approach is to pass your data to the approxfun
or splinefun functions and then use the integrate function on the
result.

On Mon, Aug 24, 2015 at 3:10 AM, CarstenH <cahoff at gmx.de> wrote:
> Hi all
>
> I need to calculate the area under a curve (integral) for the following data
> pairs:
>
> Depth SOC
> 22.5    0.143
> 28.5    0.165
> 34.5    0.131
> 37.5    0.134
> 40.5    0.138
> 43.5    0.107
> 46.5    0.132
> 49.5    0.175
> 52.5    0.087
> 55.5    0.117
> 58.5    0.126
> 61.5    0.13
> 64.5    0.122
> 67.5    0.161
> 71.5    0.144
> 76.5    0.146
> 82.5    0.156
> 94.5    0.132
>
> (Table name is P)
>
> After reading the data set I assiged the collumns by:
>
> /x <- (P$Depth)
> y <- (P$SOC)
> /
>
> and decided to make a ploynominal function (3rd order):
>
> /fitP <- lm( y~poly(x,3,raw=TRUE) )/
>
> At the next step I failed. I can plot point and function but am not able to
> integrate the curve between e.g. depths 20 and 80.
>
> If I try:
> /
> integrand <-function(fitP1)
>   predict(y)
> integrate(integrand, lower = 25, upper = 80)/
>
> the "Conosle" opend with the message: "Source unavailable or out of sync"
> and
> /
> function(fitP1)
> predict(y)
> /
> )
>
>
> Would be great if somebody could help!
>
> Thanks
>
> Carsten
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Calculate-the-area-under-a-curve-tp4711418.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jdnewmil at dcn.davis.CA.us  Mon Aug 24 19:42:46 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 24 Aug 2015 10:42:46 -0700
Subject: [R] Understand Rcode- subset
In-Reply-To: <BAY179-W8519E1569279DA75C6ACDCBE620@phx.gbl>
References: <BAY179-W47BF839B60B4654931D12EBE620@phx.gbl>,
	<CAJuCY5xCQG28rXqz_PVqYUm6FHKi_zt8noAZcHefWpO6TXZfUA@mail.gmail.com>,
	<BAY179-W44CE818EFF1B32A8D8E3AEBE620@phx.gbl>,
	<CAJuCY5xX_u1EmQyd8HwBbrztxnbQpfbOPp8HhT0NXEs2kfqXZw@mail.gmail.com>
	<BAY179-W8519E1569279DA75C6ACDCBE620@phx.gbl>
Message-ID: <58934B54-EC40-46A7-BA42-B0586ADBB49F@dcn.davis.CA.us>

The first id was ignored (d[2:length(id)]) and the last id in id.lag was set to FALSE. Because the values are in new positions even though the same number of id values are kept, a lag (shift) has been created that takes effect when id.lag is used as an index into transact.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 24, 2015 9:29:41 AM PDT, Jhon Grey <butt_its_me at hotmail.com> wrote:
>Can you please explain elaborately! I understood that TRUE has been
>shifted ahead. But unfortunately did not understand the code- as how
>using logical vector it was shifted ? # lagged vector of id. TRUE is
>shifted one position aheadid.lag <- c(id[2:length(id)], FALSE)It
>shifted ahead twice using the code-id.lag <- c(id[3:length(id)],
>FALSE,FALSE)
>Thanking you again for your prompt response!
>> Date: Mon, 24 Aug 2015 17:55:28 +0200
>> Subject: Re: [R] Understand Rcode- subset
>> From: thierry.onkelinx at inbo.be
>> To: butt_its_me at hotmail.com
>> CC: r-help at r-project.org
>> 
>> # logical vector, TRUE when record_type equals 1
>> id <- transact$record_type == 1
>> # lagged vector of id. TRUE is shifted one position ahead
>> id.lag <- c(id[2:length(id)], FALSE)
>> sub <- transact[id.lag, ]
>> # have a look at the row numbers
>> transact[id, ]
>> sub
>> 
>> Best regards,
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for
>Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>> 
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given
>body
>> of data. ~ John Tukey
>> 
>> 
>> 2015-08-24 17:32 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
>> > Hi!
>> >
>> > Thanks for pointing out the mistake.
>> >
>> > I am resubmitting my question as follows:
>> >
>> > Hi!
>> > I am facing a problem in understanding the R-Code
>> > Suppose I have a transactional dataset named- "transact" with its
>values
>> > like following:
>> > customer_ID
>> >
><-c(10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000000,10000005,10000005,10000005,10000005,10000005,10000005,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000007,10000013,10000013)
>> > shopping_pt <-
>c(1,2,2,3,4,5,6,7,8,9,1,2,3,4,5,6,1,2,3,4,5,6,7,8,1,2)
>> > record_type <-
>c(0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0)
>> > transact <- data.frame(customer_ID, shopping_pt, record_type)
>> >
>> > How does the following code work
>> > id<-transact$record_type==1
>> > sub<-transact[c(id[2:length(id)],FALSE),]
>> > id<-c(id[3:length(id)],FALSE,FALSE)
>> > sub2<-transact[id,]
>> > Thanks in advance!
>> >
>> >> Date: Mon, 24 Aug 2015 15:25:09 +0200
>> >> Subject: Re: [R] Understand Rcode- subset
>> >> From: thierry.onkelinx at inbo.be
>> >> To: butt_its_me at hotmail.com
>> >> CC: r-help at r-project.org
>> >
>> >>
>> >> Posting in HTML mangles up your code, making it hard to read.
>Please
>> >> resend your question in plain text and make the code reproducible.
>See
>> >> http://adv-r.had.co.nz/Reproducibility.html for more details on
>that.
>> >> ir. Thierry Onkelinx
>> >> Instituut voor natuur- en bosonderzoek / Research Institute for
>Nature
>> >> and Forest
>> >> team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>Assurance
>> >> Kliniekstraat 25
>> >> 1070 Anderlecht
>> >> Belgium
>> >>
>> >> To call in the statistician after the experiment is done may be no
>> >> more than asking him to perform a post-mortem examination: he may
>be
>> >> able to say what the experiment died of. ~ Sir Ronald Aylmer
>Fisher
>> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> The combination of some data and an aching desire for an answer
>does
>> >> not ensure that a reasonable answer can be extracted from a given
>body
>> >> of data. ~ John Tukey
>> >>
>> >>
>> >> 2015-08-24 13:00 GMT+02:00 Jhon Grey <butt_its_me at hotmail.com>:
>> >> > Hi!
>> >> > I am facing a problem in understanding the R-Code
>> >> > Suppose I have a dataset named- transact with its values like
>following:
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > customer_ID
>> >> > shopping_pt
>> >> > record_type
>> >> >
>> >> >
>> >> > 10000000
>> >> > 1
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 2
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 3
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 4
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 5
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 6
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 7
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 8
>> >> > 0
>> >> >
>> >> >
>> >> > 10000000
>> >> > 9
>> >> > 1
>> >> >
>> >> >
>> >> > 10000005
>> >> > 1
>> >> > 0
>> >> >
>> >> >
>> >> > 10000005
>> >> > 2
>> >> > 0
>> >> >
>> >> >
>> >> > 10000005
>> >> > 3
>> >> > 0
>> >> >
>> >> >
>> >> > 10000005
>> >> > 4
>> >> > 0
>> >> >
>> >> >
>> >> > 10000005
>> >> > 5
>> >> > 0
>> >> >
>> >> >
>> >> > 10000005
>> >> > 6
>> >> > 1
>> >> >
>> >> >
>> >> > 10000007
>> >> > 1
>> >> > 0
>> >> >
>> >> >
>> >> > 10000007
>> >> > 2
>> >> > 0
>> >> >
>> >> >
>> >> > 10000007
>> >> > 3
>> >> > 0
>> >> >
>> >> >
>> >> > 10000007
>> >> > 4
>> >> > 0
>> >> >
>> >> > How does the following code work and the results of sub and id-
>> >> >
>> >> >
>id<-transact$record_type==1sub<-train[c(id[2:length(id)],FALSE),]id<-c(id[3:length(id)],FALSE,FALSE)
>> >> > sub2<-train[id,]
>> >> > Thanks in advance!
>> >> >
>> >> > [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marco.colagrossi at gmail.com  Mon Aug 24 19:49:09 2015
From: marco.colagrossi at gmail.com (Marco Colagrossi)
Date: Mon, 24 Aug 2015 19:49:09 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
Message-ID: <CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>

I tried to upload the file once again. I tweaked it a bit, now my code is:

forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1, subset=(pub==1),
       xlim = c(-16, 6),
       ilab = cbind(SIMdv, SIMiv),
       ilab.xpos = c(-7.5, -5.5), cex = 0.75)
op <- par(cex=.75, font=2)
      text(c(-7.5, -5.5), 54, c("DV", "IV"))
      text(-16,                54, "Author(s) and Year",     pos=4)
      text(6,                  54, "Outcome [95% CI]", pos=2)
par(op)

I managed to show both the Ilab argument and the text above. I still
have 3 issues:
- now the forest plot is too narrow - that is, pretty unreadable;
- I cannot still export it properly, as shown in the enclosed .png
- SIMdv, SIMiv are shown as number while on mine .csv are actually
text variable.

regarding the rma.mv package, I set it up this way (preliminarily)

multi <- rma.mv(pc, var, random = ~ 1 | author, data=codebook)

I'm trying to compare the results with this equation, which is what -
I think, correct me if I'm wrong -  in econometrics we call
author-fixed effect, that is, model which are constant across
individuals (the random\fix notation is a bit tricky):

author_fix <- rma(pc, var, mods = ~ I(author), data=codebook, method="ML")

What I was wondering if that the two equation above mentioned also
correct for heteroskedasticity which I need since my studies have
different sample and specifications.

Thanks for your help, your patience and your time, and many
compliments for the package, is guiding me through the use of R for
the first time - as you might have guessed.

Marco


On 24 August 2015 at 16:50, Viechtbauer Wolfgang (STAT)
<wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> I cannot reproduce the issue with 'ilab' not being shown when using 'subset'. My guess is that the values for 'ilab.xpos' specified are actually outside of the plotting region. After you have drawn the forest plot, try:
>
> par("usr")[1:2]
>
> to see what the default limits actually are. Then use 'xlim' to adjust the limits to your taste. And then use appropriate values for 'ilab.xpos', so they are inside those limits.
>
>> Moreover, the graph is showed correctly only within the zoom in
>> Rstudio but if I save it it is showed as enclosed.
>
> Nothing was enclosed (or it was stripped).
>
>> Moreover, how would you suggest to handle (graphically) the
>> multiple-cases-per-study thing? It's a 'good' way to average the cases
>> among different studies in the graphs?
>
> Maybe add some space between groupings (i.e., studies). The example given here can provide some clues how one could go about this: http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups But drawing a plot like this requires a lot of hand-tweaking.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
> Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marco
>> Colagrossi
>> Sent: Monday, August 24, 2015 16:04
>> To: r-help at r-project.org
>> Subject: [R] Metafor and forest(); not showing 'ilab' and text
>>
>> Hello folks,
>>
>> I have a couple of issues with the metafor package, specifically with
>> the forest graphs.
>> I am currently conducting a Meta-Analysis in economics throughout the
>> metafor package.
>>
>> My meta-analysis has the specific of having different cases from
>> single studies, and this proven to be challenging especially when
>> trying to plot graphically the results I'm obtaining.
>>
>> Here's the code:
>>
>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>> subset=(pub==1),
>>        ilab = cbind(ys, f_dim, SIMdv, SIMiv),
>>        ilab.xpos = c(-9.5, -8, -6, -4.5), cex = 0.75)
>> par(font=2)
>>       text(c(-9.5,-8,-6,-4.5), 26, c("Years", "Firm(s) Dimension", "DV",
>> "IV"))
>>       text(-16,                26, "Author(s) and Year",     pos=4)
>>       text(6,                  26, "Observed Outcome [95% CI]", pos=2)
>> par(op)
>>
>> 'pc' is the 'effect size', 'var' the variance, 'ci95m & ci95p' the CI,
>> 'pub' if the paper has been published or not. the pub subset was the
>> first idea I had in order to split my sample that otherwise would have
>> been to big. The issue with this solution is that forest() displays
>> only the slap argument and the forest with the confidence interval,
>> completely ignoring the lab argument and the text I'm trying to add.
>> Moreover, the graph is showed correctly only within the zoom in
>> Rstudio but if I save it it is showed as enclosed.
>>
>> What I'm doing wrong? I tried both to look at the package
>> documentation and online but I can't figure it out.
>>
>> Moreover, how would you suggest to handle (graphically) the
>> multiple-cases-per-study thing? It's a 'good' way to average the cases
>> among different studies in the graphs?
>> In my meta-analysis I'm using a multilevel model as shown in
>> Gelman-Hill but graphically (and in tables) I'm struggling.
>>
>> Thanks for your help and patience
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 105241 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150824/7e75b138/attachment.png>

From johannesradinger at gmail.com  Tue Aug 25 01:31:49 2015
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 25 Aug 2015 01:31:49 +0200
Subject: [R] Package dismo: Extracting sensitivity and specificity from
	gbm.step() object
Message-ID: <CABsGe_yyx76jQ4CyS-ZTiV3KPVYF2WMgK-Kny99ce+jBtA25sA@mail.gmail.com>

Dear R-User!

This is a question to all of you that are familiar with the 'dismo'
package, in particular we are interested in the gbm.step() function to
create a boosted regression tree model in R. From the model output object we
can use the $cv.statistics to get information on the cross-validation model
performance (e.g. cross-validation AUC). However, quite often the AUC has
been criticized for various reasons (e.g. Lobo et al. 2008) and it was
proposed also to use other measures of model performance (e.g. sensitivity
and specificity, Cohen's kappa, TSS).

Thus I am wondering wondering which of the $cv.statistical output is the
most appropriate indicator of model performance (e.g. for comparing two
boosted regression tree models). Moreover I'd like to know if it is somehow
possible to extract/calculate values of specificity and sensitivity from
the output model object (i.e without re-calculating the model). This would
be valuable information to calculate e.g. a kappa value or TSS value from a
gbm.step - model-object.

Thanks for your answers,

Best,
Johannes

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Tue Aug 25 03:36:45 2015
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 25 Aug 2015 13:36:45 +1200
Subject: [R] [FORGED] Re: plotting over a raster image with control over
 location and orientation
In-Reply-To: <1208388625.140155.1440246723749.JavaMail.yahoo@mail.yahoo.com>
References: <2048639744.8977490.1440167432929.JavaMail.yahoo@mail.yahoo.com>	<1591601188.65252.1440233400745.JavaMail.yahoo@mail.yahoo.com>
	<1208388625.140155.1440246723749.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <55DBC6AD.50703@stat.auckland.ac.nz>

Hi

The main problem with the code you have below is that it mixes drawing 
based on the 'graphics' package with drawing based on the 'grid' package 
and those packages do not mix easily.

I am not clear on what you want as your final result, but I wonder 
whether you need to just set up the plotting region how you would like 
it (plot.new(), plot.window()) and then position the raster within that 
(with rasterImage()) and then draw some more stuff on top (lines(), 
text(), ...).

Paul

On 08/23/15 00:32, ravi wrote:
> Hi,I am sorry for not having control checked the code before posting (in my earlier mail). I have done this now.
> I just have a simple question now. Why is the overlay plot (the final plot ) not falling into the intended position (as defined by the viewport vp2)?#Setting up the initial example raster image
> library(grid)
> x <- y <- c(-15,seq(-4*pi, 4*pi, len=27),15)
> r <- sqrt(outer(x^2, y^2, "+"))
> z <- cos(r^2)*exp(-r/6)
> image <- (z - min(z))/diff(range(z))
> xrange <- range(x)
> yrange <- range(y)
>
> vp1<-viewport(x = unit(0.5, "npc"), y = unit(0.5, "npc"),
>           width = unit(1, "npc"), height = unit(1, "npc"),
>           default.units = "npc", just = c("left","bottom"),name="vp1")
> pushViewport(vp1)
> plot(x, y, ann=FALSE,xlim=xrange, ylim=yrange,xaxs="i", yaxs="i")
> rasterImage(image,xrange[1], yrange[1],xrange[2], yrange[2],interpolate=FALSE)
> lines(c(-10,4),c(-12,-12),col="red",lwd=2)
>
> lim<-par("usr")
> lim
> limplt<-par("plt")
> limplt
> #par(new=TRUE,plt=c(limplt[1],limplt[2],limplt[3]))
>
> #convertX(unit(0:1,"npc"),"native")
> x1<-convertX(unit(-10,"native"),"npc")
> x2<-convertX(unit(5,"native"),"npc")
> y1<-convertY(unit(-12,"native"),"npc")
> y2<-convertY(unit(3,"native"),"npc")
>
> wx<-(5-(-10))/(15-(-15))
> wy<-(3-(-12))/(15-(-15))
>
> xw<-convertWidth(unit(wx,"native"),"npc")
> yw<-convertHeight(unit(wy,"native"),"npc")
>
>
> vp2<-viewport(x = unit(x1, "npc"), y = unit(y1, "npc"),
>                width = unit(xw, "npc"), height = unit(yw, "npc"),
>                default.units = "npc", name="vp2")
> pushViewport(vp2)
> #data with a different scale
> xs<-seq(0.01,0.1,0.01)ys<-xs^2
> #points(xs,ys,type='b',col='red',newpage=FALSE)
>
> plot(xs,ys,type='b',col='red') #fills the whole screen instead of just the intended viewport
>
>
> Thanks,Ravi
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From shivibhatia at ymail.com  Tue Aug 25 06:16:31 2015
From: shivibhatia at ymail.com (Shivi82)
Date: Mon, 24 Aug 2015 21:16:31 -0700 (PDT)
Subject: [R] Date as Integer
In-Reply-To: <AB763649AB2.000003E8jrkrideau@inbox.com>
References: <1440229385099-4711377.post@n4.nabble.com>
	<AB763649AB2.000003E8jrkrideau@inbox.com>
Message-ID: <1440476191624-4711456.post@n4.nabble.com>

Hi John,

Sorry but if this sounds really as a newbie question. 
I looked at the data as you suggested using glimpse(name of the dataset) 

and then View(dput(head(ak,20))) to capture it as a table. Is there an
option where i can save this view table & share along. 
I used dput but that would not work as it is not giving data out in the
required format due to multiple columns. 

Please suggest on view. 
Also i tried mutate but still get the same error message:
Error in UseMethod("group_by_") : 
  no applicable method for 'group_by_' applied to an object of class
"c('integer', 'numeric')".

Please see the output from View(dput(head(ak,20)))
Observations: 379674
Variables:
$ waybill          (int) 43360533, 43361203, 42754126, 43154067...
$ branch           (fctr) GURGAON-25, GURGAON-25, AHMEDABAD-03,...
$ type             (fctr) FMC, FMC, RBA, HBA, HBA, HBA, RBA, RB...
$ pickdate         (fctr) 2015/06/21, 2015/06/22, 2015/06/04, 2...
$ city             (fctr) Gurgaon, Gurgaon, Ahmedabad, Vapi, Va...
$ bookingzone      (fctr) G-N1, G-N1, G-W1, G-W1, G-W1, G-W1, G...
$ destinationzone  (fctr) G-N1, G-N1, G-W1, G-W1, G-W1, G-W1, G...
$ state            (fctr) G-N1, G-N1, G-W1, G-W1, G-W1, G-W1, G...
$ mod              (fctr) AIR, AIR, SURFACE, AIR, AIR, SURFACE,...
$ mode_payment     (fctr) CREDIT, CREDIT, TOPAY, CREDIT, CREDIT...
$ delivery_gateway (fctr) KANNUR, KANNUR, KANNUR, KANNUR, KANNU...
$ delivery_date    (fctr) 7/8/2015, , 6/20/2015, 6/13/2015, 6/1

Does this help?









--
View this message in context: http://r.789695.n4.nabble.com/Date-as-Integer-tp4711377p4711456.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Tue Aug 25 08:35:01 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 25 Aug 2015 06:35:01 +0000
Subject: [R] Calculate the area under a curve
In-Reply-To: <1440407411144-4711418.post@n4.nabble.com>
References: <1440407411144-4711418.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3C75A@SRVEXCHMBX.precheza.cz>

Hi

Your data are rather wild so I am not sure if following function can do what you want. I designed it primarily for intagration of peaks from different sources.

integ1 <- function (x, y, dm = -Inf, hm = +Inf)
{
    ifelse(dm == -Inf, dm <- min(x), dm <- dm)
    ifelse(hm == +Inf, hm <- max(x), hm <- hm)
    vyber <- x <= hm & x >= dm
    f3 <- splinefun(x, y)
    osum <- integrate(f3, dm, hm)$value
    o1 <- (y[x == min(x[vyber])] + y[x == max(x[vyber])]) * (max(x[vyber]) -
        min(x[vyber]))/2
    cista <- osum - o1
    return(c(osum, cista))
  }

From your data:

> integ1(P[,1], P[,2])
[1] 10.1677308  0.2677308
>

> integ1(P[,1], P[,2], dm=25, hm=80)
[1] 7.5668092 0.1028092
>

The first number shall be the area between zero and the curve, the second number is area between baseline constructed as a line between lower and margin.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> CarstenH
> Sent: Monday, August 24, 2015 11:10 AM
> To: r-help at r-project.org
> Subject: [R] Calculate the area under a curve
>
> Hi all
>
> I need to calculate the area under a curve (integral) for the following
> data
> pairs:
>
> Depth SOC
> 22.5  0.143
> 28.5  0.165
> 34.5  0.131
> 37.5  0.134
> 40.5  0.138
> 43.5  0.107
> 46.5  0.132
> 49.5  0.175
> 52.5  0.087
> 55.5  0.117
> 58.5  0.126
> 61.5  0.13
> 64.5  0.122
> 67.5  0.161
> 71.5  0.144
> 76.5  0.146
> 82.5  0.156
> 94.5  0.132
>
> (Table name is P)
>
> After reading the data set I assiged the collumns by:
>
> /x <- (P$Depth)
> y <- (P$SOC)
> /
>
> and decided to make a ploynominal function (3rd order):
>
> /fitP <- lm( y~poly(x,3,raw=TRUE) )/
>
> At the next step I failed. I can plot point and function but am not
> able to integrate the curve between e.g. depths 20 and 80.
>
> If I try:
> /
> integrand <-function(fitP1)
>   predict(y)
> integrate(integrand, lower = 25, upper = 80)/
>
> the "Conosle" opend with the message: "Source unavailable or out of
> sync"
> and
> /
> function(fitP1)
> predict(y)
> /
> )
>
>
> Would be great if somebody could help!
>
> Thanks
>
> Carsten
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Calculate-
> the-area-under-a-curve-tp4711418.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dpmeddings at gmail.com  Tue Aug 25 09:44:58 2015
From: dpmeddings at gmail.com (Daniel Meddings)
Date: Tue, 25 Aug 2015 08:44:58 +0100
Subject: [R] Estimating group modes using GLMs for skewed distributions
Message-ID: <CABrUXPW824GotzU-4OcEDA1wzD5YD=2K7e3-JWPj9Dfz_xSs8w@mail.gmail.com>

I am wondering why for generalized linear models with Gamma, Poisson and
Negative Binomial distributions that there appears to be no discussion
about estimating the medians or the modes of the distributions. For example
in clinical trials for count data where a log link is used it is the
quantity

E[Y|T] / E[Y|C] =   exp( beta_T + beta^{-}x^{*} )  / exp(beta_C +
beta^{-}x^{*})
                       =   exp( beta_T  )  / exp(beta_C )

that seems to be of interest, where beta_T, and beta_C are the effects of
treatment and control respectively, x^{*} is the chosen covariate point to
estimate the ratio at (doesn't matter what this is here since they cancel),
and beta^{-} is the model parameters excluding the treatment and control
effects.

Whilst I have no objection to this ratio, in addition I would also wish to
know what the mode or the median of the treated and control group is (and
the difference in these quantities), given that these distributions are
skewed (i.e. the mean is not too relevant).

For example for a skewed continuous variable modeled with the gamma
distribution if $alpha$ is the shape parameter then the mode for treated
subjects at x^{*} is given as follows

mode(Y|T) = ((alpha-1)(alpha))* exp(beta_T+beta^{-}x^{*})

as long as alpha >= 1. However I see no mention of this kind of summary
being estimated in these GLMs and I am wondering why. Is it perhaps that
the ratio of means is more difficult to affect by small treatment effects
than is a difference in modes or medians - i.e. analogous to risk ratios
generally being preferred to risk differences when comparing disease
incidence rates?

The reason I am interested in estimating modes or medians is that I wish to
compare how well a linear mixed model performs (which assumes normally
distributed responses) at estimating the mode or median by using the
standard mixed model estimates of the group means when the distribution of
Y is skewed. However perhaps I should be looking at how well the mixed
model estimates the ratio of means?

For comparison I have implemented the above estimation of the treatment and
control group modes using GLMs with random effects (the formula is similar
to the above but with simple functions of the random effects covariance
parameters multiplying the expression). As expected estimates of the group
means from the mixed model agree well with the estimates of the modes from
the GLM for reasonably symmetrical distributions, but the mixed model's
mean estimates start to increase beyond the modes as the distribution
becomes skewed.

I can do inference on the difference in the modes using a parametric
bootstrap, so as far as I am concerned I cannot see any problems with this
approach. However if there are some I would welcome somebody pointing these
out.

Many thanks

Dan

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Tue Aug 25 13:15:15 2015
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 25 Aug 2015 19:15:15 +0800 (CST)
Subject: [R]  how to generate 2 dimensional mesh  and hyper-cubes ?
Message-ID: <42fffa0e.14cb9.14f6491b5d1.Coremail.rhelpmaillist@163.com>



Dear expeRts,
? ? i want to know how to generate?the 2 dimensional mesh (i.e. grid on?the torus) of size n,?The grid mesh (with wrap around of?boundaries into a torus to avoid edge-effects). and?the hyper-cube which is the log2(n)-dimensional grid of size n.?? ?Does anyone happen to know it? BTW, how to find "spargraphs" this package, i find almost everywhere i know but still can not find it in R, is it a matlab package or other language package? Tks!


--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From lists at dewey.myzen.co.uk  Tue Aug 25 13:23:04 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 25 Aug 2015 12:23:04 +0100
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
Message-ID: <55DC5018.8040000@dewey.myzen.co.uk>

Hello Marco

Comments in line again

On 24/08/2015 18:49, Marco Colagrossi wrote:
> I tried to upload the file once again. I tweaked it a bit, now my code is:
>
> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1, subset=(pub==1),
>         xlim = c(-16, 6),
>         ilab = cbind(SIMdv, SIMiv),
>         ilab.xpos = c(-7.5, -5.5), cex = 0.75)
> op <- par(cex=.75, font=2)
>        text(c(-7.5, -5.5), 54, c("DV", "IV"))
>        text(-16,                54, "Author(s) and Year",     pos=4)
>        text(6,                  54, "Outcome [95% CI]", pos=2)
> par(op)
>
> I managed to show both the Ilab argument and the text above. I still
> have 3 issues:
> - now the forest plot is too narrow - that is, pretty unreadable;

You need to re-read Wolfgang's advice again. The forest function tells 
you what values of xlim it used and you can then adjust them to suit. 
This will take a few attempts in my experience.

> - I cannot still export it properly, as shown in the enclosed .png

It looked correctly exported to me. One comment, do you really need the 
complete citation of each study? Most of the forest plots I see as a 
reviewer just use the first author name and the year. This would 
potentially give you a lot more space.

> - SIMdv, SIMiv are shown as number while on mine .csv are actually
> text variable.
>
> regarding the rma.mv package, I set it up this way (preliminarily)
>

I will leave this one to Wolfgang to answer.

> multi <- rma.mv(pc, var, random = ~ 1 | author, data=codebook)
>
> I'm trying to compare the results with this equation, which is what -
> I think, correct me if I'm wrong -  in econometrics we call
> author-fixed effect, that is, model which are constant across
> individuals (the random\fix notation is a bit tricky):
>
> author_fix <- rma(pc, var, mods = ~ I(author), data=codebook, method="ML")
>
> What I was wondering if that the two equation above mentioned also
> correct for heteroskedasticity which I need since my studies have
> different sample and specifications.
>
> Thanks for your help, your patience and your time, and many
> compliments for the package, is guiding me through the use of R for
> the first time - as you might have guessed.
>
> Marco
>
>
> On 24 August 2015 at 16:50, Viechtbauer Wolfgang (STAT)
> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> I cannot reproduce the issue with 'ilab' not being shown when using 'subset'. My guess is that the values for 'ilab.xpos' specified are actually outside of the plotting region. After you have drawn the forest plot, try:
>>
>> par("usr")[1:2]
>>
>> to see what the default limits actually are. Then use 'xlim' to adjust the limits to your taste. And then use appropriate values for 'ilab.xpos', so they are inside those limits.
>>
>>> Moreover, the graph is showed correctly only within the zoom in
>>> Rstudio but if I save it it is showed as enclosed.
>>
>> Nothing was enclosed (or it was stripped).
>>
>>> Moreover, how would you suggest to handle (graphically) the
>>> multiple-cases-per-study thing? It's a 'good' way to average the cases
>>> among different studies in the graphs?
>>
>> Maybe add some space between groupings (i.e., studies). The example given here can provide some clues how one could go about this: http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups But drawing a plot like this requires a lot of hand-tweaking.
>>
>> Best,
>> Wolfgang
>>
>> --
>> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
>> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
>> Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marco
>>> Colagrossi
>>> Sent: Monday, August 24, 2015 16:04
>>> To: r-help at r-project.org
>>> Subject: [R] Metafor and forest(); not showing 'ilab' and text
>>>
>>> Hello folks,
>>>
>>> I have a couple of issues with the metafor package, specifically with
>>> the forest graphs.
>>> I am currently conducting a Meta-Analysis in economics throughout the
>>> metafor package.
>>>
>>> My meta-analysis has the specific of having different cases from
>>> single studies, and this proven to be challenging especially when
>>> trying to plot graphically the results I'm obtaining.
>>>
>>> Here's the code:
>>>
>>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>>> subset=(pub==1),
>>>         ilab = cbind(ys, f_dim, SIMdv, SIMiv),
>>>         ilab.xpos = c(-9.5, -8, -6, -4.5), cex = 0.75)
>>> par(font=2)
>>>        text(c(-9.5,-8,-6,-4.5), 26, c("Years", "Firm(s) Dimension", "DV",
>>> "IV"))
>>>        text(-16,                26, "Author(s) and Year",     pos=4)
>>>        text(6,                  26, "Observed Outcome [95% CI]", pos=2)
>>> par(op)
>>>
>>> 'pc' is the 'effect size', 'var' the variance, 'ci95m & ci95p' the CI,
>>> 'pub' if the paper has been published or not. the pub subset was the
>>> first idea I had in order to split my sample that otherwise would have
>>> been to big. The issue with this solution is that forest() displays
>>> only the slap argument and the forest with the confidence interval,
>>> completely ignoring the lab argument and the text I'm trying to add.
>>> Moreover, the graph is showed correctly only within the zoom in
>>> Rstudio but if I save it it is showed as enclosed.
>>>
>>> What I'm doing wrong? I tried both to look at the package
>>> documentation and online but I can't figure it out.
>>>
>>> Moreover, how would you suggest to handle (graphically) the
>>> multiple-cases-per-study thing? It's a 'good' way to average the cases
>>> among different studies in the graphs?
>>> In my meta-analysis I'm using a multilevel model as shown in
>>> Gelman-Hill but graphically (and in tables) I'm struggling.
>>>
>>> Thanks for your help and patience
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Aug 25 15:54:46 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 25 Aug 2015 15:54:46 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <55DC5018.8040000@dewey.myzen.co.uk>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>

Further comments in line as well.

> -----Original Message-----
> From: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> Sent: Tuesday, August 25, 2015 13:23
> To: Marco Colagrossi; Viechtbauer Wolfgang (STAT)
> Cc: r-help at r-project.org
> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
> 
> Hello Marco
> 
> Comments in line again
> 
> On 24/08/2015 18:49, Marco Colagrossi wrote:
> > I tried to upload the file once again. I tweaked it a bit, now my code
> is:
> >
> > forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
> subset=(pub==1),
> >         xlim = c(-16, 6),
> >         ilab = cbind(SIMdv, SIMiv),
> >         ilab.xpos = c(-7.5, -5.5), cex = 0.75)
> > op <- par(cex=.75, font=2)
> >        text(c(-7.5, -5.5), 54, c("DV", "IV"))
> >        text(-16,                54, "Author(s) and Year",     pos=4)
> >        text(6,                  54, "Outcome [95% CI]", pos=2)
> > par(op)
> >
> > I managed to show both the Ilab argument and the text above. I still
> > have 3 issues:
> > - now the forest plot is too narrow - that is, pretty unreadable;
> 
> You need to re-read Wolfgang's advice again. The forest function tells
> you what values of xlim it used and you can then adjust them to suit.
> This will take a few attempts in my experience.
> 
> > - I cannot still export it properly, as shown in the enclosed .png
> 
> It looked correctly exported to me. One comment, do you really need the
> complete citation of each study? Most of the forest plots I see as a
> reviewer just use the first author name and the year. This would
> potentially give you a lot more space.

Also, if you have lots of outcomes, you may need to increase the height of the plotting device to make everything fit (or you need to reduce the font size even further, but things will become illegible eventually).

> > - SIMdv, SIMiv are shown as number while on mine .csv are actually
> > text variable.

Those variables are apparently coded as factors, so use data.frame() instead of cbind() to avoid the coercion to integer codes.

> > regarding the rma.mv package, I set it up this way (preliminarily)
> >
> 
> I will leave this one to Wolfgang to answer.
> 
> > multi <- rma.mv(pc, var, random = ~ 1 | author, data=codebook)
> >
> > I'm trying to compare the results with this equation, which is what -
> > I think, correct me if I'm wrong -  in econometrics we call
> > author-fixed effect, that is, model which are constant across
> > individuals (the random\fix notation is a bit tricky):
> >
> > author_fix <- rma(pc, var, mods = ~ I(author), data=codebook,
> method="ML")
> >
> > What I was wondering if that the two equation above mentioned also
> > correct for heteroskedasticity which I need since my studies have
> > different sample and specifications.

I cannot comment on model choices. But yes, the functions properly account for the fact that the sampling variances are heteroskedastic.

> > Thanks for your help, your patience and your time, and many
> > compliments for the package, is guiding me through the use of R for
> > the first time - as you might have guessed.
> >
> > Marco
> >
> >
> > On 24 August 2015 at 16:50, Viechtbauer Wolfgang (STAT)
> > <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> I cannot reproduce the issue with 'ilab' not being shown when using
> 'subset'. My guess is that the values for 'ilab.xpos' specified are
> actually outside of the plotting region. After you have drawn the forest
> plot, try:
> >>
> >> par("usr")[1:2]
> >>
> >> to see what the default limits actually are. Then use 'xlim' to adjust
> the limits to your taste. And then use appropriate values for
> 'ilab.xpos', so they are inside those limits.
> >>
> >>> Moreover, the graph is showed correctly only within the zoom in
> >>> Rstudio but if I save it it is showed as enclosed.
> >>
> >> Nothing was enclosed (or it was stripped).
> >>
> >>> Moreover, how would you suggest to handle (graphically) the
> >>> multiple-cases-per-study thing? It's a 'good' way to average the
> cases
> >>> among different studies in the graphs?
> >>
> >> Maybe add some space between groupings (i.e., studies). The example
> given here can provide some clues how one could go about this:
> http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups
> But drawing a plot like this requires a lot of hand-tweaking.
> >>
> >> Best,
> >> Wolfgang
> >>
> >> --
> >> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry
> and
> >> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200
> MD
> >> Maastricht, The Netherlands | +31 (43) 388-4170 |
> http://www.wvbauer.com
> >>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marco
> >>> Colagrossi
> >>> Sent: Monday, August 24, 2015 16:04
> >>> To: r-help at r-project.org
> >>> Subject: [R] Metafor and forest(); not showing 'ilab' and text
> >>>
> >>> Hello folks,
> >>>
> >>> I have a couple of issues with the metafor package, specifically with
> >>> the forest graphs.
> >>> I am currently conducting a Meta-Analysis in economics throughout the
> >>> metafor package.
> >>>
> >>> My meta-analysis has the specific of having different cases from
> >>> single studies, and this proven to be challenging especially when
> >>> trying to plot graphically the results I'm obtaining.
> >>>
> >>> Here's the code:
> >>>
> >>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
> >>> subset=(pub==1),
> >>>         ilab = cbind(ys, f_dim, SIMdv, SIMiv),
> >>>         ilab.xpos = c(-9.5, -8, -6, -4.5), cex = 0.75)
> >>> par(font=2)
> >>>        text(c(-9.5,-8,-6,-4.5), 26, c("Years", "Firm(s) Dimension",
> "DV",
> >>> "IV"))
> >>>        text(-16,                26, "Author(s) and Year",     pos=4)
> >>>        text(6,                  26, "Observed Outcome [95% CI]",
> pos=2)
> >>> par(op)
> >>>
> >>> 'pc' is the 'effect size', 'var' the variance, 'ci95m & ci95p' the
> CI,
> >>> 'pub' if the paper has been published or not. the pub subset was the
> >>> first idea I had in order to split my sample that otherwise would
> have
> >>> been to big. The issue with this solution is that forest() displays
> >>> only the slap argument and the forest with the confidence interval,
> >>> completely ignoring the lab argument and the text I'm trying to add.
> >>> Moreover, the graph is showed correctly only within the zoom in
> >>> Rstudio but if I save it it is showed as enclosed.
> >>>
> >>> What I'm doing wrong? I tried both to look at the package
> >>> documentation and online but I can't figure it out.
> >>>
> >>> Moreover, how would you suggest to handle (graphically) the
> >>> multiple-cases-per-study thing? It's a 'good' way to average the
> cases
> >>> among different studies in the graphs?
> >>> In my meta-analysis I'm using a multilevel model as shown in
> >>> Gelman-Hill but graphically (and in tables) I'm struggling.
> >>>
> >>> Thanks for your help and patience

From alexis.sarda at gmail.com  Sun Aug 23 20:14:06 2015
From: alexis.sarda at gmail.com (Alexis Sarda)
Date: Sun, 23 Aug 2015 20:14:06 +0200
Subject: [R] [R-pkgs] R Package dtwclust: Shape-based clustering of
	univariate	time series
Message-ID: <CAA4naPBAfEZz9fs4Uu3Lx-0r-37oxwu2LNgqmJ=p-BK8+6E-gw@mail.gmail.com>

Time Series Clustering With Dynamic Time Warping Distance (DTW)
===============================================================

The dtwclust package attempts to consolidate some of the recent techniques
related to time series clustering under DTW and implement them in R. Most
of these algorithms make use of traditional clustering techniques
(partitional and hierarchical clustering) but change the distance
definition. In this case, the distance between time series is measured with
DTW.

DTW is, however, computationally expensive, so several optimization
techniques exist. They mostly deal with bounding the DTW distance. These
bounds are only defined for time series of equal lengths. Nevertheless, if
the length of the time series of interest vary only slightly,
reinterpolating them to a common length is probably an appropriate solution.

Additionally, a recently proposed algorithm called k-Shape could serve as
an alternative. k-Shape clustering relies on custom distance and centroid
definitions, which are unrelated to DTW. The shape extraction algorithm
proposed therein is particularly interesting if time series can be
normalized.

Many of the algorithms and optimizations require that all series have the
same length. The ones that don't are usually slow but can still be used.

Please see the references for more information.

Dependencies
------------

-   Partitional procedures are implemented by leveraging the `flexclust`
package.
-   Hierarchical procedures use the native `hclust` function.
-   Cross-distances make use of the `proxy` package.
-   The core DTW calculations are done by the `dtw` package.
-   Plotting is done with the `ggplot2` package.

Implementations
---------------

-   Keogh's and Lemire's lower bounds
-   DTW Barycenter Averaging
-   k-Shape clustering
-   TADPole clustering

--
Best,
Alexis Sard? Espinosa.

https://github.com/asardaes/dtwclust
https://cran.rstudio.com/web/packages/dtwclust/index.html

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From tonightsthenight at gmail.com  Tue Aug 25 17:17:43 2015
From: tonightsthenight at gmail.com (Sam Albers)
Date: Tue, 25 Aug 2015 08:17:43 -0700
Subject: [R] Choosing columns by number
Message-ID: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>

Hi all,

This is a process question. How do folks efficiently identify column
numbers in a dataframe without manually counting them. For example, if I
want to choose columns from the iris dataframe I know of two options. I can
do this:

> str(iris)'data.frame':	150 obs. of  5 variables:
 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
1 1 1 1 1 1 ...

or this:

> names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"

Neither option explicitly identifies the column number so that I can
do something like this:

iris[,c(2,4)]

I feel like there must be a better way to do this so I wanted to ask
the collective wisdom here what people do to accomplish this.
Obviously this is a trivial example, but the issue really becomes
problematic when you have a large dataframe.

Thanks in advance!

Sam

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Aug 25 17:29:23 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 25 Aug 2015 10:29:23 -0500
Subject: [R] Choosing columns by number
In-Reply-To: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
Message-ID: <B66274A5-5D14-4C39-B804-61CF773EF443@me.com>


> On Aug 25, 2015, at 10:17 AM, Sam Albers <tonightsthenight at gmail.com> wrote:
> 
> Hi all,
> 
> This is a process question. How do folks efficiently identify column
> numbers in a dataframe without manually counting them. For example, if I
> want to choose columns from the iris dataframe I know of two options. I can
> do this:
> 
>> str(iris)'data.frame':	150 obs. of  5 variables:
> $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
> $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
> $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
> $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
> $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
> 1 1 1 1 1 1 ...
> 
> or this:
> 
>> names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
> 
> Neither option explicitly identifies the column number so that I can
> do something like this:
> 
> iris[,c(2,4)]
> 
> I feel like there must be a better way to do this so I wanted to ask
> the collective wisdom here what people do to accomplish this.
> Obviously this is a trivial example, but the issue really becomes
> problematic when you have a large dataframe.
> 
> Thanks in advance!
> 
> Sam


Just use ?subset:

  NewDF <- subset(iris, select = c(Sepal.Width, Petal.Width))

which is the same as:

  NewDF <- iris[, c(2, 4)]

You can also define sequential columns using ?:?, thus:

  NewDF <- subset(iris, select = c(Sepal.Width:Petal.Width)

is the same as:

  NewDF <- iris[, 2:4]

and use combinations of the two approaches as well.

You can also negate the selection by using:

  select = -c(?)

That avoids having to worry about using integer indices.

Regards,

Marc Schwartz


From dwinsemius at comcast.net  Tue Aug 25 17:29:51 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Aug 2015 08:29:51 -0700
Subject: [R] Choosing columns by number
In-Reply-To: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
Message-ID: <45536559-A8FF-4611-92A7-6A5AE0F6E8C7@comcast.net>


On Aug 25, 2015, at 8:17 AM, Sam Albers wrote:

> Hi all,
> 
> This is a process question. How do folks efficiently identify column
> numbers in a dataframe without manually counting them. For example, if I
> want to choose columns from the iris dataframe I know of two options. I can
> do this:
> 
>> str(iris)'data.frame':	150 obs. of  5 variables:
> $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
> $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
> $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
> $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
> $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
> 1 1 1 1 1 1 ...
> 
> or this:
> 
>> names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
> 
> Neither option explicitly identifies the column number so that I can
> do something like this:
> 
> iris[,c(2,4)]

The request to "identify column numbers" seems a bit vague at the moment because it misses any criterion for such "identification". If your goal is to construct a vector that "identified" (by number) the names of the columns that contained the text "Width" it would be:

grep("Width",   names(iris) )

You do need some rule ... which you never articulated.

> 
> I feel like there must be a better way to do this so I wanted to ask
> the collective wisdom here what people do to accomplish this.
> Obviously this is a trivial example, but the issue really becomes
> problematic when you have a large dataframe.
> 
> Thanks in advance!
> 
> Sam
> 
> 	[[alternative HTML version deleted]]

Still posting in HTML? Having trouble finding the Posting Guide? Can't find the mechanism in gmail to send plain text? What is the problem?

-- 


David Winsemius
Alameda, CA, USA


From ssefick at gmail.com  Tue Aug 25 17:32:01 2015
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 25 Aug 2015 10:32:01 -0500
Subject: [R] Choosing columns by number
In-Reply-To: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
Message-ID: <CADKEMqi-jK8T4nNRnmomQhTYUG=ymMGM_aHk7tyWaPaJ-3xo6A@mail.gmail.com>

?grep

I think this will do what you want.

#something like
a <- data.frame(a=rnorm(10), b=rnorm(10), c=rnorm(10), d=rnorm(10))

toMatch <- c("a", "d")

grep(paste(toMatch,collapse="|"), colnames(a))

#to subset
a[,grep(paste(toMatch,collapse="|"), colnames(a))]


On Tue, Aug 25, 2015 at 10:17 AM, Sam Albers <tonightsthenight at gmail.com>
wrote:

> Hi all,
>
> This is a process question. How do folks efficiently identify column
> numbers in a dataframe without manually counting them. For example, if I
> want to choose columns from the iris dataframe I know of two options. I can
> do this:
>
> > str(iris)'data.frame':        150 obs. of  5 variables:
>  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>  $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
> 1 1 1 1 1 1 ...
>
> or this:
>
> > names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length"
> "Petal.Width"  "Species"
>
> Neither option explicitly identifies the column number so that I can
> do something like this:
>
> iris[,c(2,4)]
>
> I feel like there must be a better way to do this so I wanted to ask
> the collective wisdom here what people do to accomplish this.
> Obviously this is a trivial example, but the issue really becomes
> problematic when you have a large dataframe.
>
> Thanks in advance!
>
> Sam
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From maillists at nic.fi  Tue Aug 25 17:32:37 2015
From: maillists at nic.fi (K. Elo)
Date: Tue, 25 Aug 2015 18:32:37 +0300
Subject: [R] Choosing columns by number
In-Reply-To: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
Message-ID: <55DC8A95.5030202@nic.fi>



Hi!

25.08.2015, 18:17, Sam Albers wrote:
> Hi all,
>
> This is a process question. How do folks efficiently identify column
> numbers in a dataframe without manually counting them. For example, if I
> want to choose columns from the iris dataframe I know of two options. I can
> do this:
>
>> str(iris)'data.frame':	150 obs. of  5 variables:
>   $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>   $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>   $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>   $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>   $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
> 1 1 1 1 1 1 ...
>
> or this:
>
>> names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
>
> Neither option explicitly identifies the column number so that I can
> do something like this:
>
> iris[,c(2,4)]
>
> I feel like there must be a better way to do this so I wanted to ask
> the collective wisdom here what people do to accomplish this.
> Obviously this is a trivial example, but the issue really becomes
> problematic when you have a large dataframe.

Maybe with 'which'?

 > which(colnames(iris)=="Sepal.Length")
[1] 1

Or did I somehow misunderstood what you are looking for?

HTH,
Kimmo


From thierry.onkelinx at inbo.be  Tue Aug 25 17:28:37 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 25 Aug 2015 17:28:37 +0200
Subject: [R] Choosing columns by number
In-Reply-To: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
Message-ID: <CAJuCY5xCOsfUQUmHZ4HT+890Z4AhS21AUChAiu_kh2ViRdTg1w@mail.gmail.com>

Here are a few ideas.

data.frame(
  seq_along(iris),
  colnames(iris)
)
which(colnames(iris) %in% c("Sepal.Width", "Petal.Width"))
grep("\\.Width$", colnames(iris))

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2015-08-25 17:17 GMT+02:00 Sam Albers <tonightsthenight at gmail.com>:
> Hi all,
>
> This is a process question. How do folks efficiently identify column
> numbers in a dataframe without manually counting them. For example, if I
> want to choose columns from the iris dataframe I know of two options. I can
> do this:
>
>> str(iris)'data.frame':        150 obs. of  5 variables:
>  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>  $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
> 1 1 1 1 1 1 ...
>
> or this:
>
>> names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"
>
> Neither option explicitly identifies the column number so that I can
> do something like this:
>
> iris[,c(2,4)]
>
> I feel like there must be a better way to do this so I wanted to ask
> the collective wisdom here what people do to accomplish this.
> Obviously this is a trivial example, but the issue really becomes
> problematic when you have a large dataframe.
>
> Thanks in advance!
>
> Sam
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tonightsthenight at gmail.com  Tue Aug 25 17:44:38 2015
From: tonightsthenight at gmail.com (Sam Albers)
Date: Tue, 25 Aug 2015 08:44:38 -0700
Subject: [R] Choosing columns by number
In-Reply-To: <CADKEMqi-jK8T4nNRnmomQhTYUG=ymMGM_aHk7tyWaPaJ-3xo6A@mail.gmail.com>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
	<CADKEMqi-jK8T4nNRnmomQhTYUG=ymMGM_aHk7tyWaPaJ-3xo6A@mail.gmail.com>
Message-ID: <CADkXsV3nPc-xT01ZFqji3n7xAwK1GLx2GX6ktikyTh06t2QNyw@mail.gmail.com>

Thierry's answer of:

data.frame(
  seq_along(iris),
  colnames(iris)
)

is exactly what I was looking for. Apologies for vagueness and HTML.
It was unintended.

Sam

On Tue, Aug 25, 2015 at 8:32 AM, stephen sefick <ssefick at gmail.com> wrote:
> ?grep
>
> I think this will do what you want.
>
> #something like
> a <- data.frame(a=rnorm(10), b=rnorm(10), c=rnorm(10), d=rnorm(10))
>
> toMatch <- c("a", "d")
>
> grep(paste(toMatch,collapse="|"), colnames(a))
>
> #to subset
> a[,grep(paste(toMatch,collapse="|"), colnames(a))]
>
>
> On Tue, Aug 25, 2015 at 10:17 AM, Sam Albers <tonightsthenight at gmail.com>
> wrote:
>>
>> Hi all,
>>
>> This is a process question. How do folks efficiently identify column
>> numbers in a dataframe without manually counting them. For example, if I
>> want to choose columns from the iris dataframe I know of two options. I
>> can
>> do this:
>>
>> > str(iris)'data.frame':        150 obs. of  5 variables:
>>  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>>  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>>  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>>  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>>  $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
>> 1 1 1 1 1 1 ...
>>
>> or this:
>>
>> > names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length"
>> > "Petal.Width"  "Species"
>>
>> Neither option explicitly identifies the column number so that I can
>> do something like this:
>>
>> iris[,c(2,4)]
>>
>> I feel like there must be a better way to do this so I wanted to ask
>> the collective wisdom here what people do to accomplish this.
>> Obviously this is a trivial example, but the issue really becomes
>> problematic when you have a large dataframe.
>>
>> Thanks in advance!
>>
>> Sam
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>


From jdnewmil at dcn.davis.CA.us  Tue Aug 25 17:45:56 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 25 Aug 2015 08:45:56 -0700
Subject: [R] how to generate 2 dimensional mesh  and hyper-cubes ?
In-Reply-To: <42fffa0e.14cb9.14f6491b5d1.Coremail.rhelpmaillist@163.com>
References: <42fffa0e.14cb9.14f6491b5d1.Coremail.rhelpmaillist@163.com>
Message-ID: <87CCF8E8-BD14-4629-B043-C975C4F0AD45@dcn.davis.CA.us>

I would think that ?expand.grid with appropriate choice of coordinates would be the best tool for defining the mesh. As for edge effects, doesn't that depend on the (unnamed) algorithms you intend to apply?

As for "spargraphs"... findFn from package sos could not find it, and I have never heard of it... I recommend using a web search engine, as I doubt it has anything to do with R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 25, 2015 4:15:15 AM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>
>
>Dear expeRts,
>? ? i want to know how to generate?the 2 dimensional mesh (i.e. grid
>on?the torus) of size n,?The grid mesh (with wrap around of?boundaries
>into a torus to avoid edge-effects). and?the hyper-cube which is the
>log2(n)-dimensional grid of size n.?? ?Does anyone happen to know it?
>BTW, how to find "spargraphs" this package, i find almost everywhere i
>know but still can not find it in R, is it a matlab package or other
>language package? Tks!
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marco.colagrossi at gmail.com  Tue Aug 25 17:58:56 2015
From: marco.colagrossi at gmail.com (Marco Colagrossi)
Date: Tue, 25 Aug 2015 17:58:56 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
Message-ID: <CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>

Thanks again for your help. I'm sorry to bother you but I don't get
how to widen the forest plot; if I try to change the values of xlim or
the ilab.xpos values the width of the forest plot region does not
change, but only moves on the graphs. What I'm I missing?


forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1, subset=(pub==1),
       xlim = c(-16, 6),
       ilab = data.frame(SIMdv, SIMiv),
       ilab.xpos = c(-7.5, -5.5), cex = 0.75)
op <- par(cex=.75, font=2)
      text(c(-7.5, -5.5), 54, c("DV", "IV"))
      text(-16,                54, "Author(s) and Year",     pos=4)
      text(6,                  54, "Outcome [95% CI]", pos=2)
par(op)
> par("usr")[1:2]
[1] -16   6

On 25 August 2015 at 15:54, Viechtbauer Wolfgang (STAT)
<wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> Further comments in line as well.
>
>> -----Original Message-----
>> From: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
>> Sent: Tuesday, August 25, 2015 13:23
>> To: Marco Colagrossi; Viechtbauer Wolfgang (STAT)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
>>
>> Hello Marco
>>
>> Comments in line again
>>
>> On 24/08/2015 18:49, Marco Colagrossi wrote:
>> > I tried to upload the file once again. I tweaked it a bit, now my code
>> is:
>> >
>> > forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>> subset=(pub==1),
>> >         xlim = c(-16, 6),
>> >         ilab = cbind(SIMdv, SIMiv),
>> >         ilab.xpos = c(-7.5, -5.5), cex = 0.75)
>> > op <- par(cex=.75, font=2)
>> >        text(c(-7.5, -5.5), 54, c("DV", "IV"))
>> >        text(-16,                54, "Author(s) and Year",     pos=4)
>> >        text(6,                  54, "Outcome [95% CI]", pos=2)
>> > par(op)
>> >
>> > I managed to show both the Ilab argument and the text above. I still
>> > have 3 issues:
>> > - now the forest plot is too narrow - that is, pretty unreadable;
>>
>> You need to re-read Wolfgang's advice again. The forest function tells
>> you what values of xlim it used and you can then adjust them to suit.
>> This will take a few attempts in my experience.
>>
>> > - I cannot still export it properly, as shown in the enclosed .png
>>
>> It looked correctly exported to me. One comment, do you really need the
>> complete citation of each study? Most of the forest plots I see as a
>> reviewer just use the first author name and the year. This would
>> potentially give you a lot more space.
>
> Also, if you have lots of outcomes, you may need to increase the height of the plotting device to make everything fit (or you need to reduce the font size even further, but things will become illegible eventually).
>
>> > - SIMdv, SIMiv are shown as number while on mine .csv are actually
>> > text variable.
>
> Those variables are apparently coded as factors, so use data.frame() instead of cbind() to avoid the coercion to integer codes.
>
>> > regarding the rma.mv package, I set it up this way (preliminarily)
>> >
>>
>> I will leave this one to Wolfgang to answer.
>>
>> > multi <- rma.mv(pc, var, random = ~ 1 | author, data=codebook)
>> >
>> > I'm trying to compare the results with this equation, which is what -
>> > I think, correct me if I'm wrong -  in econometrics we call
>> > author-fixed effect, that is, model which are constant across
>> > individuals (the random\fix notation is a bit tricky):
>> >
>> > author_fix <- rma(pc, var, mods = ~ I(author), data=codebook,
>> method="ML")
>> >
>> > What I was wondering if that the two equation above mentioned also
>> > correct for heteroskedasticity which I need since my studies have
>> > different sample and specifications.
>
> I cannot comment on model choices. But yes, the functions properly account for the fact that the sampling variances are heteroskedastic.
>
>> > Thanks for your help, your patience and your time, and many
>> > compliments for the package, is guiding me through the use of R for
>> > the first time - as you might have guessed.
>> >
>> > Marco
>> >
>> >
>> > On 24 August 2015 at 16:50, Viechtbauer Wolfgang (STAT)
>> > <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >> I cannot reproduce the issue with 'ilab' not being shown when using
>> 'subset'. My guess is that the values for 'ilab.xpos' specified are
>> actually outside of the plotting region. After you have drawn the forest
>> plot, try:
>> >>
>> >> par("usr")[1:2]
>> >>
>> >> to see what the default limits actually are. Then use 'xlim' to adjust
>> the limits to your taste. And then use appropriate values for
>> 'ilab.xpos', so they are inside those limits.
>> >>
>> >>> Moreover, the graph is showed correctly only within the zoom in
>> >>> Rstudio but if I save it it is showed as enclosed.
>> >>
>> >> Nothing was enclosed (or it was stripped).
>> >>
>> >>> Moreover, how would you suggest to handle (graphically) the
>> >>> multiple-cases-per-study thing? It's a 'good' way to average the
>> cases
>> >>> among different studies in the graphs?
>> >>
>> >> Maybe add some space between groupings (i.e., studies). The example
>> given here can provide some clues how one could go about this:
>> http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups
>> But drawing a plot like this requires a lot of hand-tweaking.
>> >>
>> >> Best,
>> >> Wolfgang
>> >>
>> >> --
>> >> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry
>> and
>> >> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200
>> MD
>> >> Maastricht, The Netherlands | +31 (43) 388-4170 |
>> http://www.wvbauer.com
>> >>
>> >>> -----Original Message-----
>> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marco
>> >>> Colagrossi
>> >>> Sent: Monday, August 24, 2015 16:04
>> >>> To: r-help at r-project.org
>> >>> Subject: [R] Metafor and forest(); not showing 'ilab' and text
>> >>>
>> >>> Hello folks,
>> >>>
>> >>> I have a couple of issues with the metafor package, specifically with
>> >>> the forest graphs.
>> >>> I am currently conducting a Meta-Analysis in economics throughout the
>> >>> metafor package.
>> >>>
>> >>> My meta-analysis has the specific of having different cases from
>> >>> single studies, and this proven to be challenging especially when
>> >>> trying to plot graphically the results I'm obtaining.
>> >>>
>> >>> Here's the code:
>> >>>
>> >>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>> >>> subset=(pub==1),
>> >>>         ilab = cbind(ys, f_dim, SIMdv, SIMiv),
>> >>>         ilab.xpos = c(-9.5, -8, -6, -4.5), cex = 0.75)
>> >>> par(font=2)
>> >>>        text(c(-9.5,-8,-6,-4.5), 26, c("Years", "Firm(s) Dimension",
>> "DV",
>> >>> "IV"))
>> >>>        text(-16,                26, "Author(s) and Year",     pos=4)
>> >>>        text(6,                  26, "Observed Outcome [95% CI]",
>> pos=2)
>> >>> par(op)
>> >>>
>> >>> 'pc' is the 'effect size', 'var' the variance, 'ci95m & ci95p' the
>> CI,
>> >>> 'pub' if the paper has been published or not. the pub subset was the
>> >>> first idea I had in order to split my sample that otherwise would
>> have
>> >>> been to big. The issue with this solution is that forest() displays
>> >>> only the slap argument and the forest with the confidence interval,
>> >>> completely ignoring the lab argument and the text I'm trying to add.
>> >>> Moreover, the graph is showed correctly only within the zoom in
>> >>> Rstudio but if I save it it is showed as enclosed.
>> >>>
>> >>> What I'm doing wrong? I tried both to look at the package
>> >>> documentation and online but I can't figure it out.
>> >>>
>> >>> Moreover, how would you suggest to handle (graphically) the
>> >>> multiple-cases-per-study thing? It's a 'good' way to average the
>> cases
>> >>> among different studies in the graphs?
>> >>> In my meta-analysis I'm using a multilevel model as shown in
>> >>> Gelman-Hill but graphically (and in tables) I'm struggling.
>> >>>
>> >>> Thanks for your help and patience


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Aug 25 18:11:14 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 25 Aug 2015 18:11:14 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>

The 'xlim' argument does not change the actual width of the plotting device. For that, you need to use the 'width' argument with whatever device you are actually using. You can then use the 'xlim' argument to create appropriate spacing to the left/right of the part of the plot that shows the estimates and their CIs. Within that space, you can then add additional columns with the 'ilab' argument. It's up to you to find an appropriate combination of plotting device width, character/symbol expansion factor ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create a nice looking plot that has no overlapping text and no excessive white space. An example is this:

http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups 

Note that it took me dozens of iterations to create that plot. You just have to start experimenting.

Best,
Wolfgang

> -----Original Message-----
> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
> Sent: Tuesday, August 25, 2015 17:59
> To: Viechtbauer Wolfgang (STAT)
> Cc: r-help at r-project.org; Michael Dewey
> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
> 
> Thanks again for your help. I'm sorry to bother you but I don't get
> how to widen the forest plot; if I try to change the values of xlim or
> the ilab.xpos values the width of the forest plot region does not
> change, but only moves on the graphs. What I'm I missing?
> 
> 
> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
> subset=(pub==1),
>        xlim = c(-16, 6),
>        ilab = data.frame(SIMdv, SIMiv),
>        ilab.xpos = c(-7.5, -5.5), cex = 0.75)
> op <- par(cex=.75, font=2)
>       text(c(-7.5, -5.5), 54, c("DV", "IV"))
>       text(-16,                54, "Author(s) and Year",     pos=4)
>       text(6,                  54, "Outcome [95% CI]", pos=2)
> par(op)
> > par("usr")[1:2]
> [1] -16   6

From dwinsemius at comcast.net  Tue Aug 25 18:17:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Aug 2015 09:17:18 -0700
Subject: [R] how to generate 2 dimensional mesh  and hyper-cubes ?
In-Reply-To: <42fffa0e.14cb9.14f6491b5d1.Coremail.rhelpmaillist@163.com>
References: <42fffa0e.14cb9.14f6491b5d1.Coremail.rhelpmaillist@163.com>
Message-ID: <2ED4D08C-8B61-4671-B005-7641CF1DEC60@comcast.net>


On Aug 25, 2015, at 4:15 AM, PO SU wrote:

> 
> 
> Dear expeRts,
>     i want to know how to generate the 2 dimensional mesh (i.e. grid on the torus) of size n, The grid mesh (with wrap around of boundaries into a torus to avoid edge-effects). and the hyper-cube which is the log2(n)-dimensional grid of size n.    Does anyone happen to know it? BTW, how to find "spargraphs" this package, i find almost everywhere i know but still can not find it in R, is it a matlab package or other language package? Tks!

In searching I found nothing re: "spargraphs". I did find some genetics oriented tutorials for students that mentioned producing "spar graphs" with the limma-package. You might address this question to the BioConductor mailing list if your area of interest is genetics/molecular biology.

-- 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Tue Aug 25 18:31:34 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 25 Aug 2015 16:31:34 +0000
Subject: [R] Choosing columns by number
In-Reply-To: <CADkXsV3nPc-xT01ZFqji3n7xAwK1GLx2GX6ktikyTh06t2QNyw@mail.gmail.com>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
	<CADKEMqi-jK8T4nNRnmomQhTYUG=ymMGM_aHk7tyWaPaJ-3xo6A@mail.gmail.com>
	<CADkXsV3nPc-xT01ZFqji3n7xAwK1GLx2GX6ktikyTh06t2QNyw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B9D79@mb02.ads.tamu.edu>

You might also look at Str() in package DescTools. It is basically str() with column numbers added:

> library(DescTools)
Loading required package: manipulate
> data(iris)
> Str(iris)
'data.frame':   150 obs. of  5 variables:
 1 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
 2 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
 3 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
 4 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
 5 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sam Albers
Sent: Tuesday, August 25, 2015 10:45 AM
To: stephen sefick
Cc: r-help at r-project.org
Subject: Re: [R] Choosing columns by number

Thierry's answer of:

data.frame(
  seq_along(iris),
  colnames(iris)
)

is exactly what I was looking for. Apologies for vagueness and HTML.
It was unintended.

Sam

On Tue, Aug 25, 2015 at 8:32 AM, stephen sefick <ssefick at gmail.com> wrote:
> ?grep
>
> I think this will do what you want.
>
> #something like
> a <- data.frame(a=rnorm(10), b=rnorm(10), c=rnorm(10), d=rnorm(10))
>
> toMatch <- c("a", "d")
>
> grep(paste(toMatch,collapse="|"), colnames(a))
>
> #to subset
> a[,grep(paste(toMatch,collapse="|"), colnames(a))]
>
>
> On Tue, Aug 25, 2015 at 10:17 AM, Sam Albers <tonightsthenight at gmail.com>
> wrote:
>>
>> Hi all,
>>
>> This is a process question. How do folks efficiently identify column
>> numbers in a dataframe without manually counting them. For example, if I
>> want to choose columns from the iris dataframe I know of two options. I
>> can
>> do this:
>>
>> > str(iris)'data.frame':        150 obs. of  5 variables:
>>  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>>  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>>  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>>  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>>  $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
>> 1 1 1 1 1 1 ...
>>
>> or this:
>>
>> > names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length"
>> > "Petal.Width"  "Species"
>>
>> Neither option explicitly identifies the column number so that I can
>> do something like this:
>>
>> iris[,c(2,4)]
>>
>> I feel like there must be a better way to do this so I wanted to ask
>> the collective wisdom here what people do to accomplish this.
>> Obviously this is a trivial example, but the issue really becomes
>> problematic when you have a large dataframe.
>>
>> Thanks in advance!
>>
>> Sam
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rhelpmaillist at 163.com  Tue Aug 25 18:44:52 2015
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 26 Aug 2015 00:44:52 +0800 (CST)
Subject: [R] how to generate 2 dimensional mesh  and hyper-cubes ?
In-Reply-To: <2ED4D08C-8B61-4671-B005-7641CF1DEC60@comcast.net>
References: <42fffa0e.14cb9.14f6491b5d1.Coremail.rhelpmaillist@163.com>
	<2ED4D08C-8B61-4671-B005-7641CF1DEC60@comcast.net>
Message-ID: <495d7af8.18406.14f65bf7bf5.Coremail.rhelpmaillist@163.com>


Tks a lot, i will study the limma package as you mentioned first ~ ~ 




--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU



At 2015-08-26 00:17:18, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>On Aug 25, 2015, at 4:15 AM, PO SU wrote:
>
>> 
>> 
>> Dear expeRts,
>>     i want to know how to generate the 2 dimensional mesh (i.e. grid on the torus) of size n, The grid mesh (with wrap around of boundaries into a torus to avoid edge-effects). and the hyper-cube which is the log2(n)-dimensional grid of size n.    Does anyone happen to know it? BTW, how to find "spargraphs" this package, i find almost everywhere i know but still can not find it in R, is it a matlab package or other language package? Tks!
>
>In searching I found nothing re: "spargraphs". I did find some genetics oriented tutorials for students that mentioned producing "spar graphs" with the limma-package. You might address this question to the BioConductor mailing list if your area of interest is genetics/molecular biology.
>
>-- 
>
>David Winsemius
>Alameda, CA, USA
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Aug 25 19:24:54 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 25 Aug 2015 18:24:54 +0100
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
	<CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>
Message-ID: <55DCA4E6.40204@dewey.myzen.co.uk>

Dear Marco

When you change xlim it increases the width of the forest plot in the 
sense you describe. It does not push your text out of the way to make 
space for it but instead overprints it. You may like to use alim to 
truncate your confidence interval whiskers to fit within the space you 
see or make your labels shorter.

On 25/08/2015 17:25, Marco Colagrossi wrote:
> I think I've not explained myself well. When I say "the width of the
> forest plot" I mean the region above the observed outcome, the
> "actual" forest plot, not the plot as a whole. Even if I change values
> for Xlim, cex or ilab.xpos the width of that particular region within
> the plot doesn't change.
>
> Best,
>
> Marco
>
> On 25 August 2015 at 18:11, Viechtbauer Wolfgang (STAT)
> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> The 'xlim' argument does not change the actual width of the plotting device. For that, you need to use the 'width' argument with whatever device you are actually using. You can then use the 'xlim' argument to create appropriate spacing to the left/right of the part of the plot that shows the estimates and their CIs. Within that space, you can then add additional columns with the 'ilab' argument. It's up to you to find an appropriate combination of plotting device width, character/symbol expansion factor ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create a nice looking plot that has no overlapping text and no excessive white space. An example is this:
>>
>> http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups
>>
>> Note that it took me dozens of iterations to create that plot. You just have to start experimenting.
>>
>> Best,
>> Wolfgang
>>
>>> -----Original Message-----
>>> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
>>> Sent: Tuesday, August 25, 2015 17:59
>>> To: Viechtbauer Wolfgang (STAT)
>>> Cc: r-help at r-project.org; Michael Dewey
>>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
>>>
>>> Thanks again for your help. I'm sorry to bother you but I don't get
>>> how to widen the forest plot; if I try to change the values of xlim or
>>> the ilab.xpos values the width of the forest plot region does not
>>> change, but only moves on the graphs. What I'm I missing?
>>>
>>>
>>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>>> subset=(pub==1),
>>>         xlim = c(-16, 6),
>>>         ilab = data.frame(SIMdv, SIMiv),
>>>         ilab.xpos = c(-7.5, -5.5), cex = 0.75)
>>> op <- par(cex=.75, font=2)
>>>        text(c(-7.5, -5.5), 54, c("DV", "IV"))
>>>        text(-16,                54, "Author(s) and Year",     pos=4)
>>>        text(6,                  54, "Outcome [95% CI]", pos=2)
>>> par(op)
>>>> par("usr")[1:2]
>>> [1] -16   6

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From callyak4real at yahoo.com  Tue Aug 25 19:41:02 2015
From: callyak4real at yahoo.com (Babatunde Yakub)
Date: Tue, 25 Aug 2015 17:41:02 +0000 (UTC)
Subject: [R] Cusum and Ewma charts
Message-ID: <795082213.274492.1440524462201.JavaMail.yahoo@mail.yahoo.com>

I want to know the codes for computing the optimal cusum and ewma chart. I will also like to know the R codes for plotting each of these categories. And if it is not present in R, I will like to know another statistical package that can help me deal with this situation.Thanks

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Aug 25 20:07:06 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Aug 2015 11:07:06 -0700
Subject: [R] Choosing columns by number
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6B9D79@mb02.ads.tamu.edu>
References: <CADkXsV07M35V1TVyLDkMC=jGE_OZ49=VGSiz2=R5K-2S3YUGjw@mail.gmail.com>
	<CADKEMqi-jK8T4nNRnmomQhTYUG=ymMGM_aHk7tyWaPaJ-3xo6A@mail.gmail.com>
	<CADkXsV3nPc-xT01ZFqji3n7xAwK1GLx2GX6ktikyTh06t2QNyw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6B9D79@mb02.ads.tamu.edu>
Message-ID: <DFE0EA63-21D0-4C0F-92CD-42E05AAA0F22@comcast.net>


On Aug 25, 2015, at 9:31 AM, David L Carlson wrote:

> You might also look at Str() in package DescTools. It is basically str() with column numbers added:
> 
>> library(DescTools)
> Loading required package: manipulate
>> data(iris)
>> Str(iris)
> 'data.frame':   150 obs. of  5 variables:
> 1 $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
> 2 $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
> 3 $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
> 4 $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
> 5 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...

You can also display character vectors with numbering at the console with as.matrix:

> as.matrix(names(iris))
     [,1]          
[1,] "Sepal.Length"
[2,] "Sepal.Width" 
[3,] "Petal.Length"
[4,] "Petal.Width" 
[5,] "Species"  

-- 
(the other) David.

> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sam Albers
> Sent: Tuesday, August 25, 2015 10:45 AM
> To: stephen sefick
> Cc: r-help at r-project.org
> Subject: Re: [R] Choosing columns by number
> 
> Thierry's answer of:
> 
> data.frame(
>  seq_along(iris),
>  colnames(iris)
> )
> 
> is exactly what I was looking for. Apologies for vagueness and HTML.
> It was unintended.
> 
> Sam
> 
> On Tue, Aug 25, 2015 at 8:32 AM, stephen sefick <ssefick at gmail.com> wrote:
>> ?grep
>> 
>> I think this will do what you want.
>> 
>> #something like
>> a <- data.frame(a=rnorm(10), b=rnorm(10), c=rnorm(10), d=rnorm(10))
>> 
>> toMatch <- c("a", "d")
>> 
>> grep(paste(toMatch,collapse="|"), colnames(a))
>> 
>> #to subset
>> a[,grep(paste(toMatch,collapse="|"), colnames(a))]
>> 
>> 
>> On Tue, Aug 25, 2015 at 10:17 AM, Sam Albers <tonightsthenight at gmail.com>
>> wrote:
>>> 
>>> Hi all,
>>> 
>>> This is a process question. How do folks efficiently identify column
>>> numbers in a dataframe without manually counting them. For example, if I
>>> want to choose columns from the iris dataframe I know of two options. I
>>> can
>>> do this:
>>> 
>>>> str(iris)'data.frame':        150 obs. of  5 variables:
>>> $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>>> $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>>> $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>>> $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>>> $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1
>>> 1 1 1 1 1 1 ...
>>> 
>>> or this:
>>> 
>>>> names(iris)[1] "Sepal.Length" "Sepal.Width"  "Petal.Length"
>>>> "Petal.Width"  "Species"
>>> 
>>> Neither option explicitly identifies the column number so that I can
>>> do something like this:
>>> 
>>> iris[,c(2,4)]
>>> 
>>> I feel like there must be a better way to do this so I wanted to ask
>>> the collective wisdom here what people do to accomplish this.
>>> Obviously this is a trivial example, but the issue really becomes
>>> problematic when you have a large dataframe.
>>> 
>>> Thanks in advance!
>>> 
>>> Sam
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> --
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>> 
>> Let's not spend our time and resources thinking about things that are so
>> little or so large that all they really do for us is puff us up and make us
>> feel like gods.  We are mammals, and have not exhausted the annoying little
>> problems of being mammals.
>> 
>>                                -K. Mullis
>> 
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>> 
>>                              -Robert Gentleman
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bogaso.christofer at gmail.com  Tue Aug 25 20:10:40 2015
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 25 Aug 2015 23:40:40 +0530
Subject: [R] How to download this data
Message-ID: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>

Hi,

I would like to download data from below page directly onto R.

http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm

Could you please assist me how can I do that programmatically.

Thanks for your time.


From bgunter.4567 at gmail.com  Tue Aug 25 20:23:26 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 25 Aug 2015 11:23:26 -0700
Subject: [R] How to download this data
In-Reply-To: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
Message-ID: <CAGxFJbSC2x81WxBny_9qSe_h+kaaxKW4GPnDSox=QhaaOYzBNg@mail.gmail.com>

This is not a simple question. The data are in an html-formatted web
page. You must "scrape" the html for the data and read it into an R
table (or other appropriate R data structure). Searching (the web) on
"scrape data from html into R"  listed several packages that claim to
enable you to do this "easily". Choose what seems best for you.

You should also install and read the documentation for the XML
package, which is also used for this purpose, though those you find
above may be slicker.

Disclaimer: I have no direct experience with this. I'm just pointing
out what I believe are relevant resources.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Aug 25, 2015 at 11:10 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi,
>
> I would like to download data from below page directly onto R.
>
> http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>
> Could you please assist me how can I do that programmatically.
>
> Thanks for your time.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bob at rudis.net  Tue Aug 25 20:49:07 2015
From: bob at rudis.net (boB Rudis)
Date: Tue, 25 Aug 2015 14:49:07 -0400
Subject: [R] How to download this data
In-Reply-To: <CAGxFJbSC2x81WxBny_9qSe_h+kaaxKW4GPnDSox=QhaaOYzBNg@mail.gmail.com>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
	<CAGxFJbSC2x81WxBny_9qSe_h+kaaxKW4GPnDSox=QhaaOYzBNg@mail.gmail.com>
Message-ID: <CAJ4QxaPOHg=S1m6OgNwEkrBkJ2L=7hZObE3PGieqOkoakZbAfA@mail.gmail.com>

Looks like you can get what you need from
http://www.nseindia.com/homepage/Indices1.json on that page.

On Tue, Aug 25, 2015 at 2:23 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> This is not a simple question. The data are in an html-formatted web
> page. You must "scrape" the html for the data and read it into an R
> table (or other appropriate R data structure). Searching (the web) on
> "scrape data from html into R"  listed several packages that claim to
> enable you to do this "easily". Choose what seems best for you.
>
> You should also install and read the documentation for the XML
> package, which is also used for this purpose, though those you find
> above may be slicker.
>
> Disclaimer: I have no direct experience with this. I'm just pointing
> out what I believe are relevant resources.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Tue, Aug 25, 2015 at 11:10 AM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>> Hi,
>>
>> I would like to download data from below page directly onto R.
>>
>> http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>>
>> Could you please assist me how can I do that programmatically.
>>
>> Thanks for your time.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Aug 25 20:59:35 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 25 Aug 2015 11:59:35 -0700
Subject: [R] How to download this data
In-Reply-To: <CAGxFJbSC2x81WxBny_9qSe_h+kaaxKW4GPnDSox=QhaaOYzBNg@mail.gmail.com>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
	<CAGxFJbSC2x81WxBny_9qSe_h+kaaxKW4GPnDSox=QhaaOYzBNg@mail.gmail.com>
Message-ID: <B80377CD-C842-4F8A-9E0C-6C4DEEE86F01@dcn.davis.CA.us>

I agree that this is a tricky task... even more so than using a"scraping" package because the page is built dynamically. This will take someone with skills in multiple web technologies to decipher the web page scripts to figure out how to manipulate the server to give you the data, because it isn't actually in the web page.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 25, 2015 11:23:26 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>This is not a simple question. The data are in an html-formatted web
>page. You must "scrape" the html for the data and read it into an R
>table (or other appropriate R data structure). Searching (the web) on
>"scrape data from html into R"  listed several packages that claim to
>enable you to do this "easily". Choose what seems best for you.
>
>You should also install and read the documentation for the XML
>package, which is also used for this purpose, though those you find
>above may be slicker.
>
>Disclaimer: I have no direct experience with this. I'm just pointing
>out what I believe are relevant resources.
>
>Cheers,
>Bert
>Bert Gunter
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>   -- Clifford Stoll
>
>
>On Tue, Aug 25, 2015 at 11:10 AM, Christofer Bogaso
><bogaso.christofer at gmail.com> wrote:
>> Hi,
>>
>> I would like to download data from below page directly onto R.
>>
>>
>http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>>
>> Could you please assist me how can I do that programmatically.
>>
>> Thanks for your time.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hasan.diwan at gmail.com  Tue Aug 25 21:10:20 2015
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Tue, 25 Aug 2015 12:10:20 -0700
Subject: [R] How to download this data
In-Reply-To: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
Message-ID: <CAP+bYWDDsL8fxCwt3PLKhWnRE8Bh2DuKAy-tRtgwRT6rt9Yjtg@mail.gmail.com>

If there's no api available, I would use selenium to grab what I need and
pipe it to R. Let me know if you need further assistance. Cheers! -- H
On Aug 25, 2015 11:12 AM, "Christofer Bogaso" <bogaso.christofer at gmail.com>
wrote:

> Hi,
>
> I would like to download data from below page directly onto R.
>
>
> http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>
> Could you please assist me how can I do that programmatically.
>
> Thanks for your time.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Aug 25 21:11:15 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 25 Aug 2015 12:11:15 -0700
Subject: [R] How to download this data
In-Reply-To: <B80377CD-C842-4F8A-9E0C-6C4DEEE86F01@dcn.davis.CA.us>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
	<CAGxFJbSC2x81WxBny_9qSe_h+kaaxKW4GPnDSox=QhaaOYzBNg@mail.gmail.com>
	<B80377CD-C842-4F8A-9E0C-6C4DEEE86F01@dcn.davis.CA.us>
Message-ID: <CAGxFJbSNwhGg=fcoeqWN36LYN5Q7nuN+zAVpBbDMfG2AnG6=nA@mail.gmail.com>

Actually, in looking again, I noticed a "download in csv" link on the
page, and this appears to provide a csv -formatted table that then can
trivially be read into R by, e.g. read.csv() .

So maybe all the html (or JSON) stuff can be ignored.


-- Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Aug 25, 2015 at 11:59 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> I agree that this is a tricky task... even more so than using a"scraping" package because the page is built dynamically. This will take someone with skills in multiple web technologies to decipher the web page scripts to figure out how to manipulate the server to give you the data, because it isn't actually in the web page.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 25, 2015 11:23:26 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>This is not a simple question. The data are in an html-formatted web
>>page. You must "scrape" the html for the data and read it into an R
>>table (or other appropriate R data structure). Searching (the web) on
>>"scrape data from html into R"  listed several packages that claim to
>>enable you to do this "easily". Choose what seems best for you.
>>
>>You should also install and read the documentation for the XML
>>package, which is also used for this purpose, though those you find
>>above may be slicker.
>>
>>Disclaimer: I have no direct experience with this. I'm just pointing
>>out what I believe are relevant resources.
>>
>>Cheers,
>>Bert
>>Bert Gunter
>>
>>"Data is not information. Information is not knowledge. And knowledge
>>is certainly not wisdom."
>>   -- Clifford Stoll
>>
>>
>>On Tue, Aug 25, 2015 at 11:10 AM, Christofer Bogaso
>><bogaso.christofer at gmail.com> wrote:
>>> Hi,
>>>
>>> I would like to download data from below page directly onto R.
>>>
>>>
>>http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>>>
>>> Could you please assist me how can I do that programmatically.
>>>
>>> Thanks for your time.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Tue Aug 25 21:36:06 2015
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 25 Aug 2015 20:36:06 +0100
Subject: [R] How to download this data
In-Reply-To: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
Message-ID: <55DCC3A6.5010507@sapo.pt>

Hello,

There might be a problem:

 > url <- 
"http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm"
 > readLines(url)
Error in file(con, "r") : cannot open the connection
In addition: Warning message:
In file(con, "r") : cannot open: HTTP status was '403 Forbidden'


So I've downloaded the csv file with the data, but that's not 
programmatically.

Rui Barradas

Em 25-08-2015 19:10, Christofer Bogaso escreveu:
> Hi,
>
> I would like to download data from below page directly onto R.
>
> http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>
> Could you please assist me how can I do that programmatically.
>
> Thanks for your time.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Tue Aug 25 21:55:40 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 25 Aug 2015 12:55:40 -0700
Subject: [R] How to download this data
In-Reply-To: <CAGxFJbSNwhGg=fcoeqWN36LYN5Q7nuN+zAVpBbDMfG2AnG6=nA@mail.gmail.com>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
	<CAGxFJbSC2x81WxBny_9qSe_h+kaaxKW4GPnDSox=QhaaOYzBNg@mail.gmail.com>
	<B80377CD-C842-4F8A-9E0C-6C4DEEE86F01@dcn.davis.CA.us>
	<CAGxFJbSNwhGg=fcoeqWN36LYN5Q7nuN+zAVpBbDMfG2AnG6=nA@mail.gmail.com>
Message-ID: <04FC731F-4CFD-4495-AF8A-9B0E25B0FAFF@dcn.davis.CA.us>

... but not programmatically.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 25, 2015 12:11:15 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Actually, in looking again, I noticed a "download in csv" link on the
>page, and this appears to provide a csv -formatted table that then can
>trivially be read into R by, e.g. read.csv() .
>
>So maybe all the html (or JSON) stuff can be ignored.
>
>
>-- Bert
>Bert Gunter
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>   -- Clifford Stoll
>
>
>On Tue, Aug 25, 2015 at 11:59 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> I agree that this is a tricky task... even more so than using
>a"scraping" package because the page is built dynamically. This will
>take someone with skills in multiple web technologies to decipher the
>web page scripts to figure out how to manipulate the server to give you
>the data, because it isn't actually in the web page.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On August 25, 2015 11:23:26 AM PDT, Bert Gunter
><bgunter.4567 at gmail.com> wrote:
>>>This is not a simple question. The data are in an html-formatted web
>>>page. You must "scrape" the html for the data and read it into an R
>>>table (or other appropriate R data structure). Searching (the web) on
>>>"scrape data from html into R"  listed several packages that claim to
>>>enable you to do this "easily". Choose what seems best for you.
>>>
>>>You should also install and read the documentation for the XML
>>>package, which is also used for this purpose, though those you find
>>>above may be slicker.
>>>
>>>Disclaimer: I have no direct experience with this. I'm just pointing
>>>out what I believe are relevant resources.
>>>
>>>Cheers,
>>>Bert
>>>Bert Gunter
>>>
>>>"Data is not information. Information is not knowledge. And knowledge
>>>is certainly not wisdom."
>>>   -- Clifford Stoll
>>>
>>>
>>>On Tue, Aug 25, 2015 at 11:10 AM, Christofer Bogaso
>>><bogaso.christofer at gmail.com> wrote:
>>>> Hi,
>>>>
>>>> I would like to download data from below page directly onto R.
>>>>
>>>>
>>>http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>>>>
>>>> Could you please assist me how can I do that programmatically.
>>>>
>>>> Thanks for your time.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>


From john.archie.mckown at gmail.com  Tue Aug 25 22:07:35 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 25 Aug 2015 15:07:35 -0500
Subject: [R] How to download this data
In-Reply-To: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
References: <CA+dpOJmYYwUJBVTzpoj4AroKLFTxquFrDBF3RshTXLtDB6g+ng@mail.gmail.com>
Message-ID: <CAAJSdjjo7euxoXSp_mgubxoOKxS0tr+1C2w9WxbU5J9i_bKvDw@mail.gmail.com>

FWIW. This violates their terms of service, unless you have their
permission:

http://www.nseindia.com/global/content/termsofuse.htm

<quote>

You may not conduct any systematic or automated data collection activities
(including scraping, data mining, data extraction and data harvesting) on
or in relation to our website without our express written consent.

<quote/>

On Tue, Aug 25, 2015 at 1:10 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I would like to download data from below page directly onto R.
>
>
> http://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm
>
> Could you please assist me how can I do that programmatically.
>
> Thanks for your time.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From marco.colagrossi at gmail.com  Tue Aug 25 18:25:20 2015
From: marco.colagrossi at gmail.com (Marco Colagrossi)
Date: Tue, 25 Aug 2015 18:25:20 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
Message-ID: <CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>

I think I've not explained myself well. When I say "the width of the
forest plot" I mean the region above the observed outcome, the
"actual" forest plot, not the plot as a whole. Even if I change values
for Xlim, cex or ilab.xpos the width of that particular region within
the plot doesn't change.

Best,

Marco

On 25 August 2015 at 18:11, Viechtbauer Wolfgang (STAT)
<wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> The 'xlim' argument does not change the actual width of the plotting device. For that, you need to use the 'width' argument with whatever device you are actually using. You can then use the 'xlim' argument to create appropriate spacing to the left/right of the part of the plot that shows the estimates and their CIs. Within that space, you can then add additional columns with the 'ilab' argument. It's up to you to find an appropriate combination of plotting device width, character/symbol expansion factor ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create a nice looking plot that has no overlapping text and no excessive white space. An example is this:
>
> http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups
>
> Note that it took me dozens of iterations to create that plot. You just have to start experimenting.
>
> Best,
> Wolfgang
>
>> -----Original Message-----
>> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
>> Sent: Tuesday, August 25, 2015 17:59
>> To: Viechtbauer Wolfgang (STAT)
>> Cc: r-help at r-project.org; Michael Dewey
>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
>>
>> Thanks again for your help. I'm sorry to bother you but I don't get
>> how to widen the forest plot; if I try to change the values of xlim or
>> the ilab.xpos values the width of the forest plot region does not
>> change, but only moves on the graphs. What I'm I missing?
>>
>>
>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>> subset=(pub==1),
>>        xlim = c(-16, 6),
>>        ilab = data.frame(SIMdv, SIMiv),
>>        ilab.xpos = c(-7.5, -5.5), cex = 0.75)
>> op <- par(cex=.75, font=2)
>>       text(c(-7.5, -5.5), 54, c("DV", "IV"))
>>       text(-16,                54, "Author(s) and Year",     pos=4)
>>       text(6,                  54, "Outcome [95% CI]", pos=2)
>> par(op)
>> > par("usr")[1:2]
>> [1] -16   6
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot01.png
Type: image/png
Size: 119435 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150825/5b8eac03/attachment.png>

From paulocfonsecat at gmail.com  Tue Aug 25 23:01:48 2015
From: paulocfonsecat at gmail.com (Paulo Fonseca)
Date: Tue, 25 Aug 2015 16:01:48 -0500
Subject: [R] Fwd: ayuda- help me
In-Reply-To: <CAGSwdRBZccp3tsp03Z0Rxvv1sXNv=8Gr8SR4cRGhSFiamcm3ew@mail.gmail.com>
References: <CAGSwdRBZccp3tsp03Z0Rxvv1sXNv=8Gr8SR4cRGhSFiamcm3ew@mail.gmail.com>
Message-ID: <CAGSwdRDszqYyLW6SMps+kojHHqH2xsswpaoe_jbJHJZSPE0Grw@mail.gmail.com>

Cordial saludo,

Muy amablemente solicito su ayuda con la siguiente inquietud:

Estoy tratando de interpolar datos de variables clim?ticas en R pero no he
podido ustedes me podr?a colaborar con un instructivo que me gui? paso a
paso como se hace , ya que el objeto es tener como resultado el mapa de
precipitaci?n para un determinado a?o.

De antemano agradezco su atenci?n y su colaboraci?n

Atentamente

Paulo Fonseca


Best regard,

I kindly request your assistance with the following concers:

I'm trying to interpolate climatic data variables in R but I could not you
could help me with intructions to guide me step by step how it is done,
since the object is to result in the precipitation map for a given year.

thaks in advance for your attention and colaboration.

Sincerely

Paulo Fonseca

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Aug 25 23:45:57 2015
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 25 Aug 2015 16:45:57 -0500
Subject: [R] Fwd: ayuda- help me
In-Reply-To: <CAGSwdRDszqYyLW6SMps+kojHHqH2xsswpaoe_jbJHJZSPE0Grw@mail.gmail.com>
References: <CAGSwdRBZccp3tsp03Z0Rxvv1sXNv=8Gr8SR4cRGhSFiamcm3ew@mail.gmail.com>
	<CAGSwdRDszqYyLW6SMps+kojHHqH2xsswpaoe_jbJHJZSPE0Grw@mail.gmail.com>
Message-ID: <CADKEMqgG7TjPO8V0qBhypBZ-ggteA95unCO-B_iB2meC4D1C6g@mail.gmail.com>

You will generally get more and better responses if you have a reproducible
example. Please read the posting guide.

Please excuse my brevity; this message was sent from my telephone.
On Aug 25, 2015 4:14 PM, "Paulo Fonseca" <paulocfonsecat at gmail.com> wrote:

> Cordial saludo,
>
> Muy amablemente solicito su ayuda con la siguiente inquietud:
>
> Estoy tratando de interpolar datos de variables clim?ticas en R pero no he
> podido ustedes me podr?a colaborar con un instructivo que me gui? paso a
> paso como se hace , ya que el objeto es tener como resultado el mapa de
> precipitaci?n para un determinado a?o.
>
> De antemano agradezco su atenci?n y su colaboraci?n
>
> Atentamente
>
> Paulo Fonseca
>
>
> Best regard,
>
> I kindly request your assistance with the following concers:
>
> I'm trying to interpolate climatic data variables in R but I could not you
> could help me with intructions to guide me step by step how it is done,
> since the object is to result in the precipitation map for a given year.
>
> thaks in advance for your attention and colaboration.
>
> Sincerely
>
> Paulo Fonseca
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From fanjianling at gmail.com  Wed Aug 26 00:34:29 2015
From: fanjianling at gmail.com (Jianling Fan)
Date: Tue, 25 Aug 2015 16:34:29 -0600
Subject: [R] nls model parameter compare?
Message-ID: <CAJ7mryKkAsgqNps4G7UYBu=FBM6BZa5mFUfhzzoNogGjDuUT2A@mail.gmail.com>

Hello everyone,

I am doing nonlinear regression using a same sigmoidal model for
different treatments. for each treatment, I got a set of estimated
parameters (a1, b1, c1 for treatment 1; a2, b2, c2 for treatment 2;
a3, b3, c3 for treatment 3). And I want to compare these parameters
for different treatments to see is there any differences? does
estimated parameter for treatment i different from other treatments?

How can I do this analysis please?

Thanks in advance!

Regards,

Julian


From bgunter.4567 at gmail.com  Wed Aug 26 00:59:53 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 25 Aug 2015 15:59:53 -0700
Subject: [R] nls model parameter compare?
In-Reply-To: <CAJ7mryKkAsgqNps4G7UYBu=FBM6BZa5mFUfhzzoNogGjDuUT2A@mail.gmail.com>
References: <CAJ7mryKkAsgqNps4G7UYBu=FBM6BZa5mFUfhzzoNogGjDuUT2A@mail.gmail.com>
Message-ID: <CAGxFJbSChd5h9ZsYsbRn6jK3ENwhAO_Q=qi6YHopAd_q0oLw4g@mail.gmail.com>

This is a statistical question, and is off topic for this list, which
is about R programming. Post to a statistical list, like
stats.stackexchange.com, instead.

Warning: This is not a simple issue. You should seriously consider
getting local advice from someone with the necessary statistical
expertise.

Gratuitous Question born from personal frustration with such
queries(so feel free to ignore): Why are you using (statistical)
procedures that you do not understand? Of course the parameters for
different treatments are "different"! -- but how and with what
importance depends on the context in which you are working. Instead of
fooling with cryptic statistical mumbo jumbo that invite misuse -- and
which are probably valueless or idiotic anyway --  why don't you make
some graphs and consider what they say in terms of the substantive
issues at play? (Of course I know the answer -- it is because that is
what your academic culture/journals demand. But therein lies the
problem: what is demanded is junk).

Cheers,
Bert




Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Aug 25, 2015 at 3:34 PM, Jianling Fan <fanjianling at gmail.com> wrote:
> Hello everyone,
>
> I am doing nonlinear regression using a same sigmoidal model for
> different treatments. for each treatment, I got a set of estimated
> parameters (a1, b1, c1 for treatment 1; a2, b2, c2 for treatment 2;
> a3, b3, c3 for treatment 3). And I want to compare these parameters
> for different treatments to see is there any differences? does
> estimated parameter for treatment i different from other treatments?
>
> How can I do this analysis please?
>
> Thanks in advance!
>
> Regards,
>
> Julian
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Aug 26 01:14:03 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 26 Aug 2015 11:14:03 +1200
Subject: [R] [FORGED] Re:  nls model parameter compare?
In-Reply-To: <CAGxFJbSChd5h9ZsYsbRn6jK3ENwhAO_Q=qi6YHopAd_q0oLw4g@mail.gmail.com>
References: <CAJ7mryKkAsgqNps4G7UYBu=FBM6BZa5mFUfhzzoNogGjDuUT2A@mail.gmail.com>
	<CAGxFJbSChd5h9ZsYsbRn6jK3ENwhAO_Q=qi6YHopAd_q0oLw4g@mail.gmail.com>
Message-ID: <55DCF6BB.2010407@auckland.ac.nz>

On 26/08/15 10:59, Bert Gunter wrote:

<SNIP>

> Gratuitous Question born from personal frustration with such
> queries(so feel free to ignore): Why are you using (statistical)
> procedures that you do not understand? Of course the parameters for
> different treatments are "different"! -- but how and with what
> importance depends on the context in which you are working. Instead of
> fooling with cryptic statistical mumbo jumbo that invite misuse -- and
> which are probably valueless or idiotic anyway --  why don't you make
> some graphs and consider what they say in terms of the substantive
> issues at play? (Of course I know the answer -- it is because that is
> what your academic culture/journals demand. But therein lies the
> problem: what is demanded is junk).

Fortune nomination!!!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From javajimburke at gmail.com  Wed Aug 26 00:51:38 2015
From: javajimburke at gmail.com (Jim Burke)
Date: Tue, 25 Aug 2015 17:51:38 -0500
Subject: [R] Fwd: Text in Spatial Polygrams
In-Reply-To: <CALkjiFQewYO=i+=PnUtUMsb-a2632Vn6=bgMvuMvttNnyCqLJQ@mail.gmail.com>
References: <CALkjiFQewYO=i+=PnUtUMsb-a2632Vn6=bgMvuMvttNnyCqLJQ@mail.gmail.com>
Message-ID: <CALkjiFTxtHQTD83do431gMH2CB-79DrUZS-9bBcgvVTaGGdZaQ@mail.gmail.com>

Setup for the OSM Map is below

   ul <- as.vector(cbind(bbox(all_pcts_osm_sp) [2,2], bbox(all_pcts_osm_sp)
[1,1]))
   lr <- as.vector(cbind(bbox(all_pcts_osm_sp) [2,1], bbox(all_pcts_osm_sp)
[1,2]))
   map_types <- c("osm", "maptoolkit-topo", "waze", "mapquest",
"mapquest-aerial",
      "bing", "stamen-toner", "stamen-terrain", "stamen-watercolor",
"osm-german",
      "osm-wanderreitkarte", "mapbox", "esri", "esri-topo", "nps",
"apple-iphoto",
      "skobbler", "opencyclemap", "osm-transport", "osm-public-transport",
      "osm-bbike", "osm-bbike-german")
   MyMap <- openmap(ul,lr, zoom = NULL, minNumTiles = 16L, type =
map_types[1] ,mergeTiles = TRUE)
   # now plot the layer and the backdrop
   par(mar = c(0,0,0,0))
      plot(MyMap)
      plot(spTransform(all_pcts_osm_sp, osm()), add = FALSE, lwd=.5,
border='blue')

	[[alternative HTML version deleted]]


From javajimburke at gmail.com  Wed Aug 26 00:44:33 2015
From: javajimburke at gmail.com (Jim Burke)
Date: Tue, 25 Aug 2015 17:44:33 -0500
Subject: [R] Text in Spatial Polygrams
Message-ID: <CALkjiFQewYO=i+=PnUtUMsb-a2632Vn6=bgMvuMvttNnyCqLJQ@mail.gmail.com>

I can do this fine for one polygram BUT a for-loop fails.The concept is
multiple lines within each polygon.  I am doing something sub-genius.

ONE POLYGON
   plot(all_pcts_osm_sp[i,], add = FALSE, lwd=.5, border='blue')
   hght <- strheight("Here")
   MyLines <- list(
      bquote( .(all_pcts_osm_sp$PCT[i]) ),
      bquote( .(all_pcts_osm_sp$First_Name[i]) ),
      bquote( .(all_pcts_osm_sp$Last_Name[i]) ),
      bquote( .(all_pcts_osm_sp$Phone) ))
   text( all_pcts_osm_sp[i,]@polygons[[ 1 ]]@labpt[[1]],
         all_pcts_osm_sp[i,]@polygons[[ 1 ]]@labpt[[2]] - (hght * 1.5 *
seq(length(MyLines))),
     do.call(expression, MyLines))

ALL POLYGONS JUST DO NOT WORK.  PUZZLED? Help me please. Also ultimate
target is an OpenStreet ("OSM") backdrop.

   tmp_sp_length <- length(all_pcts_osm_sp)
   i = 1
   for(i in 1:tmp_sp_length) {
      hght <- strheight("Here")
      MyLines <- list(
         bquote( .(all_pcts_osm_sp$PCT[i]) ),
         bquote( .(all_pcts_osm_sp$First_Name[i]) ),
         bquote( .(all_pcts_osm_sp$Last_Name[i]) ),
         bquote( .(all_pcts_osm_sp$Phone) ))
      text( all_pcts_osm_sp[i,]@polygons[[ 1 ]]@labpt[[1]],
         all_pcts_osm_sp[i,]@polygons[[ 1 ]]@labpt[[2]] - (hght * 1.5 *
       seq(length(MyLines))),
         do.call(expression, MyLines))
   }

All your comments, ideas, and thoughts are appreciated.
Thanks
Jim Burke

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Aug 26 08:33:08 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Aug 2015 06:33:08 +0000
Subject: [R] Fwd: ayuda- help me
In-Reply-To: <CAGSwdRDszqYyLW6SMps+kojHHqH2xsswpaoe_jbJHJZSPE0Grw@mail.gmail.com>
References: <CAGSwdRBZccp3tsp03Z0Rxvv1sXNv=8Gr8SR4cRGhSFiamcm3ew@mail.gmail.com>
	<CAGSwdRDszqYyLW6SMps+kojHHqH2xsswpaoe_jbJHJZSPE0Grw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3CFDF@SRVEXCHMBX.precheza.cz>

Hi

You probably need to look at package akima (function interp), together with ?image or ?contour.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paulo
> Fonseca
> Sent: Tuesday, August 25, 2015 11:02 PM
> To: r-help at r-project.org
> Subject: [R] Fwd: ayuda- help me
>
> Cordial saludo,
>
> Muy amablemente solicito su ayuda con la siguiente inquietud:
>
> Estoy tratando de interpolar datos de variables clim?ticas en R pero no
> he podido ustedes me podr?a colaborar con un instructivo que me gui?
> paso a paso como se hace , ya que el objeto es tener como resultado el
> mapa de precipitaci?n para un determinado a?o.
>
> De antemano agradezco su atenci?n y su colaboraci?n
>
> Atentamente
>
> Paulo Fonseca
>
>
> Best regard,
>
> I kindly request your assistance with the following concers:
>
> I'm trying to interpolate climatic data variables in R but I could not
> you could help me with intructions to guide me step by step how it is
> done, since the object is to result in the precipitation map for a
> given year.
>
> thaks in advance for your attention and colaboration.
>
> Sincerely
>
> Paulo Fonseca
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Aug 26 08:43:59 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Aug 2015 06:43:59 +0000
Subject: [R] Cusum and Ewma charts
In-Reply-To: <795082213.274492.1440524462201.JavaMail.yahoo@mail.yahoo.com>
References: <795082213.274492.1440524462201.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D03C@SRVEXCHMBX.precheza.cz>

Hi

If you really wanted to know the answer why on earth you did not query an internet? Asking ewma R gave me (among many other answers) as second hit package qcc, which seems to me does what you want.

You had to wait one hour for my answer. You would get it in seconds if you used internet search.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Babatunde Yakub via R-help
> Sent: Tuesday, August 25, 2015 7:41 PM
> To: r-help at r-project.org
> Subject: [R] Cusum and Ewma charts
>
> I want to know the codes for computing the optimal cusum and ewma
> chart. I will also like to know the R codes for plotting each of these
> categories. And if it is not present in R, I will like to know another
> statistical package that can help me deal with this situation.Thanks
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Aug 26 09:03:23 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Aug 2015 07:03:23 +0000
Subject: [R] Cusum and Ewma charts
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D03C@SRVEXCHMBX.precheza.cz>
References: <795082213.274492.1440524462201.JavaMail.yahoo@mail.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D03C@SRVEXCHMBX.precheza.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D06F@SRVEXCHMBX.precheza.cz>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL
> Petr
> Sent: Wednesday, August 26, 2015 8:44 AM
> To: Babatunde Yakub
> Cc: r-help at r-project.org
> Subject: Re: [R] Cusum and Ewma charts
>
> Hi
>
> If you really wanted to know the answer why on earth you did not query
> an internet? Asking ewma R gave me (among many other answers) as second
> hit package qcc, which seems to me does what you want.
>
> You had to wait one hour for my answer. You would get it in seconds if
> you used internet search.

Sorry, you waited one day and one hour. I did not noticed that it is Wednesday today :-).

Cheers
Petr

>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Babatunde Yakub via R-help
> > Sent: Tuesday, August 25, 2015 7:41 PM
> > To: r-help at r-project.org
> > Subject: [R] Cusum and Ewma charts
> >
> > I want to know the codes for computing the optimal cusum and ewma
> > chart. I will also like to know the R codes for plotting each of
> these
> > categories. And if it is not present in R, I will like to know
> another
> > statistical package that can help me deal with this situation.Thanks
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any
> reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Aug 26 09:56:05 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Aug 2015 07:56:05 +0000
Subject: [R] Cusum and Ewma charts
In-Reply-To: <9qwe3g4wa6fftow9tn3emgw3.1440574443942@email.android.com>
References: <9qwe3g4wa6fftow9tn3emgw3.1440574443942@email.android.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D12F@SRVEXCHMBX.precheza.cz>

Hi

Sorry that you consider my answer as an insult.

Anyway, from your post I did not find any clue you already had tried to find an answer. I had to look up myself and found qcc (BTW does it do what you want?) quite easily ("ewma R").

Cheers
Petr

> -----Original Message-----
> From: callyak4real [mailto:callyak4real at yahoo.com]
> Sent: Wednesday, August 26, 2015 9:39 AM
> To: PIKAL Petr
> Subject: RE: [R] Cusum and Ewma charts
>
> U think have not query the internet already. I couldn't find the answer
> on the internet, that was why I considered using help line believing
> someone who ones worked on this can give me a lead.....Thanks for
> insulting me. The last time I checked, this is also the INTERNET.
>
> On Aug 26, 2015 8:03 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > > PIKAL Petr
> > > Sent: Wednesday, August 26, 2015 8:44 AM
> > > To: Babatunde Yakub
> > > Cc: r-help at r-project.org
> > > Subject: Re: [R] Cusum and Ewma charts
> > >
> > > Hi
> > >
> > > If you really wanted to know the answer why on earth you did not
> > > query an internet? Asking ewma R gave me (among many other answers)
> > > as second hit package qcc, which seems to me does what you want.
> > >
> > > You had to wait one hour for my answer. You would get it in seconds
> > > if you used internet search.
> >
> > Sorry, you waited one day and one hour. I did not noticed that it is
> Wednesday today :-).
> >
> > Cheers
> > Petr
> >
> > >
> > > Cheers
> > > Petr
> > >
> > > > -----Original Message-----
> > > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > > > Babatunde Yakub via R-help
> > > > Sent: Tuesday, August 25, 2015 7:41 PM
> > > > To: r-help at r-project.org
> > > > Subject: [R] Cusum and Ewma charts
> > > >
> > > > I want to know the codes for computing the optimal cusum and ewma
> > > > chart. I will also like to know the R codes for plotting each of
> > > these
> > > > categories. And if it is not present in R, I will like to know
> > > another
> > > > statistical package that can help me deal with this
> > > > situation.Thanks
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-
> project.org/posting-
> > > > guide.html and provide commented, minimal, self-contained,
> > > > reproducible code.
> > >
> > > ________________________________
> > > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> > > jsou ur?eny pouze jeho adres?t?m.
> > > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
> > > jeho kopie vyma?te ze sv?ho syst?mu.
> > > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
> tento
> > > email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> > > modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> > >
> > > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> > > p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
> > > nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> > > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> > > zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> > > adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> > > p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
> > > zastoupen? zn?m?.
> > >
> > > This e-mail and any documents attached to it may be confidential
> and
> > > are intended only for its intended recipients.
> > > If you received this e-mail by mistake, please immediately inform
> > > its sender. Delete the contents of this e-mail with all attachments
> > > and its copies from your system.
> > > If you are not the intended recipient of this e-mail, you are not
> > > authorized to use, disseminate, copy or disclose this e-mail in any
> > > manner.
> > > The sender of this e-mail shall not be liable fo

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Wed Aug 26 10:33:08 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 26 Aug 2015 10:33:08 +0200
Subject: [R] nls model parameter compare?
In-Reply-To: <CAJ7mryKkAsgqNps4G7UYBu=FBM6BZa5mFUfhzzoNogGjDuUT2A@mail.gmail.com>
References: <CAJ7mryKkAsgqNps4G7UYBu=FBM6BZa5mFUfhzzoNogGjDuUT2A@mail.gmail.com>
Message-ID: <F95F0EFF-F767-43EE-8AF2-D2DDBF3089B5@gmail.com>


On 26 Aug 2015, at 00:34 , Jianling Fan <fanjianling at gmail.com> wrote:

> Hello everyone,
> 
> I am doing nonlinear regression using a same sigmoidal model for
> different treatments. for each treatment, I got a set of estimated
> parameters (a1, b1, c1 for treatment 1; a2, b2, c2 for treatment 2;
> a3, b3, c3 for treatment 3). And I want to compare these parameters
> for different treatments to see is there any differences? does
> estimated parameter for treatment i different from other treatments?
> 
> How can I do this analysis please?


Notwithstanding possibly well-founded snide remarks from Bert and Rolf...

If we take this as a purely technical question, it might be helpful to notice that you can do stuff like this:

> plot(y~x,data=dd)
> y1 <- rnorm(10,exp(0.1*x),.1)
> y2 <- rnorm(10,exp(0.2*x),.1)
> y3 <- rnorm(10,exp(0.3*x),.1)
> dd <- data.frame(x=c(x,x,x), y=c(y1,y2,y3), g = factor(rep(1:3, each=10)))
> plot(y~x, pch=g, data=dd)

> nls(y ~ exp(a[g]*x), data=dd, start=list(a=c(.1,.2,.3)))
Nonlinear regression model
  model: y ~ exp(a[g] * x)
   data: dd
    a1     a2     a3 
0.1017 0.2011 0.2997 
 residual sum-of-squares: 0.2578

Number of iterations to convergence: 2 
Achieved convergence tolerance: 2.678e-06

> m1 <- nls(y ~ exp(a[g]*x), data=dd, start=list(a=c(.1,.2,.3)))
> m2 <- nls(y ~ exp(a*x), data=dd, start=list(a=.2))
> anova(m1,m2)
Analysis of Variance Table

Model 1: y ~ exp(a[g] * x)
Model 2: y ~ exp(a * x)
  Res.Df Res.Sum Sq Df  Sum Sq F value    Pr(>F)    
1     27      0.258                                 
2     29    315.326 -2 -315.07   16498 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

I.e.:

1) The principle is to formulate your three separate models as a single model for _all_ data, with parameters depending on group, then reduce the model by letting one or more of the parameter sets being a single parameter.

2) The []-notation for group-dependent parameters in nls() is useful and rather easily overlooked.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wewolski at gmail.com  Wed Aug 26 11:46:13 2015
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 26 Aug 2015 11:46:13 +0200
Subject: [R] compiling Rmd - can't find tex file....
Message-ID: <CAAjnpdg0gV473vF4Hp5p8HJnmb0BKeEkcosuB3xRLdg-GX_EWw@mail.gmail.com>

I am using from within R-studio and the .Rmd file builds nicely.

However, when I try to compile the fiel using :

knit2pdf( "specL.Rmd", output=file.path("res.12345","specL.pdf") )
I am getting tex errors (see below). When I wan't to check what's wrong I
can't find the tex file.
Any ideas?

Thank you


PS: Errors:

 |..............................................................   |  95%

label: writepepProt

  |.................................................................| 100%

  ordinary text without R code



*output file: res.12345/specL.pdf*


*Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,
: *

*  Running 'texi2dvi' on 'specL.pdf' failed.*

*LaTeX errors:*

*! Missing $ inserted.*

*<inserted text> *

*                $*

*<to be read again> *

*                   _*

*! Missing $ inserted.*

*<inserted text> *

*                $*

*<to be read again> *

*                   \par *

*! You can't use `macro parameter character #' in horizontal mode.*

*l.15 #*






-- 
Witold Eryk Wolski

	[[alternative HTML version deleted]]


From hwborchers at gmail.com  Wed Aug 26 12:22:01 2015
From: hwborchers at gmail.com (Hans W Borchers)
Date: Wed, 26 Aug 2015 12:22:01 +0200
Subject: [R] lsqlin in R package pracma
Message-ID: <CAML4n3OeKiQBQVPCz-OdmSTdWwG766FeUvuwRJmBzdaX6FMDtw@mail.gmail.com>

On Mon Aug 24 Wang, Xue, Ph.D. Wang.Xue at mayo.edu wrote
> I am looking for a R version of Matlab function lsqlin. I came across
> R pracma package which has a lsqlin function. Compared with Matlab lsqlin,
> the R version does not allow inequality constraints.
> I am wondering if this functionality will be available in future. And also
> like to get your opinion on which R package/function is the best for
solving
> least square minimization problem with linear inequality constraints.
> Thanks very much for your time and attention!


Solving (linear) least-squares problems with linear inequality constraints
is more difficult then one would expect. Inspecting the MATLAB code reveals
that it employs advanced methods such as active-set (linear inequality
constraints) and interior-point (for bounds constraints).

Function nlsLM() in package *minpack.lm* supports bound constraints if that
is sufficient for you. The same is true for *nlmrt*. Convex optimization
might be a promising approach for linear inequality constraints, but there
is no easy-to-handle convex solver in R at this moment.

So the most straightforward way would be to use constrOptim(), that is
optim with linear constraints. It requires a reasonable starting point, and
keeping your fingers crossed that you are able to find such a point in the
interior of the feasible region.

I someone wants to try: Here is the example from the MATLAB "lsqlin" page:

    C <- matrix(c(
        0.9501,   0.7620,   0.6153,   0.4057,
        0.2311,   0.4564,   0.7919,   0.9354,
        0.6068,   0.0185,   0.9218,   0.9169,
        0.4859,   0.8214,   0.7382,   0.4102,
        0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
    d <- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
    A <- matrix(c(
        0.2027,   0.2721,   0.7467,   0.4659,
        0.1987,   0.1988,   0.4450,   0.4186,
        0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
    b <- c(0.5251, 0.2026, 0.6721)

The least-square function to be minimized is  ||C x - d||_2 , and the
constraints are  A x <= b :

    f <- function(x) sum((C %*% x - d)^2)

The solution x0 returned by MATLAB has a minimum of  f(x0) = 0.01759204 .
This point does not lie in the interior and cannot be used for a start.

	[[alternative HTML version deleted]]


From Wang.Xue at mayo.edu  Wed Aug 26 14:18:14 2015
From: Wang.Xue at mayo.edu (Wang, Xue, Ph.D.)
Date: Wed, 26 Aug 2015 12:18:14 +0000
Subject: [R] lsqlin in R package pracma
In-Reply-To: <CAML4n3OeKiQBQVPCz-OdmSTdWwG766FeUvuwRJmBzdaX6FMDtw@mail.gmail.com>
References: <CAML4n3OeKiQBQVPCz-OdmSTdWwG766FeUvuwRJmBzdaX6FMDtw@mail.gmail.com>
Message-ID: <2f3a88$19rlfg@ironport10.mayo.edu>

Hi Hans,

Thanks for your comments!

I need the linear inequality constraints so nlsLM is not a candidate. 

I am also looking at the functions mma and slsqp in R package nloptr. Compared with constrOptim(), which approach would you recommend?

Thanks,


Xue 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Hans W Borchers
Sent: Wednesday, August 26, 2015 6:22 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] lsqlin in R package pracma

On Mon Aug 24 Wang, Xue, Ph.D. Wang.Xue at mayo.edu wrote
> I am looking for a R version of Matlab function lsqlin. I came across 
> R pracma package which has a lsqlin function. Compared with Matlab 
> lsqlin, the R version does not allow inequality constraints.
> I am wondering if this functionality will be available in future. And 
> also like to get your opinion on which R package/function is the best 
> for
solving
> least square minimization problem with linear inequality constraints.
> Thanks very much for your time and attention!


Solving (linear) least-squares problems with linear inequality constraints is more difficult then one would expect. Inspecting the MATLAB code reveals that it employs advanced methods such as active-set (linear inequality
constraints) and interior-point (for bounds constraints).

Function nlsLM() in package *minpack.lm* supports bound constraints if that is sufficient for you. The same is true for *nlmrt*. Convex optimization might be a promising approach for linear inequality constraints, but there is no easy-to-handle convex solver in R at this moment.

So the most straightforward way would be to use constrOptim(), that is optim with linear constraints. It requires a reasonable starting point, and keeping your fingers crossed that you are able to find such a point in the interior of the feasible region.

I someone wants to try: Here is the example from the MATLAB "lsqlin" page:

    C <- matrix(c(
        0.9501,   0.7620,   0.6153,   0.4057,
        0.2311,   0.4564,   0.7919,   0.9354,
        0.6068,   0.0185,   0.9218,   0.9169,
        0.4859,   0.8214,   0.7382,   0.4102,
        0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
    d <- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
    A <- matrix(c(
        0.2027,   0.2721,   0.7467,   0.4659,
        0.1987,   0.1988,   0.4450,   0.4186,
        0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
    b <- c(0.5251, 0.2026, 0.6721)

The least-square function to be minimized is  ||C x - d||_2 , and the constraints are  A x <= b :

    f <- function(x) sum((C %*% x - d)^2)

The solution x0 returned by MATLAB has a minimum of  f(x0) = 0.01759204 .
This point does not lie in the interior and cannot be used for a start.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hwborchers at gmail.com  Wed Aug 26 16:10:53 2015
From: hwborchers at gmail.com (Hans W Borchers)
Date: Wed, 26 Aug 2015 16:10:53 +0200
Subject: [R] lsqlin in R package pracma
In-Reply-To: <2f3a88$19rlff@ironport10.mayo.edu>
References: <CAML4n3OeKiQBQVPCz-OdmSTdWwG766FeUvuwRJmBzdaX6FMDtw@mail.gmail.com>
	<2f3a88$19rlff@ironport10.mayo.edu>
Message-ID: <CAML4n3O1+__MzeD=Rq97zoo=Xdv0hok+RJcjRWZeg1vjQw7OLA@mail.gmail.com>

I am a strong advocate of the *nloptr* package; and "sequential
quadratic programming", i.e. slsqp(), should be a good choice for
least-squares problems. Note that you still have to provide a starting
point.

BUT: this point does not need to lie in the interior of the feasible region.
So you can start with a point that solves the problem on the boundary
(with lsqlin()) and then continue with slsqp().

For the example mentioned above, it looks like this:

    library(pracma)
    x0 <- lsqlin(C, d, A, b)  # starting point on the boundary

    library(nloptr)
    f <- function(x) sum((C %*% x - d)^2)  # objective
    hin <- function(x) -A %*% x + b        # constraint, w/  A x >= 0 !

    slsqp(x0, f, hin = hin)
    # $par
    # [1]  0.1298620 -0.5756944  0.4251035  0.2438448
    #
    # $value
    # [1] 0.01758538
    # ...

The solution is slightly better than the MATLAB one or the constrOptim one.
Of course, all these can be improved by changing some optional parameters.


On Wed, Aug 26, 2015 at 2:18 PM, Wang, Xue, Ph.D. <Wang.Xue at mayo.edu> wrote:
> Hi Hans,
>
> Thanks for your comments!
>
> I need the linear inequality constraints so nlsLM is not a candidate.
>
> I am also looking at the functions mma and slsqp in R package nloptr. Compared with constrOptim(), which approach would you recommend?
>
> Thanks,
>
> Xue


From arun.kumar8 at safexpress.com  Wed Aug 26 10:30:32 2015
From: arun.kumar8 at safexpress.com (Arun84441)
Date: Wed, 26 Aug 2015 01:30:32 -0700 (PDT)
Subject: [R] Convert character Variables to numeric
Message-ID: <1440577832731-4711518.post@n4.nabble.com>

I have imported the csv file having 398800 obs of 30 variables. There is a
variable "TOTALFRT" which is showing as character in R environment. I am
trying to convert it to numeric by using as.numeric function.
Wherein function is converting character to numeric but with an error
message "Warning message:
NAs introduced by coercion", it omitted 388800 entries. Hence I am unable to
perform calculation.

Is there anyway by which I can convert NAs to numeric??

Below is the code I used for conversion :-

Mac<-read.csv("July'15.csv", header = TRUE)
Book=as.character(Mac$TOTALFRT)
V = as.numeric(Book)







--
View this message in context: http://r.789695.n4.nabble.com/Convert-character-Variables-to-numeric-tp4711518.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Wed Aug 26 17:05:21 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Aug 2015 15:05:21 +0000
Subject: [R] folder selection and aggregation
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D214@SRVEXCHMBX.precheza.cz>

Dear all

I attached file whose basic structure is

Z:\\AAAAAAA\\BBBBB\\XXXXXX\\CCCCCC\\DDDDD\\....

I would like to select value from first column after let say third "\\" (but sometimes it can be second or first) and find out all permissions located in second column regarding this folder.

So far I found this way:

ctvrta<-sapply(strsplit(writelist[,1],"\\", fixed=T),"[", 4)
ctvrta <- addNA(as.factor(ctvrta))
aggregate(writelist[,2], list(ctvrta), function(x) unique(as.character(x)))

structure(list(Group.1 = structure(1:4, .Label = c("Kov??ov?",
"Laborato? stavebn?ch hmot - Vesel?", "Valenta-Vidl?kov?", NA
), class = "factor"), x = structure(list(`1` = c("Administrators",
" PRECHEZA\\FA-KU-GLB-RW", " PRECHEZA\\FA-KU-TEC-GLB-RW", " PRECHEZA\\FA-KU-TEC-VedouciVyzkumu-RW"
), `2` = c("Administrators", " PRECHEZA\\FA-KU-GLB-RW", " PRECHEZA\\FA-KU-TEC-GLB-RW",
" PRECHEZA\\FA-KU-TEC-VedouciVyzkumu-RW", " PRECHEZA\\LabSTHM"
), `3` = c("Administrators", " PRECHEZA\\FA-KU-GLB-RW", " PRECHEZA\\FA-KU-TEC-GLB-RW",
" PRECHEZA\\FA-KU-TEC-VedouciVyzkumu-RW"), `4` = c("Administrators",
" PRECHEZA\\FA-KU-GLB-RW", " PRECHEZA\\FA-KU-TEC-GLB-RW", " PRECHEZA\\FA-KU-TEC-VedouciVyzkumu-RW"
)), .Names = c("1", "2", "3", "4"))), .Names = c("Group.1", "x"
), row.names = c(NA, -4L), class = "data.frame")

If there are same permissions for all folders I could melt resulting data.frame using reshape2 but if there are different number of permissions, the second column is list. I basically know how to separate items of those lists using rep, length and unlist but maybe somebody more capable than myself can come with more elegant solution.

Best regards
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: writelist.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150826/e11ef898/attachment-0001.txt>

From solano at europrofessionals.org  Wed Aug 26 10:02:44 2015
From: solano at europrofessionals.org (GloriaSolano)
Date: Wed, 26 Aug 2015 01:02:44 -0700 (PDT)
Subject: [R] TSclust multivariate time series clustering
Message-ID: <1440576164201-4711517.post@n4.nabble.com>

Hello,

I am trying to cluster multivariate time series with the R package TSclust.
I have a dataset of 45 companies with 10 years information on 6 variables. I
understand from the TSclust package manual that the first step is choosing
the dissimilarity meassure we are going to use. However I cannot find a
function in TSclust that gives the dissimilarity between multivariate time
series? Could you please let me know which would be the right function? 
If there is a function, could you please let me know which form should have
the input data for this function?
Thanks!
Gloria



--
View this message in context: http://r.789695.n4.nabble.com/TSclust-multivariate-time-series-clustering-tp4711517.html
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Wed Aug 26 22:33:28 2015
From: jholtman at gmail.com (jim holtman)
Date: Wed, 26 Aug 2015 16:33:28 -0400
Subject: [R] Convert character Variables to numeric
In-Reply-To: <1440577832731-4711518.post@n4.nabble.com>
References: <1440577832731-4711518.post@n4.nabble.com>
Message-ID: <CAAxdm-74sSAFyz+_EDb98-qpfNT7H56zbihPX7DbAWBQ-E_CBA@mail.gmail.com>

Please provide a sample of the data that you are trying to convert.  BTW
does it have commas in numeric values, or what else is strange about the
data.  The error message is very clear in the column of data that you are
trying to convert is not numeric.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Aug 26, 2015 at 4:30 AM, Arun84441 <arun.kumar8 at safexpress.com>
wrote:

> I have imported the csv file having 398800 obs of 30 variables. There is a
> variable "TOTALFRT" which is showing as character in R environment. I am
> trying to convert it to numeric by using as.numeric function.
> Wherein function is converting character to numeric but with an error
> message "Warning message:
> NAs introduced by coercion", it omitted 388800 entries. Hence I am unable
> to
> perform calculation.
>
> Is there anyway by which I can convert NAs to numeric??
>
> Below is the code I used for conversion :-
>
> Mac<-read.csv("July'15.csv", header = TRUE)
> Book=as.character(Mac$TOTALFRT)
> V = as.numeric(Book)
>
>
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Convert-character-Variables-to-numeric-tp4711518.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Aug 26 22:52:25 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 26 Aug 2015 13:52:25 -0700
Subject: [R] Convert character Variables to numeric
In-Reply-To: <CAAxdm-74sSAFyz+_EDb98-qpfNT7H56zbihPX7DbAWBQ-E_CBA@mail.gmail.com>
References: <1440577832731-4711518.post@n4.nabble.com>
	<CAAxdm-74sSAFyz+_EDb98-qpfNT7H56zbihPX7DbAWBQ-E_CBA@mail.gmail.com>
Message-ID: <9C3E19C5-CB8F-4B4D-AD22-3B491DF97980@dcn.davis.CA.us>

I agree that having a few (5-20 perhaps) rows of the data is essential to give you appropriate help. Be warned that files with extension ".CSV" (or must others as well) don't make it through the mailing list filters, so be sure to read the Posting Guide and either change the name of the file so it ends in ".txt" or use the dput function on data after you have read it in [1] and just include that in your email not as an attachment.

Note that adding certain arguments to the read.csv function call can make it do you don't have to convert from factor to character:

Mac <- read.csv("July'15.csv", header = TRUE, as.is=TRUE)

or

Mac <- read.csv("July'15.csv", header = TRUE, stringsAsFactors=FALSE)

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 26, 2015 1:33:28 PM PDT, jim holtman <jholtman at gmail.com> wrote:
>Please provide a sample of the data that you are trying to convert. 
>BTW
>does it have commas in numeric values, or what else is strange about
>the
>data.  The error message is very clear in the column of data that you
>are
>trying to convert is not numeric.
>
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>On Wed, Aug 26, 2015 at 4:30 AM, Arun84441 <arun.kumar8 at safexpress.com>
>wrote:
>
>> I have imported the csv file having 398800 obs of 30 variables. There
>is a
>> variable "TOTALFRT" which is showing as character in R environment. I
>am
>> trying to convert it to numeric by using as.numeric function.
>> Wherein function is converting character to numeric but with an error
>> message "Warning message:
>> NAs introduced by coercion", it omitted 388800 entries. Hence I am
>unable
>> to
>> perform calculation.
>>
>> Is there anyway by which I can convert NAs to numeric??
>>
>> Below is the code I used for conversion :-
>>
>> Mac<-read.csv("July'15.csv", header = TRUE)
>> Book=as.character(Mac$TOTALFRT)
>> V = as.numeric(Book)
>>
>>
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>>
>http://r.789695.n4.nabble.com/Convert-character-Variables-to-numeric-tp4711518.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Wed Aug 26 22:55:40 2015
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 26 Aug 2015 13:55:40 -0700
Subject: [R] TSclust multivariate time series clustering
In-Reply-To: <1440576164201-4711517.post@n4.nabble.com>
References: <1440576164201-4711517.post@n4.nabble.com>
Message-ID: <25A23AB5-4015-4D3F-8069-DD1A5C0AC981@noaa.gov>

I suggest you look at this paper:

http://www.jstatsoft.org/v62/i01/paper

-Roy

> On Aug 26, 2015, at 1:02 AM, GloriaSolano <solano at europrofessionals.org> wrote:
> 
> Hello,
> 
> I am trying to cluster multivariate time series with the R package TSclust.
> I have a dataset of 45 companies with 10 years information on 6 variables. I
> understand from the TSclust package manual that the first step is choosing
> the dissimilarity meassure we are going to use. However I cannot find a
> function in TSclust that gives the dissimilarity between multivariate time
> series? Could you please let me know which would be the right function? 
> If there is a function, could you please let me know which form should have
> the input data for this function?
> Thanks!
> Gloria
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/TSclust-multivariate-time-series-clustering-tp4711517.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From macqueen1 at llnl.gov  Thu Aug 27 02:25:27 2015
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 27 Aug 2015 00:25:27 +0000
Subject: [R] Convert character Variables to numeric
In-Reply-To: <1440577832731-4711518.post@n4.nabble.com>
References: <1440577832731-4711518.post@n4.nabble.com>
Message-ID: <D203A561.1368D2%macqueen1@llnl.gov>

In addition to what Jim and Jeff said, I would suggest trying this:

tmp <- is.na(V)
## then
head(Mac$TOTALFRT[tmp])
## or
head( V[tmp] )

This will show you the first few rows of the values which you think should
be numeric but are not.

Hopefully, you will be able to see why they are not numeric. Perhaps, as
Jim suggested, they contain commas, which are not considered numeric.

I?d also suggest
  Mac <- read.csv("July'15.csv", header = TRUE, stringsAsFactors=FALSE)
While you are trying to solve this problem. This is because you said
TOTALFRT is showing as character, in which case there should be no need to
use as.character(Mac$TOTALFRT).

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/26/15, 1:30 AM, "R-help on behalf of Arun84441"
<r-help-bounces at r-project.org on behalf of arun.kumar8 at safexpress.com>
wrote:

>I have imported the csv file having 398800 obs of 30 variables. There is a
>variable "TOTALFRT" which is showing as character in R environment. I am
>trying to convert it to numeric by using as.numeric function.
>Wherein function is converting character to numeric but with an error
>message "Warning message:
>NAs introduced by coercion", it omitted 388800 entries. Hence I am unable
>to
>perform calculation.
>
>Is there anyway by which I can convert NAs to numeric??
>
>Below is the code I used for conversion :-
>
>Mac<-read.csv("July'15.csv", header = TRUE)
>Book=as.character(Mac$TOTALFRT)
>V = as.numeric(Book)
>
>
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Convert-character-Variables-to-numeric-tp471
>1518.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From leptostracan at yahoo.com  Thu Aug 27 05:41:01 2015
From: leptostracan at yahoo.com (Christine Lee)
Date: Wed, 26 Aug 2015 20:41:01 -0700
Subject: [R] xyplot colour points and layout
Message-ID: <1440646861.27915.YahooMailBasic@web120802.mail.ne1.yahoo.com>

Dear All,

I have tried to plot graphs of one row of four figures for each station.  In each graph, black points indicate data in the year of 2002, denoted as Y2002, whereas grey points indicate data in the year of 2014, denoted as Y2014.  I ended up with 2x2 plots with all data points in black.  Can anyone find out what has gone wrong by any chance please?

Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L, 
2L, 4L, 12L, 6L, 15L, 14L, 3L, 6L, 1L, 16L, 5L, 11L, 8L, 4L, 
10L, 13L, 6L, 1L, 16L, 5L, 11L, 8L, 4L, 10L, 13L, 6L, 1L, 16L, 
5L, 11L, 8L, 4L, 10L, 13L, 11L, 8L, 4L, 10L, 13L), .Label = c("1/10", 
"1/11", "11/11", "12/11", "13/10", "19/9", "2/10", "2/11", "20/9", 
"26/11", "29/10", "29/11", "30/11", "31/10", "4/10", "6/10"), class = "factor"), 
    Year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Y2002", "Y2014"), class = "factor"), 
    Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
    2L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 4L, 4L, 4L, 4L, 4L), .Label = c("E", "F", "H", "I"
    ), class = "factor"), Abun = c(3.42, 1.33, 3.67, 3.67, 3.92, 
    2.17, 2.5, 1.67, 6.33, 0.67, 1, 1, 1.33, 2.08, 0, 0, 0.33, 
    0.08, 0.08, 0, 0.5, 0.17, 0.67, 0.67, 0, 1, 0.58, 1.5, 2.67, 
    0.67, 1.33, 3, 0.58, 1.17, 1.25, 0.75, 1.25, 1.75, 0.92, 
    1.5, 0.83, 0.75, 2.33, 0.67, 1.33, 1.58), Date1 = structure(c(16697, 
    16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768, 
    16697, 16712, 16739, 16750, 16697, 16709, 16714, 16721, 16737, 
    16741, 16751, 16765, 16769, 16697, 16709, 16714, 16721, 16737, 
    16741, 16751, 16765, 16769, 16697, 16709, 16714, 16721, 16737, 
    16741, 16751, 16765, 16769, 16737, 16741, 16751, 16765, 16769
    ), class = "Date")), .Names = c("Date", "Year", "Station", 
"Abun", "Date1"), row.names = c(NA, -46L), class = "data.frame")
Raw$Date1<-as.Date(Raw$Date,"%d/%m")
library(lattice)
par(mfrow=c(1,4))
culr<-ifelse(Raw$Year=="Y2002","Black","Grey")
xyplot(Abun~Date1|Station,Raw,type="p",xlab=list("Month",cex=1.5),ylab=list("Abundance",cex=1.5),cex=2,pch=16,col=culr,strip=strip.custom(bg='white'))


Many thanks.

Regards,
Christine


From rhelp10 at gmail.com  Wed Aug 26 23:05:39 2015
From: rhelp10 at gmail.com (DJ L)
Date: Wed, 26 Aug 2015 17:05:39 -0400
Subject: [R] Plotting wind direction as arrows with precipitation
In-Reply-To: <22A30A0E92F.00000328jrkrideau@inbox.com>
References: <cagphrqrbe91prqxw2e3sapybs_fp4zovxixy7ystbmg-cje5-a@mail.gmail.com>
	<2146629a792.000000e5jrkrideau@inbox.com>
	<CAGxFJbTSdjCjeLnzYTrCbYwQhcC6zbH9iVYc38foHmdvrY5ywA@mail.gmail.com>
	<22A30A0E92F.00000328jrkrideau@inbox.com>
Message-ID: <CAGphrqr96aRrd00YzbfY+ct2CpdK64L_pJjzGDeMzt6_2LAB1A@mail.gmail.com>

Hello All,

Thank you so much for replying. Sorry I have been out of contact, I was in
the field with limited internet collecting more data. I will read over the
suggestions and will provide feedback or more questions. Looks like I have
some looking up to do on the packages suggested.

Also something I should have included was a general picture idea. See
picture attached of the goal in mind. I was able to create a rose diagram
with the wind data, but that is more of a summary vs time series showing
the direction and time.

I have also separated the degrees into 8 categories, to simply things. Rose
diagram, also attached.

Thank you again and talk soon!

On Tue, Aug 11, 2015 at 12:52 PM, John Kane <jrkrideau at inbox.com> wrote:

> Thanks Bert,
> I think that arrow()  would do what the OP needs. The main problem would
> be calculating the angles properly if I understand the issue. Still there
> cannot be "that" many points on a compass, can there?
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: bgunter.4567 at gmail.com
> > Sent: Tue, 11 Aug 2015 07:55:55 -0700
> > To: jrkrideau at inbox.com
> > Subject: Re: [R] Plotting wind direction as arrows with precipitation
> >
> > ... don't know if this will help, but grid graphics, which is the
> > graphics engine for both trellis and ggplot, has a basic arrow()
> > function. Trellis's provides an interface to it with the
> > panel.arrows() panel function. I suspect ggplot has something similar,
> > but as I don't use it, I don't know for sure.
> >
> > There is also an arrows() function in the basic (non-grid) graphics
> > engine, but this is probably irrelevant for your needs.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> >    -- Clifford Stoll
> >
> >
> > On Tue, Aug 11, 2015 at 7:16 AM, John Kane <jrkrideau at inbox.com> wrote:
> >> Hi,
> >> Good example and data.  Thanks.
> >>
> >> Here are a couple of approaches that may help.
> >> I tend to use a lot of what I tend to think of as the ggplot family of
> >> associated so you may need to install a couple packages. I used
> >> lubridate to transform your character dates to  POSIXct. Jeff N's code
> >> does exatly the same in base R. so you don't really need the lubridate
> >> package.
> >>
> >>  I changed the data set name to dat1 and transformed the column names to
> >> lower case just for my convenience.  Data is now in dput() form. See
> >> ?dput() for more information. It is the preferred way to share data on
> >> R-help
> >>
> >> Given what appears to be vastly different y-scales for rainfall and wind
> >> direction it struck me that it might be better to have the data in two
> >> plots so I included that option.
> >>
> >> I am not really sure how to get the arrows you want. You may be able to
> >> do it using scale_shape_manual  but I am not sure if the required
> >> symbols are available.
> >>
> >> You may have to manually draw them. See
>
> http://stackoverflow.com/questions/3421331/example-needed-using-arrow-with-ggplot2
> >> for how to draw an arrow.
> >>
> >> John Kane
> >> Kingston ON Canada
> >> ##============Start code==============
> >> library(ggplot2)
> >> library(reshape2)
> >> library(lubridate)
> >> library(gridExtra)
> >>
> >> dat1  <-  structure(list(deal1 = c("10/22/2012 0:00", "10/22/2012 0:15",
> >> "10/22/2012 0:30", "10/22/2012 0:45", "10/22/2012 1:00", "10/22/2012
> >> 1:15"
> >> ), rainfall_cm = c(0L, 0L, 0L, 0L, 0L, 0L), wind_direction1 = c(296L,
> >> 317L, 323L, 323L, 326L, 326L), wind_direction2 = c("W", "NW",
> >> "NW", "NW", "NW", "NW")), .Names = c("deal1", "rainfall_cm",
> >> "wind_direction1", "wind_direction2"), class = "data.frame", row.names =
> >> c(NA,
> >> -6L))
> >>
> >>
> >> dat1$deal1 <- mdy_hm(dat1$deal1) # Lazy man's equivalent of Jeff N's
> >> Sandy$Deal1 <- as.POSIXct( Sandy$Deal1, format="%m/%d/%Y %H:%M")
> >>
> >> dat2  <-  melt(dat1[ , 1:3], id.var = "deal1")  # use reshape to
> >> rearrange data.
> >> p  <-  ggplot(dat2, aes(deal1, value, colour = variable) )+ geom_point()
> >> p
> >>
> >> ## possible option
> >> g1  <-  ggplot(dat1, aes(deal1,  wind_direction1)) + geom_point() +
> >> theme(axis.title.x=element_blank())
> >> g2  <-  ggplot(dat1, aes(deal1, rainfall_cm ) )+ geom_point()
> >>
> >> grid.arrange( g1, g2, ncol=1)
> >>
> >> ##===========end code==================
> >>
> >>
> >>> -----Original Message-----
> >>> From: rhelp10 at gmail.com
> >>> Sent: Mon, 10 Aug 2015 00:05:27 -0400
> >>> To: r-help at r-project.org
> >>> Subject: [R] Plotting wind direction as arrows with precipitation
> >>>
> >>> Hello R users!
> >>>
> >>> I am trying to create a time series in R with two variables,
> >>> precipitation
> >>> and wind direction vs Date/Time.
> >>>
> >>> I am looking for suggestions and maybe even sample code.
> >>>
> >>> My workbook is called "Sandy" and has columns with Date/Time,
> >>> Raindall_cm,
> >>> Wind Direction in both degree format (0-359) and in character form (N,
> >>> NW,
> >>> S, SW, SE, E, NE, NW).
> >>>
> >>> I have done some reading for it on stackoverflow and other sites but
> >>> not
> >>> making head way.
> >>>
> >>> I will be graphing with ggplot most likely and am a beginner in R, self
> >>> taught from books and online resources.
> >>>
> >>> This is the code I have and a small peak into the data.
> >>>
> >>> Sandy<-read.csv("Sandy.csv", header=TRUE,
> >>> sep=",",stringsAsFactors=FALSE)
> >>>> head(Sandy)
> >>>       Deal1     Rainfall_cm    Wind_Direction1 Wind_Direction2
> >>> 1 10/22/2012 0:00           0        296         W
> >>> 2 10/22/2012 0:15           0        317        NW
> >>> 3 10/22/2012 0:30           0        323        NW
> >>> 4 10/22/2012 0:45           0        323        NW
> >>> 5 10/22/2012 1:00           0        326        NW
> >>> 6 10/22/2012 1:15           0        326        NW
> >>>
> >>>> class(Sandy)
> >>> [1] "data.frame"
> >>>
> >>>> str(Sandy)
> >>> 'data.frame':   1832 obs. of  4 variables:
> >>>  $ Deal1         : chr  "10/22/2012 0:00" "10/22/2012 0:15" "10/22/2012
> >>> 0:30" "10/22/2012 0:45" ...
> >>>  $ Rainfall_cm   : num  0 0 0 0 0 0 0 0 0 0 ...
> >>>
> >>>  $ Wind_Direction: num 296 317  323   323  326  326
> >>>
> >>>  $ Wind_Direction: chr  "W" "NW" "NW" "NW" ...
> >>>
> >>>> require(ggplot2)
> >>> Loading required package: ggplot2
> >>>
> >>> # this graph does the precipitation vs time graph, but not the wind
> >>>
> >>>> ggplot(Sandy, aes(x = Deal1, y = Rainfall_cm, group = 1)) +
> >>> geom_line(stat = "identity")
> >>>
> >>>
> >>> Ideally I want it to have the precipitation graph vs time, then wind vs
> >>> time on the same graph. I would like the wind direction to be arrows
> >>> pointing in the designated direction (i.e. North points north).
> >>>
> >>> Thank you!
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ____________________________________________________________
> >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> >> your desktop!
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example.png
Type: image/png
Size: 151219 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150826/337e567c/attachment.png>

From NordlDJ at dshs.wa.gov  Wed Aug 26 23:35:37 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 26 Aug 2015 21:35:37 +0000
Subject: [R] Convert character Variables to numeric
In-Reply-To: <9C3E19C5-CB8F-4B4D-AD22-3B491DF97980@dcn.davis.CA.us>
References: <1440577832731-4711518.post@n4.nabble.com>
	<CAAxdm-74sSAFyz+_EDb98-qpfNT7H56zbihPX7DbAWBQ-E_CBA@mail.gmail.com>
	<9C3E19C5-CB8F-4B4D-AD22-3B491DF97980@dcn.davis.CA.us>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662ED8566A@WAXMXOLYMB025.WAX.wa.lcl>

Or to provide data without using an attachment,  use dput()  and cut-n-paste the result into an email.

dput(Mac[1:10,])



Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Newmiller
Sent: Wednesday, August 26, 2015 1:52 PM
To: jim holtman; Arun84441
Cc: R mailing list
Subject: Re: [R] Convert character Variables to numeric

I agree that having a few (5-20 perhaps) rows of the data is essential to give you appropriate help. Be warned that files with extension ".CSV" (or must others as well) don't make it through the mailing list filters, so be sure to read the Posting Guide and either change the name of the file so it ends in ".txt" or use the dput function on data after you have read it in [1] and just include that in your email not as an attachment.

Note that adding certain arguments to the read.csv function call can make it do you don't have to convert from factor to character:

Mac <- read.csv("July'15.csv", header = TRUE, as.is=TRUE)

or

Mac <- read.csv("July'15.csv", header = TRUE, stringsAsFactors=FALSE)

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On August 26, 2015 1:33:28 PM PDT, jim holtman <jholtman at gmail.com> wrote:
>Please provide a sample of the data that you are trying to convert. 
>BTW
>does it have commas in numeric values, or what else is strange about 
>the data.  The error message is very clear in the column of data that 
>you are trying to convert is not numeric.
>
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>On Wed, Aug 26, 2015 at 4:30 AM, Arun84441 <arun.kumar8 at safexpress.com>
>wrote:
>
>> I have imported the csv file having 398800 obs of 30 variables. There
>is a
>> variable "TOTALFRT" which is showing as character in R environment. I
>am
>> trying to convert it to numeric by using as.numeric function.
>> Wherein function is converting character to numeric but with an error 
>> message "Warning message:
>> NAs introduced by coercion", it omitted 388800 entries. Hence I am
>unable
>> to
>> perform calculation.
>>
>> Is there anyway by which I can convert NAs to numeric??
>>
>> Below is the code I used for conversion :-
>>
>> Mac<-read.csv("July'15.csv", header = TRUE)
>> Book=as.character(Mac$TOTALFRT)
>> V = as.numeric(Book)
>>
>>
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>>
>http://r.789695.n4.nabble.com/Convert-character-Variables-to-numeric-tp
>4711518.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From preetiranjan.2008 at gmail.com  Thu Aug 27 00:43:11 2015
From: preetiranjan.2008 at gmail.com (Preeti ranjan Pradhan)
Date: Thu, 27 Aug 2015 04:13:11 +0530
Subject: [R] How to Turn OFF Vectors Recycling Rule in Paste()
Message-ID: <CAN6tJbipXXDkhWbpJvw-mukb4K-J6p61dHq02P1jzjtiX67uCA@mail.gmail.com>

Hello Team,

Platform:Windows 7 32-bit
R Version:3.2.2

I have two vectors as follows

> S = c("aa", "bb", "cc", "dd", "ee")
> X= c("aa", "bb", "cc", "dd")

When I trying a paste function

> z=paste(S,X)
> z

I am getting result as

[1] "aa aa" "bb bb" "cc cc" "dd dd" "ee aa"

I don't need the last element of S vector should get concatenated with
first element of X vector rather than it should take a space or null value
for concatenation. If I specify explicit space value in X vector like

> X= c("aa", "bb", "cc", "dd", " ")

Then I am getting result as
> z=paste(S,X)
> z
[1] "aa aa" "bb bb" "cc cc" "dd dd" "ee  "

Could you please suggest me how to turn off the Vector recycle in paste
function?

Thanks and Regards
Preetiranjan Pradhan

	[[alternative HTML version deleted]]


From joeceradini at gmail.com  Thu Aug 27 01:35:41 2015
From: joeceradini at gmail.com (Joe Ceradini)
Date: Wed, 26 Aug 2015 17:35:41 -0600
Subject: [R] Universal axis is overwritten in ggplot panel plot using
	grid.arrange
Message-ID: <CAKq2vL5LZESJGr0U8v2e+rWAM2sRzWh6=5EU8cY0fyMBfdawqA@mail.gmail.com>

R-helpers,

I am trying to make a panel of ggplots with universal Y and X axes. There
are many examples that show how to do this with grid.arrange. However, my x
axis label looks like it is (maybe) overwritten by the margin of the lower
left plot and I cannot figure out how to fix it. I realize this is not a
reproducible example, but I'm hoping the problem is obvious to someone more
experienced. I attached a pdf of the plot (which, if I understood the
posting guide correctly, will not be stripped off before posting).

Thanks!

*Code for one plot (lower left) and grid.arrange:*

E <- ggplot(data, aes(x = data_x)) +
  geom_line(aes(y = estimate), color = "black", linetype = "solid", size =
.6) +
  geom_line(aes(y = lcl), color = "black", linetype = "dashed", size = .6) +
  geom_line(aes(y = ucl), color = "black", linetype = "dashed", size = .6) +
  scale_y_continuous(limits = c(0.0, 1), breaks = seq(0.0, 1, .25)) +
  scale_x_continuous(limits = c(0, 80), breaks = seq(0, 80, 20)) +
  ggtitle("E)") +
  theme_bw() +
  theme(text = element_text(family = "Times"),
        plot.title = element_text(hjust = 0.2, vjust = -1, face = "bold",
size = 10),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        axis.title.x = element_blank(), # element_text(size = 16,
vjust=-0.5, hjust = 0)
        axis.title.y = element_blank(),
        plot.margin = unit(c(-1, 0.05, 2, .6), "lines"), # top, right,
bottom, left
        panel.border = element_blank(), # removes plot border
        panel.grid.major = element_blank(), # removes major gridlines
        panel.grid.minor = element_blank(), # removes minor gridlines
        axis.line = element_line(size=.25), # add x and y axis lines and
control width
        axis.ticks = element_line(size=.25), # tick width
        axis.ticks.length = unit(.1, "cm"))

grid.arrange(A, B, C, D, E, ncol=2,
            left = textGrob("U  n  i  v  e  r  s  a  l   Y   A  x  i  s",
                            rot = 90, vjust = .6, hjust = .45,
                            gp = gpar(fontsize = 20, fontfamily = "Times")),
            bottom = textGrob("U  n  i  v  e  r  s  a  l   X   A  x  i  s",
                              hjust = 1, vjust=5,
                      gp = gpar(fontsize = 20, fontfamily = "Times")))
-------------- next part --------------
A non-text attachment was scrubbed...
Name: axis_obscured.pdf
Type: application/pdf
Size: 8348 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150826/d764992c/attachment.pdf>

From jdnewmil at dcn.davis.CA.us  Thu Aug 27 07:09:37 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 26 Aug 2015 22:09:37 -0700
Subject: [R] How to Turn OFF Vectors Recycling Rule in Paste()
In-Reply-To: <CAN6tJbipXXDkhWbpJvw-mukb4K-J6p61dHq02P1jzjtiX67uCA@mail.gmail.com>
References: <CAN6tJbipXXDkhWbpJvw-mukb4K-J6p61dHq02P1jzjtiX67uCA@mail.gmail.com>
Message-ID: <36D70F42-FE85-41F7-8693-4CC75861804C@dcn.davis.CA.us>

No can do. You need to modify the input vectors so you get what you want.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 26, 2015 3:43:11 PM PDT, Preeti ranjan Pradhan <preetiranjan.2008 at gmail.com> wrote:
>Hello Team,
>
>Platform:Windows 7 32-bit
>R Version:3.2.2
>
>I have two vectors as follows
>
>> S = c("aa", "bb", "cc", "dd", "ee")
>> X= c("aa", "bb", "cc", "dd")
>
>When I trying a paste function
>
>> z=paste(S,X)
>> z
>
>I am getting result as
>
>[1] "aa aa" "bb bb" "cc cc" "dd dd" "ee aa"
>
>I don't need the last element of S vector should get concatenated with
>first element of X vector rather than it should take a space or null
>value
>for concatenation. If I specify explicit space value in X vector like
>
>> X= c("aa", "bb", "cc", "dd", " ")
>
>Then I am getting result as
>> z=paste(S,X)
>> z
>[1] "aa aa" "bb bb" "cc cc" "dd dd" "ee  "
>
>Could you please suggest me how to turn off the Vector recycle in paste
>function?
>
>Thanks and Regards
>Preetiranjan Pradhan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Aug 27 07:38:24 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 26 Aug 2015 22:38:24 -0700
Subject: [R] xyplot colour points and layout
In-Reply-To: <1440646861.27915.YahooMailBasic@web120802.mail.ne1.yahoo.com>
References: <1440646861.27915.YahooMailBasic@web120802.mail.ne1.yahoo.com>
Message-ID: <0BF9D38D-C686-45BD-9FE4-4FD053CA8EF5@comcast.net>


On Aug 26, 2015, at 8:41 PM, Christine Lee via R-help wrote:

> Dear All,
> 
> I have tried to plot graphs of one row of four figures for each station.  In each graph, black points indicate data in the year of 2002, denoted as Y2002, whereas grey points indicate data in the year of 2014, denoted as Y2014.  I ended up with 2x2 plots with all data points in black.  Can anyone find out what has gone wrong by any chance please?
> 
> Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L, 
> 2L, 4L, 12L, 6L, 15L, 14L, 3L, 6L, 1L, 16L, 5L, 11L, 8L, 4L, 
> 10L, 13L, 6L, 1L, 16L, 5L, 11L, 8L, 4L, 10L, 13L, 6L, 1L, 16L, 
> 5L, 11L, 8L, 4L, 10L, 13L, 11L, 8L, 4L, 10L, 13L), .Label = c("1/10", 
> "1/11", "11/11", "12/11", "13/10", "19/9", "2/10", "2/11", "20/9", 
> "26/11", "29/10", "29/11", "30/11", "31/10", "4/10", "6/10"), class = "factor"), 
>    Year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
>    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
>    2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Y2002", "Y2014"), class = "factor"), 
>    Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
>    2L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
>    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
>    3L, 3L, 4L, 4L, 4L, 4L, 4L), .Label = c("E", "F", "H", "I"
>    ), class = "factor"), Abun = c(3.42, 1.33, 3.67, 3.67, 3.92, 
>    2.17, 2.5, 1.67, 6.33, 0.67, 1, 1, 1.33, 2.08, 0, 0, 0.33, 
>    0.08, 0.08, 0, 0.5, 0.17, 0.67, 0.67, 0, 1, 0.58, 1.5, 2.67, 
>    0.67, 1.33, 3, 0.58, 1.17, 1.25, 0.75, 1.25, 1.75, 0.92, 
>    1.5, 0.83, 0.75, 2.33, 0.67, 1.33, 1.58), Date1 = structure(c(16697, 
>    16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768, 
>    16697, 16712, 16739, 16750, 16697, 16709, 16714, 16721, 16737, 
>    16741, 16751, 16765, 16769, 16697, 16709, 16714, 16721, 16737, 
>    16741, 16751, 16765, 16769, 16697, 16709, 16714, 16721, 16737, 
>    16741, 16751, 16765, 16769, 16737, 16741, 16751, 16765, 16769
>    ), class = "Date")), .Names = c("Date", "Year", "Station", 
> "Abun", "Date1"), row.names = c(NA, -46L), class = "data.frame")
> Raw$Date1<-as.Date(Raw$Date,"%d/%m")
> library(lattice)
> par(mfrow=c(1,4))
> culr<-ifelse(Raw$Year=="Y2002","Black","Grey")
> xyplot(Abun~Date1|Station,Raw,type="p",xlab=list("Month",cex=1.5),ylab=list("Abundance",cex=1.5),cex=2,pch=16,col=culr,strip=strip.custom(bg='white'))

Try putting in a groups argument (after adding the group identifier to the dataframe:

 xyplot(Abun~Date1|Station,  groups=culr, col=c("grey","black"),      
        data=Raw, type="p", xlab=list("Month",cex=1.5), ylab=list("Abundance",cex=1.5),
       cex=2, pch=16, strip=strip. custom(bg='white'))


> 
> 
> Many thanks.
> 
> Regards,
> Christine
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Thu Aug 27 09:07:44 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 27 Aug 2015 07:07:44 +0000
Subject: [R] How to Turn OFF Vectors Recycling Rule in Paste()
In-Reply-To: <CAN6tJbipXXDkhWbpJvw-mukb4K-J6p61dHq02P1jzjtiX67uCA@mail.gmail.com>
References: <CAN6tJbipXXDkhWbpJvw-mukb4K-J6p61dHq02P1jzjtiX67uCA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D2BC@SRVEXCHMBX.precheza.cz>

Hi

as Jeff said you cannot without modifying source code for paste.

If your problem is as you expressed it you can do e.g.

paste(S, append(X, rep(NA, length(S)-length(X))))

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Preeti
> ranjan Pradhan
> Sent: Thursday, August 27, 2015 12:43 AM
> To: r-help at r-project.org
> Subject: [R] How to Turn OFF Vectors Recycling Rule in Paste()
>
> Hello Team,
>
> Platform:Windows 7 32-bit
> R Version:3.2.2
>
> I have two vectors as follows
>
> > S = c("aa", "bb", "cc", "dd", "ee")
> > X= c("aa", "bb", "cc", "dd")
>
> When I trying a paste function
>
> > z=paste(S,X)
> > z
>
> I am getting result as
>
> [1] "aa aa" "bb bb" "cc cc" "dd dd" "ee aa"
>
> I don't need the last element of S vector should get concatenated with
> first element of X vector rather than it should take a space or null
> value for concatenation. If I specify explicit space value in X vector
> like
>
> > X= c("aa", "bb", "cc", "dd", " ")
>
> Then I am getting result as
> > z=paste(S,X)
> > z
> [1] "aa aa" "bb bb" "cc cc" "dd dd" "ee  "
>
> Could you please suggest me how to turn off the Vector recycle in paste
> function?
>
> Thanks and Regards
> Preetiranjan Pradhan
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From loris.bennett at fu-berlin.de  Thu Aug 27 11:22:11 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 27 Aug 2015 11:22:11 +0200
Subject: [R] igraph plot slowness
References: <87h9plogf5.fsf@hornfels.zedat.fu-berlin.de>
	<CAAxdm-5YiwPjVa5m_fZtL-+onGvdoKUP=o99jJ3ZPBCG7ipzZQ@mail.gmail.com>
	<87zj39u0fv.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <876141qe64.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Hi Jim,
>
> jim holtman <jholtman at gmail.com> writes:
>
>> Here is what it does locally on my PC:
>>
>>> library("igraph")
>>>  topo_data <- read.table(text = "ibcore01        ibswitch01
>> +  ibcore01        ibswitch02
>> +  ibcore01        ibswitch03
>> +  ibcore02        ibswitch01
>> +  ibcore02        ibswitch02
>> +  ibcore02        ibswitch03
>> +  ibswitch01      node001
>> +  ibswitch01      node002
>> +  ibswitch01      node003
>> +  ibswitch02      node004
>> +  ibswitch02      node005
>> +  ibswitch02      node006
>> +  ibswitch03      node007
>> +  ibswitch03      node008
>> +  ibswitch03      node009" ,head=FALSE)
>>>  system.time({
>> +  network_data <-graph.data.frame(topo_data, directed=F)
>> +  plot(network_data)
>> + })
>>    user  system elapsed
>>    0.01    0.01    0.03
>>>
>>>
>>
>> Does not seem too slow.  Creating a PDF file takes a little longer:
>>
>>> library("igraph")
>>>  topo_data <- read.table(text = "ibcore01        ibswitch01
>> +  ibcore01        ibswitch02
>> +  ibcore01        ibswitch03
>> +  ibcore02        ibswitch01
>> +  ibcore02        ibswitch02
>> +  ibcore02        ibswitch03
>> +  ibswitch01      node001
>> +  ibswitch01      node002
>> +  ibswitch01      node003
>> +  ibswitch02      node004
>> +  ibswitch02      node005
>> +  ibswitch02      node006
>> +  ibswitch03      node007
>> +  ibswitch03      node008
>> +  ibswitch03      node009" ,head=FALSE)
>>>  system.time({
>> +  network_data <-graph.data.frame(topo_data, directed=F)
>> +  pdf('test.pdf')
>> +  plot(network_data)
>> +  dev.off()
>> + })
>>    user  system elapsed
>>    0.09    0.00    0.16
>>
>> The PDF file is attached.  So maybe it is something with your remote
>> connection.
>
> You're right.  Running locally even the plot of complete network takes
> less than 0.2 seconds via the X11 device.  I'll have a closer look at
> the connection.
>
> Thanks,
>
> Loris

I found the solution here:

http://www.r-bloggers.com/slow-r-graphics-via-ssh/

namely calling

X11.options(type="Xlib")

in the remote R session.

Cheers,

Loris

-- 
This signature is currently under construction.


From cgenolin at u-paris10.fr  Thu Aug 27 12:20:56 2015
From: cgenolin at u-paris10.fr (cgenolin)
Date: Thu, 27 Aug 2015 03:20:56 -0700 (PDT)
Subject: [R] TSclust multivariate time series clustering
In-Reply-To: <25A23AB5-4015-4D3F-8069-DD1A5C0AC981@noaa.gov>
References: <1440576164201-4711517.post@n4.nabble.com>
	<25A23AB5-4015-4D3F-8069-DD1A5C0AC981@noaa.gov>
Message-ID: <1440670856543-4711555.post@n4.nabble.com>

You can also try kml3d. You can either use some default distances or define
your own.

http://www.jstatsoft.org/v65/i04/paper

Christophe



--
View this message in context: http://r.789695.n4.nabble.com/TSclust-multivariate-time-series-clustering-tp4711517p4711555.html
Sent from the R help mailing list archive at Nabble.com.


From maitra.mbox.ignored at inbox.com  Thu Aug 27 14:32:50 2015
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Thu, 27 Aug 2015 07:32:50 -0500
Subject: [R] TSclust multivariate time series clustering
In-Reply-To: <1440670856543-4711555.post@n4.nabble.com>
References: <1440576164201-4711517.post@n4.nabble.com>
	<25A23AB5-4015-4D3F-8069-DD1A5C0AC981@noaa.gov>
	<1440670856543-4711555.post@n4.nabble.com>
Message-ID: <20150827073250.a162f3930710eb377fe4312a@inbox.com>

Hello, 

Although there is no R package available (we did not think of it), if you want a Gaussian-mixture=model-based approach, you may look at the paper:

"Model-Based Clustering of Regression Time Series Data via APECM?An AECM Algorithm Sung to an Even Faster Beat" by Wei-Chen Chen and Ranjan Maitra 

which appeared in Statistical Analysis and Data Mining in December 2011 (pages 567-578), has DOI:10.1002/sam.10143 and won the primary author (Wei-Chen Chen) a JSM 2011 Best Student Paper award in Statistical Learning and Data Mining.

The code was all in R, so it is available as such upon personal request -- see e-mail addresses in the paper, but (as I mentioned earlier) not as a R package (yet).

Many thanks and best wishes,
Ranjan

-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Send any screenshot to your friends in seconds...
Works in all emails, instant messengers, blogs, forums and social networks.
TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if2 for FREE


From wewolski at gmail.com  Thu Aug 27 16:37:57 2015
From: wewolski at gmail.com (Witold E Wolski)
Date: Thu, 27 Aug 2015 16:37:57 +0200
Subject: [R] compiling Rmd - can't find tex file....
In-Reply-To: <CAAjnpdg0gV473vF4Hp5p8HJnmb0BKeEkcosuB3xRLdg-GX_EWw@mail.gmail.com>
References: <CAAjnpdg0gV473vF4Hp5p8HJnmb0BKeEkcosuB3xRLdg-GX_EWw@mail.gmail.com>
Message-ID: <CAAjnpdhjP92EmEoE8refTwNRLEB9MPrqZzzfoF9TwSnU=RQgQg@mail.gmail.com>

to answer my own question.

I did not find out what knit2pdf is good for
but rmarkdown::render does the job.

regards




On 26 August 2015 at 11:46, Witold E Wolski <wewolski at gmail.com> wrote:

> I am using from within R-studio and the .Rmd file builds nicely.
>
> However, when I try to compile the fiel using :
>
> knit2pdf( "specL.Rmd", output=file.path("res.12345","specL.pdf") )
> I am getting tex errors (see below). When I wan't to check what's wrong I
> can't find the tex file.
> Any ideas?
>
> Thank you
>
>
> PS: Errors:
>
>  |..............................................................   |  95%
>
> label: writepepProt
>
>   |.................................................................| 100%
>
>   ordinary text without R code
>
>
>
> *output file: res.12345/specL.pdf*
>
>
> *Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,
> : *
>
> *  Running 'texi2dvi' on 'specL.pdf' failed.*
>
> *LaTeX errors:*
>
> *! Missing $ inserted.*
>
> *<inserted text> *
>
> *                $*
>
> *<to be read again> *
>
> *                   _*
>
> *! Missing $ inserted.*
>
> *<inserted text> *
>
> *                $*
>
> *<to be read again> *
>
> *                   \par *
>
> *! You can't use `macro parameter character #' in horizontal mode.*
>
> *l.15 #*
>
>
>
>
>
>
> --
> Witold Eryk Wolski
>
>


-- 
Witold Eryk Wolski

	[[alternative HTML version deleted]]


From preetiranjan.2008 at gmail.com  Thu Aug 27 16:35:59 2015
From: preetiranjan.2008 at gmail.com (Preeti ranjan Pradhan)
Date: Thu, 27 Aug 2015 20:05:59 +0530
Subject: [R] How to Turn OFF Vectors Recycling Rule in Paste()
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D2BC@SRVEXCHMBX.precheza.cz>
References: <CAN6tJbipXXDkhWbpJvw-mukb4K-J6p61dHq02P1jzjtiX67uCA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D2BC@SRVEXCHMBX.precheza.cz>
Message-ID: <CAN6tJbhvOq-1S4h1ppAsB+59riisCN7vf4nW82jRFHxvauJUpA@mail.gmail.com>

Okay, thank you all for your reply.

In SAS it doesn't do that way, so I was bit confused. Anyways thanks all.

Cheers.


On Thu, Aug 27, 2015 at 12:37 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> as Jeff said you cannot without modifying source code for paste.
>
> If your problem is as you expressed it you can do e.g.
>
> paste(S, append(X, rep(NA, length(S)-length(X))))
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Preeti
> > ranjan Pradhan
> > Sent: Thursday, August 27, 2015 12:43 AM
> > To: r-help at r-project.org
> > Subject: [R] How to Turn OFF Vectors Recycling Rule in Paste()
> >
> > Hello Team,
> >
> > Platform:Windows 7 32-bit
> > R Version:3.2.2
> >
> > I have two vectors as follows
> >
> > > S = c("aa", "bb", "cc", "dd", "ee")
> > > X= c("aa", "bb", "cc", "dd")
> >
> > When I trying a paste function
> >
> > > z=paste(S,X)
> > > z
> >
> > I am getting result as
> >
> > [1] "aa aa" "bb bb" "cc cc" "dd dd" "ee aa"
> >
> > I don't need the last element of S vector should get concatenated with
> > first element of X vector rather than it should take a space or null
> > value for concatenation. If I specify explicit space value in X vector
> > like
> >
> > > X= c("aa", "bb", "cc", "dd", " ")
> >
> > Then I am getting result as
> > > z=paste(S,X)
> > > z
> > [1] "aa aa" "bb bb" "cc cc" "dd dd" "ee  "
> >
> > Could you please suggest me how to turn off the Vector recycle in paste
> > function?
> >
> > Thanks and Regards
> > Preetiranjan Pradhan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From spyqqqdia at yahoo.com  Thu Aug 27 12:37:15 2015
From: spyqqqdia at yahoo.com (Michael Meyer)
Date: Thu, 27 Aug 2015 18:37:15 +0800
Subject: [R] Rcpp, function signature
Message-ID: <1440671835.54919.YahooMailBasic@web193402.mail.sg3.yahoo.com>

Greetings,

I am an  (very) grateful user of Rcpp.
As such I defined a function 

// [[Rcpp::export]]
NumericVector
leftShift(NumericVector x){

  for(int i=0;i<n-1;i++) x[i]=x[i+1];
  return x;
}

expecting this function not to affect the parameter x outside
the function body as it is passed in by value.

However subsequent tests showed that it does affect x.
What is going on here?
Is sourceCpp rewriting this code in somne fashion??

Michael Meyer


From Mike.Conklin at gfk.com  Thu Aug 27 19:55:10 2015
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Thu, 27 Aug 2015 19:55:10 +0200
Subject: [R] Problem R markdown document
Message-ID: <FB454C9C2759D64BA12708C3073C30BB81F7B416EA@NUEW-EXMBCRB1.gfk.com>

I have successfully done this many times using RStudio's rmarkdown capabilities and knitting the document to HTML or Word. However, I am running into this error today.

"C:/Program Files/RStudio/bin/pandoc/pandoc" FusionTestsAugust25.utf8.md --to docx --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output FusionTestsAugust25.docx --highlight-style tango 
pandoc.exe: getMBlocks: VirtualAlloc MEM_COMMIT failed
Error: pandoc document conversion failed with error 1

Same error occurs whether to knitting to Word or to HTML.  It looks like the a memory issue but this whole process is of limited use if the entire analysis runs but the document can't be output.  If anyone has any ideas on how to deal with memory issues in the final step of pandoc conversion or can point me to where to look for this I would appreciate it.

Best regards,

Mike


--
W. Michael Conklin
Executive Vice President
Marketing & Data Sciences - North America
GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
mike.conklin at gfk.com 
T +1 763 417 4545 | M +1 612 567 8287 
www.gfk.com 


From bob at rudis.net  Thu Aug 27 20:09:26 2015
From: bob at rudis.net (boB Rudis)
Date: Thu, 27 Aug 2015 14:09:26 -0400
Subject: [R] Problem R markdown document
In-Reply-To: <FB454C9C2759D64BA12708C3073C30BB81F7B416EA@NUEW-EXMBCRB1.gfk.com>
References: <FB454C9C2759D64BA12708C3073C30BB81F7B416EA@NUEW-EXMBCRB1.gfk.com>
Message-ID: <CAJ4QxaMYHONJaYurXNtpQAuenMzWmV10aa-DATgXu9y_Xuj3tg@mail.gmail.com>

Try increasing the memory for pandoc via knitr YAML options:

--
title: "TITLE"
output:
  html_document:
    pandoc_args: [
      "+RTS", "-K64m",
      "-RTS"
    ]
---

ref: http://stackoverflow.com/a/28015894/1457051

you can bump up those #'s IIRC, too, if they don't work at first.

On Thu, Aug 27, 2015 at 1:55 PM, Conklin, Mike (GfK)
<Mike.Conklin at gfk.com> wrote:
> I have successfully done this many times using RStudio's rmarkdown capabilities and knitting the document to HTML or Word. However, I am running into this error today.
>
> "C:/Program Files/RStudio/bin/pandoc/pandoc" FusionTestsAugust25.utf8.md --to docx --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures --output FusionTestsAugust25.docx --highlight-style tango
> pandoc.exe: getMBlocks: VirtualAlloc MEM_COMMIT failed
> Error: pandoc document conversion failed with error 1
>
> Same error occurs whether to knitting to Word or to HTML.  It looks like the a memory issue but this whole process is of limited use if the entire analysis runs but the document can't be output.  If anyone has any ideas on how to deal with memory issues in the final step of pandoc conversion or can point me to where to look for this I would appreciate it.
>
> Best regards,
>
> Mike
>
>
> --
> W. Michael Conklin
> Executive Vice President
> Marketing & Data Sciences - North America
> GfK | 8401 Golden Valley Road | Minneapolis | MN | 55427
> mike.conklin at gfk.com
> T +1 763 417 4545 | M +1 612 567 8287
> www.gfk.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Thu Aug 27 21:33:16 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 27 Aug 2015 21:33:16 +0200
Subject: [R] Problem with gridExtra
Message-ID: <20150827193316.GA14710@localhost.localdomain>

Dear All,
Please consider the snippet at the end of the email, largely based on
what you find here

http://bit.ly/1ND6MGa

When I run it, I get this error

Error in arrangeGrob(p, sub = textGrob("Footnote", x = 0, hjust =
-0.1,  :
  could not find function "textGrob"

However, the code runs on another machine I own. I suppose something
must have changed in the gridExtra library but right now I am banging
my head against the wall.

This is my sessionInfo()

> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux stretch/sid

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
     [9] LC_ADDRESS=C              LC_TELEPHONE=C
     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] gridExtra_2.0.0 ggplot2_1.0.1

loaded via a namespace (and not attached):
 [1] Rcpp_0.11.6      digest_0.6.8     MASS_7.3-43      grid_3.2.2
  [5] plyr_1.8.3       gtable_0.1.2     magrittr_1.5     scales_0.3.0
   [9] stringi_0.5-5    reshape2_1.4.1   proto_0.3-10     labeling_0.3
   [13] tools_3.2.2      stringr_1.0.0    munsell_0.4.2
 colorspace_1.2-6

Any suggestion is appreciated.
Cheers

Lorenzo


##############################################################
library(ggplot2)
toyota <- mpg[which(mpg$manufacturer == 'toyota'), ]
p <- ggplot(toyota, aes(displ, hwy)) + facet_wrap(~ class, ncol = 2) +
geom_point(aes(size=cyl))
print(p)
library(gridExtra)
g <- arrangeGrob(p, sub = textGrob("Footnote", x = 0, hjust = -0.1,
vjust=0.1, gp = gpar(fontface = "italic", fontsize = 18)))
ggsave("/Users/Alan/Desktop/plot_grid_extra.png", g)


From brettpaul16 at gmail.com  Thu Aug 27 19:36:14 2015
From: brettpaul16 at gmail.com (paul brett)
Date: Thu, 27 Aug 2015 19:36:14 +0200
Subject: [R] Fisher's Test 5x4 table
Message-ID: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>

Dear all,
            I am trying to do a fishers test on a 5x4 table on R
statistics. I have already done a chi squared test using Minitab on this
data set, getting a result of (1, N = 165.953, DF 12, p>0.001), yet using
these results (even though they are excellent) may not be suitable for
publication. I have tried numerous other statistical packages in the hope
of doing this test, yet each one has just the 2x2 table.
            I am struggling to edit the template fishers test on R to fit
my table (as according to the R book it is possible, yet i cannot get it to
work). The template given on the R documentation and R book is for a 2x2
fisher test. What do i need to change to get this to work? I have attached
the data with the email so one can see what i am on about. Or do i have to
write my own new code to compute this.

             Yours Sincerely,
                                     Paul Brett
-------------- next part --------------
Traps	Insecta	Diplopoda	Arachnia	Malocostan
5.trap.4.barrier	345	77	200	154
1.trap.4.barrier	170	54	61	58
1.trap.no.barrier	232	19	30	5
1.trap.no.barrier	59	5	6	5
5.trap.no.barrier	105	11	26	37

From edd at debian.org  Thu Aug 27 17:40:04 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 27 Aug 2015 15:40:04 +0000
Subject: [R] Rcpp, function signature
References: <1440671835.54919.YahooMailBasic@web193402.mail.sg3.yahoo.com>
Message-ID: <loom.20150827T173914-631@post.gmane.org>

Michael Meyer via R-help <r-help <at> r-project.org> writes:

> I am an  (very) grateful user of Rcpp.

Glad to hear that!

But you are on the wrong mailing list. Please ask on rcpp-devel.

Dirk


From mathewanalytics at gmail.com  Thu Aug 27 21:29:28 2015
From: mathewanalytics at gmail.com (Abraham Mathew)
Date: Thu, 27 Aug 2015 14:29:28 -0500
Subject: [R] Issues with RPostgres
Message-ID: <CABbYsteJJ=0Hjwbs1F0mAK8mHKuv089RhNaO=mjA5HZXGTSCZg@mail.gmail.com>

I have a user-defined function that I'm using alongside a postgresql
connection to
summarize some data. I've connected to the local machine with no problem.
However,
the connection keeps throwing the following error when I attempt to use it.
Can anyone point
to what I could be doing wrong.

> ds_summary(con, "test", vars=c("Age"), y=c("Class"))
Error in postgresqlNewConnection(drv, ...) :
  RS-DBI driver: (could not connect postgres at localhost on dbname "test"
)


con is the connection
test is the database table
age is the attribute that will be summarized
class is the response variable

Can anyone help?


-- 


*Abraham MathewData Ninja and Statistical Modeler*



*Minneapolis, MN720-648-0108 at abmathewksAnalytics_Blog
<https://mathewanalytics.wordpress.com/>*

	[[alternative HTML version deleted]]


From richard_raubertas at merck.com  Thu Aug 27 18:06:45 2015
From: richard_raubertas at merck.com (Raubertas, Richard)
Date: Thu, 27 Aug 2015 12:06:45 -0400
Subject: [R] lsqlin in R package pracma
Message-ID: <1D693EC430D9BA40A64CB59875BED8CF0172F96EF339@USCTMXP51004.merck.com>

Is it really that complicated?  This looks like an ordinary quadratic programming problem, and 'solve.QP' from the 'quadprog' package seems to solve it without user-specified starting values:

library(quadprog)
Dmat <- t(C) %*% C
dvec <- (t(C) %*% d)
Amat <- -1 * t(A)
bvec <- -1 * b

rslt <- solve.QP(Dmat, dvec, Amat, bvec)
sum((C %*% rslt$solution - d)^2)

[1] 0.01758538

Richard Raubertas
Merck & Co.

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Hans W Borchers
Sent: Wednesday, August 26, 2015 6:22 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] lsqlin in R package pracma

On Mon Aug 24 Wang, Xue, Ph.D. Wang.Xue at mayo.edu wrote
> I am looking for a R version of Matlab function lsqlin. I came across
> R pracma package which has a lsqlin function. Compared with Matlab lsqlin,
> the R version does not allow inequality constraints.
> I am wondering if this functionality will be available in future. And also
> like to get your opinion on which R package/function is the best for
solving
> least square minimization problem with linear inequality constraints.
> Thanks very much for your time and attention!


Solving (linear) least-squares problems with linear inequality constraints
is more difficult then one would expect. Inspecting the MATLAB code reveals
that it employs advanced methods such as active-set (linear inequality
constraints) and interior-point (for bounds constraints).

Function nlsLM() in package *minpack.lm* supports bound constraints if that
is sufficient for you. The same is true for *nlmrt*. Convex optimization
might be a promising approach for linear inequality constraints, but there
is no easy-to-handle convex solver in R at this moment.

So the most straightforward way would be to use constrOptim(), that is
optim with linear constraints. It requires a reasonable starting point, and
keeping your fingers crossed that you are able to find such a point in the
interior of the feasible region.

I someone wants to try: Here is the example from the MATLAB "lsqlin" page:

    C <- matrix(c(
        0.9501,   0.7620,   0.6153,   0.4057,
        0.2311,   0.4564,   0.7919,   0.9354,
        0.6068,   0.0185,   0.9218,   0.9169,
        0.4859,   0.8214,   0.7382,   0.4102,
        0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
    d <- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
    A <- matrix(c(
        0.2027,   0.2721,   0.7467,   0.4659,
        0.1987,   0.1988,   0.4450,   0.4186,
        0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
    b <- c(0.5251, 0.2026, 0.6721)

The least-square function to be minimized is  ||C x - d||_2 , and the
constraints are  A x <= b :

    f <- function(x) sum((C %*% x - d)^2)

The solution x0 returned by MATLAB has a minimum of  f(x0) = 0.01759204 .
This point does not lie in the interior and cannot be used for a start.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From john.archie.mckown at gmail.com  Thu Aug 27 22:46:38 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 27 Aug 2015 15:46:38 -0500
Subject: [R] Issues with RPostgres
In-Reply-To: <CABbYsteJJ=0Hjwbs1F0mAK8mHKuv089RhNaO=mjA5HZXGTSCZg@mail.gmail.com>
References: <CABbYsteJJ=0Hjwbs1F0mAK8mHKuv089RhNaO=mjA5HZXGTSCZg@mail.gmail.com>
Message-ID: <CAAJSdjhqZwUh0z10Qh6-VZK6Uw3nryMxiWC1mGAeBg8Agny03A@mail.gmail.com>

On Thu, Aug 27, 2015 at 2:29 PM, Abraham Mathew <mathewanalytics at gmail.com>
wrote:

> I have a user-defined function that I'm using alongside a postgresql
> connection to
> summarize some data. I've connected to the local machine with no problem.
> However,
> the connection keeps throwing the following error when I attempt to use it.
> Can anyone point
> to what I could be doing wrong.
>
> > ds_summary(con, "test", vars=c("Age"), y=c("Class"))
> Error in postgresqlNewConnection(drv, ...) :
>   RS-DBI driver: (could not connect postgres at localhost on dbname "test"
> )
>
>
> con is the connection
>

?It would be helpful to see the assignment to "con" as well as any other
assignments related to this. If you are using the DBI package, then what I
am talking about would be something like:

drv<-dbDriver("PgSQL")
con<-dbConnect(drb,user=...,password=...,dbname="test');

>From looking at the message, it appears to me that you are trying to
connect to PostgreSQL as the "postgres" user. That just seems wrong to me.
Normally that user is only for administration purposes. It does not
normally contain user tables such as "test". I would think that what you
needed would be your PostgreSQL user id. Or the id of the owner of the
"test" table.?




> test is the database table
> age is the attribute that will be summarized
> class is the response variable
>
> Can anyone help?
>
>
> --
>
>
> *Abraham MathewData Ninja and Statistical Modeler*
>
>
>
> *Minneapolis, MN720-648-0108 at abmathewksAnalytics_Blog
> <https://mathewanalytics.wordpress.com/>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From Wang.Xue at mayo.edu  Thu Aug 27 23:12:29 2015
From: Wang.Xue at mayo.edu (Wang, Xue, Ph.D.)
Date: Thu, 27 Aug 2015 21:12:29 +0000
Subject: [R] lsqlin in R package pracma
In-Reply-To: <1D693EC430D9BA40A64CB59875BED8CF0172F96EF339@USCTMXP51004.merck.com>
References: <1D693EC430D9BA40A64CB59875BED8CF0172F96EF339@USCTMXP51004.merck.com>
Message-ID: <2f3a88$1aa933@ironport10.mayo.edu>

Hi Richard,

It is good to know that solve.QP could solve quadratic programming problem. The difficulty here is that the objective function might not be in quadratic form. It is not in the form of t(X)QX, where Q is an n by n symmetric matrix.

Thanks,

Xue 

 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Raubertas, Richard
Sent: Thursday, August 27, 2015 12:07 PM
To: Hans W Borchers; r-help at stat.math.ethz.ch
Subject: Re: [R] lsqlin in R package pracma

Is it really that complicated?  This looks like an ordinary quadratic programming problem, and 'solve.QP' from the 'quadprog' package seems to solve it without user-specified starting values:

library(quadprog)
Dmat <- t(C) %*% C
dvec <- (t(C) %*% d)
Amat <- -1 * t(A)
bvec <- -1 * b

rslt <- solve.QP(Dmat, dvec, Amat, bvec) sum((C %*% rslt$solution - d)^2)

[1] 0.01758538

Richard Raubertas
Merck & Co.

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Hans W Borchers
Sent: Wednesday, August 26, 2015 6:22 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] lsqlin in R package pracma

On Mon Aug 24 Wang, Xue, Ph.D. Wang.Xue at mayo.edu wrote
> I am looking for a R version of Matlab function lsqlin. I came across 
> R pracma package which has a lsqlin function. Compared with Matlab 
> lsqlin, the R version does not allow inequality constraints.
> I am wondering if this functionality will be available in future. And 
> also like to get your opinion on which R package/function is the best 
> for
solving
> least square minimization problem with linear inequality constraints.
> Thanks very much for your time and attention!


Solving (linear) least-squares problems with linear inequality constraints is more difficult then one would expect. Inspecting the MATLAB code reveals that it employs advanced methods such as active-set (linear inequality
constraints) and interior-point (for bounds constraints).

Function nlsLM() in package *minpack.lm* supports bound constraints if that is sufficient for you. The same is true for *nlmrt*. Convex optimization might be a promising approach for linear inequality constraints, but there is no easy-to-handle convex solver in R at this moment.

So the most straightforward way would be to use constrOptim(), that is optim with linear constraints. It requires a reasonable starting point, and keeping your fingers crossed that you are able to find such a point in the interior of the feasible region.

I someone wants to try: Here is the example from the MATLAB "lsqlin" page:

    C <- matrix(c(
        0.9501,   0.7620,   0.6153,   0.4057,
        0.2311,   0.4564,   0.7919,   0.9354,
        0.6068,   0.0185,   0.9218,   0.9169,
        0.4859,   0.8214,   0.7382,   0.4102,
        0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
    d <- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
    A <- matrix(c(
        0.2027,   0.2721,   0.7467,   0.4659,
        0.1987,   0.1988,   0.4450,   0.4186,
        0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
    b <- c(0.5251, 0.2026, 0.6721)

The least-square function to be minimized is  ||C x - d||_2 , and the constraints are  A x <= b :

    f <- function(x) sum((C %*% x - d)^2)

The solution x0 returned by MATLAB has a minimum of  f(x0) = 0.01759204 .
This point does not lie in the interior and cannot be used for a start.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Thu Aug 27 23:42:08 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 27 Aug 2015 16:42:08 -0500
Subject: [R] Issues with RPostgres
In-Reply-To: <CAAJSdjhqZwUh0z10Qh6-VZK6Uw3nryMxiWC1mGAeBg8Agny03A@mail.gmail.com>
References: <CABbYsteJJ=0Hjwbs1F0mAK8mHKuv089RhNaO=mjA5HZXGTSCZg@mail.gmail.com>
	<CAAJSdjhqZwUh0z10Qh6-VZK6Uw3nryMxiWC1mGAeBg8Agny03A@mail.gmail.com>
Message-ID: <CABdHhvG=Dc2CoHBes-8MTd+d=cg+v+8acxcB-oJ_mSGHmbZGqQ@mail.gmail.com>

On Thu, Aug 27, 2015 at 3:46 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Thu, Aug 27, 2015 at 2:29 PM, Abraham Mathew <mathewanalytics at gmail.com>
> wrote:
>
>> I have a user-defined function that I'm using alongside a postgresql
>> connection to
>> summarize some data. I've connected to the local machine with no problem.
>> However,
>> the connection keeps throwing the following error when I attempt to use it.
>> Can anyone point
>> to what I could be doing wrong.
>>
>> > ds_summary(con, "test", vars=c("Age"), y=c("Class"))
>> Error in postgresqlNewConnection(drv, ...) :
>>   RS-DBI driver: (could not connect postgres at localhost on dbname "test"
>> )
>>
>>
>> con is the connection
>>
>
> It would be helpful to see the assignment to "con" as well as any other
> assignments related to this. If you are using the DBI package, then what I
> am talking about would be something like:
>
> drv<-dbDriver("PgSQL")
> con<-dbConnect(drb,user=...,password=...,dbname="test');

FWIW the best way to create a connection is:

library(DBI)
con <- dbConnect(RPostgreSQL::PostgreSQL(), ...)

The older string based approach is not advised.

Hadley
-- 
http://had.co.nz/


From mtalbert at usgs.gov  Thu Aug 27 23:48:21 2015
From: mtalbert at usgs.gov (Marian Talbert)
Date: Thu, 27 Aug 2015 14:48:21 -0700 (PDT)
Subject: [R] ggplot2 scale_shape_manual with large numbers instead of shapes
Message-ID: <1440712101601-4711580.post@n4.nabble.com>

I'm trying to produce a plot with climate data in which colors describe one
aspect of the data (emissions scenario) and numbers rather than shapes show
the model used (there are 36 models for one emissions scenario and 34 for
the other).  I'm trying to use numbers rather than symbols because there are
36 climate models and thus not enough symbols.  Numbering seems more
consistent than some combo of letters and symbols.  I couldn't figure out
how to define my own shapes as numbers 1 to 36 using scale_shape_manual so
I'm adding the numbers with annotate.  The problem is that I'd like a second
legend linking the numbering to the long model names but am having a hard
time with this.  I've created a toy example below to make this more clear.
p1 below was my original plot and I'd like p2 only with the second legend
linking numbers to long model names any suggestions? 

library(ggplot2)


Dat<-data.frame(Temp=c(rnorm(36,0,1),rnorm(36,1.5,1)),Precp=c(rnorm(36,0,1),rnorm(36,1,1)),
     
model=factor(rep(paste("LongModelName",c(letters,1:10),sep="_"),times=2)),
      Emissions=factor(rep(c("RCP 4.5","RCP 8.5"),each=36)))
 EmissionsCol<-c("goldenrod2","red")
 Pquants <- aggregate(Dat$Precp,list(RCP=Dat$Emissions),
               quantile,c(.25,.5,.75),na.rm=TRUE)
 Tquants <- aggregate(Dat$Temp,list(RCP=Dat$Emissions),
               quantile,c(.25,.5,.75),na.rm=TRUE)
 Quants<-data.frame(Emissions=Tquants$RCP,Tmin=Tquants[[2]][,1],
          TMedian=Tquants[[2]][,2],Tmax=Tquants[[2]][,3],
         
Pmin=Pquants[[2]][,1],PMedian=Pquants[[2]][,2],Pmax=Pquants[[2]][,3])

#Original Plot
Labels<-Dat$model
 p1 <- ggplot()+geom_point(Dat,mapping=aes(x=Temp,y=Precp,colour=Emissions),
     size=.1)+
 scale_colour_manual(values=c("#EEB422BE","#FF0000BE"),guide="none")+
  annotate("text", label=Labels, x=Dat$Temp,
y=Dat$Precp,colour=c("#EEB422BE","#FF0000BE")[Dat$Emissions]) +
  guides(fill=guide_legend(reverse=TRUE))+theme(axis.title =
element_text(size = 2)) +
  
geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian),size=2,colour="black")+
 
geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax),size=2,colour="black")+
 
geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian,colour=Emissions),size=1)+
 
geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax,colour=Emissions),size=1)+
 
geom_point(data=Quants,mapping=aes(x=TMedian,y=PMedian,fill=Emissions),size=6,pch=21,colour="black")+
  scale_fill_manual(values=EmissionsCol)
p1

#with numbers instead of model names
Labels<-as.numeric(factor(Dat$model))
 p2<-
ggplot()+geom_point(Dat,mapping=aes(x=Temp,y=Precp,colour=Emissions),size=.1)+
 scale_colour_manual(values=c("#EEB422BE","#FF0000BE"),guide="none")+
  annotate("text", label=Labels, x=Dat$Temp,
y=Dat$Precp,colour=c("#EEB422BE","#FF0000BE")[Dat$Emissions])+
  guides(fill=guide_legend(reverse=TRUE))+theme(axis.title =
element_text(size = 2)) +
 
geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian),size=2,colour="black")+
 
geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax),size=2,colour="black")+
 
geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian,colour=Emissions),size=1)+
 
geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax,colour=Emissions),size=1)+
 
geom_point(data=Quants,mapping=aes(x=TMedian,y=PMedian,fill=Emissions),size=6,pch=21,colour="black")+
  scale_fill_manual(values=EmissionsCol)
  
p2





--
View this message in context: http://r.789695.n4.nabble.com/ggplot2-scale-shape-manual-with-large-numbers-instead-of-shapes-tp4711580.html
Sent from the R help mailing list archive at Nabble.com.


From h.wickham at gmail.com  Thu Aug 27 23:59:39 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 27 Aug 2015 16:59:39 -0500
Subject: [R] ggplot2 scale_shape_manual with large numbers instead of
	shapes
In-Reply-To: <1440712101601-4711580.post@n4.nabble.com>
References: <1440712101601-4711580.post@n4.nabble.com>
Message-ID: <CABdHhvHG3k8bZoJ1-9SZsf+fV=ORfsTepPjVgTRJ9BFeqX_JHw@mail.gmail.com>

Something like this?

df <- data.frame(
  x = runif(30),
  y = runif(30),
  z = factor(1:30)
)

ggplot(df, aes(x, y)) +
  geom_point(aes(shape = z), size = 5) +
  scale_shape_manual(values = c(letters, 0:9))

Hadley

On Thu, Aug 27, 2015 at 4:48 PM, Marian Talbert <mtalbert at usgs.gov> wrote:
> I'm trying to produce a plot with climate data in which colors describe one
> aspect of the data (emissions scenario) and numbers rather than shapes show
> the model used (there are 36 models for one emissions scenario and 34 for
> the other).  I'm trying to use numbers rather than symbols because there are
> 36 climate models and thus not enough symbols.  Numbering seems more
> consistent than some combo of letters and symbols.  I couldn't figure out
> how to define my own shapes as numbers 1 to 36 using scale_shape_manual so
> I'm adding the numbers with annotate.  The problem is that I'd like a second
> legend linking the numbering to the long model names but am having a hard
> time with this.  I've created a toy example below to make this more clear.
> p1 below was my original plot and I'd like p2 only with the second legend
> linking numbers to long model names any suggestions?
>
> library(ggplot2)
>
>
> Dat<-data.frame(Temp=c(rnorm(36,0,1),rnorm(36,1.5,1)),Precp=c(rnorm(36,0,1),rnorm(36,1,1)),
>
> model=factor(rep(paste("LongModelName",c(letters,1:10),sep="_"),times=2)),
>       Emissions=factor(rep(c("RCP 4.5","RCP 8.5"),each=36)))
>  EmissionsCol<-c("goldenrod2","red")
>  Pquants <- aggregate(Dat$Precp,list(RCP=Dat$Emissions),
>                quantile,c(.25,.5,.75),na.rm=TRUE)
>  Tquants <- aggregate(Dat$Temp,list(RCP=Dat$Emissions),
>                quantile,c(.25,.5,.75),na.rm=TRUE)
>  Quants<-data.frame(Emissions=Tquants$RCP,Tmin=Tquants[[2]][,1],
>           TMedian=Tquants[[2]][,2],Tmax=Tquants[[2]][,3],
>
> Pmin=Pquants[[2]][,1],PMedian=Pquants[[2]][,2],Pmax=Pquants[[2]][,3])
>
> #Original Plot
> Labels<-Dat$model
>  p1 <- ggplot()+geom_point(Dat,mapping=aes(x=Temp,y=Precp,colour=Emissions),
>      size=.1)+
>  scale_colour_manual(values=c("#EEB422BE","#FF0000BE"),guide="none")+
>   annotate("text", label=Labels, x=Dat$Temp,
> y=Dat$Precp,colour=c("#EEB422BE","#FF0000BE")[Dat$Emissions]) +
>   guides(fill=guide_legend(reverse=TRUE))+theme(axis.title =
> element_text(size = 2)) +
>
> geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian),size=2,colour="black")+
>
> geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax),size=2,colour="black")+
>
> geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian,colour=Emissions),size=1)+
>
> geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax,colour=Emissions),size=1)+
>
> geom_point(data=Quants,mapping=aes(x=TMedian,y=PMedian,fill=Emissions),size=6,pch=21,colour="black")+
>   scale_fill_manual(values=EmissionsCol)
> p1
>
> #with numbers instead of model names
> Labels<-as.numeric(factor(Dat$model))
>  p2<-
> ggplot()+geom_point(Dat,mapping=aes(x=Temp,y=Precp,colour=Emissions),size=.1)+
>  scale_colour_manual(values=c("#EEB422BE","#FF0000BE"),guide="none")+
>   annotate("text", label=Labels, x=Dat$Temp,
> y=Dat$Precp,colour=c("#EEB422BE","#FF0000BE")[Dat$Emissions])+
>   guides(fill=guide_legend(reverse=TRUE))+theme(axis.title =
> element_text(size = 2)) +
>
> geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian),size=2,colour="black")+
>
> geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax),size=2,colour="black")+
>
> geom_segment(data=Quants,mapping=aes(x=Tmin,y=PMedian,xend=Tmax,yend=PMedian,colour=Emissions),size=1)+
>
> geom_segment(data=Quants,mapping=aes(x=TMedian,y=Pmin,xend=TMedian,yend=Pmax,colour=Emissions),size=1)+
>
> geom_point(data=Quants,mapping=aes(x=TMedian,y=PMedian,fill=Emissions),size=6,pch=21,colour="black")+
>   scale_fill_manual(values=EmissionsCol)
>
> p2
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/ggplot2-scale-shape-manual-with-large-numbers-instead-of-shapes-tp4711580.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From mtalbert at usgs.gov  Thu Aug 27 23:59:46 2015
From: mtalbert at usgs.gov (Marian Talbert)
Date: Thu, 27 Aug 2015 14:59:46 -0700 (PDT)
Subject: [R] ggplot2 scale_shape_manual with large numbers instead of
	shapes
In-Reply-To: <CABdHhvHG3k8bZoJ1-9SZsf+fV=ORfsTepPjVgTRJ9BFeqX_JHw@mail.gmail.com>
References: <1440712101601-4711580.post@n4.nabble.com>
	<CABdHhvHG3k8bZoJ1-9SZsf+fV=ORfsTepPjVgTRJ9BFeqX_JHw@mail.gmail.com>
Message-ID: <1440712786316-4711582.post@n4.nabble.com>

Not exactly I was trying to only numbers for symbols instead of a mix of
letters and numbers just to be consistent.  I'm pretty sure someone will nag
me if I use both letters and numbers as symbols  



--
View this message in context: http://r.789695.n4.nabble.com/ggplot2-scale-shape-manual-with-large-numbers-instead-of-shapes-tp4711580p4711582.html
Sent from the R help mailing list archive at Nabble.com.


From angelat416 at yahoo.com  Fri Aug 28 01:02:34 2015
From: angelat416 at yahoo.com (Angela)
Date: Thu, 27 Aug 2015 16:02:34 -0700
Subject: [R] heat map labeling
Message-ID: <1440716554.57060.YahooMailBasic@web161501.mail.bf1.yahoo.com>

Hello,

I have a dataset of 985 genes, looks something like the ones below. I want to label only those with the high intensities, since labeling all doesn't show up. Is there a way to do that? If not, is there a way to pull out the highest ones (say, highest 50, or those above X amount) and only show those in a heat map? Thanks!

-Angela

Z transforming gives all cells the same value, just + or - (for example, all have 0.5 and -0.5). The researchers want the actual values used.

Gene???var1? ? ???var2
A? ? 8000000? ? 0
B? ? 250000? ? 300000
C? ? 750000? ? 2000000
D? ? 0? ? ? ? ? ? 0
E? ? 4000000? ? 6000000
E? ? 5000000? ? 700000
E? ? 1000000? ? 1000000
F? ? 6000000? ? 6000000
F? ? 700000? ? 827460
G? ? 420930? ? 400000
H? ? 0? ? ? ? ? ? 0
H? ? 1000000? ? 1000000
I? ? 700000? ? 600000
J? ? 0? ? ? ? ? ? 700000
K? ? 0? ? ? ? ? ? 0
L? ? 200000? ? 500000
L? ? 1000000? ? 3000000


From dulcalma at bigpond.com  Fri Aug 28 01:03:16 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 28 Aug 2015 09:03:16 +1000
Subject: [R] xyplot colour points and layout
In-Reply-To: <1440646861.27915.YahooMailBasic@web120802.mail.ne1.yahoo.com>
References: <1440646861.27915.YahooMailBasic@web120802.mail.ne1.yahoo.com>
Message-ID: <000901d0e11c$8f26c140$ad7443c0$@bigpond.com>

Hi 

Following on from Davids reply you can do the following if you want a key or
legend.
By putting the colour scheme in par.settings the "local" equivalent of
setting trellis.par.set() for that plot
you can get things right for the key without having to have add arguments to
key

  culr<-ifelse(Raw$Year=="Y2002","Year 2002","Year 2014")

  xyplot(Abun~Date1|Station, data=Raw,
        groups = culr,
        par.settings = list(strip.background = list(col = "transparent"),
                            superpose.symbol = list(cex = rep(2, 2),
                                                    col=c("grey","black"),
                                                    pch = rep(16,2))),
        type="p",
        xlab=list("Month",cex=1.5),
        ylab=list("Abundance",cex=1.5),
        auto.key = T)

see 
names(trellis.par.get())
for a list of the settings

Regards

Duncan
Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Christine
Lee via R-help
Sent: Thursday, 27 August 2015 13:41
To: r-help at r-project.org
Subject: [R] xyplot colour points and layout

Dear All,

I have tried to plot graphs of one row of four figures for each station.  In
each graph, black points indicate data in the year of 2002, denoted as
Y2002, whereas grey points indicate data in the year of 2014, denoted as
Y2014.  I ended up with 2x2 plots with all data points in black.  Can anyone
find out what has gone wrong by any chance please?

Raw<-structure(list(Date = structure(c(6L, 7L, 2L, 4L, 12L, 9L, 7L, 
2L, 4L, 12L, 6L, 15L, 14L, 3L, 6L, 1L, 16L, 5L, 11L, 8L, 4L, 
10L, 13L, 6L, 1L, 16L, 5L, 11L, 8L, 4L, 10L, 13L, 6L, 1L, 16L, 
5L, 11L, 8L, 4L, 10L, 13L, 11L, 8L, 4L, 10L, 13L), .Label = c("1/10", 
"1/11", "11/11", "12/11", "13/10", "19/9", "2/10", "2/11", "20/9", 
"26/11", "29/10", "29/11", "30/11", "31/10", "4/10", "6/10"), class =
"factor"), 
    Year = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Y2002", "Y2014"), class =
"factor"), 
    Station = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
    2L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 4L, 4L, 4L, 4L, 4L), .Label = c("E", "F", "H", "I"
    ), class = "factor"), Abun = c(3.42, 1.33, 3.67, 3.67, 3.92, 
    2.17, 2.5, 1.67, 6.33, 0.67, 1, 1, 1.33, 2.08, 0, 0, 0.33, 
    0.08, 0.08, 0, 0.5, 0.17, 0.67, 0.67, 0, 1, 0.58, 1.5, 2.67, 
    0.67, 1.33, 3, 0.58, 1.17, 1.25, 0.75, 1.25, 1.75, 0.92, 
    1.5, 0.83, 0.75, 2.33, 0.67, 1.33, 1.58), Date1 = structure(c(16697, 
    16710, 16740, 16751, 16768, 16698, 16710, 16740, 16751, 16768, 
    16697, 16712, 16739, 16750, 16697, 16709, 16714, 16721, 16737, 
    16741, 16751, 16765, 16769, 16697, 16709, 16714, 16721, 16737, 
    16741, 16751, 16765, 16769, 16697, 16709, 16714, 16721, 16737, 
    16741, 16751, 16765, 16769, 16737, 16741, 16751, 16765, 16769
    ), class = "Date")), .Names = c("Date", "Year", "Station", 
"Abun", "Date1"), row.names = c(NA, -46L), class = "data.frame")
Raw$Date1<-as.Date(Raw$Date,"%d/%m")
library(lattice)
par(mfrow=c(1,4))
culr<-ifelse(Raw$Year=="Y2002","Black","Grey")
xyplot(Abun~Date1|Station,Raw,type="p",xlab=list("Month",cex=1.5),ylab=list(
"Abundance",cex=1.5),cex=2,pch=16,col=culr,strip=strip.custom(bg='white'))


Many thanks.

Regards,
Christine

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Fri Aug 28 01:50:40 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 27 Aug 2015 19:50:40 -0400
Subject: [R] Problem with gridExtra
In-Reply-To: <20150827193316.GA14710@localhost.localdomain>
References: <20150827193316.GA14710@localhost.localdomain>
Message-ID: <CAGx1TMBOZKfJsNzi8reyqghsLeOXZd4RyLm-FDhLyFbFvwVNgA@mail.gmail.com>

gridExtra was changed.  This is the email from Baptiste to CRAN package
developers that describes the changes and
points to the vignettes that will describe the changes.  The changes
described here are now in the current release of gridExtra.

Baptiste Auguie <baptiste.auguie at gmail.com>
Jul 9
Reply
to Borja, Pablo, Paul-Christian, Zachary, Andrey, Liam, Michael, Rafael,
Mikkel, Xinyu, Christopher, Andrew, Thierry, Diogo, Grigori, Felix, Adelino
, Dean, Wencke, Brian, me, Frank, Jason, Pieter, Timothy
Dear package maintainers,

I'm working on a long-overdue update of gridExtra for CRAN, and I believe
your package depends on it. Please have a look at the dev version on
github, and let me know if it breaks something in your package.

https://github.com/baptiste/gridextra

I've removed practically everything; only two main functions are left:
grid.arrange(),
and grid.table(). I believe they were by-and-large the only ones actually
used, and the rest was mostly experimental code that shouldn't stay on
CRAN.
I've rewritten these two functions using gtable, which I found more
practical and extensible. However, this means that the new functions are
entirely different from their predecessor, internally, and may break a lot
of code. I have included two vignettes for an overview of these updated
functions, also reproduced in the wiki:
https://github.com/baptiste/gridextra/wiki/tableGrob
https://github.com/baptiste/gridextra/wiki/arrangeGrob

Regards,

baptiste

On Thu, Aug 27, 2015 at 3:33 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> Please consider the snippet at the end of the email, largely based on
> what you find here
>
> http://bit.ly/1ND6MGa
>
> When I run it, I get this error
>
> Error in arrangeGrob(p, sub = textGrob("Footnote", x = 0, hjust =
> -0.1,  :
>  could not find function "textGrob"
>
> However, the code runs on another machine I own. I suppose something
> must have changed in the gridExtra library but right now I am banging
> my head against the wall.
>
> This is my sessionInfo()
>
> sessionInfo()
>>
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux stretch/sid
>
> locale:
> [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
>    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
>     [9] LC_ADDRESS=C              LC_TELEPHONE=C
>     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] gridExtra_2.0.0 ggplot2_1.0.1
>
> loaded via a namespace (and not attached):
> [1] Rcpp_0.11.6      digest_0.6.8     MASS_7.3-43      grid_3.2.2
>  [5] plyr_1.8.3       gtable_0.1.2     magrittr_1.5     scales_0.3.0
>   [9] stringi_0.5-5    reshape2_1.4.1   proto_0.3-10     labeling_0.3
>   [13] tools_3.2.2      stringr_1.0.0    munsell_0.4.2
> colorspace_1.2-6
>
> Any suggestion is appreciated.
> Cheers
>
> Lorenzo
>
>
> ##############################################################
> library(ggplot2)
> toyota <- mpg[which(mpg$manufacturer == 'toyota'), ]
> p <- ggplot(toyota, aes(displ, hwy)) + facet_wrap(~ class, ncol = 2) +
> geom_point(aes(size=cyl))
> print(p)
> library(gridExtra)
> g <- arrangeGrob(p, sub = textGrob("Footnote", x = 0, hjust = -0.1,
> vjust=0.1, gp = gpar(fontface = "italic", fontsize = 18)))
> ggsave("/Users/Alan/Desktop/plot_grid_extra.png", g)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From s-dhar at northwestern.edu  Fri Aug 28 06:11:45 2015
From: s-dhar at northwestern.edu (Sumitrajit Dhar)
Date: Fri, 28 Aug 2015 04:11:45 +0000
Subject: [R] Piecewise regression using segmented package plotted in xyplot
Message-ID: <D81659F0-721B-44DE-AF80-EC2269429ACB@northwestern.edu>

Hi,

xyplot(threshold ~ age |frequency.a, data=rage,
groups=HL,
  cex=0.5,
  layout=c(7,4),
par.strip.tex=list(cex=0.8),
  xlab="Age (years)",
  ylab="Threshold (dB SPL)",
  na.rm="TRUE",
  panel=function(x,y,groups,...) {
panel.superpose(x,y,groups=HL,...)
# panel.abline(segmented(lm(threshold~age),seg.Z = ~age, psi = NA, control = seg.control(K=1)))
panel.abline(lm(threshold~age))
  },
  )

Is there anyway to make the commented line work in lattice? I need to fit my data in each panel using piecewise regression. Being able to use segmented would make it easy.

The code above works to give me a linear fit.

Thanks for your help in advance.

Regards,
Sumit



	[[alternative HTML version deleted]]


From lucasmalta at yahoo.com.br  Fri Aug 28 00:15:09 2015
From: lucasmalta at yahoo.com.br (lucasmalta)
Date: Thu, 27 Aug 2015 15:15:09 -0700 (PDT)
Subject: [R] Gaussian Mixture Regression
Message-ID: <1440713709001-4711583.post@n4.nabble.com>

Hi,

I am looking for a way to run a Gaussian Mixture Regression (GMR) in R.

In other words, say that I have a Gaussian Mixture Model (GMM) calculated
using, for example, the MClust library. This model represents the joint
distribution of two independent variables P(A,B). I need to calculate P(A|B
= b).

I have seen implementations in  Matlab
<http://www.mathworks.com/matlabcentral/fileexchange/19630-gaussian-mixture-model--gmm--gaussian-mixture-regression--gmr-/content/GMM-GMR-v2.0/GMR.m>  
and  Python <http://pypr.sourceforge.net/mog.html>   for that, but the rest
of my project is in R. I wanted to make sure it does not exist (no luck on
Google so far...) before trying to implement it myself. 

Thanks in advance,

l.



--
View this message in context: http://r.789695.n4.nabble.com/Gaussian-Mixture-Regression-tp4711583.html
Sent from the R help mailing list archive at Nabble.com.


From daffodil416 at yahoo.com  Fri Aug 28 01:00:43 2015
From: daffodil416 at yahoo.com (Angela)
Date: Thu, 27 Aug 2015 16:00:43 -0700
Subject: [R] heat map labeling
Message-ID: <1440716443.82545.YahooMailBasic@web161501.mail.bf1.yahoo.com>

Hello,

I have a dataset of 985 genes, looks something like the ones below. I want to label only those with the high intensities, since labeling all doesn't show up. Is there a way to do that? If not, is there a way to pull out the highest ones (say, highest 50, or those above X amount) and only show those in a heat map? Thanks!

-Angela

Z transforming gives all cells the same value, just + or - (for example, all have 0.5 and -0.5). The researchers want the actual values used.

Gene   var1       var2
A	8000000	0
B	250000	300000
C	750000	2000000
D	0	        0
E	4000000	6000000
E	5000000	700000
E	1000000	1000000
F	6000000	6000000
F	700000	827460
G	420930	400000
H	0	        0
H	1000000	1000000
I	700000	600000
J	0	        700000
K	0	        0
L	200000	500000
L	1000000	3000000


From bhh at xs4all.nl  Fri Aug 28 06:48:39 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 28 Aug 2015 06:48:39 +0200
Subject: [R] lsqlin in R package pracma
In-Reply-To: <2f3a88$1aa933@ironport10.mayo.edu>
References: <1D693EC430D9BA40A64CB59875BED8CF0172F96EF339@USCTMXP51004.merck.com>
	<2f3a88$1aa933@ironport10.mayo.edu>
Message-ID: <E5740CFB-155F-4832-8C83-ED0B3E1FB647@xs4all.nl>


> On 27 Aug 2015, at 23:12, Wang, Xue, Ph.D. <Wang.Xue at mayo.edu> wrote:
> 
> Hi Richard,
> 
> It is good to know that solve.QP could solve quadratic programming problem. The difficulty here is that the objective function might not be in quadratic form. It is not in the form of t(X)QX, where Q is an n by n symmetric matrix.

Unless I?m very mistaken the objective function is in the form you mention.
The quadratic part is  t(x) %*% t(C) %*% C %*% x so your Q is simply equivalent to t(C) %*% C.

Berend


From Gerrit.Eichner at math.uni-giessen.de  Fri Aug 28 08:56:08 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 28 Aug 2015 08:56:08 +0200 (MEST)
Subject: [R] Fisher's Test 5x4 table
In-Reply-To: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
References: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>

Dear Paul,

quoting the email-footer: "PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html and provide commented, 
minimal, self-contained, reproducible code."

So, what exactly did you try and what was the actual problem/error 
message?

Besides that, have you noted that two of you data rows have the same name?


Have you read the online help page of fisher.test():

  ?fisher.test


Have you tried anything like the following?

W <- as.matrix( read.table( "w.txt", head = T)[-1])

fisher.test( W, workspace = 1e8)
    # For workspace look at the help page, but it presumably
    # won't work because of your sample size.


set.seed( 20150828) # for reproducibility
fisher.test( W, simulate.p.value = TRUE, B = 1e5)
    # For B look at the help page.


Finally: Did Minitab really report "p > 0.001"? ;-)

  Hth  --  Gerrit

> Dear all,
>            I am trying to do a fishers test on a 5x4 table on R
> statistics. I have already done a chi squared test using Minitab on this
> data set, getting a result of (1, N = 165.953, DF 12, p>0.001), yet using
> these results (even though they are excellent) may not be suitable for
> publication. I have tried numerous other statistical packages in the hope
> of doing this test, yet each one has just the 2x2 table.
>            I am struggling to edit the template fishers test on R to fit
> my table (as according to the R book it is possible, yet i cannot get it to
> work). The template given on the R documentation and R book is for a 2x2
> fisher test. What do i need to change to get this to work? I have attached
> the data with the email so one can see what i am on about. Or do i have to
> write my own new code to compute this.
>
>             Yours Sincerely,
>                                     Paul Brett
>


From suparna.mitra.sm at gmail.com  Fri Aug 28 11:22:44 2015
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 28 Aug 2015 10:22:44 +0100
Subject: [R] Problem loading mvabund package
Message-ID: <CAFdg=fWFk=3q1=0TNrZ40+RVAVX86N_0YPfmy3VsThGv+a7XyA@mail.gmail.com>

Hello,
  Can anybody please help me with mvabund  package installation?
I downloaded and installed it. It seems installed, but I can't load the
package.
Here is what I tried:


> install.packages("/Users/smitra/Documents/Soft/mvabund_3.10.4.tgz", repos
= NULL, type="source")
* installing *binary* package ?mvabund? ...
* DONE (mvabund)

> library(mvabund)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
:
  there is no package called ?tweedie?
Error: package or namespace load failed for ?mvabund?


Any help will be great.
Thanks.
Suparna

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Aug 28 12:16:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 28 Aug 2015 20:16:27 +1000
Subject: [R] heat map labeling
In-Reply-To: <1440716443.82545.YahooMailBasic@web161501.mail.bf1.yahoo.com>
References: <1440716443.82545.YahooMailBasic@web161501.mail.bf1.yahoo.com>
Message-ID: <CA+8X3fUX0SxD3uyuDRopMaO7eApOqPaUdrBG_tcUm5aRCU1nTQ@mail.gmail.com>

Hi Angela,
Assuming the above data frame is named angela.df:

angela.mat<-as.matrix(angela.df[,2:3])
angela.mat<-angela.mat[apply(angela.mat,1,function(x) all(x) > 0),]

will remove all of the rows that have contain at least one zero.

Jim


On Fri, Aug 28, 2015 at 9:00 AM, Angela via R-help <r-help at r-project.org>
wrote:

> Hello,
>
> I have a dataset of 985 genes, looks something like the ones below. I want
> to label only those with the high intensities, since labeling all doesn't
> show up. Is there a way to do that? If not, is there a way to pull out the
> highest ones (say, highest 50, or those above X amount) and only show those
> in a heat map? Thanks!
>
> -Angela
>
> Z transforming gives all cells the same value, just + or - (for example,
> all have 0.5 and -0.5). The researchers want the actual values used.
>
> Gene   var1       var2
> A       8000000 0
> B       250000  300000
> C       750000  2000000
> D       0               0
> E       4000000 6000000
> E       5000000 700000
> E       1000000 1000000
> F       6000000 6000000
> F       700000  827460
> G       420930  400000
> H       0               0
> H       1000000 1000000
> I       700000  600000
> J       0               700000
> K       0               0
> L       200000  500000
> L       1000000 3000000
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Fri Aug 28 12:16:48 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 28 Aug 2015 11:16:48 +0100
Subject: [R] attribute color to a list
Message-ID: <CALJKBv9WzauVYMVYjw+c92pnbu45Cx=21098Sb61yLFQ-eNsgQ@mail.gmail.com>

Hi,
attriColorValue works with one value. I would like to get the color of a
list with lappy but in input I have two variables (the value and the list).


attriColorValue <- function(Value, list, colors=c(a,b,c, d,e),feet){

     list <- round(list, digits = 0)
    Max <- max(list, na.rm=TRUE)
    Min <- min(list, na.rm=TRUE)

  my.colors <- colorRampPalette(colors)
  #generates Max-Min colors from the color ramp
  color.df<-data.frame(COLOR_VALUE=seq(Min,Max,feet),
color.name=my.colors(length(seq(Min,Max,feet))))

  colorRef <- color.df[which(color.df[,1]==Value),2]
  return(colorRef)
}

list <-
c(7607.2149,36.0673,26.5613,-21.094,535.1462,8460.8617,3112.3839,1810.5521,-2783.7832,-1283.5496,879.4978,-307.8481,133.6729,51.6518,-212.3436,-118.6624,912.8616,16.7501,465.6139,486.3803,1051.6673,-1529.426,198.9787,-265.013,74.0492,-52.0192,-97.655,-5963.4183,-2118.4033,5701.5644,1987.7252,1638.274,1576.775,1520.7626,1039.4264,905.7974,-966.3739,365.2626,364.8378,258.3969,-323.999,-394.7463)

works
as.character(attriColorValue(123,list, colors=c("blue","white","red") ,
feet=1))

not working??
lapply(list, function(x) attriColorValue(x,df$exprsMeanDiff ,colors, feet))

Thanks
Karim

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Aug 28 12:35:10 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 28 Aug 2015 20:35:10 +1000
Subject: [R] attribute color to a list
In-Reply-To: <CALJKBv9WzauVYMVYjw+c92pnbu45Cx=21098Sb61yLFQ-eNsgQ@mail.gmail.com>
References: <CALJKBv9WzauVYMVYjw+c92pnbu45Cx=21098Sb61yLFQ-eNsgQ@mail.gmail.com>
Message-ID: <CA+8X3fXDbtHri1hRkbaCxKnbmM-RUTvuT97KGJ4zisDj3nCwNA@mail.gmail.com>

Hi Karim,
I'm not sure that this is what is causing the error, but your "list" is
actually a vector. The following runs, but the function is obviously not
working:

sapply(list,
 function(x)
as.character(attriColorValue(x,list,colors=c("blue","white","red"),feet=1)))

There is probably a better name for your vector than "list".

Jim


On Fri, Aug 28, 2015 at 8:16 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Hi,
> attriColorValue works with one value. I would like to get the color of a
> list with lappy but in input I have two variables (the value and the list).
>
>
> attriColorValue <- function(Value, list, colors=c(a,b,c, d,e),feet){
>
>      list <- round(list, digits = 0)
>     Max <- max(list, na.rm=TRUE)
>     Min <- min(list, na.rm=TRUE)
>
>   my.colors <- colorRampPalette(colors)
>   #generates Max-Min colors from the color ramp
>   color.df<-data.frame(COLOR_VALUE=seq(Min,Max,feet),
> color.name=my.colors(length(seq(Min,Max,feet))))
>
>   colorRef <- color.df[which(color.df[,1]==Value),2]
>   return(colorRef)
> }
>
> list <-
>
> c(7607.2149,36.0673,26.5613,-21.094,535.1462,8460.8617,3112.3839,1810.5521,-2783.7832,-1283.5496,879.4978,-307.8481,133.6729,51.6518,-212.3436,-118.6624,912.8616,16.7501,465.6139,486.3803,1051.6673,-1529.426,198.9787,-265.013,74.0492,-52.0192,-97.655,-5963.4183,-2118.4033,5701.5644,1987.7252,1638.274,1576.775,1520.7626,1039.4264,905.7974,-966.3739,365.2626,364.8378,258.3969,-323.999,-394.7463)
>
> works
> as.character(attriColorValue(123,list, colors=c("blue","white","red") ,
> feet=1))
>
> not working??
> lapply(list, function(x) attriColorValue(x,df$exprsMeanDiff ,colors, feet))
>
> Thanks
> Karim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Fri Aug 28 12:51:28 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 28 Aug 2015 11:51:28 +0100
Subject: [R] attribute color to a list
In-Reply-To: <CA+8X3fXDbtHri1hRkbaCxKnbmM-RUTvuT97KGJ4zisDj3nCwNA@mail.gmail.com>
References: <CALJKBv9WzauVYMVYjw+c92pnbu45Cx=21098Sb61yLFQ-eNsgQ@mail.gmail.com>
	<CA+8X3fXDbtHri1hRkbaCxKnbmM-RUTvuT97KGJ4zisDj3nCwNA@mail.gmail.com>
Message-ID: <CALJKBv9QErv+6meUHpPPLk2OqLQFPTVDA-3w1Nxm6RWiu-XU2g@mail.gmail.com>

Hi,
Thank you for comments.
Yes it is a vector an not a list ;).
I need to round also the input Value (Value <- round(Value, digits=0). If
not Matching is not possible. The vector is a real number and the color.df
are Integer.
Thanks for sapply is better than lapply in my case.
Karim

On Fri, Aug 28, 2015 at 11:35 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Karim,
> I'm not sure that this is what is causing the error, but your "list" is
> actually a vector. The following runs, but the function is obviously not
> working:
>
> sapply(list,
>  function(x)
> as.character(attriColorValue(x,list,colors=c("blue","white","red"),feet=1)))
>
> There is probably a better name for your vector than "list".
>
> Jim
>
>
> On Fri, Aug 28, 2015 at 8:16 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> Hi,
>> attriColorValue works with one value. I would like to get the color of a
>> list with lappy but in input I have two variables (the value and the
>> list).
>>
>>
>> attriColorValue <- function(Value, list, colors=c(a,b,c, d,e),feet){
>>
>>      list <- round(list, digits = 0)
>>     Max <- max(list, na.rm=TRUE)
>>     Min <- min(list, na.rm=TRUE)
>>
>>   my.colors <- colorRampPalette(colors)
>>   #generates Max-Min colors from the color ramp
>>   color.df<-data.frame(COLOR_VALUE=seq(Min,Max,feet),
>> color.name=my.colors(length(seq(Min,Max,feet))))
>>
>>   colorRef <- color.df[which(color.df[,1]==Value),2]
>>   return(colorRef)
>> }
>>
>> list <-
>>
>> c(7607.2149,36.0673,26.5613,-21.094,535.1462,8460.8617,3112.3839,1810.5521,-2783.7832,-1283.5496,879.4978,-307.8481,133.6729,51.6518,-212.3436,-118.6624,912.8616,16.7501,465.6139,486.3803,1051.6673,-1529.426,198.9787,-265.013,74.0492,-52.0192,-97.655,-5963.4183,-2118.4033,5701.5644,1987.7252,1638.274,1576.775,1520.7626,1039.4264,905.7974,-966.3739,365.2626,364.8378,258.3969,-323.999,-394.7463)
>>
>> works
>> as.character(attriColorValue(123,list, colors=c("blue","white","red") ,
>> feet=1))
>>
>> not working??
>> lapply(list, function(x) attriColorValue(x,df$exprsMeanDiff ,colors,
>> feet))
>>
>> Thanks
>> Karim
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From hwborchers at gmail.com  Fri Aug 28 12:56:57 2015
From: hwborchers at gmail.com (Hans W Borchers)
Date: Fri, 28 Aug 2015 12:56:57 +0200
Subject: [R] lsqlin in R package pracma
In-Reply-To: <1D693EC430D9BA40A64CB59875BED8CF0172F96EF339@USCTMXP51004.merck.com>
References: <1D693EC430D9BA40A64CB59875BED8CF0172F96EF339@USCTMXP51004.merck.com>
Message-ID: <CAML4n3Nbty1vgzeueLPccp_xj__UweZ1-O1Vnr7U8UUGk2QK9w@mail.gmail.com>

I got interested in enabling the full funcionality that MATLAB's
lsqlin() has, that is with equality and bound constraints. To replace
an equality constraint with two inequality constraints will not work
with solve.QP() because it requires positive definite matrices. I will
use kernlab::ipop() instead.

To handle the full MATLAB example, add the following simple linear
equality constraint  3x1 + 5x2 + 7x3 + 9x4 = 4 to the example above,
plus lower and upper bounds -0.1 and 2.0 for all x_i.

    C <- matrix(c(
        0.9501,   0.7620,   0.6153,   0.4057,
        0.2311,   0.4564,   0.7919,   0.9354,
        0.6068,   0.0185,   0.9218,   0.9169,
        0.4859,   0.8214,   0.7382,   0.4102,
        0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
    d <- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
    A <- matrix(c(
        0.2027,   0.2721,   0.7467,   0.4659,
        0.1987,   0.1988,   0.4450,   0.4186,
        0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
    b <- c(0.5251, 0.2026, 0.6721)

    # Add the equality constraint to matrix A
    Aeq <- c(3, 5, 7, 9)
    beq <- 4
    A1 <- rbind(A ,  c(3, 5, 7, 9))
    b1 <- c(b, 4)
    lb <- rep(-0.1, 4)   # lower and upper bounds
    ub <- rep( 2.0, 4)
    r1 <- c(1, 1, 1, 0)  # 0 to force an equality constraint

    # Prepare for a quadratic solver
    Dmat <- t(C) %*% C
    dvec <- (t(C) %*% d)
    Amat <- -1 * A1
    bvec <- -1 * b1

    library(kernlab)
    s <- ipop(-dvec, Dmat, Amat, bvec, lb, ub, r1)
    s
    # An object of class "ipop"
    # Slot "primal":
    # [1] -0.09999885 -0.09999997  0.15990817  0.40895991
    # ...

    x <- s at primal           # [1] -0.1000  -0.1000  0.1599  0.4090
    A1 %*% x - b1 <= 0      # i.e., A x <= b and 3x[1] + ... + 9x[4] = 4
    sum((C %*% x - d)^2)    # minimum: 0.1695

And this is exactly the solution that lsqlin() in MATLAB computes.


On Thu, Aug 27, 2015 at 6:06 PM, Raubertas, Richard
<richard_raubertas at merck.com> wrote:
> Is it really that complicated?  This looks like an ordinary quadratic programming problem, and 'solve.QP' from the 'quadprog' package seems to solve it without user-specified starting values:
>
> library(quadprog)
> Dmat <- t(C) %*% C
> dvec <- (t(C) %*% d)
> Amat <- -1 * t(A)
> bvec <- -1 * b
>
> rslt <- solve.QP(Dmat, dvec, Amat, bvec)
> sum((C %*% rslt$solution - d)^2)
>
> [1] 0.01758538
>
> Richard Raubertas
> Merck & Co.
>


From S.Ellison at LGCGroup.com  Fri Aug 28 13:04:11 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 28 Aug 2015 12:04:11 +0100
Subject: [R] Piecewise regression using segmented package plotted in
	xyplot
In-Reply-To: <D81659F0-721B-44DE-AF80-EC2269429ACB@northwestern.edu>
References: <D81659F0-721B-44DE-AF80-EC2269429ACB@northwestern.edu>
Message-ID: <1A8C1289955EF649A09086A153E2672403B455185E@GBTEDVPEXCMB04.corp.lgc-group.com>

There isn't an abline method for segmented, and even if there were you'd need segments() for a segmented line plot. You're going to have to roll your own.  That will need a function to extract the break locations and predicted values at those points

I don't have your data, so I can't do one specifically for you. But here's a version that works on the data in the first example in ?segmented. I've deliberately separated segmented model fitting and line segment extraction (get.segments) from the panel function that plots them, as that would then work with the base graphics segments function

#Construct the data set (from ?segmented, though the z covariate is not used here)
  set.seed(12)
  xx<-1:100
  zz<-runif(100)
  yy<-2+1.5*pmax(xx-35,0)-1.5*pmax(xx-70,0)+15*pmax(zz-.5,0)+rnorm(100,0,2)
  dati<-data.frame(x=xx,y=yy,z=zz)
  


# Function to fit a simple model using segmented
# and then get line segment data from the model
# For the latter, I've used code from plot. segmented to locate extremes 
# and break points (in psi) and then just used 
# predict() rather crudely to get the corresponding ordinate values
# you would have to do something more clever
# if your model is not just y~x

get.segments <- function(x, y, term, ...) {
   #Returns a data frame of line segment coordinates
   #from a simple segmented() model
   
    S <- segmented(lm(y~x), seg.Z=~x,psi=list(x=c(30,60)),
                   control=seg.control(display=FALSE))
   if(missing(term)) term <- S$nameUV$Z[1]
   x<-with(S, sort(c(psi[,'Est.'], rangeZ[,term])))
   #Then cheat a bit
   new <- data.frame(x=unname(x))
   names(new) <- term
   y <- predict(S, new=new)
   L <- length(x) -1
  #return the line segment data in an easy-to-use format
  data.frame(x0=x[1:L], y0=y[1:L], x1=x[1:L + 1], y1=y[1:L + 1])
}

#Write a panel function using that...
panel.segmented <- function(x, y, ...) {
	## Fit the simple model
     	m <- get.segments( x, y )
	#Plot the segments
	with(m, panel.segments(x0, y0, x1, y1, ... ))
}

library(lattice)
xyplot(y~x, data=dati,
    panel = function(x, y, ...) {
	panel.xyplot(x, y, ...)
     	panel.segmented(x, y, ...)
    }
)

#And just to see if it works for panel-grouped data:
set.seed(1023)
dati$parts <- sample(gl(2, 50))
xyplot(y~x|parts, data=dati,
    panel = function(x, y, ...) {
	panel.xyplot(x, y, ...)
     	panel.segmented(x, y, ...)
    }
)

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From lists at dewey.myzen.co.uk  Fri Aug 28 13:09:44 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 28 Aug 2015 12:09:44 +0100
Subject: [R] Problem loading mvabund package
In-Reply-To: <CAFdg=fWFk=3q1=0TNrZ40+RVAVX86N_0YPfmy3VsThGv+a7XyA@mail.gmail.com>
References: <CAFdg=fWFk=3q1=0TNrZ40+RVAVX86N_0YPfmy3VsThGv+a7XyA@mail.gmail.com>
Message-ID: <55E04178.4070603@dewey.myzen.co.uk>

Dear Suparna,

See below

On 28/08/2015 10:22, Suparna Mitra wrote:
> Hello,
>    Can anybody please help me with mvabund  package installation?
> I downloaded and installed it. It seems installed, but I can't load the
> package.
> Here is what I tried:
>
>
>> install.packages("/Users/smitra/Documents/Soft/mvabund_3.10.4.tgz", repos
> = NULL, type="source")
> * installing *binary* package ?mvabund? ...
> * DONE (mvabund)
>
>> library(mvabund)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
> :
>    there is no package called ?tweedie?

There are two possibilities here
1 - you have not installed tweedie
2 - you have and R cannot find it

> Error: package or namespace load failed for ?mvabund?
>
>
> Any help will be great.
> Thanks.
> Suparna
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From S.Ellison at LGCGroup.com  Fri Aug 28 13:25:50 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 28 Aug 2015 12:25:50 +0100
Subject: [R] Piecewise regression using segmented package plotted in
	xyplot
In-Reply-To: <D81659F0-721B-44DE-AF80-EC2269429ACB@northwestern.edu>
References: <D81659F0-721B-44DE-AF80-EC2269429ACB@northwestern.edu>
Message-ID: <1A8C1289955EF649A09086A153E2672403B455187C@GBTEDVPEXCMB04.corp.lgc-group.com>

I perhaps should have added a stronger warning here; note that the model fitting in my previous post (below) uses explicit initial breakpoints for segmented (specifically, c(30,60) at line 1 of the get.segments() ). if you know where yours are, substitute them there.  Otherwise, you'd need to use the automated breakpoint routines documented in ?segmented, typically adjusting the control list. To be general,  you'd need a way to get a choice of at least number of breakpoints into the model. xyplot doesn't (I think) pass extra parameters to its panel function, but it will pick up environment parameters so you _could_ just rely on that, or perhaps on setting something in options(), as a quick and dirty work-round. 
 
S Ellisaon

--------------------------
There isn't an abline method for segmented, and even if there were you'd need segments() for a segmented line plot. You're going to have to roll your own.  That will need a function to extract the break locations and predicted values at those points

I don't have your data, so I can't do one specifically for you. But here's a version that works on the data in the first example in ?segmented. I've deliberately separated segmented model fitting and line segment extraction (get.segments) from the panel function that plots them, as that would then work with the base graphics segments function

#Construct the data set (from ?segmented, though the z covariate is not used here)
  set.seed(12)
  xx<-1:100
  zz<-runif(100)
  yy<-2+1.5*pmax(xx-35,0)-1.5*pmax(xx-70,0)+15*pmax(zz-.5,0)+rnorm(100,0,2)
  dati<-data.frame(x=xx,y=yy,z=zz)
  


# Function to fit a simple model using segmented
# and then get line segment data from the model
# For the latter, I've used code from plot. segmented to locate extremes 
# and break points (in psi) and then just used 
# predict() rather crudely to get the corresponding ordinate values
# you would have to do something more clever
# if your model is not just y~x

get.segments <- function(x, y, term, ...) {
   #Returns a data frame of line segment coordinates
   #from a simple segmented() model
   
    S <- segmented(lm(y~x), seg.Z=~x,psi=list(x=c(30,60)),
                   control=seg.control(display=FALSE))
   if(missing(term)) term <- S$nameUV$Z[1]
   x<-with(S, sort(c(psi[,'Est.'], rangeZ[,term])))
   #Then cheat a bit
   new <- data.frame(x=unname(x))
   names(new) <- term
   y <- predict(S, new=new)
   L <- length(x) -1
  #return the line segment data in an easy-to-use format
  data.frame(x0=x[1:L], y0=y[1:L], x1=x[1:L + 1], y1=y[1:L + 1])
}

#Write a panel function using that...
panel.segmented <- function(x, y, ...) {
	## Fit the simple model
     	m <- get.segments( x, y )
	#Plot the segments
	with(m, panel.segments(x0, y0, x1, y1, ... ))
}

library(lattice)
xyplot(y~x, data=dati,
    panel = function(x, y, ...) {
	panel.xyplot(x, y, ...)
     	panel.segmented(x, y, ...)
    }
)

#And just to see if it works for panel-grouped data:
set.seed(1023)
dati$parts <- sample(gl(2, 50))
xyplot(y~x|parts, data=dati,
    panel = function(x, y, ...) {
	panel.xyplot(x, y, ...)
     	panel.segmented(x, y, ...)
    }
)

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From Gerrit.Eichner at math.uni-giessen.de  Fri Aug 28 15:52:37 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 28 Aug 2015 15:52:37 +0200 (MEST)
Subject: [R] Fisher's Test 5x4 table
In-Reply-To: <CAE1X91oc9wa=LaAc=Sk3r2c4OS-ZSMbnmWd25eacXtWODvUbFw@mail.gmail.com>
References: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
	<Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91oc9wa=LaAc=Sk3r2c4OS-ZSMbnmWd25eacXtWODvUbFw@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1508281537530.27473@solcom.hrz.uni-giessen.de>

Paul,

as the error messages of your first three attempts (see below) tell you - 
in an admittedly rather cryptic way - your table or its sample size, 
respectively, are too large, so that either the "largest (hash table) key" 
is too large, or your (i.e., R's) workspace is too small, or your 
hardware/os cannot allocate enough memory to calculate the p-value of 
Fisher Exact Test exactly by means of the implemented algorithm.

One way out of this is to approximate the exact p-value through 
simulation, but apparently there occurred a typo in your (last) attempt to 
do that (Error: unexpected '>' in ">").


So, for me the following works (and it should also for you) and gives the 
shown output (after a very short while):

> Trapz <- as.matrix( read.table( "w.txt", head = T, row.names = "Traps"))

> set.seed( 20150828)   # For the sake of reproducibility.
> fisher.test( Trapz, simulate.p.value = TRUE,
+             B = 1e5)

    Fisher's Exact Test for Count Data with simulated p-value (based on
    1e+05 replicates)

data:  Trapz
p-value = 1e-05
alternative hypothesis: two.sided



Or for a higher value for B if you are patient enough (with a computing 
time of several seconds) :

> set.seed( 20150828)
> fisher.test( Trapz, simulate.p.value=TRUE, B = 1e7)

    Fisher's Exact Test for Count Data with simulated p-value (based on
    1e+07 replicates)

data:  Trapz
p-value = 1e-07
alternative hypothesis: two.sided


  Hth  --  Gerrit

(BTW, you don't have to specify arguments (in function calls) whose 
default values you don't want to change.)



On Fri, 28 Aug 2015, paul brett wrote:

> Hi Gerrit,
>             I spotted that, it was a mistake on my own part, it should
> read 1.trap.2.barrier. I have corrected it on the file attached.
>
> So I have done these so far:
> > fisher.test(Trapz, workspace = 200000, hybrid = FALSE, control = list(),
> or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
> 0.95,simulate.p.value = FALSE, B = 2000)
> Error in fisher.test(Trapz, workspace = 2e+05, hybrid = FALSE, control =
> list(),  :
>  FEXACT error 501.
> The hash table key cannot be computed because the largest key
> is larger than the largest representable int.
> The algorithm cannot proceed.
> Reduce the workspace size or use another algorithm.
>
>> fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control = list(), or
> = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
> 0.95,simulate.p.value = FALSE, B = 2000)
> Error in fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control =
> list(),  :
>  FEXACT error 40.
> Out of workspace.
>> fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or
> = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
> 0.95,simulate.p.value = FALSE, B = 2000)
> Error in fisher.test(Trapz, workspace = 1e+08, hybrid = FALSE, control =
> list(),  :
>  FEXACT error 501.
> The hash table key cannot be computed because the largest key
> is larger than the largest representable int.
> The algorithm cannot proceed.
> Reduce the workspace size or use another algorithm.
>> fisher.test(Trapz, workspace = 2000000000, hybrid = FALSE, control =
> list(), or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
> 0.95,simulate.p.value = FALSE, B = 2000)
> Error: cannot allocate vector of size 7.5 Gb
> In addition: Warning messages:
> 1: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
> list(),  :
>  Reached total allocation of 6027Mb: see help(memory.size)
> 2: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
> list(),  :
>  Reached total allocation of 6027Mb: see help(memory.size)
> 3: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
> list(),  :
>  Reached total allocation of 6027Mb: see help(memory.size)
> 4: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
> list(),  :
>  Reached total allocation of 6027Mb: see help(memory.size)
>
> fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or =
> 1, alternative = "two.sided", conf.int = TRUE, conf.level =
> 0.95,simulate.p.value = TRUE, B = 1e5)
> Error: unexpected '>' in ">"
>
> So the issue could be perhaps that R cannot compute my sample as the
> workspace needed is too big? Is there a way around this? I think I have
> everything set out correctly.
> Is my only other alternative is to do a 2x2 fisher test for each of the
> variables?
>
> I attach on the pdf the Minitab result for the Chi squared test as proof (I
> know that getting very low p values are highly unlikely but sometimes it
> happens). Seeing is believing i suppose!
>
> Regards,
>             Paul
>
>
>
> On Fri, Aug 28, 2015 at 8:56 AM, Gerrit Eichner <
> Gerrit.Eichner at math.uni-giessen.de> wrote:
>
>> Dear Paul,
>>
>> quoting the email-footer: "PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code."
>>
>> So, what exactly did you try and what was the actual problem/error message?
>>
>> Besides that, have you noted that two of you data rows have the same name?
>>
>>
>> Have you read the online help page of fisher.test():
>>
>>  ?fisher.test
>>
>>
>> Have you tried anything like the following?
>>
>> W <- as.matrix( read.table( "w.txt", head = T)[-1])
>>
>> fisher.test( W, workspace = 1e8)
>>    # For workspace look at the help page, but it presumably
>>    # won't work because of your sample size.
>>
>>
>> set.seed( 20150828) # for reproducibility
>> fisher.test( W, simulate.p.value = TRUE, B = 1e5)
>>    # For B look at the help page.
>>
>>
>> Finally: Did Minitab really report "p > 0.001"? ;-)
>>
>>  Hth  --  Gerrit
>>
>>
>> Dear all,
>>>            I am trying to do a fishers test on a 5x4 table on R
>>> statistics. I have already done a chi squared test using Minitab on this
>>> data set, getting a result of (1, N = 165.953, DF 12, p>0.001), yet using
>>> these results (even though they are excellent) may not be suitable for
>>> publication. I have tried numerous other statistical packages in the hope
>>> of doing this test, yet each one has just the 2x2 table.
>>>            I am struggling to edit the template fishers test on R to fit
>>> my table (as according to the R book it is possible, yet i cannot get it
>>> to
>>> work). The template given on the R documentation and R book is for a 2x2
>>> fisher test. What do i need to change to get this to work? I have attached
>>> the data with the email so one can see what i am on about. Or do i have to
>>> write my own new code to compute this.
>>>
>>>             Yours Sincerely,
>>>                                     Paul Brett
>>>
>>>


From brettpaul16 at gmail.com  Fri Aug 28 14:38:04 2015
From: brettpaul16 at gmail.com (paul brett)
Date: Fri, 28 Aug 2015 14:38:04 +0200
Subject: [R] Fisher's Test 5x4 table
In-Reply-To: <Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>
References: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
	<Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>
Message-ID: <CAE1X91oc9wa=LaAc=Sk3r2c4OS-ZSMbnmWd25eacXtWODvUbFw@mail.gmail.com>

Hi Gerrit,
             I spotted that, it was a mistake on my own part, it should
read 1.trap.2.barrier. I have corrected it on the file attached.

So I have done these so far:
 > fisher.test(Trapz, workspace = 200000, hybrid = FALSE, control = list(),
or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
0.95,simulate.p.value = FALSE, B = 2000)
Error in fisher.test(Trapz, workspace = 2e+05, hybrid = FALSE, control =
list(),  :
  FEXACT error 501.
The hash table key cannot be computed because the largest key
is larger than the largest representable int.
The algorithm cannot proceed.
Reduce the workspace size or use another algorithm.

> fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control = list(), or
= 1, alternative = "two.sided", conf.int = TRUE, conf.level =
0.95,simulate.p.value = FALSE, B = 2000)
Error in fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control =
list(),  :
  FEXACT error 40.
Out of workspace.
> fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or
= 1, alternative = "two.sided", conf.int = TRUE, conf.level =
0.95,simulate.p.value = FALSE, B = 2000)
Error in fisher.test(Trapz, workspace = 1e+08, hybrid = FALSE, control =
list(),  :
  FEXACT error 501.
The hash table key cannot be computed because the largest key
is larger than the largest representable int.
The algorithm cannot proceed.
Reduce the workspace size or use another algorithm.
> fisher.test(Trapz, workspace = 2000000000, hybrid = FALSE, control =
list(), or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
0.95,simulate.p.value = FALSE, B = 2000)
Error: cannot allocate vector of size 7.5 Gb
In addition: Warning messages:
1: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
list(),  :
  Reached total allocation of 6027Mb: see help(memory.size)
2: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
list(),  :
  Reached total allocation of 6027Mb: see help(memory.size)
3: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
list(),  :
  Reached total allocation of 6027Mb: see help(memory.size)
4: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
list(),  :
  Reached total allocation of 6027Mb: see help(memory.size)

fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or =
1, alternative = "two.sided", conf.int = TRUE, conf.level =
0.95,simulate.p.value = TRUE, B = 1e5)
Error: unexpected '>' in ">"

 So the issue could be perhaps that R cannot compute my sample as the
workspace needed is too big? Is there a way around this? I think I have
everything set out correctly.
Is my only other alternative is to do a 2x2 fisher test for each of the
variables?

I attach on the pdf the Minitab result for the Chi squared test as proof (I
know that getting very low p values are highly unlikely but sometimes it
happens). Seeing is believing i suppose!

Regards,
             Paul



On Fri, Aug 28, 2015 at 8:56 AM, Gerrit Eichner <
Gerrit.Eichner at math.uni-giessen.de> wrote:

> Dear Paul,
>
> quoting the email-footer: "PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code."
>
> So, what exactly did you try and what was the actual problem/error message?
>
> Besides that, have you noted that two of you data rows have the same name?
>
>
> Have you read the online help page of fisher.test():
>
>  ?fisher.test
>
>
> Have you tried anything like the following?
>
> W <- as.matrix( read.table( "w.txt", head = T)[-1])
>
> fisher.test( W, workspace = 1e8)
>    # For workspace look at the help page, but it presumably
>    # won't work because of your sample size.
>
>
> set.seed( 20150828) # for reproducibility
> fisher.test( W, simulate.p.value = TRUE, B = 1e5)
>    # For B look at the help page.
>
>
> Finally: Did Minitab really report "p > 0.001"? ;-)
>
>  Hth  --  Gerrit
>
>
> Dear all,
>>            I am trying to do a fishers test on a 5x4 table on R
>> statistics. I have already done a chi squared test using Minitab on this
>> data set, getting a result of (1, N = 165.953, DF 12, p>0.001), yet using
>> these results (even though they are excellent) may not be suitable for
>> publication. I have tried numerous other statistical packages in the hope
>> of doing this test, yet each one has just the 2x2 table.
>>            I am struggling to edit the template fishers test on R to fit
>> my table (as according to the R book it is possible, yet i cannot get it
>> to
>> work). The template given on the R documentation and R book is for a 2x2
>> fisher test. What do i need to change to get this to work? I have attached
>> the data with the email so one can see what i am on about. Or do i have to
>> write my own new code to compute this.
>>
>>             Yours Sincerely,
>>                                     Paul Brett
>>
>>
-------------- next part --------------
Traps	Insecta	Diplopoda	Arachnia	Malocostan
5.trap.4.barrier	345	77	200	154
1.trap.4.barrier	170	54	61	58
1.trap.2.barrier	232	19	30	5
1.trap.no.barrier	59	5	6	5
5.trap.no.barrier	105	11	26	37
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Chi squared test in Minitab.pdf
Type: application/pdf
Size: 144073 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150828/8b303833/attachment.pdf>

From pdalgd at gmail.com  Fri Aug 28 16:25:18 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 28 Aug 2015 16:25:18 +0200
Subject: [R] Rcpp, function signature
In-Reply-To: <loom.20150827T173914-631@post.gmane.org>
References: <1440671835.54919.YahooMailBasic@web193402.mail.sg3.yahoo.com>
	<loom.20150827T173914-631@post.gmane.org>
Message-ID: <2CBC2298-C4F6-478E-973D-8FFE1467115B@gmail.com>


On 27 Aug 2015, at 17:40 , Dirk Eddelbuettel <edd at debian.org> wrote:

> Michael Meyer via R-help <r-help <at> r-project.org> writes:
> 
>> I am an  (very) grateful user of Rcpp.
> 
> Glad to hear that!
> 
> But you are on the wrong mailing list. Please ask on rcpp-devel.

But for the benefit of the rest of us: A NumericVector is a pointer, right?

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sethagrima at gmail.com  Fri Aug 28 13:49:29 2015
From: sethagrima at gmail.com (agrima seth)
Date: Fri, 28 Aug 2015 17:19:29 +0530
Subject: [R] Frequency count of terms only in a given column in R
Message-ID: <CANnXLTDiEN+yKPQ-k5-fyGVYpEYGAEoAJnHcBRFB7Fgm53OdOA@mail.gmail.com>

i have a text file with data of the given format:

white snow
lived snow
in snow
lived place
in place
a place
called place
as place

here i have to find the frequency of the terms only in the first column
(i.e.)
white - 1
lived- 2
in -2
a-1
called - 1
as -1

Could you please guide me how to do the above in R.

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Fri Aug 28 16:31:15 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sat, 29 Aug 2015 00:31:15 +1000
Subject: [R] Piecewise regression using segmented package plotted in
	xyplot
In-Reply-To: <D81659F0-721B-44DE-AF80-EC2269429ACB@northwestern.edu>
References: <D81659F0-721B-44DE-AF80-EC2269429ACB@northwestern.edu>
Message-ID: <000d01d0e19e$33082ac0$99188040$@bigpond.com>

Hi

Without a reproducible example I am only guessing 

Try this 

xyplot(threshold ~ age |frequency.a, data=subset(rage !is.na(threshold} &
!is.na(age)),
       groups = HL,
       cex=0.5,
       layout=c(7,4),
       par.strip.tex=list(cex=0.8),
       xlab="Age (years)",
       ylab="Threshold (dB SPL)",
       # na.rm="TRUE", # see above
       type = c("p","l"),  # re-read ?xyplot: from the panel section:
panel.abline(lm(threshold~age))
       panel = panel.superpose,
       panel.groups =function(x,y,groups,...) {

                        panel.xyplot(x,y,...)
                        # panel.abline(segmented(lm(threshold~age),seg.Z =
~age, psi = NA, control = seg.control(K=1)))

                      },
)

I do not know what the commented line means-- you may need to look at the
subscripts section as well as panel.groups of ?xyplot
and ?panel.xyplot

Regards

Duncan

Duncan
Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sumitrajit
Dhar
Sent: Friday, 28 August 2015 14:12
To: r-help at r-project.org
Subject: [R] Piecewise regression using segmented package plotted in xyplot

Hi,

xyplot(threshold ~ age |frequency.a, data=rage,
groups=HL,
  cex=0.5,
  layout=c(7,4),
par.strip.tex=list(cex=0.8),
  xlab="Age (years)",
  ylab="Threshold (dB SPL)",
  na.rm="TRUE",
  panel=function(x,y,groups,...) {
panel.superpose(x,y,groups=HL,...)
# panel.abline(segmented(lm(threshold~age),seg.Z = ~age, psi = NA, control =
seg.control(K=1)))
panel.abline(lm(threshold~age))
  },
  )

Is there anyway to make the commented line work in lattice? I need to fit my
data in each panel using piecewise regression. Being able to use segmented
would make it easy.

The code above works to give me a linear fit.

Thanks for your help in advance.

Regards,
Sumit



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Fri Aug 28 16:42:25 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 28 Aug 2015 10:42:25 -0400
Subject: [R] Frequency count of terms only in a given column in R
In-Reply-To: <CANnXLTDiEN+yKPQ-k5-fyGVYpEYGAEoAJnHcBRFB7Fgm53OdOA@mail.gmail.com>
References: <CANnXLTDiEN+yKPQ-k5-fyGVYpEYGAEoAJnHcBRFB7Fgm53OdOA@mail.gmail.com>
Message-ID: <CAM_vjuk3AVX9LA=cRmHO93SYTCoGpCFmh9oQv=dMyN+1Y9NpFA@mail.gmail.com>

Hi,

On Fri, Aug 28, 2015 at 7:49 AM, agrima seth <sethagrima at gmail.com> wrote:
> i have a text file with data of the given format:
>
> white snow
> lived snow
> in snow
> lived place
> in place
> a place
> called place
> as place

That doesn't specify the format. I can think of at least seven things
that could be:
a character vector
a two-column matrix
a one-column matrix
a two-column data frame, with or without values correctly specified as character
a one-column data frame, with or without values correctly specified as character

The correct answer depends on what the format actually is; you need to
use dput() or some other unambiguous way of providing sample data.

Here are some suggestions for creating a good reproducible example:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Some combination of strsplit() and table(), possibly with apply(),
will be the answer, though.

Sarah

> here i have to find the frequency of the terms only in the first column
> (i.e.)
> white - 1
> lived- 2
> in -2
> a-1
> called - 1
> as -1
>
> Could you please guide me how to do the above in R.
>
>         [[alternative HTML version deleted]]
and please don't post in HTML, as it makes figuring out what you meant
even more difficult.

Sarah


-- 
Sarah Goslee
http://www.functionaldiversity.org


From bhh at xs4all.nl  Fri Aug 28 16:48:52 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 28 Aug 2015 16:48:52 +0200
Subject: [R] lsqlin in R package pracma
In-Reply-To: <CAML4n3Nbty1vgzeueLPccp_xj__UweZ1-O1Vnr7U8UUGk2QK9w@mail.gmail.com>
References: <1D693EC430D9BA40A64CB59875BED8CF0172F96EF339@USCTMXP51004.merck.com>
	<CAML4n3Nbty1vgzeueLPccp_xj__UweZ1-O1Vnr7U8UUGk2QK9w@mail.gmail.com>
Message-ID: <7238F988-D7F5-4C42-9931-F0B1C67242D3@xs4all.nl>



Nice and interesting! Something to remember.

Lesson (for me):

Always first look in Task Views on CRAN.
Choose Optimization and look at Mathematical Programming Solvers.

Berend

> On 28 Aug 2015, at 12:56, Hans W Borchers <hwborchers at gmail.com> wrote:
> 
> I got interested in enabling the full funcionality that MATLAB's
> lsqlin() has, that is with equality and bound constraints. To replace
> an equality constraint with two inequality constraints will not work
> with solve.QP() because it requires positive definite matrices. I will
> use kernlab::ipop() instead.
> 
> To handle the full MATLAB example, add the following simple linear
> equality constraint  3x1 + 5x2 + 7x3 + 9x4 = 4 to the example above,
> plus lower and upper bounds -0.1 and 2.0 for all x_i.
> 
>    C <- matrix(c(
>        0.9501,   0.7620,   0.6153,   0.4057,
>        0.2311,   0.4564,   0.7919,   0.9354,
>        0.6068,   0.0185,   0.9218,   0.9169,
>        0.4859,   0.8214,   0.7382,   0.4102,
>        0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
>    d <- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
>    A <- matrix(c(
>        0.2027,   0.2721,   0.7467,   0.4659,
>        0.1987,   0.1988,   0.4450,   0.4186,
>        0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
>    b <- c(0.5251, 0.2026, 0.6721)
> 
>    # Add the equality constraint to matrix A
>    Aeq <- c(3, 5, 7, 9)
>    beq <- 4
>    A1 <- rbind(A ,  c(3, 5, 7, 9))
>    b1 <- c(b, 4)
>    lb <- rep(-0.1, 4)   # lower and upper bounds
>    ub <- rep( 2.0, 4)
>    r1 <- c(1, 1, 1, 0)  # 0 to force an equality constraint
> 
>    # Prepare for a quadratic solver
>    Dmat <- t(C) %*% C
>    dvec <- (t(C) %*% d)
>    Amat <- -1 * A1
>    bvec <- -1 * b1
> 
>    library(kernlab)
>    s <- ipop(-dvec, Dmat, Amat, bvec, lb, ub, r1)
>    s
>    # An object of class "ipop"
>    # Slot "primal":
>    # [1] -0.09999885 -0.09999997  0.15990817  0.40895991
>    # ...
> 
>    x <- s at primal           # [1] -0.1000  -0.1000  0.1599  0.4090
>    A1 %*% x - b1 <= 0      # i.e., A x <= b and 3x[1] + ... + 9x[4] = 4
>    sum((C %*% x - d)^2)    # minimum: 0.1695
> 
> And this is exactly the solution that lsqlin() in MATLAB computes.
> 
> 
> On Thu, Aug 27, 2015 at 6:06 PM, Raubertas, Richard
> <richard_raubertas at merck.com> wrote:
>> Is it really that complicated?  This looks like an ordinary quadratic programming problem, and 'solve.QP' from the 'quadprog' package seems to solve it without user-specified starting values:
>> 
>> library(quadprog)
>> Dmat <- t(C) %*% C
>> dvec <- (t(C) %*% d)
>> Amat <- -1 * t(A)
>> bvec <- -1 * b
>> 
>> rslt <- solve.QP(Dmat, dvec, Amat, bvec)
>> sum((C %*% rslt$solution - d)^2)
>> 
>> [1] 0.01758538
>> 
>> Richard Raubertas
>> Merck & Co.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Fri Aug 28 17:16:09 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 28 Aug 2015 16:16:09 +0100
Subject: [R] Frequency count of terms only in a given column in R
In-Reply-To: <CAM_vjuk3AVX9LA=cRmHO93SYTCoGpCFmh9oQv=dMyN+1Y9NpFA@mail.gmail.com>
References: <CANnXLTDiEN+yKPQ-k5-fyGVYpEYGAEoAJnHcBRFB7Fgm53OdOA@mail.gmail.com>
	<CAM_vjuk3AVX9LA=cRmHO93SYTCoGpCFmh9oQv=dMyN+1Y9NpFA@mail.gmail.com>
Message-ID: <55E07B39.1080803@dewey.myzen.co.uk>

Dear Agrima

As well as Sarah's seven possibilities an eighth occurs to me: you have 
not yet read it into R in the first place. If that is the case you may 
be able to use read.table to get it into a data frame with columns 
corresponding to your words.
?read.table may be your friend here.

On 28/08/2015 15:42, Sarah Goslee wrote:
> Hi,
>
> On Fri, Aug 28, 2015 at 7:49 AM, agrima seth <sethagrima at gmail.com> wrote:
>> i have a text file with data of the given format:
>>
>> white snow
>> lived snow
>> in snow
>> lived place
>> in place
>> a place
>> called place
>> as place
>
> That doesn't specify the format. I can think of at least seven things
> that could be:
> a character vector
> a two-column matrix
> a one-column matrix
> a two-column data frame, with or without values correctly specified as character
> a one-column data frame, with or without values correctly specified as character
>
> The correct answer depends on what the format actually is; you need to
> use dput() or some other unambiguous way of providing sample data.
>
> Here are some suggestions for creating a good reproducible example:
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> Some combination of strsplit() and table(), possibly with apply(),
> will be the answer, though.
>
> Sarah
>
>> here i have to find the frequency of the terms only in the first column
>> (i.e.)
>> white - 1
>> lived- 2
>> in -2
>> a-1
>> called - 1
>> as -1
>>
>> Could you please guide me how to do the above in R.
>>
>>          [[alternative HTML version deleted]]
> and please don't post in HTML, as it makes figuring out what you meant
> even more difficult.
>
> Sarah
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From edd at debian.org  Fri Aug 28 17:15:51 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 28 Aug 2015 15:15:51 +0000
Subject: [R] Rcpp, function signature
References: <1440671835.54919.YahooMailBasic@web193402.mail.sg3.yahoo.com>
	<loom.20150827T173914-631@post.gmane.org>
	<2CBC2298-C4F6-478E-973D-8FFE1467115B@gmail.com>
Message-ID: <loom.20150828T170713-19@post.gmane.org>

peter dalgaard <pdalgd <at> gmail.com> writes:
> But for the benefit of the rest of us: A NumericVector is a pointer, right?

Effectively even though it is not treated as one by the users.  But you 
know what P in SEXP stands for, and Rcpp objects really are what we call
"proxy objects" for the respective underlying SEXP objects.

Searching the rcpp-devel list archives for the clone() function will bring
a number of preceding discussions.  As I said in the previous email, this
list is not the best place to discuss Rcpp matters --- rcpp-devel is. 
Please feel free to bring follow-up questions there.

Dirk


From alaasindi at gmail.com  Fri Aug 28 20:00:31 2015
From: alaasindi at gmail.com (Alaa Sindi)
Date: Fri, 28 Aug 2015 21:00:31 +0300
Subject: [R] Change the maximum likelihood of multinomial logic model in R
Message-ID: <6371FADF-0B2F-4934-9614-1EC483861AF7@gmail.com>

Dear all,

Can anyone help me to change the maximum likelihood of multinomial logic model in R?

Thanks

From alaasindi at gmail.com  Fri Aug 28 20:26:59 2015
From: alaasindi at gmail.com (Alaa Sindi)
Date: Fri, 28 Aug 2015 21:26:59 +0300
Subject: [R] Change the maximum likelihood of multinomial logic model in
	R
In-Reply-To: <6371FADF-0B2F-4934-9614-1EC483861AF7@gmail.com>
References: <6371FADF-0B2F-4934-9614-1EC483861AF7@gmail.com>
Message-ID: <55DABCD4-A6F6-48A3-B92D-3CD9C3315FB1@gmail.com>

Dear All,
 can anybody help me with an example on how to use mlogit.optim?

Regards


> On Aug 28, 2015, at 9:00 PM, Alaa Sindi <alaasindi at gmail.com> wrote:
> 
> Dear all,
> 
> Can anyone help me to change the maximum likelihood of multinomial logic model in R?
> 
> Thanks


From lamonta at mailbox.sc.edu  Fri Aug 28 21:17:20 2015
From: lamonta at mailbox.sc.edu (Andrea Lamont)
Date: Fri, 28 Aug 2015 15:17:20 -0400
Subject: [R] Referencing a component of a large object (Error: slot NULL)
Message-ID: <CALxSy05dd8mS1Bt_2ZPs4vvxM4FMNwSizR7dYK6Hr0dBYbVWWw@mail.gmail.com>

I am running a simulation and need to refer to a matrix of parameters from
a large object. Here is a snippet of the object structure itself:

Formal class 'mi' [package "mi"] with 3 slots
  ..@ call       : language .local(y = y, n.chains = ..2, max.minutes = 20000)
  ..@ data       :List of 100
  .. ..$ chain:1  :'data.frame':    10000 obs. of  76 variables:
Formal class 'missing_data.frame' [package "mi"] with 17 slots
  .. .. .. ..@ .Data       : list()
  .. .. .. ..@ variables   :List of 76
  .. .. .. .. ..$ y.obs.tx:Formal class 'binary' [package "mi"] with 27 slots...

The parameter list I need can be referenced by:

mi.control.i at data$'chain:1'@variables$y.obs.tx at parameters[30,]

Since this is a simulation, I would like to grab the parameters from each
chain and join them together in a matrix. I have this:

tf <- vector("list", numberofchains)for (j in 1:numberofchains){
  s <- paste("'chain:",j,"'" ,sep="")
  tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters[30,]}

Within the loop, however, the reference to the object (tf[[j]]) does not
work. I get an error that reads

Error: trying to get slot "variables" from an object of a basic class
("NULL") with no slots


I am happy to send reproducible code, however, I obtain this object through
the package 'mi' and is computationally intensive. I'm not sure if it makes
it easier for folks. Let me know.

Any ideas?

	[[alternative HTML version deleted]]


From suparna.mitra.sm at gmail.com  Fri Aug 28 22:21:52 2015
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 28 Aug 2015 21:21:52 +0100
Subject: [R] Problem loading mvabund package
In-Reply-To: <55E04178.4070603@dewey.myzen.co.uk>
References: <CAFdg=fWFk=3q1=0TNrZ40+RVAVX86N_0YPfmy3VsThGv+a7XyA@mail.gmail.com>
	<55E04178.4070603@dewey.myzen.co.uk>
Message-ID: <CAFdg=fVM8tbx4EdcrZMCqcVrv4YsC0CS1oVW_siJC_s49R8fbA@mail.gmail.com>

Thank you Michael :)
S

On 28 August 2015 at 12:09, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Suparna,
>
> See below
>
> On 28/08/2015 10:22, Suparna Mitra wrote:
>
>> Hello,
>>    Can anybody please help me with mvabund  package installation?
>> I downloaded and installed it. It seems installed, but I can't load the
>> package.
>> Here is what I tried:
>>
>>
>> install.packages("/Users/smitra/Documents/Soft/mvabund_3.10.4.tgz", repos
>>>
>> = NULL, type="source")
>> * installing *binary* package ?mvabund? ...
>> * DONE (mvabund)
>>
>> library(mvabund)
>>>
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]])
>> :
>>    there is no package called ?tweedie?
>>
>
> There are two possibilities here
> 1 - you have not installed tweedie
> 2 - you have and R cannot find it
>
> Error: package or namespace load failed for ?mvabund?
>>
>>
>> Any help will be great.
>> Thanks.
>> Suparna
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Aug 28 22:31:07 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 28 Aug 2015 13:31:07 -0700
Subject: [R] Change the maximum likelihood of multinomial logic model in
	R
In-Reply-To: <55DABCD4-A6F6-48A3-B92D-3CD9C3315FB1@gmail.com>
References: <6371FADF-0B2F-4934-9614-1EC483861AF7@gmail.com>
	<55DABCD4-A6F6-48A3-B92D-3CD9C3315FB1@gmail.com>
Message-ID: <C58EC026-78B2-4D6F-A27A-1CC1CADB1ED1@comcast.net>


On Aug 28, 2015, at 11:26 AM, Alaa Sindi wrote:

> Dear All,
> can anybody help me with an example on how to use mlogit.optim?

That is just a helper function. The examples are all on the  mogit help page.

> 
>> On Aug 28, 2015, at 9:00 PM, Alaa Sindi <alaasindi at gmail.com> wrote:
>> 
>> Dear all,
>> 
>> Can anyone help me to change the maximum likelihood of multinomial logic model in R?
>> 
>> Thanks
> 
> ______________________________________________
> 

David Winsemius
Alameda, CA, USA


From alamont082 at gmail.com  Fri Aug 28 21:08:25 2015
From: alamont082 at gmail.com (Andrea Lamont)
Date: Fri, 28 Aug 2015 15:08:25 -0400
Subject: [R] Referencing a component of a large object (Error: slot NULL)
Message-ID: <CALxSy07h3C8sU4eXWQsDmp_+MxYN5Wz32QtX9WxsuqgWngkJoA@mail.gmail.com>

I am running a simulation and need to refer to a matrix of parameters from
a large object. Here is a snippet of the object structure itself:

Formal class 'mi' [package "mi"] with 3 slots
  ..@ call       : language .local(y = y, n.chains = ..2, max.minutes = 20000)
  ..@ data       :List of 100
  .. ..$ chain:1  :'data.frame':    10000 obs. of  76 variables:
Formal class 'missing_data.frame' [package "mi"] with 17 slots
  .. .. .. ..@ .Data       : list()
  .. .. .. ..@ variables   :List of 76
  .. .. .. .. ..$ y.obs.tx:Formal class 'binary' [package "mi"] with 27 slots...

The parameter list I need can be referenced by:

mi.control.i at data$'chain:1'@variables$y.obs.tx at parameters[30,]

Since this is a simulation, I would like to grab the parameters from each
chain and join them together in a matrix. I have this:

tf <- vector("list", numberofchains)for (j in 1:numberofchains){
  s <- paste("'chain:",j,"'" ,sep="")
  tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters[30,]}

Within the loop, however, the reference to the object (tf[[j]]) does not
work. I get an error that reads

Error: trying to get slot "variables" from an object of a basic class
("NULL") with no slots


I am happy to send reproducible code, however, I obtain this object through
the package 'mi' and is computationally intensive. I'm not sure if it makes
it easier for folks. Let me know.

Any ideas?

-- 
Andrea Lamont, PhD
Post-Doctoral Fellow
University of South Carolina
Columbia, SC 29208

*Please consider the environment before printing this email.*

	[[alternative HTML version deleted]]


From attenka at utu.fi  Fri Aug 28 22:00:12 2015
From: attenka at utu.fi (Atte Tenkanen)
Date: Fri, 28 Aug 2015 23:00:12 +0300
Subject: [R] Separate point sizes in rgl.points()?
Message-ID: <55E0BDCC.90102@utu.fi>

Hi,

DrawDensity3D-function in package VecStatGraphs3D utilizes 
rgl.points-function {rgl}:

function (vectors, Div = 40, Layers = 3, DrawAxes = FALSE)
{
     open3d(windowRect = c(100, 100, 800, 800))
     bg3d("white")
     Cx = vectors[, 1]
     Cy = vectors[, 2]
     Cz = vectors[, 3]
     Cr <- kde3d(x = Cx, y = Cy, z = Cz, n = Div)
     th <- seq(min(Cr$d), max(Cr$d), len = Layers + 2)
     ramp <- colorRamp(c("white", "yellow", "red"))
     colo <- rgb(ramp(seq(0, 1, length = Layers)), maxColorValue = 255)
     al <- seq(0.1, 0.6, len = Layers)
     module = sqrt(Cx * Cx + Cy * Cy + Cz * Cz)
     spheres3d(0, 0, 0, radius = max(module), color = "black",
         front = "line", back = "line", lwd = 1, smooth = TRUE,
         lit = TRUE, line_antialias = FALSE, alpha = 0.2)
     x <- c(0, max(module), 0, 0)
     y <- c(0, 0, max(module), 0)
     z <- c(0, 0, 0, max(module))
     labels <- c("", "X", "Y", "Z")
     i <- c(1, 2, 1, 3, 1, 4)
     text3d(x, y, z, labels, adj = 0.8, cex = 1.5, font = 2, color = 
"black")
     segments3d(x[i], y[i], z[i], lwd = 3)
     rgl.points(x = Cx, y = Cy, z = Cz, size = 3, color = "black")
     contour3d(Cr$d, level = th[c(-1, -(Layers + 2))], x = Cr$x,
         y = Cr$y, z = Cr$z, alpha = al, color = colo, add = TRUE,
         engine = "rgl", fill = TRUE, smooth = 2, material = "shiny")
     if (DrawAxes == TRUE) {
         axes3d()
     }
}

Is it somehow possible to define the sizes of the points all separately?

I tried by adding ?Psize? to function arguments and changing

rgl.points(x = Cx, y = Cy, z = Cz, size = Psize, color = "black?),

then giving individual point size to each point but this does not work.

This does?t work either:

for(i in 1:length(Cx))
{
     rgl.points(x=Cx[i], y=Cz[i], z=Cz[i], size=PSize[i], col= Colors[i])
}

Atte Tenkanen


From daffodil416 at yahoo.com  Fri Aug 28 22:06:00 2015
From: daffodil416 at yahoo.com (Angela)
Date: Fri, 28 Aug 2015 13:06:00 -0700
Subject: [R] heat map labeling
In-Reply-To: <CA+8X3fUX0SxD3uyuDRopMaO7eApOqPaUdrBG_tcUm5aRCU1nTQ@mail.gmail.com>
Message-ID: <1440792360.47636.YahooMailBasic@web161506.mail.bf1.yahoo.com>

Hi Jim,

Thank you, that definitely reduced it but there are still about 600 genes, so too many to label. It does make the heat map itself look cleaner. Maybe labeling isn't necessary for the heat map?

-Angela
--------------------------------------------
On Fri, 8/28/15, Jim Lemon <drjimlemon at gmail.com> wrote:

 Subject: Re: [R] heat map labeling

 Cc: "r-help mailing list" <r-help at r-project.org>
 Date: Friday, August 28, 2015, 6:16 AM

 Hi
 Angela,Assuming the above data frame is named
 angela.df:
 angela.mat<-as.matrix(angela.df[,2:3])angela.mat<-angela.mat[apply(angela.mat,1,function(x)
 all(x) > 0),]
 will remove all of the rows
 that have contain at least one zero.
 Jim

 On Fri, Aug 28, 2015 at
 9:00 AM, Angela via R-help <r-help at r-project.org>
 wrote:
 Hello,



 I have a dataset of 985 genes, looks something like the ones
 below. I want to label only those with the high intensities,
 since labeling all doesn't show up. Is there a way to do
 that? If not, is there a way to pull out the highest ones
 (say, highest 50, or those above X amount) and only show
[[elided Yahoo spam]]



 -Angela



 Z transforming gives all cells the same value, just + or -
 (for example, all have 0.5 and -0.5). The researchers want
 the actual values used.



 Gene? ?var1? ? ? ?var2

 A? ? ? ?8000000 0

 B? ? ? ?250000? 300000

 C? ? ? ?750000? 2000000

 D? ? ? ?0? ? ? ? ? ? ? ?0

 E? ? ? ?4000000 6000000

 E? ? ? ?5000000 700000

 E? ? ? ?1000000 1000000

 F? ? ? ?6000000 6000000

 F? ? ? ?700000? 827460

 G? ? ? ?420930? 400000

 H? ? ? ?0? ? ? ? ? ? ? ?0

 H? ? ? ?1000000 1000000

 I? ? ? ?700000? 600000

 J? ? ? ?0? ? ? ? ? ? ? ?700000

 K? ? ? ?0? ? ? ? ? ? ? ?0

 L? ? ? ?200000? 500000

 L? ? ? ?1000000 3000000



 ______________________________________________

 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see

 https://stat.ethz.ch/mailman/listinfo/r-help

 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

 and provide commented, minimal, self-contained, reproducible
 code.


From dmck at u.washington.edu  Fri Aug 28 21:13:55 2015
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 28 Aug 2015 12:13:55 -0700
Subject: [R] Change the maximum likelihood of multinomial logic model in
	R
In-Reply-To: <55DABCD4-A6F6-48A3-B92D-3CD9C3315FB1@gmail.com>
References: <6371FADF-0B2F-4934-9614-1EC483861AF7@gmail.com>
	<55DABCD4-A6F6-48A3-B92D-3CD9C3315FB1@gmail.com>
Message-ID: <5F864C22-E687-4A4F-A5EA-5E456D1B0E11@u.washington.edu>

Have you looked at the help for mlogit.optim?  At the minimum you need a likelihood function and starting value(s).  If you don?t understand the function syntax you may have difficulty interpreting any output that you do get.

> On Aug 28, 2015, at 11:26 AM, Alaa Sindi <alaasindi at gmail.com> wrote:
> 
> Dear All,
> can anybody help me with an example on how to use mlogit.optim?
> 
> Regards
> 
> 
>> On Aug 28, 2015, at 9:00 PM, Alaa Sindi <alaasindi at gmail.com> wrote:
>> 
>> Dear all,
>> 
>> Can anyone help me to change the maximum likelihood of multinomial logic model in R?
>> 
>> Thanks
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




From wdunlap at tibco.com  Fri Aug 28 23:52:49 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 28 Aug 2015 14:52:49 -0700
Subject: [R] Referencing a component of a large object (Error: slot NULL)
In-Reply-To: <CALxSy07h3C8sU4eXWQsDmp_+MxYN5Wz32QtX9WxsuqgWngkJoA@mail.gmail.com>
References: <CALxSy07h3C8sU4eXWQsDmp_+MxYN5Wz32QtX9WxsuqgWngkJoA@mail.gmail.com>
Message-ID: <CAF8bMca6a==KdQLDQ-G7x=_wYrNBiYBdy--V6Ym8cbB+P3P2GQ@mail.gmail.com>

  tf <- vector("list", numberofchains)
  for (j in 1:numberofchains){
      s <- paste("'chain:",j,"'" ,sep="")
      tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters[30,]
  }


If you want the component whose name is the value of the variable 's'
use data[[s]].

The syntax 'data$s' means to get the component of 'data' called "s",
usually the same as 'data[["s"]]'.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 28, 2015 at 12:08 PM, Andrea Lamont <alamont082 at gmail.com>
wrote:

> I am running a simulation and need to refer to a matrix of parameters from
> a large object. Here is a snippet of the object structure itself:
>
> Formal class 'mi' [package "mi"] with 3 slots
>   ..@ call       : language .local(y = y, n.chains = ..2, max.minutes =
> 20000)
>   ..@ data       :List of 100
>   .. ..$ chain:1  :'data.frame':    10000 obs. of  76 variables:
> Formal class 'missing_data.frame' [package "mi"] with 17 slots
>   .. .. .. ..@ .Data       : list()
>   .. .. .. ..@ variables   :List of 76
>   .. .. .. .. ..$ y.obs.tx:Formal class 'binary' [package "mi"] with 27
> slots...
>
> The parameter list I need can be referenced by:
>
> mi.control.i at data$'chain:1'@variables$y.obs.tx at parameters[30,]
>
> Since this is a simulation, I would like to grab the parameters from each
> chain and join them together in a matrix. I have this:
>
> tf <- vector("list", numberofchains)for (j in 1:numberofchains){
>   s <- paste("'chain:",j,"'" ,sep="")
>   tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters[30,]}
>
> Within the loop, however, the reference to the object (tf[[j]]) does not
> work. I get an error that reads
>
> Error: trying to get slot "variables" from an object of a basic class
> ("NULL") with no slots
>
>
> I am happy to send reproducible code, however, I obtain this object through
> the package 'mi' and is computationally intensive. I'm not sure if it makes
> it easier for folks. Let me know.
>
> Any ideas?
>
> --
> Andrea Lamont, PhD
> Post-Doctoral Fellow
> University of South Carolina
> Columbia, SC 29208
>
> *Please consider the environment before printing this email.*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Aug 29 00:21:56 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 29 Aug 2015 08:21:56 +1000
Subject: [R] heat map labeling
In-Reply-To: <1440792360.47636.YahooMailBasic@web161506.mail.bf1.yahoo.com>
References: <CA+8X3fUX0SxD3uyuDRopMaO7eApOqPaUdrBG_tcUm5aRCU1nTQ@mail.gmail.com>
	<1440792360.47636.YahooMailBasic@web161506.mail.bf1.yahoo.com>
Message-ID: <CA+8X3fWf2yiX5Aq_uYQygLwJuO4ZCQB5yGMmqPeTbX2wrz+tYA@mail.gmail.com>

Hi Angela,
It depends upon what you want to illustrate. If you are just interested in
the relative values, you can suppress the labels. One solution is to create
a very high PDF to look at the colors, which you could then expand and
scroll around to see the labels.

Jim

On Sat, Aug 29, 2015 at 6:06 AM, Angela via R-help <r-help at r-project.org>
wrote:

> Hi Jim,
>
> Thank you, that definitely reduced it but there are still about 600 genes,
> so too many to label. It does make the heat map itself look cleaner. Maybe
> labeling isn't necessary for the heat map?
>
> -Angela
>
>

	[[alternative HTML version deleted]]


From sha1one at yahoo.com  Fri Aug 28 23:55:19 2015
From: sha1one at yahoo.com (Shant Ch)
Date: Fri, 28 Aug 2015 21:55:19 +0000 (UTC)
Subject: [R] Multiple Integrals
Message-ID: <435817969.2436401.1440798919093.JavaMail.yahoo@mail.yahoo.com>

Hello all,
For a study I want to find E|X1/3+X2/3+X3/3-X4| for variables following lognormal distribution. To get the value we need to use four integrals. This is the code which I is used

????? fx<-function(x){
??????? dlnorm(x,meanlog=2.185,sdlog=0.562)
????? }
U31<-integrate(function(y1) { sapply(y1, function(y1) { 
+????????????? integrate(function(y2){? sapply(y2, function(y2) {
+????????????? integrate(function(x1){? sapply(x1, function(x1) { 
+????????????? integrate(function(x2)
+?????????????? abs(y1/3+y2/3+x1/3-x2)*fx(y1)*fx(y2)*fx(x1)*fx(x2),0, Inf)$value
+????????????? })},0, Inf)$value })},0, Inf)$value})},0,Inf)$value
The error I received is the following:
Error in integrate(function(y2) { : 
? maximum number of subdivisions reached

I can understand the problem, but I am unable to figure out what can be done.. It would be great if you can let me know a solution to the problem so as to find a value for the integral.

Shant

	[[alternative HTML version deleted]]


From jonathan.henkelman at usask.ca  Sat Aug 29 00:21:22 2015
From: jonathan.henkelman at usask.ca (Jonathan Henkelman)
Date: Fri, 28 Aug 2015 15:21:22 -0700 (PDT)
Subject: [R] kknn::predict and kknn$fitted.values
Message-ID: <1440800482384-4711625.post@n4.nabble.com>

I am noticing that there is a difference between the fitted.values returned
by train.kknn, and the values returned using predict with the same model and
dataset. For example:

> data (glass)
> tmp <- train.kknn(Type ~ ., glass, kmax=1, kernel="rectangular",
> distance=1)
> tmp$fitted.values
[[1]]
  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1
 [62] 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 1 2 1 2 2 1 2 2 5 2 2 2 6 2 2 2 2 2 2 2 2 2 2 2 2
[123] 2 2 2 2 3 2 2 2 5 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 2 3 3
3 3 3 3 2 3 7 5 5 5 5 5 5 5 5 5 5 2 5 6 6 6 6 6 6 6
[184] 2 6 7 7 2 6 7 7 7 7 7 7 7 7 7 7 7 7 5 7 7 7 7 7 7 7 7 7 7 7 7
attr(,"kernel")
[1] rectangular
attr(,"k")
[1] 1
Levels: 1 2 3 5 6 7

> predict (tmp,glass)
  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 [62] 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
[123] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3
3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6
[184] 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
Levels: 1 2 3 5 6 7

When I check the confusion matricies for these I see that fitted.values is
giving some confusion, that is, like it is a true fit, whereas predict is
returning the exact answers.

> table (tmp$fitted.values[[1]],glass$Type)
     1  2  3  5  6  7
  1 69  4  0  0  0  0
  2  1 67  2  1  1  1
  3  0  1 15  0  0  0
  5  0  3  0 11  0  1
  6  0  1  0  0  8  1
  7  0  0  0  1  0 26

> table (predict(tmp,glass),glass$Type)   
     1  2  3  5  6  7
  1 70  0  0  0  0  0
  2  0 76  0  0  0  0
  3  0  0 17  0  0  0
  5  0  0  0 13  0  0
  6  0  0  0  0  9  0
  7  0  0  0  0  0 29

Can anyone clarify what fitted.values and predict actually do? I would have
expected they would give the same output.

Thanks... Jonathan



--
View this message in context: http://r.789695.n4.nabble.com/kknn-predict-and-kknn-fitted-values-tp4711625.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Sat Aug 29 05:59:09 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 28 Aug 2015 20:59:09 -0700
Subject: [R] Referencing a component of a large object (Error: slot NULL)
In-Reply-To: <CALxSy04Cx+mcJr7TKsfLHo44=A+J56KxCYCcwie2RkoPyihphg@mail.gmail.com>
References: <CALxSy07h3C8sU4eXWQsDmp_+MxYN5Wz32QtX9WxsuqgWngkJoA@mail.gmail.com>
	<CAF8bMca6a==KdQLDQ-G7x=_wYrNBiYBdy--V6Ym8cbB+P3P2GQ@mail.gmail.com>
	<CALxSy04Cx+mcJr7TKsfLHo44=A+J56KxCYCcwie2RkoPyihphg@mail.gmail.com>
Message-ID: <CAF8bMcYaCfk0RCDdBvc-+r2Vqyxt8yMcmViepH40VV8n+N3_Jw@mail.gmail.com>

   s <- paste("'chain:",j,"'" ,sep="")

You don't want the single quotes around the string you are constructing.
Try
   s <- paste0("chain:", j)
which will give you, e.g.,
   "chain:1"
instead of
   "'chain:1'"

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 28, 2015 at 6:08 PM, Andrea Lamont <alamont082 at gmail.com> wrote:

> Hm.
>
> It still doesn't seem to be working and has me completely stumped.
>
> This works:
> mi.control.i at data[['chain:1']]@variables$y.obs.tx at parameters[30,]
>
> But this doesn't:
> > mi.control.i at data[[s]]@variables$y.obs.tx at parameters[30,]
> Error: trying to get slot "variables" from an object of a basic class
> ("NULL") with no slots
> > s
> [1] "'chain:1'"
>
> On Fri, Aug 28, 2015 at 5:52 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>>
>>   tf <- vector("list", numberofchains)
>>   for (j in 1:numberofchains){
>>       s <- paste("'chain:",j,"'" ,sep="")
>>       tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters[30,]
>>   }
>>
>>
>> If you want the component whose name is the value of the variable 's'
>> use data[[s]].
>>
>> The syntax 'data$s' means to get the component of 'data' called "s",
>> usually the same as 'data[["s"]]'.
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Fri, Aug 28, 2015 at 12:08 PM, Andrea Lamont <alamont082 at gmail.com>
>> wrote:
>>
>>> I am running a simulation and need to refer to a matrix of parameters
>>> from
>>> a large object. Here is a snippet of the object structure itself:
>>>
>>> Formal class 'mi' [package "mi"] with 3 slots
>>>   ..@ call       : language .local(y = y, n.chains = ..2, max.minutes =
>>> 20000)
>>>   ..@ data       :List of 100
>>>   .. ..$ chain:1  :'data.frame':    10000 obs. of  76 variables:
>>> Formal class 'missing_data.frame' [package "mi"] with 17 slots
>>>   .. .. .. ..@ .Data       : list()
>>>   .. .. .. ..@ variables   :List of 76
>>>   .. .. .. .. ..$ y.obs.tx:Formal class 'binary' [package "mi"] with 27
>>> slots...
>>>
>>> The parameter list I need can be referenced by:
>>>
>>> mi.control.i at data$'chain:1'@variables$y.obs.tx at parameters[30,]
>>>
>>> Since this is a simulation, I would like to grab the parameters from each
>>> chain and join them together in a matrix. I have this:
>>>
>>> tf <- vector("list", numberofchains)for (j in 1:numberofchains){
>>>   s <- paste("'chain:",j,"'" ,sep="")
>>>   tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters[30,]}
>>>
>>> Within the loop, however, the reference to the object (tf[[j]]) does not
>>> work. I get an error that reads
>>>
>>> Error: trying to get slot "variables" from an object of a basic class
>>> ("NULL") with no slots
>>>
>>>
>>> I am happy to send reproducible code, however, I obtain this object
>>> through
>>> the package 'mi' and is computationally intensive. I'm not sure if it
>>> makes
>>> it easier for folks. Let me know.
>>>
>>> Any ideas?
>>>
>>> --
>>> Andrea Lamont, PhD
>>> Post-Doctoral Fellow
>>> University of South Carolina
>>> Columbia, SC 29208
>>>
>>> *Please consider the environment before printing this email.*
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
> Andrea Lamont, PhD
> Post-Doctoral Fellow
> University of South Carolina
> Columbia, SC 29208
>
> *Please consider the environment before printing this email.*
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Aug 29 13:21:21 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 29 Aug 2015 07:21:21 -0400
Subject: [R] Separate point sizes in rgl.points()?
In-Reply-To: <55E0BDCC.90102@utu.fi>
References: <55E0BDCC.90102@utu.fi>
Message-ID: <55E195B1.6060002@gmail.com>

On 28/08/2015 4:00 PM, Atte Tenkanen wrote:
> Hi,
> 
> DrawDensity3D-function in package VecStatGraphs3D utilizes 
> rgl.points-function {rgl}:

You shouldn't be using rgl.points.  Use points3d.

The pointsize is a material property (see ?material3d), and isn't a
vector, so you only get one size per call to points3d.

Duncan Murdoch

> 
> function (vectors, Div = 40, Layers = 3, DrawAxes = FALSE)
> {
>      open3d(windowRect = c(100, 100, 800, 800))
>      bg3d("white")
>      Cx = vectors[, 1]
>      Cy = vectors[, 2]
>      Cz = vectors[, 3]
>      Cr <- kde3d(x = Cx, y = Cy, z = Cz, n = Div)
>      th <- seq(min(Cr$d), max(Cr$d), len = Layers + 2)
>      ramp <- colorRamp(c("white", "yellow", "red"))
>      colo <- rgb(ramp(seq(0, 1, length = Layers)), maxColorValue = 255)
>      al <- seq(0.1, 0.6, len = Layers)
>      module = sqrt(Cx * Cx + Cy * Cy + Cz * Cz)
>      spheres3d(0, 0, 0, radius = max(module), color = "black",
>          front = "line", back = "line", lwd = 1, smooth = TRUE,
>          lit = TRUE, line_antialias = FALSE, alpha = 0.2)
>      x <- c(0, max(module), 0, 0)
>      y <- c(0, 0, max(module), 0)
>      z <- c(0, 0, 0, max(module))
>      labels <- c("", "X", "Y", "Z")
>      i <- c(1, 2, 1, 3, 1, 4)
>      text3d(x, y, z, labels, adj = 0.8, cex = 1.5, font = 2, color = 
> "black")
>      segments3d(x[i], y[i], z[i], lwd = 3)
>      rgl.points(x = Cx, y = Cy, z = Cz, size = 3, color = "black")
>      contour3d(Cr$d, level = th[c(-1, -(Layers + 2))], x = Cr$x,
>          y = Cr$y, z = Cr$z, alpha = al, color = colo, add = TRUE,
>          engine = "rgl", fill = TRUE, smooth = 2, material = "shiny")
>      if (DrawAxes == TRUE) {
>          axes3d()
>      }
> }
> 
> Is it somehow possible to define the sizes of the points all separately?
> 
> I tried by adding ?Psize? to function arguments and changing
> 
> rgl.points(x = Cx, y = Cy, z = Cz, size = Psize, color = "black?),
> 
> then giving individual point size to each point but this does not work.
> 
> This does?t work either:
> 
> for(i in 1:length(Cx))
> {
>      rgl.points(x=Cx[i], y=Cz[i], z=Cz[i], size=PSize[i], col= Colors[i])
> }
> 
> Atte Tenkanen
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lorenzo.isella at gmail.com  Sat Aug 29 17:31:57 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sat, 29 Aug 2015 17:31:57 +0200
Subject: [R] Problem with gridExtra
In-Reply-To: <CAGx1TMBOZKfJsNzi8reyqghsLeOXZd4RyLm-FDhLyFbFvwVNgA@mail.gmail.com>
References: <20150827193316.GA14710@localhost.localdomain>
	<CAGx1TMBOZKfJsNzi8reyqghsLeOXZd4RyLm-FDhLyFbFvwVNgA@mail.gmail.com>
Message-ID: <20150829153157.GA1643@localhost.localdomain>

Hello,
And thanks for pointing this out to me.
Do you have any idea about how to "fix" the example I provided?
I made some attempts, but they were unsuccessful.
Cheers

Lorenzo

On Thu, Aug 27, 2015 at 07:50:40PM -0400, Richard M. Heiberger wrote:
>gridExtra was changed.  This is the email from Baptiste to CRAN package
>developers that describes the changes and
>points to the vignettes that will describe the changes.  The changes
>described here are now in the current release of gridExtra.
>
>Baptiste Auguie <baptiste.auguie at gmail.com>
>Jul 9
>Reply
>to Borja, Pablo, Paul-Christian, Zachary, Andrey, Liam, Michael, Rafael,
>Mikkel, Xinyu, Christopher, Andrew, Thierry, Diogo, Grigori, Felix, Adelino
>, Dean, Wencke, Brian, me, Frank, Jason, Pieter, Timothy
>Dear package maintainers,
>
>I'm working on a long-overdue update of gridExtra for CRAN, and I believe
>your package depends on it. Please have a look at the dev version on
>github, and let me know if it breaks something in your package.
>
>https://github.com/baptiste/gridextra
>
>I've removed practically everything; only two main functions are left:
>grid.arrange(),
>and grid.table(). I believe they were by-and-large the only ones actually
>used, and the rest was mostly experimental code that shouldn't stay on
>CRAN.
>I've rewritten these two functions using gtable, which I found more
>practical and extensible. However, this means that the new functions are
>entirely different from their predecessor, internally, and may break a lot
>of code. I have included two vignettes for an overview of these updated
>functions, also reproduced in the wiki:
>https://github.com/baptiste/gridextra/wiki/tableGrob
>https://github.com/baptiste/gridextra/wiki/arrangeGrob
>
>Regards,
>
>baptiste
>
>On Thu, Aug 27, 2015 at 3:33 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
>wrote:
>
>> Dear All,
>> Please consider the snippet at the end of the email, largely based on
>> what you find here
>>
>> http://bit.ly/1ND6MGa
>>
>> When I run it, I get this error
>>
>> Error in arrangeGrob(p, sub = textGrob("Footnote", x = 0, hjust =
>> -0.1,  :
>>  could not find function "textGrob"
>>
>> However, the code runs on another machine I own. I suppose something
>> must have changed in the gridExtra library but right now I am banging
>> my head against the wall.
>>
>> This is my sessionInfo()
>>
>> sessionInfo()
>>>
>> R version 3.2.2 (2015-08-14)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Debian GNU/Linux stretch/sid
>>
>> locale:
>> [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>>  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>>   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
>>    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
>>     [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] gridExtra_2.0.0 ggplot2_1.0.1
>>
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.11.6      digest_0.6.8     MASS_7.3-43      grid_3.2.2
>>  [5] plyr_1.8.3       gtable_0.1.2     magrittr_1.5     scales_0.3.0
>>   [9] stringi_0.5-5    reshape2_1.4.1   proto_0.3-10     labeling_0.3
>>   [13] tools_3.2.2      stringr_1.0.0    munsell_0.4.2
>> colorspace_1.2-6
>>
>> Any suggestion is appreciated.
>> Cheers
>>
>> Lorenzo
>>
>>
>> ##############################################################
>> library(ggplot2)
>> toyota <- mpg[which(mpg$manufacturer == 'toyota'), ]
>> p <- ggplot(toyota, aes(displ, hwy)) + facet_wrap(~ class, ncol = 2) +
>> geom_point(aes(size=cyl))
>> print(p)
>> library(gridExtra)
>> g <- arrangeGrob(p, sub = textGrob("Footnote", x = 0, hjust = -0.1,
>> vjust=0.1, gp = gpar(fontface = "italic", fontsize = 18)))
>> ggsave("/Users/Alan/Desktop/plot_grid_extra.png", g)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From wdunlap at tibco.com  Sat Aug 29 17:59:18 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 29 Aug 2015 08:59:18 -0700
Subject: [R] Referencing a component of a large object (Error: slot NULL)
In-Reply-To: <CALxSy04gd67ogm5ZGxEwU8=AbaEz7cwaqQkU=mTC8XLQ7BEFGg@mail.gmail.com>
References: <CALxSy07h3C8sU4eXWQsDmp_+MxYN5Wz32QtX9WxsuqgWngkJoA@mail.gmail.com>
	<CAF8bMca6a==KdQLDQ-G7x=_wYrNBiYBdy--V6Ym8cbB+P3P2GQ@mail.gmail.com>
	<CALxSy04Cx+mcJr7TKsfLHo44=A+J56KxCYCcwie2RkoPyihphg@mail.gmail.com>
	<CAF8bMcYaCfk0RCDdBvc-+r2Vqyxt8yMcmViepH40VV8n+N3_Jw@mail.gmail.com>
	<CALxSy05EcbQkrfbZ=OspbpPn0B1z7VfgOyYt32J+Tep=AaVkWA@mail.gmail.com>
	<CALxSy04gd67ogm5ZGxEwU8=AbaEz7cwaqQkU=mTC8XLQ7BEFGg@mail.gmail.com>
Message-ID: <CAF8bMcbw_L_JTUbJBk6e=gz1A6ed6a0cz-YDSiDeZpOTOjQH9Q@mail.gmail.com>

Recall that List$name is usually equivalent to List[["name"]] (2 square
brackets),
not List["name"].

Look at names(mi.control.i at data) to see what your paste command
ought to be producing.

Unless the names are important you can use ...data[[j]] to index the
components
in data by number instead of by name (assuming data is a list).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Aug 29, 2015 at 6:33 AM, Andrea Lamont <alamont082 at gmail.com> wrote:

> Sorry, keyboard shortcuts sent too soon.
>
> That still doesn't work. Actually, the way I "stumbled" on those single
> quotes was that it didn't reference the object without it. Ihave created a
> smaller version of the code/computations for reproducibility. I thought
> this may help troubleshoot? It requires package mi, but since i reduced the
> size, it runs in about a minute.
>
> dataGen=function(N,p,signp,seed){
>  set.seed(2398)
> Xsign=rbinom(N*signp,1,.05)
> df1=data.frame(matrix(Xsign,nrow=N, ncol=signp))
>
> Xns=rbinom(N*(p-signp),1,.5)
>  df2=data.frame(matrix(Xns,nrow=N,ncol=(p-signp)))
>
> df=cbind(df1,df2)
> names(df) <- paste("X", 1:p, sep="")
>  df$obs.txt=rep(0:1,N/2)
> df$TE=(-5+1.1*df$X1+
>  1.4*df$X2+
>  2.5*df$X3+
>   1.3*df$X4+
>          2.2*df$X5+
>  1.6*df$X6+
>  1.8*df$X7)
> #df$oddsTE=exp(df$TE)
> df$pTE= (1/(1+exp(-1*(df$TE))))
> df$pTEneg=df$pTE*-1
> #df$pTEoriginal=df$oddsTE/(1+df$oddsTE)
>  seed=set.seed(seed)
>  df$y.obs.control=rbinom(N,1,.02)#observed y value under control
>  df$y.obs.tx= ifelse(df$obs.txt==1, rbinom(N,1, df$pTE),NA) #observed y
> value under TX
>  df$Y=ifelse(df$obs.txt==0,df$y.obs.control,df$y.obs.tx) #observed Y value
>  df$y.obs.control=ifelse(df$obs.txt==0,df$y.obs.control,NA) #observed y
> value under control
>  df$ob=rep(0:1,each=N/2)
>  df$sim=rep(length(seed),each=N)
>  return(df)}
>
>  library(mi)
> x=dataGen(10000,7,7,542)
> txt.imp=as.data.frame(x[,c(13,1:7)])
> cont.imp=as.data.frame(x[,c(12,1:7)])
> mdf <- missing_data.frame(txt.imp)
>
> mi.control.i<-mi (mdf,n.chains=2)
> str(mi.control.i)
>
> #Get coefficients for each chain (imputation)
> tf <- vector("list", 7)
>
> for (j in 1:7){
>         s=noquote(paste0("chain:",j))
> s
>       tf[[j]] =  mi.control.i at data[s]@variables$y.obs.tx at parameters[30,]
> }
>
>
> On Sat, Aug 29, 2015 at 9:31 AM, Andrea Lamont <alamont082 at gmail.com>
> wrote:
>
>> That still doesn't work. Actually, the way I "stumbled" on those single
>> quotes was that it didn't reference the object without it. Ihave created a
>> smaller version of the code/computations for reproducibility. I thought
>> this may help troubleshoot? It requires package mi, but since i reduced the
>> size, it runs in about a minute.
>>
>>
>>
>> On Fri, Aug 28, 2015 at 11:59 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>>>    s <- paste("'chain:",j,"'" ,sep="")
>>>
>>> You don't want the single quotes around the string you are
>>> constructing.  Try
>>>    s <- paste0("chain:", j)
>>> which will give you, e.g.,
>>>    "chain:1"
>>> instead of
>>>    "'chain:1'"
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Fri, Aug 28, 2015 at 6:08 PM, Andrea Lamont <alamont082 at gmail.com>
>>> wrote:
>>>
>>>> Hm.
>>>>
>>>> It still doesn't seem to be working and has me completely stumped.
>>>>
>>>> This works:
>>>> mi.control.i at data[['chain:1']]@variables$y.obs.tx at parameters[30,]
>>>>
>>>> But this doesn't:
>>>> > mi.control.i at data[[s]]@variables$y.obs.tx at parameters[30,]
>>>> Error: trying to get slot "variables" from an object of a basic class
>>>> ("NULL") with no slots
>>>> > s
>>>> [1] "'chain:1'"
>>>>
>>>> On Fri, Aug 28, 2015 at 5:52 PM, William Dunlap <wdunlap at tibco.com>
>>>> wrote:
>>>>
>>>>>
>>>>>   tf <- vector("list", numberofchains)
>>>>>   for (j in 1:numberofchains){
>>>>>       s <- paste("'chain:",j,"'" ,sep="")
>>>>>       tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters
>>>>> [30,]
>>>>>   }
>>>>>
>>>>>
>>>>> If you want the component whose name is the value of the variable 's'
>>>>> use data[[s]].
>>>>>
>>>>> The syntax 'data$s' means to get the component of 'data' called "s",
>>>>> usually the same as 'data[["s"]]'.
>>>>>
>>>>>
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>> On Fri, Aug 28, 2015 at 12:08 PM, Andrea Lamont <alamont082 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> I am running a simulation and need to refer to a matrix of parameters
>>>>>> from
>>>>>> a large object. Here is a snippet of the object structure itself:
>>>>>>
>>>>>> Formal class 'mi' [package "mi"] with 3 slots
>>>>>>   ..@ call       : language .local(y = y, n.chains = ..2, max.minutes
>>>>>> = 20000)
>>>>>>   ..@ data       :List of 100
>>>>>>   .. ..$ chain:1  :'data.frame':    10000 obs. of  76 variables:
>>>>>> Formal class 'missing_data.frame' [package "mi"] with 17 slots
>>>>>>   .. .. .. ..@ .Data       : list()
>>>>>>   .. .. .. ..@ variables   :List of 76
>>>>>>   .. .. .. .. ..$ y.obs.tx:Formal class 'binary' [package "mi"] with
>>>>>> 27 slots...
>>>>>>
>>>>>> The parameter list I need can be referenced by:
>>>>>>
>>>>>> mi.control.i at data$'chain:1'@variables$y.obs.tx at parameters[30,]
>>>>>>
>>>>>> Since this is a simulation, I would like to grab the parameters from
>>>>>> each
>>>>>> chain and join them together in a matrix. I have this:
>>>>>>
>>>>>> tf <- vector("list", numberofchains)for (j in 1:numberofchains){
>>>>>>   s <- paste("'chain:",j,"'" ,sep="")
>>>>>>   tf[[j]] =  mi.control.i at data$s at variables$y.obs.tx at parameters[30,]}
>>>>>>
>>>>>> Within the loop, however, the reference to the object (tf[[j]]) does
>>>>>> not
>>>>>> work. I get an error that reads
>>>>>>
>>>>>> Error: trying to get slot "variables" from an object of a basic class
>>>>>> ("NULL") with no slots
>>>>>>
>>>>>>
>>>>>> I am happy to send reproducible code, however, I obtain this object
>>>>>> through
>>>>>> the package 'mi' and is computationally intensive. I'm not sure if it
>>>>>> makes
>>>>>> it easier for folks. Let me know.
>>>>>>
>>>>>> Any ideas?
>>>>>>
>>>>>> --
>>>>>> Andrea Lamont, PhD
>>>>>> Post-Doctoral Fellow
>>>>>> University of South Carolina
>>>>>> Columbia, SC 29208
>>>>>>
>>>>>> *Please consider the environment before printing this email.*
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> Andrea Lamont, PhD
>>>> Post-Doctoral Fellow
>>>> University of South Carolina
>>>> Columbia, SC 29208
>>>>
>>>> *Please consider the environment before printing this email.*
>>>>
>>>
>>>
>>
>>
>> --
>> Andrea Lamont, PhD
>> Post-Doctoral Fellow
>> University of South Carolina
>> Columbia, SC 29208
>>
>> *Please consider the environment before printing this email.*
>>
>
>
>
> --
> Andrea Lamont, PhD
> Post-Doctoral Fellow
> University of South Carolina
> Columbia, SC 29208
>
> *Please consider the environment before printing this email.*
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Sat Aug 29 18:29:04 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sat, 29 Aug 2015 16:29:04 +0000
Subject: [R] lsqlin in pracma
Message-ID: <1440865731313.83895@jhu.edu>

In solve.QP(), you don't need to expand the equality into two inequalities.  It can DIRECTLY handle the equality constraints.  The first `meq' rows of the constraint matrix are equality constraints. Here is the excerpt from  the documentation.

meq
the first meq constraints are treated as equality constraints, all further as inequality constraints (defaults to 0).


Therefore, solve.QP() can provide the full functionality of lsqlin in Matlab.  However, one caveat is that the bounds constraints have to be implemented via inequalities in solve.QP(), which is a slight pain, but not a deal breaker.

Best,
Ravi



	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Sat Aug 29 18:59:34 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Sat, 29 Aug 2015 09:59:34 -0700
Subject: [R] Multiple Integrals
In-Reply-To: <435817969.2436401.1440798919093.JavaMail.yahoo@mail.yahoo.com>
References: <435817969.2436401.1440798919093.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.OSX.2.11.1508290916350.547@charles-berrys-macbook.local>

On Fri, 28 Aug 2015, Shant Ch via R-help wrote:

> Hello all,

> For a study I want to find E|X1/3+X2/3+X3/3-X4| for variables following 
> lognormal distribution. To get the value we need to use four integrals.

So far, so good.


> This is the code which I is used
>
> ????? fx<-function(x){
> ??????? dlnorm(x,meanlog=2.185,sdlog=0.562)
> ????? }
> U31<-integrate(function(y1) { sapply(y1, function(y1) { 
> +????????????? integrate(function(y2){? sapply(y2, function(y2) {
> +????????????? integrate(function(x1){? sapply(x1, function(x1) { 
> +????????????? integrate(function(x2)
> +?????????????? abs(y1/3+y2/3+x1/3-x2)*fx(y1)*fx(y2)*fx(x1)*fx(x2),0, Inf)$value
> +????????????? })},0, Inf)$value })},0, Inf)$value})},0,Inf)$value
> The error I received is the following:
> Error in integrate(function(y2) { :
> ? maximum number of subdivisions reached
>
> I can understand the problem,

This is NOT a problem for which a numerical solution (apart from 
evaluating exp(x) and then doing some arithmetic) is required.

You are calculating the expectation of a sum of random variables. And from 
your code, these are independent random variables.

There is a well known calculus of expectations. Consult a book on 
probability theory. The expectation of a lognormal distribution is 
both well known and easy to work out. So is the expectation of a constant 
times a random variable. The expectation of a sum of random variables is 
also well known.

So write down the expectation of the lognormal. Render that expression as 
an R function.

Write down the expectation of a random variable times a constant. Render 
that expression as an R function.

Write down the expression for expectation of a sum of independent 
random variables as a function of the expectations of the random 
variables.

Lastly, write an R function that calls all of the above to yield the 
expectation of a sum of lognormal variables times fixed constants.

You do not need to use (and should not use!) the integrate() function to 
accomplish your aim.

Chuck

p.s. Nesting calls to integrate() is almost certainly a very bad approach 
to any multiple integration problem. If you ever do need to solve a 
multiple integration problem numerically, consult an expert before trying 
to write the solution as R code.


> but I am unable to figure out what can be done.. It would be great if 
> you can let me know a solution to the problem so as to find a value for 
> the integral.
>
> Shant
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Charles C. Berry                 Dept of Family Medicine & Public Health
cberry at ucsd edu               UC San Diego / La Jolla, CA 92093-0901
http://famprevmed.ucsd.edu/faculty/cberry/

From jfox at mcmaster.ca  Sat Aug 29 19:06:26 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 29 Aug 2015 17:06:26 +0000
Subject: [R] using survreg() in survival package with "long" data
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8A3E570@FHSDB2D11-2.csu.mcmaster.ca>

Dear list members,

I'm unable to fit a parametric survival regression using survreg() in the survival package with data in "counting-process" ("long") form.

To illustrate using a scaled-down problem with 10 subjects (with data placed on the web):

--------------- snip ------------
> library(survival)
> RW <- read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RW.txt")
> RL <- read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RL.txt")

> RW # "wide" data
   week arrest age
1    20      1  27
2    17      1  18
3    25      1  19
4    52      0  23
5    52      0  19
6    52      0  24
7    23      1  25
8    52      0  21
9    52      0  22
10   52      0  20

> head(RL, 20) # "long" data, counting-process form
     start stop arrest.time age
1.1      0    1           0  27
1.2      1    2           0  27
1.3      2    3           0  27
1.4      3    4           0  27
1.5      4    5           0  27
1.6      5    6           0  27
1.7      6    7           0  27
1.8      7    8           0  27
1.9      8    9           0  27
1.10     9   10           0  27
1.11    10   11           0  27
1.12    11   12           0  27
1.13    12   13           0  27
1.14    13   14           0  27
1.15    14   15           0  27
1.16    15   16           0  27
1.17    16   17           0  27
1.18    17   18           0  27
1.19    18   19           0  27
1.20    19   20           1  27

--------------- snip ------------

I have no trouble fitting a Cox model to both the wide and long forms of the data, obtaining (as should be the case) identical results:

--------------- snip ------------

> coxph(Surv(week, arrest) ~ age, data=RW)  # works
Call:
coxph(formula = Surv(week, arrest) ~ age, data = RW)


      coef exp(coef) se(coef)    z    p
age 0.0963    1.1011   0.2073 0.46 0.64

Likelihood ratio test=0.21  on 1 df, p=0.643
n= 10, number of events= 4 
> coxph(Surv(start, stop, arrest.time) ~ age,  data=RL) # works, same
Call:
coxph(formula = Surv(start, stop, arrest.time) ~ age, data = RL)


      coef exp(coef) se(coef)    z    p
age 0.0963    1.1011   0.2073 0.46 0.64

Likelihood ratio test=0.21  on 1 df, p=0.643
n= 397, number of events= 4 

--------------- snip ------------

But when I try to fit a parametric survival regression with survreg(), I get an error with the long form of the data:

--------------- snip ------------

> survreg(Surv(week, arrest) ~ age, data=RW) # works
Call:
survreg(formula = Surv(week, arrest) ~ age, data = RW)

Coefficients:
(Intercept)         age 
 6.35386771 -0.08982624 

Scale= 0.7363196 

Loglik(model)= -22.1   Loglik(intercept only)= -22.2
	Chisq= 0.3 on 1 degrees of freedom, p= 0.58 
n= 10 

> survreg(Surv(start, stop, arrest.time) ~ age,  data=RL) # fails
Error in survreg(Surv(start, stop, arrest.time) ~ age, data = RL) : 
  Invalid survival type

--------------- snip ------------

I expect that there's something about survreg() that I'm missing. I first noted this problem quite some time ago but didn't look into it carefully because I didn't really need to use survreg().

Any help would be appreciated.

Thanks,
 John
-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


From bhh at xs4all.nl  Sat Aug 29 20:53:46 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 29 Aug 2015 20:53:46 +0200
Subject: [R] lsqlin in pracma
In-Reply-To: <1440865731313.83895@jhu.edu>
References: <1440865731313.83895@jhu.edu>
Message-ID: <7439A22F-FA04-46BE-959F-822DAA4D9BD1@xs4all.nl>


> On 29 Aug 2015, at 18:29, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> 
> In solve.QP(), you don't need to expand the equality into two inequalities.  It can DIRECTLY handle the equality constraints.  The first `meq' rows of the constraint matrix are equality constraints. Here is the excerpt from  the documentation.
> 
> meq
> the first meq constraints are treated as equality constraints, all further as inequality constraints (defaults to 0).
> 
> 
> Therefore, solve.QP() can provide the full functionality of lsqlin in Matlab.  However, one caveat is that the bounds constraints have to be implemented via inequalities in solve.QP(), which is a slight pain, but not a deal breaker.
> 

It would be helpful if you could show us how to use solve.QP() in this case.
I?ve been trying with no success.

Berend


From bhh at xs4all.nl  Sat Aug 29 21:31:54 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 29 Aug 2015 21:31:54 +0200
Subject: [R] lsqlin in pracma
In-Reply-To: <7439A22F-FA04-46BE-959F-822DAA4D9BD1@xs4all.nl>
References: <1440865731313.83895@jhu.edu>
	<7439A22F-FA04-46BE-959F-822DAA4D9BD1@xs4all.nl>
Message-ID: <477326B2-CE31-4CD6-9B65-E6DCEB4A0FC1@xs4all.nl>


> On 29 Aug 2015, at 20:53, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
>> On 29 Aug 2015, at 18:29, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>> 
>> In solve.QP(), you don't need to expand the equality into two inequalities.  It can DIRECTLY handle the equality constraints.  The first `meq' rows of the constraint matrix are equality constraints. Here is the excerpt from  the documentation.
>> 
>> meq
>> the first meq constraints are treated as equality constraints, all further as inequality constraints (defaults to 0).
>> 
>> 
>> Therefore, solve.QP() can provide the full functionality of lsqlin in Matlab.  However, one caveat is that the bounds constraints have to be implemented via inequalities in solve.QP(), which is a slight pain, but not a deal breaker.
>> 
> 
> It would be helpful if you could show us how to use solve.QP() in this case.
> I?ve been trying with no success.
> 
> B

I?ll answer my comment.

# Example from Matlab for lsqlin

C <- matrix(c(
    0.9501,   0.7620,   0.6153,   0.4057,
    0.2311,   0.4564,   0.7919,   0.9354,
    0.6068,   0.0185,   0.9218,   0.9169,
    0.4859,   0.8214,   0.7382,   0.4102,
    0.8912,   0.4447,   0.1762,   0.8936), 5, 4, byrow=TRUE)
d <- c(0.0578, 0.3528, 0.8131, 0.0098, 0.1388)
A <- matrix(c(
    0.2027,   0.2721,   0.7467,   0.4659,
    0.1987,   0.1988,   0.4450,   0.4186,
    0.6037,   0.0152,   0.9318,   0.8462), 3, 4, byrow=TRUE)
b <- c(0.5251, 0.2026, 0.6721)

Dmat <- t(C) %*% C
dvec <- (t(C) %*% d)

Aeq <- c(3, 5, 7, 9)
beq <- 4
lb <- rep(-0.1, 4)   # lower and upper bounds
ub <- rep( 2.0, 4)

Amat <- rbind(Aeq,-A,diag(4),-diag(4))
bvec <- c(beq,-b,lb,-ub)
rslt <- solve.QP(Dmat, dvec, t(Amat), bvec, meq=1)
rslt$solution
sum(Aeq * rslt$solution) - beq
sum((C %*% rslt$solution - d)^2)


What a fiddle.

Berend


From goran.brostrom at umu.se  Sat Aug 29 21:59:02 2015
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sat, 29 Aug 2015 21:59:02 +0200
Subject: [R] using survreg() in survival package with "long" data
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8A3E570@FHSDB2D11-2.csu.mcmaster.ca>
References: <ACD1644AA6C67E4FBD0C350625508EC8A3E570@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <55E20F06.6000902@umu.se>

Dear John,

I think you are missing that 'survreg' does not handle left truncated
data. With that you should use the 'eha' package, for a PH model the
function 'phreg', and for an AFT model the function 'aftreg' (you didn't
tell which model you want to fit).

Your attempt with the 'survreg' function implies that you are satisfied 
with a Weibull baseline distribution, in which case you could choose 
either model.

G?ran


On 08/29/2015 07:06 PM, Fox, John wrote:
> Dear list members,
>
> I'm unable to fit a parametric survival regression using survreg() in
> the survival package with data in "counting-process" ("long") form.
>
> To illustrate using a scaled-down problem with 10 subjects (with data
> placed on the web):
>
> --------------- snip ------------
>> library(survival) RW <-
>> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RW.txt") RL <-
>> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RL.txt")
>
>> RW # "wide" data
> week arrest age 1    20      1  27 2    17      1  18 3    25      1
> 19 4    52      0  23 5    52      0  19 6    52      0  24 7    23
> 1  25 8    52      0  21 9    52      0  22 10   52      0  20
>
>> head(RL, 20) # "long" data, counting-process form
> start stop arrest.time age 1.1      0    1           0  27 1.2      1
> 2           0  27 1.3      2    3           0  27 1.4      3    4
> 0  27 1.5      4    5           0  27 1.6      5    6           0
> 27 1.7      6    7           0  27 1.8      7    8           0  27
> 1.9      8    9           0  27 1.10     9   10           0  27 1.11
> 10   11           0  27 1.12    11   12           0  27 1.13    12
> 13           0  27 1.14    13   14           0  27 1.15    14   15
> 0  27 1.16    15   16           0  27 1.17    16   17           0
> 27 1.18    17   18           0  27 1.19    18   19           0  27
> 1.20    19   20           1  27
>
> --------------- snip ------------
>
> I have no trouble fitting a Cox model to both the wide and long forms
> of the data, obtaining (as should be the case) identical results:
>
> --------------- snip ------------
>
>> coxph(Surv(week, arrest) ~ age, data=RW)  # works
> Call: coxph(formula = Surv(week, arrest) ~ age, data = RW)
>
>
> coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073 0.46
> 0.64
>
> Likelihood ratio test=0.21  on 1 df, p=0.643 n= 10, number of events=
> 4
>> coxph(Surv(start, stop, arrest.time) ~ age,  data=RL) # works,
>> same
> Call: coxph(formula = Surv(start, stop, arrest.time) ~ age, data =
> RL)
>
>
> coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073 0.46
> 0.64
>
> Likelihood ratio test=0.21  on 1 df, p=0.643 n= 397, number of
> events= 4
>
> --------------- snip ------------
>
> But when I try to fit a parametric survival regression with
> survreg(), I get an error with the long form of the data:
>
> --------------- snip ------------
>
>> survreg(Surv(week, arrest) ~ age, data=RW) # works
> Call: survreg(formula = Surv(week, arrest) ~ age, data = RW)
>
> Coefficients: (Intercept)         age 6.35386771 -0.08982624
>
> Scale= 0.7363196
>
> Loglik(model)= -22.1   Loglik(intercept only)= -22.2 Chisq= 0.3 on 1
> degrees of freedom, p= 0.58 n= 10
>
>> survreg(Surv(start, stop, arrest.time) ~ age,  data=RL) # fails
> Error in survreg(Surv(start, stop, arrest.time) ~ age, data = RL) :
> Invalid survival type
>
> --------------- snip ------------
>
> I expect that there's something about survreg() that I'm missing. I
> first noted this problem quite some time ago but didn't look into it
> carefully because I didn't really need to use survreg().
>
> Any help would be appreciated.
>
> Thanks, John ----------------------------- John Fox, Professor
> McMaster University Hamilton, Ontario Canada L8S 4M4 Web:
> socserv.mcmaster.ca/jfox
>
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


From ccberry at ucsd.edu  Sat Aug 29 23:00:09 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Sat, 29 Aug 2015 14:00:09 -0700
Subject: [R] Multiple Integrals
In-Reply-To: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>
References: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>
Message-ID: <alpine.OSX.2.11.1508291346001.895@charles-berrys-macbook.local>

On Sat, 29 Aug 2015, Shant Ch wrote:

> Hello Dr. Berry,
>
> I know the theoretical side but note we are not talking about 
> expectation of sums rather expectation of ABSOLUTE value of the function 
> (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4| , I don&#39;t think this 
> can be handled for log normal distribution by integrals by hand.
>

Sorry! My tired eyes missed the absolute value.

FWIW, there are some quadrature packages on CRAN.

Chuck


From bgunter.4567 at gmail.com  Sat Aug 29 23:33:59 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 29 Aug 2015 14:33:59 -0700
Subject: [R] Multiple Integrals
In-Reply-To: <alpine.OSX.2.11.1508291346001.895@charles-berrys-macbook.local>
References: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>
	<alpine.OSX.2.11.1508291346001.895@charles-berrys-macbook.local>
Message-ID: <CAGxFJbSZq0Lxz_hq+jj1yvLfB7mTArttbyNsfb5EjEh7812Vow@mail.gmail.com>

Well, it's trivial to simulate, and for n=250000, for example,  I get
a mean of 6.875. Depending on your needs, you can choose a much larger
sample to make it more precise, or, as Chuck suggested, try numerical
integration.


Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Aug 29, 2015 at 2:00 PM, Charles C. Berry <ccberry at ucsd.edu> wrote:
> On Sat, 29 Aug 2015, Shant Ch wrote:
>
>> Hello Dr. Berry,
>>
>> I know the theoretical side but note we are not talking about expectation
>> of sums rather expectation of ABSOLUTE value of the function
>> (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4| , I don&#39;t think this can
>> be handled for log normal distribution by integrals by hand.
>>
>
> Sorry! My tired eyes missed the absolute value.
>
> FWIW, there are some quadrature packages on CRAN.
>
> Chuck
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sat Aug 29 23:56:18 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 29 Aug 2015 21:56:18 +0000
Subject: [R] using survreg() in survival package with "long" data
In-Reply-To: <55E20F06.6000902@umu.se>
References: <ACD1644AA6C67E4FBD0C350625508EC8A3E570@FHSDB2D11-2.csu.mcmaster.ca>
	<55E20F06.6000902@umu.se>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8A3E63A@FHSDB2D11-2.csu.mcmaster.ca>

Dear G?ran,

Thank you for responding to my query; please see below:

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of G?ran
> Brostr?m
> Sent: August 29, 2015 3:59 PM
> To: r-help at r-project.org
> Subject: Re: [R] using survreg() in survival package with "long" data
> 
> Dear John,
> 
> I think you are missing that 'survreg' does not handle left truncated data. With
> that you should use the 'eha' package, for a PH model the function 'phreg', and
> for an AFT model the function 'aftreg' (you didn't tell which model you want to
> fit).

That's odd, in that it's not true in general, since, e.g., survreg() can be used to fit the left-censored Tobit regression model, as illustrated in this example from ?survreg: 
	tobinfit <- survreg(Surv(durable, durable>0, type='left') ~ age + quant, data=tobin, dist='gaussian')

In fact, in my example, the data are right-censored, but in the second data set are represented in counting-process form as one-week intervals. I imagine that you're right in the sense that survreg() can't handle data like this in counting-process form. Yet, I've reviewed the documentation in the survey package but can't find any reference to this -- which is not to say that it's not there, only that I don't see it.

> 
> Your attempt with the 'survreg' function implies that you are satisfied with a
> Weibull baseline distribution, in which case you could choose either model.

Right, I understand that this is the default. The problem is just a small toy example meant to illustrate the error.

Thanks again,
 John

> 
> G?ran
> 
> 
> On 08/29/2015 07:06 PM, Fox, John wrote:
> > Dear list members,
> >
> > I'm unable to fit a parametric survival regression using survreg() in
> > the survival package with data in "counting-process" ("long") form.
> >
> > To illustrate using a scaled-down problem with 10 subjects (with data
> > placed on the web):
> >
> > --------------- snip ------------
> >> library(survival) RW <-
> >> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RW.txt") RL <-
> >> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RL.txt")
> >
> >> RW # "wide" data
> > week arrest age 1    20      1  27 2    17      1  18 3    25      1
> > 19 4    52      0  23 5    52      0  19 6    52      0  24 7    23
> > 1  25 8    52      0  21 9    52      0  22 10   52      0  20
> >
> >> head(RL, 20) # "long" data, counting-process form
> > start stop arrest.time age 1.1      0    1           0  27 1.2      1
> > 2           0  27 1.3      2    3           0  27 1.4      3    4
> > 0  27 1.5      4    5           0  27 1.6      5    6           0
> > 27 1.7      6    7           0  27 1.8      7    8           0  27
> > 1.9      8    9           0  27 1.10     9   10           0  27 1.11
> > 10   11           0  27 1.12    11   12           0  27 1.13    12
> > 13           0  27 1.14    13   14           0  27 1.15    14   15
> > 0  27 1.16    15   16           0  27 1.17    16   17           0
> > 27 1.18    17   18           0  27 1.19    18   19           0  27
> > 1.20    19   20           1  27
> >
> > --------------- snip ------------
> >
> > I have no trouble fitting a Cox model to both the wide and long forms
> > of the data, obtaining (as should be the case) identical results:
> >
> > --------------- snip ------------
> >
> >> coxph(Surv(week, arrest) ~ age, data=RW)  # works
> > Call: coxph(formula = Surv(week, arrest) ~ age, data = RW)
> >
> >
> > coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073 0.46
> > 0.64
> >
> > Likelihood ratio test=0.21  on 1 df, p=0.643 n= 10, number of events=
> > 4
> >> coxph(Surv(start, stop, arrest.time) ~ age,  data=RL) # works, same
> > Call: coxph(formula = Surv(start, stop, arrest.time) ~ age, data =
> > RL)
> >
> >
> > coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073 0.46
> > 0.64
> >
> > Likelihood ratio test=0.21  on 1 df, p=0.643 n= 397, number of events=
> > 4
> >
> > --------------- snip ------------
> >
> > But when I try to fit a parametric survival regression with survreg(),
> > I get an error with the long form of the data:
> >
> > --------------- snip ------------
> >
> >> survreg(Surv(week, arrest) ~ age, data=RW) # works
> > Call: survreg(formula = Surv(week, arrest) ~ age, data = RW)
> >
> > Coefficients: (Intercept)         age 6.35386771 -0.08982624
> >
> > Scale= 0.7363196
> >
> > Loglik(model)= -22.1   Loglik(intercept only)= -22.2 Chisq= 0.3 on 1
> > degrees of freedom, p= 0.58 n= 10
> >
> >> survreg(Surv(start, stop, arrest.time) ~ age,  data=RL) # fails
> > Error in survreg(Surv(start, stop, arrest.time) ~ age, data = RL) :
> > Invalid survival type
> >
> > --------------- snip ------------
> >
> > I expect that there's something about survreg() that I'm missing. I
> > first noted this problem quite some time ago but didn't look into it
> > carefully because I didn't really need to use survreg().
> >
> > Any help would be appreciated.
> >
> > Thanks, John ----------------------------- John Fox, Professor
> > McMaster University Hamilton, Ontario Canada L8S 4M4 Web:
> > socserv.mcmaster.ca/jfox
> >
> > ______________________________________________ R-help at r-project.org
> > mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> > posting guide http://www.R-project.org/posting-guide.html and provide
> > commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jonathan.henkelman at usask.ca  Sat Aug 29 18:46:24 2015
From: jonathan.henkelman at usask.ca (Jonathan Henkelman)
Date: Sat, 29 Aug 2015 09:46:24 -0700 (PDT)
Subject: [R] kknn::predict and kknn$fitted.values
In-Reply-To: <1440800482384-4711625.post@n4.nabble.com>
References: <1440800482384-4711625.post@n4.nabble.com>
Message-ID: <1440866784797-4711634.post@n4.nabble.com>

In thinking about this 'problem' last night, I found the 'solution'. Any NN
algorithm needs to keep track of all the data it is given, both X and Y
data, otherwise how could it find and report the nearest neighbour! When
predicting (i.e. predict.kknn) it will find the closest match (nearest
neighbour), which, for a point from the original dataset /is that point/!

In contrast, the kknn$fitted.values are derived from some cross validation
approach; likely either finding the nearest point with non-zero distance, or
build a model without that point and see where it falls. Otherwise, it
wouldn't be possible to report the accuracy of the model using only a single
dataset.

I will retest the algorithm using a split training/test dataset to better
understand how predict.kknn selects a model from the suite generated by
train.kknn?my original question. I assume it chooses kknn$best.parameters,
but want to verify this.

Hopefully that clarifies the issue. I post here in case future users have a
similar question. 

Thanks to any who took the time to think about this!
Jonathan



--
View this message in context: http://r.789695.n4.nabble.com/kknn-predict-and-kknn-fitted-values-tp4711625p4711634.html
Sent from the R help mailing list archive at Nabble.com.


From sha1one at yahoo.com  Sat Aug 29 20:35:15 2015
From: sha1one at yahoo.com (Shant Ch)
Date: Sat, 29 Aug 2015 11:35:15 -0700
Subject: [R] Multiple Integrals
In-Reply-To: <alpine.OSX.2.11.1508290916350.547@charles-berrys-macbook.local>
Message-ID: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>

Hello Dr. Berry,

I know the theoretical side but note we are not talking about expectation of sums rather expectation of ABSOLUTE value of the function (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4|  , I don&#39;t think this can be handled for log normal distribution by integrals by hand.

Shant
	[[alternative HTML version deleted]]


From cc571309 at gmail.com  Sat Aug 29 22:19:35 2015
From: cc571309 at gmail.com (C Campbell)
Date: Sat, 29 Aug 2015 16:19:35 -0400
Subject: [R] Advanced Level Script for Traceability Between Worksheets
Message-ID: <CAMHDO8r-19gRzfvKofDi1GstDHbSVsnvfKUoFkuTcCg-M_atBQ@mail.gmail.com>

Hi folks - I have almost know R skills yet and have been put 'in charge' of
the below script created by a former employee.  Although some of this is
understandable to me, much of it is not.  If anyone can help with
explaining sections, commenting on the skill level it takes to understand
this level of scripting in R, and/or point me to some resources that may
cover some of this (e.g., what is ..A[..B, in_B := TRUE, allow.cartesian =
TRUE]; and specifically what do the 2 dots mean?), I would very much
appreciate it.  Would also be interested in communicating offline if you
prefer.
Thank you,
Jay



# Locate file ####
parameterization_file <- file.choose()
cd <- dirname(parameterization_file)

# Front matter ####
message("Installing and loading packages...")

# Packages
required_packages <- c("openxlsx", "xlsx", "magrittr", "data.table",
"reshape2",
                       "XML")
install_these <- setdiff(required_packages, rownames(installed.packages()))

while (length(install_these) > 0) {
  install.packages(install_these, repos = "http://cran.rstudio.com")
  install_these <- setdiff(required_packages,
rownames(installed.packages()))
}

suppressPackageStartupMessages(library(openxlsx))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(reshape2))
suppressPackageStartupMessages(library(XML))


# Options
options(stringsAsFactors = FALSE)

# Functions
message("Loading functions...")

A__in__B <- function(A, B, case = TRUE, ...) {

  # Copies
  ..A <- copy(A)
  ..B <- copy(B)
  setkey(..A, value)
  setkey(..B, value)
  ..A <- unique(..A)
  ..B <- unique(..B)

  # Rownames are unnecessary
  ..A[, rn := NULL]
  ..B[, rn := NULL]

  # Case sensitivity
  if (!case) {
    ..A <- tableToLower(..A)
    ..B <- tableToLower(..B)
  }

  # Check if A is in B
  ..A[..B, in_B := TRUE, allow.cartesian = TRUE]
  if ("in_B" %in% names(..A))
    ..A[is.na(in_B), in_B := FALSE]
  else
    ..A[, in_B := FALSE]

  # Case sensitivity
  if (!case)
    ..A <- tableDropLower(..A)

  # Set attributes
  setABattr(..A, A, B)

  # Return results
  setkey(..A, value)
  return(..A)

}

A__unique <- function(A, case = TRUE, ...) {

  # Copies
  ..A <- copy(A)
  setkey(..A, value)

  # Case sensitivity
  if (!case)
    ..A <- tableToLower(..A)

  # Check if A_i values are unique
  ..A[..A[duplicated(..A), SJ(value)], is_unique := FALSE,
      allow.cartesian = TRUE]
  if ("is_unique" %in% names(..A))
    ..A[is.na(is_unique), is_unique := TRUE]
  else
    ..A[, is_unique := TRUE]

  # Case sensitivity
  if (!case)
    ..A <- tableDropLower(..A)

  # Roll up to value level
  ..A <- ..A[, list(is_unique = all(is_unique)), keyby = value]

  # Return results
  return(..A)

}

A_i__in__B <- function(A, B, case = TRUE, ...) {

  # Copies
  ..A <- copy(A)
  setkey(..A, value, rn)
  ..A <- unique(..A)
  ..B <- copy(B)
  setkey(..B, value)
  ..B %>% unique

  # B rownames are unnecessary
  ..B[, rn := NULL]

  # Case sensitivity
  if (!case) {
    ..A <- tableToLower(..A)
    ..B <- tableToLower(..B)
  }

  # Check if A is in B
  if ("in_B" %in% names(..A))
    ..A[is.na(in_B), in_B := FALSE]
  else
    ..A[, in_B := FALSE]

  # Case sensitivity
  if (!case)
    ..A <- tableDropLower(..A)

  # Set attributes
  setABattr(..A, A, B)

  # Return results
  setkey(..A, value, rn)
  return(..A)

}

A_i__in__B_i <- function(A, B, case = TRUE, ...) {

  # Copies
  ..A <- copy(A)
  setkey(..A, value, rn)
  ..A <- unique(..A)
  ..B <- copy(B)
  setkey(..B, value, rn)
  ..B <- unique(..B)

  # Case sensitivity
  if (!case) {
    ..A <- tableToLower(..A)
    ..B <- tableToLower(..B)
  }

  # Check if A_i terms are in B_i terms
  ..A[..B, in_B := TRUE, allow.cartesian = TRUE]
  if ("in_B" %in% names(..A))
    ..A[is.na(in_B), in_B := FALSE]
  else
    ..A[, in_B := FALSE]

  # Case sensitivity
  if (!case)
    ..A <- tableDropLower(..A)

  # Set attributes
  setABattr(..A, A, B)

  # Return results
  setkey(..A, value, rn)
  return(..A)

}

A_i__substr__B_i <- function(A, B, case = TRUE, ...) {

  # Copies
  ..A <- copy(A)
  setkey(..A, rn)
  ..B <- copy(B)
  setkey(..B, rn)

  # Renames
  setnames(..A, "value", "A_value")
  setnames(..B, "value", "B_value")

  # Merge
  ..X <- ..B[..A, allow.cartesian = TRUE]

  # Check if A_i values are substrings of B_i values
  ..X[is.na(B_value), is_substring := FALSE]
  Encoding(..X$A_value) <- "UTF-8"
  Encoding(..X$B_value) <- "UTF-8"
  if (case) {
    ..X[!is.na(B_value), is_substring := mapply(
      grepl, A_value, B_value, fixed = TRUE)]
  } else {
    ..X[!is.na(B_value), is_substring := mapply(
      grepl, tolower(A_value), tolower(B_value), fixed = TRUE)]
  }
  Encoding(..X$A_value) <- "bytes"
  Encoding(..X$B_value) <- "bytes"

  # Rename/reorder
  ..X <- ..X[, list(value = A_value, rn, is_substring)]

  # Set attributes
  setABattr(..X, A, B)

  # Return results
  setkey(..X, value, rn)
  return(..X)

}

A_i__unique <- function(A, case = TRUE, ...) {

  # Copies
  ..A <- copy(A)
  setkey(..A, value)

  # Case sensitivity
  if (!case)
    ..A <- tableToLower(..A)

  # Check if A_i values are unique
  ..A[..A[duplicated(..A), SJ(value)], is_unique := FALSE,
      allow.cartesian = TRUE]
  if ("is_unique" %in% names(..A))
    ..A[is.na(is_unique), is_unique := TRUE]
  else
    ..A[, is_unique := TRUE]

  # Case sensitivity
  if (!case)
    ..A <- tableDropLower(..A)

  # Return results
  setkey(..A, value, rn)
  return(..A)

}

extractColumn <- function(x, column_name, value_delimiter = NULL, rows =
NULL)
{

  # Validate formatting on column name args
  column_name %<>% trimCompress

  # Multiple columns?
  mult_cols <- grepl(",", column_name)
  if (mult_cols)
    column_name %<>% strsplit(",") %>% unlist %>% trimCompress

  # Get column + rn
  ..table <- x[, c("rn", column_name), with = FALSE]
  setnames(..table, 2, "value")

  # Long if multiple
  if (mult_cols) {
    ..table %<>% melt(1)
    ..table[, variable := NULL]
  }

  # Key table by rowname
  setkey(..table, rn)

  # If rows was provided, subset
  if (!is.null(rows))
    if (rows != "All")
      ..table <- ..table[textrange2vector(rows) %>% SJ]

  # Split values according to delimiter...
  dlm <- Rdelim(value_delimiter)
  if (!is.null(dlm))
    ..values <- strsplit(..table[, value], Rdelim(value_delimiter)) %>%
    lapply(trimCompress)
  # ... or convert to list if no delimiter
  else
    ..values <- ..table[, value] %>% trimCompress %>% as.list

  # Set list name values to rowname values
  names(..values) <- ..table[, rn]

  # Convert from list to table
  ..values %<>% melt %>% as.data.table
  setnames(..values, 2, "rn")

  # Remove any instances of blank values
  ..values <- ..values[!is.na(value) & grepl("[^[:space:]]", value)]

  # Encode all text to bytes
  # Will need to encode to UTF-8 before output to make it readable
  Encoding(..values$value) <- "bytes"
  if (is.character(..values$rn)) Encoding(..values$rn) <- "bytes"

  # If row names can be converted to numeric, do so
  if (..values[, rn] %>% is.character)
    if (..values[, rn] %>% type.convert %>% is.numeric)
      ..values[, rn := as.numeric(rn)]

  # Key table by value
  setkey(..values, value, rn)

  # Add attributes
  setattr(..values, "file_path", attr(x, "file_path"))
  setattr(..values, "sheet_name", attr(x, "sheet_name"))
  setattr(..values, "header_row", attr(x, "header_row"))
  setattr(..values, "column_name", column_name)
  setattr(..values, "rownames_name", attr(x, "rownames_name"))
  setattr(..values, "value_delimiter", value_delimiter)
  setattr(..values, "rows", rows)

  # Return the values table
  return(..values)

}

fillNAlast <- function(x) {
  na <- is.na(x)
  miss <- which(na)
  nonmiss <- which(!na)
  map <- outer(nonmiss, miss, "<") %>%
    apply(2, . %>% which %>% max)
  x[miss] <- x[nonmiss[map]]
  return(x)
}

getSheetIndex <- function(file_path, sheet_name) {

  # Extract workbook.xml to temporary file that will be deleted at end of
  # run
  xmlDir <- file.path(tempdir(), "findSheet")
  workbook <- unzip(file_path, files = "xl/workbook.xml", exdir = xmlDir)
  on.exit(unlink(xmlDir, recursive = TRUE), add = TRUE)

  # Read workbook.xml and get sheet nodes
  workbook <- readLines(workbook, warn = FALSE, encoding = "UTF-8") %>%
    unlist
  sheets <- gregexpr("<sheet .*/sheets>", workbook, perl = TRUE) %>%
    regmatches(workbook, .) %>%
    unlist

  # Extract sheet names from nodes, parse as html, and return text
values
  sheetNames <- gregexpr('(?<=name=")[^"]+', sheets, perl = TRUE) %>%
    regmatches(sheets, .) %>%
    unlist %>%
    lapply(htmlParse, asText = TRUE) %>%
    sapply(. %>% xpathApply("//body//text()", xmlValue) %>% unlist)

  # Which sheet name is equal to the sheet_name argument?
  which(sheetNames == sheet_name)

}

Rdelim <- function(x, ...) {
  if (!is.null(x)) {
    if (!is.na(x) & x != "None") {
      if (x == "Newline") "\\n" else x
    } else NULL
  } else NULL
}

readSource <- function(file_path, sheet_name, header_row, column_names,
                       rownames_name = NULL)
{

  # Validate formatting on column name args
  column_names %<>% strsplit(",") %>% unlist %>% trimCompress
  rownames_name %<>% trimCompress

  # Sheet index
  sheet_index <- getSheetIndex(file_path, sheet_name)

  # Read column names according to header row
  ..names <- read.xlsx(
    xlsxFile = file_path
    , sheet = sheet_index
    , colNames = FALSE
    , rows = header_row
  ) %>% unlist %>% unname %>% trimCompress

  # Read in column plus and any rownames column
  ..table <- read.xlsx(
    xlsxFile = file_path
    , sheet = sheet_index
    , startRow = header_row
    , cols = which(..names %in% c(rownames_name, column_names))
    , skipEmptyRows = FALSE
    , detectDates = TRUE
  ) %>% as.data.table

  # Set names
  setnames(..table,
           ..names[which(..names %in% c(rownames_name, column_names))])

  # Rownames
  ## If no rownames column, use row number
  if (is.null(rownames_name)) {
    if (is.null(rows)) ..table[, rn := 1:.N + 1L] else ..table[, rn := rows]
  } else { # Otherwise, just copy the column
    ..table[, rn := lapply(.SD, identity), .SDcols = rownames_name]
  }
  setcolorder(..table, c("rn", setdiff(names(..table), "rn")))

  # If row can be converted to numeric, do so
  if (..table[, rn] %>% is.character)
    if (..table[, rn] %>% type.convert %>% is.numeric)
      ..table[, rn := as.numeric(rn)]

  # Key table by row
  setkey(..table, rn)

  # Add attributes
  setattr(..table, "file_path", file_path)
  setattr(..table, "sheet_name", sheet_name)
  setattr(..table, "header_row", header_row)
  setattr(..table, "column_names", column_names)
  setattr(..table, "rownames_name", rownames_name)

  # Return the values table
  return(..table)

}

setABattr <- function(new_table, A, B) {

  # Strip existing attributes in new_table
  setattr(new_table, "file_path", NULL)
  setattr(new_table, "sheet_name", NULL)
  setattr(new_table, "header_row", NULL)
  setattr(new_table, "column_name", NULL)
  setattr(new_table, "rownames_name", NULL)
  setattr(new_table, "value_delimiter", NULL)
  setattr(new_table, "rows", NULL)
  setattr(new_table, "rows_are_rownames", NULL)

  # Set A attributes in new_table
  setattr(new_table, "A_file_path", attributes(A)$file_path)
  setattr(new_table, "A_sheet_name", attributes(A)$sheet_name)
  setattr(new_table, "A_header_row", attributes(A)$header_row)
  setattr(new_table, "A_column_name", attributes(A)$column_name)
  setattr(new_table, "A_rownames_name", attributes(A)$rownames_name)
  setattr(new_table, "A_value_delimiter", attributes(A)$value_delimiter)
  setattr(new_table, "A_rows", attributes(A)$rows)
  setattr(new_table, "A_rows_are_rownames", attributes(A)$rows_are_rownames)

  # Set B attributes in new_table
  setattr(new_table, "B_file_path", attributes(B)$file_path)
  setattr(new_table, "B_sheet_name", attributes(B)$sheet_name)
  setattr(new_table, "B_header_row", attributes(B)$header_row)
  setattr(new_table, "B_column_name", attributes(B)$column_name)
  setattr(new_table, "B_rownames_name", attributes(B)$rownames_name)
  setattr(new_table, "B_value_delimiter", attributes(B)$value_delimiter)
  setattr(new_table, "B_rows", attributes(B)$rows)
  setattr(new_table, "B_rows_are_rownames", attributes(B)$rows_are_rownames)

}

tableToLower <- function(X, ...) {

  # Copy
  x <- copy(X)

  # Existing keys
  keys <- key(x)
  setkey(x, NULL)

  # Rename value column
  setnames(x, "value", "value_orig")

  # Derived value column
  Encoding(x$value_orig) <- "UTF-8"
  x[, value := tolower(value_orig)]
  Encoding(x$value) <- "bytes"
  Encoding(x$value_orig) <- "bytes"

  # Rekey
  setkeyv(x, keys)

  # Return
  return(x)

}

tableDropLower <- function(X, ...) {

  # Copy
  x <- copy(X)

  # Existing keys
  keys <- key(x)
  setkey(x, NULL)

  # Drop derived value column
  x[, value := NULL]

  # Rename value_orig column
  setnames(x, "value_orig", "value")

  # Rekey
  setkeyv(x, keys)

  # Return
  return(x)

}

textrange2vector <- function(x) {
  strsplit(x, ",") %>%
    lapply(
      . %>%
        strsplit("-") %>%
        lapply(as.numeric) %>%
        lapply(function(s)
          if (length(s) == 1) s
          else seq(s[1], s[2]))) %>%
    lapply(unlist)
}

trimCompress <- function(x) {

  if (!"magrittr" %in% loadedNamespaces()) # check if magrittr is loaded
    library(magrittr)                      # load if not

  if (is.null(x)) return(NULL)

  x %>%
    gsub("^\\s+", "", .) %>% # remove leading blanks
    gsub("\\s+$", "", .) %>% # remove trailing blanks
    gsub("\\s+", " ", .)     # compress multiple blanks to one

}







# Read parameterization file ####

message("Reading parameters...")

## Catalog parameters
avail_params <- read.xlsx(
  parameterization_file
  , "Available Parameters"
  , colNames = FALSE
  , startRow = 2
) %>% as.data.table
sheet_params <- c("name", "path", "sheet", "header", "rn")
setnames(avail_params, 1:5, sheet_params)
avail_params <- avail_params[!is.na(name) & grepl("[^[:space:]]", name)] %>%
  melt(id.vars = 1:5, value.name = "columns")
avail_params <- avail_params[, lapply(.SD, . %>% Filter(Negate(is.na), .)
%>%
                                        list), by = eval(sheet_params)]
avail_params[, variable := NULL]

## Analysis parameters
analysis_params <- read.xlsx(
  parameterization_file
  , "Parameterization"
  , startRow = 2
  , colNames = FALSE
) %>% as.data.table
setnames(analysis_params, c(
  "name1", "col1", "rows1", "dlm1",
  "verb", "case",
  "name2", "col2", "rows2", "dlm2",
  "outname", "outcols", "outflat"
))
analysis_params <- analysis_params[-1][!is.na(name1) &
                                         grepl("[^[:space:]]", name1)]
analysis_params[, n := 1:.N]

## Combine parameters
setkey(avail_params, name)
setkey(analysis_params, name1)
analysis_params[avail_params, ":="(
  path1 = path
  ,sheet1 = sheet
  ,header1 = header
  ,rn1 = rn
), allow.cartesian = TRUE]
setkey(analysis_params, name2)
analysis_params[avail_params, ":="(
  path2 = path
  ,sheet2 = sheet
  ,header2 = header
  ,rn2 = rn
), allow.cartesian = TRUE]
setkey(analysis_params, n)


# Match actions to functions
verb_function_map <- list(
  "A_i__in__B" = c("In", "Not In"),
  "A_i__in__B_i" = c("In (Same Row)", "Not In (Same Row)"),
  "A_i__substr__B_i" = c("Substring Of (Same Row)",
                         "Not Substring Of (Same Row)"),
  "A_i__unique" = c("Is Unique", "Not Unique")
) %>% unlist
names(verb_function_map) %<>% gsub("[0-9]+", "", .)
analysis_params[, fun := factor(verb)]
levels(analysis_params$fun) %<>%
  match(verb_function_map) %>%
  "["(names(verb_function_map), .)
analysis_params$fun %<>% as.character



# Read data sources

message("Reading data sources...")

data_names <- avail_params[, name]
data_list <- replicate(length(data_names), list(), simplify = FALSE)
names(data_list) <- data_names
for (i in 1:nrow(avail_params))
  data_list[[i]] <- with(avail_params[i], readSource(
    file_path = path
    , sheet_name = sheet
    , header_row = header
    , column_names = columns[[1]]
    , rownames_name = rn
  ))




# Analysis ####

message("Performing comparisons...")

reports <- analyses <- vector("list", nrow(analysis_params))
names(reports) <- names(analyses) <- analysis_params[, outname]

rowAnalysis2report <- function(analysis, params = list()) {

  # Create a copy
  x <- copy(analysis)

  # Subset to logical_val of logical_col
  setnames(x, setdiff(names(x), c("rn", "value")), "logical_col")
  x <- x[logical_col == !grepl("Not", params$verb)]
  x[, logical_col := NULL]

  # Re-encode
  Encoding(x$value) <- "UTF-8"
  if (is.character(x$rn))
    Encoding(x$rn) <- "UTF-8"

  # Unique results only
  setkey(x, rn, value)
  setcolorder(x, key(x))
  x <- unique(x)

  # Flatten if desired
  if (params$outflat == "Yes") {
    dlm <- Rdelim(params$dlm1)
    if (!is.null(dlm)) {
      if (dlm == "\\n") dlm <- "\n"
      x <- x[, list(value = paste(value, collapse = dlm)), by = rn]
    }
  }

  # Retrieve all columns if desired
  setkey(x, rn)
  if (params$outcols == "Yes") {
    full_source <- copy(data_list[[params$name1]])
    setkey(full_source, rn)
    x <- x[full_source, nomatch = 0, allow.cartesian = TRUE]
  }

  # Rename results columns
  if (is.null(params$rn1)) setnames(x, 1, "Row") else {
    if (is.na(params$rn1) | params$rn1 == params$col1) setnames(x, 1,
"Row")
    else setnames(x, 1, params$rn1)
  }
  setnames(x, 2, params$col1)

  return(x)

}

## Do it
for (i in 1:nrow(analysis_params)) {
  r <- analysis_params[i]
  args <- list(
    A = extractColumn(data_list[[r$name1]], r$col1, r$dlm1, r$rows1),
    B = if (!is.na(r$name2))
      extractColumn(data_list[[r$name2]], r$col2, r$dlm2, r$rows2),
    case = (r$case == "Yes")
  )
  analyses[[i]] <- do.call(r$fun, args)
  reports[[i]] <- rowAnalysis2report(analyses[[i]], r)
  rm(r, args)
}






# Output ####

message("Writing results to output file...")

detach("package:openxlsx")
suppressPackageStartupMessages(library(xlsx))

# Output file
exists <- TRUE
i <- 0
while (exists) {
  out_file <- if (i > 0) {
    file.path(cd, sprintf("Comparison_Reports_%s_(%s).xlsx", Sys.Date(), i))
  } else file.path(cd, sprintf("Comparison_Reports_%s.xlsx", Sys.Date()))
  exists <- file.exists(out_file)
  if (!exists)
    file.copy(parameterization_file, out_file)
  i <- i + 1
}

# Headers
headers <- analysis_params[, lapply(.SD, as.character), .SDcols = c(
  "outname", "col1", "verb", "col2", "case", "name1", "name2",
  "rows1", "rows2", "dlm1", "dlm2")]
headers[, case := factor(case, c("Yes", "No"),
                         c("(Case Sensitive)", "(Not Case Sensitive)"))]
headers[!is.na(col2), header_title := paste(col1, verb, col2, case)]
headers[is.na(col2), header_title := paste(col1, verb, case)]
headers[, header_time := Sys.time()]
headers$header_col1 <- headers[, list(col1, name1, rows1, dlm1)] %>%
  t %>%
  as.data.table %>%
  lapply(as.list) %>%
  lapply(as.data.table) %>%
  lapply(setnames, c("Column", "Source", "Rows", "Delimiter")) %>%
  lapply(as.list)
headers$header_col2 <- headers[, list(col2, name2, rows2, dlm2)] %>%
  t %>%
  as.data.table %>%
  lapply(as.list) %>%
  lapply(as.data.table) %>%
  lapply(setnames, c("Column", "Source", "Rows", "Delimiter")) %>%
  lapply(as.list)


# Write
keep <- c(ls(), "i", "keep")

## Loop through reports and write
for (i in names(reports)) {

  message(i, "...")

  # Load workbook
  wb <- loadWorkbook(out_file)

  # Workbook styles

  ## Header title
  hd <- CellStyle(
    wb,
    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
"VERTICAL_TOP"),
    font = Font(wb, heightInPoints = 16, isBold = TRUE)
  )

  ## Date
  dt <- CellStyle(
    wb,
    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
"VERTICAL_TOP"),
    dataFormat = DataFormat("m/d/yyyy h:mm:ss;@")
  )

  ## Parameters header
  ph <- CellStyle(
    wb,
    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
"VERTICAL_TOP"),
    font = Font(wb, isItalic = TRUE)
  )

  ## Column names header
  cn <- CellStyle(
    wb,
    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
"VERTICAL_TOP"),
    border = Border(position = c("BOTTOM", "TOP"),
                    pen = c("BORDER_THIN", "BORDER_MEDIUM")),
    font = Font(wb, isBold = TRUE)
  )

  ## Column names header for reproduced data
  cnr <- CellStyle(
    wb,
    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
"VERTICAL_TOP"),
    border = Border(position = c("BOTTOM", "TOP"),
                    pen = c("BORDER_THIN", "BORDER_MEDIUM")),
    font = Font(wb, isBold = TRUE, isItalic = TRUE)
  )

  ## Values
  vl <- CellStyle(
    wb,
    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
"VERTICAL_TOP",
                          wrapText = TRUE)
  )

  ## Values for reproduced data
  vlr <- CellStyle(
    wb,
    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
"VERTICAL_TOP",
                          wrapText = TRUE),
    font = Font(wb, isItalic = TRUE)
  )


  # Create sheet
  sh <- createSheet(wb, i)

  # Add header rows
  h <- headers[outname == i]
  addMergedRegion(sh, 1, 1, 1, 10)
  addMergedRegion(sh, 2, 2, 1, 10)
  rw <- createRow(sh, 1:2)
  cl <- createCell(rw, 1)

  ## Title
  addDataFrame(h[, header_title], sh, FALSE, FALSE, 1, 1)
  rw <- getRows(sh, 1)
  cl <- getCells(rw)
  lapply(cl, setCellStyle, hd)

  ## Date
  addDataFrame(h[, header_time], sh, FALSE, FALSE, 2, 1)
  rw <- getRows(sh, 2)
  cl <- getCells(rw)
  lapply(cl, setCellStyle, dt)

  ## Parameters
  addDataFrame(h[, header_col1] %>% as.data.frame, sh, TRUE, FALSE, 4, 1)
  if (h[, !is.na(col2)])
    addDataFrame(h[, header_col2] %>% as.data.frame, sh, FALSE, FALSE, 6, 1)
  rw <- getRows(sh, 4)
  cl <- getCells(rw)
  lapply(cl, setCellStyle, ph)
  rw <- getRows(sh, 5:6)
  cl <- getCells(rw)
  lapply(cl, setCellStyle, vl)

  # Add report
  addDataFrame(reports[[i]], sh, TRUE, FALSE, 8, 1)
  nc <- ncol(reports[[i]])

  ## Format column names
  rw <- getRows(sh, 8)
  cl <- getCells(rw, 1:2)
  lapply(cl, setCellStyle, cn)
  if (nc > 2)  {
    cl <- getCells(rw, 3:nc)
    lapply(cl, setCellStyle, cnr)
  }

  ## Format values
  rw <- getRows(sh, 9:(nrow(reports[[i]]) + 9))
  cl <- getCells(rw, 1:2)
  lapply(cl, setCellStyle, vl)
  if (nc > 2)  {
    cl <- getCells(rw, 3:nc)
    lapply(cl, setCellStyle, vlr)
  }

  ## Add autofilters
  if (ncol(reports[[i]]) > 26) {
    addAutoFilter(sh, sprintf("A8:%s%s%s",
                              LETTERS[floor(ncol(reports[[i]]) / 26)],
                              LETTERS[ncol(reports[[i]]) %% 26],
                              nrow(reports[[i]]) + 9))
  } else {
    addAutoFilter(sh, sprintf("A8:%s%s", LETTERS[ncol(reports[[i]])],
                              nrow(reports[[i]]) + 9))
  }

  # Autofit columns
  autoSizeColumn(sh, 1:ncol(reports[[i]]))

  # Create freeze on report column names and results columns
  if (nc > 2) createFreezePane(sh, rowSplit = 9, colSplit = 3) else
    createFreezePane(sh, rowSplit = 9, colSplit = 1)

  # Save
  saveWorkbook(wb, out_file)
  rm(list = setdiff(ls(), keep))

}
b

	[[alternative HTML version deleted]]


From spencer.graves at prodsyse.com  Sat Aug 29 23:21:22 2015
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 29 Aug 2015 16:21:22 -0500
Subject: [R] Multiple Integrals
In-Reply-To: <alpine.OSX.2.11.1508291346001.895@charles-berrys-macbook.local>
References: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>
	<alpine.OSX.2.11.1508291346001.895@charles-berrys-macbook.local>
Message-ID: <55E22252.60709@prodsyse.com>



On 8/29/2015 4:00 PM, Charles C. Berry wrote:
> On Sat, 29 Aug 2015, Shant Ch wrote:
>
>> Hello Dr. Berry,
>>
>> I know the theoretical side but note we are not talking about 
>> expectation of sums rather expectation of ABSOLUTE value of the 
>> function (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4| , I don&#39;t 
>> think this can be handled for log normal distribution by integrals by 
>> hand.
>>


       Have you looked at "distr" and related packages on CRAN?


       Spencer Graves

>
> Sorry! My tired eyes missed the absolute value.
>
> FWIW, there are some quadrature packages on CRAN.
>
> Chuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sun Aug 30 02:24:55 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 29 Aug 2015 17:24:55 -0700
Subject: [R] Multiple Integrals
In-Reply-To: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>
References: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>
Message-ID: <76D2748F-92D1-40E3-8C76-FE237A05B7BC@comcast.net>


On Aug 29, 2015, at 11:35 AM, Shant Ch via R-help wrote:

> Hello Dr. Berry,
> 
> I know the theoretical side but note we are not talking about expectation of sums rather expectation of ABSOLUTE value of the function (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4|  , I don&#39;t think this can be handled for log normal distribution by integrals by hand.
> 

To Shnant Ch;

I admit to puzzlement (being a humble country doctor). Can you explain why there should be a difference between the absolute value of an expectation for a sum of values from a function, in this case dlnorm,  that is positive definite versus an expectation simply of the sum of such values?

-- 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Sun Aug 30 02:55:06 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 29 Aug 2015 17:55:06 -0700
Subject: [R] Multiple Integrals
In-Reply-To: <76D2748F-92D1-40E3-8C76-FE237A05B7BC@comcast.net>
References: <1440873315.62131.YahooMailMobile@web141603.mail.bf1.yahoo.com>
	<76D2748F-92D1-40E3-8C76-FE237A05B7BC@comcast.net>
Message-ID: <1049EAB4-3E5B-4FAC-8A4A-DF9F5B8CB842@dcn.davis.CA.us>

X4 is being subtracted, not added.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 29, 2015 5:24:55 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>On Aug 29, 2015, at 11:35 AM, Shant Ch via R-help wrote:
>
>> Hello Dr. Berry,
>> 
>> I know the theoretical side but note we are not talking about
>expectation of sums rather expectation of ABSOLUTE value of the
>function (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4|  , I don&#39;t
>think this can be handled for log normal distribution by integrals by
>hand.
>> 
>
>To Shnant Ch;
>
>I admit to puzzlement (being a humble country doctor). Can you explain
>why there should be a difference between the absolute value of an
>expectation for a sum of values from a function, in this case dlnorm, 
>that is positive definite versus an expectation simply of the sum of
>such values?


From jdnewmil at dcn.davis.CA.us  Sun Aug 30 03:35:28 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 29 Aug 2015 18:35:28 -0700
Subject: [R] Advanced Level Script for Traceability Between Worksheets
In-Reply-To: <CAMHDO8r-19gRzfvKofDi1GstDHbSVsnvfKUoFkuTcCg-M_atBQ@mail.gmail.com>
References: <CAMHDO8r-19gRzfvKofDi1GstDHbSVsnvfKUoFkuTcCg-M_atBQ@mail.gmail.com>
Message-ID: <DB26D8F6-A679-4B83-AFDB-5F2B12697C46@dcn.davis.CA.us>

Some notes:

1) HTML damages your email on this mailing list (we often see run-on lines and garbage characters.. definitely not whatever you saw).

2) Massive scripts are off topic... please read the Posting Guide. If you can't narrow your question to a smaller example then you may really need a consultant.

3) Periods in this case don't have any special meaning... They just make the variable look weird.

4) This script makes liberal use of the data.tables package, which has some advantage in speed and memory efficiency if you are working with large data sets. The odd indexing used in ..A[..B, in_B := TRUE, allow.cartesian = TRUE] is a relational join that is discussed in the vignette for the data.table package. I only use data.tables if I need to optimise memory or execution speed because I don't find them very intuitive. The fact that this code makes copies so frequently may indicate that it is not as optimised as it could be. Or perhaps they are necessary and I just have not looked at it closely enough.

5) A very few uses of %>? and ?<>? are from the magrittr package... I do find that helpful though it seems like the author here was only just getting started using it. Again, you would need to read the vignette and/or some internet tutorials to follow that syntax... I find it much easier than data.table though it is solving a different problem.

6) I don't consult off list... sorry.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 29, 2015 1:19:35 PM PDT, C Campbell <cc571309 at gmail.com> wrote:
>Hi folks - I have almost know R skills yet and have been put 'in
>charge' of
>the below script created by a former employee.  Although some of this
>is
>understandable to me, much of it is not.  If anyone can help with
>explaining sections, commenting on the skill level it takes to
>understand
>this level of scripting in R, and/or point me to some resources that
>may
>cover some of this (e.g., what is ..A[..B, in_B := TRUE,
>allow.cartesian =
>TRUE]; and specifically what do the 2 dots mean?), I would very much
>appreciate it.  Would also be interested in communicating offline if
>you
>prefer.
>Thank you,
>Jay
>
>
>
># Locate file ####
>parameterization_file <- file.choose()
>cd <- dirname(parameterization_file)
>
># Front matter ####
>message("Installing and loading packages...")
>
># Packages
>required_packages <- c("openxlsx", "xlsx", "magrittr", "data.table",
>"reshape2",
>                       "XML")
>install_these <- setdiff(required_packages,
>rownames(installed.packages()))
>
>while (length(install_these) > 0) {
>  install.packages(install_these, repos = "http://cran.rstudio.com")
>  install_these <- setdiff(required_packages,
>rownames(installed.packages()))
>}
>
>suppressPackageStartupMessages(library(openxlsx))
>suppressPackageStartupMessages(library(magrittr))
>suppressPackageStartupMessages(library(data.table))
>suppressPackageStartupMessages(library(reshape2))
>suppressPackageStartupMessages(library(XML))
>
>
># Options
>options(stringsAsFactors = FALSE)
>
># Functions
>message("Loading functions...")
>
>A__in__B <- function(A, B, case = TRUE, ...) {
>
>  # Copies
>  ..A <- copy(A)
>  ..B <- copy(B)
>  setkey(..A, value)
>  setkey(..B, value)
>  ..A <- unique(..A)
>  ..B <- unique(..B)
>
>  # Rownames are unnecessary
>  ..A[, rn := NULL]
>  ..B[, rn := NULL]
>
>  # Case sensitivity
>  if (!case) {
>    ..A <- tableToLower(..A)
>    ..B <- tableToLower(..B)
>  }
>
>  # Check if A is in B
>  ..A[..B, in_B := TRUE, allow.cartesian = TRUE]
>  if ("in_B" %in% names(..A))
>    ..A[is.na(in_B), in_B := FALSE]
>  else
>    ..A[, in_B := FALSE]
>
>  # Case sensitivity
>  if (!case)
>    ..A <- tableDropLower(..A)
>
>  # Set attributes
>  setABattr(..A, A, B)
>
>  # Return results
>  setkey(..A, value)
>  return(..A)
>
>}
>
>A__unique <- function(A, case = TRUE, ...) {
>
>  # Copies
>  ..A <- copy(A)
>  setkey(..A, value)
>
>  # Case sensitivity
>  if (!case)
>    ..A <- tableToLower(..A)
>
>  # Check if A_i values are unique
>  ..A[..A[duplicated(..A), SJ(value)], is_unique := FALSE,
>      allow.cartesian = TRUE]
>  if ("is_unique" %in% names(..A))
>    ..A[is.na(is_unique), is_unique := TRUE]
>  else
>    ..A[, is_unique := TRUE]
>
>  # Case sensitivity
>  if (!case)
>    ..A <- tableDropLower(..A)
>
>  # Roll up to value level
>  ..A <- ..A[, list(is_unique = all(is_unique)), keyby = value]
>
>  # Return results
>  return(..A)
>
>}
>
>A_i__in__B <- function(A, B, case = TRUE, ...) {
>
>  # Copies
>  ..A <- copy(A)
>  setkey(..A, value, rn)
>  ..A <- unique(..A)
>  ..B <- copy(B)
>  setkey(..B, value)
>  ..B %>% unique
>
>  # B rownames are unnecessary
>  ..B[, rn := NULL]
>
>  # Case sensitivity
>  if (!case) {
>    ..A <- tableToLower(..A)
>    ..B <- tableToLower(..B)
>  }
>
>  # Check if A is in B
>  if ("in_B" %in% names(..A))
>    ..A[is.na(in_B), in_B := FALSE]
>  else
>    ..A[, in_B := FALSE]
>
>  # Case sensitivity
>  if (!case)
>    ..A <- tableDropLower(..A)
>
>  # Set attributes
>  setABattr(..A, A, B)
>
>  # Return results
>  setkey(..A, value, rn)
>  return(..A)
>
>}
>
>A_i__in__B_i <- function(A, B, case = TRUE, ...) {
>
>  # Copies
>  ..A <- copy(A)
>  setkey(..A, value, rn)
>  ..A <- unique(..A)
>  ..B <- copy(B)
>  setkey(..B, value, rn)
>  ..B <- unique(..B)
>
>  # Case sensitivity
>  if (!case) {
>    ..A <- tableToLower(..A)
>    ..B <- tableToLower(..B)
>  }
>
>  # Check if A_i terms are in B_i terms
>  ..A[..B, in_B := TRUE, allow.cartesian = TRUE]
>  if ("in_B" %in% names(..A))
>    ..A[is.na(in_B), in_B := FALSE]
>  else
>    ..A[, in_B := FALSE]
>
>  # Case sensitivity
>  if (!case)
>    ..A <- tableDropLower(..A)
>
>  # Set attributes
>  setABattr(..A, A, B)
>
>  # Return results
>  setkey(..A, value, rn)
>  return(..A)
>
>}
>
>A_i__substr__B_i <- function(A, B, case = TRUE, ...) {
>
>  # Copies
>  ..A <- copy(A)
>  setkey(..A, rn)
>  ..B <- copy(B)
>  setkey(..B, rn)
>
>  # Renames
>  setnames(..A, "value", "A_value")
>  setnames(..B, "value", "B_value")
>
>  # Merge
>  ..X <- ..B[..A, allow.cartesian = TRUE]
>
>  # Check if A_i values are substrings of B_i values
>  ..X[is.na(B_value), is_substring := FALSE]
>  Encoding(..X$A_value) <- "UTF-8"
>  Encoding(..X$B_value) <- "UTF-8"
>  if (case) {
>    ..X[!is.na(B_value), is_substring := mapply(
>      grepl, A_value, B_value, fixed = TRUE)]
>  } else {
>    ..X[!is.na(B_value), is_substring := mapply(
>      grepl, tolower(A_value), tolower(B_value), fixed = TRUE)]
>  }
>  Encoding(..X$A_value) <- "bytes"
>  Encoding(..X$B_value) <- "bytes"
>
>  # Rename/reorder
>  ..X <- ..X[, list(value = A_value, rn, is_substring)]
>
>  # Set attributes
>  setABattr(..X, A, B)
>
>  # Return results
>  setkey(..X, value, rn)
>  return(..X)
>
>}
>
>A_i__unique <- function(A, case = TRUE, ...) {
>
>  # Copies
>  ..A <- copy(A)
>  setkey(..A, value)
>
>  # Case sensitivity
>  if (!case)
>    ..A <- tableToLower(..A)
>
>  # Check if A_i values are unique
>  ..A[..A[duplicated(..A), SJ(value)], is_unique := FALSE,
>      allow.cartesian = TRUE]
>  if ("is_unique" %in% names(..A))
>    ..A[is.na(is_unique), is_unique := TRUE]
>  else
>    ..A[, is_unique := TRUE]
>
>  # Case sensitivity
>  if (!case)
>    ..A <- tableDropLower(..A)
>
>  # Return results
>  setkey(..A, value, rn)
>  return(..A)
>
>}
>
>extractColumn <- function(x, column_name, value_delimiter = NULL, rows
>=
>NULL)
>{
>
>  # Validate formatting on column name args
>  column_name %<>% trimCompress
>
>  # Multiple columns?
>  mult_cols <- grepl(",", column_name)
>  if (mult_cols)
>    column_name %<>% strsplit(",") %>% unlist %>% trimCompress
>
>  # Get column + rn
>  ..table <- x[, c("rn", column_name), with = FALSE]
>  setnames(..table, 2, "value")
>
>  # Long if multiple
>  if (mult_cols) {
>    ..table %<>% melt(1)
>    ..table[, variable := NULL]
>  }
>
>  # Key table by rowname
>  setkey(..table, rn)
>
>  # If rows was provided, subset
>  if (!is.null(rows))
>    if (rows != "All")
>      ..table <- ..table[textrange2vector(rows) %>% SJ]
>
>  # Split values according to delimiter...
>  dlm <- Rdelim(value_delimiter)
>  if (!is.null(dlm))
>    ..values <- strsplit(..table[, value], Rdelim(value_delimiter)) %>%
>    lapply(trimCompress)
>  # ... or convert to list if no delimiter
>  else
>    ..values <- ..table[, value] %>% trimCompress %>% as.list
>
>  # Set list name values to rowname values
>  names(..values) <- ..table[, rn]
>
>  # Convert from list to table
>  ..values %<>% melt %>% as.data.table
>  setnames(..values, 2, "rn")
>
>  # Remove any instances of blank values
>  ..values <- ..values[!is.na(value) & grepl("[^[:space:]]", value)]
>
>  # Encode all text to bytes
>  # Will need to encode to UTF-8 before output to make it readable
>  Encoding(..values$value) <- "bytes"
>  if (is.character(..values$rn)) Encoding(..values$rn) <- "bytes"
>
>  # If row names can be converted to numeric, do so
>  if (..values[, rn] %>% is.character)
>    if (..values[, rn] %>% type.convert %>% is.numeric)
>      ..values[, rn := as.numeric(rn)]
>
>  # Key table by value
>  setkey(..values, value, rn)
>
>  # Add attributes
>  setattr(..values, "file_path", attr(x, "file_path"))
>  setattr(..values, "sheet_name", attr(x, "sheet_name"))
>  setattr(..values, "header_row", attr(x, "header_row"))
>  setattr(..values, "column_name", column_name)
>  setattr(..values, "rownames_name", attr(x, "rownames_name"))
>  setattr(..values, "value_delimiter", value_delimiter)
>  setattr(..values, "rows", rows)
>
>  # Return the values table
>  return(..values)
>
>}
>
>fillNAlast <- function(x) {
>  na <- is.na(x)
>  miss <- which(na)
>  nonmiss <- which(!na)
>  map <- outer(nonmiss, miss, "<") %>%
>    apply(2, . %>% which %>% max)
>  x[miss] <- x[nonmiss[map]]
>  return(x)
>}
>
>getSheetIndex <- function(file_path, sheet_name) {
>
># Extract workbook.xml to temporary file that will be deleted at end of
>  # run
>  xmlDir <- file.path(tempdir(), "findSheet")
>workbook <- unzip(file_path, files = "xl/workbook.xml", exdir = xmlDir)
>  on.exit(unlink(xmlDir, recursive = TRUE), add = TRUE)
>
>  # Read workbook.xml and get sheet nodes
>  workbook <- readLines(workbook, warn = FALSE, encoding = "UTF-8") %>%
>    unlist
>  sheets <- gregexpr("<sheet .*/sheets>", workbook, perl = TRUE) %>%
>    regmatches(workbook, .) %>%
>    unlist
>
>  # Extract sheet names from nodes, parse as html, and return text
>values
>  sheetNames <- gregexpr('(?<=name=")[^"]+', sheets, perl = TRUE) %>%
>    regmatches(sheets, .) %>%
>    unlist %>%
>    lapply(htmlParse, asText = TRUE) %>%
>    sapply(. %>% xpathApply("//body//text()", xmlValue) %>% unlist)
>
>  # Which sheet name is equal to the sheet_name argument?
>  which(sheetNames == sheet_name)
>
>}
>
>Rdelim <- function(x, ...) {
>  if (!is.null(x)) {
>    if (!is.na(x) & x != "None") {
>      if (x == "Newline") "\\n" else x
>    } else NULL
>  } else NULL
>}
>
>readSource <- function(file_path, sheet_name, header_row, column_names,
>                       rownames_name = NULL)
>{
>
>  # Validate formatting on column name args
>  column_names %<>% strsplit(",") %>% unlist %>% trimCompress
>  rownames_name %<>% trimCompress
>
>  # Sheet index
>  sheet_index <- getSheetIndex(file_path, sheet_name)
>
>  # Read column names according to header row
>  ..names <- read.xlsx(
>    xlsxFile = file_path
>    , sheet = sheet_index
>    , colNames = FALSE
>    , rows = header_row
>  ) %>% unlist %>% unname %>% trimCompress
>
>  # Read in column plus and any rownames column
>  ..table <- read.xlsx(
>    xlsxFile = file_path
>    , sheet = sheet_index
>    , startRow = header_row
>    , cols = which(..names %in% c(rownames_name, column_names))
>    , skipEmptyRows = FALSE
>    , detectDates = TRUE
>  ) %>% as.data.table
>
>  # Set names
>  setnames(..table,
>           ..names[which(..names %in% c(rownames_name, column_names))])
>
>  # Rownames
>  ## If no rownames column, use row number
>  if (is.null(rownames_name)) {
>if (is.null(rows)) ..table[, rn := 1:.N + 1L] else ..table[, rn :=
>rows]
>  } else { # Otherwise, just copy the column
>    ..table[, rn := lapply(.SD, identity), .SDcols = rownames_name]
>  }
>  setcolorder(..table, c("rn", setdiff(names(..table), "rn")))
>
>  # If row can be converted to numeric, do so
>  if (..table[, rn] %>% is.character)
>    if (..table[, rn] %>% type.convert %>% is.numeric)
>      ..table[, rn := as.numeric(rn)]
>
>  # Key table by row
>  setkey(..table, rn)
>
>  # Add attributes
>  setattr(..table, "file_path", file_path)
>  setattr(..table, "sheet_name", sheet_name)
>  setattr(..table, "header_row", header_row)
>  setattr(..table, "column_names", column_names)
>  setattr(..table, "rownames_name", rownames_name)
>
>  # Return the values table
>  return(..table)
>
>}
>
>setABattr <- function(new_table, A, B) {
>
>  # Strip existing attributes in new_table
>  setattr(new_table, "file_path", NULL)
>  setattr(new_table, "sheet_name", NULL)
>  setattr(new_table, "header_row", NULL)
>  setattr(new_table, "column_name", NULL)
>  setattr(new_table, "rownames_name", NULL)
>  setattr(new_table, "value_delimiter", NULL)
>  setattr(new_table, "rows", NULL)
>  setattr(new_table, "rows_are_rownames", NULL)
>
>  # Set A attributes in new_table
>  setattr(new_table, "A_file_path", attributes(A)$file_path)
>  setattr(new_table, "A_sheet_name", attributes(A)$sheet_name)
>  setattr(new_table, "A_header_row", attributes(A)$header_row)
>  setattr(new_table, "A_column_name", attributes(A)$column_name)
>  setattr(new_table, "A_rownames_name", attributes(A)$rownames_name)
> setattr(new_table, "A_value_delimiter", attributes(A)$value_delimiter)
>  setattr(new_table, "A_rows", attributes(A)$rows)
>setattr(new_table, "A_rows_are_rownames",
>attributes(A)$rows_are_rownames)
>
>  # Set B attributes in new_table
>  setattr(new_table, "B_file_path", attributes(B)$file_path)
>  setattr(new_table, "B_sheet_name", attributes(B)$sheet_name)
>  setattr(new_table, "B_header_row", attributes(B)$header_row)
>  setattr(new_table, "B_column_name", attributes(B)$column_name)
>  setattr(new_table, "B_rownames_name", attributes(B)$rownames_name)
> setattr(new_table, "B_value_delimiter", attributes(B)$value_delimiter)
>  setattr(new_table, "B_rows", attributes(B)$rows)
>setattr(new_table, "B_rows_are_rownames",
>attributes(B)$rows_are_rownames)
>
>}
>
>tableToLower <- function(X, ...) {
>
>  # Copy
>  x <- copy(X)
>
>  # Existing keys
>  keys <- key(x)
>  setkey(x, NULL)
>
>  # Rename value column
>  setnames(x, "value", "value_orig")
>
>  # Derived value column
>  Encoding(x$value_orig) <- "UTF-8"
>  x[, value := tolower(value_orig)]
>  Encoding(x$value) <- "bytes"
>  Encoding(x$value_orig) <- "bytes"
>
>  # Rekey
>  setkeyv(x, keys)
>
>  # Return
>  return(x)
>
>}
>
>tableDropLower <- function(X, ...) {
>
>  # Copy
>  x <- copy(X)
>
>  # Existing keys
>  keys <- key(x)
>  setkey(x, NULL)
>
>  # Drop derived value column
>  x[, value := NULL]
>
>  # Rename value_orig column
>  setnames(x, "value_orig", "value")
>
>  # Rekey
>  setkeyv(x, keys)
>
>  # Return
>  return(x)
>
>}
>
>textrange2vector <- function(x) {
>  strsplit(x, ",") %>%
>    lapply(
>      . %>%
>        strsplit("-") %>%
>        lapply(as.numeric) %>%
>        lapply(function(s)
>          if (length(s) == 1) s
>          else seq(s[1], s[2]))) %>%
>    lapply(unlist)
>}
>
>trimCompress <- function(x) {
>
> if (!"magrittr" %in% loadedNamespaces()) # check if magrittr is loaded
>    library(magrittr)                      # load if not
>
>  if (is.null(x)) return(NULL)
>
>  x %>%
>    gsub("^\\s+", "", .) %>% # remove leading blanks
>    gsub("\\s+$", "", .) %>% # remove trailing blanks
>    gsub("\\s+", " ", .)     # compress multiple blanks to one
>
>}
>
>
>
>
>
>
>
># Read parameterization file ####
>
>message("Reading parameters...")
>
>## Catalog parameters
>avail_params <- read.xlsx(
>  parameterization_file
>  , "Available Parameters"
>  , colNames = FALSE
>  , startRow = 2
>) %>% as.data.table
>sheet_params <- c("name", "path", "sheet", "header", "rn")
>setnames(avail_params, 1:5, sheet_params)
>avail_params <- avail_params[!is.na(name) & grepl("[^[:space:]]",
>name)] %>%
>  melt(id.vars = 1:5, value.name = "columns")
>avail_params <- avail_params[, lapply(.SD, . %>% Filter(Negate(is.na),
>.)
>%>%
>                                        list), by = eval(sheet_params)]
>avail_params[, variable := NULL]
>
>## Analysis parameters
>analysis_params <- read.xlsx(
>  parameterization_file
>  , "Parameterization"
>  , startRow = 2
>  , colNames = FALSE
>) %>% as.data.table
>setnames(analysis_params, c(
>  "name1", "col1", "rows1", "dlm1",
>  "verb", "case",
>  "name2", "col2", "rows2", "dlm2",
>  "outname", "outcols", "outflat"
>))
>analysis_params <- analysis_params[-1][!is.na(name1) &
>                                         grepl("[^[:space:]]", name1)]
>analysis_params[, n := 1:.N]
>
>## Combine parameters
>setkey(avail_params, name)
>setkey(analysis_params, name1)
>analysis_params[avail_params, ":="(
>  path1 = path
>  ,sheet1 = sheet
>  ,header1 = header
>  ,rn1 = rn
>), allow.cartesian = TRUE]
>setkey(analysis_params, name2)
>analysis_params[avail_params, ":="(
>  path2 = path
>  ,sheet2 = sheet
>  ,header2 = header
>  ,rn2 = rn
>), allow.cartesian = TRUE]
>setkey(analysis_params, n)
>
>
># Match actions to functions
>verb_function_map <- list(
>  "A_i__in__B" = c("In", "Not In"),
>  "A_i__in__B_i" = c("In (Same Row)", "Not In (Same Row)"),
>  "A_i__substr__B_i" = c("Substring Of (Same Row)",
>                         "Not Substring Of (Same Row)"),
>  "A_i__unique" = c("Is Unique", "Not Unique")
>) %>% unlist
>names(verb_function_map) %<>% gsub("[0-9]+", "", .)
>analysis_params[, fun := factor(verb)]
>levels(analysis_params$fun) %<>%
>  match(verb_function_map) %>%
>  "["(names(verb_function_map), .)
>analysis_params$fun %<>% as.character
>
>
>
># Read data sources
>
>message("Reading data sources...")
>
>data_names <- avail_params[, name]
>data_list <- replicate(length(data_names), list(), simplify = FALSE)
>names(data_list) <- data_names
>for (i in 1:nrow(avail_params))
>  data_list[[i]] <- with(avail_params[i], readSource(
>    file_path = path
>    , sheet_name = sheet
>    , header_row = header
>    , column_names = columns[[1]]
>    , rownames_name = rn
>  ))
>
>
>
>
># Analysis ####
>
>message("Performing comparisons...")
>
>reports <- analyses <- vector("list", nrow(analysis_params))
>names(reports) <- names(analyses) <- analysis_params[, outname]
>
>rowAnalysis2report <- function(analysis, params = list()) {
>
>  # Create a copy
>  x <- copy(analysis)
>
>  # Subset to logical_val of logical_col
>  setnames(x, setdiff(names(x), c("rn", "value")), "logical_col")
>  x <- x[logical_col == !grepl("Not", params$verb)]
>  x[, logical_col := NULL]
>
>  # Re-encode
>  Encoding(x$value) <- "UTF-8"
>  if (is.character(x$rn))
>    Encoding(x$rn) <- "UTF-8"
>
>  # Unique results only
>  setkey(x, rn, value)
>  setcolorder(x, key(x))
>  x <- unique(x)
>
>  # Flatten if desired
>  if (params$outflat == "Yes") {
>    dlm <- Rdelim(params$dlm1)
>    if (!is.null(dlm)) {
>      if (dlm == "\\n") dlm <- "\n"
>      x <- x[, list(value = paste(value, collapse = dlm)), by = rn]
>    }
>  }
>
>  # Retrieve all columns if desired
>  setkey(x, rn)
>  if (params$outcols == "Yes") {
>    full_source <- copy(data_list[[params$name1]])
>    setkey(full_source, rn)
>    x <- x[full_source, nomatch = 0, allow.cartesian = TRUE]
>  }
>
>  # Rename results columns
>  if (is.null(params$rn1)) setnames(x, 1, "Row") else {
>    if (is.na(params$rn1) | params$rn1 == params$col1) setnames(x, 1,
>"Row")
>    else setnames(x, 1, params$rn1)
>  }
>  setnames(x, 2, params$col1)
>
>  return(x)
>
>}
>
>## Do it
>for (i in 1:nrow(analysis_params)) {
>  r <- analysis_params[i]
>  args <- list(
>    A = extractColumn(data_list[[r$name1]], r$col1, r$dlm1, r$rows1),
>    B = if (!is.na(r$name2))
>      extractColumn(data_list[[r$name2]], r$col2, r$dlm2, r$rows2),
>    case = (r$case == "Yes")
>  )
>  analyses[[i]] <- do.call(r$fun, args)
>  reports[[i]] <- rowAnalysis2report(analyses[[i]], r)
>  rm(r, args)
>}
>
>
>
>
>
>
># Output ####
>
>message("Writing results to output file...")
>
>detach("package:openxlsx")
>suppressPackageStartupMessages(library(xlsx))
>
># Output file
>exists <- TRUE
>i <- 0
>while (exists) {
>  out_file <- if (i > 0) {
>file.path(cd, sprintf("Comparison_Reports_%s_(%s).xlsx", Sys.Date(),
>i))
>} else file.path(cd, sprintf("Comparison_Reports_%s.xlsx", Sys.Date()))
>  exists <- file.exists(out_file)
>  if (!exists)
>    file.copy(parameterization_file, out_file)
>  i <- i + 1
>}
>
># Headers
>headers <- analysis_params[, lapply(.SD, as.character), .SDcols = c(
>  "outname", "col1", "verb", "col2", "case", "name1", "name2",
>  "rows1", "rows2", "dlm1", "dlm2")]
>headers[, case := factor(case, c("Yes", "No"),
>                        c("(Case Sensitive)", "(Not Case Sensitive)"))]
>headers[!is.na(col2), header_title := paste(col1, verb, col2, case)]
>headers[is.na(col2), header_title := paste(col1, verb, case)]
>headers[, header_time := Sys.time()]
>headers$header_col1 <- headers[, list(col1, name1, rows1, dlm1)] %>%
>  t %>%
>  as.data.table %>%
>  lapply(as.list) %>%
>  lapply(as.data.table) %>%
>  lapply(setnames, c("Column", "Source", "Rows", "Delimiter")) %>%
>  lapply(as.list)
>headers$header_col2 <- headers[, list(col2, name2, rows2, dlm2)] %>%
>  t %>%
>  as.data.table %>%
>  lapply(as.list) %>%
>  lapply(as.data.table) %>%
>  lapply(setnames, c("Column", "Source", "Rows", "Delimiter")) %>%
>  lapply(as.list)
>
>
># Write
>keep <- c(ls(), "i", "keep")
>
>## Loop through reports and write
>for (i in names(reports)) {
>
>  message(i, "...")
>
>  # Load workbook
>  wb <- loadWorkbook(out_file)
>
>  # Workbook styles
>
>  ## Header title
>  hd <- CellStyle(
>    wb,
>    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
>"VERTICAL_TOP"),
>    font = Font(wb, heightInPoints = 16, isBold = TRUE)
>  )
>
>  ## Date
>  dt <- CellStyle(
>    wb,
>    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
>"VERTICAL_TOP"),
>    dataFormat = DataFormat("m/d/yyyy h:mm:ss;@")
>  )
>
>  ## Parameters header
>  ph <- CellStyle(
>    wb,
>    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
>"VERTICAL_TOP"),
>    font = Font(wb, isItalic = TRUE)
>  )
>
>  ## Column names header
>  cn <- CellStyle(
>    wb,
>    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
>"VERTICAL_TOP"),
>    border = Border(position = c("BOTTOM", "TOP"),
>                    pen = c("BORDER_THIN", "BORDER_MEDIUM")),
>    font = Font(wb, isBold = TRUE)
>  )
>
>  ## Column names header for reproduced data
>  cnr <- CellStyle(
>    wb,
>    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
>"VERTICAL_TOP"),
>    border = Border(position = c("BOTTOM", "TOP"),
>                    pen = c("BORDER_THIN", "BORDER_MEDIUM")),
>    font = Font(wb, isBold = TRUE, isItalic = TRUE)
>  )
>
>  ## Values
>  vl <- CellStyle(
>    wb,
>    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
>"VERTICAL_TOP",
>                          wrapText = TRUE)
>  )
>
>  ## Values for reproduced data
>  vlr <- CellStyle(
>    wb,
>    alignment = Alignment(horizontal = "ALIGN_LEFT", vertical =
>"VERTICAL_TOP",
>                          wrapText = TRUE),
>    font = Font(wb, isItalic = TRUE)
>  )
>
>
>  # Create sheet
>  sh <- createSheet(wb, i)
>
>  # Add header rows
>  h <- headers[outname == i]
>  addMergedRegion(sh, 1, 1, 1, 10)
>  addMergedRegion(sh, 2, 2, 1, 10)
>  rw <- createRow(sh, 1:2)
>  cl <- createCell(rw, 1)
>
>  ## Title
>  addDataFrame(h[, header_title], sh, FALSE, FALSE, 1, 1)
>  rw <- getRows(sh, 1)
>  cl <- getCells(rw)
>  lapply(cl, setCellStyle, hd)
>
>  ## Date
>  addDataFrame(h[, header_time], sh, FALSE, FALSE, 2, 1)
>  rw <- getRows(sh, 2)
>  cl <- getCells(rw)
>  lapply(cl, setCellStyle, dt)
>
>  ## Parameters
>addDataFrame(h[, header_col1] %>% as.data.frame, sh, TRUE, FALSE, 4, 1)
>  if (h[, !is.na(col2)])
>addDataFrame(h[, header_col2] %>% as.data.frame, sh, FALSE, FALSE, 6,
>1)
>  rw <- getRows(sh, 4)
>  cl <- getCells(rw)
>  lapply(cl, setCellStyle, ph)
>  rw <- getRows(sh, 5:6)
>  cl <- getCells(rw)
>  lapply(cl, setCellStyle, vl)
>
>  # Add report
>  addDataFrame(reports[[i]], sh, TRUE, FALSE, 8, 1)
>  nc <- ncol(reports[[i]])
>
>  ## Format column names
>  rw <- getRows(sh, 8)
>  cl <- getCells(rw, 1:2)
>  lapply(cl, setCellStyle, cn)
>  if (nc > 2)  {
>    cl <- getCells(rw, 3:nc)
>    lapply(cl, setCellStyle, cnr)
>  }
>
>  ## Format values
>  rw <- getRows(sh, 9:(nrow(reports[[i]]) + 9))
>  cl <- getCells(rw, 1:2)
>  lapply(cl, setCellStyle, vl)
>  if (nc > 2)  {
>    cl <- getCells(rw, 3:nc)
>    lapply(cl, setCellStyle, vlr)
>  }
>
>  ## Add autofilters
>  if (ncol(reports[[i]]) > 26) {
>    addAutoFilter(sh, sprintf("A8:%s%s%s",
>                              LETTERS[floor(ncol(reports[[i]]) / 26)],
>                              LETTERS[ncol(reports[[i]]) %% 26],
>                              nrow(reports[[i]]) + 9))
>  } else {
>    addAutoFilter(sh, sprintf("A8:%s%s", LETTERS[ncol(reports[[i]])],
>                              nrow(reports[[i]]) + 9))
>  }
>
>  # Autofit columns
>  autoSizeColumn(sh, 1:ncol(reports[[i]]))
>
>  # Create freeze on report column names and results columns
>  if (nc > 2) createFreezePane(sh, rowSplit = 9, colSplit = 3) else
>    createFreezePane(sh, rowSplit = 9, colSplit = 1)
>
>  # Save
>  saveWorkbook(wb, out_file)
>  rm(list = setdiff(ls(), keep))
>
>}
>b
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ramesh_naikap at yahoo.com  Sun Aug 30 04:17:13 2015
From: ramesh_naikap at yahoo.com (ramesh shrestha)
Date: Sun, 30 Aug 2015 02:17:13 +0000 (UTC)
Subject: [R] Seeking solution for loading Source R Code
Message-ID: <14259538.2774494.1440901033340.JavaMail.yahoo@mail.yahoo.com>

Dear Sirs/Madams,
I am Ramesh Shrestha, a student of M.Sc. in Environmental Sciences from Nepal.??I am using RClimDex version 3.2.1 software in quality control, homogeneity test and?core Climate Indices calculation of temperature and precipitation data for?my dissertation related to climate change.?
Unfortunately, I had to change my laptop after the one in which this software was installed, crashed. I installed the software in my new laptop but I am facing some difficulties in trying to load source R Code.?
I installed this software version 3.2.1 on my new laptop but could not locate rclimdex.r and?rhtest_gui.r?while trying to load them going through:?File???Source R code???C??Program Files??R???R-3.2.1???bin
Attaching herewith are the snapshots of the steps I followed while trying to load source r code and rclimdex.r and?rhtest_gui.r...

Please suggest what I should do.... I tried to run in another computer of my friend but the problem is same.... I also tried with older versions but the problem remains same. I went through FAQs too but could not get solution. Please help.....??Sincerely yours',
Ramesh Shrestha
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Pic_1.PNG
Type: image/png
Size: 38283 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150830/c8fc8d8e/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Pic_2.PNG
Type: image/png
Size: 90837 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150830/c8fc8d8e/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Pic_3.PNG
Type: image/png
Size: 66763 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150830/c8fc8d8e/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Pic_4.PNG
Type: image/png
Size: 65869 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150830/c8fc8d8e/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Pic_5 (No .r file).PNG
Type: image/png
Size: 67808 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20150830/c8fc8d8e/attachment-0004.png>

From aunmuhammad78 at yahoo.com  Sun Aug 30 04:57:21 2015
From: aunmuhammad78 at yahoo.com (aun syed)
Date: Sun, 30 Aug 2015 02:57:21 +0000 (UTC)
Subject: [R] R-help
Message-ID: <2032094060.2850741.1440903441733.JavaMail.yahoo@mail.yahoo.com>

Dear R administration,?
i have installed R x64 3.2.2 and i am trying to install annotation software on it (hgu133a.db and hgu133acdf), but i am getting this error, how can i solve this issue, thanks for your help.Regards,Dr. Syed AunPost-Doctoral Fellow, China



* installing *source* package 'hgu133acdf' ...** R** data** preparing package for lazy loadingError in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :?? there is no package called 'DBI'ERROR: lazy loading failed for package 'hgu133acdf'* removing 'C:/Users/PC/Documents/R/win-library/3.2/hgu133acdf'
The downloaded source packages are in? ? ? ? ?C:\Users\PC\AppData\Local\Temp\RtmpySLSpD\downloaded_packages?Warning messages:1: running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\PC\Documents\R\win-library\3.2" C:\Users\PC\AppData\Local\Temp\RtmpySLSpD/downloaded_packages/hgu133acdf_2.16.0.tar.gz' had status 1?2: In install.packages(NULL, .libPaths()[1L], dependencies = NA, type = type) :? installation of package ?hgu133acdf? had non-zero exit status





	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Aug 30 06:40:56 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 30 Aug 2015 14:40:56 +1000
Subject: [R] Seeking solution for loading Source R Code
In-Reply-To: <14259538.2774494.1440901033340.JavaMail.yahoo@mail.yahoo.com>
References: <14259538.2774494.1440901033340.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fXbJKH1pe7vTDmzN9BEmSu9gXF-_b03NDcj76Z7+z8ifQ@mail.gmail.com>

Hi Ramesh,
This may be completely wrong, but did you transfer the R source code files
from your old computer to your new one? They won't just appear when you
load R 3.2.1 on a computer.

Jim


On Sun, Aug 30, 2015 at 12:17 PM, ramesh shrestha via R-help <
r-help at r-project.org> wrote:

> Dear Sirs/Madams,
> I am Ramesh Shrestha, a student of M.Sc. in Environmental Sciences from
> Nepal.  I am using RClimDex version 3.2.1 software in quality control,
> homogeneity test and core Climate Indices calculation of temperature and
> precipitation data for my dissertation related to climate change.
> Unfortunately, I had to change my laptop after the one in which this
> software was installed, crashed. I installed the software in my new laptop
> but I am facing some difficulties in trying to load source R Code.
> I installed this software version 3.2.1 on my new laptop but could not
> locate rclimdex.r and rhtest_gui.r while trying to load them going
> through: File ? Source R code ? C? Program Files? R ? R-3.2.1 ? bin
> Attaching herewith are the snapshots of the steps I followed while trying
> to load source r code and rclimdex.r and rhtest_gui.r...
>
> Please suggest what I should do.... I tried to run in another computer of
> my friend but the problem is same.... I also tried with older versions but
> the problem remains same. I went through FAQs too but could not get
> solution. Please help.....  Sincerely yours',
> Ramesh Shrestha
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Aug 30 06:45:03 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 30 Aug 2015 14:45:03 +1000
Subject: [R] R-help
In-Reply-To: <2032094060.2850741.1440903441733.JavaMail.yahoo@mail.yahoo.com>
References: <2032094060.2850741.1440903441733.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fXc=7qMdQLzWUPT5qxnPdGteBcjDaQV7b_u92N6xkwXeg@mail.gmail.com>

Hi Aun,
It looks like you haven't installed the DBI package, which seems to be
required by the hgu133acdf package. Try installing DBI first.

Jim

On Sun, Aug 30, 2015 at 12:57 PM, aun syed via R-help <r-help at r-project.org>
wrote:

> Dear R administration,
> i have installed R x64 3.2.2 and i am trying to install annotation
> software on it (hgu133a.db and hgu133acdf), but i am getting this error,
> how can i solve this issue, thanks for your help.Regards,Dr. Syed
> AunPost-Doctoral Fellow, China
>
>
>
> * installing *source* package 'hgu133acdf' ...** R** data** preparing
> package for lazy loadingError in loadNamespace(i, c(lib.loc, .libPaths()),
> versionCheck = vI[[i]]) :   there is no package called 'DBI'ERROR: lazy
> loading failed for package 'hgu133acdf'* removing
> 'C:/Users/PC/Documents/R/win-library/3.2/hgu133acdf'
> The downloaded source packages are in
> ?C:\Users\PC\AppData\Local\Temp\RtmpySLSpD\downloaded_packages?Warning
> messages:1: running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL
> -l "C:\Users\PC\Documents\R\win-library\3.2"
> C:\Users\PC\AppData\Local\Temp\RtmpySLSpD/downloaded_packages/hgu133acdf_2.16.0.tar.gz'
> had status 1 2: In install.packages(NULL, .libPaths()[1L], dependencies =
> NA, type = type) :  installation of package ?hgu133acdf? had non-zero exit
> status
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Aug 30 06:57:45 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 29 Aug 2015 21:57:45 -0700
Subject: [R] Seeking solution for loading Source R Code
In-Reply-To: <CA+8X3fXbJKH1pe7vTDmzN9BEmSu9gXF-_b03NDcj76Z7+z8ifQ@mail.gmail.com>
References: <14259538.2774494.1440901033340.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fXbJKH1pe7vTDmzN9BEmSu9gXF-_b03NDcj76Z7+z8ifQ@mail.gmail.com>
Message-ID: <63340555-637E-40D9-8C96-585C13EE3E90@dcn.davis.CA.us>

These files are not part of R (and are not supported here), but Google seems to recognise them... I put "rclimdex.r" in and some hits came up right away.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 29, 2015 9:40:56 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Ramesh,
>This may be completely wrong, but did you transfer the R source code
>files
>from your old computer to your new one? They won't just appear when you
>load R 3.2.1 on a computer.
>
>Jim
>
>
>On Sun, Aug 30, 2015 at 12:17 PM, ramesh shrestha via R-help <
>r-help at r-project.org> wrote:
>
>> Dear Sirs/Madams,
>> I am Ramesh Shrestha, a student of M.Sc. in Environmental Sciences
>from
>> Nepal.  I am using RClimDex version 3.2.1 software in quality
>control,
>> homogeneity test and core Climate Indices calculation of temperature
>and
>> precipitation data for my dissertation related to climate change.
>> Unfortunately, I had to change my laptop after the one in which this
>> software was installed, crashed. I installed the software in my new
>laptop
>> but I am facing some difficulties in trying to load source R Code.
>> I installed this software version 3.2.1 on my new laptop but could
>not
>> locate rclimdex.r and rhtest_gui.r while trying to load them going
>> through: File ? Source R code ? C? Program Files? R ? R-3.2.1 ? bin
>> Attaching herewith are the snapshots of the steps I followed while
>trying
>> to load source r code and rclimdex.r and rhtest_gui.r...
>>
>> Please suggest what I should do.... I tried to run in another
>computer of
>> my friend but the problem is same.... I also tried with older
>versions but
>> the problem remains same. I went through FAQs too but could not get
>> solution. Please help.....  Sincerely yours',
>> Ramesh Shrestha
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From goran.brostrom at umu.se  Sun Aug 30 16:15:33 2015
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sun, 30 Aug 2015 16:15:33 +0200
Subject: [R] using survreg() in survival package with "long" data
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8A3E63A@FHSDB2D11-2.csu.mcmaster.ca>
References: <ACD1644AA6C67E4FBD0C350625508EC8A3E570@FHSDB2D11-2.csu.mcmaster.ca>
	<55E20F06.6000902@umu.se>
	<ACD1644AA6C67E4FBD0C350625508EC8A3E63A@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <55E31005.7060102@umu.se>

On 08/29/2015 11:56 PM, Fox, John wrote:
> Dear G?ran,
>
> Thank you for responding to my query; please see below:
>
>> -----Original Message----- From: R-help
>> [mailto:r-help-bounces at r-project.org] On Behalf Of G?ran Brostr?m
>> Sent: August 29, 2015 3:59 PM To: r-help at r-project.org Subject: Re:
>> [R] using survreg() in survival package with "long" data
>>
>> Dear John,
>>
>> I think you are missing that 'survreg' does not handle left
>> truncated data. With that you should use the 'eha' package, for a
>> PH model the function 'phreg', and for an AFT model the function
>> 'aftreg' (you didn't tell which model you want to fit).
>
> That's odd, in that it's not true in general, since, e.g., survreg()
> can be used to fit the left-censored Tobit regression model, as
> illustrated in this example from ?survreg: tobinfit <-
> survreg(Surv(durable, durable>0, type='left') ~ age + quant,
> data=tobin, dist='gaussian')

Well, it is true that survreg doesn't handle left truncated data. Its 
ability to cope with left censored data does not change that.

> In fact, in my example, the data are right-censored, but in the
> second data set are represented in counting-process form as one-week
> intervals. I imagine that you're right in the sense that survreg()
> can't handle data like this in counting-process form.

Which implies left truncation, at least formally.

> Yet, I've
> reviewed the documentation in the survey package but can't find any
> reference to this -- which is not to say that it's not there, only
> that I don't see it.

Right, it is not explicitly spelled out in the documentation. But this 
has been discussed earlier on R-help. See e.g.
https://stat.ethz.ch/pipermail/r-help/2008-November/178621.html

G?ran

>
>>
>> Your attempt with the 'survreg' function implies that you are
>> satisfied with a Weibull baseline distribution, in which case you
>> could choose either model.
>
> Right, I understand that this is the default. The problem is just a
> small toy example meant to illustrate the error.
>
> Thanks again, John
>
>>
>> G?ran
>>
>>
>> On 08/29/2015 07:06 PM, Fox, John wrote:
>>> Dear list members,
>>>
>>> I'm unable to fit a parametric survival regression using
>>> survreg() in the survival package with data in "counting-process"
>>> ("long") form.
>>>
>>> To illustrate using a scaled-down problem with 10 subjects (with
>>> data placed on the web):
>>>
>>> --------------- snip ------------
>>>> library(survival) RW <-
>>>> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RW.txt") RL
>>>> <-
>>>> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RL.txt")
>>>
>>>> RW # "wide" data
>>> week arrest age 1    20      1  27 2    17      1  18 3    25
>>> 1 19 4    52      0  23 5    52      0  19 6    52      0  24 7
>>> 23 1  25 8    52      0  21 9    52      0  22 10   52      0
>>> 20
>>>
>>>> head(RL, 20) # "long" data, counting-process form
>>> start stop arrest.time age 1.1      0    1           0  27 1.2
>>> 1 2           0  27 1.3      2    3           0  27 1.4      3
>>> 4 0  27 1.5      4    5           0  27 1.6      5    6
>>> 0 27 1.7      6    7           0  27 1.8      7    8           0
>>> 27 1.9      8    9           0  27 1.10     9   10           0
>>> 27 1.11 10   11           0  27 1.12    11   12           0  27
>>> 1.13    12 13           0  27 1.14    13   14           0  27
>>> 1.15    14   15 0  27 1.16    15   16           0  27 1.17    16
>>> 17           0 27 1.18    17   18           0  27 1.19    18   19
>>> 0  27 1.20    19   20           1  27
>>>
>>> --------------- snip ------------
>>>
>>> I have no trouble fitting a Cox model to both the wide and long
>>> forms of the data, obtaining (as should be the case) identical
>>> results:
>>>
>>> --------------- snip ------------
>>>
>>>> coxph(Surv(week, arrest) ~ age, data=RW)  # works
>>> Call: coxph(formula = Surv(week, arrest) ~ age, data = RW)
>>>
>>>
>>> coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073
>>> 0.46 0.64
>>>
>>> Likelihood ratio test=0.21  on 1 df, p=0.643 n= 10, number of
>>> events= 4
>>>> coxph(Surv(start, stop, arrest.time) ~ age,  data=RL) # works,
>>>> same
>>> Call: coxph(formula = Surv(start, stop, arrest.time) ~ age, data
>>> = RL)
>>>
>>>
>>> coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073
>>> 0.46 0.64
>>>
>>> Likelihood ratio test=0.21  on 1 df, p=0.643 n= 397, number of
>>> events= 4
>>>
>>> --------------- snip ------------
>>>
>>> But when I try to fit a parametric survival regression with
>>> survreg(), I get an error with the long form of the data:
>>>
>>> --------------- snip ------------
>>>
>>>> survreg(Surv(week, arrest) ~ age, data=RW) # works
>>> Call: survreg(formula = Surv(week, arrest) ~ age, data = RW)
>>>
>>> Coefficients: (Intercept)         age 6.35386771 -0.08982624
>>>
>>> Scale= 0.7363196
>>>
>>> Loglik(model)= -22.1   Loglik(intercept only)= -22.2 Chisq= 0.3
>>> on 1 degrees of freedom, p= 0.58 n= 10
>>>
>>>> survreg(Surv(start, stop, arrest.time) ~ age,  data=RL) #
>>>> fails
>>> Error in survreg(Surv(start, stop, arrest.time) ~ age, data = RL)
>>> : Invalid survival type
>>>
>>> --------------- snip ------------
>>>
>>> I expect that there's something about survreg() that I'm missing.
>>> I first noted this problem quite some time ago but didn't look
>>> into it carefully because I didn't really need to use survreg().
>>>
>>> Any help would be appreciated.
>>>
>>> Thanks, John ----------------------------- John Fox, Professor
>>> McMaster University Hamilton, Ontario Canada L8S 4M4 Web:
>>> socserv.mcmaster.ca/jfox
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>> the posting guide http://www.R-project.org/posting-guide.html and
>>> provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and
>> provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sun Aug 30 17:47:10 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 30 Aug 2015 15:47:10 +0000
Subject: [R] using survreg() in survival package with "long" data
In-Reply-To: <55E31005.7060102@umu.se>
References: <ACD1644AA6C67E4FBD0C350625508EC8A3E570@FHSDB2D11-2.csu.mcmaster.ca>
	<55E20F06.6000902@umu.se>
	<ACD1644AA6C67E4FBD0C350625508EC8A3E63A@FHSDB2D11-2.csu.mcmaster.ca>,
	<55E31005.7060102@umu.se>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8A3E79F@FHSDB2D11-2.csu.mcmaster.ca>

Dear G?ran,

Yes, you're right -- I didn't read your message carefully enough and was confusing left-censoring with left-truncation.

Thanks for the correction,
 John
________________________________________
From: G?ran Brostr?m [goran.brostrom at umu.se]
Sent: August 30, 2015 10:15 AM
To: Fox, John
Cc: r-help at r-project.org
Subject: Re: [R] using survreg() in survival package with "long" data

On 08/29/2015 11:56 PM, Fox, John wrote:
> Dear G?ran,
>
> Thank you for responding to my query; please see below:
>
>> -----Original Message----- From: R-help
>> [mailto:r-help-bounces at r-project.org] On Behalf Of G?ran Brostr?m
>> Sent: August 29, 2015 3:59 PM To: r-help at r-project.org Subject: Re:
>> [R] using survreg() in survival package with "long" data
>>
>> Dear John,
>>
>> I think you are missing that 'survreg' does not handle left
>> truncated data. With that you should use the 'eha' package, for a
>> PH model the function 'phreg', and for an AFT model the function
>> 'aftreg' (you didn't tell which model you want to fit).
>
> That's odd, in that it's not true in general, since, e.g., survreg()
> can be used to fit the left-censored Tobit regression model, as
> illustrated in this example from ?survreg: tobinfit <-
> survreg(Surv(durable, durable>0, type='left') ~ age + quant,
> data=tobin, dist='gaussian')

Well, it is true that survreg doesn't handle left truncated data. Its
ability to cope with left censored data does not change that.

> In fact, in my example, the data are right-censored, but in the
> second data set are represented in counting-process form as one-week
> intervals. I imagine that you're right in the sense that survreg()
> can't handle data like this in counting-process form.

Which implies left truncation, at least formally.

> Yet, I've
> reviewed the documentation in the survey package but can't find any
> reference to this -- which is not to say that it's not there, only
> that I don't see it.

Right, it is not explicitly spelled out in the documentation. But this
has been discussed earlier on R-help. See e.g.
https://stat.ethz.ch/pipermail/r-help/2008-November/178621.html

G?ran

>
>>
>> Your attempt with the 'survreg' function implies that you are
>> satisfied with a Weibull baseline distribution, in which case you
>> could choose either model.
>
> Right, I understand that this is the default. The problem is just a
> small toy example meant to illustrate the error.
>
> Thanks again, John
>
>>
>> G?ran
>>
>>
>> On 08/29/2015 07:06 PM, Fox, John wrote:
>>> Dear list members,
>>>
>>> I'm unable to fit a parametric survival regression using
>>> survreg() in the survival package with data in "counting-process"
>>> ("long") form.
>>>
>>> To illustrate using a scaled-down problem with 10 subjects (with
>>> data placed on the web):
>>>
>>> --------------- snip ------------
>>>> library(survival) RW <-
>>>> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RW.txt") RL
>>>> <-
>>>> read.table("http://socserv.mcmaster.ca/jfox/.Pickup/RL.txt")
>>>
>>>> RW # "wide" data
>>> week arrest age 1    20      1  27 2    17      1  18 3    25
>>> 1 19 4    52      0  23 5    52      0  19 6    52      0  24 7
>>> 23 1  25 8    52      0  21 9    52      0  22 10   52      0
>>> 20
>>>
>>>> head(RL, 20) # "long" data, counting-process form
>>> start stop arrest.time age 1.1      0    1           0  27 1.2
>>> 1 2           0  27 1.3      2    3           0  27 1.4      3
>>> 4 0  27 1.5      4    5           0  27 1.6      5    6
>>> 0 27 1.7      6    7           0  27 1.8      7    8           0
>>> 27 1.9      8    9           0  27 1.10     9   10           0
>>> 27 1.11 10   11           0  27 1.12    11   12           0  27
>>> 1.13    12 13           0  27 1.14    13   14           0  27
>>> 1.15    14   15 0  27 1.16    15   16           0  27 1.17    16
>>> 17           0 27 1.18    17   18           0  27 1.19    18   19
>>> 0  27 1.20    19   20           1  27
>>>
>>> --------------- snip ------------
>>>
>>> I have no trouble fitting a Cox model to both the wide and long
>>> forms of the data, obtaining (as should be the case) identical
>>> results:
>>>
>>> --------------- snip ------------
>>>
>>>> coxph(Surv(week, arrest) ~ age, data=RW)  # works
>>> Call: coxph(formula = Surv(week, arrest) ~ age, data = RW)
>>>
>>>
>>> coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073
>>> 0.46 0.64
>>>
>>> Likelihood ratio test=0.21  on 1 df, p=0.643 n= 10, number of
>>> events= 4
>>>> coxph(Surv(start, stop, arrest.time) ~ age,  data=RL) # works,
>>>> same
>>> Call: coxph(formula = Surv(start, stop, arrest.time) ~ age, data
>>> = RL)
>>>
>>>
>>> coef exp(coef) se(coef)    z    p age 0.0963    1.1011   0.2073
>>> 0.46 0.64
>>>
>>> Likelihood ratio test=0.21  on 1 df, p=0.643 n= 397, number of
>>> events= 4
>>>
>>> --------------- snip ------------
>>>
>>> But when I try to fit a parametric survival regression with
>>> survreg(), I get an error with the long form of the data:
>>>
>>> --------------- snip ------------
>>>
>>>> survreg(Surv(week, arrest) ~ age, data=RW) # works
>>> Call: survreg(formula = Surv(week, arrest) ~ age, data = RW)
>>>
>>> Coefficients: (Intercept)         age 6.35386771 -0.08982624
>>>
>>> Scale= 0.7363196
>>>
>>> Loglik(model)= -22.1   Loglik(intercept only)= -22.2 Chisq= 0.3
>>> on 1 degrees of freedom, p= 0.58 n= 10
>>>
>>>> survreg(Surv(start, stop, arrest.time) ~ age,  data=RL) #
>>>> fails
>>> Error in survreg(Surv(start, stop, arrest.time) ~ age, data = RL)
>>> : Invalid survival type
>>>
>>> --------------- snip ------------
>>>
>>> I expect that there's something about survreg() that I'm missing.
>>> I first noted this problem quite some time ago but didn't look
>>> into it carefully because I didn't really need to use survreg().
>>>
>>> Any help would be appreciated.
>>>
>>> Thanks, John ----------------------------- John Fox, Professor
>>> McMaster University Hamilton, Ontario Canada L8S 4M4 Web:
>>> socserv.mcmaster.ca/jfox
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>> the posting guide http://www.R-project.org/posting-guide.html and
>>> provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and
>> provide commented, minimal, self-contained, reproducible code.


From brettpaul16 at gmail.com  Sun Aug 30 13:54:09 2015
From: brettpaul16 at gmail.com (paul brett)
Date: Sun, 30 Aug 2015 13:54:09 +0200
Subject: [R] Fisher's Test 5x4 table
In-Reply-To: <Pine.SOC.4.64.1508281537530.27473@solcom.hrz.uni-giessen.de>
References: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
	<Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91oc9wa=LaAc=Sk3r2c4OS-ZSMbnmWd25eacXtWODvUbFw@mail.gmail.com>
	<Pine.SOC.4.64.1508281537530.27473@solcom.hrz.uni-giessen.de>
Message-ID: <CAE1X91qFY6qF9bf5vKXAqGefpH18Qs=W1nUgVDD=oZMyCi=U-A@mail.gmail.com>

Hi Gerrit,
             I tried both of your suggestions and got the exact same thing.
Fisher's Exact Test for Count Data with simulated p-value (based on 1e+05
replicates)

data:  Trapz
p-value = 1e-05
alternative hypothesis: two.sided

I put in a few changes myself based on the details section on what should
be used for a larger than 2x2 table, getting the exact same thing as
before. I have removed or = 1, conf.int = TRUE. Added y = NULL, control =
list(30) and changed simulate.p.value = TRUE.
> fisher.test( Trapz, y = NULL, workspace = 200000, hybrid = TRUE,control =
list(30), simulate.p.value = TRUE, B =1e5)
isher's Exact Test for Count Data with simulated p-value (based on 1e+05
replicates)

data:  Trapz
p-value = 1e-05
alternative hypothesis: two.sided

> fisher.test( Trapz, y = NULL, workspace = 200000, hybrid = TRUE,control =
list(30), simulate.p.value = TRUE, B =1e7)

Fisher's Exact Test for Count Data with simulated p-value (based on 1e+07
replicates)

data:  Trapz
p-value = 1e-07
alternative hypothesis: two.sided


Dispite these chages, the changes equations is not giving me the results
for the calculations. The changes I have made seem to satisfy what is in
the details section on R, and I don't have the issue of workspace in R.
What I do to get the results of the fisher test?
Is there something simple that I am missing?

Regards,
             Paul

On Fri, Aug 28, 2015 at 3:52 PM, Gerrit Eichner <
Gerrit.Eichner at math.uni-giessen.de> wrote:

> Paul,
>
> as the error messages of your first three attempts (see below) tell you -
> in an admittedly rather cryptic way - your table or its sample size,
> respectively, are too large, so that either the "largest (hash table) key"
> is too large, or your (i.e., R's) workspace is too small, or your
> hardware/os cannot allocate enough memory to calculate the p-value of
> Fisher Exact Test exactly by means of the implemented algorithm.
>
> One way out of this is to approximate the exact p-value through
> simulation, but apparently there occurred a typo in your (last) attempt to
> do that (Error: unexpected '>' in ">").
>
>
> So, for me the following works (and it should also for you) and gives the
> shown output (after a very short while):
>
> Trapz <- as.matrix( read.table( "w.txt", head = T, row.names = "Traps"))
>>
>
> set.seed( 20150828)   # For the sake of reproducibility.
>> fisher.test( Trapz, simulate.p.value = TRUE,
>>
> +             B = 1e5)
>
>    Fisher's Exact Test for Count Data with simulated p-value (based on
>    1e+05 replicates)
>
> data:  Trapz
> p-value = 1e-05
> alternative hypothesis: two.sided
>
>
>
> Or for a higher value for B if you are patient enough (with a computing
> time of several seconds) :
>
> set.seed( 20150828)
>> fisher.test( Trapz, simulate.p.value=TRUE, B = 1e7)
>>
>
>    Fisher's Exact Test for Count Data with simulated p-value (based on
>    1e+07 replicates)
>
> data:  Trapz
> p-value = 1e-07
> alternative hypothesis: two.sided
>
>
>  Hth  --  Gerrit
>
> (BTW, you don't have to specify arguments (in function calls) whose
> default values you don't want to change.)
>
>
>
>
> On Fri, 28 Aug 2015, paul brett wrote:
>
> Hi Gerrit,
>>             I spotted that, it was a mistake on my own part, it should
>> read 1.trap.2.barrier. I have corrected it on the file attached.
>>
>> So I have done these so far:
>> > fisher.test(Trapz, workspace = 200000, hybrid = FALSE, control = list(),
>> or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>> 0.95,simulate.p.value = FALSE, B = 2000)
>> Error in fisher.test(Trapz, workspace = 2e+05, hybrid = FALSE, control =
>> list(),  :
>>  FEXACT error 501.
>> The hash table key cannot be computed because the largest key
>> is larger than the largest representable int.
>> The algorithm cannot proceed.
>> Reduce the workspace size or use another algorithm.
>>
>> fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control = list(), or
>>>
>> = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>> 0.95,simulate.p.value = FALSE, B = 2000)
>> Error in fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control =
>> list(),  :
>>  FEXACT error 40.
>> Out of workspace.
>>
>>> fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or
>>>
>> = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>> 0.95,simulate.p.value = FALSE, B = 2000)
>> Error in fisher.test(Trapz, workspace = 1e+08, hybrid = FALSE, control =
>> list(),  :
>>  FEXACT error 501.
>> The hash table key cannot be computed because the largest key
>> is larger than the largest representable int.
>> The algorithm cannot proceed.
>> Reduce the workspace size or use another algorithm.
>>
>>> fisher.test(Trapz, workspace = 2000000000, hybrid = FALSE, control =
>>>
>> list(), or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>> 0.95,simulate.p.value = FALSE, B = 2000)
>> Error: cannot allocate vector of size 7.5 Gb
>> In addition: Warning messages:
>> 1: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>> list(),  :
>>  Reached total allocation of 6027Mb: see help(memory.size)
>> 2: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>> list(),  :
>>  Reached total allocation of 6027Mb: see help(memory.size)
>> 3: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>> list(),  :
>>  Reached total allocation of 6027Mb: see help(memory.size)
>> 4: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>> list(),  :
>>  Reached total allocation of 6027Mb: see help(memory.size)
>>
>> fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or =
>> 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>> 0.95,simulate.p.value = TRUE, B = 1e5)
>> Error: unexpected '>' in ">"
>>
>> So the issue could be perhaps that R cannot compute my sample as the
>> workspace needed is too big? Is there a way around this? I think I have
>> everything set out correctly.
>> Is my only other alternative is to do a 2x2 fisher test for each of the
>> variables?
>>
>> I attach on the pdf the Minitab result for the Chi squared test as proof
>> (I
>> know that getting very low p values are highly unlikely but sometimes it
>> happens). Seeing is believing i suppose!
>>
>> Regards,
>>             Paul
>>
>>
>>
>> On Fri, Aug 28, 2015 at 8:56 AM, Gerrit Eichner <
>> Gerrit.Eichner at math.uni-giessen.de> wrote:
>>
>> Dear Paul,
>>>
>>> quoting the email-footer: "PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide commented,
>>> minimal, self-contained, reproducible code."
>>>
>>> So, what exactly did you try and what was the actual problem/error
>>> message?
>>>
>>> Besides that, have you noted that two of you data rows have the same
>>> name?
>>>
>>>
>>> Have you read the online help page of fisher.test():
>>>
>>>  ?fisher.test
>>>
>>>
>>> Have you tried anything like the following?
>>>
>>> W <- as.matrix( read.table( "w.txt", head = T)[-1])
>>>
>>> fisher.test( W, workspace = 1e8)
>>>    # For workspace look at the help page, but it presumably
>>>    # won't work because of your sample size.
>>>
>>>
>>> set.seed( 20150828) # for reproducibility
>>> fisher.test( W, simulate.p.value = TRUE, B = 1e5)
>>>    # For B look at the help page.
>>>
>>>
>>> Finally: Did Minitab really report "p > 0.001"? ;-)
>>>
>>>  Hth  --  Gerrit
>>>
>>>
>>> Dear all,
>>>
>>>>            I am trying to do a fishers test on a 5x4 table on R
>>>> statistics. I have already done a chi squared test using Minitab on this
>>>> data set, getting a result of (1, N = 165.953, DF 12, p>0.001), yet
>>>> using
>>>> these results (even though they are excellent) may not be suitable for
>>>> publication. I have tried numerous other statistical packages in the
>>>> hope
>>>> of doing this test, yet each one has just the 2x2 table.
>>>>            I am struggling to edit the template fishers test on R to fit
>>>> my table (as according to the R book it is possible, yet i cannot get it
>>>> to
>>>> work). The template given on the R documentation and R book is for a 2x2
>>>> fisher test. What do i need to change to get this to work? I have
>>>> attached
>>>> the data with the email so one can see what i am on about. Or do i have
>>>> to
>>>> write my own new code to compute this.
>>>>
>>>>             Yours Sincerely,
>>>>                                     Paul Brett
>>>>
>>>>
>>>>

	[[alternative HTML version deleted]]


From sha1one at yahoo.com  Sun Aug 30 17:41:39 2015
From: sha1one at yahoo.com (Shant Ch)
Date: Sun, 30 Aug 2015 15:41:39 +0000 (UTC)
Subject: [R] Fw:  Multiple Integrals
In-Reply-To: <76D2748F-92D1-40E3-8C76-FE237A05B7BC@comcast.net>
References: <76D2748F-92D1-40E3-8C76-FE237A05B7BC@comcast.net>
Message-ID: <137773544.2879665.1440949299520.JavaMail.yahoo@mail.yahoo.com>

Thank you very much to all for all your responses.

@Dr. Winsemius, E[f(X)] >=f(E(X)) if f is convex. Now we know |x| is convex function, so clearly in this scenario if we compute the expectation of the ((X1+X2+X3)/3-X4) and then take the absolute, then, we will get a lower bound of the expectation I want to find. 

      On Saturday, August 29, 2015 7:24 PM, David Winsemius <dwinsemius at comcast.net> wrote:
   

 
On Aug 29, 2015, at 11:35 AM, Shant Ch via R-help wrote:

> Hello Dr. Berry,
> 
> I know the theoretical side but note we are not talking about expectation of sums rather expectation of ABSOLUTE value of the function (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4|? , I don't think this can be handled for log normal distribution by integrals by hand.
> 

To Shnant Ch;

I admit to puzzlement (being a humble country doctor). Can you explain why there should be a difference between the absolute value of an expectation for a sum of values from a function, in this case dlnorm,? that is positive definite versus an expectation simply of the sum of such values?

-- 

David Winsemius
Alameda, CA, USA


   
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Aug 31 00:48:46 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 30 Aug 2015 15:48:46 -0700
Subject: [R] Fw:  Multiple Integrals
In-Reply-To: <137773544.2879665.1440949299520.JavaMail.yahoo@mail.yahoo.com>
References: <76D2748F-92D1-40E3-8C76-FE237A05B7BC@comcast.net>
	<137773544.2879665.1440949299520.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <614C46E5-2BB7-403F-916A-B7CF2B9E49A8@comcast.net>


On Aug 30, 2015, at 8:41 AM, Shant Ch via R-help wrote:

> Thank you very much to all for all your responses.
> 
> @Dr. Winsemius, E[f(X)] >=f(E(X)) if f is convex. Now we know |x| is convex function, so clearly in this scenario if we compute the expectation of the ((X1+X2+X3)/3-X4) and then take the absolute, then, we will get a lower bound of the expectation I want to find. 
> 

I understood the error in my thinking when Jeff Newmiller pointed out the minus sign that I had missed.

Thanks;
David.


>      On Saturday, August 29, 2015 7:24 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> On Aug 29, 2015, at 11:35 AM, Shant Ch via R-help wrote:
> 
>> Hello Dr. Berry,
>> 
>> I know the theoretical side but note we are not talking about expectation of sums rather expectation of ABSOLUTE value of the function (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4|  , I don't think this can be handled for log normal distribution by integrals by hand.
>> 
> 
> To Shnant Ch;
> 
> I admit to puzzlement (being a humble country doctor). Can you explain why there should be a difference between the absolute value of an expectation for a sum of values from a function, in this case dlnorm,  that is positive definite versus an expectation simply of the sum of such values?
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Aug 31 04:17:06 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 30 Aug 2015 19:17:06 -0700
Subject: [R] Multiple Integrals
In-Reply-To: <137773544.2879665.1440949299520.JavaMail.yahoo@mail.yahoo.com>
References: <76D2748F-92D1-40E3-8C76-FE237A05B7BC@comcast.net>
	<137773544.2879665.1440949299520.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5F866862-222A-48E7-93D6-4BCD055E9956@comcast.net>


On Aug 30, 2015, at 8:41 AM, Shant Ch via R-help wrote:

> Thank you very much to all for all your responses.
> 
> @Dr. Winsemius, E[f(X)] >=f(E(X)) if f is convex. Now we know |x| is convex function, so clearly in this scenario if we compute the expectation of the ((X1+X2+X3)/3-X4) and then take the absolute, then, we will get a lower bound of the expectation I want to find. 
> 
>      On Saturday, August 29, 2015 7:24 PM, David Winsemius <dwinsemius at comcast.net> wrote:

Using the adaptIntegrate function in package:cubature I seem to be getting convergence near  5.359359 as I extend the limits of integration. I don't think that `adaptIntegrate` can handle infinite range. Either than or the NaN it is returning is a signal of pathology that I don't understand.

> require(cubature)
> fx<-function(x){
+         dlnorm(x,meanlog=2.185,sdlog=0.562)
+       }
> I.4d <- function(x) {
+   x1 = x[1]; y1 <- x[3]
+   x2 = x[2]; y2 <- x[4];   abs(y1/3+y2/3+x1/3-x2)*fx(y1)*fx(y2)*fx(x1)*fx(x2)}
> 
> adaptIntegrate(I.4d, rep(0, 4), rep(1000, 4), maxEval=1000000)
$integral
[1] 5.359082

$error
[1] 0.001922979

$functionEvaluations
[1] 1000065

$returnCode
[1] 0

> I.4d <- function(x) {
+   x1 = x[1]; y1 <- x[3]
+   x2 = x[2]; y2 <- x[4];   abs(y1/3+y2/3+x1/3-x2)*fx(y1)*fx(y2)*fx(x1)*fx(x2)}
> 
> adaptIntegrate(I.4d, rep(0, 4), rep(100, 4), maxEval=1000000)
$integral
[1] 5.357679

$error
[1] 0.001820893

$functionEvaluations
[1] 1000065

$returnCode
[1] 0

> I.4d <- function(x) {
+   x1 = x[1]; y1 <- x[3]
+   x2 = x[2]; y2 <- x[4];   abs(y1/3+y2/3+x1/3-x2)*fx(y1)*fx(y2)*fx(x1)*fx(x2)}
> 
> adaptIntegrate(I.4d, rep(0, 4), rep(10000, 4), maxEval=1000000)
$integral
[1] 5.359359

$error
[1] 0.001871926

$functionEvaluations
[1] 1000065

$returnCode
[1] 0


Best;
David.

> 
> 
> 
> On Aug 29, 2015, at 11:35 AM, Shant Ch via R-help wrote:
> 
>> Hello Dr. Berry,
>> 
>> I know the theoretical side but note we are not talking about expectation of sums rather expectation of ABSOLUTE value of the function (X1/3+X2/3+X3/3-X4), i.e. E|X1/3+X2/3+X3/3-X4|  , I don't think this can be handled for log normal distribution by integrals by hand.
>> 
> 
> To Shnant Ch;
> 
> I admit to puzzlement (being a humble country doctor). Can you explain why there should be a difference between the absolute value of an expectation for a sum of values from a function, in this case dlnorm,  that is positive definite versus an expectation simply of the sum of such values?
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mathewanalytics at gmail.com  Mon Aug 31 02:07:16 2015
From: mathewanalytics at gmail.com (Abraham Mathew)
Date: Sun, 30 Aug 2015 19:07:16 -0500
Subject: [R] knitr error when using knit2wp: "need a login and password"
Message-ID: <CABbYstd26tCkL3bYR7poF16Av+-7iWCgZtiO-GwQ_a0vve3gOQ@mail.gmail.com>

I'm using the knitr package to post an .Rmd file to wordpress. First time
I'm working this type of project and am having the following error/issue.
Can anyone help identify the issue. Have done a number of Google searches
but haven't seem similar issues. Also tried to use the newPost function for
this task but that was unfruitful.

if (!require('RWordPress'))
  install.packages('RWordPress', repos = 'http://www.omegahat.org/R',
type = 'source')
library(RWordPress)
options(WordPressLogin = c(username = "*****"),
        WordPressURL = "https://mathewanalytics.com/xmlrpc.php")

library(knitr)
knit2wp("Logistic_Regression_Document.Rmd",
        title = "Evaluation Logistic Regression in R",
        shortcode=TRUE, publish=FALSE )


List of 4
 $ results: chr "hide"
 $ message: logi FALSE
 $ warning: logi FALSE
 $ eval   : logi FALSE

  |.................................................................| 100%
  ordinary text without R code


output file: Logistic_Regression_Document.md

Error in getOption("WordpressLogin", stop("need a login and password")) :
  need a login and password
In addition: Warning messages:1: In Ops.factor(1, obs) : '-' not
meaningful for factors2: In Ops.factor(1, obs) : '-' not meaningful
for factors3: In Ops.factor(1, y) : '-' not meaningful for factors





-- 


*Abraham MathewData Ninja and Statistical Modeler*



*Minneapolis, MN720-648-0108 at abmathewksAnalytics_Blog
<https://mathewanalytics.wordpress.com/>*

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Aug 31 08:08:45 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 31 Aug 2015 06:08:45 +0000
Subject: [R] Frequency count of terms only in a given column in R
In-Reply-To: <55E07B39.1080803@dewey.myzen.co.uk>
References: <CANnXLTDiEN+yKPQ-k5-fyGVYpEYGAEoAJnHcBRFB7Fgm53OdOA@mail.gmail.com>
	<CAM_vjuk3AVX9LA=cRmHO93SYTCoGpCFmh9oQv=dMyN+1Y9NpFA@mail.gmail.com>
	<55E07B39.1080803@dewey.myzen.co.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C3D7B2@SRVEXCHMBX.precheza.cz>

Hi

and if you manage to read the file to R correctly as two column data frame, you can achieve your task by:

table(yourdata[,1])

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Dewey
> Sent: Friday, August 28, 2015 5:16 PM
> To: Sarah Goslee; agrima seth
> Cc: r-help
> Subject: Re: [R] Frequency count of terms only in a given column in R
>
> Dear Agrima
>
> As well as Sarah's seven possibilities an eighth occurs to me: you have
> not yet read it into R in the first place. If that is the case you may
> be able to use read.table to get it into a data frame with columns
> corresponding to your words.
> ?read.table may be your friend here.
>
> On 28/08/2015 15:42, Sarah Goslee wrote:
> > Hi,
> >
> > On Fri, Aug 28, 2015 at 7:49 AM, agrima seth <sethagrima at gmail.com>
> wrote:
> >> i have a text file with data of the given format:
> >>
> >> white snow
> >> lived snow
> >> in snow
> >> lived place
> >> in place
> >> a place
> >> called place
> >> as place
> >
> > That doesn't specify the format. I can think of at least seven things
> > that could be:
> > a character vector
> > a two-column matrix
> > a one-column matrix
> > a two-column data frame, with or without values correctly specified
> as
> > character a one-column data frame, with or without values correctly
> > specified as character
> >
> > The correct answer depends on what the format actually is; you need
> to
> > use dput() or some other unambiguous way of providing sample data.
> >
> > Here are some suggestions for creating a good reproducible example:
> > http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> repro
> > ducible-example
> >
> > Some combination of strsplit() and table(), possibly with apply(),
> > will be the answer, though.
> >
> > Sarah
> >
> >> here i have to find the frequency of the terms only in the first
> >> column
> >> (i.e.)
> >> white - 1
> >> lived- 2
> >> in -2
> >> a-1
> >> called - 1
> >> as -1
> >>
> >> Could you please guide me how to do the above in R.
> >>
> >>          [[alternative HTML version deleted]]
> > and please don't post in HTML, as it makes figuring out what you
> meant
> > even more difficult.
> >
> > Sarah
> >
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Mon Aug 31 09:00:03 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 31 Aug 2015 09:00:03 +0200
Subject: [R] Fisher's Test 5x4 table
In-Reply-To: <CAE1X91qFY6qF9bf5vKXAqGefpH18Qs=W1nUgVDD=oZMyCi=U-A@mail.gmail.com>
References: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
	<Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91oc9wa=LaAc=Sk3r2c4OS-ZSMbnmWd25eacXtWODvUbFw@mail.gmail.com>
	<Pine.SOC.4.64.1508281537530.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91qFY6qF9bf5vKXAqGefpH18Qs=W1nUgVDD=oZMyCi=U-A@mail.gmail.com>
Message-ID: <0E6A7651-7A89-4472-9BAA-44A441E18E79@gmail.com>


> On 30 Aug 2015, at 13:54 , paul brett <brettpaul16 at gmail.com> wrote:
> 
> Fisher's Exact Test for Count Data with simulated p-value (based on 1e+07
> replicates)
> 
> data:  Trapz
> p-value = 1e-07
> alternative hypothesis: two.sided
> 
> 
> Dispite these chages, the changes equations is not giving me the results
> for the calculations. The changes I have made seem to satisfy what is in
> the details section on R, and I don't have the issue of workspace in R.
> What I do to get the results of the fisher test?
> Is there something simple that I am missing?

The theory?

There is nothing more to Fisher's test than the calculation of the probability of obtaining a table as or less (im-)probable as the one observed. This is the p-value. You have done 10 million simulations and not found a single table that is less likely than the one observed. Hence, the p-value is 1/10 000 001 = ca. 1e-7, counting in the observed table. 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Gerrit.Eichner at math.uni-giessen.de  Mon Aug 31 09:28:49 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Mon, 31 Aug 2015 09:28:49 +0200 (MEST)
Subject: [R] Fisher's Test 5x4 table
In-Reply-To: <CAE1X91qFY6qF9bf5vKXAqGefpH18Qs=W1nUgVDD=oZMyCi=U-A@mail.gmail.com>
References: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
	<Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91oc9wa=LaAc=Sk3r2c4OS-ZSMbnmWd25eacXtWODvUbFw@mail.gmail.com>
	<Pine.SOC.4.64.1508281537530.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91qFY6qF9bf5vKXAqGefpH18Qs=W1nUgVDD=oZMyCi=U-A@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1508310913120.4275@solcom.hrz.uni-giessen.de>

Paul,

in addition to Peter's suggestion about the missing of theory you are also 
completely missing to explain what you mean by "[it] is not giving me the 
results for the calculations" or "[how] to get the results of the fisher 
test". They are there in the output of R's fisher.test() (if you have an 
idea about the theory).

And again:

> fisher.test( Trapz, simulate.p.value = TRUE, B = 1e5)

specifies enough arguments in the case of simulating to approximate the 
p-value since workspace (quoting from the help page) is "Only used for 
***non-simulated*** p-values [of] larger than 2 by 2 tables." (Similarly, 
control and hybrid are not needed either here.)

  Regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
---------------------------------------------------------------------


On Sun, 30 Aug 2015, paul brett wrote:

> Hi Gerrit,
>             I tried both of your suggestions and got the exact same thing.
> Fisher's Exact Test for Count Data with simulated p-value (based on 1e+05
> replicates)
>
> data:  Trapz
> p-value = 1e-05
> alternative hypothesis: two.sided
>
> I put in a few changes myself based on the details section on what should
> be used for a larger than 2x2 table, getting the exact same thing as
> before. I have removed or = 1, conf.int = TRUE. Added y = NULL, control =
> list(30) and changed simulate.p.value = TRUE.
>> fisher.test( Trapz, y = NULL, workspace = 200000, hybrid = TRUE,control =
> list(30), simulate.p.value = TRUE, B =1e5)
> isher's Exact Test for Count Data with simulated p-value (based on 1e+05
> replicates)
>
> data:  Trapz
> p-value = 1e-05
> alternative hypothesis: two.sided
>
>> fisher.test( Trapz, y = NULL, workspace = 200000, hybrid = TRUE,control =
> list(30), simulate.p.value = TRUE, B =1e7)
>
> Fisher's Exact Test for Count Data with simulated p-value (based on 1e+07
> replicates)
>
> data:  Trapz
> p-value = 1e-07
> alternative hypothesis: two.sided
>
>
> Dispite these chages, the changes equations is not giving me the results
> for the calculations. The changes I have made seem to satisfy what is in
> the details section on R, and I don't have the issue of workspace in R.
> What I do to get the results of the fisher test?
> Is there something simple that I am missing?
>
> Regards,
>             Paul
>
> On Fri, Aug 28, 2015 at 3:52 PM, Gerrit Eichner <
> Gerrit.Eichner at math.uni-giessen.de> wrote:
>
>> Paul,
>>
>> as the error messages of your first three attempts (see below) tell you -
>> in an admittedly rather cryptic way - your table or its sample size,
>> respectively, are too large, so that either the "largest (hash table) key"
>> is too large, or your (i.e., R's) workspace is too small, or your
>> hardware/os cannot allocate enough memory to calculate the p-value of
>> Fisher Exact Test exactly by means of the implemented algorithm.
>>
>> One way out of this is to approximate the exact p-value through
>> simulation, but apparently there occurred a typo in your (last) attempt to
>> do that (Error: unexpected '>' in ">").
>>
>>
>> So, for me the following works (and it should also for you) and gives the
>> shown output (after a very short while):
>>
>> Trapz <- as.matrix( read.table( "w.txt", head = T, row.names = "Traps"))
>>>
>>
>> set.seed( 20150828)   # For the sake of reproducibility.
>>> fisher.test( Trapz, simulate.p.value = TRUE,
>>>
>> +             B = 1e5)
>>
>>    Fisher's Exact Test for Count Data with simulated p-value (based on
>>    1e+05 replicates)
>>
>> data:  Trapz
>> p-value = 1e-05
>> alternative hypothesis: two.sided
>>
>>
>>
>> Or for a higher value for B if you are patient enough (with a computing
>> time of several seconds) :
>>
>> set.seed( 20150828)
>>> fisher.test( Trapz, simulate.p.value=TRUE, B = 1e7)
>>>
>>
>>    Fisher's Exact Test for Count Data with simulated p-value (based on
>>    1e+07 replicates)
>>
>> data:  Trapz
>> p-value = 1e-07
>> alternative hypothesis: two.sided
>>
>>
>>  Hth  --  Gerrit
>>
>> (BTW, you don't have to specify arguments (in function calls) whose
>> default values you don't want to change.)
>>
>>
>>
>>
>> On Fri, 28 Aug 2015, paul brett wrote:
>>
>> Hi Gerrit,
>>>             I spotted that, it was a mistake on my own part, it should
>>> read 1.trap.2.barrier. I have corrected it on the file attached.
>>>
>>> So I have done these so far:
>>>> fisher.test(Trapz, workspace = 200000, hybrid = FALSE, control = list(),
>>> or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>>> 0.95,simulate.p.value = FALSE, B = 2000)
>>> Error in fisher.test(Trapz, workspace = 2e+05, hybrid = FALSE, control =
>>> list(),  :
>>>  FEXACT error 501.
>>> The hash table key cannot be computed because the largest key
>>> is larger than the largest representable int.
>>> The algorithm cannot proceed.
>>> Reduce the workspace size or use another algorithm.
>>>
>>> fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control = list(), or
>>>>
>>> = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>>> 0.95,simulate.p.value = FALSE, B = 2000)
>>> Error in fisher.test(Trapz, workspace = 2000, hybrid = FALSE, control =
>>> list(),  :
>>>  FEXACT error 40.
>>> Out of workspace.
>>>
>>>> fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or
>>>>
>>> = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>>> 0.95,simulate.p.value = FALSE, B = 2000)
>>> Error in fisher.test(Trapz, workspace = 1e+08, hybrid = FALSE, control =
>>> list(),  :
>>>  FEXACT error 501.
>>> The hash table key cannot be computed because the largest key
>>> is larger than the largest representable int.
>>> The algorithm cannot proceed.
>>> Reduce the workspace size or use another algorithm.
>>>
>>>> fisher.test(Trapz, workspace = 2000000000, hybrid = FALSE, control =
>>>>
>>> list(), or = 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>>> 0.95,simulate.p.value = FALSE, B = 2000)
>>> Error: cannot allocate vector of size 7.5 Gb
>>> In addition: Warning messages:
>>> 1: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>>> list(),  :
>>>  Reached total allocation of 6027Mb: see help(memory.size)
>>> 2: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>>> list(),  :
>>>  Reached total allocation of 6027Mb: see help(memory.size)
>>> 3: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>>> list(),  :
>>>  Reached total allocation of 6027Mb: see help(memory.size)
>>> 4: In fisher.test(Trapz, workspace = 2e+09, hybrid = FALSE, control =
>>> list(),  :
>>>  Reached total allocation of 6027Mb: see help(memory.size)
>>>
>>> fisher.test(Trapz, workspace = 1e8, hybrid = FALSE, control = list(), or =
>>> 1, alternative = "two.sided", conf.int = TRUE, conf.level =
>>> 0.95,simulate.p.value = TRUE, B = 1e5)
>>> Error: unexpected '>' in ">"
>>>
>>> So the issue could be perhaps that R cannot compute my sample as the
>>> workspace needed is too big? Is there a way around this? I think I have
>>> everything set out correctly.
>>> Is my only other alternative is to do a 2x2 fisher test for each of the
>>> variables?
>>>
>>> I attach on the pdf the Minitab result for the Chi squared test as proof
>>> (I
>>> know that getting very low p values are highly unlikely but sometimes it
>>> happens). Seeing is believing i suppose!
>>>
>>> Regards,
>>>             Paul
>>>
>>>
>>>
>>> On Fri, Aug 28, 2015 at 8:56 AM, Gerrit Eichner <
>>> Gerrit.Eichner at math.uni-giessen.de> wrote:
>>>
>>> Dear Paul,
>>>>
>>>> quoting the email-footer: "PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html and provide commented,
>>>> minimal, self-contained, reproducible code."
>>>>
>>>> So, what exactly did you try and what was the actual problem/error
>>>> message?
>>>>
>>>> Besides that, have you noted that two of you data rows have the same
>>>> name?
>>>>
>>>>
>>>> Have you read the online help page of fisher.test():
>>>>
>>>>  ?fisher.test
>>>>
>>>>
>>>> Have you tried anything like the following?
>>>>
>>>> W <- as.matrix( read.table( "w.txt", head = T)[-1])
>>>>
>>>> fisher.test( W, workspace = 1e8)
>>>>    # For workspace look at the help page, but it presumably
>>>>    # won't work because of your sample size.
>>>>
>>>>
>>>> set.seed( 20150828) # for reproducibility
>>>> fisher.test( W, simulate.p.value = TRUE, B = 1e5)
>>>>    # For B look at the help page.
>>>>
>>>>
>>>> Finally: Did Minitab really report "p > 0.001"? ;-)
>>>>
>>>>  Hth  --  Gerrit
>>>>
>>>>
>>>> Dear all,
>>>>
>>>>>            I am trying to do a fishers test on a 5x4 table on R
>>>>> statistics. I have already done a chi squared test using Minitab on this
>>>>> data set, getting a result of (1, N = 165.953, DF 12, p>0.001), yet
>>>>> using
>>>>> these results (even though they are excellent) may not be suitable for
>>>>> publication. I have tried numerous other statistical packages in the
>>>>> hope
>>>>> of doing this test, yet each one has just the 2x2 table.
>>>>>            I am struggling to edit the template fishers test on R to fit
>>>>> my table (as according to the R book it is possible, yet i cannot get it
>>>>> to
>>>>> work). The template given on the R documentation and R book is for a 2x2
>>>>> fisher test. What do i need to change to get this to work? I have
>>>>> attached
>>>>> the data with the email so one can see what i am on about. Or do i have
>>>>> to
>>>>> write my own new code to compute this.
>>>>>
>>>>>             Yours Sincerely,
>>>>>                                     Paul Brett


From therneau at mayo.edu  Mon Aug 31 15:56:34 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 31 Aug 2015 08:56:34 -0500
Subject: [R] using survreg() in survival package with "long" data
In-Reply-To: <mailman.3.1440928802.5178.r-help@r-project.org>
References: <mailman.3.1440928802.5178.r-help@r-project.org>
Message-ID: <2f3a88$1aocca@ironport10.mayo.edu>


On 08/30/2015 05:00 AM, r-help-request at r-project.org wrote:
> I'm unable to fit a parametric survival regression using survreg() in the survival package with data in "counting-process" ("long") form.
>
> To illustrate using a scaled-down problem with 10 subjects (with data placed on the web):
>

As usual I'm a day late since I read digests, and Goran has already clarified things.  A 
discussion of this is badly needed in my as yet unwrritten book on using the survival 
package.  From a higher level view:
   If an observation is interval censored (a,b) then one knows that the event happened 
between time "a" and time "b", but not when.  The survreg routine can handle interval 
censored data since it is parametric (you need to integrate over the interval).  The 
interval (-infinity, b) is called 'left censored' and the interval (a, infinity) is 'right 
censored'.  Left censored data is rare in medical work, an example might be a chronic 
disease like rhuematoid arthritis where we know that the true disease onset was some time 
before the date it was first detected, and one is trying to deduce the duration of disease.

   Left truncation at time 'a' means that any events before time "a" are not in the data 
set.  In a referral center like mine this includes any subjects who die before they come 
to us.  The coxph model handles left truncation naturally via its counting process 
formulation.  That same formulation also allows it to deal with time dependent 
covariates.   Accelerated failure time models like survreg can handle left truncation in 
principle, but they require that the values of any covariates are known from time 0 -- 
even for a truncated subject.   I have never added left-truncation to the survreg code, 
mostly because I have never needed it myself, but also because users would immediately 
think that they could accomplish time-dependent covariates by simply using a long format 
data set. Rather, each subject needs to be linked to a full covariate history, which is a 
bit more work.

  So:  coxph does left truncation but not left (or interval) censoring
       survreg does interval censoring but not left truncation (or time dependent covariates).

Terry T


From marco.colagrossi at gmail.com  Mon Aug 31 17:08:43 2015
From: marco.colagrossi at gmail.com (Marco Colagrossi)
Date: Mon, 31 Aug 2015 17:08:43 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <55DCA4E6.40204@dewey.myzen.co.uk>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
	<CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>
	<55DCA4E6.40204@dewey.myzen.co.uk>
Message-ID: <CALxyAHQ-9Q-fAuAX1MPxOw9o8=4DyJzkKDngcrdC1Ory-_pMTg@mail.gmail.com>

Thanks for your help,

I got the mistake I was making and I managed to find a solution
regarding those graphs; I don't want to abuse of your patience but I
have three further questions:

1. Always regarding the forest plots, it is possible to make a
cross-subset? I try to explain my self better; I have one dummy
variable called pub and another variable called SIMiv that can take
the values of "share", "loan", "number" and "duration". How can I
subset my sample so that the forest shows only (for example) studies
when the dummy takes the value of 1 and the SIMiv variable takes the
values of "share" and "loan"?
Something like this:
forest(pc, var, ci95m, ci95p, slab = authoryear2, psize=1,
subset=(pub==1, SIMiv=("share", "loan", "duration"))

2. I have few doubts regarding the multilevel modeling;
    rma.mv(pc, var, random = ~ 1 | author, data=codebook)
   if I'm correct this should be a multilevel model nested at "author"
level; what I cannot understand If it is a varying intercept
(Y=A+BjX), a varying slope (Y=Aj+BX) or a varying intercept&slope
model (Y=Aj+BjX). Are there the formulas for it somewhere? So far I
only found the formulas for the estimators included in the metafor
package.

3. metareg1 <- rma.mv(pc, var, random = ~ 1 | author, mods = ~ pub +
SIMiv, data=codebook)
Again, if I'm correct this should be a multilevel meta regression
(correct me if I'm wrong); I have the same doubts as before.

Thank you again

Marco

On 25 August 2015 at 19:24, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> Dear Marco
>
> When you change xlim it increases the width of the forest plot in the sense
> you describe. It does not push your text out of the way to make space for it
> but instead overprints it. You may like to use alim to truncate your
> confidence interval whiskers to fit within the space you see or make your
> labels shorter.
>
>
> On 25/08/2015 17:25, Marco Colagrossi wrote:
>>
>> I think I've not explained myself well. When I say "the width of the
>> forest plot" I mean the region above the observed outcome, the
>> "actual" forest plot, not the plot as a whole. Even if I change values
>> for Xlim, cex or ilab.xpos the width of that particular region within
>> the plot doesn't change.
>>
>> Best,
>>
>> Marco
>>
>> On 25 August 2015 at 18:11, Viechtbauer Wolfgang (STAT)
>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>
>>> The 'xlim' argument does not change the actual width of the plotting
>>> device. For that, you need to use the 'width' argument with whatever device
>>> you are actually using. You can then use the 'xlim' argument to create
>>> appropriate spacing to the left/right of the part of the plot that shows the
>>> estimates and their CIs. Within that space, you can then add additional
>>> columns with the 'ilab' argument. It's up to you to find an appropriate
>>> combination of plotting device width, character/symbol expansion factor
>>> ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create a nice
>>> looking plot that has no overlapping text and no excessive white space. An
>>> example is this:
>>>
>>> http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups
>>>
>>> Note that it took me dozens of iterations to create that plot. You just
>>> have to start experimenting.
>>>
>>> Best,
>>> Wolfgang
>>>
>>>> -----Original Message-----
>>>> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
>>>> Sent: Tuesday, August 25, 2015 17:59
>>>> To: Viechtbauer Wolfgang (STAT)
>>>> Cc: r-help at r-project.org; Michael Dewey
>>>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
>>>>
>>>> Thanks again for your help. I'm sorry to bother you but I don't get
>>>> how to widen the forest plot; if I try to change the values of xlim or
>>>> the ilab.xpos values the width of the forest plot region does not
>>>> change, but only moves on the graphs. What I'm I missing?
>>>>
>>>>
>>>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>>>> subset=(pub==1),
>>>>         xlim = c(-16, 6),
>>>>         ilab = data.frame(SIMdv, SIMiv),
>>>>         ilab.xpos = c(-7.5, -5.5), cex = 0.75)
>>>> op <- par(cex=.75, font=2)
>>>>        text(c(-7.5, -5.5), 54, c("DV", "IV"))
>>>>        text(-16,                54, "Author(s) and Year",     pos=4)
>>>>        text(6,                  54, "Outcome [95% CI]", pos=2)
>>>> par(op)
>>>>>
>>>>> par("usr")[1:2]
>>>>
>>>> [1] -16   6
>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html


From jfox at mcmaster.ca  Mon Aug 31 17:09:36 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 31 Aug 2015 15:09:36 +0000
Subject: [R] using survreg() in survival package with "long" data
In-Reply-To: <2f3a88$1aocc9@ironport10.mayo.edu>
References: <mailman.3.1440928802.5178.r-help@r-project.org>,
	<2f3a88$1aocc9@ironport10.mayo.edu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8A40282@FHSDB2D11-2.csu.mcmaster.ca>

Dear Terry,

Thank you for the extended explanation -- it's helpful. 

Best,
 John

________________________________________
From: Therneau, Terry M., Ph.D. [therneau at mayo.edu]
Sent: August 31, 2015 9:56 AM
To: r-help at r-project.org; Fox, John; G?ran Brostr?m
Subject: Re: using survreg() in survival package with "long" data

On 08/30/2015 05:00 AM, r-help-request at r-project.org wrote:
> I'm unable to fit a parametric survival regression using survreg() in the survival package with data in "counting-process" ("long") form.
>
> To illustrate using a scaled-down problem with 10 subjects (with data placed on the web):
>

As usual I'm a day late since I read digests, and Goran has already clarified things.  A
discussion of this is badly needed in my as yet unwrritten book on using the survival
package.  From a higher level view:
   If an observation is interval censored (a,b) then one knows that the event happened
between time "a" and time "b", but not when.  The survreg routine can handle interval
censored data since it is parametric (you need to integrate over the interval).  The
interval (-infinity, b) is called 'left censored' and the interval (a, infinity) is 'right
censored'.  Left censored data is rare in medical work, an example might be a chronic
disease like rhuematoid arthritis where we know that the true disease onset was some time
before the date it was first detected, and one is trying to deduce the duration of disease.

   Left truncation at time 'a' means that any events before time "a" are not in the data
set.  In a referral center like mine this includes any subjects who die before they come
to us.  The coxph model handles left truncation naturally via its counting process
formulation.  That same formulation also allows it to deal with time dependent
covariates.   Accelerated failure time models like survreg can handle left truncation in
principle, but they require that the values of any covariates are known from time 0 --
even for a truncated subject.   I have never added left-truncation to the survreg code,
mostly because I have never needed it myself, but also because users would immediately
think that they could accomplish time-dependent covariates by simply using a long format
data set. Rather, each subject needs to be linked to a full covariate history, which is a
bit more work.

  So:  coxph does left truncation but not left (or interval) censoring
       survreg does interval censoring but not left truncation (or time dependent covariates).

Terry T




From me at markedmondson.me  Sun Aug 30 20:29:26 2015
From: me at markedmondson.me (Mark Edmondson)
Date: Sun, 30 Aug 2015 20:29:26 +0200
Subject: [R] [R-pkgs] New packages on CRAN: googleAuthR and searchConsoleR
Message-ID: <CAGPCWY2N+KLO75+9GVOCAk-tsrTcPREPbWTYKbBO43k4CU+jng@mail.gmail.com>

Hi R package users,

You may be interested in these two new packages now available on CRAN:

*googleAuthR* lets you easily authenticate with Google OAuth2 APIs and make
your own packages with them.  It also is multi-user Shiny compatible, so
you can publish your apps and users can work with their own data.  With
Google APIs including Gmail, Google Predict and Google Drive this offers
access to some nice resources.

*searchConsoleR* is the first package released using googleAuthR, working
with the Google Search Console.  This data includes what keywords people
have used to find your website.

Hope they are of interest, do let me know what you build with them!
Yours sincerely,
Mark

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From brettpaul16 at gmail.com  Mon Aug 31 16:54:02 2015
From: brettpaul16 at gmail.com (paul brett)
Date: Mon, 31 Aug 2015 16:54:02 +0200
Subject: [R] Fisher's Test 5x4 table
In-Reply-To: <0E6A7651-7A89-4472-9BAA-44A441E18E79@gmail.com>
References: <CAE1X91qzKuDmsp1jMOQ2o2ZaRigdPZHtojm=PPR8efmt43kiLQ@mail.gmail.com>
	<Pine.SOC.4.64.1508280846170.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91oc9wa=LaAc=Sk3r2c4OS-ZSMbnmWd25eacXtWODvUbFw@mail.gmail.com>
	<Pine.SOC.4.64.1508281537530.27473@solcom.hrz.uni-giessen.de>
	<CAE1X91qFY6qF9bf5vKXAqGefpH18Qs=W1nUgVDD=oZMyCi=U-A@mail.gmail.com>
	<0E6A7651-7A89-4472-9BAA-44A441E18E79@gmail.com>
Message-ID: <CAE1X91ozFb=U59hnNtT50bjYZaEPowQ=WJZ0rrYkU5G8GeOwtg@mail.gmail.com>

Hi Peter and Gerrit,
                            Sorry about my confusion with the results I was
not entirely sure what they were. I was expecting some form of a table and
i didn't realize that with the results of a fisher test, one just gets a
p-value. I had tried the 'estimate' and 'null.value' which gave me a null
value which upon looking again I don't do but I know that now).
                            Thanks very much for the help, this has been my
5th different statistical package to try and do this test. So I suppose I
had a suspicous/this is too good to be true reaction to the result. I
wasn't entirely sure what it was. Thanks for clearing this up for me.

                            Thanks again,
                                                Paul

On Mon, Aug 31, 2015 at 9:00 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 30 Aug 2015, at 13:54 , paul brett <brettpaul16 at gmail.com> wrote:
> >
> > Fisher's Exact Test for Count Data with simulated p-value (based on 1e+07
> > replicates)
> >
> > data:  Trapz
> > p-value = 1e-07
> > alternative hypothesis: two.sided
> >
> >
> > Dispite these chages, the changes equations is not giving me the results
> > for the calculations. The changes I have made seem to satisfy what is in
> > the details section on R, and I don't have the issue of workspace in R.
> > What I do to get the results of the fisher test?
> > Is there something simple that I am missing?
>
> The theory?
>
> There is nothing more to Fisher's test than the calculation of the
> probability of obtaining a table as or less (im-)probable as the one
> observed. This is the p-value. You have done 10 million simulations and not
> found a single table that is less likely than the one observed. Hence, the
> p-value is 1/10 000 001 = ca. 1e-7, counting in the observed table.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Aug 31 18:34:32 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 31 Aug 2015 17:34:32 +0100
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <CALxyAHQ-9Q-fAuAX1MPxOw9o8=4DyJzkKDngcrdC1Ory-_pMTg@mail.gmail.com>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
	<CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>
	<55DCA4E6.40204@dewey.myzen.co.uk>
	<CALxyAHQ-9Q-fAuAX1MPxOw9o8=4DyJzkKDngcrdC1Ory-_pMTg@mail.gmail.com>
Message-ID: <55E48218.9090008@dewey.myzen.co.uk>

Comments in line

On 31/08/2015 16:08, Marco Colagrossi wrote:
> Thanks for your help,
>
> I got the mistake I was making and I managed to find a solution
> regarding those graphs; I don't want to abuse of your patience but I
> have three further questions:
>
> 1. Always regarding the forest plots, it is possible to make a
> cross-subset? I try to explain my self better; I have one dummy
> variable called pub and another variable called SIMiv that can take
> the values of "share", "loan", "number" and "duration". How can I
> subset my sample so that the forest shows only (for example) studies
> when the dummy takes the value of 1 and the SIMiv variable takes the
> values of "share" and "loan"?
> Something like this:
> forest(pc, var, ci95m, ci95p, slab = authoryear2, psize=1,
> subset=(pub==1, SIMiv=("share", "loan", "duration"))
>

Do you not want something like
(pub == 1) & (SIMIv %in% c("share", "loan", "duration"))


> 2. I have few doubts regarding the multilevel modeling;
>      rma.mv(pc, var, random = ~ 1 | author, data=codebook)
>     if I'm correct this should be a multilevel model nested at "author"
> level; what I cannot understand If it is a varying intercept
> (Y=A+BjX), a varying slope (Y=Aj+BX) or a varying intercept&slope
> model (Y=Aj+BjX). Are there the formulas for it somewhere? So far I
> only found the formulas for the estimators included in the metafor
> package.
>

I think it a random intercept but Wolfgang may correct me there.

> 3. metareg1 <- rma.mv(pc, var, random = ~ 1 | author, mods = ~ pub +
> SIMiv, data=codebook)
> Again, if I'm correct this should be a multilevel meta regression
> (correct me if I'm wrong); I have the same doubts as before.
>
> Thank you again
>
> Marco
>
> On 25 August 2015 at 19:24, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>> Dear Marco
>>
>> When you change xlim it increases the width of the forest plot in the sense
>> you describe. It does not push your text out of the way to make space for it
>> but instead overprints it. You may like to use alim to truncate your
>> confidence interval whiskers to fit within the space you see or make your
>> labels shorter.
>>
>>
>> On 25/08/2015 17:25, Marco Colagrossi wrote:
>>>
>>> I think I've not explained myself well. When I say "the width of the
>>> forest plot" I mean the region above the observed outcome, the
>>> "actual" forest plot, not the plot as a whole. Even if I change values
>>> for Xlim, cex or ilab.xpos the width of that particular region within
>>> the plot doesn't change.
>>>
>>> Best,
>>>
>>> Marco
>>>
>>> On 25 August 2015 at 18:11, Viechtbauer Wolfgang (STAT)
>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>>
>>>> The 'xlim' argument does not change the actual width of the plotting
>>>> device. For that, you need to use the 'width' argument with whatever device
>>>> you are actually using. You can then use the 'xlim' argument to create
>>>> appropriate spacing to the left/right of the part of the plot that shows the
>>>> estimates and their CIs. Within that space, you can then add additional
>>>> columns with the 'ilab' argument. It's up to you to find an appropriate
>>>> combination of plotting device width, character/symbol expansion factor
>>>> ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create a nice
>>>> looking plot that has no overlapping text and no excessive white space. An
>>>> example is this:
>>>>
>>>> http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups
>>>>
>>>> Note that it took me dozens of iterations to create that plot. You just
>>>> have to start experimenting.
>>>>
>>>> Best,
>>>> Wolfgang
>>>>
>>>>> -----Original Message-----
>>>>> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
>>>>> Sent: Tuesday, August 25, 2015 17:59
>>>>> To: Viechtbauer Wolfgang (STAT)
>>>>> Cc: r-help at r-project.org; Michael Dewey
>>>>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
>>>>>
>>>>> Thanks again for your help. I'm sorry to bother you but I don't get
>>>>> how to widen the forest plot; if I try to change the values of xlim or
>>>>> the ilab.xpos values the width of the forest plot region does not
>>>>> change, but only moves on the graphs. What I'm I missing?
>>>>>
>>>>>
>>>>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>>>>> subset=(pub==1),
>>>>>          xlim = c(-16, 6),
>>>>>          ilab = data.frame(SIMdv, SIMiv),
>>>>>          ilab.xpos = c(-7.5, -5.5), cex = 0.75)
>>>>> op <- par(cex=.75, font=2)
>>>>>         text(c(-7.5, -5.5), 54, c("DV", "IV"))
>>>>>         text(-16,                54, "Author(s) and Year",     pos=4)
>>>>>         text(6,                  54, "Outcome [95% CI]", pos=2)
>>>>> par(op)
>>>>>>
>>>>>> par("usr")[1:2]
>>>>>
>>>>> [1] -16   6
>>
>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From marco.colagrossi at gmail.com  Mon Aug 31 18:36:38 2015
From: marco.colagrossi at gmail.com (Marco Colagrossi)
Date: Mon, 31 Aug 2015 18:36:38 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <55E48218.9090008@dewey.myzen.co.uk>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
	<CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>
	<55DCA4E6.40204@dewey.myzen.co.uk>
	<CALxyAHQ-9Q-fAuAX1MPxOw9o8=4DyJzkKDngcrdC1Ory-_pMTg@mail.gmail.com>
	<55E48218.9090008@dewey.myzen.co.uk>
Message-ID: <CALxyAHTKPoyHpxD-Z+BgGZrF+4GHZsQOt1J_dn2xxfVoqHVhgA@mail.gmail.com>

The solution that you proposed works perfectly, thank you very much.

I'll wait for Wolfgang answer as I'm having few doubts about the models.

Thanks

On 31 August 2015 at 18:34, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> Comments in line
>
> On 31/08/2015 16:08, Marco Colagrossi wrote:
>>
>> Thanks for your help,
>>
>> I got the mistake I was making and I managed to find a solution
>> regarding those graphs; I don't want to abuse of your patience but I
>> have three further questions:
>>
>> 1. Always regarding the forest plots, it is possible to make a
>> cross-subset? I try to explain my self better; I have one dummy
>> variable called pub and another variable called SIMiv that can take
>> the values of "share", "loan", "number" and "duration". How can I
>> subset my sample so that the forest shows only (for example) studies
>> when the dummy takes the value of 1 and the SIMiv variable takes the
>> values of "share" and "loan"?
>> Something like this:
>> forest(pc, var, ci95m, ci95p, slab = authoryear2, psize=1,
>> subset=(pub==1, SIMiv=("share", "loan", "duration"))
>>
>
> Do you not want something like
> (pub == 1) & (SIMIv %in% c("share", "loan", "duration"))
>
>
>> 2. I have few doubts regarding the multilevel modeling;
>>      rma.mv(pc, var, random = ~ 1 | author, data=codebook)
>>     if I'm correct this should be a multilevel model nested at "author"
>> level; what I cannot understand If it is a varying intercept
>> (Y=A+BjX), a varying slope (Y=Aj+BX) or a varying intercept&slope
>> model (Y=Aj+BjX). Are there the formulas for it somewhere? So far I
>> only found the formulas for the estimators included in the metafor
>> package.
>>
>
> I think it a random intercept but Wolfgang may correct me there.
>
>
>> 3. metareg1 <- rma.mv(pc, var, random = ~ 1 | author, mods = ~ pub +
>> SIMiv, data=codebook)
>> Again, if I'm correct this should be a multilevel meta regression
>> (correct me if I'm wrong); I have the same doubts as before.
>>
>> Thank you again
>>
>> Marco
>>
>> On 25 August 2015 at 19:24, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>>>
>>> Dear Marco
>>>
>>> When you change xlim it increases the width of the forest plot in the
>>> sense
>>> you describe. It does not push your text out of the way to make space for
>>> it
>>> but instead overprints it. You may like to use alim to truncate your
>>> confidence interval whiskers to fit within the space you see or make your
>>> labels shorter.
>>>
>>>
>>> On 25/08/2015 17:25, Marco Colagrossi wrote:
>>>>
>>>>
>>>> I think I've not explained myself well. When I say "the width of the
>>>> forest plot" I mean the region above the observed outcome, the
>>>> "actual" forest plot, not the plot as a whole. Even if I change values
>>>> for Xlim, cex or ilab.xpos the width of that particular region within
>>>> the plot doesn't change.
>>>>
>>>> Best,
>>>>
>>>> Marco
>>>>
>>>> On 25 August 2015 at 18:11, Viechtbauer Wolfgang (STAT)
>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>>>
>>>>>
>>>>> The 'xlim' argument does not change the actual width of the plotting
>>>>> device. For that, you need to use the 'width' argument with whatever
>>>>> device
>>>>> you are actually using. You can then use the 'xlim' argument to create
>>>>> appropriate spacing to the left/right of the part of the plot that
>>>>> shows the
>>>>> estimates and their CIs. Within that space, you can then add additional
>>>>> columns with the 'ilab' argument. It's up to you to find an appropriate
>>>>> combination of plotting device width, character/symbol expansion factor
>>>>> ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create a
>>>>> nice
>>>>> looking plot that has no overlapping text and no excessive white space.
>>>>> An
>>>>> example is this:
>>>>>
>>>>>
>>>>> http://www.metafor-project.org/doku.php/plots:forest_plot_with_subgroups
>>>>>
>>>>> Note that it took me dozens of iterations to create that plot. You just
>>>>> have to start experimenting.
>>>>>
>>>>> Best,
>>>>> Wolfgang
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
>>>>>> Sent: Tuesday, August 25, 2015 17:59
>>>>>> To: Viechtbauer Wolfgang (STAT)
>>>>>> Cc: r-help at r-project.org; Michael Dewey
>>>>>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
>>>>>>
>>>>>> Thanks again for your help. I'm sorry to bother you but I don't get
>>>>>> how to widen the forest plot; if I try to change the values of xlim or
>>>>>> the ilab.xpos values the width of the forest plot region does not
>>>>>> change, but only moves on the graphs. What I'm I missing?
>>>>>>
>>>>>>
>>>>>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
>>>>>> subset=(pub==1),
>>>>>>          xlim = c(-16, 6),
>>>>>>          ilab = data.frame(SIMdv, SIMiv),
>>>>>>          ilab.xpos = c(-7.5, -5.5), cex = 0.75)
>>>>>> op <- par(cex=.75, font=2)
>>>>>>         text(c(-7.5, -5.5), 54, c("DV", "IV"))
>>>>>>         text(-16,                54, "Author(s) and Year",     pos=4)
>>>>>>         text(6,                  54, "Outcome [95% CI]", pos=2)
>>>>>> par(op)
>>>>>>>
>>>>>>>
>>>>>>> par("usr")[1:2]
>>>>>>
>>>>>>
>>>>>> [1] -16   6
>>>
>>>
>>>
>>> --
>>> Michael
>>> http://www.dewey.myzen.co.uk/home.html
>>
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Aug 31 19:28:21 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 31 Aug 2015 19:28:21 +0200
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <CALxyAHTKPoyHpxD-Z+BgGZrF+4GHZsQOt1J_dn2xxfVoqHVhgA@mail.gmail.com>
References: <CALxyAHTr2xjF9ZYcH2fKVe0-JuCtVV1GU+Nt2Qr5yLrj5+FKLQ@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92004@UM-MAIL4112.unimaas.nl>
	<CALxyAHTKXM6zw+BZhG3OHpn9ONGj+DRSAq3hNd0O_TZAVRy+YQ@mail.gmail.com>
	<55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
	<CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>
	<55DCA4E6.40204@dewey.myzen.co.uk>
	<CALxyAHQ-9Q-fAuAX1MPxOw9o8=4DyJzkKDngcrdC1Ory-_pMTg@mail.gmail.com>
	<55E48218.9090008@dewey.myzen.co.uk>
	<CALxyAHTKPoyHpxD-Z+BgGZrF+4GHZsQOt1J_dn2xxfVoqHVhgA@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F1ADBC6F2@UM-MAIL4112.unimaas.nl>

Have you read help(rma.mv)? It describes in detail what "random = ~ 1 | author" does. Also, I think you may find some of these useful:

http://www.metafor-project.org/doku.php/analyses#multivariate_multilevel_meta-analysis_models

Especially: http://www.metafor-project.org/doku.php/analyses:konstantopoulos2011

Using "random = ~ 1 | author" is likely to be insufficient. You also need to add random effects at the observation level.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
> Sent: Monday, August 31, 2015 18:37
> To: Michael Dewey
> Cc: Viechtbauer Wolfgang (STAT); r-help at r-project.org
> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
> 
> The solution that you proposed works perfectly, thank you very much.
> 
> I'll wait for Wolfgang answer as I'm having few doubts about the models.
> 
> Thanks
> 
> On 31 August 2015 at 18:34, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
> > Comments in line
> >
> > On 31/08/2015 16:08, Marco Colagrossi wrote:
> >>
> >> Thanks for your help,
> >>
> >> I got the mistake I was making and I managed to find a solution
> >> regarding those graphs; I don't want to abuse of your patience but I
> >> have three further questions:
> >>
> >> 1. Always regarding the forest plots, it is possible to make a
> >> cross-subset? I try to explain my self better; I have one dummy
> >> variable called pub and another variable called SIMiv that can take
> >> the values of "share", "loan", "number" and "duration". How can I
> >> subset my sample so that the forest shows only (for example) studies
> >> when the dummy takes the value of 1 and the SIMiv variable takes the
> >> values of "share" and "loan"?
> >> Something like this:
> >> forest(pc, var, ci95m, ci95p, slab = authoryear2, psize=1,
> >> subset=(pub==1, SIMiv=("share", "loan", "duration"))
> >>
> >
> > Do you not want something like
> > (pub == 1) & (SIMIv %in% c("share", "loan", "duration"))
> >
> >
> >> 2. I have few doubts regarding the multilevel modeling;
> >>      rma.mv(pc, var, random = ~ 1 | author, data=codebook)
> >>     if I'm correct this should be a multilevel model nested at
> "author"
> >> level; what I cannot understand If it is a varying intercept
> >> (Y=A+BjX), a varying slope (Y=Aj+BX) or a varying intercept&slope
> >> model (Y=Aj+BjX). Are there the formulas for it somewhere? So far I
> >> only found the formulas for the estimators included in the metafor
> >> package.
> >>
> >
> > I think it a random intercept but Wolfgang may correct me there.
> >
> >
> >> 3. metareg1 <- rma.mv(pc, var, random = ~ 1 | author, mods = ~ pub +
> >> SIMiv, data=codebook)
> >> Again, if I'm correct this should be a multilevel meta regression
> >> (correct me if I'm wrong); I have the same doubts as before.
> >>
> >> Thank you again
> >>
> >> Marco
> >>
> >> On 25 August 2015 at 19:24, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
> >>>
> >>> Dear Marco
> >>>
> >>> When you change xlim it increases the width of the forest plot in the
> >>> sense
> >>> you describe. It does not push your text out of the way to make space
> for
> >>> it
> >>> but instead overprints it. You may like to use alim to truncate your
> >>> confidence interval whiskers to fit within the space you see or make
> your
> >>> labels shorter.
> >>>
> >>>
> >>> On 25/08/2015 17:25, Marco Colagrossi wrote:
> >>>>
> >>>>
> >>>> I think I've not explained myself well. When I say "the width of the
> >>>> forest plot" I mean the region above the observed outcome, the
> >>>> "actual" forest plot, not the plot as a whole. Even if I change
> values
> >>>> for Xlim, cex or ilab.xpos the width of that particular region
> within
> >>>> the plot doesn't change.
> >>>>
> >>>> Best,
> >>>>
> >>>> Marco
> >>>>
> >>>> On 25 August 2015 at 18:11, Viechtbauer Wolfgang (STAT)
> >>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>>>>
> >>>>>
> >>>>> The 'xlim' argument does not change the actual width of the
> plotting
> >>>>> device. For that, you need to use the 'width' argument with
> whatever
> >>>>> device
> >>>>> you are actually using. You can then use the 'xlim' argument to
> create
> >>>>> appropriate spacing to the left/right of the part of the plot that
> >>>>> shows the
> >>>>> estimates and their CIs. Within that space, you can then add
> additional
> >>>>> columns with the 'ilab' argument. It's up to you to find an
> appropriate
> >>>>> combination of plotting device width, character/symbol expansion
> factor
> >>>>> ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create a
> >>>>> nice
> >>>>> looking plot that has no overlapping text and no excessive white
> space.
> >>>>> An
> >>>>> example is this:
> >>>>>
> >>>>>
> >>>>> http://www.metafor-
> project.org/doku.php/plots:forest_plot_with_subgroups
> >>>>>
> >>>>> Note that it took me dozens of iterations to create that plot. You
> just
> >>>>> have to start experimenting.
> >>>>>
> >>>>> Best,
> >>>>> Wolfgang
> >>>>>
> >>>>>> -----Original Message-----
> >>>>>> From: Marco Colagrossi [mailto:marco.colagrossi at gmail.com]
> >>>>>> Sent: Tuesday, August 25, 2015 17:59
> >>>>>> To: Viechtbauer Wolfgang (STAT)
> >>>>>> Cc: r-help at r-project.org; Michael Dewey
> >>>>>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
> >>>>>>
> >>>>>> Thanks again for your help. I'm sorry to bother you but I don't
> get
> >>>>>> how to widen the forest plot; if I try to change the values of
> xlim or
> >>>>>> the ilab.xpos values the width of the forest plot region does not
> >>>>>> change, but only moves on the graphs. What I'm I missing?
> >>>>>>
> >>>>>>
> >>>>>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
> >>>>>> subset=(pub==1),
> >>>>>>          xlim = c(-16, 6),
> >>>>>>          ilab = data.frame(SIMdv, SIMiv),
> >>>>>>          ilab.xpos = c(-7.5, -5.5), cex = 0.75)
> >>>>>> op <- par(cex=.75, font=2)
> >>>>>>         text(c(-7.5, -5.5), 54, c("DV", "IV"))
> >>>>>>         text(-16,                54, "Author(s) and Year",
> pos=4)
> >>>>>>         text(6,                  54, "Outcome [95% CI]", pos=2)
> >>>>>> par(op)
> >>>>>>>
> >>>>>>>
> >>>>>>> par("usr")[1:2]
> >>>>>>
> >>>>>>
> >>>>>> [1] -16   6

From naving2uk at gmail.com  Mon Aug 31 19:29:05 2015
From: naving2uk at gmail.com (Navien)
Date: Mon, 31 Aug 2015 10:29:05 -0700 (PDT)
Subject: [R] Metafor and forest(); not showing 'ilab' and text
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F1ADBC6F2@UM-MAIL4112.unimaas.nl>
References: <55DC5018.8040000@dewey.myzen.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730F1AA922CF@UM-MAIL4112.unimaas.nl>
	<CALxyAHQu6Q=grjPfVZL8=9mJNHxY1pe9wwn6tjj38-YJBW7c5A@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1AA92353@UM-MAIL4112.unimaas.nl>
	<CALxyAHQ=O__2U+p16N=3VaTdd9_+QZBT5NrBPijzX0RQmKVjog@mail.gmail.com>
	<55DCA4E6.40204@dewey.myzen.co.uk>
	<CALxyAHQ-9Q-fAuAX1MPxOw9o8=4DyJzkKDngcrdC1Ory-_pMTg@mail.gmail.com>
	<55E48218.9090008@dewey.myzen.co.uk>
	<CALxyAHTKPoyHpxD-Z+BgGZrF+4GHZsQOt1J_dn2xxfVoqHVhgA@mail.gmail.com>
	<077E31A57DA26E46AB0D493C9966AC730F1ADBC6F2@UM-MAIL4112.unimaas.nl>
Message-ID: <CAM1GnGNPE5QOWk_NZMjrG0WGHufKnLcbo17-sN-N7bP68yhkRg@mail.gmail.com>

Dear Wolfgang,

Kindly please i have an issue with R code could you please help me.

Best Regards

On Mon, Aug 31, 2015 at 6:24 PM, Viechtbauer Wolfgang (STAT)-2 [via R] <
ml-node+s789695n4711682h19 at n4.nabble.com> wrote:

> Have you read help(rma.mv)? It describes in detail what "random = ~ 1 |
> author" does. Also, I think you may find some of these useful:
>
>
> http://www.metafor-project.org/doku.php/analyses#multivariate_multilevel_meta-analysis_models
>
> Especially:
> http://www.metafor-project.org/doku.php/analyses:konstantopoulos2011
>
> Using "random = ~ 1 | author" is likely to be insufficient. You also need
> to add random effects at the observation level.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
>
> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
>
> Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>
>
> > -----Original Message-----
> > From: Marco Colagrossi [mailto:[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711682&i=0>]
> > Sent: Monday, August 31, 2015 18:37
> > To: Michael Dewey
> > Cc: Viechtbauer Wolfgang (STAT); [hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711682&i=1>
> > Subject: Re: [R] Metafor and forest(); not showing 'ilab' and text
> >
> > The solution that you proposed works perfectly, thank you very much.
> >
> > I'll wait for Wolfgang answer as I'm having few doubts about the models.
> >
> > Thanks
> >
> > On 31 August 2015 at 18:34, Michael Dewey <[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711682&i=2>>
> > wrote:
> > > Comments in line
> > >
> > > On 31/08/2015 16:08, Marco Colagrossi wrote:
> > >>
> > >> Thanks for your help,
> > >>
> > >> I got the mistake I was making and I managed to find a solution
> > >> regarding those graphs; I don't want to abuse of your patience but I
> > >> have three further questions:
> > >>
> > >> 1. Always regarding the forest plots, it is possible to make a
> > >> cross-subset? I try to explain my self better; I have one dummy
> > >> variable called pub and another variable called SIMiv that can take
> > >> the values of "share", "loan", "number" and "duration". How can I
> > >> subset my sample so that the forest shows only (for example) studies
> > >> when the dummy takes the value of 1 and the SIMiv variable takes the
> > >> values of "share" and "loan"?
> > >> Something like this:
> > >> forest(pc, var, ci95m, ci95p, slab = authoryear2, psize=1,
> > >> subset=(pub==1, SIMiv=("share", "loan", "duration"))
> > >>
> > >
> > > Do you not want something like
> > > (pub == 1) & (SIMIv %in% c("share", "loan", "duration"))
> > >
> > >
> > >> 2. I have few doubts regarding the multilevel modeling;
> > >>      rma.mv(pc, var, random = ~ 1 | author, data=codebook)
> > >>     if I'm correct this should be a multilevel model nested at
> > "author"
> > >> level; what I cannot understand If it is a varying intercept
> > >> (Y=A+BjX), a varying slope (Y=Aj+BX) or a varying intercept&slope
> > >> model (Y=Aj+BjX). Are there the formulas for it somewhere? So far I
> > >> only found the formulas for the estimators included in the metafor
> > >> package.
> > >>
> > >
> > > I think it a random intercept but Wolfgang may correct me there.
> > >
> > >
> > >> 3. metareg1 <- rma.mv(pc, var, random = ~ 1 | author, mods = ~ pub +
> > >> SIMiv, data=codebook)
> > >> Again, if I'm correct this should be a multilevel meta regression
> > >> (correct me if I'm wrong); I have the same doubts as before.
> > >>
> > >> Thank you again
> > >>
> > >> Marco
> > >>
> > >> On 25 August 2015 at 19:24, Michael Dewey <[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711682&i=3>>
> > wrote:
> > >>>
> > >>> Dear Marco
> > >>>
> > >>> When you change xlim it increases the width of the forest plot in
> the
> > >>> sense
> > >>> you describe. It does not push your text out of the way to make
> space
> > for
> > >>> it
> > >>> but instead overprints it. You may like to use alim to truncate your
> > >>> confidence interval whiskers to fit within the space you see or make
> > your
> > >>> labels shorter.
> > >>>
> > >>>
> > >>> On 25/08/2015 17:25, Marco Colagrossi wrote:
> > >>>>
> > >>>>
> > >>>> I think I've not explained myself well. When I say "the width of
> the
> > >>>> forest plot" I mean the region above the observed outcome, the
> > >>>> "actual" forest plot, not the plot as a whole. Even if I change
> > values
> > >>>> for Xlim, cex or ilab.xpos the width of that particular region
> > within
> > >>>> the plot doesn't change.
> > >>>>
> > >>>> Best,
> > >>>>
> > >>>> Marco
> > >>>>
> > >>>> On 25 August 2015 at 18:11, Viechtbauer Wolfgang (STAT)
> > >>>> <[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711682&i=4>> wrote:
> > >>>>>
> > >>>>>
> > >>>>> The 'xlim' argument does not change the actual width of the
> > plotting
> > >>>>> device. For that, you need to use the 'width' argument with
> > whatever
> > >>>>> device
> > >>>>> you are actually using. You can then use the 'xlim' argument to
> > create
> > >>>>> appropriate spacing to the left/right of the part of the plot that
> > >>>>> shows the
> > >>>>> estimates and their CIs. Within that space, you can then add
> > additional
> > >>>>> columns with the 'ilab' argument. It's up to you to find an
> > appropriate
> > >>>>> combination of plotting device width, character/symbol expansion
> > factor
> > >>>>> ('cex' argument), 'xlim' values, and 'ilab.xpos' values to create
> a
> > >>>>> nice
> > >>>>> looking plot that has no overlapping text and no excessive white
> > space.
> > >>>>> An
> > >>>>> example is this:
> > >>>>>
> > >>>>>
> > >>>>> http://www.metafor-
> > project.org/doku.php/plots:forest_plot_with_subgroups
> > >>>>>
> > >>>>> Note that it took me dozens of iterations to create that plot. You
> > just
> > >>>>> have to start experimenting.
> > >>>>>
> > >>>>> Best,
> > >>>>> Wolfgang
> > >>>>>
> > >>>>>> -----Original Message-----
> > >>>>>> From: Marco Colagrossi [mailto:[hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711682&i=5>]
> > >>>>>> Sent: Tuesday, August 25, 2015 17:59
> > >>>>>> To: Viechtbauer Wolfgang (STAT)
> > >>>>>> Cc: [hidden email]
> <http:///user/SendEmail.jtp?type=node&node=4711682&i=6>; Michael Dewey
> > >>>>>> Subject: Re: [R] Metafor and forest(); not showing 'ilab' and
> text
> > >>>>>>
> > >>>>>> Thanks again for your help. I'm sorry to bother you but I don't
> > get
> > >>>>>> how to widen the forest plot; if I try to change the values of
> > xlim or
> > >>>>>> the ilab.xpos values the width of the forest plot region does not
> > >>>>>> change, but only moves on the graphs. What I'm I missing?
> > >>>>>>
> > >>>>>>
> > >>>>>> forest(pc, var, ci95m, ci95p, slab = authoryear, psize=1,
> > >>>>>> subset=(pub==1),
> > >>>>>>          xlim = c(-16, 6),
> > >>>>>>          ilab = data.frame(SIMdv, SIMiv),
> > >>>>>>          ilab.xpos = c(-7.5, -5.5), cex = 0.75)
> > >>>>>> op <- par(cex=.75, font=2)
> > >>>>>>         text(c(-7.5, -5.5), 54, c("DV", "IV"))
> > >>>>>>         text(-16,                54, "Author(s) and Year",
> > pos=4)
> > >>>>>>         text(6,                  54, "Outcome [95% CI]", pos=2)
> > >>>>>> par(op)
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> par("usr")[1:2]
> > >>>>>>
> > >>>>>>
> > >>>>>> [1] -16   6
> ______________________________________________
> [hidden email] <http:///user/SendEmail.jtp?type=node&node=4711682&i=7>
> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ------------------------------
> If you reply to this email, your message will be added to the discussion
> below:
>
> http://r.789695.n4.nabble.com/Metafor-and-forest-not-showing-ilab-and-text-tp4711432p4711682.html
> To start a new topic under R help, email
> ml-node+s789695n789696h53 at n4.nabble.com
> To unsubscribe from R, click here
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=789695&code=bmF2aW5nMnVrQGdtYWlsLmNvbXw3ODk2OTV8LTczNzQxMTY0Ng==>
> .
> NAML
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/Metafor-and-forest-not-showing-ilab-and-text-tp4711432p4711683.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Mon Aug 31 21:25:36 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 31 Aug 2015 21:25:36 +0200
Subject: [R] Trouble with Caret and C5.0
Message-ID: <20150831192536.GA10471@localhost.localdomain>

Dear All,
I am trying to mine a small dataset.
Admittedly, it is a bit odd since it is an example of
multi-classification task where I have more than 300 different classes for about 600
observations.
Having said that, the problem is not the output of my script, but the
fact that it gets stuck, without an error message, when I use C5.0 and
caret.
I recycled another script of mine which never gave me any headache, so
I do not know what is going on.
The small training set can be downloaded from


https://www.dropbox.com/s/4yseukqqvssvh63/training.csv?dl=0


whereas I paste my script at the end of the email.
C5.0 without caret completes in seconds, so I must be making some
mistakes with Caret.
Any suggestion is appreciated.

Lorenzo

####################################################

library(caret)
library(readr)
library(C50)
library(doMC)
library(digest)


train <- read_csv("training.csv")

ncores <- 2


registerDoMC(cores = ncores)


set.seed(123)


shuffle <- sample(nrow(train))

train <- train[shuffle, ]


train$productid <- as.character(train$productid)

train$productid <- paste('fac', train$productid, sep='')

train$productid <- as.factor(train$productid)

train$State <- as.factor(train$State)

train$category <- as.factor(train$category)

train$unit <- as.factor(train$unit)

for (i in seq(nrow(train))){

train$myname[i] <- digest(train$myname[i], algo='crc32')

}


train <- subset(train, select=-c(straincategory, description))


### this completes quickly
oneTree <- C5.0(productid ~ ., data = train, trials=10)




c50Grid <- expand.grid(trials = c(10),
         model = c( "tree" ## ,"rules"
	                    ),winnow = c(## TRUE,
			                             FALSE ))




tc <- trainControl(method = "repeatedCV", summaryFunction=mnLogLoss,
                   number = 5, repeats = 5, verboseIter=TRUE,
                   classProbs=TRUE)



### but this takes forever
model <- train(productid~., data=train, method="C5.0", trControl=tc,
                              metric="logLoss",##
                              strata=train$donation,
			                     ## sampsize=rep(nmin,
                              length(levels(train$donation))),
			                     ## control =
                              C5.0Control(fuzzyThreshold = T),
			                     maximize=FALSE,
                              tuneGrid=c50Grid)


From marongiu.luigi at gmail.com  Mon Aug 31 22:17:50 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 31 Aug 2015 21:17:50 +0100
Subject: [R] modify strip labels with given text using lattice package
Message-ID: <CAMk+s2RKfDsNeQM30dvrEkrST6i+t2URWvbAsoirWES+UYbsPw@mail.gmail.com>

Dear all,
I am drawing a barchart plot with lattice and the resulting strips are
taking the value of the variable being compared (in this example
"assay"). However I would like to write myself the value to place into
the strips, let's say I want to call the variables as "molecular test"
and "serological test" the values "a" and "b" respectively within
"assay". I have tried different approaches taken from the web but
nothing worked.
Would you have any tip?
Best regards
Luigi

>>>
test <- rep(c("Adenovirus", "Rotavirus", "Norovirus", "Rotarix",
"Sapovirus"), 2)
res <- c(0, 1, 0, 1,0, 1,0, 1,0, 1, 0, 1, 0, 1,0, 1,0, 1,0, 1)
count <- rnorm(20)
assay <- c(rep("a", 10), rep("b", 10))

df <- data.frame(test, res, count, assay, stringsAsFactors = FALSE)

library(lattice)
barchart(
    test ~ count|assay,
    df,
    groups = res,
    stack = TRUE,
    main = "Comparison of test results",
    xlab = "Count",
    col = c("yellow", "blue"),
    par.settings = list(
        strip.background = list(col="light grey"),
        superpose.polygon=list(col= c("yellow", "blue"))
    ),
    scales = list(
        alternating = FALSE
    ),
    key = list(
        space="top",
        columns=2,
        text=list(c("Negative", "Positive"), col="black"),
        rectangles=list(col=c("yellow", "blue"))
    )
)


From marongiu.luigi at gmail.com  Mon Aug 31 22:49:15 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 31 Aug 2015 21:49:15 +0100
Subject: [R] Conditional replacement and removal of data frame values
Message-ID: <CAMk+s2R_yPO3ygNFLUnaM9TVZy7ZB7neO-3o_=4s2jRGACHZqg@mail.gmail.com>

Dear all,
I have a data frame and I would like to do the following:
a) replace value of one variable "a" according to the value of another one "b"
b) remove all the instances of the variable "b"

For the sake of argument, let's say I have the following data frame:
test <- rep(c("Adenovirus", "Rotavirus", "Norovirus", "Rotarix",
"Sapovirus"), 3)
res <- c(0, 1, 0, 0, 1,
         1, 0, 1, 1, 0,
         0, 1, 0, 1, 0)
samp <- c(rep(1, 5), rep(2, 5), rep(3, 5))
df <- data.frame(test, res, samp, stringsAsFactors = FALSE)

The task I need is to coerce the results of the "Rotavirus" to
negative (0) if and only if "Rotarix" is positive (1). In this
example, the results shows that for "samp" 3 "Rotavirus" should be 0:
    test           res samp
2  Rotavirus   1    1
4  Rotarix       0    1
7  Rotavirus    0    2
9  Rotarix       1    2
12 Rotavirus   1    3
14 Rotarix       1    3

I can't use the subset function because then I would work on a
separate object and I don't know how to implement the conditions for
the replacements.
Finally, all the "Rotarix" entries should be removed from the data frame.
Thank you.
Best regards,
Luigi


From joaquin.aldabe at gmail.com  Mon Aug 31 23:06:13 2015
From: joaquin.aldabe at gmail.com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Mon, 31 Aug 2015 18:06:13 -0300
Subject: [R] Interpreting interaction terms in a glmm
Message-ID: <CAMM93=Kv4KuXicSnKQhrfg1O4aZAP9oeNLV=46BqPuf88bk8ug@mail.gmail.com>

Hi, I would appreciate if someone could send me or indicate where to find
information on how to interpret second order interactions (especially when
variables are both continuous) in the context of glmm R output.

Thanks in advanced,
Joaqu?n

-- 
*Joaqu?n Aldabe*

*Grupo Biodiversidad, Ambiente y Sociedad*
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*Departamento de Conservaci?n*
Aves Uruguay
BirdLife International
Canelones 1164, Montevideo

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From shawinkarim at gmail.com  Mon Aug 31 21:46:08 2015
From: shawinkarim at gmail.com (shawin)
Date: Mon, 31 Aug 2015 12:46:08 -0700 (PDT)
Subject: [R] Median on second group of CSV file produce Na
In-Reply-To: <1441049748473-4711689.post@n4.nabble.com>
References: <1441049748473-4711689.post@n4.nabble.com>
Message-ID: <CAPR_rLFANxncOh2xP7QjDVd7X6Qc2ptmwi8a=4+hf3oPi=Br0g@mail.gmail.com>

I have an issue ans i posted it , so i would like to receive a solution
please

On Mon, Aug 31, 2015 at 8:35 PM, shawin [via R] <
ml-node+s789695n4711689h58 at n4.nabble.com> wrote:

> I have a data frame  csv file and I'm trying to calculate median for each
> group separately row by row . When I separate the data frame in two groups
> and calculate the median for each one, I am getting an NA result for the
> second group :
> the data
>   x1  x2  x3  x4  x5  x6  x7  y1  y2  y3  y4  y5  y6  y7  y8
> 9.488404158 9.470895414 9.282433728 9.366707445 9.955383045 9.640816474
> 9.606262272   9.329651027 9.434541611 9.473922432 9.311412966 9.3154885
> 9.434977488 9.470895414 9.764258059
> 8.630629966 8.55831075  8.788391003 8.576231135 8.671587906 8.842979993
> 8.861958856 8.58330436  8.603596508 8.570129609 8.59798922  8.572686772
> 8.679751791 8.663950953 8.432875347
> 9.354748885 9.367668838 9.259952558 9.421538213 9.554635162 9.603744578
> 9.452197983 9.284228877 9.404607878 9.317737979 9.343115301 9.310644266
> 9.27227486  9.360337823 9.44706281
> 9.944863964 9.950427516 10.19101759 10.07350804 10.03269879 10.1307908
>  10.03487287 9.74609383  9.886379007 9.775472567 10.036596   9.544738458
> 9.699611598 9.911962567
> 9.625804277
>
>
>                                    Code:
>
>        rowN <- nrow(AT1)
>        MD1<-vector(length=rowN)
>       MD2<-vector(length=rowN)
>
>           MD1[1:rowN]<-NA
>           MD2[1:rowN]<-NA
>
>
>          x<- AT1[,c(2,3,4,5,6,7,8) ]
>         write.csv(x,"x.csv",row.names=TRUE)
>          x<-as.matrix(x)
>         for(i in 2:rowN) {
>        MD1[i]=median(x[i,])
>           }
>          write.csv(MD1,"MD1.csv",row.names=TRUE)
>
>          y<- AT1[,c(9,10,11,12,13,14,15,16)]
>          write.csv(y,"y.csv",row.names=TRUE)
>          y<-as.matrix(y)
>          for(j in 2:rowN) {
>          MD2[j]=median(y[j,])
>           }
>          write.csv(MD2,"MD2.csv",row.names=TRUE)
>
>
> ------------------------------
> If you reply to this email, your message will be added to the discussion
> below:
>
> http://r.789695.n4.nabble.com/Median-on-second-group-of-CSV-file-produce-Na-tp4711689.html
> To start a new topic under R help, email
> ml-node+s789695n789696h75 at n4.nabble.com
> To unsubscribe from R, click here
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=789695&code=c2hhd2lua2FyaW1AZ21haWwuY29tfDc4OTY5NXwtMjQ0MzkwMjQ1>
> .
> NAML
> <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/Median-on-second-group-of-CSV-file-produce-Na-tp4711689p4711690.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From dominic.roye at gmail.com  Mon Aug 31 22:11:28 2015
From: dominic.roye at gmail.com (Dominic Roye)
Date: Mon, 31 Aug 2015 22:11:28 +0200
Subject: [R] Non zero padding dates
Message-ID: <CALvVS-HZ3QUXYT+cDqedxJTTtzQTLfSJRoYGbO9DhvWyx4E86w@mail.gmail.com>

Hello,

How can I convert date-time in which month and day have non zero padding?

For example: "2015119_06"  ("2015-01-19 06:00")

Thanks

Dominic

	[[alternative HTML version deleted]]


From joe_beu at hotmail.com  Mon Aug 31 22:22:59 2015
From: joe_beu at hotmail.com (iclozm)
Date: Mon, 31 Aug 2015 13:22:59 -0700 (PDT)
Subject: [R] PLS Regression: Non-Metric
Message-ID: <1441052579978-4711693.post@n4.nabble.com>

Hello,

I was wondering if anyone has successfully implemented the non-metric pls
regression algorithm presented by Giorgio Russolillo in the appendix of his
PhD dissertation. 

I am having issues calling the function with his example matrices (tea data
set) and I think there may be a few mistakes in the R-Code given in the
appendix. 

The function is defined as:

myPLSQQ(Y = NA, Yc = NA, X = NA, Xc = NA, ncomp)

however nowhere does he specify what Xc and Yc refer to (I am assuming data
containing the non metric variables). Furthermore, I do not understand how
to call a function with arguments initialized to NA. 

Can I simply say: 

Y <- Y_Matrix
Xc <- X_Matrix
ncomp <- 3

data <- myPLSQQ(Y = Y, Yc = NA, X = NA, Xc = Xc, ncomp)

Kind Regards,
Chris



--
View this message in context: http://r.789695.n4.nabble.com/PLS-Regression-Non-Metric-tp4711693.html
Sent from the R help mailing list archive at Nabble.com.


