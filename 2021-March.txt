From re|chm@nj @end|ng |rom @bcg|ob@|@net  Mon Mar  1 00:55:08 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sun, 28 Feb 2021 17:55:08 -0600
Subject: [R] Making model predictions
In-Reply-To: <1a0badbb-14ab-66b5-ff25-702caea57faa@sapo.pt>
References: <002f01d70d16$c0d6c060$42844120$.ref@sbcglobal.net>
 <002f01d70d16$c0d6c060$42844120$@sbcglobal.net>
 <1a0badbb-14ab-66b5-ff25-702caea57faa@sapo.pt>
Message-ID: <001301d70e2d$25f83660$71e8a320$@sbcglobal.net>

Rui

Actually yes.  I was able to work this into my shiny app this afternoon. 

Thank you

Jeff

-----Original Message-----
From: Rui Barradas <ruipbarradas at sapo.pt> 
Sent: Sunday, February 28, 2021 5:26 AM
To: reichmanj at sbcglobal.net; R-help at r-project.org
Subject: Re: [R] Making model predictions

Hello,

Are you looking for this?


newd <- data.frame(
   Class = '1st',
   Sex = 'Male',
   Age = 'Child'
)
predict(m, newdata = newd, type = 'raw')
#            No       Yes
#[1,] 0.3169345 0.6830655


With the default type = 'class' the result is

predict(m, newdata = newd)
#[1] Yes
#Levels: No Yes


Hope this helps,

Rui Barradas

?s 14:42 de 27/02/21, Jeff Reichman escreveu:
> R User Forum
> 
> Is there a better way than grabbing individual cell values from a 
> model output to make predictions. For example the output from the 
> following Na?ve Bayes model
> 
> library(e1071)
> 
> ## Example of using a contingency table:
> data(Titanic)
> m <- naiveBayes(Survived ~ ., data = Titanic) m
> 
> will produce the following results:
> 
> Call:
> naiveBayes.formula(formula = Survived ~ ., data = Titanic)
> 
> A-priori probabilities:
> Survived
>        No      Yes
> 0.676965 0.323035
> 
> Conditional probabilities:
>          Class
> Survived        1st        2nd        3rd       Crew
>       No  0.08187919 0.11208054 0.35436242 0.45167785
>       Yes 0.28551336 0.16596343 0.25035162 0.29817159
> 
>          Sex
> Survived       Male     Female
>       No  0.91543624 0.08456376
>       Yes 0.51617440 0.48382560
> 
>          Age
> Survived      Child      Adult
>       No  0.03489933 0.96510067
>       Yes 0.08016878 0.91983122
> 
> Say I want to calculate the probability of P(survival = No | Class = 
> 1st, Sex = Male, and Age= Child).
> 
> While I  can set an object (e.g. myObj <- m$tables$Class[1,1])  to the 
> respective cell and perform the calculation, there must be a better 
> way, as I continue to learn R.
> 
> Jeff
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From @purd|e@@ @end|ng |rom gm@||@com  Mon Mar  1 01:52:54 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 1 Mar 2021 13:52:54 +1300
Subject: [R] Image processing in R for BMI calculation
In-Reply-To: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
References: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
Message-ID: <CAB8pepxYz=zrnKSLaPLp3BE9nZz_8qgfw_1qqJ4pVuY2b4LQxQ@mail.gmail.com>

Hi Paul,

If the background is relatively uniform:
Then a simple algorithm could be used, to distinguish foreground from
background points.
Essentially, returning a logical matrix.

Otherwise, I'm assuming that suitable pooling/convolution operations
could be used for this purpose.

Then you could estimate *relative* measures of height and mass from
the logical matrix.
(With more precise measures being possible, if you know the image scales).

There are a number of R packages for reading images.
Currently, I mainly use Simon Urbanek's package, "png".

I'm currently creating a package with support for pooling/convolution
operations, and related utility functions.
However, it's not ready yet.

Another option is Jeroen Ooms' package, "magick".


best,
B.


On Mon, Mar 1, 2021 at 5:39 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Hello everyone,
>
> Does anyone know about any package for image processing, for example, to
> calculate body mass index pased on a picture, silouette or image.
>
> Any guidance will be greatly appreciated.
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Mon Mar  1 12:23:28 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 2 Mar 2021 00:23:28 +1300
Subject: [R] Image processing in R for BMI calculation
In-Reply-To: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
References: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
Message-ID: <CABcYAdJiC90yT0nRR2ZwgRMZw3Yo=6mNyYdE2y03f-ToXTVLNg@mail.gmail.com>

"Body Mass Index" is a rather bizarre thing:
body.mass.in.kg / height.in.m^2
I have never been able to find any biological
or physical meaning for this.  Yet clinicians
are solemnly advised to measure the weight to
the nearest 0.1kg and the height to the
nearest 0.1cm.

How do you propose to determine the weight from
a single image?  Even an R package cannot perform magic.


On Mon, 1 Mar 2021 at 05:39, Paul Bernal <paulbernal07 at gmail.com> wrote:

> Hello everyone,
>
> Does anyone know about any package for image processing, for example, to
> calculate body mass index pased on a picture, silouette or image.
>
> Any guidance will be greatly appreciated.
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m||net@ @end|ng |rom tut@@|o  Mon Mar  1 15:17:09 2021
From: m||net@ @end|ng |rom tut@@|o (T. A. Milne)
Date: Mon, 1 Mar 2021 15:17:09 +0100 (CET)
Subject: [R] Image processing in R for BMI calculation
Message-ID: <MUi8_wm--3-2@tuta.io>

"Body Mass Index" is a rather bizarre thing:body.mass.in.kg / height.in.m^2I have never been able to find any biologicalor physical meaning for this.  Yet cliniciansare solemnly advised to measure the weight tothe nearest 0.1kg and the height to thenearest 0.1cm.How do you propose to determine the weight froma single image?  Even an R package cannot perform magic.On Mon, 1 Mar 2021 at 05:39, Paul Bernal <paulbernal07 at gmail.com> <mailto:paulbernal07 at gmail.com> wrote:

> Hello everyone,Does anyone know about any package for image processing, for example, tocalculate body mass index pased on a picture, silouette or image.Any guidance will be greatly appreciated.Best regards,Paul
>

A quick search with the terms "BMI flawed" produces an enormous list of hits pointing out the problems with BMI as an index.? Here's one from a dozen or so years ago:

https://www.npr.org/templates/story/story.php?storyId=106268439

And a quote from that piece:

"The BMI was introduced in the early 19th century by a Belgian named Lambert Adolphe Jacques Quetelet. He was a mathematician, not a physician. He produced the formula to give a quick and easy way to measure the degree of obesity of the general population to assist the government in allocating resources. In other words, it is a 200-year-old hack."
As an index of obesity in individuals, BMI has some glaring flaws.



- T. Arthur Milne


From u@er2021 @end|ng |rom r-project@org  Mon Mar  1 08:34:23 2021
From: u@er2021 @end|ng |rom r-project@org (useR! 2021 global)
Date: Mon, 1 Mar 2021 08:34:23 +0100
Subject: [R] Call for Abstracts: useR! 2021
Message-ID: <CAMZ-NW7UDqnhyVGPN4T50UhpYY7oLvdiPhMwMdVFyL3enSwk1A@mail.gmail.com>

Hello all,

submissions for useR! 2021 are open until March 15th.

You can submit an abstract for a regular talk, an elevator pitch (that
would be the equivalent of a poster at an in-person conference), a panel,
or an incubator session.

Full details here:
https://user2021.r-project.org/participation/call-for-abstracts/

Abstract submission: Jan 25?Mar 15

Deadline for video, blogs, scripts: Jun 20

Registration opens: Apr 15 (rates depend on location and employment, from 0
to 100 USD, https://user2021.r-project.org/participation/registration/)

Conference dates: July 05?09 (virtual)

useR! call for abstracts on Twitter:
https://twitter.com/_useRconf/status/1354352011978956806?s=09

Please share the announcement with relevant units.



Thank you and hope to see you soon!

On behalf of the useR! Program Committee,

Dorothea Hug Peter


-- 

*useR! 2021 - user2021 at r-project.org <user2021 at r-project.org>*
*user2021.r-project.org <http://user2021.r-project.org/> - @_useRConf
<https://twitter.com/_useRConf> - LinkedIn Profile
<https://www.linkedin.com/company/user-conf>*

	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From dc@r|@on @end|ng |rom t@mu@edu  Mon Mar  1 21:29:35 2021
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Mon, 1 Mar 2021 14:29:35 -0600
Subject: [R] Command history
In-Reply-To: <440e200c-1ce9-b05d-87f5-cb83d3947eec@lisse.NA>
References: <9a4dc0afa8944b2f81c7a40c68b73e17@ugent.be>
 <440e200c-1ce9-b05d-87f5-cb83d3947eec@lisse.NA>
Message-ID: <CAE-dL2ot2O=95jKEsnhXmvzsX6JBHvY66zBa7xz3VryScrByfQ@mail.gmail.com>

On the Mac there can be 2 files.  The R Studio uses .Rhistory, but Rapp
uses .Rapp.history.

David L Carlson

On Sun, Feb 28, 2021 at 9:06 AM Dr Eberhard W Lisse <el at lisse.na> wrote:

> On the Mac it is ~/.Rhistory
>
> el
>
> On 2021-02-28 15:39 , Mahmood Naderan-Tahan wrote:
> > Hi
> >
> > May I know where is the location of commands we used in R in the history?
> >
> >
> > Regards,
> > Mahmood--
> Dr. Eberhard W. Lisse   \         /       Obstetrician & Gynaecologist
> el at lisse.NA             / *      |  Telephone: +264 81 124 6733 (cell)
> PO Box 8421 Bachbrecht  \      /  If this email is signed with GPG/PGP
> 10007, Namibia           ;____/ Sect 20 of Act No. 4 of 2019 may apply
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!SUf5kuq252PAyFzTK-iHj_UuxwZnkuU_IN9jLFqA2A4KEY2Tg5h4iIQNLWMbd-s$
> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!SUf5kuq252PAyFzTK-iHj_UuxwZnkuU_IN9jLFqA2A4KEY2Tg5h4iIQNnW6K_7Y$
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e| @end|ng |rom ||@@e@NA  Mon Mar  1 21:38:18 2021
From: e| @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Mon, 1 Mar 2021 22:38:18 +0200
Subject: [R] Command history
In-Reply-To: <CAE-dL2ot2O=95jKEsnhXmvzsX6JBHvY66zBa7xz3VryScrByfQ@mail.gmail.com>
References: <9a4dc0afa8944b2f81c7a40c68b73e17@ugent.be>
 <440e200c-1ce9-b05d-87f5-cb83d3947eec@lisse.NA>
 <CAE-dL2ot2O=95jKEsnhXmvzsX6JBHvY66zBa7xz3VryScrByfQ@mail.gmail.com>
Message-ID: <f8c0a705-5e50-b173-5c20-e0969bd7b034@lisse.NA>

I don't use R.app.

And as I wrote later, there are a number of .Rhistory so it depends
on where you start R/RStudio from.


el

On 2021-03-01 22:29 , David Carlson wrote:
> On the Mac there can be 2 files.? The R Studio uses .Rhistory, but Rapp
> uses .Rapp.history.
> 
> David L Carlson
> 
> On Sun, Feb 28, 2021 at 9:06 AM Dr Eberhard W Lisse <el at lisse.na
> <mailto:el at lisse.na>> wrote:
> 
>     On the Mac it is ~/.Rhistory
> 
>     el
> 
>     On 2021-02-28 15:39 , Mahmood Naderan-Tahan wrote:
>     > Hi
>     >
>     > May I know where is the location of commands we used in R in the
>     history?
>     >
>     >
>     > Regards,
>     > Mahmood--
>     Dr. Eberhard W. Lisse? ?\? ? ? ? ?/? ? ? ?Obstetrician & Gynaecologist
>     el at lisse.NA? ? ? ? ? ? ?/ *? ? ? |? Telephone: +264 81 124 6733 (cell)
>     PO Box 8421 Bachbrecht? \? ? ? /? If this email is signed with GPG/PGP
>     10007, Namibia? ? ? ? ? ?;____/ Sect 20 of Act No. 4 of 2019 may apply
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!SUf5kuq252PAyFzTK-iHj_UuxwZnkuU_IN9jLFqA2A4KEY2Tg5h4iIQNLWMbd-s$
>     <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!SUf5kuq252PAyFzTK-iHj_UuxwZnkuU_IN9jLFqA2A4KEY2Tg5h4iIQNLWMbd-s$>
> 
>     PLEASE do read the posting guide
>     https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!SUf5kuq252PAyFzTK-iHj_UuxwZnkuU_IN9jLFqA2A4KEY2Tg5h4iIQNnW6K_7Y$
>     <https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!SUf5kuq252PAyFzTK-iHj_UuxwZnkuU_IN9jLFqA2A4KEY2Tg5h4iIQNnW6K_7Y$>
> 
>     and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr. Eberhard W. Lisse   \         /       Obstetrician & Gynaecologist
el at lisse.NA             / *      |  Telephone: +264 81 124 6733 (cell)
PO Box 8421 Bachbrecht  \      /  If this email is signed with GPG/PGP
10007, Namibia           ;____/ Sect 20 of Act No. 4 of 2019 may apply


From drj|m|emon @end|ng |rom gm@||@com  Mon Mar  1 22:23:24 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Mar 2021 08:23:24 +1100
Subject: [R] Image processing in R for BMI calculation
In-Reply-To: <CABcYAdJiC90yT0nRR2ZwgRMZw3Yo=6mNyYdE2y03f-ToXTVLNg@mail.gmail.com>
References: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
 <CABcYAdJiC90yT0nRR2ZwgRMZw3Yo=6mNyYdE2y03f-ToXTVLNg@mail.gmail.com>
Message-ID: <CA+8X3fWBDCnHqmS-FfW457SCLAypnjM5mqfn8izCzZO1cMFK+Q@mail.gmail.com>

I must agree with the criticism of BMI as a diagnostic index. It is
easy to tell if a person is - ahem - wide and not very high with a
single glance. These elementary parameters can easily be deduced from
an image of said person. However, it does not convey that essential
ratio of muscle to - ahem - adipose tissue that is the stated reason
for its prominence. I suggest an older, but more valid, index that was
used in the identification of witches. Simply tie the person's hands
behind their back and throw him or her into the deep end of the pool.
Time to drowning is the response variable and I am certain that those
now chastised for their adipose tissue will vastly prefer it.

Jim

On Mon, Mar 1, 2021 at 10:24 PM Richard O'Keefe <raoknz at gmail.com> wrote:
>
> "Body Mass Index" is a rather bizarre thing:
> body.mass.in.kg / height.in.m^2
> I have never been able to find any biological
> or physical meaning for this.  Yet clinicians
> are solemnly advised to measure the weight to
> the nearest 0.1kg and the height to the
> nearest 0.1cm.
>
> How do you propose to determine the weight from
> a single image?  Even an R package cannot perform magic.
>
>
> On Mon, 1 Mar 2021 at 05:39, Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> > Hello everyone,
> >
> > Does anyone know about any package for image processing, for example, to
> > calculate body mass index pased on a picture, silouette or image.
> >
> > Any guidance will be greatly appreciated.
> >
> > Best regards,
> >
> > Paul
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Mon Mar  1 22:42:15 2021
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Mon, 1 Mar 2021 21:42:15 +0000
Subject: [R] Image processing in R for BMI calculation
In-Reply-To: <CA+8X3fWBDCnHqmS-FfW457SCLAypnjM5mqfn8izCzZO1cMFK+Q@mail.gmail.com>
References: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
 <CABcYAdJiC90yT0nRR2ZwgRMZw3Yo=6mNyYdE2y03f-ToXTVLNg@mail.gmail.com>,
 <CA+8X3fWBDCnHqmS-FfW457SCLAypnjM5mqfn8izCzZO1cMFK+Q@mail.gmail.com>
Message-ID: <MN2PR03MB51673736D5548A859E648A3CE29A9@MN2PR03MB5167.namprd03.prod.outlook.com>

Colleagues,

BMI has is failures, but it has demonstrated utility. BMI predicts multiple outcome measures including cardiovascular disease and mortality. Don't through out a useful metric because it is not the perfect metric. 

As to why BMI is computed as weight/height^2, it can be shown that dividing height by the square of weight decreases the correlation between weight and height. The optimum exponent (i.e. the power that most effectively minimizes the correlation between weight and height) is not the same in men and women and it differs by race. In general an exponent of 2.0 is best for men; for women an exponent of 2.2 is a bit better than 2.0.

In any event, don't let the perfect get in the way of the good.

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Jim Lemon <drjimlemon at gmail.com>
Sent: Monday, March 1, 2021 4:23 PM
To: Richard O'Keefe; r-help mailing list
Subject: Re: [R] Image processing in R for BMI calculation

I must agree with the criticism of BMI as a diagnostic index. It is
easy to tell if a person is - ahem - wide and not very high with a
single glance. These elementary parameters can easily be deduced from
an image of said person. However, it does not convey that essential
ratio of muscle to - ahem - adipose tissue that is the stated reason
for its prominence. I suggest an older, but more valid, index that was
used in the identification of witches. Simply tie the person's hands
behind their back and throw him or her into the deep end of the pool.
Time to drowning is the response variable and I am certain that those
now chastised for their adipose tissue will vastly prefer it.

Jim

On Mon, Mar 1, 2021 at 10:24 PM Richard O'Keefe <raoknz at gmail.com> wrote:
>
> "Body Mass Index" is a rather bizarre thing:
> body.mass.in.kg / height.in.m^2
> I have never been able to find any biological
> or physical meaning for this.  Yet clinicians
> are solemnly advised to measure the weight to
> the nearest 0.1kg and the height to the
> nearest 0.1cm.
>
> How do you propose to determine the weight from
> a single image?  Even an R package cannot perform magic.
>
>
> On Mon, 1 Mar 2021 at 05:39, Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> > Hello everyone,
> >
> > Does anyone know about any package for image processing, for example, to
> > calculate body mass index pased on a picture, silouette or image.
> >
> > Any guidance will be greatly appreciated.
> >
> > Best regards,
> >
> > Paul
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432633266%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=h%2FZ9zAI4aad5GEtvB1H9BoN4bxRYnATV%2Fds7r8D2s04%3D&amp;reserved=0
> > PLEASE do read the posting guide
> > https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432633266%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=2IvMsdifWeGaAyBNT%2F7695rmNX6O1Pb3G90%2FlrpU0KA%3D&amp;reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432633266%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=h%2FZ9zAI4aad5GEtvB1H9BoN4bxRYnATV%2Fds7r8D2s04%3D&amp;reserved=0
> PLEASE do read the posting guide https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432643223%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=Ht2zAvvZpRhQ%2FKwjJXEbPreJd2RleNgzjD%2FhdbXhQc0%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432643223%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=6hUDWapuTlwnbSWTupkoiE6b9%2FyYxZIxjkJitJRZNiE%3D&amp;reserved=0
PLEASE do read the posting guide https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432643223%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=Ht2zAvvZpRhQ%2FKwjJXEbPreJd2RleNgzjD%2FhdbXhQc0%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Mar  1 23:02:34 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 1 Mar 2021 14:02:34 -0800
Subject: [R] Image processing in R for BMI calculation
In-Reply-To: <MN2PR03MB51673736D5548A859E648A3CE29A9@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
 <CABcYAdJiC90yT0nRR2ZwgRMZw3Yo=6mNyYdE2y03f-ToXTVLNg@mail.gmail.com>
 <CA+8X3fWBDCnHqmS-FfW457SCLAypnjM5mqfn8izCzZO1cMFK+Q@mail.gmail.com>
 <MN2PR03MB51673736D5548A859E648A3CE29A9@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <CAGxFJbRKye4t3t7=RtHf8szKTnNt+juWZv00jSpRxMSaKvN45g@mail.gmail.com>

This discussion is completely offr topic here. Please take it elsewhere.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 1, 2021 at 1:42 PM Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> Colleagues,
>
> BMI has is failures, but it has demonstrated utility. BMI predicts
> multiple outcome measures including cardiovascular disease and mortality.
> Don't through out a useful metric because it is not the perfect metric.
>
> As to why BMI is computed as weight/height^2, it can be shown that
> dividing height by the square of weight decreases the correlation between
> weight and height. The optimum exponent (i.e. the power that most
> effectively minimizes the correlation between weight and height) is not the
> same in men and women and it differs by race. In general an exponent of 2.0
> is best for men; for women an exponent of 2.2 is a bit better than 2.0.
>
> In any event, don't let the perfect get in the way of the good.
>
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Jim Lemon <
> drjimlemon at gmail.com>
> Sent: Monday, March 1, 2021 4:23 PM
> To: Richard O'Keefe; r-help mailing list
> Subject: Re: [R] Image processing in R for BMI calculation
>
> I must agree with the criticism of BMI as a diagnostic index. It is
> easy to tell if a person is - ahem - wide and not very high with a
> single glance. These elementary parameters can easily be deduced from
> an image of said person. However, it does not convey that essential
> ratio of muscle to - ahem - adipose tissue that is the stated reason
> for its prominence. I suggest an older, but more valid, index that was
> used in the identification of witches. Simply tie the person's hands
> behind their back and throw him or her into the deep end of the pool.
> Time to drowning is the response variable and I am certain that those
> now chastised for their adipose tissue will vastly prefer it.
>
> Jim
>
> On Mon, Mar 1, 2021 at 10:24 PM Richard O'Keefe <raoknz at gmail.com> wrote:
> >
> > "Body Mass Index" is a rather bizarre thing:
> > body.mass.in.kg / height.in.m^2
> > I have never been able to find any biological
> > or physical meaning for this.  Yet clinicians
> > are solemnly advised to measure the weight to
> > the nearest 0.1kg and the height to the
> > nearest 0.1cm.
> >
> > How do you propose to determine the weight from
> > a single image?  Even an R package cannot perform magic.
> >
> >
> > On Mon, 1 Mar 2021 at 05:39, Paul Bernal <paulbernal07 at gmail.com> wrote:
> >
> > > Hello everyone,
> > >
> > > Does anyone know about any package for image processing, for example,
> to
> > > calculate body mass index pased on a picture, silouette or image.
> > >
> > > Any guidance will be greatly appreciated.
> > >
> > > Best regards,
> > >
> > > Paul
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432633266%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=h%2FZ9zAI4aad5GEtvB1H9BoN4bxRYnATV%2Fds7r8D2s04%3D&amp;reserved=0
> > > PLEASE do read the posting guide
> > >
> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432633266%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=2IvMsdifWeGaAyBNT%2F7695rmNX6O1Pb3G90%2FlrpU0KA%3D&amp;reserved=0
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432633266%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=h%2FZ9zAI4aad5GEtvB1H9BoN4bxRYnATV%2Fds7r8D2s04%3D&amp;reserved=0
> > PLEASE do read the posting guide
> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432643223%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=Ht2zAvvZpRhQ%2FKwjJXEbPreJd2RleNgzjD%2FhdbXhQc0%3D&amp;reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432643223%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=6hUDWapuTlwnbSWTupkoiE6b9%2FyYxZIxjkJitJRZNiE%3D&amp;reserved=0
> PLEASE do read the posting guide
> https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7C58f4e3f9226c4ac456cf08d8dcf8532e%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502306432643223%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=Ht2zAvvZpRhQ%2FKwjJXEbPreJd2RleNgzjD%2FhdbXhQc0%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Mar  1 23:02:01 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 2 Mar 2021 11:02:01 +1300
Subject: [R] Image processing in R for BMI calculation
In-Reply-To: <MN2PR03MB51673736D5548A859E648A3CE29A9@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
 <CABcYAdJiC90yT0nRR2ZwgRMZw3Yo=6mNyYdE2y03f-ToXTVLNg@mail.gmail.com>
 <CA+8X3fWBDCnHqmS-FfW457SCLAypnjM5mqfn8izCzZO1cMFK+Q@mail.gmail.com>
 <MN2PR03MB51673736D5548A859E648A3CE29A9@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <CAB8pepx_h6NEoJ9toiUXHYT4hXdhn1zt2CbpUhGYsAo-LzK-4w@mail.gmail.com>

I can't help but feel that a discussion on the merit of BMI is a
digression, from the OP's question.
In addition, to being of no relevance to "R Programming".

In relation to Richard's technical comments:
As per my previous post, it is possible to get *relative" measures.
(Assuming the images are not on a standardized scale, which they could be).

In relation to Jim's anatomical comments:
An improved algorithm could evaluate a subject's body type.
In addition to factoring in gender, ethnic characteristics and age.

In any case, I don't see why image-based classification is any less
worthwhile than conclusions based on timeseries plots and
scatterplots...


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Mar  2 01:04:46 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 1 Mar 2021 19:04:46 -0500
Subject: [R] Help Required for R Markdown function.
In-Reply-To: <79258e3d-f3df-450b-a131-ad35cf9a01c3@email.android.com>
References: <078a01d70e1d$bd9cf6a0$38d6e3e0$@verizon.net>
 <79258e3d-f3df-450b-a131-ad35cf9a01c3@email.android.com>
Message-ID: <071a01d70ef7$a7dda230$f798e690$@verizon.net>

Calum,

 

Thanks for your thoughts. As mentioned, I fixed the problem. I actually was using require() and also tried library() but the problem was elsewhere as my R installation and startup seemed to no longer have variables set properly to find packages remotely or locally.

 

And yes, I made a new empty markdown but as it asks for nothing, it has no problems ?

 

 

From: CALUM POLWART <cpolwart at chemo.org.uk> 
Sent: Monday, March 1, 2021 2:31 AM
To: Avi Gross <avigross at verizon.net>
Cc: 'R. Help Mailing List' <r-help at r-project.org>
Subject: Re: [R] Help Required for R Markdown function.

 

Sounds like you have an install.packages("tidyverse") line in your Rmd rather than library (tidyverse)

 

Does this happen on a Rmd example created by doing File/New/R Markdown

 

With no changes?

 

 

 

On 28 Feb 2021 22:04, Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:

I am sure you can get more done with a caret than a stick. I need a stick for another problem, though. 

A serious question. I somehow upset my R/RSTUDIO setup while trying to see why a markdown only allowed me to save an HTML version, not PDF and DOC as it used to. It now fails on any such document with a code that indicates it is not set to find a CRAN mirror: 

It seems to be upset by a simple call to get the tidyverse loaded and may succeed in one sense but not continue: 

" Installing package into ?C:/Users/avid2016/Documents/R/win-library/4.0? 
(as ?lib? is unspecified) 
trying URL 'https://cran.rstudio.com/bin/windows/contrib/4.0/tidyverse_1.3.0.zip' 
Content type 'application/zip' length 439972 bytes (429 KB) 
downloaded 429 KB 

package ?tidyverse? successfully unpacked and MD5 sums checked 
..." 

The R Markdown lower console window says: 

"Error in contrib.url(repos, "source") : trying to use CRAN without setting a mirror calls <Anonymous> ... 
withVisible -> eval -> eval install.packages -> contrib.url Exection halted" 

I have done some work that failed. I am running on windows with the latest versions of both R and RSTUDIO after removing all old versions and re-installing both. I have seen hints I need to set some definitions in a .Rprofile or so and tried but it continues to fail. So I now can knit nothing! 

Anyone have a pointer on problems like this? My next attempt would be to reinstall the programs on another hard disk entirely in case the problem is in my folder structure of ~/R and below but I dod not want to toss years of work because of one errant configuration file or the lack thereof. 

Thanks in advance for any advice. It may be something trivial such as kit not knowing where to place a library so it puts it into a temp area? 

Avi 

-----Original Message----- 
From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of John Kane 
Sent: Saturday, February 27, 2021 3:07 PM 
To: Kishor raut <rautkishor01 at gmail.com <mailto:rautkishor01 at gmail.com> > 
Cc: R. Help Mailing List <r-help at r-project.org <mailto:r-help at r-project.org> > 
Subject: Re: [R] Help Required for R Markdown function. 

The "confusionMatrix" function appears to be from the 'caret' package. 
Have you loaded 'caret' with the library(caret) command? 

On Sat, 27 Feb 2021 at 14:20, Kishor raut <rautkishor01 at gmail.com <mailto:rautkishor01 at gmail.com> > wrote: 

> Respected Sir, 
> 
> I Mr Kishor Tried to get help online but wont found the solution so 
> writting an email. 
> 
> Step1: While writting in rmarkdown all codes get executted very well 
> till the fuction Confusionmatrix were written on it. 
> 
> Step2: As confusionmatrix command inserted following error is on 
> screen board 
> 
> 
> processing file: RMarkdown.Rmd 
>   |.....                                                                 | 
>   7% 
>   ordinary text without R code 
> 
>   |.........                                                             | 
>  13% 
> label: unnamed-chunk-1 
>   |..............                                                        | 
>  20% 
>   ordinary text without R code 
> 
>   |...................                                                   | 
>  27% 
> label: unnamed-chunk-2 
>   |.......................                                               | 
>  33% 
>   ordinary text without R code 
> 
>   |............................                                          | 
>  40% 
> label: unnamed-chunk-3 
>   |.................................                                     | 
>  47% 
>   ordinary text without R code 
> 
>   |.....................................                                 | 
>  53% 
> label: unnamed-chunk-4 
>   |..........................................                            | 
>  60% 
>   ordinary text without R code 
> 
>   |...............................................                       | 
>  67% 
> label: unnamed-chunk-5 
>   |...................................................                   | 
>  73% 
>   ordinary text without R code 
> 
>   |........................................................              | 
>  80% 
> label: unnamed-chunk-6 
>   |.............................................................         | 
>  87% 
>   ordinary text without R code 
> 
>   |.................................................................     | 
>  93% 
> label: unnamed-chunk-7 
> Quitting from lines 98-104 (RMarkdown.Rmd) Error in 
> confusionMatrix(p1, train$CTestresult) : 
>   could not find function "confusionMatrix" 
> Calls: <Anonymous> ... handle -> withCallingHandlers -> withVisible -> 
> eval 
> -> eval 
> 
> Execution halted 
> 
> Step4: As codes were written these 
> 
> 
> Using function ?sample? the data takes into sample of the specified 
> size from the stored data ```{r} 
> set.seed(1234) 
> ind<-sample(2,nrow(FEVER1),replace=TRUE, pro = c(0.7,0.3)) 
> train<-FEVER1[ind==1,] test<-FEVER1[ind==2,] ``` 
> 
> Application of Random Forest 
> 
> ```{r} 
> library(randomForest) 
> set.seed(123) 
> rfmodel<-randomForest(CTestresult~.,data = train,prox=TRUE)    # Random 
> Forest Model 
> plot(rfmodel,main="RandomForest Model") 
> print(rfmodel,train)                    # Printing Outcome of 'model for 
> Training Data 
> 
> ``` 
> 
> Prediction using Randome Forest Model 
> ```{r} 
> # Prediction  of RandomForest Intial Model for Test and Train Data 
> 
> ptrain1<-predict(rfmodel,train)              # Predicting model Prediction 
> On Training Data 
>   # First Six Outcomes with prediction 
> head(ptrain1)                              # Printing First Six Prediction 
> using Random Forest Model 
> head(train$CTestresult)                       # Printing First Six (6) 
> Actual outcomes 
> 
> ``` 
> 
> 
> Tuning Model: 
> Tuning of Machine learning model is important step for building good 
> model for best outcome of research. 
> 
> ```{r} 
> # Tunning RandomForest  Model using Algorithm 
> 
> t<-tuneRF(train[,-11],train$CTestresult, mtryStart = 2,ntreeTry = 100, 
> stepFactor =2,improve = 0.051,trace = TRUE, plot = TRUE, doBest=TRUE) 
> 
> 
> ``` 
> 
> Building New Model: 
> 
> New model was build on the basis of tunned model parameters and controls. 
> 
> ```{r} 
> # New Model After Tuning Random Forest Model 
> 
> rf1<-randomForest(CTestresult~.,data = train,ntree = 100, mtry = 8, 
> importance = TRUE,proximity = TRUE) 
> 
> print(rf1) 
> ``` 
> 
> Prediction and Confusion MAtrix: 
> 
> outcome of model will mesuare with the help of predictive outcomes 
> with the help of confusion matrix. 
> 
> ```{r} 
> # Prediction using Random Forest and Confusion Matrix for Train Data 
> p1<-predict(rf1,train) 
> cmatrix<-confusionMatrix(p1,train$CTestresult) 
> cmatrix 
> 
> 
> ``` 
> 
> 
> I will great thank full if you will help me for to remove the error. 
> 
> 
> 
> 
> -- 
> *Kind Regards* 
> 
> Kishor Raut 
> *Cell No.-07387706552* 
> 
>         [[alternative HTML version deleted]] 
> 
> ______________________________________________ 
> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
> 


-- 
John Kane 
Kingston ON Canada 

[[alternative HTML version deleted]] 

______________________________________________ 
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 

______________________________________________ 
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 




	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Tue Mar  2 01:25:00 2021
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Tue, 2 Mar 2021 00:25:00 +0000
Subject: [R] Image processing in R for BMI calculation
In-Reply-To: <27e9c398-5425-f0ef-4cfa-63a7ba1b478a@gmx.at>
References: <CAMOcQfOPo9B3qDZhZvP8bz7eEBBB6_ds+J02W-0rEcWg6MnuUw@mail.gmail.com>
 <CABcYAdJiC90yT0nRR2ZwgRMZw3Yo=6mNyYdE2y03f-ToXTVLNg@mail.gmail.com>
 <CA+8X3fWBDCnHqmS-FfW457SCLAypnjM5mqfn8izCzZO1cMFK+Q@mail.gmail.com>
 <MN2PR03MB51673736D5548A859E648A3CE29A9@MN2PR03MB5167.namprd03.prod.outlook.com>,
 <27e9c398-5425-f0ef-4cfa-63a7ba1b478a@gmx.at>
Message-ID: <MN2PR03MB51674492139F5CBDB9A12F66E2999@MN2PR03MB5167.namprd03.prod.outlook.com>

Heinz,

I can't tell you how much I appreciated your email. I firmly believe that the rules and norms of the R-help mailing list need to be respected and followed. Nevertheless, I feared that if the comments were left unquestioned people who are not familiar with BMI, its strengths weakness, and its history, might assume from the comments that the metric is worthless, and that all studies that have used it are by extension worthless. It is for this reason, and because I thought it important the people understand that the exponent of 2 in the denominator is not a arbitrary value, but rather a value with a reason that I replied. 

I hope that the larger list community will forgive the liberty I have taken with the listerver's norms. I also hope that none of the people who were part of the email chain were personally offended by my comments.

John




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________________
From: Heinz Tuechler <tuechler at gmx.at>
Sent: Monday, March 1, 2021 6:26 PM
To: Sorkin, John; Jim Lemon; Richard O'Keefe; T. A. Milne via R-help; Abby Spurdle
Subject: Re: [R] Image processing in R for BMI calculation

Dear All,

since Bert Gunter correctly stated that the discussion is off topic, I
answer to you only.
In my view John and Abby made very reasonable comments, while
particularly the link
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.npr.org%2Ftemplates%2Fstory%2Fstory.php%3FstoryId%3D106268439&amp;data=04%7C01%7Cjsorkin%40som.umaryland.edu%7Cd5d29291516a4b5c84d408d8dd096c00%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637502379829397742%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=MKCnjEzFyRmCrO6Efxo0s%2BTJ4cV%2B3m1FPy61MPwptE8%3D&amp;reserved=0
mentioned in the note of T. Arthur Milne seems remarkably superficial -
maybe it's just a joke?

Some examples:
"Moreover, it ignores waist size, which is a clear indicator of obesity
level." Without reference to hip?

"Because the majority of people today (and in Quetelet's time) lead
fairly sedentary lives ..." 200 years ago?

"Because the BMI is a single number between 1 and 100 (like a
percentage) ..." Try to imagine a BMI of 1, or of 100. The BMI will be
between 1 and 100, but 1 to 100 will not be its range.

"It suggests there are distinct categories of underweight, ideal,
overweight and obese, with sharp boundaries that hinge on a decimal
place." Why should categories be implied by the BMI itself?

"It is embarrassing for one of the most scientifically, technologically
and medicinally advanced nations in the world ..." That's true, at least
for my eyes. When I visited the USA, I had the impression that in many
cases you don't need a measure at all.

best regards,

Heinz

Sorkin, John wrote/hat geschrieben on/am 01.03.2021 22:42:
> Colleagues,
>
> BMI has is failures, but it has demonstrated utility. BMI predicts multiple outcome measures including cardiovascular disease and mortality. Don't through out a useful metric because it is not the perfect metric.
>
> As to why BMI is computed as weight/height^2, it can be shown that dividing height by the square of weight decreases the correlation between weight and height. The optimum exponent (i.e. the power that most effectively minimizes the correlation between weight and height) is not the same in men and women and it differs by race. In general an exponent of 2.0 is best for men; for women an exponent of 2.2 is a bit better than 2.0.
>
> In any event, don't let the perfect get in the way of the good.
>
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Jim Lemon <drjimlemon at gmail.com>
> Sent: Monday, March 1, 2021 4:23 PM
> To: Richard O'Keefe; r-help mailing list
> Subject: Re: [R] Image processing in R for BMI calculation
>
> I must agree with the criticism of BMI as a diagnostic index. It is
> easy to tell if a person is - ahem - wide and not very high with a
> single glance. These elementary parameters can easily be deduced from
> an image of said person. However, it does not convey that essential
> ratio of muscle to - ahem - adipose tissue that is the stated reason
> for its prominence. I suggest an older, but more valid, index that was
> used in the identification of witches. Simply tie the person's hands
> behind their back and throw him or her into the deep end of the pool.
> Time to drowning is the response variable and I am certain that those
> now chastised for their adipose tissue will vastly prefer it.
>
> Jim
>
> On Mon, Mar 1, 2021 at 10:24 PM Richard O'Keefe <raoknz at gmail.com> wrote:
>>
>> "Body Mass Index" is a rather bizarre thing:
>> body.mass.in.kg / height.in.m^2
>> I have never been able to find any biological
>> or physical meaning for this.  Yet clinicians
>> are solemnly advised to measure the weight to
>> the nearest 0.1kg and the height to the
>> nearest 0.1cm.
>>
>> How do you propose to determine the weight from
>> a single image?  Even an R package cannot perform magic.
>>
>>
>> On Mon, 1 Mar 2021 at 05:39, Paul Bernal <paulbernal07 at gmail.com> wrote:
>>
>>> Hello everyone,
>>>
>>> Does anyone know about any package for image processing, for example, to
>>> calculate body mass index pased on a picture, silouette or image.
>>>
>>> Any guidance will be greatly appreciated.
>>>
>>> Best regards,
>>>
>>> Paul
>>>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  2 02:55:18 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 01 Mar 2021 17:55:18 -0800
Subject: [R] Help Required for R Markdown function.
In-Reply-To: <078a01d70e1d$bd9cf6a0$38d6e3e0$@verizon.net>
References: <CANDYgEO8V+q0YL8qNV5bHefD2zhcqPEYMz7KDJ5uA5NOWsbOHw@mail.gmail.com>
 <CAKZQJMBjRG2HSNYmQdKEy9DMC8ZnzUuKTaL2h1inrcfQJRtL0A@mail.gmail.com>
 <078a01d70e1d$bd9cf6a0$38d6e3e0$@verizon.net>
Message-ID: <E4F3964C-B7E2-4332-854C-63DF2A38CD75@dcn.davis.ca.us>

It is standard for install.packages to download packages into a temporary directory before actually installing them. That message has been there for many many years every time you install a contributed package.

You have not provided a complete copy of the errors that were generated... I am certain something else happened that was in the output you failed to show us.

While I think RStudio is a fine tool, it does sometimes make non-trivial changes to standard outputs... I recommend that you try things in RGui or R from the command line (in this case the install.packages call) and describe them as such when asking for help here to reduce possible confusion as to where the problem is coming from. If it works in RGui but not in RStudio then you probably need to get help in their community forum.

Also, don't hijack conversation threads... start your own to ask a question, and reply to it as needed. Even changing the subject line doesn't disconnect your question from the original thread in the archive (or most email programs).

On February 28, 2021 2:04:52 PM PST, Avi Gross via R-help <r-help at r-project.org> wrote:
>I am sure you can get more done with a caret than a stick. I need a
>stick for another problem, though.
>
>A serious question. I somehow upset my R/RSTUDIO setup while trying to
>see why a markdown only allowed me to save an HTML version, not PDF and
>DOC as it used to. It now fails on any such document with a code that
>indicates it is not set to find a CRAN mirror:
>
>It seems to be upset by a simple call to get the tidyverse loaded and
>may succeed in one sense but not continue:
>
>" Installing package into
>?C:/Users/avid2016/Documents/R/win-library/4.0?
>(as ?lib? is unspecified)
>trying URL
>'https://cran.rstudio.com/bin/windows/contrib/4.0/tidyverse_1.3.0.zip'
>Content type 'application/zip' length 439972 bytes (429 KB)
>downloaded 429 KB
>
>package ?tidyverse? successfully unpacked and MD5 sums checked
>..."
>
>The R Markdown lower console window says:
>
>"Error in contrib.url(repos, "source") : trying to use CRAN without
>setting a mirror calls <Anonymous> ...
>withVisible -> eval -> eval install.packages -> contrib.url Exection
>halted"
>
>I have done some work that failed. I am running on windows with the
>latest versions of both R and RSTUDIO after removing all old versions
>and re-installing both. I have seen hints I need to set some
>definitions in a .Rprofile or so and tried but it continues to fail. So
>I now can knit nothing!
>
>Anyone have a pointer on problems like this? My next attempt would be
>to reinstall the programs on another hard disk entirely in case the
>problem is in my folder structure of ~/R and below but I dod not want
>to toss years of work because of one errant configuration file or the
>lack thereof.
>
>Thanks in advance for any advice. It may be something trivial such as
>kit not knowing where to place a library so it puts it into a temp
>area?
>
>Avi
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of John Kane
>Sent: Saturday, February 27, 2021 3:07 PM
>To: Kishor raut <rautkishor01 at gmail.com>
>Cc: R. Help Mailing List <r-help at r-project.org>
>Subject: Re: [R] Help Required for R Markdown function.
>
>The "confusionMatrix" function appears to be from the 'caret' package.
>Have you loaded 'caret' with the library(caret) command?
>
>On Sat, 27 Feb 2021 at 14:20, Kishor raut <rautkishor01 at gmail.com>
>wrote:
>
>> Respected Sir,
>>
>> I Mr Kishor Tried to get help online but wont found the solution so 
>> writting an email.
>>
>> Step1: While writting in rmarkdown all codes get executted very well 
>> till the fuction Confusionmatrix were written on it.
>>
>> Step2: As confusionmatrix command inserted following error is on 
>> screen board
>>
>>
>> processing file: RMarkdown.Rmd
>>   |.....                                                             
>   |
>>   7%
>>   ordinary text without R code
>>
>>   |.........                                                         
>   |
>>  13%
>> label: unnamed-chunk-1
>>   |..............                                                    
>   |
>>  20%
>>   ordinary text without R code
>>
>>   |...................                                               
>   |
>>  27%
>> label: unnamed-chunk-2
>>   |.......................                                           
>   |
>>  33%
>>   ordinary text without R code
>>
>>   |............................                                      
>   |
>>  40%
>> label: unnamed-chunk-3
>>   |.................................                                 
>   |
>>  47%
>>   ordinary text without R code
>>
>>   |.....................................                             
>   |
>>  53%
>> label: unnamed-chunk-4
>>   |..........................................                        
>   |
>>  60%
>>   ordinary text without R code
>>
>>   |...............................................                   
>   |
>>  67%
>> label: unnamed-chunk-5
>>   |...................................................               
>   |
>>  73%
>>   ordinary text without R code
>>
>>   |........................................................          
>   |
>>  80%
>> label: unnamed-chunk-6
>>   |.............................................................     
>   |
>>  87%
>>   ordinary text without R code
>>
>>   |................................................................. 
>   |
>>  93%
>> label: unnamed-chunk-7
>> Quitting from lines 98-104 (RMarkdown.Rmd) Error in 
>> confusionMatrix(p1, train$CTestresult) :
>>   could not find function "confusionMatrix"
>> Calls: <Anonymous> ... handle -> withCallingHandlers -> withVisible
>-> 
>> eval
>> -> eval
>>
>> Execution halted
>>
>> Step4: As codes were written these
>>
>>
>> Using function ?sample? the data takes into sample of the specified 
>> size from the stored data ```{r}
>> set.seed(1234)
>> ind<-sample(2,nrow(FEVER1),replace=TRUE, pro = c(0.7,0.3)) 
>> train<-FEVER1[ind==1,] test<-FEVER1[ind==2,] ```
>>
>> Application of Random Forest
>>
>> ```{r}
>> library(randomForest)
>> set.seed(123)
>> rfmodel<-randomForest(CTestresult~.,data = train,prox=TRUE)    #
>Random
>> Forest Model
>> plot(rfmodel,main="RandomForest Model")
>> print(rfmodel,train)                    # Printing Outcome of 'model
>for
>> Training Data
>>
>> ```
>>
>> Prediction using Randome Forest Model
>> ```{r}
>> # Prediction  of RandomForest Intial Model for Test and Train Data
>>
>> ptrain1<-predict(rfmodel,train)              # Predicting model
>Prediction
>> On Training Data
>>   # First Six Outcomes with prediction
>> head(ptrain1)                              # Printing First Six
>Prediction
>> using Random Forest Model
>> head(train$CTestresult)                       # Printing First Six
>(6)
>> Actual outcomes
>>
>> ```
>>
>>
>> Tuning Model:
>> Tuning of Machine learning model is important step for building good 
>> model for best outcome of research.
>>
>> ```{r}
>> # Tunning RandomForest  Model using Algorithm
>>
>> t<-tuneRF(train[,-11],train$CTestresult, mtryStart = 2,ntreeTry =
>100, 
>> stepFactor =2,improve = 0.051,trace = TRUE, plot = TRUE, doBest=TRUE)
>>
>>
>> ```
>>
>> Building New Model:
>>
>> New model was build on the basis of tunned model parameters and
>controls.
>>
>> ```{r}
>> # New Model After Tuning Random Forest Model
>>
>> rf1<-randomForest(CTestresult~.,data = train,ntree = 100, mtry = 8, 
>> importance = TRUE,proximity = TRUE)
>>
>> print(rf1)
>> ```
>>
>> Prediction and Confusion MAtrix:
>>
>> outcome of model will mesuare with the help of predictive outcomes 
>> with the help of confusion matrix.
>>
>> ```{r}
>> # Prediction using Random Forest and Confusion Matrix for Train Data
>> p1<-predict(rf1,train)
>> cmatrix<-confusionMatrix(p1,train$CTestresult)
>> cmatrix
>>
>>
>> ```
>>
>>
>> I will great thank full if you will help me for to remove the error.
>>
>>
>>
>>
>> --
>> *Kind Regards*
>>
>> Kishor Raut
>> *Cell No.-07387706552*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>--
>John Kane
>Kingston ON Canada
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From nz@h@@m @end|ng |rom gm@||@com  Tue Mar  2 08:38:58 2021
From: nz@h@@m @end|ng |rom gm@||@com (Shaami)
Date: Tue, 2 Mar 2021 12:38:58 +0500
Subject: [R] vector values substitution in an expression using label_bquote
 in ggplot()
Message-ID: <CAGR+MS7Z+DCa6OeH=oe6ikNwXaBk0VhvKmeOG=f+cTt5FZ1cGw@mail.gmail.com>

Dear Sir

I am using label_bquote() for labeling facet plots in ggplot(). I need to
write the expression a_[12], a_[13] etc for each plot. I am writing as

ggplot() + facet_grid(..., labeller=label_bquote(rows = a[1, 2:3])

The above exemplary code writes only a_[12] for each facet plot.

Could anyone please guide me about that?
Thank you

Shaami

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Wed Mar  3 12:00:08 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Wed, 3 Mar 2021 19:00:08 +0800
Subject: [R] Column-by-column division
Message-ID: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>

I have a 10 x 2 matrix x. Like to divide the first column by s[1] and 
second column by s[2]. The following lines work but are clumsy. Any 
idea? Thanks.

 > x
 ????? [,1] [,2]
 ?[1,]??? 1?? 11
 ?[2,]??? 2?? 12
 ?[3,]??? 3?? 13
 ?[4,]??? 4?? 14
 ?[5,]??? 5?? 15
 ?[6,]??? 6?? 16
 ?[7,]??? 7?? 17
 ?[8,]??? 8?? 18
 ?[9,]??? 9?? 19
[10,]?? 10?? 20
 > s
[1] 1 2
 > t(t(x)/s)
 ????? [,1] [,2]
 ?[1,]??? 1? 5.5
 ?[2,]??? 2? 6.0
 ?[3,]??? 3? 6.5
 ?[4,]??? 4? 7.0
 ?[5,]??? 5? 7.5
 ?[6,]??? 6? 8.0
 ?[7,]??? 7? 8.5
 ?[8,]??? 8? 9.0
 ?[9,]??? 9? 9.5
[10,]?? 10 10.0


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Mar  3 12:12:57 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Mar 2021 11:12:57 +0000
Subject: [R] Column-by-column division
In-Reply-To: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
References: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
Message-ID: <912227ef-441e-b5f6-8ed7-6af6164f17b5@sapo.pt>

Hello,

Maybe define an infix operator?


`%!%` <- function(x, y) {
   stopifnot(ncol(x) == length(y))
   t(t(x)/y)
}

x <- matrix(1:20, ncol = 2)
s <- 1:2

x %!% s
x %!% 1:4


Hope this helps,

Rui Barradas

?s 11:00 de 03/03/21, Steven Yen escreveu:
> I have a 10 x 2 matrix x. Like to divide the first column by s[1] and 
> second column by s[2]. The following lines work but are clumsy. Any 
> idea? Thanks.
> 
>  > x
>  ????? [,1] [,2]
>  ?[1,]??? 1?? 11
>  ?[2,]??? 2?? 12
>  ?[3,]??? 3?? 13
>  ?[4,]??? 4?? 14
>  ?[5,]??? 5?? 15
>  ?[6,]??? 6?? 16
>  ?[7,]??? 7?? 17
>  ?[8,]??? 8?? 18
>  ?[9,]??? 9?? 19
> [10,]?? 10?? 20
>  > s
> [1] 1 2
>  > t(t(x)/s)
>  ????? [,1] [,2]
>  ?[1,]??? 1? 5.5
>  ?[2,]??? 2? 6.0
>  ?[3,]??? 3? 6.5
>  ?[4,]??? 4? 7.0
>  ?[5,]??? 5? 7.5
>  ?[6,]??? 6? 8.0
>  ?[7,]??? 7? 8.5
>  ?[8,]??? 8? 9.0
>  ?[9,]??? 9? 9.5
> [10,]?? 10 10.0
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Mar  3 12:16:39 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Mar 2021 11:16:39 +0000
Subject: [R] Column-by-column division
In-Reply-To: <912227ef-441e-b5f6-8ed7-6af6164f17b5@sapo.pt>
References: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
 <912227ef-441e-b5f6-8ed7-6af6164f17b5@sapo.pt>
Message-ID: <f880a902-b1ff-4f21-e63c-37135c0160ac@sapo.pt>

Hello,

I forgot about sweep:


sweep(x, 2, s, '/')
sweep(x, 2, 1:4, '/')


Hope this helps,

Rui Barradas

?s 11:12 de 03/03/21, Rui Barradas escreveu:
> Hello,
> 
> Maybe define an infix operator?
> 
> 
> `%!%` <- function(x, y) {
>  ? stopifnot(ncol(x) == length(y))
>  ? t(t(x)/y)
> }
> 
> x <- matrix(1:20, ncol = 2)
> s <- 1:2
> 
> x %!% s
> x %!% 1:4
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 11:00 de 03/03/21, Steven Yen escreveu:
>> I have a 10 x 2 matrix x. Like to divide the first column by s[1] and 
>> second column by s[2]. The following lines work but are clumsy. Any 
>> idea? Thanks.
>>
>> ?> x
>> ?????? [,1] [,2]
>> ??[1,]??? 1?? 11
>> ??[2,]??? 2?? 12
>> ??[3,]??? 3?? 13
>> ??[4,]??? 4?? 14
>> ??[5,]??? 5?? 15
>> ??[6,]??? 6?? 16
>> ??[7,]??? 7?? 17
>> ??[8,]??? 8?? 18
>> ??[9,]??? 9?? 19
>> [10,]?? 10?? 20
>> ?> s
>> [1] 1 2
>> ?> t(t(x)/s)
>> ?????? [,1] [,2]
>> ??[1,]??? 1? 5.5
>> ??[2,]??? 2? 6.0
>> ??[3,]??? 3? 6.5
>> ??[4,]??? 4? 7.0
>> ??[5,]??? 5? 7.5
>> ??[6,]??? 6? 8.0
>> ??[7,]??? 7? 8.5
>> ??[8,]??? 8? 9.0
>> ??[9,]??? 9? 9.5
>> [10,]?? 10 10.0
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Wed Mar  3 12:40:17 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Wed, 3 Mar 2021 19:40:17 +0800
Subject: [R] Column-by-column division
In-Reply-To: <f880a902-b1ff-4f21-e63c-37135c0160ac@sapo.pt>
References: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
 <912227ef-441e-b5f6-8ed7-6af6164f17b5@sapo.pt>
 <f880a902-b1ff-4f21-e63c-37135c0160ac@sapo.pt>
Message-ID: <bc80bd3b-3925-d755-0b37-f290e9bec4e8@ntu.edu.tw>

Thanks to all. sweep is convenient.

On 2021/3/3 ?? 07:16, Rui Barradas wrote:
> Hello,
>
> I forgot about sweep:
>
>
> sweep(x, 2, s, '/')
> sweep(x, 2, 1:4, '/')
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:12 de 03/03/21, Rui Barradas escreveu:
>> Hello,
>>
>> Maybe define an infix operator?
>>
>>
>> `%!%` <- function(x, y) {
>> ?? stopifnot(ncol(x) == length(y))
>> ?? t(t(x)/y)
>> }
>>
>> x <- matrix(1:20, ncol = 2)
>> s <- 1:2
>>
>> x %!% s
>> x %!% 1:4
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 11:00 de 03/03/21, Steven Yen escreveu:
>>> I have a 10 x 2 matrix x. Like to divide the first column by s[1] 
>>> and second column by s[2]. The following lines work but are clumsy. 
>>> Any idea? Thanks.
>>>
>>> ?> x
>>> ?????? [,1] [,2]
>>> ??[1,]??? 1?? 11
>>> ??[2,]??? 2?? 12
>>> ??[3,]??? 3?? 13
>>> ??[4,]??? 4?? 14
>>> ??[5,]??? 5?? 15
>>> ??[6,]??? 6?? 16
>>> ??[7,]??? 7?? 17
>>> ??[8,]??? 8?? 18
>>> ??[9,]??? 9?? 19
>>> [10,]?? 10?? 20
>>> ?> s
>>> [1] 1 2
>>> ?> t(t(x)/s)
>>> ?????? [,1] [,2]
>>> ??[1,]??? 1? 5.5
>>> ??[2,]??? 2? 6.0
>>> ??[3,]??? 3? 6.5
>>> ??[4,]??? 4? 7.0
>>> ??[5,]??? 5? 7.5
>>> ??[6,]??? 6? 8.0
>>> ??[7,]??? 7? 8.5
>>> ??[8,]??? 8? 9.0
>>> ??[9,]??? 9? 9.5
>>> [10,]?? 10 10.0
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Wed Mar  3 12:15:36 2021
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Wed, 3 Mar 2021 11:15:36 +0000
Subject: [R] Column-by-column division
In-Reply-To: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
References: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
Message-ID: <cc9cf8ca4c7a4a4381dabfde18a7602f@cambiumassessment.com>

To make sure the scalar is used instead of using the recycled vector s, maybe like this 

x <- matrix(1:20, nrow=10)
s <- c(1,2)
sapply(1:2, function(i) x[,i]/s[i])

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
Sent: Wednesday, March 3, 2021 6:00 AM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] Column-by-column division

I have a 10 x 2 matrix x. Like to divide the first column by s[1] and second column by s[2]. The following lines work but are clumsy. Any idea? Thanks.

 > x
 ????? [,1] [,2]
 ?[1,]??? 1?? 11
 ?[2,]??? 2?? 12
 ?[3,]??? 3?? 13
 ?[4,]??? 4?? 14
 ?[5,]??? 5?? 15
 ?[6,]??? 6?? 16
 ?[7,]??? 7?? 17
 ?[8,]??? 8?? 18
 ?[9,]??? 9?? 19
[10,]?? 10?? 20
 > s
[1] 1 2
 > t(t(x)/s)
 ????? [,1] [,2]
 ?[1,]??? 1? 5.5
 ?[2,]??? 2? 6.0
 ?[3,]??? 3? 6.5
 ?[4,]??? 4? 7.0
 ?[5,]??? 5? 7.5
 ?[6,]??? 6? 8.0
 ?[7,]??? 7? 8.5
 ?[8,]??? 8? 9.0
 ?[9,]??? 9? 9.5
[10,]?? 10 10.0

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com  Wed Mar  3 16:24:37 2021
From: g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com (Gayathri Nagarajan)
Date: Wed, 3 Mar 2021 07:24:37 -0800
Subject: [R] A tibble with date column appears different in shiny
Message-ID: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>

Hi Team

I have a tibble like the below :

class(us_counties)
[1] "tbl_df"     "tbl"        "data.frame"

head(us_counties)
# A tibble: 6 x 8
  date       deaths Todays_deaths county state fips
  <date>      <dbl>         <dbl> <chr>  <chr> <chr>
1 2020-03-19      0             0 Abbev~ Sout~ 45001
2 2020-03-20      0             0 Abbev~ Sout~ 45001
3 2020-03-21      0             0 Abbev~ Sout~ 45001
4 2020-03-22      0             0 Abbev~ Sout~ 45001
5 2020-03-23      0             0 Abbev~ Sout~ 45001
6 2020-03-24      0             0 Abbev~ Sout~ 45001

str(us_counties)
tibble [1,082,715 x 8] (S3: tbl_df/tbl/data.frame)
 $ date         : Date[1:1082715], format: "2020-03-19" ...
 $ deaths       : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
 $ Todays_deaths: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
 $ county       : chr [1:1082715] "Abbeville" "Abbeville" "Abbeville"
"Abbeville" ...
 $ state        : chr [1:1082715] "South Carolina" "South Carolina" "South
Carolina" "South Carolina" ...
 $ fips         : chr [1:1082715] "45001" "45001" "45001" "45001" ...
 $ cases        : num [1:1082715] 1 1 1 1 1 1 3 4 4 4 ...
 $ Todays_cases : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
 - attr(*, "spec")=
  .. cols(
  ..   date = col_date(format = ""),
  ..   county = col_character(),
  ..   state = col_character(),
  ..   fips = col_character(),
  ..   cases = col_double(),
  ..   deaths = col_double()
  .. )
 - attr(*, ".internal.selfref")=<externalptr>
>



Now when I display this in shiny UI using a simple  command:


   # Generate an HTML table view of the data ----
   output$ttable <- renderTable({
       head(us_counties
            , n = input$obs)
   })


I get a display like the below

datedeathsTodays_deathscountystatefipscasesTodays_cases
18679.00 34.00 0.00 Abbeville South Carolina 45001 2184.00 0.00
18680.00 34.00 0.00 Abbeville South Carolina 45001 2191.00 0.00
18681.00 34.00 0.00 Abbeville South Carolina 45001 2192.00 0.00

This is the change I made

old code
========
 #x <- getURL("
https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
")
  #us_counties <- read.csv(text = x)
  # 855612 Rows , 6 columns class(us_counties)


this stopped working, so I changed to below


  urlfile="
https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
"
  #GN added 3/3
  us_counties<-read_csv(url(urlfile),col_types = list(date = col_date()))

 Please let me know how to correct this

Regards
Gayathri

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Mar  3 17:25:04 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Mar 2021 16:25:04 +0000
Subject: [R] A tibble with date column appears different in shiny
In-Reply-To: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
References: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
Message-ID: <6a952e4a-dde4-f1d0-fa0d-43df77510326@sapo.pt>

Hello,

Your col_types argument is wrong, you only have col_date.


library(tidyverse)

urlfile <- 
"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
#GN added 3/3
cols_spec <- cols(
   date = col_date(format = ""),
   county = col_character(),
   state = col_character(),
   fips = col_character(),
   cases = col_double(),
   deaths = col_double()
)

us_counties <- read_csv(url(urlfile), col_types = cols_spec)


Hope this helps,

Rui Barradas

?s 15:24 de 03/03/21, Gayathri Nagarajan escreveu:
> Hi Team
> 
> I have a tibble like the below :
> 
> class(us_counties)
> [1] "tbl_df"     "tbl"        "data.frame"
> 
> head(us_counties)
> # A tibble: 6 x 8
>    date       deaths Todays_deaths county state fips
>    <date>      <dbl>         <dbl> <chr>  <chr> <chr>
> 1 2020-03-19      0             0 Abbev~ Sout~ 45001
> 2 2020-03-20      0             0 Abbev~ Sout~ 45001
> 3 2020-03-21      0             0 Abbev~ Sout~ 45001
> 4 2020-03-22      0             0 Abbev~ Sout~ 45001
> 5 2020-03-23      0             0 Abbev~ Sout~ 45001
> 6 2020-03-24      0             0 Abbev~ Sout~ 45001
> 
> str(us_counties)
> tibble [1,082,715 x 8] (S3: tbl_df/tbl/data.frame)
>   $ date         : Date[1:1082715], format: "2020-03-19" ...
>   $ deaths       : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>   $ Todays_deaths: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>   $ county       : chr [1:1082715] "Abbeville" "Abbeville" "Abbeville"
> "Abbeville" ...
>   $ state        : chr [1:1082715] "South Carolina" "South Carolina" "South
> Carolina" "South Carolina" ...
>   $ fips         : chr [1:1082715] "45001" "45001" "45001" "45001" ...
>   $ cases        : num [1:1082715] 1 1 1 1 1 1 3 4 4 4 ...
>   $ Todays_cases : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>   - attr(*, "spec")=
>    .. cols(
>    ..   date = col_date(format = ""),
>    ..   county = col_character(),
>    ..   state = col_character(),
>    ..   fips = col_character(),
>    ..   cases = col_double(),
>    ..   deaths = col_double()
>    .. )
>   - attr(*, ".internal.selfref")=<externalptr>
>>
> 
> 
> 
> Now when I display this in shiny UI using a simple  command:
> 
> 
>     # Generate an HTML table view of the data ----
>     output$ttable <- renderTable({
>         head(us_counties
>              , n = input$obs)
>     })
> 
> 
> I get a display like the below
> 
> datedeathsTodays_deathscountystatefipscasesTodays_cases
> 18679.00 34.00 0.00 Abbeville South Carolina 45001 2184.00 0.00
> 18680.00 34.00 0.00 Abbeville South Carolina 45001 2191.00 0.00
> 18681.00 34.00 0.00 Abbeville South Carolina 45001 2192.00 0.00
> 
> This is the change I made
> 
> old code
> ========
>   #x <- getURL("
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> ")
>    #us_counties <- read.csv(text = x)
>    # 855612 Rows , 6 columns class(us_counties)
> 
> 
> this stopped working, so I changed to below
> 
> 
>    urlfile="
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> "
>    #GN added 3/3
>    us_counties<-read_csv(url(urlfile),col_types = list(date = col_date()))
> 
>   Please let me know how to correct this
> 
> Regards
> Gayathri
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From er|cjberger @end|ng |rom gm@||@com  Wed Mar  3 21:18:35 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 3 Mar 2021 15:18:35 -0500
Subject: [R] Column-by-column division
In-Reply-To: <cc9cf8ca4c7a4a4381dabfde18a7602f@cambiumassessment.com>
References: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
 <cc9cf8ca4c7a4a4381dabfde18a7602f@cambiumassessment.com>
Message-ID: <CAGgJW74qkxXSTt9rCJ7zpYE8ju6brdh=gfqHF6aFWc3N5efsOQ@mail.gmail.com>

Why not use standard matrix multiplication which is straightforward here:

x %*% diag(1/s)

HTH,
Eric


On Wed, Mar 3, 2021 at 7:13 AM Harold Doran <
harold.doran at cambiumassessment.com> wrote:

> To make sure the scalar is used instead of using the recycled vector s,
> maybe like this
>
> x <- matrix(1:20, nrow=10)
> s <- c(1,2)
> sapply(1:2, function(i) x[,i]/s[i])
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Steven Yen
> Sent: Wednesday, March 3, 2021 6:00 AM
> To: R-help Mailing List <r-help at r-project.org>
> Subject: [R] Column-by-column division
>
> I have a 10 x 2 matrix x. Like to divide the first column by s[1] and
> second column by s[2]. The following lines work but are clumsy. Any idea?
> Thanks.
>
>  > x
>        [,1] [,2]
>   [1,]    1   11
>   [2,]    2   12
>   [3,]    3   13
>   [4,]    4   14
>   [5,]    5   15
>   [6,]    6   16
>   [7,]    7   17
>   [8,]    8   18
>   [9,]    9   19
> [10,]   10   20
>  > s
> [1] 1 2
>  > t(t(x)/s)
>        [,1] [,2]
>   [1,]    1  5.5
>   [2,]    2  6.0
>   [3,]    3  6.5
>   [4,]    4  7.0
>   [5,]    5  7.5
>   [6,]    6  8.0
>   [7,]    7  8.5
>   [8,]    8  9.0
>   [9,]    9  9.5
> [10,]   10 10.0
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Wed Mar  3 21:46:50 2021
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Wed, 3 Mar 2021 20:46:50 +0000
Subject: [R] Column-by-column division
In-Reply-To: <CAGgJW74qkxXSTt9rCJ7zpYE8ju6brdh=gfqHF6aFWc3N5efsOQ@mail.gmail.com>
References: <97051aa1-865c-6a8c-cf75-947a2cb8e34e@ntu.edu.tw>
 <cc9cf8ca4c7a4a4381dabfde18a7602f@cambiumassessment.com>
 <CAGgJW74qkxXSTt9rCJ7zpYE8ju6brdh=gfqHF6aFWc3N5efsOQ@mail.gmail.com>
Message-ID: <a481267462cc4f719189133e95bb4df8@cambiumassessment.com>

Some timings of the different suggestions below

> library(microbenchmark)
> x <- matrix(1:20, nrow=10)
> s <- c(1,2)
> option1 <- sapply(1:2, function(i) x[,i]/s[i])
> option2 <- x %*% diag(1/s)
> option3 <- sweep(x, 2, s, '/')
> all.equal(option1,option2)
[1] TRUE
> all.equal(option2,option3)
[1] TRUE
> microbenchmark(sapply(1:2, function(i) x[,i]/s[i]), x %*% diag(1/s), sweep(x, 2, s, '/'))
Unit: microseconds
                                 expr    min      lq     mean  median     uq      max neval
sapply(1:2, function(i) x[, i]/s[i]) 18.425 19.8800 37.42147 21.5765 22.789 1583.518   100
                      x %*% diag(1/s)  1.456  2.1830  2.86150  2.9100  3.395    9.213   100
                  sweep(x, 2, s, "/") 32.486 34.1825 37.31964 35.3950 36.364  131.395   100

From: Eric Berger <ericjberger at gmail.com>
Sent: Wednesday, March 3, 2021 3:19 PM
To: Harold Doran <harold.doran at cambiumassessment.com>
Cc: Steven Yen <styen at ntu.edu.tw>; R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] Column-by-column division

Why not use standard matrix multiplication which is straightforward here:

x %*% diag(1/s)

HTH,
Eric


On Wed, Mar 3, 2021 at 7:13 AM Harold Doran <harold.doran at cambiumassessment.com<mailto:harold.doran at cambiumassessment.com>> wrote:
To make sure the scalar is used instead of using the recycled vector s, maybe like this

x <- matrix(1:20, nrow=10)
s <- c(1,2)
sapply(1:2, function(i) x[,i]/s[i])

-----Original Message-----
From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Steven Yen
Sent: Wednesday, March 3, 2021 6:00 AM
To: R-help Mailing List <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: [R] Column-by-column division

I have a 10 x 2 matrix x. Like to divide the first column by s[1] and second column by s[2]. The following lines work but are clumsy. Any idea? Thanks.

 > x
       [,1] [,2]
  [1,]    1   11
  [2,]    2   12
  [3,]    3   13
  [4,]    4   14
  [5,]    5   15
  [6,]    6   16
  [7,]    7   17
  [8,]    8   18
  [9,]    9   19
[10,]   10   20
 > s
[1] 1 2
 > t(t(x)/s)
       [,1] [,2]
  [1,]    1  5.5
  [2,]    2  6.0
  [3,]    3  6.5
  [4,]    4  7.0
  [5,]    5  7.5
  [6,]    6  8.0
  [7,]    7  8.5
  [8,]    8  9.0
  [9,]    9  9.5
[10,]   10 10.0

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dr@@|@m@o|@ng| @end|ng |rom gm@||@com  Thu Mar  4 10:52:28 2021
From: dr@@|@m@o|@ng| @end|ng |rom gm@||@com (Shah Alam)
Date: Thu, 4 Mar 2021 10:52:28 +0100
Subject: [R] Warning messages while parallel computing
Message-ID: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>

Hello everyone,

I am using the "parallel" R package for parallel computation.

Code:

   # set number of cores
    cl <- makeCluster(8, type = "PSOCK")  # Mac/Linux need to set as "FORK"

      # pass functions and objects to the cluster environment and set seed
      # all the items exported need to stay in the global environment!!
      clusterCall(cl, function() { source("xx.R" )})
      clusterExport(cl, list("a", "b", "c", "d",
                             "5"))
      clusterSetRNGStream(cl, 1)

While parallel processing, I receive the following warning signs.  Do I
need to ignore these signs or do they potentially slow the whole process?

 *  Warning signs:*
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 19
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 18
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 17
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 16
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 15
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 14
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 13
Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 12

Best regards,
Shah Alam

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Thu Mar  4 13:36:06 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Thu, 4 Mar 2021 20:36:06 +0800
Subject: [R] Warning messages while parallel computing
In-Reply-To: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
References: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
Message-ID: <CAGiFhPMQEahzJoNTEm-T3m3f-GmHCwpkreU7uKhPhgjB9gVghQ@mail.gmail.com>

Hi Shah,

The error usually means you started a cluster and forgot to close it. From
the code you post, I cannot see any problem. Maybe you run `makeCluster`
twice by accident?

Best,
Jiefei

On Thu, Mar 4, 2021 at 5:53 PM Shah Alam <dr.alamsolangi at gmail.com> wrote:

> Hello everyone,
>
> I am using the "parallel" R package for parallel computation.
>
> Code:
>
>    # set number of cores
>     cl <- makeCluster(8, type = "PSOCK")  # Mac/Linux need to set as "FORK"
>
>       # pass functions and objects to the cluster environment and set seed
>       # all the items exported need to stay in the global environment!!
>       clusterCall(cl, function() { source("xx.R" )})
>       clusterExport(cl, list("a", "b", "c", "d",
>                              "5"))
>       clusterSetRNGStream(cl, 1)
>
> While parallel processing, I receive the following warning signs.  Do I
> need to ignore these signs or do they potentially slow the whole process?
>
>  *  Warning signs:*
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 19
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 18
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 17
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 16
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 15
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 14
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 13
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 12
>
> Best regards,
> Shah Alam
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com  Thu Mar  4 14:53:54 2021
From: g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com (Gayathri Nagarajan)
Date: Thu, 4 Mar 2021 05:53:54 -0800
Subject: [R] A tibble with date column appears different in shiny
In-Reply-To: <6a952e4a-dde4-f1d0-fa0d-43df77510326@sapo.pt>
References: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
 <6a952e4a-dde4-f1d0-fa0d-43df77510326@sapo.pt>
Message-ID: <CANt+qPh129LnG=u5jfSF+ZAbU_wKdj5_O+PyBHxNTj_fMMVx9g@mail.gmail.com>

Hi Rui

I have tried the same but this is not working.

when I do head(us_counties), I clearly see this is a date,in R studio
console

head(us_counties)
         date deaths Todays_deaths    county          state  fips
1: 2020-03-19      0             0 Abbeville South Carolina 45001
2: 2020-03-20      0             0 Abbeville South Carolina 45001
3: 2020-03-21      0             0 Abbeville South Carolina 45001
4: 2020-03-22      0             0 Abbeville South Carolina 45001
5: 2020-03-23      0             0 Abbeville South Carolina 45001
6: 2020-03-24      0             0 Abbeville South Carolina 45001
   cases Todays_cases

But the moment this appears in shiny UI, this displays like

date deaths Todays_deaths county state fips cases Todays_cases
18340.00 0.00 0.00 Abbeville South Carolina 45001 1.00 0.00
18341.00 0.00 0.00 Abbeville South Carolina 45001 1.00 0.00



Regards
Gayathri


On Wed, 3 Mar 2021 at 08:25, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Your col_types argument is wrong, you only have col_date.
>
>
> library(tidyverse)
>
> urlfile <-
> "
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> "
> #GN added 3/3
> cols_spec <- cols(
>    date = col_date(format = ""),
>    county = col_character(),
>    state = col_character(),
>    fips = col_character(),
>    cases = col_double(),
>    deaths = col_double()
> )
>
> us_counties <- read_csv(url(urlfile), col_types = cols_spec)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 15:24 de 03/03/21, Gayathri Nagarajan escreveu:
> > Hi Team
> >
> > I have a tibble like the below :
> >
> > class(us_counties)
> > [1] "tbl_df"     "tbl"        "data.frame"
> >
> > head(us_counties)
> > # A tibble: 6 x 8
> >    date       deaths Todays_deaths county state fips
> >    <date>      <dbl>         <dbl> <chr>  <chr> <chr>
> > 1 2020-03-19      0             0 Abbev~ Sout~ 45001
> > 2 2020-03-20      0             0 Abbev~ Sout~ 45001
> > 3 2020-03-21      0             0 Abbev~ Sout~ 45001
> > 4 2020-03-22      0             0 Abbev~ Sout~ 45001
> > 5 2020-03-23      0             0 Abbev~ Sout~ 45001
> > 6 2020-03-24      0             0 Abbev~ Sout~ 45001
> >
> > str(us_counties)
> > tibble [1,082,715 x 8] (S3: tbl_df/tbl/data.frame)
> >   $ date         : Date[1:1082715], format: "2020-03-19" ...
> >   $ deaths       : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
> >   $ Todays_deaths: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
> >   $ county       : chr [1:1082715] "Abbeville" "Abbeville" "Abbeville"
> > "Abbeville" ...
> >   $ state        : chr [1:1082715] "South Carolina" "South Carolina"
> "South
> > Carolina" "South Carolina" ...
> >   $ fips         : chr [1:1082715] "45001" "45001" "45001" "45001" ...
> >   $ cases        : num [1:1082715] 1 1 1 1 1 1 3 4 4 4 ...
> >   $ Todays_cases : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
> >   - attr(*, "spec")=
> >    .. cols(
> >    ..   date = col_date(format = ""),
> >    ..   county = col_character(),
> >    ..   state = col_character(),
> >    ..   fips = col_character(),
> >    ..   cases = col_double(),
> >    ..   deaths = col_double()
> >    .. )
> >   - attr(*, ".internal.selfref")=<externalptr>
> >>
> >
> >
> >
> > Now when I display this in shiny UI using a simple  command:
> >
> >
> >     # Generate an HTML table view of the data ----
> >     output$ttable <- renderTable({
> >         head(us_counties
> >              , n = input$obs)
> >     })
> >
> >
> > I get a display like the below
> >
> > datedeathsTodays_deathscountystatefipscasesTodays_cases
> > 18679.00 34.00 0.00 Abbeville South Carolina 45001 2184.00 0.00
> > 18680.00 34.00 0.00 Abbeville South Carolina 45001 2191.00 0.00
> > 18681.00 34.00 0.00 Abbeville South Carolina 45001 2192.00 0.00
> >
> > This is the change I made
> >
> > old code
> > ========
> >   #x <- getURL("
> >
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> > ")
> >    #us_counties <- read.csv(text = x)
> >    # 855612 Rows , 6 columns class(us_counties)
> >
> >
> > this stopped working, so I changed to below
> >
> >
> >    urlfile="
> >
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> > "
> >    #GN added 3/3
> >    us_counties<-read_csv(url(urlfile),col_types = list(date =
> col_date()))
> >
> >   Please let me know how to correct this
> >
> > Regards
> > Gayathri
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Mar  4 17:40:59 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 4 Mar 2021 16:40:59 +0000
Subject: [R] A tibble with date column appears different in shiny
In-Reply-To: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
References: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
Message-ID: <0c6a1e8c-8695-bd75-e589-b1b7ac26fbcb@sapo.pt>

Hello,

This is a known issue with renderTable. Show the results with 
renderDataTable instead.

Hope this helps,

Rui Barradas

?s 15:24 de 03/03/21, Gayathri Nagarajan escreveu:
> Hi Team
> 
> I have a tibble like the below :
> 
> class(us_counties)
> [1] "tbl_df"     "tbl"        "data.frame"
> 
> head(us_counties)
> # A tibble: 6 x 8
>    date       deaths Todays_deaths county state fips
>    <date>      <dbl>         <dbl> <chr>  <chr> <chr>
> 1 2020-03-19      0             0 Abbev~ Sout~ 45001
> 2 2020-03-20      0             0 Abbev~ Sout~ 45001
> 3 2020-03-21      0             0 Abbev~ Sout~ 45001
> 4 2020-03-22      0             0 Abbev~ Sout~ 45001
> 5 2020-03-23      0             0 Abbev~ Sout~ 45001
> 6 2020-03-24      0             0 Abbev~ Sout~ 45001
> 
> str(us_counties)
> tibble [1,082,715 x 8] (S3: tbl_df/tbl/data.frame)
>   $ date         : Date[1:1082715], format: "2020-03-19" ...
>   $ deaths       : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>   $ Todays_deaths: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>   $ county       : chr [1:1082715] "Abbeville" "Abbeville" "Abbeville"
> "Abbeville" ...
>   $ state        : chr [1:1082715] "South Carolina" "South Carolina" "South
> Carolina" "South Carolina" ...
>   $ fips         : chr [1:1082715] "45001" "45001" "45001" "45001" ...
>   $ cases        : num [1:1082715] 1 1 1 1 1 1 3 4 4 4 ...
>   $ Todays_cases : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>   - attr(*, "spec")=
>    .. cols(
>    ..   date = col_date(format = ""),
>    ..   county = col_character(),
>    ..   state = col_character(),
>    ..   fips = col_character(),
>    ..   cases = col_double(),
>    ..   deaths = col_double()
>    .. )
>   - attr(*, ".internal.selfref")=<externalptr>
>>
> 
> 
> 
> Now when I display this in shiny UI using a simple  command:
> 
> 
>     # Generate an HTML table view of the data ----
>     output$ttable <- renderTable({
>         head(us_counties
>              , n = input$obs)
>     })
> 
> 
> I get a display like the below
> 
> datedeathsTodays_deathscountystatefipscasesTodays_cases
> 18679.00 34.00 0.00 Abbeville South Carolina 45001 2184.00 0.00
> 18680.00 34.00 0.00 Abbeville South Carolina 45001 2191.00 0.00
> 18681.00 34.00 0.00 Abbeville South Carolina 45001 2192.00 0.00
> 
> This is the change I made
> 
> old code
> ========
>   #x <- getURL("
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> ")
>    #us_counties <- read.csv(text = x)
>    # 855612 Rows , 6 columns class(us_counties)
> 
> 
> this stopped working, so I changed to below
> 
> 
>    urlfile="
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> "
>    #GN added 3/3
>    us_counties<-read_csv(url(urlfile),col_types = list(date = col_date()))
> 
>   Please let me know how to correct this
> 
> Regards
> Gayathri
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dyk|m7411 @end|ng |rom gm@||@com  Thu Mar  4 14:41:42 2021
From: dyk|m7411 @end|ng |rom gm@||@com (DY Kim)
Date: Thu, 4 Mar 2021 08:41:42 -0500
Subject: [R] Adding a title to a plot
Message-ID: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>

Greetings!

I am currently using R x64 4.0.4.

I used the box-cox power transformation to create a range of lambdas and
log-likelihood values using the equation.

b1=boxcox (DV ~ IV1 + IV2, data= newdata)

The above codes automatically created a plot with lambdas and
log-likelihood values.

I want to add a main and subtitle to the plot. Would you please provide me
with codes? Any help would be appreciated. Thank you.

	[[alternative HTML version deleted]]


From dm@thew@63 @end|ng |rom e@rth||nk@net  Thu Mar  4 17:02:43 2021
From: dm@thew@63 @end|ng |rom e@rth||nk@net (Dick Mathews)
Date: Thu, 4 Mar 2021 08:02:43 -0800
Subject: [R] problem downloading R
Message-ID: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>

I am trying to download the Windows version of R. This computer is Win7, 
I do have Win10 computers also.

Tried R4.0.4, got message these files are corrupted.

Then tried R4.0.3, got same message as above.

Tried the next, R4.0.2, got same message.

I checked to see if I was downloading the proper version, seems okay.

What is the problem? Can anybody help me with this?

Dick Mathews


From er|cjberger @end|ng |rom gm@||@com  Thu Mar  4 18:05:06 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 4 Mar 2021 12:05:06 -0500
Subject: [R] Adding a title to a plot
In-Reply-To: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>
References: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>
Message-ID: <CAGgJW77GOGays2xzrZ=sPo=fAY3a91a_j6XeXYRA672SoV87ww@mail.gmail.com>

Untested

b1=boxcox( DV ~ IV1 + IV2, data= newdata, main="My main title\n My
Subtitle")



On Thu, Mar 4, 2021 at 11:56 AM DY Kim <dykim7411 at gmail.com> wrote:

> Greetings!
>
> I am currently using R x64 4.0.4.
>
> I used the box-cox power transformation to create a range of lambdas and
> log-likelihood values using the equation.
>
> b1=boxcox (DV ~ IV1 + IV2, data= newdata)
>
> The above codes automatically created a plot with lambdas and
> log-likelihood values.
>
> I want to add a main and subtitle to the plot. Would you please provide me
> with codes? Any help would be appreciated. Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Mar  4 18:17:42 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 04 Mar 2021 09:17:42 -0800
Subject: [R] problem downloading R
In-Reply-To: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
References: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
Message-ID: <0E0AEE48-E3FB-41D8-89CF-ABF3FADC7348@dcn.davis.ca.us>

Not much. Try a different mirror site. Try disabling anti-virus download filters. If you are using a cloud-backed directory like OneDrive, try downloading and installing on a standard local disk.

On March 4, 2021 8:02:43 AM PST, Dick Mathews <dmathews63 at earthlink.net> wrote:
>I am trying to download the Windows version of R. This computer is
>Win7, 
>I do have Win10 computers also.
>
>Tried R4.0.4, got message these files are corrupted.
>
>Then tried R4.0.3, got same message as above.
>
>Tried the next, R4.0.2, got same message.
>
>I checked to see if I was downloading the proper version, seems okay.
>
>What is the problem? Can anybody help me with this?
>
>Dick Mathews
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Mar  4 18:21:46 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 4 Mar 2021 12:21:46 -0500
Subject: [R] problem downloading R
In-Reply-To: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
References: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
Message-ID: <11fd4149-4372-5962-4a9c-476750bd4e8e@gmail.com>

On 04/03/2021 11:02 a.m., Dick Mathews wrote:
> I am trying to download the Windows version of R. This computer is Win7,
> I do have Win10 computers also.
> 
> Tried R4.0.4, got message these files are corrupted.
> 
> Then tried R4.0.3, got same message as above.
> 
> Tried the next, R4.0.2, got same message.
> 
> I checked to see if I was downloading the proper version, seems okay.
> 
> What is the problem? Can anybody help me with this?

Which mirror are you using?  I'd recommend using cloud.r-project.org . 
If you get the same problem on that mirror, then you've likely got 
something interfering with your download.  You could try using a 
different machine to download, and install from a USB stick or some 
other non-network method.

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Mar  4 18:30:07 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 4 Mar 2021 12:30:07 -0500
Subject: [R] Adding a title to a plot
In-Reply-To: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>
References: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>
Message-ID: <d53f25cc-781f-93e1-9974-368bb358d845@gmail.com>

On 04/03/2021 8:41 a.m., DY Kim wrote:
> Greetings!
> 
> I am currently using R x64 4.0.4.
> 
> I used the box-cox power transformation to create a range of lambdas and
> log-likelihood values using the equation.
> 
> b1=boxcox (DV ~ IV1 + IV2, data= newdata)
> 
> The above codes automatically created a plot with lambdas and
> log-likelihood values.
> 
> I want to add a main and subtitle to the plot. Would you please provide me
> with codes? Any help would be appreciated. Thank you.

The MASS:::boxcox.default method doesn't support adding a title.  If you 
want one, you'll have to edit the function to put in a title in the call 
to plot().  For example:

   boxcox.default <- MASS:::boxcox.default
   fix(boxcox.default)

and then edit this line

   plot(xl, loglik, xlab = xlab, ylab = ylab, type = "l",
             ylim = range(loglik, lim))

to

   plot(xl, loglik, xlab = xlab, ylab = ylab, type = "l",
             ylim = range(loglik, lim), main = "My title")

and save the result.  (You could make a slightly more sophisticated 
change such as adding "main" as an argument to the function, and using 
"main = main" in the call to plot(). )

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Mar  4 18:38:23 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 4 Mar 2021 12:38:23 -0500
Subject: [R] Adding a title to a plot
In-Reply-To: <d53f25cc-781f-93e1-9974-368bb358d845@gmail.com>
References: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>
 <d53f25cc-781f-93e1-9974-368bb358d845@gmail.com>
Message-ID: <5c6b5fc8-6442-f8fd-581f-589aa1a78d2c@gmail.com>

Wow, that was an unnecessarily complicated suggestion.

Just run

  title("My title")

after running boxcox().

Duncan Murdoch

On 04/03/2021 12:30 p.m., Duncan Murdoch wrote:
> On 04/03/2021 8:41 a.m., DY Kim wrote:
>> Greetings!
>>
>> I am currently using R x64 4.0.4.
>>
>> I used the box-cox power transformation to create a range of lambdas and
>> log-likelihood values using the equation.
>>
>> b1=boxcox (DV ~ IV1 + IV2, data= newdata)
>>
>> The above codes automatically created a plot with lambdas and
>> log-likelihood values.
>>
>> I want to add a main and subtitle to the plot. Would you please provide me
>> with codes? Any help would be appreciated. Thank you.
> 
> The MASS:::boxcox.default method doesn't support adding a title.  If you
> want one, you'll have to edit the function to put in a title in the call
> to plot().  For example:
> 
>     boxcox.default <- MASS:::boxcox.default
>     fix(boxcox.default)
> 
> and then edit this line
> 
>     plot(xl, loglik, xlab = xlab, ylab = ylab, type = "l",
>               ylim = range(loglik, lim))
> 
> to
> 
>     plot(xl, loglik, xlab = xlab, ylab = ylab, type = "l",
>               ylim = range(loglik, lim), main = "My title")
> 
> and save the result.  (You could make a slightly more sophisticated
> change such as adding "main" as an argument to the function, and using
> "main = main" in the call to plot(). )
> 
> Duncan Murdoch
>


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Mar  4 18:57:45 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 4 Mar 2021 09:57:45 -0800
Subject: [R] Warning messages while parallel computing
In-Reply-To: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
References: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
Message-ID: <CAHqSRuRCC8ywM8UusCHfKgvtFt_-C-56WAGjEn+YVvb7PwGRpQ@mail.gmail.com>

To avoid the warnings from gc(), call parallel::stopCluster(cl) before
removing or overwriting cl.

-Bill

On Thu, Mar 4, 2021 at 1:52 AM Shah Alam <dr.alamsolangi at gmail.com> wrote:
>
> Hello everyone,
>
> I am using the "parallel" R package for parallel computation.
>
> Code:
>
>    # set number of cores
>     cl <- makeCluster(8, type = "PSOCK")  # Mac/Linux need to set as "FORK"
>
>       # pass functions and objects to the cluster environment and set seed
>       # all the items exported need to stay in the global environment!!
>       clusterCall(cl, function() { source("xx.R" )})
>       clusterExport(cl, list("a", "b", "c", "d",
>                              "5"))
>       clusterSetRNGStream(cl, 1)
>
> While parallel processing, I receive the following warning signs.  Do I
> need to ignore these signs or do they potentially slow the whole process?
>
>  *  Warning signs:*
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 19
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 18
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 17
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 16
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 15
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 14
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 13
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 12
>
> Best regards,
> Shah Alam
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Mar  4 19:12:34 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 4 Mar 2021 10:12:34 -0800
Subject: [R] Warning messages while parallel computing
In-Reply-To: <CAHqSRuRCC8ywM8UusCHfKgvtFt_-C-56WAGjEn+YVvb7PwGRpQ@mail.gmail.com>
References: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
 <CAHqSRuRCC8ywM8UusCHfKgvtFt_-C-56WAGjEn+YVvb7PwGRpQ@mail.gmail.com>
Message-ID: <CAFDcVCThe0tjfu++uBfE_XtyzOC-nSjZHeS0gdAXh_fLKfXn2w@mail.gmail.com>

I don't think 'parallel' is to blame in this case. Those warnings:

Warning in for (i in seq_len(Ne + echo)) { :
  closing unused connection 19

come from base::source()
[https://github.com/wch/r-source/blob/9caddc1eaad1f480283f1e98af34a328699d1869/src/library/base/R/source.R#L166-L244].

Unless there's a bug in source() that leaves connections open, which
is unlikely, I think there's something in the 'xx.R' script that opens
a connection but doesn't close it.  Possibly multiple times.  A good
check is to see if the same warnings are produced when calling
source("xx.R") sequentially in a for() loop or an lapply() call.

Hope this helps,

Henrik

On Thu, Mar 4, 2021 at 9:58 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> To avoid the warnings from gc(), call parallel::stopCluster(cl) before
> removing or overwriting cl.
>
> -Bill
>
> On Thu, Mar 4, 2021 at 1:52 AM Shah Alam <dr.alamsolangi at gmail.com> wrote:
> >
> > Hello everyone,
> >
> > I am using the "parallel" R package for parallel computation.
> >
> > Code:
> >
> >    # set number of cores
> >     cl <- makeCluster(8, type = "PSOCK")  # Mac/Linux need to set as "FORK"
> >
> >       # pass functions and objects to the cluster environment and set seed
> >       # all the items exported need to stay in the global environment!!
> >       clusterCall(cl, function() { source("xx.R" )})
> >       clusterExport(cl, list("a", "b", "c", "d",
> >                              "5"))
> >       clusterSetRNGStream(cl, 1)
> >
> > While parallel processing, I receive the following warning signs.  Do I
> > need to ignore these signs or do they potentially slow the whole process?
> >
> >  *  Warning signs:*
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 19
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 18
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 17
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 16
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 15
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 14
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 13
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 12
> >
> > Best regards,
> > Shah Alam
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Mar  4 19:20:32 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 4 Mar 2021 10:20:32 -0800
Subject: [R] Warning messages while parallel computing
In-Reply-To: <CAFDcVCThe0tjfu++uBfE_XtyzOC-nSjZHeS0gdAXh_fLKfXn2w@mail.gmail.com>
References: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
 <CAHqSRuRCC8ywM8UusCHfKgvtFt_-C-56WAGjEn+YVvb7PwGRpQ@mail.gmail.com>
 <CAFDcVCThe0tjfu++uBfE_XtyzOC-nSjZHeS0gdAXh_fLKfXn2w@mail.gmail.com>
Message-ID: <CAHqSRuQA4quaB+Gc1p3juECq6116GROLwTQNXpgjn79PChqYOA@mail.gmail.com>

The warnings come from the garbage collector, which may be called from
almost anywhere.  It is possible that the file that is sourced causes
the problem, but if you don't call parallel::stopCluster before
removing the cluster object you will get those warnings.

> cl <- parallel::makeCluster(3, type="PSOCK")
> invisible(gc())
> rm(cl)
> invisible(gc())
Warning messages:
1: In .Internal(gc(verbose, reset, full)) :
  closing unused connection 6 (<-Bill-T490:11216)
2: In .Internal(gc(verbose, reset, full)) :
  closing unused connection 5 (<-Bill-T490:11216)
3: In .Internal(gc(verbose, reset, full)) :
  closing unused connection 4 (<-Bill-T490:11216)
>
>
> cl <- parallel::makeCluster(3, type="PSOCK")
> invisible(gc())
> parallel::stopCluster(cl)
> invisible(gc())
> rm(cl)
> invisible(gc())
>

The fact that he got 8 warnings when playing a cluster of size 8 makes
me suspect that omitting stopCluster is the problem.

-Bill

On Thu, Mar 4, 2021 at 10:12 AM Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
>
> I don't think 'parallel' is to blame in this case. Those warnings:
>
> Warning in for (i in seq_len(Ne + echo)) { :
>   closing unused connection 19
>
> come from base::source()
> [https://github.com/wch/r-source/blob/9caddc1eaad1f480283f1e98af34a328699d1869/src/library/base/R/source.R#L166-L244].
>
> Unless there's a bug in source() that leaves connections open, which
> is unlikely, I think there's something in the 'xx.R' script that opens
> a connection but doesn't close it.  Possibly multiple times.  A good
> check is to see if the same warnings are produced when calling
> source("xx.R") sequentially in a for() loop or an lapply() call.
>
> Hope this helps,
>
> Henrik
>
> On Thu, Mar 4, 2021 at 9:58 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
> >
> > To avoid the warnings from gc(), call parallel::stopCluster(cl) before
> > removing or overwriting cl.
> >
> > -Bill
> >
> > On Thu, Mar 4, 2021 at 1:52 AM Shah Alam <dr.alamsolangi at gmail.com> wrote:
> > >
> > > Hello everyone,
> > >
> > > I am using the "parallel" R package for parallel computation.
> > >
> > > Code:
> > >
> > >    # set number of cores
> > >     cl <- makeCluster(8, type = "PSOCK")  # Mac/Linux need to set as "FORK"
> > >
> > >       # pass functions and objects to the cluster environment and set seed
> > >       # all the items exported need to stay in the global environment!!
> > >       clusterCall(cl, function() { source("xx.R" )})
> > >       clusterExport(cl, list("a", "b", "c", "d",
> > >                              "5"))
> > >       clusterSetRNGStream(cl, 1)
> > >
> > > While parallel processing, I receive the following warning signs.  Do I
> > > need to ignore these signs or do they potentially slow the whole process?
> > >
> > >  *  Warning signs:*
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 19
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 18
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 17
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 16
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 15
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 14
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 13
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 12
> > >
> > > Best regards,
> > > Shah Alam
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Mar  4 20:23:34 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 4 Mar 2021 13:23:34 -0600
Subject: [R] Adding a title to a plot
In-Reply-To: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>
References: <CADmwX-Jy3tT3LeagyBrKfcy70h4SJdLTLcUraR9H+PnmUxw=uQ@mail.gmail.com>
Message-ID: <009d01d7112b$dee6c2d0$9cb44870$@sbcglobal.net>

Kim

See plot.boxcox function which has main = NULL, sub = NULL arguments

Jeff

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of DY Kim
Sent: Thursday, March 4, 2021 7:42 AM
To: r-help at r-project.org
Subject: [R] Adding a title to a plot

Greetings!

I am currently using R x64 4.0.4.

I used the box-cox power transformation to create a range of lambdas and
log-likelihood values using the equation.

b1=boxcox (DV ~ IV1 + IV2, data= newdata)

The above codes automatically created a plot with lambdas and log-likelihood
values.

I want to add a main and subtitle to the plot. Would you please provide me
with codes? Any help would be appreciated. Thank you.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Mar  4 20:27:58 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 4 Mar 2021 11:27:58 -0800
Subject: [R] Warning messages while parallel computing
In-Reply-To: <CAHqSRuQA4quaB+Gc1p3juECq6116GROLwTQNXpgjn79PChqYOA@mail.gmail.com>
References: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
 <CAHqSRuRCC8ywM8UusCHfKgvtFt_-C-56WAGjEn+YVvb7PwGRpQ@mail.gmail.com>
 <CAFDcVCThe0tjfu++uBfE_XtyzOC-nSjZHeS0gdAXh_fLKfXn2w@mail.gmail.com>
 <CAHqSRuQA4quaB+Gc1p3juECq6116GROLwTQNXpgjn79PChqYOA@mail.gmail.com>
Message-ID: <CAFDcVCRFWEGK3i-5pNMYyiuWpEO2zX7AzE1gx9wbBMGRgeNsqw@mail.gmail.com>

Test with:

clusterCall(cl, function() { suppressWarnings(source("xx.R")) })

If the warnings disappear, then the warnings are produced on the
workers from source():ing the file.

/Henrik

On Thu, Mar 4, 2021 at 10:20 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> The warnings come from the garbage collector, which may be called from
> almost anywhere.  It is possible that the file that is sourced causes
> the problem, but if you don't call parallel::stopCluster before
> removing the cluster object you will get those warnings.
>
> > cl <- parallel::makeCluster(3, type="PSOCK")
> > invisible(gc())
> > rm(cl)
> > invisible(gc())
> Warning messages:
> 1: In .Internal(gc(verbose, reset, full)) :
>   closing unused connection 6 (<-Bill-T490:11216)
> 2: In .Internal(gc(verbose, reset, full)) :
>   closing unused connection 5 (<-Bill-T490:11216)
> 3: In .Internal(gc(verbose, reset, full)) :
>   closing unused connection 4 (<-Bill-T490:11216)
> >
> >
> > cl <- parallel::makeCluster(3, type="PSOCK")
> > invisible(gc())
> > parallel::stopCluster(cl)
> > invisible(gc())
> > rm(cl)
> > invisible(gc())
> >
>
> The fact that he got 8 warnings when playing a cluster of size 8 makes
> me suspect that omitting stopCluster is the problem.
>
> -Bill
>
> On Thu, Mar 4, 2021 at 10:12 AM Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
> >
> > I don't think 'parallel' is to blame in this case. Those warnings:
> >
> > Warning in for (i in seq_len(Ne + echo)) { :
> >   closing unused connection 19
> >
> > come from base::source()
> > [https://github.com/wch/r-source/blob/9caddc1eaad1f480283f1e98af34a328699d1869/src/library/base/R/source.R#L166-L244].
> >
> > Unless there's a bug in source() that leaves connections open, which
> > is unlikely, I think there's something in the 'xx.R' script that opens
> > a connection but doesn't close it.  Possibly multiple times.  A good
> > check is to see if the same warnings are produced when calling
> > source("xx.R") sequentially in a for() loop or an lapply() call.
> >
> > Hope this helps,
> >
> > Henrik
> >
> > On Thu, Mar 4, 2021 at 9:58 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
> > >
> > > To avoid the warnings from gc(), call parallel::stopCluster(cl) before
> > > removing or overwriting cl.
> > >
> > > -Bill
> > >
> > > On Thu, Mar 4, 2021 at 1:52 AM Shah Alam <dr.alamsolangi at gmail.com> wrote:
> > > >
> > > > Hello everyone,
> > > >
> > > > I am using the "parallel" R package for parallel computation.
> > > >
> > > > Code:
> > > >
> > > >    # set number of cores
> > > >     cl <- makeCluster(8, type = "PSOCK")  # Mac/Linux need to set as "FORK"
> > > >
> > > >       # pass functions and objects to the cluster environment and set seed
> > > >       # all the items exported need to stay in the global environment!!
> > > >       clusterCall(cl, function() { source("xx.R" )})
> > > >       clusterExport(cl, list("a", "b", "c", "d",
> > > >                              "5"))
> > > >       clusterSetRNGStream(cl, 1)
> > > >
> > > > While parallel processing, I receive the following warning signs.  Do I
> > > > need to ignore these signs or do they potentially slow the whole process?
> > > >
> > > >  *  Warning signs:*
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 19
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 18
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 17
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 16
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 15
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 14
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 13
> > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > >   closing unused connection 12
> > > >
> > > > Best regards,
> > > > Shah Alam
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Mar  4 20:37:15 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 4 Mar 2021 11:37:15 -0800
Subject: [R] Warning messages while parallel computing
In-Reply-To: <CAFDcVCRFWEGK3i-5pNMYyiuWpEO2zX7AzE1gx9wbBMGRgeNsqw@mail.gmail.com>
References: <CA+bivFhiWAcs9=_-qQM4OZvdt9xjbtsBcqkCd=nJrryeUy-dCQ@mail.gmail.com>
 <CAHqSRuRCC8ywM8UusCHfKgvtFt_-C-56WAGjEn+YVvb7PwGRpQ@mail.gmail.com>
 <CAFDcVCThe0tjfu++uBfE_XtyzOC-nSjZHeS0gdAXh_fLKfXn2w@mail.gmail.com>
 <CAHqSRuQA4quaB+Gc1p3juECq6116GROLwTQNXpgjn79PChqYOA@mail.gmail.com>
 <CAFDcVCRFWEGK3i-5pNMYyiuWpEO2zX7AzE1gx9wbBMGRgeNsqw@mail.gmail.com>
Message-ID: <CAHqSRuT8cEggHLn4PYjoDyXikR82SBk=HZDQmxiS97Hc-aHZ6Q@mail.gmail.com>

Perhaps just try
    source("xx.R")
    invisible(gc()) # do warnings appear after this?
It does seem likely that the sourced file causes the problem, since
parallel::createCluster labels the connections "<host name>:<process
id>" and that label would show up in the warning.

On Thu, Mar 4, 2021 at 11:28 AM Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
>
> Test with:
>
> clusterCall(cl, function() { suppressWarnings(source("xx.R")) })
>
> If the warnings disappear, then the warnings are produced on the
> workers from source():ing the file.
>
> /Henrik
>
> On Thu, Mar 4, 2021 at 10:20 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
> >
> > The warnings come from the garbage collector, which may be called from
> > almost anywhere.  It is possible that the file that is sourced causes
> > the problem, but if you don't call parallel::stopCluster before
> > removing the cluster object you will get those warnings.
> >
> > > cl <- parallel::makeCluster(3, type="PSOCK")
> > > invisible(gc())
> > > rm(cl)
> > > invisible(gc())
> > Warning messages:
> > 1: In .Internal(gc(verbose, reset, full)) :
> >   closing unused connection 6 (<-Bill-T490:11216)
> > 2: In .Internal(gc(verbose, reset, full)) :
> >   closing unused connection 5 (<-Bill-T490:11216)
> > 3: In .Internal(gc(verbose, reset, full)) :
> >   closing unused connection 4 (<-Bill-T490:11216)
> > >
> > >
> > > cl <- parallel::makeCluster(3, type="PSOCK")
> > > invisible(gc())
> > > parallel::stopCluster(cl)
> > > invisible(gc())
> > > rm(cl)
> > > invisible(gc())
> > >
> >
> > The fact that he got 8 warnings when playing a cluster of size 8 makes
> > me suspect that omitting stopCluster is the problem.
> >
> > -Bill
> >
> > On Thu, Mar 4, 2021 at 10:12 AM Henrik Bengtsson
> > <henrik.bengtsson at gmail.com> wrote:
> > >
> > > I don't think 'parallel' is to blame in this case. Those warnings:
> > >
> > > Warning in for (i in seq_len(Ne + echo)) { :
> > >   closing unused connection 19
> > >
> > > come from base::source()
> > > [https://github.com/wch/r-source/blob/9caddc1eaad1f480283f1e98af34a328699d1869/src/library/base/R/source.R#L166-L244].
> > >
> > > Unless there's a bug in source() that leaves connections open, which
> > > is unlikely, I think there's something in the 'xx.R' script that opens
> > > a connection but doesn't close it.  Possibly multiple times.  A good
> > > check is to see if the same warnings are produced when calling
> > > source("xx.R") sequentially in a for() loop or an lapply() call.
> > >
> > > Hope this helps,
> > >
> > > Henrik
> > >
> > > On Thu, Mar 4, 2021 at 9:58 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
> > > >
> > > > To avoid the warnings from gc(), call parallel::stopCluster(cl) before
> > > > removing or overwriting cl.
> > > >
> > > > -Bill
> > > >
> > > > On Thu, Mar 4, 2021 at 1:52 AM Shah Alam <dr.alamsolangi at gmail.com> wrote:
> > > > >
> > > > > Hello everyone,
> > > > >
> > > > > I am using the "parallel" R package for parallel computation.
> > > > >
> > > > > Code:
> > > > >
> > > > >    # set number of cores
> > > > >     cl <- makeCluster(8, type = "PSOCK")  # Mac/Linux need to set as "FORK"
> > > > >
> > > > >       # pass functions and objects to the cluster environment and set seed
> > > > >       # all the items exported need to stay in the global environment!!
> > > > >       clusterCall(cl, function() { source("xx.R" )})
> > > > >       clusterExport(cl, list("a", "b", "c", "d",
> > > > >                              "5"))
> > > > >       clusterSetRNGStream(cl, 1)
> > > > >
> > > > > While parallel processing, I receive the following warning signs.  Do I
> > > > > need to ignore these signs or do they potentially slow the whole process?
> > > > >
> > > > >  *  Warning signs:*
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 19
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 18
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 17
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 16
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 15
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 14
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 13
> > > > > Warning in for (i in seq_len(Ne + echo)) { :
> > > > >   closing unused connection 12
> > > > >
> > > > > Best regards,
> > > > > Shah Alam
> > > > >
> > > > >         [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com  Fri Mar  5 06:51:05 2021
From: g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com (Gayathri Nagarajan)
Date: Thu, 4 Mar 2021 21:51:05 -0800
Subject: [R] A tibble with date column appears different in shiny
In-Reply-To: <0c6a1e8c-8695-bd75-e589-b1b7ac26fbcb@sapo.pt>
References: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
 <0c6a1e8c-8695-bd75-e589-b1b7ac26fbcb@sapo.pt>
Message-ID: <CANt+qPichHQE9P-SEGb71Q5=WhgY-fy6TK+yJOvxROX9ZKO7Xg@mail.gmail.com>

Hi Rui

Tried renderDatatable, but now my shiny UI shows Blank for my tibble. Not
sure what Iam missing suddenly when this was working fine a day back.

The one change I did was:

x <- getURL("
https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
")
us_counties <- read.csv(text = x)

Error in function (type, msg, asError = TRUE)  :
  error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol
version

Hence had to change this to :


  urlfile="
https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
"
  #GN added 3/3
  #GN comment 3/4
  #us_counties<-read_csv(url(urlfile),col_types = list(date = col_date()))
  #GN Add 3/4
  #GN added 3/3
  cols_spec <- cols(
    date = col_date(format = ""),
    county = col_character(),
    state = col_character(),
    fips = col_character(),
    cases = col_double(),
    deaths = col_double()
  )

  us_counties <- read_csv(url(urlfile), col_types = cols_spec)
 ===========================


Regards
Gayathri


On Thu, 4 Mar 2021 at 08:41, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> This is a known issue with renderTable. Show the results with
> renderDataTable instead.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 15:24 de 03/03/21, Gayathri Nagarajan escreveu:
> > Hi Team
> >
> > I have a tibble like the below :
> >
> > class(us_counties)
> > [1] "tbl_df"     "tbl"        "data.frame"
> >
> > head(us_counties)
> > # A tibble: 6 x 8
> >    date       deaths Todays_deaths county state fips
> >    <date>      <dbl>         <dbl> <chr>  <chr> <chr>
> > 1 2020-03-19      0             0 Abbev~ Sout~ 45001
> > 2 2020-03-20      0             0 Abbev~ Sout~ 45001
> > 3 2020-03-21      0             0 Abbev~ Sout~ 45001
> > 4 2020-03-22      0             0 Abbev~ Sout~ 45001
> > 5 2020-03-23      0             0 Abbev~ Sout~ 45001
> > 6 2020-03-24      0             0 Abbev~ Sout~ 45001
> >
> > str(us_counties)
> > tibble [1,082,715 x 8] (S3: tbl_df/tbl/data.frame)
> >   $ date         : Date[1:1082715], format: "2020-03-19" ...
> >   $ deaths       : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
> >   $ Todays_deaths: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
> >   $ county       : chr [1:1082715] "Abbeville" "Abbeville" "Abbeville"
> > "Abbeville" ...
> >   $ state        : chr [1:1082715] "South Carolina" "South Carolina"
> "South
> > Carolina" "South Carolina" ...
> >   $ fips         : chr [1:1082715] "45001" "45001" "45001" "45001" ...
> >   $ cases        : num [1:1082715] 1 1 1 1 1 1 3 4 4 4 ...
> >   $ Todays_cases : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
> >   - attr(*, "spec")=
> >    .. cols(
> >    ..   date = col_date(format = ""),
> >    ..   county = col_character(),
> >    ..   state = col_character(),
> >    ..   fips = col_character(),
> >    ..   cases = col_double(),
> >    ..   deaths = col_double()
> >    .. )
> >   - attr(*, ".internal.selfref")=<externalptr>
> >>
> >
> >
> >
> > Now when I display this in shiny UI using a simple  command:
> >
> >
> >     # Generate an HTML table view of the data ----
> >     output$ttable <- renderTable({
> >         head(us_counties
> >              , n = input$obs)
> >     })
> >
> >
> > I get a display like the below
> >
> > datedeathsTodays_deathscountystatefipscasesTodays_cases
> > 18679.00 34.00 0.00 Abbeville South Carolina 45001 2184.00 0.00
> > 18680.00 34.00 0.00 Abbeville South Carolina 45001 2191.00 0.00
> > 18681.00 34.00 0.00 Abbeville South Carolina 45001 2192.00 0.00
> >
> > This is the change I made
> >
> > old code
> > ========
> >   #x <- getURL("
> >
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> > ")
> >    #us_counties <- read.csv(text = x)
> >    # 855612 Rows , 6 columns class(us_counties)
> >
> >
> > this stopped working, so I changed to below
> >
> >
> >    urlfile="
> >
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> > "
> >    #GN added 3/3
> >    us_counties<-read_csv(url(urlfile),col_types = list(date =
> col_date()))
> >
> >   Please let me know how to correct this
> >
> > Regards
> > Gayathri
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar  5 08:58:10 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 5 Mar 2021 20:58:10 +1300
Subject: [R] problem downloading R
In-Reply-To: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
References: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
Message-ID: <CAB8pepwgyQKffpqsFKVxSVXfbi83_4Hh3x3v+OttcEv5VV2cpQ@mail.gmail.com>

Does the following sound familiar?

The Windows installer starts installing (or decompressing) R, flashing
one file name at a time.
And then, part way through, says XXXX file is corrupt, and gives you
the choice to ignore.
And if you click ignore, then the next file does the same thing.
And one quickly realizes, that every subsequent file will have the same message.

Then if you re-download the installation file, the same thing happens.
Except that the first file flagged as corrupted, is not necessarily
the same file.


On Fri, Mar 5, 2021 at 5:55 AM Dick Mathews <dmathews63 at earthlink.net> wrote:
>
> I am trying to download the Windows version of R. This computer is Win7,
> I do have Win10 computers also.
>
> Tried R4.0.4, got message these files are corrupted.
>
> Then tried R4.0.3, got same message as above.
>
> Tried the next, R4.0.2, got same message.
>
> I checked to see if I was downloading the proper version, seems okay.
>
> What is the problem? Can anybody help me with this?
>
> Dick Mathews
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Mar  5 09:30:33 2021
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 5 Mar 2021 09:30:33 +0100
Subject: [R] problem downloading R
In-Reply-To: <CAB8pepwgyQKffpqsFKVxSVXfbi83_4Hh3x3v+OttcEv5VV2cpQ@mail.gmail.com>
References: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
 <CAB8pepwgyQKffpqsFKVxSVXfbi83_4Hh3x3v+OttcEv5VV2cpQ@mail.gmail.com>
Message-ID: <c0f9b062-5e0e-9592-e705-54059d638181@statistik.tu-dortmund.de>

Sounds like you always got corrupted vesions. Either an issue with your 
connection or the mirror. What happens if you try another mirror and 
clear your browser caches?

Best,
Uwe Ligges

On 05.03.2021 08:58, Abby Spurdle wrote:
> Does the following sound familiar?
> 
> The Windows installer starts installing (or decompressing) R, flashing
> one file name at a time.
> And then, part way through, says XXXX file is corrupt, and gives you
> the choice to ignore.
> And if you click ignore, then the next file does the same thing.
> And one quickly realizes, that every subsequent file will have the same message.
> 
> Then if you re-download the installation file, the same thing happens.
> Except that the first file flagged as corrupted, is not necessarily
> the same file.
> 
> 
> On Fri, Mar 5, 2021 at 5:55 AM Dick Mathews <dmathews63 at earthlink.net> wrote:
>>
>> I am trying to download the Windows version of R. This computer is Win7,
>> I do have Win10 computers also.
>>
>> Tried R4.0.4, got message these files are corrupted.
>>
>> Then tried R4.0.3, got same message as above.
>>
>> Tried the next, R4.0.2, got same message.
>>
>> I checked to see if I was downloading the proper version, seems okay.
>>
>> What is the problem? Can anybody help me with this?
>>
>> Dick Mathews
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Mar  5 10:14:22 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 5 Mar 2021 09:14:22 +0000
Subject: [R] quantile from quantile table calculation without original data
Message-ID: <1614935662799.60644@precheza.cz>

Dear all

I have table of quantiles, probably from lognormal distribution

 dput(temp)
temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
), row.names = c(NA, -9L), class = "data.frame")

and I need to calculate quantile for size 0.1

plot(temp$size, temp$percent, pch=19, xlim=c(0,2))
ss <- approxfun(temp$size, temp$percent)
points((0:100)/50, ss((0:100)/50))
abline(v=.1)

If I had original data it would be quite easy with ecdf/quantile function but without it I am lost what function I could use for such task.

Please, give me some hint where to look.


Best regards

Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From ruipb@rr@d@s m@iii@g oii s@po@pt  Fri Mar  5 10:15:47 2021
From: ruipb@rr@d@s m@iii@g oii s@po@pt (ruipb@rr@d@s m@iii@g oii s@po@pt)
Date: Fri, 05 Mar 2021 09:15:47 +0000
Subject: [R] A tibble with date column appears different in shiny
In-Reply-To: <CANt+qPichHQE9P-SEGb71Q5=WhgY-fy6TK+yJOvxROX9ZKO7Xg@mail.gmail.com>
References: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
 <0c6a1e8c-8695-bd75-e589-b1b7ac26fbcb@sapo.pt>
 <CANt+qPichHQE9P-SEGb71Q5=WhgY-fy6TK+yJOvxROX9ZKO7Xg@mail.gmail.com>
Message-ID: <20210305091547.Horde.RrbcliW0q7gxhZAA-ILmEz3@mail.sapo.pt>

Hello,

In

us_counties <- read.csv(text = x)

remove 'text=', you are reading from a url, not from a text string.

Hope this helps,

Rui Barradas

----- Mensagem de Gayathri Nagarajan <gayathri.nagarajan at gmail.com> ---------

  Data: Thu, 4 Mar 2021 21:51:05 -0800

  De: Gayathri Nagarajan <gayathri.nagarajan at gmail.com>

  Assunto: Re: [R] A tibble with date column appears different in shiny

  Para: Rui Barradas <ruipbarradas at sapo.pt>

> Hi Rui
>
> Tried renderDatatable, but now my shiny UI shows Blank for my  
> tibble. Not sure what Iam missing suddenly when this was working  
> fine a day back.
>
> The one change I did was:
>
> x <-  
> getURL("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv")
>
>  us_counties <- read.csv(text = x)
>
> Error in function (type, msg, asError = TRUE) ?:
>
>  ? error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert  
> protocol version
>
> Hence had to change this to :
>
> ?  
> urlfile="https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"
>
>  ? #GN added 3/3
>
>  ? #GN comment 3/4
>
>  ? #us_counties<-read_csv(url(urlfile),col_types = list(date = col_date()))
>
>  ? #GN Add 3/4
>
>  ? #GN added 3/3
>
>  ? cols_spec <- cols(
>
>  ? ? date = col_date(format = ""),
>
>  ? ? county = col_character(),
>
>  ? ? state = col_character(),
>
>  ? ? fips = col_character(),
>
>  ? ? cases = col_double(),
>
>  ? ? deaths = col_double()
>
>  ? )
>
>  ?
>
>  ? us_counties <- read_csv(url(urlfile), col_types = cols_spec)
>
>  ?===========================
>
> ?
>
> ?
>
>
>
> Regards
>
> Gayathri
>
> On Thu, 4 Mar 2021 at 08:41, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>>
>>
>>  This is a known issue with renderTable. Show the results with
>>
>>  renderDataTable instead.
>>
>>
>>
>>  Hope this helps,
>>
>>
>>
>>  Rui Barradas
>>
>>
>>
>>  ?s 15:24 de 03/03/21, Gayathri Nagarajan escreveu:
>>
>>  > Hi Team
>>
>>  >
>>
>>  > I have a tibble like the below :
>>
>>  >
>>
>>  > class(us_counties)
>>
>>  > [1] "tbl_df"? ? ?"tbl"? ? ? ? "data.frame"
>>
>>  >
>>
>>  > head(us_counties)
>>
>>  > # A tibble: 6 x 8
>>
>>  >? ? date? ? ? ?deaths Todays_deaths county state fips
>>
>>  >? ? <date>? ? ? <dbl>? ? ? ? ?<dbl> <chr>? <chr> <chr>
>>
>>  > 1 2020-03-19? ? ? 0? ? ? ? ? ? ?0 Abbev~ Sout~ 45001
>>
>>  > 2 2020-03-20? ? ? 0? ? ? ? ? ? ?0 Abbev~ Sout~ 45001
>>
>>  > 3 2020-03-21? ? ? 0? ? ? ? ? ? ?0 Abbev~ Sout~ 45001
>>
>>  > 4 2020-03-22? ? ? 0? ? ? ? ? ? ?0 Abbev~ Sout~ 45001
>>
>>  > 5 2020-03-23? ? ? 0? ? ? ? ? ? ?0 Abbev~ Sout~ 45001
>>
>>  > 6 2020-03-24? ? ? 0? ? ? ? ? ? ?0 Abbev~ Sout~ 45001
>>
>>  >
>>
>>  > str(us_counties)
>>
>>  > tibble [1,082,715 x 8] (S3: tbl_df/tbl/data.frame)
>>
>>  >? ?$ date? ? ? ? ?: Date[1:1082715], format: "2020-03-19" ...
>>
>>  >? ?$ deaths? ? ? ?: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>>
>>  >? ?$ Todays_deaths: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>>
>>  >? ?$ county? ? ? ?: chr [1:1082715] "Abbeville" "Abbeville" "Abbeville"
>>
>>  > "Abbeville" ...
>>
>>  >? ?$ state? ? ? ? : chr [1:1082715] "South Carolina" "South  
>> Carolina" "South
>>
>>  > Carolina" "South Carolina" ...
>>
>>  >? ?$ fips? ? ? ? ?: chr [1:1082715] "45001" "45001" "45001" "45001" ...
>>
>>  >? ?$ cases? ? ? ? : num [1:1082715] 1 1 1 1 1 1 3 4 4 4 ...
>>
>>  >? ?$ Todays_cases : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>>
>>  >? ?- attr(*, "spec")=
>>
>>  >? ? .. cols(
>>
>>  >? ? ..? ?date = col_date(format = ""),
>>
>>  >? ? ..? ?county = col_character(),
>>
>>  >? ? ..? ?state = col_character(),
>>
>>  >? ? ..? ?fips = col_character(),
>>
>>  >? ? ..? ?cases = col_double(),
>>
>>  >? ? ..? ?deaths = col_double()
>>
>>  >? ? .. )
>>
>>  >? ?- attr(*, ".internal.selfref")=<externalptr>
>>
>>  >>
>>
>>  >
>>
>>  >
>>
>>  >
>>
>>  > Now when I display this in shiny UI using a simple? command:
>>
>>  >
>>
>>  >
>>
>>  >? ? ?# Generate an HTML table view of the data ----
>>
>>  >? ? ?output$ttable <- renderTable({
>>
>>  >? ? ? ? ?head(us_counties
>>
>>  >? ? ? ? ? ? ? , n = input$obs)
>>
>>  >? ? ?})
>>
>>  >
>>
>>  >
>>
>>  > I get a display like the below
>>
>>  >
>>
>>  > datedeathsTodays_deathscountystatefipscasesTodays_cases
>>
>>  > 18679.00 34.00 0.00 Abbeville South Carolina 45001 2184.00 0.00
>>
>>  > 18680.00 34.00 0.00 Abbeville South Carolina 45001 2191.00 0.00
>>
>>  > 18681.00 34.00 0.00 Abbeville South Carolina 45001 2192.00 0.00
>>
>>  >
>>
>>  > This is the change I made
>>
>>  >
>>
>>  > old code
>>
>>  > ========
>>
>>  >? ?#x <- getURL("
>>
>>  >  
>> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
>>
>>  > ")
>>
>>  >? ? #us_counties <- read.csv(text = x)
>>
>>  >? ? # 855612 Rows , 6 columns class(us_counties)
>>
>>  >
>>
>>  >
>>
>>  > this stopped working, so I changed to below
>>
>>  >
>>
>>  >
>>
>>  >? ? urlfile="
>>
>>  >  
>> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
>>
>>  > "
>>
>>  >? ? #GN added 3/3
>>
>>  >? ? us_counties<-read_csv(url(urlfile),col_types = list(date =  
>> col_date()))
>>
>>  >
>>
>>  >? ?Please let me know how to correct this
>>
>>  >
>>
>>  > Regards
>>
>>  > Gayathri
>>
>>  >
>>
>>  >? ? ? ?[[alternative HTML version deleted]]
>>
>>  >
>>
>>  > ______________________________________________
>>
>>  > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>
>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>>
>>  > PLEASE do read the posting guide  
>> http://www.R-project.org/posting-guide.html
>>
>>  > and provide commented, minimal, self-contained, reproducible code.
>>
>>  >

----- Fim da mensagem de Gayathri Nagarajan  
<gayathri.nagarajan at gmail.com> -----

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Fri Mar  5 14:25:16 2021
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 5 Mar 2021 14:25:16 +0100
Subject: [R] "global parameter" warning using data.table in package.
Message-ID: <CAGAA5beG=kcQJMmnYsGMkxymPGLi=q+5akGggutAdG2n4m7E6Q@mail.gmail.com>

Hi,

  I am converting a couple of functions into a R-package. Many of the
functions use data.table.
  I have two questions using data.table in my own package.
  Normally I would put each question in separate emails but I think they
might be connected.

First question is short and I think the answer is yes.
1. Do I always need to prefix data.table each time I use something from
that package?
Eg. DT <- data.table::data.table(x=rep(c("b","a","c"),each=3), y=c(1,3,6),
v=1:9)

Second question is longer.
2.  In this small example code:
hello <- function() {
  DT <- data.table::data.table(x=rep(c("b","a","c"),each=3), y=c(1,3,6),
v=1:9)
  DT[, .(sum(v))]
}

I get these warnings from R CMD check:
hello: no visible global function definition for ?.?
hello: no visible binding for global variable ?v?
Undefined global functions or variables:
  . v

According to: vignette("datatable-importing", package = "data.table")
The solution is
hello <- function() {
  v <- NULL
  . <- NULL

And it works but looks a bit weird.
Is there a better solution?

Regards
Martin

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Fri Mar  5 14:26:32 2021
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 5 Mar 2021 14:26:32 +0100
Subject: [R] "global parameter" warning using data.table in package.
In-Reply-To: <CAGAA5beG=kcQJMmnYsGMkxymPGLi=q+5akGggutAdG2n4m7E6Q@mail.gmail.com>
References: <CAGAA5beG=kcQJMmnYsGMkxymPGLi=q+5akGggutAdG2n4m7E6Q@mail.gmail.com>
Message-ID: <CAGAA5be7Hk-ikGpnekyoDo0AjEzLa18Pn-n=xs+h-kXWPrUL5g@mail.gmail.com>

Please ignore my previous email. I just found the R-package-devel mailing
list.

On Fri, 5 Mar 2021 at 14:25, Martin M?ller Skarbiniks Pedersen <
traxplayer at gmail.com> wrote:

> Hi,
>
>   I am converting a couple of functions into a R-package. Many of the
> functions use data.table.
>   I have two questions using data.table in my own package.
>   Normally I would put each question in separate emails but I think they
> might be connected.
>
> First question is short and I think the answer is yes.
> 1. Do I always need to prefix data.table each time I use something from
> that package?
> Eg. DT <- data.table::data.table(x=rep(c("b","a","c"),each=3), y=c(1,3,6),
> v=1:9)
>
> Second question is longer.
> 2.  In this small example code:
> hello <- function() {
>   DT <- data.table::data.table(x=rep(c("b","a","c"),each=3), y=c(1,3,6),
> v=1:9)
>   DT[, .(sum(v))]
> }
>
> I get these warnings from R CMD check:
> hello: no visible global function definition for ?.?
> hello: no visible binding for global variable ?v?
> Undefined global functions or variables:
>   . v
>
> According to: vignette("datatable-importing", package = "data.table")
> The solution is
> hello <- function() {
>   v <- NULL
>   . <- NULL
>
> And it works but looks a bit weird.
> Is there a better solution?
>
> Regards
> Martin
>


-- 
Til uvedkommende, der l?ser med: Der er ingen grund til at l?se min
mail. Jeg har intet at g?re med FARC, al-Jihad, al-Qaida, Hamas, Hizb
al-Mujahidin eller ETA. Jeg har aldrig gjort Zakat, g?r ikke ind for
Istishad, har ikke lavet en bilbombe eller kernev?ben og jeg ved
d?rligt nok, hvad Al Manar og ????? betyder.  Men tak for den udviste
interesse.

Leve Ligemageriet!
Styrk p?belv?ldet!
Bevar misundelsesafgifterne og cafepengene!
Hurra for ?ldrebyrden!

	[[alternative HTML version deleted]]


From @co|we|| @end|ng |rom uogue|ph@c@  Fri Mar  5 14:42:45 2021
From: @co|we|| @end|ng |rom uogue|ph@c@ (Scott Colwell)
Date: Fri, 5 Mar 2021 13:42:45 +0000
Subject: [R] poLCA problem
Message-ID: <YT1PR01MB244344ADE1C28B38DE1EF2F8CE969@YT1PR01MB2443.CANPRD01.PROD.OUTLOOK.COM>

Good morning everyone,

I am running into errors with poLCA as follows:

Error in round(mf) : non-numeric argument to mathematical function.

Here is what I have. Both variables are coded as 1, 2, 3

df <- as.data.frame(data)

items <- c("x1", "x2")  <- there are more variables but shortened for this
purpose

df2 <- df[items]

i <- cbind(x1, x2)~1

poLCA (i, df2, nclass=2, maxiter=100, nrep=10, verbose =TRUE)

It is after the poLCA that I get the error. Any thoughts on what is causing
this?

Thanks,

Scott

	[[alternative HTML version deleted]]


From g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com  Fri Mar  5 15:35:58 2021
From: g@y@thr|@n@g@r@j@n @end|ng |rom gm@||@com (Gayathri Nagarajan)
Date: Fri, 5 Mar 2021 06:35:58 -0800
Subject: [R] A tibble with date column appears different in shiny
In-Reply-To: <CANt+qPichHQE9P-SEGb71Q5=WhgY-fy6TK+yJOvxROX9ZKO7Xg@mail.gmail.com>
References: <CANt+qPj00J5Fqza7Y9qXrHXCUGhseYFYP4Qsb1G8XjYnvMaA0w@mail.gmail.com>
 <0c6a1e8c-8695-bd75-e589-b1b7ac26fbcb@sapo.pt>
 <CANt+qPichHQE9P-SEGb71Q5=WhgY-fy6TK+yJOvxROX9ZKO7Xg@mail.gmail.com>
Message-ID: <CANt+qPhhP9ju5Gkyj+o7N0a6R3RP8LUpxKKUCXk8RtyoQ8YSDQ@mail.gmail.com>

Hi Rui

Alas, at last this worked and this is what I did :

1) I stopped debugging and started a fresh new table to display in shiny UI
using this example-https://shiny.rstudio.com/gallery/basic-datatable.html
2) Now instead of the table mpg, I plugged in my us_counties above at first
and it worked :-)

I really don't have an answer as to how this was working fine till 2 days
back with the reactive inputs I had in Shiny UI or the read.csv
<https://stackoverflow.com/questions/14441729/read-a-csv-from-github-into-r>
command for the .csv file in GITHUB.


Thanks so much to you for your help as you tried to relentlessly help me
out the past three days.
*So the conclusion is - Starting afresh with DT::dataTableOutput solved the
issue*

*Code  change*
*===============*

In UI.R:
    tabPanel(strong("Table"),DT::dataTableOutput("dumtable"))

In Server.R
output$dumtable <- DT::renderDataTable(DT::datatable({
     data <- us_counties
       data <- data[data$state == input$state,]


       data <- data[data$county == input$county,]

       data <- data[data$date >= input$date2,]

        head(data,n=input$obs)
   }))
   ====================



Regards
Gayathri


On Thu, 4 Mar 2021 at 21:51, Gayathri Nagarajan <
gayathri.nagarajan at gmail.com> wrote:

> Hi Rui
>
> Tried renderDatatable, but now my shiny UI shows Blank for my tibble. Not
> sure what Iam missing suddenly when this was working fine a day back.
>
> The one change I did was:
>
> x <- getURL("
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> ")
> us_counties <- read.csv(text = x)
>
> Error in function (type, msg, asError = TRUE)  :
>   error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol
> version
>
> Hence had to change this to :
>
>
>   urlfile="
> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
> "
>   #GN added 3/3
>   #GN comment 3/4
>   #us_counties<-read_csv(url(urlfile),col_types = list(date = col_date()))
>   #GN Add 3/4
>   #GN added 3/3
>   cols_spec <- cols(
>     date = col_date(format = ""),
>     county = col_character(),
>     state = col_character(),
>     fips = col_character(),
>     cases = col_double(),
>     deaths = col_double()
>   )
>
>   us_counties <- read_csv(url(urlfile), col_types = cols_spec)
>  ===========================
>
>
> Regards
> Gayathri
>
>
> On Thu, 4 Mar 2021 at 08:41, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> This is a known issue with renderTable. Show the results with
>> renderDataTable instead.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 15:24 de 03/03/21, Gayathri Nagarajan escreveu:
>> > Hi Team
>> >
>> > I have a tibble like the below :
>> >
>> > class(us_counties)
>> > [1] "tbl_df"     "tbl"        "data.frame"
>> >
>> > head(us_counties)
>> > # A tibble: 6 x 8
>> >    date       deaths Todays_deaths county state fips
>> >    <date>      <dbl>         <dbl> <chr>  <chr> <chr>
>> > 1 2020-03-19      0             0 Abbev~ Sout~ 45001
>> > 2 2020-03-20      0             0 Abbev~ Sout~ 45001
>> > 3 2020-03-21      0             0 Abbev~ Sout~ 45001
>> > 4 2020-03-22      0             0 Abbev~ Sout~ 45001
>> > 5 2020-03-23      0             0 Abbev~ Sout~ 45001
>> > 6 2020-03-24      0             0 Abbev~ Sout~ 45001
>> >
>> > str(us_counties)
>> > tibble [1,082,715 x 8] (S3: tbl_df/tbl/data.frame)
>> >   $ date         : Date[1:1082715], format: "2020-03-19" ...
>> >   $ deaths       : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>> >   $ Todays_deaths: num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>> >   $ county       : chr [1:1082715] "Abbeville" "Abbeville" "Abbeville"
>> > "Abbeville" ...
>> >   $ state        : chr [1:1082715] "South Carolina" "South Carolina"
>> "South
>> > Carolina" "South Carolina" ...
>> >   $ fips         : chr [1:1082715] "45001" "45001" "45001" "45001" ...
>> >   $ cases        : num [1:1082715] 1 1 1 1 1 1 3 4 4 4 ...
>> >   $ Todays_cases : num [1:1082715] 0 0 0 0 0 0 0 0 0 0 ...
>> >   - attr(*, "spec")=
>> >    .. cols(
>> >    ..   date = col_date(format = ""),
>> >    ..   county = col_character(),
>> >    ..   state = col_character(),
>> >    ..   fips = col_character(),
>> >    ..   cases = col_double(),
>> >    ..   deaths = col_double()
>> >    .. )
>> >   - attr(*, ".internal.selfref")=<externalptr>
>> >>
>> >
>> >
>> >
>> > Now when I display this in shiny UI using a simple  command:
>> >
>> >
>> >     # Generate an HTML table view of the data ----
>> >     output$ttable <- renderTable({
>> >         head(us_counties
>> >              , n = input$obs)
>> >     })
>> >
>> >
>> > I get a display like the below
>> >
>> > datedeathsTodays_deathscountystatefipscasesTodays_cases
>> > 18679.00 34.00 0.00 Abbeville South Carolina 45001 2184.00 0.00
>> > 18680.00 34.00 0.00 Abbeville South Carolina 45001 2191.00 0.00
>> > 18681.00 34.00 0.00 Abbeville South Carolina 45001 2192.00 0.00
>> >
>> > This is the change I made
>> >
>> > old code
>> > ========
>> >   #x <- getURL("
>> >
>> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
>> > ")
>> >    #us_counties <- read.csv(text = x)
>> >    # 855612 Rows , 6 columns class(us_counties)
>> >
>> >
>> > this stopped working, so I changed to below
>> >
>> >
>> >    urlfile="
>> >
>> https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
>> > "
>> >    #GN added 3/3
>> >    us_counties<-read_csv(url(urlfile),col_types = list(date =
>> col_date()))
>> >
>> >   Please let me know how to correct this
>> >
>> > Regards
>> > Gayathri
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Mar  5 16:28:20 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 5 Mar 2021 07:28:20 -0800
Subject: [R] "global parameter" warning using data.table in package.
In-Reply-To: <CAGAA5beG=kcQJMmnYsGMkxymPGLi=q+5akGggutAdG2n4m7E6Q@mail.gmail.com>
References: <CAGAA5beG=kcQJMmnYsGMkxymPGLi=q+5akGggutAdG2n4m7E6Q@mail.gmail.com>
Message-ID: <CAGxFJbRjcM_X9cAZ3GgS0p-pAFOGbKXpBnddHdZ=E4EOwuxSpQ@mail.gmail.com>

I believe these questions belong on r-package-devel, not here.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 5, 2021 at 5:25 AM Martin M?ller Skarbiniks Pedersen <
traxplayer at gmail.com> wrote:

> Hi,
>
>   I am converting a couple of functions into a R-package. Many of the
> functions use data.table.
>   I have two questions using data.table in my own package.
>   Normally I would put each question in separate emails but I think they
> might be connected.
>
> First question is short and I think the answer is yes.
> 1. Do I always need to prefix data.table each time I use something from
> that package?
> Eg. DT <- data.table::data.table(x=rep(c("b","a","c"),each=3), y=c(1,3,6),
> v=1:9)
>
> Second question is longer.
> 2.  In this small example code:
> hello <- function() {
>   DT <- data.table::data.table(x=rep(c("b","a","c"),each=3), y=c(1,3,6),
> v=1:9)
>   DT[, .(sum(v))]
> }
>
> I get these warnings from R CMD check:
> hello: no visible global function definition for ?.?
> hello: no visible binding for global variable ?v?
> Undefined global functions or variables:
>   . v
>
> According to: vignette("datatable-importing", package = "data.table")
> The solution is
> hello <- function() {
>   v <- NULL
>   . <- NULL
>
> And it works but looks a bit weird.
> Is there a better solution?
>
> Regards
> Martin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Mar  5 19:09:41 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 05 Mar 2021 10:09:41 -0800
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <1614935662799.60644@precheza.cz>
References: <1614935662799.60644@precheza.cz>
Message-ID: <CE56E5CE-E1DE-4D26-8B39-0B6C95977BCD@dcn.davis.ca.us>

Your example could probably be resolved with approx. If you want a more robust solution, it looks like the fBasics package can do spline interpolation. You may want to spline on the log  of your size variable and use exp on the output if you want to avoid negative results.

On March 5, 2021 1:14:22 AM PST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Dear all
>
>I have table of quantiles, probably from lognormal distribution
>
> dput(temp)
>temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
>0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
>0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
>), row.names = c(NA, -9L), class = "data.frame")
>
>and I need to calculate quantile for size 0.1
>
>plot(temp$size, temp$percent, pch=19, xlim=c(0,2))
>ss <- approxfun(temp$size, temp$percent)
>points((0:100)/50, ss((0:100)/50))
>abline(v=.1)
>
>If I had original data it would be quite easy with ecdf/quantile
>function but without it I am lost what function I could use for such
>task.
>
>Please, give me some hint where to look.
>
>
>Best regards
>
>Petr
>Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
>obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
>about processing and protection of business partner's personal data are
>available on website:
>https://www.precheza.cz/en/personal-data-protection-principles/
>D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en?
>odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>documents attached to it may be confidential and are subject to the
>legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Mar  5 19:23:40 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 5 Mar 2021 10:23:40 -0800
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <1614935662799.60644@precheza.cz>
References: <1614935662799.60644@precheza.cz>
Message-ID: <72ca63c3-3b22-cc38-5d39-85d39d211500@comcast.net>


On 3/5/21 1:14 AM, PIKAL Petr wrote:
> Dear all
>
> I have table of quantiles, probably from lognormal distribution
>
>   dput(temp)
> temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
> 0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
> 0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
> ), row.names = c(NA, -9L), class = "data.frame")
>
> and I need to calculate quantile for size 0.1
>
> plot(temp$size, temp$percent, pch=19, xlim=c(0,2))
> ss <- approxfun(temp$size, temp$percent)
> points((0:100)/50, ss((0:100)/50))
> abline(v=.1)
>
> If I had original data it would be quite easy with ecdf/quantile function but without it I am lost what function I could use for such task.

The quantiles are in reverse order so tryoing to match the data to 
quantiles from candidate parameters requires subtracting them from unity:

 > temp$size
[1] 1.6000 0.9466 0.8062 0.6477 0.5069 0.3781 0.3047 0.2681 0.1907
 > qlnorm(1-temp$percent, -.5)
[1] 6.21116124 3.14198142 2.18485959 1.19063854 0.60653066 0.30897659 
0.16837670 0.11708517 0.05922877
 > qlnorm(1-temp$percent, -.9)
[1] 4.16346589 2.10613313 1.46455518 0.79810888 0.40656966 0.20711321 
0.11286628 0.07848454 0.03970223
 > qlnorm(1-temp$percent, -2)
[1] 1.38589740 0.70107082 0.48750807 0.26566737 0.13533528 0.06894200 
0.03756992 0.02612523 0.01321572
 > qlnorm(1-temp$percent, -1.6)
[1] 2.06751597 1.04587476 0.72727658 0.39632914 0.20189652 0.10284937 
0.05604773 0.03897427 0.01971554
 > qlnorm(1-temp$percent, -1.6, .5)
[1] 0.64608380 0.45951983 0.38319004 0.28287360 0.20189652 0.14410042 
0.10637595 0.08870608 0.06309120
 > qlnorm(1-temp$percent, -1, .5)
[1] 1.1772414 0.8372997 0.6982178 0.5154293 0.3678794 0.2625681 
0.1938296 0.1616330 0.1149597
 > qlnorm(1-temp$percent, -1, .4)
[1] 0.9328967 0.7103066 0.6142340 0.4818106 0.3678794 0.2808889 
0.2203318 0.1905308 0.1450700
 > qlnorm(1-temp$percent, -0.5, .4)
[1] 1.5380866 1.1710976 1.0127006 0.7943715 0.6065307 0.4631076 
0.3632657 0.3141322 0.2391799
 > qlnorm(1-temp$percent, -0.55, .4)
[1] 1.4630732 1.1139825 0.9633106 0.7556295 0.5769498 0.4405216 
0.3455491 0.2988118 0.2275150
 > qlnorm(1-temp$percent, -0.55, .35)
[1] 1.3024170 1.0260318 0.9035201 0.7305712 0.5769498 0.4556313 
0.3684158 0.3244257 0.2555795
 > qlnorm(1-temp$percent, -0.55, .45)
[1] 1.6435467 1.2094723 1.0270578 0.7815473 0.5769498 0.4259129 
0.3241016 0.2752201 0.2025322
 > qlnorm(1-temp$percent, -0.53, .45)
[1] 1.6767486 1.2339052 1.0478057 0.7973356 0.5886050 0.4345169 
0.3306489 0.2807799 0.2066236
 > qlnorm(1-temp$percent, -0.57, .45)
[1] 1.6110023 1.1855231 1.0067207 0.7660716 0.5655254 0.4174793 
0.3176840 0.2697704 0.1985218

Seems like it might be an acceptable fit. modulo the underlying data 
gathering situation which really should be considered.

You can fiddle with that result. My statistical hat (not of PhD level 
certification) says that the middle quantiles in this sequence probably 
have the lowest sampling error for a lognormal, but I'm rather unsure 
about that. A counter-argument might be that since there is a hard lower 
bound of 0 for the 0-th quantile that you should be more worried about 
matching the 0.1907 value to the 0.01 order statistic, since 99% of the 
data is know to be above it. Seems like efforts at matching the 0.50 
quantile to 0.5069 for the logmean parameter and matching the 0.01 
quantile 0.1907 for estimation of? the variance estimate might be 
preferred to worrying too much about the 1.6 value which would be in the 
right tail (and far away from your region of extrapolation.)


Further trial and error:


 > qlnorm(1-temp$percent, -0.58, .47)
[1] 1.6709353 1.2129813 1.0225804 0.7687497 0.5598984 0.4077870 
0.3065638 0.2584427 0.1876112
 > qlnorm(1-temp$percent, -0.65, .47)
[1] 1.5579697 1.1309763 0.9534476 0.7167775 0.5220458 0.3802181 
0.2858382 0.2409704 0.1749275
 > qlnorm(1-temp$percent, -0.65, .5)
[1] 1.6705851 1.1881849 0.9908182 0.7314290 0.5220458 0.3726018 
0.2750573 0.2293682 0.1631355
 > qlnorm(1-temp$percent, -0.65, .4)
[1] 1.3238434 1.0079731 0.8716395 0.6837218 0.5220458 0.3986004 
0.3126657 0.2703761 0.2058641
 > qlnorm(1-temp$percent, -0.68, .4)
[1] 1.2847179 0.9781830 0.8458786 0.6635148 0.5066170 0.3868200 
0.3034251 0.2623852 0.1997799
 > qlnorm(1-temp$percent, -0.65, .39)
[1] 1.2934016 0.9915290 0.8605402 0.6791257 0.5220458 0.4012980 
0.3166985 0.2748601 0.2107093
 >
 > qlnorm(1-temp$percent, -0.65, .42)
[1] 1.3868932 1.0416839 0.8942693 0.6930076 0.5220458 0.3932595 
0.3047536 0.2616262 0.1965053
 > qlnorm(1-temp$percent, -0.68, .42)
[1] 1.3459043 1.0108975 0.8678396 0.6725261 0.5066170 0.3816369 
0.2957468 0.2538940 0.1906976


(I did make an effort at searching for quantile matching as a method for 
distribution fitting, but came up empty.)


-- 

David.

>
> Please, give me some hint where to look.
>
>
> Best regards
>
> Petr
 >[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar  5 20:17:59 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 6 Mar 2021 08:17:59 +1300
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <1614935662799.60644@precheza.cz>
References: <1614935662799.60644@precheza.cz>
Message-ID: <CAB8pepzwR97maS4PuF9UYPPGuONqwPfQ4e4AxmyxFAoipXBZYA@mail.gmail.com>

I note three problems with your data:
(1) The name "percent" is misleading, perhaps you want "probability"?
(2) There are straight (or near-straight) regions, each of which, is
equally (or near-equally) spaced, which is not what I would expect in
problems involving "quantiles".
(3) Your plot (approximating the distribution function) is
back-the-front (as per what is customary).


On Fri, Mar 5, 2021 at 10:14 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Dear all
>
> I have table of quantiles, probably from lognormal distribution
>
>  dput(temp)
> temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
> 0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
> 0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
> ), row.names = c(NA, -9L), class = "data.frame")
>
> and I need to calculate quantile for size 0.1
>
> plot(temp$size, temp$percent, pch=19, xlim=c(0,2))
> ss <- approxfun(temp$size, temp$percent)
> points((0:100)/50, ss((0:100)/50))
> abline(v=.1)
>
> If I had original data it would be quite easy with ecdf/quantile function but without it I am lost what function I could use for such task.
>
> Please, give me some hint where to look.
>
>
> Best regards
>
> Petr
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar  5 22:08:36 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 6 Mar 2021 10:08:36 +1300
Subject: [R] problem downloading R
In-Reply-To: <c0f9b062-5e0e-9592-e705-54059d638181@statistik.tu-dortmund.de>
References: <960232bc-c4e3-25ce-e607-ec047cc22af1@earthlink.net>
 <CAB8pepwgyQKffpqsFKVxSVXfbi83_4Hh3x3v+OttcEv5VV2cpQ@mail.gmail.com>
 <c0f9b062-5e0e-9592-e705-54059d638181@statistik.tu-dortmund.de>
Message-ID: <CAB8pepzNQ8iZfhXitKXwhez1PJDOvkAMS7kex-GQVzNy0RO5pA@mail.gmail.com>

This was quite some time ago.
Namely, 2019.

At the time, I was using a mix of old Windows 8 and 9 computers.
The problem happened on Windows 8, but not Windows 9.

Note that I was trying to help the OP.
Beyond that, I'm not concerned about it.


On Fri, Mar 5, 2021 at 9:30 PM Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
> Sounds like you always got corrupted vesions. Either an issue with your
> connection or the mirror. What happens if you try another mirror and
> clear your browser caches?
>
> Best,
> Uwe Ligges
>
> On 05.03.2021 08:58, Abby Spurdle wrote:
> > Does the following sound familiar?
> >
> > The Windows installer starts installing (or decompressing) R, flashing
> > one file name at a time.
> > And then, part way through, says XXXX file is corrupt, and gives you
> > the choice to ignore.
> > And if you click ignore, then the next file does the same thing.
> > And one quickly realizes, that every subsequent file will have the same message.
> >
> > Then if you re-download the installation file, the same thing happens.
> > Except that the first file flagged as corrupted, is not necessarily
> > the same file.
> >
> >
> > On Fri, Mar 5, 2021 at 5:55 AM Dick Mathews <dmathews63 at earthlink.net> wrote:
> >>
> >> I am trying to download the Windows version of R. This computer is Win7,
> >> I do have Win10 computers also.
> >>
> >> Tried R4.0.4, got message these files are corrupted.
> >>
> >> Then tried R4.0.3, got same message as above.
> >>
> >> Tried the next, R4.0.2, got same message.
> >>
> >> I checked to see if I was downloading the proper version, seems okay.
> >>
> >> What is the problem? Can anybody help me with this?
> >>
> >> Dick Mathews
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From @purd|e@@ @end|ng |rom gm@||@com  Sat Mar  6 08:09:41 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 6 Mar 2021 20:09:41 +1300
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <CAB8pepzwR97maS4PuF9UYPPGuONqwPfQ4e4AxmyxFAoipXBZYA@mail.gmail.com>
References: <1614935662799.60644@precheza.cz>
 <CAB8pepzwR97maS4PuF9UYPPGuONqwPfQ4e4AxmyxFAoipXBZYA@mail.gmail.com>
Message-ID: <CAB8pepzddGaX5NFnzqSJq6YR3t+-cwKAg=rfH9a=1pEt08ATwQ@mail.gmail.com>

I'm sorry.
I misread your example, this morning.
(I didn't read the code after the line that calls plot).

After looking at this problem again, interpolation doesn't apply, and
extrapolation would be a last resort.
If you can assume your data comes from a particular type of
distribution, such as a lognormal distribution, then a better approach
would be to find the most likely parameters.

i.e.
This falls within the broader scope of maximum likelihood.
(Except that you're dealing with a table of quantile-probability
pairs, rather than raw observational data).

I suspect that there's a relatively easy way of finding the parameters.

I'll think about it...
But someone else may come back with an answer first...


On Sat, Mar 6, 2021 at 8:17 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I note three problems with your data:
> (1) The name "percent" is misleading, perhaps you want "probability"?
> (2) There are straight (or near-straight) regions, each of which, is
> equally (or near-equally) spaced, which is not what I would expect in
> problems involving "quantiles".
> (3) Your plot (approximating the distribution function) is
> back-the-front (as per what is customary).
>
>
> On Fri, Mar 5, 2021 at 10:14 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Dear all
> >
> > I have table of quantiles, probably from lognormal distribution
> >
> >  dput(temp)
> > temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
> > 0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
> > 0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
> > ), row.names = c(NA, -9L), class = "data.frame")
> >
> > and I need to calculate quantile for size 0.1
> >
> > plot(temp$size, temp$percent, pch=19, xlim=c(0,2))
> > ss <- approxfun(temp$size, temp$percent)
> > points((0:100)/50, ss((0:100)/50))
> > abline(v=.1)
> >
> > If I had original data it would be quite easy with ecdf/quantile function but without it I am lost what function I could use for such task.
> >
> > Please, give me some hint where to look.
> >
> >
> > Best regards
> >
> > Petr
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sat Mar  6 10:02:25 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 6 Mar 2021 22:02:25 +1300
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <CAB8pepzddGaX5NFnzqSJq6YR3t+-cwKAg=rfH9a=1pEt08ATwQ@mail.gmail.com>
References: <1614935662799.60644@precheza.cz>
 <CAB8pepzwR97maS4PuF9UYPPGuONqwPfQ4e4AxmyxFAoipXBZYA@mail.gmail.com>
 <CAB8pepzddGaX5NFnzqSJq6YR3t+-cwKAg=rfH9a=1pEt08ATwQ@mail.gmail.com>
Message-ID: <CAB8pepwdDhdozwPwa7E5QuQ_B_1BWDP28uj46YJVNEioWLsbkw@mail.gmail.com>

I came up with a solution.
But not necessarily the best solution.

I used a spline to approximate the quantile function.
Then use that to generate a large sample.
(I don't see any need for the sample to be random, as such).
Then compute the sample mean and sd, on a log scale.
Finally, plug everything into the plnorm function:

p <- seq (0.01, 0.99,, 1e6)
Fht <- splinefun (temp$percent, temp$size)
x <- log (Fht (p) )
psolution <- plnorm (0.1, mean (x), sd (x), FALSE)
psolution

The value of the solution is very close to one.
Which is not a surprise.

Here's a plot of everything:

u <- seq (0.000001, 1.65,, 200)
v <- plnorm (u, mean (x), sd (x), FALSE)
plot (u, v, type="l", ylim = c (0, 1) )
points (temp$size, temp$percent, pch=16)
points (0.1, psolution, pch=16, col="blue")


On Sat, Mar 6, 2021 at 8:09 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I'm sorry.
> I misread your example, this morning.
> (I didn't read the code after the line that calls plot).
>
> After looking at this problem again, interpolation doesn't apply, and
> extrapolation would be a last resort.
> If you can assume your data comes from a particular type of
> distribution, such as a lognormal distribution, then a better approach
> would be to find the most likely parameters.
>
> i.e.
> This falls within the broader scope of maximum likelihood.
> (Except that you're dealing with a table of quantile-probability
> pairs, rather than raw observational data).
>
> I suspect that there's a relatively easy way of finding the parameters.
>
> I'll think about it...
> But someone else may come back with an answer first...
>
>
> On Sat, Mar 6, 2021 at 8:17 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > I note three problems with your data:
> > (1) The name "percent" is misleading, perhaps you want "probability"?
> > (2) There are straight (or near-straight) regions, each of which, is
> > equally (or near-equally) spaced, which is not what I would expect in
> > problems involving "quantiles".
> > (3) Your plot (approximating the distribution function) is
> > back-the-front (as per what is customary).
> >
> >
> > On Fri, Mar 5, 2021 at 10:14 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > >
> > > Dear all
> > >
> > > I have table of quantiles, probably from lognormal distribution
> > >
> > >  dput(temp)
> > > temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
> > > 0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
> > > 0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
> > > ), row.names = c(NA, -9L), class = "data.frame")
> > >
> > > and I need to calculate quantile for size 0.1
> > >
> > > plot(temp$size, temp$percent, pch=19, xlim=c(0,2))
> > > ss <- approxfun(temp$size, temp$percent)
> > > points((0:100)/50, ss((0:100)/50))
> > > abline(v=.1)
> > >
> > > If I had original data it would be quite easy with ecdf/quantile function but without it I am lost what function I could use for such task.
> > >
> > > Please, give me some hint where to look.
> > >
> > >
> > > Best regards
> > >
> > > Petr
> > > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> > > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Mar  7 01:32:33 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 6 Mar 2021 16:32:33 -0800
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <CAB8pepwdDhdozwPwa7E5QuQ_B_1BWDP28uj46YJVNEioWLsbkw@mail.gmail.com>
References: <1614935662799.60644@precheza.cz>
 <CAB8pepzwR97maS4PuF9UYPPGuONqwPfQ4e4AxmyxFAoipXBZYA@mail.gmail.com>
 <CAB8pepzddGaX5NFnzqSJq6YR3t+-cwKAg=rfH9a=1pEt08ATwQ@mail.gmail.com>
 <CAB8pepwdDhdozwPwa7E5QuQ_B_1BWDP28uj46YJVNEioWLsbkw@mail.gmail.com>
Message-ID: <362ec2a4-8c88-36ac-1b1b-19ab97362515@comcast.net>


On 3/6/21 1:02 AM, Abby Spurdle wrote:
> I came up with a solution.
> But not necessarily the best solution.
>
> I used a spline to approximate the quantile function.
> Then use that to generate a large sample.
> (I don't see any need for the sample to be random, as such).
> Then compute the sample mean and sd, on a log scale.
> Finally, plug everything into the plnorm function:
>
> p <- seq (0.01, 0.99,, 1e6)
> Fht <- splinefun (temp$percent, temp$size)
> x <- log (Fht (p) )
> psolution <- plnorm (0.1, mean (x), sd (x), FALSE)
> psolution
>
> The value of the solution is very close to one.
> Which is not a surprise.
>
> Here's a plot of everything:
>
> u <- seq (0.000001, 1.65,, 200)
> v <- plnorm (u, mean (x), sd (x), FALSE)
> plot (u, v, type="l", ylim = c (0, 1) )
> points (temp$size, temp$percent, pch=16)
> points (0.1, psolution, pch=16, col="blue")

Here's another approach, which uses minimization of the squared error to 
get the parameters for a lognormal distribution.

temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
), row.names = c(NA, -9L), class = "data.frame")

obj <- function(x) {sum( qlnorm(1-temp$percent, x[[1]], 
x[[2]])-temp$size )^2}

# Note the inversion of the poorly named and flipped "percent" column,

optim( list(a=-0.65, b=0.42), obj)

#--------------------

$par
 ???????? a????????? b
-0.7020649? 0.4678656

$value
[1] 3.110316e-12

$counts
function gradient
 ????? 51?????? NA

$convergence
[1] 0

$message
NULL


I'm not sure how principled this might be. There's no consideration in 
this approach for expected sampling error at the right tail where the 
magnitudes of the observed values will create much larger contributions 
to the sum of squares.

-- 

David.

>
>
> On Sat, Mar 6, 2021 at 8:09 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>> I'm sorry.
>> I misread your example, this morning.
>> (I didn't read the code after the line that calls plot).
>>
>> After looking at this problem again, interpolation doesn't apply, and
>> extrapolation would be a last resort.
>> If you can assume your data comes from a particular type of
>> distribution, such as a lognormal distribution, then a better approach
>> would be to find the most likely parameters.
>>
>> i.e.
>> This falls within the broader scope of maximum likelihood.
>> (Except that you're dealing with a table of quantile-probability
>> pairs, rather than raw observational data).
>>
>> I suspect that there's a relatively easy way of finding the parameters.
>>
>> I'll think about it...
>> But someone else may come back with an answer first...
>>
>>
>> On Sat, Mar 6, 2021 at 8:17 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>> I note three problems with your data:
>>> (1) The name "percent" is misleading, perhaps you want "probability"?
>>> (2) There are straight (or near-straight) regions, each of which, is
>>> equally (or near-equally) spaced, which is not what I would expect in
>>> problems involving "quantiles".
>>> (3) Your plot (approximating the distribution function) is
>>> back-the-front (as per what is customary).
>>>
>>>
>>> On Fri, Mar 5, 2021 at 10:14 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>> Dear all
>>>>
>>>> I have table of quantiles, probably from lognormal distribution
>>>>
>>>>   dput(temp)
>>>> temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069,
>>>> 0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1,
>>>> 0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
>>>> ), row.names = c(NA, -9L), class = "data.frame")
>>>>
>>>> and I need to calculate quantile for size 0.1
>>>>
>>>> plot(temp$size, temp$percent, pch=19, xlim=c(0,2))
>>>> ss <- approxfun(temp$size, temp$percent)
>>>> points((0:100)/50, ss((0:100)/50))
>>>> abline(v=.1)
>>>>
>>>> If I had original data it would be quite easy with ecdf/quantile function but without it I am lost what function I could use for such task.
>>>>
>>>> Please, give me some hint where to look.
>>>>
>>>>
>>>> Best regards
>>>>
>>>> Petr
>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roger@bo@ @end|ng |rom gm@||@com  Sun Mar  7 01:07:33 2021
From: roger@bo@ @end|ng |rom gm@||@com (Roger Bos)
Date: Sat, 6 Mar 2021 19:07:33 -0500
Subject: [R] mpfr function in Rmpfr crashes R
Message-ID: <CAPV07m-Dxt-2BHOR1oxeSW5dfB1o3dJK8s9HRvuy-QxtyqLPkg@mail.gmail.com>

All,

The following code crashes by R on my mac with a message "R session
aborted.  A fatal error occured".

```
library(Rmpfr)
Rmpfr::mpfr(pi, 120)
```

Does anyone have any suggestions?   My session info is below:

R version 4.0.3 (2020-10-10)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Big Sur 10.16

Matrix products: default
LAPACK:
/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] datasets  utils     stats     graphics  grDevices methods   base

other attached packages:
 [1] alphavantager_0.1.2 googlesheets4_0.2.0 googledrive_1.0.1
clipr_0.7.1
 [5] jsonlite_1.7.2      stringi_1.5.3       dtplyr_1.0.1
 data.table_1.13.6
 [9] dplyr_1.0.4         plyr_1.8.6          testthat_3.0.1
 lubridate_1.7.9.2
[13] timeDate_3043.102   sendmailR_1.2-1     rmarkdown_2.6
devtools_2.3.2
[17] usethis_2.0.0       xts_0.12.1          zoo_1.8-8
MASS_7.3-53
[21] fortunes_1.5-4

loaded via a namespace (and not attached):
 [1] tinytex_0.29      tidyselect_1.1.0  xfun_0.20         remotes_2.2.0
  purrr_0.3.4
 [6] gargle_0.5.0      lattice_0.20-41   generics_0.1.0    vctrs_0.3.6
  htmltools_0.5.1.1
[11] base64enc_0.1-3   rlang_0.4.10      pkgbuild_1.2.0    pillar_1.4.7
 glue_1.4.2
[16] withr_2.4.1       DBI_1.1.1         sessioninfo_1.1.1 lifecycle_0.2.0
  cellranger_1.1.0
[21] evaluate_0.14     memoise_2.0.0     knitr_1.31        callr_3.5.1
  fastmap_1.1.0
[26] ps_1.5.0          curl_4.3          Rcpp_1.0.6        openssl_1.4.3
  cachem_1.0.1
[31] desc_1.2.0        pkgload_1.1.0     fs_1.5.0          askpass_1.1
  digest_0.6.27
[36] processx_3.4.5    grid_4.0.3        rprojroot_2.0.2   cli_2.3.0
  tools_4.0.3
[41] magrittr_2.0.1    tibble_3.0.6      crayon_1.4.0      pkgconfig_2.0.3
  ellipsis_0.3.1
[46] prettyunits_1.1.1 httr_1.4.2        assertthat_0.2.1  R6_2.5.0
 compiler_4.0.3
19:05:52  >

Thanks,

Roger

	[[alternative HTML version deleted]]


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Sun Mar  7 14:03:20 2021
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments and acoustic tools)
Date: Sun, 7 Mar 2021 06:03:20 -0700
Subject: [R] Package to generate moon phase - SR-SS
In-Reply-To: <mailman.362419.1.1615114801.64193.r-help@r-project.org>
References: <mailman.362419.1.1615114801.64193.r-help@r-project.org>
Message-ID: <52ae8c5f-5162-847f-8178-2dcc1eb5ffea@gmail.com>

Hi all

I have not found a package by Googling, but assume there must be at 
least one out there.
I need to generate/write sun rise-sun set times (civil twilight) and 
moon phase/illumination.

I would like to add a start date and end date along with location 
coordinates and have a table generated like below.
This is from a legacy program acquired some 30 years ago and is no 
longer available.? This can only generate 1 month at a time (subset 
below).? But for a year at a time both historical and for future dates 
and locations.

For this legacy program I enter the date and select a location I have in 
a simple TXT location file location with time-zone and X-Y coordinates 
and it will generate a month at a time.? this can be dumped to the 
clipboard but not written as a TXT or delimited file.

I am hoping there will be an elegant way to do this in R and have the 
results written to a file for import into an Access DB.
Tnx for any suggestions? on package(s).

Sample below.

 ??????????????????? Sun and Moon Data for March 2021
 ???????????????????????? 17.05?N? 88.57?W? 5hrW
 ????????????????????? Standard Time? Civil Twilight

 ??????????????????????????? Sun???????????????????????? Moon
 ????? Date??? Twi.? Rise? Transit? Set??? Twi.? Rise? Transit Set??? %

 ?? 3/1/2021? 06:50? 07:12? 13:07? 19:01? 19:23? 21:36? 02:52? 09:04 92
 ?? 3/2/2021? 06:50? 07:11? 13:06? 19:01? 19:23? 22:35? 03:43? 09:47 85
 ?? 3/3/2021? 06:49? 07:11? 13:06? 19:02? 19:23? 23:35? 04:35? 10:31 76
 ?? 3/4/2021? 06:48? 07:10? 13:06? 19:02? 19:24? *****? 05:28? 11:18 65

-- 
Bruce W. Miller, PhD.
Neotropical bat risk and acoustic assessments
Conservation Fellow - Wildlife Conservation Society
Research Associate, American Museum of Natural History

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From j|ox @end|ng |rom mcm@@ter@c@  Sun Mar  7 15:54:57 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sun, 7 Mar 2021 09:54:57 -0500
Subject: [R] mpfr function in Rmpfr crashes R
In-Reply-To: <1555_1615120206_127CU5fl026596_CAPV07m-Dxt-2BHOR1oxeSW5dfB1o3dJK8s9HRvuy-QxtyqLPkg@mail.gmail.com>
References: <1555_1615120206_127CU5fl026596_CAPV07m-Dxt-2BHOR1oxeSW5dfB1o3dJK8s9HRvuy-QxtyqLPkg@mail.gmail.com>
Message-ID: <2e996c6a-edd5-ef14-03c8-5a716c6d552e@mcmaster.ca>

Dear Roger,

This works perfectly fine for me on an apparently similar system, with 
the exceptions that I'm running R 4.0.4, have many fewer packages 
loaded, and am in a slightly different locale:

--------------- snip ------------

 > Rmpfr::mpfr(pi, 120)
1 'mpfr' number of precision  120   bits
[1] 3.1415926535897931159979634685441851616

 > sessionInfo()
R version 4.0.4 (2021-02-15)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Big Sur 10.16

Matrix products: default
LAPACK: 
/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Rmpfr_0.8-2 gmp_0.6-2

loaded via a namespace (and not attached):
  [1] compiler_4.0.4    htmltools_0.5.1.1 tools_4.0.4       yaml_2.2.1 
       rmarkdown_2.6
  [6] knitr_1.31        xfun_0.21         digest_0.6.27 
packrat_0.5.0     rlang_0.4.10
[11] evaluate_0.14

--------------- snip ------------

You might try updating R or running Rmpfr in a cleaner session.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-03-06 7:07 p.m., Roger Bos wrote:
> All,
> 
> The following code crashes by R on my mac with a message "R session
> aborted.  A fatal error occured".
> 
> ```
> library(Rmpfr)
> Rmpfr::mpfr(pi, 120)
> ```
> 
> Does anyone have any suggestions?   My session info is below:
> 
> R version 4.0.3 (2020-10-10)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Big Sur 10.16
> 
> Matrix products: default
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] datasets  utils     stats     graphics  grDevices methods   base
> 
> other attached packages:
>   [1] alphavantager_0.1.2 googlesheets4_0.2.0 googledrive_1.0.1
> clipr_0.7.1
>   [5] jsonlite_1.7.2      stringi_1.5.3       dtplyr_1.0.1
>   data.table_1.13.6
>   [9] dplyr_1.0.4         plyr_1.8.6          testthat_3.0.1
>   lubridate_1.7.9.2
> [13] timeDate_3043.102   sendmailR_1.2-1     rmarkdown_2.6
> devtools_2.3.2
> [17] usethis_2.0.0       xts_0.12.1          zoo_1.8-8
> MASS_7.3-53
> [21] fortunes_1.5-4
> 
> loaded via a namespace (and not attached):
>   [1] tinytex_0.29      tidyselect_1.1.0  xfun_0.20         remotes_2.2.0
>    purrr_0.3.4
>   [6] gargle_0.5.0      lattice_0.20-41   generics_0.1.0    vctrs_0.3.6
>    htmltools_0.5.1.1
> [11] base64enc_0.1-3   rlang_0.4.10      pkgbuild_1.2.0    pillar_1.4.7
>   glue_1.4.2
> [16] withr_2.4.1       DBI_1.1.1         sessioninfo_1.1.1 lifecycle_0.2.0
>    cellranger_1.1.0
> [21] evaluate_0.14     memoise_2.0.0     knitr_1.31        callr_3.5.1
>    fastmap_1.1.0
> [26] ps_1.5.0          curl_4.3          Rcpp_1.0.6        openssl_1.4.3
>    cachem_1.0.1
> [31] desc_1.2.0        pkgload_1.1.0     fs_1.5.0          askpass_1.1
>    digest_0.6.27
> [36] processx_3.4.5    grid_4.0.3        rprojroot_2.0.2   cli_2.3.0
>    tools_4.0.3
> [41] magrittr_2.0.1    tibble_3.0.6      crayon_1.4.0      pkgconfig_2.0.3
>    ellipsis_0.3.1
> [46] prettyunits_1.1.1 httr_1.4.2        assertthat_0.2.1  R6_2.5.0
>   compiler_4.0.3
> 19:05:52  >
> 
> Thanks,
> 
> Roger
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Mar  7 16:37:06 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 07 Mar 2021 07:37:06 -0800
Subject: [R] Package to generate moon phase - SR-SS
In-Reply-To: <52ae8c5f-5162-847f-8178-2dcc1eb5ffea@gmail.com>
References: <mailman.362419.1.1615114801.64193.r-help@r-project.org>
 <52ae8c5f-5162-847f-8178-2dcc1eb5ffea@gmail.com>
Message-ID: <C0F7A3B1-945D-4A74-8344-9670E2990A32@dcn.davis.ca.us>

Odd.. came right up for me. Perhaps you might find rseek.org easier to use?

On March 7, 2021 5:03:20 AM PST, Neotropical bat risk assessments and acoustic tools <neotropical.bats at gmail.com> wrote:
>Hi all
>
>I have not found a package by Googling, but assume there must be at 
>least one out there.
>I need to generate/write sun rise-sun set times (civil twilight) and 
>moon phase/illumination.
>
>I would like to add a start date and end date along with location 
>coordinates and have a table generated like below.
>This is from a legacy program acquired some 30 years ago and is no 
>longer available.? This can only generate 1 month at a time (subset 
>below).? But for a year at a time both historical and for future dates 
>and locations.
>
>For this legacy program I enter the date and select a location I have
>in 
>a simple TXT location file location with time-zone and X-Y coordinates 
>and it will generate a month at a time.? this can be dumped to the 
>clipboard but not written as a TXT or delimited file.
>
>I am hoping there will be an elegant way to do this in R and have the 
>results written to a file for import into an Access DB.
>Tnx for any suggestions? on package(s).
>
>Sample below.
>
> ??????????????????? Sun and Moon Data for March 2021
> ???????????????????????? 17.05?N? 88.57?W? 5hrW
> ????????????????????? Standard Time? Civil Twilight
>
> ??????????????????????????? Sun???????????????????????? Moon
> ????? Date??? Twi.? Rise? Transit? Set??? Twi.? Rise? Transit Set??? %
>
> ?? 3/1/2021? 06:50? 07:12? 13:07? 19:01? 19:23? 21:36? 02:52? 09:04 92
> ?? 3/2/2021? 06:50? 07:11? 13:06? 19:01? 19:23? 22:35? 03:43? 09:47 85
> ?? 3/3/2021? 06:49? 07:11? 13:06? 19:02? 19:23? 23:35? 04:35? 10:31 76
> ?? 3/4/2021? 06:48? 07:10? 13:06? 19:02? 19:24? *****? 05:28? 11:18 65

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Mar  7 19:03:26 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 7 Mar 2021 13:03:26 -0500
Subject: [R] mpfr function in Rmpfr crashes R
In-Reply-To: <CAPV07m-Dxt-2BHOR1oxeSW5dfB1o3dJK8s9HRvuy-QxtyqLPkg@mail.gmail.com>
References: <CAPV07m-Dxt-2BHOR1oxeSW5dfB1o3dJK8s9HRvuy-QxtyqLPkg@mail.gmail.com>
Message-ID: <acc38cdc-487f-bbf7-20df-c87d747b8099@gmail.com>

It works for me, on a slightly different system than yours:

 > Rmpfr::mpfr(pi, 120)
1 'mpfr' number of precision  120   bits
[1] 3.1415926535897931159979634685441851616
 > sessionInfo()
R version 4.0.3 Patched (2021-01-30 r79912)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.7

Matrix products: default
BLAS: 
/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
LAPACK: 
/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Rmpfr_0.8-2 gmp_0.6-1

loaded via a namespace (and not attached):
[1] compiler_4.0.3


On 06/03/2021 7:07 p.m., Roger Bos wrote:
> All,
> 
> The following code crashes by R on my mac with a message "R session
> aborted.  A fatal error occured".
> 
> ```
> library(Rmpfr)
> Rmpfr::mpfr(pi, 120)
> ```
> 
> Does anyone have any suggestions?   My session info is below:
> 
> R version 4.0.3 (2020-10-10)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Big Sur 10.16
> 
> Matrix products: default
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] datasets  utils     stats     graphics  grDevices methods   base
> 
> other attached packages:
>   [1] alphavantager_0.1.2 googlesheets4_0.2.0 googledrive_1.0.1
> clipr_0.7.1
>   [5] jsonlite_1.7.2      stringi_1.5.3       dtplyr_1.0.1
>   data.table_1.13.6
>   [9] dplyr_1.0.4         plyr_1.8.6          testthat_3.0.1
>   lubridate_1.7.9.2
> [13] timeDate_3043.102   sendmailR_1.2-1     rmarkdown_2.6
> devtools_2.3.2
> [17] usethis_2.0.0       xts_0.12.1          zoo_1.8-8
> MASS_7.3-53
> [21] fortunes_1.5-4
> 
> loaded via a namespace (and not attached):
>   [1] tinytex_0.29      tidyselect_1.1.0  xfun_0.20         remotes_2.2.0
>    purrr_0.3.4
>   [6] gargle_0.5.0      lattice_0.20-41   generics_0.1.0    vctrs_0.3.6
>    htmltools_0.5.1.1
> [11] base64enc_0.1-3   rlang_0.4.10      pkgbuild_1.2.0    pillar_1.4.7
>   glue_1.4.2
> [16] withr_2.4.1       DBI_1.1.1         sessioninfo_1.1.1 lifecycle_0.2.0
>    cellranger_1.1.0
> [21] evaluate_0.14     memoise_2.0.0     knitr_1.31        callr_3.5.1
>    fastmap_1.1.0
> [26] ps_1.5.0          curl_4.3          Rcpp_1.0.6        openssl_1.4.3
>    cachem_1.0.1
> [31] desc_1.2.0        pkgload_1.1.0     fs_1.5.0          askpass_1.1
>    digest_0.6.27
> [36] processx_3.4.5    grid_4.0.3        rprojroot_2.0.2   cli_2.3.0
>    tools_4.0.3
> [41] magrittr_2.0.1    tibble_3.0.6      crayon_1.4.0      pkgconfig_2.0.3
>    ellipsis_0.3.1
> [46] prettyunits_1.1.1 httr_1.4.2        assertthat_0.2.1  R6_2.5.0
>   compiler_4.0.3
> 19:05:52  >
> 
> Thanks,
> 
> Roger
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Mar  7 19:06:58 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 7 Mar 2021 13:06:58 -0500
Subject: [R] Package to generate moon phase - SR-SS
In-Reply-To: <C0F7A3B1-945D-4A74-8344-9670E2990A32@dcn.davis.ca.us>
References: <mailman.362419.1.1615114801.64193.r-help@r-project.org>
 <52ae8c5f-5162-847f-8178-2dcc1eb5ffea@gmail.com>
 <C0F7A3B1-945D-4A74-8344-9670E2990A32@dcn.davis.ca.us>
Message-ID: <4ad24a9b-cdd6-1675-113b-5066e47a43ed@gmail.com>

For me too:  suncalc is the package.

Duncan Murdoc

On 07/03/2021 10:37 a.m., Jeff Newmiller wrote:
> Odd.. came right up for me. Perhaps you might find rseek.org easier to use?
> 
> On March 7, 2021 5:03:20 AM PST, Neotropical bat risk assessments and acoustic tools <neotropical.bats at gmail.com> wrote:
>> Hi all
>>
>> I have not found a package by Googling, but assume there must be at
>> least one out there.
>> I need to generate/write sun rise-sun set times (civil twilight) and
>> moon phase/illumination.
>>
>> I would like to add a start date and end date along with location
>> coordinates and have a table generated like below.
>> This is from a legacy program acquired some 30 years ago and is no
>> longer available.? This can only generate 1 month at a time (subset
>> below).? But for a year at a time both historical and for future dates
>> and locations.
>>
>> For this legacy program I enter the date and select a location I have
>> in
>> a simple TXT location file location with time-zone and X-Y coordinates
>> and it will generate a month at a time.? this can be dumped to the
>> clipboard but not written as a TXT or delimited file.
>>
>> I am hoping there will be an elegant way to do this in R and have the
>> results written to a file for import into an Access DB.
>> Tnx for any suggestions? on package(s).
>>
>> Sample below.
>>
>>  ??????????????????? Sun and Moon Data for March 2021
>>  ???????????????????????? 17.05?N? 88.57?W? 5hrW
>>  ????????????????????? Standard Time? Civil Twilight
>>
>>  ??????????????????????????? Sun???????????????????????? Moon
>>  ????? Date??? Twi.? Rise? Transit? Set??? Twi.? Rise? Transit Set??? %
>>
>>  ?? 3/1/2021? 06:50? 07:12? 13:07? 19:01? 19:23? 21:36? 02:52? 09:04 92
>>  ?? 3/2/2021? 06:50? 07:11? 13:06? 19:01? 19:23? 22:35? 03:43? 09:47 85
>>  ?? 3/3/2021? 06:49? 07:11? 13:06? 19:02? 19:23? 23:35? 04:35? 10:31 76
>>  ?? 3/4/2021? 06:48? 07:10? 13:06? 19:02? 19:24? *****? 05:28? 11:18 65
>


From rmh @end|ng |rom temp|e@edu  Sun Mar  7 19:33:11 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sun, 7 Mar 2021 18:33:11 +0000
Subject: [R] [External] Re:  mpfr function in Rmpfr crashes R
In-Reply-To: <acc38cdc-487f-bbf7-20df-c87d747b8099@gmail.com>
References: <CAPV07m-Dxt-2BHOR1oxeSW5dfB1o3dJK8s9HRvuy-QxtyqLPkg@mail.gmail.com>,
 <acc38cdc-487f-bbf7-20df-c87d747b8099@gmail.com>
Message-ID: <SA2PR11MB51158EF968D62812B48EED2FD2949@SA2PR11MB5115.namprd11.prod.outlook.com>

this is probably a Mac M1.
The problem and potential solution is described here:

https://stat.ethz.ch/pipermail/r-sig-mac/2021-February/014003.html

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Sunday, March 7, 2021 13:03
To: Roger Bos; r-help at r-project.org
Subject: [External] Re: [R] mpfr function in Rmpfr crashes R

It works for me, on a slightly different system than yours:

 > Rmpfr::mpfr(pi, 120)
1 'mpfr' number of precision  120   bits
[1] 3.1415926535897931159979634685441851616
 > sessionInfo()
R version 4.0.3 Patched (2021-01-30 r79912)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.7

Matrix products: default
BLAS:
/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
LAPACK:
/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Rmpfr_0.8-2 gmp_0.6-1

loaded via a namespace (and not attached):
[1] compiler_4.0.3


On 06/03/2021 7:07 p.m., Roger Bos wrote:
> All,
>
> The following code crashes by R on my mac with a message "R session
> aborted.  A fatal error occured".
>
> ```
> library(Rmpfr)
> Rmpfr::mpfr(pi, 120)
> ```
>
> Does anyone have any suggestions?   My session info is below:
>
> R version 4.0.3 (2020-10-10)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Big Sur 10.16
>
> Matrix products: default
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] datasets  utils     stats     graphics  grDevices methods   base
>
> other attached packages:
>   [1] alphavantager_0.1.2 googlesheets4_0.2.0 googledrive_1.0.1
> clipr_0.7.1
>   [5] jsonlite_1.7.2      stringi_1.5.3       dtplyr_1.0.1
>   data.table_1.13.6
>   [9] dplyr_1.0.4         plyr_1.8.6          testthat_3.0.1
>   lubridate_1.7.9.2
> [13] timeDate_3043.102   sendmailR_1.2-1     rmarkdown_2.6
> devtools_2.3.2
> [17] usethis_2.0.0       xts_0.12.1          zoo_1.8-8
> MASS_7.3-53
> [21] fortunes_1.5-4
>
> loaded via a namespace (and not attached):
>   [1] tinytex_0.29      tidyselect_1.1.0  xfun_0.20         remotes_2.2.0
>    purrr_0.3.4
>   [6] gargle_0.5.0      lattice_0.20-41   generics_0.1.0    vctrs_0.3.6
>    htmltools_0.5.1.1
> [11] base64enc_0.1-3   rlang_0.4.10      pkgbuild_1.2.0    pillar_1.4.7
>   glue_1.4.2
> [16] withr_2.4.1       DBI_1.1.1         sessioninfo_1.1.1 lifecycle_0.2.0
>    cellranger_1.1.0
> [21] evaluate_0.14     memoise_2.0.0     knitr_1.31        callr_3.5.1
>    fastmap_1.1.0
> [26] ps_1.5.0          curl_4.3          Rcpp_1.0.6        openssl_1.4.3
>    cachem_1.0.1
> [31] desc_1.2.0        pkgload_1.1.0     fs_1.5.0          askpass_1.1
>    digest_0.6.27
> [36] processx_3.4.5    grid_4.0.3        rprojroot_2.0.2   cli_2.3.0
>    tools_4.0.3
> [41] magrittr_2.0.1    tibble_3.0.6      crayon_1.4.0      pkgconfig_2.0.3
>    ellipsis_0.3.1
> [46] prettyunits_1.1.1 httr_1.4.2        assertthat_0.2.1  R6_2.5.0
>   compiler_4.0.3
> 19:05:52  >
>
> Thanks,
>
> Roger
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From roger@bo@ @end|ng |rom gm@||@com  Sun Mar  7 22:10:30 2021
From: roger@bo@ @end|ng |rom gm@||@com (Roger Bos)
Date: Sun, 7 Mar 2021 16:10:30 -0500
Subject: [R] [External] Re:  mpfr function in Rmpfr crashes R
In-Reply-To: <SA2PR11MB51158EF968D62812B48EED2FD2949@SA2PR11MB5115.namprd11.prod.outlook.com>
References: <CAPV07m-Dxt-2BHOR1oxeSW5dfB1o3dJK8s9HRvuy-QxtyqLPkg@mail.gmail.com>
 <acc38cdc-487f-bbf7-20df-c87d747b8099@gmail.com>
 <SA2PR11MB51158EF968D62812B48EED2FD2949@SA2PR11MB5115.namprd11.prod.outlook.com>
Message-ID: <CAPV07m88cADgj+S+AZ9TATPkv8y9pNPX4N5izptePwPq8vRnJA@mail.gmail.com>

Richard,

Yes, I am on an M1, sorry I didn't mention it.  Sounds like I just have to
wait a bit until the problem is fixed in Rosetta2 (whatever that is).
Thanks for bringing this to my attention.

Roger


On Sun, Mar 7, 2021 at 1:33 PM Richard M. Heiberger <rmh at temple.edu> wrote:

> this is probably a Mac M1.
> The problem and potential solution is described here:
>
> https://stat.ethz.ch/pipermail/r-sig-mac/2021-February/014003.html
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Duncan Murdoch <
> murdoch.duncan at gmail.com>
> Sent: Sunday, March 7, 2021 13:03
> To: Roger Bos; r-help at r-project.org
> Subject: [External] Re: [R] mpfr function in Rmpfr crashes R
>
> It works for me, on a slightly different system than yours:
>
>  > Rmpfr::mpfr(pi, 120)
> 1 'mpfr' number of precision  120   bits
> [1] 3.1415926535897931159979634685441851616
>  > sessionInfo()
> R version 4.0.3 Patched (2021-01-30 r79912)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Catalina 10.15.7
>
> Matrix products: default
> BLAS:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] Rmpfr_0.8-2 gmp_0.6-1
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.3
>
>
> On 06/03/2021 7:07 p.m., Roger Bos wrote:
> > All,
> >
> > The following code crashes by R on my mac with a message "R session
> > aborted.  A fatal error occured".
> >
> > ```
> > library(Rmpfr)
> > Rmpfr::mpfr(pi, 120)
> > ```
> >
> > Does anyone have any suggestions?   My session info is below:
> >
> > R version 4.0.3 (2020-10-10)
> > Platform: x86_64-apple-darwin17.0 (64-bit)
> > Running under: macOS Big Sur 10.16
> >
> > Matrix products: default
> > LAPACK:
> >
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] datasets  utils     stats     graphics  grDevices methods   base
> >
> > other attached packages:
> >   [1] alphavantager_0.1.2 googlesheets4_0.2.0 googledrive_1.0.1
> > clipr_0.7.1
> >   [5] jsonlite_1.7.2      stringi_1.5.3       dtplyr_1.0.1
> >   data.table_1.13.6
> >   [9] dplyr_1.0.4         plyr_1.8.6          testthat_3.0.1
> >   lubridate_1.7.9.2
> > [13] timeDate_3043.102   sendmailR_1.2-1     rmarkdown_2.6
> > devtools_2.3.2
> > [17] usethis_2.0.0       xts_0.12.1          zoo_1.8-8
> > MASS_7.3-53
> > [21] fortunes_1.5-4
> >
> > loaded via a namespace (and not attached):
> >   [1] tinytex_0.29      tidyselect_1.1.0  xfun_0.20         remotes_2.2.0
> >    purrr_0.3.4
> >   [6] gargle_0.5.0      lattice_0.20-41   generics_0.1.0    vctrs_0.3.6
> >    htmltools_0.5.1.1
> > [11] base64enc_0.1-3   rlang_0.4.10      pkgbuild_1.2.0    pillar_1.4.7
> >   glue_1.4.2
> > [16] withr_2.4.1       DBI_1.1.1         sessioninfo_1.1.1
> lifecycle_0.2.0
> >    cellranger_1.1.0
> > [21] evaluate_0.14     memoise_2.0.0     knitr_1.31        callr_3.5.1
> >    fastmap_1.1.0
> > [26] ps_1.5.0          curl_4.3          Rcpp_1.0.6        openssl_1.4.3
> >    cachem_1.0.1
> > [31] desc_1.2.0        pkgload_1.1.0     fs_1.5.0          askpass_1.1
> >    digest_0.6.27
> > [36] processx_3.4.5    grid_4.0.3        rprojroot_2.0.2   cli_2.3.0
> >    tools_4.0.3
> > [41] magrittr_2.0.1    tibble_3.0.6      crayon_1.4.0
> pkgconfig_2.0.3
> >    ellipsis_0.3.1
> > [46] prettyunits_1.1.1 httr_1.4.2        assertthat_0.2.1  R6_2.5.0
> >   compiler_4.0.3
> > 19:05:52  >
> >
> > Thanks,
> >
> > Roger
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Mar  8 09:41:40 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 8 Mar 2021 09:41:40 +0100
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <CE56E5CE-E1DE-4D26-8B39-0B6C95977BCD@dcn.davis.ca.us>
References: <1614935662799.60644@precheza.cz>
 <CE56E5CE-E1DE-4D26-8B39-0B6C95977BCD@dcn.davis.ca.us>
Message-ID: <24645.58180.611192.607936@stat.math.ethz.ch>

>>>>> Jeff Newmiller 
>>>>>     on Fri, 05 Mar 2021 10:09:41 -0800 writes:

    > Your example could probably be resolved with approx. If
    > you want a more robust solution, it looks like the fBasics
    > package can do spline interpolation. 

base R's  spline package does spline interpolation !!

Martin


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Mar  8 10:12:17 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 08 Mar 2021 01:12:17 -0800
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <24645.58180.611192.607936@stat.math.ethz.ch>
References: <1614935662799.60644@precheza.cz>
 <CE56E5CE-E1DE-4D26-8B39-0B6C95977BCD@dcn.davis.ca.us>
 <24645.58180.611192.607936@stat.math.ethz.ch>
Message-ID: <347A5C1F-49D6-4FD7-AE6E-23D2C0F86FFD@dcn.davis.ca.us>

I am aware of that... I have my own functions for this purpose that use splinefun. But if you are trying to also do other aspects of probability distribution calculations, it looked like using fBasics would be easier than re-inventing the wheel. I could be wrong, though, since I haven't used fBasics myself.

On March 8, 2021 12:41:40 AM PST, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>>>>>> Jeff Newmiller 
>>>>>>     on Fri, 05 Mar 2021 10:09:41 -0800 writes:
>
>    > Your example could probably be resolved with approx. If
>    > you want a more robust solution, it looks like the fBasics
>    > package can do spline interpolation. 
>
>base R's  spline package does spline interpolation !!
>
>Martin

-- 
Sent from my phone. Please excuse my brevity.


From j@b@y@t194 @end|ng |rom gm@||@com  Mon Mar  8 11:05:17 2021
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Mon, 8 Mar 2021 13:35:17 +0330
Subject: [R] Split Dataframe into several
Message-ID: <CANTxAmLzQcAmQLQ1gMQiq0iD2A8iuWmBzv2rBvKHWEkPj7k5-w@mail.gmail.com>

Dear R users;
Hi.
I have a problem with splitting dataframe into several.
I have a large dataframe (Length of 61000). It has 4 Columns as below:
"
               Date             Cases          Country
1            2020-12-14     746            Country1
2            2020-12-15      324           Country1
..
6000      2020-12-13      298            Country2
.
.
"
Each country has a different number of rows and their related dates are
different. What I want to do is: Extract rows for each country and make a
new column for that case of the country.
"
             Date             Cases_Country1      Cases_Country2
 Cases_Country3 ......
1           2020-12-14     746                      25
                65
2           2020-12-15      324
..
6000      2020-12-13      298                      352
              75
"
I used split function, but it create a list and I cannot use the data.
Please help me to fix this problem.
Sincerely



-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Mon Mar  8 14:17:32 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 8 Mar 2021 14:17:32 +0100
Subject: [R] Split Dataframe into several
In-Reply-To: <CANTxAmLzQcAmQLQ1gMQiq0iD2A8iuWmBzv2rBvKHWEkPj7k5-w@mail.gmail.com>
References: <CANTxAmLzQcAmQLQ1gMQiq0iD2A8iuWmBzv2rBvKHWEkPj7k5-w@mail.gmail.com>
Message-ID: <YEYj7MZmifap9InJ@posteo.no>

Dear Javad,

	data <- "Date Cases Country
	2020-12-14 746 Country1
	2020-12-15 324 Country1
	2020-12-15   1 Country3
	2020-12-13 298 Country2"
	data <- read.table(text=data, header=T)
	x <- reshape(
	  data=data,
	  timevar = "Country",
	  idvar = "Date",
	  direction = "wide")
	data
	x

yields

	        Date Cases  Country
	1 2020-12-14   746 Country1
	2 2020-12-15   324 Country1
	3 2020-12-15     1 Country3
	4 2020-12-13   298 Country2
	        Date Cases.Country1
	1 2020-12-14            746
	2 2020-12-15            324
	4 2020-12-13             NA
	  Cases.Country3 Cases.Country2
	1             NA             NA
	2              1             NA
	4             NA            298

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210308/3b88debe/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Mon Mar  8 14:50:07 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 8 Mar 2021 14:50:07 +0100
Subject: [R] Split Dataframe into several
In-Reply-To: <CANTxAmLzfLeBm4m_Dd9eBkVBUs5F8U4qFQufHuiSv4t-0XBxRQ@mail.gmail.com>
References: <CANTxAmLzQcAmQLQ1gMQiq0iD2A8iuWmBzv2rBvKHWEkPj7k5-w@mail.gmail.com>
 <YEYj7MZmifap9InJ@posteo.no>
 <CANTxAmLzfLeBm4m_Dd9eBkVBUs5F8U4qFQufHuiSv4t-0XBxRQ@mail.gmail.com>
Message-ID: <YEYrj6i5iph1mb9J@posteo.no>

On 2021-03-08 17:14 +0330, javad bayat wrote:
> Dear Rasmus;
> Many thanks. It works for me.
> Sincerely yours

Great :)

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210308/1d5e9620/attachment.sig>

From petr@p|k@| @end|ng |rom prechez@@cz  Mon Mar  8 14:52:03 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 8 Mar 2021 13:52:03 +0000
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <362ec2a4-8c88-36ac-1b1b-19ab97362515@comcast.net>
References: <1614935662799.60644@precheza.cz>
 <CAB8pepzwR97maS4PuF9UYPPGuONqwPfQ4e4AxmyxFAoipXBZYA@mail.gmail.com>
 <CAB8pepzddGaX5NFnzqSJq6YR3t+-cwKAg=rfH9a=1pEt08ATwQ@mail.gmail.com>
 <CAB8pepwdDhdozwPwa7E5QuQ_B_1BWDP28uj46YJVNEioWLsbkw@mail.gmail.com>
 <362ec2a4-8c88-36ac-1b1b-19ab97362515@comcast.net>
Message-ID: <a49f19e7a79641f7878f11ba478f0773@SRVEXCHCM1302.precheza.cz>

Hallo David, Abby and Bert

Thank you for your solutions. In the meantime I found package rriskDistributions, which was able to calculate values for lognormal distribution from quantiles.

Abby
> 1-psolution
[1] 9.980823e-06

David
> plnorm(0.1, -.7020649, .4678656)
[1] 0.0003120744

rriskDistributions
> plnorm(0.1, -.6937355, .3881209)
[1] 1.697379e-05

Bert suggested to ask for original data before quantile calculation what is probably the best but also the most problematic solution. Actually, maybe original data are unavailable as it is the result from particle size measurement, where the software always twist the original data and spits only descriptive results.

All your results are quite consistent with the available values as they are close to 1, so for me, each approach works.

Thank you again.

Best regards.
Petr

> -----Original Message-----
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: Sunday, March 7, 2021 1:33 AM
> To: Abby Spurdle <spurdle.a at gmail.com>; PIKAL Petr
> <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Re: [R] quantile from quantile table calculation without original data
> 
> 
> On 3/6/21 1:02 AM, Abby Spurdle wrote:
> > I came up with a solution.
> > But not necessarily the best solution.
> >
> > I used a spline to approximate the quantile function.
> > Then use that to generate a large sample.
> > (I don't see any need for the sample to be random, as such).
> > Then compute the sample mean and sd, on a log scale.
> > Finally, plug everything into the plnorm function:
> >
> > p <- seq (0.01, 0.99,, 1e6)
> > Fht <- splinefun (temp$percent, temp$size) x <- log (Fht (p) )
> > psolution <- plnorm (0.1, mean (x), sd (x), FALSE) psolution
> >
> > The value of the solution is very close to one.
> > Which is not a surprise.
> >
> > Here's a plot of everything:
> >
> > u <- seq (0.000001, 1.65,, 200)
> > v <- plnorm (u, mean (x), sd (x), FALSE) plot (u, v, type="l", ylim =
> > c (0, 1) ) points (temp$size, temp$percent, pch=16) points (0.1,
> > psolution, pch=16, col="blue")
> 
> Here's another approach, which uses minimization of the squared error to
> get the parameters for a lognormal distribution.
> 
> temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069, 0.3781,
> 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95,
> 0.99)), .Names = c("size", "percent"
> ), row.names = c(NA, -9L), class = "data.frame")
> 
> obj <- function(x) {sum( qlnorm(1-temp$percent, x[[1]], x[[2]])-temp$size
> )^2}
> 
> # Note the inversion of the poorly named and flipped "percent" column,
> 
> optim( list(a=-0.65, b=0.42), obj)
> 
> #--------------------
> 
> $par
>           a          b
> -0.7020649  0.4678656
> 
> $value
> [1] 3.110316e-12
> 
> $counts
> function gradient
>        51       NA
> 
> $convergence
> [1] 0
> 
> $message
> NULL
> 
> 
> I'm not sure how principled this might be. There's no consideration in this
> approach for expected sampling error at the right tail where the magnitudes
> of the observed values will create much larger contributions to the sum of
> squares.
> 
> --
> 
> David.
> 
> >
> >
> > On Sat, Mar 6, 2021 at 8:09 PM Abby Spurdle <spurdle.a at gmail.com>
> wrote:
> >> I'm sorry.
> >> I misread your example, this morning.
> >> (I didn't read the code after the line that calls plot).
> >>
> >> After looking at this problem again, interpolation doesn't apply, and
> >> extrapolation would be a last resort.
> >> If you can assume your data comes from a particular type of
> >> distribution, such as a lognormal distribution, then a better
> >> approach would be to find the most likely parameters.
> >>
> >> i.e.
> >> This falls within the broader scope of maximum likelihood.
> >> (Except that you're dealing with a table of quantile-probability
> >> pairs, rather than raw observational data).
> >>
> >> I suspect that there's a relatively easy way of finding the parameters.
> >>
> >> I'll think about it...
> >> But someone else may come back with an answer first...
> >>
> >>
> >> On Sat, Mar 6, 2021 at 8:17 AM Abby Spurdle <spurdle.a at gmail.com>
> wrote:
> >>> I note three problems with your data:
> >>> (1) The name "percent" is misleading, perhaps you want "probability"?
> >>> (2) There are straight (or near-straight) regions, each of which, is
> >>> equally (or near-equally) spaced, which is not what I would expect
> >>> in problems involving "quantiles".
> >>> (3) Your plot (approximating the distribution function) is
> >>> back-the-front (as per what is customary).
> >>>
> >>>
> >>> On Fri, Mar 5, 2021 at 10:14 PM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >>>> Dear all
> >>>>
> >>>> I have table of quantiles, probably from lognormal distribution
> >>>>
> >>>>   dput(temp)
> >>>> temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477,
> >>>> 0.5069, 0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05,
> >>>> 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
> >>>> ), row.names = c(NA, -9L), class = "data.frame")
> >>>>
> >>>> and I need to calculate quantile for size 0.1
> >>>>
> >>>> plot(temp$size, temp$percent, pch=19, xlim=c(0,2)) ss <-
> >>>> approxfun(temp$size, temp$percent) points((0:100)/50,
> >>>> ss((0:100)/50))
> >>>> abline(v=.1)
> >>>>
> >>>> If I had original data it would be quite easy with ecdf/quantile function
> but without it I am lost what function I could use for such task.
> >>>>
> >>>> Please, give me some hint where to look.
> >>>>
> >>>>
> >>>> Best regards
> >>>>
> >>>> Petr
> >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> >>>> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> >>>> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ |
> >>>> Information about processing and protection of business partner's
> >>>> personal data are available on website:
> >>>> https://www.precheza.cz/en/personal-data-protection-principles/
> >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> >>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> >>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and
> >>>> any documents attached to it may be confidential and are subject to
> >>>> the legally binding disclaimer:
> >>>> https://www.precheza.cz/en/01-disclaimer/
> >>>>
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From c@ghpm @end|ng |rom gm@||@com  Mon Mar  8 21:52:49 2021
From: c@ghpm @end|ng |rom gm@||@com (Carlos Gonzalez)
Date: Mon, 8 Mar 2021 17:52:49 -0300
Subject: [R] read_csv not recognized
Message-ID: <CAGa55hTyTrfp1LsUUv1fLdDpDdpktJWuAGe_E032EfEZOekhyQ@mail.gmail.com>

Hi everybody,

I've load tidyverse:

library(tidyverse)

and then try to use the function read_csv() but  it didn't recognize it.

Thanks!

-- 
Saludos / Regards

Carlos A. Gonzalez
Mobile +598 94 234 653
caghpm at gmail.com

	[[alternative HTML version deleted]]


From h@@@n@d|w@n @end|ng |rom gm@||@com  Mon Mar  8 21:56:58 2021
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Mon, 8 Mar 2021 12:56:58 -0800
Subject: [R] read_csv not recognized
In-Reply-To: <CAGa55hTyTrfp1LsUUv1fLdDpDdpktJWuAGe_E032EfEZOekhyQ@mail.gmail.com>
References: <CAGa55hTyTrfp1LsUUv1fLdDpDdpktJWuAGe_E032EfEZOekhyQ@mail.gmail.com>
Message-ID: <CAP+bYWD13iC6-DdBsSnzHSJUMDrVCERQ-7ba6z38+REV=Vrq7g@mail.gmail.com>

function (file, col_names = TRUE, col_types = NULL, locale =
default_locale(),
    na = c("", "NA"), quoted_na = TRUE, quote = "\"", comment = "",
    trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000,
        n_max), progress = show_progress(), skip_empty_rows = TRUE)
{
    tokenizer <- tokenizer_csv(na = na, quoted_na = quoted_na,
        quote = quote, comment = comment, trim_ws = trim_ws,
        skip_empty_rows = skip_empty_rows)
    read_delimited(file, tokenizer, col_names = col_names, col_types =
col_types,
        locale = locale, skip = skip, skip_empty_rows = skip_empty_rows,
        comment = comment, n_max = n_max, guess_max = guess_max,
        progress = progress)
}

Is the source from my copy of tidyverse. Not too involved to copy/paste
into one's .Rprofile or type into the console session. -- H

On Mon, 8 Mar 2021 at 12:53, Carlos Gonzalez <caghpm at gmail.com> wrote:

> Hi everybody,
>
> I've load tidyverse:
>
> library(tidyverse)
>
> and then try to use the function read_csv() but  it didn't recognize it.
>
> Thanks!
>
> --
> Saludos / Regards
>
> Carlos A. Gonzalez
> Mobile +598 94 234 653
> caghpm at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
OpenPGP: https://hasan.d8u.us/openpgp.asc
If you wish to request my time, please do so using
*bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.
Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
<http://bit.ly/hd1AppointmentRequest>*.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Mar  8 22:23:45 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 8 Mar 2021 16:23:45 -0500
Subject: [R] read_csv not recognized
In-Reply-To: <CAP+bYWD13iC6-DdBsSnzHSJUMDrVCERQ-7ba6z38+REV=Vrq7g@mail.gmail.com>
References: <CAGa55hTyTrfp1LsUUv1fLdDpDdpktJWuAGe_E032EfEZOekhyQ@mail.gmail.com>
 <CAP+bYWD13iC6-DdBsSnzHSJUMDrVCERQ-7ba6z38+REV=Vrq7g@mail.gmail.com>
Message-ID: <CAGgJW75hCpPvetZ87c-VCoWQt_hT5_=oMj_5p4Cn0Eo5Yxa-7g@mail.gmail.com>

Hi Carlos,
That is strange. The function read_csv is in the readr package.
You could try

library(readr)
readr::read_csv(etc)

Let us know what happens.
Eric


On Mon, Mar 8, 2021 at 3:57 PM Hasan Diwan <hasan.diwan at gmail.com> wrote:

> function (file, col_names = TRUE, col_types = NULL, locale =
> default_locale(),
>     na = c("", "NA"), quoted_na = TRUE, quote = "\"", comment = "",
>     trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000,
>         n_max), progress = show_progress(), skip_empty_rows = TRUE)
> {
>     tokenizer <- tokenizer_csv(na = na, quoted_na = quoted_na,
>         quote = quote, comment = comment, trim_ws = trim_ws,
>         skip_empty_rows = skip_empty_rows)
>     read_delimited(file, tokenizer, col_names = col_names, col_types =
> col_types,
>         locale = locale, skip = skip, skip_empty_rows = skip_empty_rows,
>         comment = comment, n_max = n_max, guess_max = guess_max,
>         progress = progress)
> }
>
> Is the source from my copy of tidyverse. Not too involved to copy/paste
> into one's .Rprofile or type into the console session. -- H
>
> On Mon, 8 Mar 2021 at 12:53, Carlos Gonzalez <caghpm at gmail.com> wrote:
>
> > Hi everybody,
> >
> > I've load tidyverse:
> >
> > library(tidyverse)
> >
> > and then try to use the function read_csv() but  it didn't recognize it.
> >
> > Thanks!
> >
> > --
> > Saludos / Regards
> >
> > Carlos A. Gonzalez
> > Mobile +598 94 234 653
> > caghpm at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> OpenPGP: https://hasan.d8u.us/openpgp.asc
> If you wish to request my time, please do so using
> *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
> Si vous voudrais faire connnaisance, allez a *bit.ly/hd1AppointmentRequest
> <http://bit.ly/hd1AppointmentRequest>*.
>
> <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> >Sent
> from my mobile device
> Envoye de mon portable
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@ghpm @end|ng |rom gm@||@com  Mon Mar  8 22:38:29 2021
From: c@ghpm @end|ng |rom gm@||@com (Carlos Gonzalez)
Date: Mon, 8 Mar 2021 18:38:29 -0300
Subject: [R] read_csv not recognized
In-Reply-To: <CAGgJW75hCpPvetZ87c-VCoWQt_hT5_=oMj_5p4Cn0Eo5Yxa-7g@mail.gmail.com>
References: <CAGa55hTyTrfp1LsUUv1fLdDpDdpktJWuAGe_E032EfEZOekhyQ@mail.gmail.com>
 <CAP+bYWD13iC6-DdBsSnzHSJUMDrVCERQ-7ba6z38+REV=Vrq7g@mail.gmail.com>
 <CAGgJW75hCpPvetZ87c-VCoWQt_hT5_=oMj_5p4Cn0Eo5Yxa-7g@mail.gmail.com>
Message-ID: <CAGa55hQZCqn8G0qzFTb1syGmgZhyFBYxGkr3K+0AuhmxsiwePg@mail.gmail.com>

Thank you!

The problem was that tidyverse has not been loaded correctly. Sorry!

El lun, 8 de mar. de 2021 a la(s) 18:24, Eric Berger (ericjberger at gmail.com)
escribi?:

> Hi Carlos,
> That is strange. The function read_csv is in the readr package.
> You could try
>
> library(readr)
> readr::read_csv(etc)
>
> Let us know what happens.
> Eric
>
>
> On Mon, Mar 8, 2021 at 3:57 PM Hasan Diwan <hasan.diwan at gmail.com> wrote:
>
> > function (file, col_names = TRUE, col_types = NULL, locale =
> > default_locale(),
> >     na = c("", "NA"), quoted_na = TRUE, quote = "\"", comment = "",
> >     trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000,
> >         n_max), progress = show_progress(), skip_empty_rows = TRUE)
> > {
> >     tokenizer <- tokenizer_csv(na = na, quoted_na = quoted_na,
> >         quote = quote, comment = comment, trim_ws = trim_ws,
> >         skip_empty_rows = skip_empty_rows)
> >     read_delimited(file, tokenizer, col_names = col_names, col_types =
> > col_types,
> >         locale = locale, skip = skip, skip_empty_rows = skip_empty_rows,
> >         comment = comment, n_max = n_max, guess_max = guess_max,
> >         progress = progress)
> > }
> >
> > Is the source from my copy of tidyverse. Not too involved to copy/paste
> > into one's .Rprofile or type into the console session. -- H
> >
> > On Mon, 8 Mar 2021 at 12:53, Carlos Gonzalez <caghpm at gmail.com> wrote:
> >
> > > Hi everybody,
> > >
> > > I've load tidyverse:
> > >
> > > library(tidyverse)
> > >
> > > and then try to use the function read_csv() but  it didn't recognize
> it.
> > >
> > > Thanks!
> > >
> > > --
> > > Saludos / Regards
> > >
> > > Carlos A. Gonzalez
> > > Mobile +598 94 234 653
> > > caghpm at gmail.com
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >
> > --
> > OpenPGP: https://hasan.d8u.us/openpgp.asc
> > If you wish to request my time, please do so using
> > *bit.ly/hd1AppointmentRequest
> > <http://bit.ly/hd1AppointmentRequest>*.
> > Si vous voudrais faire connnaisance, allez a *
> bit.ly/hd1AppointmentRequest
> > <http://bit.ly/hd1AppointmentRequest>*.
> >
> > <https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> > >Sent
> > from my mobile device
> > Envoye de mon portable
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Saludos / Regards

Carlos A. Gonzalez
Mobile +598 94 234 653
caghpm at gmail.com

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Mar  9 00:15:40 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 8 Mar 2021 15:15:40 -0800
Subject: [R] hist from a list
In-Reply-To: <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>
References: <CAB-TgNv88YE29BkrXg9teFoMGXVOGfrYtDWy+Ltb8znRK9_OFQ@mail.gmail.com>
 <42a74b91-08ed-f5f2-b621-193e447dd824@dewey.myzen.co.uk>
 <70ef6db0-8a9d-d140-8347-b4e8b758f640@sapo.pt>
 <CAPPM_gQTOQwXdiMQtD_smhZDJ7uAjwyfT65TR_J-0Vhh+xhYqg@mail.gmail.com>
 <20200731162847.GB106339@posteo.no>
 <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>
Message-ID: <a47100fe-a2da-0196-b4b6-407e1f72b914@comcast.net>


On 8/3/20 11:48 AM, Pedro p?ramo wrote:
> Hi Rasmus, Josh and Rui,
>
> First of all many thanks in advance about your help.
>
> The first thig is sometimes you say " you are posting in HTML and that
> makes the
> post unreadable as this is a plain text list" how can I put the code in the
> correct way, not html (attaching in txt?)

Set your gmail client to deliver in plain text.

Attached is a png file that is a screen shot of a Chrome mediated effort 
at composing a message and clicking the three-stacked-dots icon at the 
lower right corner. (Learn to use your chosen software tools by reading 
manuals or searching.)


-- 

David.

>
> The second about the code:
>
> I have used this:
>
> bwc <- cbind(bwfinal2,bwfinal)
> colnames(bwc)=c("Accion","reval")
> df <- matrix(unlist(bwc), nrow=nrow(bwc), byrow=F)
> colnames(bwchist)=c("Accion","reval")
> bwchist <-as.data.frame(bwc[order(df[,2]), ])
>
> bwchist is the ordered cum stock returns in the year but because is a list
> it is not possible to plot and histogram with x (names of stocks) and the x
> axist the value of cum stocks (reval)
>
> when I put dput(bwchist) the console says:
>
> dput(bwchist)
> structure(list(Accion = list("REE", "Enagas", "Grifols", "Ferrovial",
>      "Acerinox", "Naturgy", "Inditex", "Bankia", "ENCE", "Aena",
>      "Bankinter", "Mapfre", "CaixaBank", "CIE", "Colonial", "Almirall",
>      "Indra", "ArcelorMittal", "ACS", "Telefonica", "Amadeus",
>      "BBVA", "Merlin", "Santander", "Repsol", "Melia", "Sabadell",
>      "IAG", "Acciona", "Endesa", "MasMovil", "Iberdrola", "SGamesa",
>      "Viscofan", "Cellnex"), reval = list(-0.0200827282700085,
>      -0.0590294115600855, -0.214126598790964, -0.220773677809979,
>      -0.229653300324357, -0.257944379583984, -0.283942789063822,
>      -0.285159347392533, -0.303814713896458, -0.30734460425763,
>      -0.309408155539818, -0.319912221435868, -0.322790949659181,
>      -0.344047579452905, -0.347919538415482, -0.356898907103825,
>      -0.374263261296661, -0.40147247119078, -0.405150043834815,
>      -0.406022775042175, -0.413786100987797, -0.440679109311707,
>      -0.442603156492871, -0.491634140733524, -0.499254932434042,
>      -0.6, -0.709737357505148, -0.724461258850966, 0.0220528711420083,
>      0.0462767672643172, 0.115044247787611, 0.238734548714937,
>      0.274578114644054, 0.343422896082666, 0.387826126094928)), class =
> "data.frame", row.names = c(NA,
> -35L))
>
> I try to make an hist or barplot but because it is a list no way to obtain
> the plot.
>
> Many thanks again for your help.
>
> I have printed two manuals to improve my level, but if you can help me, I
> would be very very gratefull.
>
>
>
> El vie., 31 jul. 2020 a las 18:28, Rasmus Liland (<jral at posteo.no>)
> escribi?:
>
>> On 2020-07-31 10:07 -0500, Joshua Ulrich wrote:
>> | On Fri, Jul 31, 2020 at 9:55 AM Rui Barradas wrote:
>> | | ?s 15:44 de 31/07/2020, Michael Dewey escreveu:
>> | | | Dear Pedro
>> | | |
>> | | | Some comments in-line
>> | | |
>> | | | On 30/07/2020 21:16, Pedro p?ramo wrote:
>> | | | | Hi all,
>> | | | |
>> | | | | I attach my code, the think is I
>> | | | | want to make a bar plot the last
>> | | | | variable called "bwchist" so the
>> | | | | X axis are "Accion" and the y
>> | | | | axis are "reval" values.
>> | | | |
>> | | | | I have prove class(bwchist) and
>> | | | | says dataframe but its still a
>> | | | | list because it says me I have
>> | | | | prove to unlist, but it doesnt
>> | | | | work
>> | | | |
>> | | | | hist(bwchist)
>> | | | | Error in hist.default(bwchist) : 'x' must be numeric
>> | | |
>> | | | So bwchist is not a numeric
>> | | | variable as hist needs. Aboce you
>> | | | said it is a data frame but data
>> | | | frames are not numeric.
>> | | |
>> | | | For future reference your example
>> | | | is way too long for anyone to go
>> | | | through and try to help you. Try
>> | | | next time to reduce it to the
>> | | | absolute minimum by removing
>> | | | sections while you still get the
>> | | | error.  It is also easier to get
>> | | | help if you can remove unnecessary
>> | | | packages.
>> | | |
>> | | | It is also unreadable because you
>> | | | are posting in HTML and that makes
>> | | | the post unreadable as this is a
>> | | | plain text list.
>> | |
>> | | Hello,
>> | |
>> | | I second Michael's opinion. When the
>> | | post's code is very long, there is a
>> | | tendency to have less answers.
>> | |
>> | | Please post the output of
>> | |
>> | |     dput(head(bwchist, 30))
>> | |
>> | | It's much shorter code and it
>> | | recreates the data so we will be
>> | | able to see what's wrong and try to
>> | | find a solution.
>> |
>> | Hi Pedro,
>> |
>> | Another 'best practice' and polite
>> | thing to do is link to other places
>> | you may have cross-posted.  That will
>> | give people the opportunity to see if
>> | your questions has been answered in
>> | another forum.
>> |
>> | I saw your post on R-SIG-Finance
>> | (https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/014979.html),
>> | and started to work on a solution.
>> |
>> | I don't know how to do this in
>> | tidyquant, but here's how you can do
>> | it with quantmod:
>> |
>> | # all tickers
>> | tk <- c("ANA.MC", "ACS.MC", "AENA.MC", "AMS.MC", "MTS.MC", "BBVA.MC", "
>> SAB.MC",
>> |   "SAN.MC", "BKT.MC", "CABK.MC", "CLNX.MC", "ENG.MC", "ENC.MC", "ELE.MC
>> ",
>> |   "FER.MC", "GRF.MC", "IBE.MC", "ITX.MC", "COL.MC", "IAG.MC", "MAP.MC",
>> |   "MEL.MC", "MRL.MC", "NTGY.MC", "REE.MC", "REP.MC", "SGRE.MC", "TEF.MC
>> ",
>> |   "VIS.MC", "ACX.MC", "BKIA.MC", "CIE.MC", "MAS.MC", "ALM.MC", "IDR.MC")
>> |
>> | # download them into an environment ('e')
>> | require(quantmod)
>> | getSymbols(tk, from = "2019-12-31", env = (e <- new.env()))
>> |
>> | # extract adjusted close column
>> | adj <- lapply(e, Ad)
>> | # calculate daily returns from adjusted data,
>> | # merge into a xts matrix, and fill NA with 0
>> | ret <- do.call(merge, c(lapply(adj, dailyReturn), fill = 0))
>> | # cumulative returns
>> | cumret <- cumprod(1 + ret) - 1
>> | # set names
>> | colnames(cumret) <- names(adj)
>> | last(cumret)
>> | # calculate histogram for period-to-date returns
>> | hist(drop(last(cumret)))
>> |
>> | I'm not sure that's the histogram
>> | you're looking for, but I hope it
>> | gives you a start toward a solution.
>> |
>> | Best,
>> | Josh
>>
>> Wow Josh!  That's very elegant.
>>
>> Myself now, I just plowed through the
>> original code to make it simpler, but am
>> at a loss as to how this histogram looks
>> ...
>>
>>          x <- c("ANA.MC", "ACS.MC", "AENA.MC", "AMS.MC", "MTS.MC", "BBVA.MC
>> ",
>>            "SAB.MC", "SAN.MC", "BKT.MC", "CABK.MC", "CLNX.MC", "ENG.MC",
>>            "ENC.MC", "ELE.MC", "FER.MC", "GRF.MC", "IBE.MC", "ITX.MC",
>>            "COL.MC", "IAG.MC", "MAP.MC", "MEL.MC", "MRL.MC", "NTGY.MC",
>>            "REE.MC", "REP.MC", "SGRE.MC", "TEF.MC", "VIS.MC", "ACX.MC",
>>            "BKIA.MC", "CIE.MC", "MAS.MC", "ALM.MC", "IDR.MC")
>>          stock.prices <-
>>            lapply(x, function(stock) {
>>              tidyquant::tq_get(x=stock,from = '2019-12-31',get =
>> "stock.prices")
>>            })
>>          names(stock.prices) <- x
>>
>>          library(tidyquant)
>>
>>          returns <- lapply(stock.prices, function(data) {
>>            tab <-
>>              tq_transmute(
>>                data = data,
>>                select = adjusted,           # this specifies which column
>> to select
>>                mutate_fun = periodReturn,   # This specifies what to do
>> with that column
>>                period = "daily",            # This argument calculates
>> Daily returns
>>                col_rename = "idr_returns")  # renames the column
>>            tab[,"cr"] <- cumprod(1 + tab[,"idr_returns"])
>>            tab[,"cumulative_returns"] <- tab[,"cr"] - 1
>>
>>            dplyr::pull(
>>              tab[nrow(tab[,"cumulative_returns"]),
>>                            "cumulative_returns"]
>>            )
>>          })
>>
>>          bestworst <- simplify2array(returns)
>>
>>          namebw <-
>>            c("Acciona", "ACS", "Aena", "Amadeus",
>>              "ArcelorMittal", "BBVA", "Sabadell",
>>              "Santander", "Bankinter",
>>              "CaixaBank", "Cellnex", "Enagas",
>>              "ENCE", "Endesa", "Ferrovial",
>>              "Grifols", "Iberdrola", "Inditex",
>>              "Colonial", "IAG", "Mapfre",
>>              "Melia", "Merlin", "Naturgy", "REE",
>>              "Repsol", "SGamesa", "Telefonica",
>>              "Viscofan", "Acerinox", "Bankia",
>>              "CIE", "MasMovil", "Almirall",
>>              "Indra")
>>
>>          bwc <- data.frame(
>>            symbol=names(bestworst),
>>            Accion=namebw,
>>            reval=bestworst)
>>
>> | | | | bwc<-cbind(bwfinal2,bwfinal)
>> | | | | colnames(bwc)=c("Accion","reval")
>> | | | | bwc <- as.data.frame(bwc)
>>
>> ... aaaand you know something's
>> happening between here (where bwchist is
>> created), but you don't know what it is,
>> do you, Mr p?ramo?
>>
>> | | | | colnames(bwchist)=c("Accion","reval")
>> | | | | bwchist <-as.data.frame(bwc[order(bwc$reval), ])
>>
>> Best,
>> Rasmus
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2021-03-08 15-12-07.png
Type: image/png
Size: 32747 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210308/d52ce55d/attachment.png>

From phii m@iii@g oii phiiipsmith@c@  Tue Mar  9 05:05:52 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Mon, 08 Mar 2021 23:05:52 -0500
Subject: [R] Gradient plots in ggplot2
Message-ID: <4aef82068c893777dd89dcfa2cabcd84@philipsmith.ca>

I am having trouble with a gradient fill application in ggplot2, caused 
by outlier values. In my reprex, most of the values are between 2 and 
-2, but there are two outliers, 10 and -15. The outliers stand out well, 
which is good, but all the other numbers show almost no colour 
variation. I would like to continue with bold colours for the outliers, 
while having a more variable gradient, perhaps but not necessarily in a 
different colour, for the values between 2 nd -2. Any ideas on how this 
can be done?


library(ggplot2)
a <- c(rep(1,6),rep(2,6),rep(3,6),rep(4,6))
b <- c(0.1, 0.5,-0.3, 1.2,-0.4,-1.2,
        0.7, 0.8,-1.2,-0.5,10.0, 0.3,
        0.2,-0.4,-15.,-0.4,-0.9,  NA,
        0.1, 1.3,-1.4, 0.5,-0.5, 0.1)
c <- c(rep(c("a","b","c","d","e","f"),4))
df <- data.frame(a,b)
ggplot(df,aes(x=a,y=c,fill=b))+
   geom_tile()+
   geom_text(label=paste0(round(b,1),"%"),
     size=10,colour="gold")+
   scale_fill_gradient(low="red",high="blue",na.value="grey50")


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar  9 05:44:10 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 08 Mar 2021 20:44:10 -0800
Subject: [R] Gradient plots in ggplot2
In-Reply-To: <4aef82068c893777dd89dcfa2cabcd84@philipsmith.ca>
References: <4aef82068c893777dd89dcfa2cabcd84@philipsmith.ca>
Message-ID: <5A4F5B33-E946-4570-A940-29D74B6B34AA@dcn.davis.ca.us>

Perhaps scale_fill_gradientn() would be useful.

On March 8, 2021 8:05:52 PM PST, phil at philipsmith.ca wrote:
>I am having trouble with a gradient fill application in ggplot2, caused
>
>by outlier values. In my reprex, most of the values are between 2 and 
>-2, but there are two outliers, 10 and -15. The outliers stand out
>well, 
>which is good, but all the other numbers show almost no colour 
>variation. I would like to continue with bold colours for the outliers,
>
>while having a more variable gradient, perhaps but not necessarily in a
>
>different colour, for the values between 2 nd -2. Any ideas on how this
>
>can be done?
>
>
>library(ggplot2)
>a <- c(rep(1,6),rep(2,6),rep(3,6),rep(4,6))
>b <- c(0.1, 0.5,-0.3, 1.2,-0.4,-1.2,
>        0.7, 0.8,-1.2,-0.5,10.0, 0.3,
>        0.2,-0.4,-15.,-0.4,-0.9,  NA,
>        0.1, 1.3,-1.4, 0.5,-0.5, 0.1)
>c <- c(rep(c("a","b","c","d","e","f"),4))
>df <- data.frame(a,b)
>ggplot(df,aes(x=a,y=c,fill=b))+
>   geom_tile()+
>   geom_text(label=paste0(round(b,1),"%"),
>     size=10,colour="gold")+
>   scale_fill_gradient(low="red",high="blue",na.value="grey50")
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Mar  9 08:30:17 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 9 Mar 2021 07:30:17 +0000
Subject: [R] Gradient plots in ggplot2
In-Reply-To: <4aef82068c893777dd89dcfa2cabcd84@philipsmith.ca>
References: <4aef82068c893777dd89dcfa2cabcd84@philipsmith.ca>
Message-ID: <cd44709b2ad848c086e3a30e526cf12b@SRVEXCHCM1302.precheza.cz>

Hi Phillip.

You could try some transformations of your data. Either directly in
scale_fill_gradient or in original data. log transition would be OK but not
with negative data. You could play with some transitions from scales
package. I think that you could also use rescaler function, but I do not
know how.

ggplot(df,aes(x=a,y=c,fill=b))+
   geom_tile()+
   geom_text(label=paste0(round(b,1),"%"),
     size=10,colour="gold")+
   scale_fill_gradient(low="red",high="blue",na.value="grey50", trans="log")

Cheers.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of
> phil at philipsmith.ca
> Sent: Tuesday, March 9, 2021 5:06 AM
> To: r-help at r-project.org
> Subject: [R] Gradient plots in ggplot2
> 
> I am having trouble with a gradient fill application in ggplot2, caused
> by outlier values. In my reprex, most of the values are between 2 and
> -2, but there are two outliers, 10 and -15. The outliers stand out well,
> which is good, but all the other numbers show almost no colour
> variation. I would like to continue with bold colours for the outliers,
> while having a more variable gradient, perhaps but not necessarily in a
> different colour, for the values between 2 nd -2. Any ideas on how this
> can be done?
> 
> 
> library(ggplot2)
> a <- c(rep(1,6),rep(2,6),rep(3,6),rep(4,6))
> b <- c(0.1, 0.5,-0.3, 1.2,-0.4,-1.2,
>         0.7, 0.8,-1.2,-0.5,10.0, 0.3,
>         0.2,-0.4,-15.,-0.4,-0.9,  NA,
>         0.1, 1.3,-1.4, 0.5,-0.5, 0.1)
> c <- c(rep(c("a","b","c","d","e","f"),4))
> df <- data.frame(a,b)
> ggplot(df,aes(x=a,y=c,fill=b))+
>    geom_tile()+
>    geom_text(label=paste0(round(b,1),"%"),
>      size=10,colour="gold")+
>    scale_fill_gradient(low="red",high="blue",na.value="grey50")
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From nev||@@mo@ @end|ng |rom gm@||@com  Tue Mar  9 08:42:21 2021
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Tue, 9 Mar 2021 18:42:21 +1100
Subject: [R] Plot_ly bar plots - bars span sevral x values when there are
 missing values.
Message-ID: <CAN9eD7nitpaX07SoaE2yN6Hicr6BzV6owViqqBQRjQVeZUTg7Q@mail.gmail.com>

I need to plot a number of bar charts as part of a shiny app.

I am using ploty ly

x and y  values are both numeric x being consecutive integer values.

there are often missing values in the data I wish to plot - each plot needs
to have a fixed x range.

When there are more than a few missing values  the bars for the remaining
values are being plotted much wider spanning several x values ( see example
2)

curiously when there is a single remaining value the bar width is correct
(example 3)

how can I maintain a constant bar width regardless of number of missing
values? I cannot find a bar-width setting.


df<-data.frame(x=1:20,y=rnorm(20)^2)

#twenty bars each centred above a single x value:
df%>%plot_ly(
  x =  ~ x,
  y =  ~ y,
  type = "bar")%>%
  layout(xaxis = list(range = c(0,20)),
         title = "example 1")

# this produces wide bars first one spread x= 0-6 second x= 8-14
# expected two column same width as in example 1 centred above x=3 and x=11
df[c(3,11),]%>%plot_ly(
  x =  ~ x,
  y =  ~ y,
  type = "bar")%>%
  layout(xaxis = list(range = c(0,20)),
         title = "example 2 column width expands across multiple x values")

# when only a single bar is present it is again the correct width - in this
case centred above x=3
df[3,]%>%plot_ly(
  x =  ~ x,
  y =  ~ y,
  type = "bar")%>%
  layout(xaxis = list(range = c(0,20)),
         title = "example 3 correct columns again")

	[[alternative HTML version deleted]]


From me @end|ng |rom n@nx@me  Tue Mar  9 00:04:28 2021
From: me @end|ng |rom n@nx@me (Nan Xiao)
Date: Mon, 08 Mar 2021 18:04:28 -0500
Subject: [R] [R-pkgs] pkglite: Compact Package Representations
Message-ID: <07d7001b-45b0-4b0d-88cf-7fcea46de017@www.fastmail.com>

Dear all,

I am happy to announce that {pkglite} is now on CRAN. It aims to offer a tool, grammar, and standard to represent and exchange R packages as text files. It can convert one or more source packages to a text file and restore the package structures from the file.

I hope you find it helpful. Please feel free to reach out with feedback or questions.

CRAN: https://cran.r-project.org/package=pkglite
Documentation: https://merck.github.io/pkglite/

Thanks,
-Nan

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@hmood@n@der@n @end|ng |rom ugent@be  Tue Mar  9 13:11:15 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Tue, 9 Mar 2021 12:11:15 +0000
Subject: [R] Specifying plot file name in the rscript
Message-ID: <ca0e55f6d10a49d8bdde0855d688f647@ugent.be>

Hi

I use the following R script to plot two graphs.


library(FactoMineR)
mydata <- read.csv('test.csv', header=T,row.names=1)
res.pca = PCA(mydata, quali.sup=5, graph=F)
plot(res.pca, choix="var", axes=c(1,2))
dev.new()
plot(res.pca, choix="ind", axes=c(1,2))

After running "Rscript my.r", I see two pdf files Rplots.pdf and Rplots1.pdf.
I would like to specify file names in the script as well. How can I do that?


Regards,
Mahmood

	[[alternative HTML version deleted]]


From m@hmood@n@der@n @end|ng |rom ugent@be  Tue Mar  9 13:43:34 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Tue, 9 Mar 2021 12:43:34 +0000
Subject: [R] Changing chart border's color
Message-ID: <48d3f6393e8447efa2578d2ded7b7daa@ugent.be>

Hi

I would like to make the color of the chart border to black. However, the following command doesn't work


plot(res.pca, choix="ind", border="black")


Any way to fix that?

Regards,
Mahmood

	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Tue Mar  9 14:58:17 2021
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Tue, 9 Mar 2021 08:58:17 -0500
Subject: [R] Specifying plot file name in the rscript
In-Reply-To: <ca0e55f6d10a49d8bdde0855d688f647@ugent.be>
References: <ca0e55f6d10a49d8bdde0855d688f647@ugent.be>
Message-ID: <CALrbzg34F1qv=h6hk9Sre8=tg88dDVThu5+t6EuJK0ivYytr3Q@mail.gmail.com>

Hi,

When you call plot() it will draw to the default device - in your case
the pdf() device. When the default device results in a file, R selects
a filename for you unless you tell it otherwise.  You can specify the
filename by explicitly calling pdf() first.

pdf("var_plot.pdf")
plot(res.pca, choix="var", axes=c(1,2))
dev.off()

pdf("ind_plot.pdf")
plot(res.pca, choix="ind", axes=c(1,2))
dev.off()

See ?device for a listing of available devices.

Ben


On Tue, Mar 9, 2021 at 7:11 AM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi
>
> I use the following R script to plot two graphs.
>
>
> library(FactoMineR)
> mydata <- read.csv('test.csv', header=T,row.names=1)
> res.pca = PCA(mydata, quali.sup=5, graph=F)
> plot(res.pca, choix="var", axes=c(1,2))
> dev.new()
> plot(res.pca, choix="ind", axes=c(1,2))
>
> After running "Rscript my.r", I see two pdf files Rplots.pdf and Rplots1.pdf.
> I would like to specify file names in the script as well. How can I do that?
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From m@hmood@n@der@n @end|ng |rom ugent@be  Tue Mar  9 15:58:21 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Tue, 9 Mar 2021 14:58:21 +0000
Subject: [R] Specifying plot file name in the rscript
In-Reply-To: <CALrbzg34F1qv=h6hk9Sre8=tg88dDVThu5+t6EuJK0ivYytr3Q@mail.gmail.com>
References: <ca0e55f6d10a49d8bdde0855d688f647@ugent.be>,
 <CALrbzg34F1qv=h6hk9Sre8=tg88dDVThu5+t6EuJK0ivYytr3Q@mail.gmail.com>
Message-ID: <b7fcdb8394e94722a2cd0972824122f9@ugent.be>

Right. Thank you very much.


Regards,
Mahmood

________________________________
From: Ben Tupper <btupper at bigelow.org>
Sent: Tuesday, March 9, 2021 2:58:17 PM
To: Mahmood Naderan-Tahan
Cc: r-help at r-project.org
Subject: Re: [R] Specifying plot file name in the rscript

Hi,

When you call plot() it will draw to the default device - in your case
the pdf() device. When the default device results in a file, R selects
a filename for you unless you tell it otherwise.  You can specify the
filename by explicitly calling pdf() first.

pdf("var_plot.pdf")
plot(res.pca, choix="var", axes=c(1,2))
dev.off()

pdf("ind_plot.pdf")
plot(res.pca, choix="ind", axes=c(1,2))
dev.off()

See ?device for a listing of available devices.

Ben


On Tue, Mar 9, 2021 at 7:11 AM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi
>
> I use the following R script to plot two graphs.
>
>
> library(FactoMineR)
> mydata <- read.csv('test.csv', header=T,row.names=1)
> res.pca = PCA(mydata, quali.sup=5, graph=F)
> plot(res.pca, choix="var", axes=c(1,2))
> dev.new()
> plot(res.pca, choix="ind", axes=c(1,2))
>
> After running "Rscript my.r", I see two pdf files Rplots.pdf and Rplots1.pdf.
> I would like to specify file names in the script as well. How can I do that?
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Tue Mar  9 16:36:42 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Tue, 09 Mar 2021 10:36:42 -0500
Subject: [R] Gradient plots in ggplot2
In-Reply-To: <5A4F5B33-E946-4570-A940-29D74B6B34AA@dcn.davis.ca.us>
References: <4aef82068c893777dd89dcfa2cabcd84@philipsmith.ca>
 <5A4F5B33-E946-4570-A940-29D74B6B34AA@dcn.davis.ca.us>
Message-ID: <fc9bb088326bba6b57dd132ae78783ca@philipsmith.ca>

Thank you for your suggestions. I found, after much experimentation, 
that scale_fill_gradientn did indeed provide a good solution, as below.

library(ggplot2)
a <- c(rep(1,6),rep(2,6),rep(3,6),rep(4,6))
b <- c(0.1, 0.5,-0.3, 1.2,-0.4,-1.2,
        0.7, 0.8,-1.2,-0.5,10.0, 0.3,
        0.2,-0.4,-15.,-0.4,-0.9,  NA,
        0.1, 1.3,-1.4, 0.5,-0.5, 0.1)
c <- c(rep(c("a","b","c","d","e","f"),4))
df <- data.frame(a,b)
ggplot(df,aes(x=a,y=c,fill=b))+
   geom_tile()+
   geom_text(label=ifelse(is.na(b),"NA",paste0(round(b,1),"%")),
     size=10,colour="black")+
   scale_fill_gradientn(colours=c("yellow","green","red","lightblue"),
     values=c(0.0,0.5,0.7,1.0),na.value="white")

Philip


On 2021-03-08 23:44, Jeff Newmiller wrote:

> Perhaps scale_fill_gradientn() would be useful.
> 
> On March 8, 2021 8:05:52 PM PST, phil at philipsmith.ca wrote:
>> I am having trouble with a gradient fill application in ggplot2, 
>> caused
>> 
>> by outlier values. In my reprex, most of the values are between 2 and
>> -2, but there are two outliers, 10 and -15. The outliers stand out
>> well,
>> which is good, but all the other numbers show almost no colour
>> variation. I would like to continue with bold colours for the 
>> outliers,
>> 
>> while having a more variable gradient, perhaps but not necessarily in 
>> a
>> 
>> different colour, for the values between 2 nd -2. Any ideas on how 
>> this
>> 
>> can be done?
>> 
>> 
>> library(ggplot2)
>> a <- c(rep(1,6),rep(2,6),rep(3,6),rep(4,6))
>> b <- c(0.1, 0.5,-0.3, 1.2,-0.4,-1.2,
>>        0.7, 0.8,-1.2,-0.5,10.0, 0.3,
>>        0.2,-0.4,-15.,-0.4,-0.9,  NA,
>>        0.1, 1.3,-1.4, 0.5,-0.5, 0.1)
>> c <- c(rep(c("a","b","c","d","e","f"),4))
>> df <- data.frame(a,b)
>> ggplot(df,aes(x=a,y=c,fill=b))+
>>   geom_tile()+
>>   geom_text(label=paste0(round(b,1),"%"),
>>     size=10,colour="gold")+
>>   scale_fill_gradient(low="red",high="blue",na.value="grey50")
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Tue Mar  9 19:57:17 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 9 Mar 2021 19:57:17 +0100
Subject: [R] 
 Plot_ly bar plots - bars span sevral x values when there are
 missing values.
In-Reply-To: <CAN9eD7nitpaX07SoaE2yN6Hicr6BzV6owViqqBQRjQVeZUTg7Q@mail.gmail.com>
References: <CAN9eD7nitpaX07SoaE2yN6Hicr6BzV6owViqqBQRjQVeZUTg7Q@mail.gmail.com>
Message-ID: <YEfFDTrhBW3Lr+99@posteo.no>

Dear Nevil,

Although I am a bit unfamiliar with 
plotly, it seems it is possible to plot 
two bars side by side at least:

	h <- df[3:4,]
	p <- plotly::plot_ly(
	  data = h,
	  x =  ~ x,
	  y =  ~ y,
	  type = "bar")
	p <- plotly::layout(p=p,
	  xaxis = list(range = c(0,20)),
	  title = "example 4 two bars side by side")
	plotly::orca(p=p, file="amos4.png")

Thus, if you want to only plot x=3 and 
x=11 you need to set y=0 when x=4:10:

	h <- df[c(3, 11),]
	h <- rbind(h, cbind(x=4:10, y=0))
	p <- plotly::plot_ly(
	  data = h,
	  x =  ~ x,
	  y =  ~ y,
	  type = "bar")
	p <- plotly::layout(p=p,
	  xaxis = list(range = c(0,20)),
	  title = "example 2 corrected")
	plotly::orca(p=p, file="amos2.png")

I think this has to do with the xaxis 
option in plotly::layout there, and not 
with the bar width.

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210309/61ad8b56/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Tue Mar  9 20:16:24 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 9 Mar 2021 20:16:24 +0100
Subject: [R] Changing chart border's color
In-Reply-To: <48d3f6393e8447efa2578d2ded7b7daa@ugent.be>
References: <48d3f6393e8447efa2578d2ded7b7daa@ugent.be>
Message-ID: <YEfJiL0000c9uLy4@posteo.no>

Hi,  it would be useful to know how you 
created res.pca.   
https://rdrr.io/r/graphics/box.html

Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210309/02f945e5/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Tue Mar  9 20:37:03 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 9 Mar 2021 20:37:03 +0100
Subject: [R] poLCA problem
In-Reply-To: <YT1PR01MB244344ADE1C28B38DE1EF2F8CE969@YT1PR01MB2443.CANPRD01.PROD.OUTLOOK.COM>
References: <YT1PR01MB244344ADE1C28B38DE1EF2F8CE969@YT1PR01MB2443.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <YEfOX2vGZr1yJ/FR@posteo.no>

Dear Scott,

I think the issue here is you need to 
form a correct formula poLCA::poLCA can 
accept.

The help page ?poLCA::election has this 
example:

	# Latent class models with one (loglinear independence) to three classes
	data(election)
	f <- cbind(MORALG,CARESG,KNOWG,LEADG,DISHONG,INTELG,
	           MORALB,CARESB,KNOWB,LEADB,DISHONB,INTELB)~1
	nes1 <- poLCA(f,election,nclass=1)  # log-likelihood: -18647.31
	nes2 <- poLCA(f,election,nclass=2)  # log-likelihood: -17344.92
	nes3 <- poLCA(f,election,nclass=3)  # log-likelihood: -16714.66

Perhaps if you export df first using 
data() and try to use cbind(x1, x2)~1 as 
the formula ... 

	data(df2)
	f <- cbind(x1, x2)~1
	poLCA(f, df2, nclass=2, maxiter=100, nrep=10, verbose =TRUE)

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210309/6d3664f7/attachment.sig>

From m@hmood@n@der@n @end|ng |rom ugent@be  Tue Mar  9 21:43:44 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Tue, 9 Mar 2021 20:43:44 +0000
Subject: [R] Changing chart border's color
In-Reply-To: <YEfJiL0000c9uLy4@posteo.no>
References: <48d3f6393e8447efa2578d2ded7b7daa@ugent.be>,
 <YEfJiL0000c9uLy4@posteo.no>
Message-ID: <c426e42c89ff490495c2419bf974de1e@ugent.be>

Hi Rasmus,

Please see the following commands. The box fails.


> library("FactoMineR")
> mydata <- read.csv('test.csv', header=T,row.names=1)
> res.pca = PCA(mydata, quali.sup=5, graph=F)
> plot(res.pca, choix="ind")
> box(col='black')
Error in box(col = "black") : plot.new has not been called yet




Regards,
Mahmood

________________________________
From: Rasmus Liland <jral at posteo.no>
Sent: Tuesday, March 9, 2021 8:16:24 PM
To: Mahmood Naderan-Tahan
Cc: r-help at r-project.org
Subject: Re: [R] Changing chart border's color

Hi,  it would be useful to know how you
created res.pca.
https://rdrr.io/r/graphics/box.html

Rasmus

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Tue Mar  9 22:50:06 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 09 Mar 2021 22:50:06 +0100
Subject: [R] Changing chart border's color
In-Reply-To: <c426e42c89ff490495c2419bf974de1e@ugent.be>
References: <48d3f6393e8447efa2578d2ded7b7daa@ugent.be>,
 <YEfJiL0000c9uLy4@posteo.no>
 <c426e42c89ff490495c2419bf974de1e@ugent.be>
Message-ID: <3E4B336A-C73C-4319-A448-DBE546477CF1@posteo.no>

Please add test.csv using dput ?


From jr@| @end|ng |rom po@teo@no  Wed Mar 10 01:23:13 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 10 Mar 2021 01:23:13 +0100
Subject: [R] Changing chart border's color
In-Reply-To: <c426e42c89ff490495c2419bf974de1e@ugent.be>
References: <48d3f6393e8447efa2578d2ded7b7daa@ugent.be>
 <YEfJiL0000c9uLy4@posteo.no>
 <c426e42c89ff490495c2419bf974de1e@ugent.be>
Message-ID: <YEgRcf/r2tAzslNt@posteo.no>

Right, adding a black border around a 
plot in R is meaningless.  

There is also another circular plot 
being created everytime FactoMineR::PCA 
runs.  

It might be (perhaps, idk) fruitful for 
you to look at the contents of res.pca 
using str and create the PCA plot 
yourself using ggplot2 ...  or maybe 
plotly inside a shiny app ....

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210310/b201c9ab/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Wed Mar 10 02:46:31 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 10 Mar 2021 02:46:31 +0100
Subject: [R] Extract data from .nc file
In-Reply-To: <AC81C13F-22AA-4A41-911A-13AF5A9A99CD@noaa.gov>
References: <CAMUcscBQ42wYxn4wWA3LRT0hjf+berdnpayrYx_foEFqrizZRg@mail.gmail.com>
 <AC81C13F-22AA-4A41-911A-13AF5A9A99CD@noaa.gov>
Message-ID: <YEgk9w0uM9TAyeQY@posteo.no>

Dear Shailendra and Roy,

Yes, the info ncvar_get retrieves is of 
different lengths.  soi_final does not 
have a time variable for the x axis, and 
tt is a integer vector 
int [1:2001(1d)] 0 365 730 1095 1460 1825 2190 2555 2920 3285 ...

The file is a HDF5 file:

	rasmus at twosixty ~ % file posterior_climate_indices_MCruns_ensemble_full_LMRv2.1.nc
	posterior_climate_indices_MCruns_ensemble_full_LMRv2.1.nc: Hierarchical Data Format (version 5) data

I have read the HDF5 files dsk 
https://github.com/GATB/dsk creates 
before using hdf5r.  It's more 
detailed for digging around in there:

	fname <- "posterior_climate_indices_MCruns_ensemble_full_LMRv2.1.nc"
	file <- hdf5r::h5file(fname, mode = "a")
	hdf5r::list.datasets(file)
	str(file)
	names(file)
	file[["lon_npac"]][["key_info"]][["space"]]
	names(file[["lon_npac"]][["key_info"]])
	file$close_all()

But, I think you perhaps don't want more 
level of detail ...

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210310/74fef9ac/attachment.sig>

From R@H@un@ch||d @end|ng |rom |k|@mpg@de  Wed Mar 10 14:08:11 2021
From: R@H@un@ch||d @end|ng |rom |k|@mpg@de (Dr. Robin Haunschild)
Date: Wed, 10 Mar 2021 14:08:11 +0100
Subject: [R] Color in stripchart
Message-ID: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>

Dear fellow R users,

I'd like to color individual points in a stripchart. This works well as
long as I have only a single value per y axis category:

df <- data.frame(year = seq(2011, 2018), value = seq(10,80, 10))
df$color <- 'black'
df[df$value<33,]$color <- 'blue'
df[df$value>66,]$color <- 'red'
stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack')

When I use multiple values per y axis category, all points in a specific
y axis category have the same color:

set.seed(20210310)
years <- sample(x=seq(2011, 2018), size = 365*8, replace = TRUE)
values <- sample(x=seq(0,100), size = 365*8, replace = TRUE)
df <- data.frame(year = years, value = values)
df$color <- 'black'
df[df$value<33,]$color <- 'blue'
df[df$value>66,]$color <- 'red'
stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack')

I'd expect to see all points with a value below 33 in blue color, all
points with a value above 66 in red color, and the remaining points in
black color.

I can use a black stripchart plot as basis and plot blue and red points
over the black ones, but I do not get the stacking right:

stripchart(df$value ~ df$year, pch=18, method='stack')
points(df[df$color=='blue',]$value, df[df$color=='blue',]$year-2010,
type='p', pch=18, col='blue')
points(df[df$color=='red',]$value, df[df$color=='red',]$year-2010,
type='p', pch=18, col='red')

Am I somehow misusing the stripchart function?


Best regards,

Robin
-- 
Dr. Robin Haunschild
Max Planck Institute for Solid State Research
Heisenbergstr. 1
D-70569 Stuttgart (Germany)
phone: +49 (0) 711-689-1285
fax:   +49 (0) 711-689-1292
email: R.Haunschild at fkf.mpg.de
http://www.fkf.mpg.de/ivs
Publons: https://publons.com/researcher/2845202/robin-haunschild/
GS: https://scholar.google.de/citations?user=kDfateQAAAAJ&hl=de&oi=ao


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Wed Mar 10 15:04:05 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Wed, 10 Mar 2021 15:04:05 +0100
Subject: [R] Color in stripchart
In-Reply-To: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
References: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
Message-ID: <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>

Dear Robin,

if you study stripchart's code (graphics:::stripchart) carefully
you will find out that the elements of the vector provided to the
col-argument (and the pch-argument as well) are selected by iterating
along the groups (in your case year). I don't seen easy solution for
your problem using stripchart, but you may want to look at the
examples of function beeswarm in package beeswarm.

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 10.03.2021 um 14:08 schrieb Dr. Robin Haunschild:
> Dear fellow R users,
> 
> I'd like to color individual points in a stripchart. This works well as
> long as I have only a single value per y axis category:
> 
> df <- data.frame(year = seq(2011, 2018), value = seq(10,80, 10))
> df$color <- 'black'
> df[df$value<33,]$color <- 'blue'
> df[df$value>66,]$color <- 'red'
> stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack')
> 
> When I use multiple values per y axis category, all points in a specific
> y axis category have the same color:
> 
> set.seed(20210310)
> years <- sample(x=seq(2011, 2018), size = 365*8, replace = TRUE)
> values <- sample(x=seq(0,100), size = 365*8, replace = TRUE)
> df <- data.frame(year = years, value = values)
> df$color <- 'black'
> df[df$value<33,]$color <- 'blue'
> df[df$value>66,]$color <- 'red'
> stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack')
> 
> I'd expect to see all points with a value below 33 in blue color, all
> points with a value above 66 in red color, and the remaining points in
> black color.
> 
> I can use a black stripchart plot as basis and plot blue and red points
> over the black ones, but I do not get the stacking right:
> 
> stripchart(df$value ~ df$year, pch=18, method='stack')
> points(df[df$color=='blue',]$value, df[df$color=='blue',]$year-2010,
> type='p', pch=18, col='blue')
> points(df[df$color=='red',]$value, df[df$color=='red',]$year-2010,
> type='p', pch=18, col='red')
> 
> Am I somehow misusing the stripchart function?
> 
> 
> Best regards,
> 
> Robin
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jr@| @end|ng |rom po@teo@no  Wed Mar 10 15:15:06 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 10 Mar 2021 15:15:06 +0100
Subject: [R] Color in stripchart
In-Reply-To: <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
References: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
 <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
Message-ID: <YEjUaj4o/3yqk5+x@posteo.no>

Dear Robin and Gerrit,

I am unable to see the difference in the 
plot in the two cases ... 

	df <- data.frame(year = seq(2011, 2018), value = seq(10, 80, 10))
	df$color <- 'black'
	df[df$value<33,]$color <- 'blue'
	df[df$value>66,]$color <- 'red'
	
	file <- "/tmp/robin.png"
	width <- 1000
	height <- 1000
	res <- 150
	png(file=file, width=width, height=height, res=res)
	par(mfrow=c(2,1))
	
	stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack', main="stripchart with color column as col")
	
	stripchart(df$value ~ df$year, pch=18, method='stack', main="stripchart with black basis")
	points(df[df$color=='blue',]$value, df[df$color=='blue',]$year-2010,
	type='p', pch=18, col='blue')
	points(df[df$color=='red',]$value, df[df$color=='red',]$year-2010,
	type='p', pch=18, col='red')
	
	dev.off()

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: robin.png
Type: image/png
Size: 38927 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210310/5862f5ba/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210310/5862f5ba/attachment.sig>

From R@H@un@ch||d @end|ng |rom |k|@mpg@de  Wed Mar 10 15:49:05 2021
From: R@H@un@ch||d @end|ng |rom |k|@mpg@de (Dr. Robin Haunschild)
Date: Wed, 10 Mar 2021 15:49:05 +0100
Subject: [R] Color in stripchart
In-Reply-To: <YEjUaj4o/3yqk5+x@posteo.no>
References: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
 <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
 <YEjUaj4o/3yqk5+x@posteo.no>
Message-ID: <7981c1d9-4c64-5f87-a4cd-47ceba19e254@fkf.mpg.de>

Dear Rasmus,

there is no difference in the small exmaple, because there is only one
point per year.

If you use the example with multiple points per year, you will see the
difference.

Best, Robin


On 3/10/21 3:15 PM, Rasmus Liland wrote:
> Dear Robin and Gerrit,
> 
> I am unable to see the difference in the 
> plot in the two cases ... 
> 
> 	df <- data.frame(year = seq(2011, 2018), value = seq(10, 80, 10))
> 	df$color <- 'black'
> 	df[df$value<33,]$color <- 'blue'
> 	df[df$value>66,]$color <- 'red'
> 	
> 	file <- "/tmp/robin.png"
> 	width <- 1000
> 	height <- 1000
> 	res <- 150
> 	png(file=file, width=width, height=height, res=res)
> 	par(mfrow=c(2,1))
> 	
> 	stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack', main="stripchart with color column as col")
> 	
> 	stripchart(df$value ~ df$year, pch=18, method='stack', main="stripchart with black basis")
> 	points(df[df$color=='blue',]$value, df[df$color=='blue',]$year-2010,
> 	type='p', pch=18, col='blue')
> 	points(df[df$color=='red',]$value, df[df$color=='red',]$year-2010,
> 	type='p', pch=18, col='red')
> 	
> 	dev.off()
> 
> Best,
> Rasmus
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Dr. Robin Haunschild
Max Planck Institute for Solid State Research
Heisenbergstr. 1
D-70569 Stuttgart (Germany)
phone: +49 (0) 711-689-1285
fax:   +49 (0) 711-689-1292
email: R.Haunschild at fkf.mpg.de
http://www.fkf.mpg.de/ivs
Publons: https://publons.com/researcher/2845202/robin-haunschild/
GS: https://scholar.google.de/citations?user=kDfateQAAAAJ&hl=de&oi=ao


From R@H@un@ch||d @end|ng |rom |k|@mpg@de  Wed Mar 10 17:17:22 2021
From: R@H@un@ch||d @end|ng |rom |k|@mpg@de (Dr. Robin Haunschild)
Date: Wed, 10 Mar 2021 17:17:22 +0100
Subject: [R] Color in stripchart
In-Reply-To: <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
References: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
 <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
Message-ID: <7aead6f6-f592-5c32-9221-30b4be36f56e@fkf.mpg.de>

Dear Gerrit,

thanks a lot; it works with beeswarm and pwcol=df$color.

Best, Robin


On 3/10/21 3:04 PM, Gerrit Eichner wrote:
> Dear Robin,
> 
> if you study stripchart's code (graphics:::stripchart) carefully
> you will find out that the elements of the vector provided to the
> col-argument (and the pch-argument as well) are selected by iterating
> along the groups (in your case year). I don't seen easy solution for
> your problem using stripchart, but you may want to look at the
> examples of function beeswarm in package beeswarm.
> 
> ?Hth? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 10.03.2021 um 14:08 schrieb Dr. Robin Haunschild:
>> Dear fellow R users,
>>
>> I'd like to color individual points in a stripchart. This works well as
>> long as I have only a single value per y axis category:
>>
>> df <- data.frame(year = seq(2011, 2018), value = seq(10,80, 10))
>> df$color <- 'black'
>> df[df$value<33,]$color <- 'blue'
>> df[df$value>66,]$color <- 'red'
>> stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack')
>>
>> When I use multiple values per y axis category, all points in a specific
>> y axis category have the same color:
>>
>> set.seed(20210310)
>> years <- sample(x=seq(2011, 2018), size = 365*8, replace = TRUE)
>> values <- sample(x=seq(0,100), size = 365*8, replace = TRUE)
>> df <- data.frame(year = years, value = values)
>> df$color <- 'black'
>> df[df$value<33,]$color <- 'blue'
>> df[df$value>66,]$color <- 'red'
>> stripchart(df$value ~ df$year, pch=18, col=df$color, method='stack')
>>
>> I'd expect to see all points with a value below 33 in blue color, all
>> points with a value above 66 in red color, and the remaining points in
>> black color.
>>
>> I can use a black stripchart plot as basis and plot blue and red points
>> over the black ones, but I do not get the stacking right:
>>
>> stripchart(df$value ~ df$year, pch=18, method='stack')
>> points(df[df$color=='blue',]$value, df[df$color=='blue',]$year-2010,
>> type='p', pch=18, col='blue')
>> points(df[df$color=='red',]$value, df[df$color=='red',]$year-2010,
>> type='p', pch=18, col='red')
>>
>> Am I somehow misusing the stripchart function?
>>
>>
>> Best regards,
>>
>> Robin
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Dr. Robin Haunschild
Max Planck Institute for Solid State Research
Heisenbergstr. 1
D-70569 Stuttgart (Germany)
phone: +49 (0) 711-689-1285
fax:   +49 (0) 711-689-1292
email: R.Haunschild at fkf.mpg.de
http://www.fkf.mpg.de/ivs
Publons: https://publons.com/researcher/2845202/robin-haunschild/
GS: https://scholar.google.de/citations?user=kDfateQAAAAJ&hl=de&oi=ao


From jr@| @end|ng |rom po@teo@no  Wed Mar 10 17:22:54 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 10 Mar 2021 17:22:54 +0100
Subject: [R] Color in stripchart
In-Reply-To: <7981c1d9-4c64-5f87-a4cd-47ceba19e254@fkf.mpg.de>
References: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
 <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
 <YEjUaj4o/3yqk5+x@posteo.no>
 <7981c1d9-4c64-5f87-a4cd-47ceba19e254@fkf.mpg.de>
Message-ID: <YEjyXhVuF6m3Idpa@posteo.no>

Hello there again,

Sorry, I missed that part in the middle 
about set.seed.  As per [1], you need to 
run stripchart again with the add 
argument set to TRUE, and slicing the df 
according to the color, like so

	set.seed(20210310)
	years <- sample(x=seq(2011, 2018), size = 365*8, replace = TRUE)
	values <- sample(x=seq(0,100), size = 365*8, replace = TRUE)
	df <- data.frame(year = years, value = values)
	df$color <- 'black'
	df[df$value<33,]$color <- 'blue'
	df[df$value>66,]$color <- 'red'
	
	stripchart(value ~ year, pch=18, method='stack', data=df)
	for (color in unique(df$color)) {
	  stripchart(value ~ year, pch=18, method='stack', data=df[df$color==color,], col=color, add=TRUE)
	}

Best,
Rasmus

[1] https://stackoverflow.com/questions/32833210/define-color-for-each-datapoint-in-a-stripchart-separately

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210310/f42f0e5a/attachment.sig>

From R@H@un@ch||d @end|ng |rom |k|@mpg@de  Wed Mar 10 17:35:43 2021
From: R@H@un@ch||d @end|ng |rom |k|@mpg@de (Dr. Robin Haunschild)
Date: Wed, 10 Mar 2021 17:35:43 +0100
Subject: [R] Color in stripchart
In-Reply-To: <YEjyXhVuF6m3Idpa@posteo.no>
References: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
 <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
 <YEjUaj4o/3yqk5+x@posteo.no>
 <7981c1d9-4c64-5f87-a4cd-47ceba19e254@fkf.mpg.de>
 <YEjyXhVuF6m3Idpa@posteo.no>
Message-ID: <a22ff195-366b-9484-cd96-c4ccb4df3c26@fkf.mpg.de>

Dear Rasmus,

thanks, that works, too.

Great!

Best, Robin


On 3/10/21 5:22 PM, Rasmus Liland wrote:
> Hello there again,
> 
> Sorry, I missed that part in the middle 
> about set.seed.  As per [1], you need to 
> run stripchart again with the add 
> argument set to TRUE, and slicing the df 
> according to the color, like so
> 
> 	set.seed(20210310)
> 	years <- sample(x=seq(2011, 2018), size = 365*8, replace = TRUE)
> 	values <- sample(x=seq(0,100), size = 365*8, replace = TRUE)
> 	df <- data.frame(year = years, value = values)
> 	df$color <- 'black'
> 	df[df$value<33,]$color <- 'blue'
> 	df[df$value>66,]$color <- 'red'
> 	
> 	stripchart(value ~ year, pch=18, method='stack', data=df)
> 	for (color in unique(df$color)) {
> 	  stripchart(value ~ year, pch=18, method='stack', data=df[df$color==color,], col=color, add=TRUE)
> 	}
> 
> Best,
> Rasmus
> 
> [1] https://stackoverflow.com/questions/32833210/define-color-for-each-datapoint-in-a-stripchart-separately
> 


-- 
Dr. Robin Haunschild
Max Planck Institute for Solid State Research
Heisenbergstr. 1
D-70569 Stuttgart (Germany)
phone: +49 (0) 711-689-1285
fax:   +49 (0) 711-689-1292
email: R.Haunschild at fkf.mpg.de
http://www.fkf.mpg.de/ivs
Publons: https://publons.com/researcher/2845202/robin-haunschild/
GS: https://scholar.google.de/citations?user=kDfateQAAAAJ&hl=de&oi=ao


From j@cobg314 @end|ng |rom hotm@||@com  Wed Mar 10 08:36:30 2021
From: j@cobg314 @end|ng |rom hotm@||@com (Jacob Goldsmith)
Date: Wed, 10 Mar 2021 07:36:30 +0000
Subject: [R] [R-pkgs] {peruse}
Message-ID: <CO2PR04MB2231845593028B6FF61BC86FFB919@CO2PR04MB2231.namprd04.prod.outlook.com>

Hello all,

R package {peruse 0.3.1} is on CRAN. {peruse} provides simple tools for sequence iteration and set comprehension. It is especially useful for analyzing recursively generated sequences, including any stochastic process. The main page at https://jacgoldsm.github.io/peruse/ provides in-depth examples and extensive explanation of how to use the tool.

CRAN link:
https://CRAN.R-project.org/package=peruse<https://cran.r-project.org/package=peruse>


Best,
Jacob Goldsmith




	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @ret|p@nopou|ou @end|ng |rom gm@||@com  Wed Mar 10 19:29:11 2021
From: @ret|p@nopou|ou @end|ng |rom gm@||@com (Areti Panopoulou)
Date: Wed, 10 Mar 2021 18:29:11 +0000
Subject: [R] Help please
Message-ID: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>

Hello,

I am trying to make a stacked barplot with different behaviours
("inactive", "active", "foraging" etc) on different substrates ("tree",
"ground" etc). I have found this function:

# Stacked Bar Plot with Colors and Legend
counts <- table(mtcars$vs, mtcars$gear)
barplot(counts, main="Car Distribution by Gears and VS",
  xlab="Number of Gears", col=c("darkblue","red"),
  legend = rownames(counts))

But don't know how to apply it. Can anybody help me apply the function to
work with my variables ( I can send more information if necessary, or make
any clarifications).

This is a great help, thanks a lot.

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Mar 10 23:58:56 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 10 Mar 2021 22:58:56 +0000
Subject: [R] [External]  Help please
In-Reply-To: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
Message-ID: <CO1PR11MB51070A027154D704B30AE61BD2919@CO1PR11MB5107.namprd11.prod.outlook.com>

install.packages("HH")
library(HH)
?likert

>From your description, I think your data is set up to work with likert()

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Areti Panopoulou <aretipanopoulou at gmail.com>
Sent: Wednesday, March 10, 2021 13:29
To: r-help at r-project.org
Subject: [External] [R] Help please

Hello,

I am trying to make a stacked barplot with different behaviours
("inactive", "active", "foraging" etc) on different substrates ("tree",
"ground" etc). I have found this function:

# Stacked Bar Plot with Colors and Legend
counts <- table(mtcars$vs, mtcars$gear)
barplot(counts, main="Car Distribution by Gears and VS",
  xlab="Number of Gears", col=c("darkblue","red"),
  legend = rownames(counts))

But don't know how to apply it. Can anybody help me apply the function to
work with my variables ( I can send more information if necessary, or make
any clarifications).

This is a great help, thanks a lot.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Mar 11 00:01:20 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 10 Mar 2021 23:01:20 +0000
Subject: [R] Help please
In-Reply-To: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
Message-ID: <48cb4eed-7c20-c02d-de34-418db4fe040c@sapo.pt>

Hello,

Please read the posting guide at the end of this and every R-Help mail.
You should post the output of

dput(data)

or, if the data set 'data' is too big, the output of

dput(head(data, 20))

for us to be able to help you.

Rui Barradas

?s 18:29 de 10/03/21, Areti Panopoulou escreveu:
> Hello,
> 
> I am trying to make a stacked barplot with different behaviours
> ("inactive", "active", "foraging" etc) on different substrates ("tree",
> "ground" etc). I have found this function:
> 
> # Stacked Bar Plot with Colors and Legend
> counts <- table(mtcars$vs, mtcars$gear)
> barplot(counts, main="Car Distribution by Gears and VS",
>    xlab="Number of Gears", col=c("darkblue","red"),
>    legend = rownames(counts))
> 
> But don't know how to apply it. Can anybody help me apply the function to
> work with my variables ( I can send more information if necessary, or make
> any clarifications).
> 
> This is a great help, thanks a lot.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh @end|ng |rom temp|e@edu  Thu Mar 11 01:19:20 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 11 Mar 2021 00:19:20 +0000
Subject: [R] [External]  Help please
In-Reply-To: <CO1PR11MB51070A027154D704B30AE61BD2919@CO1PR11MB5107.namprd11.prod.outlook.com>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>,
 <CO1PR11MB51070A027154D704B30AE61BD2919@CO1PR11MB5107.namprd11.prod.outlook.com>
Message-ID: <CO1PR11MB5107625EF956757E9BB37D71D2909@CO1PR11MB5107.namprd11.prod.outlook.com>

> counts <- with(mtcars, table(gear, vs))
> counts
    vs
gear  0  1
   3 12  3
   4  2 10
   5  4  1
> likert(counts)
>

If this isn't enough, ask a more specific question.

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Richard M. Heiberger <rmh at temple.edu>
Sent: Wednesday, March 10, 2021 17:58
To: Areti Panopoulou; r-help at r-project.org
Subject: Re: [R] [External]  Help please

install.packages("HH")
library(HH)
?likert

>From your description, I think your data is set up to work with likert()

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Areti Panopoulou <aretipanopoulou at gmail.com>
Sent: Wednesday, March 10, 2021 13:29
To: r-help at r-project.org
Subject: [External] [R] Help please

Hello,

I am trying to make a stacked barplot with different behaviours
("inactive", "active", "foraging" etc) on different substrates ("tree",
"ground" etc). I have found this function:

# Stacked Bar Plot with Colors and Legend
counts <- table(mtcars$vs, mtcars$gear)
barplot(counts, main="Car Distribution by Gears and VS",
  xlab="Number of Gears", col=c("darkblue","red"),
  legend = rownames(counts))

But don't know how to apply it. Can anybody help me apply the function to
work with my variables ( I can send more information if necessary, or make
any clarifications).

This is a great help, thanks a lot.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Mar 11 01:35:51 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Mar 2021 11:35:51 +1100
Subject: [R] Help please
In-Reply-To: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
Message-ID: <CA+8X3fWOuq6+NJet7dLVX4gkbHAt_gjM_UbxU_52n_ngW2XS1g@mail.gmail.com>

Hi Areti,
Maybe this will help:

scrounging<-data.frame(
 behav=sample(c("inactive","active","foraging","snoozing"),50,TRUE),
 substr=sample(c("tree","ground","vine","air"),50,TRUE))
scrounge.tab<-table(scrounging)
barplot(scrounge.tab)
legend(3.8,14,c("inactive","active","foraging","snoozing"),
 fill=c("gray80","gray60","gray40","gray20"))

Jim

On Thu, Mar 11, 2021 at 9:54 AM Areti Panopoulou
<aretipanopoulou at gmail.com> wrote:
>
> Hello,
>
> I am trying to make a stacked barplot with different behaviours
> ("inactive", "active", "foraging" etc) on different substrates ("tree",
> "ground" etc). I have found this function:
>
> # Stacked Bar Plot with Colors and Legend
> counts <- table(mtcars$vs, mtcars$gear)
> barplot(counts, main="Car Distribution by Gears and VS",
>   xlab="Number of Gears", col=c("darkblue","red"),
>   legend = rownames(counts))
>
> But don't know how to apply it. Can anybody help me apply the function to
> work with my variables ( I can send more information if necessary, or make
> any clarifications).
>
> This is a great help, thanks a lot.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Thu Mar 11 01:54:00 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 11 Mar 2021 00:54:00 +0000
Subject: [R] [External] Re:  Help please
In-Reply-To: <CA+8X3fWOuq6+NJet7dLVX4gkbHAt_gjM_UbxU_52n_ngW2XS1g@mail.gmail.com>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>,
 <CA+8X3fWOuq6+NJet7dLVX4gkbHAt_gjM_UbxU_52n_ngW2XS1g@mail.gmail.com>
Message-ID: <CO1PR11MB5107360278AB43B3DF1B6DE0D2909@CO1PR11MB5107.namprd11.prod.outlook.com>

> table(scrounging)
          substr
behav      air ground tree vine
  active     1      5    3    6
  foraging   2      6    3    0
  inactive   6      1    1    3
  snoozing   2      1    3    7
> likert(t(table(scrounging)))

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Jim Lemon <drjimlemon at gmail.com>
Sent: Wednesday, March 10, 2021 19:35
To: Areti Panopoulou; r-help mailing list
Subject: [External] Re: [R] Help please

Hi Areti,
Maybe this will help:

scrounging<-data.frame(
 behav=sample(c("inactive","active","foraging","snoozing"),50,TRUE),
 substr=sample(c("tree","ground","vine","air"),50,TRUE))
scrounge.tab<-table(scrounging)
barplot(scrounge.tab)
legend(3.8,14,c("inactive","active","foraging","snoozing"),
 fill=c("gray80","gray60","gray40","gray20"))

Jim

On Thu, Mar 11, 2021 at 9:54 AM Areti Panopoulou
<aretipanopoulou at gmail.com> wrote:
>
> Hello,
>
> I am trying to make a stacked barplot with different behaviours
> ("inactive", "active", "foraging" etc) on different substrates ("tree",
> "ground" etc). I have found this function:
>
> # Stacked Bar Plot with Colors and Legend
> counts <- table(mtcars$vs, mtcars$gear)
> barplot(counts, main="Car Distribution by Gears and VS",
>   xlab="Number of Gears", col=c("darkblue","red"),
>   legend = rownames(counts))
>
> But don't know how to apply it. Can anybody help me apply the function to
> work with my variables ( I can send more information if necessary, or make
> any clarifications).
>
> This is a great help, thanks a lot.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Thu Mar 11 12:30:59 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 11 Mar 2021 12:30:59 +0100
Subject: [R] Color in stripchart
In-Reply-To: <a22ff195-366b-9484-cd96-c4ccb4df3c26@fkf.mpg.de>
References: <5479650c-1324-87a2-0cd5-ecc792c5844d@fkf.mpg.de>
 <8a2ed06b-dff2-17ea-1bee-785b420a3c74@math.uni-giessen.de>
 <YEjUaj4o/3yqk5+x@posteo.no>
 <7981c1d9-4c64-5f87-a4cd-47ceba19e254@fkf.mpg.de>
 <YEjyXhVuF6m3Idpa@posteo.no>
 <a22ff195-366b-9484-cd96-c4ccb4df3c26@fkf.mpg.de>
Message-ID: <YEn/c2by9z/TxQP7@posteo.no>

Good for you!


From jr@| @end|ng |rom po@teo@no  Thu Mar 11 15:03:05 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 11 Mar 2021 15:03:05 +0100
Subject: [R] [External] Re:  Help please
In-Reply-To: <CO1PR11MB5107360278AB43B3DF1B6DE0D2909@CO1PR11MB5107.namprd11.prod.outlook.com>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
 <CA+8X3fWOuq6+NJet7dLVX4gkbHAt_gjM_UbxU_52n_ngW2XS1g@mail.gmail.com>
 <CO1PR11MB5107360278AB43B3DF1B6DE0D2909@CO1PR11MB5107.namprd11.prod.outlook.com>
Message-ID: <YEojGReE43FIEgS/@posteo.no>

Dear Areti,

this dcast data.frame presents the same 
info as Jim's barplot

	reshape2::dcast(data=scrounging, formula=behav~substr, fun.aggregate=length)

yielding

	     behav air ground tree vine
	1   active   5      4    3    3
	2 foraging   2      1    3    4
	3 inactive   0      4    4    5
	4 snoozing   3      5    1    3

I tried to use likert by the example in 
the example in ?likert::likert

	library(likert)
	data(pisaitems)
	items29 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST25Q']
	names(items29) <- c("Magazines", "Comic books", "Fiction",
	                   "Non-fiction books", "Newspapers")
	l29 <- likert(items29)
	l29
	lapply(items29, levels)

like this 

	u <- unique(scrounging$behav)
	levels.behav <- c("inactive", u[u!="inactive"])
	scrounging$behav <- factor(x=scrounging$behav, levels=levels.behav)
	u <- unique(scrounging$substr)
	levels.substr <- c("ground", u[u!="ground"])
	scrounging$substr <- factor(x=scrounging$substr, levels=levels.substr)
	likert::likert(scrounging)

yielding

	    Item inactive active foraging snoozing
	1  behav       36     20       20       24
	2 substr       20     28       30       22

but I doubt this is meaningful ... 

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210311/5e5a412e/attachment.sig>

From rmh @end|ng |rom temp|e@edu  Thu Mar 11 19:48:46 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 11 Mar 2021 18:48:46 +0000
Subject: [R] [External] Re:  [External] Re:  Help please
In-Reply-To: <YEojGReE43FIEgS/@posteo.no>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
 <CA+8X3fWOuq6+NJet7dLVX4gkbHAt_gjM_UbxU_52n_ngW2XS1g@mail.gmail.com>
 <CO1PR11MB5107360278AB43B3DF1B6DE0D2909@CO1PR11MB5107.namprd11.prod.outlook.com>,
 <YEojGReE43FIEgS/@posteo.no>
Message-ID: <CO1PR11MB51075B4DB7DB513BC9F77DD1D2909@CO1PR11MB5107.namprd11.prod.outlook.com>

The likert() function in library(likert) is not the same as
the likert() function in library(HH).

The likert function in the likert package creates an object that needs to be plotted.
For the likert package you left out the line
        plot(likert::likert(scrounging))
This plot is not consistent with what your initial email said it was looking for.


Both Jim Lemon and I gave you plots that are consistent with your description.
You could probably get a similar plot from likert::likert(), but not by the lines you are using.
The likert::likert() function does not work with the table that HH::likert() and barplot() are using.
look at str(l29) to see what it needs

The likert package and the HH package cannot be loaded simultaneously.
Their use the same function names in incompatible ways.

How to get the ?likert::likert plot using HH:

HH::likert(t(sapply(items29, table)), as.percent=TRUE, positive.order=TRUE)

Here is a complete example using Jim Lemon's data.



## NO library() statements!
## The likert and HH packages have incompatible usage
## of the same function names.

## this is the example from ?likert::likert
data(pisaitems, package="likert")
items29 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST25Q']
names(items29) <- c("Magazines", "Comic books", "Fiction",
                    "Non-fiction books", "Newspapers")
## plot using likert package
l29 <- likert::likert(items29)
likert:::plot.likert(l29)


## plot using HH package
HH::likert(t(sapply(items29, table)), as.percent=TRUE,
           positive.order=TRUE, main="HH::likert")

HH::likert(t(sapply(items29, table)), as.percent=TRUE,
           positive.order=TRUE, main="HH::likert",
           auto.key=list(columns=2),
           scales=list(y=list(tck=c(0,2)))) ## prettier



## Jim Lemon's example
scrounging <- data.frame(
  behav=sample(c("inactive","active","foraging","snoozing"),50,TRUE),
  substr=sample(c("tree","ground","vine","air"),50,TRUE))

scroungeTable <- t(table(scrounging))
scroungeTable
HH::likert(scroungeTable)

## I don't think Jim Lemon's example can be used directly in the likert package.
## look at
str(l29)
## and notice that it must include both raw data and the table
l29$results
head(l29$items)


## For any further discussion on this list please include the output from
dput(head(yourRealData))
## in the body of the email.

## Jim's example is based on base graphics barplot
## The HH likert() function is based on lattice barchart.
## the likert package's likert:::plot.likert() function is based on ggplot.


________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Rasmus Liland <jral at posteo.no>
Sent: Thursday, March 11, 2021 09:03
To: Areti Panopoulou
Cc: r-help
Subject: [External] Re: [R] [External] Re:  Help please

Dear Areti,

this dcast data.frame presents the same
info as Jim's barplot

        reshape2::dcast(data=scrounging, formula=behav~substr, fun.aggregate=length)

yielding

             behav air ground tree vine
        1   active   5      4    3    3
        2 foraging   2      1    3    4
        3 inactive   0      4    4    5
        4 snoozing   3      5    1    3

I tried to use likert by the example in
the example in ?likert::likert

        library(likert)
        data(pisaitems)
        items29 <- pisaitems[,substr(names(pisaitems), 1,5) == 'ST25Q']
        names(items29) <- c("Magazines", "Comic books", "Fiction",
                           "Non-fiction books", "Newspapers")
        l29 <- likert(items29)
        l29
        lapply(items29, levels)

like this

        u <- unique(scrounging$behav)
        levels.behav <- c("inactive", u[u!="inactive"])
        scrounging$behav <- factor(x=scrounging$behav, levels=levels.behav)
        u <- unique(scrounging$substr)
        levels.substr <- c("ground", u[u!="ground"])
        scrounging$substr <- factor(x=scrounging$substr, levels=levels.substr)
        likert::likert(scrounging)

yielding

            Item inactive active foraging snoozing
        1  behav       36     20       20       24
        2 substr       20     28       30       22

but I doubt this is meaningful ...

Best,
Rasmus


From jr@| @end|ng |rom po@teo@no  Thu Mar 11 23:32:59 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 11 Mar 2021 23:32:59 +0100
Subject: [R] [External] Re:  [External] Re:  Help please
In-Reply-To: <CO1PR11MB51075B4DB7DB513BC9F77DD1D2909@CO1PR11MB5107.namprd11.prod.outlook.com>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
 <CA+8X3fWOuq6+NJet7dLVX4gkbHAt_gjM_UbxU_52n_ngW2XS1g@mail.gmail.com>
 <CO1PR11MB5107360278AB43B3DF1B6DE0D2909@CO1PR11MB5107.namprd11.prod.outlook.com>
 <YEojGReE43FIEgS/@posteo.no>
 <CO1PR11MB51075B4DB7DB513BC9F77DD1D2909@CO1PR11MB5107.namprd11.prod.outlook.com>
Message-ID: <YEqamzGPSD0xhevH@posteo.no>

That is such a nice email crammed with 
useful info I'm sure Areti Panopoulou 
appreciates.  JR

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210311/5f964368/attachment.sig>

From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar 12 10:22:39 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 12 Mar 2021 22:22:39 +1300
Subject: [R] 
 quantile from quantile table calculation without original data
In-Reply-To: <a49f19e7a79641f7878f11ba478f0773@SRVEXCHCM1302.precheza.cz>
References: <1614935662799.60644@precheza.cz>
 <CAB8pepzwR97maS4PuF9UYPPGuONqwPfQ4e4AxmyxFAoipXBZYA@mail.gmail.com>
 <CAB8pepzddGaX5NFnzqSJq6YR3t+-cwKAg=rfH9a=1pEt08ATwQ@mail.gmail.com>
 <CAB8pepwdDhdozwPwa7E5QuQ_B_1BWDP28uj46YJVNEioWLsbkw@mail.gmail.com>
 <362ec2a4-8c88-36ac-1b1b-19ab97362515@comcast.net>
 <a49f19e7a79641f7878f11ba478f0773@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAB8pepy2m_jjXZeHisS4UfuyFnV8RA2w51fOecGdV+a-3PW4DQ@mail.gmail.com>

Hi Petr,

In principle, I like David's approach the best.
However, I note that there's a bug in the squared step.
Furthemore, the variance of the sample quantiles should increase as
they move away from the modal region.

I've built on David's approach, but changed it to a two stage
optimization algorithm.
The parameter estimates from the first stage are used to compute density values.
Then the second stage is weighted, using the scaled density values.

I tried to create an iteratively reweighted algorithm.
However, it didn't converge.
(But that doesn't necessarily mean it can't be done).

The following code returns the value: 1.648416e-05

qfit.lnorm <- function (p, q, lower.tail=TRUE, ...,
    par0 = c (-0.5, 0.5) )
{   n <- length (p)
    qsample <- q

    objf <- function (par)
    {   qmodel <- qlnorm (p, par [1], par [2], lower.tail)
        sum ( (qmodel - qsample)^2) / n
    }
    objf.w <- function (wpar, w)
    {   qmodel <- qlnorm (p, wpar [1], wpar [2], lower.tail)
        sum (w * (qmodel - qsample)^2)
    }

    wpar0 <- optim (par0, objf)$par
    w <- dlnorm (p, wpar0 [1], wpar0 [2], lower.tail)
    optim (wpar0, objf.w,, w=w)
}

par <- qfit.lnorm (temp$percent, temp$size, FALSE)$par
plnorm (0.1, par [1], par [2])


On Tue, Mar 9, 2021 at 2:52 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hallo David, Abby and Bert
>
> Thank you for your solutions. In the meantime I found package rriskDistributions, which was able to calculate values for lognormal distribution from quantiles.
>
> Abby
> > 1-psolution
> [1] 9.980823e-06
>
> David
> > plnorm(0.1, -.7020649, .4678656)
> [1] 0.0003120744
>
> rriskDistributions
> > plnorm(0.1, -.6937355, .3881209)
> [1] 1.697379e-05
>
> Bert suggested to ask for original data before quantile calculation what is probably the best but also the most problematic solution. Actually, maybe original data are unavailable as it is the result from particle size measurement, where the software always twist the original data and spits only descriptive results.
>
> All your results are quite consistent with the available values as they are close to 1, so for me, each approach works.
>
> Thank you again.
>
> Best regards.
> Petr
>
> > -----Original Message-----
> > From: David Winsemius <dwinsemius at comcast.net>
> > Sent: Sunday, March 7, 2021 1:33 AM
> > To: Abby Spurdle <spurdle.a at gmail.com>; PIKAL Petr
> > <petr.pikal at precheza.cz>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] quantile from quantile table calculation without original data
> >
> >
> > On 3/6/21 1:02 AM, Abby Spurdle wrote:
> > > I came up with a solution.
> > > But not necessarily the best solution.
> > >
> > > I used a spline to approximate the quantile function.
> > > Then use that to generate a large sample.
> > > (I don't see any need for the sample to be random, as such).
> > > Then compute the sample mean and sd, on a log scale.
> > > Finally, plug everything into the plnorm function:
> > >
> > > p <- seq (0.01, 0.99,, 1e6)
> > > Fht <- splinefun (temp$percent, temp$size) x <- log (Fht (p) )
> > > psolution <- plnorm (0.1, mean (x), sd (x), FALSE) psolution
> > >
> > > The value of the solution is very close to one.
> > > Which is not a surprise.
> > >
> > > Here's a plot of everything:
> > >
> > > u <- seq (0.000001, 1.65,, 200)
> > > v <- plnorm (u, mean (x), sd (x), FALSE) plot (u, v, type="l", ylim =
> > > c (0, 1) ) points (temp$size, temp$percent, pch=16) points (0.1,
> > > psolution, pch=16, col="blue")
> >
> > Here's another approach, which uses minimization of the squared error to
> > get the parameters for a lognormal distribution.
> >
> > temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477, 0.5069, 0.3781,
> > 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95,
> > 0.99)), .Names = c("size", "percent"
> > ), row.names = c(NA, -9L), class = "data.frame")
> >
> > obj <- function(x) {sum( qlnorm(1-temp$percent, x[[1]], x[[2]])-temp$size
> > )^2}
> >
> > # Note the inversion of the poorly named and flipped "percent" column,
> >
> > optim( list(a=-0.65, b=0.42), obj)
> >
> > #--------------------
> >
> > $par
> >           a          b
> > -0.7020649  0.4678656
> >
> > $value
> > [1] 3.110316e-12
> >
> > $counts
> > function gradient
> >        51       NA
> >
> > $convergence
> > [1] 0
> >
> > $message
> > NULL
> >
> >
> > I'm not sure how principled this might be. There's no consideration in this
> > approach for expected sampling error at the right tail where the magnitudes
> > of the observed values will create much larger contributions to the sum of
> > squares.
> >
> > --
> >
> > David.
> >
> > >
> > >
> > > On Sat, Mar 6, 2021 at 8:09 PM Abby Spurdle <spurdle.a at gmail.com>
> > wrote:
> > >> I'm sorry.
> > >> I misread your example, this morning.
> > >> (I didn't read the code after the line that calls plot).
> > >>
> > >> After looking at this problem again, interpolation doesn't apply, and
> > >> extrapolation would be a last resort.
> > >> If you can assume your data comes from a particular type of
> > >> distribution, such as a lognormal distribution, then a better
> > >> approach would be to find the most likely parameters.
> > >>
> > >> i.e.
> > >> This falls within the broader scope of maximum likelihood.
> > >> (Except that you're dealing with a table of quantile-probability
> > >> pairs, rather than raw observational data).
> > >>
> > >> I suspect that there's a relatively easy way of finding the parameters.
> > >>
> > >> I'll think about it...
> > >> But someone else may come back with an answer first...
> > >>
> > >>
> > >> On Sat, Mar 6, 2021 at 8:17 AM Abby Spurdle <spurdle.a at gmail.com>
> > wrote:
> > >>> I note three problems with your data:
> > >>> (1) The name "percent" is misleading, perhaps you want "probability"?
> > >>> (2) There are straight (or near-straight) regions, each of which, is
> > >>> equally (or near-equally) spaced, which is not what I would expect
> > >>> in problems involving "quantiles".
> > >>> (3) Your plot (approximating the distribution function) is
> > >>> back-the-front (as per what is customary).
> > >>>
> > >>>
> > >>> On Fri, Mar 5, 2021 at 10:14 PM PIKAL Petr <petr.pikal at precheza.cz>
> > wrote:
> > >>>> Dear all
> > >>>>
> > >>>> I have table of quantiles, probably from lognormal distribution
> > >>>>
> > >>>>   dput(temp)
> > >>>> temp <- structure(list(size = c(1.6, 0.9466, 0.8062, 0.6477,
> > >>>> 0.5069, 0.3781, 0.3047, 0.2681, 0.1907), percent = c(0.01, 0.05,
> > >>>> 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99)), .Names = c("size", "percent"
> > >>>> ), row.names = c(NA, -9L), class = "data.frame")
> > >>>>
> > >>>> and I need to calculate quantile for size 0.1
> > >>>>
> > >>>> plot(temp$size, temp$percent, pch=19, xlim=c(0,2)) ss <-
> > >>>> approxfun(temp$size, temp$percent) points((0:100)/50,
> > >>>> ss((0:100)/50))
> > >>>> abline(v=.1)
> > >>>>
> > >>>> If I had original data it would be quite easy with ecdf/quantile function
> > but without it I am lost what function I could use for such task.
> > >>>>
> > >>>> Please, give me some hint where to look.
> > >>>>
> > >>>>
> > >>>> Best regards
> > >>>>
> > >>>> Petr
> > >>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
> > >>>> obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> > >>>> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ |
> > >>>> Information about processing and protection of business partner's
> > >>>> personal data are available on website:
> > >>>> https://www.precheza.cz/en/personal-data-protection-principles/
> > >>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > >>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > >>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and
> > >>>> any documents attached to it may be confidential and are subject to
> > >>>> the legally binding disclaimer:
> > >>>> https://www.precheza.cz/en/01-disclaimer/
> > >>>>
> > >>>>
> > >>>>          [[alternative HTML version deleted]]
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide
> > >>>> http://www.R-project.org/posting-guide.html
> > >>>> and provide commented, minimal, self-contained, reproducible code.
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From @ret|p@nopou|ou @end|ng |rom gm@||@com  Fri Mar 12 14:42:28 2021
From: @ret|p@nopou|ou @end|ng |rom gm@||@com (Areti Panopoulou)
Date: Fri, 12 Mar 2021 13:42:28 +0000
Subject: [R] [External] Re:  [External] Re: Help please
In-Reply-To: <YEqamzGPSD0xhevH@posteo.no>
References: <CAGFDBznpBL9QsPVrR=i1+rawAN10dsAC0KoYq+z_wfc22ubokg@mail.gmail.com>
 <CA+8X3fWOuq6+NJet7dLVX4gkbHAt_gjM_UbxU_52n_ngW2XS1g@mail.gmail.com>
 <CO1PR11MB5107360278AB43B3DF1B6DE0D2909@CO1PR11MB5107.namprd11.prod.outlook.com>
 <YEojGReE43FIEgS/@posteo.no>
 <CO1PR11MB51075B4DB7DB513BC9F77DD1D2909@CO1PR11MB5107.namprd11.prod.outlook.com>
 <YEqamzGPSD0xhevH@posteo.no>
Message-ID: <CAGFDBz=Vu_nJQx9Qaz-vwUma8+9AOuJuO+goNNje5sNt4EVoYA@mail.gmail.com>

Thank you so much everyone for your time and help! I really appreciate it.

Kind Regards,
Areti

On Thu, Mar 11, 2021 at 10:34 PM Rasmus Liland <jral at posteo.no> wrote:

> That is such a nice email crammed with
> useful info I'm sure Areti Panopoulou
> appreciates.  JR
>

	[[alternative HTML version deleted]]


From x|@oy@n@yu @end|ng |rom gm@||@com  Fri Mar 12 18:13:23 2021
From: x|@oy@n@yu @end|ng |rom gm@||@com (xiaoyan yu)
Date: Fri, 12 Mar 2021 12:13:23 -0500
Subject: [R] R extension memory leak detection question
Message-ID: <CANjVfJ1mAeXDLp43nYrtEoKFiqP-4xpc17nz4XYuNaY8qQw+_A@mail.gmail.com>

I am writing C++ program based on R extensions and also try to test the
program with google address sanitizer.

I thought if we don't protect the variable from the allocation API such as
Rf_allocVector, there will be a memory leak. However, the address sanitizer
didn't report it. Is my understanding correct? Or I will see the memory
leak only if I compile R source code with the address sanitizer.

 Please help!

Thanks,
Xiaoyan

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Mar 12 18:35:38 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Mar 2021 09:35:38 -0800
Subject: [R] R extension memory leak detection question
In-Reply-To: <CANjVfJ1mAeXDLp43nYrtEoKFiqP-4xpc17nz4XYuNaY8qQw+_A@mail.gmail.com>
References: <CANjVfJ1mAeXDLp43nYrtEoKFiqP-4xpc17nz4XYuNaY8qQw+_A@mail.gmail.com>
Message-ID: <CAGxFJbTtjwoBG=rMf3e2g3+emNQcLwTauRQqgb8Rkqw3cvEVpw@mail.gmail.com>

This is the wrong list for such questions. Post to r-devel instead.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 12, 2021 at 9:13 AM xiaoyan yu <xiaoyan.yu at gmail.com> wrote:

> I am writing C++ program based on R extensions and also try to test the
> program with google address sanitizer.
>
> I thought if we don't protect the variable from the allocation API such as
> Rf_allocVector, there will be a memory leak. However, the address sanitizer
> didn't report it. Is my understanding correct? Or I will see the memory
> leak only if I compile R source code with the address sanitizer.
>
>  Please help!
>
> Thanks,
> Xiaoyan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Mar 12 18:37:00 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 12 Mar 2021 12:37:00 -0500
Subject: [R] R extension memory leak detection question
In-Reply-To: <CANjVfJ1mAeXDLp43nYrtEoKFiqP-4xpc17nz4XYuNaY8qQw+_A@mail.gmail.com>
References: <CANjVfJ1mAeXDLp43nYrtEoKFiqP-4xpc17nz4XYuNaY8qQw+_A@mail.gmail.com>
Message-ID: <bd2d1667-75ca-f745-548d-ad15f96e41fb@gmail.com>

On 12/03/2021 12:13 p.m., xiaoyan yu wrote:
> I am writing C++ program based on R extensions and also try to test the
> program with google address sanitizer.
> 
> I thought if we don't protect the variable from the allocation API such as
> Rf_allocVector, there will be a memory leak. However, the address sanitizer
> didn't report it. Is my understanding correct? Or I will see the memory
> leak only if I compile R source code with the address sanitizer.
> 

Your question is unclear without an actual example.  It all depends on 
how the variable was created and how you use it.

If your real code is only a few lines, post it here.  Otherwise, please 
put together a minimal working example that contains the essence of what 
you are doing in a few lines.  Check that it compiles, and we can 
provide advice about whether it is doing dangerous things.

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Mar 12 18:38:51 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 12 Mar 2021 12:38:51 -0500
Subject: [R] R extension memory leak detection question
In-Reply-To: <bd2d1667-75ca-f745-548d-ad15f96e41fb@gmail.com>
References: <CANjVfJ1mAeXDLp43nYrtEoKFiqP-4xpc17nz4XYuNaY8qQw+_A@mail.gmail.com>
 <bd2d1667-75ca-f745-548d-ad15f96e41fb@gmail.com>
Message-ID: <dbd92a6d-76eb-a276-20d1-043f9ac93905@gmail.com>

On 12/03/2021 12:37 p.m., Duncan Murdoch wrote:
> On 12/03/2021 12:13 p.m., xiaoyan yu wrote:
>> I am writing C++ program based on R extensions and also try to test the
>> program with google address sanitizer.
>>
>> I thought if we don't protect the variable from the allocation API such as
>> Rf_allocVector, there will be a memory leak. However, the address sanitizer
>> didn't report it. Is my understanding correct? Or I will see the memory
>> leak only if I compile R source code with the address sanitizer.
>>
> 
> Your question is unclear without an actual example.  It all depends on
> how the variable was created and how you use it.
> 
> If your real code is only a few lines, post it here. 

Sorry, to R-devel, not here.


  Otherwise, please
> put together a minimal working example that contains the essence of what
> you are doing in a few lines.  Check that it compiles, and we can
> provide advice about whether it is doing dangerous things.
> 
> Duncan Murdoch
>


From |by409014519 @end|ng |rom |c|oud@com  Fri Mar 12 05:32:17 2021
From: |by409014519 @end|ng |rom |c|oud@com (=?gb2312?B?sc+3vMTd?=)
Date: Fri, 12 Mar 2021 12:32:17 +0800
Subject: [R] Very slow optim(): solved
Message-ID: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>

Dear list, 
 I am using optim() to estimate over 60 thousans of parameters, and use the server to run the program.But it took me 5 hours and there was just no result coming out.How could I do to show some results that have been calculated by optim()?

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Mar 13 03:31:26 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 12 Mar 2021 18:31:26 -0800
Subject: [R] Very slow optim(): solved
In-Reply-To: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
References: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
Message-ID: <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>

Calculate fewer of them?

If you don't setup your code to save intermediate results, then you cannot see intermediate results.

On March 11, 2021 8:32:17 PM PST, "??? via R-help" <r-help at r-project.org> wrote:
>Dear list, 
>I am using optim() to estimate over 60 thousans of parameters, and use
>the server to run the program.But it took me 5 hours and there was just
>no result coming out.How could I do to show some results that have been
>calculated by optim()?
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Mar 13 03:53:26 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 12 Mar 2021 21:53:26 -0500
Subject: [R] Very slow optim()
In-Reply-To: <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>
References: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
 <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>
Message-ID: <64210cd0-d1d4-586c-f57f-b5adf80b1f23@gmail.com>

optim() has no method really suitable for very large numbers of parameters.

- CG as set up has never worked very well in any of its implementations
  (I wrote it, so am allowed to say so!). Rcgmin in optimx package works
  better, as does Rtnmin. Neither are really intended for 60K parameters
  however.

- optim::L-BFGS-B is reasonable, but my experience is that it still is not
  intended for more than a couple of hundred parameters.

JN



On 2021-03-12 9:31 p.m., Jeff Newmiller wrote:
> Calculate fewer of them?
> 
> If you don't setup your code to save intermediate results, then you cannot see intermediate results.
> 
> On March 11, 2021 8:32:17 PM PST, "??? via R-help" <r-help at r-project.org> wrote:
>> Dear list, 
>> I am using optim() to estimate over 60 thousans of parameters, and use
>> the server to run the program.But it took me 5 hours and there was just
>> no result coming out.How could I do to show some results that have been
>> calculated by optim()?
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sat Mar 13 05:38:22 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Fri, 12 Mar 2021 22:38:22 -0600
Subject: [R] Very slow optim()
In-Reply-To: <64210cd0-d1d4-586c-f57f-b5adf80b1f23@gmail.com>
References: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
 <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>
 <64210cd0-d1d4-586c-f57f-b5adf80b1f23@gmail.com>
Message-ID: <a0ac02d0-7f9c-75ba-fd9b-94f206a1ac41@effectivedefense.org>

TWO COMMENTS:


1.  DID YOU ASSIGN THE OUTPUT OF "optim" to an object, like "est <- 
optim(...)"?  If yes and if "optim" terminated normally, the 60,000+ 
paramters should be there as est$par.  See the documentation on "optim".


2.  WHAT PROBLEM ARE YOU TRYING TO SOLVE?


	  I hope you will forgive me for being blunt (or perhaps bigoted), but 
I'm skeptical about anyone wanting to use optim to estimate 60,000+ 
parameters.  With a situation like that, I think you would be wise to 
recast the problem as one in which those 60,000+ parameters are sampled 
from some hyperdistribution characterized by a small number of 
hyperparameters.  Then write a model where your observations are sampled 
from distribution(s) controlled by these random parameters.  Then 
multiply the likelihood of the observations by the likelihood of the 
hyperdistribution and integrate out the 60,000+ parameters, leaving only 
a small number hyperparameters.


	  When everything is linear and all the random variables / random 
effects and observation errors follow normal distributions, this is the 
classic linear, mixed-effects situation that is routinely handled well 
for most such situations by the nlme package, documented with in 
companion book Pinhiero and Bates (2000) Mixed-Effects Models in S and 
S-PLUS (Springer).  If the models are nonlinear but with curvature that 
is reasonably well behaved and the random variables / random effects and 
observation errors are still normal, the nlme package and Pinhiero and 
Bates still provide a great approach to most such situations, as far as 
I know.  When the observations are non-normally distributed, then the 
best software I know is the lme4 package.  I have not used it recently, 
but it was written and being maintained by some of the leading experts 
in this area as far as I know.


CONCLUSION:


	  If you are short on time and "1" will work for you, do that. 
Obviously, you will need to do some further analysis to understand the 
60,000+ parameters you estimated -- which implies by itself that you 
really should be using approach "2".  However, if I'm short on time and 
need an answer, then I'd ignore "2" and hope to get something by 
plotting and doing other things with the 60,000+ parameters that should 
be in "est$par" if "optim" actually ended normally.


	  However, if the problem is sufficiently important to justify more 
work, then I'd want to cast it as some kind if mixed-effects model, per 
"2" -- perhaps using an analysis of "1" as a first step towards "2".


	  Hope this helps.
	  Spencer


On 2021-03-12 20:53, J C Nash wrote:
> optim() has no method really suitable for very large numbers of parameters.
> 
> - CG as set up has never worked very well in any of its implementations
>    (I wrote it, so am allowed to say so!). Rcgmin in optimx package works
>    better, as does Rtnmin. Neither are really intended for 60K parameters
>    however.
> 
> - optim::L-BFGS-B is reasonable, but my experience is that it still is not
>    intended for more than a couple of hundred parameters.
> 
> JN
> 
> 
> 
> On 2021-03-12 9:31 p.m., Jeff Newmiller wrote:
>> Calculate fewer of them?
>>
>> If you don't setup your code to save intermediate results, then you cannot see intermediate results.
>>
>> On March 11, 2021 8:32:17 PM PST, "??? via R-help" <r-help at r-project.org> wrote:
>>> Dear list,
>>> I am using optim() to estimate over 60 thousans of parameters, and use
>>> the server to run the program.But it took me 5 hours and there was just
>>> no result coming out.How could I do to show some results that have been
>>> calculated by optim()?
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Mar 13 08:27:57 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 13 Mar 2021 12:57:57 +0530
Subject: [R] Very slow optim()
In-Reply-To: <a0ac02d0-7f9c-75ba-fd9b-94f206a1ac41@effectivedefense.org>
References: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
 <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>
 <64210cd0-d1d4-586c-f57f-b5adf80b1f23@gmail.com>
 <a0ac02d0-7f9c-75ba-fd9b-94f206a1ac41@effectivedefense.org>
Message-ID: <CADfFDC51pfwfkDQMEjmtKUitJV=0Y+q334RQEqSwGBp3B=yMgQ@mail.gmail.com>

On Sat, Mar 13, 2021 at 10:08 AM Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
>
> TWO COMMENTS:
>
>
> 1.  DID YOU ASSIGN THE OUTPUT OF "optim" to an object, like "est <-
> optim(...)"?  If yes and if "optim" terminated normally, the 60,000+
> paramters should be there as est$par.  See the documentation on "optim".
>
>
> 2.  WHAT PROBLEM ARE YOU TRYING TO SOLVE?
>
>
>           I hope you will forgive me for being blunt (or perhaps bigoted), but
> I'm skeptical about anyone wanting to use optim to estimate 60,000+
> parameters.  With a situation like that, I think you would be wise to
> recast the problem as one in which those 60,000+ parameters are sampled
> from some hyperdistribution characterized by a small number of
> hyperparameters.  Then write a model where your observations are sampled
> from distribution(s) controlled by these random parameters.  Then
> multiply the likelihood of the observations by the likelihood of the
> hyperdistribution and integrate out the 60,000+ parameters, leaving only
> a small number hyperparameters.

Just a comment on this comment: I think it's perfectly reasonable to
optimize 60k+ parameters with conjugate gradient. CG was originally
developed to solve linear equations of the form Ax=b. If x was not
large in size, one would just use solve(A, b) instead of an iterative
method.

Use of CG is quite common in image processing. A relatively small
300x300 image will give you 90k parameters.

-Deepayan


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sat Mar 13 12:03:48 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sat, 13 Mar 2021 05:03:48 -0600
Subject: [R] Very slow optim()
In-Reply-To: <CADfFDC51pfwfkDQMEjmtKUitJV=0Y+q334RQEqSwGBp3B=yMgQ@mail.gmail.com>
References: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
 <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>
 <64210cd0-d1d4-586c-f57f-b5adf80b1f23@gmail.com>
 <a0ac02d0-7f9c-75ba-fd9b-94f206a1ac41@effectivedefense.org>
 <CADfFDC51pfwfkDQMEjmtKUitJV=0Y+q334RQEqSwGBp3B=yMgQ@mail.gmail.com>
Message-ID: <9d250158-5f94-71fb-8163-26252ceb1dba@effectivedefense.org>

Hi, Deepayan:


On 2021-03-13 01:27, Deepayan Sarkar wrote:
> On Sat, Mar 13, 2021 at 10:08 AM Spencer Graves
> <spencer.graves at effectivedefense.org> wrote:
>>
>> TWO COMMENTS:
>>
>>
>> 1.  DID YOU ASSIGN THE OUTPUT OF "optim" to an object, like "est <-
>> optim(...)"?  If yes and if "optim" terminated normally, the 60,000+
>> paramters should be there as est$par.  See the documentation on "optim".
>>
>>
>> 2.  WHAT PROBLEM ARE YOU TRYING TO SOLVE?
>>
>>
>>            I hope you will forgive me for being blunt (or perhaps bigoted), but
>> I'm skeptical about anyone wanting to use optim to estimate 60,000+
>> parameters.  With a situation like that, I think you would be wise to
>> recast the problem as one in which those 60,000+ parameters are sampled
>> from some hyperdistribution characterized by a small number of
>> hyperparameters.  Then write a model where your observations are sampled
>> from distribution(s) controlled by these random parameters.  Then
>> multiply the likelihood of the observations by the likelihood of the
>> hyperdistribution and integrate out the 60,000+ parameters, leaving only
>> a small number hyperparameters.
> 
> Just a comment on this comment: I think it's perfectly reasonable to
> optimize 60k+ parameters with conjugate gradient. CG was originally
> developed to solve linear equations of the form Ax=b. If x was not
> large in size, one would just use solve(A, b) instead of an iterative
> method.
> 
> Use of CG is quite common in image processing. A relatively small
> 300x300 image will give you 90k parameters.
> 
> -Deepayan
> 

	  Thanks for this.


	  If both A and b are 300x300, then x will also be 300x300.


	  What do you do in this case if A is not square or even ill conditioned?


	  Do you care if you get only one of many possible or approximate 
solutions, and the algorithm spends most of its time making adjustments 
in a singular subspace that would have best been avoided?


	  Spencer


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Mar 13 12:56:08 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 13 Mar 2021 17:26:08 +0530
Subject: [R] Very slow optim()
In-Reply-To: <9d250158-5f94-71fb-8163-26252ceb1dba@effectivedefense.org>
References: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
 <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>
 <64210cd0-d1d4-586c-f57f-b5adf80b1f23@gmail.com>
 <a0ac02d0-7f9c-75ba-fd9b-94f206a1ac41@effectivedefense.org>
 <CADfFDC51pfwfkDQMEjmtKUitJV=0Y+q334RQEqSwGBp3B=yMgQ@mail.gmail.com>
 <9d250158-5f94-71fb-8163-26252ceb1dba@effectivedefense.org>
Message-ID: <CADfFDC6o2V=aWk6aqhYWqAbihZ7K6tynMUWPOOsF-eDypNXLLg@mail.gmail.com>

On Sat, Mar 13, 2021 at 4:33 PM Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
>
> Hi, Deepayan:
>
>
> On 2021-03-13 01:27, Deepayan Sarkar wrote:
> > On Sat, Mar 13, 2021 at 10:08 AM Spencer Graves
> > <spencer.graves at effectivedefense.org> wrote:
> >>
> >> TWO COMMENTS:
> >>
> >>
> >> 1.  DID YOU ASSIGN THE OUTPUT OF "optim" to an object, like "est <-
> >> optim(...)"?  If yes and if "optim" terminated normally, the 60,000+
> >> paramters should be there as est$par.  See the documentation on "optim".
> >>
> >>
> >> 2.  WHAT PROBLEM ARE YOU TRYING TO SOLVE?
> >>
> >>
> >>            I hope you will forgive me for being blunt (or perhaps bigoted), but
> >> I'm skeptical about anyone wanting to use optim to estimate 60,000+
> >> parameters.  With a situation like that, I think you would be wise to
> >> recast the problem as one in which those 60,000+ parameters are sampled
> >> from some hyperdistribution characterized by a small number of
> >> hyperparameters.  Then write a model where your observations are sampled
> >> from distribution(s) controlled by these random parameters.  Then
> >> multiply the likelihood of the observations by the likelihood of the
> >> hyperdistribution and integrate out the 60,000+ parameters, leaving only
> >> a small number hyperparameters.
> >
> > Just a comment on this comment: I think it's perfectly reasonable to
> > optimize 60k+ parameters with conjugate gradient. CG was originally
> > developed to solve linear equations of the form Ax=b. If x was not
> > large in size, one would just use solve(A, b) instead of an iterative
> > method.
> >
> > Use of CG is quite common in image processing. A relatively small
> > 300x300 image will give you 90k parameters.
> >
> > -Deepayan
> >
>
>           Thanks for this.
>
>
>           If both A and b are 300x300, then x will also be 300x300.

Sorry for being unclear: the images themselves (b or x) are viewed as
a vector, so would be 90000x1. A would be 90000x90000, so essentially
impossible to construct. CG can solve Ax=b as long as Ax can be
evaluated (for arbitrary x).

>           What do you do in this case if A is not square or even ill conditioned?

A has to be p.d.

>           Do you care if you get only one of many possible or approximate
> solutions, and the algorithm spends most of its time making adjustments
> in a singular subspace that would have best been avoided?

Well, in my experience, optim(method="CG") behaves quite badly if A is
not full-rank. I don't think other implementations will be any better,
but I am not sure.

If you are interested in practical uses of this, we can discuss more off-list.

-Deepayan


>           Spencer
>
>
>


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Mar 13 15:05:45 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sat, 13 Mar 2021 09:05:45 -0500
Subject: [R] Very slow optim()
In-Reply-To: <CADfFDC6o2V=aWk6aqhYWqAbihZ7K6tynMUWPOOsF-eDypNXLLg@mail.gmail.com>
References: <C194FBAA-9935-415A-9448-EBCE42CEFB0D@icloud.com>
 <B94D51F0-2DFE-458F-A4AA-3E132006B098@dcn.davis.ca.us>
 <64210cd0-d1d4-586c-f57f-b5adf80b1f23@gmail.com>
 <a0ac02d0-7f9c-75ba-fd9b-94f206a1ac41@effectivedefense.org>
 <CADfFDC51pfwfkDQMEjmtKUitJV=0Y+q334RQEqSwGBp3B=yMgQ@mail.gmail.com>
 <9d250158-5f94-71fb-8163-26252ceb1dba@effectivedefense.org>
 <CADfFDC6o2V=aWk6aqhYWqAbihZ7K6tynMUWPOOsF-eDypNXLLg@mail.gmail.com>
Message-ID: <8d8911e0-6f1f-2a98-c37a-f81a2b6345fe@gmail.com>

As per my post on this, it is important to distinguish between
"CG" as a general approach and optim::CG. The latter -- my algorithm 22
from Compact Numerical Methods for Computers in 1979 -- never worked
terribly well. But Rcgmin and Rtnmin from optimx often (but not always)
perform quite well.

There are some developments that I've poked at a few times. If the
optimization of very large numbers of parameters as a general (rather
than specific problem type), then this would be worth pursuing for R.
However, we need some representative, and easy to set up, test problems.
Otherwise we get this very hand-waving list discussion.

JN


On 2021-03-13 6:56 a.m., Deepayan Sarkar wrote:
> On Sat, Mar 13, 2021 at 4:33 PM Spencer Graves
> <spencer.graves at effectivedefense.org> wrote:
>>
>> Hi, Deepayan:
>>
>>
>> On 2021-03-13 01:27, Deepayan Sarkar wrote:
>>> On Sat, Mar 13, 2021 at 10:08 AM Spencer Graves
>>> <spencer.graves at effectivedefense.org> wrote:
>>>>
>>>> TWO COMMENTS:
>>>>
>>>>
>>>> 1.  DID YOU ASSIGN THE OUTPUT OF "optim" to an object, like "est <-
>>>> optim(...)"?  If yes and if "optim" terminated normally, the 60,000+
>>>> paramters should be there as est$par.  See the documentation on "optim".
>>>>
>>>>
>>>> 2.  WHAT PROBLEM ARE YOU TRYING TO SOLVE?
>>>>
>>>>
>>>>            I hope you will forgive me for being blunt (or perhaps bigoted), but
>>>> I'm skeptical about anyone wanting to use optim to estimate 60,000+
>>>> parameters.  With a situation like that, I think you would be wise to
>>>> recast the problem as one in which those 60,000+ parameters are sampled
>>>> from some hyperdistribution characterized by a small number of
>>>> hyperparameters.  Then write a model where your observations are sampled
>>>> from distribution(s) controlled by these random parameters.  Then
>>>> multiply the likelihood of the observations by the likelihood of the
>>>> hyperdistribution and integrate out the 60,000+ parameters, leaving only
>>>> a small number hyperparameters.
>>>
>>> Just a comment on this comment: I think it's perfectly reasonable to
>>> optimize 60k+ parameters with conjugate gradient. CG was originally
>>> developed to solve linear equations of the form Ax=b. If x was not
>>> large in size, one would just use solve(A, b) instead of an iterative
>>> method.
>>>
>>> Use of CG is quite common in image processing. A relatively small
>>> 300x300 image will give you 90k parameters.
>>>
>>> -Deepayan
>>>
>>
>>           Thanks for this.
>>
>>
>>           If both A and b are 300x300, then x will also be 300x300.
> 
> Sorry for being unclear: the images themselves (b or x) are viewed as
> a vector, so would be 90000x1. A would be 90000x90000, so essentially
> impossible to construct. CG can solve Ax=b as long as Ax can be
> evaluated (for arbitrary x).
> 
>>           What do you do in this case if A is not square or even ill conditioned?
> 
> A has to be p.d.
> 
>>           Do you care if you get only one of many possible or approximate
>> solutions, and the algorithm spends most of its time making adjustments
>> in a singular subspace that would have best been avoided?
> 
> Well, in my experience, optim(method="CG") behaves quite badly if A is
> not full-rank. I don't think other implementations will be any better,
> but I am not sure.
> 
> If you are interested in practical uses of this, we can discuss more off-list.
> 
> -Deepayan
> 
> 
>>           Spencer
>>
>>
>>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Mar 14 17:46:18 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 14 Mar 2021 17:46:18 +0100
Subject: [R] Failure in predicting parameters
Message-ID: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>

Hello,
I would like to use the Rutledge equation
(https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
equation is:
Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
I defined the equation and another that subtracts the values from the
expectations. I used minpack.lm to get the parameters, but I got an
error:
```

> library("minpack.lm")
> h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
+        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
+        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
+        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
+        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
+        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35, 12100.63,
+        12133.57, 12148.89, 12137.09)
> high <- h[1:45]
> MaxFluo <- max(high)
> halfFluo <- MaxFluo/2
> halfCycle = 27
> find_slope <- function(X, Y) {
+   Slope <- c(0)
+   for (i in 2:length(X)) {
+     delta_x <- X[i] - X[i-1]
+     delta_y <- Y[i] - Y[i-1]
+     Slope[i] <- delta_y/delta_x
+   }
+   return(Slope)
+ }
> slopes <- find_slope(1:45, high)
>
> rutledge <- function(m, s, M, B, x) {
+   divisor = 1 + exp(-1* ((x-m)/s) )
+   y = (M/divisor) + B
+   return(y)
+ }
> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
>
>
> init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
> points(1:45, init, type="l", col="red")
> estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
+                 fn = rutledge_param, x = 1:45, y = high)
Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
high[1]),  :
  evaluation of fn function returns non-sensible value!
```

Where could the error be?


-- 
Best regards,
Luigi


From bgunter@4567 @end|ng |rom gm@||@com  Sun Mar 14 18:29:16 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 14 Mar 2021 10:29:16 -0700
Subject: [R] Failure in predicting parameters
In-Reply-To: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
References: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
Message-ID: <CAGxFJbRnmqmMcwRGBKvTX6UdP0xeXTsJDUOGaR2-JyP5jX-Hcw@mail.gmail.com>

Do the negative values in your data make any sense? Note that if Fb must be
>0, Fc must be also.

But I have *not* examined your code/equations in detail, so feel free to
ignore if this is irrelevant.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 14, 2021 at 9:46 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I would like to use the Rutledge equation
> (https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
> equation is:
> Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
> I defined the equation and another that subtracts the values from the
> expectations. I used minpack.lm to get the parameters, but I got an
> error:
> ```
>
> > library("minpack.lm")
> > h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> +        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28,
> 15.01,
> +        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> +        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> +        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07,
> 11684.96,
> +        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35,
> 12100.63,
> +        12133.57, 12148.89, 12137.09)
> > high <- h[1:45]
> > MaxFluo <- max(high)
> > halfFluo <- MaxFluo/2
> > halfCycle = 27
> > find_slope <- function(X, Y) {
> +   Slope <- c(0)
> +   for (i in 2:length(X)) {
> +     delta_x <- X[i] - X[i-1]
> +     delta_y <- Y[i] - Y[i-1]
> +     Slope[i] <- delta_y/delta_x
> +   }
> +   return(Slope)
> + }
> > slopes <- find_slope(1:45, high)
> >
> > rutledge <- function(m, s, M, B, x) {
> +   divisor = 1 + exp(-1* ((x-m)/s) )
> +   y = (M/divisor) + B
> +   return(y)
> + }
> > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s)))
> + p$B) - y
> >
> >
> > init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
> > points(1:45, init, type="l", col="red")
> > estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
> high[1]),
> +                 fn = rutledge_param, x = 1:45, y = high)
> Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
> high[1]),  :
>   evaluation of fn function returns non-sensible value!
> ```
>
> Where could the error be?
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sun Mar 14 20:04:56 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 14 Mar 2021 12:04:56 -0700
Subject: [R] Failure in predicting parameters
In-Reply-To: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
References: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
Message-ID: <CAHqSRuR3EvPudJWZignHHWCLJJVpiOBh1+QguC+V2z87XOQ2hg@mail.gmail.com>

> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y

Did you mean that p$x to be just x?  As is, this returns numeric(0)
for the p that nls.lm gives it because p$x is NULL and NULL-aNumber is
numeric().

-Bill

On Sun, Mar 14, 2021 at 9:46 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I would like to use the Rutledge equation
> (https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
> equation is:
> Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
> I defined the equation and another that subtracts the values from the
> expectations. I used minpack.lm to get the parameters, but I got an
> error:
> ```
>
> > library("minpack.lm")
> > h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> +        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> +        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> +        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> +        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> +        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35, 12100.63,
> +        12133.57, 12148.89, 12137.09)
> > high <- h[1:45]
> > MaxFluo <- max(high)
> > halfFluo <- MaxFluo/2
> > halfCycle = 27
> > find_slope <- function(X, Y) {
> +   Slope <- c(0)
> +   for (i in 2:length(X)) {
> +     delta_x <- X[i] - X[i-1]
> +     delta_y <- Y[i] - Y[i-1]
> +     Slope[i] <- delta_y/delta_x
> +   }
> +   return(Slope)
> + }
> > slopes <- find_slope(1:45, high)
> >
> > rutledge <- function(m, s, M, B, x) {
> +   divisor = 1 + exp(-1* ((x-m)/s) )
> +   y = (M/divisor) + B
> +   return(y)
> + }
> > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> >
> >
> > init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
> > points(1:45, init, type="l", col="red")
> > estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> +                 fn = rutledge_param, x = 1:45, y = high)
> Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
> high[1]),  :
>   evaluation of fn function returns non-sensible value!
> ```
>
> Where could the error be?
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Mar 15 07:39:26 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 15 Mar 2021 07:39:26 +0100
Subject: [R] Failure in predicting parameters
In-Reply-To: <CAHqSRuR3EvPudJWZignHHWCLJJVpiOBh1+QguC+V2z87XOQ2hg@mail.gmail.com>
References: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
 <CAHqSRuR3EvPudJWZignHHWCLJJVpiOBh1+QguC+V2z87XOQ2hg@mail.gmail.com>
Message-ID: <CAMk+s2SEKx-HDreBPr0b6QMtvEHquV=FBotaeHnti57goEA0Fw@mail.gmail.com>

Hello,
the negative data comes from the machine. Probably I should use raw
data directly, although in the paper this requirement is not reported.
The p$x was a typo. Now I corrected it and I got this error:
```

> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(x-p$m)/p$s))) + p$B) - y
> estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
+             fn = rutledge_param, x = 1:45, y = high)
Error in dimnames(x) <- dn :
  length of 'dimnames' [2] not equal to array extent
```
Probably because 'slopes' is a vector instead of a scalar. Since the
slope is changing, I don't think is right to use a scalar, but I tried
and I got:
```
> estim <- nls.lm(par = list(m = halfFluo, s = 1, M = MaxFluo, B = high[1]),
+             fn = rutledge_param, x = 1:45, y = high)
> estim
Nonlinear regression via the Levenberg-Marquardt algorithm
parameter estimates: 6010.94, 1, 12021.88, 4700.49288888889
residual sum-of-squares: 1.14e+09
reason terminated: Relative error in the sum of squares is at most `ftol'.
```
The values reported are the same I used at the beginning apart from
the last (the background parameter) which is 4700 instead of zero. If
I plug it, I get an L shaped plot that is worse than that at the
beginning:
```
after = init = rutledge(halfFluo, 1, MaxFluo, 4700.49288888889, high)
points(1:45, after, type="l", col="blue")
```
What did I get wrong here?
Thanks

On Sun, Mar 14, 2021 at 8:05 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
>
> Did you mean that p$x to be just x?  As is, this returns numeric(0)
> for the p that nls.lm gives it because p$x is NULL and NULL-aNumber is
> numeric().
>
> -Bill
>
> On Sun, Mar 14, 2021 at 9:46 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I would like to use the Rutledge equation
> > (https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
> > equation is:
> > Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
> > I defined the equation and another that subtracts the values from the
> > expectations. I used minpack.lm to get the parameters, but I got an
> > error:
> > ```
> >
> > > library("minpack.lm")
> > > h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> > +        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> > +        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> > +        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> > +        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> > +        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35, 12100.63,
> > +        12133.57, 12148.89, 12137.09)
> > > high <- h[1:45]
> > > MaxFluo <- max(high)
> > > halfFluo <- MaxFluo/2
> > > halfCycle = 27
> > > find_slope <- function(X, Y) {
> > +   Slope <- c(0)
> > +   for (i in 2:length(X)) {
> > +     delta_x <- X[i] - X[i-1]
> > +     delta_y <- Y[i] - Y[i-1]
> > +     Slope[i] <- delta_y/delta_x
> > +   }
> > +   return(Slope)
> > + }
> > > slopes <- find_slope(1:45, high)
> > >
> > > rutledge <- function(m, s, M, B, x) {
> > +   divisor = 1 + exp(-1* ((x-m)/s) )
> > +   y = (M/divisor) + B
> > +   return(y)
> > + }
> > > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> > >
> > >
> > > init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
> > > points(1:45, init, type="l", col="red")
> > > estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> > +                 fn = rutledge_param, x = 1:45, y = high)
> > Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
> > high[1]),  :
> >   evaluation of fn function returns non-sensible value!
> > ```
> >
> > Where could the error be?
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From gregco@t@ @end|ng |rom me@com  Mon Mar 15 22:33:33 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Mon, 15 Mar 2021 17:33:33 -0400
Subject: [R] How to plot dates
Message-ID: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>

I store in a text file the dates and times that an event occurred.
How do I direct R to import these text characters, and store the year, month, day, hour, minute, and second as a date?
How do I then plot this series of dates?
2021-03-11 10:00:00
2021-03-11 14:17:00
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56 
2021-03-14 17:25:23
2021-03-14 21:36:26
Greg Coats
gregcoats at me.com


	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Mon Mar 15 22:52:19 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Mon, 15 Mar 2021 16:52:19 -0500
Subject: [R] How to plot dates
In-Reply-To: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
Message-ID: <!&!LgAAAAAAAAAZcQfbZO6bT47JznTNjpL1AQDDto4Q93URzrTNAKoAu7bmAAAAAAAOAABGAAAAAAAAABlxB9tk7ptPjsnOdM2OkvUHAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AADntCQQjL3NIo494goqkANAAAAAAGFYAAAAAAAAQAAAAGw1IDAYA2k+Da2od784TjBoAAABSRTogW1JdIEhvdyB0byBwbG90IGRhdGVzAA==@sbcglobal.net>

Gregory

myDat <- data.frame(datetime = c("2021-03-11 10:00:00","2021-03-11
14:17:00","2021-03-12 05:16:46","2021-03-12 09:17:02",
           "2021-03-12 13:31:43","2021-03-12 22:00:32","2021-03-13
09:21:43","2021-03-13 13:51:12",
           "2021-03-13 18:03:13","2021-03-13 22:20:28","2021-03-14
08:59:03","2021-03-14 13:15:56",
           "2021-03-14 17:25:23","2021-03-14 21:36:26"))

# convert date to date time object
myDat$ datetime <- as.POSIXlt(myDat$ datetime, tz = "", format = "%Y-%M-%d
%H:%M:%OS")

# plotting
ggplot(myDat, aes(datetime, <y variable>)) .....

Jeff

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Gregory Coats via
R-help
Sent: Monday, March 15, 2021 4:34 PM
To: r-help mailing list <r-help at r-project.org>
Subject: [R] How to plot dates

I store in a text file the dates and times that an event occurred.
How do I direct R to import these text characters, and store the year,
month, day, hour, minute, and second as a date?
How do I then plot this series of dates?
2021-03-11 10:00:00
2021-03-11 14:17:00
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56 
2021-03-14 17:25:23
2021-03-14 21:36:26
Greg Coats
gregcoats at me.com


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 16 06:26:13 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 16 Mar 2021 16:26:13 +1100
Subject: [R] How to plot dates
In-Reply-To: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
Message-ID: <CA+8X3fWJioTt3wt8Yv-nue7mSeQVtSA_JQU+VDUvFeTuROow_w@mail.gmail.com>

Hi Greg,
As the POSIX conversion part is already answered, I'll add:

as.Date("16/03/2021",format="%d/%m/%Y")

converts to Date object and

axis.Date()

will display dates on the date axis in base graphics.

Jim

On Tue, 16 Mar 2021, 08:33 Gregory Coats via R-help <r-help at r-project.org
wrote:

> I store in a text file the dates and times that an event occurred.
> How do I direct R to import these text characters, and store the year,
> month, day, hour, minute, and second as a date?
> How do I then plot this series of dates?
> 2021-03-11 10:00:00
> 2021-03-11 14:17:00
> 2021-03-12 05:16:46
> 2021-03-12 09:17:02
> 2021-03-12 13:31:43
> 2021-03-12 22:00:32
> 2021-03-13 09:21:43
> 2021-03-13 13:51:12
> 2021-03-13 18:03:13
> 2021-03-13 22:20:28
> 2021-03-14 08:59:03
> 2021-03-14 13:15:56
> 2021-03-14 17:25:23
> 2021-03-14 21:36:26
> Greg Coats
> gregcoats at me.com
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Mar 16 08:29:09 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 16 Mar 2021 08:29:09 +0100
Subject: [R] Failure in predicting parameters
In-Reply-To: <CAMk+s2SEKx-HDreBPr0b6QMtvEHquV=FBotaeHnti57goEA0Fw@mail.gmail.com>
References: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
 <CAHqSRuR3EvPudJWZignHHWCLJJVpiOBh1+QguC+V2z87XOQ2hg@mail.gmail.com>
 <CAMk+s2SEKx-HDreBPr0b6QMtvEHquV=FBotaeHnti57goEA0Fw@mail.gmail.com>
Message-ID: <CAMk+s2S270X=QVnrFsVgsX7Wmr9vKCXnsG9Fn0tg8nqz=bk4xQ@mail.gmail.com>

Just an update:
I tried with desmos and the fitting looks good. Desmos calculated the
parameters as:
Fmax = 11839.8
Chalf = 27.1102 (with matches with my estimate of 27 cycles)
k = 2.76798
Fb = -138.864
I forced R to accept the right parameters using a single named list
and re-written the formula (it was a bit unclear in the paper):
```
rutledge <- function(p, x) {
  m = p$half_fluorescence
  s = p$slope
  M = p$max_fluorescence
  B = p$back_fluorescence
  y = (M / (1+exp( -((x-m)/s) )) ) + B
  return(y)
}
```
but when I apply it I get a funny graph:
```
desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
                        max_fluorescence = 11839.8, back_fluorescence
= -138.864) , high)
```

On Mon, Mar 15, 2021 at 7:39 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> the negative data comes from the machine. Probably I should use raw
> data directly, although in the paper this requirement is not reported.
> The p$x was a typo. Now I corrected it and I got this error:
> ```
>
> > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(x-p$m)/p$s))) + p$B) - y
> > estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> +             fn = rutledge_param, x = 1:45, y = high)
> Error in dimnames(x) <- dn :
>   length of 'dimnames' [2] not equal to array extent
> ```
> Probably because 'slopes' is a vector instead of a scalar. Since the
> slope is changing, I don't think is right to use a scalar, but I tried
> and I got:
> ```
> > estim <- nls.lm(par = list(m = halfFluo, s = 1, M = MaxFluo, B = high[1]),
> +             fn = rutledge_param, x = 1:45, y = high)
> > estim
> Nonlinear regression via the Levenberg-Marquardt algorithm
> parameter estimates: 6010.94, 1, 12021.88, 4700.49288888889
> residual sum-of-squares: 1.14e+09
> reason terminated: Relative error in the sum of squares is at most `ftol'.
> ```
> The values reported are the same I used at the beginning apart from
> the last (the background parameter) which is 4700 instead of zero. If
> I plug it, I get an L shaped plot that is worse than that at the
> beginning:
> ```
> after = init = rutledge(halfFluo, 1, MaxFluo, 4700.49288888889, high)
> points(1:45, after, type="l", col="blue")
> ```
> What did I get wrong here?
> Thanks
>
> On Sun, Mar 14, 2021 at 8:05 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
> >
> > > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> >
> > Did you mean that p$x to be just x?  As is, this returns numeric(0)
> > for the p that nls.lm gives it because p$x is NULL and NULL-aNumber is
> > numeric().
> >
> > -Bill
> >
> > On Sun, Mar 14, 2021 at 9:46 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I would like to use the Rutledge equation
> > > (https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
> > > equation is:
> > > Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
> > > I defined the equation and another that subtracts the values from the
> > > expectations. I used minpack.lm to get the parameters, but I got an
> > > error:
> > > ```
> > >
> > > > library("minpack.lm")
> > > > h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> > > +        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> > > +        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> > > +        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> > > +        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> > > +        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35, 12100.63,
> > > +        12133.57, 12148.89, 12137.09)
> > > > high <- h[1:45]
> > > > MaxFluo <- max(high)
> > > > halfFluo <- MaxFluo/2
> > > > halfCycle = 27
> > > > find_slope <- function(X, Y) {
> > > +   Slope <- c(0)
> > > +   for (i in 2:length(X)) {
> > > +     delta_x <- X[i] - X[i-1]
> > > +     delta_y <- Y[i] - Y[i-1]
> > > +     Slope[i] <- delta_y/delta_x
> > > +   }
> > > +   return(Slope)
> > > + }
> > > > slopes <- find_slope(1:45, high)
> > > >
> > > > rutledge <- function(m, s, M, B, x) {
> > > +   divisor = 1 + exp(-1* ((x-m)/s) )
> > > +   y = (M/divisor) + B
> > > +   return(y)
> > > + }
> > > > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> > > >
> > > >
> > > > init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
> > > > points(1:45, init, type="l", col="red")
> > > > estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> > > +                 fn = rutledge_param, x = 1:45, y = high)
> > > Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
> > > high[1]),  :
> > >   evaluation of fn function returns non-sensible value!
> > > ```
> > >
> > > Where could the error be?
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From gregco@t@ @end|ng |rom me@com  Tue Mar 16 14:25:38 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Tue, 16 Mar 2021 09:25:38 -0400
Subject: [R] How to plot dates
In-Reply-To: <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
Message-ID: <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>

My computer is an Apple MacBook. I do not have POSIX. 
The command
myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
yields the error
Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) : 
  replacement has 0 rows, data has 13
Please advise, How to proceed?
Greg Coats

> library(ggplot2)
> # Read a txt file on the Desktop, named "myDat.txt"
> myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep = ",")
> head(myDat)
  X2021.03.11.10.00.00
1  2021-03-11 14:17:00
2  2021-03-12 05:16:46
3  2021-03-12 09:17:02
4  2021-03-12 13:31:43
5  2021-03-12 22:00:32
6  2021-03-13 09:21:43
> # convert data to date time object
> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) : 
  replacement has 0 rows, data has 13
> 
	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Mar 16 14:36:09 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 16 Mar 2021 09:36:09 -0400
Subject: [R] How to plot dates
In-Reply-To: <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
Message-ID: <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>

Hi,

It doesn't have anything to do with having a Mac - you have POSIX.

It's because something is wrong with your data import. Looking at the
head() output you provided, it looks like your data file does NOT have
a header, because there's no datetime column, and the column name is
actually X2021.03.11.10.00.0

So you specified a nonexistent column, and got a zero-length answer.

With correct specification, the as.POSIXct function works as expected on Mac:


myDat <- read.table(text =
"datetime
2021-03-11 10:00:00
2021-03-11 14:17:00
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43",
sep = ",", header = TRUE)


myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
"%Y-%M-%d %H:%M:%OS")

Sarah

On Tue, Mar 16, 2021 at 9:26 AM Gregory Coats via R-help
<r-help at r-project.org> wrote:
>
> My computer is an Apple MacBook. I do not have POSIX.
> The command
> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
> yields the error
> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>   replacement has 0 rows, data has 13
> Please advise, How to proceed?
> Greg Coats
>
> > library(ggplot2)
> > # Read a txt file on the Desktop, named "myDat.txt"
> > myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep = ",")
> > head(myDat)
>   X2021.03.11.10.00.00
> 1  2021-03-11 14:17:00
> 2  2021-03-12 05:16:46
> 3  2021-03-12 09:17:02
> 4  2021-03-12 13:31:43
> 5  2021-03-12 22:00:32
> 6  2021-03-13 09:21:43
> > # convert data to date time object
> > myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>   replacement has 0 rows, data has 13
> >
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From |@r|dcher @end|ng |rom gm@||@com  Tue Mar 16 15:49:23 2021
From: |@r|dcher @end|ng |rom gm@||@com (Farid Cheraghi)
Date: Tue, 16 Mar 2021 18:19:23 +0330
Subject: [R] Error: ignoring SIGPIPE signal
Message-ID: <CAJTBV4XhzhFRewxqSJJmMSv+zw9pHri_3Yvsgz5TwcbE0LDvgg@mail.gmail.com>

Hi,

```R
> sessionInfo()
R version 4.0.3 (2020-10-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux bullseye/sid

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.13.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
LC_MONETARY=en_US.UTF-8
 [6] LC_MESSAGES=en_US.UTF-8    LC_PAPER=en_US.UTF-8       LC_NAME=C
               LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

other attached packages:
[1] colorout_1.2-2

loaded via a namespace (and not attached):
[1] compiler_4.0.3
```

What is wrong with the following Shell script that gives the error? If
you decrease the sequencing number from 50 to e.g. 10 the error might
disappear!

```bash
seq 50 | Rscript -e "cat(readLines(file('stdin')), sep='\n')" | head -n 2
1
2
Error in cat(readLines(file("stdin")), sep = "\n") :
  ignoring SIGPIPE signal
Execution halted
```

It is already asked on StackOverflow without a good answer:
https://stackoverflow.com/questions/28915838/piping-rscript-gives-error-after-output

thanks,
Farid


From jr@| @end|ng |rom po@teo@no  Tue Mar 16 16:05:09 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 16 Mar 2021 16:05:09 +0100
Subject: [R] Error: ignoring SIGPIPE signal
In-Reply-To: <CAJTBV4XhzhFRewxqSJJmMSv+zw9pHri_3Yvsgz5TwcbE0LDvgg@mail.gmail.com>
References: <CAJTBV4XhzhFRewxqSJJmMSv+zw9pHri_3Yvsgz5TwcbE0LDvgg@mail.gmail.com>
Message-ID: <YFDJJWJWr4dubCBx@posteo.no>

Hello there,

This error happens if you did not finish 
reading from the pipe.  

E.g. I have this function in my local 
zshrc, to read tsv files with less in 
terminal width ...

	readdelim() { Rscript -e "options(width=$COLUMNS); read.delim('$1', check.names=FALSE, na='N/A')" | less }

... and if the tsv file has many lines I 
did not scroll completely to the bottom 
(read all of the pipe into less), I also 
get that error from the R end of the 
pipe.

R

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210316/26ae8a26/attachment.sig>

From gregco@t@ @end|ng |rom me@com  Tue Mar 16 17:21:05 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Tue, 16 Mar 2021 12:21:05 -0400
Subject: [R] How to plot dates
In-Reply-To: <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
Message-ID: <A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>

Sarah, Thank you. Yes, now as.POSIXct works.
But the ggplot command I was told to use yields an Error message, and there is no output plot.
Please help me. Greg
> library(ggplot2)
> myDat <- read.table(text =
+ "datetime
+ 2021-03-11 10:00:00
+ 2021-03-11 14:17:00
+ 2021-03-12 05:16:46
+ 2021-03-12 09:17:02
+ 2021-03-12 13:31:43
+ 2021-03-12 22:00:32
+ 2021-03-13 09:21:43",
+ sep = ",", header = TRUE)
> head(myDat)
             datetime
1 2021-03-11 10:00:00
2 2021-03-11 14:17:00
3 2021-03-12 05:16:46
4 2021-03-12 09:17:02
5 2021-03-12 13:31:43
6 2021-03-12 22:00:32
> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format ="%Y-%M-%d %H:%M:%OS?)
> ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
Error in FUN(X[[i]], ...) : object 'Y_Var' not found

> On Mar 16, 2021, at 9:36 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi,
> 
> It doesn't have anything to do with having a Mac - you have POSIX.
> 
> It's because something is wrong with your data import. Looking at the
> head() output you provided, it looks like your data file does NOT have
> a header, because there's no datetime column, and the column name is
> actually X2021.03.11.10.00.0
> 
> So you specified a nonexistent column, and got a zero-length answer.
> 
> With correct specification, the as.POSIXct function works as expected on Mac:
> 
> myDat <- read.table(text =
> "datetime
> 2021-03-11 10:00:00
> 2021-03-11 14:17:00
> 2021-03-12 05:16:46
> 2021-03-12 09:17:02
> 2021-03-12 13:31:43
> 2021-03-12 22:00:32
> 2021-03-13 09:21:43",
> sep = ",", header = TRUE)
> 
> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
> "%Y-%M-%d %H:%M:%OS")
> 
> Sarah
> 
> On Tue, Mar 16, 2021 at 9:26 AM Gregory Coats via R-help
> <r-help at r-project.org> wrote:
>> 
>> My computer is an Apple MacBook. I do not have POSIX.
>> The command
>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
>> yields the error
>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>  replacement has 0 rows, data has 13
>> Please advise, How to proceed?
>> Greg Coats
>> 
>>> library(ggplot2)
>>> # Read a txt file on the Desktop, named "myDat.txt"
>>> myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep = ",")
>>> head(myDat)
>>  X2021.03.11.10.00.00
>> 1  2021-03-11 14:17:00
>> 2  2021-03-12 05:16:46
>> 3  2021-03-12 09:17:02
>> 4  2021-03-12 13:31:43
>> 5  2021-03-12 22:00:32
>> 6  2021-03-13 09:21:43
>>> # convert data to date time object
>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>  replacement has 0 rows, data has 13
>>> 
>>        [[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> -- 
> Sarah Goslee (she/her)
> http://www.numberwright.com


	[[alternative HTML version deleted]]


From h@t|cegurd||1985 @end|ng |rom gm@||@com  Tue Mar 16 13:52:11 2021
From: h@t|cegurd||1985 @end|ng |rom gm@||@com (=?UTF-8?Q?hatice_g=C3=BCrdil?=)
Date: Tue, 16 Mar 2021 15:52:11 +0300
Subject: [R] help
Message-ID: <CAJmLsKLao4hTxRn92wRKEEEqovgde2vfFe6U4+ZqsoPd_vJcNA@mail.gmail.com>

Code a is working. But code b is given error like given below. How can I
write code b?

> a<-rmvnorm(750, mean=c(0, 0),
+                        sigma=matrix(c(1, .3, .3, 1), ncol=2))

> head(a)
            [,1]        [,2]
[1,] -0.97622921 -0.87129405
[2,]  0.54763494  0.16080131
[3,] -1.16627647  0.31225125
[4,]  1.72541168  2.06513939
[5,]  0.05372489 -0.07525197
[6,] -0.85062230 -1.02188473

> b<-rmvnorm(round(500,0), mean=c(0,-1),
+                        sigma=matrix(c(.3, 1,1,1,.3, 1, 1,1, .3), ncol=3))

Error in rmvnorm(round(500, 0), mean = c(0, -1), sigma = matrix(c(0.3,  :
  mean and sigma have non-conforming size

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Tue Mar 16 19:04:02 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 16 Mar 2021 18:04:02 +0000
Subject: [R] unanticipated axis labels
Message-ID: <CO1PR11MB510756F5F9A77853EF17A188D26B9@CO1PR11MB5107.namprd11.prod.outlook.com>

library(lattice)
library(latticeExtra)

barchart(matrix(c(1:6, 5:6)), main="unanticipated left axis labels", ylab="unanticipated inside labels") +
  latticeExtra::layer(panel.axis("left", half=FALSE, labels=1:8        ))

barchart(matrix(c(1:6, 5:6)), main="ok 1", ylab="anticipated") +
  latticeExtra::layer(panel.axis("left", half=FALSE, labels=1:8, at=1:8))
                                                            
barchart(matrix(c(1:6, 5:6)), main="ok 2", ylab="anticipated") +
  latticeExtra::layer(panel.axis("left", half=FALSE,             at=1:8))

barchart(matrix(c(1:6, 5:6)), main="ok 3", ylab="anticipated") +
  latticeExtra::layer(panel.axis("left", half=FALSE                    ))




From bgunter@4567 @end|ng |rom gm@||@com  Tue Mar 16 19:07:06 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 16 Mar 2021 11:07:06 -0700
Subject: [R] help
In-Reply-To: <CAJmLsKLao4hTxRn92wRKEEEqovgde2vfFe6U4+ZqsoPd_vJcNA@mail.gmail.com>
References: <CAJmLsKLao4hTxRn92wRKEEEqovgde2vfFe6U4+ZqsoPd_vJcNA@mail.gmail.com>
Message-ID: <CAGxFJbT_qNB09KEPKXaXK=r0LJpAzyZbhcb6fJVdm_PGp47SHg@mail.gmail.com>

A 2 dim distribution must have a 2 x 2 covariance matrix. Your mean in b)
specifies 2 dim, but your covariance matrix is 3x3.

If you haven't just made a typo and you don't know what this means, then
either consult statistics references or find someone to help you.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 16, 2021 at 10:55 AM hatice g?rdil <haticegurdil1985 at gmail.com>
wrote:

> Code a is working. But code b is given error like given below. How can I
> write code b?
>
> > a<-rmvnorm(750, mean=c(0, 0),
> +                        sigma=matrix(c(1, .3, .3, 1), ncol=2))
>
> > head(a)
>             [,1]        [,2]
> [1,] -0.97622921 -0.87129405
> [2,]  0.54763494  0.16080131
> [3,] -1.16627647  0.31225125
> [4,]  1.72541168  2.06513939
> [5,]  0.05372489 -0.07525197
> [6,] -0.85062230 -1.02188473
>
> > b<-rmvnorm(round(500,0), mean=c(0,-1),
> +                        sigma=matrix(c(.3, 1,1,1,.3, 1, 1,1, .3), ncol=3))
>
> Error in rmvnorm(round(500, 0), mean = c(0, -1), sigma = matrix(c(0.3,  :
>   mean and sigma have non-conforming size
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Mar 16 19:08:56 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 16 Mar 2021 11:08:56 -0700
Subject: [R] help
In-Reply-To: <CAJmLsKLao4hTxRn92wRKEEEqovgde2vfFe6U4+ZqsoPd_vJcNA@mail.gmail.com>
References: <CAJmLsKLao4hTxRn92wRKEEEqovgde2vfFe6U4+ZqsoPd_vJcNA@mail.gmail.com>
Message-ID: <CAHqSRuTip=JCukJFKEFd9Gg3rJEnwRm-p5bj9awmeoGPx=dDwA@mail.gmail.com>

The length of the mean vector must match the number of rows and
columns of the sigma matrix.  Once you give 3 entries in the mean
vector you will run into the problem that the sigma you are using is
not positive (semi-)definite - a variance must be the product of a
matrix and its transpose.

-Bill

On Tue, Mar 16, 2021 at 10:55 AM hatice g?rdil
<haticegurdil1985 at gmail.com> wrote:
>
> Code a is working. But code b is given error like given below. How can I
> write code b?
>
> > a<-rmvnorm(750, mean=c(0, 0),
> +                        sigma=matrix(c(1, .3, .3, 1), ncol=2))
>
> > head(a)
>             [,1]        [,2]
> [1,] -0.97622921 -0.87129405
> [2,]  0.54763494  0.16080131
> [3,] -1.16627647  0.31225125
> [4,]  1.72541168  2.06513939
> [5,]  0.05372489 -0.07525197
> [6,] -0.85062230 -1.02188473
>
> > b<-rmvnorm(round(500,0), mean=c(0,-1),
> +                        sigma=matrix(c(.3, 1,1,1,.3, 1, 1,1, .3), ncol=3))
>
> Error in rmvnorm(round(500, 0), mean = c(0, -1), sigma = matrix(c(0.3,  :
>   mean and sigma have non-conforming size
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Tue Mar 16 19:18:33 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 16 Mar 2021 14:18:33 -0400
Subject: [R] How to plot dates
In-Reply-To: <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
Message-ID: <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>

Dear Greg,

There is no variable named Y_Var in your data set. I suspect that it's 
intended to be a generic specification in the recipe you were apparently 
given. In fact, there appears to be only one variable in myDat and 
that's datetime. What is it that you're trying to do?

A more general comment: If I'm correct and you're just following a 
recipe, that's a recipe for problems. You'd probably be more successful 
if you tried to learn how ggplot(), etc., work. My apologies if I'm 
misinterpreting the source of your difficulties.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-03-16 12:21 p.m., Gregory Coats via R-help wrote:
> Sarah, Thank you. Yes, now as.POSIXct works.
> But the ggplot command I was told to use yields an Error message, and there is no output plot.
> Please help me. Greg
>> library(ggplot2)
>> myDat <- read.table(text =
> + "datetime
> + 2021-03-11 10:00:00
> + 2021-03-11 14:17:00
> + 2021-03-12 05:16:46
> + 2021-03-12 09:17:02
> + 2021-03-12 13:31:43
> + 2021-03-12 22:00:32
> + 2021-03-13 09:21:43",
> + sep = ",", header = TRUE)
>> head(myDat)
>               datetime
> 1 2021-03-11 10:00:00
> 2 2021-03-11 14:17
> 3 2021-03-12 05:16:46
> 4 2021-03-12 09:17:02
> 5 2021-03-12 13:31:43
> 6 2021-03-12 22:00:32
>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format ="%Y-%M-%d %H:%M:%OS?)
>> ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
> Error in FUN(X[[i]], ...) : object 'Y_Var' not found
> 
>> On Mar 16, 2021, at 9:36 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> It doesn't have anything to do with having a Mac - you have POSIX.
>>
>> It's because something is wrong with your data import. Looking at the
>> head() output you provided, it looks like your data file does NOT have
>> a header, because there's no datetime column, and the column name is
>> actually X2021.03.11.10.00.0
>>
>> So you specified a nonexistent column, and got a zero-length answer.
>>
>> With correct specification, the as.POSIXct function works as expected on Mac:
>>
>> myDat <- read.table(text =
>> "datetime
>> 2021-03-11 10:00:00
>> 2021-03-11 14:17:00
>> 2021-03-12 05:16:46
>> 2021-03-12 09:17:02
>> 2021-03-12 13:31:43
>> 2021-03-12 22:00:32
>> 2021-03-13 09:21:43",
>> sep = ",", header = TRUE)
>>
>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>> "%Y-%M-%d %H:%M:%OS")
>>
>> Sarah
>>
>> On Tue, Mar 16, 2021 at 9:26 AM Gregory Coats via R-help
>> <r-help at r-project.org> wrote:
>>>
>>> My computer is an Apple MacBook. I do not have POSIX.
>>> The command
>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
>>> yields the error
>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>   replacement has 0 rows, data has 13
>>> Please advise, How to proceed?
>>> Greg Coats
>>>
>>>> library(ggplot2)
>>>> # Read a txt file on the Desktop, named "myDat.txt"
>>>> myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep = ",")
>>>> head(myDat)
>>>   X2021.03.11.10.00.00
>>> 1  2021-03-11 14:17:00
>>> 2  2021-03-12 05:16:46
>>> 3  2021-03-12 09:17:02
>>> 4  2021-03-12 13:31:43
>>> 5  2021-03-12 22:00:32
>>> 6  2021-03-13 09:21:43
>>>> # convert data to date time object
>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>   replacement has 0 rows, data has 13
>>>>
>>>         [[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> -- 
>> Sarah Goslee (she/her)
>> http://www.numberwright.com
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar 16 19:23:13 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 16 Mar 2021 11:23:13 -0700
Subject: [R] How to plot dates
In-Reply-To: <A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
Message-ID: <1350471C-2010-448A-9A00-B0F5E6BEBC26@dcn.davis.ca.us>

You don't seem to have a Y_Var in your data. What is it that you want to plot?

On March 16, 2021 9:21:05 AM PDT, Gregory Coats via R-help <r-help at r-project.org> wrote:
>Sarah, Thank you. Yes, now as.POSIXct works.
>But the ggplot command I was told to use yields an Error message, and
>there is no output plot.
>Please help me. Greg
>> library(ggplot2)
>> myDat <- read.table(text =
>+ "datetime
>+ 2021-03-11 10:00:00
>+ 2021-03-11 14:17:00
>+ 2021-03-12 05:16:46
>+ 2021-03-12 09:17:02
>+ 2021-03-12 13:31:43
>+ 2021-03-12 22:00:32
>+ 2021-03-13 09:21:43",
>+ sep = ",", header = TRUE)
>> head(myDat)
>             datetime
>1 2021-03-11 10:00:00
>2 2021-03-11 14:17:00
>3 2021-03-12 05:16:46
>4 2021-03-12 09:17:02
>5 2021-03-12 13:31:43
>6 2021-03-12 22:00:32
>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format
>="%Y-%M-%d %H:%M:%OS?)
>> ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
>Error in FUN(X[[i]], ...) : object 'Y_Var' not found
>
>> On Mar 16, 2021, at 9:36 AM, Sarah Goslee <sarah.goslee at gmail.com>
>wrote:
>> 
>> Hi,
>> 
>> It doesn't have anything to do with having a Mac - you have POSIX.
>> 
>> It's because something is wrong with your data import. Looking at the
>> head() output you provided, it looks like your data file does NOT
>have
>> a header, because there's no datetime column, and the column name is
>> actually X2021.03.11.10.00.0
>> 
>> So you specified a nonexistent column, and got a zero-length answer.
>> 
>> With correct specification, the as.POSIXct function works as expected
>on Mac:
>> 
>> myDat <- read.table(text =
>> "datetime
>> 2021-03-11 10:00:00
>> 2021-03-11 14:17:00
>> 2021-03-12 05:16:46
>> 2021-03-12 09:17:02
>> 2021-03-12 13:31:43
>> 2021-03-12 22:00:32
>> 2021-03-13 09:21:43",
>> sep = ",", header = TRUE)
>> 
>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>> "%Y-%M-%d %H:%M:%OS")
>> 
>> Sarah
>> 
>> On Tue, Mar 16, 2021 at 9:26 AM Gregory Coats via R-help
>> <r-help at r-project.org> wrote:
>>> 
>>> My computer is an Apple MacBook. I do not have POSIX.
>>> The command
>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>"%Y-%M-%d %H:%M:%OS")
>>> yields the error
>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>  replacement has 0 rows, data has 13
>>> Please advise, How to proceed?
>>> Greg Coats
>>> 
>>>> library(ggplot2)
>>>> # Read a txt file on the Desktop, named "myDat.txt"
>>>> myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep =
>",")
>>>> head(myDat)
>>>  X2021.03.11.10.00.00
>>> 1  2021-03-11 14:17:00
>>> 2  2021-03-12 05:16:46
>>> 3  2021-03-12 09:17:02
>>> 4  2021-03-12 13:31:43
>>> 5  2021-03-12 22:00:32
>>> 6  2021-03-13 09:21:43
>>>> # convert data to date time object
>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>"%Y-%M-%d %H:%M:%OS")
>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>  replacement has 0 rows, data has 13
>>>> 
>>>        [[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> -- 
>> Sarah Goslee (she/her)
>> http://www.numberwright.com
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From gregco@t@ @end|ng |rom me@com  Tue Mar 16 19:45:32 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Tue, 16 Mar 2021 14:45:32 -0400
Subject: [R] How to plot dates
In-Reply-To: <1350471C-2010-448A-9A00-B0F5E6BEBC26@dcn.davis.ca.us>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <1350471C-2010-448A-9A00-B0F5E6BEBC26@dcn.davis.ca.us>
Message-ID: <65D4A972-36C6-4480-83B3-62054253EB6E@me.com>

I want to plot the date and time of the event, as reflected in data.
2021-03-11 10:00:00
Greg Coats

> On Mar 16, 2021, at 2:23 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> You don't seem to have a Y_Var in your data. What is it that you want to plot?
> 
> On March 16, 2021 9:21:05 AM PDT, Gregory Coats via R-help <r-help at r-project.org> wrote:
>> Sarah, Thank you. Yes, now as.POSIXct works.
>> But the ggplot command I was told to use yields an Error message, and
>> there is no output plot.
>> Please help me. Greg
>>> library(ggplot2)
>>> myDat <- read.table(text =
>> + "datetime
>> + 2021-03-11 10:00:00
>> + 2021-03-11 14:17:00
>> + 2021-03-12 05:16:46
>> + 2021-03-12 09:17:02
>> + 2021-03-12 13:31:43
>> + 2021-03-12 22:00:32
>> + 2021-03-13 09:21:43",
>> + sep = ",", header = TRUE)
>>> head(myDat)
>>            datetime
>> 1 2021-03-11 10:00:00
>> 2 2021-03-11 14:17:00
>> 3 2021-03-12 05:16:46
>> 4 2021-03-12 09:17:02
>> 5 2021-03-12 13:31:43
>> 6 2021-03-12 22:00:32
>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format
>> ="%Y-%M-%d %H:%M:%OS?)
>>> ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
>> Error in FUN(X[[i]], ...) : object 'Y_Var' not found
>> 
>>> On Mar 16, 2021, at 9:36 AM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>> 
>>> Hi,
>>> 
>>> It doesn't have anything to do with having a Mac - you have POSIX.
>>> 
>>> It's because something is wrong with your data import. Looking at the
>>> head() output you provided, it looks like your data file does NOT
>> have
>>> a header, because there's no datetime column, and the column name is
>>> actually X2021.03.11.10.00.0
>>> 
>>> So you specified a nonexistent column, and got a zero-length answer.
>>> 
>>> With correct specification, the as.POSIXct function works as expected
>> on Mac:
>>> 
>>> myDat <- read.table(text =
>>> "datetime
>>> 2021-03-11 10:00:00
>>> 2021-03-11 14:17:00
>>> 2021-03-12 05:16:46
>>> 2021-03-12 09:17:02
>>> 2021-03-12 13:31:43
>>> 2021-03-12 22:00:32
>>> 2021-03-13 09:21:43",
>>> sep = ",", header = TRUE)
>>> 
>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>>> "%Y-%M-%d %H:%M:%OS")
>>> 
>>> Sarah
>>> 
>>> On Tue, Mar 16, 2021 at 9:26 AM Gregory Coats via R-help
>>> <r-help at r-project.org> wrote:
>>>> 
>>>> My computer is an Apple MacBook. I do not have POSIX.
>>>> The command
>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>> "%Y-%M-%d %H:%M:%OS")
>>>> yields the error
>>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>> replacement has 0 rows, data has 13
>>>> Please advise, How to proceed?
>>>> Greg Coats
>>>> 
>>>>> library(ggplot2)
>>>>> # Read a txt file on the Desktop, named "myDat.txt"
>>>>> myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep =
>> ",")
>>>>> head(myDat)
>>>> X2021.03.11.10.00.00
>>>> 1  2021-03-11 14:17:00
>>>> 2  2021-03-12 05:16:46
>>>> 3  2021-03-12 09:17:02
>>>> 4  2021-03-12 13:31:43
>>>> 5  2021-03-12 22:00:32
>>>> 6  2021-03-13 09:21:43
>>>>> # convert data to date time object
>>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>> "%Y-%M-%d %H:%M:%OS")
>>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>> replacement has 0 rows, data has 13
>>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> -- 
>>> Sarah Goslee (she/her)
>>> http://www.numberwright.com
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Mar 16 19:51:46 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 16 Mar 2021 11:51:46 -0700
Subject: [R] How to plot dates
In-Reply-To: <65D4A972-36C6-4480-83B3-62054253EB6E@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <1350471C-2010-448A-9A00-B0F5E6BEBC26@dcn.davis.ca.us>
 <65D4A972-36C6-4480-83B3-62054253EB6E@me.com>
Message-ID: <D095BA9C-1482-4880-86BA-C38B14A5AA58@dcn.davis.ca.us>

So what do you want quantity on the y-axis to be?

On March 16, 2021 11:45:32 AM PDT, Gregory Coats <gregcoats at me.com> wrote:
>I want to plot the date and time of the event, as reflected in data.
>2021-03-11 10:00:00
>Greg Coats
>
>> On Mar 16, 2021, at 2:23 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> You don't seem to have a Y_Var in your data. What is it that you want
>to plot?
>> 
>> On March 16, 2021 9:21:05 AM PDT, Gregory Coats via R-help
><r-help at r-project.org> wrote:
>>> Sarah, Thank you. Yes, now as.POSIXct works.
>>> But the ggplot command I was told to use yields an Error message,
>and
>>> there is no output plot.
>>> Please help me. Greg
>>>> library(ggplot2)
>>>> myDat <- read.table(text =
>>> + "datetime
>>> + 2021-03-11 10:00:00
>>> + 2021-03-11 14:17:00
>>> + 2021-03-12 05:16:46
>>> + 2021-03-12 09:17:02
>>> + 2021-03-12 13:31:43
>>> + 2021-03-12 22:00:32
>>> + 2021-03-13 09:21:43",
>>> + sep = ",", header = TRUE)
>>>> head(myDat)
>>>            datetime
>>> 1 2021-03-11 10:00:00
>>> 2 2021-03-11 14:17:00
>>> 3 2021-03-12 05:16:46
>>> 4 2021-03-12 09:17:02
>>> 5 2021-03-12 13:31:43
>>> 6 2021-03-12 22:00:32
>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format
>>> ="%Y-%M-%d %H:%M:%OS?)
>>>> ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
>>> Error in FUN(X[[i]], ...) : object 'Y_Var' not found
>>> 
>>>> On Mar 16, 2021, at 9:36 AM, Sarah Goslee <sarah.goslee at gmail.com>
>>> wrote:
>>>> 
>>>> Hi,
>>>> 
>>>> It doesn't have anything to do with having a Mac - you have POSIX.
>>>> 
>>>> It's because something is wrong with your data import. Looking at
>the
>>>> head() output you provided, it looks like your data file does NOT
>>> have
>>>> a header, because there's no datetime column, and the column name
>is
>>>> actually X2021.03.11.10.00.0
>>>> 
>>>> So you specified a nonexistent column, and got a zero-length
>answer.
>>>> 
>>>> With correct specification, the as.POSIXct function works as
>expected
>>> on Mac:
>>>> 
>>>> myDat <- read.table(text =
>>>> "datetime
>>>> 2021-03-11 10:00:00
>>>> 2021-03-11 14:17:00
>>>> 2021-03-12 05:16:46
>>>> 2021-03-12 09:17:02
>>>> 2021-03-12 13:31:43
>>>> 2021-03-12 22:00:32
>>>> 2021-03-13 09:21:43",
>>>> sep = ",", header = TRUE)
>>>> 
>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>>>> "%Y-%M-%d %H:%M:%OS")
>>>> 
>>>> Sarah
>>>> 
>>>> On Tue, Mar 16, 2021 at 9:26 AM Gregory Coats via R-help
>>>> <r-help at r-project.org> wrote:
>>>>> 
>>>>> My computer is an Apple MacBook. I do not have POSIX.
>>>>> The command
>>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>>> "%Y-%M-%d %H:%M:%OS")
>>>>> yields the error
>>>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>>> replacement has 0 rows, data has 13
>>>>> Please advise, How to proceed?
>>>>> Greg Coats
>>>>> 
>>>>>> library(ggplot2)
>>>>>> # Read a txt file on the Desktop, named "myDat.txt"
>>>>>> myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep =
>>> ",")
>>>>>> head(myDat)
>>>>> X2021.03.11.10.00.00
>>>>> 1  2021-03-11 14:17:00
>>>>> 2  2021-03-12 05:16:46
>>>>> 3  2021-03-12 09:17:02
>>>>> 4  2021-03-12 13:31:43
>>>>> 5  2021-03-12 22:00:32
>>>>> 6  2021-03-13 09:21:43
>>>>>> # convert data to date time object
>>>>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
>>> "%Y-%M-%d %H:%M:%OS")
>>>>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>>>> replacement has 0 rows, data has 13
>>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> -- 
>>>> Sarah Goslee (she/her)
>>>> http://www.numberwright.com
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From gregco@t@ @end|ng |rom me@com  Tue Mar 16 19:56:34 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Tue, 16 Mar 2021 14:56:34 -0400
Subject: [R] How to plot dates
In-Reply-To: <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
Message-ID: <0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>

I need a plot that shows the date and time that each event started.
This ggplot command was publicly given to me via this R Help Mailing LIst.
But the result of issuing the ggplot command is an Error in FUN message.
ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
Error in FUN(X[[i]], ...) : object 'Y_Var' not found
Greg Coats

> On Mar 16, 2021, at 2:18 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> There is no variable named Y_Var in your data set. I suspect that it's intended to be a generic specification in the recipe you were apparently given. In fact, there appears to be only one variable in myDat and that's datetime. What is it that you're trying to do?


	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Mar 16 20:34:52 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Tue, 16 Mar 2021 15:34:52 -0400
Subject: [R] How to plot dates
In-Reply-To: <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
Message-ID: <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>

Dear Greg,

Coordinate plots typically have a horizontal (x) and vertical (y) axis. 
The command

	ggplot(myDat, aes(x=datetime, y = datetime)) + geom_point()

works, but I doubt that it produces what you want.

You have only one variable in your data set -- datetime -- so it's not 
obvious what you want to do. If you can't clearly describe the structure 
of the plot you intend to draw, it's doubtful that I or anyone else can 
help you.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-03-16 2:56 p.m., Gregory Coats via R-help wrote:
> I need a plot that shows the date and time that each event started.
> This ggplot command was publicly given to me via this R Help Mailing LIst.
> But the result of issuing the ggplot command is an Error in FUN message.
> ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
> Error in FUN(X[[i]], ...) : object 'Y_Var' not found
> Greg Coats
> 
>> On Mar 16, 2021, at 2:18 PM, John Fox <jfox at mcmaster.ca> wrote:
>>
>> There is no variable named Y_Var in your data set. I suspect that it's intended to be a generic specification in the recipe you were apparently given. In fact, there appears to be only one variable in myDat and that's datetime. What is it that you're trying to do?
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j||m08 @end|ng |rom qub@@c@uk  Tue Mar 16 19:19:41 2021
From: j||m08 @end|ng |rom qub@@c@uk (Jonathan Lim)
Date: Tue, 16 Mar 2021 18:19:41 +0000
Subject: [R] R
Message-ID: <AM7PR07MB686865F6EBBA977AE23D62578A6B9@AM7PR07MB6868.eurprd07.prod.outlook.com>

Hi

I found your email on a website

Can I ask some questions about R please

Many thanks

Jonathan

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Mar 16 20:59:12 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 16 Mar 2021 19:59:12 +0000
Subject: [R] How to plot dates
In-Reply-To: <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
Message-ID: <efe59e43-0d54-ed75-03ac-09036a913f40@sapo.pt>

Hello,

I don't really understand what is to be plotted, just the time of the 
event? But what event?

Anyway, with the data read with Sarah's code, maybe


library(ggplot2)

ggplot(myDat, aes(x = datetime, y = 1)) +
   geom_linerange(aes(ymin = 0, ymax = 1), linetype = "dotted") +
   geom_point() +
   scale_x_datetime(breaks = myDat$datetime) +
   scale_y_continuous(labels = NULL) +
   ylab("event") +
   theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust=1),
         axis.ticks.y = element_blank())


Hope this helps,

Rui Barradas

?s 13:36 de 16/03/21, Sarah Goslee escreveu:
> Hi,
> 
> It doesn't have anything to do with having a Mac - you have POSIX.
> 
> It's because something is wrong with your data import. Looking at the
> head() output you provided, it looks like your data file does NOT have
> a header, because there's no datetime column, and the column name is
> actually X2021.03.11.10.00.0
> 
> So you specified a nonexistent column, and got a zero-length answer.
> 
> With correct specification, the as.POSIXct function works as expected on Mac:
> 
> 
> myDat <- read.table(text =
> "datetime
> 2021-03-11 10:00:00
> 2021-03-11 14:17:00
> 2021-03-12 05:16:46
> 2021-03-12 09:17:02
> 2021-03-12 13:31:43
> 2021-03-12 22:00:32
> 2021-03-13 09:21:43",
> sep = ",", header = TRUE)
> 
> 
> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format =
> "%Y-%M-%d %H:%M:%OS")
> 
> Sarah
> 
> On Tue, Mar 16, 2021 at 9:26 AM Gregory Coats via R-help
> <r-help at r-project.org> wrote:
>>
>> My computer is an Apple MacBook. I do not have POSIX.
>> The command
>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
>> yields the error
>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>    replacement has 0 rows, data has 13
>> Please advise, How to proceed?
>> Greg Coats
>>
>>> library(ggplot2)
>>> # Read a txt file on the Desktop, named "myDat.txt"
>>> myDat <- read.delim("~/Desktop/myDat.txt", header = TRUE, sep = ",")
>>> head(myDat)
>>    X2021.03.11.10.00.00
>> 1  2021-03-11 14:17:00
>> 2  2021-03-12 05:16:46
>> 3  2021-03-12 09:17:02
>> 4  2021-03-12 13:31:43
>> 5  2021-03-12 22:00:32
>> 6  2021-03-13 09:21:43
>>> # convert data to date time object
>>> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%M-%d %H:%M:%OS")
>> Error in `$<-.data.frame`(`*tmp*`, datetime, value = numeric(0)) :
>>    replacement has 0 rows, data has 13
>>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From bgunter@4567 @end|ng |rom gm@||@com  Tue Mar 16 20:59:16 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 16 Mar 2021 12:59:16 -0700
Subject: [R] R
In-Reply-To: <AM7PR07MB686865F6EBBA977AE23D62578A6B9@AM7PR07MB6868.eurprd07.prod.outlook.com>
References: <AM7PR07MB686865F6EBBA977AE23D62578A6B9@AM7PR07MB6868.eurprd07.prod.outlook.com>
Message-ID: <CAGxFJbTF3iDFjO_Zkf1Q03QAhkbwt14G+7buBBKjjPkAOm+6Lg@mail.gmail.com>

https://www.r-project.org/mail.html

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 16, 2021 at 12:51 PM Jonathan Lim <jlim08 at qub.ac.uk> wrote:

> Hi
>
> I found your email on a website
>
> Can I ask some questions about R please
>
> Many thanks
>
> Jonathan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Mar 16 21:02:15 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 16 Mar 2021 20:02:15 +0000
Subject: [R] R
In-Reply-To: <AM7PR07MB686865F6EBBA977AE23D62578A6B9@AM7PR07MB6868.eurprd07.prod.outlook.com>
References: <AM7PR07MB686865F6EBBA977AE23D62578A6B9@AM7PR07MB6868.eurprd07.prod.outlook.com>
Message-ID: <9ef5b36f-6ff8-fe9e-1610-27b8e9de6dd5@sapo.pt>

Hello,

Yes, you can ask R-Help questions on R code, that's what it is intended for.

But please read the posting guide, it's link is at the bottom of this 
and of any R-Help mail.

Good luck, enjoy R!

Rui Barradas

?s 18:19 de 16/03/21, Jonathan Lim escreveu:
> Hi
> 
> I found your email on a website
> 
> Can I ask some questions about R please
> 
> Many thanks
> 
> Jonathan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 16 22:54:58 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 17 Mar 2021 08:54:58 +1100
Subject: [R] How to plot dates
In-Reply-To: <0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
Message-ID: <CA+8X3fXovfpu16EeLFfCo+_NBxy0L64M5DdiEUBaM7Vt99vfrg@mail.gmail.com>

Hi Greg,
This example may give you a start:

myDat<-read.table(text=
  "2021-03-11 10:00:00
  2021-03-11 14:17:00
  2021-03-12 05:16:46
  2021-03-12 09:17:02
  2021-03-12 13:31:43
  2021-03-12 22:00:32
  2021-03-13 09:21:43",
  sep=",",
  stringsAsFactors=FALSE)
myDat$datetime<-strptime(myDat$X,format="%Y-%m-%d %H:%M:%S")
plot(myDat$datetime,rnorm(7),type="b")

Note that I have corrected what I think is a mistake in reading in
your data. The first date has been converted into the field name by
prepending an "X" and then replacing the hyphen and semicolon
characters with periods to coerce it to a name.  I changed that back
to what I think it was and this produces s basic plot with the dates
on the abscissa and some random numbers on the ordinate.

Jim

On Wed, Mar 17, 2021 at 6:26 AM Gregory Coats via R-help
<r-help at r-project.org> wrote:
>
> I need a plot that shows the date and time that each event started.
> This ggplot command was publicly given to me via this R Help Mailing LIst.
> But the result of issuing the ggplot command is an Error in FUN message.
> ggplot(myDat, aes(x=datetime, y = Y_Var)) + geom_point()
> Error in FUN(X[[i]], ...) : object 'Y_Var' not found
> Greg Coats
>
> > On Mar 16, 2021, at 2:18 PM, John Fox <jfox at mcmaster.ca> wrote:
> >
> > There is no variable named Y_Var in your data set. I suspect that it's intended to be a generic specification in the recipe you were apparently given. In fact, there appears to be only one variable in myDat and that's datetime. What is it that you're trying to do?
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gregco@t@ @end|ng |rom me@com  Tue Mar 16 23:32:23 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Tue, 16 Mar 2021 18:32:23 -0400
Subject: [R] How to plot dates
In-Reply-To: <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
 <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
Message-ID: <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>

Thank you. Let me redefine the situation.
Each time an event starts, I record the date and time.
Each day there are 4 new events. Time is the only variable.
I would like to graphically show how the time for events 1, 2, 3, and 4 for the current day compare to the times for events 1, 2, 3, and 4 for the previous day. How would I plot / display those times differences?
Greg Coats

library (ggplot2)
myDat <- read.table(text =
"datetime
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56 
2021-03-14 17:25:23
2021-03-14 21:36:26",
sep = ",", header = TRUE)
head(myDat)
myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format ="%Y-%M-%d %H:%M:%OS")

> On Mar 16, 2021, at 3:34 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> Dear Greg,
> 
> Coordinate plots typically have a horizontal (x) and vertical (y) axis. The command
> 
> 	ggplot(myDat, aes(x=datetime, y = datetime)) + geom_point()
> 
> works, but I doubt that it produces what you want.
> 
> You have only one variable in your data set -- datetime -- so it's not obvious what you want to do. If you can't clearly describe the structure of the plot you intend to draw, it's doubtful that I or anyone else can help you.
> 
> Best,
> John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/ <https://socialsciences.mcmaster.ca/jfox/>

	[[alternative HTML version deleted]]


From djnord|und @end|ng |rom gm@||@com  Wed Mar 17 00:49:26 2021
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Tue, 16 Mar 2021 16:49:26 -0700
Subject: [R] How to plot dates
In-Reply-To: <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
 <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
 <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
Message-ID: <d7a49d98-cc3b-673f-980c-480a322d0efc@gmail.com>

On 3/16/2021 3:32 PM, Gregory Coats via R-help wrote:
> Thank you. Let me redefine the situation.
> Each time an event starts, I record the date and time.
> Each day there are 4 new events. Time is the only variable.
> I would like to graphically show how the time for events 1, 2, 3, and 4 for the current day compare to the times for events 1, 2, 3, and 4 for the previous day. How would I plot / display those times differences?
> Greg Coats
>
> library (ggplot2)
> myDat <- read.table(text =
> "datetime
> 2021-03-12 05:16:46
> 2021-03-12 09:17:02
> 2021-03-12 13:31:43
> 2021-03-12 22:00:32
> 2021-03-13 09:21:43
> 2021-03-13 13:51:12
> 2021-03-13 18:03:13
> 2021-03-13 22:20:28
> 2021-03-14 08:59:03
> 2021-03-14 13:15:56
> 2021-03-14 17:25:23
> 2021-03-14 21:36:26",
> sep = ",", header = TRUE)
> head(myDat)
> myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format ="%Y-%M-%d %H:%M:%OS")
>
>> On Mar 16, 2021, at 3:34 PM, John Fox <jfox at mcmaster.ca> wrote:
>>
>> Dear Greg,
>>
>> Coordinate plots typically have a horizontal (x) and vertical (y) axis. The command
>>
>> 	ggplot(myDat, aes(x=datetime, y = datetime)) + geom_point()
>>
>> works, but I doubt that it produces what you want.
>>
>> You have only one variable in your data set -- datetime -- so it's not obvious what you want to do. If you can't clearly describe the structure of the plot you intend to draw, it's doubtful that I or anyone else can help you.
>>
>> Best,
>> John
>>
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> web: https://socialsciences.mcmaster.ca/jfox/ <https://socialsciences.mcmaster.ca/jfox/>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

I am only guessing about what you are looking for by way of a visual 
comparison.? Here is one way of visualizing the variation of event times

library (ggplot2)
myDat <- read.table(text =
"datetime
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56
2021-03-14 17:25:23
2021-03-14 21:36:26",
sep = ",", header = TRUE)

# create datepart variable - dte
myDat$dte <- as.Date(myDat$datetime, "%m/%d/%Y", tz='')

# create timepart variable - tme
library(lubridate)
myDat$tme <- hms::hms(as.numeric(myDat$datetime - 
floor_date(myDat$datetime, "1 day"), unit="secs"))

# plot event date by time grouped by date
ggplot(myDat, aes(x=tme, y = dte, group = dte)) + geom_line() + 
geom_point() +
?????? expand_limits(y=as.Date(c('20210301', '20210331'),'%Y%m%d'))

If this doesn't help get you started, you need to provide a description 
of what you want your plot to look like.

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Mar 17 01:01:25 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 16 Mar 2021 20:01:25 -0400
Subject: [R] How to plot dates
In-Reply-To: <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
 <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
 <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
Message-ID: <033401d71ac0$ac6ce660$0546b320$@verizon.net>

It sounds to me like you want to take your data and extract one column for
JUST the date and another column for just some measure of the time, such as
the number of seconds since midnight or hours in a decimal format where
12:45 PM might be 12.75.

You now can graph date along the X axis and time along the Y (or vice versa)
and show the result in one of many ways as points or horizontal line
segments or whatever works for you.

If you always had 4 time measures for each day, or did some work, you might
also have a column for which time that is for a day, a number ranging from
one to 4 and this column could be used to set the color or other attribute
if that was useful.

So, to review. Your one data item need not be kept as the only column and if
you make more columns, you might have something to graph.

Here is an example that worked for me doing roughly what I mentioned but
note my names changed. It makes two plots.

library (ggplot2)
myDat <- read.table(text =
                      "datetimeraw
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56
2021-03-14 17:25:23
2021-03-14 21:36:26",
                    sep = ",", header = TRUE)
head(myDat)
myDat$datetime <- as.POSIXct(myDat$datetimeraw, tz = "", format ="%Y-%M-%d
%H:%M:%OS")
myDat$date <- factor(format(myDat$datetime, "%Y-%m-%d"))
myDat$time <- format(myDat$datetime, "%H:%M")
myDat$seq <- factor(rep(1:4, 3))

# just dots
ggplot(data=myDat,aes(x=date, y=time)) + geom_point(aes(color=seq))

# Also text
ggplot(data=myDat,aes(x=date, y=time, label=time)) + 
  geom_point(aes(color=seq)) + 
               geom_text(aes(color=seq))



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Gregory Coats via
R-help
Sent: Tuesday, March 16, 2021 6:32 PM
To: John Fox <jfox at mcmaster.ca>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] How to plot dates

Thank you. Let me redefine the situation.
Each time an event starts, I record the date and time.
Each day there are 4 new events. Time is the only variable.
I would like to graphically show how the time for events 1, 2, 3, and 4 for
the current day compare to the times for events 1, 2, 3, and 4 for the
previous day. How would I plot / display those times differences?
Greg Coats

library (ggplot2)
myDat <- read.table(text =
"datetime
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56
2021-03-14 17:25:23
2021-03-14 21:36:26",
sep = ",", header = TRUE)
head(myDat)
myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format ="%Y-%M-%d
%H:%M:%OS")

> On Mar 16, 2021, at 3:34 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> Dear Greg,
> 
> Coordinate plots typically have a horizontal (x) and vertical (y) 
> axis. The command
> 
> 	ggplot(myDat, aes(x=datetime, y = datetime)) + geom_point()
> 
> works, but I doubt that it produces what you want.
> 
> You have only one variable in your data set -- datetime -- so it's not
obvious what you want to do. If you can't clearly describe the structure of
the plot you intend to draw, it's doubtful that I or anyone else can help
you.
> 
> Best,
> John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/ 
> <https://socialsciences.mcmaster.ca/jfox/>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gregco@t@ @end|ng |rom me@com  Wed Mar 17 01:10:35 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Tue, 16 Mar 2021 20:10:35 -0400
Subject: [R] How to plot dates
In-Reply-To: <d7a49d98-cc3b-673f-980c-480a322d0efc@gmail.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
 <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
 <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
 <d7a49d98-cc3b-673f-980c-480a322d0efc@gmail.com>
Message-ID: <E3B863C9-2C05-4917-A72D-782703AA3D83@me.com>

Dan, Thank you for this guidance.
Unfortunately, I do not have the library lubridate, and I do not at this moment know where to go to get this library for an Apple MacBook.

> library(lubridate)
Error in library(lubridate) : there is no package called ?lubridate?

Greg Coats
Reston, Virginia USA

> On Mar 16, 2021, at 7:49 PM, Daniel Nordlund <djnordlund at gmail.com> wrote:
> 
> # create timepart variable - tme
> library(lubridate)


	[[alternative HTML version deleted]]


From gregco@t@ @end|ng |rom me@com  Wed Mar 17 01:26:29 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Tue, 16 Mar 2021 20:26:29 -0400
Subject: [R] How to plot dates
In-Reply-To: <033401d71ac0$ac6ce660$0546b320$@verizon.net>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
 <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
 <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
 <033401d71ac0$ac6ce660$0546b320$@verizon.net>
Message-ID: <35B740D0-85D6-444E-945C-8E5DBAFF7017@me.com>

Thank you very much.
In addition to what your did, for event 1, I would like to draw a horizontal line connecting from day 1 to day 2 to day 3 to day 4.
Then, for event 2, I would like to draw a horizontal line connecting from day 1 to day 2 to day 3 to day 4.
Similarly for events 3, and 4. Is that convenient to do?
Greg Coats

> On Mar 16, 2021, at 8:01 PM, Avi Gross via R-help <r-help at r-project.org> wrote:
> 
> Here is an example that worked for me doing roughly what I mentioned but
> note my names changed. It makes two plots.
> 
> library (ggplot2)
> myDat <- read.table(text =
>                      "datetimeraw
> 2021-03-12 05:16:46
> 2021-03-12 09:17:02
> 2021-03-12 13:31:43
> 2021-03-12 22:00:32
> 2021-03-13 09:21:43
> 2021-03-13 13:51:12
> 2021-03-13 18:03:13
> 2021-03-13 22:20:28
> 2021-03-14 08:59:03
> 2021-03-14 13:15:56
> 2021-03-14 17:25:23
> 2021-03-14 21:36:26",
>                    sep = ",", header = TRUE)
> head(myDat)
> myDat$datetime <- as.POSIXct(myDat$datetimeraw, tz = "", format ="%Y-%M-%d
> %H:%M:%OS")
> myDat$date <- factor(format(myDat$datetime, "%Y-%m-%d"))
> myDat$time <- format(myDat$datetime, "%H:%M")
> myDat$seq <- factor(rep(1:4, 3))
> 
> # just dots
> ggplot(data=myDat,aes(x=date, y=time)) + geom_point(aes(color=seq))
> 
> # Also text
> ggplot(data=myDat,aes(x=date, y=time, label=time)) + 
>  geom_point(aes(color=seq)) + 
>               geom_text(aes(color=seq))

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Wed Mar 17 01:34:06 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Tue, 16 Mar 2021 20:34:06 -0400
Subject: [R] Problem with the str_replace function
Message-ID: <313da24d0e254072c3183a34f30f41e5@philipsmith.ca>

I have a problem with the str_replace() function in the stringr package. 
Please refer to my reprex below.

I start with a vector of strings, called x. Some of the strings contain 
apostrophes and brackets. I make a simple replacement as with x1, and 
there is no problem. I make another simple replacement, x2, where the 
pattern string has an apostrophe. Again no problem. Then I make a third 
replacement, x3, where the pattern has opening and closing brackets and 
the function still works fine. Finally I make a replacement where the 
pattern has both an apostrophe and opening and closing brackets and the 
replacement does not work. I tried to solve this by putting backslashes 
before the apostrophe and/or the brackets, but that accomplished 
nothing. I am stumped.

# Reprex for str_replace problem

library(stringr)

x <- c(
   "Clothing and footwear",
   "Women's clothing",
   "Women's footwear (excluding athletic)",
   "Clothing accessories (belts and so on)",
   "Clothing and footwear",
   "Women's clothing",
   "Women's footwear (excluding athletic)",
   "Clothing accessories (belts and so on)"
)
x
x1 <- str_replace(x,
   "Clothing and footwear",
   "Clothing and shoes"
)
x1
x2 <- str_replace(x,
   "Women's clothing",
   "Women's clothing goods"
)
x2
x3 <- str_replace(x,
   "Clothing accessories (belts and so on)",
   "Clothing accessories")
x3
x4 <- str_replace(x,
   "Women's footwear (excluding athletic)",
   "Women's footwear")
x4


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Mar 17 01:59:27 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 16 Mar 2021 20:59:27 -0400
Subject: [R] How to plot dates
In-Reply-To: <35B740D0-85D6-444E-945C-8E5DBAFF7017@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
 <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
 <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
 <033401d71ac0$ac6ce660$0546b320$@verizon.net>
 <35B740D0-85D6-444E-945C-8E5DBAFF7017@me.com>
Message-ID: <042501d71ac8$c796f720$56c4e560$@verizon.net>

Not sure what you mean by a horizontal line, Greg.

I change one of my plots to add a path between corresponding values of the
sequence variable but obviously those lines are mostly not horizontal. Look
at geom_path and similar geoms like geom_line to connect endpoints grouped
whatever way you specify.

ggplot(data=myDat,aes(x=date, y=time, label=time)) + 
??geom_point(aes(color=seq)) + 
??geom_path(aes(group=seq)) +
? geom_text(aes(color=seq))

As this is a help group, I think I am done.

From: Gregory Coats <mailto:gregcoats at me.com> 
Sent: Tuesday, March 16, 2021 8:26 PM
To: Avi Gross <mailto:avigross at verizon.net>
Cc: mailto:r-help at r-project.org
Subject: Re: [R] How to plot dates

Thank you very much.
In addition to what your did, for event 1, I would like to draw a horizontal
line connecting from day 1 to day 2 to day 3 to day 4.
Then, for event 2, I would like to draw a horizontal line connecting from
day 1 to day 2 to day 3 to day 4.
Similarly for events 3, and 4. Is that convenient to do?
Greg Coats

On Mar 16, 2021, at 8:01 PM, Avi Gross via R-help
<mailto:r-help at r-project.org> wrote:

Here is an example that worked for me doing roughly what I mentioned but
note my names changed. It makes two plots.

library (ggplot2)
myDat <- read.table(text =
?????????????????????"datetimeraw
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56
2021-03-14 17:25:23
2021-03-14 21:36:26",
???????????????????sep = ",", header = TRUE)
head(myDat)
myDat$datetime <- as.POSIXct(myDat$datetimeraw, tz = "", format ="%Y-%M-%d
%H:%M:%OS")
myDat$date <- factor(format(myDat$datetime, "%Y-%m-%d"))
myDat$time <- format(myDat$datetime, "%H:%M")
myDat$seq <- factor(rep(1:4, 3))

# just dots
ggplot(data=myDat,aes(x=date, y=time)) + geom_point(aes(color=seq))

# Also text
ggplot(data=myDat,aes(x=date, y=time, label=time)) +?
?geom_point(aes(color=seq)) +?
??????????????geom_text(aes(color=seq))


From: Gregory Coats <gregcoats at me.com> 
Sent: Tuesday, March 16, 2021 8:26 PM
To: Avi Gross <avigross at verizon.net>
Cc: r-help at r-project.org
Subject: Re: [R] How to plot dates

Thank you very much.
In addition to what your did, for event 1, I would like to draw a horizontal
line connecting from day 1 to day 2 to day 3 to day 4.
Then, for event 2, I would like to draw a horizontal line connecting from
day 1 to day 2 to day 3 to day 4.
Similarly for events 3, and 4. Is that convenient to do?
Greg Coats


On Mar 16, 2021, at 8:01 PM, Avi Gross via R-help
<mailto:r-help at r-project.org> wrote:

Here is an example that worked for me doing roughly what I mentioned but
note my names changed. It makes two plots.

library (ggplot2)
myDat <- read.table(text =
?????????????????????"datetimeraw
2021-03-12 05:16:46
2021-03-12 09:17:02
2021-03-12 13:31:43
2021-03-12 22:00:32
2021-03-13 09:21:43
2021-03-13 13:51:12
2021-03-13 18:03:13
2021-03-13 22:20:28
2021-03-14 08:59:03
2021-03-14 13:15:56
2021-03-14 17:25:23
2021-03-14 21:36:26",
???????????????????sep = ",", header = TRUE)
head(myDat)
myDat$datetime <- as.POSIXct(myDat$datetimeraw, tz = "", format ="%Y-%M-%d
%H:%M:%OS")
myDat$date <- factor(format(myDat$datetime, "%Y-%m-%d"))
myDat$time <- format(myDat$datetime, "%H:%M")
myDat$seq <- factor(rep(1:4, 3))

# just dots
ggplot(data=myDat,aes(x=date, y=time)) + geom_point(aes(color=seq))

# Also text
ggplot(data=myDat,aes(x=date, y=time, label=time)) +?
?geom_point(aes(color=seq)) +?
??????????????geom_text(aes(color=seq))


From bgunter@4567 @end|ng |rom gm@||@com  Wed Mar 17 02:23:03 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 16 Mar 2021 18:23:03 -0700
Subject: [R] Problem with the str_replace function
In-Reply-To: <313da24d0e254072c3183a34f30f41e5@philipsmith.ca>
References: <313da24d0e254072c3183a34f30f41e5@philipsmith.ca>
Message-ID: <CAGxFJbSEYwVbXTVbXM4uz08anyWdXWHRqNp7C0C0t=5Umqwong@mail.gmail.com>

I prefer using regular expressions directly, so this may not satisfy you:

> a <-"Women's footwear (excluding athletic)"
> b <- gsub("(.*) \\(.*$","\\1",a)
> b
[1] "Women's footwear"

There are, of course other ways to do this with regex's or even substring()

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Mar 16, 2021 at 5:36 PM <phil at philipsmith.ca> wrote:

> I have a problem with the str_replace() function in the stringr package.
> Please refer to my reprex below.
>
> I start with a vector of strings, called x. Some of the strings contain
> apostrophes and brackets. I make a simple replacement as with x1, and
> there is no problem. I make another simple replacement, x2, where the
> pattern string has an apostrophe. Again no problem. Then I make a third
> replacement, x3, where the pattern has opening and closing brackets and
> the function still works fine. Finally I make a replacement where the
> pattern has both an apostrophe and opening and closing brackets and the
> replacement does not work. I tried to solve this by putting backslashes
> before the apostrophe and/or the brackets, but that accomplished
> nothing. I am stumped.
>
> # Reprex for str_replace problem
>
> library(stringr)
>
> x <- c(
>    "Clothing and footwear",
>    "Women's clothing",
>    "Women's footwear (excluding athletic)",
>    "Clothing accessories (belts and so on)",
>    "Clothing and footwear",
>    "Women's clothing",
>    "Women's footwear (excluding athletic)",
>    "Clothing accessories (belts and so on)"
> )
> x
> x1 <- str_replace(x,
>    "Clothing and footwear",
>    "Clothing and shoes"
> )
> x1
> x2 <- str_replace(x,
>    "Women's clothing",
>    "Women's clothing goods"
> )
> x2
> x3 <- str_replace(x,
>    "Clothing accessories (belts and so on)",
>    "Clothing accessories")
> x3
> x4 <- str_replace(x,
>    "Women's footwear (excluding athletic)",
>    "Women's footwear")
> x4
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hp@ge@@on@g|thub @end|ng |rom gm@||@com  Wed Mar 17 06:19:52 2021
From: hp@ge@@on@g|thub @end|ng |rom gm@||@com (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 16 Mar 2021 22:19:52 -0700
Subject: [R] Problem with the str_replace function
In-Reply-To: <313da24d0e254072c3183a34f30f41e5@philipsmith.ca>
References: <313da24d0e254072c3183a34f30f41e5@philipsmith.ca>
Message-ID: <0d857753-d6ba-f61e-9ecd-7411577ec969@gmail.com>

Hi,

stringr::str_replace() treats the 2nd argument ('pattern') as a regular 
expression and some characters have a special meaning when they are used 
in a regular expression. For example the dot plays the role of a 
wildcard (i.e. it means "any character"):

   > str_replace("aaXcc", "a.c", "ZZ")
   [1] "aZZc"

If you want to treat a special character literally, you need to escape 
it with a double backslahe '\\':

   > str_replace(c("aaXcc", "aa.cc"), "a.c", "ZZ")
   [1] "aZZc" "aZZc"

   > str_replace(c("aaXcc", "aa.cc"), "a\\.c", "ZZ")
   [1] "aaXcc" "aZZc"

Turns out that parenthesis are also special characters so you also need 
to escape them:

   > str_replace("aa(X)cc", "a(X)c", "ZZ")
   [1] "aa(X)cc"

   > str_replace("aa(X)cc", "a\\(X\\)c", "ZZ")
   [1] "aZZc"

There are plenty of example in the man page for str_replace() (see 
'?str_replace') including examples showing the use of parenthesis in the 
pattern.

Hope this helps,

H.


On 3/16/21 5:34 PM, phil at philipsmith.ca wrote:
> I have a problem with the str_replace() function in the stringr package. 
> Please refer to my reprex below.
> 
> I start with a vector of strings, called x. Some of the strings contain 
> apostrophes and brackets. I make a simple replacement as with x1, and 
> there is no problem. I make another simple replacement, x2, where the 
> pattern string has an apostrophe. Again no problem. Then I make a third 
> replacement, x3, where the pattern has opening and closing brackets and 
> the function still works fine. Finally I make a replacement where the 
> pattern has both an apostrophe and opening and closing brackets and the 
> replacement does not work. I tried to solve this by putting backslashes 
> before the apostrophe and/or the brackets, but that accomplished 
> nothing. I am stumped.
> 
> # Reprex for str_replace problem
> 
> library(stringr)
> 
> x <- c(
>  ? "Clothing and footwear",
>  ? "Women's clothing",
>  ? "Women's footwear (excluding athletic)",
>  ? "Clothing accessories (belts and so on)",
>  ? "Clothing and footwear",
>  ? "Women's clothing",
>  ? "Women's footwear (excluding athletic)",
>  ? "Clothing accessories (belts and so on)"
> )
> x
> x1 <- str_replace(x,
>  ? "Clothing and footwear",
>  ? "Clothing and shoes"
> )
> x1
> x2 <- str_replace(x,
>  ? "Women's clothing",
>  ? "Women's clothing goods"
> )
> x2
> x3 <- str_replace(x,
>  ? "Clothing accessories (belts and so on)",
>  ? "Clothing accessories")
> x3
> x4 <- str_replace(x,
>  ? "Women's footwear (excluding athletic)",
>  ? "Women's footwear")
> x4
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Herv? Pag?s

Bioconductor Core Team
hpages.on.github at gmail.com


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Wed Mar 17 07:41:40 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Wed, 17 Mar 2021 12:11:40 +0530
Subject: [R] unanticipated axis labels
In-Reply-To: <CO1PR11MB510756F5F9A77853EF17A188D26B9@CO1PR11MB5107.namprd11.prod.outlook.com>
References: <CO1PR11MB510756F5F9A77853EF17A188D26B9@CO1PR11MB5107.namprd11.prod.outlook.com>
Message-ID: <CADfFDC6qWw2LGR_5qYTASZz+8mKAVG8OG67beMDWX2wPKxSG8Q@mail.gmail.com>

On Tue, Mar 16, 2021 at 11:35 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> library(lattice)
> library(latticeExtra)
>
> barchart(matrix(c(1:6, 5:6)), main="unanticipated left axis labels", ylab="unanticipated inside labels") +
>   latticeExtra::layer(panel.axis("left", half=FALSE, labels=1:8        ))

So to summarize, your problem case happens when you explicitly specify
'labels' but not 'at' in panel.axis(), right?

Unfortunately, this is not intended to work at all, so what you are
seeing is undefined behaviour. This is hinted at, but not quite
explicitly spelled out, in the documentation. I will fix that, and
maybe add a warning as well.

-Deepayan

> barchart(matrix(c(1:6, 5:6)), main="ok 1", ylab="anticipated") +
>   latticeExtra::layer(panel.axis("left", half=FALSE, labels=1:8, at=1:8))
>
> barchart(matrix(c(1:6, 5:6)), main="ok 2", ylab="anticipated") +
>   latticeExtra::layer(panel.axis("left", half=FALSE,             at=1:8))
>
> barchart(matrix(c(1:6, 5:6)), main="ok 3", ylab="anticipated") +
>   latticeExtra::layer(panel.axis("left", half=FALSE                    ))
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Mar 17 09:07:42 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 17 Mar 2021 08:07:42 +0000
Subject: [R] How to plot dates
In-Reply-To: <E3B863C9-2C05-4917-A72D-782703AA3D83@me.com>
References: <2E71F31E-AEE8-4FF7-B9E7-067CCD314C3C@me.com>
 <58CBF8DE-B17E-4376-A4CA-10F865CBEF2D@me.com>
 <005b01d719e9$b8373860$28a5a920$@sbcglobal.net>
 <2DB01128-C5DA-4D02-961B-C784B09033BD@me.com>
 <D0B46B0A-E5E2-4807-9847-50D97BD2904F@me.com>
 <CAM_vjumroRzQ3n7TqFzx+gsdmY-7K4VXzj4B4sP_s=_ui=w4zA@mail.gmail.com>
 <10399_1615911692_12GGLVsA010523_A35EDAF8-203F-4EB0-90D8-3D6DB6B2744E@me.com>
 <0945c0aa-dec8-59e3-b706-11eefb06fcd5@mcmaster.ca>
 <19785_1615922771_12GJQAG6024811_0072F6CA-2F04-461D-A815-7DEB763BA8BD@me.com>
 <bfea0be3-53b3-d127-d1f5-b2e631e78483@mcmaster.ca>
 <10A9844D-CCF9-4745-8B02-1CC824A3EF8B@me.com>
 <d7a49d98-cc3b-673f-980c-480a322d0efc@gmail.com>
 <E3B863C9-2C05-4917-A72D-782703AA3D83@me.com>
Message-ID: <b287c9fa08a747fb867d0426d746848d@SRVEXCHCM1302.precheza.cz>

Hi

install.packages("lubridate") does not work on Mac?

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Gregory Coats
> via R-help
> Sent: Wednesday, March 17, 2021 1:11 AM
> To: Daniel Nordlund <djnordlund at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] How to plot dates
> 
> Dan, Thank you for this guidance.
> Unfortunately, I do not have the library lubridate, and I do not at this
> moment know where to go to get this library for an Apple MacBook.
> 
> > library(lubridate)
> Error in library(lubridate) : there is no package called ?lubridate?
> 
> Greg Coats
> Reston, Virginia USA
> 
> > On Mar 16, 2021, at 7:49 PM, Daniel Nordlund <djnordlund at gmail.com>
> wrote:
> >
> > # create timepart variable - tme
> > library(lubridate)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Mar 17 10:41:03 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 17 Mar 2021 10:41:03 +0100
Subject: [R] modelling 4-parameter curve in R does not match data - how to
 proceed?
Message-ID: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>

Hello,
I have a dataset from a polymerase chain reaction. I am using the
equation given by Rutledge
(https://pubmed.ncbi.nlm.nih.gov/15601990/) but the profile I get in R
does not match the data. I ran the same thing in Desmos and instead
the profile is correct (attached).
Why do I not get the same matching model as in Desmos? I believe the
formula in R is the same as the one in Desmos, and I am using the same
parameters.
Is there a procedure to debug models?
Thanks

Here is the code:
```
high <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
       -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
       75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
       6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
       10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
       11781.77, 11863.35, 11927.44, 11980.81, 12021.88)
plot(1:45, high, type = "l")
rutledge <- function(p, x) {
  m = p$half_fluorescence
  s = p$slope
  M = p$max_fluorescence
  B = p$back_fluorescence
  y = (M / ( 1 + exp(-(x-m)/s)) ) + B
  return(y)
}
desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
                        max_fluorescence = 11839.8, back_fluorescence
= -138.864) , high)

points(1:45, desmos, type="l", col="blue")
```

-- 
Best regards,
Luigi

-------------- next part --------------
A non-text attachment was scrubbed...
Name: model.png
Type: image/png
Size: 74299 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210317/f9a5d1d5/attachment.png>

From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Mar 17 11:31:35 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 17 Mar 2021 06:31:35 -0400
Subject: [R] 
 modelling 4-parameter curve in R does not match data - how to
 proceed?
In-Reply-To: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>
References: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>
Message-ID: <1936fa40-601f-4756-caa7-5bed63ca6a62@gmail.com>

On 17/03/2021 5:41 a.m., Luigi Marongiu wrote:
> Hello,
> I have a dataset from a polymerase chain reaction. I am using the
> equation given by Rutledge
> (https://pubmed.ncbi.nlm.nih.gov/15601990/) but the profile I get in R
> does not match the data. I ran the same thing in Desmos and instead
> the profile is correct (attached).
> Why do I not get the same matching model as in Desmos? I believe the
> formula in R is the same as the one in Desmos, and I am using the same
> parameters.
> Is there a procedure to debug models?
> Thanks
> 
> Here is the code:
> ```
> high <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
>         -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
>         75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
>         6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
>         10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
>         11781.77, 11863.35, 11927.44, 11980.81, 12021.88)
> plot(1:45, high, type = "l")
> rutledge <- function(p, x) {
>    m = p$half_fluorescence
>    s = p$slope
>    M = p$max_fluorescence
>    B = p$back_fluorescence
>    y = (M / ( 1 + exp(-(x-m)/s)) ) + B
>    return(y)
> }
> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>                          max_fluorescence = 11839.8, back_fluorescence
> = -138.864) , high)
> 
> points(1:45, desmos, type="l", col="blue")


In your calculation of desmos, you are using the Y variable for x in the 
formula.  Calculate it this way instead:

desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
                           max_fluorescence = 11839.8, back_fluorescence
  = -138.864) , 1:45)

Duncan Murdoch


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Mar 17 11:59:45 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 17 Mar 2021 11:59:45 +0100
Subject: [R] 
 modelling 4-parameter curve in R does not match data - how to
 proceed?
In-Reply-To: <1936fa40-601f-4756-caa7-5bed63ca6a62@gmail.com>
References: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>
 <1936fa40-601f-4756-caa7-5bed63ca6a62@gmail.com>
Message-ID: <CAMk+s2Q5z3DrH5wkYDXqGzDb3eLfWyw17kAATn23s9QvNJVYAA@mail.gmail.com>

yes, but in `rutledge` I model y as `y = (M / ( 1 + exp(-(x-m)/s)) ) +
B`, with x being 1:45. Isn't that the equivalent of what I fed Desmos
with? Tx

On Wed, Mar 17, 2021 at 11:31 AM Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> On 17/03/2021 5:41 a.m., Luigi Marongiu wrote:
> > Hello,
> > I have a dataset from a polymerase chain reaction. I am using the
> > equation given by Rutledge
> > (https://pubmed.ncbi.nlm.nih.gov/15601990/) but the profile I get in R
> > does not match the data. I ran the same thing in Desmos and instead
> > the profile is correct (attached).
> > Why do I not get the same matching model as in Desmos? I believe the
> > formula in R is the same as the one in Desmos, and I am using the same
> > parameters.
> > Is there a procedure to debug models?
> > Thanks
> >
> > Here is the code:
> > ```
> > high <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> >         -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> >         75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> >         6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> >         10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> >         11781.77, 11863.35, 11927.44, 11980.81, 12021.88)
> > plot(1:45, high, type = "l")
> > rutledge <- function(p, x) {
> >    m = p$half_fluorescence
> >    s = p$slope
> >    M = p$max_fluorescence
> >    B = p$back_fluorescence
> >    y = (M / ( 1 + exp(-(x-m)/s)) ) + B
> >    return(y)
> > }
> > desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
> >                          max_fluorescence = 11839.8, back_fluorescence
> > = -138.864) , high)
> >
> > points(1:45, desmos, type="l", col="blue")
>
>
> In your calculation of desmos, you are using the Y variable for x in the
> formula.  Calculate it this way instead:
>
> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>                            max_fluorescence = 11839.8, back_fluorescence
>   = -138.864) , 1:45)
>
> Duncan Murdoch
>


-- 
Best regards,
Luigi


From phii m@iii@g oii phiiipsmith@c@  Wed Mar 17 12:59:43 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Wed, 17 Mar 2021 07:59:43 -0400
Subject: [R] Problem with the str_replace function
In-Reply-To: <0d857753-d6ba-f61e-9ecd-7411577ec969@gmail.com>
References: <313da24d0e254072c3183a34f30f41e5@philipsmith.ca>
 <0d857753-d6ba-f61e-9ecd-7411577ec969@gmail.com>
Message-ID: <7e2efc59a9d2e52c0e5854f885cf3a58@philipsmith.ca>

Your help is much appreciated. I now understand what my problem was and 
can move forward.

Philip


On 2021-03-17 01:19, Herv? Pag?s wrote:
> Hi,
> 
> stringr::str_replace() treats the 2nd argument ('pattern') as a
> regular expression and some characters have a special meaning when
> they are used in a regular expression. For example the dot plays the
> role of a wildcard (i.e. it means "any character"):
> 
>   > str_replace("aaXcc", "a.c", "ZZ")
>   [1] "aZZc"
> 
> If you want to treat a special character literally, you need to escape
> it with a double backslahe '\\':
> 
>   > str_replace(c("aaXcc", "aa.cc"), "a.c", "ZZ")
>   [1] "aZZc" "aZZc"
> 
>   > str_replace(c("aaXcc", "aa.cc"), "a\\.c", "ZZ")
>   [1] "aaXcc" "aZZc"
> 
> Turns out that parenthesis are also special characters so you also
> need to escape them:
> 
>   > str_replace("aa(X)cc", "a(X)c", "ZZ")
>   [1] "aa(X)cc"
> 
>   > str_replace("aa(X)cc", "a\\(X\\)c", "ZZ")
>   [1] "aZZc"
> 
> There are plenty of example in the man page for str_replace() (see
> '?str_replace') including examples showing the use of parenthesis in
> the pattern.
> 
> Hope this helps,
> 
> H.
> 
> 
> On 3/16/21 5:34 PM, phil at philipsmith.ca wrote:
>> I have a problem with the str_replace() function in the stringr 
>> package. Please refer to my reprex below.
>> 
>> I start with a vector of strings, called x. Some of the strings 
>> contain apostrophes and brackets. I make a simple replacement as with 
>> x1, and there is no problem. I make another simple replacement, x2, 
>> where the pattern string has an apostrophe. Again no problem. Then I 
>> make a third replacement, x3, where the pattern has opening and 
>> closing brackets and the function still works fine. Finally I make a 
>> replacement where the pattern has both an apostrophe and opening and 
>> closing brackets and the replacement does not work. I tried to solve 
>> this by putting backslashes before the apostrophe and/or the brackets, 
>> but that accomplished nothing. I am stumped.
>> 
>> # Reprex for str_replace problem
>> 
>> library(stringr)
>> 
>> x <- c(
>>  ? "Clothing and footwear",
>>  ? "Women's clothing",
>>  ? "Women's footwear (excluding athletic)",
>>  ? "Clothing accessories (belts and so on)",
>>  ? "Clothing and footwear",
>>  ? "Women's clothing",
>>  ? "Women's footwear (excluding athletic)",
>>  ? "Clothing accessories (belts and so on)"
>> )
>> x
>> x1 <- str_replace(x,
>>  ? "Clothing and footwear",
>>  ? "Clothing and shoes"
>> )
>> x1
>> x2 <- str_replace(x,
>>  ? "Women's clothing",
>>  ? "Women's clothing goods"
>> )
>> x2
>> x3 <- str_replace(x,
>>  ? "Clothing accessories (belts and so on)",
>>  ? "Clothing accessories")
>> x3
>> x4 <- str_replace(x,
>>  ? "Women's footwear (excluding athletic)",
>>  ? "Women's footwear")
>> x4
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Mar 17 14:35:53 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 17 Mar 2021 09:35:53 -0400
Subject: [R] 
 modelling 4-parameter curve in R does not match data - how to
 proceed?
In-Reply-To: <CAMk+s2Q5z3DrH5wkYDXqGzDb3eLfWyw17kAATn23s9QvNJVYAA@mail.gmail.com>
References: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>
 <1936fa40-601f-4756-caa7-5bed63ca6a62@gmail.com>
 <CAMk+s2Q5z3DrH5wkYDXqGzDb3eLfWyw17kAATn23s9QvNJVYAA@mail.gmail.com>
Message-ID: <b0d7e65c-4140-4150-e9a5-d6e9bfbd2ef7@gmail.com>

On 17/03/2021 6:59 a.m., Luigi Marongiu wrote:
> yes, but in `rutledge` I model y as `y = (M / ( 1 + exp(-(x-m)/s)) ) +
> B`, with x being 1:45. Isn't that the equivalent of what I fed Desmos
> with? Tx

No, it's not.

Duncan Murdoch

> 
> On Wed, Mar 17, 2021 at 11:31 AM Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>>
>> On 17/03/2021 5:41 a.m., Luigi Marongiu wrote:
>>> Hello,
>>> I have a dataset from a polymerase chain reaction. I am using the
>>> equation given by Rutledge
>>> (https://pubmed.ncbi.nlm.nih.gov/15601990/) but the profile I get in R
>>> does not match the data. I ran the same thing in Desmos and instead
>>> the profile is correct (attached).
>>> Why do I not get the same matching model as in Desmos? I believe the
>>> formula in R is the same as the one in Desmos, and I am using the same
>>> parameters.
>>> Is there a procedure to debug models?
>>> Thanks
>>>
>>> Here is the code:
>>> ```
>>> high <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
>>>          -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
>>>          75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
>>>          6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
>>>          10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
>>>          11781.77, 11863.35, 11927.44, 11980.81, 12021.88)
>>> plot(1:45, high, type = "l")
>>> rutledge <- function(p, x) {
>>>     m = p$half_fluorescence
>>>     s = p$slope
>>>     M = p$max_fluorescence
>>>     B = p$back_fluorescence
>>>     y = (M / ( 1 + exp(-(x-m)/s)) ) + B
>>>     return(y)
>>> }
>>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>>>                           max_fluorescence = 11839.8, back_fluorescence
>>> = -138.864) , high)
>>>
>>> points(1:45, desmos, type="l", col="blue")
>>
>>
>> In your calculation of desmos, you are using the Y variable for x in the
>> formula.  Calculate it this way instead:
>>
>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>>                             max_fluorescence = 11839.8, back_fluorescence
>>    = -138.864) , 1:45)
>>
>> Duncan Murdoch
>>
> 
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Mar 17 17:37:28 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 17 Mar 2021 17:37:28 +0100
Subject: [R] 
 modelling 4-parameter curve in R does not match data - how to
 proceed?
In-Reply-To: <b0d7e65c-4140-4150-e9a5-d6e9bfbd2ef7@gmail.com>
References: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>
 <1936fa40-601f-4756-caa7-5bed63ca6a62@gmail.com>
 <CAMk+s2Q5z3DrH5wkYDXqGzDb3eLfWyw17kAATn23s9QvNJVYAA@mail.gmail.com>
 <b0d7e65c-4140-4150-e9a5-d6e9bfbd2ef7@gmail.com>
Message-ID: <CAMk+s2Rdxb2TFtPcSFVUk_D6EXFGQ+7JXOmZgriQ0imX7amg1g@mail.gmail.com>

sorry, I don't get it...

On Wed, Mar 17, 2021 at 2:35 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 17/03/2021 6:59 a.m., Luigi Marongiu wrote:
> > yes, but in `rutledge` I model y as `y = (M / ( 1 + exp(-(x-m)/s)) ) +
> > B`, with x being 1:45. Isn't that the equivalent of what I fed Desmos
> > with? Tx
>
> No, it's not.
>
> Duncan Murdoch
>
> >
> > On Wed, Mar 17, 2021 at 11:31 AM Duncan Murdoch
> > <murdoch.duncan at gmail.com> wrote:
> >>
> >> On 17/03/2021 5:41 a.m., Luigi Marongiu wrote:
> >>> Hello,
> >>> I have a dataset from a polymerase chain reaction. I am using the
> >>> equation given by Rutledge
> >>> (https://pubmed.ncbi.nlm.nih.gov/15601990/) but the profile I get in R
> >>> does not match the data. I ran the same thing in Desmos and instead
> >>> the profile is correct (attached).
> >>> Why do I not get the same matching model as in Desmos? I believe the
> >>> formula in R is the same as the one in Desmos, and I am using the same
> >>> parameters.
> >>> Is there a procedure to debug models?
> >>> Thanks
> >>>
> >>> Here is the code:
> >>> ```
> >>> high <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> >>>          -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> >>>          75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> >>>          6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> >>>          10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> >>>          11781.77, 11863.35, 11927.44, 11980.81, 12021.88)
> >>> plot(1:45, high, type = "l")
> >>> rutledge <- function(p, x) {
> >>>     m = p$half_fluorescence
> >>>     s = p$slope
> >>>     M = p$max_fluorescence
> >>>     B = p$back_fluorescence
> >>>     y = (M / ( 1 + exp(-(x-m)/s)) ) + B
> >>>     return(y)
> >>> }
> >>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
> >>>                           max_fluorescence = 11839.8, back_fluorescence
> >>> = -138.864) , high)
> >>>
> >>> points(1:45, desmos, type="l", col="blue")
> >>
> >>
> >> In your calculation of desmos, you are using the Y variable for x in the
> >> formula.  Calculate it this way instead:
> >>
> >> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
> >>                             max_fluorescence = 11839.8, back_fluorescence
> >>    = -138.864) , 1:45)
> >>
> >> Duncan Murdoch
> >>
> >
> >
>


-- 
Best regards,
Luigi


From gregco@t@ @end|ng |rom me@com  Wed Mar 17 18:07:54 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Wed, 17 Mar 2021 13:07:54 -0400
Subject: [R] library(hms)
Message-ID: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>

On my MacBook, I do not have, and do not know how to install, library(hms).
Greg Coats

> library(hms)
Error in library(hms) : there is no package called ?hms?
> Install.libraries(?hms?)
Error: unexpected input in "Install.libraries(?"
> 
	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Mar 17 18:16:08 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 17 Mar 2021 10:16:08 -0700
Subject: [R] library(hms)
In-Reply-To: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
References: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
Message-ID: <CAHqSRuRkVzN3V9vw4ff9FN_bExStwAB3kQi7mznywnFLFv5DAQ@mail.gmail.com>

install.packages("hms")

A 'library' is a directory (aka folder) that contains installed
'packages'.  I.e., one installs packages into a library, but one does
not install a library.

-Bill

On Wed, Mar 17, 2021 at 10:08 AM Gregory Coats via R-help
<r-help at r-project.org> wrote:
>
> On my MacBook, I do not have, and do not know how to install, library(hms).
> Greg Coats
>
> > library(hms)
> Error in library(hms) : there is no package called ?hms?
> > Install.libraries(?hms?)
> Error: unexpected input in "Install.libraries(?"
> >
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rk|eed@2 @end|ng |rom gm@||@com  Wed Mar 17 18:17:14 2021
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Wed, 17 Mar 2021 13:17:14 -0400
Subject: [R] library(hms)
In-Reply-To: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
References: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
Message-ID: <CAHz+bWa-R+wf_9s-NW0=OrsyULAMfo1N-V+EOsA5sf9n49BZsQ@mail.gmail.com>

Hi: install.packages("hms") should work if you have R installed along with
an internet connection.

When you do above, if you get a message about other packages needing to be
installed, then use

install.packages("hms", dependencies = TRUE).





On Wed, Mar 17, 2021 at 1:08 PM Gregory Coats via R-help <
r-help at r-project.org> wrote:

> On my MacBook, I do not have, and do not know how to install, library(hms).
> Greg Coats
>
> > library(hms)
> Error in library(hms) : there is no package called ?hms?
> > Install.libraries(?hms?)
> Error: unexpected input in "Install.libraries(?"
> >
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From b|oprogr@mmer @end|ng |rom gm@||@com  Wed Mar 17 18:19:40 2021
From: b|oprogr@mmer @end|ng |rom gm@||@com (Caitlin Gibbons)
Date: Wed, 17 Mar 2021 10:19:40 -0700
Subject: [R] library(hms)
In-Reply-To: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
References: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
Message-ID: <03F4828C-B3AB-47FA-8BE5-58E5889A29C2@gmail.com>

Maybe you used the wrong quotes with the parentheses? 

> On Mar 17, 2021, at 10:08 AM, Gregory Coats via R-help <r-help at r-project.org> wrote:
> 
> ?On my MacBook, I do not have, and do not know how to install, library(hms).
> Greg Coats
> 
>> library(hms)
> Error in library(hms) : there is no package called ?hms?
>> Install.libraries(?hms?)
> Error: unexpected input in "Install.libraries(?"
>> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Mar 17 18:30:13 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 17 Mar 2021 17:30:13 +0000
Subject: [R] [External]  unanticipated axis labels
In-Reply-To: <CADfFDC6qWw2LGR_5qYTASZz+8mKAVG8OG67beMDWX2wPKxSG8Q@mail.gmail.com>
References: <CO1PR11MB510756F5F9A77853EF17A188D26B9@CO1PR11MB5107.namprd11.prod.outlook.com>
 <CADfFDC6qWw2LGR_5qYTASZz+8mKAVG8OG67beMDWX2wPKxSG8Q@mail.gmail.com>
Message-ID: <DCB1751D-7F7B-4DCF-8E86-D835472FDA28@temple.edu>

exactly!
a warning when running would be very helpful.

Thank you.

Rich

> On Mar 17, 2021, at 02:41, Deepayan Sarkar <deepayan.sarkar at gmail.com> wrote:
> 
> On Tue, Mar 16, 2021 at 11:35 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>> 
>> library(lattice)
>> library(latticeExtra)
>> 
>> barchart(matrix(c(1:6, 5:6)), main="unanticipated left axis labels", ylab="unanticipated inside labels") +
>>  latticeExtra::layer(panel.axis("left", half=FALSE, labels=1:8        ))
> 
> So to summarize, your problem case happens when you explicitly specify
> 'labels' but not 'at' in panel.axis(), right?
> 
> Unfortunately, this is not intended to work at all, so what you are
> seeing is undefined behaviour. This is hinted at, but not quite
> explicitly spelled out, in the documentation. I will fix that, and
> maybe add a warning as well.
> 
> -Deepayan
> 
>> barchart(matrix(c(1:6, 5:6)), main="ok 1", ylab="anticipated") +
>>  latticeExtra::layer(panel.axis("left", half=FALSE, labels=1:8, at=1:8))
>> 
>> barchart(matrix(c(1:6, 5:6)), main="ok 2", ylab="anticipated") +
>>  latticeExtra::layer(panel.axis("left", half=FALSE,             at=1:8))
>> 
>> barchart(matrix(c(1:6, 5:6)), main="ok 3", ylab="anticipated") +
>>  latticeExtra::layer(panel.axis("left", half=FALSE                    ))
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From b|oprogr@mmer @end|ng |rom gm@||@com  Wed Mar 17 18:33:41 2021
From: b|oprogr@mmer @end|ng |rom gm@||@com (Caitlin Gibbons)
Date: Wed, 17 Mar 2021 10:33:41 -0700
Subject: [R] library(hms)
In-Reply-To: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
References: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
Message-ID: <EE1F23E8-3778-4D54-9E38-379F40E968B1@gmail.com>

Your opening quote looks slightly different from the closing quote. This probably explains why you received the error message regarding ?unexpected input?. 

I hope this helps. 


> On Mar 17, 2021, at 10:08 AM, Gregory Coats via R-help <r-help at r-project.org> wrote:
> 
> ?On my MacBook, I do not have, and do not know how to install, library(hms).
> Greg Coats
> 
>> library(hms)
> Error in library(hms) : there is no package called ?hms?
>> Install.libraries(?hms?)
> Error: unexpected input in "Install.libraries(?"
>> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gregco@t@ @end|ng |rom me@com  Wed Mar 17 18:34:25 2021
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Wed, 17 Mar 2021 13:34:25 -0400
Subject: [R] library(hms)
In-Reply-To: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
References: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
Message-ID: <582DFB6C-D08A-4B80-A281-C5BA3ED6CA08@me.com>

It appears that 
install.libraries(?hms?)
is unsuccessful, but that
install.packages(?hms?)
is successful.

install.packages("lubridate")
downloaded 1.5 MB
install.packages("hms")
downloaded 95 KB
install.packages("data.table")
downloaded 2.2 MB
Greg
> On Mar 17, 2021, at 1:07 PM, Gregory Coats via R-help <r-help at r-project.org> wrote:
> 
> On my MacBook, I do not have, and do not know how to install, library(hms).
> Greg Coats
> 
>> library(hms)
> Error in library(hms) : there is no package called ?hms?
>> Install.libraries(?hms?)
> Error: unexpected input in "Install.libraries(?"
>> 
> 	[[alternative HTML version deleted]]
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Wed Mar 17 19:04:08 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 17 Mar 2021 14:04:08 -0400
Subject: [R] library(hms)
In-Reply-To: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
References: <BDAFBB5C-811A-4D8E-BA1E-2AD2EC8FF22C@me.com>
Message-ID: <a284e9d0-b9a2-e7e5-b02b-df12b7b2bc38@mcmaster.ca>

Dear Greg,

As I explained to you in a private email, and as others have told you, 
there is no Install.libraries() command, nor is there an 
install.libraries(0 command, but there is an install.packages() command.

So install.packages("hms") should work, on a Mac or on any other 
internet-connected computer on which R runs -- as you've also been told 
by others, this is not a Mac-specific issue. Note that the argument to 
install.packages must be quoted. See ?install.packages for details.

I'll also repeat the advice that I gave you privately to learn something 
about R before you try to use it, possibly starting with the "An 
Introduction to R" manual that ships with the standard R distribution.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-03-17 1:07 p.m., Gregory Coats wrote:
> On my MacBook, I do not have, and do not know how to install, library(hms).
> Greg Coats
> 
>> library(hms)
> Error in library(hms) : there is no package called ?hms?
>> Install.libraries(?hms?)
> Error: unexpected input in "Install.libraries(?"
>>


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Mar 17 20:58:21 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 17 Mar 2021 15:58:21 -0400
Subject: [R] 
 modelling 4-parameter curve in R does not match data - how to
 proceed?
In-Reply-To: <CAMk+s2Rdxb2TFtPcSFVUk_D6EXFGQ+7JXOmZgriQ0imX7amg1g@mail.gmail.com>
References: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>
 <1936fa40-601f-4756-caa7-5bed63ca6a62@gmail.com>
 <CAMk+s2Q5z3DrH5wkYDXqGzDb3eLfWyw17kAATn23s9QvNJVYAA@mail.gmail.com>
 <b0d7e65c-4140-4150-e9a5-d6e9bfbd2ef7@gmail.com>
 <CAMk+s2Rdxb2TFtPcSFVUk_D6EXFGQ+7JXOmZgriQ0imX7amg1g@mail.gmail.com>
Message-ID: <7de4372d-0804-2e31-20d3-65a203e16225@gmail.com>

On 17/03/2021 12:37 p.m., Luigi Marongiu wrote:
> sorry, I don't get it...

Modify your rutledge function to print x, and you'll see the values of 
high printed.  x should be 1:45.

Duncan Murdoch

> 
> On Wed, Mar 17, 2021 at 2:35 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 17/03/2021 6:59 a.m., Luigi Marongiu wrote:
>>> yes, but in `rutledge` I model y as `y = (M / ( 1 + exp(-(x-m)/s)) ) +
>>> B`, with x being 1:45. Isn't that the equivalent of what I fed Desmos
>>> with? Tx
>>
>> No, it's not.
>>
>> Duncan Murdoch
>>
>>>
>>> On Wed, Mar 17, 2021 at 11:31 AM Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> On 17/03/2021 5:41 a.m., Luigi Marongiu wrote:
>>>>> Hello,
>>>>> I have a dataset from a polymerase chain reaction. I am using the
>>>>> equation given by Rutledge
>>>>> (https://pubmed.ncbi.nlm.nih.gov/15601990/) but the profile I get in R
>>>>> does not match the data. I ran the same thing in Desmos and instead
>>>>> the profile is correct (attached).
>>>>> Why do I not get the same matching model as in Desmos? I believe the
>>>>> formula in R is the same as the one in Desmos, and I am using the same
>>>>> parameters.
>>>>> Is there a procedure to debug models?
>>>>> Thanks
>>>>>
>>>>> Here is the code:
>>>>> ```
>>>>> high <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
>>>>>           -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
>>>>>           75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
>>>>>           6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
>>>>>           10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
>>>>>           11781.77, 11863.35, 11927.44, 11980.81, 12021.88)
>>>>> plot(1:45, high, type = "l")
>>>>> rutledge <- function(p, x) {
>>>>>      m = p$half_fluorescence
>>>>>      s = p$slope
>>>>>      M = p$max_fluorescence
>>>>>      B = p$back_fluorescence
>>>>>      y = (M / ( 1 + exp(-(x-m)/s)) ) + B
>>>>>      return(y)
>>>>> }
>>>>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>>>>>                            max_fluorescence = 11839.8, back_fluorescence
>>>>> = -138.864) , high)
>>>>>
>>>>> points(1:45, desmos, type="l", col="blue")
>>>>
>>>>
>>>> In your calculation of desmos, you are using the Y variable for x in the
>>>> formula.  Calculate it this way instead:
>>>>
>>>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>>>>                              max_fluorescence = 11839.8, back_fluorescence
>>>>     = -138.864) , 1:45)
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>>
>>
> 
>


From jo@e@b@rrer@ @end|ng |rom |@g|ob@|@org  Thu Mar 11 22:14:12 2021
From: jo@e@b@rrer@ @end|ng |rom |@g|ob@|@org (Jose Barrera)
Date: Thu, 11 Mar 2021 22:14:12 +0100
Subject: [R] [R-pkgs] {miclust} Multiple imputation & cluster analysis
Message-ID: <CACr7k5K+8dVGX=uGRFtr6PrCKoL5pJBQLj8c-FjQqNN0aJpbpQ@mail.gmail.com>

Dear all,

Want to perform cluster analysis but you have missing data?

Following researchers' suggestion, our R package miclust is now on CRAN:
https://CRAN.R-project.org/package=miclust

miclust implements a framework to integrate multiple imputed data sets due
to missing data in cluster analysis. Methods are described in the original
work: https://academic.oup.com/aje/article/177/7/718/91109

I hope you find it helpful.

On behalf of the authors,

Jose Barrera
Statistician, Associate Lecturer

*IS**Global*
Barcelona Institute for Global Health - Campus MAR
Barcelona Biomedical Research Park (PRBB) (Room Hypatia)

Doctor Aiguader, 88
08003 Barcelona, Spain
Tel. +34 93 2147383
jose.barrera at isglobal.org
<https://www.linkedin.com/in/josebarrera>
Personal website: sites.google.com/view/josebarrera
www.isglobal.org

This message is intended exclusively for its addressee and may contain
information that is CONFIDENTIAL and protected by professional privilege.
If you are not the intended recipient you are hereby notified that any
dissemination, copy or disclosure of this communication is strictly
prohibited by law. If this message has been received in error, please
immediately notify us via e-mail and delete it.

DATA PROTECTION. We inform you that your personal data, including your
e-mail address and data included in your email correspondence, are included
in the ISGlobal Foundation filing system. Your personal data will be used
for the purpose of contacting you and sending information on the activities
of the above foundations. You can exercise your rights to  access to
personal data, rectification, erasure, restriction of processing, data
portability and object by contacting the following address: *lopd at isglobal.org
<lopd at isglobal.org>*. ISGlobal Privacy Policy at *www.isglobal.org
<http://www.isglobal.org/>*.


-----------------------------------------------------------------------------------------------------------------------------

CONFIDENCIALIDAD. Este mensaje y sus anexos se dirigen exclusivamente a su
destinatario y puede contener informaci?n confidencial, por lo que la
utilizaci?n, divulgaci?n y/o copia sin autorizaci?n est? prohibida por la
legislaci?n vigente. Si ha recibido este mensaje por error, le rogamos lo
comunique inmediatamente por esta misma v?a y proceda a su destrucci?n.

PROTECCI?N DE DATOS. Sus datos de car?cter personal utilizados en este
env?o, incluida su direcci?n de e-mail, forman parte de ficheros de
titularidad de la Fundaci?n ISGlobal  para cualquier finalidades de
contacto, relaci?n institucional y/o env?o de informaci?n sobre sus
actividades. Los datos que usted nos pueda facilitar contestando este
correo quedar?n incorporados en los correspondientes ficheros, autorizando
el uso de su direcci?n de e-mail para las finalidades citadas. Puede
ejercer los derechos de acceso, rectificaci?n, supresi?n, limitaci?n del
tratamiento, portabilidad y oposici?n dirigi?ndose a *lopd at isglobal.org
<lopd at isglobal.org>* . Pol?tica de privacidad en *www.isglobal.org
<http://www.isglobal.org/>*.

-- 


This message is intended exclusively for its addressee and may contain
information that is CONFIDENTIAL and protected by professional privilege. 
If
you are not the intended recipient you are hereby notified that any
dissemination, copy or disclosure of this communication is strictly 
prohibited
by law. If this message has been received in error, please 
immediately notify
us via e-mail and delete it.



DATA PROTECTION. We 
inform you that your personal data, including your
e-mail address and data 
included in your email correspondence, are included in
the ISGlobal 
Foundation files. Your personal data will be used for the purpose
of 
contacting you and sending information on the activities of the above
foundations. You can exercise your rights of access, rectification,
cancellation and opposition by contacting the following address: 
lopd at isglobal.org <mailto:lopd at isglobal.org>. ISGlobal
Privacy Policy at 
www.isglobal.org <http://www.isglobal.org/>.



-----------------------------------------------------------------------------------------------------------------------------

CONFIDENCIALIDAD. Este mensaje y sus anexos se dirigen exclusivamente a
su 
destinatario y puede contener informaci?n confidencial, por lo que la
utilizaci?n,
divulgaci?n y/o copia sin autorizaci?n est? prohibida por la
legislaci?n
vigente. Si ha recibido este mensaje por error, le rogamos lo 
comunique
inmediatamente por esta misma v?a y proceda a su destrucci?n.









PROTECCI?N DE DATOS. Sus datos de car?cter personal utilizados en este
env?o, incluida su direcci?n de e-mail, forman parte de ficheros de 
titularidad
de la Fundaci?n ISGlobal? para cualquier
finalidades de 
contacto, relaci?n institucional y/o env?o de informaci?n sobre
sus 
actividades. Los datos que usted nos pueda facilitar contestando este
correo quedar?n incorporados en los correspondientes ficheros, autorizando 
el
uso de su direcci?n de e-mail para las finalidades citadas. Puede 
ejercer los
derechos de acceso, rectificaci?n, cancelaci?n y oposici?n 
dirigi?ndose a lopd at isglobal.org <mailto:lopd at isglobal.org>* *. Pol?tica de 
privacidad
en www.isglobal.org <http://www.isglobal.org/>.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From krzy@zto|@podgor@k| @end|ng |rom @t@t@|u@@e  Mon Mar 15 23:13:15 2021
From: krzy@zto|@podgor@k| @end|ng |rom @t@t@|u@@e (=?windows-1258?Q?Krzysztof_Podg=F3rski?=)
Date: Mon, 15 Mar 2021 22:13:15 +0000
Subject: [R] [R-pkgs] Splinets
Message-ID: <4ef974d1a266475389de09490bcbf20b@stat.lu.se>

Splinets -- a package with an efficient B-spline orthogonalization suitable for sparse functional data analysis.

See also: 

Liu, X., Nassar, H., Podgo?rski, K. (2019) "Splinets ? efficient orthonormalization of the B-splines." <arXiv:1910.07341>.
Podgo?rski, K. (2021) "Splinets ? splines through the Taylor expansion, their support sets and orthogonal bases." <arXiv:2102.00733>.
 

#############################
Krzysztof Podgorski
Professor
Department of Statistics 
Lund University
#############################
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From j|uchm@n @end|ng |rom gm@||@com  Mon Mar 15 15:38:32 2021
From: j|uchm@n @end|ng |rom gm@||@com (Joseph Luchman)
Date: Mon, 15 Mar 2021 09:38:32 -0500
Subject: [R] [R-pkgs] domir: Tools to Support Relative Importance Analysis
Message-ID: <80M0QQ.U03F1AGIZT4B@gmail.com>

Hello All,

  I am pleased to announce that {domir} is now available on CRAN.

  {domir} aims to provide broadly applicable tools for the relative 
importance analysis of facets of statistical models and machine 
learning algorithms.  The focus for this initial release is on 
Dominance Analysis/Shapley Value Decomposition as a methodology - which 
is to be expanded in future versions.

  I hope the community finds the tool(s) in this package of value and I 
look forward to further developing the package in collaboration with 
the community.

  Note: {domir} version 0.0.0 has a known bug that affects 
functionality in R versions < 4.  Working on a patch to revise.

  Cordially,

- Joseph

CRAN: <https://cran.r-project.org/package=domir>
GibHub: <https://github.com/jluchman/domir>


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From h@t|cegurd||1985 @end|ng |rom gm@||@com  Wed Mar 17 18:31:05 2021
From: h@t|cegurd||1985 @end|ng |rom gm@||@com (=?UTF-8?Q?hatice_g=C3=BCrdil?=)
Date: Wed, 17 Mar 2021 20:31:05 +0300
Subject: [R] help
In-Reply-To: <CAHqSRuTip=JCukJFKEFd9Gg3rJEnwRm-p5bj9awmeoGPx=dDwA@mail.gmail.com>
References: <CAJmLsKLao4hTxRn92wRKEEEqovgde2vfFe6U4+ZqsoPd_vJcNA@mail.gmail.com>
 <CAHqSRuTip=JCukJFKEFd9Gg3rJEnwRm-p5bj9awmeoGPx=dDwA@mail.gmail.com>
Message-ID: <CAJmLsKLUtE_r3x4Yvy1ZroDf6W7O8J_J1We1Om16o6f9bEj-UA@mail.gmail.com>

Thank you so much
I thought that ncol is for dimension .
ncol= 2, 2x2 matris for 2 dimension
ncol= 3, 3x3 matris for 3 dimention

I have to work a little more considering what you said.

Cheers,

Hatice G?rdil.

Bill Dunlap <williamwdunlap at gmail.com>, 16 Mar 2021 Sal, 21:09 tarihinde
?unu yazd?:

> The length of the mean vector must match the number of rows and
> columns of the sigma matrix.  Once you give 3 entries in the mean
> vector you will run into the problem that the sigma you are using is
> not positive (semi-)definite - a variance must be the product of a
> matrix and its transpose.
>
> -Bill
>
> On Tue, Mar 16, 2021 at 10:55 AM hatice g?rdil
> <haticegurdil1985 at gmail.com> wrote:
> >
> > Code a is working. But code b is given error like given below. How can I
> > write code b?
> >
> > > a<-rmvnorm(750, mean=c(0, 0),
> > +                        sigma=matrix(c(1, .3, .3, 1), ncol=2))
> >
> > > head(a)
> >             [,1]        [,2]
> > [1,] -0.97622921 -0.87129405
> > [2,]  0.54763494  0.16080131
> > [3,] -1.16627647  0.31225125
> > [4,]  1.72541168  2.06513939
> > [5,]  0.05372489 -0.07525197
> > [6,] -0.85062230 -1.02188473
> >
> > > b<-rmvnorm(round(500,0), mean=c(0,-1),
> > +                        sigma=matrix(c(.3, 1,1,1,.3, 1, 1,1, .3),
> ncol=3))
> >
> > Error in rmvnorm(round(500, 0), mean = c(0, -1), sigma = matrix(c(0.3,  :
> >   mean and sigma have non-conforming size
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Mar 18 07:44:43 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 18 Mar 2021 07:44:43 +0100
Subject: [R] 
 modelling 4-parameter curve in R does not match data - how to
 proceed?
In-Reply-To: <7de4372d-0804-2e31-20d3-65a203e16225@gmail.com>
References: <CAMk+s2QuG9M_YLjRPJmD60uAuinno5LWK64Gs41zCS04gLpojw@mail.gmail.com>
 <1936fa40-601f-4756-caa7-5bed63ca6a62@gmail.com>
 <CAMk+s2Q5z3DrH5wkYDXqGzDb3eLfWyw17kAATn23s9QvNJVYAA@mail.gmail.com>
 <b0d7e65c-4140-4150-e9a5-d6e9bfbd2ef7@gmail.com>
 <CAMk+s2Rdxb2TFtPcSFVUk_D6EXFGQ+7JXOmZgriQ0imX7amg1g@mail.gmail.com>
 <7de4372d-0804-2e31-20d3-65a203e16225@gmail.com>
Message-ID: <CAMk+s2ToiYRX4dn2OxWMSKuBNqSDuXw9h5kTdGDiKm29BtV_9g@mail.gmail.com>

Oh, I got it! I was sending the fluorescence instead of the cycles x.
Thank you

```
desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
                        max_fluorescence = 11839.8, back_fluorescence
= -138.864) , 1:45)
```

On Wed, Mar 17, 2021 at 8:58 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 17/03/2021 12:37 p.m., Luigi Marongiu wrote:
> > sorry, I don't get it...
>
> Modify your rutledge function to print x, and you'll see the values of
> high printed.  x should be 1:45.
>
> Duncan Murdoch
>
> >
> > On Wed, Mar 17, 2021 at 2:35 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >>
> >> On 17/03/2021 6:59 a.m., Luigi Marongiu wrote:
> >>> yes, but in `rutledge` I model y as `y = (M / ( 1 + exp(-(x-m)/s)) ) +
> >>> B`, with x being 1:45. Isn't that the equivalent of what I fed Desmos
> >>> with? Tx
> >>
> >> No, it's not.
> >>
> >> Duncan Murdoch
> >>
> >>>
> >>> On Wed, Mar 17, 2021 at 11:31 AM Duncan Murdoch
> >>> <murdoch.duncan at gmail.com> wrote:
> >>>>
> >>>> On 17/03/2021 5:41 a.m., Luigi Marongiu wrote:
> >>>>> Hello,
> >>>>> I have a dataset from a polymerase chain reaction. I am using the
> >>>>> equation given by Rutledge
> >>>>> (https://pubmed.ncbi.nlm.nih.gov/15601990/) but the profile I get in R
> >>>>> does not match the data. I ran the same thing in Desmos and instead
> >>>>> the profile is correct (attached).
> >>>>> Why do I not get the same matching model as in Desmos? I believe the
> >>>>> formula in R is the same as the one in Desmos, and I am using the same
> >>>>> parameters.
> >>>>> Is there a procedure to debug models?
> >>>>> Thanks
> >>>>>
> >>>>> Here is the code:
> >>>>> ```
> >>>>> high <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> >>>>>           -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> >>>>>           75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> >>>>>           6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> >>>>>           10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> >>>>>           11781.77, 11863.35, 11927.44, 11980.81, 12021.88)
> >>>>> plot(1:45, high, type = "l")
> >>>>> rutledge <- function(p, x) {
> >>>>>      m = p$half_fluorescence
> >>>>>      s = p$slope
> >>>>>      M = p$max_fluorescence
> >>>>>      B = p$back_fluorescence
> >>>>>      y = (M / ( 1 + exp(-(x-m)/s)) ) + B
> >>>>>      return(y)
> >>>>> }
> >>>>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
> >>>>>                            max_fluorescence = 11839.8, back_fluorescence
> >>>>> = -138.864) , high)
> >>>>>
> >>>>> points(1:45, desmos, type="l", col="blue")
> >>>>
> >>>>
> >>>> In your calculation of desmos, you are using the Y variable for x in the
> >>>> formula.  Calculate it this way instead:
> >>>>
> >>>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
> >>>>                              max_fluorescence = 11839.8, back_fluorescence
> >>>>     = -138.864) , 1:45)
> >>>>
> >>>> Duncan Murdoch
> >>>>
> >>>
> >>>
> >>
> >
> >
>


-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Mar 18 07:51:02 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 18 Mar 2021 07:51:02 +0100
Subject: [R] Failure in predicting parameters
In-Reply-To: <CAMk+s2S270X=QVnrFsVgsX7Wmr9vKCXnsG9Fn0tg8nqz=bk4xQ@mail.gmail.com>
References: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
 <CAHqSRuR3EvPudJWZignHHWCLJJVpiOBh1+QguC+V2z87XOQ2hg@mail.gmail.com>
 <CAMk+s2SEKx-HDreBPr0b6QMtvEHquV=FBotaeHnti57goEA0Fw@mail.gmail.com>
 <CAMk+s2S270X=QVnrFsVgsX7Wmr9vKCXnsG9Fn0tg8nqz=bk4xQ@mail.gmail.com>
Message-ID: <CAMk+s2R+21LBjyesQ5ZchGXB=AeCOi4fN_dmRtU+FVj1nsvXOg@mail.gmail.com>

It worked. I re-written the equation as:
```
rutledge_param <- function(p, x, y) ( (p$M / ( 1 + exp(-(x-p$m)/p$s))
) + p$B ) - y
```
and used Desmos to estimate the slope, so:
```
estim <- nls.lm(par = list(m = halfCycle, s = 2.77, M = MaxFluo, B = high[1]),
            fn = rutledge_param, x = 1:45, y = high)
summary(estim)
R <- rutledge(list(half_fluorescence = 27.1102, slope = 2.7680,
                   max_fluorescence = 11839.7745, back_fluorescence =
-138.8615) , 1:45)
points(1:45, R, type="l", col="red")
```

Thanks

On Tue, Mar 16, 2021 at 8:29 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Just an update:
> I tried with desmos and the fitting looks good. Desmos calculated the
> parameters as:
> Fmax = 11839.8
> Chalf = 27.1102 (with matches with my estimate of 27 cycles)
> k = 2.76798
> Fb = -138.864
> I forced R to accept the right parameters using a single named list
> and re-written the formula (it was a bit unclear in the paper):
> ```
> rutledge <- function(p, x) {
>   m = p$half_fluorescence
>   s = p$slope
>   M = p$max_fluorescence
>   B = p$back_fluorescence
>   y = (M / (1+exp( -((x-m)/s) )) ) + B
>   return(y)
> }
> ```
> but when I apply it I get a funny graph:
> ```
> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>                         max_fluorescence = 11839.8, back_fluorescence
> = -138.864) , high)
> ```
>
> On Mon, Mar 15, 2021 at 7:39 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > the negative data comes from the machine. Probably I should use raw
> > data directly, although in the paper this requirement is not reported.
> > The p$x was a typo. Now I corrected it and I got this error:
> > ```
> >
> > > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(x-p$m)/p$s))) + p$B) - y
> > > estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> > +             fn = rutledge_param, x = 1:45, y = high)
> > Error in dimnames(x) <- dn :
> >   length of 'dimnames' [2] not equal to array extent
> > ```
> > Probably because 'slopes' is a vector instead of a scalar. Since the
> > slope is changing, I don't think is right to use a scalar, but I tried
> > and I got:
> > ```
> > > estim <- nls.lm(par = list(m = halfFluo, s = 1, M = MaxFluo, B = high[1]),
> > +             fn = rutledge_param, x = 1:45, y = high)
> > > estim
> > Nonlinear regression via the Levenberg-Marquardt algorithm
> > parameter estimates: 6010.94, 1, 12021.88, 4700.49288888889
> > residual sum-of-squares: 1.14e+09
> > reason terminated: Relative error in the sum of squares is at most `ftol'.
> > ```
> > The values reported are the same I used at the beginning apart from
> > the last (the background parameter) which is 4700 instead of zero. If
> > I plug it, I get an L shaped plot that is worse than that at the
> > beginning:
> > ```
> > after = init = rutledge(halfFluo, 1, MaxFluo, 4700.49288888889, high)
> > points(1:45, after, type="l", col="blue")
> > ```
> > What did I get wrong here?
> > Thanks
> >
> > On Sun, Mar 14, 2021 at 8:05 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
> > >
> > > > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> > >
> > > Did you mean that p$x to be just x?  As is, this returns numeric(0)
> > > for the p that nls.lm gives it because p$x is NULL and NULL-aNumber is
> > > numeric().
> > >
> > > -Bill
> > >
> > > On Sun, Mar 14, 2021 at 9:46 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I would like to use the Rutledge equation
> > > > (https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
> > > > equation is:
> > > > Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
> > > > I defined the equation and another that subtracts the values from the
> > > > expectations. I used minpack.lm to get the parameters, but I got an
> > > > error:
> > > > ```
> > > >
> > > > > library("minpack.lm")
> > > > > h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> > > > +        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> > > > +        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> > > > +        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> > > > +        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> > > > +        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35, 12100.63,
> > > > +        12133.57, 12148.89, 12137.09)
> > > > > high <- h[1:45]
> > > > > MaxFluo <- max(high)
> > > > > halfFluo <- MaxFluo/2
> > > > > halfCycle = 27
> > > > > find_slope <- function(X, Y) {
> > > > +   Slope <- c(0)
> > > > +   for (i in 2:length(X)) {
> > > > +     delta_x <- X[i] - X[i-1]
> > > > +     delta_y <- Y[i] - Y[i-1]
> > > > +     Slope[i] <- delta_y/delta_x
> > > > +   }
> > > > +   return(Slope)
> > > > + }
> > > > > slopes <- find_slope(1:45, high)
> > > > >
> > > > > rutledge <- function(m, s, M, B, x) {
> > > > +   divisor = 1 + exp(-1* ((x-m)/s) )
> > > > +   y = (M/divisor) + B
> > > > +   return(y)
> > > > + }
> > > > > rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> > > > >
> > > > >
> > > > > init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
> > > > > points(1:45, init, type="l", col="red")
> > > > > estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> > > > +                 fn = rutledge_param, x = 1:45, y = high)
> > > > Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
> > > > high[1]),  :
> > > >   evaluation of fn function returns non-sensible value!
> > > > ```
> > > >
> > > > Where could the error be?
> > > >
> > > >
> > > > --
> > > > Best regards,
> > > > Luigi
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Mar 18 21:46:40 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 18 Mar 2021 20:46:40 +0000
Subject: [R] Failure in predicting parameters
In-Reply-To: <CAMk+s2R+21LBjyesQ5ZchGXB=AeCOi4fN_dmRtU+FVj1nsvXOg@mail.gmail.com>
References: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
 <CAHqSRuR3EvPudJWZignHHWCLJJVpiOBh1+QguC+V2z87XOQ2hg@mail.gmail.com>
 <CAMk+s2SEKx-HDreBPr0b6QMtvEHquV=FBotaeHnti57goEA0Fw@mail.gmail.com>
 <CAMk+s2S270X=QVnrFsVgsX7Wmr9vKCXnsG9Fn0tg8nqz=bk4xQ@mail.gmail.com>
 <CAMk+s2R+21LBjyesQ5ZchGXB=AeCOi4fN_dmRtU+FVj1nsvXOg@mail.gmail.com>
Message-ID: <e0a79c8e-e69c-e6e4-fd93-a6d334527289@sapo.pt>

Hello,

Maybe a bit late but there is a contributed package [1] for quantitative 
PCR fitting non-linear models with the Levenberg-Marquardt algorithm.

estim and vector R below are your model and your fitted values vector. 
The RMSE of this fit is smaller than your model's.


Isn't this simpler?


library(qpcR)

df1 <- data.frame(Cycles = seq_along(high), high)

fit <- pcrfit(
   data = df1,
   cyc = 1,
   fluo = 2
)
summary(fit)

coef(estim)
coef(fit)


sqrt(sum(resid(estim)^2))
#[1] 1724.768
sqrt(sum(resid(fit)^2))
#[1] 1178.318


highpred <- predict(fit, newdata = df1)

plot(1:45, high, type = "l", col = "red")
points(1:45, R, col = "blue")
points(1:45, highpred$Prediction, col = "cyan", pch = 3)


[1] https://CRAN.R-project.org/package=qpcR

Hope this helps,

Rui Barradas

?s 06:51 de 18/03/21, Luigi Marongiu escreveu:
> It worked. I re-written the equation as:
> ```
> rutledge_param <- function(p, x, y) ( (p$M / ( 1 + exp(-(x-p$m)/p$s))
> ) + p$B ) - y
> ```
> and used Desmos to estimate the slope, so:
> ```
> estim <- nls.lm(par = list(m = halfCycle, s = 2.77, M = MaxFluo, B = high[1]),
>              fn = rutledge_param, x = 1:45, y = high)
> summary(estim)
> R <- rutledge(list(half_fluorescence = 27.1102, slope = 2.7680,
>                     max_fluorescence = 11839.7745, back_fluorescence =
> -138.8615) , 1:45)
> points(1:45, R, type="l", col="red")
> ```
> 
> Thanks
> 
> On Tue, Mar 16, 2021 at 8:29 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Just an update:
>> I tried with desmos and the fitting looks good. Desmos calculated the
>> parameters as:
>> Fmax = 11839.8
>> Chalf = 27.1102 (with matches with my estimate of 27 cycles)
>> k = 2.76798
>> Fb = -138.864
>> I forced R to accept the right parameters using a single named list
>> and re-written the formula (it was a bit unclear in the paper):
>> ```
>> rutledge <- function(p, x) {
>>    m = p$half_fluorescence
>>    s = p$slope
>>    M = p$max_fluorescence
>>    B = p$back_fluorescence
>>    y = (M / (1+exp( -((x-m)/s) )) ) + B
>>    return(y)
>> }
>> ```
>> but when I apply it I get a funny graph:
>> ```
>> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
>>                          max_fluorescence = 11839.8, back_fluorescence
>> = -138.864) , high)
>> ```
>>
>> On Mon, Mar 15, 2021 at 7:39 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>>
>>> Hello,
>>> the negative data comes from the machine. Probably I should use raw
>>> data directly, although in the paper this requirement is not reported.
>>> The p$x was a typo. Now I corrected it and I got this error:
>>> ```
>>>
>>>> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(x-p$m)/p$s))) + p$B) - y
>>>> estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
>>> +             fn = rutledge_param, x = 1:45, y = high)
>>> Error in dimnames(x) <- dn :
>>>    length of 'dimnames' [2] not equal to array extent
>>> ```
>>> Probably because 'slopes' is a vector instead of a scalar. Since the
>>> slope is changing, I don't think is right to use a scalar, but I tried
>>> and I got:
>>> ```
>>>> estim <- nls.lm(par = list(m = halfFluo, s = 1, M = MaxFluo, B = high[1]),
>>> +             fn = rutledge_param, x = 1:45, y = high)
>>>> estim
>>> Nonlinear regression via the Levenberg-Marquardt algorithm
>>> parameter estimates: 6010.94, 1, 12021.88, 4700.49288888889
>>> residual sum-of-squares: 1.14e+09
>>> reason terminated: Relative error in the sum of squares is at most `ftol'.
>>> ```
>>> The values reported are the same I used at the beginning apart from
>>> the last (the background parameter) which is 4700 instead of zero. If
>>> I plug it, I get an L shaped plot that is worse than that at the
>>> beginning:
>>> ```
>>> after = init = rutledge(halfFluo, 1, MaxFluo, 4700.49288888889, high)
>>> points(1:45, after, type="l", col="blue")
>>> ```
>>> What did I get wrong here?
>>> Thanks
>>>
>>> On Sun, Mar 14, 2021 at 8:05 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>>>>
>>>>> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
>>>>
>>>> Did you mean that p$x to be just x?  As is, this returns numeric(0)
>>>> for the p that nls.lm gives it because p$x is NULL and NULL-aNumber is
>>>> numeric().
>>>>
>>>> -Bill
>>>>
>>>> On Sun, Mar 14, 2021 at 9:46 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>>>>
>>>>> Hello,
>>>>> I would like to use the Rutledge equation
>>>>> (https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
>>>>> equation is:
>>>>> Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
>>>>> I defined the equation and another that subtracts the values from the
>>>>> expectations. I used minpack.lm to get the parameters, but I got an
>>>>> error:
>>>>> ```
>>>>>
>>>>>> library("minpack.lm")
>>>>>> h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
>>>>> +        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
>>>>> +        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
>>>>> +        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
>>>>> +        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
>>>>> +        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35, 12100.63,
>>>>> +        12133.57, 12148.89, 12137.09)
>>>>>> high <- h[1:45]
>>>>>> MaxFluo <- max(high)
>>>>>> halfFluo <- MaxFluo/2
>>>>>> halfCycle = 27
>>>>>> find_slope <- function(X, Y) {
>>>>> +   Slope <- c(0)
>>>>> +   for (i in 2:length(X)) {
>>>>> +     delta_x <- X[i] - X[i-1]
>>>>> +     delta_y <- Y[i] - Y[i-1]
>>>>> +     Slope[i] <- delta_y/delta_x
>>>>> +   }
>>>>> +   return(Slope)
>>>>> + }
>>>>>> slopes <- find_slope(1:45, high)
>>>>>>
>>>>>> rutledge <- function(m, s, M, B, x) {
>>>>> +   divisor = 1 + exp(-1* ((x-m)/s) )
>>>>> +   y = (M/divisor) + B
>>>>> +   return(y)
>>>>> + }
>>>>>> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
>>>>>>
>>>>>>
>>>>>> init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
>>>>>> points(1:45, init, type="l", col="red")
>>>>>> estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
>>>>> +                 fn = rutledge_param, x = 1:45, y = high)
>>>>> Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
>>>>> high[1]),  :
>>>>>    evaluation of fn function returns non-sensible value!
>>>>> ```
>>>>>
>>>>> Where could the error be?
>>>>>
>>>>>
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> Best regards,
>>> Luigi
>>
>>
>>
>> --
>> Best regards,
>> Luigi
> 
> 
>


From nev||@@mo@ @end|ng |rom gm@||@com  Thu Mar 18 23:35:54 2021
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Fri, 19 Mar 2021 09:35:54 +1100
Subject: [R] 
 Plot_ly bar plots - bars span sevral x values when there are
 missing values.
In-Reply-To: <YEfFDTrhBW3Lr+99@posteo.no>
References: <CAN9eD7nitpaX07SoaE2yN6Hicr6BzV6owViqqBQRjQVeZUTg7Q@mail.gmail.com>
 <YEfFDTrhBW3Lr+99@posteo.no>
Message-ID: <CAN9eD7=dYLsRZXuXykd1BP+X1QUNpprvMtxhOyS56STM4mYUMg@mail.gmail.com>

Hi Rasmus,

thanks for that suggestion. It does indeed fix the column widths in this
example.  the reason it does this is becuase it means that the additonal 0
values added result in values for two adjacent columns.

so if adjacent columns are present the "correct" column width is maintained

df[c(3,4),]%>%plot_ly(
  x =  ~ x,
  y =  ~ y,
  type = "bar")%>%
  layout(xaxis = list(range = c(0,20)),
         title = "adjcant x values get correct column width")
however if there are not tow adjacent columns  then the width increases

df[c(3,5),]%>%plot_ly(
  x =  ~ x,
  y =  ~ y,
  type = "bar")%>%
  layout(xaxis = list(range = c(0,20)),
         title = "gap between x values column width changes")

given this I'm still not sure why the single value example produces a
correct column width.

for now the generic work around is to pad with y=0 as you suggested.




On Wed, 10 Mar 2021 at 05:58, Rasmus Liland <jral at posteo.no> wrote:

> Dear Nevil,
>
> Although I am a bit unfamiliar with
> plotly, it seems it is possible to plot
> two bars side by side at least:
>
>         h <- df[3:4,]
>         p <- plotly::plot_ly(
>           data = h,
>           x =  ~ x,
>           y =  ~ y,
>           type = "bar")
>         p <- plotly::layout(p=p,
>           xaxis = list(range = c(0,20)),
>           title = "example 4 two bars side by side")
>         plotly::orca(p=p, file="amos4.png")
>
> Thus, if you want to only plot x=3 and
> x=11 you need to set y=0 when x=4:10:
>
>         h <- df[c(3, 11),]
>         h <- rbind(h, cbind(x=4:10, y=0))
>         p <- plotly::plot_ly(
>           data = h,
>           x =  ~ x,
>           y =  ~ y,
>           type = "bar")
>         p <- plotly::layout(p=p,
>           xaxis = list(range = c(0,20)),
>           title = "example 2 corrected")
>         plotly::orca(p=p, file="amos2.png")
>
> I think this has to do with the xaxis
> option in plotly::layout there, and not
> with the bar width.
>
> Best,
> Rasmus
>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Mar 19 03:53:34 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 18 Mar 2021 21:53:34 -0500
Subject: [R] How to plot dates
References: <001201d71c6b$0e3a0200$2aae0600$.ref@sbcglobal.net>
Message-ID: <001201d71c6b$0e3a0200$2aae0600$@sbcglobal.net>

Greg

 

Based upon you last email I suspect this is what you were looking for.

 

# create the data.frame

datetime <- c("2021-03-12 05:16:46","2021-03-12 09:17:02","2021-03-12
13:31:43","2021-03-12 22:00:32",

              "2021-03-13 09:21:43","2021-03-13 13:51:12","2021-03-13
18:03:13","2021-03-13 22:20:28",

              "2021-03-14 08:59:03","2021-03-14 13:15:56","2021-03-14
17:25:23","2021-03-14 21:36:26")

group_id <- rep(1:4, 3)

myDat <- data.frame(datetime, group_id)

myDat

 

# library

library(ggplot2)   # package used to plot results

library(lubridate) # package used to extract the "dates"

 

# convert data to date time object

myDat$datetime <- as.POSIXct(myDat$datetime, tz = "", format = "%Y-%m-%d
%H:%M:%S")

 

# extract time

myDat$time <- strftime(myDat$datetime, format = "%H:%M:%S")

 

# convert time to seconds

myDat$seconds <- seconds(hms(myDat$time))

 

# extract date

myDat$dates <- as.Date(ymd_hms(myDat$datetime))

 

# plot results by datetime  

ggplot(data = myDat, aes(x = dates, y = seconds, group = group_id, colour =
factor(group_id)))+

  geom_line() +

  geom_point() +

  # Rotate and adjust x axis text

  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +

  labs(title = "Event Time (seconds) verse Date", x = "Date", y = "Time
(seconds)") +

  scale_colour_discrete(name="Group ID",

                        breaks=c("1", "2", "3", "4"),

                        labels=c("Gp 1", "Gp 2", "Gp 3", "Gp 4"))


	[[alternative HTML version deleted]]


From t@n@@@ @end|ng |rom gm@||@com  Fri Mar 19 05:12:47 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 18 Mar 2021 21:12:47 -0700
Subject: [R] about a p-value < 2.2e-16
Message-ID: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>

 <https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16>
Dear all,

i would appreciate having your advice on the following please :

in R, the wilcox.test() provides "a p-value < 2.2e-16", when we compare
sets of 1000 genes expression (in the genomics field).

however, the journal asks us to provide the exact p value ...

would it be legitimate to write : "p-value = 0" ? thanks a lot,

-- bogdan

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Fri Mar 19 06:05:06 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Fri, 19 Mar 2021 00:05:06 -0500
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
Message-ID: <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>

 ????? I would push back on that from two perspectives:


 ??? ??????? 1.? I would study exactly what the journal said very 
carefully.? If they mandated "wilcox.test", that function has an 
argument called "exact".? If that's what they are asking, then using 
that argument gives the exact p-value, e.g.:


 > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)

 ??????? Wilcoxon rank sum exact test

data:? rnorm(100) and rnorm(100, 2)
W = 691, p-value < 2.2e-16


 ??? ??????? 2.? If that's NOT what they are asking, then I'm not 
convinced what they are asking makes sense:? There is is no such thing 
as an "exact p value" except to the extent that certain assumptions 
hold, and all models are wrong (but some are useful), as George Box 
famously said years ago.[1]? Truth only exists in mathematics, and 
that's because it's a fiction to start with ;-)


 ????? Hope this helps.
 ????? Spencer Graves


[1]
https://en.wikipedia.org/wiki/All_models_are_wrong


On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>   <https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16>
> Dear all,
>
> i would appreciate having your advice on the following please :
>
> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we compare
> sets of 1000 genes expression (in the genomics field).
>
> however, the journal asks us to provide the exact p value ...
>
> would it be legitimate to write : "p-value = 0" ? thanks a lot,
>
> -- bogdan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter@|@ng|e|der @end|ng |rom gm@||@com  Fri Mar 19 06:15:23 2021
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 18 Mar 2021 22:15:23 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
Message-ID: <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>

I thinnk the answer is much simpler. The print method for hypothesis
tests (class htest) truncates the p-values. In the above example,
instead of using

wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)

and copying the output, just print the p-value:

tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
tst$p.value

[1] 2.988368e-32


I think this value is what the journal asks for.

HTH,

Peter

On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
>
>        I would push back on that from two perspectives:
>
>
>              1.  I would study exactly what the journal said very
> carefully.  If they mandated "wilcox.test", that function has an
> argument called "exact".  If that's what they are asking, then using
> that argument gives the exact p-value, e.g.:
>
>
>  > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>
>          Wilcoxon rank sum exact test
>
> data:  rnorm(100) and rnorm(100, 2)
> W = 691, p-value < 2.2e-16
>
>
>              2.  If that's NOT what they are asking, then I'm not
> convinced what they are asking makes sense:  There is is no such thing
> as an "exact p value" except to the extent that certain assumptions
> hold, and all models are wrong (but some are useful), as George Box
> famously said years ago.[1]  Truth only exists in mathematics, and
> that's because it's a fiction to start with ;-)
>
>
>        Hope this helps.
>        Spencer Graves
>
>
> [1]
> https://en.wikipedia.org/wiki/All_models_are_wrong
>
>
> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> >   <https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16>
> > Dear all,
> >
> > i would appreciate having your advice on the following please :
> >
> > in R, the wilcox.test() provides "a p-value < 2.2e-16", when we compare
> > sets of 1000 genes expression (in the genomics field).
> >
> > however, the journal asks us to provide the exact p value ...
> >
> > would it be legitimate to write : "p-value = 0" ? thanks a lot,
> >
> > -- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From t@n@@@ @end|ng |rom gm@||@com  Fri Mar 19 06:15:45 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 18 Mar 2021 22:15:45 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
Message-ID: <CA+JEM00U2kya9MXGkujTbjrRfabbu3qn+435D655FMqasRStbQ@mail.gmail.com>

Dear Spencer, thank you very much for your prompt email and help. When
using :

> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
W = 698, p-value < 2.2e-16

> wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
W = 1443, p-value < 2.2e-16

and in both cases p-value < 2.2e-16. By "exact" p-value, i have meant the
"precise" p-value ;

If I may ask please, could we write p-value = 0 ?

i have noted a similar conversation on stackexchange, although the answer
is not very clear (to me).

https://stats.stackexchange.com/questions/78839/how-should-tiny-p-values-be-reported-and-why-does-r-put-a-minimum-on-2-22e-1

thanks again,

bogdan

On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>        I would push back on that from two perspectives:
>
>
>              1.  I would study exactly what the journal said very
> carefully.  If they mandated "wilcox.test", that function has an
> argument called "exact".  If that's what they are asking, then using
> that argument gives the exact p-value, e.g.:
>
>
>  > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>
>          Wilcoxon rank sum exact test
>
> data:  rnorm(100) and rnorm(100, 2)
> W = 691, p-value < 2.2e-16
>
>
>              2.  If that's NOT what they are asking, then I'm not
> convinced what they are asking makes sense:  There is is no such thing
> as an "exact p value" except to the extent that certain assumptions
> hold, and all models are wrong (but some are useful), as George Box
> famously said years ago.[1]  Truth only exists in mathematics, and
> that's because it's a fiction to start with ;-)
>
>
>        Hope this helps.
>        Spencer Graves
>
>
> [1]
> https://en.wikipedia.org/wiki/All_models_are_wrong
>
>
> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> >   <
> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16>
> > Dear all,
> >
> > i would appreciate having your advice on the following please :
> >
> > in R, the wilcox.test() provides "a p-value < 2.2e-16", when we compare
> > sets of 1000 genes expression (in the genomics field).
> >
> > however, the journal asks us to provide the exact p value ...
> >
> > would it be legitimate to write : "p-value = 0" ? thanks a lot,
> >
> > -- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From t@n@@@ @end|ng |rom gm@||@com  Fri Mar 19 06:31:04 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 18 Mar 2021 22:31:04 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
Message-ID: <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>

Dear Peter, thanks a lot. yes, we can see a very precise p-value, and that
was the request from the journal.

if I may ask another question please : what is the meaning of "exact=TRUE"
or "exact=FALSE" in wilcox.test ?

i can see that the "numerically precise" p-values are different. thanks a
lot !

tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
tst$p.value
[1] 8.535524e-25

tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
tst$p.value
[1] 3.448211e-25

On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> I thinnk the answer is much simpler. The print method for hypothesis
> tests (class htest) truncates the p-values. In the above example,
> instead of using
>
> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>
> and copying the output, just print the p-value:
>
> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> tst$p.value
>
> [1] 2.988368e-32
>
>
> I think this value is what the journal asks for.
>
> HTH,
>
> Peter
>
> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
> <spencer.graves at effectivedefense.org> wrote:
> >
> >        I would push back on that from two perspectives:
> >
> >
> >              1.  I would study exactly what the journal said very
> > carefully.  If they mandated "wilcox.test", that function has an
> > argument called "exact".  If that's what they are asking, then using
> > that argument gives the exact p-value, e.g.:
> >
> >
> >  > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >
> >          Wilcoxon rank sum exact test
> >
> > data:  rnorm(100) and rnorm(100, 2)
> > W = 691, p-value < 2.2e-16
> >
> >
> >              2.  If that's NOT what they are asking, then I'm not
> > convinced what they are asking makes sense:  There is is no such thing
> > as an "exact p value" except to the extent that certain assumptions
> > hold, and all models are wrong (but some are useful), as George Box
> > famously said years ago.[1]  Truth only exists in mathematics, and
> > that's because it's a fiction to start with ;-)
> >
> >
> >        Hope this helps.
> >        Spencer Graves
> >
> >
> > [1]
> > https://en.wikipedia.org/wiki/All_models_are_wrong
> >
> >
> > On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> > >   <
> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16>
> > > Dear all,
> > >
> > > i would appreciate having your advice on the following please :
> > >
> > > in R, the wilcox.test() provides "a p-value < 2.2e-16", when we compare
> > > sets of 1000 genes expression (in the genomics field).
> > >
> > > however, the journal asks us to provide the exact p value ...
> > >
> > > would it be legitimate to write : "p-value = 0" ? thanks a lot,
> > >
> > > -- bogdan
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From vd4mm|nd @end|ng |rom gm@||@com  Fri Mar 19 06:47:24 2021
From: vd4mm|nd @end|ng |rom gm@||@com (Vivek Das)
Date: Thu, 18 Mar 2021 22:47:24 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
Message-ID: <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>

Hi Bogdan,

You can also get the information from the link of the Wilcox.test function
page.

?By default (if exact is not specified), an exact p-value is computed if
the samples contain less than 50 finite values and there are no ties.
Otherwise, a normal approximation is used.?

For more:

https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html

Hope this helps!

Best,

VD


On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear Peter, thanks a lot. yes, we can see a very precise p-value, and that
> was the request from the journal.
>
> if I may ask another question please : what is the meaning of "exact=TRUE"
> or "exact=FALSE" in wilcox.test ?
>
> i can see that the "numerically precise" p-values are different. thanks a
> lot !
>
> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> tst$p.value
> [1] 8.535524e-25
>
> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
> tst$p.value
> [1] 3.448211e-25
>
> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
> peter.langfelder at gmail.com> wrote:
>
> > I thinnk the answer is much simpler. The print method for hypothesis
> > tests (class htest) truncates the p-values. In the above example,
> > instead of using
> >
> > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >
> > and copying the output, just print the p-value:
> >
> > tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > tst$p.value
> >
> > [1] 2.988368e-32
> >
> >
> > I think this value is what the journal asks for.
> >
> > HTH,
> >
> > Peter
> >
> > On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
> > <spencer.graves at effectivedefense.org> wrote:
> > >
> > >        I would push back on that from two perspectives:
> > >
> > >
> > >              1.  I would study exactly what the journal said very
> > > carefully.  If they mandated "wilcox.test", that function has an
> > > argument called "exact".  If that's what they are asking, then using
> > > that argument gives the exact p-value, e.g.:
> > >
> > >
> > >  > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >
> > >          Wilcoxon rank sum exact test
> > >
> > > data:  rnorm(100) and rnorm(100, 2)
> > > W = 691, p-value < 2.2e-16
> > >
> > >
> > >              2.  If that's NOT what they are asking, then I'm not
> > > convinced what they are asking makes sense:  There is is no such thing
> > > as an "exact p value" except to the extent that certain assumptions
> > > hold, and all models are wrong (but some are useful), as George Box
> > > famously said years ago.[1]  Truth only exists in mathematics, and
> > > that's because it's a fiction to start with ;-)
> > >
> > >
> > >        Hope this helps.
> > >        Spencer Graves
> > >
> > >
> > > [1]
> > > https://en.wikipedia.org/wiki/All_models_are_wrong
> > >
> > >
> > > On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> > > >   <
> > https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16>
> > > > Dear all,
> > > >
> > > > i would appreciate having your advice on the following please :
> > > >
> > > > in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
> compare
> > > > sets of 1000 genes expression (in the genomics field).
> > > >
> > > > however, the journal asks us to provide the exact p value ...
> > > >
> > > > would it be legitimate to write : "p-value = 0" ? thanks a lot,
> > > >
> > > > -- bogdan
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
----------------------------------------------------------

Vivek Das, PhD

	[[alternative HTML version deleted]]


From t@n@@@ @end|ng |rom gm@||@com  Fri Mar 19 06:54:53 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Thu, 18 Mar 2021 22:54:53 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
Message-ID: <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>

thanks a lot, Vivek ! in other words, assuming that we work with 1000 data
points,

shall we use EXACT = TRUE, it uses the normal approximation,

while if EXACT=FALSE (for these large samples), it does not ?

On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com> wrote:

> Hi Bogdan,
>
> You can also get the information from the link of the Wilcox.test function
> page.
>
> ?By default (if exact is not specified), an exact p-value is computed if
> the samples contain less than 50 finite values and there are no ties.
> Otherwise, a normal approximation is used.?
>
> For more:
>
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>
> Hope this helps!
>
> Best,
>
> VD
>
>
> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
>> Dear Peter, thanks a lot. yes, we can see a very precise p-value, and that
>> was the request from the journal.
>>
>> if I may ask another question please : what is the meaning of "exact=TRUE"
>> or "exact=FALSE" in wilcox.test ?
>>
>> i can see that the "numerically precise" p-values are different. thanks a
>> lot !
>>
>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> tst$p.value
>> [1] 8.535524e-25
>>
>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>> tst$p.value
>> [1] 3.448211e-25
>>
>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>> peter.langfelder at gmail.com> wrote:
>>
>> > I thinnk the answer is much simpler. The print method for hypothesis
>> > tests (class htest) truncates the p-values. In the above example,
>> > instead of using
>> >
>> > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> >
>> > and copying the output, just print the p-value:
>> >
>> > tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > tst$p.value
>> >
>> > [1] 2.988368e-32
>> >
>> >
>> > I think this value is what the journal asks for.
>> >
>> > HTH,
>> >
>> > Peter
>> >
>> > On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>> > <spencer.graves at effectivedefense.org> wrote:
>> > >
>> > >        I would push back on that from two perspectives:
>> > >
>> > >
>> > >              1.  I would study exactly what the journal said very
>> > > carefully.  If they mandated "wilcox.test", that function has an
>> > > argument called "exact".  If that's what they are asking, then using
>> > > that argument gives the exact p-value, e.g.:
>> > >
>> > >
>> > >  > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >
>> > >          Wilcoxon rank sum exact test
>> > >
>> > > data:  rnorm(100) and rnorm(100, 2)
>> > > W = 691, p-value < 2.2e-16
>> > >
>> > >
>> > >              2.  If that's NOT what they are asking, then I'm not
>> > > convinced what they are asking makes sense:  There is is no such thing
>> > > as an "exact p value" except to the extent that certain assumptions
>> > > hold, and all models are wrong (but some are useful), as George Box
>> > > famously said years ago.[1]  Truth only exists in mathematics, and
>> > > that's because it's a fiction to start with ;-)
>> > >
>> > >
>> > >        Hope this helps.
>> > >        Spencer Graves
>> > >
>> > >
>> > > [1]
>> > > https://en.wikipedia.org/wiki/All_models_are_wrong
>> > >
>> > >
>> > > On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>> > > >   <
>> > https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>> >
>> > > > Dear all,
>> > > >
>> > > > i would appreciate having your advice on the following please :
>> > > >
>> > > > in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
>> compare
>> > > > sets of 1000 genes expression (in the genomics field).
>> > > >
>> > > > however, the journal asks us to provide the exact p value ...
>> > > >
>> > > > would it be legitimate to write : "p-value = 0" ? thanks a lot,
>> > > >
>> > > > -- bogdan
>> > > >
>> > > >       [[alternative HTML version deleted]]
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> ----------------------------------------------------------
>
> Vivek Das, PhD
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Mar 19 07:28:59 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 19 Mar 2021 07:28:59 +0100
Subject: [R] Failure in predicting parameters
In-Reply-To: <e0a79c8e-e69c-e6e4-fd93-a6d334527289@sapo.pt>
References: <CAMk+s2SQhbkBdoGw7acbCd2uO9sS7fidVhfyOA8bgHnyf46uVg@mail.gmail.com>
 <CAHqSRuR3EvPudJWZignHHWCLJJVpiOBh1+QguC+V2z87XOQ2hg@mail.gmail.com>
 <CAMk+s2SEKx-HDreBPr0b6QMtvEHquV=FBotaeHnti57goEA0Fw@mail.gmail.com>
 <CAMk+s2S270X=QVnrFsVgsX7Wmr9vKCXnsG9Fn0tg8nqz=bk4xQ@mail.gmail.com>
 <CAMk+s2R+21LBjyesQ5ZchGXB=AeCOi4fN_dmRtU+FVj1nsvXOg@mail.gmail.com>
 <e0a79c8e-e69c-e6e4-fd93-a6d334527289@sapo.pt>
Message-ID: <CAMk+s2SnLA1MuL08JPz+uLFmmqF6f47BdQHUW55qCJutHuVrgg@mail.gmail.com>

Thank you, I'll try it!

On Thu, Mar 18, 2021 at 9:46 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Maybe a bit late but there is a contributed package [1] for quantitative
> PCR fitting non-linear models with the Levenberg-Marquardt algorithm.
>
> estim and vector R below are your model and your fitted values vector.
> The RMSE of this fit is smaller than your model's.
>
>
> Isn't this simpler?
>
>
> library(qpcR)
>
> df1 <- data.frame(Cycles = seq_along(high), high)
>
> fit <- pcrfit(
>    data = df1,
>    cyc = 1,
>    fluo = 2
> )
> summary(fit)
>
> coef(estim)
> coef(fit)
>
>
> sqrt(sum(resid(estim)^2))
> #[1] 1724.768
> sqrt(sum(resid(fit)^2))
> #[1] 1178.318
>
>
> highpred <- predict(fit, newdata = df1)
>
> plot(1:45, high, type = "l", col = "red")
> points(1:45, R, col = "blue")
> points(1:45, highpred$Prediction, col = "cyan", pch = 3)
>
>
> [1] https://CRAN.R-project.org/package=qpcR
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 06:51 de 18/03/21, Luigi Marongiu escreveu:
> > It worked. I re-written the equation as:
> > ```
> > rutledge_param <- function(p, x, y) ( (p$M / ( 1 + exp(-(x-p$m)/p$s))
> > ) + p$B ) - y
> > ```
> > and used Desmos to estimate the slope, so:
> > ```
> > estim <- nls.lm(par = list(m = halfCycle, s = 2.77, M = MaxFluo, B = high[1]),
> >              fn = rutledge_param, x = 1:45, y = high)
> > summary(estim)
> > R <- rutledge(list(half_fluorescence = 27.1102, slope = 2.7680,
> >                     max_fluorescence = 11839.7745, back_fluorescence =
> > -138.8615) , 1:45)
> > points(1:45, R, type="l", col="red")
> > ```
> >
> > Thanks
> >
> > On Tue, Mar 16, 2021 at 8:29 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>
> >> Just an update:
> >> I tried with desmos and the fitting looks good. Desmos calculated the
> >> parameters as:
> >> Fmax = 11839.8
> >> Chalf = 27.1102 (with matches with my estimate of 27 cycles)
> >> k = 2.76798
> >> Fb = -138.864
> >> I forced R to accept the right parameters using a single named list
> >> and re-written the formula (it was a bit unclear in the paper):
> >> ```
> >> rutledge <- function(p, x) {
> >>    m = p$half_fluorescence
> >>    s = p$slope
> >>    M = p$max_fluorescence
> >>    B = p$back_fluorescence
> >>    y = (M / (1+exp( -((x-m)/s) )) ) + B
> >>    return(y)
> >> }
> >> ```
> >> but when I apply it I get a funny graph:
> >> ```
> >> desmos <- rutledge(list(half_fluorescence = 27.1102, slope = 2.76798,
> >>                          max_fluorescence = 11839.8, back_fluorescence
> >> = -138.864) , high)
> >> ```
> >>
> >> On Mon, Mar 15, 2021 at 7:39 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>>
> >>> Hello,
> >>> the negative data comes from the machine. Probably I should use raw
> >>> data directly, although in the paper this requirement is not reported.
> >>> The p$x was a typo. Now I corrected it and I got this error:
> >>> ```
> >>>
> >>>> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(x-p$m)/p$s))) + p$B) - y
> >>>> estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> >>> +             fn = rutledge_param, x = 1:45, y = high)
> >>> Error in dimnames(x) <- dn :
> >>>    length of 'dimnames' [2] not equal to array extent
> >>> ```
> >>> Probably because 'slopes' is a vector instead of a scalar. Since the
> >>> slope is changing, I don't think is right to use a scalar, but I tried
> >>> and I got:
> >>> ```
> >>>> estim <- nls.lm(par = list(m = halfFluo, s = 1, M = MaxFluo, B = high[1]),
> >>> +             fn = rutledge_param, x = 1:45, y = high)
> >>>> estim
> >>> Nonlinear regression via the Levenberg-Marquardt algorithm
> >>> parameter estimates: 6010.94, 1, 12021.88, 4700.49288888889
> >>> residual sum-of-squares: 1.14e+09
> >>> reason terminated: Relative error in the sum of squares is at most `ftol'.
> >>> ```
> >>> The values reported are the same I used at the beginning apart from
> >>> the last (the background parameter) which is 4700 instead of zero. If
> >>> I plug it, I get an L shaped plot that is worse than that at the
> >>> beginning:
> >>> ```
> >>> after = init = rutledge(halfFluo, 1, MaxFluo, 4700.49288888889, high)
> >>> points(1:45, after, type="l", col="blue")
> >>> ```
> >>> What did I get wrong here?
> >>> Thanks
> >>>
> >>> On Sun, Mar 14, 2021 at 8:05 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
> >>>>
> >>>>> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> >>>>
> >>>> Did you mean that p$x to be just x?  As is, this returns numeric(0)
> >>>> for the p that nls.lm gives it because p$x is NULL and NULL-aNumber is
> >>>> numeric().
> >>>>
> >>>> -Bill
> >>>>
> >>>> On Sun, Mar 14, 2021 at 9:46 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>>>>
> >>>>> Hello,
> >>>>> I would like to use the Rutledge equation
> >>>>> (https://pubmed.ncbi.nlm.nih.gov/15601990/) to model PCR data. The
> >>>>> equation is:
> >>>>> Fc = Fmax / (1+exp(-(C-Chalf)/k)) + Fb
> >>>>> I defined the equation and another that subtracts the values from the
> >>>>> expectations. I used minpack.lm to get the parameters, but I got an
> >>>>> error:
> >>>>> ```
> >>>>>
> >>>>>> library("minpack.lm")
> >>>>>> h <- c(120.64, 66.14, 34.87, 27.11, 8.87, -5.8, 4.52, -7.16, -17.39,
> >>>>> +        -14.29, -20.26, -14.99, -21.05, -20.64, -8.03, -21.56, -1.28, 15.01,
> >>>>> +        75.26, 191.76, 455.09, 985.96, 1825.59, 2908.08, 3993.18, 5059.94,
> >>>>> +        6071.93, 6986.32, 7796.01, 8502.25, 9111.46, 9638.01, 10077.19,
> >>>>> +        10452.02, 10751.81, 11017.49, 11240.37, 11427.47, 11570.07, 11684.96,
> >>>>> +        11781.77, 11863.35, 11927.44, 11980.81, 12021.88, 12058.35, 12100.63,
> >>>>> +        12133.57, 12148.89, 12137.09)
> >>>>>> high <- h[1:45]
> >>>>>> MaxFluo <- max(high)
> >>>>>> halfFluo <- MaxFluo/2
> >>>>>> halfCycle = 27
> >>>>>> find_slope <- function(X, Y) {
> >>>>> +   Slope <- c(0)
> >>>>> +   for (i in 2:length(X)) {
> >>>>> +     delta_x <- X[i] - X[i-1]
> >>>>> +     delta_y <- Y[i] - Y[i-1]
> >>>>> +     Slope[i] <- delta_y/delta_x
> >>>>> +   }
> >>>>> +   return(Slope)
> >>>>> + }
> >>>>>> slopes <- find_slope(1:45, high)
> >>>>>>
> >>>>>> rutledge <- function(m, s, M, B, x) {
> >>>>> +   divisor = 1 + exp(-1* ((x-m)/s) )
> >>>>> +   y = (M/divisor) + B
> >>>>> +   return(y)
> >>>>> + }
> >>>>>> rutledge_param <- function(p, x, y) ((p$M / (1 + exp(-1*(p$x-p$m)/p$s))) + p$B) - y
> >>>>>>
> >>>>>>
> >>>>>> init = rutledge(halfFluo, slopes, MaxFluo, 0, high)
> >>>>>> points(1:45, init, type="l", col="red")
> >>>>>> estim <- nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B = high[1]),
> >>>>> +                 fn = rutledge_param, x = 1:45, y = high)
> >>>>> Error in nls.lm(par = list(m = halfFluo, s = slopes, M = MaxFluo, B =
> >>>>> high[1]),  :
> >>>>>    evaluation of fn function returns non-sensible value!
> >>>>> ```
> >>>>>
> >>>>> Where could the error be?
> >>>>>
> >>>>>
> >>>>> --
> >>>>> Best regards,
> >>>>> Luigi
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>>
> >>> --
> >>> Best regards,
> >>> Luigi
> >>
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
> >
> >
> >



-- 
Best regards,
Luigi


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Mar 19 07:32:45 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 18 Mar 2021 23:32:45 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+JEM00U2kya9MXGkujTbjrRfabbu3qn+435D655FMqasRStbQ@mail.gmail.com>
References: <CA+JEM00U2kya9MXGkujTbjrRfabbu3qn+435D655FMqasRStbQ@mail.gmail.com>
Message-ID: <FDF82827-AB0C-45AD-A8E1-95253B3EE944@comcast.net>



Sent from my iPhone

> On Mar 18, 2021, at 10:26 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> 
> ?Dear Spencer, thank you very much for your prompt email and help. When
> using :
> 
>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> W = 698, p-value < 2.2e-16
> 
>> wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
> W = 1443, p-value < 2.2e-16
> 
> and in both cases p-value < 2.2e-16. By "exact" p-value, i have meant the
> "precise" p-value ;
> 
> If I may ask please, could we write p-value = 0 ?
> 
> i have noted a similar conversation on stackexchange, although the answer
> is not very clear (to me).

The reason it wasn?t and couldn?t be ?clear? was that the underlying scientific question and the statistical methods were not precisely described. 

The same lack of background information still persists in this discussion. 

? 
David
> 
> https://stats.stackexchange.com/questions/78839/how-should-tiny-p-values-be-reported-and-why-does-r-put-a-minimum-on-2-22e-1
> 
> thanks again,
> 
> bogdan
> 
>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves <
>> spencer.graves at effectivedefense.org> wrote:
>>      I would push back on that from two perspectives:
>>            1.  I would study exactly what the journal said very
>> carefully.  If they mandated "wilcox.test", that function has an
>> argument called "exact".  If that's what they are asking, then using
>> that argument gives the exact p-value, e.g.:
>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>        Wilcoxon rank sum exact test
>> data:  rnorm(100) and rnorm(100, 2)
>> W = 691, p-value < 2.2e-16
>>            2.  If that's NOT what they are asking, then I'm not
>> convinced what they are asking makes sense:  There is is no such thing
>> as an "exact p value" except to the extent that certain assumptions
>> hold, and all models are wrong (but some are useful), as George Box
>> famously said years ago.[1]  Truth only exists in mathematics, and
>> that's because it's a fiction to start with ;-)
>>      Hope this helps.
>>      Spencer Graves
>> [1]
>> https://en.wikipedia.org/wiki/All_models_are_wrong
>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>>>> <
>> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16>
>>> Dear all,
>>> i would appreciate having your advice on the following please :
>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we compare
>>> sets of 1000 genes expression (in the genomics field).
>>> however, the journal asks us to provide the exact p value ...
>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
>>> -- bogdan
>>>     [[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
>   [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Fri Mar 19 14:30:36 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Fri, 19 Mar 2021 08:30:36 -0500
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
Message-ID: <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>



On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
> thanks a lot, Vivek ! in other words, assuming that we work with 1000 data
> points,
>
> shall we use EXACT = TRUE, it uses the normal approximation,
>
> while if EXACT=FALSE (for these large samples), it does not ?


 ????? As David Winsemius noted, the documentation is not clear. 
Consider the following:

> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > > wilcox.test(x, y)$p.value 
[1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > > 
wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, 
y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y, 
exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y, 
exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y, 
EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y, 
EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y, 
exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y, 
exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here: 
1.172189e-25 and 4.123875e-32. The first one, I think, is the normal 
approximation, which is the same as exact=FALSE. I think that with 
exact=FALSE, you get a permutation distribution, though I'm not sure. 
You might try looking at "wilcox_test in package coin for exact, 
asymptotic and Monte Carlo conditional p-values, including in the 
presence of ties" to see if it is clearer. NOTE: R is case sensitive, so 
"EXACT" is a different variable from "exact". It is interpreted as an 
optional argument, which is not recognized and therefore ignored in this 
context.
	  Hope this helps.
	  Spencer


> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com> wrote:
>
>> Hi Bogdan,
>>
>> You can also get the information from the link of the Wilcox.test function
>> page.
>>
>> ?By default (if exact is not specified), an exact p-value is computed if
>> the samples contain less than 50 finite values and there are no ties.
>> Otherwise, a normal approximation is used.?
>>
>> For more:
>>
>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>>
>> Hope this helps!
>>
>> Best,
>>
>> VD
>>
>>
>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>>
>>> Dear Peter, thanks a lot. yes, we can see a very precise p-value, and that
>>> was the request from the journal.
>>>
>>> if I may ask another question please : what is the meaning of "exact=TRUE"
>>> or "exact=FALSE" in wilcox.test ?
>>>
>>> i can see that the "numerically precise" p-values are different. thanks a
>>> lot !
>>>
>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> tst$p.value
>>> [1] 8.535524e-25
>>>
>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>>> tst$p.value
>>> [1] 3.448211e-25
>>>
>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>>> peter.langfelder at gmail.com> wrote:
>>>
>>>> I thinnk the answer is much simpler. The print method for hypothesis
>>>> tests (class htest) truncates the p-values. In the above example,
>>>> instead of using
>>>>
>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>
>>>> and copying the output, just print the p-value:
>>>>
>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>> tst$p.value
>>>>
>>>> [1] 2.988368e-32
>>>>
>>>>
>>>> I think this value is what the journal asks for.
>>>>
>>>> HTH,
>>>>
>>>> Peter
>>>>
>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>>         I would push back on that from two perspectives:
>>>>>
>>>>>
>>>>>               1.  I would study exactly what the journal said very
>>>>> carefully.  If they mandated "wilcox.test", that function has an
>>>>> argument called "exact".  If that's what they are asking, then using
>>>>> that argument gives the exact p-value, e.g.:
>>>>>
>>>>>
>>>>>   > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>
>>>>>           Wilcoxon rank sum exact test
>>>>>
>>>>> data:  rnorm(100) and rnorm(100, 2)
>>>>> W = 691, p-value < 2.2e-16
>>>>>
>>>>>
>>>>>               2.  If that's NOT what they are asking, then I'm not
>>>>> convinced what they are asking makes sense:  There is is no such thing
>>>>> as an "exact p value" except to the extent that certain assumptions
>>>>> hold, and all models are wrong (but some are useful), as George Box
>>>>> famously said years ago.[1]  Truth only exists in mathematics, and
>>>>> that's because it's a fiction to start with ;-)
>>>>>
>>>>>
>>>>>         Hope this helps.
>>>>>         Spencer Graves
>>>>>
>>>>>
>>>>> [1]
>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>>>>>
>>>>>
>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>>>>>>    <
>>>> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>>>>
>>>>>> Dear all,
>>>>>>
>>>>>> i would appreciate having your advice on the following please :
>>>>>>
>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
>>> compare
>>>>>> sets of 1000 genes expression (in the genomics field).
>>>>>>
>>>>>> however, the journal asks us to provide the exact p value ...
>>>>>>
>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
>>>>>>
>>>>>> -- bogdan
>>>>>>
>>>>>>        [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> --
>> ----------------------------------------------------------
>>
>> Vivek Das, PhD
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Fri Mar 19 15:01:51 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Fri, 19 Mar 2021 22:01:51 +0800
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
Message-ID: <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>

Hey,

I just want to point out that the word "exact" has two meanings. It can
mean the numerically accurate p-value as Bogdan asked in his first email,
or it could mean the p-value calculated from the exact distribution of the
statistic(In this case, U stat). These two are actually not related, even
though they all called "exact".

Best,
Jiefei

On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>
>
> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
> > thanks a lot, Vivek ! in other words, assuming that we work with 1000
> data
> > points,
> >
> > shall we use EXACT = TRUE, it uses the normal approximation,
> >
> > while if EXACT=FALSE (for these large samples), it does not ?
>
>
>        As David Winsemius noted, the documentation is not clear.
> Consider the following:
>
> > set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > > wilcox.test(x,
> y)$p.value
> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x,
> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
> approximation, which is the same as exact=FALSE. I think that with
> exact=FALSE, you get a permutation distribution, though I'm not sure.
> You might try looking at "wilcox_test in package coin for exact,
> asymptotic and Monte Carlo conditional p-values, including in the
> presence of ties" to see if it is clearer. NOTE: R is case sensitive, so
> "EXACT" is a different variable from "exact". It is interpreted as an
> optional argument, which is not recognized and therefore ignored in this
> context.
>           Hope this helps.
>           Spencer
>
>
> > On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com> wrote:
> >
> >> Hi Bogdan,
> >>
> >> You can also get the information from the link of the Wilcox.test
> function
> >> page.
> >>
> >> ?By default (if exact is not specified), an exact p-value is computed if
> >> the samples contain less than 50 finite values and there are no ties.
> >> Otherwise, a normal approximation is used.?
> >>
> >> For more:
> >>
> >>
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
> >>
> >> Hope this helps!
> >>
> >> Best,
> >>
> >> VD
> >>
> >>
> >> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
> wrote:
> >>
> >>> Dear Peter, thanks a lot. yes, we can see a very precise p-value, and
> that
> >>> was the request from the journal.
> >>>
> >>> if I may ask another question please : what is the meaning of
> "exact=TRUE"
> >>> or "exact=FALSE" in wilcox.test ?
> >>>
> >>> i can see that the "numerically precise" p-values are different.
> thanks a
> >>> lot !
> >>>
> >>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>> tst$p.value
> >>> [1] 8.535524e-25
> >>>
> >>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
> >>> tst$p.value
> >>> [1] 3.448211e-25
> >>>
> >>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
> >>> peter.langfelder at gmail.com> wrote:
> >>>
> >>>> I thinnk the answer is much simpler. The print method for hypothesis
> >>>> tests (class htest) truncates the p-values. In the above example,
> >>>> instead of using
> >>>>
> >>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>
> >>>> and copying the output, just print the p-value:
> >>>>
> >>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>> tst$p.value
> >>>>
> >>>> [1] 2.988368e-32
> >>>>
> >>>>
> >>>> I think this value is what the journal asks for.
> >>>>
> >>>> HTH,
> >>>>
> >>>> Peter
> >>>>
> >>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
> >>>> <spencer.graves at effectivedefense.org> wrote:
> >>>>>         I would push back on that from two perspectives:
> >>>>>
> >>>>>
> >>>>>               1.  I would study exactly what the journal said very
> >>>>> carefully.  If they mandated "wilcox.test", that function has an
> >>>>> argument called "exact".  If that's what they are asking, then using
> >>>>> that argument gives the exact p-value, e.g.:
> >>>>>
> >>>>>
> >>>>>   > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>
> >>>>>           Wilcoxon rank sum exact test
> >>>>>
> >>>>> data:  rnorm(100) and rnorm(100, 2)
> >>>>> W = 691, p-value < 2.2e-16
> >>>>>
> >>>>>
> >>>>>               2.  If that's NOT what they are asking, then I'm not
> >>>>> convinced what they are asking makes sense:  There is is no such
> thing
> >>>>> as an "exact p value" except to the extent that certain assumptions
> >>>>> hold, and all models are wrong (but some are useful), as George Box
> >>>>> famously said years ago.[1]  Truth only exists in mathematics, and
> >>>>> that's because it's a fiction to start with ;-)
> >>>>>
> >>>>>
> >>>>>         Hope this helps.
> >>>>>         Spencer Graves
> >>>>>
> >>>>>
> >>>>> [1]
> >>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
> >>>>>
> >>>>>
> >>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> >>>>>>    <
> >>>>
> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
> >>>>
> >>>>>> Dear all,
> >>>>>>
> >>>>>> i would appreciate having your advice on the following please :
> >>>>>>
> >>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
> >>> compare
> >>>>>> sets of 1000 genes expression (in the genomics field).
> >>>>>>
> >>>>>> however, the journal asks us to provide the exact p value ...
> >>>>>>
> >>>>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
> >>>>>>
> >>>>>> -- bogdan
> >>>>>>
> >>>>>>        [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >> --
> >> ----------------------------------------------------------
> >>
> >> Vivek Das, PhD
> >>
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Fri Mar 19 15:52:29 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Fri, 19 Mar 2021 22:52:29 +0800
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
Message-ID: <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>

After digging into the R source, it turns out that the argument `exact` has
nothing to do with the numeric precision. It only affects the statistic
model used to compute the p-value. When `exact=TRUE` the true distribution
of the statistic will be used. Otherwise, a normal approximation will be
used.

I think the documentation needs to be improved here, you can compute the
exact p-value *only* when you do not have any ties in your data. If you
have ties in your data you will get the p-value from the normal
approximation no matter what value you put in `exact`. This behavior should
be documented or a warning should be given when `exact=TRUE` and ties
present.

FYI, if the exact p-value is required, `pwilcox` function will be used to
compute the p-value. There are no details on how it computes the pvalue but
its C code seems to compute the probability table, so I assume it computes
the exact p-value from the true distribution of the statistic, not a
permutation or MC p-value.

Best,
Jiefei



On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hey,
>
> I just want to point out that the word "exact" has two meanings. It can
> mean the numerically accurate p-value as Bogdan asked in his first email,
> or it could mean the p-value calculated from the exact distribution of the
> statistic(In this case, U stat). These two are actually not related, even
> though they all called "exact".
>
> Best,
> Jiefei
>
> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
> spencer.graves at effectivedefense.org> wrote:
>
>>
>>
>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
>> > thanks a lot, Vivek ! in other words, assuming that we work with 1000
>> data
>> > points,
>> >
>> > shall we use EXACT = TRUE, it uses the normal approximation,
>> >
>> > while if EXACT=FALSE (for these large samples), it does not ?
>>
>>
>>        As David Winsemius noted, the documentation is not clear.
>> Consider the following:
>>
>> > set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > > wilcox.test(x,
>> y)$p.value
>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x,
>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
>> approximation, which is the same as exact=FALSE. I think that with
>> exact=FALSE, you get a permutation distribution, though I'm not sure.
>> You might try looking at "wilcox_test in package coin for exact,
>> asymptotic and Monte Carlo conditional p-values, including in the
>> presence of ties" to see if it is clearer. NOTE: R is case sensitive, so
>> "EXACT" is a different variable from "exact". It is interpreted as an
>> optional argument, which is not recognized and therefore ignored in this
>> context.
>>           Hope this helps.
>>           Spencer
>>
>>
>> > On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com> wrote:
>> >
>> >> Hi Bogdan,
>> >>
>> >> You can also get the information from the link of the Wilcox.test
>> function
>> >> page.
>> >>
>> >> ?By default (if exact is not specified), an exact p-value is computed
>> if
>> >> the samples contain less than 50 finite values and there are no ties.
>> >> Otherwise, a normal approximation is used.?
>> >>
>> >> For more:
>> >>
>> >>
>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>> >>
>> >> Hope this helps!
>> >>
>> >> Best,
>> >>
>> >> VD
>> >>
>> >>
>> >> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
>> wrote:
>> >>
>> >>> Dear Peter, thanks a lot. yes, we can see a very precise p-value, and
>> that
>> >>> was the request from the journal.
>> >>>
>> >>> if I may ask another question please : what is the meaning of
>> "exact=TRUE"
>> >>> or "exact=FALSE" in wilcox.test ?
>> >>>
>> >>> i can see that the "numerically precise" p-values are different.
>> thanks a
>> >>> lot !
>> >>>
>> >>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> >>> tst$p.value
>> >>> [1] 8.535524e-25
>> >>>
>> >>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>> >>> tst$p.value
>> >>> [1] 3.448211e-25
>> >>>
>> >>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>> >>> peter.langfelder at gmail.com> wrote:
>> >>>
>> >>>> I thinnk the answer is much simpler. The print method for hypothesis
>> >>>> tests (class htest) truncates the p-values. In the above example,
>> >>>> instead of using
>> >>>>
>> >>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> >>>>
>> >>>> and copying the output, just print the p-value:
>> >>>>
>> >>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> >>>> tst$p.value
>> >>>>
>> >>>> [1] 2.988368e-32
>> >>>>
>> >>>>
>> >>>> I think this value is what the journal asks for.
>> >>>>
>> >>>> HTH,
>> >>>>
>> >>>> Peter
>> >>>>
>> >>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>> >>>> <spencer.graves at effectivedefense.org> wrote:
>> >>>>>         I would push back on that from two perspectives:
>> >>>>>
>> >>>>>
>> >>>>>               1.  I would study exactly what the journal said very
>> >>>>> carefully.  If they mandated "wilcox.test", that function has an
>> >>>>> argument called "exact".  If that's what they are asking, then using
>> >>>>> that argument gives the exact p-value, e.g.:
>> >>>>>
>> >>>>>
>> >>>>>   > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> >>>>>
>> >>>>>           Wilcoxon rank sum exact test
>> >>>>>
>> >>>>> data:  rnorm(100) and rnorm(100, 2)
>> >>>>> W = 691, p-value < 2.2e-16
>> >>>>>
>> >>>>>
>> >>>>>               2.  If that's NOT what they are asking, then I'm not
>> >>>>> convinced what they are asking makes sense:  There is is no such
>> thing
>> >>>>> as an "exact p value" except to the extent that certain assumptions
>> >>>>> hold, and all models are wrong (but some are useful), as George Box
>> >>>>> famously said years ago.[1]  Truth only exists in mathematics, and
>> >>>>> that's because it's a fiction to start with ;-)
>> >>>>>
>> >>>>>
>> >>>>>         Hope this helps.
>> >>>>>         Spencer Graves
>> >>>>>
>> >>>>>
>> >>>>> [1]
>> >>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>> >>>>>
>> >>>>>
>> >>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>> >>>>>>    <
>> >>>>
>> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>> >>>>
>> >>>>>> Dear all,
>> >>>>>>
>> >>>>>> i would appreciate having your advice on the following please :
>> >>>>>>
>> >>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
>> >>> compare
>> >>>>>> sets of 1000 genes expression (in the genomics field).
>> >>>>>>
>> >>>>>> however, the journal asks us to provide the exact p value ...
>> >>>>>>
>> >>>>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
>> >>>>>>
>> >>>>>> -- bogdan
>> >>>>>>
>> >>>>>>        [[alternative HTML version deleted]]
>> >>>>>>
>> >>>>>> ______________________________________________
>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>          [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >> --
>> >> ----------------------------------------------------------
>> >>
>> >> Vivek Das, PhD
>> >>
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Fri Mar 19 15:57:08 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Fri, 19 Mar 2021 09:57:08 -0500
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
Message-ID: <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>



On 2021-3-19 9:52 AM, Jiefei Wang wrote:
> After digging into the R source, it turns out that the argument `exact` has
> nothing to do with the numeric precision. It only affects the statistic
> model used to compute the p-value. When `exact=TRUE` the true distribution
> of the statistic will be used. Otherwise, a normal approximation will be
> used.
>
> I think the documentation needs to be improved here, you can compute the
> exact p-value *only* when you do not have any ties in your data. If you
> have ties in your data you will get the p-value from the normal
> approximation no matter what value you put in `exact`. This behavior should
> be documented or a warning should be given when `exact=TRUE` and ties
> present.
>
> FYI, if the exact p-value is required, `pwilcox` function will be used to
> compute the p-value. There are no details on how it computes the pvalue but
> its C code seems to compute the probability table, so I assume it computes
> the exact p-value from the true distribution of the statistic, not a
> permutation or MC p-value.


 ????? My example shows that it does NOT use Monte Carlo, because 
otherwise it uses some distribution.? I believe the term "exact" means 
that it uses the permutation distribution, though I could be mistaken.? 
If it's NOT a permutation distribution, I don't know what it is.


 ????? Spencer
>
> Best,
> Jiefei
>
>
>
> On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com> wrote:
>
>> Hey,
>>
>> I just want to point out that the word "exact" has two meanings. It can
>> mean the numerically accurate p-value as Bogdan asked in his first email,
>> or it could mean the p-value calculated from the exact distribution of the
>> statistic(In this case, U stat). These two are actually not related, even
>> though they all called "exact".
>>
>> Best,
>> Jiefei
>>
>> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
>> spencer.graves at effectivedefense.org> wrote:
>>
>>>
>>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
>>>> thanks a lot, Vivek ! in other words, assuming that we work with 1000
>>> data
>>>> points,
>>>>
>>>> shall we use EXACT = TRUE, it uses the normal approximation,
>>>>
>>>> while if EXACT=FALSE (for these large samples), it does not ?
>>>
>>>         As David Winsemius noted, the documentation is not clear.
>>> Consider the following:
>>>
>>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > > wilcox.test(x,
>>> y)$p.value
>>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
>>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x,
>>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
>>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
>>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
>>> approximation, which is the same as exact=FALSE. I think that with
>>> exact=FALSE, you get a permutation distribution, though I'm not sure.
>>> You might try looking at "wilcox_test in package coin for exact,
>>> asymptotic and Monte Carlo conditional p-values, including in the
>>> presence of ties" to see if it is clearer. NOTE: R is case sensitive, so
>>> "EXACT" is a different variable from "exact". It is interpreted as an
>>> optional argument, which is not recognized and therefore ignored in this
>>> context.
>>>            Hope this helps.
>>>            Spencer
>>>
>>>
>>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com> wrote:
>>>>
>>>>> Hi Bogdan,
>>>>>
>>>>> You can also get the information from the link of the Wilcox.test
>>> function
>>>>> page.
>>>>>
>>>>> ?By default (if exact is not specified), an exact p-value is computed
>>> if
>>>>> the samples contain less than 50 finite values and there are no ties.
>>>>> Otherwise, a normal approximation is used.?
>>>>>
>>>>> For more:
>>>>>
>>>>>
>>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>>>>> Hope this helps!
>>>>>
>>>>> Best,
>>>>>
>>>>> VD
>>>>>
>>>>>
>>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
>>> wrote:
>>>>>> Dear Peter, thanks a lot. yes, we can see a very precise p-value, and
>>> that
>>>>>> was the request from the journal.
>>>>>>
>>>>>> if I may ask another question please : what is the meaning of
>>> "exact=TRUE"
>>>>>> or "exact=FALSE" in wilcox.test ?
>>>>>>
>>>>>> i can see that the "numerically precise" p-values are different.
>>> thanks a
>>>>>> lot !
>>>>>>
>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>> tst$p.value
>>>>>> [1] 8.535524e-25
>>>>>>
>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>>>>>> tst$p.value
>>>>>> [1] 3.448211e-25
>>>>>>
>>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>>>>>> peter.langfelder at gmail.com> wrote:
>>>>>>
>>>>>>> I thinnk the answer is much simpler. The print method for hypothesis
>>>>>>> tests (class htest) truncates the p-values. In the above example,
>>>>>>> instead of using
>>>>>>>
>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>>>
>>>>>>> and copying the output, just print the p-value:
>>>>>>>
>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>>> tst$p.value
>>>>>>>
>>>>>>> [1] 2.988368e-32
>>>>>>>
>>>>>>>
>>>>>>> I think this value is what the journal asks for.
>>>>>>>
>>>>>>> HTH,
>>>>>>>
>>>>>>> Peter
>>>>>>>
>>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>>>>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>>>>>          I would push back on that from two perspectives:
>>>>>>>>
>>>>>>>>
>>>>>>>>                1.  I would study exactly what the journal said very
>>>>>>>> carefully.  If they mandated "wilcox.test", that function has an
>>>>>>>> argument called "exact".  If that's what they are asking, then using
>>>>>>>> that argument gives the exact p-value, e.g.:
>>>>>>>>
>>>>>>>>
>>>>>>>>    > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>>>>
>>>>>>>>            Wilcoxon rank sum exact test
>>>>>>>>
>>>>>>>> data:  rnorm(100) and rnorm(100, 2)
>>>>>>>> W = 691, p-value < 2.2e-16
>>>>>>>>
>>>>>>>>
>>>>>>>>                2.  If that's NOT what they are asking, then I'm not
>>>>>>>> convinced what they are asking makes sense:  There is is no such
>>> thing
>>>>>>>> as an "exact p value" except to the extent that certain assumptions
>>>>>>>> hold, and all models are wrong (but some are useful), as George Box
>>>>>>>> famously said years ago.[1]  Truth only exists in mathematics, and
>>>>>>>> that's because it's a fiction to start with ;-)
>>>>>>>>
>>>>>>>>
>>>>>>>>          Hope this helps.
>>>>>>>>          Spencer Graves
>>>>>>>>
>>>>>>>>
>>>>>>>> [1]
>>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>>>>>>>>
>>>>>>>>
>>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>>>>>>>>>     <
>>> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>>>>>>>>> Dear all,
>>>>>>>>>
>>>>>>>>> i would appreciate having your advice on the following please :
>>>>>>>>>
>>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
>>>>>> compare
>>>>>>>>> sets of 1000 genes expression (in the genomics field).
>>>>>>>>>
>>>>>>>>> however, the journal asks us to provide the exact p value ...
>>>>>>>>>
>>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
>>>>>>>>>
>>>>>>>>> -- bogdan
>>>>>>>>>
>>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>           [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>> --
>>>>> ----------------------------------------------------------
>>>>>
>>>>> Vivek Das, PhD
>>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Fri Mar 19 16:17:56 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Fri, 19 Mar 2021 15:17:56 +0000
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
Message-ID: <1355e688b3c54b0fa9ef751b90ecdd11@UM-MAIL3214.unimaas.nl>

Dear Jiefei,

This behavior is documented. From help(wilcox.test):

"By default (if exact is not specified), an exact p-value is computed if the samples contain less than 50 finite values and there are no ties. Otherwise, a normal approximation is used."

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jiefei Wang
>Sent: Friday, 19 March, 2021 15:52
>To: Spencer Graves
>Cc: r-help; Bogdan Tanasa
>Subject: Re: [R] about a p-value < 2.2e-16
>
>After digging into the R source, it turns out that the argument `exact` has
>nothing to do with the numeric precision. It only affects the statistic
>model used to compute the p-value. When `exact=TRUE` the true distribution
>of the statistic will be used. Otherwise, a normal approximation will be
>used.
>
>I think the documentation needs to be improved here, you can compute the
>exact p-value *only* when you do not have any ties in your data. If you
>have ties in your data you will get the p-value from the normal
>approximation no matter what value you put in `exact`. This behavior should
>be documented or a warning should be given when `exact=TRUE` and ties
>present.
>
>FYI, if the exact p-value is required, `pwilcox` function will be used to
>compute the p-value. There are no details on how it computes the pvalue but
>its C code seems to compute the probability table, so I assume it computes
>the exact p-value from the true distribution of the statistic, not a
>permutation or MC p-value.
>
>Best,
>Jiefei

From @zwj|08 @end|ng |rom gm@||@com  Fri Mar 19 16:31:43 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Fri, 19 Mar 2021 23:31:43 +0800
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <1355e688b3c54b0fa9ef751b90ecdd11@UM-MAIL3214.unimaas.nl>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <1355e688b3c54b0fa9ef751b90ecdd11@UM-MAIL3214.unimaas.nl>
Message-ID: <CAGiFhPMVN+j-9178WDqTQCj5m_mkjyMd7ekig7Nu-z=oy6rWFg@mail.gmail.com>

Dear Wolfgang,

Thanks for the documentation, but the document only states the default
behavior, it does not mention what would happen if we tell it to compute
the exact p-value but the data has ties. I think this would be misleading
as people might think their result is exact by specifying `exact=TRUE` but
the truth is that their data contains ties and the result is from the
normal approximation.

Best,
Jiefei

On Fri, Mar 19, 2021 at 11:18 PM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear Jiefei,
>
> This behavior is documented. From help(wilcox.test):
>
> "By default (if exact is not specified), an exact p-value is computed if
> the samples contain less than 50 finite values and there are no ties.
> Otherwise, a normal approximation is used."
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jiefei
> Wang
> >Sent: Friday, 19 March, 2021 15:52
> >To: Spencer Graves
> >Cc: r-help; Bogdan Tanasa
> >Subject: Re: [R] about a p-value < 2.2e-16
> >
> >After digging into the R source, it turns out that the argument `exact`
> has
> >nothing to do with the numeric precision. It only affects the statistic
> >model used to compute the p-value. When `exact=TRUE` the true distribution
> >of the statistic will be used. Otherwise, a normal approximation will be
> >used.
> >
> >I think the documentation needs to be improved here, you can compute the
> >exact p-value *only* when you do not have any ties in your data. If you
> >have ties in your data you will get the p-value from the normal
> >approximation no matter what value you put in `exact`. This behavior
> should
> >be documented or a warning should be given when `exact=TRUE` and ties
> >present.
> >
> >FYI, if the exact p-value is required, `pwilcox` function will be used to
> >compute the p-value. There are no details on how it computes the pvalue
> but
> >its C code seems to compute the probability table, so I assume it computes
> >the exact p-value from the true distribution of the statistic, not a
> >permutation or MC p-value.
> >
> >Best,
> >Jiefei
>

	[[alternative HTML version deleted]]


From t@n@@@ @end|ng |rom gm@||@com  Fri Mar 19 16:40:10 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 19 Mar 2021 08:40:10 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
Message-ID: <CA+JEM01qbg_k0RqAaKyc_=Tz99PrJMB1K8gMZMa_UUdEUCPSyw@mail.gmail.com>

Dear Jiefei, and all,

many thanks for your time and comments, suggestions, insights.

-- bogdan

On Fri, Mar 19, 2021 at 7:52 AM Jiefei Wang <szwjf08 at gmail.com> wrote:

> After digging into the R source, it turns out that the argument `exact`
> has nothing to do with the numeric precision. It only affects the statistic
> model used to compute the p-value. When `exact=TRUE` the true distribution
> of the statistic will be used. Otherwise, a normal approximation will be
> used.
>
> I think the documentation needs to be improved here, you can compute the
> exact p-value *only* when you do not have any ties in your data. If you
> have ties in your data you will get the p-value from the normal
> approximation no matter what value you put in `exact`. This behavior should
> be documented or a warning should be given when `exact=TRUE` and ties
> present.
>
> FYI, if the exact p-value is required, `pwilcox` function will be used to
> compute the p-value. There are no details on how it computes the pvalue but
> its C code seems to compute the probability table, so I assume it computes
> the exact p-value from the true distribution of the statistic, not a
> permutation or MC p-value.
>
> Best,
> Jiefei
>
>
>
> On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com> wrote:
>
>> Hey,
>>
>> I just want to point out that the word "exact" has two meanings. It can
>> mean the numerically accurate p-value as Bogdan asked in his first email,
>> or it could mean the p-value calculated from the exact distribution of the
>> statistic(In this case, U stat). These two are actually not related, even
>> though they all called "exact".
>>
>> Best,
>> Jiefei
>>
>> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
>> spencer.graves at effectivedefense.org> wrote:
>>
>>>
>>>
>>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
>>> > thanks a lot, Vivek ! in other words, assuming that we work with 1000
>>> data
>>> > points,
>>> >
>>> > shall we use EXACT = TRUE, it uses the normal approximation,
>>> >
>>> > while if EXACT=FALSE (for these large samples), it does not ?
>>>
>>>
>>>        As David Winsemius noted, the documentation is not clear.
>>> Consider the following:
>>>
>>> > set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > > wilcox.test(x,
>>> y)$p.value
>>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
>>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x,
>>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
>>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
>>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
>>> approximation, which is the same as exact=FALSE. I think that with
>>> exact=FALSE, you get a permutation distribution, though I'm not sure.
>>> You might try looking at "wilcox_test in package coin for exact,
>>> asymptotic and Monte Carlo conditional p-values, including in the
>>> presence of ties" to see if it is clearer. NOTE: R is case sensitive, so
>>> "EXACT" is a different variable from "exact". It is interpreted as an
>>> optional argument, which is not recognized and therefore ignored in this
>>> context.
>>>           Hope this helps.
>>>           Spencer
>>>
>>>
>>> > On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com> wrote:
>>> >
>>> >> Hi Bogdan,
>>> >>
>>> >> You can also get the information from the link of the Wilcox.test
>>> function
>>> >> page.
>>> >>
>>> >> ?By default (if exact is not specified), an exact p-value is computed
>>> if
>>> >> the samples contain less than 50 finite values and there are no ties.
>>> >> Otherwise, a normal approximation is used.?
>>> >>
>>> >> For more:
>>> >>
>>> >>
>>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>>> >>
>>> >> Hope this helps!
>>> >>
>>> >> Best,
>>> >>
>>> >> VD
>>> >>
>>> >>
>>> >> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
>>> wrote:
>>> >>
>>> >>> Dear Peter, thanks a lot. yes, we can see a very precise p-value,
>>> and that
>>> >>> was the request from the journal.
>>> >>>
>>> >>> if I may ask another question please : what is the meaning of
>>> "exact=TRUE"
>>> >>> or "exact=FALSE" in wilcox.test ?
>>> >>>
>>> >>> i can see that the "numerically precise" p-values are different.
>>> thanks a
>>> >>> lot !
>>> >>>
>>> >>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> >>> tst$p.value
>>> >>> [1] 8.535524e-25
>>> >>>
>>> >>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>>> >>> tst$p.value
>>> >>> [1] 3.448211e-25
>>> >>>
>>> >>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>>> >>> peter.langfelder at gmail.com> wrote:
>>> >>>
>>> >>>> I thinnk the answer is much simpler. The print method for hypothesis
>>> >>>> tests (class htest) truncates the p-values. In the above example,
>>> >>>> instead of using
>>> >>>>
>>> >>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> >>>>
>>> >>>> and copying the output, just print the p-value:
>>> >>>>
>>> >>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> >>>> tst$p.value
>>> >>>>
>>> >>>> [1] 2.988368e-32
>>> >>>>
>>> >>>>
>>> >>>> I think this value is what the journal asks for.
>>> >>>>
>>> >>>> HTH,
>>> >>>>
>>> >>>> Peter
>>> >>>>
>>> >>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>>> >>>> <spencer.graves at effectivedefense.org> wrote:
>>> >>>>>         I would push back on that from two perspectives:
>>> >>>>>
>>> >>>>>
>>> >>>>>               1.  I would study exactly what the journal said very
>>> >>>>> carefully.  If they mandated "wilcox.test", that function has an
>>> >>>>> argument called "exact".  If that's what they are asking, then
>>> using
>>> >>>>> that argument gives the exact p-value, e.g.:
>>> >>>>>
>>> >>>>>
>>> >>>>>   > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> >>>>>
>>> >>>>>           Wilcoxon rank sum exact test
>>> >>>>>
>>> >>>>> data:  rnorm(100) and rnorm(100, 2)
>>> >>>>> W = 691, p-value < 2.2e-16
>>> >>>>>
>>> >>>>>
>>> >>>>>               2.  If that's NOT what they are asking, then I'm not
>>> >>>>> convinced what they are asking makes sense:  There is is no such
>>> thing
>>> >>>>> as an "exact p value" except to the extent that certain assumptions
>>> >>>>> hold, and all models are wrong (but some are useful), as George Box
>>> >>>>> famously said years ago.[1]  Truth only exists in mathematics, and
>>> >>>>> that's because it's a fiction to start with ;-)
>>> >>>>>
>>> >>>>>
>>> >>>>>         Hope this helps.
>>> >>>>>         Spencer Graves
>>> >>>>>
>>> >>>>>
>>> >>>>> [1]
>>> >>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>>> >>>>>
>>> >>>>>
>>> >>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>>> >>>>>>    <
>>> >>>>
>>> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>>> >>>>
>>> >>>>>> Dear all,
>>> >>>>>>
>>> >>>>>> i would appreciate having your advice on the following please :
>>> >>>>>>
>>> >>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
>>> >>> compare
>>> >>>>>> sets of 1000 genes expression (in the genomics field).
>>> >>>>>>
>>> >>>>>> however, the journal asks us to provide the exact p value ...
>>> >>>>>>
>>> >>>>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
>>> >>>>>>
>>> >>>>>> -- bogdan
>>> >>>>>>
>>> >>>>>>        [[alternative HTML version deleted]]
>>> >>>>>>
>>> >>>>>> ______________________________________________
>>> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>>>> PLEASE do read the posting guide
>>> >>>> http://www.R-project.org/posting-guide.html
>>> >>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>>> ______________________________________________
>>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>>> PLEASE do read the posting guide
>>> >>>> http://www.R-project.org/posting-guide.html
>>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>          [[alternative HTML version deleted]]
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> PLEASE do read the posting guide
>>> >>> http://www.R-project.org/posting-guide.html
>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>
>>> >> --
>>> >> ----------------------------------------------------------
>>> >>
>>> >> Vivek Das, PhD
>>> >>
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Fri Mar 19 16:41:33 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Fri, 19 Mar 2021 23:41:33 +0800
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
Message-ID: <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>

Hi Spencer,

Thanks for your test results, I do not know the answer as I haven't
used wilcox.test for many years. I do not know if it is possible to compute
the exact distribution of the Wilcoxon rank sum statistic, but I think it
is very likely, as the document of `Wilcoxon` says:

This distribution is obtained as follows. Let x and y be two random,
independent samples of size m and n. Then the Wilcoxon rank sum statistic
is the number of all pairs (x[i], y[j]) for which y[j] is not greater than
x[i]. This statistic takes values between 0 and m * n, and its mean and
variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.

As a nice feature of the non-parametric statistic, it is usually
distribution-free so you can pick any distribution you like to compute the
same statistic. I wonder if this is the case, but I might be wrong.

Cheers,
Jiefei


On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>
>
> On 2021-3-19 9:52 AM, Jiefei Wang wrote:
> > After digging into the R source, it turns out that the argument `exact`
> has
> > nothing to do with the numeric precision. It only affects the statistic
> > model used to compute the p-value. When `exact=TRUE` the true
> distribution
> > of the statistic will be used. Otherwise, a normal approximation will be
> > used.
> >
> > I think the documentation needs to be improved here, you can compute the
> > exact p-value *only* when you do not have any ties in your data. If you
> > have ties in your data you will get the p-value from the normal
> > approximation no matter what value you put in `exact`. This behavior
> should
> > be documented or a warning should be given when `exact=TRUE` and ties
> > present.
> >
> > FYI, if the exact p-value is required, `pwilcox` function will be used to
> > compute the p-value. There are no details on how it computes the pvalue
> but
> > its C code seems to compute the probability table, so I assume it
> computes
> > the exact p-value from the true distribution of the statistic, not a
> > permutation or MC p-value.
>
>
>        My example shows that it does NOT use Monte Carlo, because
> otherwise it uses some distribution.  I believe the term "exact" means
> that it uses the permutation distribution, though I could be mistaken.
> If it's NOT a permutation distribution, I don't know what it is.
>
>
>        Spencer
> >
> > Best,
> > Jiefei
> >
> >
> >
> > On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> >> Hey,
> >>
> >> I just want to point out that the word "exact" has two meanings. It can
> >> mean the numerically accurate p-value as Bogdan asked in his first
> email,
> >> or it could mean the p-value calculated from the exact distribution of
> the
> >> statistic(In this case, U stat). These two are actually not related,
> even
> >> though they all called "exact".
> >>
> >> Best,
> >> Jiefei
> >>
> >> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
> >> spencer.graves at effectivedefense.org> wrote:
> >>
> >>>
> >>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
> >>>> thanks a lot, Vivek ! in other words, assuming that we work with 1000
> >>> data
> >>>> points,
> >>>>
> >>>> shall we use EXACT = TRUE, it uses the normal approximation,
> >>>>
> >>>> while if EXACT=FALSE (for these large samples), it does not ?
> >>>
> >>>         As David Winsemius noted, the documentation is not clear.
> >>> Consider the following:
> >>>
> >>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > > wilcox.test(x,
> >>> y)$p.value
> >>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
> >>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x,
> >>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
> >>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
> >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
> >>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
> >>> approximation, which is the same as exact=FALSE. I think that with
> >>> exact=FALSE, you get a permutation distribution, though I'm not sure.
> >>> You might try looking at "wilcox_test in package coin for exact,
> >>> asymptotic and Monte Carlo conditional p-values, including in the
> >>> presence of ties" to see if it is clearer. NOTE: R is case sensitive,
> so
> >>> "EXACT" is a different variable from "exact". It is interpreted as an
> >>> optional argument, which is not recognized and therefore ignored in
> this
> >>> context.
> >>>            Hope this helps.
> >>>            Spencer
> >>>
> >>>
> >>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com>
> wrote:
> >>>>
> >>>>> Hi Bogdan,
> >>>>>
> >>>>> You can also get the information from the link of the Wilcox.test
> >>> function
> >>>>> page.
> >>>>>
> >>>>> ?By default (if exact is not specified), an exact p-value is computed
> >>> if
> >>>>> the samples contain less than 50 finite values and there are no ties.
> >>>>> Otherwise, a normal approximation is used.?
> >>>>>
> >>>>> For more:
> >>>>>
> >>>>>
> >>>
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
> >>>>> Hope this helps!
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>> VD
> >>>>>
> >>>>>
> >>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
> >>> wrote:
> >>>>>> Dear Peter, thanks a lot. yes, we can see a very precise p-value,
> and
> >>> that
> >>>>>> was the request from the journal.
> >>>>>>
> >>>>>> if I may ask another question please : what is the meaning of
> >>> "exact=TRUE"
> >>>>>> or "exact=FALSE" in wilcox.test ?
> >>>>>>
> >>>>>> i can see that the "numerically precise" p-values are different.
> >>> thanks a
> >>>>>> lot !
> >>>>>>
> >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>> tst$p.value
> >>>>>> [1] 8.535524e-25
> >>>>>>
> >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
> >>>>>> tst$p.value
> >>>>>> [1] 3.448211e-25
> >>>>>>
> >>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
> >>>>>> peter.langfelder at gmail.com> wrote:
> >>>>>>
> >>>>>>> I thinnk the answer is much simpler. The print method for
> hypothesis
> >>>>>>> tests (class htest) truncates the p-values. In the above example,
> >>>>>>> instead of using
> >>>>>>>
> >>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>>>
> >>>>>>> and copying the output, just print the p-value:
> >>>>>>>
> >>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>>> tst$p.value
> >>>>>>>
> >>>>>>> [1] 2.988368e-32
> >>>>>>>
> >>>>>>>
> >>>>>>> I think this value is what the journal asks for.
> >>>>>>>
> >>>>>>> HTH,
> >>>>>>>
> >>>>>>> Peter
> >>>>>>>
> >>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
> >>>>>>> <spencer.graves at effectivedefense.org> wrote:
> >>>>>>>>          I would push back on that from two perspectives:
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>                1.  I would study exactly what the journal said
> very
> >>>>>>>> carefully.  If they mandated "wilcox.test", that function has an
> >>>>>>>> argument called "exact".  If that's what they are asking, then
> using
> >>>>>>>> that argument gives the exact p-value, e.g.:
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>    > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>>>>
> >>>>>>>>            Wilcoxon rank sum exact test
> >>>>>>>>
> >>>>>>>> data:  rnorm(100) and rnorm(100, 2)
> >>>>>>>> W = 691, p-value < 2.2e-16
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>                2.  If that's NOT what they are asking, then I'm
> not
> >>>>>>>> convinced what they are asking makes sense:  There is is no such
> >>> thing
> >>>>>>>> as an "exact p value" except to the extent that certain
> assumptions
> >>>>>>>> hold, and all models are wrong (but some are useful), as George
> Box
> >>>>>>>> famously said years ago.[1]  Truth only exists in mathematics, and
> >>>>>>>> that's because it's a fiction to start with ;-)
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>          Hope this helps.
> >>>>>>>>          Spencer Graves
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> [1]
> >>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> >>>>>>>>>     <
> >>>
> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
> >>>>>>>>> Dear all,
> >>>>>>>>>
> >>>>>>>>> i would appreciate having your advice on the following please :
> >>>>>>>>>
> >>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
> >>>>>> compare
> >>>>>>>>> sets of 1000 genes expression (in the genomics field).
> >>>>>>>>>
> >>>>>>>>> however, the journal asks us to provide the exact p value ...
> >>>>>>>>>
> >>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
> >>>>>>>>>
> >>>>>>>>> -- bogdan
> >>>>>>>>>
> >>>>>>>>>         [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>           [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>> --
> >>>>> ----------------------------------------------------------
> >>>>>
> >>>>> Vivek Das, PhD
> >>>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Mar 19 17:04:51 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 19 Mar 2021 09:04:51 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
 <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
Message-ID: <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>

I **believe** -- if my old memory still serves-- that the "exact"
specification uses a home grown version of the algorithm to calculate
exact,  or close approximations to the exact, permutation distribution
originally developed by Cyrus Mehta, founder of StatXact software.  Of
course, examining the C code source would determine this, but I don't care
to attempt this.

If this is (no longer?) correct, please point this out.

Best,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 19, 2021 at 8:42 AM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hi Spencer,
>
> Thanks for your test results, I do not know the answer as I haven't
> used wilcox.test for many years. I do not know if it is possible to compute
> the exact distribution of the Wilcoxon rank sum statistic, but I think it
> is very likely, as the document of `Wilcoxon` says:
>
> This distribution is obtained as follows. Let x and y be two random,
> independent samples of size m and n. Then the Wilcoxon rank sum statistic
> is the number of all pairs (x[i], y[j]) for which y[j] is not greater than
> x[i]. This statistic takes values between 0 and m * n, and its mean and
> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
>
> As a nice feature of the non-parametric statistic, it is usually
> distribution-free so you can pick any distribution you like to compute the
> same statistic. I wonder if this is the case, but I might be wrong.
>
> Cheers,
> Jiefei
>
>
> On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
> spencer.graves at effectivedefense.org> wrote:
>
> >
> >
> > On 2021-3-19 9:52 AM, Jiefei Wang wrote:
> > > After digging into the R source, it turns out that the argument `exact`
> > has
> > > nothing to do with the numeric precision. It only affects the statistic
> > > model used to compute the p-value. When `exact=TRUE` the true
> > distribution
> > > of the statistic will be used. Otherwise, a normal approximation will
> be
> > > used.
> > >
> > > I think the documentation needs to be improved here, you can compute
> the
> > > exact p-value *only* when you do not have any ties in your data. If you
> > > have ties in your data you will get the p-value from the normal
> > > approximation no matter what value you put in `exact`. This behavior
> > should
> > > be documented or a warning should be given when `exact=TRUE` and ties
> > > present.
> > >
> > > FYI, if the exact p-value is required, `pwilcox` function will be used
> to
> > > compute the p-value. There are no details on how it computes the pvalue
> > but
> > > its C code seems to compute the probability table, so I assume it
> > computes
> > > the exact p-value from the true distribution of the statistic, not a
> > > permutation or MC p-value.
> >
> >
> >        My example shows that it does NOT use Monte Carlo, because
> > otherwise it uses some distribution.  I believe the term "exact" means
> > that it uses the permutation distribution, though I could be mistaken.
> > If it's NOT a permutation distribution, I don't know what it is.
> >
> >
> >        Spencer
> > >
> > > Best,
> > > Jiefei
> > >
> > >
> > >
> > > On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com>
> wrote:
> > >
> > >> Hey,
> > >>
> > >> I just want to point out that the word "exact" has two meanings. It
> can
> > >> mean the numerically accurate p-value as Bogdan asked in his first
> > email,
> > >> or it could mean the p-value calculated from the exact distribution of
> > the
> > >> statistic(In this case, U stat). These two are actually not related,
> > even
> > >> though they all called "exact".
> > >>
> > >> Best,
> > >> Jiefei
> > >>
> > >> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
> > >> spencer.graves at effectivedefense.org> wrote:
> > >>
> > >>>
> > >>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
> > >>>> thanks a lot, Vivek ! in other words, assuming that we work with
> 1000
> > >>> data
> > >>>> points,
> > >>>>
> > >>>> shall we use EXACT = TRUE, it uses the normal approximation,
> > >>>>
> > >>>> while if EXACT=FALSE (for these large samples), it does not ?
> > >>>
> > >>>         As David Winsemius noted, the documentation is not clear.
> > >>> Consider the following:
> > >>>
> > >>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > >
> wilcox.test(x,
> > >>> y)$p.value
> > >>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
> > >>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 >
> wilcox.test(x,
> > >>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
> > >>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
> > >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
> > >>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
> > >>> approximation, which is the same as exact=FALSE. I think that with
> > >>> exact=FALSE, you get a permutation distribution, though I'm not sure.
> > >>> You might try looking at "wilcox_test in package coin for exact,
> > >>> asymptotic and Monte Carlo conditional p-values, including in the
> > >>> presence of ties" to see if it is clearer. NOTE: R is case sensitive,
> > so
> > >>> "EXACT" is a different variable from "exact". It is interpreted as an
> > >>> optional argument, which is not recognized and therefore ignored in
> > this
> > >>> context.
> > >>>            Hope this helps.
> > >>>            Spencer
> > >>>
> > >>>
> > >>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com>
> > wrote:
> > >>>>
> > >>>>> Hi Bogdan,
> > >>>>>
> > >>>>> You can also get the information from the link of the Wilcox.test
> > >>> function
> > >>>>> page.
> > >>>>>
> > >>>>> ?By default (if exact is not specified), an exact p-value is
> computed
> > >>> if
> > >>>>> the samples contain less than 50 finite values and there are no
> ties.
> > >>>>> Otherwise, a normal approximation is used.?
> > >>>>>
> > >>>>> For more:
> > >>>>>
> > >>>>>
> > >>>
> >
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
> > >>>>> Hope this helps!
> > >>>>>
> > >>>>> Best,
> > >>>>>
> > >>>>> VD
> > >>>>>
> > >>>>>
> > >>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
> > >>> wrote:
> > >>>>>> Dear Peter, thanks a lot. yes, we can see a very precise p-value,
> > and
> > >>> that
> > >>>>>> was the request from the journal.
> > >>>>>>
> > >>>>>> if I may ask another question please : what is the meaning of
> > >>> "exact=TRUE"
> > >>>>>> or "exact=FALSE" in wilcox.test ?
> > >>>>>>
> > >>>>>> i can see that the "numerically precise" p-values are different.
> > >>> thanks a
> > >>>>>> lot !
> > >>>>>>
> > >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>> tst$p.value
> > >>>>>> [1] 8.535524e-25
> > >>>>>>
> > >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
> > >>>>>> tst$p.value
> > >>>>>> [1] 3.448211e-25
> > >>>>>>
> > >>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
> > >>>>>> peter.langfelder at gmail.com> wrote:
> > >>>>>>
> > >>>>>>> I thinnk the answer is much simpler. The print method for
> > hypothesis
> > >>>>>>> tests (class htest) truncates the p-values. In the above example,
> > >>>>>>> instead of using
> > >>>>>>>
> > >>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>>>
> > >>>>>>> and copying the output, just print the p-value:
> > >>>>>>>
> > >>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>>> tst$p.value
> > >>>>>>>
> > >>>>>>> [1] 2.988368e-32
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> I think this value is what the journal asks for.
> > >>>>>>>
> > >>>>>>> HTH,
> > >>>>>>>
> > >>>>>>> Peter
> > >>>>>>>
> > >>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
> > >>>>>>> <spencer.graves at effectivedefense.org> wrote:
> > >>>>>>>>          I would push back on that from two perspectives:
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>>                1.  I would study exactly what the journal said
> > very
> > >>>>>>>> carefully.  If they mandated "wilcox.test", that function has an
> > >>>>>>>> argument called "exact".  If that's what they are asking, then
> > using
> > >>>>>>>> that argument gives the exact p-value, e.g.:
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>>    > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>>>>
> > >>>>>>>>            Wilcoxon rank sum exact test
> > >>>>>>>>
> > >>>>>>>> data:  rnorm(100) and rnorm(100, 2)
> > >>>>>>>> W = 691, p-value < 2.2e-16
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>>                2.  If that's NOT what they are asking, then I'm
> > not
> > >>>>>>>> convinced what they are asking makes sense:  There is is no such
> > >>> thing
> > >>>>>>>> as an "exact p value" except to the extent that certain
> > assumptions
> > >>>>>>>> hold, and all models are wrong (but some are useful), as George
> > Box
> > >>>>>>>> famously said years ago.[1]  Truth only exists in mathematics,
> and
> > >>>>>>>> that's because it's a fiction to start with ;-)
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>>          Hope this helps.
> > >>>>>>>>          Spencer Graves
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>> [1]
> > >>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> > >>>>>>>>>     <
> > >>>
> > https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
> > >>>>>>>>> Dear all,
> > >>>>>>>>>
> > >>>>>>>>> i would appreciate having your advice on the following please :
> > >>>>>>>>>
> > >>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when we
> > >>>>>> compare
> > >>>>>>>>> sets of 1000 genes expression (in the genomics field).
> > >>>>>>>>>
> > >>>>>>>>> however, the journal asks us to provide the exact p value ...
> > >>>>>>>>>
> > >>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a lot,
> > >>>>>>>>>
> > >>>>>>>>> -- bogdan
> > >>>>>>>>>
> > >>>>>>>>>         [[alternative HTML version deleted]]
> > >>>>>>>>>
> > >>>>>>>>> ______________________________________________
> > >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > see
> > >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>>> PLEASE do read the posting guide
> > >>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> > code.
> > >>>>>>>> ______________________________________________
> > >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>> PLEASE do read the posting guide
> > >>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> > >>>>>>           [[alternative HTML version deleted]]
> > >>>>>>
> > >>>>>> ______________________________________________
> > >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>> PLEASE do read the posting guide
> > >>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>>>>
> > >>>>> --
> > >>>>> ----------------------------------------------------------
> > >>>>>
> > >>>>> Vivek Das, PhD
> > >>>>>
> > >>>>        [[alternative HTML version deleted]]
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide
> > >>> http://www.R-project.org/posting-guide.html
> > >>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>>          [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >>> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Fri Mar 19 17:34:34 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Fri, 19 Mar 2021 16:34:34 +0000
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGiFhPMVN+j-9178WDqTQCj5m_mkjyMd7ekig7Nu-z=oy6rWFg@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <1355e688b3c54b0fa9ef751b90ecdd11@UM-MAIL3214.unimaas.nl>
 <CAGiFhPMVN+j-9178WDqTQCj5m_mkjyMd7ekig7Nu-z=oy6rWFg@mail.gmail.com>
Message-ID: <290bad605c314e5e8fbfc53eae1e6615@UM-MAIL3214.unimaas.nl>

For me, it was always clear based on the documentation that if there are ties, then the normal approximation is used (irrespective of what 'exact' is set to). In fact, if there are ties, the output even tells you that this is happening:

wilcox.test(c(1,3,2,2,4), exact=TRUE)

[...]
Warning message:
In wilcox.test.default(c(1, 3, 2, 2, 4), exact = TRUE) :
  cannot compute exact p-value with ties

Best,
Wolfgang

>-----Original Message-----
>From: Jiefei Wang [mailto:szwjf08 at gmail.com]
>Sent: Friday, 19 March, 2021 16:32
>To: Viechtbauer, Wolfgang (SP)
>Cc: r-help
>Subject: Re: [R] about a p-value < 2.2e-16
>
>Dear?Wolfgang,
>
>Thanks for the documentation, but the document only states the default behavior,
>it does not mention what would happen if we tell it to compute the exact p-value
>but the data has ties. I think this would be misleading as people might think
>their result is exact by specifying `exact=TRUE` but the truth is that their data
>contains ties and the result is from the normal approximation.
>
>Best,
>Jiefei
>
>On Fri, Mar 19, 2021 at 11:18 PM Viechtbauer, Wolfgang (SP)
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>Dear Jiefei,
>
>This behavior is documented. From help(wilcox.test):
>
>"By default (if exact is not specified), an exact p-value is computed if the
>samples contain less than 50 finite values and there are no ties. Otherwise, a
>normal approximation is used."
>
>Best,
>Wolfgang
>
>>-----Original Message-----
>>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jiefei Wang
>>Sent: Friday, 19 March, 2021 15:52
>>To: Spencer Graves
>>Cc: r-help; Bogdan Tanasa
>>Subject: Re: [R] about a p-value < 2.2e-16
>>
>>After digging into the R source, it turns out that the argument `exact` has
>>nothing to do with the numeric precision. It only affects the statistic
>>model used to compute the p-value. When `exact=TRUE` the true distribution
>>of the statistic will be used. Otherwise, a normal approximation will be
>>used.
>>
>>I think the documentation needs to be improved here, you can compute the
>>exact p-value *only* when you do not have any ties in your data. If you
>>have ties in your data you will get the p-value from the normal
>>approximation no matter what value you put in `exact`. This behavior should
>>be documented or a warning should be given when `exact=TRUE` and ties
>>present.
>>
>>FYI, if the exact p-value is required, `pwilcox` function will be used to
>>compute the p-value. There are no details on how it computes the pvalue but
>>its C code seems to compute the probability table, so I assume it computes
>>the exact p-value from the true distribution of the statistic, not a
>>permutation or MC p-value.
>>
>>Best,
>>Jiefei

From t@n@@@ @end|ng |rom gm@||@com  Fri Mar 19 18:22:09 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 19 Mar 2021 10:22:09 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
 <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
 <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>
Message-ID: <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>

Dear all, thank you all for comments and help.

as far as i can see, shall we have samples of 1000 records, only
"exact=FALSE" allows the code to run:

wilcox.test(rnorm(1000), rnorm(1000, 2), exact=FALSE)$p.value
[1] 7.304863e-231

shall i use "exact=TRUE", it runs out of memory on my 64GB RAM PC :

wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
(the job is terminated by OS)

shall you have any other suggestions, please let me know. thanks a lot !

On Fri, Mar 19, 2021 at 9:05 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I **believe** -- if my old memory still serves-- that the "exact"
> specification uses a home grown version of the algorithm to calculate
> exact,  or close approximations to the exact, permutation distribution
> originally developed by Cyrus Mehta, founder of StatXact software.  Of
> course, examining the C code source would determine this, but I don't care
> to attempt this.
>
> If this is (no longer?) correct, please point this out.
>
> Best,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Mar 19, 2021 at 8:42 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>
>> Hi Spencer,
>>
>> Thanks for your test results, I do not know the answer as I haven't
>> used wilcox.test for many years. I do not know if it is possible to
>> compute
>> the exact distribution of the Wilcoxon rank sum statistic, but I think it
>> is very likely, as the document of `Wilcoxon` says:
>>
>> This distribution is obtained as follows. Let x and y be two random,
>> independent samples of size m and n. Then the Wilcoxon rank sum statistic
>> is the number of all pairs (x[i], y[j]) for which y[j] is not greater than
>> x[i]. This statistic takes values between 0 and m * n, and its mean and
>> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
>>
>> As a nice feature of the non-parametric statistic, it is usually
>> distribution-free so you can pick any distribution you like to compute the
>> same statistic. I wonder if this is the case, but I might be wrong.
>>
>> Cheers,
>> Jiefei
>>
>>
>> On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
>> spencer.graves at effectivedefense.org> wrote:
>>
>> >
>> >
>> > On 2021-3-19 9:52 AM, Jiefei Wang wrote:
>> > > After digging into the R source, it turns out that the argument
>> `exact`
>> > has
>> > > nothing to do with the numeric precision. It only affects the
>> statistic
>> > > model used to compute the p-value. When `exact=TRUE` the true
>> > distribution
>> > > of the statistic will be used. Otherwise, a normal approximation will
>> be
>> > > used.
>> > >
>> > > I think the documentation needs to be improved here, you can compute
>> the
>> > > exact p-value *only* when you do not have any ties in your data. If
>> you
>> > > have ties in your data you will get the p-value from the normal
>> > > approximation no matter what value you put in `exact`. This behavior
>> > should
>> > > be documented or a warning should be given when `exact=TRUE` and ties
>> > > present.
>> > >
>> > > FYI, if the exact p-value is required, `pwilcox` function will be
>> used to
>> > > compute the p-value. There are no details on how it computes the
>> pvalue
>> > but
>> > > its C code seems to compute the probability table, so I assume it
>> > computes
>> > > the exact p-value from the true distribution of the statistic, not a
>> > > permutation or MC p-value.
>> >
>> >
>> >        My example shows that it does NOT use Monte Carlo, because
>> > otherwise it uses some distribution.  I believe the term "exact" means
>> > that it uses the permutation distribution, though I could be mistaken.
>> > If it's NOT a permutation distribution, I don't know what it is.
>> >
>> >
>> >        Spencer
>> > >
>> > > Best,
>> > > Jiefei
>> > >
>> > >
>> > >
>> > > On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com>
>> wrote:
>> > >
>> > >> Hey,
>> > >>
>> > >> I just want to point out that the word "exact" has two meanings. It
>> can
>> > >> mean the numerically accurate p-value as Bogdan asked in his first
>> > email,
>> > >> or it could mean the p-value calculated from the exact distribution
>> of
>> > the
>> > >> statistic(In this case, U stat). These two are actually not related,
>> > even
>> > >> though they all called "exact".
>> > >>
>> > >> Best,
>> > >> Jiefei
>> > >>
>> > >> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
>> > >> spencer.graves at effectivedefense.org> wrote:
>> > >>
>> > >>>
>> > >>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
>> > >>>> thanks a lot, Vivek ! in other words, assuming that we work with
>> 1000
>> > >>> data
>> > >>>> points,
>> > >>>>
>> > >>>> shall we use EXACT = TRUE, it uses the normal approximation,
>> > >>>>
>> > >>>> while if EXACT=FALSE (for these large samples), it does not ?
>> > >>>
>> > >>>         As David Winsemius noted, the documentation is not clear.
>> > >>> Consider the following:
>> > >>>
>> > >>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > >
>> wilcox.test(x,
>> > >>> y)$p.value
>> > >>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
>> > >>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 >
>> wilcox.test(x,
>> > >>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
>> > >>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
>> > >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
>> > >>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
>> > >>> approximation, which is the same as exact=FALSE. I think that with
>> > >>> exact=FALSE, you get a permutation distribution, though I'm not
>> sure.
>> > >>> You might try looking at "wilcox_test in package coin for exact,
>> > >>> asymptotic and Monte Carlo conditional p-values, including in the
>> > >>> presence of ties" to see if it is clearer. NOTE: R is case
>> sensitive,
>> > so
>> > >>> "EXACT" is a different variable from "exact". It is interpreted as
>> an
>> > >>> optional argument, which is not recognized and therefore ignored in
>> > this
>> > >>> context.
>> > >>>            Hope this helps.
>> > >>>            Spencer
>> > >>>
>> > >>>
>> > >>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com>
>> > wrote:
>> > >>>>
>> > >>>>> Hi Bogdan,
>> > >>>>>
>> > >>>>> You can also get the information from the link of the Wilcox.test
>> > >>> function
>> > >>>>> page.
>> > >>>>>
>> > >>>>> ?By default (if exact is not specified), an exact p-value is
>> computed
>> > >>> if
>> > >>>>> the samples contain less than 50 finite values and there are no
>> ties.
>> > >>>>> Otherwise, a normal approximation is used.?
>> > >>>>>
>> > >>>>> For more:
>> > >>>>>
>> > >>>>>
>> > >>>
>> >
>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>> > >>>>> Hope this helps!
>> > >>>>>
>> > >>>>> Best,
>> > >>>>>
>> > >>>>> VD
>> > >>>>>
>> > >>>>>
>> > >>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
>> > >>> wrote:
>> > >>>>>> Dear Peter, thanks a lot. yes, we can see a very precise p-value,
>> > and
>> > >>> that
>> > >>>>>> was the request from the journal.
>> > >>>>>>
>> > >>>>>> if I may ask another question please : what is the meaning of
>> > >>> "exact=TRUE"
>> > >>>>>> or "exact=FALSE" in wilcox.test ?
>> > >>>>>>
>> > >>>>>> i can see that the "numerically precise" p-values are different.
>> > >>> thanks a
>> > >>>>>> lot !
>> > >>>>>>
>> > >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>> tst$p.value
>> > >>>>>> [1] 8.535524e-25
>> > >>>>>>
>> > >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>> > >>>>>> tst$p.value
>> > >>>>>> [1] 3.448211e-25
>> > >>>>>>
>> > >>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>> > >>>>>> peter.langfelder at gmail.com> wrote:
>> > >>>>>>
>> > >>>>>>> I thinnk the answer is much simpler. The print method for
>> > hypothesis
>> > >>>>>>> tests (class htest) truncates the p-values. In the above
>> example,
>> > >>>>>>> instead of using
>> > >>>>>>>
>> > >>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>>>
>> > >>>>>>> and copying the output, just print the p-value:
>> > >>>>>>>
>> > >>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>>> tst$p.value
>> > >>>>>>>
>> > >>>>>>> [1] 2.988368e-32
>> > >>>>>>>
>> > >>>>>>>
>> > >>>>>>> I think this value is what the journal asks for.
>> > >>>>>>>
>> > >>>>>>> HTH,
>> > >>>>>>>
>> > >>>>>>> Peter
>> > >>>>>>>
>> > >>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>> > >>>>>>> <spencer.graves at effectivedefense.org> wrote:
>> > >>>>>>>>          I would push back on that from two perspectives:
>> > >>>>>>>>
>> > >>>>>>>>
>> > >>>>>>>>                1.  I would study exactly what the journal said
>> > very
>> > >>>>>>>> carefully.  If they mandated "wilcox.test", that function has
>> an
>> > >>>>>>>> argument called "exact".  If that's what they are asking, then
>> > using
>> > >>>>>>>> that argument gives the exact p-value, e.g.:
>> > >>>>>>>>
>> > >>>>>>>>
>> > >>>>>>>>    > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>>>>
>> > >>>>>>>>            Wilcoxon rank sum exact test
>> > >>>>>>>>
>> > >>>>>>>> data:  rnorm(100) and rnorm(100, 2)
>> > >>>>>>>> W = 691, p-value < 2.2e-16
>> > >>>>>>>>
>> > >>>>>>>>
>> > >>>>>>>>                2.  If that's NOT what they are asking, then I'm
>> > not
>> > >>>>>>>> convinced what they are asking makes sense:  There is is no
>> such
>> > >>> thing
>> > >>>>>>>> as an "exact p value" except to the extent that certain
>> > assumptions
>> > >>>>>>>> hold, and all models are wrong (but some are useful), as George
>> > Box
>> > >>>>>>>> famously said years ago.[1]  Truth only exists in mathematics,
>> and
>> > >>>>>>>> that's because it's a fiction to start with ;-)
>> > >>>>>>>>
>> > >>>>>>>>
>> > >>>>>>>>          Hope this helps.
>> > >>>>>>>>          Spencer Graves
>> > >>>>>>>>
>> > >>>>>>>>
>> > >>>>>>>> [1]
>> > >>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>> > >>>>>>>>
>> > >>>>>>>>
>> > >>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>> > >>>>>>>>>     <
>> > >>>
>> > https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>> > >>>>>>>>> Dear all,
>> > >>>>>>>>>
>> > >>>>>>>>> i would appreciate having your advice on the following please
>> :
>> > >>>>>>>>>
>> > >>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when
>> we
>> > >>>>>> compare
>> > >>>>>>>>> sets of 1000 genes expression (in the genomics field).
>> > >>>>>>>>>
>> > >>>>>>>>> however, the journal asks us to provide the exact p value ...
>> > >>>>>>>>>
>> > >>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a
>> lot,
>> > >>>>>>>>>
>> > >>>>>>>>> -- bogdan
>> > >>>>>>>>>
>> > >>>>>>>>>         [[alternative HTML version deleted]]
>> > >>>>>>>>>
>> > >>>>>>>>> ______________________________________________
>> > >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> > see
>> > >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>>>>> PLEASE do read the posting guide
>> > >>>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> > code.
>> > >>>>>>>> ______________________________________________
>> > >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>>>> PLEASE do read the posting guide
>> > >>>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> > >>>>>>           [[alternative HTML version deleted]]
>> > >>>>>>
>> > >>>>>> ______________________________________________
>> > >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>> PLEASE do read the posting guide
>> > >>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> > >>>>>>
>> > >>>>> --
>> > >>>>> ----------------------------------------------------------
>> > >>>>>
>> > >>>>> Vivek Das, PhD
>> > >>>>>
>> > >>>>        [[alternative HTML version deleted]]
>> > >>>>
>> > >>>> ______________________________________________
>> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>> PLEASE do read the posting guide
>> > >>> http://www.R-project.org/posting-guide.html
>> > >>>> and provide commented, minimal, self-contained, reproducible code.
>> > >>>
>> > >>>          [[alternative HTML version deleted]]
>> > >>>
>> > >>> ______________________________________________
>> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>> PLEASE do read the posting guide
>> > >>> http://www.R-project.org/posting-guide.html
>> > >>> and provide commented, minimal, self-contained, reproducible code.
>> > >>>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Fri Mar 19 19:10:43 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Fri, 19 Mar 2021 18:10:43 +0000
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
 <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
 <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>
 <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>
Message-ID: <A480EB2B-6F79-4C37-8ACF-54081FBC13D1@utoronto.ca>

I have to ask since. Are you sure the journal simply means by exact p-value that they don?t want to see a p-value given as < 0.0001, for example, and simply want the actual number?

I cannot imagine they really meant exact as in the p-value from some exact distribution.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

> On Mar 19, 2021, at 1:22 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> 
> EXTERNAL EMAIL:
> 
> Dear all, thank you all for comments and help.
> 
> as far as i can see, shall we have samples of 1000 records, only
> "exact=FALSE" allows the code to run:
> 
> wilcox.test(rnorm(1000), rnorm(1000, 2), exact=FALSE)$p.value
> [1] 7.304863e-231
> 
> shall i use "exact=TRUE", it runs out of memory on my 64GB RAM PC :
> 
> wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
> (the job is terminated by OS)
> 
> shall you have any other suggestions, please let me know. thanks a lot !
> 
> On Fri, Mar 19, 2021 at 9:05 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> I **believe** -- if my old memory still serves-- that the "exact"
>> specification uses a home grown version of the algorithm to calculate
>> exact,  or close approximations to the exact, permutation distribution
>> originally developed by Cyrus Mehta, founder of StatXact software.  Of
>> course, examining the C code source would determine this, but I don't care
>> to attempt this.
>> 
>> If this is (no longer?) correct, please point this out.
>> 
>> Best,
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Fri, Mar 19, 2021 at 8:42 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>> 
>>> Hi Spencer,
>>> 
>>> Thanks for your test results, I do not know the answer as I haven't
>>> used wilcox.test for many years. I do not know if it is possible to
>>> compute
>>> the exact distribution of the Wilcoxon rank sum statistic, but I think it
>>> is very likely, as the document of `Wilcoxon` says:
>>> 
>>> This distribution is obtained as follows. Let x and y be two random,
>>> independent samples of size m and n. Then the Wilcoxon rank sum statistic
>>> is the number of all pairs (x[i], y[j]) for which y[j] is not greater than
>>> x[i]. This statistic takes values between 0 and m * n, and its mean and
>>> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
>>> 
>>> As a nice feature of the non-parametric statistic, it is usually
>>> distribution-free so you can pick any distribution you like to compute the
>>> same statistic. I wonder if this is the case, but I might be wrong.
>>> 
>>> Cheers,
>>> Jiefei
>>> 
>>> 
>>> On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
>>> spencer.graves at effectivedefense.org> wrote:
>>> 
>>>> 
>>>> 
>>>> On 2021-3-19 9:52 AM, Jiefei Wang wrote:
>>>>> After digging into the R source, it turns out that the argument
>>> `exact`
>>>> has
>>>>> nothing to do with the numeric precision. It only affects the
>>> statistic
>>>>> model used to compute the p-value. When `exact=TRUE` the true
>>>> distribution
>>>>> of the statistic will be used. Otherwise, a normal approximation will
>>> be
>>>>> used.
>>>>> 
>>>>> I think the documentation needs to be improved here, you can compute
>>> the
>>>>> exact p-value *only* when you do not have any ties in your data. If
>>> you
>>>>> have ties in your data you will get the p-value from the normal
>>>>> approximation no matter what value you put in `exact`. This behavior
>>>> should
>>>>> be documented or a warning should be given when `exact=TRUE` and ties
>>>>> present.
>>>>> 
>>>>> FYI, if the exact p-value is required, `pwilcox` function will be
>>> used to
>>>>> compute the p-value. There are no details on how it computes the
>>> pvalue
>>>> but
>>>>> its C code seems to compute the probability table, so I assume it
>>>> computes
>>>>> the exact p-value from the true distribution of the statistic, not a
>>>>> permutation or MC p-value.
>>>> 
>>>> 
>>>>       My example shows that it does NOT use Monte Carlo, because
>>>> otherwise it uses some distribution.  I believe the term "exact" means
>>>> that it uses the permutation distribution, though I could be mistaken.
>>>> If it's NOT a permutation distribution, I don't know what it is.
>>>> 
>>>> 
>>>>       Spencer
>>>>> 
>>>>> Best,
>>>>> Jiefei
>>>>> 
>>>>> 
>>>>> 
>>>>> On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com>
>>> wrote:
>>>>> 
>>>>>> Hey,
>>>>>> 
>>>>>> I just want to point out that the word "exact" has two meanings. It
>>> can
>>>>>> mean the numerically accurate p-value as Bogdan asked in his first
>>>> email,
>>>>>> or it could mean the p-value calculated from the exact distribution
>>> of
>>>> the
>>>>>> statistic(In this case, U stat). These two are actually not related,
>>>> even
>>>>>> though they all called "exact".
>>>>>> 
>>>>>> Best,
>>>>>> Jiefei
>>>>>> 
>>>>>> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
>>>>>> spencer.graves at effectivedefense.org> wrote:
>>>>>> 
>>>>>>> 
>>>>>>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
>>>>>>>> thanks a lot, Vivek ! in other words, assuming that we work with
>>> 1000
>>>>>>> data
>>>>>>>> points,
>>>>>>>> 
>>>>>>>> shall we use EXACT = TRUE, it uses the normal approximation,
>>>>>>>> 
>>>>>>>> while if EXACT=FALSE (for these large samples), it does not ?
>>>>>>> 
>>>>>>>        As David Winsemius noted, the documentation is not clear.
>>>>>>> Consider the following:
>>>>>>> 
>>>>>>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > >
>>> wilcox.test(x,
>>>>>>> y)$p.value
>>>>>>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
>>>>>>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 >
>>> wilcox.test(x,
>>>>>>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
>>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
>>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
>>>>>>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the normal
>>>>>>> approximation, which is the same as exact=FALSE. I think that with
>>>>>>> exact=FALSE, you get a permutation distribution, though I'm not
>>> sure.
>>>>>>> You might try looking at "wilcox_test in package coin for exact,
>>>>>>> asymptotic and Monte Carlo conditional p-values, including in the
>>>>>>> presence of ties" to see if it is clearer. NOTE: R is case
>>> sensitive,
>>>> so
>>>>>>> "EXACT" is a different variable from "exact". It is interpreted as
>>> an
>>>>>>> optional argument, which is not recognized and therefore ignored in
>>>> this
>>>>>>> context.
>>>>>>>           Hope this helps.
>>>>>>>           Spencer
>>>>>>> 
>>>>>>> 
>>>>>>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com>
>>>> wrote:
>>>>>>>> 
>>>>>>>>> Hi Bogdan,
>>>>>>>>> 
>>>>>>>>> You can also get the information from the link of the Wilcox.test
>>>>>>> function
>>>>>>>>> page.
>>>>>>>>> 
>>>>>>>>> ?By default (if exact is not specified), an exact p-value is
>>> computed
>>>>>>> if
>>>>>>>>> the samples contain less than 50 finite values and there are no
>>> ties.
>>>>>>>>> Otherwise, a normal approximation is used.?
>>>>>>>>> 
>>>>>>>>> For more:
>>>>>>>>> 
>>>>>>>>> 
>>>>>>> 
>>>> 
>>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>>>>>>>>> Hope this helps!
>>>>>>>>> 
>>>>>>>>> Best,
>>>>>>>>> 
>>>>>>>>> VD
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com>
>>>>>>> wrote:
>>>>>>>>>> Dear Peter, thanks a lot. yes, we can see a very precise p-value,
>>>> and
>>>>>>> that
>>>>>>>>>> was the request from the journal.
>>>>>>>>>> 
>>>>>>>>>> if I may ask another question please : what is the meaning of
>>>>>>> "exact=TRUE"
>>>>>>>>>> or "exact=FALSE" in wilcox.test ?
>>>>>>>>>> 
>>>>>>>>>> i can see that the "numerically precise" p-values are different.
>>>>>>> thanks a
>>>>>>>>>> lot !
>>>>>>>>>> 
>>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>>>>>> tst$p.value
>>>>>>>>>> [1] 8.535524e-25
>>>>>>>>>> 
>>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>>>>>>>>>> tst$p.value
>>>>>>>>>> [1] 3.448211e-25
>>>>>>>>>> 
>>>>>>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>>>>>>>>>> peter.langfelder at gmail.com> wrote:
>>>>>>>>>> 
>>>>>>>>>>> I thinnk the answer is much simpler. The print method for
>>>> hypothesis
>>>>>>>>>>> tests (class htest) truncates the p-values. In the above
>>> example,
>>>>>>>>>>> instead of using
>>>>>>>>>>> 
>>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>>>>>>> 
>>>>>>>>>>> and copying the output, just print the p-value:
>>>>>>>>>>> 
>>>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>>>>>>> tst$p.value
>>>>>>>>>>> 
>>>>>>>>>>> [1] 2.988368e-32
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> I think this value is what the journal asks for.
>>>>>>>>>>> 
>>>>>>>>>>> HTH,
>>>>>>>>>>> 
>>>>>>>>>>> Peter
>>>>>>>>>>> 
>>>>>>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>>>>>>>>>>> <spencer.graves at effectivedefense.org> wrote:
>>>>>>>>>>>>         I would push back on that from two perspectives:
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>>               1.  I would study exactly what the journal said
>>>> very
>>>>>>>>>>>> carefully.  If they mandated "wilcox.test", that function has
>>> an
>>>>>>>>>>>> argument called "exact".  If that's what they are asking, then
>>>> using
>>>>>>>>>>>> that argument gives the exact p-value, e.g.:
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>>>>>>>>>>> 
>>>>>>>>>>>>           Wilcoxon rank sum exact test
>>>>>>>>>>>> 
>>>>>>>>>>>> data:  rnorm(100) and rnorm(100, 2)
>>>>>>>>>>>> W = 691, p-value < 2.2e-16
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>>               2.  If that's NOT what they are asking, then I'm
>>>> not
>>>>>>>>>>>> convinced what they are asking makes sense:  There is is no
>>> such
>>>>>>> thing
>>>>>>>>>>>> as an "exact p value" except to the extent that certain
>>>> assumptions
>>>>>>>>>>>> hold, and all models are wrong (but some are useful), as George
>>>> Box
>>>>>>>>>>>> famously said years ago.[1]  Truth only exists in mathematics,
>>> and
>>>>>>>>>>>> that's because it's a fiction to start with ;-)
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>>         Hope this helps.
>>>>>>>>>>>>         Spencer Graves
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> [1]
>>>>>>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>>>>>>>>>>>> 
>>>>>>>>>>>> 
>>>>>>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>>>>>>>>>>>>>    <
>>>>>>> 
>>>> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>>>>>>>>>>>>> Dear all,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> i would appreciate having your advice on the following please
>>> :
>>>>>>>>>>>>> 
>>>>>>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when
>>> we
>>>>>>>>>> compare
>>>>>>>>>>>>> sets of 1000 genes expression (in the genomics field).
>>>>>>>>>>>>> 
>>>>>>>>>>>>> however, the journal asks us to provide the exact p value ...
>>>>>>>>>>>>> 
>>>>>>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a
>>> lot,
>>>>>>>>>>>>> 
>>>>>>>>>>>>> -- bogdan
>>>>>>>>>>>>> 
>>>>>>>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>>>>>>> 
>>>>>>>>>>>>> ______________________________________________
>>>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see
>>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>>>>>>>>>> ______________________________________________
>>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>>>> 
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>>>>> 
>>>>>>>>> --
>>>>>>>>> ----------------------------------------------------------
>>>>>>>>> 
>>>>>>>>> Vivek Das, PhD
>>>>>>>>> 
>>>>>>>>       [[alternative HTML version deleted]]
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>> 
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From t@n@@@ @end|ng |rom gm@||@com  Fri Mar 19 19:39:08 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 19 Mar 2021 11:39:08 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <A480EB2B-6F79-4C37-8ACF-54081FBC13D1@utoronto.ca>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
 <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
 <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>
 <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>
 <A480EB2B-6F79-4C37-8ACF-54081FBC13D1@utoronto.ca>
Message-ID: <CA+JEM01TEREONeqYoHw59fPPv_YWYhVHJNm1ONu+y64vf00f_A@mail.gmail.com>

Thank you Kevin, their wording is "Please note that the exact p value
should be provided, when possible, etc"

by "exact p-value" i believe that they do mean indeed the actual number,
and not to specify "exact=TRUE" ;

as we are working with 1000 genes, shall i specify "exact=TRUE" on my PC,
it runs out of memory ...

wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value

On Fri, Mar 19, 2021 at 11:10 AM Kevin Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> I have to ask since. Are you sure the journal simply means by exact
> p-value that they don?t want to see a p-value given as < 0.0001, for
> example, and simply want the actual number?
>
> I cannot imagine they really meant exact as in the p-value from some exact
> distribution.
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> > On Mar 19, 2021, at 1:22 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >
> > EXTERNAL EMAIL:
> >
> > Dear all, thank you all for comments and help.
> >
> > as far as i can see, shall we have samples of 1000 records, only
> > "exact=FALSE" allows the code to run:
> >
> > wilcox.test(rnorm(1000), rnorm(1000, 2), exact=FALSE)$p.value
> > [1] 7.304863e-231
> >
> > shall i use "exact=TRUE", it runs out of memory on my 64GB RAM PC :
> >
> > wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
> > (the job is terminated by OS)
> >
> > shall you have any other suggestions, please let me know. thanks a lot !
> >
> > On Fri, Mar 19, 2021 at 9:05 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> I **believe** -- if my old memory still serves-- that the "exact"
> >> specification uses a home grown version of the algorithm to calculate
> >> exact,  or close approximations to the exact, permutation distribution
> >> originally developed by Cyrus Mehta, founder of StatXact software.  Of
> >> course, examining the C code source would determine this, but I don't
> care
> >> to attempt this.
> >>
> >> If this is (no longer?) correct, please point this out.
> >>
> >> Best,
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Fri, Mar 19, 2021 at 8:42 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >>
> >>> Hi Spencer,
> >>>
> >>> Thanks for your test results, I do not know the answer as I haven't
> >>> used wilcox.test for many years. I do not know if it is possible to
> >>> compute
> >>> the exact distribution of the Wilcoxon rank sum statistic, but I think
> it
> >>> is very likely, as the document of `Wilcoxon` says:
> >>>
> >>> This distribution is obtained as follows. Let x and y be two random,
> >>> independent samples of size m and n. Then the Wilcoxon rank sum
> statistic
> >>> is the number of all pairs (x[i], y[j]) for which y[j] is not greater
> than
> >>> x[i]. This statistic takes values between 0 and m * n, and its mean and
> >>> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
> >>>
> >>> As a nice feature of the non-parametric statistic, it is usually
> >>> distribution-free so you can pick any distribution you like to compute
> the
> >>> same statistic. I wonder if this is the case, but I might be wrong.
> >>>
> >>> Cheers,
> >>> Jiefei
> >>>
> >>>
> >>> On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
> >>> spencer.graves at effectivedefense.org> wrote:
> >>>
> >>>>
> >>>>
> >>>> On 2021-3-19 9:52 AM, Jiefei Wang wrote:
> >>>>> After digging into the R source, it turns out that the argument
> >>> `exact`
> >>>> has
> >>>>> nothing to do with the numeric precision. It only affects the
> >>> statistic
> >>>>> model used to compute the p-value. When `exact=TRUE` the true
> >>>> distribution
> >>>>> of the statistic will be used. Otherwise, a normal approximation will
> >>> be
> >>>>> used.
> >>>>>
> >>>>> I think the documentation needs to be improved here, you can compute
> >>> the
> >>>>> exact p-value *only* when you do not have any ties in your data. If
> >>> you
> >>>>> have ties in your data you will get the p-value from the normal
> >>>>> approximation no matter what value you put in `exact`. This behavior
> >>>> should
> >>>>> be documented or a warning should be given when `exact=TRUE` and ties
> >>>>> present.
> >>>>>
> >>>>> FYI, if the exact p-value is required, `pwilcox` function will be
> >>> used to
> >>>>> compute the p-value. There are no details on how it computes the
> >>> pvalue
> >>>> but
> >>>>> its C code seems to compute the probability table, so I assume it
> >>>> computes
> >>>>> the exact p-value from the true distribution of the statistic, not a
> >>>>> permutation or MC p-value.
> >>>>
> >>>>
> >>>>       My example shows that it does NOT use Monte Carlo, because
> >>>> otherwise it uses some distribution.  I believe the term "exact" means
> >>>> that it uses the permutation distribution, though I could be mistaken.
> >>>> If it's NOT a permutation distribution, I don't know what it is.
> >>>>
> >>>>
> >>>>       Spencer
> >>>>>
> >>>>> Best,
> >>>>> Jiefei
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com>
> >>> wrote:
> >>>>>
> >>>>>> Hey,
> >>>>>>
> >>>>>> I just want to point out that the word "exact" has two meanings. It
> >>> can
> >>>>>> mean the numerically accurate p-value as Bogdan asked in his first
> >>>> email,
> >>>>>> or it could mean the p-value calculated from the exact distribution
> >>> of
> >>>> the
> >>>>>> statistic(In this case, U stat). These two are actually not related,
> >>>> even
> >>>>>> though they all called "exact".
> >>>>>>
> >>>>>> Best,
> >>>>>> Jiefei
> >>>>>>
> >>>>>> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
> >>>>>> spencer.graves at effectivedefense.org> wrote:
> >>>>>>
> >>>>>>>
> >>>>>>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
> >>>>>>>> thanks a lot, Vivek ! in other words, assuming that we work with
> >>> 1000
> >>>>>>> data
> >>>>>>>> points,
> >>>>>>>>
> >>>>>>>> shall we use EXACT = TRUE, it uses the normal approximation,
> >>>>>>>>
> >>>>>>>> while if EXACT=FALSE (for these large samples), it does not ?
> >>>>>>>
> >>>>>>>        As David Winsemius noted, the documentation is not clear.
> >>>>>>> Consider the following:
> >>>>>>>
> >>>>>>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > >
> >>> wilcox.test(x,
> >>>>>>> y)$p.value
> >>>>>>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
> >>>>>>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 >
> >>> wilcox.test(x,
> >>>>>>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
> >>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
> >>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> >>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
> >>>>>>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the
> normal
> >>>>>>> approximation, which is the same as exact=FALSE. I think that with
> >>>>>>> exact=FALSE, you get a permutation distribution, though I'm not
> >>> sure.
> >>>>>>> You might try looking at "wilcox_test in package coin for exact,
> >>>>>>> asymptotic and Monte Carlo conditional p-values, including in the
> >>>>>>> presence of ties" to see if it is clearer. NOTE: R is case
> >>> sensitive,
> >>>> so
> >>>>>>> "EXACT" is a different variable from "exact". It is interpreted as
> >>> an
> >>>>>>> optional argument, which is not recognized and therefore ignored in
> >>>> this
> >>>>>>> context.
> >>>>>>>           Hope this helps.
> >>>>>>>           Spencer
> >>>>>>>
> >>>>>>>
> >>>>>>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com>
> >>>> wrote:
> >>>>>>>>
> >>>>>>>>> Hi Bogdan,
> >>>>>>>>>
> >>>>>>>>> You can also get the information from the link of the Wilcox.test
> >>>>>>> function
> >>>>>>>>> page.
> >>>>>>>>>
> >>>>>>>>> ?By default (if exact is not specified), an exact p-value is
> >>> computed
> >>>>>>> if
> >>>>>>>>> the samples contain less than 50 finite values and there are no
> >>> ties.
> >>>>>>>>> Otherwise, a normal approximation is used.?
> >>>>>>>>>
> >>>>>>>>> For more:
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>
> >>>>
> >>>
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
> >>>>>>>>> Hope this helps!
> >>>>>>>>>
> >>>>>>>>> Best,
> >>>>>>>>>
> >>>>>>>>> VD
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com
> >
> >>>>>>> wrote:
> >>>>>>>>>> Dear Peter, thanks a lot. yes, we can see a very precise
> p-value,
> >>>> and
> >>>>>>> that
> >>>>>>>>>> was the request from the journal.
> >>>>>>>>>>
> >>>>>>>>>> if I may ask another question please : what is the meaning of
> >>>>>>> "exact=TRUE"
> >>>>>>>>>> or "exact=FALSE" in wilcox.test ?
> >>>>>>>>>>
> >>>>>>>>>> i can see that the "numerically precise" p-values are different.
> >>>>>>> thanks a
> >>>>>>>>>> lot !
> >>>>>>>>>>
> >>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>>>>>> tst$p.value
> >>>>>>>>>> [1] 8.535524e-25
> >>>>>>>>>>
> >>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
> >>>>>>>>>> tst$p.value
> >>>>>>>>>> [1] 3.448211e-25
> >>>>>>>>>>
> >>>>>>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
> >>>>>>>>>> peter.langfelder at gmail.com> wrote:
> >>>>>>>>>>
> >>>>>>>>>>> I thinnk the answer is much simpler. The print method for
> >>>> hypothesis
> >>>>>>>>>>> tests (class htest) truncates the p-values. In the above
> >>> example,
> >>>>>>>>>>> instead of using
> >>>>>>>>>>>
> >>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>>>>>>>
> >>>>>>>>>>> and copying the output, just print the p-value:
> >>>>>>>>>>>
> >>>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>>>>>>> tst$p.value
> >>>>>>>>>>>
> >>>>>>>>>>> [1] 2.988368e-32
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>> I think this value is what the journal asks for.
> >>>>>>>>>>>
> >>>>>>>>>>> HTH,
> >>>>>>>>>>>
> >>>>>>>>>>> Peter
> >>>>>>>>>>>
> >>>>>>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
> >>>>>>>>>>> <spencer.graves at effectivedefense.org> wrote:
> >>>>>>>>>>>>         I would push back on that from two perspectives:
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>               1.  I would study exactly what the journal said
> >>>> very
> >>>>>>>>>>>> carefully.  If they mandated "wilcox.test", that function has
> >>> an
> >>>>>>>>>>>> argument called "exact".  If that's what they are asking, then
> >>>> using
> >>>>>>>>>>>> that argument gives the exact p-value, e.g.:
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> >>>>>>>>>>>>
> >>>>>>>>>>>>           Wilcoxon rank sum exact test
> >>>>>>>>>>>>
> >>>>>>>>>>>> data:  rnorm(100) and rnorm(100, 2)
> >>>>>>>>>>>> W = 691, p-value < 2.2e-16
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>               2.  If that's NOT what they are asking, then I'm
> >>>> not
> >>>>>>>>>>>> convinced what they are asking makes sense:  There is is no
> >>> such
> >>>>>>> thing
> >>>>>>>>>>>> as an "exact p value" except to the extent that certain
> >>>> assumptions
> >>>>>>>>>>>> hold, and all models are wrong (but some are useful), as
> George
> >>>> Box
> >>>>>>>>>>>> famously said years ago.[1]  Truth only exists in mathematics,
> >>> and
> >>>>>>>>>>>> that's because it's a fiction to start with ;-)
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>>         Hope this helps.
> >>>>>>>>>>>>         Spencer Graves
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>> [1]
> >>>>>>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
> >>>>>>>>>>>>
> >>>>>>>>>>>>
> >>>>>>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> >>>>>>>>>>>>>    <
> >>>>>>>
> >>>>
> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
> >>>>>>>>>>>>> Dear all,
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> i would appreciate having your advice on the following please
> >>> :
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when
> >>> we
> >>>>>>>>>> compare
> >>>>>>>>>>>>> sets of 1000 genes expression (in the genomics field).
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> however, the journal asks us to provide the exact p value ...
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a
> >>> lot,
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> -- bogdan
> >>>>>>>>>>>>>
> >>>>>>>>>>>>>        [[alternative HTML version deleted]]
> >>>>>>>>>>>>>
> >>>>>>>>>>>>> ______________________________________________
> >>>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more,
> >>>> see
> >>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>>> code.
> >>>>>>>>>>>> ______________________________________________
> >>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>> see
> >>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>>>>>>>>          [[alternative HTML version deleted]]
> >>>>>>>>>>
> >>>>>>>>>> ______________________________________________
> >>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>> see
> >>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>>>>>>>>
> >>>>>>>>> --
> >>>>>>>>> ----------------------------------------------------------
> >>>>>>>>>
> >>>>>>>>> Vivek Das, PhD
> >>>>>>>>>
> >>>>>>>>       [[alternative HTML version deleted]]
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>
> >>>>>>>         [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>
> >>>>
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Mar 19 19:50:26 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 19 Mar 2021 11:50:26 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
 <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
 <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>
 <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>
Message-ID: <CAGxFJbQho+gWaJZrXUPkFojdGQSrHakDWXvRBrJ1s6MoBWuXOw@mail.gmail.com>

Yes, Bogdan, that sounds *exactly* right.  ;-)  -- it runs out of memory
trying to calculate the exact permutation distribution. What you apparently
get with exact = FALSE is the exact answer( to within floating point
arithmetic's approximation) to a normal approximation.

... and furthermore...
I would imagine any random number below, say, 1e-100 would serve equally
well and would be equally correct/incorrect. I also imagine that a sensible
display of the paired differences  or even just a count of how many of the
thousand are, say, >0, would make even more sense than an overwrought and
unnecessary p-value. But that is just my personal opinion of senseless
standard scientific practice, and if anyone want to dispute it, please
reply OFFLIST, though I would probably not disagree with any such criticism
of my cynicism.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 19, 2021 at 10:22 AM Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all, thank you all for comments and help.
>
> as far as i can see, shall we have samples of 1000 records, only
> "exact=FALSE" allows the code to run:
>
> wilcox.test(rnorm(1000), rnorm(1000, 2), exact=FALSE)$p.value
> [1] 7.304863e-231
>
> shall i use "exact=TRUE", it runs out of memory on my 64GB RAM PC :
>
> wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
> (the job is terminated by OS)
>
> shall you have any other suggestions, please let me know. thanks a lot !
>
> On Fri, Mar 19, 2021 at 9:05 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> I **believe** -- if my old memory still serves-- that the "exact"
>> specification uses a home grown version of the algorithm to calculate
>> exact,  or close approximations to the exact, permutation distribution
>> originally developed by Cyrus Mehta, founder of StatXact software.  Of
>> course, examining the C code source would determine this, but I don't care
>> to attempt this.
>>
>> If this is (no longer?) correct, please point this out.
>>
>> Best,
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Mar 19, 2021 at 8:42 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>>
>>> Hi Spencer,
>>>
>>> Thanks for your test results, I do not know the answer as I haven't
>>> used wilcox.test for many years. I do not know if it is possible to
>>> compute
>>> the exact distribution of the Wilcoxon rank sum statistic, but I think it
>>> is very likely, as the document of `Wilcoxon` says:
>>>
>>> This distribution is obtained as follows. Let x and y be two random,
>>> independent samples of size m and n. Then the Wilcoxon rank sum statistic
>>> is the number of all pairs (x[i], y[j]) for which y[j] is not greater
>>> than
>>> x[i]. This statistic takes values between 0 and m * n, and its mean and
>>> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
>>>
>>> As a nice feature of the non-parametric statistic, it is usually
>>> distribution-free so you can pick any distribution you like to compute
>>> the
>>> same statistic. I wonder if this is the case, but I might be wrong.
>>>
>>> Cheers,
>>> Jiefei
>>>
>>>
>>> On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
>>> spencer.graves at effectivedefense.org> wrote:
>>>
>>> >
>>> >
>>> > On 2021-3-19 9:52 AM, Jiefei Wang wrote:
>>> > > After digging into the R source, it turns out that the argument
>>> `exact`
>>> > has
>>> > > nothing to do with the numeric precision. It only affects the
>>> statistic
>>> > > model used to compute the p-value. When `exact=TRUE` the true
>>> > distribution
>>> > > of the statistic will be used. Otherwise, a normal approximation
>>> will be
>>> > > used.
>>> > >
>>> > > I think the documentation needs to be improved here, you can compute
>>> the
>>> > > exact p-value *only* when you do not have any ties in your data. If
>>> you
>>> > > have ties in your data you will get the p-value from the normal
>>> > > approximation no matter what value you put in `exact`. This behavior
>>> > should
>>> > > be documented or a warning should be given when `exact=TRUE` and ties
>>> > > present.
>>> > >
>>> > > FYI, if the exact p-value is required, `pwilcox` function will be
>>> used to
>>> > > compute the p-value. There are no details on how it computes the
>>> pvalue
>>> > but
>>> > > its C code seems to compute the probability table, so I assume it
>>> > computes
>>> > > the exact p-value from the true distribution of the statistic, not a
>>> > > permutation or MC p-value.
>>> >
>>> >
>>> >        My example shows that it does NOT use Monte Carlo, because
>>> > otherwise it uses some distribution.  I believe the term "exact" means
>>> > that it uses the permutation distribution, though I could be mistaken.
>>> > If it's NOT a permutation distribution, I don't know what it is.
>>> >
>>> >
>>> >        Spencer
>>> > >
>>> > > Best,
>>> > > Jiefei
>>> > >
>>> > >
>>> > >
>>> > > On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com>
>>> wrote:
>>> > >
>>> > >> Hey,
>>> > >>
>>> > >> I just want to point out that the word "exact" has two meanings. It
>>> can
>>> > >> mean the numerically accurate p-value as Bogdan asked in his first
>>> > email,
>>> > >> or it could mean the p-value calculated from the exact distribution
>>> of
>>> > the
>>> > >> statistic(In this case, U stat). These two are actually not related,
>>> > even
>>> > >> though they all called "exact".
>>> > >>
>>> > >> Best,
>>> > >> Jiefei
>>> > >>
>>> > >> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
>>> > >> spencer.graves at effectivedefense.org> wrote:
>>> > >>
>>> > >>>
>>> > >>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
>>> > >>>> thanks a lot, Vivek ! in other words, assuming that we work with
>>> 1000
>>> > >>> data
>>> > >>>> points,
>>> > >>>>
>>> > >>>> shall we use EXACT = TRUE, it uses the normal approximation,
>>> > >>>>
>>> > >>>> while if EXACT=FALSE (for these large samples), it does not ?
>>> > >>>
>>> > >>>         As David Winsemius noted, the documentation is not clear.
>>> > >>> Consider the following:
>>> > >>>
>>> > >>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > >
>>> wilcox.test(x,
>>> > >>> y)$p.value
>>> > >>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
>>> > >>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 >
>>> wilcox.test(x,
>>> > >>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> > >>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
>>> > >>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
>>> > >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> > >>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> > >>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>>> > >>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
>>> > >>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the
>>> normal
>>> > >>> approximation, which is the same as exact=FALSE. I think that with
>>> > >>> exact=FALSE, you get a permutation distribution, though I'm not
>>> sure.
>>> > >>> You might try looking at "wilcox_test in package coin for exact,
>>> > >>> asymptotic and Monte Carlo conditional p-values, including in the
>>> > >>> presence of ties" to see if it is clearer. NOTE: R is case
>>> sensitive,
>>> > so
>>> > >>> "EXACT" is a different variable from "exact". It is interpreted as
>>> an
>>> > >>> optional argument, which is not recognized and therefore ignored in
>>> > this
>>> > >>> context.
>>> > >>>            Hope this helps.
>>> > >>>            Spencer
>>> > >>>
>>> > >>>
>>> > >>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com>
>>> > wrote:
>>> > >>>>
>>> > >>>>> Hi Bogdan,
>>> > >>>>>
>>> > >>>>> You can also get the information from the link of the Wilcox.test
>>> > >>> function
>>> > >>>>> page.
>>> > >>>>>
>>> > >>>>> ?By default (if exact is not specified), an exact p-value is
>>> computed
>>> > >>> if
>>> > >>>>> the samples contain less than 50 finite values and there are no
>>> ties.
>>> > >>>>> Otherwise, a normal approximation is used.?
>>> > >>>>>
>>> > >>>>> For more:
>>> > >>>>>
>>> > >>>>>
>>> > >>>
>>> >
>>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>>> > >>>>> Hope this helps!
>>> > >>>>>
>>> > >>>>> Best,
>>> > >>>>>
>>> > >>>>> VD
>>> > >>>>>
>>> > >>>>>
>>> > >>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <tanasa at gmail.com
>>> >
>>> > >>> wrote:
>>> > >>>>>> Dear Peter, thanks a lot. yes, we can see a very precise
>>> p-value,
>>> > and
>>> > >>> that
>>> > >>>>>> was the request from the journal.
>>> > >>>>>>
>>> > >>>>>> if I may ask another question please : what is the meaning of
>>> > >>> "exact=TRUE"
>>> > >>>>>> or "exact=FALSE" in wilcox.test ?
>>> > >>>>>>
>>> > >>>>>> i can see that the "numerically precise" p-values are different.
>>> > >>> thanks a
>>> > >>>>>> lot !
>>> > >>>>>>
>>> > >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> > >>>>>> tst$p.value
>>> > >>>>>> [1] 8.535524e-25
>>> > >>>>>>
>>> > >>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>>> > >>>>>> tst$p.value
>>> > >>>>>> [1] 3.448211e-25
>>> > >>>>>>
>>> > >>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>>> > >>>>>> peter.langfelder at gmail.com> wrote:
>>> > >>>>>>
>>> > >>>>>>> I thinnk the answer is much simpler. The print method for
>>> > hypothesis
>>> > >>>>>>> tests (class htest) truncates the p-values. In the above
>>> example,
>>> > >>>>>>> instead of using
>>> > >>>>>>>
>>> > >>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> > >>>>>>>
>>> > >>>>>>> and copying the output, just print the p-value:
>>> > >>>>>>>
>>> > >>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> > >>>>>>> tst$p.value
>>> > >>>>>>>
>>> > >>>>>>> [1] 2.988368e-32
>>> > >>>>>>>
>>> > >>>>>>>
>>> > >>>>>>> I think this value is what the journal asks for.
>>> > >>>>>>>
>>> > >>>>>>> HTH,
>>> > >>>>>>>
>>> > >>>>>>> Peter
>>> > >>>>>>>
>>> > >>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>>> > >>>>>>> <spencer.graves at effectivedefense.org> wrote:
>>> > >>>>>>>>          I would push back on that from two perspectives:
>>> > >>>>>>>>
>>> > >>>>>>>>
>>> > >>>>>>>>                1.  I would study exactly what the journal said
>>> > very
>>> > >>>>>>>> carefully.  If they mandated "wilcox.test", that function has
>>> an
>>> > >>>>>>>> argument called "exact".  If that's what they are asking, then
>>> > using
>>> > >>>>>>>> that argument gives the exact p-value, e.g.:
>>> > >>>>>>>>
>>> > >>>>>>>>
>>> > >>>>>>>>    > wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>>> > >>>>>>>>
>>> > >>>>>>>>            Wilcoxon rank sum exact test
>>> > >>>>>>>>
>>> > >>>>>>>> data:  rnorm(100) and rnorm(100, 2)
>>> > >>>>>>>> W = 691, p-value < 2.2e-16
>>> > >>>>>>>>
>>> > >>>>>>>>
>>> > >>>>>>>>                2.  If that's NOT what they are asking, then
>>> I'm
>>> > not
>>> > >>>>>>>> convinced what they are asking makes sense:  There is is no
>>> such
>>> > >>> thing
>>> > >>>>>>>> as an "exact p value" except to the extent that certain
>>> > assumptions
>>> > >>>>>>>> hold, and all models are wrong (but some are useful), as
>>> George
>>> > Box
>>> > >>>>>>>> famously said years ago.[1]  Truth only exists in
>>> mathematics, and
>>> > >>>>>>>> that's because it's a fiction to start with ;-)
>>> > >>>>>>>>
>>> > >>>>>>>>
>>> > >>>>>>>>          Hope this helps.
>>> > >>>>>>>>          Spencer Graves
>>> > >>>>>>>>
>>> > >>>>>>>>
>>> > >>>>>>>> [1]
>>> > >>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>>> > >>>>>>>>
>>> > >>>>>>>>
>>> > >>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>>> > >>>>>>>>>     <
>>> > >>>
>>> >
>>> https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>>> > >>>>>>>>> Dear all,
>>> > >>>>>>>>>
>>> > >>>>>>>>> i would appreciate having your advice on the following
>>> please :
>>> > >>>>>>>>>
>>> > >>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16", when
>>> we
>>> > >>>>>> compare
>>> > >>>>>>>>> sets of 1000 genes expression (in the genomics field).
>>> > >>>>>>>>>
>>> > >>>>>>>>> however, the journal asks us to provide the exact p value ...
>>> > >>>>>>>>>
>>> > >>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a
>>> lot,
>>> > >>>>>>>>>
>>> > >>>>>>>>> -- bogdan
>>> > >>>>>>>>>
>>> > >>>>>>>>>         [[alternative HTML version deleted]]
>>> > >>>>>>>>>
>>> > >>>>>>>>> ______________________________________________
>>> > >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> more,
>>> > see
>>> > >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>>>>>>> PLEASE do read the posting guide
>>> > >>>>>>> http://www.R-project.org/posting-guide.html
>>> > >>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> > code.
>>> > >>>>>>>> ______________________________________________
>>> > >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> more, see
>>> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>>>>>> PLEASE do read the posting guide
>>> > >>>>>>> http://www.R-project.org/posting-guide.html
>>> > >>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>> > >>>>>>           [[alternative HTML version deleted]]
>>> > >>>>>>
>>> > >>>>>> ______________________________________________
>>> > >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>> > >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>>>> PLEASE do read the posting guide
>>> > >>>>>> http://www.R-project.org/posting-guide.html
>>> > >>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>> > >>>>>>
>>> > >>>>> --
>>> > >>>>> ----------------------------------------------------------
>>> > >>>>>
>>> > >>>>> Vivek Das, PhD
>>> > >>>>>
>>> > >>>>        [[alternative HTML version deleted]]
>>> > >>>>
>>> > >>>> ______________________________________________
>>> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>>> PLEASE do read the posting guide
>>> > >>> http://www.R-project.org/posting-guide.html
>>> > >>>> and provide commented, minimal, self-contained, reproducible code.
>>> > >>>
>>> > >>>          [[alternative HTML version deleted]]
>>> > >>>
>>> > >>> ______________________________________________
>>> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >>> PLEASE do read the posting guide
>>> > >>> http://www.R-project.org/posting-guide.html
>>> > >>> and provide commented, minimal, self-contained, reproducible code.
>>> > >>>
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Sat Mar 20 06:00:56 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sat, 20 Mar 2021 13:00:56 +0800
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CA+JEM01TEREONeqYoHw59fPPv_YWYhVHJNm1ONu+y64vf00f_A@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
 <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
 <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>
 <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>
 <A480EB2B-6F79-4C37-8ACF-54081FBC13D1@utoronto.ca>
 <CA+JEM01TEREONeqYoHw59fPPv_YWYhVHJNm1ONu+y64vf00f_A@mail.gmail.com>
Message-ID: <CAGiFhPNj129uvkwCNP=1wx9Tja+NVB=y3etLn-11J7gN+2kuHg@mail.gmail.com>

Hi Bogdan,

I think the journal is asking about the exact value of the pvalue, it
doesn't matter if it is from the exact distribution or normal
approximation. However, it does not make any sense to report such a small
pvlaue. If I was you, I would show the reviewers the exact pvalue they want
and gently explain why you did not put it into your paper. If they insist
that the number must be on the paper, then go ahead and do it.

Best,
Jiefei



Bogdan Tanasa <tanasa at gmail.com> ? 2021?3?20??? ??2:39???

> Thank you Kevin, their wording is "Please note that the exact p value
> should be provided, when possible, etc"
>
> by "exact p-value" i believe that they do mean indeed the actual number,
> and not to specify "exact=TRUE" ;
>
> as we are working with 1000 genes, shall i specify "exact=TRUE" on my PC,
> it runs out of memory ...
>
> wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
>
> On Fri, Mar 19, 2021 at 11:10 AM Kevin Thorpe <kevin.thorpe at utoronto.ca>
> wrote:
>
> > I have to ask since. Are you sure the journal simply means by exact
> > p-value that they don?t want to see a p-value given as < 0.0001, for
> > example, and simply want the actual number?
> >
> > I cannot imagine they really meant exact as in the p-value from some
> exact
> > distribution.
> >
> > --
> > Kevin E. Thorpe
> > Head of Biostatistics,  Applied Health Research Centre (AHRC)
> > Li Ka Shing Knowledge Institute of St. Michael's
> > Assistant Professor, Dalla Lana School of Public Health
> > University of Toronto
> > email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> >
> > > On Mar 19, 2021, at 1:22 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> > >
> > > EXTERNAL EMAIL:
> > >
> > > Dear all, thank you all for comments and help.
> > >
> > > as far as i can see, shall we have samples of 1000 records, only
> > > "exact=FALSE" allows the code to run:
> > >
> > > wilcox.test(rnorm(1000), rnorm(1000, 2), exact=FALSE)$p.value
> > > [1] 7.304863e-231
> > >
> > > shall i use "exact=TRUE", it runs out of memory on my 64GB RAM PC :
> > >
> > > wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
> > > (the job is terminated by OS)
> > >
> > > shall you have any other suggestions, please let me know. thanks a lot
> !
> > >
> > > On Fri, Mar 19, 2021 at 9:05 AM Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> > >
> > >> I **believe** -- if my old memory still serves-- that the "exact"
> > >> specification uses a home grown version of the algorithm to calculate
> > >> exact,  or close approximations to the exact, permutation distribution
> > >> originally developed by Cyrus Mehta, founder of StatXact software.  Of
> > >> course, examining the C code source would determine this, but I don't
> > care
> > >> to attempt this.
> > >>
> > >> If this is (no longer?) correct, please point this out.
> > >>
> > >> Best,
> > >>
> > >> Bert Gunter
> > >>
> > >> "The trouble with having an open mind is that people keep coming along
> > and
> > >> sticking things into it."
> > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>
> > >>
> > >> On Fri, Mar 19, 2021 at 8:42 AM Jiefei Wang <szwjf08 at gmail.com>
> wrote:
> > >>
> > >>> Hi Spencer,
> > >>>
> > >>> Thanks for your test results, I do not know the answer as I haven't
> > >>> used wilcox.test for many years. I do not know if it is possible to
> > >>> compute
> > >>> the exact distribution of the Wilcoxon rank sum statistic, but I
> think
> > it
> > >>> is very likely, as the document of `Wilcoxon` says:
> > >>>
> > >>> This distribution is obtained as follows. Let x and y be two random,
> > >>> independent samples of size m and n. Then the Wilcoxon rank sum
> > statistic
> > >>> is the number of all pairs (x[i], y[j]) for which y[j] is not greater
> > than
> > >>> x[i]. This statistic takes values between 0 and m * n, and its mean
> and
> > >>> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
> > >>>
> > >>> As a nice feature of the non-parametric statistic, it is usually
> > >>> distribution-free so you can pick any distribution you like to
> compute
> > the
> > >>> same statistic. I wonder if this is the case, but I might be wrong.
> > >>>
> > >>> Cheers,
> > >>> Jiefei
> > >>>
> > >>>
> > >>> On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
> > >>> spencer.graves at effectivedefense.org> wrote:
> > >>>
> > >>>>
> > >>>>
> > >>>> On 2021-3-19 9:52 AM, Jiefei Wang wrote:
> > >>>>> After digging into the R source, it turns out that the argument
> > >>> `exact`
> > >>>> has
> > >>>>> nothing to do with the numeric precision. It only affects the
> > >>> statistic
> > >>>>> model used to compute the p-value. When `exact=TRUE` the true
> > >>>> distribution
> > >>>>> of the statistic will be used. Otherwise, a normal approximation
> will
> > >>> be
> > >>>>> used.
> > >>>>>
> > >>>>> I think the documentation needs to be improved here, you can
> compute
> > >>> the
> > >>>>> exact p-value *only* when you do not have any ties in your data. If
> > >>> you
> > >>>>> have ties in your data you will get the p-value from the normal
> > >>>>> approximation no matter what value you put in `exact`. This
> behavior
> > >>>> should
> > >>>>> be documented or a warning should be given when `exact=TRUE` and
> ties
> > >>>>> present.
> > >>>>>
> > >>>>> FYI, if the exact p-value is required, `pwilcox` function will be
> > >>> used to
> > >>>>> compute the p-value. There are no details on how it computes the
> > >>> pvalue
> > >>>> but
> > >>>>> its C code seems to compute the probability table, so I assume it
> > >>>> computes
> > >>>>> the exact p-value from the true distribution of the statistic, not
> a
> > >>>>> permutation or MC p-value.
> > >>>>
> > >>>>
> > >>>>       My example shows that it does NOT use Monte Carlo, because
> > >>>> otherwise it uses some distribution.  I believe the term "exact"
> means
> > >>>> that it uses the permutation distribution, though I could be
> mistaken.
> > >>>> If it's NOT a permutation distribution, I don't know what it is.
> > >>>>
> > >>>>
> > >>>>       Spencer
> > >>>>>
> > >>>>> Best,
> > >>>>> Jiefei
> > >>>>>
> > >>>>>
> > >>>>>
> > >>>>> On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com>
> > >>> wrote:
> > >>>>>
> > >>>>>> Hey,
> > >>>>>>
> > >>>>>> I just want to point out that the word "exact" has two meanings.
> It
> > >>> can
> > >>>>>> mean the numerically accurate p-value as Bogdan asked in his first
> > >>>> email,
> > >>>>>> or it could mean the p-value calculated from the exact
> distribution
> > >>> of
> > >>>> the
> > >>>>>> statistic(In this case, U stat). These two are actually not
> related,
> > >>>> even
> > >>>>>> though they all called "exact".
> > >>>>>>
> > >>>>>> Best,
> > >>>>>> Jiefei
> > >>>>>>
> > >>>>>> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
> > >>>>>> spencer.graves at effectivedefense.org> wrote:
> > >>>>>>
> > >>>>>>>
> > >>>>>>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
> > >>>>>>>> thanks a lot, Vivek ! in other words, assuming that we work with
> > >>> 1000
> > >>>>>>> data
> > >>>>>>>> points,
> > >>>>>>>>
> > >>>>>>>> shall we use EXACT = TRUE, it uses the normal approximation,
> > >>>>>>>>
> > >>>>>>>> while if EXACT=FALSE (for these large samples), it does not ?
> > >>>>>>>
> > >>>>>>>        As David Winsemius noted, the documentation is not clear.
> > >>>>>>> Consider the following:
> > >>>>>>>
> > >>>>>>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > >
> > >>> wilcox.test(x,
> > >>>>>>> y)$p.value
> > >>>>>>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 > >
> > >>>>>>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 >
> > >>> wilcox.test(x,
> > >>>>>>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
> > >>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
> > >>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
> > >>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
> > >>>>>>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the
> > normal
> > >>>>>>> approximation, which is the same as exact=FALSE. I think that
> with
> > >>>>>>> exact=FALSE, you get a permutation distribution, though I'm not
> > >>> sure.
> > >>>>>>> You might try looking at "wilcox_test in package coin for exact,
> > >>>>>>> asymptotic and Monte Carlo conditional p-values, including in the
> > >>>>>>> presence of ties" to see if it is clearer. NOTE: R is case
> > >>> sensitive,
> > >>>> so
> > >>>>>>> "EXACT" is a different variable from "exact". It is interpreted
> as
> > >>> an
> > >>>>>>> optional argument, which is not recognized and therefore ignored
> in
> > >>>> this
> > >>>>>>> context.
> > >>>>>>>           Hope this helps.
> > >>>>>>>           Spencer
> > >>>>>>>
> > >>>>>>>
> > >>>>>>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com>
> > >>>> wrote:
> > >>>>>>>>
> > >>>>>>>>> Hi Bogdan,
> > >>>>>>>>>
> > >>>>>>>>> You can also get the information from the link of the
> Wilcox.test
> > >>>>>>> function
> > >>>>>>>>> page.
> > >>>>>>>>>
> > >>>>>>>>> ?By default (if exact is not specified), an exact p-value is
> > >>> computed
> > >>>>>>> if
> > >>>>>>>>> the samples contain less than 50 finite values and there are no
> > >>> ties.
> > >>>>>>>>> Otherwise, a normal approximation is used.?
> > >>>>>>>>>
> > >>>>>>>>> For more:
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>
> > >>>>
> > >>>
> >
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
> > >>>>>>>>> Hope this helps!
> > >>>>>>>>>
> > >>>>>>>>> Best,
> > >>>>>>>>>
> > >>>>>>>>> VD
> > >>>>>>>>>
> > >>>>>>>>>
> > >>>>>>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <
> tanasa at gmail.com
> > >
> > >>>>>>> wrote:
> > >>>>>>>>>> Dear Peter, thanks a lot. yes, we can see a very precise
> > p-value,
> > >>>> and
> > >>>>>>> that
> > >>>>>>>>>> was the request from the journal.
> > >>>>>>>>>>
> > >>>>>>>>>> if I may ask another question please : what is the meaning of
> > >>>>>>> "exact=TRUE"
> > >>>>>>>>>> or "exact=FALSE" in wilcox.test ?
> > >>>>>>>>>>
> > >>>>>>>>>> i can see that the "numerically precise" p-values are
> different.
> > >>>>>>> thanks a
> > >>>>>>>>>> lot !
> > >>>>>>>>>>
> > >>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>>>>>> tst$p.value
> > >>>>>>>>>> [1] 8.535524e-25
> > >>>>>>>>>>
> > >>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
> > >>>>>>>>>> tst$p.value
> > >>>>>>>>>> [1] 3.448211e-25
> > >>>>>>>>>>
> > >>>>>>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
> > >>>>>>>>>> peter.langfelder at gmail.com> wrote:
> > >>>>>>>>>>
> > >>>>>>>>>>> I thinnk the answer is much simpler. The print method for
> > >>>> hypothesis
> > >>>>>>>>>>> tests (class htest) truncates the p-values. In the above
> > >>> example,
> > >>>>>>>>>>> instead of using
> > >>>>>>>>>>>
> > >>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>>>>>>>
> > >>>>>>>>>>> and copying the output, just print the p-value:
> > >>>>>>>>>>>
> > >>>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>>>>>>> tst$p.value
> > >>>>>>>>>>>
> > >>>>>>>>>>> [1] 2.988368e-32
> > >>>>>>>>>>>
> > >>>>>>>>>>>
> > >>>>>>>>>>> I think this value is what the journal asks for.
> > >>>>>>>>>>>
> > >>>>>>>>>>> HTH,
> > >>>>>>>>>>>
> > >>>>>>>>>>> Peter
> > >>>>>>>>>>>
> > >>>>>>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
> > >>>>>>>>>>> <spencer.graves at effectivedefense.org> wrote:
> > >>>>>>>>>>>>         I would push back on that from two perspectives:
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>               1.  I would study exactly what the journal
> said
> > >>>> very
> > >>>>>>>>>>>> carefully.  If they mandated "wilcox.test", that function
> has
> > >>> an
> > >>>>>>>>>>>> argument called "exact".  If that's what they are asking,
> then
> > >>>> using
> > >>>>>>>>>>>> that argument gives the exact p-value, e.g.:
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>           Wilcoxon rank sum exact test
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> data:  rnorm(100) and rnorm(100, 2)
> > >>>>>>>>>>>> W = 691, p-value < 2.2e-16
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>               2.  If that's NOT what they are asking, then
> I'm
> > >>>> not
> > >>>>>>>>>>>> convinced what they are asking makes sense:  There is is no
> > >>> such
> > >>>>>>> thing
> > >>>>>>>>>>>> as an "exact p value" except to the extent that certain
> > >>>> assumptions
> > >>>>>>>>>>>> hold, and all models are wrong (but some are useful), as
> > George
> > >>>> Box
> > >>>>>>>>>>>> famously said years ago.[1]  Truth only exists in
> mathematics,
> > >>> and
> > >>>>>>>>>>>> that's because it's a fiction to start with ;-)
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>         Hope this helps.
> > >>>>>>>>>>>>         Spencer Graves
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> [1]
> > >>>>>>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
> > >>>>>>>>>>>>
> > >>>>>>>>>>>>
> > >>>>>>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
> > >>>>>>>>>>>>>    <
> > >>>>>>>
> > >>>>
> > https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
> > >>>>>>>>>>>>> Dear all,
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> i would appreciate having your advice on the following
> please
> > >>> :
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16",
> when
> > >>> we
> > >>>>>>>>>> compare
> > >>>>>>>>>>>>> sets of 1000 genes expression (in the genomics field).
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> however, the journal asks us to provide the exact p value
> ...
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a
> > >>> lot,
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> -- bogdan
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>>        [[alternative HTML version deleted]]
> > >>>>>>>>>>>>>
> > >>>>>>>>>>>>> ______________________________________________
> > >>>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> > more,
> > >>>> see
> > >>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>>>>>>> PLEASE do read the posting guide
> > >>>>>>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>>>>>>> and provide commented, minimal, self-contained,
> reproducible
> > >>>> code.
> > >>>>>>>>>>>> ______________________________________________
> > >>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more,
> > >>> see
> > >>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>>>>>> PLEASE do read the posting guide
> > >>>>>>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> > >>> code.
> > >>>>>>>>>>          [[alternative HTML version deleted]]
> > >>>>>>>>>>
> > >>>>>>>>>> ______________________________________________
> > >>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > >>> see
> > >>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>>>> PLEASE do read the posting guide
> > >>>>>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> > >>> code.
> > >>>>>>>>>>
> > >>>>>>>>> --
> > >>>>>>>>> ----------------------------------------------------------
> > >>>>>>>>>
> > >>>>>>>>> Vivek Das, PhD
> > >>>>>>>>>
> > >>>>>>>>       [[alternative HTML version deleted]]
> > >>>>>>>>
> > >>>>>>>> ______________________________________________
> > >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>> PLEASE do read the posting guide
> > >>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> > >>>>>>>
> > >>>>>>>         [[alternative HTML version deleted]]
> > >>>>>>>
> > >>>>>>> ______________________________________________
> > >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>> PLEASE do read the posting guide
> > >>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> > >>>>>>>
> > >>>>
> > >>>>
> > >>>
> > >>>        [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >>> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>
> > >
> > >        [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From t@n@@@ @end|ng |rom gm@||@com  Sat Mar 20 06:05:11 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 19 Mar 2021 22:05:11 -0700
Subject: [R] about a p-value < 2.2e-16
In-Reply-To: <CAGiFhPNj129uvkwCNP=1wx9Tja+NVB=y3etLn-11J7gN+2kuHg@mail.gmail.com>
References: <CA+JEM01+aoWGgJacRU2asVu7R9L-cN23Mpe3R3ZO+ovWxbXuxA@mail.gmail.com>
 <7181e33f-be82-2b98-2eff-e4c2af75adcc@effectivedefense.org>
 <CA+hbrhWim5dBs9yPKsvWZ9iUFRvt=LAGDD_zzwxQYG1WyGdg3A@mail.gmail.com>
 <CA+JEM02qyWFK_0XPBrNKA=b5jUVUr1QfkSRUAaV1w_cthb3_Ug@mail.gmail.com>
 <CAFkF=gEyXzqDyDDAROBXwYRFxNrnYvAejb52nbtyndpZA-jdCg@mail.gmail.com>
 <CA+JEM008MW4AJAGAxnJaMOjrcFOngvTOsDZh3WszNf8cMtAp_Q@mail.gmail.com>
 <a309915d-8a4b-d9cf-18b5-56d40ec5a2a7@effectivedefense.org>
 <CAGiFhPMYLyBa1HEnyEWGy5AsLsvQ09K52ksyANo-2m7QMh8cRQ@mail.gmail.com>
 <CAGiFhPMpe8g6fuEtxqiQeK+9wrs8_zn+3uLG9UQ-iMz4n0vatQ@mail.gmail.com>
 <3638a3be-26ee-0ca4-fe09-26442f741161@effectivedefense.org>
 <CAGiFhPONtbLgTuqvRcbrsZcgiz-1sv8Ka=kKj72LhKCtfBMPSg@mail.gmail.com>
 <CAGxFJbQ1NnyLr48UZxGRBXZ7d-vnYAebD6NR4fFDRmxfTNtiRA@mail.gmail.com>
 <CA+JEM03KHcQpAs6=JCUiE1CcrL8ZS1m1pSSZKty_C+WqHV8-mA@mail.gmail.com>
 <A480EB2B-6F79-4C37-8ACF-54081FBC13D1@utoronto.ca>
 <CA+JEM01TEREONeqYoHw59fPPv_YWYhVHJNm1ONu+y64vf00f_A@mail.gmail.com>
 <CAGiFhPNj129uvkwCNP=1wx9Tja+NVB=y3etLn-11J7gN+2kuHg@mail.gmail.com>
Message-ID: <CA+JEM01F29e+KKB2c1Q6e527kgmZKCrheUKhN0U+1WXXyhocbA@mail.gmail.com>

thanks a lot, Jiefei ! and thanks to all for your time and comments !

have a good weekend !




On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hi Bogdan,
>
> I think the journal is asking about the exact value of the pvalue, it
> doesn't matter if it is from the exact distribution or normal
> approximation. However, it does not make any sense to report such a small
> pvlaue. If I was you, I would show the reviewers the exact pvalue they want
> and gently explain why you did not put it into your paper. If they insist
> that the number must be on the paper, then go ahead and do it.
>
> Best,
> Jiefei
>
>
>
> Bogdan Tanasa <tanasa at gmail.com> ? 2021?3?20??? ??2:39???
>
>> Thank you Kevin, their wording is "Please note that the exact p value
>> should be provided, when possible, etc"
>>
>> by "exact p-value" i believe that they do mean indeed the actual number,
>> and not to specify "exact=TRUE" ;
>>
>> as we are working with 1000 genes, shall i specify "exact=TRUE" on my PC,
>> it runs out of memory ...
>>
>> wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
>>
>> On Fri, Mar 19, 2021 at 11:10 AM Kevin Thorpe <kevin.thorpe at utoronto.ca>
>> wrote:
>>
>> > I have to ask since. Are you sure the journal simply means by exact
>> > p-value that they don?t want to see a p-value given as < 0.0001, for
>> > example, and simply want the actual number?
>> >
>> > I cannot imagine they really meant exact as in the p-value from some
>> exact
>> > distribution.
>> >
>> > --
>> > Kevin E. Thorpe
>> > Head of Biostatistics,  Applied Health Research Centre (AHRC)
>> > Li Ka Shing Knowledge Institute of St. Michael's
>> > Assistant Professor, Dalla Lana School of Public Health
>> > University of Toronto
>> > email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>> >
>> > > On Mar 19, 2021, at 1:22 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
>> > >
>> > > EXTERNAL EMAIL:
>> > >
>> > > Dear all, thank you all for comments and help.
>> > >
>> > > as far as i can see, shall we have samples of 1000 records, only
>> > > "exact=FALSE" allows the code to run:
>> > >
>> > > wilcox.test(rnorm(1000), rnorm(1000, 2), exact=FALSE)$p.value
>> > > [1] 7.304863e-231
>> > >
>> > > shall i use "exact=TRUE", it runs out of memory on my 64GB RAM PC :
>> > >
>> > > wilcox.test(rnorm(1000), rnorm(1000, 2), exact=TRUE)$p.value
>> > > (the job is terminated by OS)
>> > >
>> > > shall you have any other suggestions, please let me know. thanks a
>> lot !
>> > >
>> > > On Fri, Mar 19, 2021 at 9:05 AM Bert Gunter <bgunter.4567 at gmail.com>
>> > wrote:
>> > >
>> > >> I **believe** -- if my old memory still serves-- that the "exact"
>> > >> specification uses a home grown version of the algorithm to calculate
>> > >> exact,  or close approximations to the exact, permutation
>> distribution
>> > >> originally developed by Cyrus Mehta, founder of StatXact software.
>> Of
>> > >> course, examining the C code source would determine this, but I don't
>> > care
>> > >> to attempt this.
>> > >>
>> > >> If this is (no longer?) correct, please point this out.
>> > >>
>> > >> Best,
>> > >>
>> > >> Bert Gunter
>> > >>
>> > >> "The trouble with having an open mind is that people keep coming
>> along
>> > and
>> > >> sticking things into it."
>> > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> > >>
>> > >>
>> > >> On Fri, Mar 19, 2021 at 8:42 AM Jiefei Wang <szwjf08 at gmail.com>
>> wrote:
>> > >>
>> > >>> Hi Spencer,
>> > >>>
>> > >>> Thanks for your test results, I do not know the answer as I haven't
>> > >>> used wilcox.test for many years. I do not know if it is possible to
>> > >>> compute
>> > >>> the exact distribution of the Wilcoxon rank sum statistic, but I
>> think
>> > it
>> > >>> is very likely, as the document of `Wilcoxon` says:
>> > >>>
>> > >>> This distribution is obtained as follows. Let x and y be two random,
>> > >>> independent samples of size m and n. Then the Wilcoxon rank sum
>> > statistic
>> > >>> is the number of all pairs (x[i], y[j]) for which y[j] is not
>> greater
>> > than
>> > >>> x[i]. This statistic takes values between 0 and m * n, and its mean
>> and
>> > >>> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
>> > >>>
>> > >>> As a nice feature of the non-parametric statistic, it is usually
>> > >>> distribution-free so you can pick any distribution you like to
>> compute
>> > the
>> > >>> same statistic. I wonder if this is the case, but I might be wrong.
>> > >>>
>> > >>> Cheers,
>> > >>> Jiefei
>> > >>>
>> > >>>
>> > >>> On Fri, Mar 19, 2021 at 10:57 PM Spencer Graves <
>> > >>> spencer.graves at effectivedefense.org> wrote:
>> > >>>
>> > >>>>
>> > >>>>
>> > >>>> On 2021-3-19 9:52 AM, Jiefei Wang wrote:
>> > >>>>> After digging into the R source, it turns out that the argument
>> > >>> `exact`
>> > >>>> has
>> > >>>>> nothing to do with the numeric precision. It only affects the
>> > >>> statistic
>> > >>>>> model used to compute the p-value. When `exact=TRUE` the true
>> > >>>> distribution
>> > >>>>> of the statistic will be used. Otherwise, a normal approximation
>> will
>> > >>> be
>> > >>>>> used.
>> > >>>>>
>> > >>>>> I think the documentation needs to be improved here, you can
>> compute
>> > >>> the
>> > >>>>> exact p-value *only* when you do not have any ties in your data.
>> If
>> > >>> you
>> > >>>>> have ties in your data you will get the p-value from the normal
>> > >>>>> approximation no matter what value you put in `exact`. This
>> behavior
>> > >>>> should
>> > >>>>> be documented or a warning should be given when `exact=TRUE` and
>> ties
>> > >>>>> present.
>> > >>>>>
>> > >>>>> FYI, if the exact p-value is required, `pwilcox` function will be
>> > >>> used to
>> > >>>>> compute the p-value. There are no details on how it computes the
>> > >>> pvalue
>> > >>>> but
>> > >>>>> its C code seems to compute the probability table, so I assume it
>> > >>>> computes
>> > >>>>> the exact p-value from the true distribution of the statistic,
>> not a
>> > >>>>> permutation or MC p-value.
>> > >>>>
>> > >>>>
>> > >>>>       My example shows that it does NOT use Monte Carlo, because
>> > >>>> otherwise it uses some distribution.  I believe the term "exact"
>> means
>> > >>>> that it uses the permutation distribution, though I could be
>> mistaken.
>> > >>>> If it's NOT a permutation distribution, I don't know what it is.
>> > >>>>
>> > >>>>
>> > >>>>       Spencer
>> > >>>>>
>> > >>>>> Best,
>> > >>>>> Jiefei
>> > >>>>>
>> > >>>>>
>> > >>>>>
>> > >>>>> On Fri, Mar 19, 2021 at 10:01 PM Jiefei Wang <szwjf08 at gmail.com>
>> > >>> wrote:
>> > >>>>>
>> > >>>>>> Hey,
>> > >>>>>>
>> > >>>>>> I just want to point out that the word "exact" has two meanings.
>> It
>> > >>> can
>> > >>>>>> mean the numerically accurate p-value as Bogdan asked in his
>> first
>> > >>>> email,
>> > >>>>>> or it could mean the p-value calculated from the exact
>> distribution
>> > >>> of
>> > >>>> the
>> > >>>>>> statistic(In this case, U stat). These two are actually not
>> related,
>> > >>>> even
>> > >>>>>> though they all called "exact".
>> > >>>>>>
>> > >>>>>> Best,
>> > >>>>>> Jiefei
>> > >>>>>>
>> > >>>>>> On Fri, Mar 19, 2021 at 9:31 PM Spencer Graves <
>> > >>>>>> spencer.graves at effectivedefense.org> wrote:
>> > >>>>>>
>> > >>>>>>>
>> > >>>>>>> On 2021-3-19 12:54 AM, Bogdan Tanasa wrote:
>> > >>>>>>>> thanks a lot, Vivek ! in other words, assuming that we work
>> with
>> > >>> 1000
>> > >>>>>>> data
>> > >>>>>>>> points,
>> > >>>>>>>>
>> > >>>>>>>> shall we use EXACT = TRUE, it uses the normal approximation,
>> > >>>>>>>>
>> > >>>>>>>> while if EXACT=FALSE (for these large samples), it does not ?
>> > >>>>>>>
>> > >>>>>>>        As David Winsemius noted, the documentation is not clear.
>> > >>>>>>> Consider the following:
>> > >>>>>>>
>> > >>>>>>>> set.seed(1)  > x <- rnorm(100) > y <- rnorm(100, 2) > >
>> > >>> wilcox.test(x,
>> > >>>>>>> y)$p.value
>> > >>>>>>> [1] 1.172189e-25 > wilcox.test(x, y)$p.value [1] 1.172189e-25 >
>> >
>> > >>>>>>> wilcox.test(x, y, EXACT=TRUE)$p.value [1] 1.172189e-25 >
>> > >>> wilcox.test(x,
>> > >>>>>>> y, EXACT=TRUE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > wilcox.test(x, y,
>> > >>>>>>> exact=TRUE)$p.value [1] 4.123875e-32 > > wilcox.test(x, y,
>> > >>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>>>>>> EXACT=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > wilcox.test(x, y,
>> > >>>>>>> exact=FALSE)$p.value [1] 1.172189e-25 > We get two values here:
>> > >>>>>>> 1.172189e-25 and 4.123875e-32. The first one, I think, is the
>> > normal
>> > >>>>>>> approximation, which is the same as exact=FALSE. I think that
>> with
>> > >>>>>>> exact=FALSE, you get a permutation distribution, though I'm not
>> > >>> sure.
>> > >>>>>>> You might try looking at "wilcox_test in package coin for exact,
>> > >>>>>>> asymptotic and Monte Carlo conditional p-values, including in
>> the
>> > >>>>>>> presence of ties" to see if it is clearer. NOTE: R is case
>> > >>> sensitive,
>> > >>>> so
>> > >>>>>>> "EXACT" is a different variable from "exact". It is interpreted
>> as
>> > >>> an
>> > >>>>>>> optional argument, which is not recognized and therefore
>> ignored in
>> > >>>> this
>> > >>>>>>> context.
>> > >>>>>>>           Hope this helps.
>> > >>>>>>>           Spencer
>> > >>>>>>>
>> > >>>>>>>
>> > >>>>>>>> On Thu, Mar 18, 2021 at 10:47 PM Vivek Das <vd4mmind at gmail.com
>> >
>> > >>>> wrote:
>> > >>>>>>>>
>> > >>>>>>>>> Hi Bogdan,
>> > >>>>>>>>>
>> > >>>>>>>>> You can also get the information from the link of the
>> Wilcox.test
>> > >>>>>>> function
>> > >>>>>>>>> page.
>> > >>>>>>>>>
>> > >>>>>>>>> ?By default (if exact is not specified), an exact p-value is
>> > >>> computed
>> > >>>>>>> if
>> > >>>>>>>>> the samples contain less than 50 finite values and there are
>> no
>> > >>> ties.
>> > >>>>>>>>> Otherwise, a normal approximation is used.?
>> > >>>>>>>>>
>> > >>>>>>>>> For more:
>> > >>>>>>>>>
>> > >>>>>>>>>
>> > >>>>>>>
>> > >>>>
>> > >>>
>> >
>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html
>> > >>>>>>>>> Hope this helps!
>> > >>>>>>>>>
>> > >>>>>>>>> Best,
>> > >>>>>>>>>
>> > >>>>>>>>> VD
>> > >>>>>>>>>
>> > >>>>>>>>>
>> > >>>>>>>>> On Thu, Mar 18, 2021 at 10:36 PM Bogdan Tanasa <
>> tanasa at gmail.com
>> > >
>> > >>>>>>> wrote:
>> > >>>>>>>>>> Dear Peter, thanks a lot. yes, we can see a very precise
>> > p-value,
>> > >>>> and
>> > >>>>>>> that
>> > >>>>>>>>>> was the request from the journal.
>> > >>>>>>>>>>
>> > >>>>>>>>>> if I may ask another question please : what is the meaning of
>> > >>>>>>> "exact=TRUE"
>> > >>>>>>>>>> or "exact=FALSE" in wilcox.test ?
>> > >>>>>>>>>>
>> > >>>>>>>>>> i can see that the "numerically precise" p-values are
>> different.
>> > >>>>>>> thanks a
>> > >>>>>>>>>> lot !
>> > >>>>>>>>>>
>> > >>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>>>>>> tst$p.value
>> > >>>>>>>>>> [1] 8.535524e-25
>> > >>>>>>>>>>
>> > >>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=FALSE)
>> > >>>>>>>>>> tst$p.value
>> > >>>>>>>>>> [1] 3.448211e-25
>> > >>>>>>>>>>
>> > >>>>>>>>>> On Thu, Mar 18, 2021 at 10:15 PM Peter Langfelder <
>> > >>>>>>>>>> peter.langfelder at gmail.com> wrote:
>> > >>>>>>>>>>
>> > >>>>>>>>>>> I thinnk the answer is much simpler. The print method for
>> > >>>> hypothesis
>> > >>>>>>>>>>> tests (class htest) truncates the p-values. In the above
>> > >>> example,
>> > >>>>>>>>>>> instead of using
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> and copying the output, just print the p-value:
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> tst = wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>>>>>>> tst$p.value
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> [1] 2.988368e-32
>> > >>>>>>>>>>>
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> I think this value is what the journal asks for.
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> HTH,
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> Peter
>> > >>>>>>>>>>>
>> > >>>>>>>>>>> On Thu, Mar 18, 2021 at 10:05 PM Spencer Graves
>> > >>>>>>>>>>> <spencer.graves at effectivedefense.org> wrote:
>> > >>>>>>>>>>>>         I would push back on that from two perspectives:
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>               1.  I would study exactly what the journal
>> said
>> > >>>> very
>> > >>>>>>>>>>>> carefully.  If they mandated "wilcox.test", that function
>> has
>> > >>> an
>> > >>>>>>>>>>>> argument called "exact".  If that's what they are asking,
>> then
>> > >>>> using
>> > >>>>>>>>>>>> that argument gives the exact p-value, e.g.:
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>> wilcox.test(rnorm(100), rnorm(100, 2), exact=TRUE)
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>           Wilcoxon rank sum exact test
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> data:  rnorm(100) and rnorm(100, 2)
>> > >>>>>>>>>>>> W = 691, p-value < 2.2e-16
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>               2.  If that's NOT what they are asking, then
>> I'm
>> > >>>> not
>> > >>>>>>>>>>>> convinced what they are asking makes sense:  There is is no
>> > >>> such
>> > >>>>>>> thing
>> > >>>>>>>>>>>> as an "exact p value" except to the extent that certain
>> > >>>> assumptions
>> > >>>>>>>>>>>> hold, and all models are wrong (but some are useful), as
>> > George
>> > >>>> Box
>> > >>>>>>>>>>>> famously said years ago.[1]  Truth only exists in
>> mathematics,
>> > >>> and
>> > >>>>>>>>>>>> that's because it's a fiction to start with ;-)
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>         Hope this helps.
>> > >>>>>>>>>>>>         Spencer Graves
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> [1]
>> > >>>>>>>>>>>> https://en.wikipedia.org/wiki/All_models_are_wrong
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>>
>> > >>>>>>>>>>>> On 2021-3-18 11:12 PM, Bogdan Tanasa wrote:
>> > >>>>>>>>>>>>>    <
>> > >>>>>>>
>> > >>>>
>> > https://meta.stackexchange.com/questions/362285/about-a-p-value-2-2e-16
>> > >>>>>>>>>>>>> Dear all,
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> i would appreciate having your advice on the following
>> please
>> > >>> :
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> in R, the wilcox.test() provides "a p-value < 2.2e-16",
>> when
>> > >>> we
>> > >>>>>>>>>> compare
>> > >>>>>>>>>>>>> sets of 1000 genes expression (in the genomics field).
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> however, the journal asks us to provide the exact p value
>> ...
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> would it be legitimate to write : "p-value = 0" ? thanks a
>> > >>> lot,
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> -- bogdan
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>>        [[alternative HTML version deleted]]
>> > >>>>>>>>>>>>>
>> > >>>>>>>>>>>>> ______________________________________________
>> > >>>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> > more,
>> > >>>> see
>> > >>>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>>>>>>>>> PLEASE do read the posting guide
>> > >>>>>>>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>>>>>>>>> and provide commented, minimal, self-contained,
>> reproducible
>> > >>>> code.
>> > >>>>>>>>>>>> ______________________________________________
>> > >>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> more,
>> > >>> see
>> > >>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>>>>>>>> PLEASE do read the posting guide
>> > >>>>>>>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>>>>>>>> and provide commented, minimal, self-contained,
>> reproducible
>> > >>> code.
>> > >>>>>>>>>>          [[alternative HTML version deleted]]
>> > >>>>>>>>>>
>> > >>>>>>>>>> ______________________________________________
>> > >>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> more,
>> > >>> see
>> > >>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>>>>>> PLEASE do read the posting guide
>> > >>>>>>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> > >>> code.
>> > >>>>>>>>>>
>> > >>>>>>>>> --
>> > >>>>>>>>> ----------------------------------------------------------
>> > >>>>>>>>>
>> > >>>>>>>>> Vivek Das, PhD
>> > >>>>>>>>>
>> > >>>>>>>>       [[alternative HTML version deleted]]
>> > >>>>>>>>
>> > >>>>>>>> ______________________________________________
>> > >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>>>> PLEASE do read the posting guide
>> > >>>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> > >>>>>>>
>> > >>>>>>>         [[alternative HTML version deleted]]
>> > >>>>>>>
>> > >>>>>>> ______________________________________________
>> > >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> > >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>>>>>> PLEASE do read the posting guide
>> > >>>>>>> http://www.R-project.org/posting-guide.html
>> > >>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> > >>>>>>>
>> > >>>>
>> > >>>>
>> > >>>
>> > >>>        [[alternative HTML version deleted]]
>> > >>>
>> > >>> ______________________________________________
>> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >>> PLEASE do read the posting guide
>> > >>> http://www.R-project.org/posting-guide.html
>> > >>> and provide commented, minimal, self-contained, reproducible code.
>> > >>>
>> > >>
>> > >
>> > >        [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Sat Mar 20 13:43:30 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Sat, 20 Mar 2021 07:43:30 -0500
Subject: [R] "exact" p-values
Message-ID: <9b53cf$fkk4bp@ironport10.mayo.edu>

I am late to this discussion -- I read R-help as a once-a-day summary.? A few comments.

1. In the gene-discovery subfield of statistics (SNP studies, etc.)? there is a huge 
multiple-testing problem.? In defense, the field thinks in terms of thresholds like 1e-5 
or 1e-10 rather than the .05 or .01 most of us are used to.?? In that literature, they do 
care about? 1e-16 vs 1e-20.??? We can all argue about whether that is a sensible approach 
or not, but it is what it is.? I think that this is the context of the journal's request, 
i.e., they want the actual number, however you calculate it.

My own opinion is that these rarified p-values are an arbitrary scale, one that no longer 
has a probability interpretation.?? For the central limit theorem to be correct that far 
from the mean requires a sample size that is beyond imagination? (`number of atoms in the 
earth' order of size).?? Such a scale may still be useful, but it's not really a probability.

2. The label of "Fisher's exact test" has caused decades of confusion.? In this context 
the word means "a particular test whose distribution can be completely enumerated": it 
does not mean either "correct" or "precise".? The original enumeration methods had 
limitations with resspect to the sample size or the presence of complications such as tied 
values;? from the discussion so far it would appear that the 'exact' argument of 
wilcox.test uses such a method.?? Cyrus Mehta did nice work on improved algorithms that do 
not have these restrictions, methods that have been refiined and expanded in the software 
offerings from Cytel among others. Perhaps someone could update R's code to use this, but 
see 3 below.

My own opinion is that permutation tests are an important tool, one "wrench" in our 
statistical toolbox.?? But they are only one tool out of many.? I am quite put off by 
arguments that purposefully conflate "exact" and "correct".

3. The concordance statistic C, the Wilcoxon test, and Somer's d are all the same 
statistic, just written a little differently. (Somer's d is essentially Kendalls' tau, but 
with a slightly different rule for ties).? A test for C=.5 is the same as a Wilcoxon.? For 
a binary response C = the area under the reciever operating curve (AUC). ? The concordance 
command in the surivival library computes this statistic for continuous, binary, or 
censored responses. ?? The variance is based on a jackknife argument, and is computed by 
organizing the data into a binary tree structure, very similar to the methods used by 
Mehta, is efficient for large n and is valid for ties.?? Perhaps add a link in the? 
wilcox.test help page?

Footnote: AUC is a special case of C but not vice versa.? People sometimes try to extend 
AUC to the other data types, but IMHO with only moderate success.

-- 
Terry M Therneau, PhD
Department of Health Science Research
Mayo Clinic
therneau at mayo.edu

"TERR-ree THUR-noh"


	[[alternative HTML version deleted]]


From mn@3 @end|ng |rom jhu@edu  Sat Mar 20 06:04:14 2021
From: mn@3 @end|ng |rom jhu@edu (Miso Na)
Date: Sat, 20 Mar 2021 05:04:14 +0000
Subject: [R] Surprising behavior and bugs in R 4.0.4
Message-ID: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>

Dear helpers,

Although I uninstalled and reinstalled R more than 3 times to delete the error in api_create, it did not work. The error is representing on the very first page on R consol.
Error: could not find function "api_create"

I guess this error makes impossible to install library 'SCMAP', 'SingleCellExperiment' or 'Seurat'.
For example, I got this error when I tried to install those libraries.
Installing package into 'C:/Users/user/Documents/R/win-library/4.0'
(as 'lib' is unspecified)
Error: could not find function "api_create"
Execution halted
Error: Failed to install 'Seurat' from GitHub:
  (converted from warning) installation of package 'C:/Users/user/AppData/Local/Temp/RtmpKYL3Pe/file2c2c6cb0766e/Seurat_4.0.1.tar.gz' had non-zero exit status


My sessionInfo is here!

> sessionInfo()
R version 4.0.4 (2021-02-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19041)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252
system code page: 949

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.4

Thanks for your help!

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Mar 20 15:39:37 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 20 Mar 2021 10:39:37 -0400
Subject: [R] Surprising behavior and bugs in R 4.0.4
In-Reply-To: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>
References: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>
Message-ID: <279ea4df-2662-5a31-40ba-af8fa66b7f26@gmail.com>

On 20/03/2021 1:04 a.m., Miso Na wrote:
> Dear helpers,
> 
> Although I uninstalled and reinstalled R more than 3 times to delete the error in api_create, it did not work. The error is representing on the very first page on R consol.
> Error: could not find function "api_create"

Why would you think this is a bug in R, rather than in whatever 
unreleased package(s) you were trying to install?

Duncan Murdoch

> 
> I guess this error makes impossible to install library 'SCMAP', 'SingleCellExperiment' or 'Seurat'.
> For example, I got this error when I tried to install those libraries.
> Installing package into 'C:/Users/user/Documents/R/win-library/4.0'
> (as 'lib' is unspecified)
> Error: could not find function "api_create"
> Execution halted
> Error: Failed to install 'Seurat' from GitHub:
>    (converted from warning) installation of package 'C:/Users/user/AppData/Local/Temp/RtmpKYL3Pe/file2c2c6cb0766e/Seurat_4.0.1.tar.gz' had non-zero exit status
> 
> 
> My sessionInfo is here!
> 
>> sessionInfo()
> R version 4.0.4 (2021-02-15)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 19041)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> system code page: 949
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.0.4
> 
> Thanks for your help!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @zwj|08 @end|ng |rom gm@||@com  Sat Mar 20 17:04:37 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sun, 21 Mar 2021 00:04:37 +0800
Subject: [R] Surprising behavior and bugs in R 4.0.4
In-Reply-To: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>
References: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>
Message-ID: <CAGiFhPMHv68Rtb4wWbtmkXXQGW2zW24U_oEuQ6ev-ttCJfpv7Q@mail.gmail.com>

Hi Miso,

Have you tried to install Seurat from CRAN? What you were using is the
GitHub version of the package and has been actively updating, so the
problem might be from the package.

Best,
Jiefei

On Sat, Mar 20, 2021 at 10:32 PM Miso Na <mna3 at jhu.edu> wrote:

> Dear helpers,
>
> Although I uninstalled and reinstalled R more than 3 times to delete the
> error in api_create, it did not work. The error is representing on the very
> first page on R consol.
> Error: could not find function "api_create"
>
> I guess this error makes impossible to install library 'SCMAP',
> 'SingleCellExperiment' or 'Seurat'.
> For example, I got this error when I tried to install those libraries.
> Installing package into 'C:/Users/user/Documents/R/win-library/4.0'
> (as 'lib' is unspecified)
> Error: could not find function "api_create"
> Execution halted
> Error: Failed to install 'Seurat' from GitHub:
>   (converted from warning) installation of package
> 'C:/Users/user/AppData/Local/Temp/RtmpKYL3Pe/file2c2c6cb0766e/Seurat_4.0.1.tar.gz'
> had non-zero exit status
>
>
> My sessionInfo is here!
>
> > sessionInfo()
> R version 4.0.4 (2021-02-15)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 19041)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> system code page: 949
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.4
>
> Thanks for your help!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sat Mar 20 19:53:58 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 20 Mar 2021 20:53:58 +0200
Subject: [R] Surprising behavior and bugs in R 4.0.4
In-Reply-To: <CAGiFhPMHv68Rtb4wWbtmkXXQGW2zW24U_oEuQ6ev-ttCJfpv7Q@mail.gmail.com>
References: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>
 <CAGiFhPMHv68Rtb4wWbtmkXXQGW2zW24U_oEuQ6ev-ttCJfpv7Q@mail.gmail.com>
Message-ID: <CAGgJW77SCtSaVqJ9FRpT7g1UQntMK7ywKPV8j2-yOAEuNgHV3g@mail.gmail.com>

I have no familiarity with these packages but I did a search in CRAN on
api_create and found it is defined in the plotly package. I then confirmed
that the seurat package does reference plotly.

You might try installing the plotly package before trying to install seurat.

HTH,
Eric


On Sat, Mar 20, 2021 at 6:05 PM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hi Miso,
>
> Have you tried to install Seurat from CRAN? What you were using is the
> GitHub version of the package and has been actively updating, so the
> problem might be from the package.
>
> Best,
> Jiefei
>
> On Sat, Mar 20, 2021 at 10:32 PM Miso Na <mna3 at jhu.edu> wrote:
>
> > Dear helpers,
> >
> > Although I uninstalled and reinstalled R more than 3 times to delete the
> > error in api_create, it did not work. The error is representing on the
> very
> > first page on R consol.
> > Error: could not find function "api_create"
> >
> > I guess this error makes impossible to install library 'SCMAP',
> > 'SingleCellExperiment' or 'Seurat'.
> > For example, I got this error when I tried to install those libraries.
> > Installing package into 'C:/Users/user/Documents/R/win-library/4.0'
> > (as 'lib' is unspecified)
> > Error: could not find function "api_create"
> > Execution halted
> > Error: Failed to install 'Seurat' from GitHub:
> >   (converted from warning) installation of package
> >
> 'C:/Users/user/AppData/Local/Temp/RtmpKYL3Pe/file2c2c6cb0766e/Seurat_4.0.1.tar.gz'
> > had non-zero exit status
> >
> >
> > My sessionInfo is here!
> >
> > > sessionInfo()
> > R version 4.0.4 (2021-02-15)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 10 x64 (build 19041)
> >
> > Matrix products: default
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> > system code page: 949
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] compiler_4.0.4
> >
> > Thanks for your help!
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From b@be|proo|re@der @end|ng |rom gm@||@com  Sat Mar 20 22:31:13 2021
From: b@be|proo|re@der @end|ng |rom gm@||@com (babelproofreader)
Date: Sat, 20 Mar 2021 22:31:13 +0100
Subject: [R] Custom annotation vector in R tsmp package
Message-ID: <CAPk9CsHyGQY-XBgSJLws8zH10=Cz1cSgCtpQQeVxPtGmzeDQjQ@mail.gmail.com>

I'd like to use a custom annotation vector (av) for a matrix profile (mp)
produced using the tsmp package, but I am unsure how to amend said profile
produced by e.g. the compute function.

I note that the package provides some functions to do this for "standard"
cases, such as av_complexity, av_hardlimit_artifact etc. and then av_apply,
but I want to apply a custom av. I have tried directly replacing the mp in
the results produced by compute, i.e.

result <- compute( data , ... )
result$mp <- my_av_mp

but this doesn't work as I get the following error

Error in `[.data.frame`(matrix_profile$mp, min_idx) :
undefined columns selected

Trying

result$mp[,1] <- my_av_mp

doesn't give an error, but when I try to use the amended result further,
i.e.

motif_results <- find_motif( result , n_motifs = 5 , ... )

I get the error

Error in apply(.mp$mp, 2, which.min) : dim(X) must have a positive length

What is the correct way to apply a custom av with the tsmp package?

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Mar 20 22:44:11 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Mar 2021 14:44:11 -0700
Subject: [R] Custom annotation vector in R tsmp package
In-Reply-To: <CAPk9CsHyGQY-XBgSJLws8zH10=Cz1cSgCtpQQeVxPtGmzeDQjQ@mail.gmail.com>
References: <CAPk9CsHyGQY-XBgSJLws8zH10=Cz1cSgCtpQQeVxPtGmzeDQjQ@mail.gmail.com>
Message-ID: <CAGxFJbQ_zBdX1deLoQzpkTkKBkcgYc25fWtWOGmWiUWQi_QCnQ@mail.gmail.com>

Please note, per the posting guide linked below:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information [see also ?maintainer]. *Only* send such questions to R-help or
R-devel if you get no reply or need further assistance. This applies to
both requests for help and to bug reports."

So while you might get a response here, you should not expect one. Also, I
think it will be very difficult for anyone to help you without knowing what
"data" looks like. Could be wrong, of course...

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 20, 2021 at 2:31 PM babelproofreader <babelproofreader at gmail.com>
wrote:

> I'd like to use a custom annotation vector (av) for a matrix profile (mp)
> produced using the tsmp package, but I am unsure how to amend said profile
> produced by e.g. the compute function.
>
> I note that the package provides some functions to do this for "standard"
> cases, such as av_complexity, av_hardlimit_artifact etc. and then av_apply,
> but I want to apply a custom av. I have tried directly replacing the mp in
> the results produced by compute, i.e.
>
> result <- compute( data , ... )
> result$mp <- my_av_mp
>
> but this doesn't work as I get the following error
>
> Error in `[.data.frame`(matrix_profile$mp, min_idx) :
> undefined columns selected
>
> Trying
>
> result$mp[,1] <- my_av_mp
>
> doesn't give an error, but when I try to use the amended result further,
> i.e.
>
> motif_results <- find_motif( result , n_motifs = 5 , ... )
>
> I get the error
>
> Error in apply(.mp$mp, 2, which.min) : dim(X) must have a positive length
>
> What is the correct way to apply a custom av with the tsmp package?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat Mar 20 21:02:41 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Sat, 20 Mar 2021 20:02:41 +0000
Subject: [R] R-help Digest, Vol 217, Issue 20
In-Reply-To: <mailman.362575.0.1616238002.57755.r-help@r-project.org>
References: <mailman.362575.0.1616238002.57755.r-help@r-project.org>
Message-ID: <E00EF9E0-0255-4501-8417-A500E36EE235@anu.edu.au>

No, it is not distribution free.  Independent random sampling is assumed.
That is a non-trivial assumption, and one that is very often not true or not
strictly true.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 21/03/2021, at 00:00, r-help-request at r-project.org<mailto:r-help-request at r-project.org> wrote:

From: Jiefei Wang <szwjf08 at gmail.com<mailto:szwjf08 at gmail.com>>
Subject: Re: [R] about a p-value < 2.2e-16
Date: 20 March 2021 at 04:41:33 NZDT
To: Spencer Graves <spencer.graves at effectivedefense.org<mailto:spencer.graves at effectivedefense.org>>
Cc: Bogdan Tanasa <tanasa at gmail.com<mailto:tanasa at gmail.com>>, Vivek Das <vd4mmind at gmail.com<mailto:vd4mmind at gmail.com>>, r-help <r-help at r-project.org<mailto:r-help at r-project.org>>


Hi Spencer,

Thanks for your test results, I do not know the answer as I haven't
used wilcox.test for many years. I do not know if it is possible to compute
the exact distribution of the Wilcoxon rank sum statistic, but I think it
is very likely, as the document of `Wilcoxon` says:

This distribution is obtained as follows. Let x and y be two random,
independent samples of size m and n. Then the Wilcoxon rank sum statistic
is the number of all pairs (x[i], y[j]) for which y[j] is not greater than
x[i]. This statistic takes values between 0 and m * n, and its mean and
variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.

As a nice feature of the non-parametric statistic, it is usually
distribution-free so you can pick any distribution you like to compute the
same statistic. I wonder if this is the case, but I might be wrong.

Cheers,
Jiefei



	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Sun Mar 21 02:41:58 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sun, 21 Mar 2021 09:41:58 +0800
Subject: [R] Surprising behavior and bugs in R 4.0.4
In-Reply-To: <DM6PR01MB3626016DBAA8B0D6F954619E86679@DM6PR01MB3626.prod.exchangelabs.com>
References: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>
 <CAGiFhPMHv68Rtb4wWbtmkXXQGW2zW24U_oEuQ6ev-ttCJfpv7Q@mail.gmail.com>
 <DM6PR01MB3626016DBAA8B0D6F954619E86679@DM6PR01MB3626.prod.exchangelabs.com>
Message-ID: <CAGiFhPO=sF5aJYexMLHtiCXfQnDg-HjKjimXknnSvs9EYJfrpg@mail.gmail.com>

Hi Miso,

It looks like you have a corrupted package library, probably due to some
packages installed from an unofficial repository(e.g. GitHub). I will
suggest first installing the package "spatstat"(This is the package that
should define "markvario"), then try to install "Seurat" again and see if
it works.

If it doesn't work. Please remove all folders under the path shown in
".libPaths()" and reinstall your R, then installing "Seurat" from CRAN
should work.

Best,
Jiefei

On Sun, Mar 21, 2021 at 2:05 AM Miso Na <mna3 at jhu.edu> wrote:

> Thanks for your reply!
>
> Seurat was downloaded from CRAN, with the below code.
>
> > install.packages('Seurat')
>
>
>
> It seems to work, but when I use as library, the error shows up!
>
> > library(Seurat)
>
> Error: package or namespace load failed for ?Seurat?:
>
> object ?markvario? is not exported by 'namespace:spatstat'
>
>
>
> And of course, I tried to download packages ?markvario?, but
>
>
>
> > install.packages('markvario')
>
> Installing package into ?C:/Users/user/Documents/R/win-library/4.0?
>
> (as ?lib? is unspecified)
>
> Warning message:
>
> package ?markvario? is not available for this version of R
>
>
>
> A version of this package for your version of R might be available
> elsewhere,
>
> see the ideas at
>
>
> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages
>
> > install.packages('
> https://cran.r-project.org/src/contrib/Archive/spatstat/spatstat_1.64-1.tar.gz',
> repos=NULL,type="source", INSTALL_opts = "--no-lock")
>
> Installing package into ?C:/Users/user/Documents/R/win-library/4.0?
>
> (as ?lib? is unspecified)
>
> trying URL '
> https://cran.r-project.org/src/contrib/Archive/spatstat/spatstat_1.64-1.tar.gz
> '
>
> Content type 'application/x-gzip' length 7943393 bytes (7.6 MB)
>
> downloaded 7.6 MB
>
>
>
> Error: could not find function "api_create"
>
> Execution halted
>
> Warning message:
>
> In install.packages(
> https://cran.r-project.org/src/contrib/Archive/spatstat/spatstat_1.64-1.tar.gz,
> :
>
>   installation of package
> ?C:/Users/user/AppData/Local/Temp/RtmpWmLFdn/downloaded_packages/spatstat_1.64-1.tar.gz?
> had non-zero exit status
>
>
>
> Thanks,
>
> Miso
>
> *From:* Jiefei Wang <szwjf08 at gmail.com>
> *Sent:* Sunday, March 21, 2021 1:05 AM
> *To:* Miso Na <mna3 at jhu.edu>
> *Cc:* r-help at r-project.org; Ray Cheng <ycheng45 at jhmi.edu>; Patrick Cahan <
> patrick.cahan at jhmi.edu>
> *Subject:* Re: [R] Surprising behavior and bugs in R 4.0.4
>
>
>
>
> *      External Email - Use Caution      *
>
>
>
>
>
> Hi Miso,
>
>
>
> Have you tried to install Seurat from CRAN? What you were using is the
> GitHub version of the package and has been actively updating, so the
> problem might be from the package.
>
>
>
> Best,
>
> Jiefei
>
>
>
> On Sat, Mar 20, 2021 at 10:32 PM Miso Na <mna3 at jhu.edu> wrote:
>
> Dear helpers,
>
> Although I uninstalled and reinstalled R more than 3 times to delete the
> error in api_create, it did not work. The error is representing on the very
> first page on R consol.
> Error: could not find function "api_create"
>
> I guess this error makes impossible to install library 'SCMAP',
> 'SingleCellExperiment' or 'Seurat'.
> For example, I got this error when I tried to install those libraries.
> Installing package into 'C:/Users/user/Documents/R/win-library/4.0'
> (as 'lib' is unspecified)
> Error: could not find function "api_create"
> Execution halted
> Error: Failed to install 'Seurat' from GitHub:
>   (converted from warning) installation of package
> 'C:/Users/user/AppData/Local/Temp/RtmpKYL3Pe/file2c2c6cb0766e/Seurat_4.0.1.tar.gz'
> had non-zero exit status
>
>
> My sessionInfo is here!
>
> > sessionInfo()
> R version 4.0.4 (2021-02-15)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 19041)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> system code page: 949
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.4
>
> Thanks for your help!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> <https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=04%7C01%7Cmna3%40jhu.edu%7Ccb5c11919a794eb1768208d8ebb9e4d4%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637518531387699796%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=eJCLhgeiwB2zy6IYHc3%2Be9Hc8kHYUOiCPbssMg8PBRg%3D&reserved=0>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=04%7C01%7Cmna3%40jhu.edu%7Ccb5c11919a794eb1768208d8ebb9e4d4%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637518531387709792%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=KMjEPl4zrYrj9awZNxr%2FLbgMvAGFAX%2FKZ5I9gd6P0IY%3D&reserved=0>
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Sun Mar 21 02:45:55 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sun, 21 Mar 2021 09:45:55 +0800
Subject: [R] Surprising behavior and bugs in R 4.0.4
In-Reply-To: <CAGiFhPO=sF5aJYexMLHtiCXfQnDg-HjKjimXknnSvs9EYJfrpg@mail.gmail.com>
References: <BN7PR01MB361887042E60595DBEF56D2A86679@BN7PR01MB3618.prod.exchangelabs.com>
 <CAGiFhPMHv68Rtb4wWbtmkXXQGW2zW24U_oEuQ6ev-ttCJfpv7Q@mail.gmail.com>
 <DM6PR01MB3626016DBAA8B0D6F954619E86679@DM6PR01MB3626.prod.exchangelabs.com>
 <CAGiFhPO=sF5aJYexMLHtiCXfQnDg-HjKjimXknnSvs9EYJfrpg@mail.gmail.com>
Message-ID: <CAGiFhPO7J2K9YfLwpRnTKLWZbrX7EPFHXzY0=7RC4LbQq0aWXg@mail.gmail.com>

FYI, you do not have to provide a full link to the function
"install.packages". Please install the package just by
install.package("package name")

Best,
Jiefei

On Sun, Mar 21, 2021 at 9:41 AM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hi Miso,
>
> It looks like you have a corrupted package library, probably due to some
> packages installed from an unofficial repository(e.g. GitHub). I will
> suggest first installing the package "spatstat"(This is the package that
> should define "markvario"), then try to install "Seurat" again and see if
> it works.
>
> If it doesn't work. Please remove all folders under the path shown in
> ".libPaths()" and reinstall your R, then installing "Seurat" from CRAN
> should work.
>
> Best,
> Jiefei
>
> On Sun, Mar 21, 2021 at 2:05 AM Miso Na <mna3 at jhu.edu> wrote:
>
>> Thanks for your reply!
>>
>> Seurat was downloaded from CRAN, with the below code.
>>
>> > install.packages('Seurat')
>>
>>
>>
>> It seems to work, but when I use as library, the error shows up!
>>
>> > library(Seurat)
>>
>> Error: package or namespace load failed for ?Seurat?:
>>
>> object ?markvario? is not exported by 'namespace:spatstat'
>>
>>
>>
>> And of course, I tried to download packages ?markvario?, but
>>
>>
>>
>> > install.packages('markvario')
>>
>> Installing package into ?C:/Users/user/Documents/R/win-library/4.0?
>>
>> (as ?lib? is unspecified)
>>
>> Warning message:
>>
>> package ?markvario? is not available for this version of R
>>
>>
>>
>> A version of this package for your version of R might be available
>> elsewhere,
>>
>> see the ideas at
>>
>>
>> https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages
>>
>> > install.packages('
>> https://cran.r-project.org/src/contrib/Archive/spatstat/spatstat_1.64-1.tar.gz',
>> repos=NULL,type="source", INSTALL_opts = "--no-lock")
>>
>> Installing package into ?C:/Users/user/Documents/R/win-library/4.0?
>>
>> (as ?lib? is unspecified)
>>
>> trying URL '
>> https://cran.r-project.org/src/contrib/Archive/spatstat/spatstat_1.64-1.tar.gz
>> '
>>
>> Content type 'application/x-gzip' length 7943393 bytes (7.6 MB)
>>
>> downloaded 7.6 MB
>>
>>
>>
>> Error: could not find function "api_create"
>>
>> Execution halted
>>
>> Warning message:
>>
>> In install.packages(
>> https://cran.r-project.org/src/contrib/Archive/spatstat/spatstat_1.64-1.tar.gz,
>> :
>>
>>   installation of package
>> ?C:/Users/user/AppData/Local/Temp/RtmpWmLFdn/downloaded_packages/spatstat_1.64-1.tar.gz?
>> had non-zero exit status
>>
>>
>>
>> Thanks,
>>
>> Miso
>>
>> *From:* Jiefei Wang <szwjf08 at gmail.com>
>> *Sent:* Sunday, March 21, 2021 1:05 AM
>> *To:* Miso Na <mna3 at jhu.edu>
>> *Cc:* r-help at r-project.org; Ray Cheng <ycheng45 at jhmi.edu>; Patrick Cahan
>> <patrick.cahan at jhmi.edu>
>> *Subject:* Re: [R] Surprising behavior and bugs in R 4.0.4
>>
>>
>>
>>
>> *      External Email - Use Caution      *
>>
>>
>>
>>
>>
>> Hi Miso,
>>
>>
>>
>> Have you tried to install Seurat from CRAN? What you were using is the
>> GitHub version of the package and has been actively updating, so the
>> problem might be from the package.
>>
>>
>>
>> Best,
>>
>> Jiefei
>>
>>
>>
>> On Sat, Mar 20, 2021 at 10:32 PM Miso Na <mna3 at jhu.edu> wrote:
>>
>> Dear helpers,
>>
>> Although I uninstalled and reinstalled R more than 3 times to delete the
>> error in api_create, it did not work. The error is representing on the very
>> first page on R consol.
>> Error: could not find function "api_create"
>>
>> I guess this error makes impossible to install library 'SCMAP',
>> 'SingleCellExperiment' or 'Seurat'.
>> For example, I got this error when I tried to install those libraries.
>> Installing package into 'C:/Users/user/Documents/R/win-library/4.0'
>> (as 'lib' is unspecified)
>> Error: could not find function "api_create"
>> Execution halted
>> Error: Failed to install 'Seurat' from GitHub:
>>   (converted from warning) installation of package
>> 'C:/Users/user/AppData/Local/Temp/RtmpKYL3Pe/file2c2c6cb0766e/Seurat_4.0.1.tar.gz'
>> had non-zero exit status
>>
>>
>> My sessionInfo is here!
>>
>> > sessionInfo()
>> R version 4.0.4 (2021-02-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 19041)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>> system code page: 949
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_4.0.4
>>
>> Thanks for your help!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> <https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=04%7C01%7Cmna3%40jhu.edu%7Ccb5c11919a794eb1768208d8ebb9e4d4%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637518531387699796%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=eJCLhgeiwB2zy6IYHc3%2Be9Hc8kHYUOiCPbssMg8PBRg%3D&reserved=0>
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=04%7C01%7Cmna3%40jhu.edu%7Ccb5c11919a794eb1768208d8ebb9e4d4%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637518531387709792%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&sdata=KMjEPl4zrYrj9awZNxr%2FLbgMvAGFAX%2FKZ5I9gd6P0IY%3D&reserved=0>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Mar 21 00:50:51 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Mar 2021 16:50:51 -0700
Subject: [R] R-help Digest, Vol 217, Issue 20
In-Reply-To: <E00EF9E0-0255-4501-8417-A500E36EE235@anu.edu.au>
References: <mailman.362575.0.1616238002.57755.r-help@r-project.org>
 <E00EF9E0-0255-4501-8417-A500E36EE235@anu.edu.au>
Message-ID: <CAGxFJbSy4v6Pa84S0wqvbUr6oBEX-P-D6Kwwnb6X65CN6dCRaQ@mail.gmail.com>

... or a George Box (I believe) said: The crucial "Declaration of
Independence."


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Mar 20, 2021 at 4:25 PM John Maindonald <john.maindonald at anu.edu.au>
wrote:

> No, it is not distribution free.  Independent random sampling is assumed.
> That is a non-trivial assumption, and one that is very often not true or
> not
> strictly true.
>
>
> John Maindonald             email: john.maindonald at anu.edu.au<mailto:
> john.maindonald at anu.edu.au>
>
>
> On 21/03/2021, at 00:00, r-help-request at r-project.org<mailto:
> r-help-request at r-project.org> wrote:
>
> From: Jiefei Wang <szwjf08 at gmail.com<mailto:szwjf08 at gmail.com>>
> Subject: Re: [R] about a p-value < 2.2e-16
> Date: 20 March 2021 at 04:41:33 NZDT
> To: Spencer Graves <spencer.graves at effectivedefense.org<mailto:
> spencer.graves at effectivedefense.org>>
> Cc: Bogdan Tanasa <tanasa at gmail.com<mailto:tanasa at gmail.com>>, Vivek Das <
> vd4mmind at gmail.com<mailto:vd4mmind at gmail.com>>, r-help <
> r-help at r-project.org<mailto:r-help at r-project.org>>
>
>
> Hi Spencer,
>
> Thanks for your test results, I do not know the answer as I haven't
> used wilcox.test for many years. I do not know if it is possible to compute
> the exact distribution of the Wilcoxon rank sum statistic, but I think it
> is very likely, as the document of `Wilcoxon` says:
>
> This distribution is obtained as follows. Let x and y be two random,
> independent samples of size m and n. Then the Wilcoxon rank sum statistic
> is the number of all pairs (x[i], y[j]) for which y[j] is not greater than
> x[i]. This statistic takes values between 0 and m * n, and its mean and
> variance are m * n / 2 and m * n * (m + n + 1) / 12, respectively.
>
> As a nice feature of the non-parametric statistic, it is usually
> distribution-free so you can pick any distribution you like to compute the
> same statistic. I wonder if this is the case, but I might be wrong.
>
> Cheers,
> Jiefei
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Sun Mar 21 15:31:10 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Sun, 21 Mar 2021 16:31:10 +0200
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
Message-ID: <s37lbh$svd$1@ciao.gmane.io>

Hi,

I have minutes worked by day (with some more information)

which when using

	library(tidyverse)
	library(lubridate)

run through

	CONSMINUTES %>%
		select(datum, dauer) %>%
		arrange(desc(datum))

look somewhat like

	# A tibble: 142 x 2
	   datum      dauer
	   <date>     <int>
	 1 2021-03-18    30
	 2 2021-03-17    30
	 3 2021-03-16    30
	 4 2021-03-16    30
	 5 2021-03-16    30
	 6 2021-03-16    30
	 7 2021-03-11    30
	 8 2021-03-11    30
	 9 2021-03-11    30
	10 2021-03-11    30
	# ? with 132 more rows

I can extract minutes per hour

	CONSMINUTES %>%
	select(datum, dauer) %>%
	group_by(week = format(datum, '%Y %V'))%>%
	summarise_if(is.numeric, sum)

and minutes per month

	CONSMINUTES %>%
	select(datum, dauer) %>%
	group_by(month = format(datum, '%Y %m'))%>%
	summarise_if(is.numeric, sum)

I need to show the time worked per week per month in the format of

	'# hours # minutes'

and would like to also be able to show the average time per week per
month.

How can I do that (preferably with tidyverse :-)-O)?

greetings, el


From b@k|un@| @end|ng |rom y@hoo@com  Sun Mar 21 17:21:43 2021
From: b@k|un@| @end|ng |rom y@hoo@com (Baki UNAL)
Date: Sun, 21 Mar 2021 16:21:43 +0000 (UTC)
Subject: [R] Rstudio crashed when I try to train a nnet model.
References: <1709238116.929530.1616343703467.ref@mail.yahoo.com>
Message-ID: <1709238116.929530.1616343703467@mail.yahoo.com>

Hi,
I tried to train a neural network with following code:
nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000, maxit=2000)

When I executed the code R studio crashed with following error:
"R Session Aborted
R encountered a fatal error.
The session was terminated.
Start new session"
When I set the hidden layer as c(15) as below the code works fine.
nn2 <- nnet(TQ~.,data = train, size=c(15), linout=T, MaxNWts =4000, maxit=2000)

What could be the problem?

Best regards.


	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Sun Mar 21 17:35:19 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Mon, 22 Mar 2021 00:35:19 +0800
Subject: [R] Rstudio crashed when I try to train a nnet model.
In-Reply-To: <1709238116.929530.1616343703467@mail.yahoo.com>
References: <1709238116.929530.1616343703467.ref@mail.yahoo.com>
 <1709238116.929530.1616343703467@mail.yahoo.com>
Message-ID: <CAGiFhPPPhG9YUbR7_kwhAKkt+vpQ7BEOJNsmZEp0PnWz53JM1w@mail.gmail.com>

Hi Baki,

Perhaps out of memory? Would you be able to run your code through the R
terminal? It probably can give us more information to debug the issue.

Best,
Jiefei

On Mon, Mar 22, 2021 at 12:23 AM Baki UNAL via R-help <r-help at r-project.org>
wrote:

> Hi,
> I tried to train a neural network with following code:
> nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> When I executed the code R studio crashed with following error:
> "R Session Aborted
> R encountered a fatal error.
> The session was terminated.
> Start new session"
> When I set the hidden layer as c(15) as below the code works fine.
> nn2 <- nnet(TQ~.,data = train, size=c(15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> What could be the problem?
>
> Best regards.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From b@k|un@| @end|ng |rom y@hoo@com  Sun Mar 21 17:57:09 2021
From: b@k|un@| @end|ng |rom y@hoo@com (Baki UNAL)
Date: Sun, 21 Mar 2021 16:57:09 +0000 (UTC)
Subject: [R] Rstudio crashed when I try to train a nnet model.
In-Reply-To: <CAGiFhPPPhG9YUbR7_kwhAKkt+vpQ7BEOJNsmZEp0PnWz53JM1w@mail.gmail.com>
References: <1709238116.929530.1616343703467.ref@mail.yahoo.com>
 <1709238116.929530.1616343703467@mail.yahoo.com>
 <CAGiFhPPPhG9YUbR7_kwhAKkt+vpQ7BEOJNsmZEp0PnWz53JM1w@mail.gmail.com>
Message-ID: <1746095704.1153304.1616345829298@mail.yahoo.com>

 Hi?Jiefei
I run the code below in RGui
> nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000, maxit=2000)

But I got the following output:
# weights:? 435initial? value 55650.887782?final? value 55650.887782?converged
Program early converged. Program didn't any calculations.?
Best,Baki
    On Sunday, March 21, 2021, 07:35:31 PM GMT+3, Jiefei Wang <szwjf08 at gmail.com> wrote:  
 
 Hi Baki,
Perhaps out of memory? Would you be able to run your code through the R terminal? It probably can give us more information to debug the issue.?
Best,Jiefei
On Mon, Mar 22, 2021 at 12:23 AM Baki UNAL via R-help <r-help at r-project.org> wrote:

Hi,
I tried to train a neural network with following code:
nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000, maxit=2000)

When I executed the code R studio crashed with following error:
"R Session Aborted
R encountered a fatal error.
The session was terminated.
Start new session"
When I set the hidden layer as c(15) as below the code works fine.
nn2 <- nnet(TQ~.,data = train, size=c(15), linout=T, MaxNWts =4000, maxit=2000)

What could be the problem?

Best regards.


? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From m@hmood@n@der@n @end|ng |rom ugent@be  Sun Mar 21 18:11:55 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Sun, 21 Mar 2021 17:11:55 +0000
Subject: [R] About fviz_famd_ind()
Message-ID: <65ba73090b5f489e8de4c5f352bce3da@ugent.be>

Hi

I use fviz_famd_ind() from factoextra and I would like to know

1) How can I decrease the font size?

2) How to increase max.overlaps?


ind <- get_famd_ind(res.famd)
fviz_famd_ind(res.famd, col.ind = "cos2",
              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
              repel = TRUE)


Regards,
Mahmood

	[[alternative HTML version deleted]]


From dr@@|@m@o|@ng| @end|ng |rom gm@||@com  Sun Mar 21 18:20:21 2021
From: dr@@|@m@o|@ng| @end|ng |rom gm@||@com (Shah Alam)
Date: Sun, 21 Mar 2021 18:20:21 +0100
Subject: [R] Optimization function producing negative parameter values
Message-ID: <CA+bivFhPg_T4SXxSPiBntZtp=rO2cw7U03Apm5k5N0eed3Fkug@mail.gmail.com>

Dear all,

I am using optim() to estimate unknown parameters by minimizing the
residual sums of squares. I created a function with the model. The model is
working fine. The optim function is producing negative parameter values, even
I have introduced upper and lower bounds (given in code). Therefore,
the model produces *NAs*.

Following is my code.

param <<- c(0.002,0.002, 0.14,0.012,0.01,0.02, 0.03, 0.001)# initial
> parameter values
> opt <- optim(param, fn= f.opt, obsdata =obsdata_10000, method= "L-BFGS-B",
> lower = c(0.001, 0.001, 0.08,0.008, 0.009, 0.008, 0.009, 0.001),

upper = c(0.00375, 0.002, 0.2, 0.018, 0.08, 0.08, 0.08, 0.01),
> control=list(maxit=10), hessian = T)


Error:

*"NAs producedError in if (rnd_1 < liferisk) { : missing value where
TRUE/FALSE needed "*

The model function which produces NA due to negative parameter values

liferisk <- rnorm(n = 1, mean =
(calib_para[which(names(calib_para)=="r_mu")]),sd =
(calib_para[which(names(calib_para)=="r_sd")]))

  rnd_1 <- runif(1, 0, 1)

  if (rnd_1 < liferisk) { ca_case <- 1} else {ca_case <- 0}


How to design/ modify optim() function, and upper-lower bounds to stop
producing negative values during parameter search?
Thanks

Best regards,
Shah

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Sun Mar 21 18:29:34 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sun, 21 Mar 2021 13:29:34 -0400
Subject: [R] Optimization function producing negative parameter values
In-Reply-To: <CA+bivFhPg_T4SXxSPiBntZtp=rO2cw7U03Apm5k5N0eed3Fkug@mail.gmail.com>
References: <CA+bivFhPg_T4SXxSPiBntZtp=rO2cw7U03Apm5k5N0eed3Fkug@mail.gmail.com>
Message-ID: <d35fd291-64da-694d-1671-bbc48b23d69f@gmail.com>

Can you put together your example as a single runnable scipt?

If so, I'll try some other tools to see what is going on. There
have been rumours of some glitches in the L-BFGS-B R implementation,
but so far I've not been able to acquire any that I can reproduce.

John Nash (maintainer of optimx package and some other optimization tools)





On 2021-03-21 1:20 p.m., Shah Alam wrote:
> Dear all,
> 
> I am using optim() to estimate unknown parameters by minimizing the
> residual sums of squares. I created a function with the model. The model is
> working fine. The optim function is producing negative parameter values, even
> I have introduced upper and lower bounds (given in code). Therefore,
> the model produces *NAs*.
> 
> Following is my code.
> 
> param <<- c(0.002,0.002, 0.14,0.012,0.01,0.02, 0.03, 0.001)# initial
>> parameter values
>> opt <- optim(param, fn= f.opt, obsdata =obsdata_10000, method= "L-BFGS-B",
>> lower = c(0.001, 0.001, 0.08,0.008, 0.009, 0.008, 0.009, 0.001),
> 
> upper = c(0.00375, 0.002, 0.2, 0.018, 0.08, 0.08, 0.08, 0.01),
>> control=list(maxit=10), hessian = T)
> 
> 
> Error:
> 
> *"NAs producedError in if (rnd_1 < liferisk) { : missing value where
> TRUE/FALSE needed "*
> 
> The model function which produces NA due to negative parameter values
> 
> liferisk <- rnorm(n = 1, mean =
> (calib_para[which(names(calib_para)=="r_mu")]),sd =
> (calib_para[which(names(calib_para)=="r_sd")]))
> 
>   rnd_1 <- runif(1, 0, 1)
> 
>   if (rnd_1 < liferisk) { ca_case <- 1} else {ca_case <- 0}
> 
> 
> How to design/ modify optim() function, and upper-lower bounds to stop
> producing negative values during parameter search?
> Thanks
> 
> Best regards,
> Shah
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@hmood@n@der@n @end|ng |rom ugent@be  Sun Mar 21 18:31:31 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Sun, 21 Mar 2021 17:31:31 +0000
Subject: [R] Colorizing contribution of variables
Message-ID: <f3ac9649dcb54991964a6a6087dcaa7a@ugent.be>

Hi

I use the following function to plot the variables with their contributions.


fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
              repel = TRUE)


The result can be seen at https://i.stack.imgur.com/Kbq1j.png

When I use "quanti.var$contrib" I see multiple dimensions and the question is which dimension is used for colorizing the contributions? For example, is the blue color of V2 related to low contribution on Dim1 or Dim2?


Regards,
Mahmood

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sun Mar 21 18:50:05 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 21 Mar 2021 10:50:05 -0700
Subject: [R] Optimization function producing negative parameter values
In-Reply-To: <CA+bivFhPg_T4SXxSPiBntZtp=rO2cw7U03Apm5k5N0eed3Fkug@mail.gmail.com>
References: <CA+bivFhPg_T4SXxSPiBntZtp=rO2cw7U03Apm5k5N0eed3Fkug@mail.gmail.com>
Message-ID: <CAHqSRuRYB6LqJ=AsX+acCZxEi1fs7-CTLE7LEa=+T39ip2QXDg@mail.gmail.com>

Does optim go out of bounds when you specify hessian=FALSE?
hessian=TRUE causes some out-of-bounds evaluations of f.

> optim(c(X=1,Y=1), function(XY){print(unname(XY));(XY[["X"]]+1)^4+(XY[["Y"]]-2)^4}, method= "L-BFGS-B", lower=c(0.001,0.001), upper=c(1.5,1.5), hessian=TRUE)
[1] 1 1
[1] 1.001 1.000
[1] 0.999 1.000
[1] 1.000 1.001
[1] 1.000 0.999
[1] 0.001 1.500
[1] 0.002 1.500
[1] 0.001 1.500
[1] 0.001 1.500
[1] 0.001 1.499
[1] 0.003 1.500
[1] 0.001 1.500
[1] 0.002 1.501
[1] 0.002 1.499
[1] 0.001 1.500
[1] -0.001  1.500
[1] 0.000 1.501
[1] 0.000 1.499
[1] 0.002 1.501
[1] 0.000 1.501
[1] 0.001 1.502
[1] 0.001 1.500
[1] 0.002 1.499
[1] 0.000 1.499
[1] 0.001 1.500
[1] 0.001 1.498
$par
    X     Y
0.001 1.500

$value
[1] 1.066506

On Sun, Mar 21, 2021 at 10:22 AM Shah Alam <dr.alamsolangi at gmail.com> wrote:
>
> Dear all,
>
> I am using optim() to estimate unknown parameters by minimizing the
> residual sums of squares. I created a function with the model. The model is
> working fine. The optim function is producing negative parameter values, even
> I have introduced upper and lower bounds (given in code). Therefore,
> the model produces *NAs*.
>
> Following is my code.
>
> param <<- c(0.002,0.002, 0.14,0.012,0.01,0.02, 0.03, 0.001)# initial
> > parameter values
> > opt <- optim(param, fn= f.opt, obsdata =obsdata_10000, method= "L-BFGS-B",
> > lower = c(0.001, 0.001, 0.08,0.008, 0.009, 0.008, 0.009, 0.001),
>
> upper = c(0.00375, 0.002, 0.2, 0.018, 0.08, 0.08, 0.08, 0.01),
> > control=list(maxit=10), hessian = T)
>
>
> Error:
>
> *"NAs producedError in if (rnd_1 < liferisk) { : missing value where
> TRUE/FALSE needed "*
>
> The model function which produces NA due to negative parameter values
>
> liferisk <- rnorm(n = 1, mean =
> (calib_para[which(names(calib_para)=="r_mu")]),sd =
> (calib_para[which(names(calib_para)=="r_sd")]))
>
>   rnd_1 <- runif(1, 0, 1)
>
>   if (rnd_1 < liferisk) { ca_case <- 1} else {ca_case <- 0}
>
>
> How to design/ modify optim() function, and upper-lower bounds to stop
> producing negative values during parameter search?
> Thanks
>
> Best regards,
> Shah
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pro|jcn@@h @end|ng |rom gm@||@com  Sun Mar 21 18:58:03 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sun, 21 Mar 2021 13:58:03 -0400
Subject: [R] Optimization function producing negative parameter values
In-Reply-To: <CAHqSRuRYB6LqJ=AsX+acCZxEi1fs7-CTLE7LEa=+T39ip2QXDg@mail.gmail.com>
References: <CA+bivFhPg_T4SXxSPiBntZtp=rO2cw7U03Apm5k5N0eed3Fkug@mail.gmail.com>
 <CAHqSRuRYB6LqJ=AsX+acCZxEi1fs7-CTLE7LEa=+T39ip2QXDg@mail.gmail.com>
Message-ID: <67ff1a99-71de-9a94-debe-bce5b8fad12f@gmail.com>

This is likely because Hessian is being approximated.

Numerical approximation to Hessian will overstep the bounds because
the routines that are called don't respect the bounds (they likely
don't have the bounds available).

Writing numerical approximations that respect bounds and other constraints
is an interesting and very challenging problem. It's likely a lot easier to
do the work and get the derivatives analytically.

JN

On 2021-03-21 1:50 p.m., Bill Dunlap wrote:
> Does optim go out of bounds when you specify hessian=FALSE?
> hessian=TRUE causes some out-of-bounds evaluations of f.
> 
>> optim(c(X=1,Y=1), function(XY){print(unname(XY));(XY[["X"]]+1)^4+(XY[["Y"]]-2)^4}, method= "L-BFGS-B", lower=c(0.001,0.001), upper=c(1.5,1.5), hessian=TRUE)
> [1] 1 1
> [1] 1.001 1.000
> [1] 0.999 1.000
> [1] 1.000 1.001
> [1] 1.000 0.999
> [1] 0.001 1.500
> [1] 0.002 1.500
> [1] 0.001 1.500
> [1] 0.001 1.500
> [1] 0.001 1.499
> [1] 0.003 1.500
> [1] 0.001 1.500
> [1] 0.002 1.501
> [1] 0.002 1.499
> [1] 0.001 1.500
> [1] -0.001  1.500
> [1] 0.000 1.501
> [1] 0.000 1.499
> [1] 0.002 1.501
> [1] 0.000 1.501
> [1] 0.001 1.502
> [1] 0.001 1.500
> [1] 0.002 1.499
> [1] 0.000 1.499
> [1] 0.001 1.500
> [1] 0.001 1.498
> $par
>     X     Y
> 0.001 1.500
> 
> $value
> [1] 1.066506
> 
> On Sun, Mar 21, 2021 at 10:22 AM Shah Alam <dr.alamsolangi at gmail.com> wrote:
>>
>> Dear all,
>>
>> I am using optim() to estimate unknown parameters by minimizing the
>> residual sums of squares. I created a function with the model. The model is
>> working fine. The optim function is producing negative parameter values, even
>> I have introduced upper and lower bounds (given in code). Therefore,
>> the model produces *NAs*.
>>
>> Following is my code.
>>
>> param <<- c(0.002,0.002, 0.14,0.012,0.01,0.02, 0.03, 0.001)# initial
>>> parameter values
>>> opt <- optim(param, fn= f.opt, obsdata =obsdata_10000, method= "L-BFGS-B",
>>> lower = c(0.001, 0.001, 0.08,0.008, 0.009, 0.008, 0.009, 0.001),
>>
>> upper = c(0.00375, 0.002, 0.2, 0.018, 0.08, 0.08, 0.08, 0.01),
>>> control=list(maxit=10), hessian = T)
>>
>>
>> Error:
>>
>> *"NAs producedError in if (rnd_1 < liferisk) { : missing value where
>> TRUE/FALSE needed "*
>>
>> The model function which produces NA due to negative parameter values
>>
>> liferisk <- rnorm(n = 1, mean =
>> (calib_para[which(names(calib_para)=="r_mu")]),sd =
>> (calib_para[which(names(calib_para)=="r_sd")]))
>>
>>   rnd_1 <- runif(1, 0, 1)
>>
>>   if (rnd_1 < liferisk) { ca_case <- 1} else {ca_case <- 0}
>>
>>
>> How to design/ modify optim() function, and upper-lower bounds to stop
>> producing negative values during parameter search?
>> Thanks
>>
>> Best regards,
>> Shah
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From z@nkrut20 @end|ng |rom gm@||@com  Sun Mar 21 17:55:56 2021
From: z@nkrut20 @end|ng |rom gm@||@com (Goyani Zankrut)
Date: Sun, 21 Mar 2021 22:25:56 +0530
Subject: [R] for loop implementation in below problem
Message-ID: <CAF-BbQpKtyrvsYtEegom5WiKxFQw9SCi12W2pqWcYGBJp=EaOQ@mail.gmail.com>

I created custom function according to my requirement which is given below:














*selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){  ID =
toString(ID)  p<- as.matrix(phen_mat)  g<- as.matrix(gen_mat)  w<-
as.matrix(weight_mat)  bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5  PRE<-
if(missing(GAY)){    (GA/GA) * 100  } else {    (GA/GAY) * 100  }  result<-
list("ID" = ID, "b" = matrix(round(bmat,4), nrow = 1), "GA" = round(GA,4),
"PRE" = round(PRE,4))  return(data.frame(result))}*

*sc<- list()*
*sc[[1]]<- selection.index(ID = 12, pmat[1:2,1:2], gmat[1:2,1:2],
wmat[1:2,1])*
*sc[[2]]<- selection.index(ID = 13, pmat[c(1,3),c(1,3)],
gmat[c(1,3),c(1,3)], wmat[c(1,3),1])*

for more detail about question follow stack overflow link:
https://stackoverflow.com/questions/66734928/how-to-solve-this-through-loop
*"Healthy soil, Healthy life."*
*"A war based on Satyagraha is always of two kinds. One is the war we wage
against injustice, and the other we fight our won weaknesses."* - *Sardar
Patel*
*"You have to dream before your dreams can come true."* - *A. P. J.* *Abdul
Kalam*
*"Think before you print and save a tree."*

*ZANKRUT GOYANI*
*B.Sc. (Hons.) Agriculture*

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sun Mar 21 20:26:55 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Sun, 21 Mar 2021 15:26:55 -0400
Subject: [R] Colorizing contribution of variables
In-Reply-To: <f3ac9649dcb54991964a6a6087dcaa7a@ugent.be>
References: <f3ac9649dcb54991964a6a6087dcaa7a@ugent.be>
Message-ID: <CAM_vju=WZLeEYO_O8tZaO+i0VqArK2zWhP9f7BDvUzvk0MiUcQ@mail.gmail.com>

Hi,

I am going to assume that you are using factoextra, and are working
the example from the function in question, but it would be useful for
you to explicitly state that when you're asking a question about a
particular package and function.

When you choose the argument "contrib" the colors are based on the
strength of the relationship overall (the length of the arrow), not
the contribution of any individual direction.

See here http://www.sthda.com/english/wiki/factoextra-r-package-easy-multivariate-data-analyses-and-elegant-visualization
and the various other sources of documentation for the packages.

Sarah

On Sun, Mar 21, 2021 at 1:32 PM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi
>
> I use the following function to plot the variables with their contributions.
>
>
> fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
>               gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
>               repel = TRUE)
>
>
> The result can be seen at https://i.stack.imgur.com/Kbq1j.png
>
> When I use "quanti.var$contrib" I see multiple dimensions and the question is which dimension is used for colorizing the contributions? For example, is the blue color of V2 related to low contribution on Dim1 or Dim2?
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sun Mar 21 20:29:36 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Sun, 21 Mar 2021 15:29:36 -0400
Subject: [R] About fviz_famd_ind()
In-Reply-To: <65ba73090b5f489e8de4c5f352bce3da@ugent.be>
References: <65ba73090b5f489e8de4c5f352bce3da@ugent.be>
Message-ID: <CAM_vju=hEjyaLKrW11Uz30yY0DA6LyNK_n_xUTnAd3Kp0MkHGw@mail.gmail.com>

The way to start is looking at the help for that function, which includes:

... Arguments to be passed to the function fviz()

so you may have more low-level control through those arguments. If
fviz() itself doesn't do what you want, it also allows you to pass
additional arguments to its lower-level functions. If you go down far
enough, you should be able to control everything.

Sarah

On Sun, Mar 21, 2021 at 1:12 PM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi
>
> I use fviz_famd_ind() from factoextra and I would like to know
>
> 1) How can I decrease the font size?
>
> 2) How to increase max.overlaps?
>
>
> ind <- get_famd_ind(res.famd)
> fviz_famd_ind(res.famd, col.ind = "cos2",
>               gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
>               repel = TRUE)
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From m@hmood@n@der@n @end|ng |rom ugent@be  Sun Mar 21 21:07:15 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Sun, 21 Mar 2021 20:07:15 +0000
Subject: [R] Colorizing contribution of variables
In-Reply-To: <CAM_vju=WZLeEYO_O8tZaO+i0VqArK2zWhP9f7BDvUzvk0MiUcQ@mail.gmail.com>
References: <f3ac9649dcb54991964a6a6087dcaa7a@ugent.be>,
 <CAM_vju=WZLeEYO_O8tZaO+i0VqArK2zWhP9f7BDvUzvk0MiUcQ@mail.gmail.com>
Message-ID: <e6e80627eb614a8f832c05d8f67ce9a6@ugent.be>

Yes I am using factoextra.


>When you choose the argument "contrib" the colors are based on the
>strength of the relationship overall (the length of the arrow), not
>the contribution of any individual direction.


Then, the question is why the legend is not in 0 to 1 scale?


Regards,
Mahmood

________________________________
From: Sarah Goslee <sarah.goslee at gmail.com>
Sent: Sunday, March 21, 2021 8:26:55 PM
To: Mahmood Naderan-Tahan
Cc: r-help at r-project.org
Subject: Re: [R] Colorizing contribution of variables

Hi,

I am going to assume that you are using factoextra, and are working
the example from the function in question, but it would be useful for
you to explicitly state that when you're asking a question about a
particular package and function.

When you choose the argument "contrib" the colors are based on the
strength of the relationship overall (the length of the arrow), not
the contribution of any individual direction.

See here http://www.sthda.com/english/wiki/factoextra-r-package-easy-multivariate-data-analyses-and-elegant-visualization
and the various other sources of documentation for the packages.

Sarah

On Sun, Mar 21, 2021 at 1:32 PM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi
>
> I use the following function to plot the variables with their contributions.
>
>
> fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
>               gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
>               repel = TRUE)
>
>
> The result can be seen at https://i.stack.imgur.com/Kbq1j.png
>
> When I use "quanti.var$contrib" I see multiple dimensions and the question is which dimension is used for colorizing the contributions? For example, is the blue color of V2 related to low contribution on Dim1 or Dim2?
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Sarah Goslee (she/her)
http://www.numberwright.com

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun Mar 21 22:14:43 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 22 Mar 2021 08:14:43 +1100
Subject: [R] for loop implementation in below problem
In-Reply-To: <CAF-BbQpKtyrvsYtEegom5WiKxFQw9SCi12W2pqWcYGBJp=EaOQ@mail.gmail.com>
References: <CAF-BbQpKtyrvsYtEegom5WiKxFQw9SCi12W2pqWcYGBJp=EaOQ@mail.gmail.com>
Message-ID: <CA+8X3fUccRDdRxx6JuKaDWorU+P3z7E8YcLbsyBnF0hBzxCCEg@mail.gmail.com>

Hi Goyani,
In its present form, the function stalls because you haven't defined
pmat before trying to pass it to the function. gmat and wmat suffered
the same fate. Even if I define these matrices as I think you have,
"solve" fails because at least one is singular. First, put the
function in order as below. I think this is what you sent made
readable.

selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
 ID<-toString(ID)
 p<-as.matrix(phen_mat)
 g<-as.matrix(gen_mat)
 w<-as.matrix(weight_mat)
 bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
 GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
 if(missing(GAY)) PRE<-(GA/GA) * 100
 else PRE<-(GA/GAY) * 100
 result<-list(ID=ID,b=matrix(round(bmat,4),nrow=1),
  GA=round(GA,4),PRE=round(PRE,4))
 return(data.frame(result))
}

Next, what sort of matrices do you want to pass? Then an answer may emerge.

Jim

On Mon, Mar 22, 2021 at 6:03 AM Goyani Zankrut <zankrut20 at gmail.com> wrote:
>
> I created custom function according to my requirement which is given below:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> *selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){  ID =
> toString(ID)  p<- as.matrix(phen_mat)  g<- as.matrix(gen_mat)  w<-
> as.matrix(weight_mat)  bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
> GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5  PRE<-
> if(missing(GAY)){    (GA/GA) * 100  } else {    (GA/GAY) * 100  }  result<-
> list("ID" = ID, "b" = matrix(round(bmat,4), nrow = 1), "GA" = round(GA,4),
> "PRE" = round(PRE,4))  return(data.frame(result))}*
>
> *sc<- list()*
> *sc[[1]]<- selection.index(ID = 12, pmat[1:2,1:2], gmat[1:2,1:2],
> wmat[1:2,1])*
> *sc[[2]]<- selection.index(ID = 13, pmat[c(1,3),c(1,3)],
> gmat[c(1,3),c(1,3)], wmat[c(1,3),1])*
>
> for more detail about question follow stack overflow link:
> https://stackoverflow.com/questions/66734928/how-to-solve-this-through-loop
> *"Healthy soil, Healthy life."*
> *"A war based on Satyagraha is always of two kinds. One is the war we wage
> against injustice, and the other we fight our won weaknesses."* - *Sardar
> Patel*
> *"You have to dream before your dreams can come true."* - *A. P. J.* *Abdul
> Kalam*
> *"Think before you print and save a tree."*
>
> *ZANKRUT GOYANI*
> *B.Sc. (Hons.) Agriculture*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @zwj|08 @end|ng |rom gm@||@com  Mon Mar 22 04:54:46 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Mon, 22 Mar 2021 11:54:46 +0800
Subject: [R] Rstudio crashed when I try to train a nnet model.
In-Reply-To: <1746095704.1153304.1616345829298@mail.yahoo.com>
References: <1709238116.929530.1616343703467.ref@mail.yahoo.com>
 <1709238116.929530.1616343703467@mail.yahoo.com>
 <CAGiFhPPPhG9YUbR7_kwhAKkt+vpQ7BEOJNsmZEp0PnWz53JM1w@mail.gmail.com>
 <1746095704.1153304.1616345829298@mail.yahoo.com>
Message-ID: <CAGiFhPNuVqe6i-Evc2yWxCwyAb9+1pfsrc2t-eu=rtmr=O_LVg@mail.gmail.com>

Hi Baki,

This should be a different issue. It looks like there is no problem in the
R terminal. Does the crash happen every time when you run the code in
RStudio? If so, this should be a bug in RStudio and you need to consult
RStudio's mailing list as R and RStudio are maintained by different teams.

Best,
Jiefei

On Mon, Mar 22, 2021 at 12:57 AM Baki UNAL <bakiunal at yahoo.com> wrote:

> Hi Jiefei
>
> I run the code below in RGui
>
> > nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> But I got the following output:
>
> # weights:  435
> initial  value 55650.887782
> final  value 55650.887782
> converged
>
> Program early converged. Program didn't any calculations.
>
> Best,
> Baki
>
> On Sunday, March 21, 2021, 07:35:31 PM GMT+3, Jiefei Wang <
> szwjf08 at gmail.com> wrote:
>
>
> Hi Baki,
>
> Perhaps out of memory? Would you be able to run your code through the R
> terminal? It probably can give us more information to debug the issue.
>
> Best,
> Jiefei
>
> On Mon, Mar 22, 2021 at 12:23 AM Baki UNAL via R-help <
> r-help at r-project.org> wrote:
>
> Hi,
> I tried to train a neural network with following code:
> nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> When I executed the code R studio crashed with following error:
> "R Session Aborted
> R encountered a fatal error.
> The session was terminated.
> Start new session"
> When I set the hidden layer as c(15) as below the code works fine.
> nn2 <- nnet(TQ~.,data = train, size=c(15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> What could be the problem?
>
> Best regards.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From nev||@@mo@ @end|ng |rom gm@||@com  Mon Mar 22 06:18:56 2021
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Mon, 22 Mar 2021 16:18:56 +1100
Subject: [R] using aws.s3::s3 sync to dowlaod files from public s3 Bucket
 without credentials?
Message-ID: <CAN9eD7mEjH31RzHqWxwTwag-GbXFC87zk=9Me=TF01wcEyt8uw@mail.gmail.com>

Hi I am developing a package that reives on some large datasets stored in
aws s3.
I have made the bucket and all objects in the bucket public, but still
cannot sync them to my local directory without providing my AWS key pair.
without these credentials I get a "bucket does not exist" message.

Should it be possible to "see" and use
Sys.setenv("AWS_DEFAULT_REGION" =MYDEFAULTREGION)
aws.s3::s3sync (path ="./", bucket=MYBUCKETNAME,check_region = F,direction
= "download")

to download the bucket contents without providing a keypair where both
bucket and contents are public?

thanks

Nevil Amos

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Mar 22 06:59:13 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 22 Mar 2021 16:59:13 +1100
Subject: [R] for loop implementation in below problem
In-Reply-To: <CAF-BbQqHEDu5miar+mQiRV7J5VVKU9K4bPdHz-m02+wOeUc06g@mail.gmail.com>
References: <CAF-BbQpKtyrvsYtEegom5WiKxFQw9SCi12W2pqWcYGBJp=EaOQ@mail.gmail.com>
 <CA+8X3fUccRDdRxx6JuKaDWorU+P3z7E8YcLbsyBnF0hBzxCCEg@mail.gmail.com>
 <CAF-BbQqHEDu5miar+mQiRV7J5VVKU9K4bPdHz-m02+wOeUc06g@mail.gmail.com>
Message-ID: <CA+8X3fXt_KsFGXHdZutg8A2vCuXGn2_wODxSSE6RsfKbqBt3jQ@mail.gmail.com>

Hi Goyani,
You are setting "PRE" to the return value of "if" which is one of TRUE
(1), FALSE(0) or NULL. Because GAY is always missing in your example,
"PRE" is always set to 1. Then you always want to pass 1 in the sample
list, and that will not assign anything to PRE. By correcting the "if"
clause and defining matrices that are unlikely to be singular, I can
run a "for" loop as follows:

selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
 p<-as.matrix(phen_mat)
 g<-as.matrix(gen_mat)
 w<-as.matrix(weight_mat)
 bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
 GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
 if(missing(GAY)) PRE<-(GA/GA) * 100
 else PRE<-(GA/GAY) * 100
 result<-list(ID=ID,b=matrix(round(bmat,4),nrow=1),
  GA=round(GA,4),PRE=round(PRE,4))
 return(data.frame(result))
}

pmat<-matrix(sample(1:16,16),4)
gmat<-matrix(sample(17:32),16,4)
wmat<-matrix(sample(1:4,4),4)

mi<-combn(1:4,2)
sc<-list()
for(i in 1:ncol(matindx)) {
 as.numeric(ID<-paste0(mi[,i]))
 sc[[i]]<-selection.index(ID,pmat[mi[,i],mi[,i]],gmat[mi[,i],mi[,i]],
  wmat[mi[,i]],1)
}

This produces output for me. Good luck with whatever you are doing with this.

Jim





On Mon, Mar 22, 2021 at 2:51 PM Goyani Zankrut <zankrut20 at gmail.com> wrote:
>
> Greetings of the day,
> Thank you for your response, Sir.
> The full problem statement is given below:
>
> In our case, I'm taking 4 traits.
> library(arrangements)
> a<- combinations(4,2) # gives 6 pairwise combinations
> class(a) # it's a "matrix" "array"
>
> now hypothetical data of three matrix for further calculation:
> pmat<- matrix(1:16, nrow = 4)
> gmat<- matrix(17:32, nrow = 4)
> wmat<- matrix(1:4, nrow = 4)
>
> My custom function for further calculations:
> selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
>   ID = toString(ID)
>   p<- as.matrix(phen_mat)
>   g<- as.matrix(gen_mat)
>   w<- as.matrix(weight_mat)
>   bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
>   GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
>   PRE<- if(missing(GAY)){
>     (GA/GA) * 100
>   } else {
>     (GA/GAY) * 100
>   }
>   result<- list("ID" = ID, "b" = matrix(round(bmat,4), nrow = 1), "GA" = round(GA,4), "PRE" = round(PRE,4))
>   return(data.frame(result))
> }
>
> Now I want to store this data into a list for further calculation:
> sc<- list()
> sc[[1]]<- selection.index(ID = 12, phen_mat = pmat[c(1,2),c(1,2)], gen_mat = gmat[c(1,2),c(1,2)], weight_mat = wmat[c(1,2),1])
> sc[[2]]<- selection.index(ID = 13, phen_mat = pmat[c(1,3),c(1,3)], gen_mat = gmat[c(1,3),c(1,3)], weight_mat = wmat[c(1,3),1])
> sc[[3]]<- selection.index(ID = 14, phen_mat = pmat[c(1,4),c(1,4)], gen_mat = gmat[c(1,4),c(1,4)], weight_mat = wmat[c(1,4),1])
> sc[[4]]<- selection.index(ID = 23, phen_mat = pmat[c(2,3),c(2,3)], gen_mat = gmat[c(2,3),c(2,3)], weight_mat = wmat[c(2,3),1])
> sc[[5]]<- selection.index(ID = 24, phen_mat = pmat[c(2,4),c(2,4)], gen_mat = gmat[c(2,4),c(2,4)], weight_mat = wmat[c(2,4),1])
> sc[[6]]<- selection.index(ID = 34, phen_mat = pmat[c(3,4),c(3,4)], gen_mat = gmat[c(3,4),c(3,4)], weight_mat = wmat[c(3,4),1])
> above list code is monotonous and time consuming for large data combination cycles like (7,2) = 21 combinations, (10,2) = 45 combinations. So I want to use the matrix a's each row as a vector in the selection.index function and result stores in a list.
>
> I hope now you will understand the full problem. I have checked the selection.index which has no issues and works well.
> Thank you.
>


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Mar 22 08:25:43 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 22 Mar 2021 07:25:43 +0000
Subject: [R] About fviz_famd_ind()
In-Reply-To: <CAM_vju=hEjyaLKrW11Uz30yY0DA6LyNK_n_xUTnAd3Kp0MkHGw@mail.gmail.com>
References: <65ba73090b5f489e8de4c5f352bce3da@ugent.be>
 <CAM_vju=hEjyaLKrW11Uz30yY0DA6LyNK_n_xUTnAd3Kp0MkHGw@mail.gmail.com>
Message-ID: <e6e340a97b904c2fbe93396157cdece4@SRVEXCHCM1302.precheza.cz>

Hallo

However sometimes it could be easier to fine tune simple biplot function.

fit <- prcomp(iris[,-5])
biplot(fit, col=c("white", "grey"), xlim=c(-.15,.15), ylim=c(-0.05, .05),
expand=1)
points(fit$x[,1:2]*3, pch=c(17, 19)[as.numeric(iris$Sepal.Length<6)+1],
col=c(2,4)[as.numeric(iris$Petal.Length<5)+1], cex=2)
box()

You could use various pch, col and cex for points. You could annotate points
with text function. You could add legends.

Cheers.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Sarah Goslee
> Sent: Sunday, March 21, 2021 8:30 PM
> To: Mahmood Naderan-Tahan <mahmood.naderan at ugent.be>
> Cc: r-help at r-project.org
> Subject: Re: [R] About fviz_famd_ind()
> 
> The way to start is looking at the help for that function, which includes:
> 
> ... Arguments to be passed to the function fviz()
> 
> so you may have more low-level control through those arguments. If
> fviz() itself doesn't do what you want, it also allows you to pass
additional
> arguments to its lower-level functions. If you go down far enough, you
should
> be able to control everything.
> 
> Sarah
> 
> On Sun, Mar 21, 2021 at 1:12 PM Mahmood Naderan-Tahan
> <mahmood.naderan at ugent.be> wrote:
> >
> > Hi
> >
> > I use fviz_famd_ind() from factoextra and I would like to know
> >
> > 1) How can I decrease the font size?
> >
> > 2) How to increase max.overlaps?
> >
> >
> > ind <- get_famd_ind(res.famd)
> > fviz_famd_ind(res.famd, col.ind = "cos2",
> >               gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
> >               repel = TRUE)
> >
> >
> > Regards,
> > Mahmood
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From petr@p|k@| @end|ng |rom prechez@@cz  Mon Mar 22 08:44:51 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 22 Mar 2021 07:44:51 +0000
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <s37lbh$svd$1@ciao.gmane.io>
References: <s37lbh$svd$1@ciao.gmane.io>
Message-ID: <8e4e35793843478dbcaec92baaaa3c61@SRVEXCHCM1302.precheza.cz>

Hallo

Sorry I cannot help you in tidyverse. I would use aggregate together with format

aggregate(whatever, list(format(datum, "%Y")), sum)
aggregate(whatever, list(format(datum, "%m")), sum)

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Eberhard W
> Lisse
> Sent: Sunday, March 21, 2021 3:31 PM
> To: r-help at r-project.org
> Subject: [R] How to average minutes per hour per month in the form of '# hours
> #minutes'
> 
> Hi,
> 
> I have minutes worked by day (with some more information)
> 
> which when using
> 
> 	library(tidyverse)
> 	library(lubridate)
> 
> run through
> 
> 	CONSMINUTES %>%
> 		select(datum, dauer) %>%
> 		arrange(desc(datum))
> 
> look somewhat like
> 
> 	# A tibble: 142 x 2
> 	   datum      dauer
> 	   <date>     <int>
> 	 1 2021-03-18    30
> 	 2 2021-03-17    30
> 	 3 2021-03-16    30
> 	 4 2021-03-16    30
> 	 5 2021-03-16    30
> 	 6 2021-03-16    30
> 	 7 2021-03-11    30
> 	 8 2021-03-11    30
> 	 9 2021-03-11    30
> 	10 2021-03-11    30
> 	# ? with 132 more rows
> 
> I can extract minutes per hour
> 
> 	CONSMINUTES %>%
> 	select(datum, dauer) %>%
> 	group_by(week = format(datum, '%Y %V'))%>%
> 	summarise_if(is.numeric, sum)
> 
> and minutes per month
> 
> 	CONSMINUTES %>%
> 	select(datum, dauer) %>%
> 	group_by(month = format(datum, '%Y %m'))%>%
> 	summarise_if(is.numeric, sum)
> 
> I need to show the time worked per week per month in the format of
> 
> 	'# hours # minutes'
> 
> and would like to also be able to show the average time per week per month.
> 
> How can I do that (preferably with tidyverse :-)-O)?
> 
> greetings, el
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Mar 22 10:34:37 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 22 Mar 2021 05:34:37 -0400
Subject: [R] for loop implementation in below problem
In-Reply-To: <CA+8X3fXt_KsFGXHdZutg8A2vCuXGn2_wODxSSE6RsfKbqBt3jQ@mail.gmail.com>
References: <CAF-BbQpKtyrvsYtEegom5WiKxFQw9SCi12W2pqWcYGBJp=EaOQ@mail.gmail.com>
 <CA+8X3fUccRDdRxx6JuKaDWorU+P3z7E8YcLbsyBnF0hBzxCCEg@mail.gmail.com>
 <CAF-BbQqHEDu5miar+mQiRV7J5VVKU9K4bPdHz-m02+wOeUc06g@mail.gmail.com>
 <CA+8X3fXt_KsFGXHdZutg8A2vCuXGn2_wODxSSE6RsfKbqBt3jQ@mail.gmail.com>
Message-ID: <c2e700dc-cfea-e03b-b7eb-16f09c35fa91@gmail.com>

On 22/03/2021 1:59 a.m., Jim Lemon wrote:
> Hi Goyani,
> You are setting "PRE" to the return value of "if" which is one of TRUE
> (1), FALSE(0) or NULL. 

That's not true at all.  The statement was

     PRE<- if(missing(GAY)){
       (GA/GA) * 100
     } else {
       (GA/GAY) * 100
     }

so the result is (GA/GA) * 100 or (GA/GAY)*100.

> Because GAY is always missing in your example,

If that's true and GA isn't missing, the result will always be 100.

Duncan Murdoch

> "PRE" is always set to 1. Then you always want to pass 1 in the sample
> list, and that will not assign anything to PRE. By correcting the "if"
> clause and defining matrices that are unlikely to be singular, I can
> run a "for" loop as follows:
> 
> selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
>   p<-as.matrix(phen_mat)
>   g<-as.matrix(gen_mat)
>   w<-as.matrix(weight_mat)
>   bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
>   GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
>   if(missing(GAY)) PRE<-(GA/GA) * 100
>   else PRE<-(GA/GAY) * 100
>   result<-list(ID=ID,b=matrix(round(bmat,4),nrow=1),
>    GA=round(GA,4),PRE=round(PRE,4))
>   return(data.frame(result))
> }
> 
> pmat<-matrix(sample(1:16,16),4)
> gmat<-matrix(sample(17:32),16,4)
> wmat<-matrix(sample(1:4,4),4)
> 
> mi<-combn(1:4,2)
> sc<-list()
> for(i in 1:ncol(matindx)) {
>   as.numeric(ID<-paste0(mi[,i]))
>   sc[[i]]<-selection.index(ID,pmat[mi[,i],mi[,i]],gmat[mi[,i],mi[,i]],
>    wmat[mi[,i]],1)
> }
> 
> This produces output for me. Good luck with whatever you are doing with this.
> 
> Jim
> 
> 
> 
> 
> 
> On Mon, Mar 22, 2021 at 2:51 PM Goyani Zankrut <zankrut20 at gmail.com> wrote:
>>
>> Greetings of the day,
>> Thank you for your response, Sir.
>> The full problem statement is given below:
>>
>> In our case, I'm taking 4 traits.
>> library(arrangements)
>> a<- combinations(4,2) # gives 6 pairwise combinations
>> class(a) # it's a "matrix" "array"
>>
>> now hypothetical data of three matrix for further calculation:
>> pmat<- matrix(1:16, nrow = 4)
>> gmat<- matrix(17:32, nrow = 4)
>> wmat<- matrix(1:4, nrow = 4)
>>
>> My custom function for further calculations:
>> selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
>>    ID = toString(ID)
>>    p<- as.matrix(phen_mat)
>>    g<- as.matrix(gen_mat)
>>    w<- as.matrix(weight_mat)
>>    bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
>>    GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
>>    PRE<- if(missing(GAY)){
>>      (GA/GA) * 100
>>    } else {
>>      (GA/GAY) * 100
>>    }
>>    result<- list("ID" = ID, "b" = matrix(round(bmat,4), nrow = 1), "GA" = round(GA,4), "PRE" = round(PRE,4))
>>    return(data.frame(result))
>> }
>>
>> Now I want to store this data into a list for further calculation:
>> sc<- list()
>> sc[[1]]<- selection.index(ID = 12, phen_mat = pmat[c(1,2),c(1,2)], gen_mat = gmat[c(1,2),c(1,2)], weight_mat = wmat[c(1,2),1])
>> sc[[2]]<- selection.index(ID = 13, phen_mat = pmat[c(1,3),c(1,3)], gen_mat = gmat[c(1,3),c(1,3)], weight_mat = wmat[c(1,3),1])
>> sc[[3]]<- selection.index(ID = 14, phen_mat = pmat[c(1,4),c(1,4)], gen_mat = gmat[c(1,4),c(1,4)], weight_mat = wmat[c(1,4),1])
>> sc[[4]]<- selection.index(ID = 23, phen_mat = pmat[c(2,3),c(2,3)], gen_mat = gmat[c(2,3),c(2,3)], weight_mat = wmat[c(2,3),1])
>> sc[[5]]<- selection.index(ID = 24, phen_mat = pmat[c(2,4),c(2,4)], gen_mat = gmat[c(2,4),c(2,4)], weight_mat = wmat[c(2,4),1])
>> sc[[6]]<- selection.index(ID = 34, phen_mat = pmat[c(3,4),c(3,4)], gen_mat = gmat[c(3,4),c(3,4)], weight_mat = wmat[c(3,4),1])
>> above list code is monotonous and time consuming for large data combination cycles like (7,2) = 21 combinations, (10,2) = 45 combinations. So I want to use the matrix a's each row as a vector in the selection.index function and result stores in a list.
>>
>> I hope now you will understand the full problem. I have checked the selection.index which has no issues and works well.
>> Thank you.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drj|m|emon @end|ng |rom gm@||@com  Mon Mar 22 11:35:44 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 22 Mar 2021 21:35:44 +1100
Subject: [R] for loop implementation in below problem
In-Reply-To: <c2e700dc-cfea-e03b-b7eb-16f09c35fa91@gmail.com>
References: <CAF-BbQpKtyrvsYtEegom5WiKxFQw9SCi12W2pqWcYGBJp=EaOQ@mail.gmail.com>
 <CA+8X3fUccRDdRxx6JuKaDWorU+P3z7E8YcLbsyBnF0hBzxCCEg@mail.gmail.com>
 <CAF-BbQqHEDu5miar+mQiRV7J5VVKU9K4bPdHz-m02+wOeUc06g@mail.gmail.com>
 <CA+8X3fXt_KsFGXHdZutg8A2vCuXGn2_wODxSSE6RsfKbqBt3jQ@mail.gmail.com>
 <c2e700dc-cfea-e03b-b7eb-16f09c35fa91@gmail.com>
Message-ID: <CA+8X3fX7S-4PKVrcHyypxX_NjkOXuBwk06p7Y_timUasbYq-=g@mail.gmail.com>

If he's setting PRE to the return value of "if", that is the logical
value of the expression in the if statement as far as I know. I think
that the expression within the else clause would be evaluated but not
assigned to anything and since it is within the loop, would just be
lost.

PRE<-ifelse(missing(GAY),(GA/GA)*100,(GA/GAY)*100)

would return either value depending upon whether GAY was missing.
That's what I get from the help pages.

Jim

On Mon, Mar 22, 2021 at 8:34 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 22/03/2021 1:59 a.m., Jim Lemon wrote:
> > Hi Goyani,
> > You are setting "PRE" to the return value of "if" which is one of TRUE
> > (1), FALSE(0) or NULL.
>
> That's not true at all.  The statement was
>
>      PRE<- if(missing(GAY)){
>        (GA/GA) * 100
>      } else {
>        (GA/GAY) * 100
>      }
>
> so the result is (GA/GA) * 100 or (GA/GAY)*100.
>
> > Because GAY is always missing in your example,
>
> If that's true and GA isn't missing, the result will always be 100.
>
> Duncan Murdoch
>
> > "PRE" is always set to 1. Then you always want to pass 1 in the sample
> > list, and that will not assign anything to PRE. By correcting the "if"
> > clause and defining matrices that are unlikely to be singular, I can
> > run a "for" loop as follows:
> >
> > selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
> >   p<-as.matrix(phen_mat)
> >   g<-as.matrix(gen_mat)
> >   w<-as.matrix(weight_mat)
> >   bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
> >   GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
> >   if(missing(GAY)) PRE<-(GA/GA) * 100
> >   else PRE<-(GA/GAY) * 100
> >   result<-list(ID=ID,b=matrix(round(bmat,4),nrow=1),
> >    GA=round(GA,4),PRE=round(PRE,4))
> >   return(data.frame(result))
> > }
> >
> > pmat<-matrix(sample(1:16,16),4)
> > gmat<-matrix(sample(17:32),16,4)
> > wmat<-matrix(sample(1:4,4),4)
> >
> > mi<-combn(1:4,2)
> > sc<-list()
> > for(i in 1:ncol(matindx)) {
> >   as.numeric(ID<-paste0(mi[,i]))
> >   sc[[i]]<-selection.index(ID,pmat[mi[,i],mi[,i]],gmat[mi[,i],mi[,i]],
> >    wmat[mi[,i]],1)
> > }
> >
> > This produces output for me. Good luck with whatever you are doing with this.
> >
> > Jim
> >
> >
> >
> >
> >
> > On Mon, Mar 22, 2021 at 2:51 PM Goyani Zankrut <zankrut20 at gmail.com> wrote:
> >>
> >> Greetings of the day,
> >> Thank you for your response, Sir.
> >> The full problem statement is given below:
> >>
> >> In our case, I'm taking 4 traits.
> >> library(arrangements)
> >> a<- combinations(4,2) # gives 6 pairwise combinations
> >> class(a) # it's a "matrix" "array"
> >>
> >> now hypothetical data of three matrix for further calculation:
> >> pmat<- matrix(1:16, nrow = 4)
> >> gmat<- matrix(17:32, nrow = 4)
> >> wmat<- matrix(1:4, nrow = 4)
> >>
> >> My custom function for further calculations:
> >> selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
> >>    ID = toString(ID)
> >>    p<- as.matrix(phen_mat)
> >>    g<- as.matrix(gen_mat)
> >>    w<- as.matrix(weight_mat)
> >>    bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
> >>    GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
> >>    PRE<- if(missing(GAY)){
> >>      (GA/GA) * 100
> >>    } else {
> >>      (GA/GAY) * 100
> >>    }
> >>    result<- list("ID" = ID, "b" = matrix(round(bmat,4), nrow = 1), "GA" = round(GA,4), "PRE" = round(PRE,4))
> >>    return(data.frame(result))
> >> }
> >>
> >> Now I want to store this data into a list for further calculation:
> >> sc<- list()
> >> sc[[1]]<- selection.index(ID = 12, phen_mat = pmat[c(1,2),c(1,2)], gen_mat = gmat[c(1,2),c(1,2)], weight_mat = wmat[c(1,2),1])
> >> sc[[2]]<- selection.index(ID = 13, phen_mat = pmat[c(1,3),c(1,3)], gen_mat = gmat[c(1,3),c(1,3)], weight_mat = wmat[c(1,3),1])
> >> sc[[3]]<- selection.index(ID = 14, phen_mat = pmat[c(1,4),c(1,4)], gen_mat = gmat[c(1,4),c(1,4)], weight_mat = wmat[c(1,4),1])
> >> sc[[4]]<- selection.index(ID = 23, phen_mat = pmat[c(2,3),c(2,3)], gen_mat = gmat[c(2,3),c(2,3)], weight_mat = wmat[c(2,3),1])
> >> sc[[5]]<- selection.index(ID = 24, phen_mat = pmat[c(2,4),c(2,4)], gen_mat = gmat[c(2,4),c(2,4)], weight_mat = wmat[c(2,4),1])
> >> sc[[6]]<- selection.index(ID = 34, phen_mat = pmat[c(3,4),c(3,4)], gen_mat = gmat[c(3,4),c(3,4)], weight_mat = wmat[c(3,4),1])
> >> above list code is monotonous and time consuming for large data combination cycles like (7,2) = 21 combinations, (10,2) = 45 combinations. So I want to use the matrix a's each row as a vector in the selection.index function and result stores in a list.
> >>
> >> I hope now you will understand the full problem. I have checked the selection.index which has no issues and works well.
> >> Thank you.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From drj|m|emon @end|ng |rom gm@||@com  Mon Mar 22 11:39:37 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 22 Mar 2021 21:39:37 +1100
Subject: [R] for loop implementation in below problem
In-Reply-To: <CA+8X3fX7S-4PKVrcHyypxX_NjkOXuBwk06p7Y_timUasbYq-=g@mail.gmail.com>
References: <CAF-BbQpKtyrvsYtEegom5WiKxFQw9SCi12W2pqWcYGBJp=EaOQ@mail.gmail.com>
 <CA+8X3fUccRDdRxx6JuKaDWorU+P3z7E8YcLbsyBnF0hBzxCCEg@mail.gmail.com>
 <CAF-BbQqHEDu5miar+mQiRV7J5VVKU9K4bPdHz-m02+wOeUc06g@mail.gmail.com>
 <CA+8X3fXt_KsFGXHdZutg8A2vCuXGn2_wODxSSE6RsfKbqBt3jQ@mail.gmail.com>
 <c2e700dc-cfea-e03b-b7eb-16f09c35fa91@gmail.com>
 <CA+8X3fX7S-4PKVrcHyypxX_NjkOXuBwk06p7Y_timUasbYq-=g@mail.gmail.com>
Message-ID: <CA+8X3fXzQVbnLz5bf58_57kBB43vnmD=ZF02iFuZxu9G+2ad+w@mail.gmail.com>

No, I am confounded, It does return the value of the expressions
within the respective braces, just like ifelse. Learn something every
day.

Jim

On Mon, Mar 22, 2021 at 9:35 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> If he's setting PRE to the return value of "if", that is the logical
> value of the expression in the if statement as far as I know. I think
> that the expression within the else clause would be evaluated but not
> assigned to anything and since it is within the loop, would just be
> lost.
>
> PRE<-ifelse(missing(GAY),(GA/GA)*100,(GA/GAY)*100)
>
> would return either value depending upon whether GAY was missing.
> That's what I get from the help pages.
>
> Jim
>
> On Mon, Mar 22, 2021 at 8:34 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > On 22/03/2021 1:59 a.m., Jim Lemon wrote:
> > > Hi Goyani,
> > > You are setting "PRE" to the return value of "if" which is one of TRUE
> > > (1), FALSE(0) or NULL.
> >
> > That's not true at all.  The statement was
> >
> >      PRE<- if(missing(GAY)){
> >        (GA/GA) * 100
> >      } else {
> >        (GA/GAY) * 100
> >      }
> >
> > so the result is (GA/GA) * 100 or (GA/GAY)*100.
> >
> > > Because GAY is always missing in your example,
> >
> > If that's true and GA isn't missing, the result will always be 100.
> >
> > Duncan Murdoch
> >
> > > "PRE" is always set to 1. Then you always want to pass 1 in the sample
> > > list, and that will not assign anything to PRE. By correcting the "if"
> > > clause and defining matrices that are unlikely to be singular, I can
> > > run a "for" loop as follows:
> > >
> > > selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
> > >   p<-as.matrix(phen_mat)
> > >   g<-as.matrix(gen_mat)
> > >   w<-as.matrix(weight_mat)
> > >   bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
> > >   GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
> > >   if(missing(GAY)) PRE<-(GA/GA) * 100
> > >   else PRE<-(GA/GAY) * 100
> > >   result<-list(ID=ID,b=matrix(round(bmat,4),nrow=1),
> > >    GA=round(GA,4),PRE=round(PRE,4))
> > >   return(data.frame(result))
> > > }
> > >
> > > pmat<-matrix(sample(1:16,16),4)
> > > gmat<-matrix(sample(17:32),16,4)
> > > wmat<-matrix(sample(1:4,4),4)
> > >
> > > mi<-combn(1:4,2)
> > > sc<-list()
> > > for(i in 1:ncol(matindx)) {
> > >   as.numeric(ID<-paste0(mi[,i]))
> > >   sc[[i]]<-selection.index(ID,pmat[mi[,i],mi[,i]],gmat[mi[,i],mi[,i]],
> > >    wmat[mi[,i]],1)
> > > }
> > >
> > > This produces output for me. Good luck with whatever you are doing with this.
> > >
> > > Jim
> > >
> > >
> > >
> > >
> > >
> > > On Mon, Mar 22, 2021 at 2:51 PM Goyani Zankrut <zankrut20 at gmail.com> wrote:
> > >>
> > >> Greetings of the day,
> > >> Thank you for your response, Sir.
> > >> The full problem statement is given below:
> > >>
> > >> In our case, I'm taking 4 traits.
> > >> library(arrangements)
> > >> a<- combinations(4,2) # gives 6 pairwise combinations
> > >> class(a) # it's a "matrix" "array"
> > >>
> > >> now hypothetical data of three matrix for further calculation:
> > >> pmat<- matrix(1:16, nrow = 4)
> > >> gmat<- matrix(17:32, nrow = 4)
> > >> wmat<- matrix(1:4, nrow = 4)
> > >>
> > >> My custom function for further calculations:
> > >> selection.index<- function(ID, phen_mat, gen_mat, weight_mat, GAY){
> > >>    ID = toString(ID)
> > >>    p<- as.matrix(phen_mat)
> > >>    g<- as.matrix(gen_mat)
> > >>    w<- as.matrix(weight_mat)
> > >>    bmat<- solve(phen_mat) %*% gen_mat %*% weight_mat
> > >>    GA<- 2.063 * t(bmat) %*% g %*% w / (t(bmat) %*% p %*% bmat)^0.5
> > >>    PRE<- if(missing(GAY)){
> > >>      (GA/GA) * 100
> > >>    } else {
> > >>      (GA/GAY) * 100
> > >>    }
> > >>    result<- list("ID" = ID, "b" = matrix(round(bmat,4), nrow = 1), "GA" = round(GA,4), "PRE" = round(PRE,4))
> > >>    return(data.frame(result))
> > >> }
> > >>
> > >> Now I want to store this data into a list for further calculation:
> > >> sc<- list()
> > >> sc[[1]]<- selection.index(ID = 12, phen_mat = pmat[c(1,2),c(1,2)], gen_mat = gmat[c(1,2),c(1,2)], weight_mat = wmat[c(1,2),1])
> > >> sc[[2]]<- selection.index(ID = 13, phen_mat = pmat[c(1,3),c(1,3)], gen_mat = gmat[c(1,3),c(1,3)], weight_mat = wmat[c(1,3),1])
> > >> sc[[3]]<- selection.index(ID = 14, phen_mat = pmat[c(1,4),c(1,4)], gen_mat = gmat[c(1,4),c(1,4)], weight_mat = wmat[c(1,4),1])
> > >> sc[[4]]<- selection.index(ID = 23, phen_mat = pmat[c(2,3),c(2,3)], gen_mat = gmat[c(2,3),c(2,3)], weight_mat = wmat[c(2,3),1])
> > >> sc[[5]]<- selection.index(ID = 24, phen_mat = pmat[c(2,4),c(2,4)], gen_mat = gmat[c(2,4),c(2,4)], weight_mat = wmat[c(2,4),1])
> > >> sc[[6]]<- selection.index(ID = 34, phen_mat = pmat[c(3,4),c(3,4)], gen_mat = gmat[c(3,4),c(3,4)], weight_mat = wmat[c(3,4),1])
> > >> above list code is monotonous and time consuming for large data combination cycles like (7,2) = 21 combinations, (10,2) = 45 combinations. So I want to use the matrix a's each row as a vector in the selection.index function and result stores in a list.
> > >>
> > >> I hope now you will understand the full problem. I have checked the selection.index which has no issues and works well.
> > >> Thank you.
> > >>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >


From u@m|ecknew @end|ng |rom gm@||@com  Mon Mar 22 07:58:31 2021
From: u@m|ecknew @end|ng |rom gm@||@com (Usmle Ck)
Date: Mon, 22 Mar 2021 08:58:31 +0200
Subject: [R] forest plot -metafor package
Message-ID: <CAEeC7bqHkGckp=0cFPqVO8EmsQkLovQGdFKY1q3RRYTw20tCvQ@mail.gmail.com>

*I am performing a meta-analysis using the metafor package. My data are
**proportions and I used the Freeman Tukey double arcine (FT)**
transformation to fit the random effects model. To create a **forest
plot with my estimates backtransformed to the original scale of
**proportions i found this post which helped alot>*

https://stat.ethz.ch/pipermail/r-help/2010-December/263286.html

*but i still cant enter the study names/authors to the forest plot?
can you help *


*thanks in advance*

	[[alternative HTML version deleted]]


From |ern@ndo @end|ng |rom |ort|etwo@com  Sun Mar 21 11:38:43 2021
From: |ern@ndo @end|ng |rom |ort|etwo@com (Fernando da Silva)
Date: Sun, 21 Mar 2021 07:38:43 -0300
Subject: [R] [R-pkgs] CRAN new release: meedr package provides access to
 Central Bank of Brazil API
Message-ID: <CAFF4+8YWHVO0EkxeLJbPxxGFv+wKeUWN69m=uO7WsTEPbzaFPA@mail.gmail.com>

Hello everyone,

Very happy to announce my first release on CRAN: *meedr. *The goal is to
provide quick and easy access to market expectations data to the main
macroeconomic indicators in the Focus report, made available by the Central
Bank of Brazil through the Expectations System data API. This data comes
from several financial institutions, such as: banks, brokers, funds,
consultancies, etc.

The *meedr* package offers an R interface to the API and other advantages:

   - Use of a caching system with package memoise to speed up repeated
   requests of data;
   - User can utilize all cores of the machine (parallel computing) when
   fetching a large batch of time series.


You can install the released version of meedr from CRAN with:
*install.packages("meedr")*

Best regards,

*Fernando da Silva*
Economist
E-mail: fernando at fortietwo.com
Website: www.fortietwo.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Mon Mar 22 12:51:32 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Mon, 22 Mar 2021 11:51:32 +0000
Subject: [R] forest plot -metafor package
In-Reply-To: <CAEeC7bqHkGckp=0cFPqVO8EmsQkLovQGdFKY1q3RRYTw20tCvQ@mail.gmail.com>
References: <CAEeC7bqHkGckp=0cFPqVO8EmsQkLovQGdFKY1q3RRYTw20tCvQ@mail.gmail.com>
Message-ID: <f276171c332349c5a175a5d24bd529d9@UM-MAIL3214.unimaas.nl>

Dear Usmle Ck,

This is what the 'slab' argument is for (for adding 'study labels'). For an example, see:

https://www.metafor-project.org/doku.php/plots:forest_plot

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Usmle Ck
>Sent: Monday, 22 March, 2021 7:59
>To: r-help at r-project.org
>Subject: [R] forest plot -metafor package
>
>*I am performing a meta-analysis using the metafor package. My data are
>**proportions and I used the Freeman Tukey double arcine (FT)**
>transformation to fit the random effects model. To create a **forest
>plot with my estimates backtransformed to the original scale of
>**proportions i found this post which helped alot>*
>
>https://stat.ethz.ch/pipermail/r-help/2010-December/263286.html
>
>*but i still cant enter the study names/authors to the forest plot?
>can you help *
>
>*thanks in advance*


From b@k|un@| @end|ng |rom y@hoo@com  Mon Mar 22 13:20:20 2021
From: b@k|un@| @end|ng |rom y@hoo@com (Baki UNAL)
Date: Mon, 22 Mar 2021 12:20:20 +0000 (UTC)
Subject: [R] Rstudio crashed when I try to train a nnet model.
In-Reply-To: <CAGiFhPNuVqe6i-Evc2yWxCwyAb9+1pfsrc2t-eu=rtmr=O_LVg@mail.gmail.com>
References: <1709238116.929530.1616343703467.ref@mail.yahoo.com>
 <1709238116.929530.1616343703467@mail.yahoo.com>
 <CAGiFhPPPhG9YUbR7_kwhAKkt+vpQ7BEOJNsmZEp0PnWz53JM1w@mail.gmail.com>
 <1746095704.1153304.1616345829298@mail.yahoo.com>
 <CAGiFhPNuVqe6i-Evc2yWxCwyAb9+1pfsrc2t-eu=rtmr=O_LVg@mail.gmail.com>
Message-ID: <1808210421.453436.1616415620721@mail.yahoo.com>

 Hi,
I tried to run the code in another computer in RGui. This time program run until final iteration. But after the last iteration RGui quit without any error code. I mailed this issue to?Brian Ripley who is the maintainer of R nnet package. What can I do to solve this problem?
Best regardsBaki
    On Monday, March 22, 2021, 06:55:00 AM GMT+3, Jiefei Wang <szwjf08 at gmail.com> wrote:  
 
 Hi Baki,
This should be a different issue. It looks like there is no problem in the R?terminal. Does?the crash happen every time when you run the code in RStudio? If so, this should be a bug in RStudio and you need to consult RStudio's mailing?list as R and RStudio are maintained by different teams.
Best,Jiefei
On Mon, Mar 22, 2021 at 12:57 AM Baki UNAL <bakiunal at yahoo.com> wrote:

 Hi?Jiefei
I run the code below in RGui
> nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000, maxit=2000)

But I got the following output:
# weights:? 435initial? value 55650.887782?final? value 55650.887782?converged
Program early converged. Program didn't any calculations.?
Best,Baki
    On Sunday, March 21, 2021, 07:35:31 PM GMT+3, Jiefei Wang <szwjf08 at gmail.com> wrote:  
 
 Hi Baki,
Perhaps out of memory? Would you be able to run your code through the R terminal? It probably can give us more information to debug the issue.?
Best,Jiefei
On Mon, Mar 22, 2021 at 12:23 AM Baki UNAL via R-help <r-help at r-project.org> wrote:

Hi,
I tried to train a neural network with following code:
nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000, maxit=2000)

When I executed the code R studio crashed with following error:
"R Session Aborted
R encountered a fatal error.
The session was terminated.
Start new session"
When I set the hidden layer as c(15) as below the code works fine.
nn2 <- nnet(TQ~.,data = train, size=c(15), linout=T, MaxNWts =4000, maxit=2000)

What could be the problem?

Best regards.


? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
  
	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Mon Mar 22 13:39:05 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Mon, 22 Mar 2021 20:39:05 +0800
Subject: [R] Rstudio crashed when I try to train a nnet model.
In-Reply-To: <1808210421.453436.1616415620721@mail.yahoo.com>
References: <1709238116.929530.1616343703467.ref@mail.yahoo.com>
 <1709238116.929530.1616343703467@mail.yahoo.com>
 <CAGiFhPPPhG9YUbR7_kwhAKkt+vpQ7BEOJNsmZEp0PnWz53JM1w@mail.gmail.com>
 <1746095704.1153304.1616345829298@mail.yahoo.com>
 <CAGiFhPNuVqe6i-Evc2yWxCwyAb9+1pfsrc2t-eu=rtmr=O_LVg@mail.gmail.com>
 <1808210421.453436.1616415620721@mail.yahoo.com>
Message-ID: <CAGiFhPNnoB+aBNo_Ca=e1C+tiyAnk8vyy6FK7mTPSBQ7p14wyg@mail.gmail.com>

Hi Baki,

The crash is very likely due to the bug in nnet. If this is the case, there
is almost nothing you can do. I think you only need to wait for the
response from the package maintainer. You can send your data to the
maintainer and help them to debug the issue.

Best,
Jiefei

On Mon, Mar 22, 2021 at 8:20 PM Baki UNAL <bakiunal at yahoo.com> wrote:

> Hi,
>
> I tried to run the code in another computer in RGui. This time program run
> until final iteration. But after the last iteration RGui quit without any
> error code. I mailed this issue to Brian Ripley who is the maintainer of
> R nnet package. What can I do to solve this problem?
>
> Best regards
> Baki
>
> On Monday, March 22, 2021, 06:55:00 AM GMT+3, Jiefei Wang <
> szwjf08 at gmail.com> wrote:
>
>
> Hi Baki,
>
> This should be a different issue. It looks like there is no problem in the
> R terminal. Does the crash happen every time when you run the code in
> RStudio? If so, this should be a bug in RStudio and you need to consult
> RStudio's mailing list as R and RStudio are maintained by different teams.
>
> Best,
> Jiefei
>
> On Mon, Mar 22, 2021 at 12:57 AM Baki UNAL <bakiunal at yahoo.com> wrote:
>
> Hi Jiefei
>
> I run the code below in RGui
>
> > nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> But I got the following output:
>
> # weights:  435
> initial  value 55650.887782
> final  value 55650.887782
> converged
>
> Program early converged. Program didn't any calculations.
>
> Best,
> Baki
>
> On Sunday, March 21, 2021, 07:35:31 PM GMT+3, Jiefei Wang <
> szwjf08 at gmail.com> wrote:
>
>
> Hi Baki,
>
> Perhaps out of memory? Would you be able to run your code through the R
> terminal? It probably can give us more information to debug the issue.
>
> Best,
> Jiefei
>
> On Mon, Mar 22, 2021 at 12:23 AM Baki UNAL via R-help <
> r-help at r-project.org> wrote:
>
> Hi,
> I tried to train a neural network with following code:
> nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> When I executed the code R studio crashed with following error:
> "R Session Aborted
> R encountered a fatal error.
> The session was terminated.
> Start new session"
> When I set the hidden layer as c(15) as below the code works fine.
> nn2 <- nnet(TQ~.,data = train, size=c(15), linout=T, MaxNWts =4000,
> maxit=2000)
>
> What could be the problem?
>
> Best regards.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From |r@nce@c@brun @end|ng |rom y@hoo@|t  Mon Mar 22 12:54:54 2021
From: |r@nce@c@brun @end|ng |rom y@hoo@|t (francesca brun)
Date: Mon, 22 Mar 2021 11:54:54 +0000 (UTC)
Subject: [R] Help Package 'CLIMTRENDS' from Archive
References: <997992864.4728673.1616414094317.ref@mail.yahoo.com>
Message-ID: <997992864.4728673.1616414094317@mail.yahoo.com>

Hello,
I need to run the 'climtrend' library which is no longer available, I downloaded and installed it from the archive on my pc but it doesn't work, it says "I can't find the function ..." what should I do? I absolutely need to use it, in addition to installing it, what should I do to use it?
thank you in advance for your kindness,
Regards
Francesca

From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Mar 22 14:16:22 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 22 Mar 2021 09:16:22 -0400
Subject: [R] Rstudio crashed when I try to train a nnet model.
In-Reply-To: <CAGiFhPNnoB+aBNo_Ca=e1C+tiyAnk8vyy6FK7mTPSBQ7p14wyg@mail.gmail.com>
References: <1709238116.929530.1616343703467.ref@mail.yahoo.com>
 <1709238116.929530.1616343703467@mail.yahoo.com>
 <CAGiFhPPPhG9YUbR7_kwhAKkt+vpQ7BEOJNsmZEp0PnWz53JM1w@mail.gmail.com>
 <1746095704.1153304.1616345829298@mail.yahoo.com>
 <CAGiFhPNuVqe6i-Evc2yWxCwyAb9+1pfsrc2t-eu=rtmr=O_LVg@mail.gmail.com>
 <1808210421.453436.1616415620721@mail.yahoo.com>
 <CAGiFhPNnoB+aBNo_Ca=e1C+tiyAnk8vyy6FK7mTPSBQ7p14wyg@mail.gmail.com>
Message-ID: <d17e448d-042c-3d56-39c6-142f1ac11082@gmail.com>

On 22/03/2021 8:39 a.m., Jiefei Wang wrote:
> Hi Baki,
> 
> The crash is very likely due to the bug in nnet. If this is the case, there
> is almost nothing you can do. I think you only need to wait for the
> response from the package maintainer. You can send your data to the
> maintainer and help them to debug the issue.

"Almost nothing"?  Helping to debug the problem would almost certainly 
be a welcome contribution.  If you can reproduce it while running under 
a debugger that would locate the issue, and then Prof Ripley would 
probably be able to fix it easily.

How to do that?  It's a bit easier on other systems than on Windows, but 
it's not very hard in either place.  The steps are:

  Figure out which debugger works on your system.  On macOS, it's lldb; 
I think other systems use gdb (but check the Admin manual, as I could be 
wrong).  macOS also needs a special build of R to allow debugging; see 
the "R for Mac OS X FAQ" question 10.17 for details on how to get it.

  Make sure nnet is built with debugging info.  This is automatic on 
non-Windows systems.  On Windows, reinstall it from source using R command

    install.packages("nnet", type = "source", INSTALL_opts = "--debug")

Run R under the debugger.  On Unix-alikes you start it using

   R -d lldb

or

   R -d gdb

depending on which debugger you're using.  On Windows, I think it's 
usually easiest to start R normally, then start the debugger separately 
and attach it to the R process; if you can't figure out how to do that, 
ask and someone will tell you the details, which I forget.

If R is not running, type "run" in the debugger to start it, and go 
through the process to trigger the crash.  The debugger will print very 
useful information at that point, which will likely suggest exactly what 
went wrong.  Post that here, or send it to Prof Ripley.

Duncan Murdoch

> 
> Best,
> Jiefei
> 
> On Mon, Mar 22, 2021 at 8:20 PM Baki UNAL <bakiunal at yahoo.com> wrote:
> 
>> Hi,
>>
>> I tried to run the code in another computer in RGui. This time program run
>> until final iteration. But after the last iteration RGui quit without any
>> error code. I mailed this issue to Brian Ripley who is the maintainer of
>> R nnet package. What can I do to solve this problem?
>>
>> Best regards
>> Baki
>>
>> On Monday, March 22, 2021, 06:55:00 AM GMT+3, Jiefei Wang <
>> szwjf08 at gmail.com> wrote:
>>
>>
>> Hi Baki,
>>
>> This should be a different issue. It looks like there is no problem in the
>> R terminal. Does the crash happen every time when you run the code in
>> RStudio? If so, this should be a bug in RStudio and you need to consult
>> RStudio's mailing list as R and RStudio are maintained by different teams.
>>
>> Best,
>> Jiefei
>>
>> On Mon, Mar 22, 2021 at 12:57 AM Baki UNAL <bakiunal at yahoo.com> wrote:
>>
>> Hi Jiefei
>>
>> I run the code below in RGui
>>
>>> nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000,
>> maxit=2000)
>>
>> But I got the following output:
>>
>> # weights:  435
>> initial  value 55650.887782
>> final  value 55650.887782
>> converged
>>
>> Program early converged. Program didn't any calculations.
>>
>> Best,
>> Baki
>>
>> On Sunday, March 21, 2021, 07:35:31 PM GMT+3, Jiefei Wang <
>> szwjf08 at gmail.com> wrote:
>>
>>
>> Hi Baki,
>>
>> Perhaps out of memory? Would you be able to run your code through the R
>> terminal? It probably can give us more information to debug the issue.
>>
>> Best,
>> Jiefei
>>
>> On Mon, Mar 22, 2021 at 12:23 AM Baki UNAL via R-help <
>> r-help at r-project.org> wrote:
>>
>> Hi,
>> I tried to train a neural network with following code:
>> nn2 <- nnet(TQ~.,data = train, size=c(15,15), linout=T, MaxNWts =4000,
>> maxit=2000)
>>
>> When I executed the code R studio crashed with following error:
>> "R Session Aborted
>> R encountered a fatal error.
>> The session was terminated.
>> Start new session"
>> When I set the hidden layer as c(15) as below the code works fine.
>> nn2 <- nnet(TQ~.,data = train, size=c(15), linout=T, MaxNWts =4000,
>> maxit=2000)
>>
>> What could be the problem?
>>
>> Best regards.
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Mar 22 14:27:28 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 22 Mar 2021 06:27:28 -0700
Subject: [R] Help Package 'CLIMTRENDS' from Archive
In-Reply-To: <997992864.4728673.1616414094317@mail.yahoo.com>
References: <997992864.4728673.1616414094317.ref@mail.yahoo.com>
 <997992864.4728673.1616414094317@mail.yahoo.com>
Message-ID: <FAA56CA2-EF89-4E6C-B7F4-864568E7F65A@comcast.net>



> On Mar 22, 2021, at 4:54 AM, francesca brun via R-help <r-help at r-project.org> wrote:
> 
> Hello,
> I need to run the 'climtrend' library

It's a package, not a library. Libraries are directory locations and typically hold multiple packages.

> which is no longer available, I downloaded and installed it from the archive on my pc but it doesn't work, it says "I can't find the function ..." what should I do? I absolutely need to use it, in addition to installing it, what should I do to use it?
> thank you in advance for your kindness,

If earlier you got a message telling you of successful installation, then the most likely error is failure to execute code that loads the packages contents into your R workspace. 

library(climtrends) # needs to be done before you will see functions from it in you console session.

Of course, it's always possible you misspelled the function name. I see that the package uses a lot of camelCase names and R does NOT allow errors in spelling (such as your spelling of the package names as CLIMTRENDS. )

On a mac running R 3.6 I got no error installing from source. It did not require compiler tools.

-- 
David.

> Francesca
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@hmood@n@der@n @end|ng |rom ugent@be  Mon Mar 22 15:33:06 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Mon, 22 Mar 2021 14:33:06 +0000
Subject: [R] Ellipses in factor analysis
Message-ID: <5e16162d68ad467e97e8ff18ab367f7a@ugent.be>

Hi

In the example shown in [1], there is command that adds ellipses in the individual map.


fviz_mfa_ind(res.famd,
             habillage = "Label", # color by groups
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE, ellipse.type = "confidence",
             repel = TRUE # Avoid text overlapping
             )

Where can I find more information about what is that ellipse exactly and how that is defined? For example, in the at figure, I don't know why 1VAU which is in red, is not in the red ellipse. Any note about that?



[1] http://www.sthda.com/english/articles/31-principal-component-methods-in-r-practical-guide/115-famd-factor-analysis-of-mixed-data-in-r-essentials/


Regards,
Mahmood

	[[alternative HTML version deleted]]


From |ng||mo @end|ng |rom gm@||@com  Mon Mar 22 17:17:11 2021
From: |ng||mo @end|ng |rom gm@||@com (Filippo Monari)
Date: Mon, 22 Mar 2021 17:17:11 +0100
Subject: [R] Weird (wrong?) result for fft
Message-ID: <CAG0gC1eU0R3Rz-q=T9riVZUrQ8h22HG9d20wtH99Z=r2SdAu2w@mail.gmail.com>

Hi all,

I am plying around with fft function from the stats package.
Running the example that is listed in the documentation:

x <- 1:4
fft(x) #output 1
fft(fft(x), inverse = TRUE)/length(x) #output 2

I was expecting that output 1 and two were the same but I get:

> fft(x)
[1] 10+0i -2+2i -2+0i -2-2i

> ft(fft(x), inverse = TRUE)/length(x)
[1] 1+0i 2+0i 3+0i 4+0i

Am I doing something wrong or is there a bug somewhere?

Regards,
Filippo

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Mar 22 17:32:47 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 22 Mar 2021 09:32:47 -0700
Subject: [R] Weird (wrong?) result for fft
In-Reply-To: <CAG0gC1eU0R3Rz-q=T9riVZUrQ8h22HG9d20wtH99Z=r2SdAu2w@mail.gmail.com>
References: <CAG0gC1eU0R3Rz-q=T9riVZUrQ8h22HG9d20wtH99Z=r2SdAu2w@mail.gmail.com>
Message-ID: <8A5A60F7-A308-48DE-BBE6-7E211D0FA83A@dcn.davis.ca.us>

Neither. The discrete Fourier transform is a complex number operation. R-help is per the Posting Guide not an appropriate place to discuss theory in depth, and there is plenty of theory in this question and practically no R, but you can examine your result more closely with the functions described in ?complex.

On March 22, 2021 9:17:11 AM PDT, Filippo Monari <ingfimo at gmail.com> wrote:
>Hi all,
>
>I am plying around with fft function from the stats package.
>Running the example that is listed in the documentation:
>
>x <- 1:4
>fft(x) #output 1
>fft(fft(x), inverse = TRUE)/length(x) #output 2
>
>I was expecting that output 1 and two were the same but I get:
>
>> fft(x)
>[1] 10+0i -2+2i -2+0i -2-2i
>
>> ft(fft(x), inverse = TRUE)/length(x)
>[1] 1+0i 2+0i 3+0i 4+0i
>
>Am I doing something wrong or is there a bug somewhere?
>
>Regards,
>Filippo
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |r@nce@c@brun @end|ng |rom y@hoo@|t  Mon Mar 22 16:24:48 2021
From: |r@nce@c@brun @end|ng |rom y@hoo@|t (francesca brun)
Date: Mon, 22 Mar 2021 15:24:48 +0000 (UTC)
Subject: [R] Thank you 4 Davide
References: <198947820.3307264.1616426688010.ref@mail.yahoo.com>
Message-ID: <198947820.3307264.1616426688010@mail.yahoo.com>

Hello,
The problem was that version 4.0.4 did not support the package so I tried with several old versions until 3.6.2 installs both climtrend and Rcmdr with its graphical interface !! solved and thanks again Davide !!Francesca
(from Italy)


	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Mon Mar 22 18:42:45 2021
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Mon, 22 Mar 2021 17:42:45 +0000
Subject: [R] [Rd] R 4.0.5 scheduled for March 31
Message-ID: <777ED63B-568F-45A2-A11E-9095F441A2D1@cbs.dk>

Full schedule is available on https://developer.r-project.org (or https://svn.r-project.org/R-dev-web/trunk/index.html for the impatient).

(This is a fast-track release, to resolve an issue with Asian character sets and another issue with R CMD build, before R 4.1.0)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Mar 22 18:43:40 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 22 Mar 2021 10:43:40 -0700
Subject: [R] Thank you 4 Davide
In-Reply-To: <198947820.3307264.1616426688010@mail.yahoo.com>
References: <198947820.3307264.1616426688010.ref@mail.yahoo.com>
 <198947820.3307264.1616426688010@mail.yahoo.com>
Message-ID: <b233c2f7-aab6-4397-9380-6b4e99c6a2ac@comcast.net>


On 3/22/21 8:24 AM, francesca brun via R-help wrote:
> Hello,
> The problem was that version 4.0.4 did not support the package so I tried with several old versions until 3.6.2 installs both climtrend and Rcmdr with its graphical interface !! solved and thanks again Davide !!Francesca


I'm glad you got success.

However, for anyone viewing this I must note that the proper name of the 
package is 'climtrends'. I'm not sure that you? ever spelled it 
correctly in your two postings to rhelp. R users will get little system 
help for poorly spelled package names. There is some hinting that occurs 
when using Rstudio, but that will only occur for packages that are 
already installed on one's system.


-- 

David.

> (from Italy)
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@rkhur@ @end|ng |rom |nd|@n@@edu  Mon Mar 22 19:07:39 2021
From: p@rkhur@ @end|ng |rom |nd|@n@@edu (Parkhurst, David)
Date: Mon, 22 Mar 2021 18:07:39 +0000
Subject: [R] Can't save files from the Source pane of R Studio
Message-ID: <BN7PR08MB4114E33A4953D863D4B776BBD0659@BN7PR08MB4114.namprd08.prod.outlook.com>

I?m just starting to learn and use R Studio in my Mac.  Now I find if I type lines in what I think is called the source pane, and use Save as from the menu, nothing gets saved.  That?s true if I add the extension .R or the extension .txt.  If I try reopen the file in an empty source pane, it?s empty.  And even if I open the file in a text editor, it?s blank.  How can I save my work from R Studio?

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Mar 22 19:49:10 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 22 Mar 2021 18:49:10 +0000
Subject: [R] Can't save files from the Source pane of R Studio
In-Reply-To: <BN7PR08MB4114E33A4953D863D4B776BBD0659@BN7PR08MB4114.namprd08.prod.outlook.com>
References: <BN7PR08MB4114E33A4953D863D4B776BBD0659@BN7PR08MB4114.namprd08.prod.outlook.com>
Message-ID: <5a26ac4a-29d3-2a3f-b09b-330b7a36d227@sapo.pt>

Hello,

R-Help is for questions on R code.
RStudio has its own help forum that you can access from the Help menu,

Help > RStudio Community Forum

Hope this helps,

Rui Barradas

?s 18:07 de 22/03/21, Parkhurst, David escreveu:
> I?m just starting to learn and use R Studio in my Mac.  Now I find if I type lines in what I think is called the source pane, and use Save as from the menu, nothing gets saved.  That?s true if I add the extension .R or the extension .txt.  If I try reopen the file in an empty source pane, it?s empty.  And even if I open the file in a text editor, it?s blank.  How can I save my work from R Studio?
> 
> 	[[alternative HTML version deleted]]
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkr|de@u @end|ng |rom gm@||@com  Mon Mar 22 21:02:11 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 22 Mar 2021 16:02:11 -0400
Subject: [R] Can't save files from the Source pane of R Studio
In-Reply-To: <BN7PR08MB4114E33A4953D863D4B776BBD0659@BN7PR08MB4114.namprd08.prod.outlook.com>
References: <BN7PR08MB4114E33A4953D863D4B776BBD0659@BN7PR08MB4114.namprd08.prod.outlook.com>
Message-ID: <CAKZQJMAyQAkVFyQoLXhyEUw4yLST_M7-pmcaGJpkTFz9H+wTQg@mail.gmail.com>

Rui is correct but you should also check that you have write--permission to
the directory you are accessing

On Mon, 22 Mar 2021 at 14:28, Parkhurst, David <parkhurs at indiana.edu> wrote:

> I?m just starting to learn and use R Studio in my Mac.  Now I find if I
> type lines in what I think is called the source pane, and use Save as from
> the menu, nothing gets saved.  That?s true if I add the extension .R or the
> extension .txt.  If I try reopen the file in an empty source pane, it?s
> empty.  And even if I open the file in a text editor, it?s blank.  How can
> I save my work from R Studio?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Mar 22 21:02:48 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 22 Mar 2021 13:02:48 -0700
Subject: [R] Can't save files from the Source pane of R Studio
In-Reply-To: <5a26ac4a-29d3-2a3f-b09b-330b7a36d227@sapo.pt>
References: <BN7PR08MB4114E33A4953D863D4B776BBD0659@BN7PR08MB4114.namprd08.prod.outlook.com>
 <5a26ac4a-29d3-2a3f-b09b-330b7a36d227@sapo.pt>
Message-ID: <CAGxFJbSUOSggYtejFJZ=0yefmiO-or8TY-KOhPzVmhWe9W+SuQ@mail.gmail.com>

... and moreover, the R Foundation that maintains and releases updates of R
software(open source licensed, free) is a totally separate, non-profit
entity from the RStudio organization, a for profit-company that has built a
support/data science infrastructure based on R(some of which is free and
some of which they charge for).

(Don't feel bad: this is a regular source of confusion on this forum).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 22, 2021 at 11:58 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> R-Help is for questions on R code.
> RStudio has its own help forum that you can access from the Help menu,
>
> Help > RStudio Community Forum
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 18:07 de 22/03/21, Parkhurst, David escreveu:
> > I?m just starting to learn and use R Studio in my Mac.  Now I find if I
> type lines in what I think is called the source pane, and use Save as from
> the menu, nothing gets saved.  That?s true if I add the extension .R or the
> extension .txt.  If I try reopen the file in an empty source pane, it?s
> empty.  And even if I open the file in a text editor, it?s blank.  How can
> I save my work from R Studio?
> >
> >       [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Tue Mar 23 05:06:07 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Tue, 23 Mar 2021 12:06:07 +0800
Subject: [R] Weird (wrong?) result for fft
In-Reply-To: <CAG0gC1eU0R3Rz-q=T9riVZUrQ8h22HG9d20wtH99Z=r2SdAu2w@mail.gmail.com>
References: <CAG0gC1eU0R3Rz-q=T9riVZUrQ8h22HG9d20wtH99Z=r2SdAu2w@mail.gmail.com>
Message-ID: <CAGiFhPPmcXt09j-d0ppHBe5vodWQRk=KMFRqFMj_qzZy6kYtgA@mail.gmail.com>

Hi Filippo,

Why do you expect these two expressions to produce the same output?
Especially the second expression contains the first expression. There is no
way to have the same result unless the function "fft( * , inverse = TRUE)"
does nothing but multiplies the input by the input's length. It does not
make any sense.

Actually, both results are correct as Jeff said. The first is the result of
discrete Fourier transform and the second is the reverse of the transform.
That's why the second output is the same as your variable "x". There are
some rounding errors in the computation so you might get very
small imaginary numbers after doing the reverse transformation. That's why
you see "0i" in the second output.

Best,
Jiefei

On Tue, Mar 23, 2021 at 12:17 AM Filippo Monari <ingfimo at gmail.com> wrote:

> Hi all,
>
> I am plying around with fft function from the stats package.
> Running the example that is listed in the documentation:
>
> x <- 1:4
> fft(x) #output 1
> fft(fft(x), inverse = TRUE)/length(x) #output 2
>
> I was expecting that output 1 and two were the same but I get:
>
> > fft(x)
> [1] 10+0i -2+2i -2+0i -2-2i
>
> > ft(fft(x), inverse = TRUE)/length(x)
> [1] 1+0i 2+0i 3+0i 4+0i
>
> Am I doing something wrong or is there a bug somewhere?
>
> Regards,
> Filippo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Tue Mar 23 13:14:03 2021
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Tue, 23 Mar 2021 16:44:03 +0430
Subject: [R] Increasing the resolution of a raster
Message-ID: <CANTxAmKsLTSF=XnjV6Dh9dd8f4FU=dVA3VVacef4hvPhHkJrzA@mail.gmail.com>

Dear R users;
Is there any way to increase the resolution of a raster so as to be seen
more clear?
I have a raster which is not very clear. I want to read it in R and get its
values and increase the resolution to be seen clearly.
please help me to do this.
I have tried using the following codes, but did not work.

bayat <- raster("./Bayat.jpg")
bayat
class      : RasterLayer
band       : 1  (of  3  bands)
dimensions : 1181, 827, 976687  (nrow, ncol, ncell)
resolution : 1, 1  (x, y)
extent     : 0, 827, 0, 1181  (xmin, xmax, ymin, ymax)
crs        : NA
source     : E:/New/Bayat.jpg
names      : Bayat
values     : 0, 255  (min, max)

bayat2 <- bayat
bayat_value = data.frame(xyFromCell(bayat2, 1:ncell(bayat2)))
valu <- getValues(bayat2)
i <- !is.na(valu)
bayat_value <- bayat_value[i,]
valu <- valu[i]
library(fields)
gc()
tps <- Tps(bayat_value, valu)
bayat3 <- raster(bayat)
bayat3 <- interpolate(bayat3, tps)
bayat3 <- mask(bayat3, bayat)
plot(bayat3)



Sincerely



-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 23 21:15:26 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 24 Mar 2021 07:15:26 +1100
Subject: [R] Increasing the resolution of a raster
In-Reply-To: <CANTxAmKsLTSF=XnjV6Dh9dd8f4FU=dVA3VVacef4hvPhHkJrzA@mail.gmail.com>
References: <CANTxAmKsLTSF=XnjV6Dh9dd8f4FU=dVA3VVacef4hvPhHkJrzA@mail.gmail.com>
Message-ID: <CA+8X3fVJqqEhi-AWxbsp6_LL6m=A0m2RL5p5SHf=hRjZhD6FXw@mail.gmail.com>

Hi Javad,
You may be trying to reinvent the wheel. Have you looked at Image Magick?

Jim

On Tue, Mar 23, 2021 at 11:42 PM javad bayat <j.bayat194 at gmail.com> wrote:
>
> Dear R users;
> Is there any way to increase the resolution of a raster so as to be seen
> more clear?
> I have a raster which is not very clear. I want to read it in R and get its
> values and increase the resolution to be seen clearly.
> please help me to do this.
> I have tried using the following codes, but did not work.
>
> bayat <- raster("./Bayat.jpg")
> bayat
> class      : RasterLayer
> band       : 1  (of  3  bands)
> dimensions : 1181, 827, 976687  (nrow, ncol, ncell)
> resolution : 1, 1  (x, y)
> extent     : 0, 827, 0, 1181  (xmin, xmax, ymin, ymax)
> crs        : NA
> source     : E:/New/Bayat.jpg
> names      : Bayat
> values     : 0, 255  (min, max)
>
> bayat2 <- bayat
> bayat_value = data.frame(xyFromCell(bayat2, 1:ncell(bayat2)))
> valu <- getValues(bayat2)
> i <- !is.na(valu)
> bayat_value <- bayat_value[i,]
> valu <- valu[i]
> library(fields)
> gc()
> tps <- Tps(bayat_value, valu)
> bayat3 <- raster(bayat)
> bayat3 <- interpolate(bayat3, tps)
> bayat3 <- mask(bayat3, bayat)
> plot(bayat3)
>
>
>
> Sincerely
>
>
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h@nne|ore@ne||@@en @end|ng |rom out|ook@be  Wed Mar 24 08:53:26 2021
From: h@nne|ore@ne||@@en @end|ng |rom out|ook@be (hannelore nelissen)
Date: Wed, 24 Mar 2021 07:53:26 +0000
Subject: [R] Probit model- endogeneity issue
Message-ID: <PR2PR09MB316189FAAD84903158C44A69E9639@PR2PR09MB3161.eurprd09.prod.outlook.com>

Dear all,
I am having some issues with using the IV strategy for an endogeneity problem in terms of a probit model.  In particular, I want to follow a two-stage procedure where I estimate a probit on the decision to peg the exchange rate, and then use the predicted values in the second stage regression. So, I need to get a probability that the country has a peg (estimated based on the Z variables). So, in the second stage, I have to include this estimated probability of the first stage (and exclude the Z variables that showed a significant effect). However, I do not know how to get this estimated probability of the first stage which I can then include in my second stage?
Can somebody help me with the command I should use?


I would really appreciate it, thanks Dear all,




Verzonden vanuit Mail<https://go.microsoft.com/fwlink/?LinkId=550986> voor Windows 10


	[[alternative HTML version deleted]]


From jerem|eju@te @end|ng |rom gm@||@com  Wed Mar 24 14:06:29 2021
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Wed, 24 Mar 2021 14:06:29 +0100
Subject: [R] setRefClass in package
Message-ID: <87eeg43dm2.fsf@gmail.com>

Hello,

I was wondering how to call a function outside a setRefClass but inside
the package without export it. Let me explain by means of an example.

- in the file test-package/R/test.R

##' some description
##'
##' some details
##' @title test
##' @return sideeffect
##' @author Jeremie Juste
##' @export test
##' @import data.table
test <- setRefClass("test",
            list(dt="data.table"))


test$methods(
  
  initialize = function(x){
    dt <<- remove_if_all_na(x[,abc:=1])
    }
)


##' remove rows for which all values are NA
##'
##' @title remove_if_all_NA
##' @param dt 
##' @return dt
##' @author Jeremie Juste
remove_if_all_NA <- function(dt) {
  cn <- colnames(dt)
  dt[!dt[NA],on=cn]  
}


Here when I build and install the package test-package, if I don't export
remove_if_all_NA 

##' remove rows for which all values are NA
##'
##' @title remove_if_all_NA
##' @param dt 
##' @return dt
##' @author Jeremie Juste
##' @export
remove_if_all_NA <- function(dt) {
  cn <- colnames(dt)
  dt[!dt[NA],on=cn]  
}

The package cannot use it.

library(test-package)
library(data.table)

> aa <- data.table(a=1:10,b=letters[1:10])
> b <- test(aa)
Error in remove_if_all_na(x[, `:=`(abc, 1)]) : 
  could not find function "remove_if_all_na"

Do you have any recommendations? The official documentation for
setRefClass is a bit thin for me but I wanted to use a tools that is going to stay. Any tip is
welcome.

Best regards,
Jeremie


From bgunter@4567 @end|ng |rom gm@||@com  Wed Mar 24 15:47:23 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 24 Mar 2021 07:47:23 -0700
Subject: [R] setRefClass in package
In-Reply-To: <87eeg43dm2.fsf@gmail.com>
References: <87eeg43dm2.fsf@gmail.com>
Message-ID: <CAGxFJbQxhiucGQ72cwo0sYg8OTNX4jBOf8uKE9PL3v+A-O6OdQ@mail.gmail.com>

I think this query fits better on r-package-devel rather than here.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 24, 2021 at 6:07 AM Jeremie Juste <jeremiejuste at gmail.com>
wrote:

> Hello,
>
> I was wondering how to call a function outside a setRefClass but inside
> the package without export it. Let me explain by means of an example.
>
> - in the file test-package/R/test.R
>
> ##' some description
> ##'
> ##' some details
> ##' @title test
> ##' @return sideeffect
> ##' @author Jeremie Juste
> ##' @export test
> ##' @import data.table
> test <- setRefClass("test",
>             list(dt="data.table"))
>
>
> test$methods(
>
>   initialize = function(x){
>     dt <<- remove_if_all_na(x[,abc:=1])
>     }
> )
>
>
> ##' remove rows for which all values are NA
> ##'
> ##' @title remove_if_all_NA
> ##' @param dt
> ##' @return dt
> ##' @author Jeremie Juste
> remove_if_all_NA <- function(dt) {
>   cn <- colnames(dt)
>   dt[!dt[NA],on=cn]
> }
>
>
> Here when I build and install the package test-package, if I don't export
> remove_if_all_NA
>
> ##' remove rows for which all values are NA
> ##'
> ##' @title remove_if_all_NA
> ##' @param dt
> ##' @return dt
> ##' @author Jeremie Juste
> ##' @export
> remove_if_all_NA <- function(dt) {
>   cn <- colnames(dt)
>   dt[!dt[NA],on=cn]
> }
>
> The package cannot use it.
>
> library(test-package)
> library(data.table)
>
> > aa <- data.table(a=1:10,b=letters[1:10])
> > b <- test(aa)
> Error in remove_if_all_na(x[, `:=`(abc, 1)]) :
>   could not find function "remove_if_all_na"
>
> Do you have any recommendations? The official documentation for
> setRefClass is a bit thin for me but I wanted to use a tools that is going
> to stay. Any tip is
> welcome.
>
> Best regards,
> Jeremie
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Mar 24 16:34:35 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 24 Mar 2021 11:34:35 -0400
Subject: [R] setRefClass in package
In-Reply-To: <87eeg43dm2.fsf@gmail.com>
References: <87eeg43dm2.fsf@gmail.com>
Message-ID: <b26d896b-5d03-acf0-4807-cd680b3aacd6@gmail.com>

On 24/03/2021 9:06 a.m., Jeremie Juste wrote:
> Hello,
> 
> I was wondering how to call a function outside a setRefClass but inside
> the package without export it. Let me explain by means of an example.

There are no scoping issues here:  Your initialize method can see all 
local functions in the package, including remove_if_all_NA.  But you've 
got a typo:  you called remove_if_all_na instead.  NA is not the same as na!

Duncan Murdoch

> 
> - in the file test-package/R/test.R
> 
> ##' some description
> ##'
> ##' some details
> ##' @title test
> ##' @return sideeffect
> ##' @author Jeremie Juste
> ##' @export test
> ##' @import data.table
> test <- setRefClass("test",
>              list(dt="data.table"))
> 
> 
> test$methods(
>    
>    initialize = function(x){
>      dt <<- remove_if_all_na(x[,abc:=1])
>      }
> )
> 
> 
> ##' remove rows for which all values are NA
> ##'
> ##' @title remove_if_all_NA
> ##' @param dt
> ##' @return dt
> ##' @author Jeremie Juste
> remove_if_all_NA <- function(dt) {
>    cn <- colnames(dt)
>    dt[!dt[NA],on=cn]
> }
> 
> 
> Here when I build and install the package test-package, if I don't export
> remove_if_all_NA
> 
> ##' remove rows for which all values are NA
> ##'
> ##' @title remove_if_all_NA
> ##' @param dt
> ##' @return dt
> ##' @author Jeremie Juste
> ##' @export
> remove_if_all_NA <- function(dt) {
>    cn <- colnames(dt)
>    dt[!dt[NA],on=cn]
> }
> 
> The package cannot use it.
> 
> library(test-package)
> library(data.table)
> 
>> aa <- data.table(a=1:10,b=letters[1:10])
>> b <- test(aa)
> Error in remove_if_all_na(x[, `:=`(abc, 1)]) :
>    could not find function "remove_if_all_na"
> 
> Do you have any recommendations? The official documentation for
> setRefClass is a bit thin for me but I wanted to use a tools that is going to stay. Any tip is
> welcome.
> 
> Best regards,
> Jeremie
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Mar 24 17:48:31 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 24 Mar 2021 11:48:31 -0500
Subject: [R] Calculating column differences
References: <002b01d720cd$868cfc10$93a6f430$.ref@sbcglobal.net>
Message-ID: <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>

r-help forum

 

I'm trying to calculate the diff between two rows and them mutate the
difference into a new column. I'm using the diff function but not giving me
what I want. 

 

df <- data.frame(ID=1:5,Score=4*2:6)

 

What a want  where 

  ID Score  diff

1  1     8      8

2  2    12     4

3  3    16     4

4  4    20     4

5  5    24     4

 

What I am getting

  ID Score  diff

1  1     8      NA

2  2    12     4

3  3    16     4

4  4    20     4

5  5    24     4

 

Jeff

 


	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Wed Mar 24 17:52:38 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Wed, 24 Mar 2021 17:52:38 +0100
Subject: [R] Calculating column differences
In-Reply-To: <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>
References: <002b01d720cd$868cfc10$93a6f430$.ref@sbcglobal.net>
 <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>
Message-ID: <08539cf0-1a49-1ac9-34e2-8006e8f90941@math.uni-giessen.de>

Dear Jeff,

read diff's help page, and you'll find out
what is wrong with your expectation.

What do think diff(df$Score) should give for
the first element in df$Score??

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 24.03.2021 um 17:48 schrieb Jeff Reichman:
> r-help forum
> 
>   
> 
> I'm trying to calculate the diff between two rows and them mutate the
> difference into a new column. I'm using the diff function but not giving me
> what I want.
> 
>   
> 
> df <- data.frame(ID=1:5,Score=4*2:6)
> 
>   
> 
> What a want  where
> 
>    ID Score  diff
> 
> 1  1     8      8
> 
> 2  2    12     4
> 
> 3  3    16     4
> 
> 4  4    20     4
> 
> 5  5    24     4
> 
>   
> 
> What I am getting
> 
>    ID Score  diff
> 
> 1  1     8      NA
> 
> 2  2    12     4
> 
> 3  3    16     4
> 
> 4  4    20     4
> 
> 5  5    24     4
> 
>   
> 
> Jeff
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jerem|eju@te @end|ng |rom gm@||@com  Wed Mar 24 18:12:13 2021
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Wed, 24 Mar 2021 18:12:13 +0100
Subject: [R] setRefClass in package
In-Reply-To: <b26d896b-5d03-acf0-4807-cd680b3aacd6@gmail.com> (Duncan
 Murdoch's message of "Wed, 24 Mar 2021 11:34:35 -0400")
References: <87eeg43dm2.fsf@gmail.com>
 <b26d896b-5d03-acf0-4807-cd680b3aacd6@gmail.com>
Message-ID: <87zgyszdaq.fsf@gmail.com>

Hello,


Many thanks for the reply.
Indeed there was no scoping issue here. I was sloppy.

Best regards,
Jeremie


On Wednesday, 24 Mar 2021 at 11:34, Duncan Murdoch wrote:
> On 24/03/2021 9:06 a.m., Jeremie Juste wrote:
>> Hello,
>> I was wondering how to call a function outside a setRefClass but
>> inside
>> the package without export it. Let me explain by means of an example.
>
> There are no scoping issues here:  Your initialize method can see all
> local functions in the package, including remove_if_all_NA.  But
> you've got a typo:  you called remove_if_all_na instead.  NA is not
> the same as na!
>
> Duncan Murdoch
>
>> - in the file test-package/R/test.R
>> ##' some description
>> ##'
>> ##' some details
>> ##' @title test
>> ##' @return sideeffect
>> ##' @author Jeremie Juste
>> ##' @export test
>> ##' @import data.table
>> test <- setRefClass("test",
>>              list(dt="data.table"))
>> test$methods(
>>       initialize = function(x){
>>      dt <<- remove_if_all_na(x[,abc:=1])
>>      }
>> )
>> ##' remove rows for which all values are NA
>> ##'
>> ##' @title remove_if_all_NA
>> ##' @param dt
>> ##' @return dt
>> ##' @author Jeremie Juste
>> remove_if_all_NA <- function(dt) {
>>    cn <- colnames(dt)
>>    dt[!dt[NA],on=cn]
>> }
>> Here when I build and install the package test-package, if I don't
>> export
>> remove_if_all_NA
>> ##' remove rows for which all values are NA
>> ##'
>> ##' @title remove_if_all_NA
>> ##' @param dt
>> ##' @return dt
>> ##' @author Jeremie Juste
>> ##' @export
>> remove_if_all_NA <- function(dt) {
>>    cn <- colnames(dt)
>>    dt[!dt[NA],on=cn]
>> }
>> The package cannot use it.
>> library(test-package)
>> library(data.table)
>> 
>>> aa <- data.table(a=1:10,b=letters[1:10])
>>> b <- test(aa)
>> Error in remove_if_all_na(x[, `:=`(abc, 1)]) :
>>    could not find function "remove_if_all_na"
>> Do you have any recommendations? The official documentation for
>> setRefClass is a bit thin for me but I wanted to use a tools that is going to stay. Any tip is
>> welcome.
>> Best regards,
>> Jeremie
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>

-- 
Jeremie Juste


From v|vek@utr@ @end|ng |rom gm@||@com  Wed Mar 24 18:54:37 2021
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Wed, 24 Mar 2021 18:54:37 +0100
Subject: [R] converting image formats
Message-ID: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>

Hi,
I would like to have help in converting from one image format to another
(between the packages EBImage, magick and imager). The magick package has
functions for this. But the EBImage and imager packages do not have
in-built functions for the conversion. It is, of course, possible to save
the images and then open with the other packages. But I am looking for more
direct options. I do not know how to assign data to the "slots" in the
functions.

### convert image formats
library(magick)
nuc_MAG_o <- image_read(system.file("images", "nuclei.tif",
package="EBImage"))
nuc_MAG_to_EB <- as_EBImage(manMAG)
nuc_MAG_to_IMG <- magick2cimg(manMAG,alpha="flatten")

# convert from EBImage
library(EBImage)
nucEBo <-  readImage(system.file("images", "nuclei.tif", package="EBImage"))
writeImage(nucEBo, "C:/Rfiles/nuclei-3.jpg")
nucEB_to_IMG <-
nucEB_to_MAG <-

#convert from imager
library(imager)
nuc_IMG_o <- load.image("C:/Rfiles/nuclei-3.jpg")
nuc_IMG_to_EB <-
nuc_IMG_to_MAG <-

All help is appreciated.
Thanks,
Vivek

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Mar 24 18:59:28 2021
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 24 Mar 2021 10:59:28 -0700
Subject: [R] Calculating column differences
In-Reply-To: <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>
References: <002b01d720cd$868cfc10$93a6f430$.ref@sbcglobal.net>
 <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>
Message-ID: <CAA99HCwFZj7Yvw70GRTENLiehfx+dpSr4Mr=MNwS6UW23MeXTQ@mail.gmail.com>

Dear Jeff,

Rather than diff-ing a linear vector you're trying to diff values from
two different rows. Also you indicate that you want to place the
diff-ed value in the 'lower' row of a new column. Try this (note
insertion of an initial "zero" row):

> df <- data.frame(ID=1:5,Score=4*2:6)
> df1 <- rbind(c(0,0), df)
> cbind(df1, "diff"=c(0, diff(df1$Score)) )
  ID Score diff
1  0     0    0
2  1     8    8
3  2    12    4
4  3    16    4
5  4    20    4
6  5    24    4
>

HTH, Bill.

W. Michels, Ph.D.



On Wed, Mar 24, 2021 at 9:49 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> r-help forum
>
>
>
> I'm trying to calculate the diff between two rows and them mutate the
> difference into a new column. I'm using the diff function but not giving me
> what I want.
>
>
>
> df <- data.frame(ID=1:5,Score=4*2:6)
>
>
>
> What a want  where
>
>   ID Score  diff
>
> 1  1     8      8
>
> 2  2    12     4
>
> 3  3    16     4
>
> 4  4    20     4
>
> 5  5    24     4
>
>
>
> What I am getting
>
>   ID Score  diff
>
> 1  1     8      NA
>
> 2  2    12     4
>
> 3  3    16     4
>
> 4  4    20     4
>
> 5  5    24     4
>
>
>
> Jeff
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v|vek@utr@ @end|ng |rom gm@||@com  Wed Mar 24 19:05:08 2021
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Wed, 24 Mar 2021 19:05:08 +0100
Subject: [R] converting image formats
In-Reply-To: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>
References: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>
Message-ID: <CAHLp6SCc4Vass-5Kwt3_80bubZCb91c_J6v0aA2DE0UEsOfJFA@mail.gmail.com>

Hi,
I have made a few corrections to my previous message in the naming of my
objects.

I would like to have help in converting from one image format to another
(between the packages EBImage, magick and imager). The magick package has
functions for this. But the EBImage and imager packages do not have
in-built functions for the conversion. It is, of course, possible to save
the images and then open with the other packages. But I am looking for more
direct options. I do not know how to assign data to the "slots" in the
functions.
### convert image formats
library(magick)
nuc_MAG_o <- image_read(system.file("images", "nuclei.tif",
package="EBImage"))
nuc_MAG_to_EB <- as_EBImage(nuc_MAG_o)
nuc_MAG_to_IMG <- magick2cimg(nuc_MAG_o,alpha="flatten")

# convert from EBImage
library(EBImage)
nuc_EB_o <-  readImage(system.file("images", "nuclei.tif",
package="EBImage"))
writeImage(nucEBo, "C:/Rfiles/nuclei-3.jpg")
# to convert nuc_EB_o
nucEB_to_IMG <-
nucEB_to_MAG <-

#convert from imager
library(imager)
nuc_IMG_o <- load.image("C:/Rfiles/nuclei-3.jpg")
# to convert nuc_IMG_o
nuc_IMG_to_EB <-
nuc_IMG_to_MAG <-
Thanks,
Vivek

Den ons 24 mars 2021 kl 18:54 skrev Vivek Sutradhara <viveksutra at gmail.com>:

> Hi,
> I would like to have help in converting from one image format to another
> (between the packages EBImage, magick and imager). The magick package has
> functions for this. But the EBImage and imager packages do not have
> in-built functions for the conversion. It is, of course, possible to save
> the images and then open with the other packages. But I am looking for more
> direct options. I do not know how to assign data to the "slots" in the
> functions.
>
> ### convert image formats
> library(magick)
> nuc_MAG_o <- image_read(system.file("images", "nuclei.tif",
> package="EBImage"))
> nuc_MAG_to_EB <- as_EBImage(manMAG)
> nuc_MAG_to_IMG <- magick2cimg(manMAG,alpha="flatten")
>
> # convert from EBImage
> library(EBImage)
> nucEBo <-  readImage(system.file("images", "nuclei.tif",
> package="EBImage"))
> writeImage(nucEBo, "C:/Rfiles/nuclei-3.jpg")
> nucEB_to_IMG <-
> nucEB_to_MAG <-
>
> #convert from imager
> library(imager)
> nuc_IMG_o <- load.image("C:/Rfiles/nuclei-3.jpg")
> nuc_IMG_to_EB <-
> nuc_IMG_to_MAG <-
>
> All help is appreciated.
> Thanks,
> Vivek
>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Mar 24 19:21:08 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 24 Mar 2021 13:21:08 -0500
Subject: [R] Calculating column differences
In-Reply-To: <08539cf0-1a49-1ac9-34e2-8006e8f90941@math.uni-giessen.de>
References: <002b01d720cd$868cfc10$93a6f430$.ref@sbcglobal.net>
 <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>
 <08539cf0-1a49-1ac9-34e2-8006e8f90941@math.uni-giessen.de>
Message-ID: <002c01d720da$77139390$653abab0$@sbcglobal.net>

Gerrit

 

Changed my approach ?

 

df <- data.frame(ID=1:5,Score=4*2:6)

 

df %>% 

  mutate(score_diff = Score - lag(Score, default = 0))

 

Jeff

 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Gerrit Eichner
Sent: Wednesday, March 24, 2021 11:53 AM
To: r-help at r-project.org
Subject: Re: [R] Calculating column differences

 

Dear Jeff,

 

read diff's help page, and you'll find out what is wrong with your expectation.

 

What do think diff(df$Score) should give for the first element in df$Score??

 

  Hth  --  Gerrit

 

---------------------------------------------------------------------

Dr. Gerrit Eichner                   Mathematical Institute, Room 212

 <mailto:gerrit.eichner at math.uni-giessen.de> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen

Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany

 <http://www.uni-giessen.de/eichner> http://www.uni-giessen.de/eichner

---------------------------------------------------------------------



Am 24.03.2021 um 17:48 schrieb Jeff Reichman:

> r-help forum

> 

>   

> 

> I'm trying to calculate the diff between two rows and them mutate the 

> difference into a new column. I'm using the diff function but not 

> giving me what I want.

> 

>   

> 

> df <- data.frame(ID=1:5,Score=4*2:6)

> 

>   

> 

> What a want  where

> 

>    ID Score  diff

> 

> 1  1     8      8

> 

> 2  2    12     4

> 

> 3  3    16     4

> 

> 4  4    20     4

> 

> 5  5    24     4

> 

>   

> 

> What I am getting

> 

>    ID Score  diff

> 

> 1  1     8      NA

> 

> 2  2    12     4

> 

> 3  3    16     4

> 

> 4  4    20     4

> 

> 5  5    24     4

> 

>   

> 

> Jeff

> 

>   

> 

> 

>             [[alternative HTML version deleted]]

> 

> ______________________________________________

>  <mailto:R-help at r-project.org> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 

>  <https://stat.ethz.ch/mailman/listinfo/r-help> https://stat.ethz.ch/mailman/listinfo/r-help

> PLEASE do read the posting guide 

>  <http://www.R-project.org/posting-guide.html> http://www.R-project.org/posting-guide.html

> and provide commented, minimal, self-contained, reproducible code.

> 



______________________________________________

 <mailto:R-help at r-project.org> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  <https://stat.ethz.ch/mailman/listinfo/r-help> https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide  <http://www.R-project.org/posting-guide.html> http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Mar 24 19:40:46 2021
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 24 Mar 2021 11:40:46 -0700
Subject: [R] Calculating column differences
In-Reply-To: <CAA99HCwFZj7Yvw70GRTENLiehfx+dpSr4Mr=MNwS6UW23MeXTQ@mail.gmail.com>
References: <002b01d720cd$868cfc10$93a6f430$.ref@sbcglobal.net>
 <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>
 <CAA99HCwFZj7Yvw70GRTENLiehfx+dpSr4Mr=MNwS6UW23MeXTQ@mail.gmail.com>
Message-ID: <CAA99HCxOzhq-aYDGNyUng300v5tkVYfohLXz1Q0b3=Qxf3c0Cw@mail.gmail.com>

More correctly, with an initial "NA" value in the "diff" column:

> df <- data.frame(ID=1:5,Score=4*2:6)
> df1 <- rbind(c(0,0), df)
> cbind(df1, "diff"=c(NA, diff(df1$Score)) )
  ID Score diff
1  0     0   NA
2  1     8    8
3  2    12    4
4  3    16    4
5  4    20    4
6  5    24    4
>

HTH, Bill.
On Wed, Mar 24, 2021 at 10:59 AM William Michels <wjm1 at caa.columbia.edu> wrote:
>
> Dear Jeff,
>
> Rather than diff-ing a linear vector you're trying to diff values from
> two different rows. Also you indicate that you want to place the
> diff-ed value in the 'lower' row of a new column. Try this (note
> insertion of an initial "zero" row):
>
> > df <- data.frame(ID=1:5,Score=4*2:6)
> > df1 <- rbind(c(0,0), df)
> > cbind(df1, "diff"=c(0, diff(df1$Score)) )
>   ID Score diff
> 1  0     0    0
> 2  1     8    8
> 3  2    12    4
> 4  3    16    4
> 5  4    20    4
> 6  5    24    4
> >
>
> HTH, Bill.
>
> W. Michels, Ph.D.
>
>
>
> On Wed, Mar 24, 2021 at 9:49 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> >
> > r-help forum
> >
> >
> >
> > I'm trying to calculate the diff between two rows and them mutate the
> > difference into a new column. I'm using the diff function but not giving me
> > what I want.
> >
> >
> >
> > df <- data.frame(ID=1:5,Score=4*2:6)
> >
> >
> >
> > What a want  where
> >
> >   ID Score  diff
> >
> > 1  1     8      8
> >
> > 2  2    12     4
> >
> > 3  3    16     4
> >
> > 4  4    20     4
> >
> > 5  5    24     4
> >
> >
> >
> > What I am getting
> >
> >   ID Score  diff
> >
> > 1  1     8      NA
> >
> > 2  2    12     4
> >
> > 3  3    16     4
> >
> > 4  4    20     4
> >
> > 5  5    24     4
> >
> >
> >
> > Jeff
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From m@015k3113 @end|ng |rom b|ueyonder@co@uk  Wed Mar 24 20:11:07 2021
From: m@015k3113 @end|ng |rom b|ueyonder@co@uk (e-mail ma015k3113)
Date: Wed, 24 Mar 2021 19:11:07 +0000 (GMT)
Subject: [R] Converting POSIXct format date to Character format
In-Reply-To: <CAHLp6SCc4Vass-5Kwt3_80bubZCb91c_J6v0aA2DE0UEsOfJFA@mail.gmail.com>
References: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>
 <CAHLp6SCc4Vass-5Kwt3_80bubZCb91c_J6v0aA2DE0UEsOfJFA@mail.gmail.com>
Message-ID: <1902293860.753927.1616613067660@mail2.virginmedia.com>

I have a data frame "PLC" which has two variables Year_END_Date   EPS

YEAR_END_Date     EPS
2010-09-10        .10
2009-08-10        .20

When I tried to convert Year_END_Date to character format using

select(PLC, format(Year_END_Date,format = "%B %d, %Y"), EPS) I get an error

Error: Can't subset columns that don't exist.
x Column `Year_END_Date` doesn't exist.

I tried using 

PLC_1 <- select(PLC, as.character(YEAR_END_DATE), EPS)

I get the following error

Error: Can't subset columns that don't exist.
x Columns `2010-09-30`, `2009-09-30`, `2008-09-30`, `2007-09-30`, `2006-09-30`, etc. don't exist.
Run `rlang::last_error()` to see where the error occurred.

Can anyone please guide me what is happening and how can I resolve it?


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Mar 24 20:21:44 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 24 Mar 2021 19:21:44 +0000
Subject: [R] Converting POSIXct format date to Character format
In-Reply-To: <1902293860.753927.1616613067660@mail2.virginmedia.com>
References: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>
 <CAHLp6SCc4Vass-5Kwt3_80bubZCb91c_J6v0aA2DE0UEsOfJFA@mail.gmail.com>
 <1902293860.753927.1616613067660@mail2.virginmedia.com>
Message-ID: <604ef448-2755-595a-8b1d-437aade904a6@sapo.pt>

Hello,

R is case sensitive, the column name is YEAR_END_Date, neither of

Year_END_Date
YEAR_END_DATE

matches that name. Try

select(PLC, format(YEAR_END_Date,format = "%B %d, %Y"), EPS)


Hope this helps,

Rui Barradas

?s 19:11 de 24/03/21, e-mail ma015k3113 via R-help escreveu:
> I have a data frame "PLC" which has two variables Year_END_Date   EPS
> 
> YEAR_END_Date     EPS
> 2010-09-10        .10
> 2009-08-10        .20
> 
> When I tried to convert Year_END_Date to character format using
> 
> select(PLC, format(Year_END_Date,format = "%B %d, %Y"), EPS) I get an error
> 
> Error: Can't subset columns that don't exist.
> x Column `Year_END_Date` doesn't exist.
> 
> I tried using
> 
> PLC_1 <- select(PLC, as.character(YEAR_END_DATE), EPS)
> 
> I get the following error
> 
> Error: Can't subset columns that don't exist.
> x Columns `2010-09-30`, `2009-09-30`, `2008-09-30`, `2007-09-30`, `2006-09-30`, etc. don't exist.
> Run `rlang::last_error()` to see where the error occurred.
> 
> Can anyone please guide me what is happening and how can I resolve it?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @b|@yeng@|@b@ @end|ng |rom gm@||@com  Wed Mar 24 20:24:24 2021
From: @b|@yeng@|@b@ @end|ng |rom gm@||@com (Ablaye Ngalaba)
Date: Wed, 24 Mar 2021 20:24:24 +0100
Subject: [R] Help for storing value in the matrix
Message-ID: <CAOkWQv3zoMufb=fhPJeqRoeYY1gZN0X_O1wNr1ET_-AgBHoa1w@mail.gmail.com>

Hello,
I need help with my R programming code.

I just have a problem storing the matrix calculate Gsigma[m] in sigma.
Seeing what I have coded I find NA value which doesn't generate me errors.


  library(MASS)
# Creation of the linear kernel function
#Function N?1
Kernellin<-function(X,Y){
  return(X%*%t(Y))
}
# Function N?2
SqrtMatrice0<-function(M) {
  # This function allows us to calculate the square root of a matrix
  # using the decomposition M=PDQ where Q is the inverse of P
  # here the negative eigenvalues are replaced by zero
  a=eigen(M,TRUE)
  b=a$values
  b[b<0]=0
  c=a$vectors
  d=diag(sqrt(b))
  b=solve(c)
  a=c%*%d%*%b
  return(a)
}


# declaration of parameters
m1=0.01 # value of alpha (risque de 1%)
m2=0.05 # value of alpha (risque de 5%)
m3=0.1 # value of alpha (risque de 10%)
nbrefoissim=100 # number of times the program runs
p=3 #dimension of the variable X
#q=3 #dimension of the variable Y
#R=c(5,4,3);# Number of partitions of each component of the variable Y
if(length(R) != q) stop("The size of R must be equal to q")
n=25 # Taille echantillon
N=c(25,50,100,200,300,400,500,1000) #different sample sizes
#N=c(25,50) #ifferent sample sizes
pc1=rep(0,100)
K=0
MV=matrix(0,nr=8,nc=4)
dimnames(MV)[[2]]=c("n","r1%","r5%","r10%")


#Start of the programme

for (n in N){


  l1=0 # initialization of the value to calculate the test level at 1%.
  l2=0 # initialization of the value to calculate the test level at 1%. 5%
  l3=0 # initialization of the value to calculate the test level at 1%. 10%

  # Creation of a list nl which contains the sizes of the different groups
  y <- sample(q, 10, TRUE)
  l <- sample(q, 10, TRUE)
  ind <- function(y,l) ifelse(y == l, 1,0)
  for (i in 1:q) {
    nl[[i]]<-rep(sum(ind(y,l)),i)
    nl[[i]][[i]]=n-((i-1)*nl[[i]][1])
  }
  # Creation of the lists Pl1 and Pl2 which contain the probabilities and
  # the inverses of the empirical probabilities of the different groups
respectively
  pl1<-list()
  pl2<-list()
  for (i in 1:p) {
    pl1[[i]]<-nl[[i]]/n
    pl2[[i]]<-n/nl[[i]]
  }
  #Creation of a matrix unit
  Tt<-matrix (rep(1, 3*3), 3, 3)
  #Cr?ation de matrice
  aa<-c(1,0,1)
  bb<-c(1,1,0)
  TT<-matrix(c(aa,bb),3,3)

  for (i1 in 1:nbrefoissim){
    # data generation
    X <- mvrnorm(3,rep(0,p),diag(p))

    #Sigma calculation

    #kernel gram matrix calculation

    K1<-TT%*%Kernellin(X,X)%*%t(TT)
    k2<-Tt%*%Kernellin(X,X)%*%t(Tt)
    k3<-TT%*%Kernellin(X,X)%*%t(Tt)
    k4<-Tt%*%Kernellin(X,X)%*%t(TT)
    # B calculation
    B <- matrix(0, p, p)
    for (l in 1:q) {
      B<-B + pl1[[l]][1]*( K1/n^2 - k3/n^2 - k4/n^2 + k2/n^2 )
    }
    #kernel gram matrix calculation
    K5<-t(Tt)%*%Kernellin(X,X)
    K6<-Kernellin(X,X)%*%Tt
    #V calculation
    V <- matrix(0, p, p)
    V<-V + (Kernellin(X,X) - K5/n - K6/n - k4/n^2 )/n
    #kernel gram matrix calculation
    K7<-TT%*%Kernellin(X,X)
    K8<-Kernellin(X,X)%*%TT
    #W calculation
    W<-list()
    for (i in 1:p) {
      for (j in 1:p) {
        W<-matrix(0, p, p)
        Wi<-W + (Kernellin(X,X) - K7/n - K8/n - K1/n^2 )/nl[[i]][1]

        Wj<-W + (Kernellin(X,X) - K7/n - K8/n - K1/n^2 )/nl[[j]][3]
      }
    }
    # T4 calculation
    T4<-n*sum(diag(V%*%B))
    # GGamma calculation
    GGamma<-matrix(0,p*p,p*p)
    GGamma<- kronecker(diag(pl2[[i]]), ginv(V))
    #GSigma calculation
    kron <- function(i, j) ifelse(i==j, 1, 0)

    GSigma <- list()
    m = 1
    for(i in 1:p){

    for(j in 1:p){
        GSigma[[m]] <- kron(i,j)*pl1[[l]][1]*Wi +pl1[[i]][1]*pl1[[j]][3]*(V
- Wi - Wj )
        m <- m+1
      }
    }

    sigma <- matrix(0, p*p, p*p)
    m <- 1
    s <- 1
    for(i in 1:p){
      r <- i*p
      a <- 1
      for(j in 1:p){
        b <- j*p
        sigma[s:r, a:b] <-  GSigma[[m]]
        m <- m+1
        a <- b+1
      }
      s <- r+1
    }
    # Eigenvalue determinations of sigma epsilon
    pa<-SqrtMatrice0(sigma)
    mq<- pa %*% GGamma %*% pa
    u<-Re(eigen(mq)$values)

    # determination of degree of freedom and c-value noted va
    dl<-(sum(u)^2)/(sum(u^2))
    va<-(sum(u^2))/(sum(u))
    pc<-1-pchisq(tr1/va, df= dl)
    pc1[i1]<-pc


    # Test of the value obtained
    if (pc>m1) d1<-0 else d1<-1
    if (pc>m2) d2<-0 else d2<-1
    if (pc>m3) d3<-0 else d3<-1
    l1<-l1+d1
    l2<-l2+d2
    l3<-l3+d3
  }
  K<-K+1
  MV[K,1]<-n
  MV[K,2]<-l1/nbrefoissim #nbrefoissim=
  MV[K,3]<-l2/nbrefoissim
  MV[K,4]<-l3/nbrefoissim
}
pc


And here is the R code that I used to code mine.


library(MASS)

CentrageV<-function(X,Ms,n){
  # this function centres the data from X
  X1=X*0
  for (i in 1:n){
    X1[i,]=X[i,]-Ms
  }
  return(X1)
}


# Fonction N?2
SqrtMatrice0<-function(M) {
  # This function allows us to calculate the square root of a matrix
  # using the decomposition M=PDQ where Q is the inverse of P
  # here the negative eigenvalues are replaced by zero
  a=eigen(M,TRUE)
  b=a$values
  b[b<0]=0
  c=a$vectors
  d=diag(sqrt(b))
  b=solve(c)
  a=c%*%d%*%b
  return(a)
}


# declaration of parameters
m1=0.01 # value of alpha (risque de 1%)
m2=0.05 # value of alpha (risque de 5%)
m3=0.1 # value of alpha (risque de 10%)
nbrefoissim=100 # number of times the program runs
p=3 #dimension of the variable X
q=3 #dimension of the variable Y
R=c(5,4,3);# Number of partitions of each component of the variable Y
if(length(R) != q) stop("The size of R must be equal to q")
n=25 # Taille echantillon
N=c(25,50,100,200,300,400,500,1000) #different sample sizes
#N=c(25,50) #ifferent sample sizes
pc1=rep(0,100)
K=0
MV=matrix(0,nr=8,nc=4)
dimnames(MV)[[2]]=c("n","r1%","r5%","r10%")


#Start of the programme

for (n in N){


  l1=0 # initialization of the value to calculate the test level at 1%.
  l2=0 # initialization of the value to calculate the test level at 1%. 5%
  l3=0 # initialization of the value to calculate the test level at 1%. 10%

  # Creation of a list n11 which contains the sizes of the different groups
  n11=list()
  for (i in 1:q){
    n11[[i]]=rep(as.integer(n/R[i]),R[i])
    n11[[i]][R[i]]=n-((R[i]-1)*n11[[i]][1])
  }


  # Creation of the lists P11 and P12 which contain the probabilities and
  # the inverses of the empirical probabilities of the different groups
respectively

  P11=list()
  P12=list()
  for (i in 1:q){
    P11[[i]]=n11[[i]]/n
    P12[[i]]=n/n11[[i]]

  }

  # creation of a list containing the matrices W
  W=list()
  for (i in 1:q){
    w=matrix(0,n,R[i])
    w[1:n11[[i]][1],1]=1
    if (R[i]>1){
      for (j in 2:R[i]){
        s1=sum(n11[[i]][1:(j-1)])
        w[(1+s1):(s1+n11[[i]][j]),j]=1
      }}
    W[[i]]=w
  }

  for (i1 in 1:nbrefoissim){

    # data generation
    VA1=mvrnorm(n,rep(0,(p+q)),diag((p+q)))
    X=VA1[,1:p]
    Y=VA1[,(p+1):(p+q)]

    # Xbar calculation
    Xbar=colMeans(X)

    # Calculation of Xjh bar
    Xjhbar=list()
    for (i in 1:q){
      w=matrix(0,R[i],p)
      for (j in 1:R[i]){
        w[j,]=colSums(W[[i]][,j]*X)/n11[[i]][j]
      }
      Xjhbar[[i]]=w
    }

    #Calculation  TO.jh

    TO.jh=list()
    for (i in 1:q){
      w=Xjhbar[[i]]
      to=w*0
      for (j in 1:R[i]){
        to[j,]=w[j,]-Xbar
      }
      TO.jh[[i]]=to
    }

    #Calculation Lamda J

    Lamda=matrix(0,p,p)
    for (i in 1:q){
      to=TO.jh[[i]]
      w=matrix(0,p,p)
      for (j in 1:R[i]){
        w=w+(P11[[i]][j]*(to[j,]%*%t(to[j,])))
      }
      Lamda=Lamda+w
    }

    tr1=n*sum(diag(Lamda))

    # Calculation of Gamma

    GGamma=matrix(0,p*sum(R),p*sum(R))
    PGamma=kronecker(diag(P12[[1]]),diag(p))
    Ifin=p*R[1]
    GGamma[1:Ifin,1:Ifin]=PGamma
    for (i in 2:q){
      PGamma=kronecker(diag(P12[[i]]),diag(p))
      Idebut=((p*sum(R[1:(i-1)]))+1)
      Ifin=(p*sum(R[1:i]))
      GGamma[Idebut:Ifin,Idebut:Ifin]=PGamma
    }

    #Calculation of Sigma

    # Calculation of Vn
    X1=CentrageV(X,Xbar,n)
    Vn=t(X1)%*%X1/n

    ## Calculation of Sigma
    GSigma=matrix(0,p*sum(R),p*sum(R))
    for (i in 1:q ){
      for (j in 1:R[i] ){
        Xij=CentrageV(X,Xjhbar[[i]][j,],n)
        Vij=t(W[[i]][,j]*Xij)%*%Xij/n11[[i]][j]

        for (k in 1:q ){
          for (l in 1:R[k]){

            Xkl=CentrageV(X,Xjhbar[[k]][l,],n)
            Vijkl=t(W[[i]][,j]*Xij)%*%(W[[k]][,l]*Xkl)/n

            Vkl=t(W[[k]][,l]*Xkl)%*%Xkl/n11[[k]][l]

            if (i==1) Idebut=((j-1)*p)+1 else
Idebut=((sum(R[1:(i-1)])+j-1)*p)+1
            if (i==1) Idebut1=(j*p) else Idebut1=((sum(R[1:(i-1)])+j)*p)
            if (k==1) Ifin=((l-1)*p)+1 else Ifin=((sum(R[1:(k-1)])+l-1)*p)+1
            if (k==1) Ifin1=(l*p) else Ifin1=((sum(R[1:(k-1)])+l)*p)


GSigma[Idebut:Idebut1,Ifin:Ifin1]=Vijkl+(P11[[i]][j]*P11[[k]][l]*(Vn-Vij-Vkl))
          }
        }
      }
    }


    # Eigenvalue determinations of sigma epsilon
    pa=SqrtMatrice0(GSigma)
    mq= pa %*% GGamma %*% pa
    u=Re(eigen(mq)$values)


    # determination of degree of freedom and c-value noted va
    dl=(sum(u)^2)/(sum(u^2))
    va=(sum(u^2))/(sum(u))
    pc=1-pchisq(tr1/va, df= dl)
    pc1[i1]=pc

    # Test of the value obtained
    if (pc>m1) d1=0 else d1=1
    if (pc>m2) d2=0 else d2=1
    if (pc>m3) d3=0 else d3=1
    l1=l1+d1
    l2=l2+d2
    l3=l3+d3
  }
  K=K+1
  MV[K,1]=n
  MV[K,2]=l1/nbrefoissim #nbrefoissim=number of simulations
  MV[K,3]=l2/nbrefoissim
  MV[K,4]=l3/nbrefoissim
}




       Sincerely

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Mar 24 21:50:21 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 24 Mar 2021 15:50:21 -0500
Subject: [R] Calculating column differences
In-Reply-To: <CAA99HCxOzhq-aYDGNyUng300v5tkVYfohLXz1Q0b3=Qxf3c0Cw@mail.gmail.com>
References: <002b01d720cd$868cfc10$93a6f430$.ref@sbcglobal.net>
 <002b01d720cd$868cfc10$93a6f430$@sbcglobal.net>
 <CAA99HCwFZj7Yvw70GRTENLiehfx+dpSr4Mr=MNwS6UW23MeXTQ@mail.gmail.com>
 <CAA99HCxOzhq-aYDGNyUng300v5tkVYfohLXz1Q0b3=Qxf3c0Cw@mail.gmail.com>
Message-ID: <006601d720ef$4ed62a90$ec827fb0$@sbcglobal.net>

Bill 

I ended up taking a different approach
miDat <- miDat %>% 
  mutate(new_cases = cases - lag(cases, default = 0))

 - or - 

df <- df %>% 
  mutate(diff = Score - lag(Score, default = 0))

Jeff

-----Original Message-----
From: William Michels <wjm1 at caa.columbia.edu> 
Sent: Wednesday, March 24, 2021 1:41 PM
To: r-help at r-project.org
Cc: reichmanj at sbcglobal.net; Gerrit Eichner <gerrit.eichner at math.uni-giessen.de>
Subject: Re: [R] Calculating column differences

More correctly, with an initial "NA" value in the "diff" column:

> df <- data.frame(ID=1:5,Score=4*2:6)
> df1 <- rbind(c(0,0), df)
> cbind(df1, "diff"=c(NA, diff(df1$Score)) )
  ID Score diff
1  0     0   NA
2  1     8    8
3  2    12    4
4  3    16    4
5  4    20    4
6  5    24    4
>

HTH, Bill.
On Wed, Mar 24, 2021 at 10:59 AM William Michels <wjm1 at caa.columbia.edu> wrote:
>
> Dear Jeff,
>
> Rather than diff-ing a linear vector you're trying to diff values from 
> two different rows. Also you indicate that you want to place the 
> diff-ed value in the 'lower' row of a new column. Try this (note 
> insertion of an initial "zero" row):
>
> > df <- data.frame(ID=1:5,Score=4*2:6)
> > df1 <- rbind(c(0,0), df)
> > cbind(df1, "diff"=c(0, diff(df1$Score)) )
>   ID Score diff
> 1  0     0    0
> 2  1     8    8
> 3  2    12    4
> 4  3    16    4
> 5  4    20    4
> 6  5    24    4
> >
>
> HTH, Bill.
>
> W. Michels, Ph.D.
>
>
>
> On Wed, Mar 24, 2021 at 9:49 AM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> >
> > r-help forum
> >
> >
> >
> > I'm trying to calculate the diff between two rows and them mutate 
> > the difference into a new column. I'm using the diff function but 
> > not giving me what I want.
> >
> >
> >
> > df <- data.frame(ID=1:5,Score=4*2:6)
> >
> >
> >
> > What a want  where
> >
> >   ID Score  diff
> >
> > 1  1     8      8
> >
> > 2  2    12     4
> >
> > 3  3    16     4
> >
> > 4  4    20     4
> >
> > 5  5    24     4
> >
> >
> >
> > What I am getting
> >
> >   ID Score  diff
> >
> > 1  1     8      NA
> >
> > 2  2    12     4
> >
> > 3  3    16     4
> >
> > 4  4    20     4
> >
> > 5  5    24     4
> >
> >
> >
> > Jeff
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Mar 25 00:41:49 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 24 Mar 2021 16:41:49 -0700
Subject: [R] Converting POSIXct format date to Character format
In-Reply-To: <1902293860.753927.1616613067660@mail2.virginmedia.com>
References: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>
 <CAHLp6SCc4Vass-5Kwt3_80bubZCb91c_J6v0aA2DE0UEsOfJFA@mail.gmail.com>
 <1902293860.753927.1616613067660@mail2.virginmedia.com>
Message-ID: <1EA3805F-E045-4D6B-B909-E71BD459CC30@dcn.davis.ca.us>

Please don't reply to a thread to start a new question... create a new email to avoid linking your question with the one you replied to.

On March 24, 2021 12:11:07 PM PDT, e-mail ma015k3113 via R-help <r-help at r-project.org> wrote:
>I have a data frame "PLC" which has two variables Year_END_Date   EPS
>
>YEAR_END_Date     EPS
>2010-09-10        .10
>2009-08-10        .20
>
>When I tried to convert Year_END_Date to character format using
>
>select(PLC, format(Year_END_Date,format = "%B %d, %Y"), EPS) I get an
>error
>
>Error: Can't subset columns that don't exist.
>x Column `Year_END_Date` doesn't exist.
>
>I tried using 
>
>PLC_1 <- select(PLC, as.character(YEAR_END_DATE), EPS)
>
>I get the following error
>
>Error: Can't subset columns that don't exist.
>x Columns `2010-09-30`, `2009-09-30`, `2008-09-30`, `2007-09-30`,
>`2006-09-30`, etc. don't exist.
>Run `rlang::last_error()` to see where the error occurred.
>
>Can anyone please guide me what is happening and how can I resolve it?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Mar 25 02:32:48 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 25 Mar 2021 14:32:48 +1300
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
Message-ID: <20210325143248.4982d3cd@rolf-Latitude-E7470>


I would like a real-life example of a data set which one might think to
model by a binomial distribution, but which is substantially
underdispersed. I.e. a sample X = {X_1, X_2, ..., X_N} where each X_i
is an integer between 0 and n (n known a priori) such that var(X) <<
mean(X)*(1 - mean(X)/n).

Does anyone know of any such examples?  Do any exist?  I've done
a perfunctory web search, and had a look at "A Handbook of Small
Data Sets" by Hand, Daly, Lunn, et al., and drawn a blank.

I've seen on the web some references to underdispersed "pseudo-Poisson"
data, but not to underdispersed "pseudo-binomial" data.  And of course
there's lots of *over* dispersed stuff.  But that's not what I want.

I can *simulate* data sets of the sor that I am looking for (so far the
only ideas I've had for doing this are pretty simplistic and
artificial) but I'd like to get my hands on a *real* example, if
possible.

Grateful for any pointers/suggestions.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter@4567 @end|ng |rom gm@||@com  Thu Mar 25 02:40:49 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 24 Mar 2021 18:40:49 -0700
Subject: [R] Converting POSIXct format date to Character format
In-Reply-To: <1EA3805F-E045-4D6B-B909-E71BD459CC30@dcn.davis.ca.us>
References: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>
 <CAHLp6SCc4Vass-5Kwt3_80bubZCb91c_J6v0aA2DE0UEsOfJFA@mail.gmail.com>
 <1902293860.753927.1616613067660@mail2.virginmedia.com>
 <1EA3805F-E045-4D6B-B909-E71BD459CC30@dcn.davis.ca.us>
Message-ID: <CAGxFJbSx7j+O8nWOpgwPzYdBYiiNT=vNFcw9Ndcmm4EdBtghcA@mail.gmail.com>

What package is select() in?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 24, 2021 at 4:42 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please don't reply to a thread to start a new question... create a new
> email to avoid linking your question with the one you replied to.
>
> On March 24, 2021 12:11:07 PM PDT, e-mail ma015k3113 via R-help <
> r-help at r-project.org> wrote:
> >I have a data frame "PLC" which has two variables Year_END_Date   EPS
> >
> >YEAR_END_Date     EPS
> >2010-09-10        .10
> >2009-08-10        .20
> >
> >When I tried to convert Year_END_Date to character format using
> >
> >select(PLC, format(Year_END_Date,format = "%B %d, %Y"), EPS) I get an
> >error
> >
> >Error: Can't subset columns that don't exist.
> >x Column `Year_END_Date` doesn't exist.
> >
> >I tried using
> >
> >PLC_1 <- select(PLC, as.character(YEAR_END_DATE), EPS)
> >
> >I get the following error
> >
> >Error: Can't subset columns that don't exist.
> >x Columns `2010-09-30`, `2009-09-30`, `2008-09-30`, `2007-09-30`,
> >`2006-09-30`, etc. don't exist.
> >Run `rlang::last_error()` to see where the error occurred.
> >
> >Can anyone please guide me what is happening and how can I resolve it?
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Mar 25 02:43:52 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 25 Mar 2021 12:43:52 +1100
Subject: [R] Converting POSIXct format date to Character format
In-Reply-To: <1902293860.753927.1616613067660@mail2.virginmedia.com>
References: <CAHLp6SBA5uWVEEff8CSP4U1o+3dCJYrsDi3WRByD+XzUd6XScg@mail.gmail.com>
 <CAHLp6SCc4Vass-5Kwt3_80bubZCb91c_J6v0aA2DE0UEsOfJFA@mail.gmail.com>
 <1902293860.753927.1616613067660@mail2.virginmedia.com>
Message-ID: <CA+8X3fVbhPaaxq4Fyt0v3TXvADu+NpL-ZVsToBxi7e6MfCBBrg@mail.gmail.com>

Hi ma015k3113,
I suspect that you are asking the wrong question.

# create an example data frame with an extra field
PLC<-read.table(text="YEAR_END_Date     EPS   junk
2010-09-10        .10 A
2009-08-10        .20 B",
header=TRUE,
stringsAsFactors=FALSE)
# first, I think that you may already have the date in character format
# if you get this result, you don't need to convert it
sapply(PLC,"class")
YEAR_END_Date           EPS          junk
 "character"     "numeric"   "character"
# however, if you get this result
sapply(PLC,"class")
$YEAR_END_Date
[1] "POSIXlt" "POSIXt"

$EPS
[1] "numeric"

$junk
[1] "character"
# then you do have a POSIX date in the first field,
# so you can do this:
PLC$YEAR_END_Date<-format(PLC$YEAR_END_Date,format="%Y-%m-%d")
# then if you want to select those two fields for further processing
# use this expression
PLC[,c("YEAR_END_Date","EPS")]

Jim

On Thu, Mar 25, 2021 at 6:11 AM e-mail ma015k3113 via R-help
<r-help at r-project.org> wrote:
>
> I have a data frame "PLC" which has two variables Year_END_Date   EPS
>
> YEAR_END_Date     EPS
> 2010-09-10        .10
> 2009-08-10        .20
>
> When I tried to convert Year_END_Date to character format using
>
> select(PLC, format(Year_END_Date,format = "%B %d, %Y"), EPS) I get an error
>
> Error: Can't subset columns that don't exist.
> x Column `Year_END_Date` doesn't exist.
>
> I tried using
>
> PLC_1 <- select(PLC, as.character(YEAR_END_DATE), EPS)
>
> I get the following error
>
> Error: Can't subset columns that don't exist.
> x Columns `2010-09-30`, `2009-09-30`, `2008-09-30`, `2007-09-30`, `2006-09-30`, etc. don't exist.
> Run `rlang::last_error()` to see where the error occurred.
>
> Can anyone please guide me what is happening and how can I resolve it?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From phii m@iii@g oii phiiipsmith@c@  Thu Mar 25 03:24:21 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Wed, 24 Mar 2021 22:24:21 -0400
Subject: [R] Including a ggplot call with a conditional geom in a function
Message-ID: <e1f9d4f9344baa8a3bee51df047acfa3@philipsmith.ca>

How can I write an R function that contains a call to ggplot within it, 
with one of the ggplot geom statements being conditional? In my reprex, 
I want the plot to contain a horizontal zero line if the y values are 
both positive and negative, and to exclude the horizontal line if all of 
the y values are of the same sign. I tried a simple if statement, but it 
does not work. Suggestions appreciated. Philip

library(rlang)
library(tidyverse)

a <- c(1:8)
b <- c(23,34,45,43,32,45,68,78)
c <- c(0.34,0.56,0.97,0.33,-0.23,-0.36,-0.11,0.17)
df <- data.frame(a,b,c)

posNeg <- function(x) {
   ifelse(sum(x>0)>0 & sum(x>0)<length(x), y <- TRUE,y <- FALSE)
}
plotLineFunc <- function(MYdf,MYx,MYy) {
     ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))+
     #if(posNeg({{MYy}})) geom_hline(yintercept=0,size=0.2)+   # This 
does not work
     geom_line(colour="black",size=0.5)
}
(plot1 <- plotLineFunc(df,a,b))
(plot2 <- plotLineFunc(df,a,c))


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Mar 25 03:41:25 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 24 Mar 2021 22:41:25 -0400
Subject: [R] 
 Including a ggplot call with a conditional geom in a function
In-Reply-To: <e1f9d4f9344baa8a3bee51df047acfa3@philipsmith.ca>
References: <e1f9d4f9344baa8a3bee51df047acfa3@philipsmith.ca>
Message-ID: <07e801d72120$59e5c720$0db15560$@verizon.net>

This may not be the right place to ask about ggplot which is part of
packages but are you aware how ggplot works additively?

You can say something like:

P <- ggplot(...) ... + ...

Then later say:

P <- p + geom_...()

And so on.

So if you set al the layers you want first into a variable like p, then in
an if statement you selectively add in one or another layer and finally add
in all remaining layers before printing it, would that simply meet your
need?

Realistically, ggplot creates a data structure and the PLUS of other layers
updates or expands that structure but nothing happens till you print it and
it evaluates the data structure.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of phil at philipsmith.ca
Sent: Wednesday, March 24, 2021 10:24 PM
To: r-help at r-project.org
Subject: [R] Including a ggplot call with a conditional geom in a function

How can I write an R function that contains a call to ggplot within it, with
one of the ggplot geom statements being conditional? In my reprex, I want
the plot to contain a horizontal zero line if the y values are both positive
and negative, and to exclude the horizontal line if all of the y values are
of the same sign. I tried a simple if statement, but it does not work.
Suggestions appreciated. Philip

library(rlang)
library(tidyverse)

a <- c(1:8)
b <- c(23,34,45,43,32,45,68,78)
c <- c(0.34,0.56,0.97,0.33,-0.23,-0.36,-0.11,0.17)
df <- data.frame(a,b,c)

posNeg <- function(x) {
   ifelse(sum(x>0)>0 & sum(x>0)<length(x), y <- TRUE,y <- FALSE) }
plotLineFunc <- function(MYdf,MYx,MYy) {
     ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))+
     #if(posNeg({{MYy}})) geom_hline(yintercept=0,size=0.2)+   # This 
does not work
     geom_line(colour="black",size=0.5)
}
(plot1 <- plotLineFunc(df,a,b))
(plot2 <- plotLineFunc(df,a,c))

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nev||@@mo@ @end|ng |rom gm@||@com  Thu Mar 25 05:40:20 2021
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Thu, 25 Mar 2021 15:40:20 +1100
Subject: [R] setting wd to parent directory ("..") of rmd file for all
 chunks of .Rmd
Message-ID: <CAN9eD7mAw6qcs1OXud3YP3W0DpsKTLm7Xc8qC7cphGGd8QbrEA@mail.gmail.com>

The Rmarkdown cookbook states that the working directory for r chunks in an
Rmd file is usually the directory containing the file,
 however it can be reset using

knitr::opts_knit$set(root.dir =

see:
https://bookdown.org/yihui/rmarkdown-cookbook/working-directory.html#working-directory
I want to set the directory to the parent direcotry of the default directory
usually I would acheive this using  setwd("..") so  in the rmd I used the
following:

```{r setup, include=FALSE,}
print(getwd())
knitr::opts_knit$set(root.dir = '..')
print(getwd())
```
the  print(getwd()) being just to demonstrate the result.  There is no
change in the directory.
How do I change the working directory ?

thanks

nevil Amos

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Mar 25 06:40:55 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 25 Mar 2021 18:40:55 +1300
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
In-Reply-To: <CAGxFJbT80SnBAHAV9UM+n6ETXnKn6Pt0qnvMQk5ezoyzL3RyFw@mail.gmail.com>
References: <20210325143248.4982d3cd@rolf-Latitude-E7470>
 <CAGxFJbT80SnBAHAV9UM+n6ETXnKn6Pt0qnvMQk5ezoyzL3RyFw@mail.gmail.com>
Message-ID: <20210325184055.4ab91f6d@rolf-Latitude-E7470>


On Wed, 24 Mar 2021 18:45:01 -0700
<Name suppressed to protect the innocent> wrote:

> "X = {X_1, X_2, ..., X_N} where each X_i
> is an integer between 0 and n (n known a priori)"
> 
> That is a multinomial, not a binomial distribution. A binomial
> distribution can have only two values, success or failure.
> 
> What have I misunderstood?

And then, following up:

> Oh, I think I get what you mean -- you are drawing repeated samples
> from a binomial with n trials and you are counting the number of
> successes for each.

Yes.  Exactly.  Sorry if my post was unclear.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Mar 25 07:23:48 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 25 Mar 2021 06:23:48 +0000
Subject: [R] 
 Including a ggplot call with a conditional geom in a function
In-Reply-To: <e1f9d4f9344baa8a3bee51df047acfa3@philipsmith.ca>
References: <e1f9d4f9344baa8a3bee51df047acfa3@philipsmith.ca>
Message-ID: <a190f6cc-20b6-929b-8e7b-9a4ca7b0c717@sapo.pt>

Hello,

In the following code, the fixed parts of the plot are drawn first, 
assigning the plot to p. Then geom_hline is conditionally added to p and 
the result returned to caller.
This may be a problem if the conditional geom needs to be in a specified 
order in the plot. Function plotLineFunc2 adds everything in the order 
of the question and is probably a better way of solving the problem.

I have also rewritten posNeg() without ifelse.

posNeg <- function(x) sum(x>0)>0 & sum(x>0)<length(x)

plotLineFunc <- function(MYdf,MYx,MYy) {
   p <- ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))+
     geom_line(colour="black",size=0.5)
   if(posNeg({{MYy}}))
     p + geom_hline(yintercept=0,size=0.2)
   else p
}

plotLineFunc2 <- function(MYdf,MYx,MYy) {
   p <- ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))
   p <- if(posNeg({{MYy}}))
     p + geom_hline(yintercept=0,size=0.2)
   else p
   p + geom_line(colour="black",size=0.5)
}


(plot1 <- plotLineFunc(df,a,b))
(plot2 <- plotLineFunc(df,a,c))


Hope this helps,

Rui Barradas

?s 02:24 de 25/03/21, phil at philipsmith.ca escreveu:
> How can I write an R function that contains a call to ggplot within it, 
> with one of the ggplot geom statements being conditional? In my reprex, 
> I want the plot to contain a horizontal zero line if the y values are 
> both positive and negative, and to exclude the horizontal line if all of 
> the y values are of the same sign. I tried a simple if statement, but it 
> does not work. Suggestions appreciated. Philip
> 
> library(rlang)
> library(tidyverse)
> 
> a <- c(1:8)
> b <- c(23,34,45,43,32,45,68,78)
> c <- c(0.34,0.56,0.97,0.33,-0.23,-0.36,-0.11,0.17)
> df <- data.frame(a,b,c)
> 
> posNeg <- function(x) {
>  ? ifelse(sum(x>0)>0 & sum(x>0)<length(x), y <- TRUE,y <- FALSE)
> }
> plotLineFunc <- function(MYdf,MYx,MYy) {
>  ??? ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))+
>  ??? #if(posNeg({{MYy}})) geom_hline(yintercept=0,size=0.2)+?? # This 
> does not work
>  ??? geom_line(colour="black",size=0.5)
> }
> (plot1 <- plotLineFunc(df,a,b))
> (plot2 <- plotLineFunc(df,a,c))
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From phii m@iii@g oii phiiipsmith@c@  Thu Mar 25 14:38:46 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Thu, 25 Mar 2021 09:38:46 -0400
Subject: [R] R-help Digest, Vol 217, Issue 25
In-Reply-To: <mailman.362655.1.1616670001.25955.r-help@r-project.org>
References: <mailman.362655.1.1616670001.25955.r-help@r-project.org>
Message-ID: <2d5b8ea5223f78474651113807b2d5f7@philipsmith.ca>

Thank you, Messrs Barradas and Gross, for your very helpful advice.

Philip
> 
> Message: 21
> Date: Wed, 24 Mar 2021 22:41:25 -0400
> From: "Avi Gross" <avigross at verizon.net>
> To: <r-help at r-project.org>
> Subject: Re: [R]  Including a ggplot call with a conditional geom in a
> 	function
> Message-ID: <07e801d72120$59e5c720$0db15560$@verizon.net>
> Content-Type: text/plain; charset="us-ascii"
> 
> This may not be the right place to ask about ggplot which is part of
> packages but are you aware how ggplot works additively?
> 
> You can say something like:
> 
> P <- ggplot(...) ... + ...
> 
> Then later say:
> 
> P <- p + geom_...()
> 
> And so on.
> 
> So if you set al the layers you want first into a variable like p, then 
> in
> an if statement you selectively add in one or another layer and finally 
> add
> in all remaining layers before printing it, would that simply meet your
> need?
> 
> Realistically, ggplot creates a data structure and the PLUS of other 
> layers
> updates or expands that structure but nothing happens till you print it 
> and
> it evaluates the data structure.
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of 
> phil at philipsmith.ca
> Sent: Wednesday, March 24, 2021 10:24 PM
> To: r-help at r-project.org
> Subject: [R] Including a ggplot call with a conditional geom in a 
> function
> 
> How can I write an R function that contains a call to ggplot within it, 
> with
> one of the ggplot geom statements being conditional? In my reprex, I 
> want
> the plot to contain a horizontal zero line if the y values are both 
> positive
> and negative, and to exclude the horizontal line if all of the y values 
> are
> of the same sign. I tried a simple if statement, but it does not work.
> Suggestions appreciated. Philip
> 
> library(rlang)
> library(tidyverse)
> 
> a <- c(1:8)
> b <- c(23,34,45,43,32,45,68,78)
> c <- c(0.34,0.56,0.97,0.33,-0.23,-0.36,-0.11,0.17)
> df <- data.frame(a,b,c)
> 
> posNeg <- function(x) {
>    ifelse(sum(x>0)>0 & sum(x>0)<length(x), y <- TRUE,y <- FALSE) }
> plotLineFunc <- function(MYdf,MYx,MYy) {
>      ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))+
>      #if(posNeg({{MYy}})) geom_hline(yintercept=0,size=0.2)+   # This
> does not work
>      geom_line(colour="black",size=0.5)
> }
> (plot1 <- plotLineFunc(df,a,b))
> (plot2 <- plotLineFunc(df,a,c))
> 
> ______________________________________________
> 
> Message: 24
> Date: Thu, 25 Mar 2021 06:23:48 +0000
> From: Rui Barradas <ruipbarradas at sapo.pt>
> To: phil at philipsmith.ca, r-help at r-project.org
> Subject: Re: [R]  Including a ggplot call with a conditional geom in a
> 	function
> Message-ID: <a190f6cc-20b6-929b-8e7b-9a4ca7b0c717 at sapo.pt>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
> 
> Hello,
> 
> In the following code, the fixed parts of the plot are drawn first,
> assigning the plot to p. Then geom_hline is conditionally added to p 
> and
> the result returned to caller.
> This may be a problem if the conditional geom needs to be in a 
> specified
> order in the plot. Function plotLineFunc2 adds everything in the order
> of the question and is probably a better way of solving the problem.
> 
> I have also rewritten posNeg() without ifelse.
> 
> posNeg <- function(x) sum(x>0)>0 & sum(x>0)<length(x)
> 
> plotLineFunc <- function(MYdf,MYx,MYy) {
>    p <- ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))+
>      geom_line(colour="black",size=0.5)
>    if(posNeg({{MYy}}))
>      p + geom_hline(yintercept=0,size=0.2)
>    else p
> }
> 
> plotLineFunc2 <- function(MYdf,MYx,MYy) {
>    p <- ggplot(MYdf,aes(x={{MYx}},y={{MYy}}))
>    p <- if(posNeg({{MYy}}))
>      p + geom_hline(yintercept=0,size=0.2)
>    else p
>    p + geom_line(colour="black",size=0.5)
> }
> 
> 
> (plot1 <- plotLineFunc(df,a,b))
> (plot2 <- plotLineFunc(df,a,c))
> 
> 
> Hope this helps,
> 
> Rui Barradas


From 538280 @end|ng |rom gm@||@com  Thu Mar 25 18:03:30 2021
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 25 Mar 2021 11:03:30 -0600
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <s37lbh$svd$1@ciao.gmane.io>
References: <s37lbh$svd$1@ciao.gmane.io>
Message-ID: <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>

Here is one approach:

tmp <- data.frame(min=seq(0,150, by=15))

tmp %>%
  mutate(hm=sprintf("%2d Hour%s %2d Minutes",
                    min %/% 60, ifelse((min %/% 60) == 1, " ", "s"),
                    min %% 60))

You could replace `sprintf` with `str_glue` (and update the syntax as
well) if you realy need tidyverse, but you would also loose some
formatting capability.

I don't know of tidyverse versions of `%/%` or `%%`.  If you need the
numeric values instead of a string then just remove the `sprintf` and
use mutate directly with `min %/% 60` and `min %% 60`.

This of course assumes all of your data is in minutes (by the time you
pipe to this code) and that all hours have 60 minutes (I don't know of
any leap hours.

On Sun, Mar 21, 2021 at 8:31 AM Dr Eberhard W Lisse <nospam at lisse.na> wrote:
>
> Hi,
>
> I have minutes worked by day (with some more information)
>
> which when using
>
>         library(tidyverse)
>         library(lubridate)
>
> run through
>
>         CONSMINUTES %>%
>                 select(datum, dauer) %>%
>                 arrange(desc(datum))
>
> look somewhat like
>
>         # A tibble: 142 x 2
>            datum      dauer
>            <date>     <int>
>          1 2021-03-18    30
>          2 2021-03-17    30
>          3 2021-03-16    30
>          4 2021-03-16    30
>          5 2021-03-16    30
>          6 2021-03-16    30
>          7 2021-03-11    30
>          8 2021-03-11    30
>          9 2021-03-11    30
>         10 2021-03-11    30
>         # ? with 132 more rows
>
> I can extract minutes per hour
>
>         CONSMINUTES %>%
>         select(datum, dauer) %>%
>         group_by(week = format(datum, '%Y %V'))%>%
>         summarise_if(is.numeric, sum)
>
> and minutes per month
>
>         CONSMINUTES %>%
>         select(datum, dauer) %>%
>         group_by(month = format(datum, '%Y %m'))%>%
>         summarise_if(is.numeric, sum)
>
> I need to show the time worked per week per month in the format of
>
>         '# hours # minutes'
>
> and would like to also be able to show the average time per week per
> month.
>
> How can I do that (preferably with tidyverse :-)-O)?
>
> greetings, el
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From no@p@m @end|ng |rom ||@@e@NA  Thu Mar 25 19:34:15 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Thu, 25 Mar 2021 20:34:15 +0200
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>
References: <s37lbh$svd$1@ciao.gmane.io>
 <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>
Message-ID: <s3il39$47o$1@ciao.gmane.io>

Thanks, that is helpful.

But, how do I group it to produce hours worked per week per month?

el


On 2021-03-25 19:03 , Greg Snow wrote:
> Here is one approach:
> 
> tmp <- data.frame(min=seq(0,150, by=15))
> 
> tmp %>%
>    mutate(hm=sprintf("%2d Hour%s %2d Minutes",
>                      min %/% 60, ifelse((min %/% 60) == 1, " ", "s"),
>                      min %% 60))
> 
> You could replace `sprintf` with `str_glue` (and update the syntax as
> well) if you realy need tidyverse, but you would also loose some
> formatting capability.
> 
> I don't know of tidyverse versions of `%/%` or `%%`.  If you need the
> numeric values instead of a string then just remove the `sprintf` and
> use mutate directly with `min %/% 60` and `min %% 60`.
> 
> This of course assumes all of your data is in minutes (by the time you
> pipe to this code) and that all hours have 60 minutes (I don't know of
> any leap hours.
> 
> On Sun, Mar 21, 2021 at 8:31 AM Dr Eberhard W Lisse <nospam at lisse.na> wrote:
>>
>> Hi,
>>
>> I have minutes worked by day (with some more information)
>>
>> which when using
>>
>>          library(tidyverse)
>>          library(lubridate)
>>
>> run through
>>
>>          CONSMINUTES %>%
>>                  select(datum, dauer) %>%
>>                  arrange(desc(datum))
>>
>> look somewhat like
>>
>>          # A tibble: 142 x 2
>>             datum      dauer
>>             <date>     <int>
>>           1 2021-03-18    30
>>           2 2021-03-17    30
>>           3 2021-03-16    30
>>           4 2021-03-16    30
>>           5 2021-03-16    30
>>           6 2021-03-16    30
>>           7 2021-03-11    30
>>           8 2021-03-11    30
>>           9 2021-03-11    30
>>          10 2021-03-11    30
>>          # ? with 132 more rows
>>
>> I can extract minutes per hour
>>
>>          CONSMINUTES %>%
>>          select(datum, dauer) %>%
>>          group_by(week = format(datum, '%Y %V'))%>%
>>          summarise_if(is.numeric, sum)
>>
>> and minutes per month
>>
>>          CONSMINUTES %>%
>>          select(datum, dauer) %>%
>>          group_by(month = format(datum, '%Y %m'))%>%
>>          summarise_if(is.numeric, sum)
>>
>> I need to show the time worked per week per month in the format of
>>
>>          '# hours # minutes'
>>
>> and would like to also be able to show the average time per week per
>> month.
>>
>> How can I do that (preferably with tidyverse :-)-O)?
>>
>> greetings, el
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Mar 25 21:37:53 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 25 Mar 2021 13:37:53 -0700
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <s3il39$47o$1@ciao.gmane.io>
References: <s37lbh$svd$1@ciao.gmane.io>
 <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>
 <s3il39$47o$1@ciao.gmane.io>
Message-ID: <0D75B81F-2D2A-4A77-9523-B5AB23900643@dcn.davis.ca.us>

This is a very unclear question. Weeks don't line up with months.. so you need to clarify how you would do this or at least give an explicit example of input data and result data.

On March 25, 2021 11:34:15 AM PDT, Dr Eberhard W Lisse <nospam at lisse.NA> wrote:
>Thanks, that is helpful.
>
>But, how do I group it to produce hours worked per week per month?
>
>el
>
>
>On 2021-03-25 19:03 , Greg Snow wrote:
>> Here is one approach:
>> 
>> tmp <- data.frame(min=seq(0,150, by=15))
>> 
>> tmp %>%
>>    mutate(hm=sprintf("%2d Hour%s %2d Minutes",
>>                      min %/% 60, ifelse((min %/% 60) == 1, " ", "s"),
>>                      min %% 60))
>> 
>> You could replace `sprintf` with `str_glue` (and update the syntax as
>> well) if you realy need tidyverse, but you would also loose some
>> formatting capability.
>> 
>> I don't know of tidyverse versions of `%/%` or `%%`.  If you need the
>> numeric values instead of a string then just remove the `sprintf` and
>> use mutate directly with `min %/% 60` and `min %% 60`.
>> 
>> This of course assumes all of your data is in minutes (by the time
>you
>> pipe to this code) and that all hours have 60 minutes (I don't know
>of
>> any leap hours.
>> 
>> On Sun, Mar 21, 2021 at 8:31 AM Dr Eberhard W Lisse <nospam at lisse.na>
>wrote:
>>>
>>> Hi,
>>>
>>> I have minutes worked by day (with some more information)
>>>
>>> which when using
>>>
>>>          library(tidyverse)
>>>          library(lubridate)
>>>
>>> run through
>>>
>>>          CONSMINUTES %>%
>>>                  select(datum, dauer) %>%
>>>                  arrange(desc(datum))
>>>
>>> look somewhat like
>>>
>>>          # A tibble: 142 x 2
>>>             datum      dauer
>>>             <date>     <int>
>>>           1 2021-03-18    30
>>>           2 2021-03-17    30
>>>           3 2021-03-16    30
>>>           4 2021-03-16    30
>>>           5 2021-03-16    30
>>>           6 2021-03-16    30
>>>           7 2021-03-11    30
>>>           8 2021-03-11    30
>>>           9 2021-03-11    30
>>>          10 2021-03-11    30
>>>          # ? with 132 more rows
>>>
>>> I can extract minutes per hour
>>>
>>>          CONSMINUTES %>%
>>>          select(datum, dauer) %>%
>>>          group_by(week = format(datum, '%Y %V'))%>%
>>>          summarise_if(is.numeric, sum)
>>>
>>> and minutes per month
>>>
>>>          CONSMINUTES %>%
>>>          select(datum, dauer) %>%
>>>          group_by(month = format(datum, '%Y %m'))%>%
>>>          summarise_if(is.numeric, sum)
>>>
>>> I need to show the time worked per week per month in the format of
>>>
>>>          '# hours # minutes'
>>>
>>> and would like to also be able to show the average time per week per
>>> month.
>>>
>>> How can I do that (preferably with tidyverse :-)-O)?
>>>
>>> greetings, el
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Thu Mar 25 22:55:41 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 26 Mar 2021 08:55:41 +1100
Subject: [R] Thanks for help
In-Reply-To: <CAF-BbQp-y-dJyrh0a9RvrbtCpekdR4-S6Eowdc5NkBr0RHE-Mw@mail.gmail.com>
References: <CAF-BbQq6jvrE279Jkdj4sgb5F2PaAVFJ=ySBdLwG4FU7ZWxikQ@mail.gmail.com>
 <CA+8X3fX6_C3T5daqaXxFBny_ZszVmFZyEgAXkO5EZJJiZ+4=hQ@mail.gmail.com>
 <v1-ugS779lLAt4I4euz5-9d4641d7034a1ed715ea3b98cae35f4e@gmail.com>
 <CA+8X3fW2=HJqv5apuYJwnUGK_Za2mEjoe-S9vffKvQhawVCnNw@mail.gmail.com>
 <CAF-BbQogQpTPt9axhhW0q9NR75sTqfjyN7tKucPzcZgCwJ7Y-Q@mail.gmail.com>
 <CAF-BbQp-y-dJyrh0a9RvrbtCpekdR4-S6Eowdc5NkBr0RHE-Mw@mail.gmail.com>
Message-ID: <CA+8X3fUupLADUPybVoSBemg5NztteqCzuyN-+fK3vXthi2irGw@mail.gmail.com>

Okay, if I understand this, you want to remove all rows that have, for
example, a 1 in any of ten columns:

a<-matrix(sample(1:20,350,TRUE),ncol=10)
# check it out
a
# first do it with a loop
b<-a
for(i in 1:ncol(b)) b<-b[b[,i]!=1,]
b
# now get tricky and do it in one operation
no1s<-apply(a,1,function(x) any(1 %in% x))
no1s
[1]  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE
FALSE
[25]  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE
c<-a[!no1s,]
c

Jim

On Fri, Mar 26, 2021 at 8:17 AM Goyani Zankrut <zankrut20 at gmail.com> wrote:

> Example purpose I was created 21x2 matrix.
> My actual matrix is 35x10 matrix. So i have to ran same code 10 times for
> each columns.
>
> On Fri, Mar 26, 2021, 2:44 AM Goyani Zankrut <zankrut20 at gmail.com> wrote:
>
>> I understood that.
>> c<-a[a[,1] != 1,] this will work for first column only.
>>
>> If I'm trying same by this
>> c<-a[a[,1] !=2,]
>> c<-a[a[,2] !=2,]
>> Two times
>> So i was tried for loop but I'm stucked.
>>
>> On Fri, Mar 26, 2021, 2:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>>> HI Goyani,
>>> What is happening is that rows and columns are mixed up. You have
>>> specified the sequence as 1:nrow(a)
>>>  and then applied it to the columns a[,i]. The index error occurs
>>> because you have 21 rows but only two columns. That's the bad news. The
>>> good news is that you don't have to use a loop at all:
>>>
>>> c<-a[a[,1] != 1,]
>>>
>>> To see why, look at the expression inside the outer brackets:
>>>
>>> a[,1] != 1
>>>
>>> It produces a logical vector that can be used to index the matrix as you
>>> wish.
>>>
>>> Jim
>>>
>>> On Fri, Mar 26, 2021 at 1:57 AM Goyani Zankrut <zankrut20 at gmail.com>
>>> wrote:
>>>
>>>> Sorry, I'm again disturbing you.
>>>> I have one problem which I'm trying to solve but getting no results.
>>>> Problem statement:
>>>> I created a combination matrix (dimensions 21 * 2). I want to remove
>>>> some entire rows which start with "1". I was tried lapply, apply, and
>>>> for loop for this but I'm still failing. I don't know how to do that.
>>>> I'm sharing the code and image for your reference in this email.
>>>> matrix row remove
>>>>
>>>>                   a<- t(combn(7, 2))
>>>> for(i in 1:nrow(a)) {
>>>>   c<- c(a[a[,i]!=1])
>>>>   print(c)
>>>> }
>>>> # getting this result
>>>> [1] 2 2 2 2 2 3 3 3 3 4 4 4 5 5 6 3 4 5 6 7 4 5 6 7 5 6 7 6 7 7
>>>>  [1] 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 4 4 4 5 5 6 2 3 4 5 6 7 3 4 5 6 7 4 5 6 7 5 6 7
>>>> [40] 6 7 7
>>>> Error in a[, i] : subscript out of bounds
>>>>
>>>>                 [image: Mixmax]
>>>> <https://www.mixmax.com/?ref=Code%20snippet&userId=605ca35fdea6c2667fcbd315> Not
>>>> using Mixmax yet?
>>>> <https://www.mixmax.com/?ref=Code%20snippet&userId=605ca35fdea6c2667fcbd315>
>>>> I want the remaining matrix after removing those rows which starts with
>>>> 1.
>>>> *"Healthy soil, Healthy life."*
>>>> *"A war based on Satyagraha is always of two kinds. One is the war we
>>>> wage against injustice, and the other we fight our won weaknesses."* - *Sardar
>>>> Patel*
>>>> *"You have to dream before your dreams can come true."* - *A. P. J.* *Abdul
>>>> Kalam*
>>>> *"Think before you print and save a tree."*
>>>>
>>>> *ZANKRUT GOYANI*
>>>> *B.Sc. (Hons.) Agriculture*
>>>>
>>>>
>>>>
>>>> On Tue, Mar 23, 2021 2:48 AM, Jim Lemon drjimlemon at gmail.com wrote:
>>>>
>>>>> Hi Goyani,
>>>>>
>>>>> I learned something, too, as you may have noticed.
>>>>>
>>>>>
>>>>> Dr Jim Lemon
>>>>>
>>>>> Gladesville, NSW
>>>>>
>>>>> AUSTRALIA
>>>>>
>>>>>
>>>>> I no longer have a university affiliation.
>>>>>
>>>>>
>>>>> Jim
>>>>>
>>>>>
>>>>> On Tue, Mar 23, 2021 at 3:43 AM Goyani Zankrut <zankrut20 at gmail.com>
>>>>> wrote:
>>>>>
>>>>> >
>>>>>
>>>>> > Greetings of the day,
>>>>>
>>>>> > Sir, can you share your details so I can write them in my thesis
>>>>> work. I want to write everyone's name and their designation & institute
>>>>> name. If you are not belonging to any institute, I mentioned your origin
>>>>> (City, state, Country).
>>>>>
>>>>> > I hope you will send these details.
>>>>>
>>>>> > Again thanks for the help.
>>>>>
>>>>> > "Healthy soil, Healthy life."
>>>>>
>>>>> > "A war based on Satyagraha is always of two kinds. One is the war we
>>>>> wage against injustice, and the other we fight our won weaknesses." -
>>>>> Sardar Patel
>>>>>
>>>>> > "You have to dream before your dreams can come true." - A. P. J.
>>>>> Abdul Kalam
>>>>>
>>>>> > "Think before you print and save a tree."
>>>>>
>>>>> >
>>>>>
>>>>> > ZANKRUT GOYANI
>>>>>
>>>>> > B.Sc. (Hons.) Agriculture
>>>>>
>>>>>
>>>>>
>>>>
>>>> *"Healthy soil, Healthy life."*
>>>> *"A war based on Satyagraha is always of two kinds. One is the war we
>>>> wage against injustice, and the other we fight our won weaknesses."* - *Sardar
>>>> Patel*
>>>> *"You have to dream before your dreams can come true."* - *A. P. J.* *Abdul
>>>> Kalam*
>>>> *"Think before you print and save a tree."*
>>>>
>>>> *ZANKRUT GOYANI*
>>>> *B.Sc. (Hons.) Agriculture*
>>>>
>>>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Mar 26 01:22:12 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 25 Mar 2021 17:22:12 -0700
Subject: [R] Thanks for help
In-Reply-To: <CA+8X3fUupLADUPybVoSBemg5NztteqCzuyN-+fK3vXthi2irGw@mail.gmail.com>
References: <CAF-BbQq6jvrE279Jkdj4sgb5F2PaAVFJ=ySBdLwG4FU7ZWxikQ@mail.gmail.com>
 <CA+8X3fX6_C3T5daqaXxFBny_ZszVmFZyEgAXkO5EZJJiZ+4=hQ@mail.gmail.com>
 <v1-ugS779lLAt4I4euz5-9d4641d7034a1ed715ea3b98cae35f4e@gmail.com>
 <CA+8X3fW2=HJqv5apuYJwnUGK_Za2mEjoe-S9vffKvQhawVCnNw@mail.gmail.com>
 <CAF-BbQogQpTPt9axhhW0q9NR75sTqfjyN7tKucPzcZgCwJ7Y-Q@mail.gmail.com>
 <CAF-BbQp-y-dJyrh0a9RvrbtCpekdR4-S6Eowdc5NkBr0RHE-Mw@mail.gmail.com>
 <CA+8X3fUupLADUPybVoSBemg5NztteqCzuyN-+fK3vXthi2irGw@mail.gmail.com>
Message-ID: <CAGxFJbSYgTfh+F4wT5z4L=QsDXjoK1xnLX6KAMvVPeOYTv3VGQ@mail.gmail.com>

apply() is also a (disguised) loop, though.

I think you will find that indexing via rowSums is a lot faster:

## The example
set.seed(111) ## for reproducibility
a<-matrix(sample(1:20,350,TRUE),ncol=10) ## 35 rows

## A one-liner
a[rowSums(a != 1) == 10, ]  ## 20 rows


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 25, 2021 at 2:56 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Okay, if I understand this, you want to remove all rows that have, for
> example, a 1 in any of ten columns:
>
> a<-matrix(sample(1:20,350,TRUE),ncol=10)
> # check it out
> a
> # first do it with a loop
> b<-a
> for(i in 1:ncol(b)) b<-b[b[,i]!=1,]
> b
> # now get tricky and do it in one operation
> no1s<-apply(a,1,function(x) any(1 %in% x))
> no1s
> [1]  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE
> FALSE
> [25]  TRUE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE FALSE FALSE
> c<-a[!no1s,]
> c
>
> Jim
>
> On Fri, Mar 26, 2021 at 8:17 AM Goyani Zankrut <zankrut20 at gmail.com>
> wrote:
>
> > Example purpose I was created 21x2 matrix.
> > My actual matrix is 35x10 matrix. So i have to ran same code 10 times for
> > each columns.
> >
> > On Fri, Mar 26, 2021, 2:44 AM Goyani Zankrut <zankrut20 at gmail.com>
> wrote:
> >
> >> I understood that.
> >> c<-a[a[,1] != 1,] this will work for first column only.
> >>
> >> If I'm trying same by this
> >> c<-a[a[,1] !=2,]
> >> c<-a[a[,2] !=2,]
> >> Two times
> >> So i was tried for loop but I'm stucked.
> >>
> >> On Fri, Mar 26, 2021, 2:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >>> HI Goyani,
> >>> What is happening is that rows and columns are mixed up. You have
> >>> specified the sequence as 1:nrow(a)
> >>>  and then applied it to the columns a[,i]. The index error occurs
> >>> because you have 21 rows but only two columns. That's the bad news. The
> >>> good news is that you don't have to use a loop at all:
> >>>
> >>> c<-a[a[,1] != 1,]
> >>>
> >>> To see why, look at the expression inside the outer brackets:
> >>>
> >>> a[,1] != 1
> >>>
> >>> It produces a logical vector that can be used to index the matrix as
> you
> >>> wish.
> >>>
> >>> Jim
> >>>
> >>> On Fri, Mar 26, 2021 at 1:57 AM Goyani Zankrut <zankrut20 at gmail.com>
> >>> wrote:
> >>>
> >>>> Sorry, I'm again disturbing you.
> >>>> I have one problem which I'm trying to solve but getting no results.
> >>>> Problem statement:
> >>>> I created a combination matrix (dimensions 21 * 2). I want to remove
> >>>> some entire rows which start with "1". I was tried lapply, apply, and
> >>>> for loop for this but I'm still failing. I don't know how to do that.
> >>>> I'm sharing the code and image for your reference in this email.
> >>>> matrix row remove
> >>>>
> >>>>                   a<- t(combn(7, 2))
> >>>> for(i in 1:nrow(a)) {
> >>>>   c<- c(a[a[,i]!=1])
> >>>>   print(c)
> >>>> }
> >>>> # getting this result
> >>>> [1] 2 2 2 2 2 3 3 3 3 4 4 4 5 5 6 3 4 5 6 7 4 5 6 7 5 6 7 6 7 7
> >>>>  [1] 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 4 4 4 5 5 6 2 3 4 5 6 7 3 4 5 6 7
> 4 5 6 7 5 6 7
> >>>> [40] 6 7 7
> >>>> Error in a[, i] : subscript out of bounds
> >>>>
> >>>>                 [image: Mixmax]
> >>>> <
> https://www.mixmax.com/?ref=Code%20snippet&userId=605ca35fdea6c2667fcbd315>
> Not
> >>>> using Mixmax yet?
> >>>> <
> https://www.mixmax.com/?ref=Code%20snippet&userId=605ca35fdea6c2667fcbd315
> >
> >>>> I want the remaining matrix after removing those rows which starts
> with
> >>>> 1.
> >>>> *"Healthy soil, Healthy life."*
> >>>> *"A war based on Satyagraha is always of two kinds. One is the war we
> >>>> wage against injustice, and the other we fight our won weaknesses."*
> - *Sardar
> >>>> Patel*
> >>>> *"You have to dream before your dreams can come true."* - *A. P. J.*
> *Abdul
> >>>> Kalam*
> >>>> *"Think before you print and save a tree."*
> >>>>
> >>>> *ZANKRUT GOYANI*
> >>>> *B.Sc. (Hons.) Agriculture*
> >>>>
> >>>>
> >>>>
> >>>> On Tue, Mar 23, 2021 2:48 AM, Jim Lemon drjimlemon at gmail.com wrote:
> >>>>
> >>>>> Hi Goyani,
> >>>>>
> >>>>> I learned something, too, as you may have noticed.
> >>>>>
> >>>>>
> >>>>> Dr Jim Lemon
> >>>>>
> >>>>> Gladesville, NSW
> >>>>>
> >>>>> AUSTRALIA
> >>>>>
> >>>>>
> >>>>> I no longer have a university affiliation.
> >>>>>
> >>>>>
> >>>>> Jim
> >>>>>
> >>>>>
> >>>>> On Tue, Mar 23, 2021 at 3:43 AM Goyani Zankrut <zankrut20 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>> >
> >>>>>
> >>>>> > Greetings of the day,
> >>>>>
> >>>>> > Sir, can you share your details so I can write them in my thesis
> >>>>> work. I want to write everyone's name and their designation &
> institute
> >>>>> name. If you are not belonging to any institute, I mentioned your
> origin
> >>>>> (City, state, Country).
> >>>>>
> >>>>> > I hope you will send these details.
> >>>>>
> >>>>> > Again thanks for the help.
> >>>>>
> >>>>> > "Healthy soil, Healthy life."
> >>>>>
> >>>>> > "A war based on Satyagraha is always of two kinds. One is the war
> we
> >>>>> wage against injustice, and the other we fight our won weaknesses." -
> >>>>> Sardar Patel
> >>>>>
> >>>>> > "You have to dream before your dreams can come true." - A. P. J.
> >>>>> Abdul Kalam
> >>>>>
> >>>>> > "Think before you print and save a tree."
> >>>>>
> >>>>> >
> >>>>>
> >>>>> > ZANKRUT GOYANI
> >>>>>
> >>>>> > B.Sc. (Hons.) Agriculture
> >>>>>
> >>>>>
> >>>>>
> >>>>
> >>>> *"Healthy soil, Healthy life."*
> >>>> *"A war based on Satyagraha is always of two kinds. One is the war we
> >>>> wage against injustice, and the other we fight our won weaknesses."*
> - *Sardar
> >>>> Patel*
> >>>> *"You have to dream before your dreams can come true."* - *A. P. J.*
> *Abdul
> >>>> Kalam*
> >>>> *"Think before you print and save a tree."*
> >>>>
> >>>> *ZANKRUT GOYANI*
> >>>> *B.Sc. (Hons.) Agriculture*
> >>>>
> >>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar 26 01:41:00 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 26 Mar 2021 13:41:00 +1300
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
In-Reply-To: <20210325143248.4982d3cd@rolf-Latitude-E7470>
References: <20210325143248.4982d3cd@rolf-Latitude-E7470>
Message-ID: <CAB8pepyjZKR44oav+chR6TJCzUBV4aGuAMzwQeCL1S3Fs_dqBA@mail.gmail.com>

I haven't checked this, but I guess that the number of students that
*pass* a particular exam/subject, per semester would be like that.

e.g.
Let's say you have a course in maximum likelihood, that's taught once
per year to 3rd year students, and a few postgrads.
You could count the number of passes, each year.

If you assume a near-constant probability of passing in each exam/semester:
Then I would assume it would follow the distribution that you're requesting.

If there is a significant change in the number of students:
Lets say, that less and less students study maximum likelihood because
they would rather study "advanced" R programming for "data science"
with "large data", then you might be able to apply some sort of
discrete-scaling transformation to the number of passes each semester.
This would allow you to pretend that the number of people studying
maximum likelihood is the same, and no one is studying other
apparently more important subjects.


On Thu, Mar 25, 2021 at 2:33 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> I would like a real-life example of a data set which one might think to
> model by a binomial distribution, but which is substantially
> underdispersed. I.e. a sample X = {X_1, X_2, ..., X_N} where each X_i
> is an integer between 0 and n (n known a priori) such that var(X) <<
> mean(X)*(1 - mean(X)/n).
>
> Does anyone know of any such examples?  Do any exist?  I've done
> a perfunctory web search, and had a look at "A Handbook of Small
> Data Sets" by Hand, Daly, Lunn, et al., and drawn a blank.
>
> I've seen on the web some references to underdispersed "pseudo-Poisson"
> data, but not to underdispersed "pseudo-binomial" data.  And of course
> there's lots of *over* dispersed stuff.  But that's not what I want.
>
> I can *simulate* data sets of the sor that I am looking for (so far the
> only ideas I've had for doing this are pretty simplistic and
> artificial) but I'd like to get my hands on a *real* example, if
> possible.
>
> Grateful for any pointers/suggestions.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Mar 26 03:25:18 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 26 Mar 2021 15:25:18 +1300
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
In-Reply-To: <CAB8pepyjZKR44oav+chR6TJCzUBV4aGuAMzwQeCL1S3Fs_dqBA@mail.gmail.com>
References: <20210325143248.4982d3cd@rolf-Latitude-E7470>
 <CAB8pepyjZKR44oav+chR6TJCzUBV4aGuAMzwQeCL1S3Fs_dqBA@mail.gmail.com>
Message-ID: <20210326152518.34fedcda@rolf-Latitude-E7470>


On Fri, 26 Mar 2021 13:41:00 +1300
Abby Spurdle <spurdle.a at gmail.com> wrote:

> I haven't checked this, but I guess that the number of students that
> *pass* a particular exam/subject, per semester would be like that.
> 
> e.g.
> Let's say you have a course in maximum likelihood, that's taught once
> per year to 3rd year students, and a few postgrads.
> You could count the number of passes, each year.
> 
> If you assume a near-constant probability of passing in each
> exam/semester: Then I would assume it would follow the distribution
> that you're requesting.

<SNIP>

Thanks Abby.  I've experimented (simulated) a wee bit and found
that if I keep the numbers of students (undergrad and grad) exactly
constant, then the results are underdispersed.  However if the
numbers are allowed to vary then the results are overdispersed.

It seems that the universe is very reluctant to produce underdispersed
pseudo-binomial data!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From no@p@m @end|ng |rom ||@@e@NA  Fri Mar 26 08:22:11 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Fri, 26 Mar 2021 09:22:11 +0200
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <0D75B81F-2D2A-4A77-9523-B5AB23900643@dcn.davis.ca.us>
References: <s37lbh$svd$1@ciao.gmane.io>
 <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>
 <s3il39$47o$1@ciao.gmane.io>
 <0D75B81F-2D2A-4A77-9523-B5AB23900643@dcn.davis.ca.us>
Message-ID: <s3k235$ack$1@ciao.gmane.io>

Jeff,

thank you. However, if I knew how to do this, I would probably not
have asked :-)-O

I think I have been reasonably comprehensive in describing my issue, but
let me do it now with the real life problem:

My malpractice insurance gives me a discount if I consult up to 22
hours per week in a 3 months period.

I add every patient, date and minutes whenever I see her into a MySQL
database.  I want to file the report of my hours worked with them for
the first 3 month period (November to January and not properly quarterly
unfortunately :-)-0), and while I can generate this with LyX/LateX and
knitR producing a (super)tabular table containing the full list, and
tables for time per week and time per month I really can't figure out is
how to average the hours worked per week for each month (even if weeks
don't align with months properly :-)-O)

While I am at it how would I get this to sort properly (year, month) if
I used the proper names of the months, ie '%Y %B' or '%B %Y'?

   CONSMINUTES %>%
     select(datum, dauer)  %>%
     group_by(month = format(datum, '%Y %m'),
       week = format(datum, '%V'))  %>%
     summarise_if(is.numeric, sum) %>%
     mutate(hm=sprintf("%d Hour%s %d Minutes", dauer %/% 60,
       ifelse((dauer %/% 60) == 1, " ", "s"), dauer %% 60)) %>%	
     select(-dauer)


Any help, or just pointers to where I can read this up, are highly
appreciated.

greetings, el


On 2021-03-25 22:37 , Jeff Newmiller wrote:
 > This is a very unclear question.  Weeks don't line up with months..
 > so you need to clarify how you would do this or at least give an
 > explicit example of input data and result data.
 >
 > On March 25, 2021 11:34:15 AM PDT, Dr Eberhard W Lisse 
<nospam at lisse.NA> wrote:
 >> Thanks, that is helpful.
 >>
 >> But, how do I group it to produce hours worked per week per month?
 >>
 >> el
 >>
 >>
 >> On 2021-03-25 19:03 , Greg Snow wrote:
 >>> Here is one approach:
 >>>
 >>> tmp <- data.frame(min=seq(0,150, by=15))
 >>>
 >>> tmp %>%
 >>>     mutate(hm=sprintf("%2d Hour%s %2d Minutes",
 >>>               min %/% 60, ifelse((min %/% 60) == 1, " ", "s"),
 >>>               min %% 60))
 >>>
 >>> You could replace `sprintf` with `str_glue` (and update the syntax
 >>> as well) if you realy need tidyverse, but you would also loose some
 >>> formatting capability.
 >>>
 >>> I don't know of tidyverse versions of `%/%` or `%%`.  If you need
 >>> the numeric values instead of a string then just remove the
 >>> `sprintf` and use mutate directly with `min %/% 60` and `min %% 60`.
 >>>
 >>> This of course assumes all of your data is in minutes (by the time
 >>> you pipe to this code) and that all hours have 60 minutes (I don't
 >>> know of any leap hours.
 >>>
 >>> On Sun, Mar 21, 2021 at 8:31 AM Dr Eberhard W Lisse <nospam at lisse.na>
 >> wrote:
 >>>>
 >>>> Hi,
 >>>>
 >>>> I have minutes worked by day (with some more information)
 >>>>
 >>>> which when using
 >>>>
 >>>>           library(tidyverse)
 >>>>           library(lubridate)
 >>>>
 >>>> run through
 >>>>
 >>>>           CONSMINUTES %>%
 >>>>                   select(datum, dauer) %>%
 >>>>                   arrange(desc(datum))
 >>>>
 >>>> look somewhat like
 >>>>
 >>>>           # A tibble: 142 x 2
 >>>>              datum      dauer
 >>>>              <date>     <int>
 >>>>            1 2021-03-18    30
 >>>>            2 2021-03-17    30
 >>>>            3 2021-03-16    30
 >>>>            4 2021-03-16    30
 >>>>            5 2021-03-16    30
 >>>>            6 2021-03-16    30
 >>>>            7 2021-03-11    30
 >>>>            8 2021-03-11    30
 >>>>            9 2021-03-11    30
 >>>>           10 2021-03-11    30
 >>>>           # ? with 132 more rows
 >>>>
 >>>> I can extract minutes per hour
 >>>>
 >>>>           CONSMINUTES %>%
 >>>>           select(datum, dauer) %>%
 >>>>           group_by(week = format(datum, '%Y %V'))%>%
 >>>>           summarise_if(is.numeric, sum)
 >>>>
 >>>> and minutes per month
 >>>>
 >>>>           CONSMINUTES %>%
 >>>>           select(datum, dauer) %>%
 >>>>           group_by(month = format(datum, '%Y %m'))%>%
 >>>>           summarise_if(is.numeric, sum)
 >>>>
 >>>> I need to show the time worked per week per month in the format of
 >>>>
 >>>>           '# hours # minutes'
 >>>>
 >>>> and would like to also be able to show the average time per week
 >>>> per month.
 >>>>
 >>>> How can I do that (preferably with tidyverse :-)-O)?
 >>>>
 >>>> greetings, el


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Mar 26 10:43:29 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 26 Mar 2021 05:43:29 -0400
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
In-Reply-To: <20210326152518.34fedcda@rolf-Latitude-E7470>
References: <20210325143248.4982d3cd@rolf-Latitude-E7470>
 <CAB8pepyjZKR44oav+chR6TJCzUBV4aGuAMzwQeCL1S3Fs_dqBA@mail.gmail.com>
 <20210326152518.34fedcda@rolf-Latitude-E7470>
Message-ID: <15f363fe-3612-198a-aa62-ba10bd80cd06@gmail.com>

On 25/03/2021 10:25 p.m., Rolf Turner wrote:
> 
> On Fri, 26 Mar 2021 13:41:00 +1300
> Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
>> I haven't checked this, but I guess that the number of students that
>> *pass* a particular exam/subject, per semester would be like that.
>>
>> e.g.
>> Let's say you have a course in maximum likelihood, that's taught once
>> per year to 3rd year students, and a few postgrads.
>> You could count the number of passes, each year.
>>
>> If you assume a near-constant probability of passing in each
>> exam/semester: Then I would assume it would follow the distribution
>> that you're requesting.
> 
> <SNIP>
> 
> Thanks Abby.  I've experimented (simulated) a wee bit and found
> that if I keep the numbers of students (undergrad and grad) exactly
> constant, then the results are underdispersed.  However if the
> numbers are allowed to vary then the results are overdispersed.
> 
> It seems that the universe is very reluctant to produce underdispersed
> pseudo-binomial data!

I'd expect underdispersion to happen in competitive situations:  if 
subject A succeeds, that makes it less likely that other subjects will 
also succeed.

An extreme case is a contest winner.  With some contests there will 
always be one winner (a little too-underdispersed for you, probably), 
but others allow a small amount of variation.

For example, sports events that allow ties.  This page 
https://en.wikipedia.org/wiki/List_of_ties_for_medals_at_the_Olympics 
seems to indicate that speed skating had a lot of ties up until 1980.

Duncan Murdoch


From drj|m|emon @end|ng |rom gm@||@com  Fri Mar 26 12:10:15 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 26 Mar 2021 22:10:15 +1100
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <s3k235$ack$1@ciao.gmane.io>
References: <s37lbh$svd$1@ciao.gmane.io>
 <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>
 <s3il39$47o$1@ciao.gmane.io>
 <0D75B81F-2D2A-4A77-9523-B5AB23900643@dcn.davis.ca.us>
 <s3k235$ack$1@ciao.gmane.io>
Message-ID: <CA+8X3fVbZ5RzfiJRBOYdh4=Hf06VjVOT09=UvLRRp2dyoPx3Ow@mail.gmail.com>

Hi,
As you still seem to be asking for an answer, the following code may help.

# begin with a minimal data frame
patdb<-data.frame(patno=paste0("p",sample(100:300,200,TRUE)),
 date=c(paste(2020,11,sort(sample(1:31,66,TRUE)),sep="-"),
 paste(2020,12,sort(sample(1:31,67,TRUE)),sep="-"),
 paste(2021,01,sort(sample(1:31,67,TRUE)),sep="-")),
 consdur=sample(15:40,200,TRUE))
patdb$date<-as.Date(patdb$date,"%Y-%m-%d")
patdb$year<-format(patdb$date,"%Y")
patdb$month<-as.numeric(format(patdb$date,"%m"))
patdb$weekday<-as.numeric(format(patdb$date,"%u"))
patdb$week<-as.numeric(format(patdb$date,"%W"))
# first do the easy one
minperday<-by(patdb$consdur,patdb$date,sum)
hrperday<-minperday%/%60
minperday<-minperday%%60
# now the hard one - first get the number of days per week
daysperweek<-by(patdb$consdur,patdb$week,length)
# correct for weeks less than seven days
minperweek<-by(patdb$consdur,patdb$week,sum)*7/daysperweek
hrperweek<-minperweek%/%60
minperweek<-minperweek%%60
minpermonth<-by(patdb$consdur,patdb$month,sum)
hrpermonth<-minpermonth%/%60
minpermonth<-minpermonth%%60
daystr<-paste(names(minperday),"#",hrperday,"#",minperday)
weekstr<-paste(names(minperweek),"#",hrperweek,"#",minperweek)
monthstr<-
 paste(month.name[as.numeric(names(minpermonth))],"#",
 hrpermonth,"#",minpermonth)

Further enhancements to the three vectors of output strings are
possible as are various summary measures.

Jim

On Fri, Mar 26, 2021 at 6:22 PM Dr Eberhard W Lisse <nospam at lisse.na> wrote:
>
> Jeff,
>
> thank you. However, if I knew how to do this, I would probably not
> have asked :-)-O
>
> I think I have been reasonably comprehensive in describing my issue, but
> let me do it now with the real life problem:
>
> My malpractice insurance gives me a discount if I consult up to 22
> hours per week in a 3 months period.
>
> I add every patient, date and minutes whenever I see her into a MySQL
> database.  I want to file the report of my hours worked with them for
> the first 3 month period (November to January and not properly quarterly
> unfortunately :-)-0), and while I can generate this with LyX/LateX and
> knitR producing a (super)tabular table containing the full list, and
> tables for time per week and time per month I really can't figure out is
> how to average the hours worked per week for each month (even if weeks
> don't align with months properly :-)-O)
>
> While I am at it how would I get this to sort properly (year, month) if
> I used the proper names of the months, ie '%Y %B' or '%B %Y'?
>
>    CONSMINUTES %>%
>      select(datum, dauer)  %>%
>      group_by(month = format(datum, '%Y %m'),
>        week = format(datum, '%V'))  %>%
>      summarise_if(is.numeric, sum) %>%
>      mutate(hm=sprintf("%d Hour%s %d Minutes", dauer %/% 60,
>        ifelse((dauer %/% 60) == 1, " ", "s"), dauer %% 60)) %>%
>      select(-dauer)
>
>
> Any help, or just pointers to where I can read this up, are highly
> appreciated.
>
> greetings, el
>
>
> On 2021-03-25 22:37 , Jeff Newmiller wrote:
>  > This is a very unclear question.  Weeks don't line up with months..
>  > so you need to clarify how you would do this or at least give an
>  > explicit example of input data and result data.
>  >
>  > On March 25, 2021 11:34:15 AM PDT, Dr Eberhard W Lisse
> <nospam at lisse.NA> wrote:
>  >> Thanks, that is helpful.
>  >>
>  >> But, how do I group it to produce hours worked per week per month?
>  >>
>  >> el
>  >>
>  >>
>  >> On 2021-03-25 19:03 , Greg Snow wrote:
>  >>> Here is one approach:
>  >>>
>  >>> tmp <- data.frame(min=seq(0,150, by=15))
>  >>>
>  >>> tmp %>%
>  >>>     mutate(hm=sprintf("%2d Hour%s %2d Minutes",
>  >>>               min %/% 60, ifelse((min %/% 60) == 1, " ", "s"),
>  >>>               min %% 60))
>  >>>
>  >>> You could replace `sprintf` with `str_glue` (and update the syntax
>  >>> as well) if you realy need tidyverse, but you would also loose some
>  >>> formatting capability.
>  >>>
>  >>> I don't know of tidyverse versions of `%/%` or `%%`.  If you need
>  >>> the numeric values instead of a string then just remove the
>  >>> `sprintf` and use mutate directly with `min %/% 60` and `min %% 60`.
>  >>>
>  >>> This of course assumes all of your data is in minutes (by the time
>  >>> you pipe to this code) and that all hours have 60 minutes (I don't
>  >>> know of any leap hours.
>  >>>
>  >>> On Sun, Mar 21, 2021 at 8:31 AM Dr Eberhard W Lisse <nospam at lisse.na>
>  >> wrote:
>  >>>>
>  >>>> Hi,
>  >>>>
>  >>>> I have minutes worked by day (with some more information)
>  >>>>
>  >>>> which when using
>  >>>>
>  >>>>           library(tidyverse)
>  >>>>           library(lubridate)
>  >>>>
>  >>>> run through
>  >>>>
>  >>>>           CONSMINUTES %>%
>  >>>>                   select(datum, dauer) %>%
>  >>>>                   arrange(desc(datum))
>  >>>>
>  >>>> look somewhat like
>  >>>>
>  >>>>           # A tibble: 142 x 2
>  >>>>              datum      dauer
>  >>>>              <date>     <int>
>  >>>>            1 2021-03-18    30
>  >>>>            2 2021-03-17    30
>  >>>>            3 2021-03-16    30
>  >>>>            4 2021-03-16    30
>  >>>>            5 2021-03-16    30
>  >>>>            6 2021-03-16    30
>  >>>>            7 2021-03-11    30
>  >>>>            8 2021-03-11    30
>  >>>>            9 2021-03-11    30
>  >>>>           10 2021-03-11    30
>  >>>>           # ? with 132 more rows
>  >>>>
>  >>>> I can extract minutes per hour
>  >>>>
>  >>>>           CONSMINUTES %>%
>  >>>>           select(datum, dauer) %>%
>  >>>>           group_by(week = format(datum, '%Y %V'))%>%
>  >>>>           summarise_if(is.numeric, sum)
>  >>>>
>  >>>> and minutes per month
>  >>>>
>  >>>>           CONSMINUTES %>%
>  >>>>           select(datum, dauer) %>%
>  >>>>           group_by(month = format(datum, '%Y %m'))%>%
>  >>>>           summarise_if(is.numeric, sum)
>  >>>>
>  >>>> I need to show the time worked per week per month in the format of
>  >>>>
>  >>>>           '# hours # minutes'
>  >>>>
>  >>>> and would like to also be able to show the average time per week
>  >>>> per month.
>  >>>>
>  >>>> How can I do that (preferably with tidyverse :-)-O)?
>  >>>>
>  >>>> greetings, el
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pjm|||er_57 @end|ng |rom y@hoo@com  Fri Mar 26 14:47:45 2021
From: pjm|||er_57 @end|ng |rom y@hoo@com (Paul Miller)
Date: Fri, 26 Mar 2021 13:47:45 +0000 (UTC)
Subject: [R] dplyr: summarise across using variable names and a condition
In-Reply-To: <mailman.362665.1.1616756401.56197.r-help@r-project.org>
References: <mailman.362665.1.1616756401.56197.r-help@r-project.org>
Message-ID: <125782978.721097.1616766465468@mail.yahoo.com>

Hello All,

Would like to be able to summarize across in dplyr using variable names and a condition. Below is an example "have" data set followed by an example "need" data set. After that, I've got a vector of numeric variable names. After that, I've got the very humble beginnings of a dplyr-based solution.

What I think I need to be able to do is to submit my variable names to dplyr and then to have a conditional function. If the variable is is in my list of names, calculate the mean and the std. If not, then calculate the mean but label it as a proportion. The question is how to do that. It appears that using variable names might involve !!, or possibly enquo, or possibly quo, but I haven't had much success with these. I imagine I might have been very close but not quite have gotten it. The conditional part seems less difficult but I'm not quite sure how to do that either.

Help with this would be greatly appreciated.

Thanks,

Paul


have <- structure(list(
??????? ptno = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M",
???????????????? "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z"),
??????? age1 = c(74, 70, 78, 79, 72, 81, 76, 58, 53, 74, 72, 74, 75,
???????????????? 73, 80, 62, 67, 65, 83, 67, 72, 90, 73, 84, 90, 51),
??????? age2 = c(71, 67, 72, 74, 65, 79, 70, 49, 45, 68, 70, 71, 74,
???????????????? 71, 69, 58, 65, 59, 80, 60, 68, 87, 71, 82, 80, 49),
??????? gender_male = c(1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L,
??????????????????????? 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L),
??????? gender_female = c(0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L,
????????????????????????? 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L),
??????? race_white = c(0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
?????????????????????? 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L),
??????? race_black = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
?????????????????????? 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
??????? race_other = c(1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L,
?????????????????????? 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)),
??????? row.names = c(NA, -26L), class = c("tbl_df", "tbl", "data.frame"))
?

need <-structure(list(
?????? age1_mean = 72.8076923076923, age1_std = 9.72838827666425,
?????? age2_mean = 68.2307692307692, age2_std = 10.2227498934785,
?????? gender_male_prop = 0.576923076923077, gender_female_prop = 0.423076923076923,
?????? race_white_prop = 0.769230769230769, race_black_prop = 0.0384615384615385,
?????? race_other_prop = 0.192307692307692),
?????? row.names = c(NA, -1L), class = c("tbl_df", "tbl", "data.frame"))

vars_num <-? c("age1", "age2")

library(magrittr)
library(dplyr)

have %>%
? summarise(across(
? .cols = !contains("ptno"),
? .fns = list(mean = mean, std = sd),
? .names = "{col}_{fn}"
))


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Fri Mar 26 16:35:37 2021
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Fri, 26 Mar 2021 15:35:37 +0000
Subject: [R] local maxima positions in a vector with duplicated values
Message-ID: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>

Dear list users,
I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
- duplicated local maxima, I should take the position of the first duplicated value;
- duplicated local minima, I should take the position of the last duplicated value.

Example:

>x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
>which(diff(diff(x)>=0)<0)+1

gives me 8 11 15 while I need 8 10 13;

>which(diff(diff(x)>0)>0)+1

gives me 4 6  9 12 16 while I need 4 9 12 16.

Could you please help me in this task? I would be happier not to use additional packages.

Thank you for your precious help
Stefano


         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
This message was scanned by Libraesva ESG and is believed to be clean.


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Mar 26 18:08:50 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 26 Mar 2021 17:08:50 +0000
Subject: [R] 
 dplyr: summarise across using variable names and a condition
In-Reply-To: <125782978.721097.1616766465468@mail.yahoo.com>
References: <mailman.362665.1.1616756401.56197.r-help@r-project.org>
 <125782978.721097.1616766465468@mail.yahoo.com>
Message-ID: <ad3bdd2d-137a-d2fb-d56a-3ca5c41887d9@sapo.pt>

Hello,

Here is a way of doing what the question asks for. There might be 
others, simpler, but this one works.

have %>%
   summarise(across(
     .cols = !contains("ptno"),
     .fns = list(mean = mean, std = sd),
     .names = "{col}_{fn}"
   )) %>%
   select(
     -matches("^gender_.*_std$"),
     -matches("^race_.*_std$")
   ) %>%
   rename_with(
     .cols = matches("^gender|^race"),
     ~sub("mean$", "prop", .x)
   ) %>%
   all.equal(need)
#[1] TRUE


Hope this helps,

Rui Barradas

?s 13:47 de 26/03/21, Paul Miller via R-help escreveu:
> Hello All,
> 
> Would like to be able to summarize across in dplyr using variable names and a condition. Below is an example "have" data set followed by an example "need" data set. After that, I've got a vector of numeric variable names. After that, I've got the very humble beginnings of a dplyr-based solution.
> 
> What I think I need to be able to do is to submit my variable names to dplyr and then to have a conditional function. If the variable is is in my list of names, calculate the mean and the std. If not, then calculate the mean but label it as a proportion. The question is how to do that. It appears that using variable names might involve !!, or possibly enquo, or possibly quo, but I haven't had much success with these. I imagine I might have been very close but not quite have gotten it. The conditional part seems less difficult but I'm not quite sure how to do that either.
> 
> Help with this would be greatly appreciated.
> 
> Thanks,
> 
> Paul
> 
> 
> have <- structure(list(
>  ??????? ptno = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M",
>  ???????????????? "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z"),
>  ??????? age1 = c(74, 70, 78, 79, 72, 81, 76, 58, 53, 74, 72, 74, 75,
>  ???????????????? 73, 80, 62, 67, 65, 83, 67, 72, 90, 73, 84, 90, 51),
>  ??????? age2 = c(71, 67, 72, 74, 65, 79, 70, 49, 45, 68, 70, 71, 74,
>  ???????????????? 71, 69, 58, 65, 59, 80, 60, 68, 87, 71, 82, 80, 49),
>  ??????? gender_male = c(1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L,
>  ??????????????????????? 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L),
>  ??????? gender_female = c(0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L,
>  ????????????????????????? 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L),
>  ??????? race_white = c(0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
>  ?????????????????????? 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L),
>  ??????? race_black = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>  ?????????????????????? 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
>  ??????? race_other = c(1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L,
>  ?????????????????????? 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)),
>  ??????? row.names = c(NA, -26L), class = c("tbl_df", "tbl", "data.frame"))
>   
> 
> need <-structure(list(
>  ?????? age1_mean = 72.8076923076923, age1_std = 9.72838827666425,
>  ?????? age2_mean = 68.2307692307692, age2_std = 10.2227498934785,
>  ?????? gender_male_prop = 0.576923076923077, gender_female_prop = 0.423076923076923,
>  ?????? race_white_prop = 0.769230769230769, race_black_prop = 0.0384615384615385,
>  ?????? race_other_prop = 0.192307692307692),
>  ?????? row.names = c(NA, -1L), class = c("tbl_df", "tbl", "data.frame"))
> 
> vars_num <-? c("age1", "age2")
> 
> library(magrittr)
> library(dplyr)
> 
> have %>%
>  ? summarise(across(
>  ? .cols = !contains("ptno"),
>  ? .fns = list(mean = mean, std = sd),
>  ? .names = "{col}_{fn}"
> ))
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Mar 26 18:40:56 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 26 Mar 2021 10:40:56 -0700
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
Message-ID: <CAHqSRuSUN-B4wJGiCG83nzU3wM2uvj2rC42osMXehqdcoBqe7A@mail.gmail.com>

Using rle() may make it easier - finding the peak values is easier and
select from cumsum(lengths) to get the positions of the last values
before the peaks, then add 1.  I have not tested the following very
much.

function(x) {
  rx <- rle(x)
  cumsum(rx$lengths)[c(diff(diff(rx$values)>0) == -1,FALSE,FALSE)]+1
}

-Bill

On Fri, Mar 26, 2021 at 8:36 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear list users,
> I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
> - duplicated local maxima, I should take the position of the first duplicated value;
> - duplicated local minima, I should take the position of the last duplicated value.
>
> Example:
>
> >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> >which(diff(diff(x)>=0)<0)+1
>
> gives me 8 11 15 while I need 8 10 13;
>
> >which(diff(diff(x)>0)>0)+1
>
> gives me 4 6  9 12 16 while I need 4 9 12 16.
>
> Could you please help me in this task? I would be happier not to use additional packages.
>
> Thank you for your precious help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Mar 26 18:54:11 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 26 Mar 2021 10:54:11 -0700
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
Message-ID: <CAGxFJbTO7dV8nJw5QC=-AYk+HWS+YeK1QzBWy1V3hAdPR6hsfw@mail.gmail.com>

WARNING: I have not carefully tested the following, so you will need to do
so before using.

Like Bill, I found rle a clearer approach. Here's my (not so elegant,
probably) version:

> x <-c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> z <- rle(x)
> vals <- z$values
> n <- length(vals)
> whmin<-c(vals[-1], -Inf) > vals & c(-Inf, vals[-n]) > vals
> whmax <- c(vals[-1], Inf) < vals & c(Inf, vals[-n]) < vals
> cumsum(z$lengths)[whmin]
[1]  4  9 12 16
> cumsum(z$lengths)[whmax[-1]] +1
[1]  8 10 13

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 26, 2021 at 8:36 AM Stefano Sofia <
stefano.sofia at regione.marche.it> wrote:

> Dear list users,
> I need to find local maxima and local minima positions in a vector where
> there might be duplicates; in the particular in case of
> - duplicated local maxima, I should take the position of the first
> duplicated value;
> - duplicated local minima, I should take the position of the last
> duplicated value.
>
> Example:
>
> >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> >which(diff(diff(x)>=0)<0)+1
>
> gives me 8 11 15 while I need 8 10 13;
>
> >which(diff(diff(x)>0)>0)+1
>
> gives me 4 6  9 12 16 while I need 4 9 12 16.
>
> Could you please help me in this task? I would be happier not to use
> additional packages.
>
> Thank you for your precious help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non
> infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |err|@|eber| @end|ng |rom gmx@@t  Fri Mar 26 18:55:09 2021
From: |err|@|eber| @end|ng |rom gmx@@t (Ferri Leberl)
Date: Fri, 26 Mar 2021 18:55:09 +0100
Subject: [R] Shapes of the districts of Brandenburg
Message-ID: <trinity-5e7e5c63-79fc-4aa3-bafe-7697914f1783-1616781309788@3c-app-gmx-bs54>

Dear??,
I have today done tentative steps in the use of the cartogram packages, trying the examples on page
https://www.rdocumentation.org/packages/cartogram/versions/0.2.2
Can anybody tell me how to adapt the examples to the districts of Brandenburg?
I know the population data relevant to my example. If anybody can tell me how to load the shapes (if available) this might solve my problem.
Thank you in advance!
Yours, Ferri


From bgunter@4567 @end|ng |rom gm@||@com  Fri Mar 26 19:16:47 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 26 Mar 2021 11:16:47 -0700
Subject: [R] Shapes of the districts of Brandenburg
In-Reply-To: <trinity-5e7e5c63-79fc-4aa3-bafe-7697914f1783-1616781309788@3c-app-gmx-bs54>
References: <trinity-5e7e5c63-79fc-4aa3-bafe-7697914f1783-1616781309788@3c-app-gmx-bs54>
Message-ID: <CAGxFJbSvWqXyJ+eBWndKsALJkEiREHT2YEnkXVYsOAss2Q1jLw@mail.gmail.com>

There is a specific help list devoted to geography and mapping related
issues that may be a better place to post this: r-sig-geo

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Mar 26, 2021 at 11:04 AM Ferri Leberl <ferri.leberl at gmx.at> wrote:

> Dear ?,
> I have today done tentative steps in the use of the cartogram packages,
> trying the examples on page
> https://www.rdocumentation.org/packages/cartogram/versions/0.2.2
> Can anybody tell me how to adapt the examples to the districts of
> Brandenburg?
> I know the population data relevant to my example. If anybody can tell me
> how to load the shapes (if available) this might solve my problem.
> Thank you in advance!
> Yours, Ferri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ren|e|m@o @end|ng |rom gm@||@com  Fri Mar 26 12:15:20 2021
From: ren|e|m@o @end|ng |rom gm@||@com (Renfei Mao)
Date: Fri, 26 Mar 2021 15:15:20 +0400
Subject: [R] [R-pkgs] gm: create music & generate scores and audios in R
 Markdown, Jupyter Notebooks
Message-ID: <CAA-7+EwQ+ujHvkypcJmnwu=DcmcRQog1Bj77TnWTEg23-PPvYg@mail.gmail.com>

Dear all,

I am happy to announce that gm 1.0.0 is released on CRAN.

https://CRAN.R-project.org/package=gm
<https://cran.r-project.org/package=gm>

gm provides an elegant and intuitive language, with which you can create
music algorithmically. gm converts your description of music to musical
score and audio file, and embed them in R Markdown documents, R Jupyter
Notebooks, and RStudio.

Examples and complete guide can be found at

https://flujoo.github.io/gm/articles/gm.html

You can submit an issue at

https://github.com/flujoo/gm

Best regards,
Fei

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Mar 26 22:28:21 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 26 Mar 2021 17:28:21 -0400
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <s3k235$ack$1@ciao.gmane.io>
References: <s37lbh$svd$1@ciao.gmane.io>
 <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>
 <s3il39$47o$1@ciao.gmane.io>
 <0D75B81F-2D2A-4A77-9523-B5AB23900643@dcn.davis.ca.us>
 <s3k235$ack$1@ciao.gmane.io>
Message-ID: <026801d72286$f2a4fd20$d7eef760$@verizon.net>

There are rather straightforward ways to manipulate your data step by step to make harder things possible, or you can use creative ways harder for people to understand.

So adding columns to your data that take existing times/dates and record them with names like Q1Y2021 can give you abilities but as noted they will NOT line up with weeks as in 1 to 52.

You can calculate the sum of hours per week, if you had the ability to group by week, and place that in a column that repeats that number for each day recorded for that week. You can then take the same data and group by quarter and take some kind of average of that column but it probably will be WRONG if you did the above as it will take the average of whatever rows it encounters and that may include partial weeks or other anomalies like when you only recorded three days for that week.

So consider other plans. What if you kept track of the number of weeks per month as in 28 days is 4 weeks and 31 days is 4.43 or so weeks. You could simply calculate the sum of hours for that month and divide by the number of weeks by that measure in that month. Would that number satisfy them?

And, again, rather than trying to SORT Month names, consider adding a column with a numerical version. Sure, you can play with factors so the months are recorded in the order you want and some things like ggplot will then honor that order.

If and when you become more expert, much of what you want might be done other ways without making columns for real. But it may make sense to start simple.

Here is an example of a simple change to Months Abbreviations to be made into a factor in order:

	df$mo <- factor(df$mo,levels=month.abb)

Similar ideas involve how you convert hours and minutes to just minutes for averaging by adding calculated columns and you can convert the results back to whatever format you need later.

Just FYI, many database programs might let you do much of this internally. Python using the tools you are using is arguably much more flexible.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Eberhard W Lisse
Sent: Friday, March 26, 2021 3:22 AM
To: r-help at r-project.org
Subject: Re: [R] How to average minutes per hour per month in the form of '# hours #minutes'

Jeff,

thank you. However, if I knew how to do this, I would probably not have asked :-)-O

I think I have been reasonably comprehensive in describing my issue, but let me do it now with the real life problem:

My malpractice insurance gives me a discount if I consult up to 22 hours per week in a 3 months period.

I add every patient, date and minutes whenever I see her into a MySQL database.  I want to file the report of my hours worked with them for the first 3 month period (November to January and not properly quarterly unfortunately :-)-0), and while I can generate this with LyX/LateX and knitR producing a (super)tabular table containing the full list, and tables for time per week and time per month I really can't figure out is how to average the hours worked per week for each month (even if weeks don't align with months properly :-)-O)

While I am at it how would I get this to sort properly (year, month) if I used the proper names of the months, ie '%Y %B' or '%B %Y'?

   CONSMINUTES %>%
     select(datum, dauer)  %>%
     group_by(month = format(datum, '%Y %m'),
       week = format(datum, '%V'))  %>%
     summarise_if(is.numeric, sum) %>%
     mutate(hm=sprintf("%d Hour%s %d Minutes", dauer %/% 60,
       ifelse((dauer %/% 60) == 1, " ", "s"), dauer %% 60)) %>%	
     select(-dauer)


Any help, or just pointers to where I can read this up, are highly appreciated.

greetings, el


On 2021-03-25 22:37 , Jeff Newmiller wrote:
 > This is a very unclear question.  Weeks don't line up with months..
 > so you need to clarify how you would do this or at least give an  > explicit example of input data and result data.
 >
 > On March 25, 2021 11:34:15 AM PDT, Dr Eberhard W Lisse <nospam at lisse.NA> wrote:
 >> Thanks, that is helpful.
 >>
 >> But, how do I group it to produce hours worked per week per month?
 >>
 >> el
 >>
 >>
 >> On 2021-03-25 19:03 , Greg Snow wrote:
 >>> Here is one approach:
 >>>
 >>> tmp <- data.frame(min=seq(0,150, by=15))  >>>  >>> tmp %>%
 >>>     mutate(hm=sprintf("%2d Hour%s %2d Minutes",
 >>>               min %/% 60, ifelse((min %/% 60) == 1, " ", "s"),
 >>>               min %% 60))
 >>>
 >>> You could replace `sprintf` with `str_glue` (and update the syntax  >>> as well) if you realy need tidyverse, but you would also loose some  >>> formatting capability.
 >>>
 >>> I don't know of tidyverse versions of `%/%` or `%%`.  If you need  >>> the numeric values instead of a string then just remove the  >>> `sprintf` and use mutate directly with `min %/% 60` and `min %% 60`.
 >>>
 >>> This of course assumes all of your data is in minutes (by the time  >>> you pipe to this code) and that all hours have 60 minutes (I don't  >>> know of any leap hours.
 >>>
 >>> On Sun, Mar 21, 2021 at 8:31 AM Dr Eberhard W Lisse <nospam at lisse.na>  >> wrote:
 >>>>
 >>>> Hi,
 >>>>
 >>>> I have minutes worked by day (with some more information)  >>>>  >>>> which when using  >>>>
 >>>>           library(tidyverse)
 >>>>           library(lubridate)
 >>>>
 >>>> run through
 >>>>
 >>>>           CONSMINUTES %>%
 >>>>                   select(datum, dauer) %>%
 >>>>                   arrange(desc(datum))
 >>>>
 >>>> look somewhat like
 >>>>
 >>>>           # A tibble: 142 x 2
 >>>>              datum      dauer
 >>>>              <date>     <int>
 >>>>            1 2021-03-18    30
 >>>>            2 2021-03-17    30
 >>>>            3 2021-03-16    30
 >>>>            4 2021-03-16    30
 >>>>            5 2021-03-16    30
 >>>>            6 2021-03-16    30
 >>>>            7 2021-03-11    30
 >>>>            8 2021-03-11    30
 >>>>            9 2021-03-11    30
 >>>>           10 2021-03-11    30
 >>>>           # ? with 132 more rows
 >>>>
 >>>> I can extract minutes per hour
 >>>>
 >>>>           CONSMINUTES %>%
 >>>>           select(datum, dauer) %>%
 >>>>           group_by(week = format(datum, '%Y %V'))%>%
 >>>>           summarise_if(is.numeric, sum)
 >>>>
 >>>> and minutes per month
 >>>>
 >>>>           CONSMINUTES %>%
 >>>>           select(datum, dauer) %>%
 >>>>           group_by(month = format(datum, '%Y %m'))%>%
 >>>>           summarise_if(is.numeric, sum)
 >>>>
 >>>> I need to show the time worked per week per month in the format of  >>>>
 >>>>           '# hours # minutes'
 >>>>
 >>>> and would like to also be able to show the average time per week  >>>> per month.
 >>>>
 >>>> How can I do that (preferably with tidyverse :-)-O)?
 >>>>
 >>>> greetings, el

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Fri Mar 26 23:08:40 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 27 Mar 2021 11:08:40 +1300
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
Message-ID: <CAB8pepxPG3H1oT7Fu_F1Coc2PEs0NhRxw3-CTX2ty=iueQRwJQ@mail.gmail.com>

Hi Stefano,

My package, vectools, is partly designed for this purpose.
(Unfortunately, the package *is* subject to *change*, and some of the
functions may change in the next update).

library (vectools)
which.maxs (x, ret.type="intervals")[,1] # c (8, 10, 13)
which.mins (x, ret.type="intervals")[,2] # c (4, 9, 12, 16)


best,
B.

P.S.
I'll make sure the next version has an option for the lower/upper index.


On Sat, Mar 27, 2021 at 4:36 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear list users,
> I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
> - duplicated local maxima, I should take the position of the first duplicated value;
> - duplicated local minima, I should take the position of the last duplicated value.
>
> Example:
>
> >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> >which(diff(diff(x)>=0)<0)+1
>
> gives me 8 11 15 while I need 8 10 13;
>
> >which(diff(diff(x)>0)>0)+1
>
> gives me 4 6  9 12 16 while I need 4 9 12 16.
>
> Could you please help me in this task? I would be happier not to use additional packages.
>
> Thank you for your precious help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Mar 26 23:24:58 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 26 Mar 2021 15:24:58 -0700
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <026801d72286$f2a4fd20$d7eef760$@verizon.net>
References: <s37lbh$svd$1@ciao.gmane.io>
 <CAFEqCdxcEVoAnOHjKywuyoF6==Ej1FLSAkZAPSVec9JwTNxt5w@mail.gmail.com>
 <s3il39$47o$1@ciao.gmane.io>
 <0D75B81F-2D2A-4A77-9523-B5AB23900643@dcn.davis.ca.us>
 <s3k235$ack$1@ciao.gmane.io> <026801d72286$f2a4fd20$d7eef760$@verizon.net>
Message-ID: <9FA12C17-B462-46E7-8403-0844429E90F6@dcn.davis.ca.us>

Avi, I see no limitations in using R for this task, so throwing Python into the discussion seems only to confuse the issue. I just see multiple ways to interpret the desired calculation of the result, as illustrated by your discussion and elaborated in my next paragraph, and I would rather the OP did the work of clarifying what his needs are so the question becomes about R instead of about different people guessing what the goal is.

For example, you could calculate an average daily hours billed and multiply by seven, or you could prorate hours in partial weeks and calculate the average of those weekly values, or you could simply exclude partial weeks, and then there is the issue of whether a week begins on Monday or Sunday. There is the discrepancy of asking for "by week by month" and then saying he really wants three specific months at a time... does he plan to calculate weekly summaries within months and then average three months? This is not a reasonable question for this mailing list yet.

I acknowledge that OP may not have these answers now but answers (intentional or not) will have to be embedded in whatever solution is proposed, even if some random method in a Python package purports to solve this in one line of code. So either answers from the insurance company or arbitrarily selected by OP should be identified.

On March 26, 2021 2:28:21 PM PDT, Avi Gross via R-help <r-help at r-project.org> wrote:
>There are rather straightforward ways to manipulate your data step by
>step to make harder things possible, or you can use creative ways
>harder for people to understand.
>
>So adding columns to your data that take existing times/dates and
>record them with names like Q1Y2021 can give you abilities but as noted
>they will NOT line up with weeks as in 1 to 52.
>
>You can calculate the sum of hours per week, if you had the ability to
>group by week, and place that in a column that repeats that number for
>each day recorded for that week. You can then take the same data and
>group by quarter and take some kind of average of that column but it
>probably will be WRONG if you did the above as it will take the average
>of whatever rows it encounters and that may include partial weeks or
>other anomalies like when you only recorded three days for that week.
>
>So consider other plans. What if you kept track of the number of weeks
>per month as in 28 days is 4 weeks and 31 days is 4.43 or so weeks. You
>could simply calculate the sum of hours for that month and divide by
>the number of weeks by that measure in that month. Would that number
>satisfy them?
>
>And, again, rather than trying to SORT Month names, consider adding a
>column with a numerical version. Sure, you can play with factors so the
>months are recorded in the order you want and some things like ggplot
>will then honor that order.
>
>If and when you become more expert, much of what you want might be done
>other ways without making columns for real. But it may make sense to
>start simple.
>
>Here is an example of a simple change to Months Abbreviations to be
>made into a factor in order:
>
>	df$mo <- factor(df$mo,levels=month.abb)
>
>Similar ideas involve how you convert hours and minutes to just minutes
>for averaging by adding calculated columns and you can convert the
>results back to whatever format you need later.
>
>Just FYI, many database programs might let you do much of this
>internally. Python using the tools you are using is arguably much more
>flexible.
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Eberhard W
>Lisse
>Sent: Friday, March 26, 2021 3:22 AM
>To: r-help at r-project.org
>Subject: Re: [R] How to average minutes per hour per month in the form
>of '# hours #minutes'
>
>Jeff,
>
>thank you. However, if I knew how to do this, I would probably not have
>asked :-)-O
>
>I think I have been reasonably comprehensive in describing my issue,
>but let me do it now with the real life problem:
>
>My malpractice insurance gives me a discount if I consult up to 22
>hours per week in a 3 months period.
>
>I add every patient, date and minutes whenever I see her into a MySQL
>database.  I want to file the report of my hours worked with them for
>the first 3 month period (November to January and not properly
>quarterly unfortunately :-)-0), and while I can generate this with
>LyX/LateX and knitR producing a (super)tabular table containing the
>full list, and tables for time per week and time per month I really
>can't figure out is how to average the hours worked per week for each
>month (even if weeks don't align with months properly :-)-O)
>
>While I am at it how would I get this to sort properly (year, month) if
>I used the proper names of the months, ie '%Y %B' or '%B %Y'?
>
>   CONSMINUTES %>%
>     select(datum, dauer)  %>%
>     group_by(month = format(datum, '%Y %m'),
>       week = format(datum, '%V'))  %>%
>     summarise_if(is.numeric, sum) %>%
>     mutate(hm=sprintf("%d Hour%s %d Minutes", dauer %/% 60,
>       ifelse((dauer %/% 60) == 1, " ", "s"), dauer %% 60)) %>%	
>     select(-dauer)
>
>
>Any help, or just pointers to where I can read this up, are highly
>appreciated.
>
>greetings, el
>
>
>On 2021-03-25 22:37 , Jeff Newmiller wrote:
> > This is a very unclear question.  Weeks don't line up with months..
>> so you need to clarify how you would do this or at least give an  >
>explicit example of input data and result data.
> >
>> On March 25, 2021 11:34:15 AM PDT, Dr Eberhard W Lisse
><nospam at lisse.NA> wrote:
> >> Thanks, that is helpful.
> >>
> >> But, how do I group it to produce hours worked per week per month?
> >>
> >> el
> >>
> >>
> >> On 2021-03-25 19:03 , Greg Snow wrote:
> >>> Here is one approach:
> >>>
> >>> tmp <- data.frame(min=seq(0,150, by=15))  >>>  >>> tmp %>%
> >>>     mutate(hm=sprintf("%2d Hour%s %2d Minutes",
> >>>               min %/% 60, ifelse((min %/% 60) == 1, " ", "s"),
> >>>               min %% 60))
> >>>
>>>> You could replace `sprintf` with `str_glue` (and update the syntax 
>>>> as well) if you realy need tidyverse, but you would also loose some
> >>> formatting capability.
> >>>
>>>> I don't know of tidyverse versions of `%/%` or `%%`.  If you need 
>>>> the numeric values instead of a string then just remove the  >>>
>`sprintf` and use mutate directly with `min %/% 60` and `min %% 60`.
> >>>
>>>> This of course assumes all of your data is in minutes (by the time 
>>>> you pipe to this code) and that all hours have 60 minutes (I don't 
>>>> know of any leap hours.
> >>>
>>>> On Sun, Mar 21, 2021 at 8:31 AM Dr Eberhard W Lisse
><nospam at lisse.na>  >> wrote:
> >>>>
> >>>> Hi,
> >>>>
>>>>> I have minutes worked by day (with some more information)  >>>> 
>>>>> which when using  >>>>
> >>>>           library(tidyverse)
> >>>>           library(lubridate)
> >>>>
> >>>> run through
> >>>>
> >>>>           CONSMINUTES %>%
> >>>>                   select(datum, dauer) %>%
> >>>>                   arrange(desc(datum))
> >>>>
> >>>> look somewhat like
> >>>>
> >>>>           # A tibble: 142 x 2
> >>>>              datum      dauer
> >>>>              <date>     <int>
> >>>>            1 2021-03-18    30
> >>>>            2 2021-03-17    30
> >>>>            3 2021-03-16    30
> >>>>            4 2021-03-16    30
> >>>>            5 2021-03-16    30
> >>>>            6 2021-03-16    30
> >>>>            7 2021-03-11    30
> >>>>            8 2021-03-11    30
> >>>>            9 2021-03-11    30
> >>>>           10 2021-03-11    30
> >>>>           # ? with 132 more rows
> >>>>
> >>>> I can extract minutes per hour
> >>>>
> >>>>           CONSMINUTES %>%
> >>>>           select(datum, dauer) %>%
> >>>>           group_by(week = format(datum, '%Y %V'))%>%
> >>>>           summarise_if(is.numeric, sum)
> >>>>
> >>>> and minutes per month
> >>>>
> >>>>           CONSMINUTES %>%
> >>>>           select(datum, dauer) %>%
> >>>>           group_by(month = format(datum, '%Y %m'))%>%
> >>>>           summarise_if(is.numeric, sum)
> >>>>
>>>>> I need to show the time worked per week per month in the format of
> >>>>
> >>>>           '# hours # minutes'
> >>>>
>>>>> and would like to also be able to show the average time per week 
>>>>> per month.
> >>>>
> >>>> How can I do that (preferably with tidyverse :-)-O)?
> >>>>
> >>>> greetings, el
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Sat Mar 27 09:11:16 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 27 Mar 2021 21:11:16 +1300
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
In-Reply-To: <20210325143248.4982d3cd@rolf-Latitude-E7470>
References: <20210325143248.4982d3cd@rolf-Latitude-E7470>
Message-ID: <CAB8pepyRJ0h+7+2V9WbZ6wTC9BO6LnCWEAPAFEgE0QR-w-Nmsw@mail.gmail.com>

Hi Rolf,

Let's say we have a course called Corgiology 101, with a single moderated exam.
And let's say the moderators transform initial exam scores, such that
there are fixed percentages of pass rates and A grades.

Rather than count the number of passes, we can count the number of "jumps".
That is, the number of people that pass the corgiology exam after
moderation, that would not have passed without moderation.

I've created a function to test for underdispersion, based on your expression.
(I hope I got it right).

Then I've gone on to create simulations, using both constant and
nonconstant class sizes.
The nonconstant simulations apply an (approx) discrete scaling
transformation, referred to previously.

We can see from the examples that there are a lot of these jumps.
And more importantly, they appear to be underdispersed.

----code----
PASS.SCORE <- 0.5
A.SCORE <- 0.8

#target parameters
PASS.RATE <- 0.8
A.RATE <- 0.2
#unmoderated parameters
UNMOD.MEAN.SCORE <- 0.65
UNMOD.SD.SCORE <- 0.075

NCLASSES <- 2000
NSTUD.CONST <- 200
NSTUD.NONCONST.LIMS <- c (50, 800)

sim.njump <- function (nstud, mean0=UNMOD.MEAN.SCORE, sd0=UNMOD.SD.SCORE,
    pass.score=PASS.SCORE, a.score=A.SCORE,
    pass.rate=PASS.RATE, a.rate=A.RATE)
{   x <- rnorm (nstud, mean0, sd0)
    q <- quantile (x, 1 - c (pass.rate, a.rate), names=FALSE)
    dq <- diff (q)
    q <- (a.score - pass.score) / dq * q
    y <- pass.score - q [1] + (a.score - pass.score) / dq * x
    sum (x < a.score & y >= a.score)
}

sim.nclasses <- function (nclasses, nstud, nstud.std)
{   nstud <- rep_len (nstud, nclasses)
    njump <- integer (nclasses)
    for (i in 1:nclasses)
        njump [i] <- sim.njump (nstud [i])
    if (missing (nstud.std) )
        njump
    else
        round (nstud.std / nstud * njump)
}

is.under <- function (x, n)
    var (x) < mean (x) * (1 - mean (x) / n)

njump.hom <- sim.nclasses (NCLASSES, NSTUD.CONST)
nstud <- round (runif (NCLASSES, NSTUD.NONCONST.LIMS [1],
NSTUD.NONCONST.LIMS [2]) )
njump.het <- sim.nclasses (NCLASSES, nstud, NSTUD.CONST)

under.hom <- is.under (njump.hom, NSTUD.CONST)
under.het <- is.under (njump.het, NSTUD.CONST)
main.hom <- paste0 ("const class size (under=", under.hom, ")")
main.het <- paste0 ("diff class sizes (under=", under.het, ")")

p0 <- par (mfrow = c (2, 1) )
hist (njump.hom, main=main.hom)
hist (njump.het, main=main.het)
par (p0)
----code----

best,
B.


On Thu, Mar 25, 2021 at 2:33 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> I would like a real-life example of a data set which one might think to
> model by a binomial distribution, but which is substantially
> underdispersed. I.e. a sample X = {X_1, X_2, ..., X_N} where each X_i
> is an integer between 0 and n (n known a priori) such that var(X) <<
> mean(X)*(1 - mean(X)/n).
>
> Does anyone know of any such examples?  Do any exist?  I've done
> a perfunctory web search, and had a look at "A Handbook of Small
> Data Sets" by Hand, Daly, Lunn, et al., and drawn a blank.
>
> I've seen on the web some references to underdispersed "pseudo-Poisson"
> data, but not to underdispersed "pseudo-binomial" data.  And of course
> there's lots of *over* dispersed stuff.  But that's not what I want.
>
> I can *simulate* data sets of the sor that I am looking for (so far the
> only ideas I've had for doing this are pretty simplistic and
> artificial) but I'd like to get my hands on a *real* example, if
> possible.
>
> Grateful for any pointers/suggestions.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sat Mar 27 10:00:55 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 27 Mar 2021 22:00:55 +1300
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
In-Reply-To: <CAB8pepyRJ0h+7+2V9WbZ6wTC9BO6LnCWEAPAFEgE0QR-w-Nmsw@mail.gmail.com>
References: <20210325143248.4982d3cd@rolf-Latitude-E7470>
 <CAB8pepyRJ0h+7+2V9WbZ6wTC9BO6LnCWEAPAFEgE0QR-w-Nmsw@mail.gmail.com>
Message-ID: <CAB8pepy4nMWMh5dVTRRbLJ3O3NMbToFhYnTGKAqLn=zODwJT_A@mail.gmail.com>

Sorry.
I just realized, after posting, that the "n" value in the dispersion
calculation isn't correct.
I'll have to revisit the simulation, tomorrow.

On Sat, Mar 27, 2021 at 9:11 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Hi Rolf,
>
> Let's say we have a course called Corgiology 101, with a single moderated exam.
> And let's say the moderators transform initial exam scores, such that
> there are fixed percentages of pass rates and A grades.
>
> Rather than count the number of passes, we can count the number of "jumps".
> That is, the number of people that pass the corgiology exam after
> moderation, that would not have passed without moderation.
>
> I've created a function to test for underdispersion, based on your expression.
> (I hope I got it right).
>
> Then I've gone on to create simulations, using both constant and
> nonconstant class sizes.
> The nonconstant simulations apply an (approx) discrete scaling
> transformation, referred to previously.
>
> We can see from the examples that there are a lot of these jumps.
> And more importantly, they appear to be underdispersed.
>
> ----code----
> PASS.SCORE <- 0.5
> A.SCORE <- 0.8
>
> #target parameters
> PASS.RATE <- 0.8
> A.RATE <- 0.2
> #unmoderated parameters
> UNMOD.MEAN.SCORE <- 0.65
> UNMOD.SD.SCORE <- 0.075
>
> NCLASSES <- 2000
> NSTUD.CONST <- 200
> NSTUD.NONCONST.LIMS <- c (50, 800)
>
> sim.njump <- function (nstud, mean0=UNMOD.MEAN.SCORE, sd0=UNMOD.SD.SCORE,
>     pass.score=PASS.SCORE, a.score=A.SCORE,
>     pass.rate=PASS.RATE, a.rate=A.RATE)
> {   x <- rnorm (nstud, mean0, sd0)
>     q <- quantile (x, 1 - c (pass.rate, a.rate), names=FALSE)
>     dq <- diff (q)
>     q <- (a.score - pass.score) / dq * q
>     y <- pass.score - q [1] + (a.score - pass.score) / dq * x
>     sum (x < a.score & y >= a.score)
> }
>
> sim.nclasses <- function (nclasses, nstud, nstud.std)
> {   nstud <- rep_len (nstud, nclasses)
>     njump <- integer (nclasses)
>     for (i in 1:nclasses)
>         njump [i] <- sim.njump (nstud [i])
>     if (missing (nstud.std) )
>         njump
>     else
>         round (nstud.std / nstud * njump)
> }
>
> is.under <- function (x, n)
>     var (x) < mean (x) * (1 - mean (x) / n)
>
> njump.hom <- sim.nclasses (NCLASSES, NSTUD.CONST)
> nstud <- round (runif (NCLASSES, NSTUD.NONCONST.LIMS [1],
> NSTUD.NONCONST.LIMS [2]) )
> njump.het <- sim.nclasses (NCLASSES, nstud, NSTUD.CONST)
>
> under.hom <- is.under (njump.hom, NSTUD.CONST)
> under.het <- is.under (njump.het, NSTUD.CONST)
> main.hom <- paste0 ("const class size (under=", under.hom, ")")
> main.het <- paste0 ("diff class sizes (under=", under.het, ")")
>
> p0 <- par (mfrow = c (2, 1) )
> hist (njump.hom, main=main.hom)
> hist (njump.het, main=main.het)
> par (p0)
> ----code----
>
> best,
> B.
>
>
> On Thu, Mar 25, 2021 at 2:33 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> > I would like a real-life example of a data set which one might think to
> > model by a binomial distribution, but which is substantially
> > underdispersed. I.e. a sample X = {X_1, X_2, ..., X_N} where each X_i
> > is an integer between 0 and n (n known a priori) such that var(X) <<
> > mean(X)*(1 - mean(X)/n).
> >
> > Does anyone know of any such examples?  Do any exist?  I've done
> > a perfunctory web search, and had a look at "A Handbook of Small
> > Data Sets" by Hand, Daly, Lunn, et al., and drawn a blank.
> >
> > I've seen on the web some references to underdispersed "pseudo-Poisson"
> > data, but not to underdispersed "pseudo-binomial" data.  And of course
> > there's lots of *over* dispersed stuff.  But that's not what I want.
> >
> > I can *simulate* data sets of the sor that I am looking for (so far the
> > only ideas I've had for doing this are pretty simplistic and
> > artificial) but I'd like to get my hands on a *real* example, if
> > possible.
> >
> > Grateful for any pointers/suggestions.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From m|n@h@|| @end|ng |rom um|ch@edu  Fri Mar 26 19:27:40 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Fri, 26 Mar 2021 21:27:40 +0300
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: Your message of "Fri, 26 Mar 2021 15:35:37 +0000."
 <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
Message-ID: <1193769.1616783260-6801@apollo2.minshall.org>


Stefano,

my contribution is similar to Bill Dunlap's:

  x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
  (cumsum(rle(x)$lengths)-(rle(x)$length-1))[which(diff(diff(rle(x)$values)>=0)<0)+1]
  cumsum(rle(x)$lengths)[which(diff(diff(rle(x)$value)>0)>0)+1]

kind of a cute little problem, actually.

cheers, Greg


From m|n@h@|| @end|ng |rom um|ch@edu  Fri Mar 26 12:17:31 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Fri, 26 Mar 2021 14:17:31 +0300
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: Your message of "Fri, 26 Mar 2021 09:22:11 +0200."
 <s3k235$ack$1@ciao.gmane.io>
Message-ID: <1151574.1616757451-7820@apollo2.minshall.org>


Eberhard,

> My malpractice insurance gives me a discount if I consult up to 22
> hours per week in a 3 months period.

i wonder if you might add up the number of hours worked over the (92
(?))  days of November, December, January, divide by that number of
days, then divide by seven?  that would be, obviously, a bit of an
approximation.  but, it's not clear exactly how exact the insurance
company wants.

cheers, Greg


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Mar 27 13:42:28 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 27 Mar 2021 05:42:28 -0700 (PDT)
Subject: [R] How to average minutes per hour per month in the form of '#
 hours #minutes'
In-Reply-To: <1151574.1616757451-7820@apollo2.minshall.org>
References: <1151574.1616757451-7820@apollo2.minshall.org>
Message-ID: <alpine.LNX.2.20.2103270539590.27270@salmo.appl-ecosys.com>

On Fri, 26 Mar 2021, Greg Minshall wrote:

>> My malpractice insurance gives me a discount if I consult up to 22
>> hours per week in a 3 months period.
>
> i wonder if you might add up the number of hours worked over the (92 (?))
> days of November, December, January, divide by that number of days, then
> divide by seven? that would be, obviously, a bit of an approximation. but,
> it's not clear exactly how exact the insurance company wants.

EL/Greg:

I've not closely followed this thread, but the harmonic mean is used for
rates, such as hours per week. Would calculating this value for each week
keep the insurers happy?

Rich


From m@hmood@n@der@n @end|ng |rom ugent@be  Sat Mar 27 14:19:48 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Sat, 27 Mar 2021 13:19:48 +0000
Subject: [R] Colorizing different individuals with fviz
Message-ID: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>

Hi

I use this command to generate a graph of individuals


ind <- get_famd_ind(res.famd)
fviz_famd_ind(res.famd, repel = TRUE)


I would like to know how can I specify different colors for different individuals?

The colorization is not very complex. Basically, I want to specify rows[1:10] to be shown in black and rows[11:20] to be shown in red.


Any idea about that?


Regards,
Mahmood

	[[alternative HTML version deleted]]


From D@v|dE@tup|n@nS@nt@n@ @end|ng |rom hotm@||@com  Fri Mar 26 13:31:44 2021
From: D@v|dE@tup|n@nS@nt@n@ @end|ng |rom hotm@||@com (David E.S.)
Date: Fri, 26 Mar 2021 07:31:44 -0500 (CDT)
Subject: [R] Error using nls function
Message-ID: <1616761904507-0.post-7403@n4.nabble.com>


I'm trying to fit a harmonic equation to my data, but when I'm applying the
nls function, R gives me the following error:

Error in nlsModel(formula, mf, start, wts) : singular gradient matrix at
initial parameter estimates.

All posts I've seen, related to this error, are of exponential functions,
where a linearization is used to fix this error, but in this case, I'm not
able to solve it in this way. I tried to use other starting points but it
still not working.

y <- c(20.91676, 20.65219, 20.39272, 20.58692, 21.64712, 23.30965, 23.35657,
24.22724, 24.83439, 24.34865, 23.13173, 21.96117)
t <- c(1, 2, 3, 4 , 5 , 6, 7, 8, 9, 10, 11, 12)


# Fitting function

fit <- function(x, a, b, c) {a+b*sin(2*pi*x)+c*cos(2*pi*x)}

res <- nls(y ~ fit(t, a, b, c), data=data.frame(t,y), start = list(a=1,b=0,
c=1))



Can you help me? Thanks!

David



--
Sent from: https://r.789695.n4.nabble.com/R-help-f789696.html


From g|ov@nn@@b@d|@ @end|ng |rom mcg|||@c@  Sat Mar 27 15:28:07 2021
From: g|ov@nn@@b@d|@ @end|ng |rom mcg|||@c@ (Giovanna Badia)
Date: Sat, 27 Mar 2021 14:28:07 +0000
Subject: [R] Running effect size tests on subsets of data
Message-ID: <YQXPR01MB341696B5CF4E0E96BD4B494B80609@YQXPR01MB3416.CANPRD01.PROD.OUTLOOK.COM>

Hello all,

I have seen instructions for conducting post-hoc pairwise comparisons in R after running an ANOVA, Kruskal-Wallis Test, or Yuen?s Test.

Is there a method to subset data automatically to run an effect size test across different pairs? For example, if I want to run Cohen?s d to examine the differences in data between different days of the week. My X variables would be the pairs below. (Note that no data was collected on Saturday.) I can subset the data manually and apply the effect size to each pair. Is there a way in R to create the pairs and run the effect size test all at once?

Monday-Tuesday
Monday-Wednesday
Monday-Thursday
Monday-Friday
Monday-Sunday
Tuesday-Wednesday
Tuesday-Thursday
Tuesday-Friday
Tuesday-Sunday
Wednesday-Thursday
Wednesday-Friday
Wednesday-Sunday
Thursday-Friday
Thursday-Sunday
Friday-Sunday

Any assistance you can provide would be much appreciated.

Thank you,
Giovanna

GIOVANNA BADIA | Assessment Librarian, McGill University | Office of the Dean of Libraries | giovanna.badia at mcgill.ca

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Mar 27 21:03:14 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sat, 27 Mar 2021 16:03:14 -0400
Subject: [R] Error using nls function
In-Reply-To: <1616761904507-0.post-7403@n4.nabble.com>
References: <1616761904507-0.post-7403@n4.nabble.com>
Message-ID: <e295e6a5-6090-5b10-3f9e-962c2a389f0e@gmail.com>

Use nlsr::nlxb() to get analytic derivatives. Though your problem is pretty rubbishy --
look at the singular values. (You'll need to learn some details of nlxb() results to
interpret.)

Note to change the x to t in the formula.

JN

> f1 <- y ~  a+b*sin(2*pi*t)+c*cos(2*pi*t)
> res1 <- nls(f1, data=data.frame(t,y), start=list(a=1,b=0, c=1))
Error in nlsModel(formula, mf, start, wts) :
  singular gradient matrix at initial parameter estimates
> library(nlsr)
> res1n <- nlxb(f1, data=data.frame(t,y), start=list(a=1,b=0, c=1))
> res1n
nlsr object: x
residual sumsquares =  28.644  on  12 observations
    after  3    Jacobian and  4 function evaluations
  name            coeff          SE       tstat      pval      gradient    JSingval
a                11.2235            NA         NA         NA  -2.473e-12       4.899
b           -1.55541e-09            NA         NA         NA   1.595e-14   8.399e-15
c                11.2235            NA         NA         NA  -2.473e-12   5.053e-16
>


From j|ox @end|ng |rom mcm@@ter@c@  Sat Mar 27 21:08:57 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 27 Mar 2021 16:08:57 -0400
Subject: [R] Error using nls function
In-Reply-To: <10613_1616872690_12RJIAiO013393_1616761904507-0.post-7403@n4.nabble.com>
References: <10613_1616872690_12RJIAiO013393_1616761904507-0.post-7403@n4.nabble.com>
Message-ID: <40b2d030-6401-6d22-0e97-ff8b5371cfb5@mcmaster.ca>

Dear David,

I'm afraid that this doesn't make much sense -- that is, I expect that 
you're not doing what you intended.

First, sin(2*pi*t) and cos(2*pi*t) are each invariant:

 > sin(2*pi*t)
  [1] -2.449294e-16 -4.898587e-16 -7.347881e-16 -9.797174e-16 
-1.224647e-15 -1.469576e-15
  [7] -1.714506e-15 -1.959435e-15 -2.204364e-15 -2.449294e-15 
-9.799650e-15 -2.939152e-15
 > cos(2*pi*t)
  [1] 1 1 1 1 1 1 1 1 1 1 1 1

Second, as formulated the model is linear in the parameters.

I hope this helps,
John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-03-26 8:31 a.m., David E.S. wrote:
> 
> I'm trying to fit a harmonic equation to my data, but when I'm applying the
> nls function, R gives me the following error:
> 
> Error in nlsModel(formula, mf, start, wts) : singular gradient matrix at
> initial parameter estimates.
> 
> All posts I've seen, related to this error, are of exponential functions,
> where a linearization is used to fix this error, but in this case, I'm not
> able to solve it in this way. I tried to use other starting points but it
> still not working.
> 
> y <- c(20.91676, 20.65219, 20.39272, 20.58692, 21.64712, 23.30965, 23.35657,
> 24.22724, 24.83439, 24.34865, 23.13173, 21.96117)
> t <- c(1, 2, 3, 4 , 5 , 6, 7, 8, 9, 10, 11, 12)
> 
> 
> # Fitting function
> 
> fit <- function(x, a, b, c) {a+b*sin(2*pi*x)+c*cos(2*pi*x)}
> 
> res <- nls(y ~ fit(t, a, b, c), data=data.frame(t,y), start = list(a=1,b=0,
> c=1))
> 
> 
> 
> Can you help me? Thanks!
> 
> David
> 
> 
> 
> --
> Sent from: https://r.789695.n4.nabble.com/R-help-f789696.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rk|eed@2 @end|ng |rom gm@||@com  Sat Mar 27 21:18:58 2021
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Sat, 27 Mar 2021 16:18:58 -0400
Subject: [R] Error using nls function
In-Reply-To: <e295e6a5-6090-5b10-3f9e-962c2a389f0e@gmail.com>
References: <1616761904507-0.post-7403@n4.nabble.com>
 <e295e6a5-6090-5b10-3f9e-962c2a389f0e@gmail.com>
Message-ID: <CAHz+bWakBDH_HsggPCnipCsHszWg6hXRuQ9OAhVW6BVb0dWMtA@mail.gmail.com>

David: Note that your problem is linear so it looks like you can use the lm
function to estimate a, b and c. ( or as a check against what john
did ) Unless I'm missing something  which could be the case !!!!! Also, see
Bloomfield's text for a closed form solution. I think it's
called "Intro To Fourier Analysis" or something of that nature.







On Sat, Mar 27, 2021 at 4:03 PM J C Nash <profjcnash at gmail.com> wrote:

> Use nlsr::nlxb() to get analytic derivatives. Though your problem is
> pretty rubbishy --
> look at the singular values. (You'll need to learn some details of nlxb()
> results to
> interpret.)
>
> Note to change the x to t in the formula.
>
> JN
>
> > f1 <- y ~  a+b*sin(2*pi*t)+c*cos(2*pi*t)
> > res1 <- nls(f1, data=data.frame(t,y), start=list(a=1,b=0, c=1))
> Error in nlsModel(formula, mf, start, wts) :
>   singular gradient matrix at initial parameter estimates
> > library(nlsr)
> > res1n <- nlxb(f1, data=data.frame(t,y), start=list(a=1,b=0, c=1))
> > res1n
> nlsr object: x
> residual sumsquares =  28.644  on  12 observations
>     after  3    Jacobian and  4 function evaluations
>   name            coeff          SE       tstat      pval      gradient
> JSingval
> a                11.2235            NA         NA         NA  -2.473e-12
>      4.899
> b           -1.55541e-09            NA         NA         NA   1.595e-14
>  8.399e-15
> c                11.2235            NA         NA         NA  -2.473e-12
>  5.053e-16
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Mar 27 21:19:23 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 28 Mar 2021 07:19:23 +1100
Subject: [R] Colorizing different individuals with fviz
In-Reply-To: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>
References: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>
Message-ID: <CA+8X3fW5_KVooVHvY=L75guEw0b=EvfBXmvGKLFYyjiAmi1QiA@mail.gmail.com>

Hi Mahmood,
What you have specified can be done with:

col=c(rep("black",10),rep("red",10))

depending upon what print function you are using. I suspect that this
may be based on a value in your data. For example, if you want  black
for values of some variable up to 10 and red for those over:

col=ifelse(x>10,"red","black)

Jim

On Sun, Mar 28, 2021 at 12:20 AM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi
>
> I use this command to generate a graph of individuals
>
>
> ind <- get_famd_ind(res.famd)
> fviz_famd_ind(res.famd, repel = TRUE)
>
>
> I would like to know how can I specify different colors for different individuals?
>
> The colorization is not very complex. Basically, I want to specify rows[1:10] to be shown in black and rows[11:20] to be shown in red.
>
>
> Any idea about that?
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Sat Mar 27 22:26:53 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Sat, 27 Mar 2021 21:26:53 +0000
Subject: [R] add cex.axis =1.2 to qqunif.plot from lattice library
Message-ID: <SJ0PR02MB7645A0BA124D26EDB590BAB5D4609@SJ0PR02MB7645.namprd02.prod.outlook.com>

Dear R user,

The following qqunit.plot function generated correct qq plot, however, I want to make axis label (1 ,2 ,.....8) have larger size for publication.  I tried to add cex.axis =1.2 code following the pch =20, but it does not change size of axis label. I guess lattice library setting  is different from standard R graphics setting.

Also I want to add a title on the top of plot, like main = " association" etc.

I am not familiar with lattice graphics at all. Can any one help me?

Thank you,

Ding
------------------------------------------------------------------------------------
# the first function to generate QQ plots
library(lattice)

qqunif.plot<-function(pvalues,
                      should.thin=T, thin.obs.places=2, thin.exp.places=2,
                      xlab=expression(paste("Expected (",-log[10], " p-value)")),
                      ylab=expression(paste("Observed (",-log[10], " p-value)")),
                      draw.conf=TRUE, conf.points=1000, conf.col="gray", conf.alpha=.05,
                      already.transformed=FALSE, pch=20, aspect="iso", prepanel=prepanel.qqunif,
                      par.settings=list(superpose.symbol=list(pch=pch)), ...) {


  #error checking
  if (length(pvalues)==0) stop("pvalue vector is empty, can't draw plot")
  if(!(class(pvalues)=="numeric" ||
       (class(pvalues)=="list" && all(sapply(pvalues, class)=="numeric"))))
    stop("pvalue vector is not numeric, can't draw plot")
  if (any(is.na(unlist(pvalues)))) stop("pvalue vector contains NA values, can't draw plot")
  if (already.transformed==FALSE) {
    if (any(unlist(pvalues)==0)) stop("pvalue vector contains zeros, can't draw plot")
  } else {
    if (any(unlist(pvalues)<0)) stop("-log10 pvalue vector contains negative values, can't draw plot")
  }


  grp<-NULL
  n<-1
  exp.x<-c()
  if(is.list(pvalues)) {
    nn<-sapply(pvalues, length)
    rs<-cumsum(nn)
    re<-rs-nn+1
    n<-min(nn)
    if (!is.null(names(pvalues))) {
      grp=factor(rep(names(pvalues), nn), levels=names(pvalues))
      names(pvalues)<-NULL
    } else {
      grp=factor(rep(1:length(pvalues), nn))
    }
    pvo<-pvalues
    pvalues<-numeric(sum(nn))
    exp.x<-numeric(sum(nn))
    for(i in 1:length(pvo)) {
      if (!already.transformed) {
        pvalues[rs[i]:re[i]] <- -log10(pvo[[i]])
        exp.x[rs[i]:re[i]] <- -log10((rank(pvo[[i]], ties.method="first")-.5)/nn[i])
      } else {
        pvalues[rs[i]:re[i]] <- pvo[[i]]
        exp.x[rs[i]:re[i]] <- -log10((nn[i]+1-rank(pvo[[i]], ties.method="first")-.5)/(nn[i]+1))
      }
    }
  } else {
    n <- length(pvalues)+1
    if (!already.transformed) {
      exp.x <- -log10((rank(pvalues, ties.method="first")-.5)/n)
      pvalues <- -log10(pvalues)
    } else {
      exp.x <- -log10((n-rank(pvalues, ties.method="first")-.5)/n)
    }
  }


  #this is a helper function to draw the confidence interval
  panel.qqconf<-function(n, conf.points=1000, conf.col="gray", conf.alpha=.05, ...) {
    require(grid)
    conf.points = min(conf.points, n-1);
    mpts<-matrix(nrow=conf.points*2, ncol=2)
    for(i in seq(from=1, to=conf.points)) {
      mpts[i,1]<- -log10((i-.5)/n)
      mpts[i,2]<- -log10(qbeta(1-conf.alpha/2, i, n-i))
      mpts[conf.points*2+1-i,1]<- -log10((i-.5)/n)
      mpts[conf.points*2+1-i,2]<- -log10(qbeta(conf.alpha/2, i, n-i))
    }
    grid.polygon(x=mpts[,1],y=mpts[,2], gp=gpar(fill=conf.col, lty=0), default.units="native")
  }

  #reduce number of points to plot
  if (should.thin==T) {
    if (!is.null(grp)) {
      thin <- unique(data.frame(pvalues = round(pvalues, thin.obs.places),
                                exp.x = round(exp.x, thin.exp.places),
                                grp=grp))
      grp = thin$grp
    } else {
      thin <- unique(data.frame(pvalues = round(pvalues, thin.obs.places),
                                exp.x = round(exp.x, thin.exp.places)))
    }
    pvalues <- thin$pvalues
    exp.x <- thin$exp.x
  }
  gc()

  prepanel.qqunif= function(x,y,...) {
    A = list()
    A$xlim = range(x, y)*1.02
    A$xlim[1]=0
    A$ylim = A$xlim
    return(A)
  }

  #draw the plot
  xyplot(pvalues~exp.x, groups=grp, xlab=xlab, ylab=ylab, aspect=aspect,
         prepanel=prepanel, scales=list(axs="i"), pch=pch,
         panel = function(x, y, ...) {
           if (draw.conf) {
             panel.qqconf(n, conf.points=conf.points,
                          conf.col=conf.col, conf.alpha=conf.alpha)
           };
           panel.xyplot(x,y, ...);
           panel.abline(0,1);
         }, par.settings=par.settings, ...
  )
}

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Mar 27 23:57:59 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 28 Mar 2021 11:57:59 +1300
Subject: [R] add cex.axis =1.2 to qqunif.plot from lattice library
In-Reply-To: <SJ0PR02MB7645A0BA124D26EDB590BAB5D4609@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645A0BA124D26EDB590BAB5D4609@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <20210328115759.459db0ca@rolf-Latitude-E7470>


On Sat, 27 Mar 2021 21:26:53 +0000
Yuan Chun Ding <ycding at coh.org> wrote:

> Dear R user,
> 
> The following qqunit.plot function generated correct qq plot,
> however, I want to make axis label (1 ,2 ,.....8) have larger size
> for publication.  I tried to add cex.axis =1.2 code following the pch
> =20, but it does not change size of axis label. I guess lattice
> library setting  is different from standard R graphics setting.

Yes indeed things are different.  Read e.g. the help for xyplot() --- a bit
opaque until you get used to it, but the information actually *is* there.

Your example is *far* too complicated for anyone to wade through,
but here is a toy example just using xyplot:

set.seed(42)
x <- 1:10
y <- rnorm(10)
library(lattice)
# Compare:
print(xyplot(y ~ x))
# with:
print(xyplot(y ~ x,scales=list(cex=2)))

To get an overall title you can use "main=", just like in base graphics.
E.g.:

print(xyplot(y ~ x,scales=list(cex=2),
             main="This is a load of dingoes' kidneys."))

If you can't get something like this to work in the context
in which you are interested, then please provide a *minimal* (simple!)
reproducible example illustrating the problem, and someone on this list
will probably be able to help you.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @purd|e@@ @end|ng |rom gm@||@com  Sun Mar 28 00:29:45 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 28 Mar 2021 12:29:45 +1300
Subject: [R] Off topic --- underdispersed (pseudo) binomial data.
In-Reply-To: <CAB8pepy4nMWMh5dVTRRbLJ3O3NMbToFhYnTGKAqLn=zODwJT_A@mail.gmail.com>
References: <20210325143248.4982d3cd@rolf-Latitude-E7470>
 <CAB8pepyRJ0h+7+2V9WbZ6wTC9BO6LnCWEAPAFEgE0QR-w-Nmsw@mail.gmail.com>
 <CAB8pepy4nMWMh5dVTRRbLJ3O3NMbToFhYnTGKAqLn=zODwJT_A@mail.gmail.com>
Message-ID: <CAB8pepz70KKQ0DGONbW4RnOvmrH0yzF=Jh3GQ-Y+-SccCL_iqw@mail.gmail.com>

Further to yesterday's posts:
I think the "n" value would be the maximum possible number of jumps,
not the number of students.
In theory, the minimum possible number is zero, so the distributions
are more binomial-like than they look.

Also, there was a mistake in my comments.
The jump is from non-A-grade to A-grade, not non-pass to pass.


On Sat, Mar 27, 2021 at 10:00 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Sorry.
> I just realized, after posting, that the "n" value in the dispersion
> calculation isn't correct.
> I'll have to revisit the simulation, tomorrow.
>
> On Sat, Mar 27, 2021 at 9:11 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > Hi Rolf,
> >
> > Let's say we have a course called Corgiology 101, with a single moderated exam.
> > And let's say the moderators transform initial exam scores, such that
> > there are fixed percentages of pass rates and A grades.
> >
> > Rather than count the number of passes, we can count the number of "jumps".
> > That is, the number of people that pass the corgiology exam after
> > moderation, that would not have passed without moderation.
> >
> > I've created a function to test for underdispersion, based on your expression.
> > (I hope I got it right).
> >
> > Then I've gone on to create simulations, using both constant and
> > nonconstant class sizes.
> > The nonconstant simulations apply an (approx) discrete scaling
> > transformation, referred to previously.
> >
> > We can see from the examples that there are a lot of these jumps.
> > And more importantly, they appear to be underdispersed.
> >
> > ----code----
> > PASS.SCORE <- 0.5
> > A.SCORE <- 0.8
> >
> > #target parameters
> > PASS.RATE <- 0.8
> > A.RATE <- 0.2
> > #unmoderated parameters
> > UNMOD.MEAN.SCORE <- 0.65
> > UNMOD.SD.SCORE <- 0.075
> >
> > NCLASSES <- 2000
> > NSTUD.CONST <- 200
> > NSTUD.NONCONST.LIMS <- c (50, 800)
> >
> > sim.njump <- function (nstud, mean0=UNMOD.MEAN.SCORE, sd0=UNMOD.SD.SCORE,
> >     pass.score=PASS.SCORE, a.score=A.SCORE,
> >     pass.rate=PASS.RATE, a.rate=A.RATE)
> > {   x <- rnorm (nstud, mean0, sd0)
> >     q <- quantile (x, 1 - c (pass.rate, a.rate), names=FALSE)
> >     dq <- diff (q)
> >     q <- (a.score - pass.score) / dq * q
> >     y <- pass.score - q [1] + (a.score - pass.score) / dq * x
> >     sum (x < a.score & y >= a.score)
> > }
> >
> > sim.nclasses <- function (nclasses, nstud, nstud.std)
> > {   nstud <- rep_len (nstud, nclasses)
> >     njump <- integer (nclasses)
> >     for (i in 1:nclasses)
> >         njump [i] <- sim.njump (nstud [i])
> >     if (missing (nstud.std) )
> >         njump
> >     else
> >         round (nstud.std / nstud * njump)
> > }
> >
> > is.under <- function (x, n)
> >     var (x) < mean (x) * (1 - mean (x) / n)
> >
> > njump.hom <- sim.nclasses (NCLASSES, NSTUD.CONST)
> > nstud <- round (runif (NCLASSES, NSTUD.NONCONST.LIMS [1],
> > NSTUD.NONCONST.LIMS [2]) )
> > njump.het <- sim.nclasses (NCLASSES, nstud, NSTUD.CONST)
> >
> > under.hom <- is.under (njump.hom, NSTUD.CONST)
> > under.het <- is.under (njump.het, NSTUD.CONST)
> > main.hom <- paste0 ("const class size (under=", under.hom, ")")
> > main.het <- paste0 ("diff class sizes (under=", under.het, ")")
> >
> > p0 <- par (mfrow = c (2, 1) )
> > hist (njump.hom, main=main.hom)
> > hist (njump.het, main=main.het)
> > par (p0)
> > ----code----
> >
> > best,
> > B.
> >
> >
> > On Thu, Mar 25, 2021 at 2:33 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> > >
> > >
> > > I would like a real-life example of a data set which one might think to
> > > model by a binomial distribution, but which is substantially
> > > underdispersed. I.e. a sample X = {X_1, X_2, ..., X_N} where each X_i
> > > is an integer between 0 and n (n known a priori) such that var(X) <<
> > > mean(X)*(1 - mean(X)/n).
> > >
> > > Does anyone know of any such examples?  Do any exist?  I've done
> > > a perfunctory web search, and had a look at "A Handbook of Small
> > > Data Sets" by Hand, Daly, Lunn, et al., and drawn a blank.
> > >
> > > I've seen on the web some references to underdispersed "pseudo-Poisson"
> > > data, but not to underdispersed "pseudo-binomial" data.  And of course
> > > there's lots of *over* dispersed stuff.  But that's not what I want.
> > >
> > > I can *simulate* data sets of the sor that I am looking for (so far the
> > > only ideas I've had for doing this are pretty simplistic and
> > > artificial) but I'd like to get my hands on a *real* example, if
> > > possible.
> > >
> > > Grateful for any pointers/suggestions.
> > >
> > > cheers,
> > >
> > > Rolf Turner
> > >
> > > --
> > > Honorary Research Fellow
> > > Department of Statistics
> > > University of Auckland
> > > Phone: +64-9-373-7599 ext. 88276
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sun Mar 28 06:04:20 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sun, 28 Mar 2021 09:34:20 +0530
Subject: [R] add cex.axis =1.2 to qqunif.plot from lattice library
In-Reply-To: <20210328115759.459db0ca@rolf-Latitude-E7470>
References: <SJ0PR02MB7645A0BA124D26EDB590BAB5D4609@SJ0PR02MB7645.namprd02.prod.outlook.com>
 <20210328115759.459db0ca@rolf-Latitude-E7470>
Message-ID: <CADfFDC4usHb-9p_KuaWx8-ChcO=m9bB0rPWNgweMyfJJ3g_i=A@mail.gmail.com>

In addition to what Rolf said, a relatively obscure but generally
useful way to "globally" control fontsize is to set the underlying
grid parameter (see ?grid::gpar). The easiest way to do this is
through the lattice settings, e.g.,

lattice.options(default.theme = list(grid.pars = list(cex = 1.5)))

This is particularly useful for high resolution PNG plots for
inclusion in HTML output via knitr.

-Deepayan

On Sun, Mar 28, 2021 at 4:28 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> On Sat, 27 Mar 2021 21:26:53 +0000
> Yuan Chun Ding <ycding at coh.org> wrote:
>
> > Dear R user,
> >
> > The following qqunit.plot function generated correct qq plot,
> > however, I want to make axis label (1 ,2 ,.....8) have larger size
> > for publication.  I tried to add cex.axis =1.2 code following the pch
> > =20, but it does not change size of axis label. I guess lattice
> > library setting  is different from standard R graphics setting.
>
> Yes indeed things are different.  Read e.g. the help for xyplot() --- a bit
> opaque until you get used to it, but the information actually *is* there.
>
> Your example is *far* too complicated for anyone to wade through,
> but here is a toy example just using xyplot:
>
> set.seed(42)
> x <- 1:10
> y <- rnorm(10)
> library(lattice)
> # Compare:
> print(xyplot(y ~ x))
> # with:
> print(xyplot(y ~ x,scales=list(cex=2)))
>
> To get an overall title you can use "main=", just like in base graphics.
> E.g.:
>
> print(xyplot(y ~ x,scales=list(cex=2),
>              main="This is a load of dingoes' kidneys."))
>
> If you can't get something like this to work in the context
> in which you are interested, then please provide a *minimal* (simple!)
> reproducible example illustrating the problem, and someone on this list
> will probably be able to help you.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |err|@|eber| @end|ng |rom gmx@@t  Sun Mar 28 17:59:01 2021
From: |err|@|eber| @end|ng |rom gmx@@t (Ferri Leberl)
Date: Sun, 28 Mar 2021 17:59:01 +0200
Subject: [R] Spie charts
Message-ID: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>

Dear??,
Ist there a function to plot "spie charts" in R?
https://en.wikipedia.org/wiki/spie_chart
(These are a combination of pie charts and radial pie charts, where the angle represents one dimension and the radius of the respective sector another dimension)
Thank you in advance!


From bgunter@4567 @end|ng |rom gm@||@com  Sun Mar 28 19:22:32 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 28 Mar 2021 10:22:32 -0700
Subject: [R] Spie charts
In-Reply-To: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
References: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
Message-ID: <CAGxFJbT-=HhUc+Ec3hagnUx=mCXWz3wWZ9Xau3fukO=suBCYEA@mail.gmail.com>

Probably not, for good reason (see remarks below), but you might search on
"nightingale plots"



****off topic remarks:****
The reason they are a bad idea (imo!) is that the eye is not good at
comparing angles, and this complicates the comparisons by adding radii, and
hence sector areas, into the mix. The example you linked to is nonsense: so
few numbers should not be graphed at all, because a simple table can be
easily and accurately comprehended.

For 2-d quantitative comparisons, a simple scatterplot is much more
effective at conveying the information accurately, assuming there's more
information than can be easily grasped in a small table.

Feel free to address responses and criticisms to me/ Ferri off list. I only
kept my remarks on list so that others could offer their possibly different
perspectives.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 28, 2021 at 8:59 AM Ferri Leberl <ferri.leberl at gmx.at> wrote:

> Dear ?,
> Ist there a function to plot "spie charts" in R?
> https://en.wikipedia.org/wiki/spie_chart
> (These are a combination of pie charts and radial pie charts, where the
> angle represents one dimension and the radius of the respective sector
> another dimension)
> Thank you in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun Mar 28 23:28:09 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 29 Mar 2021 08:28:09 +1100
Subject: [R] Spie charts
In-Reply-To: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
References: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
Message-ID: <CA+8X3fUENgv_a02Lw8jNxD+NLnzbUfJootcSpeNKhLyEBDwa-Q@mail.gmail.com>

Hi Ferri,
There are a number of variations on the pie chart. The fan.plot,
radial.pie and starPie functions in the plotrix package are but a few.
There are two really important considerations in using plots like
this:

1) Does the plot illustrate what you want? For example, if you want to
show that more of the A people get COVID than B people, but also that
there are more of them in the population, you could probably do this
with what you are suggesting.

2) Do the viewers get it? This is the most important part. You know
what is happening, but is that information clear to the viewer. Try it
out on unsuspecting co-workers without explanation.

Bert is right, Florence Nightingale's "coxcomb" is an early attempt at
doing this sort of thing.

Jim

On Mon, Mar 29, 2021 at 2:59 AM Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
> Dear ?,
> Ist there a function to plot "spie charts" in R?
> https://en.wikipedia.org/wiki/spie_chart
> (These are a combination of pie charts and radial pie charts, where the angle represents one dimension and the radius of the respective sector another dimension)
> Thank you in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Mar 29 07:50:38 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 29 Mar 2021 05:50:38 +0000
Subject: [R] Colorizing different individuals with fviz
In-Reply-To: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>
References: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>
Message-ID: <8de43ab38ea64c688958478d67dc0c01@SRVEXCHCM1302.precheza.cz>

Hi.

You could probably use "col.ind.sup" for this task, however factoextra is
rather rigid in its properties. I still recommend plain prcomp and finetune
biplot with points.
Maybe not so fancy as factoextra but you could format points with shape,
size, colour to characterise some differences.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Mahmood
> Naderan-Tahan
> Sent: Saturday, March 27, 2021 2:20 PM
> To: r-help at r-project.org
> Subject: [R] Colorizing different individuals with fviz
> 
> Hi
> 
> I use this command to generate a graph of individuals
> 
> 
> ind <- get_famd_ind(res.famd)
> fviz_famd_ind(res.famd, repel = TRUE)
> 
> 
> I would like to know how can I specify different colors for different
> individuals?
> 
> The colorization is not very complex. Basically, I want to specify
rows[1:10] to
> be shown in black and rows[11:20] to be shown in red.
> 
> 
> Any idea about that?
> 
> 
> Regards,
> Mahmood
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m|k@@h@m@r|73 @end|ng |rom out|ook@com  Sun Mar 28 18:02:17 2021
From: m|k@@h@m@r|73 @end|ng |rom out|ook@com (Mika Hamari)
Date: Sun, 28 Mar 2021 16:02:17 +0000
Subject: [R] seed problem?
Message-ID: <HE1PR0902MB205961BC5D2F17F581F0E1C9E67F9@HE1PR0902MB2059.eurprd09.prod.outlook.com>

Hi!

I have Windows 10 on PC and different versions of R. I noticed that when I executed simulation with R 4.0.3, it gave exactly the same results next time when I re-opened the program. I didn?t set the seed.

I tested this also with simple ?rnorm(10,100,10)?, and the results were every time the same, when I re-opened the program. It seems that it starts with the same seed. R 4.0.0 and 4.0.3 did it, both with 32- and 64-bit versions. But with R Studio the results were every time different, as they were also different with 3.4.3. This explains, why I hadn?t noticed this earlier.

I know the function set.seed(), but I wonder, how in the first place seed can be every time same, if you don?t set it to be. What I read about seeds, this should be very highly improbable occurence.

Thanks to all developers for what they are doing for common good. I love R!

Mika Hamari

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Mar 29 09:31:51 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 29 Mar 2021 00:31:51 -0700
Subject: [R] seed problem?
In-Reply-To: <HE1PR0902MB205961BC5D2F17F581F0E1C9E67F9@HE1PR0902MB2059.eurprd09.prod.outlook.com>
References: <HE1PR0902MB205961BC5D2F17F581F0E1C9E67F9@HE1PR0902MB2059.eurprd09.prod.outlook.com>
Message-ID: <E2E28790-9767-444B-A4DD-2D75E73E951D@dcn.davis.ca.us>

Check if you have a .RData file in your R startup directory. It may contain the seed.

.RData files (without anything in front of the period) are dangerous... many R users avoid them because they can easily drag in mistakes from previous sessions to plague you.

On March 28, 2021 9:02:17 AM PDT, Mika Hamari <mika.hamari73 at outlook.com> wrote:
>Hi!
>
>I have Windows 10 on PC and different versions of R. I noticed that
>when I executed simulation with R 4.0.3, it gave exactly the same
>results next time when I re-opened the program. I didn?t set the seed.
>
>I tested this also with simple ?rnorm(10,100,10)?, and the results were
>every time the same, when I re-opened the program. It seems that it
>starts with the same seed. R 4.0.0 and 4.0.3 did it, both with 32- and
>64-bit versions. But with R Studio the results were every time
>different, as they were also different with 3.4.3. This explains, why I
>hadn?t noticed this earlier.
>
>I know the function set.seed(), but I wonder, how in the first place
>seed can be every time same, if you don?t set it to be. What I read
>about seeds, this should be very highly improbable occurence.
>
>Thanks to all developers for what they are doing for common good. I
>love R!
>
>Mika Hamari
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From m|k@@h@m@r|73 @end|ng |rom out|ook@com  Mon Mar 29 11:25:25 2021
From: m|k@@h@m@r|73 @end|ng |rom out|ook@com (Mika Hamari)
Date: Mon, 29 Mar 2021 09:25:25 +0000
Subject: [R] seed problem?
In-Reply-To: <E2E28790-9767-444B-A4DD-2D75E73E951D@dcn.davis.ca.us>
References: <HE1PR0902MB205961BC5D2F17F581F0E1C9E67F9@HE1PR0902MB2059.eurprd09.prod.outlook.com>,
 <E2E28790-9767-444B-A4DD-2D75E73E951D@dcn.davis.ca.us>
Message-ID: <HE1PR0902MB205976BC599E1D5E660880C6E67E9@HE1PR0902MB2059.eurprd09.prod.outlook.com>

Thank you, Jeff! I had that file, and when I removed it, that solved the problem. Now random numbers are really random. Excellent!

Mika


L?hetetty Samsung Galaxy -?lypuhelimesta.


-------- Alkuper?inen viesti --------
L?hett?j?: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
P?iv?m??r?: 29.3.2021 10.31 (GMT+02:00)
Saaja: r-help at r-project.org, Mika Hamari <mika.hamari73 at outlook.com>, r-help at r-project.org
Aihe: Re: [R] seed problem?

Check if you have a .RData file in your R startup directory. It may contain the seed.

.RData files (without anything in front of the period) are dangerous... many R users avoid them because they can easily drag in mistakes from previous sessions to plague you.

On March 28, 2021 9:02:17 AM PDT, Mika Hamari <mika.hamari73 at outlook.com> wrote:
>Hi!
>
>I have Windows 10 on PC and different versions of R. I noticed that
>when I executed simulation with R 4.0.3, it gave exactly the same
>results next time when I re-opened the program. I didn?t set the seed.
>
>I tested this also with simple ?rnorm(10,100,10)?, and the results were
>every time the same, when I re-opened the program. It seems that it
>starts with the same seed. R 4.0.0 and 4.0.3 did it, both with 32- and
>64-bit versions. But with R Studio the results were every time
>different, as they were also different with 3.4.3. This explains, why I
>hadn?t noticed this earlier.
>
>I know the function set.seed(), but I wonder, how in the first place
>seed can be every time same, if you don?t set it to be. What I read
>about seeds, this should be very highly improbable occurence.
>
>Thanks to all developers for what they are doing for common good. I
>love R!
>
>Mika Hamari
>
>       [[alternative HTML version deleted]]

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From tg@77m @end|ng |rom y@hoo@com  Mon Mar 29 15:04:50 2021
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Mon, 29 Mar 2021 13:04:50 +0000 (UTC)
Subject: [R] Spie charts
References: <328972139.1464954.1617023090138.ref@mail.yahoo.com>
Message-ID: <328972139.1464954.1617023090138@mail.yahoo.com>

Ferri,
Radar Charts are often used to compare two or more items or groups on various features or characteristics. However, as the number of groups increases, the user has a harder time making comparisons between groups. As the number of groups increase, the number of spokes of the radar chart increases. Users in general have a harder time comparing radial distances.You're better off using a scatter plot for this. If however, you still want to create a radar chart, you may want to the fmsb package. 

Hope this helps!
Thomas SubiaStatistician


	[[alternative HTML version deleted]]


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Mar 29 15:52:39 2021
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 29 Mar 2021 13:52:39 +0000
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <CAHqSRuSUN-B4wJGiCG83nzU3wM2uvj2rC42osMXehqdcoBqe7A@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>,
 <CAHqSRuSUN-B4wJGiCG83nzU3wM2uvj2rC42osMXehqdcoBqe7A@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4FC658BF48@ESINO.regionemarche.intra>

Dear Bill, Bert, Greg and Abby,
I tested your code (honestly apart from Abby's solution because it needed an additional package and I run R in a server which is not administrated by myself), they work and I found them equivalent. (Probably Bill's and Greg's solutions are a bit faster than Bert's.)

In my real application I found a case where none of them work: when the series is monotonic. In this case the last number of the vector (or the last duplicated numbers) is not a maximum but it is anyway the highest number of the vector:

>x <- c(1,1,1,2,2,3,4,4,4,5,6,6,6)

The error is: argument is of length zero.
Your code is at the moment too complicated for me to modify. I ask if there is an "easy" extension of the code that you kindly wrote for me to handle also this possibility.

Thank you for everything
Stefano



         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------

________________________________________
Da: Bill Dunlap [williamwdunlap at gmail.com]
Inviato: venerd? 26 marzo 2021 18.40
A: Stefano Sofia
Cc: r-help mailing list
Oggetto: Re: [R] local maxima positions in a vector with duplicated values

Using rle() may make it easier - finding the peak values is easier and
select from cumsum(lengths) to get the positions of the last values
before the peaks, then add 1.  I have not tested the following very
much.

function(x) {
  rx <- rle(x)
  cumsum(rx$lengths)[c(diff(diff(rx$values)>0) == -1,FALSE,FALSE)]+1
}

-Bill

On Fri, Mar 26, 2021 at 8:36 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear list users,
> I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
> - duplicated local maxima, I should take the position of the first duplicated value;
> - duplicated local minima, I should take the position of the last duplicated value.
>
> Example:
>
> >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> >which(diff(diff(x)>=0)<0)+1
>
> gives me 8 11 15 while I need 8 10 13;
>
> >which(diff(diff(x)>0)>0)+1
>
> gives me 4 6  9 12 16 while I need 4 9 12 16.
>
> Could you please help me in this task? I would be happier not to use additional packages.
>
> Thank you for your precious help
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=5a635173&h=06ff70f3&f=y&p=y
> PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=5a635173&h=e12f63e8&f=y&p=y
> and provide commented, minimal, self-contained, reproducible code.

--

Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
This message was scanned by Libraesva ESG and is believed to be clean.


From m|n@h@|| @end|ng |rom um|ch@edu  Mon Mar 29 16:14:40 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Mon, 29 Mar 2021 17:14:40 +0300
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: Your message of "Mon, 29 Mar 2021 13:52:39 +0000."
 <8B435C9568170B469AE31E8891E8CC4FC658BF48@ESINO.regionemarche.intra>
Message-ID: <222990.1617027280@apollo2.minshall.org>

Stefano,

i notice that my and Bill's (pretty much isomorphic) solutions give a
zero-length vector.  i don't remember Bert's, but it's probably gives
similar results.  your code could check for that result, and react
accordingly.

cheers, Greg


From pjm|||er_57 @end|ng |rom y@hoo@com  Mon Mar 29 16:44:00 2021
From: pjm|||er_57 @end|ng |rom y@hoo@com (Paul Miller)
Date: Mon, 29 Mar 2021 14:44:00 +0000 (UTC)
Subject: [R] Dynamically defining dplyr across statements (was dplyr:
 summarise across using variable names and a condition)
In-Reply-To: <ad3bdd2d-137a-d2fb-d56a-3ca5c41887d9@sapo.pt>
References: <mailman.362665.1.1616756401.56197.r-help@r-project.org>
 <125782978.721097.1616766465468@mail.yahoo.com>
 <ad3bdd2d-137a-d2fb-d56a-3ca5c41887d9@sapo.pt>
Message-ID: <1378229554.1603577.1617029040600@mail.yahoo.com>

Hello All,

Thanks Rui for your response to my question. I agree that it is possible to use a workaround. Get most of what you want and then tidy it up afterwards. I too have a workaround that I have pasted below. I wanted to avoid that initially. I felt I was only using a workaround because I hadn't yet figured out how to use the dplyr software properly.

Determined how to summarise across conditionally during the weekend. That led me to rename my question as learning this changed the nature of the problem.

Below are my "have" and "need" data sets from before, for which I've reordered columns. After that, are some vectors of variable names that are already defined in my code and which I thought might be helpful in producing a solution. After that, is dplyr code that summarizes across conditionally. If the data being submitted to this code were always going to be the same, this would work perfectly. That's not the case though. So the across statements that are needed will be data dependent. Last, I've pasted my version of a workaround. This should work for any dataset.

Ideally, I'd like to get a solution that builds on the summarise across code below. It seems likely that would involve dynamically creating the various across statements though, and that might wind up being a lot more complicated and verbose than my workaround. Another possibility might be to do this in one pass using non-dplyr code. If neither of those options works out, it may be that the workaround is actually the way to go.

Thanks,

Paul

#### Have and need data ####

library(magrittr)
library(dplyr) 

have <- structure(list(
? ptno = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M",
?????????? "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z"),
? age1 = c(74, 70, 78, 79, 72, 81, 76, 58, 53, 74, 72, 74, 75,
?????????? 73, 80, 62, 67, 65, 83, 67, 72, 90, 73, 84, 90, 51),
? age2 = c(71, 67, 72, 74, 65, 79, 70, 49, 45, 68, 70, 71, 74,
?????????? 71, 69, 58, 65, 59, 80, 60, 68, 87, 71, 82, 80, 49),
? gender_male = c(1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L,
????????????????? 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L),
? gender_female = c(0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L,
??????????????????? 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L),
? race_white = c(0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
???????????????? 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L),
? race_black = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
???????????????? 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
? race_other = c(1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L,
???????????????? 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)),
? row.names = c(NA, -26L), class = c("tbl_df", "tbl", "data.frame"))

have <- have %>%
? select(ptno, age1, gender_male, gender_female, age2, everything())

need <-structure(list(
? age1_mean = 72.8076923076923, age1_std = 9.72838827666425,
? age2_mean = 68.2307692307692, age2_std = 10.2227498934785,
? gender_male_prop = 0.576923076923077, gender_female_prop = 0.423076923076923,
? race_white_prop = 0.769230769230769, race_black_prop = 0.0384615384615385,
? race_other_prop = 0.192307692307692),
? row.names = c(NA, -1L), class = c("tbl_df", "tbl", "data.frame"))

need <- need %>%
? select(age1_mean, age1_std, gender_male_prop, gender_female_prop, age2_mean, age2_std, everything())

#### Vectors of variable names ####

vars_num <-? c("age1", "age2")
vars_dmy <-? c("gender", "race")
vars_all <-? c("age1", "age2","gender", "race")

#### dplyr conditional summarize across ####

have %>%
? summarize(
???? across(2:2, list(mean = mean, std = sd)),
???? across(3:4, list(prop = mean)),
???? across(5:5, list(mean = mean, std = sd)),
???? across(6:8, list(prop = mean))
? ) %>%
? all.equal(need)?

#### Workaround ####

have %>%
? summarise(across(
???? .cols = !contains("chai_patient_id"),
???? .fns = list(mean = mean, std = sd),
???? .names = "{col}_{fn}"
? )) %>%
? select(starts_with(vars_num) | ends_with("mean")) %>%
? rename_at(vars(!starts_with(vars_num)), list(~ str_replace(., "mean$", "prop"))) %>% 
? all.equal(need)


On Friday, March 26, 2021, 1:08:58 p.m. EDT, Rui Barradas <ruipbarradas at sapo.pt> wrote: 

Hello,

Here is a way of doing what the question asks for. There might be 
others, simpler, but this one works.

have %>%
? summarise(across(
? ? .cols = !contains("ptno"),
? ? .fns = list(mean = mean, std = sd),
? ? .names = "{col}_{fn}"
? )) %>%
? select(
? ? -matches("^gender_.*_std$"),
? ? -matches("^race_.*_std$")
? ) %>%
? rename_with(
? ? .cols = matches("^gender|^race"),
? ? ~sub("mean$", "prop", .x)
? ) %>%
? all.equal(need)
#[1] TRUE


Hope this helps,

Rui Barradas

?s 13:47 de 26/03/21, Paul Miller via R-help escreveu:
> Hello All,
> 
> Would like to be able to summarize across in dplyr using variable names and a condition. Below is an example "have" data set followed by an example "need" data set. After that, I've got a vector of numeric variable names. After that, I've got the very humble beginnings of a dplyr-based solution.
> 
> What I think I need to be able to do is to submit my variable names to dplyr and then to have a conditional function. If the variable is is in my list of names, calculate the mean and the std. If not, then calculate the mean but label it as a proportion. The question is how to do that. It appears that using variable names might involve !!, or possibly enquo, or possibly quo, but I haven't had much success with these. I imagine I might have been very close but not quite have gotten it. The conditional part seems less difficult but I'm not quite sure how to do that either.
> 
> Help with this would be greatly appreciated.
> 
> Thanks,
> 
> Paul
> 
> 
> have <- structure(list(
>? ??????? ptno = c("A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M",
>? ???????????????? "N", "O", "P", "Q", "R", "S", "T", "U", "V", "W", "X", "Y", "Z"),
>? ??????? age1 = c(74, 70, 78, 79, 72, 81, 76, 58, 53, 74, 72, 74, 75,
>? ???????????????? 73, 80, 62, 67, 65, 83, 67, 72, 90, 73, 84, 90, 51),
>? ??????? age2 = c(71, 67, 72, 74, 65, 79, 70, 49, 45, 68, 70, 71, 74,
>? ???????????????? 71, 69, 58, 65, 59, 80, 60, 68, 87, 71, 82, 80, 49),
>? ??????? gender_male = c(1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L,
>? ??????????????????????? 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L),
>? ??????? gender_female = c(0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L,
>? ????????????????????????? 0L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L),
>? ??????? race_white = c(0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
>? ?????????????????????? 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L),
>? ??????? race_black = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
>? ?????????????????????? 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
>? ??????? race_other = c(1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L,
>? ?????????????????????? 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L)),
>? ??????? row.names = c(NA, -26L), class = c("tbl_df", "tbl", "data.frame"))
>? 
> 
> need <-structure(list(
>? ?????? age1_mean = 72.8076923076923, age1_std = 9.72838827666425,
>? ?????? age2_mean = 68.2307692307692, age2_std = 10.2227498934785,
>? ?????? gender_male_prop = 0.576923076923077, gender_female_prop = 0.423076923076923,
>? ?????? race_white_prop = 0.769230769230769, race_black_prop = 0.0384615384615385,
>? ?????? race_other_prop = 0.192307692307692),
>? ?????? row.names = c(NA, -1L), class = c("tbl_df", "tbl", "data.frame"))
> 
> vars_num <-? c("age1", "age2")
> 
> library(magrittr)
> library(dplyr)
> 
> have %>%
>? ? summarise(across(
>? ? .cols = !contains("ptno"),
>? ? .fns = list(mean = mean, std = sd),
>? ? .names = "{col}_{fn}"

> ))
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

> 


From e|ou@r@|n| @end|ng |rom gm@||@com  Mon Mar 29 15:09:44 2021
From: e|ou@r@|n| @end|ng |rom gm@||@com (Rachida El Ouaraini)
Date: Mon, 29 Mar 2021 15:09:44 +0200
Subject: [R] "for" loop does not work with my plot_ly command
Message-ID: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>

Hi everyone,
I am new to R programming, and I am having difficulties modifying an R
script to introduce the "for" loop in the code.
While searching I found that this issue has already been raised, but I did
not know what to do to fix mine !

*The code that works (without for command):*

CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
",", skip = 0)
# The CPM.txt file containe 1 line
......................................................................
......................................................................
options(viewer = NULL)
plot_ly() %>%
 htmlwidgets::onRender(
   "function(el, x) {
     var gd = document.getElementById(el.id);
     Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
filename: 'AnomalieRR_EcartTmoy'});
   }"
 )%>%
 add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
%>%
add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
list(color = "white", size = 14),  showarrow = FALSE)%>%
 layout(title = paste("Combinaison anomalie relative annuelle des
pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
",CPM[1,1],sep =""),
      xaxis = list(title = "Anomalie relative des pr?cipitations
annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
, family = 'Arial'), tickfont = list(color = "blue", size = 14)),
yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
'Arial'),
tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
"red", linewidth = 2),
   legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
"black")),margin = list(
      t = 70,
     r = 70,
      b = 70,
      l = 70
    ))
*The code that does not work (with for command):*
CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
",", skip = 0)
# The CPM.txt file containe several lines

*for (i in 1: (nrow(CPM)))   {*

options(viewer = NULL)
plot_ly() %>%
 htmlwidgets::onRender(
   "function(el, x) {
     var gd = document.getElementById(el.id);
     Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
filename: 'AnomalieRR_EcartTmoy'});
   }"
 )%>%
 add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
%>%
add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
list(color = "white", size = 14),  showarrow = FALSE)%>%
  layout(title = paste("Combinaison anomalie relative annuelle des
pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
",CPM[i,1],sep =""),
      xaxis = list(title = "Anomalie relative des pr?cipitations
annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
, family = 'Arial'), tickfont = list(color = "blue", size = 14)),
yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
'Arial'),
tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
"red", linewidth = 2),
  legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
"black")),margin = list(
      t = 70,
     r = 70,
      b = 70,
      l = 70
    ))

*file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i,1],".png",sep="")*
*}*


Thank you very much in advance for any help.

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Mar 29 17:22:17 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 29 Mar 2021 08:22:17 -0700
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FC658BF48@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
 <CAHqSRuSUN-B4wJGiCG83nzU3wM2uvj2rC42osMXehqdcoBqe7A@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4FC658BF48@ESINO.regionemarche.intra>
Message-ID: <CAHqSRuSusm8QPoZ3ud_=nBS9wkjc6CjMVJrboBtAOFQrRx3bkQ@mail.gmail.com>

If you want to accept maxima at the ends of the series, append -Inf to
each end and subtract one from the result.  Note that this will make
even a constant sequence have a local maximum at 1.

On Mon, Mar 29, 2021 at 6:52 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear Bill, Bert, Greg and Abby,
> I tested your code (honestly apart from Abby's solution because it needed an additional package and I run R in a server which is not administrated by myself), they work and I found them equivalent. (Probably Bill's and Greg's solutions are a bit faster than Bert's.)
>
> In my real application I found a case where none of them work: when the series is monotonic. In this case the last number of the vector (or the last duplicated numbers) is not a maximum but it is anyway the highest number of the vector:
>
> >x <- c(1,1,1,2,2,3,4,4,4,5,6,6,6)
>
> The error is: argument is of length zero.
> Your code is at the moment too complicated for me to modify. I ask if there is an "easy" extension of the code that you kindly wrote for me to handle also this possibility.
>
> Thank you for everything
> Stefano
>
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________________
> Da: Bill Dunlap [williamwdunlap at gmail.com]
> Inviato: venerd? 26 marzo 2021 18.40
> A: Stefano Sofia
> Cc: r-help mailing list
> Oggetto: Re: [R] local maxima positions in a vector with duplicated values
>
> Using rle() may make it easier - finding the peak values is easier and
> select from cumsum(lengths) to get the positions of the last values
> before the peaks, then add 1.  I have not tested the following very
> much.
>
> function(x) {
>   rx <- rle(x)
>   cumsum(rx$lengths)[c(diff(diff(rx$values)>0) == -1,FALSE,FALSE)]+1
> }
>
> -Bill
>
> On Fri, Mar 26, 2021 at 8:36 AM Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> >
> > Dear list users,
> > I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
> > - duplicated local maxima, I should take the position of the first duplicated value;
> > - duplicated local minima, I should take the position of the last duplicated value.
> >
> > Example:
> >
> > >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> > >which(diff(diff(x)>=0)<0)+1
> >
> > gives me 8 11 15 while I need 8 10 13;
> >
> > >which(diff(diff(x)>0)>0)+1
> >
> > gives me 4 6  9 12 16 while I need 4 9 12 16.
> >
> > Could you please help me in this task? I would be happier not to use additional packages.
> >
> > Thank you for your precious help
> > Stefano
> >
> >
> >          (oo)
> > --oOO--( )--OOo--------------------------------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region - Italy
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona (AN)
> > Uff: +39 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------------------------------
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> > This message was scanned by Libraesva ESG and is believed to be clean.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=5a635173&h=06ff70f3&f=y&p=y
> > PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=5a635173&h=e12f63e8&f=y&p=y
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Mar 29 17:55:50 2021
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 29 Mar 2021 15:55:50 +0000
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <CAHqSRuSusm8QPoZ3ud_=nBS9wkjc6CjMVJrboBtAOFQrRx3bkQ@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
 <CAHqSRuSUN-B4wJGiCG83nzU3wM2uvj2rC42osMXehqdcoBqe7A@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4FC658BF48@ESINO.regionemarche.intra>,
 <CAHqSRuSusm8QPoZ3ud_=nBS9wkjc6CjMVJrboBtAOFQrRx3bkQ@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4FC658BF9E@ESINO.regionemarche.intra>

Thank you Bill, your tip solved everything.

Stefano

         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------

________________________________________
Da: Bill Dunlap [williamwdunlap at gmail.com]
Inviato: luned? 29 marzo 2021 17.22
A: Stefano Sofia
Cc: bgunter.4567 at gmail.com; minshall at umich.edu; r-help mailing list
Oggetto: Re: [R] local maxima positions in a vector with duplicated values

If you want to accept maxima at the ends of the series, append -Inf to
each end and subtract one from the result.  Note that this will make
even a constant sequence have a local maximum at 1.

On Mon, Mar 29, 2021 at 6:52 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear Bill, Bert, Greg and Abby,
> I tested your code (honestly apart from Abby's solution because it needed an additional package and I run R in a server which is not administrated by myself), they work and I found them equivalent. (Probably Bill's and Greg's solutions are a bit faster than Bert's.)
>
> In my real application I found a case where none of them work: when the series is monotonic. In this case the last number of the vector (or the last duplicated numbers) is not a maximum but it is anyway the highest number of the vector:
>
> >x <- c(1,1,1,2,2,3,4,4,4,5,6,6,6)
>
> The error is: argument is of length zero.
> Your code is at the moment too complicated for me to modify. I ask if there is an "easy" extension of the code that you kindly wrote for me to handle also this possibility.
>
> Thank you for everything
> Stefano
>
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________________
> Da: Bill Dunlap [williamwdunlap at gmail.com]
> Inviato: venerd? 26 marzo 2021 18.40
> A: Stefano Sofia
> Cc: r-help mailing list
> Oggetto: Re: [R] local maxima positions in a vector with duplicated values
>
> Using rle() may make it easier - finding the peak values is easier and
> select from cumsum(lengths) to get the positions of the last values
> before the peaks, then add 1.  I have not tested the following very
> much.
>
> function(x) {
>   rx <- rle(x)
>   cumsum(rx$lengths)[c(diff(diff(rx$values)>0) == -1,FALSE,FALSE)]+1
> }
>
> -Bill
>
> On Fri, Mar 26, 2021 at 8:36 AM Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> >
> > Dear list users,
> > I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
> > - duplicated local maxima, I should take the position of the first duplicated value;
> > - duplicated local minima, I should take the position of the last duplicated value.
> >
> > Example:
> >
> > >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> > >which(diff(diff(x)>=0)<0)+1
> >
> > gives me 8 11 15 while I need 8 10 13;
> >
> > >which(diff(diff(x)>0)>0)+1
> >
> > gives me 4 6  9 12 16 while I need 4 9 12 16.
> >
> > Could you please help me in this task? I would be happier not to use additional packages.
> >
> > Thank you for your precious help
> > Stefano
> >
> >
> >          (oo)
> > --oOO--( )--OOo--------------------------------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region - Italy
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona (AN)
> > Uff: +39 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------------------------------
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> > This message was scanned by Libraesva ESG and is believed to be clean.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=5a635173&h=06ff70f3&f=y&p=y
> > PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=5a635173&h=e12f63e8&f=y&p=y
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>

--

Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
This message was scanned by Libraesva ESG and is believed to be clean.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Mar 29 17:56:04 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 29 Mar 2021 08:56:04 -0700
Subject: [R] seed problem?
In-Reply-To: <HE1PR0902MB205961BC5D2F17F581F0E1C9E67F9@HE1PR0902MB2059.eurprd09.prod.outlook.com>
References: <HE1PR0902MB205961BC5D2F17F581F0E1C9E67F9@HE1PR0902MB2059.eurprd09.prod.outlook.com>
Message-ID: <CAHqSRuRM23pvOpNza-2NmXjzujq7PS_GADD=cjNFr4Nciw8jpA@mail.gmail.com>

Does this happen if you start R with the --vanilla flag?  If so it may
be that you have a startup file, .\.Rprofile or %HOME%\.Rprofile that
is calling set.seed(n) for a fixed n.

-Bill

On Mon, Mar 29, 2021 at 12:16 AM Mika Hamari <mika.hamari73 at outlook.com> wrote:
>
> Hi!
>
> I have Windows 10 on PC and different versions of R. I noticed that when I executed simulation with R 4.0.3, it gave exactly the same results next time when I re-opened the program. I didn?t set the seed.
>
> I tested this also with simple ?rnorm(10,100,10)?, and the results were every time the same, when I re-opened the program. It seems that it starts with the same seed. R 4.0.0 and 4.0.3 did it, both with 32- and 64-bit versions. But with R Studio the results were every time different, as they were also different with 3.4.3. This explains, why I hadn?t noticed this earlier.
>
> I know the function set.seed(), but I wonder, how in the first place seed can be every time same, if you don?t set it to be. What I read about seeds, this should be very highly improbable occurence.
>
> Thanks to all developers for what they are doing for common good. I love R!
>
> Mika Hamari
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Mar 29 18:03:22 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 29 Mar 2021 09:03:22 -0700
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FC658BF9E@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
 <CAHqSRuSUN-B4wJGiCG83nzU3wM2uvj2rC42osMXehqdcoBqe7A@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4FC658BF48@ESINO.regionemarche.intra>
 <CAHqSRuSusm8QPoZ3ud_=nBS9wkjc6CjMVJrboBtAOFQrRx3bkQ@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4FC658BF9E@ESINO.regionemarche.intra>
Message-ID: <CAHqSRuTc6U3tM=bPxUD68yg2Zf+EhuVN9FurGjkXaxYYX3HrWg@mail.gmail.com>

Your original query included
    > x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
    ... I need 8 10 13.
Did you also want the 1's at the ends to count as local maxima,
so the result would be c(1,8,10,13,17)?
Or do you want the maxima at endpoints only if there are no others?

-BIll

On Mon, Mar 29, 2021 at 8:56 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Thank you Bill, your tip solved everything.
>
> Stefano
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________________
> Da: Bill Dunlap [williamwdunlap at gmail.com]
> Inviato: luned? 29 marzo 2021 17.22
> A: Stefano Sofia
> Cc: bgunter.4567 at gmail.com; minshall at umich.edu; r-help mailing list
> Oggetto: Re: [R] local maxima positions in a vector with duplicated values
>
> If you want to accept maxima at the ends of the series, append -Inf to
> each end and subtract one from the result.  Note that this will make
> even a constant sequence have a local maximum at 1.
>
> On Mon, Mar 29, 2021 at 6:52 AM Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> >
> > Dear Bill, Bert, Greg and Abby,
> > I tested your code (honestly apart from Abby's solution because it needed an additional package and I run R in a server which is not administrated by myself), they work and I found them equivalent. (Probably Bill's and Greg's solutions are a bit faster than Bert's.)
> >
> > In my real application I found a case where none of them work: when the series is monotonic. In this case the last number of the vector (or the last duplicated numbers) is not a maximum but it is anyway the highest number of the vector:
> >
> > >x <- c(1,1,1,2,2,3,4,4,4,5,6,6,6)
> >
> > The error is: argument is of length zero.
> > Your code is at the moment too complicated for me to modify. I ask if there is an "easy" extension of the code that you kindly wrote for me to handle also this possibility.
> >
> > Thank you for everything
> > Stefano
> >
> >
> >
> >          (oo)
> > --oOO--( )--OOo--------------------------------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region - Italy
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona (AN)
> > Uff: +39 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------------------------------
> >
> > ________________________________________
> > Da: Bill Dunlap [williamwdunlap at gmail.com]
> > Inviato: venerd? 26 marzo 2021 18.40
> > A: Stefano Sofia
> > Cc: r-help mailing list
> > Oggetto: Re: [R] local maxima positions in a vector with duplicated values
> >
> > Using rle() may make it easier - finding the peak values is easier and
> > select from cumsum(lengths) to get the positions of the last values
> > before the peaks, then add 1.  I have not tested the following very
> > much.
> >
> > function(x) {
> >   rx <- rle(x)
> >   cumsum(rx$lengths)[c(diff(diff(rx$values)>0) == -1,FALSE,FALSE)]+1
> > }
> >
> > -Bill
> >
> > On Fri, Mar 26, 2021 at 8:36 AM Stefano Sofia
> > <stefano.sofia at regione.marche.it> wrote:
> > >
> > > Dear list users,
> > > I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
> > > - duplicated local maxima, I should take the position of the first duplicated value;
> > > - duplicated local minima, I should take the position of the last duplicated value.
> > >
> > > Example:
> > >
> > > >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> > > >which(diff(diff(x)>=0)<0)+1
> > >
> > > gives me 8 11 15 while I need 8 10 13;
> > >
> > > >which(diff(diff(x)>0)>0)+1
> > >
> > > gives me 4 6  9 12 16 while I need 4 9 12 16.
> > >
> > > Could you please help me in this task? I would be happier not to use additional packages.
> > >
> > > Thank you for your precious help
> > > Stefano
> > >
> > >
> > >          (oo)
> > > --oOO--( )--OOo--------------------------------------
> > > Stefano Sofia PhD
> > > Civil Protection - Marche Region - Italy
> > > Meteo Section
> > > Snow Section
> > > Via del Colle Ameno 5
> > > 60126 Torrette di Ancona, Ancona (AN)
> > > Uff: +39 071 806 7743
> > > E-mail: stefano.sofia at regione.marche.it
> > > ---Oo---------oO----------------------------------------
> > >
> > > ________________________________
> > >
> > > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> > >
> > > --
> > > Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> > > This message was scanned by Libraesva ESG and is believed to be clean.
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=5a635173&h=06ff70f3&f=y&p=y
> > > PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=5a635173&h=e12f63e8&f=y&p=y
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> >
> > Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.
> >
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> > This message was scanned by Libraesva ESG and is believed to be clean.
> >
>
> --
>
> Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Mar 29 18:18:22 2021
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 29 Mar 2021 16:18:22 +0000
Subject: [R] local maxima positions in a vector with duplicated values
In-Reply-To: <CAHqSRuTc6U3tM=bPxUD68yg2Zf+EhuVN9FurGjkXaxYYX3HrWg@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4FC658BA79@ESINO.regionemarche.intra>
 <CAHqSRuSUN-B4wJGiCG83nzU3wM2uvj2rC42osMXehqdcoBqe7A@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4FC658BF48@ESINO.regionemarche.intra>
 <CAHqSRuSusm8QPoZ3ud_=nBS9wkjc6CjMVJrboBtAOFQrRx3bkQ@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4FC658BF9E@ESINO.regionemarche.intra>,
 <CAHqSRuTc6U3tM=bPxUD68yg2Zf+EhuVN9FurGjkXaxYYX3HrWg@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4FC658BFBD@ESINO.regionemarche.intra>

Maximum at the right endpoint is well accpted in both cases. If I am correst, I just append -Inf at the right end and then I apply what you wrote.

Thank you.

         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------

________________________________________
Da: Bill Dunlap [williamwdunlap at gmail.com]
Inviato: luned? 29 marzo 2021 18.03
A: Stefano Sofia
Cc: bgunter.4567 at gmail.com; minshall at umich.edu; r-help mailing list
Oggetto: Re: [R] local maxima positions in a vector with duplicated values

Your original query included
    > x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
    ... I need 8 10 13.
Did you also want the 1's at the ends to count as local maxima,
so the result would be c(1,8,10,13,17)?
Or do you want the maxima at endpoints only if there are no others?

-BIll

On Mon, Mar 29, 2021 at 8:56 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Thank you Bill, your tip solved everything.
>
> Stefano
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________________
> Da: Bill Dunlap [williamwdunlap at gmail.com]
> Inviato: luned? 29 marzo 2021 17.22
> A: Stefano Sofia
> Cc: bgunter.4567 at gmail.com; minshall at umich.edu; r-help mailing list
> Oggetto: Re: [R] local maxima positions in a vector with duplicated values
>
> If you want to accept maxima at the ends of the series, append -Inf to
> each end and subtract one from the result.  Note that this will make
> even a constant sequence have a local maximum at 1.
>
> On Mon, Mar 29, 2021 at 6:52 AM Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> >
> > Dear Bill, Bert, Greg and Abby,
> > I tested your code (honestly apart from Abby's solution because it needed an additional package and I run R in a server which is not administrated by myself), they work and I found them equivalent. (Probably Bill's and Greg's solutions are a bit faster than Bert's.)
> >
> > In my real application I found a case where none of them work: when the series is monotonic. In this case the last number of the vector (or the last duplicated numbers) is not a maximum but it is anyway the highest number of the vector:
> >
> > >x <- c(1,1,1,2,2,3,4,4,4,5,6,6,6)
> >
> > The error is: argument is of length zero.
> > Your code is at the moment too complicated for me to modify. I ask if there is an "easy" extension of the code that you kindly wrote for me to handle also this possibility.
> >
> > Thank you for everything
> > Stefano
> >
> >
> >
> >          (oo)
> > --oOO--( )--OOo--------------------------------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region - Italy
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona (AN)
> > Uff: +39 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------------------------------
> >
> > ________________________________________
> > Da: Bill Dunlap [williamwdunlap at gmail.com]
> > Inviato: venerd? 26 marzo 2021 18.40
> > A: Stefano Sofia
> > Cc: r-help mailing list
> > Oggetto: Re: [R] local maxima positions in a vector with duplicated values
> >
> > Using rle() may make it easier - finding the peak values is easier and
> > select from cumsum(lengths) to get the positions of the last values
> > before the peaks, then add 1.  I have not tested the following very
> > much.
> >
> > function(x) {
> >   rx <- rle(x)
> >   cumsum(rx$lengths)[c(diff(diff(rx$values)>0) == -1,FALSE,FALSE)]+1
> > }
> >
> > -Bill
> >
> > On Fri, Mar 26, 2021 at 8:36 AM Stefano Sofia
> > <stefano.sofia at regione.marche.it> wrote:
> > >
> > > Dear list users,
> > > I need to find local maxima and local minima positions in a vector where there might be duplicates; in the particular in case of
> > > - duplicated local maxima, I should take the position of the first duplicated value;
> > > - duplicated local minima, I should take the position of the last duplicated value.
> > >
> > > Example:
> > >
> > > >x <- c(1,0,0,0,2,2,3,4,0,1,1,0,5,5,5,0,1)
> > > >which(diff(diff(x)>=0)<0)+1
> > >
> > > gives me 8 11 15 while I need 8 10 13;
> > >
> > > >which(diff(diff(x)>0)>0)+1
> > >
> > > gives me 4 6  9 12 16 while I need 4 9 12 16.
> > >
> > > Could you please help me in this task? I would be happier not to use additional packages.
> > >
> > > Thank you for your precious help
> > > Stefano
> > >
> > >
> > >          (oo)
> > > --oOO--( )--OOo--------------------------------------
> > > Stefano Sofia PhD
> > > Civil Protection - Marche Region - Italy
> > > Meteo Section
> > > Snow Section
> > > Via del Colle Ameno 5
> > > 60126 Torrette di Ancona, Ancona (AN)
> > > Uff: +39 071 806 7743
> > > E-mail: stefano.sofia at regione.marche.it
> > > ---Oo---------oO----------------------------------------
> > >
> > > ________________________________
> > >
> > > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> > >
> > > --
> > > Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> > > This message was scanned by Libraesva ESG and is believed to be clean.
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=5a635173&h=06ff70f3&f=y&p=y
> > > PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=5a635173&h=e12f63e8&f=y&p=y
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> >
> > Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.
> >
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> > This message was scanned by Libraesva ESG and is believed to be clean.
> >
>
> --
>
> Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>

--

Questo messaggio  stato analizzato con Libraesva ESG ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
This message was scanned by Libraesva ESG and is believed to be clean.


From m|k@@h@m@r|73 @end|ng |rom out|ook@com  Mon Mar 29 18:33:33 2021
From: m|k@@h@m@r|73 @end|ng |rom out|ook@com (Mika Hamari)
Date: Mon, 29 Mar 2021 16:33:33 +0000
Subject: [R] seed problem?
In-Reply-To: <CAHqSRuRM23pvOpNza-2NmXjzujq7PS_GADD=cjNFr4Nciw8jpA@mail.gmail.com>
References: <HE1PR0902MB205961BC5D2F17F581F0E1C9E67F9@HE1PR0902MB2059.eurprd09.prod.outlook.com>,
 <CAHqSRuRM23pvOpNza-2NmXjzujq7PS_GADD=cjNFr4Nciw8jpA@mail.gmail.com>
Message-ID: <HE1PR0902MB20595F5196ED46FA5F5DD593E67E9@HE1PR0902MB2059.eurprd09.prod.outlook.com>

Thank you Bill for your help! In other cases this surely is good thing to check, but in my case it helped earlier today that I removed .RData file according to Jeff?s answer:

?Check if you have a .RData file in your R startup directory. It may contain the seed.?

Now that this file doesn?t exist, random numbers are random.

Mika

L?hett?j?: Bill Dunlap<mailto:williamwdunlap at gmail.com>
L?hetetty: maanantai 29. maaliskuuta 2021 18.56
Vastaanottaja: Mika Hamari<mailto:mika.hamari73 at outlook.com>
Kopio: r-help at r-project.org<mailto:r-help at r-project.org>
Aihe: Re: [R] seed problem?

Does this happen if you start R with the --vanilla flag?  If so it may
be that you have a startup file, .\.Rprofile or %HOME%\.Rprofile that
is calling set.seed(n) for a fixed n.

-Bill

On Mon, Mar 29, 2021 at 12:16 AM Mika Hamari <mika.hamari73 at outlook.com> wrote:
>
> Hi!
>
> I have Windows 10 on PC and different versions of R. I noticed that when I executed simulation with R 4.0.3, it gave exactly the same results next time when I re-opened the program. I didn?t set the seed.
>
> I tested this also with simple ?rnorm(10,100,10)?, and the results were every time the same, when I re-opened the program. It seems that it starts with the same seed. R 4.0.0 and 4.0.3 did it, both with 32- and 64-bit versions. But with R Studio the results were every time different, as they were also different with 3.4.3. This explains, why I hadn?t noticed this earlier.
>
> I know the function set.seed(), but I wonder, how in the first place seed can be every time same, if you don?t set it to be. What I read about seeds, this should be very highly improbable occurence.
>
> Thanks to all developers for what they are doing for common good. I love R!
>
> Mika Hamari
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7C7b2bd48fb686441312fd08d8f2cb2f43%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526301761924646%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=mmOJg62ljt3x2Adp60HLHJqdg%2FtDS6EaW%2B%2ByfcEsimk%3D&amp;reserved=0
> PLEASE do read the posting guide https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7C7b2bd48fb686441312fd08d8f2cb2f43%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526301761924646%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=mitEm6LuTLS7fPrSlsVGYvn5gyU2hNCXy70gqqp9DJc%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From m|k@@h@m@r|73 @end|ng |rom out|ook@com  Mon Mar 29 19:44:27 2021
From: m|k@@h@m@r|73 @end|ng |rom out|ook@com (Mika Hamari)
Date: Mon, 29 Mar 2021 17:44:27 +0000
Subject: [R] "for" loop does not work with my plot_ly command
In-Reply-To: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
References: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
Message-ID: <HE1PR0902MB20590B8BFDBA7614A0D5CAD8E67E9@HE1PR0902MB2059.eurprd09.prod.outlook.com>

Hi!

I am also learning, but I want try to help. I often use for-loop in R. I think that it could be due to dimensions of CPM, not the structure of the loop.

What kind of error message do you get? Is it: ?incorrect number of dimensions?? What happens if you substitute in the end instead of CPM[i,1] this:

file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i],".png",sep="")

L?hett?j?: Rachida El Ouaraini<mailto:elouaraini at gmail.com>
L?hetetty: maanantai 29. maaliskuuta 2021 18.15
Vastaanottaja: r-help at r-project.org<mailto:r-help at r-project.org>
Aihe: [R] "for" loop does not work with my plot_ly command

Hi everyone,
I am new to R programming, and I am having difficulties modifying an R
script to introduce the "for" loop in the code.
While searching I found that this issue has already been raised, but I did
not know what to do to fix mine !

*The code that works (without for command):*

CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
",", skip = 0)
# The CPM.txt file containe 1 line
......................................................................
......................................................................
options(viewer = NULL)
plot_ly() %>%
 htmlwidgets::onRender(
   "function(el, x) {
     var gd = document.getElementById(el.id);
     Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
filename: 'AnomalieRR_EcartTmoy'});
   }"
 )%>%
 add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
%>%
add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
list(color = "white", size = 14),  showarrow = FALSE)%>%
 layout(title = paste("Combinaison anomalie relative annuelle des
pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
",CPM[1,1],sep =""),
      xaxis = list(title = "Anomalie relative des pr?cipitations
annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
, family = 'Arial'), tickfont = list(color = "blue", size = 14)),
yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
'Arial'),
tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
"red", linewidth = 2),
   legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
"black")),margin = list(
      t = 70,
     r = 70,
      b = 70,
      l = 70
    ))
*The code that does not work (with for command):*
CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
",", skip = 0)
# The CPM.txt file containe several lines

*for (i in 1: (nrow(CPM)))   {*

options(viewer = NULL)
plot_ly() %>%
 htmlwidgets::onRender(
   "function(el, x) {
     var gd = document.getElementById(el.id);
     Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
filename: 'AnomalieRR_EcartTmoy'});
   }"
 )%>%
 add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
%>%
add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
list(color = "white", size = 14),  showarrow = FALSE)%>%
  layout(title = paste("Combinaison anomalie relative annuelle des
pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
",CPM[i,1],sep =""),
      xaxis = list(title = "Anomalie relative des pr?cipitations
annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
, family = 'Arial'), tickfont = list(color = "blue", size = 14)),
yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
'Arial'),
tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
"red", linewidth = 2),
  legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
"black")),margin = list(
      t = 70,
     r = 70,
      b = 70,
      l = 70
    ))

*file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i,1],".png",sep="")*
*}*


Thank you very much in advance for any help.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=wwtfLAGJ3zjOzN%2FDxopVDEVnLC5QSF6H1ER6nHMEaLI%3D&amp;reserved=0
PLEASE do read the posting guide https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=nqKgiTsjQz%2FjF5gDRc1UMQiSxRdZCurArqyGz5pnNtg%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Mar 29 22:57:54 2021
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 30 Mar 2021 09:57:54 +1300
Subject: [R] Spie charts
In-Reply-To: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
References: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
Message-ID: <CAB8pepzXRK7U77mnxDHUrfw0E3--TF247gtbMZhdz42WvWt1Sg@mail.gmail.com>

I couldn't find a predefined function for this purpose.
However, it wouldn't be too difficult to write a pair of functions.

The big question is how flexible does the rendering function need to be?

#plot from angles, distances, etc
#(angles on arbitrary scale)
spiechart.render <- function (
    angle=1, distance, ...,
    circd= stdd, labd = 1.25 * stdd,
    main="", labs="", line.col="black", area.col="white",
    stdd = mean (distance) )
{   n <- length (distance)
    angle <- rep_len (angle, n)
    angle <- 2 * pi * angle / sum (angle)
    <rest of code>
}

#compute angles and distances, from data
#(then call rendering function)
spiechart <- function (
    <rest of code>
    spiechart.render (angle, distance, ...)
}

Partially off-topic remarks:
I know there's some criticism of this approach.
However, the OP never stated the purpose.
And this approach could be useful in some cases.
Say for modelling certain ecological or weather events.
Where for each event, there's a categorical date (such as month) and a
magnitude/etc.
And then, in the top level function from above, the angles and
distances would be the result of aggregation functions.


On Mon, Mar 29, 2021 at 4:59 AM Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
> Dear ?,
> Ist there a function to plot "spie charts" in R?
> https://en.wikipedia.org/wiki/spie_chart
> (These are a combination of pie charts and radial pie charts, where the angle represents one dimension and the radius of the respective sector another dimension)
> Thank you in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@hmood@n@der@n @end|ng |rom ugent@be  Mon Mar 29 23:19:33 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Mon, 29 Mar 2021 21:19:33 +0000
Subject: [R] Colorizing different individuals with fviz
In-Reply-To: <CA+8X3fW5_KVooVHvY=L75guEw0b=EvfBXmvGKLFYyjiAmi1QiA@mail.gmail.com>
References: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>,
 <CA+8X3fW5_KVooVHvY=L75guEw0b=EvfBXmvGKLFYyjiAmi1QiA@mail.gmail.com>
Message-ID: <60bd53898c9d4e1bb2ba53583c0f46bf@ugent.be>

Hi Jim,

It seems that the following proposed method doesn't work


ind <- get_famd_ind(res.famd)
fviz_famd_ind(res.famd,
              col=ifelse(x>10,"red","black"),
              repel = TRUE)


Result is:


Error in fviz_famd_ind(res.famd, col = ifelse(x > 10, "red", "black"),  :
  argument 2 matches multiple formal arguments



Any idea to fix that?

Regards,
Mahmood

________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Saturday, March 27, 2021 9:19:23 PM
To: Mahmood Naderan-Tahan
Cc: r-help at r-project.org
Subject: Re: [R] Colorizing different individuals with fviz

Hi Mahmood,
What you have specified can be done with:

col=c(rep("black",10),rep("red",10))

depending upon what print function you are using. I suspect that this
may be based on a value in your data. For example, if you want  black
for values of some variable up to 10 and red for those over:

col=ifelse(x>10,"red","black)

Jim

On Sun, Mar 28, 2021 at 12:20 AM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi
>
> I use this command to generate a graph of individuals
>
>
> ind <- get_famd_ind(res.famd)
> fviz_famd_ind(res.famd, repel = TRUE)
>
>
> I would like to know how can I specify different colors for different individuals?
>
> The colorization is not very complex. Basically, I want to specify rows[1:10] to be shown in black and rows[11:20] to be shown in red.
>
>
> Any idea about that?
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Mar 29 23:25:30 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 29 Mar 2021 14:25:30 -0700
Subject: [R] Colorizing different individuals with fviz
In-Reply-To: <60bd53898c9d4e1bb2ba53583c0f46bf@ugent.be>
References: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>
 <CA+8X3fW5_KVooVHvY=L75guEw0b=EvfBXmvGKLFYyjiAmi1QiA@mail.gmail.com>
 <60bd53898c9d4e1bb2ba53583c0f46bf@ugent.be>
Message-ID: <CAHqSRuSsaP0eDqzTWSfQ5NHAv3Wo=cJchAPGAnY1uXFAq6qJCg@mail.gmail.com>

That error means that fviz_famd_ind has more than one argument that
starts with 'col' and you must type a more complete name to
disambiguate it.  Perhaps col.ind=ifelse(...)?

> args(factoextra::fviz_famd_ind)
function (X, axes = c(1, 2), geom = c("point", "text"),
    repel = FALSE, habillage = "none", palette = NULL,
    addEllipses = FALSE, col.ind = "blue", col.ind.sup = "darkblue",
    alpha.ind = 1, shape.ind = 19, col.quali.var = "black",
    select.ind = list(name = NULL, cos2 = NULL, contrib = NULL),
    gradient.cols = NULL, ...)

On Mon, Mar 29, 2021 at 2:20 PM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi Jim,
>
> It seems that the following proposed method doesn't work
>
>
> ind <- get_famd_ind(res.famd)
> fviz_famd_ind(res.famd,
>               col=ifelse(x>10,"red","black"),
>               repel = TRUE)
>
>
> Result is:
>
>
> Error in fviz_famd_ind(res.famd, col = ifelse(x > 10, "red", "black"),  :
>   argument 2 matches multiple formal arguments
>
>
>
> Any idea to fix that?
>
> Regards,
> Mahmood
>
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Saturday, March 27, 2021 9:19:23 PM
> To: Mahmood Naderan-Tahan
> Cc: r-help at r-project.org
> Subject: Re: [R] Colorizing different individuals with fviz
>
> Hi Mahmood,
> What you have specified can be done with:
>
> col=c(rep("black",10),rep("red",10))
>
> depending upon what print function you are using. I suspect that this
> may be based on a value in your data. For example, if you want  black
> for values of some variable up to 10 and red for those over:
>
> col=ifelse(x>10,"red","black)
>
> Jim
>
> On Sun, Mar 28, 2021 at 12:20 AM Mahmood Naderan-Tahan
> <mahmood.naderan at ugent.be> wrote:
> >
> > Hi
> >
> > I use this command to generate a graph of individuals
> >
> >
> > ind <- get_famd_ind(res.famd)
> > fviz_famd_ind(res.famd, repel = TRUE)
> >
> >
> > I would like to know how can I specify different colors for different individuals?
> >
> > The colorization is not very complex. Basically, I want to specify rows[1:10] to be shown in black and rows[11:20] to be shown in red.
> >
> >
> > Any idea about that?
> >
> >
> > Regards,
> > Mahmood
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chettyvk @end|ng |rom gm@||@com  Mon Mar 29 23:28:51 2021
From: chettyvk @end|ng |rom gm@||@com (Veerappa Chetty)
Date: Mon, 29 Mar 2021 17:28:51 -0400
Subject: [R] using eigen function in MAP and purr
Message-ID: <CAFpsATa-z3j-iLq+M9xozToifm_Qc_--S1j_pvSaZzPfFWorsA@mail.gmail.com>

I want to use map and purr functions to compute eigen values for 3000
matrices. Each matrix has 2 rows and 2 columns. The following code does not
work.

test.dat<- tibble(ID=c(1,2),a=c(1,1),b=c(1,1),c=c(2,2),d=c(4,3))

test.out<-test.dat %>% nest(-ID) %>% mutate(fit = purrr::map(data,~
function(x) eigen(matrix(x,2,2)), data=.))

This must be a trivial question for current young practitioners ( In my 9
th decade, I am having fun using R markdown and I am trying to continue my
research!) I would greatly appreciate any help.
Thanks.
V.K.Chetty
-- 
Professor of Family Medicine
Boston University

	[[alternative HTML version deleted]]


From m@hmood@n@der@n @end|ng |rom ugent@be  Mon Mar 29 23:33:11 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Mon, 29 Mar 2021 21:33:11 +0000
Subject: [R] Colorizing different individuals with fviz
In-Reply-To: <CAHqSRuSsaP0eDqzTWSfQ5NHAv3Wo=cJchAPGAnY1uXFAq6qJCg@mail.gmail.com>
References: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>
 <CA+8X3fW5_KVooVHvY=L75guEw0b=EvfBXmvGKLFYyjiAmi1QiA@mail.gmail.com>
 <60bd53898c9d4e1bb2ba53583c0f46bf@ugent.be>,
 <CAHqSRuSsaP0eDqzTWSfQ5NHAv3Wo=cJchAPGAnY1uXFAq6qJCg@mail.gmail.com>
Message-ID: <ca96c67f839046b0b603cc65457054f0@ugent.be>

I understand that I came across this error after that


ind <- get_famd_ind(res.famd)
fviz_famd_ind(res.famd,
              col.ind = ifelse(ind>10,"red","black"),
              repel = TRUE)


Error in ifelse(ind > 10, "red", "black") :
  'list' object cannot be coerced to type 'double'
Calls: fviz_famd_ind -> %in% -> ifelse



I guess ind has (x,y) type and hence "ind>10" is not valid.

I also tried


col.ind = ifelse(ind.x>10,"red","black"),


But got the same error.

Any idea about that?



Regards,
Mahmood

________________________________
From: Bill Dunlap <williamwdunlap at gmail.com>
Sent: Monday, March 29, 2021 11:25:30 PM
To: Mahmood Naderan-Tahan
Cc: Jim Lemon; r-help at r-project.org
Subject: Re: [R] Colorizing different individuals with fviz

That error means that fviz_famd_ind has more than one argument that
starts with 'col' and you must type a more complete name to
disambiguate it.  Perhaps col.ind=ifelse(...)?

> args(factoextra::fviz_famd_ind)
function (X, axes = c(1, 2), geom = c("point", "text"),
    repel = FALSE, habillage = "none", palette = NULL,
    addEllipses = FALSE, col.ind = "blue", col.ind.sup = "darkblue",
    alpha.ind = 1, shape.ind = 19, col.quali.var = "black",
    select.ind = list(name = NULL, cos2 = NULL, contrib = NULL),
    gradient.cols = NULL, ...)

On Mon, Mar 29, 2021 at 2:20 PM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> Hi Jim,
>
> It seems that the following proposed method doesn't work
>
>
> ind <- get_famd_ind(res.famd)
> fviz_famd_ind(res.famd,
>               col=ifelse(x>10,"red","black"),
>               repel = TRUE)
>
>
> Result is:
>
>
> Error in fviz_famd_ind(res.famd, col = ifelse(x > 10, "red", "black"),  :
>   argument 2 matches multiple formal arguments
>
>
>
> Any idea to fix that?
>
> Regards,
> Mahmood
>
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Saturday, March 27, 2021 9:19:23 PM
> To: Mahmood Naderan-Tahan
> Cc: r-help at r-project.org
> Subject: Re: [R] Colorizing different individuals with fviz
>
> Hi Mahmood,
> What you have specified can be done with:
>
> col=c(rep("black",10),rep("red",10))
>
> depending upon what print function you are using. I suspect that this
> may be based on a value in your data. For example, if you want  black
> for values of some variable up to 10 and red for those over:
>
> col=ifelse(x>10,"red","black)
>
> Jim
>
> On Sun, Mar 28, 2021 at 12:20 AM Mahmood Naderan-Tahan
> <mahmood.naderan at ugent.be> wrote:
> >
> > Hi
> >
> > I use this command to generate a graph of individuals
> >
> >
> > ind <- get_famd_ind(res.famd)
> > fviz_famd_ind(res.famd, repel = TRUE)
> >
> >
> > I would like to know how can I specify different colors for different individuals?
> >
> > The colorization is not very complex. Basically, I want to specify rows[1:10] to be shown in black and rows[11:20] to be shown in red.
> >
> >
> > Any idea about that?
> >
> >
> > Regards,
> > Mahmood
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Mar 30 00:53:27 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 29 Mar 2021 18:53:27 -0400
Subject: [R] using eigen function in MAP and purr
In-Reply-To: <8600_1617053434_12TLUXK1030775_CAFpsATa-z3j-iLq+M9xozToifm_Qc_--S1j_pvSaZzPfFWorsA@mail.gmail.com>
References: <8600_1617053434_12TLUXK1030775_CAFpsATa-z3j-iLq+M9xozToifm_Qc_--S1j_pvSaZzPfFWorsA@mail.gmail.com>
Message-ID: <3247fcf1-1b1b-fb60-3a97-4c7ef4bc5b76@mcmaster.ca>

Dear V. K. Chetty,

Perhaps I'm missing something but why wouldn't you just use a list of 
matrices, as in the following?

---------- snip ---------

 > set.seed(123) # for reproducibility

 > (Matrices <- lapply(1:3, function(i) matrix(sample(1:50, 4), 2, 2)))

[[1]]
      [,1] [,2]
[1,]   31   14
[2,]   15    3

[[2]]
      [,1] [,2]
[1,]   42   37
[2,]   43   14

[[3]]
      [,1] [,2]
[1,]   25   27
[2,]   26    5

 > (Eigenvalues <- lapply(Matrices, function(x) eigen(x, 
only.values=TRUE)$values))

[[1]]
[1] 37.149442 -3.149442

[[2]]
[1]  70.27292 -14.27292

[[3]]
[1]  43.3196 -13.3196

---------- snip ---------

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-03-29 5:28 p.m., Veerappa Chetty wrote:
> I want to use map and purr functions to compute eigen values for 3000
> matrices. Each matrix has 2 rows and 2 columns. The following code does not
> work.
> 
> test.dat<- tibble(ID=c(1,2),a=c(1,1),b=c(1,1),c=c(2,2),d=c(4,3))
> 
> test.out<-test.dat %>% nest(-ID) %>% mutate(fit = purrr::map(data,~
> function(x) eigen(matrix(x,2,2)), data=.))
> 
> This must be a trivial question for current young practitioners ( In my 9
> th decade, I am having fun using R markdown and I am trying to continue my
> research!) I would greatly appreciate any help.
> Thanks.
> V.K.Chetty
>


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 30 01:28:53 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 30 Mar 2021 10:28:53 +1100
Subject: [R] Spie charts
In-Reply-To: <CAB8pepzXRK7U77mnxDHUrfw0E3--TF247gtbMZhdz42WvWt1Sg@mail.gmail.com>
References: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
 <CAB8pepzXRK7U77mnxDHUrfw0E3--TF247gtbMZhdz42WvWt1Sg@mail.gmail.com>
Message-ID: <CA+8X3fVzSmHH3PYC=PwYAQDXh26HMEkdLbGBvZsy_LTcp3HY-w@mail.gmail.com>

Hi Abby,
Have a look at the first example in the radial.pie function (plotrix).

Jim

On Tue, Mar 30, 2021 at 7:59 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I couldn't find a predefined function for this purpose.
> However, it wouldn't be too difficult to write a pair of functions.
>
> The big question is how flexible does the rendering function need to be?
>
> #plot from angles, distances, etc
> #(angles on arbitrary scale)
> spiechart.render <- function (
>     angle=1, distance, ...,
>     circd= stdd, labd = 1.25 * stdd,
>     main="", labs="", line.col="black", area.col="white",
>     stdd = mean (distance) )
> {   n <- length (distance)
>     angle <- rep_len (angle, n)
>     angle <- 2 * pi * angle / sum (angle)
>     <rest of code>
> }
>
> #compute angles and distances, from data
> #(then call rendering function)
> spiechart <- function (
>     <rest of code>
>     spiechart.render (angle, distance, ...)
> }
>
> Partially off-topic remarks:
> I know there's some criticism of this approach.
> However, the OP never stated the purpose.
> And this approach could be useful in some cases.
> Say for modelling certain ecological or weather events.
> Where for each event, there's a categorical date (such as month) and a
> magnitude/etc.
> And then, in the top level function from above, the angles and
> distances would be the result of aggregation functions.
>
>
> On Mon, Mar 29, 2021 at 4:59 AM Ferri Leberl <ferri.leberl at gmx.at> wrote:
> >
> > Dear ?,
> > Ist there a function to plot "spie charts" in R?
> > https://en.wikipedia.org/wiki/spie_chart
> > (These are a combination of pie charts and radial pie charts, where the angle represents one dimension and the radius of the respective sector another dimension)
> > Thank you in advance!
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rce|o|@|@ @end|ng |rom gm@||@com  Tue Mar 30 02:17:48 2021
From: m@rce|o|@|@ @end|ng |rom gm@||@com (Marcelo Laia)
Date: Mon, 29 Mar 2021 21:17:48 -0300
Subject: [R] Word cloud based on a specific site
Message-ID: <YGJuLMHDauCI5x6r@localhost>

Hi,

I would like to do a word cloud in a specif site related to a specific
word.

For example, I could be interested in discovery what are the words
linked to word "tree" in a site like www.foo.bar and have the result in
a wordcloud image.

Please, someone could me point me out a package or a bibliography or
tutorial or somethings else?

Thank you so much!

-- 
Marcelo


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 30 04:12:11 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 30 Mar 2021 13:12:11 +1100
Subject: [R] Word cloud based on a specific site
In-Reply-To: <YGJuLMHDauCI5x6r@localhost>
References: <YGJuLMHDauCI5x6r@localhost>
Message-ID: <CA+8X3fViehjVU8QLt8MRq4e-5BiKV0NtdJakBGP_QVds5Wns0w@mail.gmail.com>

Hi Marcelo,
Just google for "word cloud r". Too much information.

Jim

On Tue, Mar 30, 2021 at 11:18 AM Marcelo Laia <marcelolaia at gmail.com> wrote:
>
> Hi,
>
> I would like to do a word cloud in a specif site related to a specific
> word.
>
> For example, I could be interested in discovery what are the words
> linked to word "tree" in a site like www.foo.bar and have the result in
> a wordcloud image.
>
> Please, someone could me point me out a package or a bibliography or
> tutorial or somethings else?
>
> Thank you so much!
>
> --
> Marcelo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Mar 30 04:16:09 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 29 Mar 2021 19:16:09 -0700
Subject: [R] Word cloud based on a specific site
In-Reply-To: <CA+8X3fViehjVU8QLt8MRq4e-5BiKV0NtdJakBGP_QVds5Wns0w@mail.gmail.com>
References: <YGJuLMHDauCI5x6r@localhost>
 <CA+8X3fViehjVU8QLt8MRq4e-5BiKV0NtdJakBGP_QVds5Wns0w@mail.gmail.com>
Message-ID: <CAGxFJbQPQRBesNnuXGFzo3BXro4bGXH7bdsu7MNao9bi5A6gmA@mail.gmail.com>

Also (I think):
https://cran.r-project.org/web/views/NaturalLanguageProcessing.html
(get to know the CRAN resources!).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 29, 2021 at 7:12 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Marcelo,
> Just google for "word cloud r". Too much information.
>
> Jim
>
> On Tue, Mar 30, 2021 at 11:18 AM Marcelo Laia <marcelolaia at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I would like to do a word cloud in a specif site related to a specific
> > word.
> >
> > For example, I could be interested in discovery what are the words
> > linked to word "tree" in a site like www.foo.bar and have the result in
> > a wordcloud image.
> >
> > Please, someone could me point me out a package or a bibliography or
> > tutorial or somethings else?
> >
> > Thank you so much!
> >
> > --
> > Marcelo
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 30 04:36:55 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 30 Mar 2021 13:36:55 +1100
Subject: [R] "for" loop does not work with my plot_ly command
In-Reply-To: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
References: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
Message-ID: <CA+8X3fVU4HBfo2oCzKgmX15XNSvXVw4CJ0PL0ZF7WffYfc+YOg@mail.gmail.com>

Hi Rachida,
My guess is that you create a vector of filenames:

filenames<-list.files(path="FicConfig",pattern="*.txt")

then use the filenames in the loop:

for(filename in filenames) {
 nextfile<- read.table(filename, header = TRUE, sep = "\t" , dec =
 ",", skip = 0)
 # do whatever you want with the resulting data frame here
 # or perhaps save it into a list for processing later
}

Jim

On Tue, Mar 30, 2021 at 2:15 AM Rachida El Ouaraini
<elouaraini at gmail.com> wrote:
>
> Hi everyone,
> I am new to R programming, and I am having difficulties modifying an R
> script to introduce the "for" loop in the code.
> While searching I found that this issue has already been raised, but I did
> not know what to do to fix mine !
>
> *The code that works (without for command):*
>
> CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> ",", skip = 0)
> # The CPM.txt file containe 1 line
> ......................................................................
> ......................................................................
> options(viewer = NULL)
> plot_ly() %>%
>  htmlwidgets::onRender(
>    "function(el, x) {
>      var gd = document.getElementById(el.id);
>      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> filename: 'AnomalieRR_EcartTmoy'});
>    }"
>  )%>%
>  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
> %>%
> add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> list(color = "white", size = 14),  showarrow = FALSE)%>%
>  layout(title = paste("Combinaison anomalie relative annuelle des
> pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> ",CPM[1,1],sep =""),
>       xaxis = list(title = "Anomalie relative des pr?cipitations
> annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
> , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> 'Arial'),
> tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> "red", linewidth = 2),
>    legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> "black")),margin = list(
>       t = 70,
>      r = 70,
>       b = 70,
>       l = 70
>     ))
> *The code that does not work (with for command):*
> CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> ",", skip = 0)
> # The CPM.txt file containe several lines
>
> *for (i in 1: (nrow(CPM)))   {*
>
> options(viewer = NULL)
> plot_ly() %>%
>  htmlwidgets::onRender(
>    "function(el, x) {
>      var gd = document.getElementById(el.id);
>      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> filename: 'AnomalieRR_EcartTmoy'});
>    }"
>  )%>%
>  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
> %>%
> add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> list(color = "white", size = 14),  showarrow = FALSE)%>%
>   layout(title = paste("Combinaison anomalie relative annuelle des
> pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> ",CPM[i,1],sep =""),
>       xaxis = list(title = "Anomalie relative des pr?cipitations
> annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
> , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> 'Arial'),
> tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> "red", linewidth = 2),
>   legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> "black")),margin = list(
>       t = 70,
>      r = 70,
>       b = 70,
>       l = 70
>     ))
>
> *file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
> paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i,1],".png",sep="")*
> *}*
>
>
> Thank you very much in advance for any help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 30 10:58:22 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 30 Mar 2021 19:58:22 +1100
Subject: [R] Spie charts
In-Reply-To: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
References: <trinity-5049e272-cfad-42a2-acf5-7b69c18c14ca-1616947141164@3c-app-gmx-bs43>
Message-ID: <CA+8X3fUZyMDk_xeeOEKAOn2LoRG9nB2Rr5TSx4ODc3-sfrhEVg@mail.gmail.com>

Hi Ferri,
Just for fun, I plotted six countries with the current COVID deaths,
per million against both population and median income. Even I was
surprised.

library(plotrix)
country<-c("USA","Brazil","India","UK","Czechia","Mexico")
COVIDdeath<-c(1694,1471,117,1858,2445,1553)
Countrypop<-c(332,214,1390,68,11,130)
poprad<-rescale(cumsum(c(0,Countrypop)),c(0,2*pi))
median_income<-c(65850,9130,2120,42220,21940,9480)
png("COVID_death_by_pop.png")
radial.pie(radial.extents=COVIDdeath,
 sector.edges=poprad,
 sector.colors=color.scale(median_income,extremes=c("red","green")),
 labels=country,radial.lim=c(0,2500))
color.legend(xl=-2600,yb=-2600,xr=500,yt=-2500,
 legend=seq(2000,66000,length.out=5),
 rect.col=color.scale(seq(2000,66000,length.out=5),extremes=c("red","green")))
text(0,2850,"COVID deaths per million population",xpd=TRUE)
text(-1095,-2700,"Median income USD",xpd=TRUE)
text(2000,-2600,"Sector angle = population",xpd=TRUE)
dev.off()


Jim

On Mon, Mar 29, 2021 at 2:59 AM Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
> Dear ?,
> Ist there a function to plot "spie charts" in R?
> https://en.wikipedia.org/wiki/spie_chart
> (These are a combination of pie charts and radial pie charts, where the angle represents one dimension and the radius of the respective sector another dimension)
> Thank you in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: COVID_death_by_pop.png
Type: image/png
Size: 40304 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210330/99e3e90a/attachment.png>

From e|ou@r@|n| @end|ng |rom gm@||@com  Tue Mar 30 11:25:30 2021
From: e|ou@r@|n| @end|ng |rom gm@||@com (Rachida El Ouaraini)
Date: Tue, 30 Mar 2021 11:25:30 +0200
Subject: [R] "for" loop does not work with my plot_ly command
In-Reply-To: <HE1PR0902MB20590B8BFDBA7614A0D5CAD8E67E9@HE1PR0902MB2059.eurprd09.prod.outlook.com>
References: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
 <HE1PR0902MB20590B8BFDBA7614A0D5CAD8E67E9@HE1PR0902MB2059.eurprd09.prod.outlook.com>
Message-ID: <CAAkw+D79idB8Y-BJToAatuAiYUazvi_QSzxgJBKrCCajVZt_EA@mail.gmail.com>

Hi Mika,
and thank you very much for your answer.
When I add the "for" loop to the code that produces before the graph I
want, it does nothing :
NO graph and NO error message.
It seems to me that the command plot_ly and the for loop DO NOT coexist.

Rachida

On Mon, Mar 29, 2021 at 7:44 PM Mika Hamari <mika.hamari73 at outlook.com>
wrote:

> Hi!
>
>
>
> I am also learning, but I want try to help. I often use for-loop in R. I
> think that it could be due to dimensions of CPM, not the structure of the
> loop.
>
>
>
> What kind of error message do you get? Is it: ?incorrect number of
> dimensions?? What happens if you substitute in the end instead of CPM[i,1]
> this:
>
>
>
> file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
> paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i],".png",sep="")
>
>
>
> *L?hett?j?: *Rachida El Ouaraini <elouaraini at gmail.com>
> *L?hetetty: *maanantai 29. maaliskuuta 2021 18.15
> *Vastaanottaja: *r-help at r-project.org
> *Aihe: *[R] "for" loop does not work with my plot_ly command
>
>
>
> Hi everyone,
> I am new to R programming, and I am having difficulties modifying an R
> script to introduce the "for" loop in the code.
> While searching I found that this issue has already been raised, but I did
> not know what to do to fix mine !
>
> *The code that works (without for command):*
>
> CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> ",", skip = 0)
> # The CPM.txt file containe 1 line
> ......................................................................
> ......................................................................
> options(viewer = NULL)
> plot_ly() %>%
>  htmlwidgets::onRender(
>    "function(el, x) {
>      var gd = document.getElementById(el.id);
>      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> filename: 'AnomalieRR_EcartTmoy'});
>    }"
>  )%>%
>  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
> %>%
> add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> list(color = "white", size = 14),  showarrow = FALSE)%>%
>  layout(title = paste("Combinaison anomalie relative annuelle des
> pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> ",CPM[1,1],sep =""),
>       xaxis = list(title = "Anomalie relative des pr?cipitations
> annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
> , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> 'Arial'),
> tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> "red", linewidth = 2),
>    legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> "black")),margin = list(
>       t = 70,
>      r = 70,
>       b = 70,
>       l = 70
>     ))
> *The code that does not work (with for command):*
> CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> ",", skip = 0)
> # The CPM.txt file containe several lines
>
> *for (i in 1: (nrow(CPM)))   {*
>
> options(viewer = NULL)
> plot_ly() %>%
>  htmlwidgets::onRender(
>    "function(el, x) {
>      var gd = document.getElementById(el.id);
>      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> filename: 'AnomalieRR_EcartTmoy'});
>    }"
>  )%>%
>  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
> %>%
> add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> list(color = "white", size = 14),  showarrow = FALSE)%>%
>   layout(title = paste("Combinaison anomalie relative annuelle des
> pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> ",CPM[i,1],sep =""),
>       xaxis = list(title = "Anomalie relative des pr?cipitations
> annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
> , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> 'Arial'),
> tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> "red", linewidth = 2),
>   legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> "black")),margin = list(
>       t = 70,
>      r = 70,
>       b = 70,
>       l = 70
>     ))
>
> *file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
> paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i,1],".png",sep="")*
> *}*
>
>
> Thank you very much in advance for any help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=wwtfLAGJ3zjOzN%2FDxopVDEVnLC5QSF6H1ER6nHMEaLI%3D&amp;reserved=0
> PLEASE do read the posting guide
> https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=nqKgiTsjQz%2FjF5gDRc1UMQiSxRdZCurArqyGz5pnNtg%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
*Best Regards, *
*Cordialement, ?? ???? ?????? *

Rachida EL OUARAINI
Service de la R?alisation des Mod?les Appliqu?s et de la T?l?d?tection
Direction de la M?t?orologie Nationale du Maroc
*T?l : +212 522 65 48 90*
*Fax: +212 522 91 34 35*

*"Your attitude, not your aptitude, will determine your altitude." Zig
Ziglar*

	[[alternative HTML version deleted]]


From e|ou@r@|n| @end|ng |rom gm@||@com  Tue Mar 30 11:29:13 2021
From: e|ou@r@|n| @end|ng |rom gm@||@com (Rachida El Ouaraini)
Date: Tue, 30 Mar 2021 11:29:13 +0200
Subject: [R] "for" loop does not work with my plot_ly command
In-Reply-To: <CA+8X3fVU4HBfo2oCzKgmX15XNSvXVw4CJ0PL0ZF7WffYfc+YOg@mail.gmail.com>
References: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
 <CA+8X3fVU4HBfo2oCzKgmX15XNSvXVw4CJ0PL0ZF7WffYfc+YOg@mail.gmail.com>
Message-ID: <CAAkw+D582UGo5m=8y+bo24s9aNLgGTDahssuLeZNe0e8WZvyCQ@mail.gmail.com>

Hi Jim,
Many thanks for your answer !
I tried what you suggested but it doesn't work.
I've got NO error message, but nothing happens at the end : no graphs !
It seems to me that the command "plot_ly" and the "for" loop DO NOT
coexist, that's why I ask you how to overcome this problem?
Thank you again Dr Jim.

On Tue, Mar 30, 2021 at 4:37 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Rachida,
> My guess is that you create a vector of filenames:
>
> filenames<-list.files(path="FicConfig",pattern="*.txt")
>
> then use the filenames in the loop:
>
> for(filename in filenames) {
>  nextfile<- read.table(filename, header = TRUE, sep = "\t" , dec =
>  ",", skip = 0)
>  # do whatever you want with the resulting data frame here
>  # or perhaps save it into a list for processing later
> }
>
> Jim
>
> On Tue, Mar 30, 2021 at 2:15 AM Rachida El Ouaraini
> <elouaraini at gmail.com> wrote:
> >
> > Hi everyone,
> > I am new to R programming, and I am having difficulties modifying an R
> > script to introduce the "for" loop in the code.
> > While searching I found that this issue has already been raised, but I
> did
> > not know what to do to fix mine !
> >
> > *The code that works (without for command):*
> >
> > CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> > ",", skip = 0)
> > # The CPM.txt file containe 1 line
> > ......................................................................
> > ......................................................................
> > options(viewer = NULL)
> > plot_ly() %>%
> >  htmlwidgets::onRender(
> >    "function(el, x) {
> >      var gd = document.getElementById(el.id);
> >      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> > filename: 'AnomalieRR_EcartTmoy'});
> >    }"
> >  )%>%
> >  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> > Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> > symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color =
> cl)))
> > %>%
> > add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> > list(color = "white", size = 14),  showarrow = FALSE)%>%
> >  layout(title = paste("Combinaison anomalie relative annuelle des
> > pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> > ",CPM[1,1],sep =""),
> >       xaxis = list(title = "Anomalie relative des pr?cipitations
> > annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size=
> 14
> > , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> > yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> > annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> > 'Arial'),
> > tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> > "red", linewidth = 2),
> >    legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> > "black")),margin = list(
> >       t = 70,
> >      r = 70,
> >       b = 70,
> >       l = 70
> >     ))
> > *The code that does not work (with for command):*
> > CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> > ",", skip = 0)
> > # The CPM.txt file containe several lines
> >
> > *for (i in 1: (nrow(CPM)))   {*
> >
> > options(viewer = NULL)
> > plot_ly() %>%
> >  htmlwidgets::onRender(
> >    "function(el, x) {
> >      var gd = document.getElementById(el.id);
> >      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> > filename: 'AnomalieRR_EcartTmoy'});
> >    }"
> >  )%>%
> >  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> > Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> > symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color =
> cl)))
> > %>%
> > add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> > list(color = "white", size = 14),  showarrow = FALSE)%>%
> >   layout(title = paste("Combinaison anomalie relative annuelle des
> > pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> > ",CPM[i,1],sep =""),
> >       xaxis = list(title = "Anomalie relative des pr?cipitations
> > annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size=
> 14
> > , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> > yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> > annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> > 'Arial'),
> > tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> > "red", linewidth = 2),
> >   legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> > "black")),margin = list(
> >       t = 70,
> >      r = 70,
> >       b = 70,
> >       l = 70
> >     ))
> >
> > *file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
> > paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i,1],".png",sep="")*
> > *}*
> >
> >
> > Thank you very much in advance for any help.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Best Regards, *
*Cordialement, ?? ???? ?????? *

Rachida EL OUARAINI
Service de la R?alisation des Mod?les Appliqu?s et de la T?l?d?tection
Direction de la M?t?orologie Nationale du Maroc
*T?l : +212 522 65 48 90*
*Fax: +212 522 91 34 35*

*?"Your attitude, not your aptitude, will determine your altitude." ?Zig
Ziglar*

	[[alternative HTML version deleted]]


From m@hmood@n@der@n @end|ng |rom ugent@be  Tue Mar 30 11:32:22 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Tue, 30 Mar 2021 09:32:22 +0000
Subject: [R] Colorizing different individuals with fviz
In-Reply-To: <CA+8X3fXiatTriF2Qit=rP1skLsbsb-WEfDZ9M-hpf6Dqwk=8Vg@mail.gmail.com>
References: <3fdfe0055c1441a9ac99b4b4e55e8251@ugent.be>
 <CA+8X3fW5_KVooVHvY=L75guEw0b=EvfBXmvGKLFYyjiAmi1QiA@mail.gmail.com>
 <60bd53898c9d4e1bb2ba53583c0f46bf@ugent.be>
 <CAHqSRuSsaP0eDqzTWSfQ5NHAv3Wo=cJchAPGAnY1uXFAq6qJCg@mail.gmail.com>
 <ca96c67f839046b0b603cc65457054f0@ugent.be>,
 <CA+8X3fXiatTriF2Qit=rP1skLsbsb-WEfDZ9M-hpf6Dqwk=8Vg@mail.gmail.com>
Message-ID: <9f5d2f5a60fc411fb8ca3691a1307852@ugent.be>

Thanks Jim,

It is now working.


Regards,
Mahmood

________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, March 30, 2021 4:28:50 AM
To: Mahmood Naderan-Tahan
Subject: Re: [R] Colorizing different individuals with fviz

Hi Mahmood,
After scanning the replies and finding the "factoextra" and
"FactoMineR" packages I can say with confidence that the col= argument
won't work. First, the graphic output if via ggplot, and I don't think
that "col=" is a valid argument in that environment.
You seem to be using an object that is a list of matrices. Whether
there is a value in there that will separate your individuals into the
"red" and "black" groups I do not know.
I think that Bill is right, you will have to fall back on something like:

col.ind=c(rep("black",10),rep("red",10))

Jim

On Tue, Mar 30, 2021 at 8:33 AM Mahmood Naderan-Tahan
<mahmood.naderan at ugent.be> wrote:
>
> I understand that I came across this error after that
>
>
> ind <- get_famd_ind(res.famd)
> fviz_famd_ind(res.famd,
>               col.ind = ifelse(ind>10,"red","black"),
>               repel = TRUE)
>
>
> Error in ifelse(ind > 10, "red", "black") :
>   'list' object cannot be coerced to type 'double'
> Calls: fviz_famd_ind -> %in% -> ifelse
>
>
> I guess ind has (x,y) type and hence "ind>10" is not valid.
>
> I also tried
>
>
> col.ind = ifelse(ind.x>10,"red","black"),
>
>
> But got the same error.
>
> Any idea about that?
>
>
>
>
> Regards,
> Mahmood
>
> ________________________________
> From: Bill Dunlap <williamwdunlap at gmail.com>
> Sent: Monday, March 29, 2021 11:25:30 PM
> To: Mahmood Naderan-Tahan
> Cc: Jim Lemon; r-help at r-project.org
> Subject: Re: [R] Colorizing different individuals with fviz
>
> That error means that fviz_famd_ind has more than one argument that
> starts with 'col' and you must type a more complete name to
> disambiguate it.  Perhaps col.ind=ifelse(...)?
>
> > args(factoextra::fviz_famd_ind)
> function (X, axes = c(1, 2), geom = c("point", "text"),
>     repel = FALSE, habillage = "none", palette = NULL,
>     addEllipses = FALSE, col.ind = "blue", col.ind.sup = "darkblue",
>     alpha.ind = 1, shape.ind = 19, col.quali.var = "black",
>     select.ind = list(name = NULL, cos2 = NULL, contrib = NULL),
>     gradient.cols = NULL, ...)
>
> On Mon, Mar 29, 2021 at 2:20 PM Mahmood Naderan-Tahan
> <mahmood.naderan at ugent.be> wrote:
> >
> > Hi Jim,
> >
> > It seems that the following proposed method doesn't work
> >
> >
> > ind <- get_famd_ind(res.famd)
> > fviz_famd_ind(res.famd,
> >               col=ifelse(x>10,"red","black"),
> >               repel = TRUE)
> >
> >
> > Result is:
> >
> >
> > Error in fviz_famd_ind(res.famd, col = ifelse(x > 10, "red", "black"),  :
> >   argument 2 matches multiple formal arguments
> >
> >
> >
> > Any idea to fix that?
> >
> > Regards,
> > Mahmood
> >
> > ________________________________
> > From: Jim Lemon <drjimlemon at gmail.com>
> > Sent: Saturday, March 27, 2021 9:19:23 PM
> > To: Mahmood Naderan-Tahan
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Colorizing different individuals with fviz
> >
> > Hi Mahmood,
> > What you have specified can be done with:
> >
> > col=c(rep("black",10),rep("red",10))
> >
> > depending upon what print function you are using. I suspect that this
> > may be based on a value in your data. For example, if you want  black
> > for values of some variable up to 10 and red for those over:
> >
> > col=ifelse(x>10,"red","black)
> >
> > Jim
> >
> > On Sun, Mar 28, 2021 at 12:20 AM Mahmood Naderan-Tahan
> > <mahmood.naderan at ugent.be> wrote:
> > >
> > > Hi
> > >
> > > I use this command to generate a graph of individuals
> > >
> > >
> > > ind <- get_famd_ind(res.famd)
> > > fviz_famd_ind(res.famd, repel = TRUE)
> > >
> > >
> > > I would like to know how can I specify different colors for different individuals?
> > >
> > > The colorization is not very complex. Basically, I want to specify rows[1:10] to be shown in black and rows[11:20] to be shown in red.
> > >
> > >
> > > Any idea about that?
> > >
> > >
> > > Regards,
> > > Mahmood
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From m@rce|o|@|@ @end|ng |rom gm@||@com  Tue Mar 30 12:20:08 2021
From: m@rce|o|@|@ @end|ng |rom gm@||@com (Marcelo Laia)
Date: Tue, 30 Mar 2021 07:20:08 -0300
Subject: [R] Word cloud based on a specific site
In-Reply-To: <CAGxFJbQPQRBesNnuXGFzo3BXro4bGXH7bdsu7MNao9bi5A6gmA@mail.gmail.com>
References: <YGJuLMHDauCI5x6r@localhost>
 <CA+8X3fViehjVU8QLt8MRq4e-5BiKV0NtdJakBGP_QVds5Wns0w@mail.gmail.com>
 <CAGxFJbQPQRBesNnuXGFzo3BXro4bGXH7bdsu7MNao9bi5A6gmA@mail.gmail.com>
Message-ID: <YGL7WAYObks7lOsb@localhost>

Hi Jim and Bert! Thank you so much!

I already did the search by "word cloud r". However, it return a lot of
resources tell me how I make a word cloud from a dataset. For example
[1] is a best resources and I understand how I made a word cloud from a
csv file.

However, I am interested in another approach. I would like to:

1. access a site www.foo.bar
2. search inside it for a word "tree"
3. made a word cloud from all others word in that page (i.e. index.html)
4. download all words in that page
5. so, I got a word cloud that tell how is the more frequent word
linked to "tree" in a specif site.

Is it possible in R? If it is, I will do a Google search. Have you a
suggestion for search? Like Jim pointed me? ("word cloud R", for
example). I'm not a native in English and I get difficult to made the
correct terms to search.

1. http://www.datascribble.com/blog/data-science/r/building-word-cloud-r/

Thank you!

A nice weekend!

Marcelo

On 29/03/21 at 07:16, Bert Gunter wrote:
>    Also (I think):
>    [1]https://cran.r-project.org/web/views/NaturalLanguageProcessing.html
>    (get to know the CRAN resources!).
>    Bert Gunter
>    "The trouble with having an open mind is that people keep coming along
>    and sticking things into it."
>    -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
>    On Mon, Mar 29, 2021 at 7:12 PM Jim Lemon <[2]drjimlemon at gmail.com>
>    wrote:
> 
>      Hi Marcelo,
>      Just google for "word cloud r". Too much information.
>      Jim
>      On Tue, Mar 30, 2021 at 11:18 AM Marcelo Laia
>      <[3]marcelolaia at gmail.com> wrote:
>      >
>      > Hi,
>      >
>      > I would like to do a word cloud in a specif site related to a
>      specific
>      > word.
>      >
>      > For example, I could be interested in discovery what are the words
>      > linked to word "tree" in a site like www.foo.bar and have the
>      result in
>      > a wordcloud image.
>      >
>      > Please, someone could me point me out a package or a bibliography
>      or
>      > tutorial or somethings else?
>      >
>      > Thank you so much!
>      >
>      > --
>      > Marcelo
>      >
>      > ______________________________________________
>      > [4]R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>      see
>      > [5]https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>      [6]http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      ______________________________________________
>      [7]R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      [8]https://stat.ethz.ch/mailman/listinfo/r-help
>      PLEASE do read the posting guide
>      [9]http://www.R-project.org/posting-guide.html
>      and provide commented, minimal, self-contained, reproducible code.
> 
> Refer?ncias
> 
>    1. https://cran.r-project.org/web/views/NaturalLanguageProcessing.html
>    2. mailto:drjimlemon at gmail.com
>    3. mailto:marcelolaia at gmail.com
>    4. mailto:R-help at r-project.org
>    5. https://stat.ethz.ch/mailman/listinfo/r-help
>    6. http://www.R-project.org/posting-guide.html
>    7. mailto:R-help at r-project.org
>    8. https://stat.ethz.ch/mailman/listinfo/r-help
>    9. http://www.R-project.org/posting-guide.html


-- 
Marcelo


From m|k@@h@m@r|73 @end|ng |rom out|ook@com  Tue Mar 30 13:52:10 2021
From: m|k@@h@m@r|73 @end|ng |rom out|ook@com (Mika Hamari)
Date: Tue, 30 Mar 2021 11:52:10 +0000
Subject: [R] "for" loop does not work with my plot_ly command
In-Reply-To: <CAAkw+D79idB8Y-BJToAatuAiYUazvi_QSzxgJBKrCCajVZt_EA@mail.gmail.com>
References: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
 <HE1PR0902MB20590B8BFDBA7614A0D5CAD8E67E9@HE1PR0902MB2059.eurprd09.prod.outlook.com>,
 <CAAkw+D79idB8Y-BJToAatuAiYUazvi_QSzxgJBKrCCajVZt_EA@mail.gmail.com>
Message-ID: <HE1PR0902MB2059AC947DA34B88652C3FFFE67D9@HE1PR0902MB2059.eurprd09.prod.outlook.com>

Hi!

That is familiar: loop goes on, but nothing visual happens. Normally when I don't get output of the loop, I put the output-line inside the function print(), and it works. But in this case it probably doesn't help. I am sure that someone here can help you, Rachida.

Mika



L?hetetty Samsung Galaxy -?lypuhelimesta.


-------- Alkuper?inen viesti --------
L?hett?j?: Rachida El Ouaraini <elouaraini at gmail.com>
P?iv?m??r?: 30.3.2021 12.25 (GMT+02:00)
Saaja: Mika Hamari <mika.hamari73 at outlook.com>
Kopio: r-help at r-project.org
Aihe: Re: [R] "for" loop does not work with my plot_ly command

Hi Mika,
and thank you very much for your answer.
When I add the "for" loop to the code that produces before the graph I want, it does nothing :
NO graph and NO error message.
It seems to me that the command plot_ly and the for loop DO NOT coexist.

Rachida

On Mon, Mar 29, 2021 at 7:44 PM Mika Hamari <mika.hamari73 at outlook.com<mailto:mika.hamari73 at outlook.com>> wrote:
Hi!

I am also learning, but I want try to help. I often use for-loop in R. I think that it could be due to dimensions of CPM, not the structure of the loop.

What kind of error message do you get? Is it: ?incorrect number of dimensions?? What happens if you substitute in the end instead of CPM[i,1] this:

file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i],".png",sep="")

L?hett?j?: Rachida El Ouaraini<mailto:elouaraini at gmail.com>
L?hetetty: maanantai 29. maaliskuuta 2021 18.15
Vastaanottaja: r-help at r-project.org<mailto:r-help at r-project.org>
Aihe: [R] "for" loop does not work with my plot_ly command

Hi everyone,
I am new to R programming, and I am having difficulties modifying an R
script to introduce the "for" loop in the code.
While searching I found that this issue has already been raised, but I did
not know what to do to fix mine !

*The code that works (without for command):*

CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
",", skip = 0)
# The CPM.txt file containe 1 line
......................................................................
......................................................................
options(viewer = NULL)
plot_ly() %>%
 htmlwidgets::onRender(
   "function(el, x) {
     var gd = document.getElementById(el.id<https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fel.id%2F&data=04%7C01%7C%7Cd44ce15fde0549644d4e08d8f35dca77%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526931442844620%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=Nn3hw1AfZso8HiTjtOYAEkzplnB3QRSrFQ5qoyNwJVA%3D&reserved=0>);
     Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
filename: 'AnomalieRR_EcartTmoy'});
   }"
 )%>%
 add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
%>%
add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
list(color = "white", size = 14),  showarrow = FALSE)%>%
 layout(title = paste("Combinaison anomalie relative annuelle des
pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
",CPM[1,1],sep =""),
      xaxis = list(title = "Anomalie relative des pr?cipitations
annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
, family = 'Arial'), tickfont = list(color = "blue", size = 14)),
yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
'Arial'),
tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
"red", linewidth = 2),
   legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
"black")),margin = list(
      t = 70,
     r = 70,
      b = 70,
      l = 70
    ))
*The code that does not work (with for command):*
CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
",", skip = 0)
# The CPM.txt file containe several lines

*for (i in 1: (nrow(CPM)))   {*

options(viewer = NULL)
plot_ly() %>%
 htmlwidgets::onRender(
   "function(el, x) {
     var gd = document.getElementById(el.id<https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fel.id%2F&data=04%7C01%7C%7Cd44ce15fde0549644d4e08d8f35dca77%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526931442854613%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=cjSxT%2BeaoRtlaDOKMHY910Pd0f8kJMVs35PErOpqfak%3D&reserved=0>);
     Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
filename: 'AnomalieRR_EcartTmoy'});
   }"
 )%>%
 add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
%>%
add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
list(color = "white", size = 14),  showarrow = FALSE)%>%
  layout(title = paste("Combinaison anomalie relative annuelle des
pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
",CPM[i,1],sep =""),
      xaxis = list(title = "Anomalie relative des pr?cipitations
annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
, family = 'Arial'), tickfont = list(color = "blue", size = 14)),
yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
'Arial'),
tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
"red", linewidth = 2),
  legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
"black")),margin = list(
      t = 70,
     r = 70,
      b = 70,
      l = 70
    ))

*file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i,1],".png",sep="")*
*}*


Thank you very much in advance for any help.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=wwtfLAGJ3zjOzN%2FDxopVDEVnLC5QSF6H1ER6nHMEaLI%3D&amp;reserved=0<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=04%7C01%7C%7Cd44ce15fde0549644d4e08d8f35dca77%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526931442854613%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=yUnIowmFSSIERPTRbUO5IwV3N04x5shoKM%2BlgfNXxHY%3D&reserved=0>
PLEASE do read the posting guide https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=nqKgiTsjQz%2FjF5gDRc1UMQiSxRdZCurArqyGz5pnNtg%3D&amp;reserved=0<https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=04%7C01%7C%7Cd44ce15fde0549644d4e08d8f35dca77%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526931442864610%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=8CDQ2TjGYzlPTPnzWQLWqM5ad3sOku8TaWqaUZlP8u0%3D&reserved=0>
and provide commented, minimal, self-contained, reproducible code.



--
Best Regards, Cordialement, ?? ???? ??????

Rachida EL OUARAINI
Service de la R?alisation des Mod?les Appliqu?s et de la T?l?d?tection
Direction de la M?t?orologie Nationale du Maroc
T?l : +212 522 65 48 90
Fax: +212 522 91 34 35

"Your attitude, not your aptitude, will determine your altitude." Zig Ziglar


	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Mar 30 16:53:28 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 30 Mar 2021 07:53:28 -0700
Subject: [R] "for" loop does not work with my plot_ly command
In-Reply-To: <CAAkw+D79idB8Y-BJToAatuAiYUazvi_QSzxgJBKrCCajVZt_EA@mail.gmail.com>
References: <CAAkw+D4_kTd820SORpssi4xJAtWkHQV2gTmYn5_5gQWS50=3WA@mail.gmail.com>
 <HE1PR0902MB20590B8BFDBA7614A0D5CAD8E67E9@HE1PR0902MB2059.eurprd09.prod.outlook.com>
 <CAAkw+D79idB8Y-BJToAatuAiYUazvi_QSzxgJBKrCCajVZt_EA@mail.gmail.com>
Message-ID: <CAHqSRuT9h-hipnYS0LPnGw_ozZacXcgn5-we5anAScJVepmwuw@mail.gmail.com>

Printing the return value of plot_ly and friends works for me in the
following examples:
# make base plot
p0 <- plotly::plot_ly(na.omit(palmerpenguins::penguins), x =
~bill_length_mm, y = ~body_mass_g)
# now add things to base plot
for(vrbl in list(~species, ~island, ~year)) {
   tmp <- plotly::add_markers(p0, symbol=vrbl, color=vrbl)
   print(tmp)
}
# or, the put the plots in a list
plots <- lapply(list(~species, ~island, ~year), function(vrbl)
plotly::add_markers(p0, symbol=vrbl, color=vrbl))
print(plots)



On Tue, Mar 30, 2021 at 2:26 AM Rachida El Ouaraini
<elouaraini at gmail.com> wrote:
>
> Hi Mika,
> and thank you very much for your answer.
> When I add the "for" loop to the code that produces before the graph I
> want, it does nothing :
> NO graph and NO error message.
> It seems to me that the command plot_ly and the for loop DO NOT coexist.
>
> Rachida
>
> On Mon, Mar 29, 2021 at 7:44 PM Mika Hamari <mika.hamari73 at outlook.com>
> wrote:
>
> > Hi!
> >
> >
> >
> > I am also learning, but I want try to help. I often use for-loop in R. I
> > think that it could be due to dimensions of CPM, not the structure of the
> > loop.
> >
> >
> >
> > What kind of error message do you get? Is it: ?incorrect number of
> > dimensions?? What happens if you substitute in the end instead of CPM[i,1]
> > this:
> >
> >
> >
> > file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
> > paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i],".png",sep="")
> >
> >
> >
> > *L?hett?j?: *Rachida El Ouaraini <elouaraini at gmail.com>
> > *L?hetetty: *maanantai 29. maaliskuuta 2021 18.15
> > *Vastaanottaja: *r-help at r-project.org
> > *Aihe: *[R] "for" loop does not work with my plot_ly command
> >
> >
> >
> > Hi everyone,
> > I am new to R programming, and I am having difficulties modifying an R
> > script to introduce the "for" loop in the code.
> > While searching I found that this issue has already been raised, but I did
> > not know what to do to fix mine !
> >
> > *The code that works (without for command):*
> >
> > CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> > ",", skip = 0)
> > # The CPM.txt file containe 1 line
> > ......................................................................
> > ......................................................................
> > options(viewer = NULL)
> > plot_ly() %>%
> >  htmlwidgets::onRender(
> >    "function(el, x) {
> >      var gd = document.getElementById(el.id);
> >      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> > filename: 'AnomalieRR_EcartTmoy'});
> >    }"
> >  )%>%
> >  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> > Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> > symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
> > %>%
> > add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> > list(color = "white", size = 14),  showarrow = FALSE)%>%
> >  layout(title = paste("Combinaison anomalie relative annuelle des
> > pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> > ",CPM[1,1],sep =""),
> >       xaxis = list(title = "Anomalie relative des pr?cipitations
> > annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
> > , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> > yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> > annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> > 'Arial'),
> > tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> > "red", linewidth = 2),
> >    legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> > "black")),margin = list(
> >       t = 70,
> >      r = 70,
> >       b = 70,
> >       l = 70
> >     ))
> > *The code that does not work (with for command):*
> > CPM <- read.table("FicConfig/CPM.txt" , header = TRUE, sep = "\t" , dec =
> > ",", skip = 0)
> > # The CPM.txt file containe several lines
> >
> > *for (i in 1: (nrow(CPM)))   {*
> >
> > options(viewer = NULL)
> > plot_ly() %>%
> >  htmlwidgets::onRender(
> >    "function(el, x) {
> >      var gd = document.getElementById(el.id);
> >      Plotly.downloadImage(gd, {format: 'png', width: 1000, height: 700,
> > filename: 'AnomalieRR_EcartTmoy'});
> >    }"
> >  )%>%
> >  add_trace(x =TAnn[ ,3],  y = TAnn[ ,5], name = "Normale mensuelle de
> > Tmax(en ?C)",type = 'scatter', mode = 'markers',  marker = list(size = T,
> > symbol = 'circle',  color = ~TAnn[ ,5], line = list(width= 2, color = cl)))
> > %>%
> > add_annotations(text = TAnn[ ,1], x= TAnn[ ,3], y = TAnn[ ,5], font =
> > list(color = "white", size = 14),  showarrow = FALSE)%>%
> >   layout(title = paste("Combinaison anomalie relative annuelle des
> > pr?cipitations et ?cart annuel ? la normale de la temp?rature moyenne  ?
> > ",CPM[i,1],sep =""),
> >       xaxis = list(title = "Anomalie relative des pr?cipitations
> > annuelles(en %)", tickangle = 20 ,titlefont = list(color= "blue", size= 14
> > , family = 'Arial'), tickfont = list(color = "blue", size = 14)),
> > yaxis = list(title = "Ecart ? la normale de la temp?rature moyenne
> > annuelle(en?C)", titlefont = list(color= "red", size= 14 , family =
> > 'Arial'),
> > tickfont = list(color = "red", size = 14) , showline = TRUE, linecolor =
> > "red", linewidth = 2),
> >   legend = list(x = 0.1, y = -0.3, font=list(size = 14,color=
> > "black")),margin = list(
> >       t = 70,
> >      r = 70,
> >       b = 70,
> >       l = 70
> >     ))
> >
> > *file.copy("C:/Users/pc/Downloads/Evolution Tmoy.png",
> > paste("C:/MONOGRAPHIE/Resultats/Evolution Tmoy_",CPM[i,1],".png",sep="")*
> > *}*
> >
> >
> > Thank you very much in advance for any help.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> > https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=wwtfLAGJ3zjOzN%2FDxopVDEVnLC5QSF6H1ER6nHMEaLI%3D&amp;reserved=0
> > PLEASE do read the posting guide
> > https://emea01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7C63572d98fe1f4af1938c08d8f2c57a0e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637526277319446692%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=nqKgiTsjQz%2FjF5gDRc1UMQiSxRdZCurArqyGz5pnNtg%3D&amp;reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>
>
> --
> *Best Regards, *
> *Cordialement, ?? ???? ?????? *
>
> Rachida EL OUARAINI
> Service de la R?alisation des Mod?les Appliqu?s et de la T?l?d?tection
> Direction de la M?t?orologie Nationale du Maroc
> *T?l : +212 522 65 48 90*
> *Fax: +212 522 91 34 35*
>
> *"Your attitude, not your aptitude, will determine your altitude." Zig
> Ziglar*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@ych@o||u @end|ng |rom gm@||@com  Tue Mar 30 19:27:23 2021
From: p@ych@o||u @end|ng |rom gm@||@com (Chao Liu)
Date: Tue, 30 Mar 2021 13:27:23 -0400
Subject: [R] Problem with updating terms in the multinom function
Message-ID: <CACCU-vNZABrLSKAY_0Vd77ztyubTVkO2tkYbW5Hcdzakv_Ydog@mail.gmail.com>

Dear R-help,

I am trying to add1() all interaction terms on top of a multinomial
baseline model using multinom() but it shows the error

"trying + x1:x2
Error in if (trace) { : argument is not interpretable as logical
Called from: nnet.default(X, Y, w, mask = mask, size = 0, skip = TRUE,
softmax = TRUE, censored = censored, rang = 0, ...)"

What is the problem here? I appreciate any input. Here is a reproducible
example:

require(nnet)
data <- data.frame(y=sample(1:3, 24, replace = TRUE),
        x1 = c(rep(1,12), rep(2,12)),
        x2 = rep(c(rep(1,4), rep(2,4), rep(3,4)),2),
        x3=rnorm(24),
        z1 = sample(1:10, 24, replace = TRUE))
m0 <- multinom(y ~ x1 + x2 + x3 + z1, data = data)
m1 <- add1(m0, scope = .~. + .^2, test="Chisq")

My end goal is to see which terms are appropriate to drop by later adding
the line: m1[order(add1.m1$'Pr(>Chi)'),].

Best,

Chao
?

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Mar 30 23:45:56 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 31 Mar 2021 08:45:56 +1100
Subject: [R] pie3D.labels
In-Reply-To: <279211430.1963047.1617108166917@mail.yahoo.com>
References: <279211430.1963047.1617108166917.ref@mail.yahoo.com>
 <279211430.1963047.1617108166917@mail.yahoo.com>
Message-ID: <CA+8X3fWDw39DrC5UughXNY2N+G2mHby2iFmYgGxU7EuW2QA_Fg@mail.gmail.com>

Hi Collins,
pie3D draws a pseudo-3D pie and then places 2D labels around it. If
you put the labels on top of the pie, it is not going to look right.
The labels will be displayed with an orthogonal viewing angle, while
the pie will be tilted. pie3D is one of those functions that I wrote
for those who might otherwise think that if R can't produce 3D pie
charts, then R is no good. You can do fulsomely decorative plots in R,
and if your boss demands a 3D pie chart, you can do it. If you really
want to create a 3D pie chart with 3D labels, do it with a 3D
rendering program like POVray. I'm afraid that I don't have the time
to provide you with an example right now.

Jim

On Tue, Mar 30, 2021 at 11:42 PM Collins Boahen <wise_coleman at yahoo.com> wrote:
>
> Dear Dr. Lemon,
>
> Thank you for developing such a fantastic package.
>
> I would like to find out if there is a way to insert the labels inside the pie and  manipulate the labels for fit perfectly.
>
> Please any tips or suggestions will be appreciated.
>
> Thank you
>
> Best
> Collins
>


From m@hmood@n@der@n @end|ng |rom ugent@be  Wed Mar 31 11:19:59 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Wed, 31 Mar 2021 09:19:59 +0000
Subject: [R] Working with violin plot
Message-ID: <96c113e854b0475498e2fce58c352d7c@ugent.be>

Hi

I would like to use the violin plot as described in the manual [1]. In the example, I see

ToothGrowth$dose <- as.factor(ToothGrowth$dose)
head(ToothGrowth)

On the other hand, my data is a csv file containing some rows and numbers. Problem is that the following code doesn't work


> mydata <- read.csv('test.csv', header=T,row.names=1)
> mydata
     V1  V2   V3 V4
P1 73.6 0.7 74.6  R
P2 75.2 0.7 75.8  R
P3  6.5 0.0  7.3  R
P4 41.4 0.3 39.2  C
P5  5.4 0.1 18.2  C
P6 18.8 0.3 30.3  C
> library(ggplot2)
> p <- ggplot(ToothGrowth, aes(x=V4, y=V1)) + geom_violin()
> p
Error in FUN(X[[i]], ...) : object 'V4' not found


Any idea to fix that?





[1] http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization


Regards,
Mahmood

	[[alternative HTML version deleted]]


From m@hmood@n@der@n @end|ng |rom ugent@be  Wed Mar 31 11:29:46 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Wed, 31 Mar 2021 09:29:46 +0000
Subject: [R] Working with violin plot
In-Reply-To: <96c113e854b0475498e2fce58c352d7c@ugent.be>
References: <96c113e854b0475498e2fce58c352d7c@ugent.be>
Message-ID: <28cbf040c2cd4ffa95fb1a962196d643@ugent.be>

Please ignore the previous email...


Regards,
Mahmood

________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Mahmood Naderan-Tahan <mahmood.naderan at ugent.be>
Sent: Wednesday, March 31, 2021 11:19:59 AM
To: r-help at r-project.org
Subject: [R] Working with violin plot

Hi

I would like to use the violin plot as described in the manual [1]. In the example, I see

ToothGrowth$dose <- as.factor(ToothGrowth$dose)
head(ToothGrowth)

On the other hand, my data is a csv file containing some rows and numbers. Problem is that the following code doesn't work


> mydata <- read.csv('test.csv', header=T,row.names=1)
> mydata
     V1  V2   V3 V4
P1 73.6 0.7 74.6  R
P2 75.2 0.7 75.8  R
P3  6.5 0.0  7.3  R
P4 41.4 0.3 39.2  C
P5  5.4 0.1 18.2  C
P6 18.8 0.3 30.3  C
> library(ggplot2)
> p <- ggplot(ToothGrowth, aes(x=V4, y=V1)) + geom_violin()
> p
Error in FUN(X[[i]], ...) : object 'V4' not found


Any idea to fix that?





[1] http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization


Regards,
Mahmood

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Mar 31 11:30:48 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 31 Mar 2021 12:30:48 +0300
Subject: [R] Working with violin plot
In-Reply-To: <96c113e854b0475498e2fce58c352d7c@ugent.be>
References: <96c113e854b0475498e2fce58c352d7c@ugent.be>
Message-ID: <CAGgJW74dUDis6csKXkd660Qm9bQ23XTbCWe=5uiESAy2dKqfvQ@mail.gmail.com>

Try replacing
ggplot(ToothGrowth, ... )
with
ggplot(mydata,...)

HTH,
Eric


On Wed, Mar 31, 2021 at 12:20 PM Mahmood Naderan-Tahan <
mahmood.naderan at ugent.be> wrote:

> Hi
>
> I would like to use the violin plot as described in the manual [1]. In the
> example, I see
>
> ToothGrowth$dose <- as.factor(ToothGrowth$dose)
> head(ToothGrowth)
>
> On the other hand, my data is a csv file containing some rows and numbers.
> Problem is that the following code doesn't work
>
>
> > mydata <- read.csv('test.csv', header=T,row.names=1)
> > mydata
>      V1  V2   V3 V4
> P1 73.6 0.7 74.6  R
> P2 75.2 0.7 75.8  R
> P3  6.5 0.0  7.3  R
> P4 41.4 0.3 39.2  C
> P5  5.4 0.1 18.2  C
> P6 18.8 0.3 30.3  C
> > library(ggplot2)
> > p <- ggplot(ToothGrowth, aes(x=V4, y=V1)) + geom_violin()
> > p
> Error in FUN(X[[i]], ...) : object 'V4' not found
>
>
> Any idea to fix that?
>
>
>
>
>
> [1]
> http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization
>
>
> Regards,
> Mahmood
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@hmood@n@der@n @end|ng |rom ugent@be  Wed Mar 31 11:32:05 2021
From: m@hmood@n@der@n @end|ng |rom ugent@be (Mahmood Naderan-Tahan)
Date: Wed, 31 Mar 2021 09:32:05 +0000
Subject: [R] Working with violin plot
In-Reply-To: <CAGgJW74dUDis6csKXkd660Qm9bQ23XTbCWe=5uiESAy2dKqfvQ@mail.gmail.com>
References: <96c113e854b0475498e2fce58c352d7c@ugent.be>,
 <CAGgJW74dUDis6csKXkd660Qm9bQ23XTbCWe=5uiESAy2dKqfvQ@mail.gmail.com>
Message-ID: <4e4eeae8378545528a7036a47abde6d3@ugent.be>

Yes thank you very much.


Regards,
Mahmood

________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Wednesday, March 31, 2021 11:30:48 AM
To: Mahmood Naderan-Tahan
Cc: r-help at r-project.org
Subject: Re: [R] Working with violin plot

Try replacing
ggplot(ToothGrowth, ... )
with
ggplot(mydata,...)

HTH,
Eric


On Wed, Mar 31, 2021 at 12:20 PM Mahmood Naderan-Tahan <mahmood.naderan at ugent.be<mailto:mahmood.naderan at ugent.be>> wrote:
Hi

I would like to use the violin plot as described in the manual [1]. In the example, I see

ToothGrowth$dose <- as.factor(ToothGrowth$dose)
head(ToothGrowth)

On the other hand, my data is a csv file containing some rows and numbers. Problem is that the following code doesn't work


> mydata <- read.csv('test.csv', header=T,row.names=1)
> mydata
     V1  V2   V3 V4
P1 73.6 0.7 74.6  R
P2 75.2 0.7 75.8  R
P3  6.5 0.0  7.3  R
P4 41.4 0.3 39.2  C
P5  5.4 0.1 18.2  C
P6 18.8 0.3 30.3  C
> library(ggplot2)
> p <- ggplot(ToothGrowth, aes(x=V4, y=V1)) + geom_violin()
> p
Error in FUN(X[[i]], ...) : object 'V4' not found


Any idea to fix that?





[1] http://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization


Regards,
Mahmood

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Mar 31 12:30:56 2021
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Wed, 31 Mar 2021 12:30:56 +0200
Subject: [R] [Rd] R 4.0.5 is released
Message-ID: <21C0B9A3-A0D0-4169-82FD-FFBE63A21F01@gmail.com>

The build system rolled up R-4.0.5.tar.gz (codename "Shake and Throw") this morning.

This is a very minor update, mostly to fix the annoyance with East Asian character sets.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.0.5.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 639fbbba9998cae70ef058be42b80a52
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 553381d79675220a90cf9b264997e458
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
MD5 (R-latest.tar.gz) = eb8fb47cc91ff287005c1633ef8599e6
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 62b1389bc9fed2bf5857c0c99ef490f2
MD5 (R-4/R-4.0.5.tar.gz) = eb8fb47cc91ff287005c1633ef8599e6


2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
0dce85f38b9d6351a1b63f057dfbc7f572966245add12946482e57e60d41547c  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
bbee124ddbd6682ecbaa5193d5ffc35aa090fcf29b30a9ad6f1498074a720388  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e  NEWS.2
7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0  NEWS.3
0a3ee079aa772e131fe5435311ab627fcbccb5a50cabc54292e6f62046f1ffef  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
6f7663cb7813af1228978d9ef356fb6e6dad131fab9bbed507b657b48e2df6bd  VERSION-INFO.dcf
0a3ee079aa772e131fe5435311ab627fcbccb5a50cabc54292e6f62046f1ffef  R-4/R-4.0.5.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.0.5:

  BUG FIXES:

    * The change to the internal table in R 4.0.4 for iswprint has been
      reverted: it contained some errors in printability of 'East
      Asian' characters.

    * For packages using LazyData, R CMD build ignored the
      --resave-data option and the BuildResaveData field of the
      DESCRIPTION file (in R versions 4.0.0 to 4.0.4).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From m@015k3113 @end|ng |rom b|ueyonder@co@uk  Wed Mar 31 19:04:52 2021
From: m@015k3113 @end|ng |rom b|ueyonder@co@uk (e-mail ma015k3113)
Date: Wed, 31 Mar 2021 18:04:52 +0100 (BST)
Subject: [R] Calculating the total change in shareprice over a time periond
Message-ID: <63365987.939790.1617210292526@mail2.virginmedia.com>

Dear All, I have a data frame which is structured as follows:


COMPANY_NUMBER 	COMPANY_NAME 	CITY 	YEAR_END_DATE 	CLOSE_SHARE_PRICE
22705 	CARDIFF PROPERTY PUBLIC LIMITED COMPANY 	(THE)Egham 	30/09/2005 	NA
22705 	CARDIFF PROPERTY PUBLIC LIMITED COMPANY 	(THE)Egham 	30/09/2006 	NA
22705 	CARDIFF PROPERTY PUBLIC LIMITED COMPANY 	(THE)Egham 	30/09/2007 	9.65
22705 	CARDIFF PROPERTY PUBLIC LIMITED COMPANY 	(THE)Egham 	30/09/2008 	6.55
22705 	CARDIFF PROPERTY PUBLIC LIMITED COMPANY 	(THE)Egham 	30/09/2009 	6.55
22705 	CARDIFF PROPERTY PUBLIC LIMITED COMPANY 	(THE)Egham 	30/09/2010 	7.5
10395804 	TOC PROPERTY BACKED LENDING TRUST PLC 	Newcastle Upon Tyne 	30/11/2016 	NA
10395804 	TOC PROPERTY BACKED LENDING TRUST PLC 	Newcastle Upon Tyne 	30/11/2017 	1.04
10395804 	TOC PROPERTY BACKED LENDING TRUST PLC 	Newcastle Upon Tyne 	30/11/2018 	1.04
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2000 	NA
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2001 	NA
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2003 	NA
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2004 	NA
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2005 	NA
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2006 	1.09
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2007 	1.17
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2008 	1.24
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2009 	0.9
SC192761 	MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC 	Edinburgh 	31/01/2010 	1.14



I am trying to calculate the total change in share price like for CARDIFF PROPERTY PUBLIC LIMITED COMPANY the total change

between 2005 and 2006 is NA and for 2006 and 2007 it is NA for 2007 and 2008 it is -3.1 and 2008 and 2009 it is 0 and 2009 and 2010 it is +.95. 


I am trying to achieve this via he following code:

for (i in 1:(nrow(PLC)-1))
if (isTRUE (PLC[i, 1] == PLC[i + 1, 1]))
{
PLC$CH_SH_PRICE(i+1) = (PLC$CLOSE_SHARE_PRICE[i+1] -
PLC$CLOSE_SHARE_PRICE[i])
}


I get the following error


Error in 1:(nrow(PLC) - 1) : argument of length 0


Can you kindly suggest any solution to this issue?


Thanks in advance.
	[[alternative HTML version deleted]]


From d@v|d@@teven@ @end|ng |rom u@u@edu  Wed Mar 31 20:17:54 2021
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David K Stevens)
Date: Wed, 31 Mar 2021 12:17:54 -0600
Subject: [R] 
 [EXT] Calculating the total change in shareprice over a time periond
In-Reply-To: <63365987.939790.1617210292526@mail2.virginmedia.com>
References: <63365987.939790.1617210292526@mail2.virginmedia.com>
Message-ID: <5c173bf0-3a48-ebb4-a8a6-5b2d99410ee6@usu.edu>

Mr. Blueyonder,

There are a number of problems with this.

1) is the data below really in a data frame? I coerced your table into a 
data frame, guessing at the structure and when I print out the 1st three 
rows I get an alignment into proper columns

COMPANY_NUMBER COMPANY_NAME??????????????? CITY YEAR_END_DATE 
CLOSE_SHARE_PRICE
1?????????? 22705? CARDIFF PROPERTY PUBLIC LIMITED COMPANY????????? 
(THE)Egham??? 30/09/2005??????????????? NA
2?????????? 22705? CARDIFF PROPERTY PUBLIC LIMITED COMPANY????????? 
(THE)Egham??? 30/09/2006??????????????? NA
3?????????? 22705? CARDIFF PROPERTY PUBLIC LIMITED COMPANY????????? 
(THE)Egham??? 30/09/2007????????????? 9.65

I'd guess that your PLC is actually a 1 column data frame based on how 
you present it. Because what you gave is so small, I just added commas 
where they seemed suitable and used

PLC <- read.csv(file='clipboard',header=T,stringsAsFactors = T)

to create the data frame above. It's likely that your actual problem is 
much larger so I'd export the data as a CSV file, and read it into R in 
a similar way using

PLC <- read.csv(file='myfile.csv',header=T,stringsAsFactors = T)

2) Your code is incorrect as is for two reasons. a) for your approach to 
work, you'll need to create an empty column CH_SH_PRICE before running 
the loop, because your loop is trying to place data into a non-existent 
column b) the code PLC$CH_SH_PRICE(i+1) has to use square brackets, 
otherwise R thinks PCL$CH_SH_PRICE is a function rather than a reference 
to column element i+1 as in PLC$CH_SH_PRICE[i+1]

Also, the functionisTRUE is actually the following

function (x)
is.logical(x) && length(x) == 1L && !is.na(x) && x

Is this really what you want to do, rather than just checking the 
company number, as inPLC[i,1] == PLC[i+1,1]?

Assuming (tentatively) I guessed right, here's what I got

COMPANY_NUMBER??????????????????????????? COMPANY_NAME CITY 
YEAR_END_DATE CLOSE_SHARE_PRICE CH_SH_PRICE
1????????? 22705 CARDIFF PROPERTY PUBLIC LIMITED COMPANY (THE)Egham??? 
30/09/2005??????????????? NA????????? NA
2????????? 22705 CARDIFF PROPERTY PUBLIC LIMITED COMPANY (THE)Egham??? 
30/09/2006??????????????? NA????????? NA
3????????? 22705 CARDIFF PROPERTY PUBLIC LIMITED COMPANY (THE)Egham??? 
30/09/2007????????????? 9.65????????? NA
4????????? 22705 CARDIFF PROPERTY PUBLIC LIMITED COMPANY (THE)Egham??? 
30/09/2008????????????? 6.55?????? -3.10

Good luck.

David Stevens

On 3/31/2021 11:04 AM, e-mail ma015k3113 via R-help wrote:
> Dear All, I have a data frame which is structured as follows:
>
>
> COMPANY_NUMBER  COMPANY_NAME    CITY    YEAR_END_DATE   CLOSE_SHARE_PRICE
> 22705   CARDIFF PROPERTY PUBLIC LIMITED COMPANY         (THE)Egham      30/09/2005      NA
> 22705   CARDIFF PROPERTY PUBLIC LIMITED COMPANY         (THE)Egham      30/09/2006      NA
> 22705   CARDIFF PROPERTY PUBLIC LIMITED COMPANY         (THE)Egham      30/09/2007      9.65
> 22705   CARDIFF PROPERTY PUBLIC LIMITED COMPANY         (THE)Egham      30/09/2008      6.55
> 22705   CARDIFF PROPERTY PUBLIC LIMITED COMPANY         (THE)Egham      30/09/2009      6.55
> 22705   CARDIFF PROPERTY PUBLIC LIMITED COMPANY         (THE)Egham      30/09/2010      7.5
> 10395804        TOC PROPERTY BACKED LENDING TRUST PLC   Newcastle Upon Tyne     30/11/2016      NA
> 10395804        TOC PROPERTY BACKED LENDING TRUST PLC   Newcastle Upon Tyne     30/11/2017      1.04
> 10395804        TOC PROPERTY BACKED LENDING TRUST PLC   Newcastle Upon Tyne     30/11/2018      1.04
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2000      NA
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2001      NA
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2003      NA
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2004      NA
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2005      NA
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2006      1.09
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2007      1.17
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2008      1.24
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2009      0.9
> SC192761        MARTIN CURRIE GLOBAL PORTFOLIO TRUST PLC        Edinburgh       31/01/2010      1.14
>
>
>
> I am trying to calculate the total change in share price like for CARDIFF PROPERTY PUBLIC LIMITED COMPANY the total change
>
> between 2005 and 2006 is NA and for 2006 and 2007 it is NA for 2007 and 2008 it is -3.1 and 2008 and 2009 it is 0 and 2009 and 2010 it is +.95.
>
>
> I am trying to achieve this via he following code:
>
> for (i in 1:(nrow(PLC)-1))
> if (isTRUE (PLC[i, 1] == PLC[i + 1, 1]))
> {
> PLC$CH_SH_PRICE(i+1) = (PLC$CLOSE_SHARE_PRICE[i+1] -
> PLC$CLOSE_SHARE_PRICE[i])
> }
>
>
> I get the following error
>
>
> Error in 1:(nrow(PLC) - 1) : argument of length 0
>
>
> Can you kindly suggest any solution to this issue?
>
>
> Thanks in advance.
>          [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> CAUTION: This email originated from outside of USU. If this appears to be a USU employee, beware of impersonators. Do not click links, reply, download images, or open attachments unless you verify the sender?s identity and know the content is safe.
>
-- 
David K Stevens, P.E., Ph.D.
Professor, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Wed Mar 31 21:29:41 2021
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Wed, 31 Mar 2021 19:29:41 +0000
Subject: [R] cox.zph
Message-ID: <MN2PR03MB5167780977C97D4A9D435094E27C9@MN2PR03MB5167.namprd03.prod.outlook.com>

Colleagues,

I would like to make certain that my understanding of the tabular output produced by cox.zph is correct.

Am I correct that the NULL hypothesis being tested is that the hazard is proportional in time?  Therefor a non-significant result indicates that we don't have evidence that the proportional hazards assumption is incorrect and we can assume that the hazard is proportional. A significant result indicates that we have evidence that the proportional hazards assumption is violated.

Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Wed Mar 31 21:38:46 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Wed, 31 Mar 2021 21:38:46 +0200
Subject: [R] cox.zph
In-Reply-To: <MN2PR03MB5167780977C97D4A9D435094E27C9@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167780977C97D4A9D435094E27C9@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <e1a550ec-6701-202b-2672-4e4c4772a617@math.uni-giessen.de>

Yes. :-)

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 31.03.2021 um 21:29 schrieb Sorkin, John:
> Colleagues,
> 
> I would like to make certain that my understanding of the tabular output produced by cox.zph is correct.
> 
> Am I correct that the NULL hypothesis being tested is that the hazard is proportional in time?  Therefor a non-significant result indicates that we don't have evidence that the proportional hazards assumption is incorrect and we can assume that the hazard is proportional. A significant result indicates that we have evidence that the proportional hazards assumption is violated.
> 
> Thank you,
> John
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Mar 31 22:20:52 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 31 Mar 2021 15:20:52 -0500
Subject: [R] how to quantify outliers on multi-dimensional scaling plot?
Message-ID: <CAF9-5jNdeq1PnpYZSjXUtx-kg7AJVMXmmEE6q5XP58o544aUHA@mail.gmail.com>

Hello,

I am in process of writing a grant where I am explaining my planned
methylation analysis using R software "minfi". In the text of the
grant I am mentioning looking for samples containing outliers in the
multi-dimensional scaling (MDS) plot
https://rdrr.io/bioc/minfi/man/mdsPlot.html . My question is: how to
more precisely define what is an outlier on a MDS plot? I know it is
not logFC like on volcano plot. Is there is a way to quantify distance
on MDA plot or it is just sufficient to say that samples that cluster
separately are outliers?

Here you can find a full workflow for minfi package including making MDS plots:
https://www.bioconductor.org/packages/release/workflows/vignettes/methylationArrayAnalysis/inst/doc/methylationArrayAnalysis.html

Thanks
Ana


From ve@n@@gu||n @end|ng |rom b|o|@pm|@hr  Wed Mar 31 13:43:33 2021
From: ve@n@@gu||n @end|ng |rom b|o|@pm|@hr (Vesna Gulin)
Date: Wed, 31 Mar 2021 13:43:33 +0200
Subject: [R] FD package_dbFD error
Message-ID: <22acffee587bcf8377643dfd95ef2c5d@biol.pmf.hr>

Hi everyone,

I am trying to conduct dbFD from the FD package, but it keeps giving me 
the same error:

ex1 <- dbFD(sites, traits)
Error in dbFD(sites, traits) :
   Different number of species in 'x' and 'a'.

Ab, bb, Ci.... are species names.
I have tried rewriting the species names so many times and ways, but 
nothing seems to work. I also checked for blank space but can't seem to 
find one. Does anyone have and idea what am I doing wrong?

My data consists of two data frames:
sites

   X Ab Bb Ci Cb Cbm Cdo Cm Cdi Dv Edi Ee Ede Es Eb Gc La Mm Op Oc Oh Or 
Pgr Ps Pgi Pf Pgri Po Pp Rr Ss Sl Ts Tv Tr
1 A  0  0  0  0   0   0  1   0  0   0  0   0  1  0  0  0  1  0  0  0  0  
  0  0   0  0    0  0  0  0  0  0  0  0  0
2 B  0  0  0  0   0   0  0   0  0   0  0   0  1  0  0  0  0  2  0  0  0  
  0  0   0  0    0  0  0  0  0  0  0  0  0
3 C  0  0  0  0   0   0  0   0  0   0  0   0  0  0  0  0  0  0  0  0  0  
  0  0   0  0    0  1  0  0  0  0  0  0  0
4 D  0  0  0  0   0   0  0   0  0   0  0   0  0  0  0  0  0  0  0  0  0  
  0  0   0  0    0  0  0  0  0  0  0  0  0
5 E  0  0  0  0   0   0  0   3  2   3  0   0  0  0  0  0  0  0  0  4  0  
  0  0   0  0    0  0  0  0  0  0  0  0  0
6 F  0  0  0  0   0   0  0   0  3   0  1   0  0  4  1  8  0  1  3  2  0  
  0  0   0  0    0  0  0  0  0  0  0  0  2
7 G  0  0  0  0   0   0  1   1  1   2  0   0  0  0  0  0  0  0  1  4  0  
  0  0   0  0    0  0  0  0  0  0  0  0  0

traits

      X body    ration  flight     feeding       lifestyle     moisture
1    Ab 29.5 0.6203390    none herbivorous geo-chortobiont  xerophilous
2    Bb 16.0 1.0625000 reduced  omnivorous     chortobiont  mesophilous
3    Ci 23.5 0.5829787    full  omnivorous geo-chortobiont  xerophilous
4    Cb 18.0 0.6000000    full herbivorous     chortobiont  mesophilous
5   Cbm 18.0 0.6000000    full herbivorous     chortobiont  mesophilous
6   Cdo 17.5 0.6342857 reduced herbivorous     chortobiont  mesophilous
7    Cm 17.5 0.5914286    full herbivorous     chortobiont  mesophilous
8   Cdi 21.5 0.5883721 reduced herbivorous     chortobiont hygrophilous
9    Dv 34.0 0.9044118 reduced carnivorous geo-chortobiont  mesophilous
10  Edi 27.0 0.7222222    none  omnivorous     thamnobiont  xerophilous
11   Ee 25.0 0.6400000    none  omnivorous     thamnobiont  mesophilous
12  Ede 20.5 0.5902439    none herbivorous     chortobiont  xerophilous
13   Es 25.5 0.9803922    none  omnivorous     thamnobiont  mesophilous
14   Eb 18.0 0.6416667 reduced herbivorous     chortobiont  mesophilous
15   Gc 22.5 0.4555556    none  omnivorous        geobiont  mesophilous
16   La 13.0 0.9807692    none herbivorous     chortobiont  mesophilous
17   Mm 18.0 1.0972222    none  omnivorous geo-chortobiont  xerophilous
18   Op 12.0 0.6666667    full  omnivorous     thamnobiont  xerophilous
19   Oc 21.0 0.5690476    full herbivorous        geobiont  xerophilous
20   Oh 15.5 0.5967742 reduced herbivorous     chortobiont  mesophilous
21   Or 15.5 0.7193548 reduced herbivorous     chortobiont  mesophilous
22  Pgr 17.0 1.0588235    none  omnivorous     thamnobiont  mesophilous
23   Ps 21.5 1.0465116    none  omnivorous     thamnobiont  mesophilous
24  Pgi 14.0 0.5500000    none herbivorous     chortobiont  mesophilous
25   Pf 26.5 0.9622642    none  omnivorous     thamnobiont  mesophilous
26 Pgri 17.5 1.0428571    none  omnivorous     thamnobiont  mesophilous
27   Po 17.0 0.8970588    none herbivorous     chortobiont  mesophilous
28   Pp 17.5 0.6542857 reduced herbivorous     chortobiont  mesophilous
29   Rr 17.5 0.8857143 reduced  omnivorous     chortobiont  mesophilous
30   Ss 22.5 0.5733333    full herbivorous     chortobiont  mesophilous
31   Sl 20.5 0.6268293 reduced herbivorous     chortobiont  mesophilous
32   Ts 12.5 0.4720000 reduced herbivorous        geobiont hygrophilous
33   Tv 33.0 0.7803030    full carnivorous     thamnobiont  mesophilous
34   Tr 20.0 0.9000000    none  omnivorous        geobiont hygrophilous


Thank you in advance and kind regards,
Vesna


-- 
Vesna Gulin,  Research and Teaching Assistant
Department of Biology
Faculty of Science
University of Zagreb
Rooseveltov trg 6, 10000 Zagreb, Croatia


