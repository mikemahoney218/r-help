From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Sep  1 22:19:38 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 1 Sep 2020 15:19:38 -0500
Subject: [R] Odd Results when generating predictions with nnet function
Message-ID: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>

Dear friends,

Hope you are all doing well. I am currently using R version 4.0.2 and
working with the nnet package.

My dataframe consists of three columns, FECHA which is the date, x, which
is a sequence from 1 to 159, and y, which is the number of covid cases (I
am also providing the dput for this data frame below).

I tried fitting a neural net model using the following code:

xnew = 1:159
Fit <- nnet(a$y ~ a$x, a, size = 5, maxit = 1000, lineout = T, decay =
0.001)

Finally, I attempted to generate predictions with the following code:

predictions <- predict(Fit, newdata = list(x = xnew), type = "raw")

But obtained extremely odd results:
As you can see, instead of obtaining numbers, more or less in the range of
the last observations  of a$y, I end up getting a bunch of 1s, which
doesn?t make any sense (if anyone could help me understand what could be
causing this):
dput(predictions)
structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim = c(159L,
1L), .Dimnames = list(c("1", "2", "3", "4", "5", "6", "7", "8",
"9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",
"20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30",
"31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41",
"42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52",
"53", "54", "55", "56", "57", "58", "59", "60", "61", "62", "63",
"64", "65", "66", "67", "68", "69", "70", "71", "72", "73", "74",
"75", "76", "77", "78", "79", "80", "81", "82", "83", "84", "85",
"86", "87", "88", "89", "90", "91", "92", "93", "94", "95", "96",
"97", "98", "99", "100", "101", "102", "103", "104", "105", "106",
"107", "108", "109", "110", "111", "112", "113", "114", "115",
"116", "117", "118", "119", "120", "121", "122", "123", "124",
"125", "126", "127", "128", "129", "130", "131", "132", "133",
"134", "135", "136", "137", "138", "139", "140", "141", "142",
"143", "144", "145", "146", "147", "148", "149", "150", "151",
"152", "153", "154", "155", "156", "157", "158", "159"), NULL))

head(a)
       FECHA    x  y
1 2020-03-09 1  1
2 2020-03-10 2  8
3 2020-03-11 3 14
4 2020-03-12 4 27
5 2020-03-13 5 36
6 2020-03-14 6 43

dput(a)
structure(list(FECHA = structure(c(18330, 18331, 18332, 18333,
18334, 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342,
18343, 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351,
18352, 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360,
18361, 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369,
18370, 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378,
18379, 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396,
18397, 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405,
18406, 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414,
18415, 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423,
18424, 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432,
18433, 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441,
18442, 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450,
18451, 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467, 18468,
18469, 18470, 18471, 18472, 18473, 18474, 18475, 18476, 18477,
18478, 18479, 18480, 18481, 18482, 18483, 18484, 18485, 18486,
18487, 18488), class = "Date"), x = 1:159, y = c(1, 8, 14, 27,
36, 43, 55, 69, 86, 109, 137, 200, 245, 313, 345, 443, 558, 674,
786, 901, 989, 1075, 1181, 1317, 1475, 1673, 1801, 1988, 2100,
2249, 2528, 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779, 6021, 6200,
6378, 6532, 6720, 7090, 7197, 7387, 7523, 7731, 7868, 8070, 8282,
8448, 8616, 8783, 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977,
10116, 10267, 10577, 10926, 11183, 11447, 11728, 12131, 12531,
13015, 13463, 13837, 14095, 14609, 15044, 15463, 16004, 16425,
16854, 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030, 29037,
29905, 30658, 31686, 32785, 33550, 34463, 35237, 35995, 36983,
38149, 39334, 40291, 41251, 42216, 43257, 44352, 45633, 47177,
48096, 49243, 50373, 51408, 52261, 53468, 54426, 55153, 55906,
56817, 57993, 58864, 60296, 61442, 62223, 63269, 64191, 65256,
66383, 67453, 68456, 69424, 70231, 71418, 72560, 73651, 74492,
75394, 76464, 77377, 78446, 79402)), row.names = c(NA, 159L), class =
"data.frame")
Any help and/or guidance will be greatly appreciated,

Cheers,

Paul

	[[alternative HTML version deleted]]


From d@v|d@tn@jone@ @end|ng |rom gm@||@com  Wed Sep  2 04:44:51 2020
From: d@v|d@tn@jone@ @end|ng |rom gm@||@com (David Jones)
Date: Tue, 1 Sep 2020 21:44:51 -0500
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
Message-ID: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>

I ran a number of analyses in R and saved the workspace, which
resulted in a 2GB .RData file. When I try to read the file back into R
later, it won't read into R and provides the error: "Error: cannot
allocate vector of size 37 Kb"

This error comes after 1 minute of trying to read things in - I
presume a single vector sends it over the memory limit. But,
memory.limit() shows that I have access to a full 16gb of ram on my
machine (12 GB are free when I try to load the RData file).

gc() shows the following after I receive this error:

used (Mb) gc trigger (Mb) max used (Mb)
Ncells 623130 33.3 4134347 220.8 5715387 305.3
Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3


From pd@|gd @end|ng |rom gm@||@com  Wed Sep  2 08:41:09 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 2 Sep 2020 08:41:09 +0200
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
Message-ID: <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>

Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x, data=a, ...) otherwise predict will go looking for a$x, no matter what is in xnew. 

But more importantly, nnet() is a _classifier_, so the LHS should be a class, not a numeric variable.

-pd

> On 1 Sep 2020, at 22:19 , Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> Hope you are all doing well. I am currently using R version 4.0.2 and
> working with the nnet package.
> 
> My dataframe consists of three columns, FECHA which is the date, x, which
> is a sequence from 1 to 159, and y, which is the number of covid cases (I
> am also providing the dput for this data frame below).
> 
> I tried fitting a neural net model using the following code:
> 
> xnew = 1:159
> Fit <- nnet(a$y ~ a$x, a, size = 5, maxit = 1000, lineout = T, decay =
> 0.001)
> 
> Finally, I attempted to generate predictions with the following code:
> 
> predictions <- predict(Fit, newdata = list(x = xnew), type = "raw")
> 
> But obtained extremely odd results:
> As you can see, instead of obtaining numbers, more or less in the range of
> the last observations  of a$y, I end up getting a bunch of 1s, which
> doesn?t make any sense (if anyone could help me understand what could be
> causing this):
> dput(predictions)
> structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim = c(159L,
> 1L), .Dimnames = list(c("1", "2", "3", "4", "5", "6", "7", "8",
> "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",
> "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30",
> "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41",
> "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52",
> "53", "54", "55", "56", "57", "58", "59", "60", "61", "62", "63",
> "64", "65", "66", "67", "68", "69", "70", "71", "72", "73", "74",
> "75", "76", "77", "78", "79", "80", "81", "82", "83", "84", "85",
> "86", "87", "88", "89", "90", "91", "92", "93", "94", "95", "96",
> "97", "98", "99", "100", "101", "102", "103", "104", "105", "106",
> "107", "108", "109", "110", "111", "112", "113", "114", "115",
> "116", "117", "118", "119", "120", "121", "122", "123", "124",
> "125", "126", "127", "128", "129", "130", "131", "132", "133",
> "134", "135", "136", "137", "138", "139", "140", "141", "142",
> "143", "144", "145", "146", "147", "148", "149", "150", "151",
> "152", "153", "154", "155", "156", "157", "158", "159"), NULL))
> 
> head(a)
>       FECHA    x  y
> 1 2020-03-09 1  1
> 2 2020-03-10 2  8
> 3 2020-03-11 3 14
> 4 2020-03-12 4 27
> 5 2020-03-13 5 36
> 6 2020-03-14 6 43
> 
> dput(a)
> structure(list(FECHA = structure(c(18330, 18331, 18332, 18333,
> 18334, 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342,
> 18343, 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351,
> 18352, 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360,
> 18361, 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369,
> 18370, 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378,
> 18379, 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396,
> 18397, 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405,
> 18406, 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414,
> 18415, 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423,
> 18424, 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432,
> 18433, 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441,
> 18442, 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450,
> 18451, 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467, 18468,
> 18469, 18470, 18471, 18472, 18473, 18474, 18475, 18476, 18477,
> 18478, 18479, 18480, 18481, 18482, 18483, 18484, 18485, 18486,
> 18487, 18488), class = "Date"), x = 1:159, y = c(1, 8, 14, 27,
> 36, 43, 55, 69, 86, 109, 137, 200, 245, 313, 345, 443, 558, 674,
> 786, 901, 989, 1075, 1181, 1317, 1475, 1673, 1801, 1988, 2100,
> 2249, 2528, 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779, 6021, 6200,
> 6378, 6532, 6720, 7090, 7197, 7387, 7523, 7731, 7868, 8070, 8282,
> 8448, 8616, 8783, 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977,
> 10116, 10267, 10577, 10926, 11183, 11447, 11728, 12131, 12531,
> 13015, 13463, 13837, 14095, 14609, 15044, 15463, 16004, 16425,
> 16854, 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030, 29037,
> 29905, 30658, 31686, 32785, 33550, 34463, 35237, 35995, 36983,
> 38149, 39334, 40291, 41251, 42216, 43257, 44352, 45633, 47177,
> 48096, 49243, 50373, 51408, 52261, 53468, 54426, 55153, 55906,
> 56817, 57993, 58864, 60296, 61442, 62223, 63269, 64191, 65256,
> 66383, 67453, 68456, 69424, 70231, 71418, 72560, 73651, 74492,
> 75394, 76464, 77377, 78446, 79402)), row.names = c(NA, 159L), class =
> "data.frame")
> Any help and/or guidance will be greatly appreciated,
> 
> Cheers,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Sep  2 09:37:28 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 2 Sep 2020 09:37:28 +0200
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
Message-ID: <24399.19384.307117.628619@stat.math.ethz.ch>

>>>>> peter dalgaard 
>>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:

    > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
    > data=a, ...) otherwise predict will go looking for a$x, no
    > matter what is in xnew.  

    > But more importantly, nnet() is a _classifier_, 
    > so the LHS should be a class, not a numeric variable.

    > -pd

Well, nnet() can be used for both classification *and* regression,
which is quite clear from the MASS book, but indeed, not from
its help page, which indeed mentions one formula  'class ~ ...'
and then only has classification examples.

So, indeed, the  ?nnet  help page could improved.

In his case, y are counts,  so  John Tukey's good old
"first aid transformation" principle would suggest to model

sqrt(y) ~ ..   in a *regression* model which nnet() can do.

Martin Maechler
ETH Zurich  and  R Core team



    >> On 1 Sep 2020, at 22:19 , Paul Bernal
    >> <paulbernal07 at gmail.com> wrote:
    >> 
    >> Dear friends,
    >> 
    >> Hope you are all doing well. I am currently using R
    >> version 4.0.2 and working with the nnet package.
    >> 
    >> My dataframe consists of three columns, FECHA which is
    >> the date, x, which is a sequence from 1 to 159, and y,
    >> which is the number of covid cases (I am also providing
    >> the dput for this data frame below).
    >> 
    >> I tried fitting a neural net model using the following
    >> code:
    >> 
    >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
    >> 1000, lineout = T, decay = 0.001)
    >> 
    >> Finally, I attempted to generate predictions with the
    >> following code:
    >> 
    >> predictions <- predict(Fit, newdata = list(x = xnew),
    >> type = "raw")
    >> 
    >> But obtained extremely odd results: As you can see,
    >> instead of obtaining numbers, more or less in the range
    >> of the last observations of a$y, I end up getting a bunch
    >> of 1s, which doesn?t make any sense (if anyone could help
    >> me understand what could be causing this):
    >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
    >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
    >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
    >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
    >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
    >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
    >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
    >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
    >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
    >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
    >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
    >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
    >> "96", "97", "98", "99", "100", "101", "102", "103",
    >> "104", "105", "106", "107", "108", "109", "110", "111",
    >> "112", "113", "114", "115", "116", "117", "118", "119",
    >> "120", "121", "122", "123", "124", "125", "126", "127",
    >> "128", "129", "130", "131", "132", "133", "134", "135",
    >> "136", "137", "138", "139", "140", "141", "142", "143",
    >> "144", "145", "146", "147", "148", "149", "150", "151",
    >> "152", "153", "154", "155", "156", "157", "158", "159"),
    >> NULL))
    >> 
    >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
    >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
    >> 2020-03-14 6 43
    >> 
    >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
    >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
    >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
    >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
    >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
    >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
    >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
    >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
    >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
    >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
    >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
    >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
    >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
    >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
    >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
    >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
    >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
    >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
    >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
    >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
    >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
    >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
    >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
    >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
    >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
    >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
    >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
    >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
    >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
    >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
    >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
    >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
    >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
    >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
    >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
    >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
    >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
    >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
    >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
    >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
    >> "data.frame") Any help and/or guidance will be greatly
    >> appreciated,
    >> 
    >> Cheers,
    >> 
    >> Paul
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > -- 
    > Peter Dalgaard, Professor, Center for Statistics,
    > Copenhagen Business School Solbjerg Plads 3, 2000
    > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
    > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep  2 11:56:12 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 2 Sep 2020 09:56:12 +0000
Subject: [R] augPred and missing data error
Message-ID: <72e84da8b5374afdaebe55ed4e637ab0@SRVEXCHCM1302.precheza.cz>

Dear all

I would like to ask if augPred is able to handle missing values. Here is
example with below data "test".  I read augPred documentation and nothing is
mentioned that fitted object from data with missing values cannot be used in
augPred. Maybe it would be worth to add something.

Or I just did not read it correctly and with some special setting augPred
can handle such objects?

Cheers
Petr Pikal

test data below

test.g <- groupedData(vodivnorm~cas|variable, data=test)
fit <- nlsList(vodivnorm ~ SSbiexp(cas, Al, lrc1, A2, lrc2), data=test.g)
Error in na.fail.default(data) : missing values in object

na.exclude (or na.omit) works as expected

fit <- nlsList(vodivnorm ~ SSbiexp(cas, Al, lrc1, A2, lrc2), data=test.g,
na.action=na.exclude)

However augPred results in error
plot(augPred(fit))
Error in tapply(object[[nm]], groups, FUN[["numeric"]], ...) : 
  arguments must have same length

The workaround is to discard missing values **before** the fit.

test.gs <- test.g[complete.cases(test.g),]
fit <- nlsList(vodivnorm ~ SSbiexp(cas, Al, lrc1, A2, lrc2), data=test.gs)
plot(augPred(fit))

test <- structure(list(cas = c(0L, 10L, 20L, 30L, 40L, 50L, 60L, 65L, 
70L, 72L, 76L, 80L, 90L, 100L, 110L, 120L, 123L, 130L, 140L, 
146L, 0L, 10L, 20L, 30L, 40L, 50L, 60L, 65L, 70L, 72L, 76L, 80L, 
90L, 100L, 110L, 120L, 123L, 130L, 140L, 146L, 0L, 10L, 20L, 
30L, 40L, 50L, 60L, 65L, 70L, 72L, 76L, 80L, 90L, 100L, 110L, 
120L, 123L, 130L, 140L, 146L), variable = structure(c(9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L), .Label = c("vod02", "vod03", "vod04", "vod10", 
"vod11", "vod12", "vod08", "vod09", "vod05", "vod06", "vod07"
), class = "factor"), value = c(45.78, 9.404, 3.915, 2.074, 1.049, 
0.502, 0.248, NA, 0.159, NA, NA, 0.124, 0.11, 0.104, 0.098, NA, 
NA, NA, NA, NA, 45.75, 12.56, 4.125, 2.204, 1.158, 0.653, 0.381, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 47.22, 15.45, 
6.337, 2.736, 1.107, 0.475, 0.241, NA, 0.187, NA, NA, 0.167, 
0.154, 0.147, 0.134, 0.124, NA, 0.114, 0.103, 0.098), vodivnorm = c(1, 
0.205417212756662, 0.0855176933158585, 0.045303626037571,
0.0229139362166885, 
0.0109654871122761, 0.0054172127566623, NA, 0.00347313237221494, 
NA, NA, 0.00270860637833115, 0.00240279598077763, 0.00227173438182612, 
0.00214067278287462, NA, NA, NA, NA, NA, 1, 0.274535519125683, 
0.0901639344262295, 0.0481748633879781, 0.0253114754098361,
0.0142732240437158, 
0.00832786885245902, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, 1, 0.327191867852605, 0.134201609487505, 0.0579415501905972, 
0.0234434561626429, 0.0100592969080898, 0.00510376958915714, 
NA, 0.00396018636171114, NA, NA, 0.00353663701821262, 0.00326132994493859, 
0.0031130876747141, 0.00283778060144007, 0.00262600592969081, 
NA, 0.00241423125794155, 0.00218127911901737, 0.00207539178314274
)), row.names = c("vod05.161", "vod05.162", "vod05.163", "vod05.164", 
"vod05.165", "vod05.166", "vod05.167", "vod05.168", "vod05.169", 
"vod05.170", "vod05.171", "vod05.172", "vod05.173", "vod05.174", 
"vod05.175", "vod05.176", "vod05.177", "vod05.178", "vod05.179", 
"vod05.180", "vod06.181", "vod06.182", "vod06.183", "vod06.184", 
"vod06.185", "vod06.186", "vod06.187", "vod06.188", "vod06.189", 
"vod06.190", "vod06.191", "vod06.192", "vod06.193", "vod06.194", 
"vod06.195", "vod06.196", "vod06.197", "vod06.198", "vod06.199", 
"vod06.200", "vod07.201", "vod07.202", "vod07.203", "vod07.204", 
"vod07.205", "vod07.206", "vod07.207", "vod07.208", "vod07.209", 
"vod07.210", "vod07.211", "vod07.212", "vod07.213", "vod07.214", 
"vod07.215", "vod07.216", "vod07.217", "vod07.218", "vod07.219", 
"vod07.220"), class = "data.frame")

From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Wed Sep  2 13:36:43 2020
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Wed, 2 Sep 2020 13:36:43 +0200
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
Message-ID: <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>



On 02.09.2020 04:44, David Jones wrote:
> I ran a number of analyses in R and saved the workspace, which
> resulted in a 2GB .RData file. When I try to read the file back into R

Compressed in RData but uncompressed in main memory....


> later, it won't read into R and provides the error: "Error: cannot
> allocate vector of size 37 Kb"
> 
> This error comes after 1 minute of trying to read things in - I
> presume a single vector sends it over the memory limit. But,
> memory.limit() shows that I have access to a full 16gb of ram on my
> machine (12 GB are free when I try to load the RData file).

But the data may need more....


> gc() shows the following after I receive this error:
> 
> used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 623130 33.3 4134347 220.8 5715387 305.3
> Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3

So 16GB were used when R gave up.

Best,
Uwe Ligges



> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Sep  2 16:21:58 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 2 Sep 2020 09:21:58 -0500
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <24399.19384.307117.628619@stat.math.ethz.ch>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
Message-ID: <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>

Dear Dr. Martin and Dr. Peter,

Hope you are doing well. Thank you for your kind feedback. I also tried
fitting the nnet using y ~ x, but the model kept on generating odd
predictions. If I understand correctly, from what Dr. Martin said, it would
be a good idea to try modeling sqrt(y) ~ x and then backtransform raising
both y and x to 0.5?

I was looking at a video where the guy modeled count data without doing any
kind of transformation and didn't get odd results, which is rather extrange.

Cheers,

Paul



El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<
maechler at stat.math.ethz.ch>) escribi?:

> >>>>> peter dalgaard
> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
>
>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
>     > data=a, ...) otherwise predict will go looking for a$x, no
>     > matter what is in xnew.
>
>     > But more importantly, nnet() is a _classifier_,
>     > so the LHS should be a class, not a numeric variable.
>
>     > -pd
>
> Well, nnet() can be used for both classification *and* regression,
> which is quite clear from the MASS book, but indeed, not from
> its help page, which indeed mentions one formula  'class ~ ...'
> and then only has classification examples.
>
> So, indeed, the  ?nnet  help page could improved.
>
> In his case, y are counts,  so  John Tukey's good old
> "first aid transformation" principle would suggest to model
>
> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
>
> Martin Maechler
> ETH Zurich  and  R Core team
>
>
>
>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
>     >> <paulbernal07 at gmail.com> wrote:
>     >>
>     >> Dear friends,
>     >>
>     >> Hope you are all doing well. I am currently using R
>     >> version 4.0.2 and working with the nnet package.
>     >>
>     >> My dataframe consists of three columns, FECHA which is
>     >> the date, x, which is a sequence from 1 to 159, and y,
>     >> which is the number of covid cases (I am also providing
>     >> the dput for this data frame below).
>     >>
>     >> I tried fitting a neural net model using the following
>     >> code:
>     >>
>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
>     >> 1000, lineout = T, decay = 0.001)
>     >>
>     >> Finally, I attempted to generate predictions with the
>     >> following code:
>     >>
>     >> predictions <- predict(Fit, newdata = list(x = xnew),
>     >> type = "raw")
>     >>
>     >> But obtained extremely odd results: As you can see,
>     >> instead of obtaining numbers, more or less in the range
>     >> of the last observations of a$y, I end up getting a bunch
>     >> of 1s, which doesn?t make any sense (if anyone could help
>     >> me understand what could be causing this):
>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
>     >> "96", "97", "98", "99", "100", "101", "102", "103",
>     >> "104", "105", "106", "107", "108", "109", "110", "111",
>     >> "112", "113", "114", "115", "116", "117", "118", "119",
>     >> "120", "121", "122", "123", "124", "125", "126", "127",
>     >> "128", "129", "130", "131", "132", "133", "134", "135",
>     >> "136", "137", "138", "139", "140", "141", "142", "143",
>     >> "144", "145", "146", "147", "148", "149", "150", "151",
>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
>     >> NULL))
>     >>
>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
>     >> 2020-03-14 6 43
>     >>
>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
>     >> "data.frame") Any help and/or guidance will be greatly
>     >> appreciated,
>     >>
>     >> Cheers,
>     >>
>     >> Paul
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html and provide
>     >> commented, minimal, self-contained, reproducible code.
>
>     > --
>     > Peter Dalgaard, Professor, Center for Statistics,
>     > Copenhagen Business School Solbjerg Plads 3, 2000
>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html and provide
>     > commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep  2 17:01:22 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Sep 2020 08:01:22 -0700
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
 <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
Message-ID: <19EA33E8-9938-4D7A-B92C-B4258BA0FC0F@dcn.davis.ca.us>

Why would you expect raising y_pred to the 0.5 to "backtransform" a model sqrt(y)~x? Wouldn't you raise to the 2?

Why would you "backtransform" x in such a model if it were never transformed in the first place? Dr Maechler did not suggest that.

And why are you mentioning some random unspecified video on Youtube? That does not enlighten anyone here, apparently including you. Please reference package documentation, and/or reproduce the analysis discussed in that video to provide a contrasting (or supporting) point with the example you gave.


On September 2, 2020 7:21:58 AM PDT, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear Dr. Martin and Dr. Peter,
>
>Hope you are doing well. Thank you for your kind feedback. I also tried
>fitting the nnet using y ~ x, but the model kept on generating odd
>predictions. If I understand correctly, from what Dr. Martin said, it
>would
>be a good idea to try modeling sqrt(y) ~ x and then backtransform
>raising
>both y and x to 0.5?
>
>I was looking at a video where the guy modeled count data without doing
>any
>kind of transformation and didn't get odd results, which is rather
>extrange.
>
>Cheers,
>
>Paul
>
>
>
>El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<
>maechler at stat.math.ethz.ch>) escribi?:
>
>> >>>>> peter dalgaard
>> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
>>
>>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
>>     > data=a, ...) otherwise predict will go looking for a$x, no
>>     > matter what is in xnew.
>>
>>     > But more importantly, nnet() is a _classifier_,
>>     > so the LHS should be a class, not a numeric variable.
>>
>>     > -pd
>>
>> Well, nnet() can be used for both classification *and* regression,
>> which is quite clear from the MASS book, but indeed, not from
>> its help page, which indeed mentions one formula  'class ~ ...'
>> and then only has classification examples.
>>
>> So, indeed, the  ?nnet  help page could improved.
>>
>> In his case, y are counts,  so  John Tukey's good old
>> "first aid transformation" principle would suggest to model
>>
>> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
>>
>> Martin Maechler
>> ETH Zurich  and  R Core team
>>
>>
>>
>>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
>>     >> <paulbernal07 at gmail.com> wrote:
>>     >>
>>     >> Dear friends,
>>     >>
>>     >> Hope you are all doing well. I am currently using R
>>     >> version 4.0.2 and working with the nnet package.
>>     >>
>>     >> My dataframe consists of three columns, FECHA which is
>>     >> the date, x, which is a sequence from 1 to 159, and y,
>>     >> which is the number of covid cases (I am also providing
>>     >> the dput for this data frame below).
>>     >>
>>     >> I tried fitting a neural net model using the following
>>     >> code:
>>     >>
>>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
>>     >> 1000, lineout = T, decay = 0.001)
>>     >>
>>     >> Finally, I attempted to generate predictions with the
>>     >> following code:
>>     >>
>>     >> predictions <- predict(Fit, newdata = list(x = xnew),
>>     >> type = "raw")
>>     >>
>>     >> But obtained extremely odd results: As you can see,
>>     >> instead of obtaining numbers, more or less in the range
>>     >> of the last observations of a$y, I end up getting a bunch
>>     >> of 1s, which doesn?t make any sense (if anyone could help
>>     >> me understand what could be causing this):
>>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
>>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
>>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
>>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
>>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
>>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
>>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
>>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
>>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
>>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
>>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
>>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
>>     >> "96", "97", "98", "99", "100", "101", "102", "103",
>>     >> "104", "105", "106", "107", "108", "109", "110", "111",
>>     >> "112", "113", "114", "115", "116", "117", "118", "119",
>>     >> "120", "121", "122", "123", "124", "125", "126", "127",
>>     >> "128", "129", "130", "131", "132", "133", "134", "135",
>>     >> "136", "137", "138", "139", "140", "141", "142", "143",
>>     >> "144", "145", "146", "147", "148", "149", "150", "151",
>>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
>>     >> NULL))
>>     >>
>>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
>>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
>>     >> 2020-03-14 6 43
>>     >>
>>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
>>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
>>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
>>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
>>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
>>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
>>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
>>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
>>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
>>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
>>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
>>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
>>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
>>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
>>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
>>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
>>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
>>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
>>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
>>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
>>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
>>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
>>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
>>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
>>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
>>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
>>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
>>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
>>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
>>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
>>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
>>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
>>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
>>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
>>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
>>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
>>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
>>     >> "data.frame") Any help and/or guidance will be greatly
>>     >> appreciated,
>>     >>
>>     >> Cheers,
>>     >>
>>     >> Paul
>>     >>
>>     >> [[alternative HTML version deleted]]
>>     >>
>>     >> ______________________________________________
>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> PLEASE do read the posting guide
>>     >> http://www.R-project.org/posting-guide.html and provide
>>     >> commented, minimal, self-contained, reproducible code.
>>
>>     > --
>>     > Peter Dalgaard, Professor, Center for Statistics,
>>     > Copenhagen Business School Solbjerg Plads 3, 2000
>>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
>>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide
>>     > http://www.R-project.org/posting-guide.html and provide
>>     > commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From pd@|gd @end|ng |rom gm@||@com  Wed Sep  2 17:33:57 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 2 Sep 2020 17:33:57 +0200
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
 <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
Message-ID: <7324A23D-0A27-4CF9-BCC5-ADE04F0C11F1@gmail.com>

The problem seems to be the fit rather than the predictions. Looks like nnet is happier with data between 0 and 1, witness

Fit <- nnet(y/max(y) ~ x, a, size = 5, maxit = 1000, lineout = T, decay = 0.001)
plot(y/max(y)~x,a)
lines(fitted(Fit)~x,a)


> On 2 Sep 2020, at 16:21 , Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear Dr. Martin and Dr. Peter, 
> 
> Hope you are doing well. Thank you for your kind feedback. I also tried fitting the nnet using y ~ x, but the model kept on generating odd predictions. If I understand correctly, from what Dr. Martin said, it would be a good idea to try modeling sqrt(y) ~ x and then backtransform raising both y and x to 0.5?
> 
> I was looking at a video where the guy modeled count data without doing any kind of transformation and didn't get odd results, which is rather extrange.
> 
> Cheers,
> 
> Paul
> 
> 
> 
> El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<maechler at stat.math.ethz.ch>) escribi?:
> >>>>> peter dalgaard 
> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
> 
>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
>     > data=a, ...) otherwise predict will go looking for a$x, no
>     > matter what is in xnew.  
> 
>     > But more importantly, nnet() is a _classifier_, 
>     > so the LHS should be a class, not a numeric variable.
> 
>     > -pd
> 
> Well, nnet() can be used for both classification *and* regression,
> which is quite clear from the MASS book, but indeed, not from
> its help page, which indeed mentions one formula  'class ~ ...'
> and then only has classification examples.
> 
> So, indeed, the  ?nnet  help page could improved.
> 
> In his case, y are counts,  so  John Tukey's good old
> "first aid transformation" principle would suggest to model
> 
> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
> 
> Martin Maechler
> ETH Zurich  and  R Core team
> 
> 
> 
>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
>     >> <paulbernal07 at gmail.com> wrote:
>     >> 
>     >> Dear friends,
>     >> 
>     >> Hope you are all doing well. I am currently using R
>     >> version 4.0.2 and working with the nnet package.
>     >> 
>     >> My dataframe consists of three columns, FECHA which is
>     >> the date, x, which is a sequence from 1 to 159, and y,
>     >> which is the number of covid cases (I am also providing
>     >> the dput for this data frame below).
>     >> 
>     >> I tried fitting a neural net model using the following
>     >> code:
>     >> 
>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
>     >> 1000, lineout = T, decay = 0.001)
>     >> 
>     >> Finally, I attempted to generate predictions with the
>     >> following code:
>     >> 
>     >> predictions <- predict(Fit, newdata = list(x = xnew),
>     >> type = "raw")
>     >> 
>     >> But obtained extremely odd results: As you can see,
>     >> instead of obtaining numbers, more or less in the range
>     >> of the last observations of a$y, I end up getting a bunch
>     >> of 1s, which doesn?t make any sense (if anyone could help
>     >> me understand what could be causing this):
>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
>     >> "96", "97", "98", "99", "100", "101", "102", "103",
>     >> "104", "105", "106", "107", "108", "109", "110", "111",
>     >> "112", "113", "114", "115", "116", "117", "118", "119",
>     >> "120", "121", "122", "123", "124", "125", "126", "127",
>     >> "128", "129", "130", "131", "132", "133", "134", "135",
>     >> "136", "137", "138", "139", "140", "141", "142", "143",
>     >> "144", "145", "146", "147", "148", "149", "150", "151",
>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
>     >> NULL))
>     >> 
>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
>     >> 2020-03-14 6 43
>     >> 
>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
>     >> "data.frame") Any help and/or guidance will be greatly
>     >> appreciated,
>     >> 
>     >> Cheers,
>     >> 
>     >> Paul
>     >> 
>     >> [[alternative HTML version deleted]]
>     >> 
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html and provide
>     >> commented, minimal, self-contained, reproducible code.
> 
>     > -- 
>     > Peter Dalgaard, Professor, Center for Statistics,
>     > Copenhagen Business School Solbjerg Plads 3, 2000
>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> 
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html and provide
>     > commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Sep  2 18:45:36 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 2 Sep 2020 11:45:36 -0500
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <19EA33E8-9938-4D7A-B92C-B4258BA0FC0F@dcn.davis.ca.us>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
 <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
 <19EA33E8-9938-4D7A-B92C-B4258BA0FC0F@dcn.davis.ca.us>
Message-ID: <CAMOcQfMf=7wNUm39U06Uub3MRowfeEfC8bw=FthPgOmu7OQJrg@mail.gmail.com>

You are right Jeff, that was a mistake, I was focusing on the square root
and made the mistake of talking about taking the square root instead of
raising to the 2nd power.

This is the example I was following (
https://www.youtube.com/watch?v=SaQgA6V8UA4). Of course, I tried fitting
the nnet model to my own data, to see what kind of results I'd get (the
data that I used, I provided in the very first e-mail).

The question I was asking is why do I get a bunch of 1s for the
predictions, given that the expected results would have to be somewhere
close to the latest observations.

The code and the data from the example I was following is provided in the
youtube link above.

Paul


<https://www.youtube.com/watch?v=SaQgA6V8UA4>

El mi?., 2 sept. 2020 a las 10:01, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
escribi?:

> Why would you expect raising y_pred to the 0.5 to "backtransform" a model
> sqrt(y)~x? Wouldn't you raise to the 2?
>
> Why would you "backtransform" x in such a model if it were never
> transformed in the first place? Dr Maechler did not suggest that.
>
> And why are you mentioning some random unspecified video on Youtube? That
> does not enlighten anyone here, apparently including you. Please reference
> package documentation, and/or reproduce the analysis discussed in that
> video to provide a contrasting (or supporting) point with the example you
> gave.
>
>
> On September 2, 2020 7:21:58 AM PDT, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >Dear Dr. Martin and Dr. Peter,
> >
> >Hope you are doing well. Thank you for your kind feedback. I also tried
> >fitting the nnet using y ~ x, but the model kept on generating odd
> >predictions. If I understand correctly, from what Dr. Martin said, it
> >would
> >be a good idea to try modeling sqrt(y) ~ x and then backtransform
> >raising
> >both y and x to 0.5?
> >
> >I was looking at a video where the guy modeled count data without doing
> >any
> >kind of transformation and didn't get odd results, which is rather
> >extrange.
> >
> >Cheers,
> >
> >Paul
> >
> >
> >
> >El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<
> >maechler at stat.math.ethz.ch>) escribi?:
> >
> >> >>>>> peter dalgaard
> >> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
> >>
> >>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
> >>     > data=a, ...) otherwise predict will go looking for a$x, no
> >>     > matter what is in xnew.
> >>
> >>     > But more importantly, nnet() is a _classifier_,
> >>     > so the LHS should be a class, not a numeric variable.
> >>
> >>     > -pd
> >>
> >> Well, nnet() can be used for both classification *and* regression,
> >> which is quite clear from the MASS book, but indeed, not from
> >> its help page, which indeed mentions one formula  'class ~ ...'
> >> and then only has classification examples.
> >>
> >> So, indeed, the  ?nnet  help page could improved.
> >>
> >> In his case, y are counts,  so  John Tukey's good old
> >> "first aid transformation" principle would suggest to model
> >>
> >> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
> >>
> >> Martin Maechler
> >> ETH Zurich  and  R Core team
> >>
> >>
> >>
> >>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
> >>     >> <paulbernal07 at gmail.com> wrote:
> >>     >>
> >>     >> Dear friends,
> >>     >>
> >>     >> Hope you are all doing well. I am currently using R
> >>     >> version 4.0.2 and working with the nnet package.
> >>     >>
> >>     >> My dataframe consists of three columns, FECHA which is
> >>     >> the date, x, which is a sequence from 1 to 159, and y,
> >>     >> which is the number of covid cases (I am also providing
> >>     >> the dput for this data frame below).
> >>     >>
> >>     >> I tried fitting a neural net model using the following
> >>     >> code:
> >>     >>
> >>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
> >>     >> 1000, lineout = T, decay = 0.001)
> >>     >>
> >>     >> Finally, I attempted to generate predictions with the
> >>     >> following code:
> >>     >>
> >>     >> predictions <- predict(Fit, newdata = list(x = xnew),
> >>     >> type = "raw")
> >>     >>
> >>     >> But obtained extremely odd results: As you can see,
> >>     >> instead of obtaining numbers, more or less in the range
> >>     >> of the last observations of a$y, I end up getting a bunch
> >>     >> of 1s, which doesn?t make any sense (if anyone could help
> >>     >> me understand what could be causing this):
> >>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
> >>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
> >>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
> >>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
> >>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
> >>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
> >>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
> >>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
> >>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
> >>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
> >>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
> >>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
> >>     >> "96", "97", "98", "99", "100", "101", "102", "103",
> >>     >> "104", "105", "106", "107", "108", "109", "110", "111",
> >>     >> "112", "113", "114", "115", "116", "117", "118", "119",
> >>     >> "120", "121", "122", "123", "124", "125", "126", "127",
> >>     >> "128", "129", "130", "131", "132", "133", "134", "135",
> >>     >> "136", "137", "138", "139", "140", "141", "142", "143",
> >>     >> "144", "145", "146", "147", "148", "149", "150", "151",
> >>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
> >>     >> NULL))
> >>     >>
> >>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
> >>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
> >>     >> 2020-03-14 6 43
> >>     >>
> >>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
> >>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
> >>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
> >>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
> >>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
> >>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
> >>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
> >>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
> >>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
> >>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
> >>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
> >>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
> >>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
> >>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
> >>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
> >>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
> >>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
> >>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
> >>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
> >>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
> >>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
> >>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
> >>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
> >>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
> >>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
> >>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
> >>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
> >>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
> >>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
> >>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
> >>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
> >>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
> >>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
> >>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
> >>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
> >>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
> >>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
> >>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
> >>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
> >>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
> >>     >> "data.frame") Any help and/or guidance will be greatly
> >>     >> appreciated,
> >>     >>
> >>     >> Cheers,
> >>     >>
> >>     >> Paul
> >>     >>
> >>     >> [[alternative HTML version deleted]]
> >>     >>
> >>     >> ______________________________________________
> >>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >>     >> PLEASE do read the posting guide
> >>     >> http://www.R-project.org/posting-guide.html and provide
> >>     >> commented, minimal, self-contained, reproducible code.
> >>
> >>     > --
> >>     > Peter Dalgaard, Professor, Center for Statistics,
> >>     > Copenhagen Business School Solbjerg Plads 3, 2000
> >>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
> >>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> >>
> >>     > ______________________________________________
> >>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >>     > PLEASE do read the posting guide
> >>     > http://www.R-project.org/posting-guide.html and provide
> >>     > commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jwd @end|ng |rom @urewe@t@net  Wed Sep  2 22:27:29 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 2 Sep 2020 13:27:29 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
Message-ID: <20200902132729.6e710c03@Draco>

On Wed, 2 Sep 2020 13:36:43 +0200
Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> On 02.09.2020 04:44, David Jones wrote:
> > I ran a number of analyses in R and saved the workspace, which
> > resulted in a 2GB .RData file. When I try to read the file back
> > into R  
> 
> Compressed in RData but uncompressed in main memory....
> 
> 
> > later, it won't read into R and provides the error: "Error: cannot
> > allocate vector of size 37 Kb"
> > 
> > This error comes after 1 minute of trying to read things in - I
> > presume a single vector sends it over the memory limit. But,
> > memory.limit() shows that I have access to a full 16gb of ram on my
> > machine (12 GB are free when I try to load the RData file).  
> 
> But the data may need more....
> 
> 
> > gc() shows the following after I receive this error:
> > 
> > used (Mb) gc trigger (Mb) max used (Mb)
> > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3  
> 
> So 16GB were used when R gave up.
> 
> Best,
> Uwe Ligges

For my own part, looking at the OP's question, it does seem curious
that R could write that .RData file, but on the same system not be able
to reload something it created.  How would that work.  Wouldn't the
memory limit have been exceeded BEFORE the the .RData file was written
the FIRST time?

JDougherty


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep  2 22:32:15 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 2 Sep 2020 13:32:15 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <20200902132729.6e710c03@Draco>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <20200902132729.6e710c03@Draco>
Message-ID: <CAGxFJbTpC-DiZjiKAixzmX0HkUbY7KLpX4Gc1Q+yQRFSZky2jA@mail.gmail.com>

R experts may give you a detailed explanation, but it is certainly possible
that the memory available to R when it wrote the file was different than
when it tried to read it, is it not?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help at r-project.org> wrote:

> On Wed, 2 Sep 2020 13:36:43 +0200
> Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
> > On 02.09.2020 04:44, David Jones wrote:
> > > I ran a number of analyses in R and saved the workspace, which
> > > resulted in a 2GB .RData file. When I try to read the file back
> > > into R
> >
> > Compressed in RData but uncompressed in main memory....
> >
> >
> > > later, it won't read into R and provides the error: "Error: cannot
> > > allocate vector of size 37 Kb"
> > >
> > > This error comes after 1 minute of trying to read things in - I
> > > presume a single vector sends it over the memory limit. But,
> > > memory.limit() shows that I have access to a full 16gb of ram on my
> > > machine (12 GB are free when I try to load the RData file).
> >
> > But the data may need more....
> >
> >
> > > gc() shows the following after I receive this error:
> > >
> > > used (Mb) gc trigger (Mb) max used (Mb)
> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
> >
> > So 16GB were used when R gave up.
> >
> > Best,
> > Uwe Ligges
>
> For my own part, looking at the OP's question, it does seem curious
> that R could write that .RData file, but on the same system not be able
> to reload something it created.  How would that work.  Wouldn't the
> memory limit have been exceeded BEFORE the the .RData file was written
> the FIRST time?
>
> JDougherty
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@v|d@tn@jone@ @end|ng |rom gm@||@com  Wed Sep  2 23:31:53 2020
From: d@v|d@tn@jone@ @end|ng |rom gm@||@com (David Jones)
Date: Wed, 2 Sep 2020 16:31:53 -0500
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
Message-ID: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>

Thank you Uwe, John, and Bert - this is very helpful context.

If it helps inform the discussion, to address John and Bert's
questions - I actually had less memory free when I originally ran the
analyses and saved the workspace, than when I read in the data back in
later on (I rebooted in an attempt to free all possible memory before
rereading the workspace back in).



On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
r-project.org> wrote:

>> On Wed, 2 Sep 2020 13:36:43 +0200
>> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
>>
>> > On 02.09.2020 04:44, David Jones wrote:
>> > > I ran a number of analyses in R and saved the workspace, which
>> > > resulted in a 2GB .RData file. When I try to read the file back
>> > > into R
>> >
>> > Compressed in RData but uncompressed in main memory....
>> >
>> >
>> > > later, it won't read into R and provides the error: "Error: cannot
>> > > allocate vector of size 37 Kb"
>> > >
>> > > This error comes after 1 minute of trying to read things in - I
>> > > presume a single vector sends it over the memory limit. But,
>> > > memory.limit() shows that I have access to a full 16gb of ram on my
>> > > machine (12 GB are free when I try to load the RData file).
>> >
>> > But the data may need more....
>> >
>> >
>> > > gc() shows the following after I receive this error:
>> > >
>> > > used (Mb) gc trigger (Mb) max used (Mb)
>> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
>> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
>> >
>> > So 16GB were used when R gave up.
>> >
>> > Best,
>> > Uwe Ligges
>>
>> For my own part, looking at the OP's question, it does seem curious
>> that R could write that .RData file, but on the same system not be able
>> to reload something it created.  How would that work.  Wouldn't the
>> memory limit have been exceeded BEFORE the the .RData file was written
>> the FIRST time?
>>
>> JDougherty


>R experts may give you a detailed explanation, but it is certainly possible
>that the memory available to R when it wrote the file was different than
>when it tried to read it, is it not?

>Bert Gunter

>"The trouble with having an open mind is that people keep coming along and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From |e@ndrom@r|no @end|ng |rom |e@ndrom@r|no@com@br  Thu Sep  3 01:21:53 2020
From: |e@ndrom@r|no @end|ng |rom |e@ndrom@r|no@com@br (Leandro Marino)
Date: Wed, 2 Sep 2020 20:21:53 -0300
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
Message-ID: <CAKSaaF=RskDefRehCW66Shhd-2YVHR6CTRpmnESJH6F6Q_9gow@mail.gmail.com>

David,

If the ".Rdata" contains more than one object you could (and maybe should
use) the SOAR package (from Venables). This package helps you to split the
objects over multiple RData files. It's useful when you have numerous
medium-large objects in the workspace but doesn't use then at the same
time.

When use SOAR::Attach(), for instance, it loads the current name of all the
objects and retain than available in the searchpath but without load then
to the memory. As you call, they will be loaded into the memory.

If needed, you can update the object and then store it again with the
SOAR::Store()

For my use, this package is terrific! I use it with an analysis that I need
to repeat over medium-large similars datasets.

Best
Leandro

Em qua., 2 de set. de 2020 ?s 18:33, David Jones <david.tn.jones at gmail.com>
escreveu:

> Thank you Uwe, John, and Bert - this is very helpful context.
>
> If it helps inform the discussion, to address John and Bert's
> questions - I actually had less memory free when I originally ran the
> analyses and saved the workspace, than when I read in the data back in
> later on (I rebooted in an attempt to free all possible memory before
> rereading the workspace back in).
>
>
>
> On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
> r-project.org> wrote:
>
> >> On Wed, 2 Sep 2020 13:36:43 +0200
> >> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
> >>
> >> > On 02.09.2020 04:44, David Jones wrote:
> >> > > I ran a number of analyses in R and saved the workspace, which
> >> > > resulted in a 2GB .RData file. When I try to read the file back
> >> > > into R
> >> >
> >> > Compressed in RData but uncompressed in main memory....
> >> >
> >> >
> >> > > later, it won't read into R and provides the error: "Error: cannot
> >> > > allocate vector of size 37 Kb"
> >> > >
> >> > > This error comes after 1 minute of trying to read things in - I
> >> > > presume a single vector sends it over the memory limit. But,
> >> > > memory.limit() shows that I have access to a full 16gb of ram on my
> >> > > machine (12 GB are free when I try to load the RData file).
> >> >
> >> > But the data may need more....
> >> >
> >> >
> >> > > gc() shows the following after I receive this error:
> >> > >
> >> > > used (Mb) gc trigger (Mb) max used (Mb)
> >> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> >> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
> >> >
> >> > So 16GB were used when R gave up.
> >> >
> >> > Best,
> >> > Uwe Ligges
> >>
> >> For my own part, looking at the OP's question, it does seem curious
> >> that R could write that .RData file, but on the same system not be able
> >> to reload something it created.  How would that work.  Wouldn't the
> >> memory limit have been exceeded BEFORE the the .RData file was written
> >> the FIRST time?
> >>
> >> JDougherty
>
>
> >R experts may give you a detailed explanation, but it is certainly
> possible
> >that the memory available to R when it wrote the file was different than
> >when it tried to read it, is it not?
>
> >Bert Gunter
>
> >"The trouble with having an open mind is that people keep coming along and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  3 01:51:15 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Sep 2020 16:51:15 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
Message-ID: <FE6986EB-431B-4B17-8FCB-FB60572B374A@dcn.davis.ca.us>

You need more RAM to load this file. As the memory was being used in your original file, certain objects (such as numeric columns) were being shared among different higher-level objects (such as data frames). When serialized into the file those optimizations were lost, and now those columns are stored separately.

Search [1] for "shared" to learn more about measuring object memory requirements.

[1] http://adv-r.had.co.nz/memory.html

On September 2, 2020 2:31:53 PM PDT, David Jones <david.tn.jones at gmail.com> wrote:
>Thank you Uwe, John, and Bert - this is very helpful context.
>
>If it helps inform the discussion, to address John and Bert's
>questions - I actually had less memory free when I originally ran the
>analyses and saved the workspace, than when I read in the data back in
>later on (I rebooted in an attempt to free all possible memory before
>rereading the workspace back in).
>
>
>
>On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
>r-project.org> wrote:
>
>>> On Wed, 2 Sep 2020 13:36:43 +0200
>>> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
>>>
>>> > On 02.09.2020 04:44, David Jones wrote:
>>> > > I ran a number of analyses in R and saved the workspace, which
>>> > > resulted in a 2GB .RData file. When I try to read the file back
>>> > > into R
>>> >
>>> > Compressed in RData but uncompressed in main memory....
>>> >
>>> >
>>> > > later, it won't read into R and provides the error: "Error:
>cannot
>>> > > allocate vector of size 37 Kb"
>>> > >
>>> > > This error comes after 1 minute of trying to read things in - I
>>> > > presume a single vector sends it over the memory limit. But,
>>> > > memory.limit() shows that I have access to a full 16gb of ram on
>my
>>> > > machine (12 GB are free when I try to load the RData file).
>>> >
>>> > But the data may need more....
>>> >
>>> >
>>> > > gc() shows the following after I receive this error:
>>> > >
>>> > > used (Mb) gc trigger (Mb) max used (Mb)
>>> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
>>> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
>>> >
>>> > So 16GB were used when R gave up.
>>> >
>>> > Best,
>>> > Uwe Ligges
>>>
>>> For my own part, looking at the OP's question, it does seem curious
>>> that R could write that .RData file, but on the same system not be
>able
>>> to reload something it created.  How would that work.  Wouldn't the
>>> memory limit have been exceeded BEFORE the the .RData file was
>written
>>> the FIRST time?
>>>
>>> JDougherty
>
>
>>R experts may give you a detailed explanation, but it is certainly
>possible
>>that the memory available to R when it wrote the file was different
>than
>>when it tried to read it, is it not?
>
>>Bert Gunter
>
>>"The trouble with having an open mind is that people keep coming along
>and
>>sticking things into it."
>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From herd_dog @end|ng |rom cox@net  Thu Sep  3 02:29:54 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Wed, 2 Sep 2020 17:29:54 -0700
Subject: [R] .grb2 Files
Message-ID: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>

Any advise about how to get NOAA .grb2 files into R?

Thanks.
	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Sep  3 02:57:28 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 2 Sep 2020 20:57:28 -0400
Subject: [R] .grb2 Files
In-Reply-To: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>
References: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>
Message-ID: <CAM_vjukc1uoKCye2P6w_bxWuUBozdnRt0G4TMvZ7Zi8OEHC+_g@mail.gmail.com>

GDAL supports GRIB2 so it should be easy using rgdal and raster packages.

Sarah

On Wed, Sep 2, 2020 at 8:32 PM Philip <herd_dog at cox.net> wrote:
>
> Any advise about how to get NOAA .grb2 files into R?
>
> Thanks.
-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Sep  3 02:59:24 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 2 Sep 2020 17:59:24 -0700
Subject: [R] .grb2 Files
In-Reply-To: <CAM_vjukc1uoKCye2P6w_bxWuUBozdnRt0G4TMvZ7Zi8OEHC+_g@mail.gmail.com>
References: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>
 <CAM_vjukc1uoKCye2P6w_bxWuUBozdnRt0G4TMvZ7Zi8OEHC+_g@mail.gmail.com>
Message-ID: <5652a48b-e50c-fc67-303d-3fdc15d464a4@comcast.net>

A very simple search (= "CRAN NOAA .grb2") and small bit of reading help 
files suggests that you might want wgrib2 and rNOMADS

https://rdrr.io/cran/rNOMADS/man/GribInfo.html

https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/

-- 

David

On 9/2/20 5:57 PM, Sarah Goslee wrote:
> GDAL supports GRIB2 so it should be easy using rgdal and raster packages.
>
> Sarah
>
> On Wed, Sep 2, 2020 at 8:32 PM Philip <herd_dog at cox.net> wrote:
>> Any advise about how to get NOAA .grb2 files into R?
>>
>> Thanks.


From he@h@m|bb @end|ng |rom y@hoo@com  Thu Sep  3 03:13:08 2020
From: he@h@m|bb @end|ng |rom y@hoo@com (Hesham A. AL-bukhaiti)
Date: Thu, 3 Sep 2020 01:13:08 +0000 (UTC)
Subject: [R] statment can tacke value in row1 and rows
References: <167820381.2055618.1599095588454.ref@mail.yahoo.com>
Message-ID: <167820381.2055618.1599095588454@mail.yahoo.com>

hello.I have this code :#################################3#read data just thee columns. first and second columns are catogary , third column? is number.?out<-read.csv("outbr.csv")
truth<-out[,seq(1,2)]?#truth about 2000 rows, some values in row1 can? show in rows2,and the some values in row2 can also show in row1 :
#for example :#G1(row1), G2(row2)
#G2(row1),G1(row2)
#if this happend add to thrid column in truth 1 otherwise add 0 as in statment followtruth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3Q:# i want make loop take all 2000 rows and comparsion between all values in row one and row two :
#Gi(value in row1), Gj(value in row2)
#Gj(varow1),Gi(row2),?#############more :#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?
(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  3 03:27:24 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 2 Sep 2020 18:27:24 -0700
Subject: [R] statment can tacke value in row1 and rows
In-Reply-To: <167820381.2055618.1599095588454@mail.yahoo.com>
References: <167820381.2055618.1599095588454.ref@mail.yahoo.com>
 <167820381.2055618.1599095588454@mail.yahoo.com>
Message-ID: <CAGxFJbT+bNANdOLVqk_F1v4yZb1XT0E7=bSUHKSvpN6+M=KMrQ@mail.gmail.com>

Please re-post in plain text. This is a plain text list and html can get
messed up, as here.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 2, 2020 at 6:18 PM Hesham A. AL-bukhaiti via R-help <
r-help at r-project.org> wrote:

> hello.I have this code :#################################3#read data just
> thee columns. first and second columns are catogary , third column  is
> number. out<-read.csv("outbr.csv")
> truth<-out[,seq(1,2)] #truth about 2000 rows, some values in row1 can
> show in rows2,and the some values in row2 can also show in row1 :
> #for example :#G1(row1), G2(row2)
> #G2(row1),G1(row2)
> #if this happend add to thrid column in truth 1 otherwise add 0 as in
> statment
> followtruth<-cbind(as.character(truth[,1]),as.character(truth[,2])
>    ,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make
> loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" &
> truth[,2]=="G2") | (truth[,1]=="G2" &
> truth[,2]=="G3"),3]<-1 ###############################3Q:# i want make loop
> take all 2000 rows and comparsion between all values in row one and row two
> :
> #Gi(value in row1), Gj(value in row2)
> #Gj(varow1),Gi(row2), #############more :#here just G2 and G3, i want make
> loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" &
> truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1
> (Simply they regulate the other. If element A is in the first group , and
> it is related to element B in the second group , and element B also in  in
> the first group , and it is related to element A(the same element  in the
> first group)  in the second group , we write 1 and otherwise 0.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jwd @end|ng |rom @urewe@t@net  Thu Sep  3 03:32:42 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 2 Sep 2020 18:32:42 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
Message-ID: <20200902183242.6719ead3@Draco>

On Wed, 2 Sep 2020 16:31:53 -0500
David Jones <david.tn.jones at gmail.com> wrote:

> Thank you Uwe, John, and Bert - this is very helpful context.
> 
> If it helps inform the discussion, to address John and Bert's
> questions - I actually had less memory free when I originally ran the
> analyses and saved the workspace, than when I read in the data back in
> later on (I rebooted in an attempt to free all possible memory before
> rereading the workspace back in).
> 
I assumed that, though I shouldn't have.  Nice to know.  Were you
working from a terminal or through a GUI like RStudio?  You will need
to provide a really clear description of the initial and later
conditions.  Your step to reboot and then load is exactly what I would
have done, I would also have killed any network connection temporarily
to see if there are other things going on that caused the problem out
side of R.  You should also let any potential helper know what OS you
are using, and what hardware configuration you have.  Since you
rebooted you are probably not working across a network, but ...

JWDougherty


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep  3 05:27:17 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 3 Sep 2020 13:27:17 +1000
Subject: [R] statment can tacke value in row1 and rows
In-Reply-To: <167820381.2055618.1599095588454@mail.yahoo.com>
References: <167820381.2055618.1599095588454.ref@mail.yahoo.com>
 <167820381.2055618.1599095588454@mail.yahoo.com>
Message-ID: <CA+8X3fUQqzmSTxha2HH-9F9q6JbQ3U2Xd7yKrwb4vBgamO3SHQ@mail.gmail.com>

Hi Hesham,
It think you are looking for something like this:

truth<-data.frame(G1=sample(LETTERS[1:4],20,TRUE),
 G2=sample(LETTERS[1:4],20,TRUE))
truth
truth$G3<-as.numeric(truth$G1 == truth$G2)
truth

Note that like quite a few emails produced with Javascript formatting,
there are embedded characters that R can't interpret.

Jim

On Thu, Sep 3, 2020 at 11:18 AM Hesham A. AL-bukhaiti via R-help
<r-help at r-project.org> wrote:
>
> hello.I have this code :#################################3#read data just thee columns. first and second columns are catogary , third column  is number. out<-read.csv("outbr.csv")
> truth<-out[,seq(1,2)] #truth about 2000 rows, some values in row1 can  show in rows2,and the some values in row2 can also show in row1 :
> #for example :#G1(row1), G2(row2)
> #G2(row1),G1(row2)
> #if this happend add to thrid column in truth 1 otherwise add 0 as in statment followtruth<-cbind(as.character(truth[,1]),as.character(truth[,2])             ,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1 ###############################3Q:# i want make loop take all 2000 rows and comparsion between all values in row one and row two :
> #Gi(value in row1), Gj(value in row2)
> #Gj(varow1),Gi(row2), #############more :#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1
> (Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in  in the first group , and it is related to element A(the same element  in the first group)  in the second group , we write 1 and otherwise 0.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pr|yb|o|n|o @end|ng |rom gm@||@com  Wed Sep  2 13:12:04 2020
From: pr|yb|o|n|o @end|ng |rom gm@||@com (Dr Priyanka Jain)
Date: Wed, 2 Sep 2020 16:42:04 +0530
Subject: [R] Error in running diffcoexp
In-Reply-To: <CANVWkqevFHYiLauYZV0cars+HmVjra-TUc9kK+n=NjdE2u-qMw@mail.gmail.com>
References: <CANVWkqevFHYiLauYZV0cars+HmVjra-TUc9kK+n=NjdE2u-qMw@mail.gmail.com>
Message-ID: <CANVWkqeMXx4Cd0CuMt4ua5etiHY5_K3noWmscTp2gNqwPAAHZA@mail.gmail.com>

Dear Sir/ Madam,
                             I am getting the following error:


geneExp <- read.table("DV_control_FPKM.txt",header=T, sep="\t",row.names=1)
geneExp=as.matrix(as.data.frame(geneExp))
head(geneExp)
geneExp2 <- read.table("DV_introgressed_line_FPKM.txt",header=T,
sep="\t",row.names=1)
geneExp2=as.matrix(as.data.frame(geneExp))
head(geneExp2)
library(diffcoexp)
allowWGCNAThreads()
res=diffcoexp(exprs.1 = geneExp, exprs.2 = geneExp2, r.method = "spearman" )
Error in exprs.1[rownames(exprs.1) != "", ] :
  incorrect number of dimensions

I have attached my input file along with mail
-- 
With Regards,
*Dr Priyanka Jain (PhD)*,
Mobile : 9718854136





-- 
With Regards,
*Dr Priyanka Jain (PhD)*,
Mobile : 9718854136

From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  3 14:54:36 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 3 Sep 2020 12:54:36 +0000
Subject: [R] Error in running diffcoexp
In-Reply-To: <CANVWkqeMXx4Cd0CuMt4ua5etiHY5_K3noWmscTp2gNqwPAAHZA@mail.gmail.com>
References: <CANVWkqevFHYiLauYZV0cars+HmVjra-TUc9kK+n=NjdE2u-qMw@mail.gmail.com>
 <CANVWkqeMXx4Cd0CuMt4ua5etiHY5_K3noWmscTp2gNqwPAAHZA@mail.gmail.com>
Message-ID: <493e330d020a4b0db585c724add24eaf@SRVEXCHCM1302.precheza.cz>

Hi.

See inline

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Priyanka Jain
> Sent: Wednesday, September 2, 2020 1:12 PM
> To: r-help at r-project.org
> Subject: [R] Error in running diffcoexp
> 
> Dear Sir/ Madam,
>                              I am getting the following error:
> 
> 
> geneExp <- read.table("DV_control_FPKM.txt",header=T,

already data frame

> sep="\t",row.names=1)
> geneExp=as.matrix(as.data.frame(geneExp))

so as.data.frame unnecessary

> head(geneExp)

better str(geneExp) to see actual structure

> geneExp2 <- read.table("DV_introgressed_line_FPKM.txt",header=T,
> sep="\t",row.names=1)
> geneExp2=as.matrix(as.data.frame(geneExp))
> head(geneExp2)
> library(diffcoexp)
> allowWGCNAThreads()
> res=diffcoexp(exprs.1 = geneExp, exprs.2 = geneExp2, r.method = "spearman"
)
> Error in exprs.1[rownames(exprs.1) != "", ] :
>   incorrect number of dimensions

My guess is that during fiddling with as.data.frame and matrix your data are
not complient with the function
>From help page 
"a SummarizedExperiment, data frame or matrix for condition 1, with gene IDs
as rownames and sample IDs as column names"

> 
> I have attached my input file along with mail

No (or almost no) attachments allowed. Better using dput for sharing data.

Cheers
Petr

> --
> With Regards,
> *Dr Priyanka Jain (PhD)*,
> Mobile : 9718854136
> 
> 
> 
> 
> 
> --
> With Regards,
> *Dr Priyanka Jain (PhD)*,
> Mobile : 9718854136
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From |@t@z@hn @end|ng |rom gm@||@com  Thu Sep  3 15:54:47 2020
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Thu, 3 Sep 2020 09:54:47 -0400
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAKSaaF=RskDefRehCW66Shhd-2YVHR6CTRpmnESJH6F6Q_9gow@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
 <CAKSaaF=RskDefRehCW66Shhd-2YVHR6CTRpmnESJH6F6Q_9gow@mail.gmail.com>
Message-ID: <CA+vqiLGnuLbPvfAhaMXCxhhBtyzGuzBYKA7huEd6vrB3WrhY-w@mail.gmail.com>

On Wed, Sep 2, 2020 at 7:22 PM Leandro Marino
<leandromarino at leandromarino.com.br> wrote:
>
> David,
>
> If the ".Rdata" contains more than one object you could (and maybe should
> use) the SOAR package (from Venables). This package helps you to split the
> objects over multiple RData files. It's useful when you have numerous
> medium-large objects in the workspace but doesn't use then at the same
> time.
>
> When use SOAR::Attach(), for instance, it loads the current name of all the
> objects and retain than available in the searchpath but without load then
> to the memory. As you call, they will be loaded into the memory.
>
> If needed, you can update the object and then store it again with the
> SOAR::Store()
>
> For my use, this package is terrific! I use it with an analysis that I need
> to repeat over medium-large similars datasets.
>

The qs package might also be worth a try. I don't have a specific
reason for thinking it will avoid the original problem, but in general
qs uses lots of fancy compression and memory management features.

--Ista

> Best
> Leandro
>
> Em qua., 2 de set. de 2020 ?s 18:33, David Jones <david.tn.jones at gmail.com>
> escreveu:
>
> > Thank you Uwe, John, and Bert - this is very helpful context.
> >
> > If it helps inform the discussion, to address John and Bert's
> > questions - I actually had less memory free when I originally ran the
> > analyses and saved the workspace, than when I read in the data back in
> > later on (I rebooted in an attempt to free all possible memory before
> > rereading the workspace back in).
> >
> >
> >
> > On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
> > r-project.org> wrote:
> >
> > >> On Wed, 2 Sep 2020 13:36:43 +0200
> > >> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
> > >>
> > >> > On 02.09.2020 04:44, David Jones wrote:
> > >> > > I ran a number of analyses in R and saved the workspace, which
> > >> > > resulted in a 2GB .RData file. When I try to read the file back
> > >> > > into R
> > >> >
> > >> > Compressed in RData but uncompressed in main memory....
> > >> >
> > >> >
> > >> > > later, it won't read into R and provides the error: "Error: cannot
> > >> > > allocate vector of size 37 Kb"
> > >> > >
> > >> > > This error comes after 1 minute of trying to read things in - I
> > >> > > presume a single vector sends it over the memory limit. But,
> > >> > > memory.limit() shows that I have access to a full 16gb of ram on my
> > >> > > machine (12 GB are free when I try to load the RData file).
> > >> >
> > >> > But the data may need more....
> > >> >
> > >> >
> > >> > > gc() shows the following after I receive this error:
> > >> > >
> > >> > > used (Mb) gc trigger (Mb) max used (Mb)
> > >> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> > >> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
> > >> >
> > >> > So 16GB were used when R gave up.
> > >> >
> > >> > Best,
> > >> > Uwe Ligges
> > >>
> > >> For my own part, looking at the OP's question, it does seem curious
> > >> that R could write that .RData file, but on the same system not be able
> > >> to reload something it created.  How would that work.  Wouldn't the
> > >> memory limit have been exceeded BEFORE the the .RData file was written
> > >> the FIRST time?
> > >>
> > >> JDougherty
> >
> >
> > >R experts may give you a detailed explanation, but it is certainly
> > possible
> > >that the memory available to R when it wrote the file was different than
> > >when it tried to read it, is it not?
> >
> > >Bert Gunter
> >
> > >"The trouble with having an open mind is that people keep coming along and
> > >sticking things into it."
> > >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep  3 19:36:05 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 3 Sep 2020 13:36:05 -0400
Subject: [R] [R-pkgs] new ivreg package for 2SLS regression with diagnostics
Message-ID: <febda047-9c87-840b-d995-41e58d116021@mcmaster.ca>

Dear list members,

Christian Kleiber, Achim Zeileis, and I would like to announce a new 
CRAN package, ivreg, which provides a comprehensive implementation of 
instrumental variables estimation using two-stage least-squares (2SLS) 
regression.

The standard regression functionality (parameter estimation, inference, 
robust covariances, predictions, etc.) in the package is derived from 
and supersedes the ivreg() function in the AER package. Additionally, 
various regression diagnostics are supported, including hat values, 
deletion diagnostics such as studentized residuals and Cook's distances; 
graphical diagnostics such as component-plus-residual plots and 
added-variable plots; and effect plots with partial residuals. In order 
to provide these features, the ivreg package integrates seamlessly with 
other packages through suitable S3 methods, specifically for generic 
functions in the base-R stats package, and in the car, effects, lmtest, 
and sandwich packages, among others.

The ivreg package is accompanied by two online vignettes: a brief 
general introduction to the package, and an introduction to the 
regression diagnostics and graphics that are provided.

For more information, see the ivreg CRAN webpage at 
<https://cran.r-project.org/package=ivreg> and the ivreg pkgdown webpage 
at <https://john-d-fox.github.io/ivreg/>.

Comments, suggestions, and bug reports would be appreciated.

John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From |e@||e@rutkow@k| @end|ng |rom gm@||@com  Thu Sep  3 19:44:34 2020
From: |e@||e@rutkow@k| @end|ng |rom gm@||@com (Leslie Rutkowski)
Date: Thu, 3 Sep 2020 13:44:34 -0400
Subject: [R] Assigning cores
Message-ID: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>

Hi all,

I'm working on a large simulation and I'm using the doParallel package to
parallelize my work. I have 20 cores on my machine and would like to
preserve some for day-to-day activities - word processing, sending emails,
etc.

I started by saving 1 core and it was clear that *everything* was so slow
as to be nearly unusable.

Any suggestions on how many cores to hold back (e.g., not to put to work on
the parallel process)?

Thanks,
Leslie

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Sep  3 19:51:22 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Thu, 03 Sep 2020 13:51:22 -0400
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <20200903135122.Horde.bOYJpYRDmOAg-IEW0YsOpIA@www.ontargettek.com>

Hi Leslie and all.

You may want to investigate using SparklyR on a cloud environment like  
AWS, where you have more packages that are designed to work on cluster  
computing environments and you have more control over those types of  
parallel operations.


V/r,

Tom W.


Quoting Leslie Rutkowski <leslie.rutkowski at gmail.com>:

> Hi all,
>
> I'm working on a large simulation and I'm using the doParallel package to
> parallelize my work. I have 20 cores on my machine and would like to
> preserve some for day-to-day activities - word processing, sending emails,
> etc.
>
> I started by saving 1 core and it was clear that *everything* was so slow
> as to be nearly unusable.
>
> Any suggestions on how many cores to hold back (e.g., not to put to work on
> the parallel process)?
>
> Thanks,
> Leslie
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@r||61 @end|ng |rom w|ndow@||ve@com  Thu Sep  3 20:36:44 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-3?Q?ahmet_varl=B9?=)
Date: Thu, 3 Sep 2020 18:36:44 +0000
Subject: [R] calculating linear regression for each word cell
Message-ID: <VI1PR0302MB31990D2BA95E068E965B7009BB2C0@VI1PR0302MB3199.eurprd03.prod.outlook.com>

Hi all,



I have 71 raster for each year. I am trying to convert all raster layer to 1 array (94 ,192 , 71) and then ? would calculate for each word cell a linear regression that shows the change but i dont know how ? can do this


For creating array with rasters between 1949 and 2019

library(raster)
r<-raster("C:/max_consecutive_days_1949.tif")
a<-array(NA,dim=c(dim(r)[1:2],71))
i <- 1
for (year in 1949:2019) {
  fi<-paste0("C:/ max_consecutive_days_",year,".tif")
  r<-raster(fi)
  a[,,i]<-getValues(r,format="matrix")
            i<-i+1
}

Windows 10 i?in Posta<https://go.microsoft.com/fwlink/?LinkId=550986> ile g?nderildi


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  3 20:58:33 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 03 Sep 2020 11:58:33 -0700
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
References: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <CD816A55-28E8-43CF-AFC7-D0FFA35A4CF7@dcn.davis.ca.us>

Do you have 20 actual cores or 10 cores/20 threads? detectCores() doesn't usually know the difference but the CPU may be too busy accessing memory to let that last thread get any useful work done. I often find that allocating real cores is more practical than thinking in terms of thread so try allocating 9 workers and watch your cpu usage.

Experiment with your settings... the right balance may be dependent on your other activities as well as your hardware, since your analysis may not be completely memory access limited and threads might make (some) sense for you.

On September 3, 2020 10:44:34 AM PDT, Leslie Rutkowski <leslie.rutkowski at gmail.com> wrote:
>Hi all,
>
>I'm working on a large simulation and I'm using the doParallel package
>to
>parallelize my work. I have 20 cores on my machine and would like to
>preserve some for day-to-day activities - word processing, sending
>emails,
>etc.
>
>I started by saving 1 core and it was clear that *everything* was so
>slow
>as to be nearly unusable.
>
>Any suggestions on how many cores to hold back (e.g., not to put to
>work on
>the parallel process)?
>
>Thanks,
>Leslie
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Thu Sep  3 22:32:39 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 3 Sep 2020 22:32:39 +0200
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
References: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <20200903203239.GC1771@posteo.no>

On 2020-09-03 13:44 -0400, Leslie Rutkowski wrote:
> Hi all,
> 
> I'm working on a large simulation and 
> I'm using the doParallel package to 
> parallelize my work. I have 20 cores 
> on my machine and would like to 
> preserve some for day-to-day 
> activities - word processing, sending 
> emails, etc.
> 
> I started by saving 1 core and it was 
> clear that *everything* was so slow as 
> to be nearly unusable.
> 
> Any suggestions on how many cores to 
> hold back (e.g., not to put to work on 
> the parallel process)?

Dear Leslie,

you can also use the core parallel 
package.  See ?parallel::makeCluster and 
?parallel::parSapply.

Here I run the function FUN on the 
vector 1:3 over three threads.  FUN 
needs otherFun, so you can export it to 
the cluster.  Remember to stop the 
cluster in the end.

	cl <- parallel::makeCluster(3)
	FUN <- function(x) {
	  return(otherFun(x^2))
	}
	otherFun <- function(x) {
	  return(x+1)
	}
	parallel::clusterExport(cl, "otherFun")
	parallel::parSapply(
	  cl=cl,
	  X=1:3,
	  FUN=FUN)
	parallel::stopCluster(cl)

You could run e.g. 15 cores or 
something?  parallel::makeCluster(15) 
...

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200903/30aa348d/attachment.sig>

From peter@|@ng|e|der @end|ng |rom gm@||@com  Thu Sep  3 22:56:38 2020
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 3 Sep 2020 13:56:38 -0700
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
References: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <CA+hbrhUdmSqCpGUSHd2UTgV_Kmw+j=DX3Hvn+Yo8Zz47+jtkKg@mail.gmail.com>

The big question is whether each worker or thread uses parallel
processing itself, or whether it uses resources like cache in which
case 20 threads fighting over the cache would slow you down
substantially. If your simulations use operations implemented in BLAS
or LAPACK, be aware that some R installations use custom fast BLAS
that can use multiple cores and the processor cache. You can see some
of it in sessionInfo().

The other issue is memory usage - if you exhaust your physical RAM,
your computer will slow down not so much because of CPU load but
rather because of memory management (swapping to and from disk).

I would run some smaller experimental runs that take just a minute or
two to finish with say 4, 8 and 12 workers and see how fast these go -
you may find no or very little speed up past 8 or perhaps even 4-6
workers.

HTH,

Peter

On Thu, Sep 3, 2020 at 10:45 AM Leslie Rutkowski
<leslie.rutkowski at gmail.com> wrote:
>
> Hi all,
>
> I'm working on a large simulation and I'm using the doParallel package to
> parallelize my work. I have 20 cores on my machine and would like to
> preserve some for day-to-day activities - word processing, sending emails,
> etc.
>
> I started by saving 1 core and it was clear that *everything* was so slow
> as to be nearly unusable.
>
> Any suggestions on how many cores to hold back (e.g., not to put to work on
> the parallel process)?
>
> Thanks,
> Leslie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep  4 01:49:23 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 4 Sep 2020 09:49:23 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB3199579461E1E56EC70A5BABBB5E0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
 <CA+8X3fUDzdJ3diRFthS=LzCH6R5wpwaowuBgisYTOETt=vTaQQ@mail.gmail.com>
 <VI1PR0302MB3199E50BAE6DF7AE78178FFCBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fWAexSRCM7mxzv58MTVaQp2rAbeAWtN7Zrd_ffxxXW==g@mail.gmail.com>
 <VI1PR0302MB3199D2DBA9ECD5A24F839B93BB470@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fVHt9MkCzKWvFB3QoeJOxxXkpgTw_omNKXfT1AqqM9QWA@mail.gmail.com>
 <VI1PR0302MB319998C51816A238854844C4BB440@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUADTEMxtjJNWs6dvdGvBZCF-7YWwS+XcUAzXOqPhYdXw@mail.gmail.com>
 <VI1PR0302MB3199579461E1E56EC70A5BABBB5E0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fU_tM4+Cv79SP6KY5fFPaxUimvXa5fnGCoi-GBgg7gbsA@mail.gmail.com>

Hi Ahmet,
I really can't work out what your problem is. I don't have access to
the data you are using and so cannot inspect "a" to see what might be
in it.

Jim

On Wed, Sep 2, 2020 at 8:54 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
> Hi jim,
>
>
>
> I have a new question. I have 71 years raster data from 1949 to 2019 and ? am trying to convert these 71 yeears raster an array to calculate a liner regration.
>
>
>
>
>
> library(raster)
>
> r<-raster("C:/Teaching/MSCprojects/2020/Ahmet/soilm/max_consecutive_days/max_consecutive_days_1949.tif")
>
> a<-array(NA,dim=c(dim(r)[1:2],70))
>
> i <- 1
>
> for (year in 1949:2019) {
>
>   fi<-paste0("C:/Teaching/MSCprojects/2020/Ahmet/soilm/max_consecutive_days_",year,".tif")
>
>   r<-raster(fi)
>
>   a[,,i]<-getValues(r,format="matrix")
>
>             i<-i+1
>
> }
>
> Best wishes,
>
> Windows 10 i?in Posta ile g?nderildi
>
>
>
> Kimden: Jim Lemon
> G?nderilme: 10 A?ustos 2020 Pazartesi 06:28
> Kime: ahmet varl?
> Konu: Re: [R] find number of consecutive days in NC files by R
>
>
>
> That's right. If you want to get the result for all cells with valid
> readings, step through the cells, texting for valid data. The result
> will be quite large, so I suggest sending the output to a file:
>
> sink("soil_moisture_result.txt")
> for(i in 1:nrows(soil_moist)) {
>  for(j in 1:ncols(soil_moist)) {
>  if(sum(!is.na(soil_moist[i,j,]) > 0) {
>   # process the cell here and print out the result
>  }
> }
> sink()
>
> caution: untested
>
> Jim
>
> On Mon, Aug 10, 2020 at 2:02 PM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> > Hi Jim,
> >
> >
> >
> > I would like to find out how many consecutive days each cell is under the specific value for a certain date range. ?f I am right your code is for just one cell
> >
> >
> >
> >
> >
> > Kimden: Jim Lemon
> > G?nderilme: 10 A?ustos 2020 Pazartesi 04:23
> > Kime: ahmet varl?; r-help mailing list
> > Konu: Re: [R] find number of consecutive days in NC files by R
> >
> >
> >
> > Hi Ahmet,
> > An easy way is this:
> >
> > library(ncdf4)
> > soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
> > soil_moist<-ncvar_get(soilm)
> > smdim<-dim(soil_moist)
> > # identify NA grid cells
> > sm_NA_count<-matrix(NA,nrow=smdim[1],ncol=smdim[2])
> > for(i in 1:smdim[1]) {
> >  for(j in 1:smdim[2]) {
> >   sm_NA_count[i,j]<-sum(!is.na(soil_moist[i,j,]))
> >  }
> > }
> >
> > The resulting matrix contains the counts of valid (not NA) values in
> > each 365 day series in the array. It looks to me as though there are
> > 5914 complete series and the rest are all NA. This does not tell you
> > why some files (the third dimension) are all NA. Probably the best
> > guess is that the soil moisture content is not measurable for some
> > reason. Here is the explanation from NOAA:
> >
> > Missing Data:
> >
> > There is no missing data though the ocean has 0's. There is a file
> > with the percent of the grid that is land. Another file has simply 1
> > and 0's for land/ocean. Grids where the percent of land is zero are
> > "missing".
> >
> > You can get a feel for the geographic coverage like this (white cells
> > are not NA):
> >
> > library(maps)
> > library(plotrix)
> > color2D.matplot(t(sm_NA_count))
> >
> > Jim
> >
> > On Mon, Aug 10, 2020 at 4:09 AM ahmet varl? <varli61 at windowslive.com> wrote:
> > >
> > > Hi Jim,
> > >
> > >
> > >
> > > Could you help me to remove NA values which are water values ?
> > >
> > >
> > >
> > >
> > >
> > > Kimden: Jim Lemon
> > > G?nderilme: 7 A?ustos 2020 Cuma 22:53
> > > Kime: ahmet varl?
> > > Konu: Re: [R] find number of consecutive days in NC files by R
> > >
> > >
> > >
> > > There are 17848 grid cells in the file I downloaded for 1949. Many of
> > > them only contain NA values, probably because they are from a
> > > geographic grid that is covered by water. In the code there is a
> > > section that prints out a list of the grid cells that contain minimum
> > > values less than 0.3. Since I don't know which grid cell you are
> > > using, I had to find one that would produce interpretable results for
> > > the problem you are trying to solve.
> > >
> > > Jim
> > >
> > > On Fri, Aug 7, 2020 at 11:03 PM ahmet varl? <varli61 at windowslive.com> wrote:
> > > >
> > > > I am greatfull for your helps and ? just want to ask why did you use cell 159,66
> > > >
> > >
> > >
> >
> >
>
>


From @rr@ypro|||e @end|ng |rom y@hoo@com  Fri Sep  4 06:46:58 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Fri, 4 Sep 2020 04:46:58 +0000 (UTC)
Subject: [R] R rounding problem?
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
Message-ID: <1362142831.3113261.1599194818782@mail.yahoo.com>

Hello,

I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.

For exmaple, when I just simply type:

> (6.9-6.3) > 0.6
[1] TRUE

6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!

Similarly, R thinks 5.6-5.5 is smaller than 0.1:

> (5.6-5.5) < 0.1
[1] TRUE

Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.

Can anyone shed a light on how to avoid the issue?

Thanks,

Yi


From jrg @end|ng |rom |oe@|@u@  Fri Sep  4 06:51:34 2020
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Fri, 4 Sep 2020 00:51:34 -0400
Subject: [R] R rounding problem?
In-Reply-To: <1362142831.3113261.1599194818782@mail.yahoo.com>
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
 <1362142831.3113261.1599194818782@mail.yahoo.com>
Message-ID: <dd180af4-703e-dc7f-fb94-8cba54fb98cf@loesl.us>

On 2020-09-04 00:46, array chip via R-help wrote:
> Hello,
>
> I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.
>
> For exmaple, when I just simply type:
>
>> (6.9-6.3) > 0.6
> [1] TRUE
>
> 6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!
>
> Similarly, R thinks 5.6-5.5 is smaller than 0.1:
>
>> (5.6-5.5) < 0.1
> [1] TRUE
>
> Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.
>
> Can anyone shed a light on how to avoid the issue?


Maybe learn a little bit about digital arithmetic?



---JRG




> Thanks,
>
> Yi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Fri Sep  4 07:12:22 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 4 Sep 2020 01:12:22 -0400
Subject: [R] [External]  R rounding problem?
In-Reply-To: <1362142831.3113261.1599194818782@mail.yahoo.com>
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
 <1362142831.3113261.1599194818782@mail.yahoo.com>
Message-ID: <CAGx1TMBEcK6cgchMOVJZfVMRspQuznKWQBXmL68rnAooP=OLWQ@mail.gmail.com>

FAQ 7.31

On Fri, Sep 4, 2020 at 12:47 AM array chip via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.
>
> For exmaple, when I just simply type:
>
> > (6.9-6.3) > 0.6
> [1] TRUE
>
> 6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!
>
> Similarly, R thinks 5.6-5.5 is smaller than 0.1:
>
> > (5.6-5.5) < 0.1
> [1] TRUE
>
> Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.
>
> Can anyone shed a light on how to avoid the issue?
>
> Thanks,
>
> Yi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @rr@ypro|||e @end|ng |rom y@hoo@com  Fri Sep  4 07:38:34 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Fri, 4 Sep 2020 05:38:34 +0000 (UTC)
Subject: [R] [External]  R rounding problem?
In-Reply-To: <CAGx1TMBEcK6cgchMOVJZfVMRspQuznKWQBXmL68rnAooP=OLWQ@mail.gmail.com>
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
 <1362142831.3113261.1599194818782@mail.yahoo.com>
 <CAGx1TMBEcK6cgchMOVJZfVMRspQuznKWQBXmL68rnAooP=OLWQ@mail.gmail.com>
Message-ID: <775217190.119177.1599197914138@mail.yahoo.com>

Thanks Richard. Got it now...


On Thursday, September 3, 2020, 10:12:36 PM PDT, Richard M. Heiberger <rmh at temple.edu> wrote: 


FAQ 7.31

On Fri, Sep 4, 2020 at 12:47 AM array chip via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.
>
> For exmaple, when I just simply type:
>
> > (6.9-6.3) > 0.6
> [1] TRUE
>
> 6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!
>
> Similarly, R thinks 5.6-5.5 is smaller than 0.1:
>
> > (5.6-5.5) < 0.1
> [1] TRUE
>
> Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.
>
> Can anyone shed a light on how to avoid the issue?
>
> Thanks,
>
> Yi

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep  4 09:19:11 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 4 Sep 2020 09:19:11 +0200
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <9DC09EF7-2E8A-42C5-AE2C-6F9DB9FC9D4D@dcn.davis.ca.us>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <9DC09EF7-2E8A-42C5-AE2C-6F9DB9FC9D4D@dcn.davis.ca.us>
Message-ID: <24401.60015.368054.501096@stat.math.ethz.ch>

>>>>> Jeff Newmiller 
>>>>>     on Thu, 06 Aug 2020 10:49:50 -0700 writes:

    > You need to make a small fake dataset that illustrates
    > what you have and what you want out of it. Telling us you
    > are not getting what you want is simply not useful.  

Indeed.

In addition:  Do *not* use  suppressWarnings( . ) lightly !

Warnings are there for a good reason, and you should think hard
and may be ask for help before "blindly" using
suppressWarnings().

Whoever told you to do that routinely
has not been a good teacher of R ..

Best regards,

Martin Maechler
ETH Zurich  and  R Core team

    > On August 6, 2020 8:58:09 AM PDT, "ahmet varl?"
    > <varli61 at windowslive.com> wrote:
    >> Hi all,
    >> 
    >> 
    >> There are 365 days of soil moisture NC files and I am
    >> trying to find out how many days the values are below and
    >> above this certain threshold are repeated by R. However,
    >> I couldn't reach exactly what I wanted. For example,
    >> Daily soil moisture is below 0.3 without interrupting how
    >> many days in 365 days. NC file contains annual soil
    >> moisture values daily
    >> 
    >> nctoarray <- function(ncfname, varid = NA) { nc <-
    >> nc_open(ncfname)
    >> 
    >> a <- aperm(ncvar_get(nc), c(2,1,3)) nc_close(nc) a }
    >> 
    >> 
    >> 
    >> function(x, threshold = 0.28, below = TRUE) {
    >> 
    >> if (below) {
    >> 
    >> y <- ifelse(x < threshold,1,0)
    >> 
    >> } else y <- ifelse(x > threshold,1,0)
    >> 
    >> 
    >> 
    >> y2 <- rle(y)
    >> 
    >> sel <- which(y2$values == 1)
    >> 
    >> max(y2$lengths[sel])
    >> 
    >> }
    >> 
    >> 
    >> 
    >> m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3,
    >> TRUE))
    >> 
    >> 
    >> 
    >> m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4,
    >> FALSE))
    >> 
    >> 
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > -- 
    > Sent from my phone. Please excuse my brevity.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From m|eher1971 @end|ng |rom gm@||@com  Fri Sep  4 03:26:21 2020
From: m|eher1971 @end|ng |rom gm@||@com (Michael Feher)
Date: Thu, 3 Sep 2020 21:26:21 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
Message-ID: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>

Greetings,

I am a brand-new user to R and want to install and run this on my iMac running macOS 10.15.6.  I successfully downloaded the correct package, installed it with no problems (I was not given any options for Tcl/Tk or Texinfo), and started it up as any other normal app.  Some introductory commands like license() and help() worked just fine.  But when I went to execute demo(), it just beach-balled.  I?ve had to force-quit R a number of times.

Yes, I read the Mac installation instructions.

Thanks in advance.

Mike

From m@rc_@chw@rtz @end|ng |rom me@com  Fri Sep  4 14:05:37 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 4 Sep 2020 08:05:37 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
In-Reply-To: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
References: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
Message-ID: <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>


> On Sep 3, 2020, at 9:26 PM, Michael Feher <mfeher1971 at gmail.com> wrote:
> 
> Greetings,
> 
> I am a brand-new user to R and want to install and run this on my iMac running macOS 10.15.6.  I successfully downloaded the correct package, installed it with no problems (I was not given any options for Tcl/Tk or Texinfo), and started it up as any other normal app.  Some introductory commands like license() and help() worked just fine.  But when I went to execute demo(), it just beach-balled.  I?ve had to force-quit R a number of times.
> 
> Yes, I read the Mac installation instructions.
> 
> Thanks in advance.
> 
> Mike


Hi,

Sounds like you need to install XQuartz:

  https://www.xquartz.org

which is referenced in the macOS installation instructions and the macOS specific FAQ.

Also, be aware that there is a macOS specific e-mail list here:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

which is where macOS specific R issues should be posted.

You will need to re-install XQuartz any time you upgrade/install a new version of R.

Regards,

Marc Schwartz


From c@|um@po|w@rt @end|ng |rom nh@@net  Fri Sep  4 17:45:57 2020
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST))
Date: Fri, 4 Sep 2020 15:45:57 +0000
Subject: [R] Survival Object - is 12month survival = 365days
Message-ID: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>

Using survfit I can get the '1 year' Survival from this dataset which holds survival in days:

require (survival)
survfit( Surv(time, status) ~sex, data=colon)
summary (fit, 365)

My current real world data I'm calculating time using lubridate to calculate time and since it made the axis easy I just told it to do and so my "time" appears to be  a float in months.

time <- time_length(interval(startDate, endDate), "months")

Is there a "right" approach to this (as in a convention). If I use 12months as a year and describe it in the write up as 12, 24 and 36 month survival rather than 1, 2 and 3 year presumably that is OK..

I've been asked to report 30, 60 & 90day. Then 6month, 1, 2 and 3 year survival.

Should I calculate time 3 times, (interval day, month and year) and run the survival on each to get the requested outputs or would people just provide something close.

Should I run a campaign to decimilise time?






Sent from Nine<http://www.9folders.com/>


********************************************************************************************************************

This message may contain confidential information. If you are not the intended recipient please inform the
sender that you have received the message in error before deleting it.
Please do not disclose, copy or distribute information in this e-mail or take any action in relation to its contents. To do so is strictly prohibited and may be unlawful. Thank you for your co-operation.

NHSmail is the secure email and directory service available for all NHS staff in England and Scotland. NHSmail is approved for exchanging patient data and other sensitive information with NHSmail and other accredited email services.

For more information and to find out how you can switch, https://portal.nhs.net/help/joiningnhsmail


	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Sep  4 18:27:07 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 4 Sep 2020 12:27:07 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
In-Reply-To: <CAN5WjXKM0cw73O53LAmyzOeTBCdj+SzFKN_+Xw98SaSEgxw-5Q@mail.gmail.com>
References: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
 <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>
 <CAN5WjXKM0cw73O53LAmyzOeTBCdj+SzFKN_+Xw98SaSEgxw-5Q@mail.gmail.com>
Message-ID: <19C1EF5A-0C67-4973-9121-013915E27ABA@me.com>

Hi Mike,

The installation interface has a minimal process, where what may be optional components are left to you to install on your own. Thus, the Installation and Admin manual references these, as does the macOS FAQ, but the wording may leave open to interpretation what may or may not be required, based upon your specific use case. In some use cases, XQuartz would not be required and you need to go to a third party site to obtain it, much like you would need to for MacTeX or similar.

With respect to the lists, each R list is moderated by a volunteer, thus will require a subscription in order to get your posts sent out without manual intervention by the list admins/moderators. For example, I am one of the two Admins for R-Devel, along with Martin M?chler, thus spend some amount of time having to manually approve posts where the poster is not, and does not become a subscriber.

Once you subscribe, and your first post is approved, subsequent posts can get through without manual intervention, which is appreciated.

If you do not want to keep getting posts from the lists, once your issue is resolved, you can return to the list interface, sign into your account, and disable getting the posts. Of course, if you need to interact again in the future, you would need to remember to re-enable the posts being sent, as responses to posts do not always include you as a cc:.

Digests are available, but can be more complicated to interact with, in some cases, depending upon your e-mail client, if you should want to reply to a specific post. You can set this in your account settings for the relevant list if you wish.

One option for you to consider, is that I have server side filters/rules set up for the R lists (and others) that I subscribe to. These then move each e-mail from my main inbox to the relevant online (IMAP) sub-folder for organization. Thus, it keeps my inbox clean and let's me review relevant posts in a more efficient and focused manner.

Regards,

Marc


> On Sep 4, 2020, at 11:43 AM, Mike Feher <mfeher1971 at gmail.com> wrote:
> 
> Good morning Marc,
> 
> Thank you kindly for your quick response.  I had read prior to installation that I might have needed or wanted to install some different packages to support R, but did not catch that XQuartz was a requirement.  (I also never got prompted for various options during the installation of R-4.0.2.pkg.)
> 
> Regarding email lists, perhaps you can assist with this question: While I don't mind becoming a registered member, I prefer not to get email traffic from groups as I have in the past (I actually really hate email for a lot of reasons these days), so I'm wondering, is there a way to get a digest (I thought I saw that) of just a weekly summary of information or questions posted, rather than getting CC:d on every back-and-forth within the user community?  Also, do I have to become an approved user to the R mailing list community or anything like that?  Or are all posts moderated?
> 
> Now that the weekend is upon me, I'll have some time to come up to speed on all this.  Thanks for your patience.
> 
> Thanks again!
> Mike
> 
> On Fri, Sep 4, 2020 at 8:05 AM Marc Schwartz <marc_schwartz at me.com> wrote:
> 
> > On Sep 3, 2020, at 9:26 PM, Michael Feher <mfeher1971 at gmail.com> wrote:
> > 
> > Greetings,
> > 
> > I am a brand-new user to R and want to install and run this on my iMac running macOS 10.15.6.  I successfully downloaded the correct package, installed it with no problems (I was not given any options for Tcl/Tk or Texinfo), and started it up as any other normal app.  Some introductory commands like license() and help() worked just fine.  But when I went to execute demo(), it just beach-balled.  I?ve had to force-quit R a number of times.
> > 
> > Yes, I read the Mac installation instructions.
> > 
> > Thanks in advance.
> > 
> > Mike
> 
> 
> Hi,
> 
> Sounds like you need to install XQuartz:
> 
>   https://www.xquartz.org
> 
> which is referenced in the macOS installation instructions and the macOS specific FAQ.
> 
> Also, be aware that there is a macOS specific e-mail list here:
> 
>   https://stat.ethz.ch/mailman/listinfo/r-sig-mac
> 
> which is where macOS specific R issues should be posted.
> 
> You will need to re-install XQuartz any time you upgrade/install a new version of R.
> 
> Regards,
> 
> Marc Schwartz
> 


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Sep  4 19:32:25 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 4 Sep 2020 13:32:25 -0400
Subject: [R] Survival Object - is 12month survival = 365days
In-Reply-To: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>
References: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>
Message-ID: <E79E13DA-C473-4FC2-B9F5-5378C172EE16@me.com>

On Sep 4, 2020, at 11:45 AM, POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST) via R-help <r-help at r-project.org> wrote:
> 
> Using survfit I can get the '1 year' Survival from this dataset which holds survival in days:
> 
> require (survival)
> survfit( Surv(time, status) ~sex, data=colon)
> summary (fit, 365)
> 
> My current real world data I'm calculating time using lubridate to calculate time and since it made the axis easy I just told it to do and so my "time" appears to be  a float in months.
> 
> time <- time_length(interval(startDate, endDate), "months")
> 
> Is there a "right" approach to this (as in a convention). If I use 12months as a year and describe it in the write up as 12, 24 and 36 month survival rather than 1, 2 and 3 year presumably that is OK..
> 
> I've been asked to report 30, 60 & 90day. Then 6month, 1, 2 and 3 year survival.
> 
> Should I calculate time 3 times, (interval day, month and year) and run the survival on each to get the requested outputs or would people just provide something close.
> 
> Should I run a campaign to decimilise time?

Hi,

The answer may depend upon whether you are presenting the results in a tabular fashion, in the body of a manuscript, or in a figure. Also, what may be the community conventions in your domain. 

If you want to get the irregular time points out in a single output, you can use the times argument to do this, remembering that the default time intervals are in days for this dataset:

> summary(fit, times = c(30, 60, 90, 180, 365.25, 2 * 365.25, 3 * 365.25))
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    887       2    0.998 0.00159        0.995        1.000
   60    880       6    0.991 0.00317        0.985        0.997
   90    869      11    0.979 0.00485        0.969        0.988
  180    827      42    0.931 0.00849        0.915        0.948
  365    731      94    0.825 0.01274        0.801        0.851
  730    595     135    0.673 0.01576        0.643        0.705
 1096    536      57    0.608 0.01641        0.577        0.641

                sex=1 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    962       5    0.995 0.00230        0.990        0.999
   60    955       6    0.989 0.00341        0.982        0.995
   90    947       8    0.980 0.00446        0.972        0.989
  180    906      41    0.938 0.00776        0.923        0.953
  365    819      85    0.850 0.01150        0.828        0.873
  730    679     133    0.711 0.01462        0.683        0.740
 1096    592      84    0.623 0.01566        0.593        0.654


Now, the time output there is arguably a bit cumbersome to read...but, at least you get the relevant values in a single output. You can transform those values as you may require.

Another option is to use the scale argument, but I just noted that, unless I am missing something, I think that there may be a lingering buglet in the code for summary.survfit(), and I am adding Terry Therneau here as a cc:, if that is correct. The behavior of the interaction between the times and scale arguments changed in 2009 after an exchange I had with Thomas Lumley: 

  https://stat.ethz.ch/pipermail/r-devel/2009-April/052901.html

and it is not clear to me if the current behavior is or is not intended after all this time. Albeit, it may be the defacto behavior at this point in either case, given some volume of code written over the years that may depend upon this behavior.

Thus, this may be better for you, using the current behavior:

> summary(fit, scale = 30.44, times = c(1, 2, 3, 6, 12, 24, 36) * 30.44)
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    887       2    0.998 0.00159        0.995        1.000
    2    880       6    0.991 0.00317        0.985        0.997
    3    868      12    0.977 0.00498        0.968        0.987
    6    826      42    0.930 0.00855        0.914        0.947
   12    731      93    0.825 0.01274        0.801        0.851
   24    595     135    0.673 0.01576        0.643        0.705
   36    536      57    0.608 0.01641        0.577        0.641

                sex=1 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    962       5    0.995 0.00230        0.990        0.999
    2    955       6    0.989 0.00341        0.982        0.995
    3    946       9    0.979 0.00458        0.970        0.988
    6    906      40    0.938 0.00776        0.923        0.953
   12    819      85    0.850 0.01150        0.828        0.873
   24    679     133    0.711 0.01462        0.683        0.740
   36    592      84    0.623 0.01566        0.593        0.654


where the times values are now in months over the range of values, instead of days.

I don't use the lubridate package, so there may be other options for you there, but the above will work, if your underlying time intervals in the source data frame for the model are still in days as a unit of measurement. 

Using the base graphics functions, albeit perhaps you are using ggplot or similar, you can plot the above model with axis markings at the irregular time intervals, using something like the following:

plot(fit, xaxt = "n", las = 1, xlim = c(0, 36 * 30.44))
axis(1, at = c(1, 2, 3, 6, 12, 24, 36) * 30.44, labels = c(1, 2, 3, 6, 12, 24, 36), cex.axis = 0.65)

This essentially truncates the x axis to 36 months, since the intervals in the example colon dataset go to about 9 years or so, and does not label the x axis. Bearing in mind that the underlying x axis unit is in days, the axis() function then places labels at the irregular intervals. You could then annotate the plot further as you may desire.

Regards,

Marc Schwartz


From c@|um@po|w@rt @end|ng |rom nh@@net  Fri Sep  4 19:43:08 2020
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST))
Date: Fri, 4 Sep 2020 17:43:08 +0000
Subject: [R] Survival Object - is 12month survival = 365days
In-Reply-To: <E79E13DA-C473-4FC2-B9F5-5378C172EE16@me.com>
References: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>,
 <E79E13DA-C473-4FC2-B9F5-5378C172EE16@me.com>
Message-ID: <f7f51d78-19a5-46c4-999f-3b1a9b2cac4a@nhs.net>

Hi Mark

Huge thanks for the detailed answer.

At the moment, likely to be a mix of tabulation (30, 60, 90), a plot and some narrative with the 6mo, 12mo and so on. I think!

So it sounds like days is the answer, and then estimate months and years from days.

Sent from Nine<http://www.9folders.com/>
________________________________
From: Marc Schwartz <marc_schwartz at me.com>
Sent: Friday, 4 September 2020 18:32
To: POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST)
Cc: R-help; Terry Therneau
Subject: Re: [R] Survival Object - is 12month survival = 365days

On Sep 4, 2020, at 11:45 AM, POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST) via R-help <r-help at r-project.org> wrote:
>
> Using survfit I can get the '1 year' Survival from this dataset which holds survival in days:
>
> require (survival)
> survfit( Surv(time, status) ~sex, data=colon)
> summary (fit, 365)
>
> My current real world data I'm calculating time using lubridate to calculate time and since it made the axis easy I just told it to do and so my "time" appears to be  a float in months.
>
> time <- time_length(interval(startDate, endDate), "months")
>
> Is there a "right" approach to this (as in a convention). If I use 12months as a year and describe it in the write up as 12, 24 and 36 month survival rather than 1, 2 and 3 year presumably that is OK..
>
> I've been asked to report 30, 60 & 90day. Then 6month, 1, 2 and 3 year survival.
>
> Should I calculate time 3 times, (interval day, month and year) and run the survival on each to get the requested outputs or would people just provide something close.
>
> Should I run a campaign to decimilise time?

Hi,

The answer may depend upon whether you are presenting the results in a tabular fashion, in the body of a manuscript, or in a figure. Also, what may be the community conventions in your domain.

If you want to get the irregular time points out in a single output, you can use the times argument to do this, remembering that the default time intervals are in days for this dataset:

> summary(fit, times = c(30, 60, 90, 180, 365.25, 2 * 365.25, 3 * 365.25))
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    887       2    0.998 0.00159        0.995        1.000
   60    880       6    0.991 0.00317        0.985        0.997
   90    869      11    0.979 0.00485        0.969        0.988
  180    827      42    0.931 0.00849        0.915        0.948
  365    731      94    0.825 0.01274        0.801        0.851
  730    595     135    0.673 0.01576        0.643        0.705
 1096    536      57    0.608 0.01641        0.577        0.641

                sex=1
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    962       5    0.995 0.00230        0.990        0.999
   60    955       6    0.989 0.00341        0.982        0.995
   90    947       8    0.980 0.00446        0.972        0.989
  180    906      41    0.938 0.00776        0.923        0.953
  365    819      85    0.850 0.01150        0.828        0.873
  730    679     133    0.711 0.01462        0.683        0.740
 1096    592      84    0.623 0.01566        0.593        0.654


Now, the time output there is arguably a bit cumbersome to read...but, at least you get the relevant values in a single output. You can transform those values as you may require.

Another option is to use the scale argument, but I just noted that, unless I am missing something, I think that there may be a lingering buglet in the code for summary.survfit(), and I am adding Terry Therneau here as a cc:, if that is correct. The behavior of the interaction between the times and scale arguments changed in 2009 after an exchange I had with Thomas Lumley:

  https://stat.ethz.ch/pipermail/r-devel/2009-April/052901.html

and it is not clear to me if the current behavior is or is not intended after all this time. Albeit, it may be the defacto behavior at this point in either case, given some volume of code written over the years that may depend upon this behavior.

Thus, this may be better for you, using the current behavior:

> summary(fit, scale = 30.44, times = c(1, 2, 3, 6, 12, 24, 36) * 30.44)
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    887       2    0.998 0.00159        0.995        1.000
    2    880       6    0.991 0.00317        0.985        0.997
    3    868      12    0.977 0.00498        0.968        0.987
    6    826      42    0.930 0.00855        0.914        0.947
   12    731      93    0.825 0.01274        0.801        0.851
   24    595     135    0.673 0.01576        0.643        0.705
   36    536      57    0.608 0.01641        0.577        0.641

                sex=1
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    962       5    0.995 0.00230        0.990        0.999
    2    955       6    0.989 0.00341        0.982        0.995
    3    946       9    0.979 0.00458        0.970        0.988
    6    906      40    0.938 0.00776        0.923        0.953
   12    819      85    0.850 0.01150        0.828        0.873
   24    679     133    0.711 0.01462        0.683        0.740
   36    592      84    0.623 0.01566        0.593        0.654


where the times values are now in months over the range of values, instead of days.

I don't use the lubridate package, so there may be other options for you there, but the above will work, if your underlying time intervals in the source data frame for the model are still in days as a unit of measurement.

Using the base graphics functions, albeit perhaps you are using ggplot or similar, you can plot the above model with axis markings at the irregular time intervals, using something like the following:

plot(fit, xaxt = "n", las = 1, xlim = c(0, 36 * 30.44))
axis(1, at = c(1, 2, 3, 6, 12, 24, 36) * 30.44, labels = c(1, 2, 3, 6, 12, 24, 36), cex.axis = 0.65)

This essentially truncates the x axis to 36 months, since the intervals in the example colon dataset go to about 9 years or so, and does not label the x axis. Bearing in mind that the underlying x axis unit is in days, the axis() function then places labels at the irregular intervals. You could then annotate the plot further as you may desire.

Regards,

Marc Schwartz



********************************************************************************************************************

This message may contain confidential information. If yo...{{dropped:19}}


From m|eher1971 @end|ng |rom gm@||@com  Fri Sep  4 17:43:11 2020
From: m|eher1971 @end|ng |rom gm@||@com (Mike Feher)
Date: Fri, 4 Sep 2020 11:43:11 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
In-Reply-To: <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>
References: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
 <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>
Message-ID: <CAN5WjXKM0cw73O53LAmyzOeTBCdj+SzFKN_+Xw98SaSEgxw-5Q@mail.gmail.com>

Good morning Marc,

Thank you kindly for your quick response.  I had read prior to installation
that I might have needed or wanted to install some different packages to
support R, but did not catch that XQuartz was a requirement.  (I also never
got prompted for various options during the installation of R-4.0.2.pkg.)

Regarding email lists, perhaps you can assist with this question: While I
don't mind becoming a registered member, I prefer not to get email traffic
from groups as I have in the past (I actually really hate email for a lot
of reasons these days), so I'm wondering, is there a way to get a digest (I
thought I saw that) of just a weekly summary of information or questions
posted, rather than getting CC:d on every back-and-forth within the user
community?  Also, do I have to become an approved user to the R mailing
list community or anything like that?  Or are all posts moderated?

Now that the weekend is upon me, I'll have some time to come up to speed on
all this.  Thanks for your patience.

Thanks again!
Mike

On Fri, Sep 4, 2020 at 8:05 AM Marc Schwartz <marc_schwartz at me.com> wrote:

>
> > On Sep 3, 2020, at 9:26 PM, Michael Feher <mfeher1971 at gmail.com> wrote:
> >
> > Greetings,
> >
> > I am a brand-new user to R and want to install and run this on my iMac
> running macOS 10.15.6.  I successfully downloaded the correct package,
> installed it with no problems (I was not given any options for Tcl/Tk or
> Texinfo), and started it up as any other normal app.  Some introductory
> commands like license() and help() worked just fine.  But when I went to
> execute demo(), it just beach-balled.  I?ve had to force-quit R a number of
> times.
> >
> > Yes, I read the Mac installation instructions.
> >
> > Thanks in advance.
> >
> > Mike
>
>
> Hi,
>
> Sounds like you need to install XQuartz:
>
>   https://www.xquartz.org
>
> which is referenced in the macOS installation instructions and the macOS
> specific FAQ.
>
> Also, be aware that there is a macOS specific e-mail list here:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>
> which is where macOS specific R issues should be posted.
>
> You will need to re-install XQuartz any time you upgrade/install a new
> version of R.
>
> Regards,
>
> Marc Schwartz
>
>

	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Sat Sep  5 00:32:05 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Fri, 4 Sep 2020 15:32:05 -0700
Subject: [R] NOAA .grb2 files
Message-ID: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>

I?m trying to download NOAA Rapid Refresh model weather data but I keep getting the error message below.  Do I just need a computer with more memory?

Philip

***********************************************************************************************************************************************
Error in paste(gsub("\"", "", csv.str), collapse = ",") : 
  could not allocate memory (994 Mb) in C function 'R_AllocStringBuffer' 
	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Sat Sep  5 00:36:05 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Fri, 4 Sep 2020 15:36:05 -0700
Subject: [R] NOAA .grp2 files
Message-ID: <5194862CE4014B22B985DF996E8CD216@OWNERPC>

Neglected to mention in the previous email that I?m using the rNOMADS package and the FReadGrib function.

Philip
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  5 00:47:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 4 Sep 2020 15:47:33 -0700
Subject: [R] NOAA .grp2 files
In-Reply-To: <5194862CE4014B22B985DF996E8CD216@OWNERPC>
References: <5194862CE4014B22B985DF996E8CD216@OWNERPC>
Message-ID: <CAGxFJbQaj0GmrX02dnNJZwG1xzgjvg2OP2q062gGs=9UQO+PwQ@mail.gmail.com>

If you don't get an answer here, try posting on the r-sig-geo list, where
folks with the expertise you seek are more likely to hang out.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 4, 2020 at 3:44 PM Philip <herd_dog at cox.net> wrote:

> Neglected to mention in the previous email that I?m using the rNOMADS
> package and the FReadGrib function.
>
> Philip
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Sep  5 00:49:01 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 4 Sep 2020 15:49:01 -0700 (PDT)
Subject: [R] NOAA .grb2 files
In-Reply-To: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
References: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
Message-ID: <alpine.LNX.2.20.2009041548380.7473@salmo.appl-ecosys.com>

On Fri, 4 Sep 2020, Philip wrote:

> I?m trying to download NOAA Rapid Refresh model weather data but I keep
> getting the error message below. Do I just need a computer with more
> memory?

Philip,

And how much available memory do you have on that host?

Rich


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sat Sep  5 01:11:04 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 4 Sep 2020 16:11:04 -0700
Subject: [R] NOAA .grb2 files
In-Reply-To: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
References: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
Message-ID: <26424FD6-CE0C-41F0-9337-4B463BF7F025@noaa.gov>

Hi Philip:

It would help if you gave the complete script you are trying to run,  and the name of the file.  

for those unfamiliar with all this,  Philip has already downloaded the grib2 file,  either using rNOMADS or directly from the NOAA website,  and the function he is calling reads the data from that grib2 file by wrapping a system call to a C-program called wgrib2.  And if you don't know about grib2 files,  they are highly compressed files of fields,  using bit-packing to do the compression. Forecast grib2 files usually have a plethora of fields,  for example since I don't know exactly which  NOAA Rapid Refresh model files he obtain,  looking at the inventory of one possible such file,  see:

https://www.nco.ncep.noaa.gov/pmb/products/rap/rap.t00z.awp252pgrbf00.grib2.shtml

Usually given this,  only one or a couple of fields at a time are unpacked,  unless you have a large computer.  Since no example script was given,  it is impossible to tell if he is trying to read in the entire grib2 file or what.  And each expanded array in R will be much much bigger than the equivalent in grib2.

-Roy



> On Sep 4, 2020, at 3:32 PM, Philip <herd_dog at cox.net> wrote:
> 
> I?m trying to download NOAA Rapid Refresh model weather data but I keep getting the error message below.  Do I just need a computer with more memory?
> 
> Philip
> 
> ***********************************************************************************************************************************************
> Error in paste(gsub("\"", "", csv.str), collapse = ",") : 
>  could not allocate memory (994 Mb) in C function 'R_AllocStringBuffer' 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From v|vek@utr@ @end|ng |rom gm@||@com  Sat Sep  5 20:18:07 2020
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Sat, 5 Sep 2020 20:18:07 +0200
Subject: [R] fusion of two matrices (numerical and logical)
Message-ID: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>

Hi
I would like to get help in combining two matrices. Here is my example:
A <- 1:20
B <- matrix(A,nrow=5,ncol=4)
# B is a numerical matrix
C <- B<7
C[4,4] <- TRUE
# C is a logical matrix
# if I combine A and C, I get a vector
D1 <- A[C==TRUE]
D1
D2 <- A[C==FALSE]
D2

I want to get a matrix with the same dimensions as matrix A. At the
coordinates given by the vector D1, I want to retain the values in
matrix A. At the locations in D2, I want a zero value.
I want to know if I can do this without using any loops.
Thanks, Vivek

	[[alternative HTML version deleted]]


From v|vek@utr@ @end|ng |rom gm@||@com  Sat Sep  5 20:41:01 2020
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Sat, 5 Sep 2020 20:41:01 +0200
Subject: [R] fusion of two matrices (numerical and logical)
In-Reply-To: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
References: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
Message-ID: <CAHLp6SD-+A2ip967q0noxF=2Ga_77ebMzRZTPyRLzR3FauvsPQ@mail.gmail.com>

The result that I want to get is this:
for (i in 1:5) {
  for (j in 1:4) {
    B[i,j] <- ifelse(C[i,j]==FALSE,0,B[i,j])
  }
}
I would like to know if I can do this without loops.

Den l?r 5 sep. 2020 kl 20:18 skrev Vivek Sutradhara <viveksutra at gmail.com>:

> Hi
> I would like to get help in combining two matrices. Here is my example:
> A <- 1:20
> B <- matrix(A,nrow=5,ncol=4)
> # B is a numerical matrix
> C <- B<7
> C[4,4] <- TRUE
> # C is a logical matrix
> # if I combine A and C, I get a vector
> D1 <- A[C==TRUE]
> D1
> D2 <- A[C==FALSE]
> D2
>
> I want to get a matrix with the same dimensions as matrix A. At the
> coordinates given by the vector D1, I want to retain the values in
> matrix A. At the locations in D2, I want a zero value.
> I want to know if I can do this without using any loops.
> Thanks, Vivek
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  5 20:51:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 5 Sep 2020 11:51:26 -0700
Subject: [R] fusion of two matrices (numerical and logical)
In-Reply-To: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
References: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
Message-ID: <CAGxFJbSKvodBk1kvP5DQmdFN+kNihgKOr_szPYRykMQaoPABwA@mail.gmail.com>

A is not a matrix. I presume you meant B. If so:

> B[!C] <- 0
> B
     [,1] [,2] [,3] [,4]
[1,]    1    6    0    0
[2,]    2    0    0    0
[3,]    3    0    0    0
[4,]    4    0    0   19
[5,]    5    0    0    0

Cheers,
Bert





On Sat, Sep 5, 2020 at 11:18 AM Vivek Sutradhara <viveksutra at gmail.com>
wrote:

> Hi
> I would like to get help in combining two matrices. Here is my example:
> A <- 1:20
> B <- matrix(A,nrow=5,ncol=4)
> # B is a numerical matrix
> C <- B<7
> C[4,4] <- TRUE
> # C is a logical matrix
> # if I combine A and C, I get a vector
> D1 <- A[C==TRUE]
> D1
> D2 <- A[C==FALSE]
> D2
>
> I want to get a matrix with the same dimensions as matrix A. At the
> coordinates given by the vector D1, I want to retain the values in
> matrix A. At the locations in D2, I want a zero value.
> I want to know if I can do this without using any loops.
> Thanks, Vivek
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 01:44:03 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 5 Sep 2020 16:44:03 -0700 (PDT)
Subject: [R] dataRetrieval query error
Message-ID: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>

I'm learning the dataRetrieval package. Following the example in Section
1.1.2 of the vignette (whatNWISdata) I prepared this script:
------
library("dataRetrieval")

siteNumbers <- c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")

dataAvailable <- whatNWISdata(siteNumbers, service="all", parameterCD="all", statCD="all")
-----

The vignette says that for service, parameterCD, and statCD the default is
"all", but the package wants that explicitly. So that's what I did. Yet, my
syntax is still off:

> source("R-scripts/get-site-data-list.R") 
Error: All components of query must be named

Please show me what I'm missing.

Rich


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep  6 02:14:23 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 5 Sep 2020 17:14:23 -0700
Subject: [R] dataRetrieval query error
In-Reply-To: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSWx5M4Gf-Mu5uVkm6x6VkxOBoACb02yDUCOC=z3gZgvQ@mail.gmail.com>

You failed to name the first parameter, siteNumbers?


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 5, 2020 at 4:44 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> I'm learning the dataRetrieval package. Following the example in Section
> 1.1.2 of the vignette (whatNWISdata) I prepared this script:
> ------
> library("dataRetrieval")
>
> siteNumbers <-
> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")
>
> dataAvailable <- whatNWISdata(siteNumbers, service="all",
> parameterCD="all", statCD="all")
> -----
>
> The vignette says that for service, parameterCD, and statCD the default is
> "all", but the package wants that explicitly. So that's what I did. Yet, my
> syntax is still off:
>
> > source("R-scripts/get-site-data-list.R")
> Error: All components of query must be named
>
> Please show me what I'm missing.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Sep  6 02:20:58 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 5 Sep 2020 17:20:58 -0700
Subject: [R] dataRetrieval query error
In-Reply-To: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
Message-ID: <13dc0272-b354-93dd-09da-b060a85c1826@comcast.net>

This worked:


 > dataAvailable <- whatNWISdata(siteNumber=siteNumbers)
 > str(dataAvailable)
'data.frame':??? 2565 obs. of? 24 variables:
 ?$ agency_cd???????? : chr? "USGS" "USGS" "USGS" "USGS" ...
 ?$ site_no?????????? : chr? "14207920" "14208000" "14208000" "14208000" ...
 ?$ station_nm??????? : chr? "POOP CREEK NEAR BIG BOTTOM, OR" "CLACKAMAS 
RIVER AT BIG BOTTOM, OREG." "CLACKAMAS RIVER AT BIG BOTTOM, OREG." 
"CLACKAMAS RIVER AT BIG BOTTOM, OREG." ...
 ?$ site_tp_cd??????? : chr? "ST" "ST" "ST" "ST" ...
 ?$ dec_lat_va??????? : num? 45 45 45 45 44.9 ...
 ?$ dec_long_va?????? : num? -122 -122 -122 -122 -122 ...
 ?$ coord_acy_cd????? : chr? "U" "U" "U" "U" ...
 ?$ dec_coord_datum_cd: chr? "NAD83" "NAD83" "NAD83" "NAD83" ...
 ?$ alt_va??????????? : chr? " 2760.00" " 2040.00" " 2040.00" " 2040.00" ...
 ?$ alt_acy_va??????? : chr? " 20" " 20" " 20" " 20" ...
 ?$ alt_datum_cd????? : chr? "NGVD29" "NGVD29" "NGVD29" "NGVD29" ...
 ?$ huc_cd??????????? : chr? "17090011" "17090011" "17090011" "17090011" ...
 ?$ data_type_cd????? : chr? "pk" "dv" "pk" "sv" ...
 ?$ parm_cd?????????? : chr? NA "00060" NA NA ...
 ?$ stat_cd?????????? : chr? NA "00003" NA NA ...
 ?$ ts_id???????????? : num? 0 114288 0 0 0 ...
 ?$ loc_web_ds??????? : chr? NA NA NA NA ...
 ?$ medium_grp_cd???? : chr? "wat" "wat" "wat" "wat" ...
 ?$ parm_grp_cd?????? : chr? NA NA NA NA ...
 ?$ srs_id??????????? : num? 0 1645423 0 0 0 ...
 ?$ access_cd???????? : num? 0 0 0 0 0 0 0 0 0 0 ...
 ?$ begin_date??????? : Date, format: "1966-05-05" "1920-04-01" 
"1921-01-03" ...
 ?$ end_date????????? : Date, format: "1983-01-06" "1970-09-29" 
"1970-01-23" ...
 ?$ count_nu????????? : num? 17 18444 50 26 10 ...
 ?- attr(*, "comment")= chr? "#" "#" "# US Geological Survey" "# 
retrieved: 2020-09-05 20:18:46 -04:00\t(caas01)" ...
 ?- attr(*, "queryTime")= POSIXct, format: "2020-09-05 17:18:46"
 ?- attr(*, "url")= chr 
"https://waterservices.usgs.gov/nwis/site/?seriesCatalogOutput=true&sites=14207920,14208000,14208200,14208300,14"| 
__truncated__
 ?- attr(*, "header")=List of 12
 ? ..$ date?????????????????????? : chr "Sun, 06 Sep 2020 00:18:45 GMT"
 ? ..$ server???????????????????? : chr "Apache-Coyote/1.1"
 ? ..$ strict-transport-security? : chr "max-age=31536000"
 ? ..$ vary?????????????????????? : chr "Accept-Encoding"
 ? ..$ content-encoding?????????? : chr "gzip"
 ? ..$ content-type?????????????? : chr "text/plain;charset=UTF-8"
 ? ..$ cache-control????????????? : chr "max-age=900"
 ? ..$ expires??????????????????? : chr "Sun, 06 Sep 2020 00:33:46 GMT"
 ? ..$ x-ua-compatible??????????? : chr "IE=edge,chrome=1"
 ? ..$ access-control-allow-origin: chr "*"
 ? ..$ x-frame-options??????????? : chr "deny"
 ? ..$ transfer-encoding????????? : chr "chunked"
 ? ..- attr(*, "class")= chr? "insensitive" "list"


--

David.


On 9/5/20 4:44 PM, Rich Shepard wrote:

> I'm learning the dataRetrieval package. Following the example in Section
> 1.1.2 of the vignette (whatNWISdata) I prepared this script:
> ------
> library("dataRetrieval")
>
> siteNumbers <- 
> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")
>
> dataAvailable <- whatNWISdata(siteNumbers, service="all", 
> parameterCD="all", statCD="all")
> -----
>
> The vignette says that for service, parameterCD, and statCD the 
> default is
> "all", but the package wants that explicitly. So that's what I did. 
> Yet, my
> syntax is still off:
>
>> source("R-scripts/get-site-data-list.R") 
> Error: All components of query must be named
>
> Please show me what I'm missing.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sun Sep  6 04:06:27 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sat, 5 Sep 2020 19:06:27 -0700
Subject: [R] dataRetrieval query error
In-Reply-To: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
Message-ID: <CAHqSRuSKOVZcokFcNcNMqSks4wtxtmrc6MCn2R-FqsH9GanthA@mail.gmail.com>

Name all your arguments (the vignette gets this wrong), including
siteNumber=siteNumbers.

Also, the vignette uses 'statCd', not 'statCD'.

dataAvailable <- whatNWISdata(siteNumber=siteNumbers, service="all",
statCd="all")

gives some results.

-Bill

On Sat, Sep 5, 2020 at 4:44 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> I'm learning the dataRetrieval package. Following the example in Section
> 1.1.2 of the vignette (whatNWISdata) I prepared this script:
> ------
> library("dataRetrieval")
>
> siteNumbers <-
> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")
>
> dataAvailable <- whatNWISdata(siteNumbers, service="all",
> parameterCD="all", statCD="all")
> -----
>
> The vignette says that for service, parameterCD, and statCD the default is
> "all", but the package wants that explicitly. So that's what I did. Yet, my
> syntax is still off:
>
> > source("R-scripts/get-site-data-list.R")
> Error: All components of query must be named
>
> Please show me what I'm missing.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From he@h@m|bb @end|ng |rom y@hoo@com  Sun Sep  6 11:58:21 2020
From: he@h@m|bb @end|ng |rom y@hoo@com (Hesham A. AL-bukhaiti)
Date: Sun, 6 Sep 2020 09:58:21 +0000 (UTC)
Subject: [R] truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[,
 1]=="G2" & truth[, 2]=="G3"), 3]<-1
References: <1445305015.747995.1599386302002.ref@mail.yahoo.com>
Message-ID: <1445305015.747995.1599386302002@mail.yahoo.com>

helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
?If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1?# note G1 and G2 are values from 1 to 2000?#if this happend add to thrid column in truth 1 otherwise add 0 as in statment follow
truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?
truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.
this the distination result:
I want this result
G1 G2? G3?D? ? B? ? 1?B? ?D? ? ?1?A? ? D? ? 0?B? ? A? ? 1B? ? C? ? 0A ? B? ? 1


	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sun Sep  6 13:04:34 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 6 Sep 2020 12:04:34 +0100
Subject: [R] truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[,
 1]=="G2" & truth[, 2]=="G3"), 3]<-1
In-Reply-To: <1445305015.747995.1599386302002@mail.yahoo.com>
References: <1445305015.747995.1599386302002.ref@mail.yahoo.com>
 <1445305015.747995.1599386302002@mail.yahoo.com>
Message-ID: <517607e5-72ba-23f3-e49e-bbe35a73ff64@dewey.myzen.co.uk>

I am afraid this is completely unreadable because you posted in HTML ad 
this is a plain text list. Best to resend it having set your mailer to 
send plain text as HTML gets mangled here.

Michael

On 06/09/2020 10:58, Hesham A. AL-bukhaiti via R-help wrote:
> helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
>  ?If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1?# note G1 and G2 are values from 1 to 2000?#if this happend add to thrid column in truth 1 otherwise add 0 as in statment follow
> truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000
> truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.
> this the distination result:
> I want this result
> G1 G2? G3?D? ? B? ? 1?B? ?D? ? ?1?A? ? D? ? 0?B? ? A? ? 1B? ? C? ? 0A ? B? ? 1
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 14:45:36 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 05:45:36 -0700 (PDT)
Subject: [R] dataRetrieval query error
In-Reply-To: <CAGxFJbSWx5M4Gf-Mu5uVkm6x6VkxOBoACb02yDUCOC=z3gZgvQ@mail.gmail.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
 <CAGxFJbSWx5M4Gf-Mu5uVkm6x6VkxOBoACb02yDUCOC=z3gZgvQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2009060542470.1648@salmo.appl-ecosys.com>

On Sat, 5 Sep 2020, Bert Gunter wrote:

> You failed to name the first parameter, siteNumbers?

Bert,

>> siteNumbers <-
>> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")

This is where I defined that vector; the MUA split it into two lines. The
vector's name is the same as in the vignette example

>> dataAvailable <- whatNWISdata(siteNumbers, service="all", parameterCD="all", statCD="all")

Have I not specified the list of site numbers properly here?

Thanks,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 14:48:10 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 05:48:10 -0700 (PDT)
Subject: [R] dataRetrieval query error [RESOLVED]
In-Reply-To: <13dc0272-b354-93dd-09da-b060a85c1826@comcast.net>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
 <13dc0272-b354-93dd-09da-b060a85c1826@comcast.net>
Message-ID: <alpine.LNX.2.20.2009060546090.1648@salmo.appl-ecosys.com>

On Sat, 5 Sep 2020, David Winsemius wrote:

> This worked:
>> dataAvailable <- whatNWISdata(siteNumber=siteNumbers)

David/Bert,

Mea culpa! The vignette example used a single siteNumber which is also the
variable name and I missed that last point.

Thank you very much.

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 14:56:10 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 05:56:10 -0700 (PDT)
Subject: [R] dataRetrieval query error
In-Reply-To: <CAHqSRuSKOVZcokFcNcNMqSks4wtxtmrc6MCn2R-FqsH9GanthA@mail.gmail.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
 <CAHqSRuSKOVZcokFcNcNMqSks4wtxtmrc6MCn2R-FqsH9GanthA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2009060553190.1648@salmo.appl-ecosys.com>

On Sat, 5 Sep 2020, Bill Dunlap wrote:

> Name all your arguments (the vignette gets this wrong), including
> siteNumber=siteNumbers.
> Also, the vignette uses 'statCd', not 'statCD'.

Bill,

Thanks very much. I missed these.

> dataAvailable <- whatNWISdata(siteNumber=siteNumbers, service="all",
> statCd="all")
> gives some results.

Much appreciated,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 21:27:54 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 12:27:54 -0700 (PDT)
Subject: [R] dataRetrieval: whatNWISdata() return value type
Message-ID: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>

The dataRetrieval package PDF has a list of values returned by
whatNWISdata(). One value returned when I run this function is not on the
list and my searches of USGS web sites doesn't find it. The value's name is
"ts_id". A pointer to where that's defined is needed.

Regards,

Rich


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Sep  7 00:02:40 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 6 Sep 2020 15:02:40 -0700
Subject: [R] dataRetrieval: whatNWISdata() return value type
In-Reply-To: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>
Message-ID: <CAHqSRuSYCqPUu9xPTtf_7+QWzgbqLPw=Q+U_MDyyxyZt_eJN-g@mail.gmail.com>

https://help.waterdata.usgs.gov/codes-and-parameters/codes


   - *Time series identifier* - A 5-6 digit number (ts_id) which uniquely
   identifies a series of data for one parameter at one location at a
   continuous-recording data site. The ts_id is used by the database for
   selecting data for download or display as a list, table, or graph and may
   change over time as new database tables are created.


On Sun, Sep 6, 2020 at 12:28 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> The dataRetrieval package PDF has a list of values returned by
> whatNWISdata(). One value returned when I run this function is not on the
> list and my searches of USGS web sites doesn't find it. The value's name is
> "ts_id". A pointer to where that's defined is needed.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep  7 00:36:42 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 15:36:42 -0700 (PDT)
Subject: [R] dataRetrieval: whatNWISdata() return value type
In-Reply-To: <CAHqSRuSYCqPUu9xPTtf_7+QWzgbqLPw=Q+U_MDyyxyZt_eJN-g@mail.gmail.com>
References: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>
 <CAHqSRuSYCqPUu9xPTtf_7+QWzgbqLPw=Q+U_MDyyxyZt_eJN-g@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2009061531400.1648@salmo.appl-ecosys.com>

On Sun, 6 Sep 2020, Bill Dunlap wrote:

> https://help.waterdata.usgs.gov/codes-and-parameters/codes
>
>   - *Time series identifier* - A 5-6 digit number (ts_id) which uniquely
>   identifies a series of data for one parameter at one location at a
>   continuous-recording data site. The ts_id is used by the database for
>   selecting data for download or display as a list, table, or graph and may
>   change over time as new database tables are created.

Bill,

I found many lists of parameters none included this one. Thank you again.

Rich


From he@h@m|bb @end|ng |rom y@hoo@com  Mon Sep  7 05:48:32 2020
From: he@h@m|bb @end|ng |rom y@hoo@com (Hesham A. AL-bukhaiti)
Date: Mon, 7 Sep 2020 03:48:32 +0000 (UTC)
Subject: [R] (i want change G3 and G2 to variable tke all elements in rows)
 (truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[, 1]=="G2" & truth[,
 2]=="G3"), 3]<-1
References: <523701431.950619.1599450512634.ref@mail.yahoo.com>
Message-ID: <523701431.950619.1599450512634@mail.yahoo.com>

helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
?If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1?# note G1 and G2 are values from 1 to 2000?#if this happend add to thrid column in truth 1 otherwise add 0 as in statment follow
truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?
truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.
this the distination result:
I want this result
G1 G2? G3?D? ? B? ? 1?B? ?D? ? ?1?A? ? D? ? 0?B? ? A? ? 1B? ? C? ? 0A ? B? ? 1

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Sep  7 08:43:37 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 7 Sep 2020 06:43:37 +0000
Subject: [R] 
 (i want change G3 and G2 to variable tke all elements in rows)
 (truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[, 1]=="G2" & truth[,
 2]=="G3"), 3]<-1
In-Reply-To: <523701431.950619.1599450512634@mail.yahoo.com>
References: <523701431.950619.1599450512634.ref@mail.yahoo.com>
 <523701431.950619.1599450512634@mail.yahoo.com>
Message-ID: <ab1b0e09e31c4f85ab920059fef089d6@SRVEXCHCM1302.precheza.cz>

Hi

You still fail to send your message in plain text, so it is unreadable.

If I managed to decipher it correctly what you wanted you probably could set 2 
related logical expression and considering that FALSE is 0 and TRUE is 1 you 
get desired result.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Hesham A. AL-
> bukhaiti via R-help
> Sent: Monday, September 7, 2020 5:49 AM
> To: r-help at r-project.org
> Subject: [R] (i want change G3 and G2 to variable tke all elements in rows)
> (truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[, 1]=="G2" & truth[,
> 2]=="G3"), 3]<-1
>
> helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
>  If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1 # note
> G1 and G2 are values from 1 to 2000 #if this happend add to thrid column in
> truth 1 otherwise add 0 as in statment follow
> truth<-
> cbind(as.character(truth[,1]),as.character(truth[,2]) 
> ,as.data.frame(rep(
> 0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all 
> values
> from G1 to G2000 truth[(truth[,1]=="G3" & truth[,2]=="G2") | 
> (truth[,1]=="G2"
> & truth[,2]=="G3"),3]<-1 ###############################3(Simply they
> regulate the other. If element A is in the first group , and it is related 
> to
> element B in the second group , and element B also in  in the first group , 
> and
> it is related to element A(the same element  in the first group)  in the 
> second
> group , we write 1 and otherwise 0.
> this the distination result:
> I want this result
> G1 G2  G3 D    B    1 B   D     1 A    D    0 B    A    1B    C    0A   B 
> 1
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Sep  7 11:17:36 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 7 Sep 2020 11:17:36 +0200
Subject: [R] How to run Hutcheson t-test on R?
Message-ID: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>

Hello,
is it possible to run the Hutcheson t-test
(https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
on R? How?

-- 
Best regards,
Luigi


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Sep  8 00:17:15 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 8 Sep 2020 10:17:15 +1200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
Message-ID: <20200908101715.0dfab483@rolf-Latitude-E7470>


On Mon, 7 Sep 2020 11:17:36 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> Hello,
> is it possible to run the Hutcheson t-test
> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
> on R?

Almost surely.  With R, all things are possible. :-)

> How?

Program it up?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Tue Sep  8 01:17:52 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Mon, 7 Sep 2020 19:17:52 -0400
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <20200908101715.0dfab483@rolf-Latitude-E7470>
References: <20200908101715.0dfab483@rolf-Latitude-E7470>
Message-ID: <9B799156-1CC0-4AEC-BE5E-86A9CAF4F898@comcast.net>

This website has an example calculation shown in Excel Which might help in programming it in R.

https://www.dataanalytics.org.uk/comparing-diversity/


Bernard
Sent from my iPhone so please excuse the spelling!"

> On Sep 7, 2020, at 6:17 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> ?
>> On Mon, 7 Sep 2020 11:17:36 +0200
>> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> 
>> Hello,
>> is it possible to run the Hutcheson t-test
>> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
>> on R?
> 
> Almost surely.  With R, all things are possible. :-)
> 
>> How?
> 
> Program it up?
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep  8 01:23:00 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 7 Sep 2020 16:23:00 -0700
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <20200908101715.0dfab483@rolf-Latitude-E7470>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <20200908101715.0dfab483@rolf-Latitude-E7470>
Message-ID: <a6a7ed5f-1d32-d2f6-127d-9b24ae080e62@comcast.net>


On 9/7/20 3:17 PM, Rolf Turner wrote:
> On Mon, 7 Sep 2020 11:17:36 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
>> Hello,
>> is it possible to run the Hutcheson t-test
>> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
>> on R?
> Almost surely.  With R, all things are possible. :-)
>
>> How?
> Program it up?


To Luigi;


Citing a 50 year-old paper that sits behind a paywall seems a bit 
ineffective in getting coding support.

Seems this might be a more appropriate question on the R-SIG-ecology or 
R-SIG-phylo mailing lists. (It would also have been appropriate to 
indicate what sort of searching has been done. My efforts at searching 
led me to the vegan package and this tutorial: 
https://cran.r-project.org/web/packages/vegan/vignettes/diversity-vegan.pdf 
. It doesn't appear to have a Hutcheson t-test, but I'm guessing that is 
because there are more modern and more sophisticated tests currently in 
use.)


See: https://www.r-project.org/mail.html

-- 

David

>
> cheers,
>
> Rolf Turner
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Sep  8 07:06:49 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 8 Sep 2020 07:06:49 +0200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <a6a7ed5f-1d32-d2f6-127d-9b24ae080e62@comcast.net>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <20200908101715.0dfab483@rolf-Latitude-E7470>
 <a6a7ed5f-1d32-d2f6-127d-9b24ae080e62@comcast.net>
Message-ID: <CAMk+s2QWkrQG1EB1maHWzV-52WchRDNK-rDfJqFadYG9THTuJg@mail.gmail.com>

I cited that paper to show what test I was referring to, I was hoping it
was already coded...
Thanks, I will look into vegan
Best regards

On Tue, 8 Sep 2020, 01:23 David Winsemius, <dwinsemius at comcast.net> wrote:

>
> On 9/7/20 3:17 PM, Rolf Turner wrote:
> > On Mon, 7 Sep 2020 11:17:36 +0200
> > Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> >> Hello,
> >> is it possible to run the Hutcheson t-test
> >> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244
> )
> >> on R?
> > Almost surely.  With R, all things are possible. :-)
> >
> >> How?
> > Program it up?
>
>
> To Luigi;
>
>
> Citing a 50 year-old paper that sits behind a paywall seems a bit
> ineffective in getting coding support.
>
> Seems this might be a more appropriate question on the R-SIG-ecology or
> R-SIG-phylo mailing lists. (It would also have been appropriate to
> indicate what sort of searching has been done. My efforts at searching
> led me to the vegan package and this tutorial:
> https://cran.r-project.org/web/packages/vegan/vignettes/diversity-vegan.pdf
> . It doesn't appear to have a Hutcheson t-test, but I'm guessing that is
> because there are more modern and more sophisticated tests currently in
> use.)
>
>
> See: https://www.r-project.org/mail.html
>
> --
>
> David
>
> >
> > cheers,
> >
> > Rolf Turner
> >
>

	[[alternative HTML version deleted]]


From bobby@kn|ght @end|ng |rom gm@||@com  Tue Sep  8 05:51:10 2020
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Mon, 7 Sep 2020 22:51:10 -0500
Subject: [R] Some R code works on Linux,
 but not Linux via Windows Subsystem Linux
Message-ID: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>

RE: Some R code works on Linux, but not Linux via Windows Subsystem Linux

This is taking data from a CSV and placing it into a data frame.  This is R
3.6.3 inside Windows Subsystem for Linux v2, Ubuntu 18.04.   The exact same
code, unchanged and on the same computer, works correctly in Ubuntu 18.04
and other Linux systems directly if the computer is dual booted into one of
those rather than Windows.

    Error in FUN(X[[i]], ?) :
      only defined on a data frame with all numeric variables
    Calls: Summary.data.frame -> lapply -> FUN

Any idea why the FUN function would error on Windows Subsytem for Linux,
but not Linux itself?  Any insight into the basic mechanism of how that
could vary between systems?  Haven't yet checked to see if the data is even
getting imported via WSL.  The script runs using Rscript as opposed to
running interactively via the R console.

Robert D. Knight, MBA

Developer of Meal Plan and Grocery List maker for Android and iOS.
https://play.google.com/store/apps/details?id=io.robertknight.MPGL
https://itunes.apple.com/us/app/meal-plan-and-grocery-list/id1452755707

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Sep  8 12:56:36 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 8 Sep 2020 13:56:36 +0300
Subject: [R] Some R code works on Linux,
 but not Linux via Windows Subsystem Linux
In-Reply-To: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
References: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
Message-ID: <CAGgJW74wHreiiRMfrPeSTB4-OaFjnb_xJsMwpOY1G5xWqa9TNw@mail.gmail.com>

Hi Robert,
You don't provide a self-contained reproducible example, so I am just
guessing here.
I doubt your theory that the error is related to R. More likely the step
that creates a data frame from reading
the CSV is probably resulting in different data frames in the two cases. I
recommend that you compare the
data frames. (And, if they differ, it might be related to filenames,
directory structures, assumptions about these, etc.)
Another possibility is that you have R 4.* somewhere and there is, in fact,
a difference between R 3.* and R4.*
in terms of creating a data frame from a CSV file.

If my "guesses" are not correct, see if you can create a self-contained
reproducible example
(that does not depend on reading in the CSV. You can just provide the
contents of the data frame via dput().)
Then post the example to the list.

HTH,
Eric


On Tue, Sep 8, 2020 at 1:47 PM Robert Knight <bobby.knight at gmail.com> wrote:

> RE: Some R code works on Linux, but not Linux via Windows Subsystem Linux
>
> This is taking data from a CSV and placing it into a data frame.  This is R
> 3.6.3 inside Windows Subsystem for Linux v2, Ubuntu 18.04.   The exact same
> code, unchanged and on the same computer, works correctly in Ubuntu 18.04
> and other Linux systems directly if the computer is dual booted into one of
> those rather than Windows.
>
>     Error in FUN(X[[i]], ?) :
>       only defined on a data frame with all numeric variables
>     Calls: Summary.data.frame -> lapply -> FUN
>
> Any idea why the FUN function would error on Windows Subsytem for Linux,
> but not Linux itself?  Any insight into the basic mechanism of how that
> could vary between systems?  Haven't yet checked to see if the data is even
> getting imported via WSL.  The script runs using Rscript as opposed to
> running interactively via the R console.
>
> Robert D. Knight, MBA
>
> Developer of Meal Plan and Grocery List maker for Android and iOS.
> https://play.google.com/store/apps/details?id=io.robertknight.MPGL
> https://itunes.apple.com/us/app/meal-plan-and-grocery-list/id1452755707
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Tue Sep  8 13:01:53 2020
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Tue, 8 Sep 2020 13:01:53 +0200
Subject: [R] Some R code works on Linux,
 but not Linux via Windows Subsystem Linux
In-Reply-To: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
References: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
Message-ID: <ed3dd221-1cd0-c484-dddc-a99f39a59201@gmail.com>

On 9/8/20 5:51 AM, Robert Knight wrote:
> RE: Some R code works on Linux, but not Linux via Windows Subsystem Linux
>
> This is taking data from a CSV and placing it into a data frame.  This is R
> 3.6.3 inside Windows Subsystem for Linux v2, Ubuntu 18.04.   The exact same
> code, unchanged and on the same computer, works correctly in Ubuntu 18.04
> and other Linux systems directly if the computer is dual booted into one of
> those rather than Windows.
>
>      Error in FUN(X[[i]], ?) :
>        only defined on a data frame with all numeric variables
>      Calls: Summary.data.frame -> lapply -> FUN
>
> Any idea why the FUN function would error on Windows Subsytem for Linux,
> but not Linux itself?  Any insight into the basic mechanism of how that
> could vary between systems?  Haven't yet checked to see if the data is even
> getting imported via WSL.  The script runs using Rscript as opposed to
> running interactively via the R console.

Yes, I think you should just try importing the data (reading the CSV), 
this is probably where things break. Then try also with a small trivial 
variant of that CSV, ensuring it only has ASCII characters, as a sanity 
check. So in other words, creating a minimal reproducible example. This 
can be an encoding issue, for instance.

Tomas

>
> Robert D. Knight, MBA
>
> Developer of Meal Plan and Grocery List maker for Android and iOS.
> https://play.google.com/store/apps/details?id=io.robertknight.MPGL
> https://itunes.apple.com/us/app/meal-plan-and-grocery-list/id1452755707
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Tue Sep  8 13:35:35 2020
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Tue, 8 Sep 2020 13:35:35 +0200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
Message-ID: <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>

Could it be that the test you are looking for is implemented in the 
vegan package (function diversity(... index = "shannon" ...), and/or the 
BiodiversityR package, function "diversityresult (..., index = 
"Shannon",...)

best,
Karl Schilling


From nev||@@mo@ @end|ng |rom gm@||@com  Tue Sep  8 13:37:44 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Tue, 8 Sep 2020 21:37:44 +1000
Subject: [R] Return filematrix column by column names instead of column
 index?
Message-ID: <CAN9eD7=-gO1xa9-vqenOjNJMzRCfDJEuAM53PtUrhE4aEoyGmQ@mail.gmail.com>

Is there a way to get columns out of a filematrix using the column name
directly in the same way that  you can with a regular matrix?

library(filematrix)
M<-t(matrix(1:3,3,4))
colnames(M)<-c("one","two", "three")
M
#Extract column
M[,1]
M[,"one"]
M[,c(1,3)]
M[,c("one","three")]
FM<-fm.create.from.matrix(filenamebase = "test",mat = M)
FM[,1]
colnames(FM)
#extract by column by name does not work
FM[,"one"]

#workaround using grep
#is there a more direct way of doing this  to retrieve more than one column?
FM[,grep("one",colnames(FM))]

FM[,c(grep("one",colnames(FM)),grep("three",colnames(FM)))]

many thanks for any suggestions

Nevil Amos

	[[alternative HTML version deleted]]


From pgokoo| @end|ng |rom gm@||@com  Tue Sep  8 14:05:18 2020
From: pgokoo| @end|ng |rom gm@||@com (pgokool)
Date: Tue, 8 Sep 2020 08:05:18 -0400
Subject: [R] Spatio-Temporal Modelling
Message-ID: <CAE+vJJ-cx9JzYmTYV3OZzYQBG50masMfMEJOgq_Tn9uB3mHU_w@mail.gmail.com>

I have a data set of rainfall from 12 weather stations over 10 years. I
would like to model it using a Spatio-Temporal model in R.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep  8 16:25:56 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 8 Sep 2020 07:25:56 -0700
Subject: [R] Spatio-Temporal Modelling
In-Reply-To: <CAE+vJJ-cx9JzYmTYV3OZzYQBG50masMfMEJOgq_Tn9uB3mHU_w@mail.gmail.com>
References: <CAE+vJJ-cx9JzYmTYV3OZzYQBG50masMfMEJOgq_Tn9uB3mHU_w@mail.gmail.com>
Message-ID: <CAGxFJbSn5EkTq3Fi7TDw6FMUYdPqLcyoUq9cVZGUATbD701q9Q@mail.gmail.com>

https://cran.r-project.org/web/views/SpatioTemporal.html


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 8, 2020 at 7:15 AM pgokool <pgokool at gmail.com> wrote:

> I have a data set of rainfall from 12 weather stations over 10 years. I
> would like to model it using a Spatio-Temporal model in R.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep  8 16:55:14 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 8 Sep 2020 15:55:14 +0100
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>
Message-ID: <88ef05c2-dda5-7e9e-e8f0-cb7f168cb7ad@sapo.pt>

Hello,

No, it's not. That's the Shannon diversity index, the test the OP is 
looking for is a t-test for Shannon diversity index equality. The index 
itself is easy to code. A very simple example, based on ?vegan::diversity:


library(vegan)

data(BCI)
H <- diversity(BCI[1,])    # just first row

divers <- function(n){
   p <- n/sum(n)
   log_p <- numeric(length(n))
   log_p[n != 0] <- log(p[n != 0])
   -sum(p * log_p)
}
HRui <- divers(BCI[1,])

identical(H, HRui)
#[1] TRUE


The vegan function is more general, it applies this and other indices 
calculations to a matrix or array.

The t-test doesn't seem difficult to code.
The variance formula in the paper and in the OP's posted link [1] are 
not the same, the original has one more term, but the degrees of freedom 
formula are the same. It all seems straightforward coding.

Luigi: Maybe later today I will have time but I am not making promises.


[1] https://www.dataanalytics.org.uk/comparing-diversity/


Hope this helps,

Rui Barradas


?s 12:35 de 08/09/20, Karl Schilling escreveu:
> Could it be that the test you are looking for is implemented in the 
> vegan package (function diversity(... index = "shannon" ...), and/or the 
> BiodiversityR package, function "diversityresult (..., index = 
> "Shannon",...)
> 
> best,
> Karl Schilling
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Tue Sep  8 20:01:55 2020
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Tue, 8 Sep 2020 20:01:55 +0200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <88ef05c2-dda5-7e9e-e8f0-cb7f168cb7ad@sapo.pt>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>
 <88ef05c2-dda5-7e9e-e8f0-cb7f168cb7ad@sapo.pt>
Message-ID: <b3b12e54-0ce8-f9c4-e665-1555d8577834@uni-bonn.de>

Maybe the following is a solution:

# load package needed
# QSutils is on Bioconductor
library(QSutils)

# here some exemplary data - these are the data from Pilou 1966 that are 
used
# in the second example of Hutcheson, J theor Biol 129:151-154 (1970)

earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)

# here starts the code ; you may replace the variables "earlier" and "later"
# by your own numbers.

# calculate h, var(h) etc
h1 <- Shannon(earlier)
varh1 <- ShannonVar(earlier)
n1 <- sum (earlier)
h2 <- Shannon(later)
varh2 <- ShannonVar(later)
n2 <- sum (later)
degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)

# compare numbers with those in the paper
h1
h2
varh1
varh2

Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess 
that explains the minor numerical differences obtained with the code 
above and the published variances.

# this is the actual t-test
t <- (h1-h2) /sqrt(varh1 + varh2)
p <- 2*pt(-abs(t),df= degfree)
p

that's it
Best
Karl




On 08.09.2020 16:55, Rui Barradas wrote:
> Hello,
> 
> No, it's not. That's the Shannon diversity index, the test the OP is 
> looking for is a t-test for Shannon diversity index equality. The index 
> itself is easy to code. A very simple example, based on ?vegan::diversity:
> 
> 
> library(vegan)
> 
> data(BCI)
> H <- diversity(BCI[1,])??? # just first row
> 
> divers <- function(n){
>  ? p <- n/sum(n)
>  ? log_p <- numeric(length(n))
>  ? log_p[n != 0] <- log(p[n != 0])
>  ? -sum(p * log_p)
> }
> HRui <- divers(BCI[1,])
> 
> identical(H, HRui)
> #[1] TRUE
> 
> 
> The vegan function is more general, it applies this and other indices 
> calculations to a matrix or array.
> 
> The t-test doesn't seem difficult to code.
> The variance formula in the paper and in the OP's posted link [1] are 
> not the same, the original has one more term, but the degrees of freedom 
> formula are the same. It all seems straightforward coding.
> 
> Luigi: Maybe later today I will have time but I am not making promises.
> 
> 
> [1] https://www.dataanalytics.org.uk/comparing-diversity/
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 12:35 de 08/09/20, Karl Schilling escreveu:
>> Could it be that the test you are looking for is implemented in the 
>> vegan package (function diversity(... index = "shannon" ...), and/or 
>> the BiodiversityR package, function "diversityresult (..., index = 
>> "Shannon",...)
>>
>> best,
>> Karl Schilling


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep  9 02:00:10 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 9 Sep 2020 10:00:10 +1000
Subject: [R] Return filematrix column by column names instead of column
 index?
In-Reply-To: <CAN9eD7=-gO1xa9-vqenOjNJMzRCfDJEuAM53PtUrhE4aEoyGmQ@mail.gmail.com>
References: <CAN9eD7=-gO1xa9-vqenOjNJMzRCfDJEuAM53PtUrhE4aEoyGmQ@mail.gmail.com>
Message-ID: <CA+8X3fXCz4-SjRNCipkTjnWyoV9ydVUMxTVFhVJ8R-TF4UJCmw@mail.gmail.com>

Hi Nevil,
As I don't have the filematrix package this is really an "any suggestion":

FM[,which(colnames(FM) %in% c("one","three"))]

Jim

On Tue, Sep 8, 2020 at 9:43 PM nevil amos <nevil.amos at gmail.com> wrote:
>
> Is there a way to get columns out of a filematrix using the column name
> directly in the same way that  you can with a regular matrix?
>
> library(filematrix)
> M<-t(matrix(1:3,3,4))
> colnames(M)<-c("one","two", "three")
> M
> #Extract column
> M[,1]
> M[,"one"]
> M[,c(1,3)]
> M[,c("one","three")]
> FM<-fm.create.from.matrix(filenamebase = "test",mat = M)
> FM[,1]
> colnames(FM)
> #extract by column by name does not work
> FM[,"one"]
>
> #workaround using grep
> #is there a more direct way of doing this  to retrieve more than one column?
> FM[,grep("one",colnames(FM))]
>
> FM[,c(grep("one",colnames(FM)),grep("three",colnames(FM)))]
>
> many thanks for any suggestions
>
> Nevil Amos
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@r||61 @end|ng |rom w|ndow@||ve@com  Wed Sep  9 16:13:51 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-3?Q?ahmet_varl=B9?=)
Date: Wed, 9 Sep 2020 14:13:51 +0000
Subject: [R] calculating a linear regression for each grid cell. firstly
Message-ID: <VI1PR0302MB3199F2DEB96EDFB0B65238C3BB260@VI1PR0302MB3199.eurprd03.prod.outlook.com>

       Hi all,


            for example, ? have 4 raster data and ? try to convert these rasters to 1 array and calculate a linear regression for each grid cell how can ? do this?



                max_consecutive_days_1<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)
                max_consecutive_days_2<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)
                max_consecutive_days_3<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)
                max_consecutive_days_4<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)

                values(max_consecutive_days_1)  <- 1:ncell(max_consecutive_days_1)
                values(max_consecutive_days_2) <- 1:ncell(max_consecutive_days_2)
                values(max_consecutive_days_3) <- 1:ncell(max_consecutive_days_3)
                values(max_consecutive_days_4) <- 1:ncell(max_consecutive_days_4)
                set.seed(0)
                values(max_consecutive_days_1)  <- runif(ncell(max_consecutive_days_1))
                values(max_consecutive_days_2) <- runif(ncell(max_consecutive_days_2))
                values(max_consecutive_days_3) <- runif(ncell(max_consecutive_days_3))
                values(max_consecutive_days_4) <- runif(ncell(max_consecutive_days_4))

         I tried to convert raster to an array and calculate a linear regression for each cell with these codes. there is something wrong in codes but I didn't find what it's wrong

        library(raster)
            r<-raster("C:/max_consecutive_days_1.tif")
            a<-array(NA,dim=c(dim(r)[1:2],4))
            i <- 1
            dir.in <- "C:/max_consecutive_days/"
            for (year in 1:4) {
              fi<-paste0(dir.in,"max_consecutive_days_",year,".tif")
              r<-raster(fi)
              a[,,i]<-getValues(r,format="matrix")
              i<-i+1
            }


     lmfunction <- function(x){

              if (is.na(x[1])){ NA }

              else

                y<-c(1:length(x))
              m1<- summary(lm(x~y))
              coef <- m1$coef[2]

              coef
             }

            storem <- array(NA,dim=dim(a)[1:2])
            for(i in 1:94){
              for(j in 1:192){
                tst<-mean(a[i,j,],n.rm=T)
                if (is.na(tst)==F){
                  storem[i,j]<-lmfunction(a[i,j,])
                }
              }
            }


Best wishes,

Windows 10 i?in Posta<https://go.microsoft.com/fwlink/?LinkId=550986> ile g?nderildi


	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Wed Sep  9 17:30:13 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 9 Sep 2020 17:30:13 +0200
Subject: [R] facet_wrap(nrow) ignored
Message-ID: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>

Dear useRs,

I have an issue with the argument nrow of ggplot2::facet_wrap().

Let's consider some sample data:
mydf <- data.frame(grp = rep(letters[1:6], each = 15), cat = rep(1:3,
30), var = rnorm(90))

And let's try to plot with 5 rows:
library(ggplot2)
ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
facet_wrap(~grp, nrow = 5)
It plots 2 rows and 3 columns rather than 5 rows and 2 columns as wanted.

These plots are as expected:
ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
facet_wrap(~grp, nrow = 2)
ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
facet_wrap(~grp, nrow = 6)

My guess is that 5 rows is not ideal for 6 facets (5 facets in 1st
column and only 1 facet for 2nd column) so it overrides the value of
nrow. In the case of 2 or 6 rows, the facets are well distributed in the
layout.

The reason why I need 5 rows with 6 facets is that this facet plot is
part of a patchwork and I would like to have the same number of rows for
all facet plots of the patchwork (so that they all align well).

Is there a way to force the number of rows in the facet_wrap()?

Thank you in advance.
Best,
Ivan

-- 


--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 10:35:45 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 10:35:45 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
Message-ID: <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>

Thank you very much for the code, that was very helpful.
I got the article by Hutcheson -- I don't know if I can distribute it
, given the possible copyrights, or if I can attach it here -- but it
does not report numbers directly: it refers to a previous article
counting bird death on a telegraph each year. The numbers
are:
bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
bird_1959 <- c(0,0,14,59,26,68,0)
bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)

This for sake of the argument.
As for my problem, I implemented the Shannon index with the package
iNext, which only gives me the index itself and the 95% CI. Even when
I implemented it with vegan, I only got the index. Essentially I don't
have a count of species I could feed into the Hutcheson's. Is there a
way to extract these data? Or to run a Hutcheson's on the final index?
Thank you

On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
<karl.schilling at uni-bonn.de> wrote:
>
> Dear Luigi,
>
> below some code I cobbled together based on the Hutcheson paper you
> mentioned. I was lucky to find code to calculate h and, importantly, its
> variance in the R-package QSutils - you may find it on the Bioconductor
> website.
>
> here is the code, along with an example. I also attach the code as an
> R-file.
>
> Hope that helps.
> All my best
>
> Karl
> PS don't forget to adjust for multiple testing if you compare more than
> two groups.
> K
>
>
> # load package needed
> # QSutils is on Bioconductor
> library(QSutils)
>
> # here some exemplary data - these are the data from Pilou 1966 that are
> used
> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
>
> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> # numbers of the first example used by Hutcheson were unfortunately not
> # available to me
>
> # here starts the code ; you may replace the variables "earlier" and "later"
> # by your own numbers.
>
> # calculate h, var(h) etc
> h1 <- Shannon(earlier)
> varh1 <- ShannonVar(earlier)
> n1 <- sum (earlier)
> h2 <- Shannon(later)
> varh2 <- ShannonVar(later)
> n2 <- sum (later)
> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
>
> # compare numbers with those in the paper
> h1
> h2
> varh1
> varh2
> # I assume that minor numerical differences are due to differences in the
> # numerical precision of computers in the early seventies and today / KS
>
> # this is the actual t-test
> t <- (h1-h2) /sqrt(varh1 + varh2)
> p <- 2*pt(-abs(t),df= degfree)
> p
>
> # that's it
> # Best
> # Karl
> --
> Karl Schilling, MD
> Professor of Anatomy and Cell Biology
> Anatomisches Institut
> Rheinische Friedrich-Wilhelms-Universit?t
> Nussallee 10
>
> D-53115 Bonn
> Germany
>
> phone ++49-228-73-2602
>


-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 10:38:41 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 10:38:41 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
Message-ID: <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>

Update:
I can see that you used the function Shannon from the package QSutils.
This would supplement the iNext package I used and solve the problem.
Thank you.

On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Thank you very much for the code, that was very helpful.
> I got the article by Hutcheson -- I don't know if I can distribute it
> , given the possible copyrights, or if I can attach it here -- but it
> does not report numbers directly: it refers to a previous article
> counting bird death on a telegraph each year. The numbers
> are:
> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> bird_1959 <- c(0,0,14,59,26,68,0)
> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
>
> This for sake of the argument.
> As for my problem, I implemented the Shannon index with the package
> iNext, which only gives me the index itself and the 95% CI. Even when
> I implemented it with vegan, I only got the index. Essentially I don't
> have a count of species I could feed into the Hutcheson's. Is there a
> way to extract these data? Or to run a Hutcheson's on the final index?
> Thank you
>
> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> <karl.schilling at uni-bonn.de> wrote:
> >
> > Dear Luigi,
> >
> > below some code I cobbled together based on the Hutcheson paper you
> > mentioned. I was lucky to find code to calculate h and, importantly, its
> > variance in the R-package QSutils - you may find it on the Bioconductor
> > website.
> >
> > here is the code, along with an example. I also attach the code as an
> > R-file.
> >
> > Hope that helps.
> > All my best
> >
> > Karl
> > PS don't forget to adjust for multiple testing if you compare more than
> > two groups.
> > K
> >
> >
> > # load package needed
> > # QSutils is on Bioconductor
> > library(QSutils)
> >
> > # here some exemplary data - these are the data from Pilou 1966 that are
> > used
> > # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> >
> > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > # numbers of the first example used by Hutcheson were unfortunately not
> > # available to me
> >
> > # here starts the code ; you may replace the variables "earlier" and "later"
> > # by your own numbers.
> >
> > # calculate h, var(h) etc
> > h1 <- Shannon(earlier)
> > varh1 <- ShannonVar(earlier)
> > n1 <- sum (earlier)
> > h2 <- Shannon(later)
> > varh2 <- ShannonVar(later)
> > n2 <- sum (later)
> > degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> >
> > # compare numbers with those in the paper
> > h1
> > h2
> > varh1
> > varh2
> > # I assume that minor numerical differences are due to differences in the
> > # numerical precision of computers in the early seventies and today / KS
> >
> > # this is the actual t-test
> > t <- (h1-h2) /sqrt(varh1 + varh2)
> > p <- 2*pt(-abs(t),df= degfree)
> > p
> >
> > # that's it
> > # Best
> > # Karl
> > --
> > Karl Schilling, MD
> > Professor of Anatomy and Cell Biology
> > Anatomisches Institut
> > Rheinische Friedrich-Wilhelms-Universit?t
> > Nussallee 10
> >
> > D-53115 Bonn
> > Germany
> >
> > phone ++49-228-73-2602
> >
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de  Thu Sep 10 11:54:52 2020
From: U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de (Ulrik Stervbo)
Date: Thu, 10 Sep 2020 11:54:52 +0200
Subject: [R] facet_wrap(nrow) ignored
In-Reply-To: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>
References: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>
Message-ID: <c94070a827f99442f190661149968da4@ruhr-uni-bochum.de>

Dear Ivan,

I don't think it is possible to force a number of rows - but I'm 
honestly just guessing.

What you can do is to add an empty plot. Here I use cowplot, but 
gridExtra should also work well.

I add an indication of the row number for the plot to the initial 
data.frame, and loop over these.

In the first variant, I add an unused factor to the grp which creates an 
empty facet. I personally think this looks a little confusing, so in the 
second variant, I add a number of empty plots.

HTH
Ulrik

```
mydf <- data.frame(
   grp = rep(letters[1:6], each = 15),
   cat = rep(1:3, 30),
   var = rnorm(90),
   row_num = rep(c(1, 1, 2, 3, 4, 5), each = 15)
)

s_mydf <- split(mydf, mydf$row_num)

plots_mydf <- lapply(s_mydf, function(x){
   # Ensure no unused factors
   x$grp <- droplevels.factor(x$grp)
   if(length(unique(x$grp)) == 1){
     x$grp <- factor(x$grp, levels = c(unique(x$grp), ""))
   }
   ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
     facet_wrap(~grp, drop=FALSE)
})

cowplot::plot_grid(plotlist = plots_mydf, nrow = 5)

# Maybe more elegant output
plots_mydf <- lapply(s_mydf, function(x, ncol = 2){
   # Ensure no unused factors
   x$grp <- droplevels.factor(x$grp)
   x <- split(x, x$grp)

   p <- lapply(x, function(x){
     ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
       facet_wrap(~grp)
   })

   if(length(p) < ncol){
     pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
     p <- c(p, pe)
   }
   cowplot::plot_grid(plotlist = p, ncol = ncol)
})

cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)

# Or if you prefer not to split the plots on the same row
plots_mydf <- lapply(s_mydf, function(x, ncol = 2){

   p <- list(ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
     facet_wrap(~grp))

   if(length(unique(x$grp)) < ncol){
     pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
     p <- c(p, pe)
   }else{
     ncol <- 1
   }
   cowplot::plot_grid(plotlist = p, ncol = ncol)
})

cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)

```

On 2020-09-09 17:30, Ivan Calandra wrote:
> Dear useRs,
> 
> I have an issue with the argument nrow of ggplot2::facet_wrap().
> 
> Let's consider some sample data:
> mydf <- data.frame(grp = rep(letters[1:6], each = 15), cat = rep(1:3,
> 30), var = rnorm(90))
> 
> And let's try to plot with 5 rows:
> library(ggplot2)
> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
> facet_wrap(~grp, nrow = 5)
> It plots 2 rows and 3 columns rather than 5 rows and 2 columns as 
> wanted.
> 
> These plots are as expected:
> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
> facet_wrap(~grp, nrow = 2)
> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
> facet_wrap(~grp, nrow = 6)
> 
> My guess is that 5 rows is not ideal for 6 facets (5 facets in 1st
> column and only 1 facet for 2nd column) so it overrides the value of
> nrow. In the case of 2 or 6 rows, the facets are well distributed in 
> the
> layout.
> 
> The reason why I need 5 rows with 6 facets is that this facet plot is
> part of a patchwork and I would like to have the same number of rows 
> for
> all facet plots of the patchwork (so that they all align well).
> 
> Is there a way to force the number of rows in the facet_wrap()?
> 
> Thank you in advance.
> Best,
> Ivan
> 
> --
> 
> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 10 12:44:39 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 10 Sep 2020 11:44:39 +0100
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
Message-ID: <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>

If you want a function automating Karl's code, here it is. It returns an 
object of S3 class "htest", R's standard for hypothesis tests functions. 
The returned object can then be subset in the usual ways, ht$statistic, 
ht$parameter, ht$p.value, etc.


library(QSutils)

hutcheson.test <- function(x1, x2){
   dataname1 <- deparse(substitute(x1))
   dataname2 <- deparse(substitute(x2))
   method <- "Hutcheson's t-test for Shannon diversity equality"
   alternative <- "the diversities of the two samples are not equal"
   h1 <- Shannon(x1)
   varh1 <- ShannonVar(x1)
   n1 <- sum(x1)
   h2 <- Shannon(x2)
   varh2 <- ShannonVar(x2)
   n2 <- sum(x2)
   degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
   tstat <- (h1 - h2)/sqrt(varh1 + varh2)
   p.value <- 2*pt(-abs(tstat), df = degfree)
   ht <- list(
     statistic = c(t = tstat),
     parameter = c(df = degfree),
     p.value = p.value,
     alternative = alternative,
     method = method,
     data.name = paste(dataname1, dataname2, sep = ", ")
   )
   class(ht) <- "htest"
   ht
}

earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)

hutcheson.test(earlier, later)



With the data you provided:


bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
bird_1959 <- c(0,0,14,59,26,68,0)
bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)

hutcheson.test(bird_1956, bird_1957)




Note that like David said earlier, there might be better ways to 
interpret Shannon's diversity index. If h is the sample's diversity, 
exp(h) gives the number of equally-common species with equivalent 
diversity.


s1 <- Shannon(earlier)
s2 <- Shannon(later)
c(earlier = s1, later = s2)
exp(c(earlier = s1, later = s2))   # Both round to 3
eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
Shannon(eq_common)                 # Slightly greater than the samples' 
diversity


round(exp(sapply(birds, Shannon))) # Your data


#-------------------------------------


Earlier Karl wrote [1] that


Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
that explains the minor numerical differences obtained with the code
above and the published variances.


I don't believe the published variances were computed with the published 
variance estimator. The code below computes the variances like QSutils 
and with formula (4) in Hutcheson's paper. The latter does not give the 
same results.

var_est <- function(n){
   s <- length(n)
   N <- sum(n)
   p <- n/N
   i <- p != 0
   inv.p <- numeric(s)
   inv.p[i] <- 1/p[i]
   log.p <- numeric(s)
   log.p[i] <- log(p[i])
   #
   term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
   term2 <- (s - 1)/(2*N^2)
   #
   numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p * 
log.p)
   denom3 <- 6*N^3
   term3 <- numer3/denom3
   list(
     Bioc = term1 + term2,
     Hutch = term1 + term2 + term3
   )
}

Vh1 <- var_est(earlier)
Vh1
all.equal(ShannonVar(earlier), Vh1$Bioc)
ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31

Vh2 <- var_est(later)
Vh2
identical(ShannonVar(later), Vh2$Bioc)    # TRUE



[1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html


Hope this helps,

Rui Barradas


?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> Update:
> I can see that you used the function Shannon from the package QSutils.
> This would supplement the iNext package I used and solve the problem.
> Thank you.
> 
> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
>>
>> Thank you very much for the code, that was very helpful.
>> I got the article by Hutcheson -- I don't know if I can distribute it
>> , given the possible copyrights, or if I can attach it here -- but it
>> does not report numbers directly: it refers to a previous article
>> counting bird death on a telegraph each year. The numbers
>> are:
>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
>> bird_1959 <- c(0,0,14,59,26,68,0)
>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
>>
>> This for sake of the argument.
>> As for my problem, I implemented the Shannon index with the package
>> iNext, which only gives me the index itself and the 95% CI. Even when
>> I implemented it with vegan, I only got the index. Essentially I don't
>> have a count of species I could feed into the Hutcheson's. Is there a
>> way to extract these data? Or to run a Hutcheson's on the final index?
>> Thank you
>>
>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
>> <karl.schilling at uni-bonn.de> wrote:
>>>
>>> Dear Luigi,
>>>
>>> below some code I cobbled together based on the Hutcheson paper you
>>> mentioned. I was lucky to find code to calculate h and, importantly, its
>>> variance in the R-package QSutils - you may find it on the Bioconductor
>>> website.
>>>
>>> here is the code, along with an example. I also attach the code as an
>>> R-file.
>>>
>>> Hope that helps.
>>> All my best
>>>
>>> Karl
>>> PS don't forget to adjust for multiple testing if you compare more than
>>> two groups.
>>> K
>>>
>>>
>>> # load package needed
>>> # QSutils is on Bioconductor
>>> library(QSutils)
>>>
>>> # here some exemplary data - these are the data from Pilou 1966 that are
>>> used
>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
>>>
>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
>>> # numbers of the first example used by Hutcheson were unfortunately not
>>> # available to me
>>>
>>> # here starts the code ; you may replace the variables "earlier" and "later"
>>> # by your own numbers.
>>>
>>> # calculate h, var(h) etc
>>> h1 <- Shannon(earlier)
>>> varh1 <- ShannonVar(earlier)
>>> n1 <- sum (earlier)
>>> h2 <- Shannon(later)
>>> varh2 <- ShannonVar(later)
>>> n2 <- sum (later)
>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
>>>
>>> # compare numbers with those in the paper
>>> h1
>>> h2
>>> varh1
>>> varh2
>>> # I assume that minor numerical differences are due to differences in the
>>> # numerical precision of computers in the early seventies and today / KS
>>>
>>> # this is the actual t-test
>>> t <- (h1-h2) /sqrt(varh1 + varh2)
>>> p <- 2*pt(-abs(t),df= degfree)
>>> p
>>>
>>> # that's it
>>> # Best
>>> # Karl
>>> --
>>> Karl Schilling, MD
>>> Professor of Anatomy and Cell Biology
>>> Anatomisches Institut
>>> Rheinische Friedrich-Wilhelms-Universit?t
>>> Nussallee 10
>>>
>>> D-53115 Bonn
>>> Germany
>>>
>>> phone ++49-228-73-2602
>>>
>>
>>
>> --
>> Best regards,
>> Luigi
> 
> 
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 10 13:04:17 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 10 Sep 2020 12:04:17 +0100
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
Message-ID: <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>

Hello,

Sorry, there's an instruction missing. See inline.

?s 11:44 de 10/09/20, Rui Barradas escreveu:
> If you want a function automating Karl's code, here it is. It returns an 
> object of S3 class "htest", R's standard for hypothesis tests functions. 
> The returned object can then be subset in the usual ways, ht$statistic, 
> ht$parameter, ht$p.value, etc.
> 
> 
> library(QSutils)
> 
> hutcheson.test <- function(x1, x2){
>  ? dataname1 <- deparse(substitute(x1))
>  ? dataname2 <- deparse(substitute(x2))
>  ? method <- "Hutcheson's t-test for Shannon diversity equality"
>  ? alternative <- "the diversities of the two samples are not equal"
>  ? h1 <- Shannon(x1)
>  ? varh1 <- ShannonVar(x1)
>  ? n1 <- sum(x1)
>  ? h2 <- Shannon(x2)
>  ? varh2 <- ShannonVar(x2)
>  ? n2 <- sum(x2)
>  ? degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
>  ? tstat <- (h1 - h2)/sqrt(varh1 + varh2)
>  ? p.value <- 2*pt(-abs(tstat), df = degfree)
>  ? ht <- list(
>  ??? statistic = c(t = tstat),
>  ??? parameter = c(df = degfree),
>  ??? p.value = p.value,
>  ??? alternative = alternative,
>  ??? method = method,
>  ??? data.name = paste(dataname1, dataname2, sep = ", ")
>  ? )
>  ? class(ht) <- "htest"
>  ? ht
> }
> 
> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> 
> hutcheson.test(earlier, later)
> 
> 
> 
> With the data you provided:
> 
> 
> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> bird_1959 <- c(0,0,14,59,26,68,0)
> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> 
> hutcheson.test(bird_1956, bird_1957)
> 
> 
> 
> 
> Note that like David said earlier, there might be better ways to 
> interpret Shannon's diversity index. If h is the sample's diversity, 
> exp(h) gives the number of equally-common species with equivalent 
> diversity.
> 
> 
> s1 <- Shannon(earlier)
> s2 <- Shannon(later)
> c(earlier = s1, later = s2)
> exp(c(earlier = s1, later = s2))?? # Both round to 3
> eq_common <- rep(1, 3)???????????? # Can be 1 specimen or any other number
> Shannon(eq_common)???????????????? # Slightly greater than the samples' 
> diversity
> 
>

# Create a list with all the data
birds <- mget(ls(pattern = "^bird"))

> round(exp(sapply(birds, Shannon))) # Your data


Hope this helps,

Rui Barradas

> 
> 
> #-------------------------------------
> 
> 
> Earlier Karl wrote [1] that
> 
> 
> Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> that explains the minor numerical differences obtained with the code
> above and the published variances.
> 
> 
> I don't believe the published variances were computed with the published 
> variance estimator. The code below computes the variances like QSutils 
> and with formula (4) in Hutcheson's paper. The latter does not give the 
> same results.
> 
> var_est <- function(n){
>  ? s <- length(n)
>  ? N <- sum(n)
>  ? p <- n/N
>  ? i <- p != 0
>  ? inv.p <- numeric(s)
>  ? inv.p[i] <- 1/p[i]
>  ? log.p <- numeric(s)
>  ? log.p[i] <- log(p[i])
>  ? #
>  ? term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
>  ? term2 <- (s - 1)/(2*N^2)
>  ? #
>  ? numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p * 
> log.p)
>  ? denom3 <- 6*N^3
>  ? term3 <- numer3/denom3
>  ? list(
>  ??? Bioc = term1 + term2,
>  ??? Hutch = term1 + term2 + term3
>  ? )
> }
> 
> Vh1 <- var_est(earlier)
> Vh1
> all.equal(ShannonVar(earlier), Vh1$Bioc)
> ShannonVar(earlier) - Vh1$Bioc??????????? # FAQ 7.31
> 
> Vh2 <- var_est(later)
> Vh2
> identical(ShannonVar(later), Vh2$Bioc)??? # TRUE
> 
> 
> 
> [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
>> Update:
>> I can see that you used the function Shannon from the package QSutils.
>> This would supplement the iNext package I used and solve the problem.
>> Thank you.
>>
>> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>>
>>> Thank you very much for the code, that was very helpful.
>>> I got the article by Hutcheson -- I don't know if I can distribute it
>>> , given the possible copyrights, or if I can attach it here -- but it
>>> does not report numbers directly: it refers to a previous article
>>> counting bird death on a telegraph each year. The numbers
>>> are:
>>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
>>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
>>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
>>> bird_1959 <- c(0,0,14,59,26,68,0)
>>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
>>>
>>> This for sake of the argument.
>>> As for my problem, I implemented the Shannon index with the package
>>> iNext, which only gives me the index itself and the 95% CI. Even when
>>> I implemented it with vegan, I only got the index. Essentially I don't
>>> have a count of species I could feed into the Hutcheson's. Is there a
>>> way to extract these data? Or to run a Hutcheson's on the final index?
>>> Thank you
>>>
>>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
>>> <karl.schilling at uni-bonn.de> wrote:
>>>>
>>>> Dear Luigi,
>>>>
>>>> below some code I cobbled together based on the Hutcheson paper you
>>>> mentioned. I was lucky to find code to calculate h and, importantly, 
>>>> its
>>>> variance in the R-package QSutils - you may find it on the Bioconductor
>>>> website.
>>>>
>>>> here is the code, along with an example. I also attach the code as an
>>>> R-file.
>>>>
>>>> Hope that helps.
>>>> All my best
>>>>
>>>> Karl
>>>> PS don't forget to adjust for multiple testing if you compare more than
>>>> two groups.
>>>> K
>>>>
>>>>
>>>> # load package needed
>>>> # QSutils is on Bioconductor
>>>> library(QSutils)
>>>>
>>>> # here some exemplary data - these are the data from Pilou 1966 that 
>>>> are
>>>> used
>>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
>>>>
>>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
>>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
>>>> # numbers of the first example used by Hutcheson were unfortunately not
>>>> # available to me
>>>>
>>>> # here starts the code ; you may replace the variables "earlier" and 
>>>> "later"
>>>> # by your own numbers.
>>>>
>>>> # calculate h, var(h) etc
>>>> h1 <- Shannon(earlier)
>>>> varh1 <- ShannonVar(earlier)
>>>> n1 <- sum (earlier)
>>>> h2 <- Shannon(later)
>>>> varh2 <- ShannonVar(later)
>>>> n2 <- sum (later)
>>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
>>>>
>>>> # compare numbers with those in the paper
>>>> h1
>>>> h2
>>>> varh1
>>>> varh2
>>>> # I assume that minor numerical differences are due to differences 
>>>> in the
>>>> # numerical precision of computers in the early seventies and today 
>>>> / KS
>>>>
>>>> # this is the actual t-test
>>>> t <- (h1-h2) /sqrt(varh1 + varh2)
>>>> p <- 2*pt(-abs(t),df= degfree)
>>>> p
>>>>
>>>> # that's it
>>>> # Best
>>>> # Karl
>>>> -- 
>>>> Karl Schilling, MD
>>>> Professor of Anatomy and Cell Biology
>>>> Anatomisches Institut
>>>> Rheinische Friedrich-Wilhelms-Universit?t
>>>> Nussallee 10
>>>>
>>>> D-53115 Bonn
>>>> Germany
>>>>
>>>> phone ++49-228-73-2602
>>>>
>>>
>>>
>>> -- 
>>> Best regards,
>>> Luigi
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Sep 10 13:53:20 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 10 Sep 2020 13:53:20 +0200
Subject: [R] facet_wrap(nrow) ignored
In-Reply-To: <c94070a827f99442f190661149968da4@ruhr-uni-bochum.de>
References: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>
 <c94070a827f99442f190661149968da4@ruhr-uni-bochum.de>
Message-ID: <4067e7b0-3a35-9db4-16fe-009e269a51a5@rgzm.de>

Thank you Ulrik for the suggestions.

I was thinking of a similar approach using a nested patchwork (which
would be easier for me).

It's just a shame that it is not possible to force a number of rows.
It's good that ggplot2 tries to do things in the most "appropriate" way,
but at some point, when the user decides it needs to have 5 rows, then
ggplot2 should listen, potentially issuing a warning like "the number of
rows specified is not appropriate, consider other values instead (e.g. 2)".

Best,
Ivan

PS: our email server is having troubles today, so I have not received
any other R-related emails. Are there few today or is it just me? There
might even be more answers to my question...

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 10/09/2020 11:54, Ulrik Stervbo wrote:
> Dear Ivan,
>
> I don't think it is possible to force a number of rows - but I'm
> honestly just guessing.
>
> What you can do is to add an empty plot. Here I use cowplot, but
> gridExtra should also work well.
>
> I add an indication of the row number for the plot to the initial
> data.frame, and loop over these.
>
> In the first variant, I add an unused factor to the grp which creates
> an empty facet. I personally think this looks a little confusing, so
> in the second variant, I add a number of empty plots.
>
> HTH
> Ulrik
>
> ```
> mydf <- data.frame(
> ? grp = rep(letters[1:6], each = 15),
> ? cat = rep(1:3, 30),
> ? var = rnorm(90),
> ? row_num = rep(c(1, 1, 2, 3, 4, 5), each = 15)
> )
>
> s_mydf <- split(mydf, mydf$row_num)
>
> plots_mydf <- lapply(s_mydf, function(x){
> ? # Ensure no unused factors
> ? x$grp <- droplevels.factor(x$grp)
> ? if(length(unique(x$grp)) == 1){
> ??? x$grp <- factor(x$grp, levels = c(unique(x$grp), ""))
> ? }
> ? ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
> ??? facet_wrap(~grp, drop=FALSE)
> })
>
> cowplot::plot_grid(plotlist = plots_mydf, nrow = 5)
>
> # Maybe more elegant output
> plots_mydf <- lapply(s_mydf, function(x, ncol = 2){
> ? # Ensure no unused factors
> ? x$grp <- droplevels.factor(x$grp)
> ? x <- split(x, x$grp)
>
> ? p <- lapply(x, function(x){
> ??? ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
> ????? facet_wrap(~grp)
> ? })
>
> ? if(length(p) < ncol){
> ??? pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
> ??? p <- c(p, pe)
> ? }
> ? cowplot::plot_grid(plotlist = p, ncol = ncol)
> })
>
> cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)
>
> # Or if you prefer not to split the plots on the same row
> plots_mydf <- lapply(s_mydf, function(x, ncol = 2){
>
> ? p <- list(ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
> ??? facet_wrap(~grp))
>
> ? if(length(unique(x$grp)) < ncol){
> ??? pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
> ??? p <- c(p, pe)
> ? }else{
> ??? ncol <- 1
> ? }
> ? cowplot::plot_grid(plotlist = p, ncol = ncol)
> })
>
> cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)
>
> ```
>
> On 2020-09-09 17:30, Ivan Calandra wrote:
>> Dear useRs,
>>
>> I have an issue with the argument nrow of ggplot2::facet_wrap().
>>
>> Let's consider some sample data:
>> mydf <- data.frame(grp = rep(letters[1:6], each = 15), cat = rep(1:3,
>> 30), var = rnorm(90))
>>
>> And let's try to plot with 5 rows:
>> library(ggplot2)
>> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
>> facet_wrap(~grp, nrow = 5)
>> It plots 2 rows and 3 columns rather than 5 rows and 2 columns as
>> wanted.
>>
>> These plots are as expected:
>> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
>> facet_wrap(~grp, nrow = 2)
>> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
>> facet_wrap(~grp, nrow = 6)
>>
>> My guess is that 5 rows is not ideal for 6 facets (5 facets in 1st
>> column and only 1 facet for 2nd column) so it overrides the value of
>> nrow. In the case of 2 or 6 rows, the facets are well distributed in the
>> layout.
>>
>> The reason why I need 5 rows with 6 facets is that this facet plot is
>> part of a patchwork and I would like to have the same number of rows for
>> all facet plots of the patchwork (so that they all align well).
>>
>> Is there a way to force the number of rows in the facet_wrap()?
>>
>> Thank you in advance.
>> Best,
>> Ivan
>>
>> -- 
>>
>>
>> -- 
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 14:10:26 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 14:10:26 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
Message-ID: <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>

Hello,
thank you for the code. To explain better, when I used vegan, I did
not count the species directly but simply prepared a dataframe where,
for each species, I counted the number of samples bearing such
species:
```

> str(new_df)
'data.frame': 3 obs. of  46 variables:
 $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
 $ NC_001623 Autographa californica nucl...: int  7 7 7
 $ NC_001895 Enterobacteria phage P2       : int  1 0 0
 $ NC_004745 Yersinia phage L-413C         : int  1 0 0
```
here the triplettes refer to healthy, tumor and metastasis. The outcome is:
```
# Shannon index
diversity(new_df)
#> Normal     Tumour     Metastasis
#> 2.520139   3.109512   1.890404
```
Using iNext, I provided a list of all the species counted in a samples
```
> new_list
$Healthy
 [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0

$Tumour
 [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
1 2 1 1 1 1 1 1 1 0 0 0 0

$Metastasis
 [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 1 1 1 1
```
>From this I get:
```
mod = iNEXT(new_list, q=0, datatype="abundance")
mod$AsyEst
#Site         Diversity Observed Estimator   s.e.    LCL     UCL
#1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
#2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
#4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
#5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
#7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
#8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
```
So here the Shannon index is 12 instead of 2.5...
Using Karl's function, I get:
```
# compute Shannon
norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
# compute Hutcheson
degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
canc_var**2 /canc_sum)
test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
(p <- 2*pt(-abs(test),df= degree))
> [1] 0.01825784
```
remarkably, the indices are the same as obtained by vegan:
```
> norm_sIdx
[1] 2.520139
> canc_sIdx
[1] 3.109512
> meta_sIdx
[1] 1.890404
```

I tried Rui's function but I got an error, so I wrote it as
```
hutcheson = function(A, B){
  # compute Shannon index, variance and sum of elements
  A_index <- Shannon(A)
  B_index <- Shannon(B)
  A_var <- ShannonVar(A)
  B_var <- ShannonVar(B)
  A_sum <- sum(A)
  B_sum <- sum(B)
  # compute Hutcheson
  DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
  test <- (A_index-B_index) /sqrt(A_var + B_var)
  p <- 2*pt(-abs(test),df= DF)
  # closure
  cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
index first group: ",
      round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
      "\n\tp-value : ", round(p, 4), "\n", sep = "")
  return(p)
}
```
and I got:
```

> n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 2.5201
Shannon index second group: 3.1095
p-value : 0.0183
> n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 2.5201
Shannon index second group: 1.8904
p-value : 0.0371
> t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 3.1095
Shannon index second group: 1.8904
p-value : 0
```
new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
the original Hutcheson data:
```
> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> hutcheson(bird_1956, bird_1957)
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 1.8429
Shannon index second group: 1.0689
p-value : 0

```
This is to compare two groups at the time. I'll probably have to
compensate for multiple testing...
But if this all OK, then the case is closed.
Thank you

On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Sorry, there's an instruction missing. See inline.
>
> ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > If you want a function automating Karl's code, here it is. It returns an
> > object of S3 class "htest", R's standard for hypothesis tests functions.
> > The returned object can then be subset in the usual ways, ht$statistic,
> > ht$parameter, ht$p.value, etc.
> >
> >
> > library(QSutils)
> >
> > hutcheson.test <- function(x1, x2){
> >    dataname1 <- deparse(substitute(x1))
> >    dataname2 <- deparse(substitute(x2))
> >    method <- "Hutcheson's t-test for Shannon diversity equality"
> >    alternative <- "the diversities of the two samples are not equal"
> >    h1 <- Shannon(x1)
> >    varh1 <- ShannonVar(x1)
> >    n1 <- sum(x1)
> >    h2 <- Shannon(x2)
> >    varh2 <- ShannonVar(x2)
> >    n2 <- sum(x2)
> >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> >    p.value <- 2*pt(-abs(tstat), df = degfree)
> >    ht <- list(
> >      statistic = c(t = tstat),
> >      parameter = c(df = degfree),
> >      p.value = p.value,
> >      alternative = alternative,
> >      method = method,
> >      data.name = paste(dataname1, dataname2, sep = ", ")
> >    )
> >    class(ht) <- "htest"
> >    ht
> > }
> >
> > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> >
> > hutcheson.test(earlier, later)
> >
> >
> >
> > With the data you provided:
> >
> >
> > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > bird_1959 <- c(0,0,14,59,26,68,0)
> > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> >
> > hutcheson.test(bird_1956, bird_1957)
> >
> >
> >
> >
> > Note that like David said earlier, there might be better ways to
> > interpret Shannon's diversity index. If h is the sample's diversity,
> > exp(h) gives the number of equally-common species with equivalent
> > diversity.
> >
> >
> > s1 <- Shannon(earlier)
> > s2 <- Shannon(later)
> > c(earlier = s1, later = s2)
> > exp(c(earlier = s1, later = s2))   # Both round to 3
> > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > Shannon(eq_common)                 # Slightly greater than the samples'
> > diversity
> >
> >
>
> # Create a list with all the data
> birds <- mget(ls(pattern = "^bird"))
>
> > round(exp(sapply(birds, Shannon))) # Your data
>
>
> Hope this helps,
>
> Rui Barradas
>
> >
> >
> > #-------------------------------------
> >
> >
> > Earlier Karl wrote [1] that
> >
> >
> > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > that explains the minor numerical differences obtained with the code
> > above and the published variances.
> >
> >
> > I don't believe the published variances were computed with the published
> > variance estimator. The code below computes the variances like QSutils
> > and with formula (4) in Hutcheson's paper. The latter does not give the
> > same results.
> >
> > var_est <- function(n){
> >    s <- length(n)
> >    N <- sum(n)
> >    p <- n/N
> >    i <- p != 0
> >    inv.p <- numeric(s)
> >    inv.p[i] <- 1/p[i]
> >    log.p <- numeric(s)
> >    log.p[i] <- log(p[i])
> >    #
> >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> >    term2 <- (s - 1)/(2*N^2)
> >    #
> >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > log.p)
> >    denom3 <- 6*N^3
> >    term3 <- numer3/denom3
> >    list(
> >      Bioc = term1 + term2,
> >      Hutch = term1 + term2 + term3
> >    )
> > }
> >
> > Vh1 <- var_est(earlier)
> > Vh1
> > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> >
> > Vh2 <- var_est(later)
> > Vh2
> > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> >
> >
> >
> > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> >> Update:
> >> I can see that you used the function Shannon from the package QSutils.
> >> This would supplement the iNext package I used and solve the problem.
> >> Thank you.
> >>
> >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> >> <marongiu.luigi at gmail.com> wrote:
> >>>
> >>> Thank you very much for the code, that was very helpful.
> >>> I got the article by Hutcheson -- I don't know if I can distribute it
> >>> , given the possible copyrights, or if I can attach it here -- but it
> >>> does not report numbers directly: it refers to a previous article
> >>> counting bird death on a telegraph each year. The numbers
> >>> are:
> >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> >>> bird_1959 <- c(0,0,14,59,26,68,0)
> >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> >>>
> >>> This for sake of the argument.
> >>> As for my problem, I implemented the Shannon index with the package
> >>> iNext, which only gives me the index itself and the 95% CI. Even when
> >>> I implemented it with vegan, I only got the index. Essentially I don't
> >>> have a count of species I could feed into the Hutcheson's. Is there a
> >>> way to extract these data? Or to run a Hutcheson's on the final index?
> >>> Thank you
> >>>
> >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> >>> <karl.schilling at uni-bonn.de> wrote:
> >>>>
> >>>> Dear Luigi,
> >>>>
> >>>> below some code I cobbled together based on the Hutcheson paper you
> >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> >>>> its
> >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> >>>> website.
> >>>>
> >>>> here is the code, along with an example. I also attach the code as an
> >>>> R-file.
> >>>>
> >>>> Hope that helps.
> >>>> All my best
> >>>>
> >>>> Karl
> >>>> PS don't forget to adjust for multiple testing if you compare more than
> >>>> two groups.
> >>>> K
> >>>>
> >>>>
> >>>> # load package needed
> >>>> # QSutils is on Bioconductor
> >>>> library(QSutils)
> >>>>
> >>>> # here some exemplary data - these are the data from Pilou 1966 that
> >>>> are
> >>>> used
> >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> >>>>
> >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> >>>> # numbers of the first example used by Hutcheson were unfortunately not
> >>>> # available to me
> >>>>
> >>>> # here starts the code ; you may replace the variables "earlier" and
> >>>> "later"
> >>>> # by your own numbers.
> >>>>
> >>>> # calculate h, var(h) etc
> >>>> h1 <- Shannon(earlier)
> >>>> varh1 <- ShannonVar(earlier)
> >>>> n1 <- sum (earlier)
> >>>> h2 <- Shannon(later)
> >>>> varh2 <- ShannonVar(later)
> >>>> n2 <- sum (later)
> >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> >>>>
> >>>> # compare numbers with those in the paper
> >>>> h1
> >>>> h2
> >>>> varh1
> >>>> varh2
> >>>> # I assume that minor numerical differences are due to differences
> >>>> in the
> >>>> # numerical precision of computers in the early seventies and today
> >>>> / KS
> >>>>
> >>>> # this is the actual t-test
> >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> >>>> p <- 2*pt(-abs(t),df= degfree)
> >>>> p
> >>>>
> >>>> # that's it
> >>>> # Best
> >>>> # Karl
> >>>> --
> >>>> Karl Schilling, MD
> >>>> Professor of Anatomy and Cell Biology
> >>>> Anatomisches Institut
> >>>> Rheinische Friedrich-Wilhelms-Universit?t
> >>>> Nussallee 10
> >>>>
> >>>> D-53115 Bonn
> >>>> Germany
> >>>>
> >>>> phone ++49-228-73-2602
> >>>>
> >>>
> >>>
> >>> --
> >>> Best regards,
> >>> Luigi
> >>
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 14:41:07 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 14:41:07 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
Message-ID: <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>

Update:
I also added the confidence interval for the Shannon index:
```
#! Hutcheson's t-test for Shannon diversity equality
# thanks to Karl Schilling and Rui Barradas
hutcheson = function(A, B){
  # compute Shannon index, variance and sum of elements
  A_index <- Shannon(A)
  B_index <- Shannon(B)
  A_var <- ShannonVar(A)
  B_var <- ShannonVar(B)
  A_sum <- sum(A)
  B_sum <- sum(B)
  # compute Hutcheson
  DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
  test <- (A_index-B_index) /sqrt(A_var + B_var)
  p <- 2*pt(-abs(test),df= DF)
  if (p < 0.001) {
    P = "<0.001"
  } else {
    P = round(p, 3)
  }
  if (p < 0.001) {
    S = "***"
  } else if (p < 0.01) {
    S = "**"
  } else if (p < 0.05) {
    S = "*"
  } else {
    S = ""
  }
  # closure
  cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
index first group: \t",
      round(A_index, 3), " (", round((A_index-2*A_var),3), "-",
round((A_index+2*A_var),3),
      ")\n\tShannon index second group: \t",
      round(B_index, 3), " (", round((B_index-2*B_var),3), "-",
round((B_index+2*B_var),3),
      ")\n\tp-value: ", P, " ", S, "\n", sep = "")
  return(p)
}
```

On Thu, Sep 10, 2020 at 2:10 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> thank you for the code. To explain better, when I used vegan, I did
> not count the species directly but simply prepared a dataframe where,
> for each species, I counted the number of samples bearing such
> species:
> ```
>
> > str(new_df)
> 'data.frame': 3 obs. of  46 variables:
>  $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
>  $ NC_001623 Autographa californica nucl...: int  7 7 7
>  $ NC_001895 Enterobacteria phage P2       : int  1 0 0
>  $ NC_004745 Yersinia phage L-413C         : int  1 0 0
> ```
> here the triplettes refer to healthy, tumor and metastasis. The outcome is:
> ```
> # Shannon index
> diversity(new_df)
> #> Normal     Tumour     Metastasis
> #> 2.520139   3.109512   1.890404
> ```
> Using iNext, I provided a list of all the species counted in a samples
> ```
> > new_list
> $Healthy
>  [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 0 0 0 0 0 0 0 0 0 0 0 0 0
>
> $Tumour
>  [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
> 1 2 1 1 1 1 1 1 1 0 0 0 0
>
> $Metastasis
>  [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 0 0 0 0 0 0 1 0 0 1 1 1 1
> ```
> From this I get:
> ```
> mod = iNEXT(new_list, q=0, datatype="abundance")
> mod$AsyEst
> #Site         Diversity Observed Estimator   s.e.    LCL     UCL
> #1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
> #2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
> #4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
> #5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
> #7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
> #8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
> ```
> So here the Shannon index is 12 instead of 2.5...
> Using Karl's function, I get:
> ```
> # compute Shannon
> norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
> canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
> meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
> norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
> canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
> meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
> norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
> canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
> meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
> # compute Hutcheson
> degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
> canc_var**2 /canc_sum)
> test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
> (p <- 2*pt(-abs(test),df= degree))
> > [1] 0.01825784
> ```
> remarkably, the indices are the same as obtained by vegan:
> ```
> > norm_sIdx
> [1] 2.520139
> > canc_sIdx
> [1] 3.109512
> > meta_sIdx
> [1] 1.890404
> ```
>
> I tried Rui's function but I got an error, so I wrote it as
> ```
> hutcheson = function(A, B){
>   # compute Shannon index, variance and sum of elements
>   A_index <- Shannon(A)
>   B_index <- Shannon(B)
>   A_var <- ShannonVar(A)
>   B_var <- ShannonVar(B)
>   A_sum <- sum(A)
>   B_sum <- sum(B)
>   # compute Hutcheson
>   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
>   test <- (A_index-B_index) /sqrt(A_var + B_var)
>   p <- 2*pt(-abs(test),df= DF)
>   # closure
>   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> index first group: ",
>       round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
>       "\n\tp-value : ", round(p, 4), "\n", sep = "")
>   return(p)
> }
> ```
> and I got:
> ```
>
> > n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 2.5201
> Shannon index second group: 3.1095
> p-value : 0.0183
> > n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 2.5201
> Shannon index second group: 1.8904
> p-value : 0.0371
> > t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 3.1095
> Shannon index second group: 1.8904
> p-value : 0
> ```
> new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
> the original Hutcheson data:
> ```
> > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > hutcheson(bird_1956, bird_1957)
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 1.8429
> Shannon index second group: 1.0689
> p-value : 0
>
> ```
> This is to compare two groups at the time. I'll probably have to
> compensate for multiple testing...
> But if this all OK, then the case is closed.
> Thank you
>
> On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Sorry, there's an instruction missing. See inline.
> >
> > ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > > If you want a function automating Karl's code, here it is. It returns an
> > > object of S3 class "htest", R's standard for hypothesis tests functions.
> > > The returned object can then be subset in the usual ways, ht$statistic,
> > > ht$parameter, ht$p.value, etc.
> > >
> > >
> > > library(QSutils)
> > >
> > > hutcheson.test <- function(x1, x2){
> > >    dataname1 <- deparse(substitute(x1))
> > >    dataname2 <- deparse(substitute(x2))
> > >    method <- "Hutcheson's t-test for Shannon diversity equality"
> > >    alternative <- "the diversities of the two samples are not equal"
> > >    h1 <- Shannon(x1)
> > >    varh1 <- ShannonVar(x1)
> > >    n1 <- sum(x1)
> > >    h2 <- Shannon(x2)
> > >    varh2 <- ShannonVar(x2)
> > >    n2 <- sum(x2)
> > >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> > >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> > >    p.value <- 2*pt(-abs(tstat), df = degfree)
> > >    ht <- list(
> > >      statistic = c(t = tstat),
> > >      parameter = c(df = degfree),
> > >      p.value = p.value,
> > >      alternative = alternative,
> > >      method = method,
> > >      data.name = paste(dataname1, dataname2, sep = ", ")
> > >    )
> > >    class(ht) <- "htest"
> > >    ht
> > > }
> > >
> > > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > >
> > > hutcheson.test(earlier, later)
> > >
> > >
> > >
> > > With the data you provided:
> > >
> > >
> > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > bird_1959 <- c(0,0,14,59,26,68,0)
> > > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > >
> > > hutcheson.test(bird_1956, bird_1957)
> > >
> > >
> > >
> > >
> > > Note that like David said earlier, there might be better ways to
> > > interpret Shannon's diversity index. If h is the sample's diversity,
> > > exp(h) gives the number of equally-common species with equivalent
> > > diversity.
> > >
> > >
> > > s1 <- Shannon(earlier)
> > > s2 <- Shannon(later)
> > > c(earlier = s1, later = s2)
> > > exp(c(earlier = s1, later = s2))   # Both round to 3
> > > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > > Shannon(eq_common)                 # Slightly greater than the samples'
> > > diversity
> > >
> > >
> >
> > # Create a list with all the data
> > birds <- mget(ls(pattern = "^bird"))
> >
> > > round(exp(sapply(birds, Shannon))) # Your data
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > >
> > >
> > > #-------------------------------------
> > >
> > >
> > > Earlier Karl wrote [1] that
> > >
> > >
> > > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > > that explains the minor numerical differences obtained with the code
> > > above and the published variances.
> > >
> > >
> > > I don't believe the published variances were computed with the published
> > > variance estimator. The code below computes the variances like QSutils
> > > and with formula (4) in Hutcheson's paper. The latter does not give the
> > > same results.
> > >
> > > var_est <- function(n){
> > >    s <- length(n)
> > >    N <- sum(n)
> > >    p <- n/N
> > >    i <- p != 0
> > >    inv.p <- numeric(s)
> > >    inv.p[i] <- 1/p[i]
> > >    log.p <- numeric(s)
> > >    log.p[i] <- log(p[i])
> > >    #
> > >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> > >    term2 <- (s - 1)/(2*N^2)
> > >    #
> > >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > > log.p)
> > >    denom3 <- 6*N^3
> > >    term3 <- numer3/denom3
> > >    list(
> > >      Bioc = term1 + term2,
> > >      Hutch = term1 + term2 + term3
> > >    )
> > > }
> > >
> > > Vh1 <- var_est(earlier)
> > > Vh1
> > > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> > >
> > > Vh2 <- var_est(later)
> > > Vh2
> > > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> > >
> > >
> > >
> > > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> > >> Update:
> > >> I can see that you used the function Shannon from the package QSutils.
> > >> This would supplement the iNext package I used and solve the problem.
> > >> Thank you.
> > >>
> > >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> > >> <marongiu.luigi at gmail.com> wrote:
> > >>>
> > >>> Thank you very much for the code, that was very helpful.
> > >>> I got the article by Hutcheson -- I don't know if I can distribute it
> > >>> , given the possible copyrights, or if I can attach it here -- but it
> > >>> does not report numbers directly: it refers to a previous article
> > >>> counting bird death on a telegraph each year. The numbers
> > >>> are:
> > >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > >>> bird_1959 <- c(0,0,14,59,26,68,0)
> > >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > >>>
> > >>> This for sake of the argument.
> > >>> As for my problem, I implemented the Shannon index with the package
> > >>> iNext, which only gives me the index itself and the 95% CI. Even when
> > >>> I implemented it with vegan, I only got the index. Essentially I don't
> > >>> have a count of species I could feed into the Hutcheson's. Is there a
> > >>> way to extract these data? Or to run a Hutcheson's on the final index?
> > >>> Thank you
> > >>>
> > >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> > >>> <karl.schilling at uni-bonn.de> wrote:
> > >>>>
> > >>>> Dear Luigi,
> > >>>>
> > >>>> below some code I cobbled together based on the Hutcheson paper you
> > >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> > >>>> its
> > >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> > >>>> website.
> > >>>>
> > >>>> here is the code, along with an example. I also attach the code as an
> > >>>> R-file.
> > >>>>
> > >>>> Hope that helps.
> > >>>> All my best
> > >>>>
> > >>>> Karl
> > >>>> PS don't forget to adjust for multiple testing if you compare more than
> > >>>> two groups.
> > >>>> K
> > >>>>
> > >>>>
> > >>>> # load package needed
> > >>>> # QSutils is on Bioconductor
> > >>>> library(QSutils)
> > >>>>
> > >>>> # here some exemplary data - these are the data from Pilou 1966 that
> > >>>> are
> > >>>> used
> > >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> > >>>>
> > >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > >>>> # numbers of the first example used by Hutcheson were unfortunately not
> > >>>> # available to me
> > >>>>
> > >>>> # here starts the code ; you may replace the variables "earlier" and
> > >>>> "later"
> > >>>> # by your own numbers.
> > >>>>
> > >>>> # calculate h, var(h) etc
> > >>>> h1 <- Shannon(earlier)
> > >>>> varh1 <- ShannonVar(earlier)
> > >>>> n1 <- sum (earlier)
> > >>>> h2 <- Shannon(later)
> > >>>> varh2 <- ShannonVar(later)
> > >>>> n2 <- sum (later)
> > >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> > >>>>
> > >>>> # compare numbers with those in the paper
> > >>>> h1
> > >>>> h2
> > >>>> varh1
> > >>>> varh2
> > >>>> # I assume that minor numerical differences are due to differences
> > >>>> in the
> > >>>> # numerical precision of computers in the early seventies and today
> > >>>> / KS
> > >>>>
> > >>>> # this is the actual t-test
> > >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> > >>>> p <- 2*pt(-abs(t),df= degfree)
> > >>>> p
> > >>>>
> > >>>> # that's it
> > >>>> # Best
> > >>>> # Karl
> > >>>> --
> > >>>> Karl Schilling, MD
> > >>>> Professor of Anatomy and Cell Biology
> > >>>> Anatomisches Institut
> > >>>> Rheinische Friedrich-Wilhelms-Universit?t
> > >>>> Nussallee 10
> > >>>>
> > >>>> D-53115 Bonn
> > >>>> Germany
> > >>>>
> > >>>> phone ++49-228-73-2602
> > >>>>
> > >>>
> > >>>
> > >>> --
> > >>> Best regards,
> > >>> Luigi
> > >>
> > >>
> > >>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 11 11:11:51 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 11 Sep 2020 11:11:51 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
Message-ID: <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>

Hello,
I have just realized in the original paper, the t test is defined as:
`t = h1-h2 -(?1?2)/(var1-var2)^1/2`. is the term -(?1?2) missing in
your formula? How to calculate ?1?2?
Thank you

On Thu, Sep 10, 2020 at 2:41 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Update:
> I also added the confidence interval for the Shannon index:
> ```
> #! Hutcheson's t-test for Shannon diversity equality
> # thanks to Karl Schilling and Rui Barradas
> hutcheson = function(A, B){
>   # compute Shannon index, variance and sum of elements
>   A_index <- Shannon(A)
>   B_index <- Shannon(B)
>   A_var <- ShannonVar(A)
>   B_var <- ShannonVar(B)
>   A_sum <- sum(A)
>   B_sum <- sum(B)
>   # compute Hutcheson
>   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
>   test <- (A_index-B_index) /sqrt(A_var + B_var)
>   p <- 2*pt(-abs(test),df= DF)
>   if (p < 0.001) {
>     P = "<0.001"
>   } else {
>     P = round(p, 3)
>   }
>   if (p < 0.001) {
>     S = "***"
>   } else if (p < 0.01) {
>     S = "**"
>   } else if (p < 0.05) {
>     S = "*"
>   } else {
>     S = ""
>   }
>   # closure
>   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> index first group: \t",
>       round(A_index, 3), " (", round((A_index-2*A_var),3), "-",
> round((A_index+2*A_var),3),
>       ")\n\tShannon index second group: \t",
>       round(B_index, 3), " (", round((B_index-2*B_var),3), "-",
> round((B_index+2*B_var),3),
>       ")\n\tp-value: ", P, " ", S, "\n", sep = "")
>   return(p)
> }
> ```
>
> On Thu, Sep 10, 2020 at 2:10 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > thank you for the code. To explain better, when I used vegan, I did
> > not count the species directly but simply prepared a dataframe where,
> > for each species, I counted the number of samples bearing such
> > species:
> > ```
> >
> > > str(new_df)
> > 'data.frame': 3 obs. of  46 variables:
> >  $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
> >  $ NC_001623 Autographa californica nucl...: int  7 7 7
> >  $ NC_001895 Enterobacteria phage P2       : int  1 0 0
> >  $ NC_004745 Yersinia phage L-413C         : int  1 0 0
> > ```
> > here the triplettes refer to healthy, tumor and metastasis. The outcome is:
> > ```
> > # Shannon index
> > diversity(new_df)
> > #> Normal     Tumour     Metastasis
> > #> 2.520139   3.109512   1.890404
> > ```
> > Using iNext, I provided a list of all the species counted in a samples
> > ```
> > > new_list
> > $Healthy
> >  [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > 0 0 0 0 0 0 0 0 0 0 0 0 0
> >
> > $Tumour
> >  [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
> > 1 2 1 1 1 1 1 1 1 0 0 0 0
> >
> > $Metastasis
> >  [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > 0 0 0 0 0 0 1 0 0 1 1 1 1
> > ```
> > From this I get:
> > ```
> > mod = iNEXT(new_list, q=0, datatype="abundance")
> > mod$AsyEst
> > #Site         Diversity Observed Estimator   s.e.    LCL     UCL
> > #1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
> > #2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
> > #4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
> > #5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
> > #7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
> > #8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
> > ```
> > So here the Shannon index is 12 instead of 2.5...
> > Using Karl's function, I get:
> > ```
> > # compute Shannon
> > norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
> > canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
> > meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
> > norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
> > canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
> > meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
> > norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
> > canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
> > meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
> > # compute Hutcheson
> > degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
> > canc_var**2 /canc_sum)
> > test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
> > (p <- 2*pt(-abs(test),df= degree))
> > > [1] 0.01825784
> > ```
> > remarkably, the indices are the same as obtained by vegan:
> > ```
> > > norm_sIdx
> > [1] 2.520139
> > > canc_sIdx
> > [1] 3.109512
> > > meta_sIdx
> > [1] 1.890404
> > ```
> >
> > I tried Rui's function but I got an error, so I wrote it as
> > ```
> > hutcheson = function(A, B){
> >   # compute Shannon index, variance and sum of elements
> >   A_index <- Shannon(A)
> >   B_index <- Shannon(B)
> >   A_var <- ShannonVar(A)
> >   B_var <- ShannonVar(B)
> >   A_sum <- sum(A)
> >   B_sum <- sum(B)
> >   # compute Hutcheson
> >   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
> >   test <- (A_index-B_index) /sqrt(A_var + B_var)
> >   p <- 2*pt(-abs(test),df= DF)
> >   # closure
> >   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> > index first group: ",
> >       round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
> >       "\n\tp-value : ", round(p, 4), "\n", sep = "")
> >   return(p)
> > }
> > ```
> > and I got:
> > ```
> >
> > > n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 2.5201
> > Shannon index second group: 3.1095
> > p-value : 0.0183
> > > n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 2.5201
> > Shannon index second group: 1.8904
> > p-value : 0.0371
> > > t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 3.1095
> > Shannon index second group: 1.8904
> > p-value : 0
> > ```
> > new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
> > the original Hutcheson data:
> > ```
> > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > hutcheson(bird_1956, bird_1957)
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 1.8429
> > Shannon index second group: 1.0689
> > p-value : 0
> >
> > ```
> > This is to compare two groups at the time. I'll probably have to
> > compensate for multiple testing...
> > But if this all OK, then the case is closed.
> > Thank you
> >
> > On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > >
> > > Hello,
> > >
> > > Sorry, there's an instruction missing. See inline.
> > >
> > > ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > > > If you want a function automating Karl's code, here it is. It returns an
> > > > object of S3 class "htest", R's standard for hypothesis tests functions.
> > > > The returned object can then be subset in the usual ways, ht$statistic,
> > > > ht$parameter, ht$p.value, etc.
> > > >
> > > >
> > > > library(QSutils)
> > > >
> > > > hutcheson.test <- function(x1, x2){
> > > >    dataname1 <- deparse(substitute(x1))
> > > >    dataname2 <- deparse(substitute(x2))
> > > >    method <- "Hutcheson's t-test for Shannon diversity equality"
> > > >    alternative <- "the diversities of the two samples are not equal"
> > > >    h1 <- Shannon(x1)
> > > >    varh1 <- ShannonVar(x1)
> > > >    n1 <- sum(x1)
> > > >    h2 <- Shannon(x2)
> > > >    varh2 <- ShannonVar(x2)
> > > >    n2 <- sum(x2)
> > > >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> > > >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> > > >    p.value <- 2*pt(-abs(tstat), df = degfree)
> > > >    ht <- list(
> > > >      statistic = c(t = tstat),
> > > >      parameter = c(df = degfree),
> > > >      p.value = p.value,
> > > >      alternative = alternative,
> > > >      method = method,
> > > >      data.name = paste(dataname1, dataname2, sep = ", ")
> > > >    )
> > > >    class(ht) <- "htest"
> > > >    ht
> > > > }
> > > >
> > > > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > >
> > > > hutcheson.test(earlier, later)
> > > >
> > > >
> > > >
> > > > With the data you provided:
> > > >
> > > >
> > > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > > bird_1959 <- c(0,0,14,59,26,68,0)
> > > > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > >
> > > > hutcheson.test(bird_1956, bird_1957)
> > > >
> > > >
> > > >
> > > >
> > > > Note that like David said earlier, there might be better ways to
> > > > interpret Shannon's diversity index. If h is the sample's diversity,
> > > > exp(h) gives the number of equally-common species with equivalent
> > > > diversity.
> > > >
> > > >
> > > > s1 <- Shannon(earlier)
> > > > s2 <- Shannon(later)
> > > > c(earlier = s1, later = s2)
> > > > exp(c(earlier = s1, later = s2))   # Both round to 3
> > > > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > > > Shannon(eq_common)                 # Slightly greater than the samples'
> > > > diversity
> > > >
> > > >
> > >
> > > # Create a list with all the data
> > > birds <- mget(ls(pattern = "^bird"))
> > >
> > > > round(exp(sapply(birds, Shannon))) # Your data
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > >
> > > >
> > > > #-------------------------------------
> > > >
> > > >
> > > > Earlier Karl wrote [1] that
> > > >
> > > >
> > > > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > > > that explains the minor numerical differences obtained with the code
> > > > above and the published variances.
> > > >
> > > >
> > > > I don't believe the published variances were computed with the published
> > > > variance estimator. The code below computes the variances like QSutils
> > > > and with formula (4) in Hutcheson's paper. The latter does not give the
> > > > same results.
> > > >
> > > > var_est <- function(n){
> > > >    s <- length(n)
> > > >    N <- sum(n)
> > > >    p <- n/N
> > > >    i <- p != 0
> > > >    inv.p <- numeric(s)
> > > >    inv.p[i] <- 1/p[i]
> > > >    log.p <- numeric(s)
> > > >    log.p[i] <- log(p[i])
> > > >    #
> > > >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> > > >    term2 <- (s - 1)/(2*N^2)
> > > >    #
> > > >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > > > log.p)
> > > >    denom3 <- 6*N^3
> > > >    term3 <- numer3/denom3
> > > >    list(
> > > >      Bioc = term1 + term2,
> > > >      Hutch = term1 + term2 + term3
> > > >    )
> > > > }
> > > >
> > > > Vh1 <- var_est(earlier)
> > > > Vh1
> > > > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > > > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> > > >
> > > > Vh2 <- var_est(later)
> > > > Vh2
> > > > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> > > >
> > > >
> > > >
> > > > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> > > >
> > > >
> > > > Hope this helps,
> > > >
> > > > Rui Barradas
> > > >
> > > >
> > > > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> > > >> Update:
> > > >> I can see that you used the function Shannon from the package QSutils.
> > > >> This would supplement the iNext package I used and solve the problem.
> > > >> Thank you.
> > > >>
> > > >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> > > >> <marongiu.luigi at gmail.com> wrote:
> > > >>>
> > > >>> Thank you very much for the code, that was very helpful.
> > > >>> I got the article by Hutcheson -- I don't know if I can distribute it
> > > >>> , given the possible copyrights, or if I can attach it here -- but it
> > > >>> does not report numbers directly: it refers to a previous article
> > > >>> counting bird death on a telegraph each year. The numbers
> > > >>> are:
> > > >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > >>> bird_1959 <- c(0,0,14,59,26,68,0)
> > > >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > >>>
> > > >>> This for sake of the argument.
> > > >>> As for my problem, I implemented the Shannon index with the package
> > > >>> iNext, which only gives me the index itself and the 95% CI. Even when
> > > >>> I implemented it with vegan, I only got the index. Essentially I don't
> > > >>> have a count of species I could feed into the Hutcheson's. Is there a
> > > >>> way to extract these data? Or to run a Hutcheson's on the final index?
> > > >>> Thank you
> > > >>>
> > > >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> > > >>> <karl.schilling at uni-bonn.de> wrote:
> > > >>>>
> > > >>>> Dear Luigi,
> > > >>>>
> > > >>>> below some code I cobbled together based on the Hutcheson paper you
> > > >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> > > >>>> its
> > > >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> > > >>>> website.
> > > >>>>
> > > >>>> here is the code, along with an example. I also attach the code as an
> > > >>>> R-file.
> > > >>>>
> > > >>>> Hope that helps.
> > > >>>> All my best
> > > >>>>
> > > >>>> Karl
> > > >>>> PS don't forget to adjust for multiple testing if you compare more than
> > > >>>> two groups.
> > > >>>> K
> > > >>>>
> > > >>>>
> > > >>>> # load package needed
> > > >>>> # QSutils is on Bioconductor
> > > >>>> library(QSutils)
> > > >>>>
> > > >>>> # here some exemplary data - these are the data from Pilou 1966 that
> > > >>>> are
> > > >>>> used
> > > >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> > > >>>>
> > > >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > >>>> # numbers of the first example used by Hutcheson were unfortunately not
> > > >>>> # available to me
> > > >>>>
> > > >>>> # here starts the code ; you may replace the variables "earlier" and
> > > >>>> "later"
> > > >>>> # by your own numbers.
> > > >>>>
> > > >>>> # calculate h, var(h) etc
> > > >>>> h1 <- Shannon(earlier)
> > > >>>> varh1 <- ShannonVar(earlier)
> > > >>>> n1 <- sum (earlier)
> > > >>>> h2 <- Shannon(later)
> > > >>>> varh2 <- ShannonVar(later)
> > > >>>> n2 <- sum (later)
> > > >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> > > >>>>
> > > >>>> # compare numbers with those in the paper
> > > >>>> h1
> > > >>>> h2
> > > >>>> varh1
> > > >>>> varh2
> > > >>>> # I assume that minor numerical differences are due to differences
> > > >>>> in the
> > > >>>> # numerical precision of computers in the early seventies and today
> > > >>>> / KS
> > > >>>>
> > > >>>> # this is the actual t-test
> > > >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> > > >>>> p <- 2*pt(-abs(t),df= degfree)
> > > >>>> p
> > > >>>>
> > > >>>> # that's it
> > > >>>> # Best
> > > >>>> # Karl
> > > >>>> --
> > > >>>> Karl Schilling, MD
> > > >>>> Professor of Anatomy and Cell Biology
> > > >>>> Anatomisches Institut
> > > >>>> Rheinische Friedrich-Wilhelms-Universit?t
> > > >>>> Nussallee 10
> > > >>>>
> > > >>>> D-53115 Bonn
> > > >>>> Germany
> > > >>>>
> > > >>>> phone ++49-228-73-2602
> > > >>>>
> > > >>>
> > > >>>
> > > >>> --
> > > >>> Best regards,
> > > >>> Luigi
> > > >>
> > > >>
> > > >>
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 11 11:39:17 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 11 Sep 2020 11:39:17 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
 <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
Message-ID: <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>

Actually,
in the working example, Hutcheson himself did not report the term
?1?2: `t0 = h1-h2/(var1-var2)^1/2`. so I think we can live without it.
Case closed.
Thank you

On Fri, Sep 11, 2020 at 11:11 AM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have just realized in the original paper, the t test is defined as:
> `t = h1-h2 -(?1?2)/(var1-var2)^1/2`. is the term -(?1?2) missing in
> your formula? How to calculate ?1?2?
> Thank you
>
> On Thu, Sep 10, 2020 at 2:41 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Update:
> > I also added the confidence interval for the Shannon index:
> > ```
> > #! Hutcheson's t-test for Shannon diversity equality
> > # thanks to Karl Schilling and Rui Barradas
> > hutcheson = function(A, B){
> >   # compute Shannon index, variance and sum of elements
> >   A_index <- Shannon(A)
> >   B_index <- Shannon(B)
> >   A_var <- ShannonVar(A)
> >   B_var <- ShannonVar(B)
> >   A_sum <- sum(A)
> >   B_sum <- sum(B)
> >   # compute Hutcheson
> >   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
> >   test <- (A_index-B_index) /sqrt(A_var + B_var)
> >   p <- 2*pt(-abs(test),df= DF)
> >   if (p < 0.001) {
> >     P = "<0.001"
> >   } else {
> >     P = round(p, 3)
> >   }
> >   if (p < 0.001) {
> >     S = "***"
> >   } else if (p < 0.01) {
> >     S = "**"
> >   } else if (p < 0.05) {
> >     S = "*"
> >   } else {
> >     S = ""
> >   }
> >   # closure
> >   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> > index first group: \t",
> >       round(A_index, 3), " (", round((A_index-2*A_var),3), "-",
> > round((A_index+2*A_var),3),
> >       ")\n\tShannon index second group: \t",
> >       round(B_index, 3), " (", round((B_index-2*B_var),3), "-",
> > round((B_index+2*B_var),3),
> >       ")\n\tp-value: ", P, " ", S, "\n", sep = "")
> >   return(p)
> > }
> > ```
> >
> > On Thu, Sep 10, 2020 at 2:10 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > thank you for the code. To explain better, when I used vegan, I did
> > > not count the species directly but simply prepared a dataframe where,
> > > for each species, I counted the number of samples bearing such
> > > species:
> > > ```
> > >
> > > > str(new_df)
> > > 'data.frame': 3 obs. of  46 variables:
> > >  $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
> > >  $ NC_001623 Autographa californica nucl...: int  7 7 7
> > >  $ NC_001895 Enterobacteria phage P2       : int  1 0 0
> > >  $ NC_004745 Yersinia phage L-413C         : int  1 0 0
> > > ```
> > > here the triplettes refer to healthy, tumor and metastasis. The outcome is:
> > > ```
> > > # Shannon index
> > > diversity(new_df)
> > > #> Normal     Tumour     Metastasis
> > > #> 2.520139   3.109512   1.890404
> > > ```
> > > Using iNext, I provided a list of all the species counted in a samples
> > > ```
> > > > new_list
> > > $Healthy
> > >  [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > > 0 0 0 0 0 0 0 0 0 0 0 0 0
> > >
> > > $Tumour
> > >  [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
> > > 1 2 1 1 1 1 1 1 1 0 0 0 0
> > >
> > > $Metastasis
> > >  [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > > 0 0 0 0 0 0 1 0 0 1 1 1 1
> > > ```
> > > From this I get:
> > > ```
> > > mod = iNEXT(new_list, q=0, datatype="abundance")
> > > mod$AsyEst
> > > #Site         Diversity Observed Estimator   s.e.    LCL     UCL
> > > #1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
> > > #2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
> > > #4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
> > > #5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
> > > #7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
> > > #8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
> > > ```
> > > So here the Shannon index is 12 instead of 2.5...
> > > Using Karl's function, I get:
> > > ```
> > > # compute Shannon
> > > norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
> > > canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
> > > meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
> > > norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
> > > canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
> > > meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
> > > norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
> > > canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
> > > meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
> > > # compute Hutcheson
> > > degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
> > > canc_var**2 /canc_sum)
> > > test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
> > > (p <- 2*pt(-abs(test),df= degree))
> > > > [1] 0.01825784
> > > ```
> > > remarkably, the indices are the same as obtained by vegan:
> > > ```
> > > > norm_sIdx
> > > [1] 2.520139
> > > > canc_sIdx
> > > [1] 3.109512
> > > > meta_sIdx
> > > [1] 1.890404
> > > ```
> > >
> > > I tried Rui's function but I got an error, so I wrote it as
> > > ```
> > > hutcheson = function(A, B){
> > >   # compute Shannon index, variance and sum of elements
> > >   A_index <- Shannon(A)
> > >   B_index <- Shannon(B)
> > >   A_var <- ShannonVar(A)
> > >   B_var <- ShannonVar(B)
> > >   A_sum <- sum(A)
> > >   B_sum <- sum(B)
> > >   # compute Hutcheson
> > >   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
> > >   test <- (A_index-B_index) /sqrt(A_var + B_var)
> > >   p <- 2*pt(-abs(test),df= DF)
> > >   # closure
> > >   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> > > index first group: ",
> > >       round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
> > >       "\n\tp-value : ", round(p, 4), "\n", sep = "")
> > >   return(p)
> > > }
> > > ```
> > > and I got:
> > > ```
> > >
> > > > n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 2.5201
> > > Shannon index second group: 3.1095
> > > p-value : 0.0183
> > > > n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 2.5201
> > > Shannon index second group: 1.8904
> > > p-value : 0.0371
> > > > t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 3.1095
> > > Shannon index second group: 1.8904
> > > p-value : 0
> > > ```
> > > new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
> > > the original Hutcheson data:
> > > ```
> > > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > hutcheson(bird_1956, bird_1957)
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 1.8429
> > > Shannon index second group: 1.0689
> > > p-value : 0
> > >
> > > ```
> > > This is to compare two groups at the time. I'll probably have to
> > > compensate for multiple testing...
> > > But if this all OK, then the case is closed.
> > > Thank you
> > >
> > > On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > > >
> > > > Hello,
> > > >
> > > > Sorry, there's an instruction missing. See inline.
> > > >
> > > > ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > > > > If you want a function automating Karl's code, here it is. It returns an
> > > > > object of S3 class "htest", R's standard for hypothesis tests functions.
> > > > > The returned object can then be subset in the usual ways, ht$statistic,
> > > > > ht$parameter, ht$p.value, etc.
> > > > >
> > > > >
> > > > > library(QSutils)
> > > > >
> > > > > hutcheson.test <- function(x1, x2){
> > > > >    dataname1 <- deparse(substitute(x1))
> > > > >    dataname2 <- deparse(substitute(x2))
> > > > >    method <- "Hutcheson's t-test for Shannon diversity equality"
> > > > >    alternative <- "the diversities of the two samples are not equal"
> > > > >    h1 <- Shannon(x1)
> > > > >    varh1 <- ShannonVar(x1)
> > > > >    n1 <- sum(x1)
> > > > >    h2 <- Shannon(x2)
> > > > >    varh2 <- ShannonVar(x2)
> > > > >    n2 <- sum(x2)
> > > > >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> > > > >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> > > > >    p.value <- 2*pt(-abs(tstat), df = degfree)
> > > > >    ht <- list(
> > > > >      statistic = c(t = tstat),
> > > > >      parameter = c(df = degfree),
> > > > >      p.value = p.value,
> > > > >      alternative = alternative,
> > > > >      method = method,
> > > > >      data.name = paste(dataname1, dataname2, sep = ", ")
> > > > >    )
> > > > >    class(ht) <- "htest"
> > > > >    ht
> > > > > }
> > > > >
> > > > > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > > > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > > >
> > > > > hutcheson.test(earlier, later)
> > > > >
> > > > >
> > > > >
> > > > > With the data you provided:
> > > > >
> > > > >
> > > > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > > > bird_1959 <- c(0,0,14,59,26,68,0)
> > > > > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > > >
> > > > > hutcheson.test(bird_1956, bird_1957)
> > > > >
> > > > >
> > > > >
> > > > >
> > > > > Note that like David said earlier, there might be better ways to
> > > > > interpret Shannon's diversity index. If h is the sample's diversity,
> > > > > exp(h) gives the number of equally-common species with equivalent
> > > > > diversity.
> > > > >
> > > > >
> > > > > s1 <- Shannon(earlier)
> > > > > s2 <- Shannon(later)
> > > > > c(earlier = s1, later = s2)
> > > > > exp(c(earlier = s1, later = s2))   # Both round to 3
> > > > > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > > > > Shannon(eq_common)                 # Slightly greater than the samples'
> > > > > diversity
> > > > >
> > > > >
> > > >
> > > > # Create a list with all the data
> > > > birds <- mget(ls(pattern = "^bird"))
> > > >
> > > > > round(exp(sapply(birds, Shannon))) # Your data
> > > >
> > > >
> > > > Hope this helps,
> > > >
> > > > Rui Barradas
> > > >
> > > > >
> > > > >
> > > > > #-------------------------------------
> > > > >
> > > > >
> > > > > Earlier Karl wrote [1] that
> > > > >
> > > > >
> > > > > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > > > > that explains the minor numerical differences obtained with the code
> > > > > above and the published variances.
> > > > >
> > > > >
> > > > > I don't believe the published variances were computed with the published
> > > > > variance estimator. The code below computes the variances like QSutils
> > > > > and with formula (4) in Hutcheson's paper. The latter does not give the
> > > > > same results.
> > > > >
> > > > > var_est <- function(n){
> > > > >    s <- length(n)
> > > > >    N <- sum(n)
> > > > >    p <- n/N
> > > > >    i <- p != 0
> > > > >    inv.p <- numeric(s)
> > > > >    inv.p[i] <- 1/p[i]
> > > > >    log.p <- numeric(s)
> > > > >    log.p[i] <- log(p[i])
> > > > >    #
> > > > >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> > > > >    term2 <- (s - 1)/(2*N^2)
> > > > >    #
> > > > >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > > > > log.p)
> > > > >    denom3 <- 6*N^3
> > > > >    term3 <- numer3/denom3
> > > > >    list(
> > > > >      Bioc = term1 + term2,
> > > > >      Hutch = term1 + term2 + term3
> > > > >    )
> > > > > }
> > > > >
> > > > > Vh1 <- var_est(earlier)
> > > > > Vh1
> > > > > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > > > > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> > > > >
> > > > > Vh2 <- var_est(later)
> > > > > Vh2
> > > > > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> > > > >
> > > > >
> > > > >
> > > > > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> > > > >
> > > > >
> > > > > Hope this helps,
> > > > >
> > > > > Rui Barradas
> > > > >
> > > > >
> > > > > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> > > > >> Update:
> > > > >> I can see that you used the function Shannon from the package QSutils.
> > > > >> This would supplement the iNext package I used and solve the problem.
> > > > >> Thank you.
> > > > >>
> > > > >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> > > > >> <marongiu.luigi at gmail.com> wrote:
> > > > >>>
> > > > >>> Thank you very much for the code, that was very helpful.
> > > > >>> I got the article by Hutcheson -- I don't know if I can distribute it
> > > > >>> , given the possible copyrights, or if I can attach it here -- but it
> > > > >>> does not report numbers directly: it refers to a previous article
> > > > >>> counting bird death on a telegraph each year. The numbers
> > > > >>> are:
> > > > >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > > >>> bird_1959 <- c(0,0,14,59,26,68,0)
> > > > >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > > >>>
> > > > >>> This for sake of the argument.
> > > > >>> As for my problem, I implemented the Shannon index with the package
> > > > >>> iNext, which only gives me the index itself and the 95% CI. Even when
> > > > >>> I implemented it with vegan, I only got the index. Essentially I don't
> > > > >>> have a count of species I could feed into the Hutcheson's. Is there a
> > > > >>> way to extract these data? Or to run a Hutcheson's on the final index?
> > > > >>> Thank you
> > > > >>>
> > > > >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> > > > >>> <karl.schilling at uni-bonn.de> wrote:
> > > > >>>>
> > > > >>>> Dear Luigi,
> > > > >>>>
> > > > >>>> below some code I cobbled together based on the Hutcheson paper you
> > > > >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> > > > >>>> its
> > > > >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> > > > >>>> website.
> > > > >>>>
> > > > >>>> here is the code, along with an example. I also attach the code as an
> > > > >>>> R-file.
> > > > >>>>
> > > > >>>> Hope that helps.
> > > > >>>> All my best
> > > > >>>>
> > > > >>>> Karl
> > > > >>>> PS don't forget to adjust for multiple testing if you compare more than
> > > > >>>> two groups.
> > > > >>>> K
> > > > >>>>
> > > > >>>>
> > > > >>>> # load package needed
> > > > >>>> # QSutils is on Bioconductor
> > > > >>>> library(QSutils)
> > > > >>>>
> > > > >>>> # here some exemplary data - these are the data from Pilou 1966 that
> > > > >>>> are
> > > > >>>> used
> > > > >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> > > > >>>>
> > > > >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > > >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > > >>>> # numbers of the first example used by Hutcheson were unfortunately not
> > > > >>>> # available to me
> > > > >>>>
> > > > >>>> # here starts the code ; you may replace the variables "earlier" and
> > > > >>>> "later"
> > > > >>>> # by your own numbers.
> > > > >>>>
> > > > >>>> # calculate h, var(h) etc
> > > > >>>> h1 <- Shannon(earlier)
> > > > >>>> varh1 <- ShannonVar(earlier)
> > > > >>>> n1 <- sum (earlier)
> > > > >>>> h2 <- Shannon(later)
> > > > >>>> varh2 <- ShannonVar(later)
> > > > >>>> n2 <- sum (later)
> > > > >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> > > > >>>>
> > > > >>>> # compare numbers with those in the paper
> > > > >>>> h1
> > > > >>>> h2
> > > > >>>> varh1
> > > > >>>> varh2
> > > > >>>> # I assume that minor numerical differences are due to differences
> > > > >>>> in the
> > > > >>>> # numerical precision of computers in the early seventies and today
> > > > >>>> / KS
> > > > >>>>
> > > > >>>> # this is the actual t-test
> > > > >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> > > > >>>> p <- 2*pt(-abs(t),df= degfree)
> > > > >>>> p
> > > > >>>>
> > > > >>>> # that's it
> > > > >>>> # Best
> > > > >>>> # Karl
> > > > >>>> --
> > > > >>>> Karl Schilling, MD
> > > > >>>> Professor of Anatomy and Cell Biology
> > > > >>>> Anatomisches Institut
> > > > >>>> Rheinische Friedrich-Wilhelms-Universit?t
> > > > >>>> Nussallee 10
> > > > >>>>
> > > > >>>> D-53115 Bonn
> > > > >>>> Germany
> > > > >>>>
> > > > >>>> phone ++49-228-73-2602
> > > > >>>>
> > > > >>>
> > > > >>>
> > > > >>> --
> > > > >>> Best regards,
> > > > >>> Luigi
> > > > >>
> > > > >>
> > > > >>
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Fri Sep 11 14:36:01 2020
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Fri, 11 Sep 2020 14:36:01 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
 <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
 <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>
Message-ID: <bf1a4363-f49c-93cd-5c4d-ddf206b60e9e@uni-bonn.de>

Dear Luigi:

no, ?1?2 is not "missing"

First, it should actually be "?1 - ?2".

And as your usual null-hypothesis when comparing h1 and h2 is that they 
are not different (i.e. ?1 = ?2), the latter term adds up to 0 and may 
be omitted.

Karl Schilling


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 11 14:41:36 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 11 Sep 2020 14:41:36 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <bf1a4363-f49c-93cd-5c4d-ddf206b60e9e@uni-bonn.de>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
 <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
 <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>
 <bf1a4363-f49c-93cd-5c4d-ddf206b60e9e@uni-bonn.de>
Message-ID: <CAMk+s2RcicQctoGoqr5t2LzmpmfCd326KFzYhufHSOe6wYZ5ig@mail.gmail.com>

Thank you for the clarification.

On Fri, Sep 11, 2020 at 2:36 PM Karl Schilling
<karl.schilling at uni-bonn.de> wrote:
>
> Dear Luigi:
>
> no, ?1?2 is not "missing"
>
> First, it should actually be "?1 - ?2".
>
> And as your usual null-hypothesis when comparing h1 and h2 is that they
> are not different (i.e. ?1 = ?2), the latter term adds up to 0 and may
> be omitted.
>
> Karl Schilling



-- 
Best regards,
Luigi


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Sep 11 16:37:45 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 11 Sep 2020 09:37:45 -0500
Subject: [R] Adjusting The size and Orientation of x-axis labes for Pareto
 Charts
Message-ID: <CAMOcQfPqt7z=psP2FdwukTtQYVHBsEB-Uy=4xwQcAhx8wbRa6g@mail.gmail.com>

Dear friends,

Hope you are doing well. I am currently using R version 3.6.2. I installed
and loaded package qcc by Mr. Luca Scrucca.

I generated the pareto chart using qcc?s pareto.chart function, but when
the graph gets generated, the x-axis labels aren?t fully shown, and so the
text can?t be viewed properly.

Is there any way to adjust the x-axis labels (font and orientation), so
that they can be easily shown?

This is the structure of my data:

str(dataset2)
'data.frame':   140 obs. of  2 variables:
 $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
106 65 17 ...
 $ Points: num  55 43 24 21 20 20 18 17 16 16 ...


Below is the dput() of my dataset.

dput(dataset2)
structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
"Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
"Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
"Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
"Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
"Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
"Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
"Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
"Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
"David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
"El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
"El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
"Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
"Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
Espinar",
"Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
"La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
"Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
"Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
"Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
"Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
"Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
"Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
"Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
"Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
"R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
"Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
"San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
Porres",
"Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
"Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
"Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
), class = "data.frame")

Best regards,

Paul

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep 11 16:59:41 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 11 Sep 2020 14:59:41 +0000
Subject: [R] 
 Adjusting The size and Orientation of x-axis labes for Pareto Charts
In-Reply-To: <CAMOcQfPqt7z=psP2FdwukTtQYVHBsEB-Uy=4xwQcAhx8wbRa6g@mail.gmail.com>
References: <CAMOcQfPqt7z=psP2FdwukTtQYVHBsEB-Uy=4xwQcAhx8wbRa6g@mail.gmail.com>
Message-ID: <96aa8426e71642d2962f1a0c269088a5@SRVEXCHCM1302.precheza.cz>

Hi.

You could try call pareto.chart with las=2 option.

See ?par.

But I am not sure if it will work as I do not have experience with this.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> Sent: Friday, September 11, 2020 4:38 PM
> To: R <r-help at r-project.org>
> Subject: [R] Adjusting The size and Orientation of x-axis labes for Pareto
> Charts
> 
> Dear friends,
> 
> Hope you are doing well. I am currently using R version 3.6.2. I installed and
> loaded package qcc by Mr. Luca Scrucca.
> 
> I generated the pareto chart using qcc?s pareto.chart function, but when the
> graph gets generated, the x-axis labels aren?t fully shown, and so the text
> can?t be viewed properly.
> 
> Is there any way to adjust the x-axis labels (font and orientation), so that they
> can be easily shown?
> 
> This is the structure of my data:
> 
> str(dataset2)
> 'data.frame':   140 obs. of  2 variables:
>  $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
> 106 65 17 ...
>  $ Points: num  55 43 24 21 20 20 18 17 16 16 ...
> 
> 
> Below is the dput() of my dataset.
> 
> dput(dataset2)
> structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L, 116L, 35L, 106L, 65L,
> 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L, 114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L,
> 76L, 19L, 25L, 93L, 14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
> 95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L, 125L, 2L, 129L, 71L,
> 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L, 80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L,
> 138L, 126L, 34L, 135L, 5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L,
> 112L, 32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L, 99L, 56L, 9L,
> 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L, 134L, 122L, 124L, 128L, 94L,
> 130L, 92L, 33L, 6L, 26L, 113L, 27L, 69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L,
> 62L, 89L, 90L, 91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
> "Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza", "Anc?n",
> "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete", "Barrio
> Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur", "Bejuco", "Belisario
> Fr?as", "Belisario Porras", "Bella Vista", "Betania", "Buena Vista", "Burunga",
> "Calidonia", "Ca?averal", "Canto del Llano", "Capira", "Cativ?", "Cerme?o",
> "Cerro Silvestre", "Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
> "Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
> "David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo", "El Coco", "El
> Espino", "El Guabo", "El Harino", "El Higo", "El Llano", "El Roble", "El Valle",
> "Ernesto C?rdoba Campos", "Escobal", "Feuillet", "Garrote o Puerto Lindo",
> "Guadalupe", "Herrera", "Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde",
> "Jos? Domingo Espinar", "Juan Dem?stenes Arosemena", "Juan D?az", "La
> Concepci?n", "La Ensenada", "La Laguna", "La Mesa", "La Raya de Calobre",
> "La Represa", "Las Cumbres", "Las Lajas", "Las Ma?anitas", "Las Ollas Arriba",
> "L?dice", "Lim?n", "Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo
> Iturralde", "Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
> "Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?", "Omar
> Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre", "Pedas?",
> "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?", "Portobelo", "Pueblo
> Nuevo", "Puerto Armuelles", "Puerto Caimito", "Puerto Pil?n", "Punta
> Chame", "Rio Abajo", "R?o Abajo", "R?o Grande", "R?o Hato", "R?o Indio",
> "Rufina Alfaro", "Sabanagrande", "Sabanitas", "Sajalices", "Salamanca", "San
> Carlos", "San Felipe", "San Francisco", "San Jos?", "San Juan", "San Juan
> Bautista", "San Mart?n", "San Mart?n de Porres", "Santa Ana", "Santa Clara",
> "Santa Fe", "Santa Isabel", "Santa Rita", "Santa Rosa", "Santiago", "Santiago
> Este", "Tinajas", "Tocumen", "Veracruz", "Victoriano Lorenzo", "Villa Rosario",
> "Vista Alegre"
> ), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18, 17, 16, 16, 15, 13, 13,
> 12, 12, 11, 11, 11, 11, 11, 10, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6,
> 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)),
> row.names = c(NA, -140L ), class = "data.frame")
> 
> Best regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Sep 14 12:19:08 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 14 Sep 2020 10:19:08 +0000
Subject: [R] monthly mean for each month and each year in the data frame
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809F7883@ESINO.regionemarche.intra>

Dear R-list users,
I know that this is a trivial question, but I already wasted quite a large amount of time on that.
I have a data frame with daily data of snow fall. I need to evaluate the monthly mean for each month and each year in the data frame.
Could you help me to find an eficient way for these calculations?

Thank you for your help
Stefano

Here a reproducibile code:

first_day_1 <- as.POSIXct("2019-01-19-00-00", format="%Y-%m-%d-%H-%M")
last_day_1 <- as.POSIXct("2019-03-20-00-00", format="%Y-%m-%d-%H-%M")
df1 <- data.frame(data_POSIX=seq(first_day_1, last_day_1, by="1 days"))
df1$value <- runif(nrow(df1), 0, 10)


first_day_2 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M")
last_day_2 <- as.POSIXct("2020-04-20-00-00", format="%Y-%m-%d-%H-%M")
df2 <- data.frame(data_POSIX=seq(first_day_2, last_day_2, by="1 days"))
df2$value <- runif(nrow(df2), 0, 10)

df <- rbind(df1, df2)





         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Sep 14 12:29:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 14 Sep 2020 20:29:07 +1000
Subject: [R] monthly mean for each month and each year in the data frame
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809F7883@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809F7883@ESINO.regionemarche.intra>
Message-ID: <CA+8X3fU=koyXkucX-U492CmjpfSLEoPyrDEWvE99mj=wZrA65A@mail.gmail.com>

Hi Stefano,
What about this?

df$months<-format(df$data_POSIX,"%Y-%m")
snow_means<-by(df$value,df$months,mean)

Jim

On Mon, Sep 14, 2020 at 8:19 PM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear R-list users,
> I know that this is a trivial question, but I already wasted quite a large amount of time on that.
> I have a data frame with daily data of snow fall. I need to evaluate the monthly mean for each month and each year in the data frame.
> Could you help me to find an eficient way for these calculations?
>
> Thank you for your help
> Stefano
>
> Here a reproducibile code:
>
> first_day_1 <- as.POSIXct("2019-01-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_1 <- as.POSIXct("2019-03-20-00-00", format="%Y-%m-%d-%H-%M")
> df1 <- data.frame(data_POSIX=seq(first_day_1, last_day_1, by="1 days"))
> df1$value <- runif(nrow(df1), 0, 10)
>
>
> first_day_2 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_2 <- as.POSIXct("2020-04-20-00-00", format="%Y-%m-%d-%H-%M")
> df2 <- data.frame(data_POSIX=seq(first_day_2, last_day_2, by="1 days"))
> df2$value <- runif(nrow(df2), 0, 10)
>
> df <- rbind(df1, df2)
>
>
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Sep 14 12:48:40 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 14 Sep 2020 10:48:40 +0000
Subject: [R] monthly mean for each month and each year in the data frame
In-Reply-To: <CA+8X3fU=koyXkucX-U492CmjpfSLEoPyrDEWvE99mj=wZrA65A@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F809F7883@ESINO.regionemarche.intra>,
 <CA+8X3fU=koyXkucX-U492CmjpfSLEoPyrDEWvE99mj=wZrA65A@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809F789C@ESINO.regionemarche.intra>

Yes, perfect.
Thank you.

Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________________
Da: Jim Lemon [drjimlemon at gmail.com]
Inviato: luned? 14 settembre 2020 12.29
A: Stefano Sofia
Cc: r-help mailing list
Oggetto: Re: [R] monthly mean for each month and each year in the data frame

Hi Stefano,
What about this?

df$months<-format(df$data_POSIX,"%Y-%m")
snow_means<-by(df$value,df$months,mean)

Jim

On Mon, Sep 14, 2020 at 8:19 PM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear R-list users,
> I know that this is a trivial question, but I already wasted quite a large amount of time on that.
> I have a data frame with daily data of snow fall. I need to evaluate the monthly mean for each month and each year in the data frame.
> Could you help me to find an eficient way for these calculations?
>
> Thank you for your help
> Stefano
>
> Here a reproducibile code:
>
> first_day_1 <- as.POSIXct("2019-01-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_1 <- as.POSIXct("2019-03-20-00-00", format="%Y-%m-%d-%H-%M")
> df1 <- data.frame(data_POSIX=seq(first_day_1, last_day_1, by="1 days"))
> df1$value <- runif(nrow(df1), 0, 10)
>
>
> first_day_2 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_2 <- as.POSIXct("2020-04-20-00-00", format="%Y-%m-%d-%H-%M")
> df2 <- data.frame(data_POSIX=seq(first_day_2, last_day_2, by="1 days"))
> df2$value <- runif(nrow(df2), 0, 10)
>
> df <- rbind(df1, df2)
>
>
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> and provide commented, minimal, self-contained, reproducible code.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 14 12:53:23 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 14 Sep 2020 11:53:23 +0100
Subject: [R] monthly mean for each month and each year in the data frame
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809F7883@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809F7883@ESINO.regionemarche.intra>
Message-ID: <3be1935e-4deb-10b1-15e3-721a87d68c4b@sapo.pt>

Hello,

Here are two aggregate options, the first base R only, the second one 
with package zoo.


year_month <- format(df$data_POSIX, "%Y-%m")
aggregate(value ~ year_month, df, mean)    # or even value ~ format(etc)
#  year_month    value
#1    2019-01 6.430922
#2    2019-02 4.846731
#3    2019-03 4.968503
#4    2020-02 6.484031
#5    2020-03 4.910305
#6    2020-04 4.906575


aggregate(value ~ zoo::as.yearmon(data_POSIX), df, mean)
#  zoo::as.yearmon(data_POSIX)    value
#1                    jan 2019 6.430922
#2                    fev 2019 4.846731
#3                    mar 2019 4.968503
#4                    fev 2020 6.484031
#5                    mar 2020 4.910305
#6                    abr 2020 4.906575


Hope this helps,

Rui Barradas

?s 11:19 de 14/09/20, Stefano Sofia escreveu:
> Dear R-list users,
> I know that this is a trivial question, but I already wasted quite a large amount of time on that.
> I have a data frame with daily data of snow fall. I need to evaluate the monthly mean for each month and each year in the data frame.
> Could you help me to find an eficient way for these calculations?
> 
> Thank you for your help
> Stefano
> 
> Here a reproducibile code:
> 
> first_day_1 <- as.POSIXct("2019-01-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_1 <- as.POSIXct("2019-03-20-00-00", format="%Y-%m-%d-%H-%M")
> df1 <- data.frame(data_POSIX=seq(first_day_1, last_day_1, by="1 days"))
> df1$value <- runif(nrow(df1), 0, 10)
> 
> 
> first_day_2 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_2 <- as.POSIXct("2020-04-20-00-00", format="%Y-%m-%d-%H-%M")
> df2 <- data.frame(data_POSIX=seq(first_day_2, last_day_2, by="1 days"))
> df2$value <- runif(nrow(df2), 0, 10)
> 
> df <- rbind(df1, df2)
> 
> 
> 
> 
> 
>           (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
> 
> ________________________________
> 
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> 
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Sep 14 15:29:50 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 14 Sep 2020 08:29:50 -0500
Subject: [R] How to represent the effect of one covariate on regression
 results?
Message-ID: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>

Hello,

I was running association analysis using --glm genotypic from:
https://www.cog-genomics.org/plink/2.0/assoc with these covariates:
sex,age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,TD,array,HBA1C. The
result looks like this:

    #CHROM    POS    ID    REF    ALT    A1    TEST    OBS_CT    BETA
  SE    Z_OR_F_STAT    P    ERRCODE
    10    135434303    rs11101905    G    A    A    ADD    11863
-0.110733    0.0986981    -1.12193    0.261891    .
    10    135434303    rs11101905    G    A    A    DOMDEV    11863
0.079797    0.111004    0.718868    0.472222    .
    10    135434303    rs11101905    G    A    A    sex=Female
11863    -0.120404    0.0536069    -2.24605    0.0247006    .
    10    135434303    rs11101905    G    A    A    age    11863
0.00524501    0.00391528    1.33963    0.180367    .
    10    135434303    rs11101905    G    A    A    PC1    11863
-0.0191779    0.0166868    -1.14928    0.25044    .
    10    135434303    rs11101905    G    A    A    PC2    11863
-0.0269939    0.0173086    -1.55957    0.118863    .
    10    135434303    rs11101905    G    A    A    PC3    11863
0.0115207    0.0168076    0.685448    0.493061    .
    10    135434303    rs11101905    G    A    A    PC4    11863
9.57832e-05    0.0124607    0.0076868    0.993867    .
    10    135434303    rs11101905    G    A    A    PC5    11863
-0.00191047    0.00543937    -0.35123    0.725416    .
    10    135434303    rs11101905    G    A    A    PC6    11863
-0.0103309    0.0159879    -0.646172    0.518168    .
    10    135434303    rs11101905    G    A    A    PC7    11863
0.00790997    0.0144025    0.549207    0.582863    .
    10    135434303    rs11101905    G    A    A    PC8    11863
-0.00205639    0.0142709    -0.144096    0.885424    .
    10    135434303    rs11101905    G    A    A    PC9    11863
-0.00873771    0.0057239    -1.52653    0.126878    .
    10    135434303    rs11101905    G    A    A    PC10    11863
0.0116197    0.0123826    0.938388    0.348045    .
    10    135434303    rs11101905    G    A    A    TD    11863
-0.670026    0.0962216    -6.96337    3.32228e-12    .
    10    135434303    rs11101905    G    A    A    array=Biobank
11863    0.160666    0.073631    2.18205    0.0291062    .
    10    135434303    rs11101905    G    A    A    HBA1C    11863
0.0265933    0.00168758    15.7583    6.0236e-56    .
    10    135434303    rs11101905    G    A    A    GENO_2DF    11863
  NA    NA    0.726514    0.483613    .

This results is shown just for one ID (rs11101905) there is about 2
million of those in the resulting file.

My question is how do I present/plot the effect of covariate "TD" in
the example it has "P" equal to 3.32228e-12 for all IDs in the
resulting file so that I show how much effect covariate "TD" has on
the analysis. Should I run another regression without covariate "TD"
and than do scatter plot of P values with and without "TD" covariate
or there is a better way to do this from the data I already have?

Thanks
Ana


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Sep 14 17:26:27 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 14 Sep 2020 15:26:27 +0000
Subject: [R] monthly mean for each month and each year in the data frame
In-Reply-To: <3be1935e-4deb-10b1-15e3-721a87d68c4b@sapo.pt>
References: <8B435C9568170B469AE31E8891E8CC4F809F7883@ESINO.regionemarche.intra>,
 <3be1935e-4deb-10b1-15e3-721a87d68c4b@sapo.pt>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809F7949@ESINO.regionemarche.intra>

Thank you again.
I finally used aggregate because it build a data frame straight away.

Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________________
Da: Rui Barradas [ruipbarradas at sapo.pt]
Inviato: luned? 14 settembre 2020 12.53
A: Stefano Sofia; r-help mailing list
Oggetto: Re: [R] monthly mean for each month and each year in the data frame

Hello,

Here are two aggregate options, the first base R only, the second one
with package zoo.


year_month <- format(df$data_POSIX, "%Y-%m")
aggregate(value ~ year_month, df, mean)    # or even value ~ format(etc)
#  year_month    value
#1    2019-01 6.430922
#2    2019-02 4.846731
#3    2019-03 4.968503
#4    2020-02 6.484031
#5    2020-03 4.910305
#6    2020-04 4.906575


aggregate(value ~ zoo::as.yearmon(data_POSIX), df, mean)
#  zoo::as.yearmon(data_POSIX)    value
#1                    jan 2019 6.430922
#2                    fev 2019 4.846731
#3                    mar 2019 4.968503
#4                    fev 2020 6.484031
#5                    mar 2020 4.910305
#6                    abr 2020 4.906575


Hope this helps,

Rui Barradas

?s 11:19 de 14/09/20, Stefano Sofia escreveu:
> Dear R-list users,
> I know that this is a trivial question, but I already wasted quite a large amount of time on that.
> I have a data frame with daily data of snow fall. I need to evaluate the monthly mean for each month and each year in the data frame.
> Could you help me to find an eficient way for these calculations?
>
> Thank you for your help
> Stefano
>
> Here a reproducibile code:
>
> first_day_1 <- as.POSIXct("2019-01-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_1 <- as.POSIXct("2019-03-20-00-00", format="%Y-%m-%d-%H-%M")
> df1 <- data.frame(data_POSIX=seq(first_day_1, last_day_1, by="1 days"))
> df1$value <- runif(nrow(df1), 0, 10)
>
>
> first_day_2 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M")
> last_day_2 <- as.POSIXct("2020-04-20-00-00", format="%Y-%m-%d-%H-%M")
> df2 <- data.frame(data_POSIX=seq(first_day_2, last_day_2, by="1 days"))
> df2$value <- runif(nrow(df2), 0, 10)
>
> df <- rbind(df1, df2)
>
>
>
>
>
>           (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> and provide commented, minimal, self-contained, reproducible code.
>

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Sep 14 18:35:02 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 14 Sep 2020 11:35:02 -0500
Subject: [R] how to replace values in a named vector
Message-ID: <CAF9-5jPBuTcmJXUkp63_7zd3nkoB8X4+jiSeMWLpjU4VATVyDA@mail.gmail.com>

Hello,

I have a vector like this:

> head(geneSymbol)
Ku8QhfS0n_hIOABXuE Bx496XsFXiAlj.Eaeo W38p0ogk.wIBVRXllY
QIBkqIS9LR5DfTlTS8 BZKiEvS0eQ305U0v34 6TheVd.HiE1UF3lX6g
           "MACC1"            "GGACT"           "A4GALT"
"NPSR1-AS1"        "NPSR1-AS1"             "AAAS"

it has around 15000 entries. How do I replace all values with NA
expect these that are named like this:

geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]


> geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]
0lQ1XozriVZTn.PezY uaeFiCdegrnWFijF_s ZOluqaxSe3ndekoNng
912ny6eCHjnlY2XSCU odF3XHR8CVl4SAUaUQ
            "FLCN"             "FLCN"             "FLCN"
"UCA1"             "IL1B"

Thanks
Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Sep 14 18:37:26 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 14 Sep 2020 11:37:26 -0500
Subject: [R] how to replace values in a named vector
In-Reply-To: <CAF9-5jPBuTcmJXUkp63_7zd3nkoB8X4+jiSeMWLpjU4VATVyDA@mail.gmail.com>
References: <CAF9-5jPBuTcmJXUkp63_7zd3nkoB8X4+jiSeMWLpjU4VATVyDA@mail.gmail.com>
Message-ID: <CAF9-5jMy-jFhxXk15BhxWzcVBxvDgk796NxfnC_pbgjGrCNs3Q@mail.gmail.com>

sorry not replace with NA but with empty string for a name, for example

for example this:

> geneSymbol["Ku8QhfS0n_hIOABXuE"]
Ku8QhfS0n_hIOABXuE
           "MACC1"

would go when I subject it to

> geneSymbol["Ku8QhfS0n_hIOABXuE"]

Ku8QhfS0n_hIOABXuE

On Mon, Sep 14, 2020 at 11:35 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have a vector like this:
>
> > head(geneSymbol)
> Ku8QhfS0n_hIOABXuE Bx496XsFXiAlj.Eaeo W38p0ogk.wIBVRXllY
> QIBkqIS9LR5DfTlTS8 BZKiEvS0eQ305U0v34 6TheVd.HiE1UF3lX6g
>            "MACC1"            "GGACT"           "A4GALT"
> "NPSR1-AS1"        "NPSR1-AS1"             "AAAS"
>
> it has around 15000 entries. How do I replace all values with NA
> expect these that are named like this:
>
> geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]
>
>
> > geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]
> 0lQ1XozriVZTn.PezY uaeFiCdegrnWFijF_s ZOluqaxSe3ndekoNng
> 912ny6eCHjnlY2XSCU odF3XHR8CVl4SAUaUQ
>             "FLCN"             "FLCN"             "FLCN"
> "UCA1"             "IL1B"
>
> Thanks
> Ana


From rmh @end|ng |rom temp|e@edu  Mon Sep 14 19:41:51 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Mon, 14 Sep 2020 13:41:51 -0400
Subject: [R] [External] Re:  how to replace values in a named vector
In-Reply-To: <CAF9-5jMy-jFhxXk15BhxWzcVBxvDgk796NxfnC_pbgjGrCNs3Q@mail.gmail.com>
References: <CAF9-5jPBuTcmJXUkp63_7zd3nkoB8X4+jiSeMWLpjU4VATVyDA@mail.gmail.com>
 <CAF9-5jMy-jFhxXk15BhxWzcVBxvDgk796NxfnC_pbgjGrCNs3Q@mail.gmail.com>
Message-ID: <CAGx1TMBwKEr57M3DvTT5mukYmr8ju2cBShkdG7CKUAQW8p3Ssg@mail.gmail.com>

I can't understand non-words with that many letters.  I think this is what you
are looking for:

> tmp <- c(A="a",B="b",C="c",D="d")
> names(tmp)
[1] "A" "B" "C" "D"
> tmp
  A   B   C   D
"a" "b" "c" "d"
> ## change values of B and C to "x" and "y"
> names(tmp) %in% c("B","C")
[1] FALSE  TRUE  TRUE FALSE
> tmp[names(tmp) %in% c("B","C")]
  B   C
"b" "c"
> tmp[names(tmp) %in% c("B","C")] <- c("x","y")
> tmp
  A   B   C   D
"a" "x" "y" "d"
>

If not, please ask the question again with simpler-appearing vectors and show
us what you would like the answer to be.

On Mon, Sep 14, 2020 at 12:37 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> sorry not replace with NA but with empty string for a name, for example
>
> for example this:
>
> > geneSymbol["Ku8QhfS0n_hIOABXuE"]
> Ku8QhfS0n_hIOABXuE
>            "MACC1"
>
> would go when I subject it to
>
> > geneSymbol["Ku8QhfS0n_hIOABXuE"]
>
> Ku8QhfS0n_hIOABXuE
>
> On Mon, Sep 14, 2020 at 11:35 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have a vector like this:
> >
> > > head(geneSymbol)
> > Ku8QhfS0n_hIOABXuE Bx496XsFXiAlj.Eaeo W38p0ogk.wIBVRXllY
> > QIBkqIS9LR5DfTlTS8 BZKiEvS0eQ305U0v34 6TheVd.HiE1UF3lX6g
> >            "MACC1"            "GGACT"           "A4GALT"
> > "NPSR1-AS1"        "NPSR1-AS1"             "AAAS"
> >
> > it has around 15000 entries. How do I replace all values with NA
> > expect these that are named like this:
> >
> > geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]
> >
> >
> > > geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]
> > 0lQ1XozriVZTn.PezY uaeFiCdegrnWFijF_s ZOluqaxSe3ndekoNng
> > 912ny6eCHjnlY2XSCU odF3XHR8CVl4SAUaUQ
> >             "FLCN"             "FLCN"             "FLCN"
> > "UCA1"             "IL1B"
> >
> > Thanks
> > Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 14 19:51:07 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 14 Sep 2020 18:51:07 +0100
Subject: [R] how to replace values in a named vector
In-Reply-To: <CAF9-5jMy-jFhxXk15BhxWzcVBxvDgk796NxfnC_pbgjGrCNs3Q@mail.gmail.com>
References: <CAF9-5jPBuTcmJXUkp63_7zd3nkoB8X4+jiSeMWLpjU4VATVyDA@mail.gmail.com>
 <CAF9-5jMy-jFhxXk15BhxWzcVBxvDgk796NxfnC_pbgjGrCNs3Q@mail.gmail.com>
Message-ID: <e255c13a-97d2-8d21-2d2c-23f79c0c916a@sapo.pt>

Hello,

Please Ana, post data in dput format.
And the expected output too.

Hope this helps,

Rui Barradas

?s 17:37 de 14/09/20, Ana Marija escreveu:
> sorry not replace with NA but with empty string for a name, for example
> 
> for example this:
> 
>> geneSymbol["Ku8QhfS0n_hIOABXuE"]
> Ku8QhfS0n_hIOABXuE
>             "MACC1"
> 
> would go when I subject it to
> 
>> geneSymbol["Ku8QhfS0n_hIOABXuE"]
> 
> Ku8QhfS0n_hIOABXuE
> 
> On Mon, Sep 14, 2020 at 11:35 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hello,
>>
>> I have a vector like this:
>>
>>> head(geneSymbol)
>> Ku8QhfS0n_hIOABXuE Bx496XsFXiAlj.Eaeo W38p0ogk.wIBVRXllY
>> QIBkqIS9LR5DfTlTS8 BZKiEvS0eQ305U0v34 6TheVd.HiE1UF3lX6g
>>             "MACC1"            "GGACT"           "A4GALT"
>> "NPSR1-AS1"        "NPSR1-AS1"             "AAAS"
>>
>> it has around 15000 entries. How do I replace all values with NA
>> expect these that are named like this:
>>
>> geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]
>>
>>
>>> geneSymbol[c("0lQ1XozriVZTn.PezY","uaeFiCdegrnWFijF_s","ZOluqaxSe3ndekoNng","912ny6eCHjnlY2XSCU","odF3XHR8CVl4SAUaUQ")]
>> 0lQ1XozriVZTn.PezY uaeFiCdegrnWFijF_s ZOluqaxSe3ndekoNng
>> 912ny6eCHjnlY2XSCU odF3XHR8CVl4SAUaUQ
>>              "FLCN"             "FLCN"             "FLCN"
>> "UCA1"             "IL1B"
>>
>> Thanks
>> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tuom@@@o@koponen @end|ng |rom gm@||@com  Mon Sep 14 13:03:01 2020
From: tuom@@@o@koponen @end|ng |rom gm@||@com (Tuomas Koponen)
Date: Mon, 14 Sep 2020 14:03:01 +0300
Subject: [R] Function that finds elements from matrix,
 and saves the indices of the elements to another matrix
Message-ID: <CAECDQQHAJ7MFGwzq9u4WwmwMru83Aqtn-p8NpBF4CzJ8_JXoQw@mail.gmail.com>

Hi all dear R-list users,

This might sound a silly problem, but but for one reason or another it has
proved unsolvable to me.

I need to solve the following task. I have tried to use two nested for
loops as a solution, but have not been able to made it work. It would be
great, if someone could formulate a code for me:

I need to create a function X that takes as its input a 10x10 matrix, which
elements consists of ones and zeros. The function X must find the elements
in the matrix A that are "ones", and save the indices of those elements in
2-column matrix, in a following way: the first column has a row number, and
the second a column number.

The answer should be formulated in a way, that it uses two nested for
loops. The matrix to be returned has a maximum of 100 rows, so one
possibility exists for a 100x2 matrix filled with zeros in the index and
finally separate those rows with zeros.

I have tried the following code:

A<-matrix(1:0, nrow = 10, ncol = 10)

X <- data.frame()
for (i in seq(1, nrow(A))) {
for (j in seq(1,ncol(A))) {
if (A [i,j] > 0) {

new_row <- data.frame(Row_number= rownames(A)[i], Column_number=
colnames(A)[j])

X <- rbind(X, new_row)

  }

  }
}

I only manage to get "Error: object 'X' not found", as a result.

thanks in advance for your help.

Br. Tuomas

	[[alternative HTML version deleted]]


From v@be|ger@ @end|ng |rom @m@terd@mumc@n|  Mon Sep 14 13:54:19 2020
From: v@be|ger@ @end|ng |rom @m@terd@mumc@n| (Belgers, V. (Vera))
Date: Mon, 14 Sep 2020 11:54:19 +0000
Subject: [R] question including crossover trials in meta-analysis
Message-ID: <VI1P193MB03178CA1DB70FBD146D02C55E9230@VI1P193MB0317.EURP193.PROD.OUTLOOK.COM>

Dear sir/madam,
Thank you in advance for taking the time to read my question. I am currently trying to conduct a meta-analysis combining parallel and crossover trials. According to the Cochrane Handbook, I can include crossover trials by using t-paired statistics. So far, I have managed to conduct a meta-analysis and forest plot of the parallel trials using the dmetar package, but I did not succeed in including the crossover trials. I do have the raw data of most of these crossover trials.
Does anybody know how to add crossover trials to the meta-analysis?
With kind regards,
Vera Belgers
______________________________________________________
VUmc disclaimer : www.vumc.nl/disclaimer
AMC disclaimer : www.amc.nl/disclaimer


From ph@edru@v @end|ng |rom gm@||@com  Mon Sep 14 20:53:40 2020
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Mon, 14 Sep 2020 19:53:40 +0100
Subject: [R] How to reduce the sparseness in a TDM to make a cluster plot
 readable?
Message-ID: <c6722f2d-e4a7-f981-0624-4a9a517b76f9@gmail.com>

Hello all

I am doing some text mining on a set of five plain text files and have 
run into a snag when I run hclust in that there are just too many leaves 
for anything to be read. It returns a solid black line.

The texts have been converted into a TDM which has a dim of 5,292 and 5 
(as per 5 docs).

My code for removing sparsity is as follows:

 > tdm2 <- removeSparseTerms(tdm, sparse=0.99999)

 > inspect(tdm2)

<<TermDocumentMatrix (terms: 5292, documents: 5)>>
Non-/sparse entries: 10415/16045
Sparsity?????????? : 61%
Maximal term length: 22
Weighting????????? : term frequency (tf)

While the tf-idf weighting returns this when 0.99999 sparseness is removed:

 > inspect(tdm.tfidf)
<<TermDocumentMatrix (terms: 5292, documents: 5)>>
Non-/sparse entries: 7915/18545
Sparsity?????????? : 70%
Maximal term length: 22
Weighting????????? : term frequency - inverse document frequency 
(normalized) (tf-idf)

I have experimented by decreasing the value I use for decreasing 
sparseness, and that helps a bit, for example:

 > tdm2 <- removeSparseTerms(tdm, sparse=0.215)
 > inspect(tdm2)
<<TermDocumentMatrix (terms: 869, documents: 5)>>
Non-/sparse entries: 3976/369
Sparsity?????????? : 8%
Maximal term length: 14
Weighting????????? : term frequency (tf)

But, no matter what I do, the resulting plot is unreadable. The code for 
plotting the cluster is:

 > hc <- hclust(dist(tdm2, method = "euclidean"), method = "complete")
 > plot(hc, yaxt = 'n', main = "Hierarchical clustering")

Can someone kindly either advise me what I am doing wrong and/ or 
signpost me to some detailed info on how to fix this.

Many thanks in anticipation.

Andy


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 14 21:11:20 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 14 Sep 2020 12:11:20 -0700
Subject: [R] Function that finds elements from matrix,
 and saves the indices of the elements to another matrix
In-Reply-To: <CAECDQQHAJ7MFGwzq9u4WwmwMru83Aqtn-p8NpBF4CzJ8_JXoQw@mail.gmail.com>
References: <CAECDQQHAJ7MFGwzq9u4WwmwMru83Aqtn-p8NpBF4CzJ8_JXoQw@mail.gmail.com>
Message-ID: <CAGxFJbSOQxDX8MJbKeHvSwKDJ4HV_WZaS3wQqmX_XyffQe3UpQ@mail.gmail.com>

Is this a homework problem? We try not to do others' homework here.

Incidentally, this can easily be done much more efficiently without any
for() loops.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 14, 2020 at 11:50 AM Tuomas Koponen <tuomas.o.koponen at gmail.com>
wrote:

> Hi all dear R-list users,
>
> This might sound a silly problem, but but for one reason or another it has
> proved unsolvable to me.
>
> I need to solve the following task. I have tried to use two nested for
> loops as a solution, but have not been able to made it work. It would be
> great, if someone could formulate a code for me:
>
> I need to create a function X that takes as its input a 10x10 matrix, which
> elements consists of ones and zeros. The function X must find the elements
> in the matrix A that are "ones", and save the indices of those elements in
> 2-column matrix, in a following way: the first column has a row number, and
> the second a column number.
>
> The answer should be formulated in a way, that it uses two nested for
> loops. The matrix to be returned has a maximum of 100 rows, so one
> possibility exists for a 100x2 matrix filled with zeros in the index and
> finally separate those rows with zeros.
>
> I have tried the following code:
>
> A<-matrix(1:0, nrow = 10, ncol = 10)
>
> X <- data.frame()
> for (i in seq(1, nrow(A))) {
> for (j in seq(1,ncol(A))) {
> if (A [i,j] > 0) {
>
> new_row <- data.frame(Row_number= rownames(A)[i], Column_number=
> colnames(A)[j])
>
> X <- rbind(X, new_row)
>
>   }
>
>   }
> }
>
> I only manage to get "Error: object 'X' not found", as a result.
>
> thanks in advance for your help.
>
> Br. Tuomas
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 14 21:14:50 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 14 Sep 2020 12:14:50 -0700
Subject: [R] question including crossover trials in meta-analysis
In-Reply-To: <VI1P193MB03178CA1DB70FBD146D02C55E9230@VI1P193MB0317.EURP193.PROD.OUTLOOK.COM>
References: <VI1P193MB03178CA1DB70FBD146D02C55E9230@VI1P193MB0317.EURP193.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbRdLRAhstJ=JSS0-GxrcG2nOYQdzcP_X6qfsnhm4fTV-Q@mail.gmail.com>

Did you first try a web search? -- you should always do this before posting
here.

"meta-analysis in R" brought up this:

https://CRAN.R-project.org/view=MetaAnalysis

Have you looked at this task view yet?


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 14, 2020 at 11:50 AM Belgers, V. (Vera) <
v.belgers at amsterdamumc.nl> wrote:

> Dear sir/madam,
> Thank you in advance for taking the time to read my question. I am
> currently trying to conduct a meta-analysis combining parallel and
> crossover trials. According to the Cochrane Handbook, I can include
> crossover trials by using t-paired statistics. So far, I have managed to
> conduct a meta-analysis and forest plot of the parallel trials using the
> dmetar package, but I did not succeed in including the crossover trials. I
> do have the raw data of most of these crossover trials.
> Does anybody know how to add crossover trials to the meta-analysis?
> With kind regards,
> Vera Belgers
> ______________________________________________________
> VUmc disclaimer : www.vumc.nl/disclaimer
> AMC disclaimer : www.amc.nl/disclaimer
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Mon Sep 14 21:41:32 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 14 Sep 2020 15:41:32 -0400
Subject: [R] question including crossover trials in meta-analysis
In-Reply-To: <CAGxFJbRdLRAhstJ=JSS0-GxrcG2nOYQdzcP_X6qfsnhm4fTV-Q@mail.gmail.com>
References: <VI1P193MB03178CA1DB70FBD146D02C55E9230@VI1P193MB0317.EURP193.PROD.OUTLOOK.COM>
 <CAGxFJbRdLRAhstJ=JSS0-GxrcG2nOYQdzcP_X6qfsnhm4fTV-Q@mail.gmail.com>
Message-ID: <2633066A-4231-41C3-8E13-36A76C7E9E61@me.com>

Hi,

Bert has pointed you to some R specific packages for meta-analyses via the Task View.

It sounds like you may need to first address some underlying conceptual issues, which strictly speaking, is off-topic for this list.

That being said, a quick Google search came up with some possible resources, beyond the Cochrane reference:

  https://academic.oup.com/ije/article/31/1/140/655940

  https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1236

  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0133023


Perhaps with additional conceptual background, that might assist in enabling you to make use of the R packages that provide relevant functionality.

Another option, if you want to stay with the dmetar package, would be to contact the package maintainer for some guidance relative to how to use the functionality in the package given your specific use case.

Regards,

Marc Schwartz


> On Sep 14, 2020, at 3:14 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Did you first try a web search? -- you should always do this before posting
> here.
> 
> "meta-analysis in R" brought up this:
> 
> https://CRAN.R-project.org/view=MetaAnalysis
> 
> Have you looked at this task view yet?
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Sep 14, 2020 at 11:50 AM Belgers, V. (Vera) <
> v.belgers at amsterdamumc.nl> wrote:
> 
>> Dear sir/madam,
>> Thank you in advance for taking the time to read my question. I am
>> currently trying to conduct a meta-analysis combining parallel and
>> crossover trials. According to the Cochrane Handbook, I can include
>> crossover trials by using t-paired statistics. So far, I have managed to
>> conduct a meta-analysis and forest plot of the parallel trials using the
>> dmetar package, but I did not succeed in including the crossover trials. I
>> do have the raw data of most of these crossover trials.
>> Does anybody know how to add crossover trials to the meta-analysis?
>> With kind regards,
>> Vera Belgers


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 14 23:45:40 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 14 Sep 2020 22:45:40 +0100
Subject: [R] Function that finds elements from matrix,
 and saves the indices of the elements to another matrix
In-Reply-To: <CAECDQQHAJ7MFGwzq9u4WwmwMru83Aqtn-p8NpBF4CzJ8_JXoQw@mail.gmail.com>
References: <CAECDQQHAJ7MFGwzq9u4WwmwMru83Aqtn-p8NpBF4CzJ8_JXoQw@mail.gmail.com>
Message-ID: <8304edb2-f575-10ed-5e02-e11da16a3b04@sapo.pt>

Hello,

This is simple:


which(A == 1, arr.ind = TRUE)


Hope this helps,

Rui Barradas

?s 12:03 de 14/09/20, Tuomas Koponen escreveu:
> Hi all dear R-list users,
> 
> This might sound a silly problem, but but for one reason or another it has
> proved unsolvable to me.
> 
> I need to solve the following task. I have tried to use two nested for
> loops as a solution, but have not been able to made it work. It would be
> great, if someone could formulate a code for me:
> 
> I need to create a function X that takes as its input a 10x10 matrix, which
> elements consists of ones and zeros. The function X must find the elements
> in the matrix A that are "ones", and save the indices of those elements in
> 2-column matrix, in a following way: the first column has a row number, and
> the second a column number.
> 
> The answer should be formulated in a way, that it uses two nested for
> loops. The matrix to be returned has a maximum of 100 rows, so one
> possibility exists for a 100x2 matrix filled with zeros in the index and
> finally separate those rows with zeros.
> 
> I have tried the following code:
> 
> A<-matrix(1:0, nrow = 10, ncol = 10)
> 
> X <- data.frame()
> for (i in seq(1, nrow(A))) {
> for (j in seq(1,ncol(A))) {
> if (A [i,j] > 0) {
> 
> new_row <- data.frame(Row_number= rownames(A)[i], Column_number=
> colnames(A)[j])
> 
> X <- rbind(X, new_row)
> 
>    }
> 
>    }
> }
> 
> I only manage to get "Error: object 'X' not found", as a result.
> 
> thanks in advance for your help.
> 
> Br. Tuomas
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From twoo|m@n @end|ng |rom ont@rgettek@com  Tue Sep 15 01:54:43 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Mon, 14 Sep 2020 19:54:43 -0400
Subject: [R] RIDIT scoring in R
In-Reply-To: <CAA99HCydSj0FmT9=zdVfOaA6Jbk54sOir6G0z7iFw1fBr2pqgw@mail.gmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
 <021bb81d-fc58-4af9-92c3-f5e6ce87a844@www.fastmail.com>
 <CAA99HCx+jvO=4==1fZCR0gyp-+59PfJOMOwZ7mwFwoPHLKyudA@mail.gmail.com>
 <ec3b35eb-a5b8-425c-8222-fa868068ce6c@www.fastmail.com>
 <CAA99HCydSj0FmT9=zdVfOaA6Jbk54sOir6G0z7iFw1fBr2pqgw@mail.gmail.com>
Message-ID: <20200914195443.Horde.Zn9AqlXLrQyviwIWwKa1_1H@www.ontargettek.com>

Hi everyone.

I'd like to perform RIDIT scoring of a column that consists of ordinal  
values, but I don't have a comparison dataset to use against it as  
required by the Ridit::ridit function.

As a question of best practice, could I use a normally distributed  
frequency distribution table generated by the rnorm function for use  
as comparison data for RIDIT scoring?

Or would I be better off using a 2nd ordinal variable from the same  
dataframe for comparison?



Thanks in advance!


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 15 03:39:50 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 14 Sep 2020 18:39:50 -0700
Subject: [R] RIDIT scoring in R
In-Reply-To: <20200914195443.Horde.Zn9AqlXLrQyviwIWwKa1_1H@www.ontargettek.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
 <021bb81d-fc58-4af9-92c3-f5e6ce87a844@www.fastmail.com>
 <CAA99HCx+jvO=4==1fZCR0gyp-+59PfJOMOwZ7mwFwoPHLKyudA@mail.gmail.com>
 <ec3b35eb-a5b8-425c-8222-fa868068ce6c@www.fastmail.com>
 <CAA99HCydSj0FmT9=zdVfOaA6Jbk54sOir6G0z7iFw1fBr2pqgw@mail.gmail.com>
 <20200914195443.Horde.Zn9AqlXLrQyviwIWwKa1_1H@www.ontargettek.com>
Message-ID: <CAGxFJbSFkD=Fzn0FWZtfY-ix+xNznrcMsKsJLdtb0AMum5ZC1g@mail.gmail.com>

Generally speaking, statistical questions like this are O/T here. This list
is mostly about R programming issues. While there is a non-null
intersection, I would nevertheless suggest that you post on
stats.stackexchange.com instead.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 14, 2020 at 4:55 PM Tom Woolman <twoolman at ontargettek.com>
wrote:

> Hi everyone.
>
> I'd like to perform RIDIT scoring of a column that consists of ordinal
> values, but I don't have a comparison dataset to use against it as
> required by the Ridit::ridit function.
>
> As a question of best practice, could I use a normally distributed
> frequency distribution table generated by the rnorm function for use
> as comparison data for RIDIT scoring?
>
> Or would I be better off using a 2nd ordinal variable from the same
> dataframe for comparison?
>
>
>
> Thanks in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Sep 15 05:12:01 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 15 Sep 2020 15:12:01 +1200
Subject: [R] How to represent the effect of one covariate on regression
 results?
In-Reply-To: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
References: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
Message-ID: <CAB8pepwKXnHhRcOM0L2SkaeJWwyc-dtaEHroNSrPi7ATrUMfyw@mail.gmail.com>

I'm wondering if you want one of these:
(1) Plots of "Main Effects".
(2) "Partial Residual Plots".

Search for them, and you should be able to tell if they're what you want.

But a word of warning:

Many people (including many senior statisticians) misinterpret this
kind of information.
Because, it's always the effect of xj on Y, while holding the other
variables *constant*.
That's not as simple as it sounds, and people have a tendency of
disregarding the importance of the second half of that sentence, in
their final interpretations.


P.S.
John Fox, announced a package with support for Regression Diagnostics,
about 11 days ago:
https://stat.ethz.ch/pipermail/r-help/2020-September/468609.html

I'm not sure how relevant it is to your question, but I just glanced
at the vignette, and it's pretty slick...




On Tue, Sep 15, 2020 at 1:30 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I was running association analysis using --glm genotypic from:
> https://www.cog-genomics.org/plink/2.0/assoc with these covariates:
> sex,age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,TD,array,HBA1C. The
> result looks like this:
>
>     #CHROM    POS    ID    REF    ALT    A1    TEST    OBS_CT    BETA
>   SE    Z_OR_F_STAT    P    ERRCODE
>     10    135434303    rs11101905    G    A    A    ADD    11863
> -0.110733    0.0986981    -1.12193    0.261891    .
>     10    135434303    rs11101905    G    A    A    DOMDEV    11863
> 0.079797    0.111004    0.718868    0.472222    .
>     10    135434303    rs11101905    G    A    A    sex=Female
> 11863    -0.120404    0.0536069    -2.24605    0.0247006    .
>     10    135434303    rs11101905    G    A    A    age    11863
> 0.00524501    0.00391528    1.33963    0.180367    .
>     10    135434303    rs11101905    G    A    A    PC1    11863
> -0.0191779    0.0166868    -1.14928    0.25044    .
>     10    135434303    rs11101905    G    A    A    PC2    11863
> -0.0269939    0.0173086    -1.55957    0.118863    .
>     10    135434303    rs11101905    G    A    A    PC3    11863
> 0.0115207    0.0168076    0.685448    0.493061    .
>     10    135434303    rs11101905    G    A    A    PC4    11863
> 9.57832e-05    0.0124607    0.0076868    0.993867    .
>     10    135434303    rs11101905    G    A    A    PC5    11863
> -0.00191047    0.00543937    -0.35123    0.725416    .
>     10    135434303    rs11101905    G    A    A    PC6    11863
> -0.0103309    0.0159879    -0.646172    0.518168    .
>     10    135434303    rs11101905    G    A    A    PC7    11863
> 0.00790997    0.0144025    0.549207    0.582863    .
>     10    135434303    rs11101905    G    A    A    PC8    11863
> -0.00205639    0.0142709    -0.144096    0.885424    .
>     10    135434303    rs11101905    G    A    A    PC9    11863
> -0.00873771    0.0057239    -1.52653    0.126878    .
>     10    135434303    rs11101905    G    A    A    PC10    11863
> 0.0116197    0.0123826    0.938388    0.348045    .
>     10    135434303    rs11101905    G    A    A    TD    11863
> -0.670026    0.0962216    -6.96337    3.32228e-12    .
>     10    135434303    rs11101905    G    A    A    array=Biobank
> 11863    0.160666    0.073631    2.18205    0.0291062    .
>     10    135434303    rs11101905    G    A    A    HBA1C    11863
> 0.0265933    0.00168758    15.7583    6.0236e-56    .
>     10    135434303    rs11101905    G    A    A    GENO_2DF    11863
>   NA    NA    0.726514    0.483613    .
>
> This results is shown just for one ID (rs11101905) there is about 2
> million of those in the resulting file.
>
> My question is how do I present/plot the effect of covariate "TD" in
> the example it has "P" equal to 3.32228e-12 for all IDs in the
> resulting file so that I show how much effect covariate "TD" has on
> the analysis. Should I run another regression without covariate "TD"
> and than do scatter plot of P values with and without "TD" covariate
> or there is a better way to do this from the data I already have?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 15 08:26:41 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 14 Sep 2020 23:26:41 -0700
Subject: [R] How to represent the effect of one covariate on regression
 results?
In-Reply-To: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
References: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
Message-ID: <16955b86-0e7c-f124-4070-e24fee6e5c5b@comcast.net>

There is a user-group for PLINK, easily found by looking at the page you 
cited. This is not the correct place to submit such questions.


https://groups.google.com/g/plink2-users?pli=1


-- 

David.

On 9/14/20 6:29 AM, Ana Marija wrote:
> Hello,
>
> I was running association analysis using --glm genotypic from:
> https://www.cog-genomics.org/plink/2.0/assoc with these covariates:
> sex,age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,TD,array,HBA1C. The
> result looks like this:
>
>      #CHROM    POS    ID    REF    ALT    A1    TEST    OBS_CT    BETA
>    SE    Z_OR_F_STAT    P    ERRCODE
>      10    135434303    rs11101905    G    A    A    ADD    11863
> -0.110733    0.0986981    -1.12193    0.261891    .
>      10    135434303    rs11101905    G    A    A    DOMDEV    11863
> 0.079797    0.111004    0.718868    0.472222    .
>      10    135434303    rs11101905    G    A    A    sex=Female
> 11863    -0.120404    0.0536069    -2.24605    0.0247006    .
>      10    135434303    rs11101905    G    A    A    age    11863
> 0.00524501    0.00391528    1.33963    0.180367    .
>      10    135434303    rs11101905    G    A    A    PC1    11863
> -0.0191779    0.0166868    -1.14928    0.25044    .
>      10    135434303    rs11101905    G    A    A    PC2    11863
> -0.0269939    0.0173086    -1.55957    0.118863    .
>      10    135434303    rs11101905    G    A    A    PC3    11863
> 0.0115207    0.0168076    0.685448    0.493061    .
>      10    135434303    rs11101905    G    A    A    PC4    11863
> 9.57832e-05    0.0124607    0.0076868    0.993867    .
>      10    135434303    rs11101905    G    A    A    PC5    11863
> -0.00191047    0.00543937    -0.35123    0.725416    .
>      10    135434303    rs11101905    G    A    A    PC6    11863
> -0.0103309    0.0159879    -0.646172    0.518168    .
>      10    135434303    rs11101905    G    A    A    PC7    11863
> 0.00790997    0.0144025    0.549207    0.582863    .
>      10    135434303    rs11101905    G    A    A    PC8    11863
> -0.00205639    0.0142709    -0.144096    0.885424    .
>      10    135434303    rs11101905    G    A    A    PC9    11863
> -0.00873771    0.0057239    -1.52653    0.126878    .
>      10    135434303    rs11101905    G    A    A    PC10    11863
> 0.0116197    0.0123826    0.938388    0.348045    .
>      10    135434303    rs11101905    G    A    A    TD    11863
> -0.670026    0.0962216    -6.96337    3.32228e-12    .
>      10    135434303    rs11101905    G    A    A    array=Biobank
> 11863    0.160666    0.073631    2.18205    0.0291062    .
>      10    135434303    rs11101905    G    A    A    HBA1C    11863
> 0.0265933    0.00168758    15.7583    6.0236e-56    .
>      10    135434303    rs11101905    G    A    A    GENO_2DF    11863
>    NA    NA    0.726514    0.483613    .
>
> This results is shown just for one ID (rs11101905) there is about 2
> million of those in the resulting file.
>
> My question is how do I present/plot the effect of covariate "TD" in
> the example it has "P" equal to 3.32228e-12 for all IDs in the
> resulting file so that I show how much effect covariate "TD" has on
> the analysis. Should I run another regression without covariate "TD"
> and than do scatter plot of P values with and without "TD" covariate
> or there is a better way to do this from the data I already have?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Sep 15 10:10:56 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 15 Sep 2020 09:10:56 +0100
Subject: [R] question including crossover trials in meta-analysis
In-Reply-To: <2633066A-4231-41C3-8E13-36A76C7E9E61@me.com>
References: <VI1P193MB03178CA1DB70FBD146D02C55E9230@VI1P193MB0317.EURP193.PROD.OUTLOOK.COM>
 <CAGxFJbRdLRAhstJ=JSS0-GxrcG2nOYQdzcP_X6qfsnhm4fTV-Q@mail.gmail.com>
 <2633066A-4231-41C3-8E13-36A76C7E9E61@me.com>
Message-ID: <e3de067e-c2cd-8aae-64b8-10c9abe4f5b6@dewey.myzen.co.uk>

Dear Vera

In addition to what you already have you might like to know about the 
mailing list specifically dedicated to meta-analysis in R.

https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis//

You might like to search the archives first as this sort of issue does 
come up there. You are also likely to get more immediate help if you 
frame your question in terms of either meta or metafor the two packages 
which dmetar uses. The authors of meta and metafor all frequent the list

Michael

On 14/09/2020 20:41, Marc Schwartz via R-help wrote:
> Hi,
> 
> Bert has pointed you to some R specific packages for meta-analyses via the Task View.
> 
> It sounds like you may need to first address some underlying conceptual issues, which strictly speaking, is off-topic for this list.
> 
> That being said, a quick Google search came up with some possible resources, beyond the Cochrane reference:
> 
>    https://academic.oup.com/ije/article/31/1/140/655940
> 
>    https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1236
> 
>    https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0133023
> 
> 
> Perhaps with additional conceptual background, that might assist in enabling you to make use of the R packages that provide relevant functionality.
> 
> Another option, if you want to stay with the dmetar package, would be to contact the package maintainer for some guidance relative to how to use the functionality in the package given your specific use case.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
>> On Sep 14, 2020, at 3:14 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Did you first try a web search? -- you should always do this before posting
>> here.
>>
>> "meta-analysis in R" brought up this:
>>
>> https://CRAN.R-project.org/view=MetaAnalysis
>>
>> Have you looked at this task view yet?
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Sep 14, 2020 at 11:50 AM Belgers, V. (Vera) <
>> v.belgers at amsterdamumc.nl> wrote:
>>
>>> Dear sir/madam,
>>> Thank you in advance for taking the time to read my question. I am
>>> currently trying to conduct a meta-analysis combining parallel and
>>> crossover trials. According to the Cochrane Handbook, I can include
>>> crossover trials by using t-paired statistics. So far, I have managed to
>>> conduct a meta-analysis and forest plot of the parallel trials using the
>>> dmetar package, but I did not succeed in including the crossover trials. I
>>> do have the raw data of most of these crossover trials.
>>> Does anybody know how to add crossover trials to the meta-analysis?
>>> With kind regards,
>>> Vera Belgers
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From he@h@m|bb @end|ng |rom y@hoo@com  Tue Sep 15 11:01:13 2020
From: he@h@m|bb @end|ng |rom y@hoo@com (Hesham A. AL-bukhaiti)
Date: Tue, 15 Sep 2020 09:01:13 +0000 (UTC)
Subject: [R] Loop for two columns and 154 rows
References: <1701769557.4495505.1600160473189.ref@mail.yahoo.com>
Message-ID: <1701769557.4495505.1600160473189@mail.yahoo.com>

 Dears in R :i have this code in R:
# this for do not work true (i tried )out<-read.csv("outbr.csv")?truth<-out[,seq(1,2)]truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));for (j in 1:2) {? for (i in 1:20) {? ??truth[(truth[,1]== truth[j,i] & truth[,2]== truth[j,i+1]) |?? ? ? ? (truth[,1]== truth[j+1,i] & truth[,2]== truth[j+1,i+1]),3]<-1?? }
}
#truth<-out[,seq(1,2)]#truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? #? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#truth[(truth[,1]=="G2" & truth[,2]=="G1") | (truth[,1]=="G1" & truth[,2]=="G2"),3]<-1?
##########################################################################3

I have file have two columns? . data in this file is text just (G1,G2,G3? to G154). one element? can repeat, no problem ,so? we have 23562 rows in two columns (for 154 elements) like :
Column1? ?column2? ? ?column3??
G1? ? ? ? ? ? ? ? ?G4? ? ? ? ? ? 0
G4? ? ? ? ? ? ? ? ?G6? ? ? ? ? ? 0
G100? ? ? ? ? ?G7? ? ? ? ? ? ?1G7? ? ? ? ? ? ? G100? ? .? ? ?1.? ? ? ? ? ? ? ? ? ? ? ..? ? ? ? ? ? ? ? ? ? ? ?.?I want to make third column (1 or 0) based on this condition:
IF? truth[,1]==?G1? & truth[,2]==?G2? | truth[,1]==?G2? & truth[,2]==?G1? <-1.then In the third column write 1 otherwise write 0.G1 and G2? just exampl? (indeed? i want test If two each elements? ?has a reciprocal relationship(G1 to G2 and G2 to G1or not)
Best regHesham?




	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Sep 15 11:54:20 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 15 Sep 2020 09:54:20 +0000
Subject: [R] FW:  Loop for two columns and 154 rows
In-Reply-To: <4fa52dcf9fcb4840a353c9ead96a7acc@SRVEXCHCM1302.precheza.cz>
References: <1701769557.4495505.1600160473189.ref@mail.yahoo.com>
 <1701769557.4495505.1600160473189@mail.yahoo.com>
 <4fa52dcf9fcb4840a353c9ead96a7acc@SRVEXCHCM1302.precheza.cz>
Message-ID: <829e992a1fa2418fb71a65ebaabc1255@SRVEXCHCM1302.precheza.cz>

Sorry, forgot to copy to r help.

Petr
> -----Original Message-----
> From: PIKAL Petr
> Sent: Tuesday, September 15, 2020 11:53 AM
> To: 'Hesham A. AL-bukhaiti' <heshamibb at yahoo.com>
> Subject: RE: [R] Loop for two columns and 154 rows
> 
> Hi
> 
> Your mail is unreadable, post in plain text not HTML.
> 
> If I deciphered it correcttly you want all values which have G1 in column 1 and
> G2 in column 2 or G2 in column 1 and G1 in column to produce 1 all other
> produce 0
> 
> So if your data frame is named truth
> 
> truth$column3 <- ((truth[,1] =="G1" & truth[,2] =="G2") | (truth[,2] =="G1" &
> truth[,1] =="G2")) * 1
> 
> Cheers
> Petr
> 
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Hesham A. AL-
> > bukhaiti via R-help
> > Sent: Tuesday, September 15, 2020 11:01 AM
> > To: r-help at r-project.org
> > Subject: [R] Loop for two columns and 154 rows
> >
> >  Dears in R :i have this code in R:
> > # this for do not work true (i tried )out<-read.csv("outbr.csv") truth<-
> > out[,seq(1,2)]truth<-
> > cbind(as.character(truth[,1]),as.character(truth[,2])
> ,as.data.frame(rep(
> > 0,,dim(out)[1])));for (j in 1:2) {  for (i in 1:20) {    truth[(truth[,1]== truth[j,i] &
> > truth[,2]== truth[j,i+1]) |         (truth[,1]== truth[j+1,i] & truth[,2]==
> > truth[j+1,i+1]),3]<-1   } }
> > #truth<-out[,seq(1,2)]#truth<-
> > cbind(as.character(truth[,1]),as.character(truth[,2])  #
> ,as.data.frame(rep
> > (0,,dim(out)[1])));#truth[(truth[,1]=="G2" & truth[,2]=="G1") |
> (truth[,1]=="G1"
> > & truth[,2]=="G2"),3]<-1
> >
> #################################################################
> > #########3
> >
> > I have file have two columns  . data in this file is text just (G1,G2,G3? to
> > G154). one element  can repeat, no problem ,so  we have 23562 rows in two
> > columns (for 154 elements) like :
> > Column1   column2     column3
> > G1                 G4            0
> > G4                 G6            0
> > G100           G7             1G7              G100    .     1.                      ..                       .
> I
> > want to make third column (1 or 0) based on this condition:
> > IF  truth[,1]==?G1? & truth[,2]==?G2? | truth[,1]==?G2? & truth[,2]==?G1? <-
> > 1.then In the third column write 1 otherwise write 0.G1 and G2  just
> > exampl  (indeed  i want test If two each elements   has a reciprocal
> > relationship(G1 to G2 and G2 to G1or not) Best regHesham
> >
> >
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From mort|mer@@teven@m @end|ng |rom gm@||@com  Sun Sep 13 12:42:18 2020
From: mort|mer@@teven@m @end|ng |rom gm@||@com (Steven M. Mortimer)
Date: Sun, 13 Sep 2020 06:42:18 -0400
Subject: [R] [R-pkgs] salesforcer v0.2.2: An Implementation of Salesforce
 APIs Using Tidy Principles
Message-ID: <CACv7DjrMyugPt1baeCpbPWqbfpEE83_YrenWciHkUt8V0jHFSA@mail.gmail.com>

The {salesforcer} package allows users to query and analyze Salesforce data
and administer their Org's records and object metadata (fields, triggers,
layouts). It has been three years in the making to map multiple
Salesforce Platform
APIs for use in R. The package implements the REST, SOAP, Bulk 1.0, Bulk
2.0, Metadata, and Reports and Dashboards APIs. If you or your colleagues
maintain or analyze Salesforce data, then I would greatly appreciate your
use and feedback of this package. Thank you.

Sincerely,
Steven M. Mortimer

CRAN: https://cran.r-project.org/package=salesforcer
GitHub: https://github.com/StevenMMortimer/salesforcer

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Sep 15 17:57:20 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 15 Sep 2020 10:57:20 -0500
Subject: [R] How to represent the effect of one covariate on regression
 results?
In-Reply-To: <16955b86-0e7c-f124-4070-e24fee6e5c5b@comcast.net>
References: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
 <16955b86-0e7c-f124-4070-e24fee6e5c5b@comcast.net>
Message-ID: <CAF9-5jNRUj35qbB-14MGVOZOHQkcNPmop7waO7GwKNfc6fGQ3g@mail.gmail.com>

Hi Abby and David,

Thanks for the useful tips! I will check those.

I completed the regression analysis in plink (as R would be very slow
for my sample size) but as I mentioned I need to determine the
influence of a specific covariate in my results and Plink is of no
help there.

I did Pearson correlation analysis for P values which I got in
regression with and without my covariate of interest and I got this:

> cor.test(tt$P_TD, tt$P_noTD, method = "pearson", conf.level = 0.95)

    Pearson's product-moment correlation

data:  tt$P_TD and tt$P_noTD
t = 20.17, df = 283, p-value < 2.2e-16
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.7156134 0.8117108
sample estimates:
      cor
0.7679493

I can see the p values are very correlated in those two instances. Can
I conclude that my covariate then doesn't have a huge effect or what
kind of conclusion I can draw from that?

Thanks for all your help
Ana



On Tue, Sep 15, 2020 at 1:26 AM David Winsemius <dwinsemius at comcast.net> wrote:
>
> There is a user-group for PLINK, easily found by looking at the page you
> cited. This is not the correct place to submit such questions.
>
>
> https://groups.google.com/g/plink2-users?pli=1
>
>
> --
>
> David.
>
> On 9/14/20 6:29 AM, Ana Marija wrote:
> > Hello,
> >
> > I was running association analysis using --glm genotypic from:
> > https://www.cog-genomics.org/plink/2.0/assoc with these covariates:
> > sex,age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,TD,array,HBA1C. The
> > result looks like this:
> >
> >      #CHROM    POS    ID    REF    ALT    A1    TEST    OBS_CT    BETA
> >    SE    Z_OR_F_STAT    P    ERRCODE
> >      10    135434303    rs11101905    G    A    A    ADD    11863
> > -0.110733    0.0986981    -1.12193    0.261891    .
> >      10    135434303    rs11101905    G    A    A    DOMDEV    11863
> > 0.079797    0.111004    0.718868    0.472222    .
> >      10    135434303    rs11101905    G    A    A    sex=Female
> > 11863    -0.120404    0.0536069    -2.24605    0.0247006    .
> >      10    135434303    rs11101905    G    A    A    age    11863
> > 0.00524501    0.00391528    1.33963    0.180367    .
> >      10    135434303    rs11101905    G    A    A    PC1    11863
> > -0.0191779    0.0166868    -1.14928    0.25044    .
> >      10    135434303    rs11101905    G    A    A    PC2    11863
> > -0.0269939    0.0173086    -1.55957    0.118863    .
> >      10    135434303    rs11101905    G    A    A    PC3    11863
> > 0.0115207    0.0168076    0.685448    0.493061    .
> >      10    135434303    rs11101905    G    A    A    PC4    11863
> > 9.57832e-05    0.0124607    0.0076868    0.993867    .
> >      10    135434303    rs11101905    G    A    A    PC5    11863
> > -0.00191047    0.00543937    -0.35123    0.725416    .
> >      10    135434303    rs11101905    G    A    A    PC6    11863
> > -0.0103309    0.0159879    -0.646172    0.518168    .
> >      10    135434303    rs11101905    G    A    A    PC7    11863
> > 0.00790997    0.0144025    0.549207    0.582863    .
> >      10    135434303    rs11101905    G    A    A    PC8    11863
> > -0.00205639    0.0142709    -0.144096    0.885424    .
> >      10    135434303    rs11101905    G    A    A    PC9    11863
> > -0.00873771    0.0057239    -1.52653    0.126878    .
> >      10    135434303    rs11101905    G    A    A    PC10    11863
> > 0.0116197    0.0123826    0.938388    0.348045    .
> >      10    135434303    rs11101905    G    A    A    TD    11863
> > -0.670026    0.0962216    -6.96337    3.32228e-12    .
> >      10    135434303    rs11101905    G    A    A    array=Biobank
> > 11863    0.160666    0.073631    2.18205    0.0291062    .
> >      10    135434303    rs11101905    G    A    A    HBA1C    11863
> > 0.0265933    0.00168758    15.7583    6.0236e-56    .
> >      10    135434303    rs11101905    G    A    A    GENO_2DF    11863
> >    NA    NA    0.726514    0.483613    .
> >
> > This results is shown just for one ID (rs11101905) there is about 2
> > million of those in the resulting file.
> >
> > My question is how do I present/plot the effect of covariate "TD" in
> > the example it has "P" equal to 3.32228e-12 for all IDs in the
> > resulting file so that I show how much effect covariate "TD" has on
> > the analysis. Should I run another regression without covariate "TD"
> > and than do scatter plot of P values with and without "TD" covariate
> > or there is a better way to do this from the data I already have?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Sep 15 18:52:40 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 15 Sep 2020 11:52:40 -0500
Subject: [R] X axis labels are not fully shown when using pareto.chart
 function
Message-ID: <CAMOcQfMvjEuE9EFFC0W_W3XQHP9jmFEX8W6338Cek0YY8xgUgQ@mail.gmail.com>

Dear friends,

Hope you are doing well. I am currently using R version 3.6.2. I installed
and loaded package qcc by Mr. Luca Scrucca.

Hopefully someone can tell me if there is a workaround for the issue I am
experiencing.

I generated the pareto chart using qcc?s pareto.chart function, but when
the graph gets generated, the x-axis labels aren?t fully shown (some labels
get truncated), and so the text can?t be viewed properly.

Is there any way to adjust the x-axis labels (font and orientation), so
that they can be easily shown?

This is the structure of my data:

str(dataset2)
'data.frame':   140 obs. of  2 variables:
 $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
106 65 17 ...
 $ Points: num  55 43 24 21 20 20 18 17 16 16 ...


Below is the dput() of my dataset.

dput(dataset2)
structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
"Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
"Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
"Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
"Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
"Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
"Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
"Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
"Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
"David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
"El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
"El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
"Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
"Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
Espinar",
"Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
"La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
"Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
"Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
"Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
"Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
"Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
"Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
"Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
"Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
"R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
"Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
"San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
Porres",
"Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
"Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
"Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
), class = "data.frame")

Best regards,

Paul

	[[alternative HTML version deleted]]


From v@be|ger@ @end|ng |rom @m@terd@mumc@n|  Tue Sep 15 08:59:04 2020
From: v@be|ger@ @end|ng |rom @m@terd@mumc@n| (Belgers, V. (Vera))
Date: Tue, 15 Sep 2020 06:59:04 +0000
Subject: [R] question including crossover trials in meta-analysis
In-Reply-To: <CAGxFJbRdLRAhstJ=JSS0-GxrcG2nOYQdzcP_X6qfsnhm4fTV-Q@mail.gmail.com>
References: <VI1P193MB03178CA1DB70FBD146D02C55E9230@VI1P193MB0317.EURP193.PROD.OUTLOOK.COM>,
 <CAGxFJbRdLRAhstJ=JSS0-GxrcG2nOYQdzcP_X6qfsnhm4fTV-Q@mail.gmail.com>
Message-ID: <VI1P193MB0317FA86493ED5AC2B421806E9200@VI1P193MB0317.EURP193.PROD.OUTLOOK.COM>

Dear mr. Schwartz and mw Gunter,
Thank you both for your reply. I did google but did not find these sources, so thank you.
With kind regards,
Vera Belgers
________________________________
Van: Bert Gunter <bgunter.4567 at gmail.com>
Verzonden: maandag 14 september 2020 21:14
Aan: Belgers, V. (Vera) <v.belgers at amsterdamumc.nl>
CC: r-help at R-project.org <r-help at r-project.org>
Onderwerp: Re: [R] question including crossover trials in meta-analysis

Did you first try a web search? -- you should always do this before posting here.

"meta-analysis in R" brought up this:

https://CRAN.R-project.org/view=MetaAnalysis<https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fcran.r-project.org%2Fview%3DMetaAnalysis&data=02%7C01%7Cv.belgers%40amsterdamumc.nl%7C460c6129ebd54ce61bb308d858e27bae%7C68dfab1a11bb4cc6beb528d756984fb6%7C0%7C0%7C637357077046991635&sdata=wtUat277Ectic3FwPyRh92uhm7Am%2FAvsam97590UJ0o%3D&reserved=0>

Have you looked at this task view yet?


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 14, 2020 at 11:50 AM Belgers, V. (Vera) <v.belgers at amsterdamumc.nl<mailto:v.belgers at amsterdamumc.nl>> wrote:
Dear sir/madam,
Thank you in advance for taking the time to read my question. I am currently trying to conduct a meta-analysis combining parallel and crossover trials. According to the Cochrane Handbook, I can include crossover trials by using t-paired statistics. So far, I have managed to conduct a meta-analysis and forest plot of the parallel trials using the dmetar package, but I did not succeed in including the crossover trials. I do have the raw data of most of these crossover trials.
Does anybody know how to add crossover trials to the meta-analysis?
With kind regards,
Vera Belgers
______________________________________________________
VUmc disclaimer : www.vumc.nl/disclaimer<http://www.vumc.nl/disclaimer>
AMC disclaimer : www.amc.nl/disclaimer<http://www.amc.nl/disclaimer>

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=02%7C01%7Cv.belgers%40amsterdamumc.nl%7C460c6129ebd54ce61bb308d858e27bae%7C68dfab1a11bb4cc6beb528d756984fb6%7C0%7C0%7C637357077047001589&sdata=yv4KfT6v%2FaTfTEXar7PgjBuYsy6STJpZjsbeieMTpEU%3D&reserved=0>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://eur04.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=02%7C01%7Cv.belgers%40amsterdamumc.nl%7C460c6129ebd54ce61bb308d858e27bae%7C68dfab1a11bb4cc6beb528d756984fb6%7C0%7C0%7C637357077047001589&sdata=YwGAWSIcazrcvZ%2B7sSC2CoaUvffAEh6Gt2dr45lweYo%3D&reserved=0>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Sep 15 22:18:16 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 16 Sep 2020 08:18:16 +1200
Subject: [R] How to represent the effect of one covariate on regression
 results?
In-Reply-To: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
References: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
Message-ID: <CAB8pepzBPAyU0OpA+Et_QrZUM8j_jV8HzKWiXY_eQLn7-ymkng@mail.gmail.com>

> My question is how do I present/plot the effect of covariate "TD" in
> the example it has "P" equal to 3.32228e-12 for all IDs in the
> resulting file so that I show how much effect covariate "TD" has on
> the analysis. Should I run another regression without covariate "TD"

I'll take a second shot in the dark:

There is R^2, and a number of generalizations.
(The most common of which, is probably adjusted R^2).
And there are various other goodness of fit tests.

https://en.wikipedia.org/wiki/Goodness_of_fit
https://en.wikipedia.org/wiki/Coefficient_of_determination

You could fit two models (one with a particular variable included, and
one without), and compare how the statistic changes.

However, I'm probably going to get told off, for going off-topic.
So, unless any further questions are specific to R programming, I
don't think I'm going to contribute further.

Also, I'd recommend you read some notes on statistical modelling, or
consult an expert, or both.
And I suspect there are additional considerations modelling genetic data.


From kweb|h@| @end|ng |rom gm@||@com  Tue Sep 15 22:13:02 2020
From: kweb|h@| @end|ng |rom gm@||@com (Fred Kwebiha)
Date: Tue, 15 Sep 2020 23:13:02 +0300
Subject: [R] Unnesting JSON using R
Message-ID: <CAED7jgNJ3354JX3Ap9rfu-zovqnA9GNxBfRjX8FjgTiVjWcw5Q@mail.gmail.com>

Source=https://jsonformatter.org/e038ec

The above is nested json.

I want the output to be as below
dataElements.name,dataElements.id,categoryOptionCombos.name,categoryOptionCombos.id

Any help in r?
*Best Regards,*

*FRED KWEBIHA*
*+256-782-746-154*

	[[alternative HTML version deleted]]


From @gent@ @end|ng |rom medd@t@|nc@com  Wed Sep 16 01:44:11 2020
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Tue, 15 Sep 2020 19:44:11 -0400
Subject: [R] 
 [R-pkgs] salesforcer v0.2.2: An Implementation of Salesforce
 APIs Using Tidy Principles
In-Reply-To: <CACv7DjrMyugPt1baeCpbPWqbfpEE83_YrenWciHkUt8V0jHFSA@mail.gmail.com>
References: <CACv7DjrMyugPt1baeCpbPWqbfpEE83_YrenWciHkUt8V0jHFSA@mail.gmail.com>
Message-ID: <0A789356-AAFE-4090-95A2-14EA84503A04@meddatainc.com>

On September 13, 2020 6:42:18 AM EDT, "Steven M. Mortimer" <mortimer.steven.m at gmail.com> wrote:
>The {salesforcer} package allows users to query and analyze Salesforce
>data
>and administer their Org's records and object metadata (fields,
>triggers,
>layouts). It has been three years in the making to map multiple
>Salesforce Platform
>APIs for use in R. The package implements the REST, SOAP, Bulk 1.0,
>Bulk
>2.0, Metadata, and Reports and Dashboards APIs. If you or your
>colleagues
>maintain or analyze Salesforce data, then I would greatly appreciate
>your
>use and feedback of this package. Thank you.
>
>Sincerely,
>Steven M. Mortimer
>
>CRAN: https://cran.r-project.org/package=salesforcer
>GitHub: https://github.com/StevenMMortimer/salesforcer
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-packages mailing list
>R-packages at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-packages
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

That sounds great. Is there any similar package that works with SuiteCRM or SugarCRM?


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 16 02:06:37 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 16 Sep 2020 10:06:37 +1000
Subject: [R] X axis labels are not fully shown when using pareto.chart
 function
In-Reply-To: <CAMOcQfMvjEuE9EFFC0W_W3XQHP9jmFEX8W6338Cek0YY8xgUgQ@mail.gmail.com>
References: <CAMOcQfMvjEuE9EFFC0W_W3XQHP9jmFEX8W6338Cek0YY8xgUgQ@mail.gmail.com>
Message-ID: <CA+8X3fWZwn9FUfAvbtLCxJRYZuZ4fx1c2Fx4E=L7mu+9Tfa0ag@mail.gmail.com>

Hi Paul,
This looks very familiar to me, but I'll send my previous suggestion.

library(qcc)
x11(width=13,height=5)
pareto.chart(dataset2$Points,xaxt="n")
library(plotrix)
staxlab(1,at=seq(0.035,0.922,length.out=140),
 labels=substr(dataset2$School,1,20),srt=90,cex=0.5)

Jim

On Wed, Sep 16, 2020 at 2:53 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> Hope you are doing well. I am currently using R version 3.6.2. I installed
> and loaded package qcc by Mr. Luca Scrucca.
>
> Hopefully someone can tell me if there is a workaround for the issue I am
> experiencing.
>
> I generated the pareto chart using qcc?s pareto.chart function, but when
> the graph gets generated, the x-axis labels aren?t fully shown (some labels
> get truncated), and so the text can?t be viewed properly.
>
> Is there any way to adjust the x-axis labels (font and orientation), so
> that they can be easily shown?
>
> This is the structure of my data:
>
> str(dataset2)
> 'data.frame':   140 obs. of  2 variables:
>  $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
> 106 65 17 ...
>  $ Points: num  55 43 24 21 20 20 18 17 16 16 ...
>
>
> Below is the dput() of my dataset.
>
> dput(dataset2)
> structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
> 116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
> 114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
> 14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
> 95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
> 125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
> 80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
> 5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
> 32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
> 99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
> 134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
> 69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
> 91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
> "Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
> "Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
> "Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
> "Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
> "Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
> "Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
> "Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
> "Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
> "David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
> "El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
> "El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
> "Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
> "Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
> Espinar",
> "Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
> "La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
> "Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
> "Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
> "Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
> "Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
> "Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
> "Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
> "Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
> "Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
> "R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
> "Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
> "San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
> Porres",
> "Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
> "Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
> "Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
> ), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
> 17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
> 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
> 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
> ), class = "data.frame")
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep 16 02:12:26 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 15 Sep 2020 17:12:26 -0700
Subject: [R] Cross-posted was Re:  Unnesting JSON using R
In-Reply-To: <CAED7jgNJ3354JX3Ap9rfu-zovqnA9GNxBfRjX8FjgTiVjWcw5Q@mail.gmail.com>
References: <CAED7jgNJ3354JX3Ap9rfu-zovqnA9GNxBfRjX8FjgTiVjWcw5Q@mail.gmail.com>
Message-ID: <509cf25d-4942-53ef-d00d-0be6d475ad62@comcast.net>

Cross-posting is deprecated on r-help. Please don't do it again.


And it was already answered on StackOverflow.


-- 

David.

On 9/15/20 1:13 PM, Fred Kwebiha wrote:
> Source=https://jsonformatter.org/e038ec
>
> The above is nested json.
>
> I want the output to be as below
> dataElements.name,dataElements.id,categoryOptionCombos.name,categoryOptionCombos.id
>
> Any help in r?
> *Best Regards,*
>
> *FRED KWEBIHA*
> *+256-782-746-154*
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep 16 02:59:25 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 15 Sep 2020 17:59:25 -0700
Subject: [R] How to represent the effect of one covariate on regression
 results?
In-Reply-To: <CAF9-5jNRUj35qbB-14MGVOZOHQkcNPmop7waO7GwKNfc6fGQ3g@mail.gmail.com>
References: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
 <16955b86-0e7c-f124-4070-e24fee6e5c5b@comcast.net>
 <CAF9-5jNRUj35qbB-14MGVOZOHQkcNPmop7waO7GwKNfc6fGQ3g@mail.gmail.com>
Message-ID: <22fea7bc-5e0d-ec52-f9a4-ed9548b51fdc@comcast.net>


On 9/15/20 8:57 AM, Ana Marija wrote:
> Hi Abby and David,
>
> Thanks for the useful tips! I will check those.
>
> I completed the regression analysis in plink (as R would be very slow
> for my sample size) but as I mentioned I need to determine the
> influence of a specific covariate in my results and Plink is of no
> help there.
>
> I did Pearson correlation analysis for P values which I got in
> regression with and without my covariate of interest and I got this:
>
>> cor.test(tt$P_TD, tt$P_noTD, method = "pearson", conf.level = 0.95)
>      Pearson's product-moment correlation
>
> data:  tt$P_TD and tt$P_noTD
> t = 20.17, df = 283, p-value < 2.2e-16
> alternative hypothesis: true correlation is not equal to 0
> 95 percent confidence interval:
>   0.7156134 0.8117108
> sample estimates:
>        cor
> 0.7679493
>
> I can see the p values are very correlated in those two instances. Can
> I conclude that my covariate then doesn't have a huge effect or what
> kind of conclusion I can draw from that?


I do not think it follows from the correlation of p-values that your 
covariate "does not have a huge effect". P-values are not really data, 
although they are random values. A simulation study of this would 
require a much better description of the original dataset. Again, that 
is something that the users of Plink are more likely to be able to 
intuit than are we. I still do not see why this question is not being 
addressed to the users of the software from which you are deriving your 
"data".


-- 

David.

>
> Thanks for all your help
> Ana
>
>
>
> On Tue, Sep 15, 2020 at 1:26 AM David Winsemius <dwinsemius at comcast.net> wrote:
>> There is a user-group for PLINK, easily found by looking at the page you
>> cited. This is not the correct place to submit such questions.
>>
>>
>> https://groups.google.com/g/plink2-users?pli=1
>>
>>
>> --
>>
>> David.
>>
>> On 9/14/20 6:29 AM, Ana Marija wrote:
>>> Hello,
>>>
>>> I was running association analysis using --glm genotypic from:
>>> https://www.cog-genomics.org/plink/2.0/assoc with these covariates:
>>> sex,age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,TD,array,HBA1C. The
>>> result looks like this:
>>>
>>>       #CHROM    POS    ID    REF    ALT    A1    TEST    OBS_CT    BETA
>>>     SE    Z_OR_F_STAT    P    ERRCODE
>>>       10    135434303    rs11101905    G    A    A    ADD    11863
>>> -0.110733    0.0986981    -1.12193    0.261891    .
>>>       10    135434303    rs11101905    G    A    A    DOMDEV    11863
>>> 0.079797    0.111004    0.718868    0.472222    .
>>>       10    135434303    rs11101905    G    A    A    sex=Female
>>> 11863    -0.120404    0.0536069    -2.24605    0.0247006    .
>>>       10    135434303    rs11101905    G    A    A    age    11863
>>> 0.00524501    0.00391528    1.33963    0.180367    .
>>>       10    135434303    rs11101905    G    A    A    PC1    11863
>>> -0.0191779    0.0166868    -1.14928    0.25044    .
>>>       10    135434303    rs11101905    G    A    A    PC2    11863
>>> -0.0269939    0.0173086    -1.55957    0.118863    .
>>>       10    135434303    rs11101905    G    A    A    PC3    11863
>>> 0.0115207    0.0168076    0.685448    0.493061    .
>>>       10    135434303    rs11101905    G    A    A    PC4    11863
>>> 9.57832e-05    0.0124607    0.0076868    0.993867    .
>>>       10    135434303    rs11101905    G    A    A    PC5    11863
>>> -0.00191047    0.00543937    -0.35123    0.725416    .
>>>       10    135434303    rs11101905    G    A    A    PC6    11863
>>> -0.0103309    0.0159879    -0.646172    0.518168    .
>>>       10    135434303    rs11101905    G    A    A    PC7    11863
>>> 0.00790997    0.0144025    0.549207    0.582863    .
>>>       10    135434303    rs11101905    G    A    A    PC8    11863
>>> -0.00205639    0.0142709    -0.144096    0.885424    .
>>>       10    135434303    rs11101905    G    A    A    PC9    11863
>>> -0.00873771    0.0057239    -1.52653    0.126878    .
>>>       10    135434303    rs11101905    G    A    A    PC10    11863
>>> 0.0116197    0.0123826    0.938388    0.348045    .
>>>       10    135434303    rs11101905    G    A    A    TD    11863
>>> -0.670026    0.0962216    -6.96337    3.32228e-12    .
>>>       10    135434303    rs11101905    G    A    A    array=Biobank
>>> 11863    0.160666    0.073631    2.18205    0.0291062    .
>>>       10    135434303    rs11101905    G    A    A    HBA1C    11863
>>> 0.0265933    0.00168758    15.7583    6.0236e-56    .
>>>       10    135434303    rs11101905    G    A    A    GENO_2DF    11863
>>>     NA    NA    0.726514    0.483613    .
>>>
>>> This results is shown just for one ID (rs11101905) there is about 2
>>> million of those in the resulting file.
>>>
>>> My question is how do I present/plot the effect of covariate "TD" in
>>> the example it has "P" equal to 3.32228e-12 for all IDs in the
>>> resulting file so that I show how much effect covariate "TD" has on
>>> the analysis. Should I run another regression without covariate "TD"
>>> and than do scatter plot of P values with and without "TD" covariate
>>> or there is a better way to do this from the data I already have?
>>>
>>> Thanks
>>> Ana
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Sep 16 03:11:07 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 15 Sep 2020 20:11:07 -0500
Subject: [R] How to represent the effect of one covariate on regression
 results?
In-Reply-To: <22fea7bc-5e0d-ec52-f9a4-ed9548b51fdc@comcast.net>
References: <CAF9-5jMh2jRKLbZxiXktA7GDfJSuka7kVRrybETkre_FC=e8cg@mail.gmail.com>
 <16955b86-0e7c-f124-4070-e24fee6e5c5b@comcast.net>
 <CAF9-5jNRUj35qbB-14MGVOZOHQkcNPmop7waO7GwKNfc6fGQ3g@mail.gmail.com>
 <22fea7bc-5e0d-ec52-f9a4-ed9548b51fdc@comcast.net>
Message-ID: <CAF9-5jN3MKdZ86uRHRzy13sj1TZAxFba2uxGf+OpCKQb-BGrhA@mail.gmail.com>

Hi David,

thanks for the useful insight I did of course wrote to plink user
group but no answer there. I guess they are more concerned about how
to run commands with plink as oppose to interpret results.

What I can tell about my cohort is that about 80% of cases had Type 2
diabetes while about 8% had Type 1. (my TD covariate is reference for
the type of diabetes) In the attach is the description of the data.

Cheers,
Ana

On Tue, Sep 15, 2020 at 7:59 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
>
> On 9/15/20 8:57 AM, Ana Marija wrote:
> > Hi Abby and David,
> >
> > Thanks for the useful tips! I will check those.
> >
> > I completed the regression analysis in plink (as R would be very slow
> > for my sample size) but as I mentioned I need to determine the
> > influence of a specific covariate in my results and Plink is of no
> > help there.
> >
> > I did Pearson correlation analysis for P values which I got in
> > regression with and without my covariate of interest and I got this:
> >
> >> cor.test(tt$P_TD, tt$P_noTD, method = "pearson", conf.level = 0.95)
> >      Pearson's product-moment correlation
> >
> > data:  tt$P_TD and tt$P_noTD
> > t = 20.17, df = 283, p-value < 2.2e-16
> > alternative hypothesis: true correlation is not equal to 0
> > 95 percent confidence interval:
> >   0.7156134 0.8117108
> > sample estimates:
> >        cor
> > 0.7679493
> >
> > I can see the p values are very correlated in those two instances. Can
> > I conclude that my covariate then doesn't have a huge effect or what
> > kind of conclusion I can draw from that?
>
>
> I do not think it follows from the correlation of p-values that your
> covariate "does not have a huge effect". P-values are not really data,
> although they are random values. A simulation study of this would
> require a much better description of the original dataset. Again, that
> is something that the users of Plink are more likely to be able to
> intuit than are we. I still do not see why this question is not being
> addressed to the users of the software from which you are deriving your
> "data".
>
>
> --
>
> David.
>
> >
> > Thanks for all your help
> > Ana
> >
> >
> >
> > On Tue, Sep 15, 2020 at 1:26 AM David Winsemius <dwinsemius at comcast.net> wrote:
> >> There is a user-group for PLINK, easily found by looking at the page you
> >> cited. This is not the correct place to submit such questions.
> >>
> >>
> >> https://groups.google.com/g/plink2-users?pli=1
> >>
> >>
> >> --
> >>
> >> David.
> >>
> >> On 9/14/20 6:29 AM, Ana Marija wrote:
> >>> Hello,
> >>>
> >>> I was running association analysis using --glm genotypic from:
> >>> https://www.cog-genomics.org/plink/2.0/assoc with these covariates:
> >>> sex,age,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10,TD,array,HBA1C. The
> >>> result looks like this:
> >>>
> >>>       #CHROM    POS    ID    REF    ALT    A1    TEST    OBS_CT    BETA
> >>>     SE    Z_OR_F_STAT    P    ERRCODE
> >>>       10    135434303    rs11101905    G    A    A    ADD    11863
> >>> -0.110733    0.0986981    -1.12193    0.261891    .
> >>>       10    135434303    rs11101905    G    A    A    DOMDEV    11863
> >>> 0.079797    0.111004    0.718868    0.472222    .
> >>>       10    135434303    rs11101905    G    A    A    sex=Female
> >>> 11863    -0.120404    0.0536069    -2.24605    0.0247006    .
> >>>       10    135434303    rs11101905    G    A    A    age    11863
> >>> 0.00524501    0.00391528    1.33963    0.180367    .
> >>>       10    135434303    rs11101905    G    A    A    PC1    11863
> >>> -0.0191779    0.0166868    -1.14928    0.25044    .
> >>>       10    135434303    rs11101905    G    A    A    PC2    11863
> >>> -0.0269939    0.0173086    -1.55957    0.118863    .
> >>>       10    135434303    rs11101905    G    A    A    PC3    11863
> >>> 0.0115207    0.0168076    0.685448    0.493061    .
> >>>       10    135434303    rs11101905    G    A    A    PC4    11863
> >>> 9.57832e-05    0.0124607    0.0076868    0.993867    .
> >>>       10    135434303    rs11101905    G    A    A    PC5    11863
> >>> -0.00191047    0.00543937    -0.35123    0.725416    .
> >>>       10    135434303    rs11101905    G    A    A    PC6    11863
> >>> -0.0103309    0.0159879    -0.646172    0.518168    .
> >>>       10    135434303    rs11101905    G    A    A    PC7    11863
> >>> 0.00790997    0.0144025    0.549207    0.582863    .
> >>>       10    135434303    rs11101905    G    A    A    PC8    11863
> >>> -0.00205639    0.0142709    -0.144096    0.885424    .
> >>>       10    135434303    rs11101905    G    A    A    PC9    11863
> >>> -0.00873771    0.0057239    -1.52653    0.126878    .
> >>>       10    135434303    rs11101905    G    A    A    PC10    11863
> >>> 0.0116197    0.0123826    0.938388    0.348045    .
> >>>       10    135434303    rs11101905    G    A    A    TD    11863
> >>> -0.670026    0.0962216    -6.96337    3.32228e-12    .
> >>>       10    135434303    rs11101905    G    A    A    array=Biobank
> >>> 11863    0.160666    0.073631    2.18205    0.0291062    .
> >>>       10    135434303    rs11101905    G    A    A    HBA1C    11863
> >>> 0.0265933    0.00168758    15.7583    6.0236e-56    .
> >>>       10    135434303    rs11101905    G    A    A    GENO_2DF    11863
> >>>     NA    NA    0.726514    0.483613    .
> >>>
> >>> This results is shown just for one ID (rs11101905) there is about 2
> >>> million of those in the resulting file.
> >>>
> >>> My question is how do I present/plot the effect of covariate "TD" in
> >>> the example it has "P" equal to 3.32228e-12 for all IDs in the
> >>> resulting file so that I show how much effect covariate "TD" has on
> >>> the analysis. Should I run another regression without covariate "TD"
> >>> and than do scatter plot of P values with and without "TD" covariate
> >>> or there is a better way to do this from the data I already have?
> >>>
> >>> Thanks
> >>> Ana
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: data.png
Type: image/png
Size: 57291 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200915/2045e2f5/attachment.png>

From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Sep 16 03:36:40 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 15 Sep 2020 20:36:40 -0500
Subject: [R] X axis labels are not fully shown when using pareto.chart
 function
In-Reply-To: <CA+8X3fWZwn9FUfAvbtLCxJRYZuZ4fx1c2Fx4E=L7mu+9Tfa0ag@mail.gmail.com>
References: <CAMOcQfMvjEuE9EFFC0W_W3XQHP9jmFEX8W6338Cek0YY8xgUgQ@mail.gmail.com>
 <CA+8X3fWZwn9FUfAvbtLCxJRYZuZ4fx1c2Fx4E=L7mu+9Tfa0ag@mail.gmail.com>
Message-ID: <CAMOcQfPyym4wYUkS=3fGmu9R-CirAAGGMZuEzTbtXCkem+P=Gw@mail.gmail.com>

Dear Jim,

Thank you so much for your valuable and kind reply. I will try what you
suggest and will let you and the group members how that goes.

Can the resolution you suggest be applied whenever I encounter an issue
like the one I just described (to make x-axis labels clearly visible)? I
imagine if work with some other x-axis labels I'd just have to play around
with the width, height, srt and cex parameters?

Best regards,

Paul


El mar., 15 de septiembre de 2020 7:06 p. m., Jim Lemon <
drjimlemon at gmail.com> escribi?:

> Hi Paul,
> This looks very familiar to me, but I'll send my previous suggestion.
>
> library(qcc)
> x11(width=13,height=5)
> pareto.chart(dataset2$Points,xaxt="n")
> library(plotrix)
> staxlab(1,at=seq(0.035,0.922,length.out=140),
>  labels=substr(dataset2$School,1,20),srt=90,cex=0.5)
>
> Jim
>
> On Wed, Sep 16, 2020 at 2:53 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >
> > Dear friends,
> >
> > Hope you are doing well. I am currently using R version 3.6.2. I
> installed
> > and loaded package qcc by Mr. Luca Scrucca.
> >
> > Hopefully someone can tell me if there is a workaround for the issue I am
> > experiencing.
> >
> > I generated the pareto chart using qcc?s pareto.chart function, but when
> > the graph gets generated, the x-axis labels aren?t fully shown (some
> labels
> > get truncated), and so the text can?t be viewed properly.
> >
> > Is there any way to adjust the x-axis labels (font and orientation), so
> > that they can be easily shown?
> >
> > This is the structure of my data:
> >
> > str(dataset2)
> > 'data.frame':   140 obs. of  2 variables:
> >  $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116
> 35
> > 106 65 17 ...
> >  $ Points: num  55 43 24 21 20 20 18 17 16 16 ...
> >
> >
> > Below is the dput() of my dataset.
> >
> > dput(dataset2)
> > structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
> > 116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
> > 114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
> > 14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
> > 95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
> > 125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
> > 80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
> > 5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
> > 32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
> > 99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
> > 134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
> > 69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
> > 91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
> > "Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
> > "Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo
> Boquete",
> > "Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
> > "Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
> > "Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
> > "Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
> > "Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
> > "Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
> > "David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
> > "El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
> > "El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
> > "Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
> > "Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
> > Espinar",
> > "Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
> > "La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las
> Cumbres",
> > "Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
> > "Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
> > "Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
> > "Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
> > "Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
> > "Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
> > "Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
> > "Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
> > "R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
> > "Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
> > "San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
> > Porres",
> > "Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
> > "Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
> > "Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
> > ), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
> > 17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
> > 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
> > 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> > 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> > 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> > 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
> > ), class = "data.frame")
> >
> > Best regards,
> >
> > Paul
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 16 06:54:44 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 16 Sep 2020 14:54:44 +1000
Subject: [R] X axis labels are not fully shown when using pareto.chart
 function
In-Reply-To: <CAMOcQfPyym4wYUkS=3fGmu9R-CirAAGGMZuEzTbtXCkem+P=Gw@mail.gmail.com>
References: <CAMOcQfMvjEuE9EFFC0W_W3XQHP9jmFEX8W6338Cek0YY8xgUgQ@mail.gmail.com>
 <CA+8X3fWZwn9FUfAvbtLCxJRYZuZ4fx1c2Fx4E=L7mu+9Tfa0ag@mail.gmail.com>
 <CAMOcQfPyym4wYUkS=3fGmu9R-CirAAGGMZuEzTbtXCkem+P=Gw@mail.gmail.com>
Message-ID: <CA+8X3fWv0q0AVihVkKPA9ZD4my8T4X09RGQNfAw3Bh70ktZjLA@mail.gmail.com>

Hi Paul,
It is a contest between the quantity of information and legibility.
You have 140 labels to place on the x-axis in your plot and I barely
managed it by almost doubling the width of the plot, halving the size
of the font and truncating the labels to a maximum of 20 characters.
Unless you want to follow something like Google Maps, where the
information springs up in a little balloon, you are close to the
limits of a static display. That said, you are correct in saying that
staxlab will cram a lot of information at the edges of a plot.

Jim

On Wed, Sep 16, 2020 at 11:36 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear Jim,
>
> Thank you so much for your valuable and kind reply. I will try what you suggest and will let you and the group members how that goes.
>
> Can the resolution you suggest be applied whenever I encounter an issue like the one I just described (to make x-axis labels clearly visible)? I imagine if work with some other x-axis labels I'd just have to play around with the width, height, srt and cex parameters?
>
> Best regards,
>
> Paul
>
>
> El mar., 15 de septiembre de 2020 7:06 p. m., Jim Lemon <drjimlemon at gmail.com> escribi?:
>>
>> Hi Paul,
>> This looks very familiar to me, but I'll send my previous suggestion.
>>
>> library(qcc)
>> x11(width=13,height=5)
>> pareto.chart(dataset2$Points,xaxt="n")
>> library(plotrix)
>> staxlab(1,at=seq(0.035,0.922,length.out=140),
>>  labels=substr(dataset2$School,1,20),srt=90,cex=0.5)
>>
>> Jim
>>
>> On Wed, Sep 16, 2020 at 2:53 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>> >
>> > Dear friends,
>> >
>> > Hope you are doing well. I am currently using R version 3.6.2. I installed
>> > and loaded package qcc by Mr. Luca Scrucca.
>> >
>> > Hopefully someone can tell me if there is a workaround for the issue I am
>> > experiencing.
>> >
>> > I generated the pareto chart using qcc?s pareto.chart function, but when
>> > the graph gets generated, the x-axis labels aren?t fully shown (some labels
>> > get truncated), and so the text can?t be viewed properly.
>> >
>> > Is there any way to adjust the x-axis labels (font and orientation), so
>> > that they can be easily shown?
>> >
>> > This is the structure of my data:
>> >
>> > str(dataset2)
>> > 'data.frame':   140 obs. of  2 variables:
>> >  $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
>> > 106 65 17 ...
>> >  $ Points: num  55 43 24 21 20 20 18 17 16 16 ...
>> >
>> >
>> > Below is the dput() of my dataset.
>> >
>> > dput(dataset2)
>> > structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
>> > 116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
>> > 114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
>> > 14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
>> > 95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
>> > 125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
>> > 80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
>> > 5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
>> > 32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
>> > 99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
>> > 134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
>> > 69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
>> > 91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
>> > "Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
>> > "Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
>> > "Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
>> > "Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
>> > "Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
>> > "Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
>> > "Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
>> > "Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
>> > "David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
>> > "El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
>> > "El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
>> > "Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
>> > "Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
>> > Espinar",
>> > "Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
>> > "La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
>> > "Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
>> > "Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
>> > "Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
>> > "Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
>> > "Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
>> > "Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
>> > "Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
>> > "Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
>> > "R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
>> > "Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
>> > "San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
>> > Porres",
>> > "Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
>> > "Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
>> > "Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
>> > ), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
>> > 17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
>> > 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
>> > 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
>> > 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
>> > 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>> > 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
>> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
>> > ), class = "data.frame")
>> >
>> > Best regards,
>> >
>> > Paul
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep 16 13:48:37 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 16 Sep 2020 11:48:37 +0000
Subject: [R] Loop for two columns and 154 rows
In-Reply-To: <792136234.4533947.1600170495895@mail.yahoo.com>
References: <1701769557.4495505.1600160473189.ref@mail.yahoo.com>
 <1701769557.4495505.1600160473189@mail.yahoo.com>
 <4fa52dcf9fcb4840a353c9ead96a7acc@SRVEXCHCM1302.precheza.cz>
 <829e992a1fa2418fb71a65ebaabc1255@SRVEXCHCM1302.precheza.cz>
 <792136234.4533947.1600170495895@mail.yahoo.com>
Message-ID: <cdf9e73c7a6a4c90bb2e768ba47e2002@SRVEXCHCM1302.precheza.cz>

Hi

 

It is recommended to keep your emails in Rhelp, there are others who could give you answer.

 

If I understand correctly you want to take 2 lines in your data frame and test them if they are same but just reversed.

 

One option could be to split the whole data frame in chunks. Based on your example

 

test <- structure(list(V1 = c("G1", "G2", "G3", "G1", "G20", "G21"), 

    V2 = c("G2", "G1", "G1", "G3", "G21", "G16")), class = "data.frame", row.names = c(NA, -6L))

test.l <- split(test, rep(1:3, each=2))

res <- rep(NA, length(test.l))

for (i in 1:length(test.l)) res[i] <- prod(as.numeric(factor(unlist(test.l[[i]]))))

test$column3 <- rep(res==4, each=2)*1

 

Maybe some clever matrix operations could do it in more elegant way.

 

Cheers

Petr

 

S pozdravem | Best Regards

RNDr. Petr PIKAL
Vedouc? V?zkumu a v?voje | Research Manager

PRECHEZA a.s.
n?b?. Dr. Edvarda Bene?e 1170/24 | 750 02 P?erov | Czech Republic
Tel: +420 581 252 256 | GSM: +420 724 008 364
 <mailto:petr.pikal at precheza.cz> petr.pikal at precheza.cz |  <https://www.precheza.cz/> www.precheza.cz

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:  <https://www.precheza.cz/zasady-ochrany-osobnich-udaju/> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website:  <https://www.precheza.cz/en/personal-data-protection-principles/> https://www.precheza.cz/en/personal-data-protection-principles/

D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:  <https://www.precheza.cz/01-dovetek/> https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer:  <https://www.precheza.cz/en/01-disclaimer/> https://www.precheza.cz/en/01-disclaimer/

 

From: Hesham A. AL-bukhaiti <heshamibb at yahoo.com> 
Sent: Tuesday, September 15, 2020 1:48 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] Loop for two columns and 154 rows

 


thanks petr v much 
i attached my problem in word and my data 
i want take all elements them have relations not just G1 and G2 this just example test (G1 AND G2) i want make loop to take all elements:

G1 G2 1 
G2 G1 1
G3 G1 1
G1 G3 1
G20 G21 0
G21 G16 0 
(notice (G1 and G2 have relation and G3 and G1 also have but G20 ,G21,G16 do not have this relations we put 0 ,

(i have G1 to G154) them make 23400 relation i want to know wich forn theses relations are true (1) or not (0)

i hope you can help me.

On Tuesday, September 15, 2020, 02:54:27 AM PDT, PIKAL Petr <petr.pikal at precheza.cz <mailto:petr.pikal at precheza.cz> > wrote: 

 

 

Sorry, forgot to copy to r help.

Petr


> -----Original Message-----
> From: PIKAL Petr
> Sent: Tuesday, September 15, 2020 11:53 AM
> To: 'Hesham A. AL-bukhaiti' <heshamibb at yahoo.com <mailto:heshamibb at yahoo.com> >
> Subject: RE: [R] Loop for two columns and 154 rows
> 
> Hi
> 
> Your mail is unreadable, post in plain text not HTML.
> 
> If I deciphered it correcttly you want all values which have G1 in column 1 and
> G2 in column 2 or G2 in column 1 and G1 in column to produce 1 all other
> produce 0
> 
> So if your data frame is named truth
> 
> truth$column3 <- ((truth[,1] =="G1" & truth[,2] =="G2") | (truth[,2] =="G1" &
> truth[,1] =="G2")) * 1
> 
> Cheers
> Petr
> 
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of Hesham A. AL-
> > bukhaiti via R-help
> > Sent: Tuesday, September 15, 2020 11:01 AM
> > To: r-help at r-project.org <mailto:r-help at r-project.org> 
> > Subject: [R] Loop for two columns and 154 rows
> >
> >  Dears in R :i have this code in R:
> > # this for do not work true (i tried )out<-read.csv("outbr.csv") truth<-
> > out[,seq(1,2)]truth<-
> > cbind(as.character(truth[,1]),as.character(truth[,2])
> ,as.data.frame(rep(
> > 0,,dim(out)[1])));for (j in 1:2) {  for (i in 1:20) {    truth[(truth[,1]== truth[j,i] &
> > truth[,2]== truth[j,i+1]) |        (truth[,1]== truth[j+1,i] & truth[,2]==
> > truth[j+1,i+1]),3]<-1  } }
> > #truth<-out[,seq(1,2)]#truth<-
> > cbind(as.character(truth[,1]),as.character(truth[,2])  #
> ,as.data.frame(rep
> > (0,,dim(out)[1])));#truth[(truth[,1]=="G2" & truth[,2]=="G1") |
> (truth[,1]=="G1"
> > & truth[,2]=="G2"),3]<-1
> >
> #################################################################
> > #########3
> >
> > I have file have two columns  . data in this file is text just (G1,G2,G3? to
> > G154). one element  can repeat, no problem ,so  we have 23562 rows in two
> > columns (for 154 elements) like :
> > Column1  column2    column3
> > G1                G4            0
> > G4                G6            0
> > G100          G7            1G7              G100    .    1.                      ..                      .
> I
> > want to make third column (1 or 0) based on this condition:
> > IF  truth[,1]==?G1? & truth[,2]==?G2? | truth[,1]==?G2? & truth[,2]==?G1? <-
> > 1.then In the third column write 1 otherwise write 0.G1 and G2  just
> > exampl  (indeed  i want test If two each elements  has a reciprocal
> > relationship(G1 to G2 and G2 to G1or not) Best regHesham
> >
> >
> >
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From |uc@@@crucc@ @end|ng |rom un|pg@|t  Wed Sep 16 16:49:02 2020
From: |uc@@@crucc@ @end|ng |rom un|pg@|t (Luca Scrucca)
Date: Wed, 16 Sep 2020 16:49:02 +0200
Subject: [R] X axis labels are not fully shown when using pareto.chart
 function
In-Reply-To: <CAMOcQfMvjEuE9EFFC0W_W3XQHP9jmFEX8W6338Cek0YY8xgUgQ@mail.gmail.com>
References: <CAMOcQfMvjEuE9EFFC0W_W3XQHP9jmFEX8W6338Cek0YY8xgUgQ@mail.gmail.com>
Message-ID: <582C5382-4770-45B6-8030-73CFD7710FC1@unipg.it>

The following works:

library(qcc)
x = dataset2$Points 
names(x) = dataset2$School
par(oma = c(2,0,0,0))
pareto.chart(x)
             
You may need to adjust the oma parameter. 

BTW, next time please provide a reproducible example. I spent more time to figure out which is the correct variable/label to plot than to find the solution to your problem.

LS


> On 15 Sep 2020, at 18:52, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> Hope you are doing well. I am currently using R version 3.6.2. I installed and loaded package qcc by Mr. Luca Scrucca.
> 
> Hopefully someone can tell me if there is a workaround for the issue I am experiencing.
> 
> I generated the pareto chart using qcc?s pareto.chart function, but when the graph gets generated, the x-axis labels aren?t fully shown (some labels get truncated), and so the text can?t be viewed properly.
> 
> Is there any way to adjust the x-axis labels (font and orientation), so that they can be easily shown?
> 
> This is the structure of my data:
> 
> str(dataset2)
> 'data.frame':   140 obs. of  2 variables:
>  $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35 106 65 17 ...
>  $ Points: num  55 43 24 21 20 20 18 17 16 16 ...
> 
> 
> Below is the dput() of my dataset.
> 
> dput(dataset2)
> structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
> 116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
> 114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
> 14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
> 95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
> 125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
> 80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
> 5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
> 32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
> 99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
> 134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
> 69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
> 91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
> "Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
> "Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
> "Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
> "Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
> "Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
> "Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
> "Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
> "Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
> "David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
> "El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
> "El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
> "Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
> "Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo Espinar",
> "Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
> "La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
> "Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
> "Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
> "Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
> "Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
> "Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
> "Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
> "Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
> "Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
> "R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
> "Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
> "San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de Porres",
> "Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
> "Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
> "Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
> ), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
> 17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
> 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
> 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
> ), class = "data.frame")
> 
> Best regards,
> 
> Paul
> 

-- 
--------------------------------------
Luca Scrucca, PhD
Associate Professor of Statistics
Department of Economics 
University of Perugia
Via A. Pascoli, 20
06123 Perugia (Italy)
Tel +39-075-5855229
Fax +39-075-5855950
E-mail luca.scrucca at unipg.it
Web page http://www.stat.unipg.it/luca


From @purd|e@@ @end|ng |rom gm@||@com  Thu Sep 17 09:43:12 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 17 Sep 2020 19:43:12 +1200
Subject: [R] 
 How to reduce the sparseness in a TDM to make a cluster plot
 readable?
In-Reply-To: <c6722f2d-e4a7-f981-0624-4a9a517b76f9@gmail.com>
References: <c6722f2d-e4a7-f981-0624-4a9a517b76f9@gmail.com>
Message-ID: <CAB8pepxx+6kAg5E37w7t7+MChf5xLxE-E9RqRXR3Q-kvCocH8Q@mail.gmail.com>

I'm not familiar with these subjects.
And hopefully, someone who is, will offer some better suggestions.

But to get things started, maybe...
(1) What packages are you using (re: tdm)?
(2) Where does the problem happen, in dist, hclust, the plot method
for hclust, or in the package(s) you are using?
(3) Do you think you could produce a small reproducible example,
showing what is wrong, and explaining you would like it to do instead?

Note that if the problem relates to hclust, or the plot method, then
you should be able to produce a much simpler example.
e.g.

    mycount.matrix <- matrix (rpois (25000, 20),, 5)
    head (mycount.matrix, 3)
    tail (mycount.matrix, 3)

    plot (hclust (dist (mycount.matrix) ) )

On Tue, Sep 15, 2020 at 6:54 AM Andrew <phaedrusv at gmail.com> wrote:
>
> Hello all
>
> I am doing some text mining on a set of five plain text files and have
> run into a snag when I run hclust in that there are just too many leaves
> for anything to be read. It returns a solid black line.
>
> The texts have been converted into a TDM which has a dim of 5,292 and 5
> (as per 5 docs).
>
> My code for removing sparsity is as follows:
>
>  > tdm2 <- removeSparseTerms(tdm, sparse=0.99999)
>
>  > inspect(tdm2)
>
> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
> Non-/sparse entries: 10415/16045
> Sparsity           : 61%
> Maximal term length: 22
> Weighting          : term frequency (tf)
>
> While the tf-idf weighting returns this when 0.99999 sparseness is removed:
>
>  > inspect(tdm.tfidf)
> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
> Non-/sparse entries: 7915/18545
> Sparsity           : 70%
> Maximal term length: 22
> Weighting          : term frequency - inverse document frequency
> (normalized) (tf-idf)
>
> I have experimented by decreasing the value I use for decreasing
> sparseness, and that helps a bit, for example:
>
>  > tdm2 <- removeSparseTerms(tdm, sparse=0.215)
>  > inspect(tdm2)
> <<TermDocumentMatrix (terms: 869, documents: 5)>>
> Non-/sparse entries: 3976/369
> Sparsity           : 8%
> Maximal term length: 14
> Weighting          : term frequency (tf)
>
> But, no matter what I do, the resulting plot is unreadable. The code for
> plotting the cluster is:
>
>  > hc <- hclust(dist(tdm2, method = "euclidean"), method = "complete")
>  > plot(hc, yaxt = 'n', main = "Hierarchical clustering")
>
> Can someone kindly either advise me what I am doing wrong and/ or
> signpost me to some detailed info on how to fix this.
>
> Many thanks in anticipation.
>
> Andy
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From joh@n|@@@en @end|ng |rom gm@||@com  Thu Sep 17 15:07:46 2020
From: joh@n|@@@en @end|ng |rom gm@||@com (Johan Lassen)
Date: Thu, 17 Sep 2020 15:07:46 +0200
Subject: [R] linearHypothesis
Message-ID: <CAAqXfsd8+cLDY9Lia4mg6WpCZ8va3wb1cB4d4str5yj56Vrq7Q@mail.gmail.com>

Dear R-users,

I am using the R-function "linearHypothesis" to test if the sum of all
parameters, but the intercept, in a multiple linear regression is different
from zero.
I wonder if it is statistically valid to use the  linearHypothesis-function
for this?
Below is a reproducible example in R. A multiple regression: y =
beta0*t0+beta1*t1+beta2*t2+beta3*t3+beta4*t4

It seems to me that the linearHypothesis function does the calculation as
an F-test on the extra residuals when going from the starting model to a
'subset' model, although all variables in the 'subset' model differ from
the variables in the starting model.
I normally think of a subset model as a model built on the same input data
as the starting model but one variable.

Hence, is this a valid calculation?

Thanks in advance,Johan

# R-code:
y <-
c(101133190,96663050,106866486,97678429,83212348,75719714,77861937,74018478,82181104,68667176,64599495,62414401,63534709,58571865,65222727,60139788,
63355011,57790610,55214971,55535484,55759192,49450719,48834699,51383864,51250871,50629835,52154608,54636478,54942637)

data <-
data.frame(y,"t0"=1,"t1"=1990:2018,"t2"=c(rep(0,12),1:17),"t3"=c(rep(0,17),1:12),"t4"=c(rep(0,23),1:6))

model <- lm(y~t0+t1+t2+t3+t4+0,data=data)

linearHypothesis(model,"t1+t2+t3+t4=0",test=c("F"))

# Reproduce the result from linearHypothesis:
# beta1+beta2+beta3+beta4=0 -> beta4=-(beta1+beta2+beta3) ->
# y=beta0+beta1*t1+beta2*t2+beta3*t3-(beta1+beta2+beta3)*t4
# y = beta0'+beta1'*(t1-t4)+beta2'*(t2-t4)+beta3'*(t3-t4)

data$t1 <- data$t1-data$t4
data$t2 <- data$t2-data$t4
data$t3 <- data$t3-data$t4

model_reduced <- lm(y~t0+t1+t2+t3+0,data=data)

anova(model_reduced,model)

-- 
Johan Lassen

"In the cities people live in time -
in the mountains people live in space" (Budistisk munk).

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep 17 15:55:24 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 17 Sep 2020 09:55:24 -0400
Subject: [R] linearHypothesis
In-Reply-To: <29588_1600348118_08HD8bO2031985_CAAqXfsd8+cLDY9Lia4mg6WpCZ8va3wb1cB4d4str5yj56Vrq7Q@mail.gmail.com>
References: <29588_1600348118_08HD8bO2031985_CAAqXfsd8+cLDY9Lia4mg6WpCZ8va3wb1cB4d4str5yj56Vrq7Q@mail.gmail.com>
Message-ID: <a3aff576-2e35-64ae-399e-f7dfbe6c7310@mcmaster.ca>

Dear Johan,

On 2020-09-17 9:07 a.m., Johan Lassen wrote:
> Dear R-users,
> 
> I am using the R-function "linearHypothesis" to test if the sum of all
> parameters, but the intercept, in a multiple linear regression is different
> from zero.
> I wonder if it is statistically valid to use the  linearHypothesis-function
> for this?

Yes, assuming of course that the hypothesis makes sense.


> Below is a reproducible example in R. A multiple regression: y =
> beta0*t0+beta1*t1+beta2*t2+beta3*t3+beta4*t4
> 
> It seems to me that the linearHypothesis function does the calculation as
> an F-test on the extra residuals when going from the starting model to a
> 'subset' model, although all variables in the 'subset' model differ from
> the variables in the starting model.
> I normally think of a subset model as a model built on the same input data
> as the starting model but one variable.
> 
> Hence, is this a valid calculation?

First, linearHypothesis() doesn't literally fit alternative models, but 
rather tests the linear hypothesis directly from the coefficient 
estimates and their covariance matrix. The test is standard -- look at 
the references in ?linearHypothesis or most texts on linear models.

Second, formulating the hypothesis using alternative models is also 
legitimate, since the second model is a restricted version of the first.

> 
> Thanks in advance,Johan
> 
> # R-code:
> y <-
> c(101133190,96663050,106866486,97678429,83212348,75719714,77861937,74018478,82181104,68667176,64599495,62414401,63534709,58571865,65222727,60139788,
> 63355011,57790610,55214971,55535484,55759192,49450719,48834699,51383864,51250871,50629835,52154608,54636478,54942637)
> 
> data <-
> data.frame(y,"t0"=1,"t1"=1990:2018,"t2"=c(rep(0,12),1:17),"t3"=c(rep(0,17),1:12),"t4"=c(rep(0,23),1:6))
> 
> model <- lm(y~t0+t1+t2+t3+t4+0,data=data)

You need not supply the constant regressor t0 explicitly and suppress 
the intercept -- you'd get the same test from linearHypothesis() for 
lm(y~t1+t2+t3+t4,data=data).

> 
> linearHypothesis(model,"t1+t2+t3+t4=0",test=c("F"))

test = "F" is the default.

> 
> # Reproduce the result from linearHypothesis:
> # beta1+beta2+beta3+beta4=0 -> beta4=-(beta1+beta2+beta3) ->
> # y=beta0+beta1*t1+beta2*t2+beta3*t3-(beta1+beta2+beta3)*t4
> # y = beta0'+beta1'*(t1-t4)+beta2'*(t2-t4)+beta3'*(t3-t4)
> 
> data$t1 <- data$t1-data$t4
> data$t2 <- data$t2-data$t4
> data$t3 <- data$t3-data$t4
> 
> model_reduced <- lm(y~t0+t1+t2+t3+0,data=data)
> 
> anova(model_reduced,model)

Yes, this is equivalent to the test performed by linearHypothesis() 
using the coefficients and their covariances from the original model.

I hope this helps,
  John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/
>


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Thu Sep 17 16:58:10 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Thu, 17 Sep 2020 07:58:10 -0700
Subject: [R] Unnesting JSON using R
In-Reply-To: <CAED7jgNJ3354JX3Ap9rfu-zovqnA9GNxBfRjX8FjgTiVjWcw5Q@mail.gmail.com>
References: <CAED7jgNJ3354JX3Ap9rfu-zovqnA9GNxBfRjX8FjgTiVjWcw5Q@mail.gmail.com>
Message-ID: <CAA99HCww7Tm1UQ+ppeUCYyYtkZedmOCw2=4ERTfchvBNN9CC=g@mail.gmail.com>

Hi Fred, I believe the preferred package is jsonlite:

https://cran.r-project.org/package=jsonlite
https://jeroen.cran.dev/jsonlite/index.html

HTH, Bill.

W. Michels, Ph.D.

On Tue, Sep 15, 2020 at 1:48 PM Fred Kwebiha <kwebihaf at gmail.com> wrote:
>
> Source=https://jsonformatter.org/e038ec
>
> The above is nested json.
>
> I want the output to be as below
> dataElements.name,dataElements.id,categoryOptionCombos.name,categoryOptionCombos.id
>
> Any help in r?
> *Best Regards,*
>
> *FRED KWEBIHA*
> *+256-782-746-154*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @y|v@|n@weber @end|ng |rom he@ge@ch  Thu Sep 17 15:59:33 2020
From: @y|v@|n@weber @end|ng |rom he@ge@ch (Weber Sylvain (HES))
Date: Thu, 17 Sep 2020 13:59:33 +0000
Subject: [R] Seasonal adjustment with seas - Error: X-13 has returned a
 non-zero exist status
Message-ID: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>

Dear all,

I am using function "seas" from package "seasonal" for seasonal adjustment of time series. I am using the latest version of R (4.0.2, 64-bit).
The following lines provide a small working example:
## EXAMPLE ##
library(seasonal)
m <- seas(AirPassengers)
m

On my private laptop, everything is going smoothly, and I obtain the following output:
## OUTPUT ##
Call:
seas(x = AirPassengers)

Coefficients:
          Weekday          Easter[1]         AO1951.May  MA-Nonseasonal-01  
         -0.00295            0.01777            0.10016            0.11562  
   MA-Seasonal-12  
          0.49736  

But on my office computer, I receive the following error message after issuing " m <- seas(AirPassengers)":
## ERROR ##
Error: X-13 has returned a non-zero exist status, which means that the current spec file cannot be processed for an unknown reason.
In addition: Warning message:
In system(cmd, intern = intern, wait = wait | intern, show.output.on.console = wait,  :
  running command 'C:\Windows\system32\cmd.exe /c "\\hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe" C:\Users\SYLVAI~1.WEB\AppData\Local\Temp\Rtmpe0MDE7\x132d0cb8579b9/iofile -n -s' had status 1

A similar issue has been already mentioned in various blogs, for instance:
https://rdrr.io/github/christophsax/seasonal/src/travis/test-x13messages.R
http://freerangestats.info/blog/2015/12/21/m3-and-x13
https://github.com/christophsax/seasonal/issues/154
but I couldn't find any solution yet.

Does anyone have any idea why this issue is occurring?

Thanks very much.

Sylvain


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 17 18:02:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 17 Sep 2020 09:02:09 -0700
Subject: [R] Seasonal adjustment with seas - Error: X-13 has returned a
 non-zero exist status
In-Reply-To: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
References: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
Message-ID: <CAGxFJbTzQY5xnM7ZZYp+-VfUDb9np9qdq=HebBMSz_=ZqkJeHw@mail.gmail.com>

Consider contacting the package maintainer, found by:
maintainer("seasonal") for such a package specific question.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 17, 2020 at 8:46 AM Weber Sylvain (HES) <sylvain.weber at hesge.ch>
wrote:

> Dear all,
>
> I am using function "seas" from package "seasonal" for seasonal adjustment
> of time series. I am using the latest version of R (4.0.2, 64-bit).
> The following lines provide a small working example:
> ## EXAMPLE ##
> library(seasonal)
> m <- seas(AirPassengers)
> m
>
> On my private laptop, everything is going smoothly, and I obtain the
> following output:
> ## OUTPUT ##
> Call:
> seas(x = AirPassengers)
>
> Coefficients:
>           Weekday          Easter[1]         AO1951.May
> MA-Nonseasonal-01
>          -0.00295            0.01777            0.10016
> 0.11562
>    MA-Seasonal-12
>           0.49736
>
> But on my office computer, I receive the following error message after
> issuing " m <- seas(AirPassengers)":
> ## ERROR ##
> Error: X-13 has returned a non-zero exist status, which means that the
> current spec file cannot be processed for an unknown reason.
> In addition: Warning message:
> In system(cmd, intern = intern, wait = wait | intern,
> show.output.on.console = wait,  :
>   running command 'C:\Windows\system32\cmd.exe /c "\\
> hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe"
> C:\Users\SYLVAI~1.WEB\AppData\Local\Temp\Rtmpe0MDE7\x132d0cb8579b9/iofile
> -n -s' had status 1
>
> A similar issue has been already mentioned in various blogs, for instance:
> https://rdrr.io/github/christophsax/seasonal/src/travis/test-x13messages.R
> http://freerangestats.info/blog/2015/12/21/m3-and-x13
> https://github.com/christophsax/seasonal/issues/154
> but I couldn't find any solution yet.
>
> Does anyone have any idea why this issue is occurring?
>
> Thanks very much.
>
> Sylvain
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep 17 18:35:19 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 17 Sep 2020 09:35:19 -0700
Subject: [R] Seasonal adjustment with seas - Error: X-13 has returned a
 non-zero exist status
In-Reply-To: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
References: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
Message-ID: <CAHqSRuTU9k7YdOTsB=1Np2LmNQsYKo0t+BOT3HPMks_ayyW+Jg@mail.gmail.com>

The problem might to due to using an UNC path (//machine//blah/...) instead
of the traditional DOS path ("H:/blah/...").

E.g., if my working directory has a UNC path, cmd.exe will not work as
expected:
> getwd()
[1] "\\\\server/dept/devel/bill-sandbox"
> system("C:\\WINDOWS\\SYSTEM32\\cmd.exe /c echo foo bar", intern=TRUE)
[1] "'\\\\server\\dept\\devel\\bill-sandbox'"
[2] "CMD.EXE was started with the above path as the current directory."
[3] "UNC paths are not supported.  Defaulting to Windows directory."
[4] "foo bar"

You can test that by mapping "\\hes-nas-prairie.hes.adhes.hesge.ch/Home_S
<http://hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe>"
to a driver letter and using letter-colon everywhere instead of "\\...".

-Bill

On Thu, Sep 17, 2020 at 8:46 AM Weber Sylvain (HES) <sylvain.weber at hesge.ch>
wrote:

> Dear all,
>
> I am using function "seas" from package "seasonal" for seasonal adjustment
> of time series. I am using the latest version of R (4.0.2, 64-bit).
> The following lines provide a small working example:
> ## EXAMPLE ##
> library(seasonal)
> m <- seas(AirPassengers)
> m
>
> On my private laptop, everything is going smoothly, and I obtain the
> following output:
> ## OUTPUT ##
> Call:
> seas(x = AirPassengers)
>
> Coefficients:
>           Weekday          Easter[1]         AO1951.May
> MA-Nonseasonal-01
>          -0.00295            0.01777            0.10016
> 0.11562
>    MA-Seasonal-12
>           0.49736
>
> But on my office computer, I receive the following error message after
> issuing " m <- seas(AirPassengers)":
> ## ERROR ##
> Error: X-13 has returned a non-zero exist status, which means that the
> current spec file cannot be processed for an unknown reason.
> In addition: Warning message:
> In system(cmd, intern = intern, wait = wait | intern,
> show.output.on.console = wait,  :
>   running command 'C:\Windows\system32\cmd.exe /c "\\
> hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe"
> C:\Users\SYLVAI~1.WEB\AppData\Local\Temp\Rtmpe0MDE7\x132d0cb8579b9/iofile
> -n -s' had status 1
>
> A similar issue has been already mentioned in various blogs, for instance:
> https://rdrr.io/github/christophsax/seasonal/src/travis/test-x13messages.R
> http://freerangestats.info/blog/2015/12/21/m3-and-x13
> https://github.com/christophsax/seasonal/issues/154
> but I couldn't find any solution yet.
>
> Does anyone have any idea why this issue is occurring?
>
> Thanks very much.
>
> Sylvain
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 17 18:17:18 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Sep 2020 09:17:18 -0700
Subject: [R] Seasonal adjustment with seas - Error: X-13 has returned a
 non-zero exist status
In-Reply-To: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
References: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
Message-ID: <E81DE60B-033E-4E4A-B177-2752AFCC0406@dcn.davis.ca.us>

I don't know definitively, but if I were in your shoes I would put my personal package library on a local drive. UNC paths are not supported by all of the Windows file-related system calls.

On September 17, 2020 6:59:33 AM PDT, "Weber Sylvain (HES)" <sylvain.weber at hesge.ch> wrote:
>Dear all,
>
>I am using function "seas" from package "seasonal" for seasonal
>adjustment of time series. I am using the latest version of R (4.0.2,
>64-bit).
>The following lines provide a small working example:
>## EXAMPLE ##
>library(seasonal)
>m <- seas(AirPassengers)
>m
>
>On my private laptop, everything is going smoothly, and I obtain the
>following output:
>## OUTPUT ##
>Call:
>seas(x = AirPassengers)
>
>Coefficients:
>     Weekday          Easter[1]         AO1951.May  MA-Nonseasonal-01  
>    -0.00295            0.01777            0.10016            0.11562  
>   MA-Seasonal-12  
>          0.49736  
>
>But on my office computer, I receive the following error message after
>issuing " m <- seas(AirPassengers)":
>## ERROR ##
>Error: X-13 has returned a non-zero exist status, which means that the
>current spec file cannot be processed for an unknown reason.
>In addition: Warning message:
>In system(cmd, intern = intern, wait = wait | intern,
>show.output.on.console = wait,  :
>running command 'C:\Windows\system32\cmd.exe /c
>"\\hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe"
>C:\Users\SYLVAI~1.WEB\AppData\Local\Temp\Rtmpe0MDE7\x132d0cb8579b9/iofile
>-n -s' had status 1
>
>A similar issue has been already mentioned in various blogs, for
>instance:
>https://rdrr.io/github/christophsax/seasonal/src/travis/test-x13messages.R
>http://freerangestats.info/blog/2015/12/21/m3-and-x13
>https://github.com/christophsax/seasonal/issues/154
>but I couldn't find any solution yet.
>
>Does anyone have any idea why this issue is occurring?
>
>Thanks very much.
>
>Sylvain
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.
-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 17 18:16:32 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Sep 2020 09:16:32 -0700
Subject: [R] Seasonal adjustment with seas - Error: X-13 has returned a
 non-zero exist status
In-Reply-To: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
References: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
Message-ID: <D81A41A0-6107-4835-9E76-7AA4D881A5E1@dcn.davis.ca.us>

I don't know definitively, but if I were in your shoes I would put my personal package library on a local drive. UNC paths are not supported by all of the Windows file-related system calls.

On September 17, 2020 6:59:33 AM PDT, "Weber Sylvain (HES)" <sylvain.weber at hesge.ch> wrote:
>Dear all,
>
>I am using function "seas" from package "seasonal" for seasonal
>adjustment of time series. I am using the latest version of R (4.0.2,
>64-bit).
>The following lines provide a small working example:
>## EXAMPLE ##
>library(seasonal)
>m <- seas(AirPassengers)
>m
>
>On my private laptop, everything is going smoothly, and I obtain the
>following output:
>## OUTPUT ##
>Call:
>seas(x = AirPassengers)
>
>Coefficients:
>     Weekday          Easter[1]         AO1951.May  MA-Nonseasonal-01  
>    -0.00295            0.01777            0.10016            0.11562  
>   MA-Seasonal-12  
>          0.49736  
>
>But on my office computer, I receive the following error message after
>issuing " m <- seas(AirPassengers)":
>## ERROR ##
>Error: X-13 has returned a non-zero exist status, which means that the
>current spec file cannot be processed for an unknown reason.
>In addition: Warning message:
>In system(cmd, intern = intern, wait = wait | intern,
>show.output.on.console = wait,  :
>running command 'C:\Windows\system32\cmd.exe /c
>"\\hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe"
>C:\Users\SYLVAI~1.WEB\AppData\Local\Temp\Rtmpe0MDE7\x132d0cb8579b9/iofile
>-n -s' had status 1
>
>A similar issue has been already mentioned in various blogs, for
>instance:
>https://rdrr.io/github/christophsax/seasonal/src/travis/test-x13messages.R
>http://freerangestats.info/blog/2015/12/21/m3-and-x13
>https://github.com/christophsax/seasonal/issues/154
>but I couldn't find any solution yet.
>
>Does anyone have any idea why this issue is occurring?
>
>Thanks very much.
>
>Sylvain
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep 17 23:20:16 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 17 Sep 2020 17:20:16 -0400
Subject: [R] linearHypothesis
In-Reply-To: <CAAqXfscOadfLbTo9LZ4uzYoY1eRKg1NpRAv+dL8t6cyO4gT85w@mail.gmail.com>
References: <29588_1600348118_08HD8bO2031985_CAAqXfsd8+cLDY9Lia4mg6WpCZ8va3wb1cB4d4str5yj56Vrq7Q@mail.gmail.com>
 <a3aff576-2e35-64ae-399e-f7dfbe6c7310@mcmaster.ca>
 <CAAqXfscOadfLbTo9LZ4uzYoY1eRKg1NpRAv+dL8t6cyO4gT85w@mail.gmail.com>
Message-ID: <2d8a9c6f-6958-ef37-61fe-9fef41a4561f@mcmaster.ca>

Dear Johan,

It's generally a good idea to keep the conversation on r-help to allow 
list members to follow it, and so I'm cc'ing this response to the list.

I hope that it's clear that car::linearHypothesis() computes the test as 
a Wald test of a linear hypothesis and not as a likelihood-ratio test by 
model comparison. As your example illustrates, however, the two tests 
are the same for a linear model, but this is not true more generally.

As I mentioned, you can find the details in many sources, including in 
Section 5.3.5 of Fox and Weisberg, An R Companion to Applied Regression, 
3rd Edition, the book with which the car package is associated.

Best,
  John

On 2020-09-17 4:03 p.m., Johan Lassen wrote:
> Thank you John - highly appreciated! Yes, you are right, the less 
> complex model may be seen as a restricted model of the starting model. 
> Although the set of variables in the less complex model is not directly 
> a subset of the variables of the starting model. What confused me at 
> first was that I think of a subset model as a model having a direct 
> subset of the set of variables of the starting model. Even though this 
> is not the case in the example, the test still is on a restricted model 
> of the starting model.
> Thanks,
> Johan
> 
> Den tor. 17. sep. 2020 kl. 15.55 skrev John Fox <jfox at mcmaster.ca 
> <mailto:jfox at mcmaster.ca>>:
> 
>     Dear Johan,
> 
>     On 2020-09-17 9:07 a.m., Johan Lassen wrote:
>      > Dear R-users,
>      >
>      > I am using the R-function "linearHypothesis" to test if the sum
>     of all
>      > parameters, but the intercept, in a multiple linear regression is
>     different
>      > from zero.
>      > I wonder if it is statistically valid to use the 
>     linearHypothesis-function
>      > for this?
> 
>     Yes, assuming of course that the hypothesis makes sense.
> 
> 
>      > Below is a reproducible example in R. A multiple regression: y =
>      > beta0*t0+beta1*t1+beta2*t2+beta3*t3+beta4*t4
>      >
>      > It seems to me that the linearHypothesis function does the
>     calculation as
>      > an F-test on the extra residuals when going from the starting
>     model to a
>      > 'subset' model, although all variables in the 'subset' model
>     differ from
>      > the variables in the starting model.
>      > I normally think of a subset model as a model built on the same
>     input data
>      > as the starting model but one variable.
>      >
>      > Hence, is this a valid calculation?
> 
>     First, linearHypothesis() doesn't literally fit alternative models, but
>     rather tests the linear hypothesis directly from the coefficient
>     estimates and their covariance matrix. The test is standard -- look at
>     the references in ?linearHypothesis or most texts on linear models.
> 
>     Second, formulating the hypothesis using alternative models is also
>     legitimate, since the second model is a restricted version of the first.
> 
>      >
>      > Thanks in advance,Johan
>      >
>      > # R-code:
>      > y <-
>      >
>     c(101133190,96663050,106866486,97678429,83212348,75719714,77861937,74018478,82181104,68667176,64599495,62414401,63534709,58571865,65222727,60139788,
>      >
>     63355011,57790610,55214971,55535484,55759192,49450719,48834699,51383864,51250871,50629835,52154608,54636478,54942637)
>      >
>      > data <-
>      >
>     data.frame(y,"t0"=1,"t1"=1990:2018,"t2"=c(rep(0,12),1:17),"t3"=c(rep(0,17),1:12),"t4"=c(rep(0,23),1:6))
>      >
>      > model <- lm(y~t0+t1+t2+t3+t4+0,data=data)
> 
>     You need not supply the constant regressor t0 explicitly and suppress
>     the intercept -- you'd get the same test from linearHypothesis() for
>     lm(y~t1+t2+t3+t4,data=data).
> 
>      >
>      > linearHypothesis(model,"t1+t2+t3+t4=0",test=c("F"))
> 
>     test = "F" is the default.
> 
>      >
>      > # Reproduce the result from linearHypothesis:
>      > # beta1+beta2+beta3+beta4=0 -> beta4=-(beta1+beta2+beta3) ->
>      > # y=beta0+beta1*t1+beta2*t2+beta3*t3-(beta1+beta2+beta3)*t4
>      > # y = beta0'+beta1'*(t1-t4)+beta2'*(t2-t4)+beta3'*(t3-t4)
>      >
>      > data$t1 <- data$t1-data$t4
>      > data$t2 <- data$t2-data$t4
>      > data$t3 <- data$t3-data$t4
>      >
>      > model_reduced <- lm(y~t0+t1+t2+t3+0,data=data)
>      >
>      > anova(model_reduced,model)
> 
>     Yes, this is equivalent to the test performed by linearHypothesis()
>     using the coefficients and their covariances from the original model.
> 
>     I hope this helps,
>      ? John
> 
>     -- 
>     John Fox, Professor Emeritus
>     McMaster University
>     Hamilton, Ontario, Canada
>     web: https://socialsciences.mcmaster.ca/jfox/
>      >
> 
> 
> 
> -- 
> Johan Lassen
> 
> "In the cities people live in time -
> in the mountains people live in space" (Budistisk munk).

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Sep 18 00:01:20 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 17 Sep 2020 17:01:20 -0500
Subject: [R] how to overlay two histograms
Message-ID: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>

Hello,

I am trying to overlay two histograms with this:

p <- ggplot(d, aes(CHR, counts, fill = name)) + geom_bar(position = "dodge")
p

but I am getting this error:
Error: stat_count() can only have an x or y aesthetic.
Run `rlang::last_error()` to see where the error occurred.

my data is this:

> d
   CHR counts name
1    1 193554  old
2    2 220816  old
3    3 174350  old
4    4 163112  old
5    5 168125  old
6    6 182366  old
7    7 143023  old
8    8 147410  old
9    9 122112  old
10  10 138394  old
11  11 130069  old
12  12 124850  old
13  13 104119  old
14  14  83931  old
15  15  72287  old
16  16  71550  old
17  17  58380  old
18  18  76812  old
19  19  37040  old
20  20  63407  old
21  21  33863  old
22  22  33812  old
23   1 202783  new
24   2 252124  new
25   3 213337  new
26   4 201001  new
27   5 207606  new
28   6 228133  new
29   7 147218  new
30   8 177518  new
31   9 121276  new
32  10 163447  new
33  11 158724  new
34  12 142183  new
35  13 111189  new
36  14  83043  new
37  15  61063  new
38  16  55439  new
39  17  32883  new
40  18  69135  new
41  19  16624  new
42  20  48541  new
43  21  25479  new
44  22  19698  new

Basically I need to show counts per CHR in "old" and "new" side by side.

Please advise,
Ana


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 18 01:01:13 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 18 Sep 2020 09:01:13 +1000
Subject: [R] how to overlay two histograms
In-Reply-To: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>
References: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>
Message-ID: <CA+8X3fWLsE0krPfAn9YmF-eXue1Dbi1-xr=uLY0QY7WR4y+_7Q@mail.gmail.com>

Hi Ana,
Sorry it's not in ggplot, but it may help:

d<-read.table(text="CHR counts name
  1 193554  old
  2 220816  old
  3 174350  old
  4 163112  old
  5 168125  old
  6 182366  old
  7 143023  old
  8 147410  old
  9 122112  old
 10 138394  old
 11 130069  old
 12 124850  old
 13 104119  old
 14  83931  old
 15  72287  old
 16  71550  old
 17  58380  old
 18  76812  old
 19  37040  old
 20  63407  old
 21  33863  old
 22  33812  old
  1 202783  new
  2 252124  new
  3 213337  new
  4 201001  new
  5 207606  new
  6 228133  new
  7 147218  new
  8 177518  new
  9 121276  new
 10 163447  new
 11 158724  new
 12 142183  new
 13 111189  new
 14  83043  new
 15  61063  new
 16  55439  new
 17  32883  new
 18  69135  new
 19  16624  new
 20  48541  new
 21  25479  new
 22  19698  new",
header=TRUE,stingsAsFactors=FALSE)
barpos<-barplot(counts~name+CHR,data=d,beside=TRUE,names.arg=rep("",22))
legend(40,220000,c("new","old"),fill=c("gray20","gray80"))
library(plotrix)
staxlab(1,at=colMeans(barpos),labels=1:22)

Jim

On Fri, Sep 18, 2020 at 8:05 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I am trying to overlay two histograms with this:
>
> p <- ggplot(d, aes(CHR, counts, fill = name)) + geom_bar(position = "dodge")
> p
>
> but I am getting this error:
> Error: stat_count() can only have an x or y aesthetic.
> Run `rlang::last_error()` to see where the error occurred.
>
> my data is this:
>
> > d
>    CHR counts name
> 1    1 193554  old
> 2    2 220816  old
> 3    3 174350  old
> 4    4 163112  old
> 5    5 168125  old
> 6    6 182366  old
> 7    7 143023  old
> 8    8 147410  old
> 9    9 122112  old
> 10  10 138394  old
> 11  11 130069  old
> 12  12 124850  old
> 13  13 104119  old
> 14  14  83931  old
> 15  15  72287  old
> 16  16  71550  old
> 17  17  58380  old
> 18  18  76812  old
> 19  19  37040  old
> 20  20  63407  old
> 21  21  33863  old
> 22  22  33812  old
> 23   1 202783  new
> 24   2 252124  new
> 25   3 213337  new
> 26   4 201001  new
> 27   5 207606  new
> 28   6 228133  new
> 29   7 147218  new
> 30   8 177518  new
> 31   9 121276  new
> 32  10 163447  new
> 33  11 158724  new
> 34  12 142183  new
> 35  13 111189  new
> 36  14  83043  new
> 37  15  61063  new
> 38  16  55439  new
> 39  17  32883  new
> 40  18  69135  new
> 41  19  16624  new
> 42  20  48541  new
> 43  21  25479  new
> 44  22  19698  new
>
> Basically I need to show counts per CHR in "old" and "new" side by side.
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Fri Sep 18 01:11:23 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 18 Sep 2020 01:11:23 +0200
Subject: [R] how to overlay two histograms
In-Reply-To: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>
References: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>
Message-ID: <20200917231123.GE164836@posteo.no>

On 2020-09-17 17:01 -0500, Ana Marija wrote:
> Hello,
> 
> I am trying to overlay two histograms with this:
> 
> p <- ggplot(d, aes(CHR, counts, fill = name)) + geom_bar(position = "dodge")
> p
> 
> but I am getting this error:
> Error: stat_count() can only have an x or y aesthetic.
> Run `rlang::last_error()` to see where the error occurred.

Dear Ana,

you need to specify stat="identity" [1], 
like so:

	mapping <- ggplot2::aes(
	  x=CHR,
	  y=counts,
	  fill=name)
	p <-
	  ggplot2::ggplot() +
	  ggplot2::geom_bar(
	    data=d,
	    mapping = mapping,
	    position="dodge",
	    stat="identity")

Best,
Rasmus

[1] https://stackoverflow.com/questions/61068031/error-stat-count-can-only-have-an-x-or-y-aesthetic

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200918/8f6f13a4/attachment.sig>

From @t@t|@t|c@84 @end|ng |rom hotm@||@com  Fri Sep 18 02:12:31 2020
From: @t@t|@t|c@84 @end|ng |rom hotm@||@com (peri He)
Date: Fri, 18 Sep 2020 00:12:31 +0000
Subject: [R] multiple time series plots
Message-ID: <AM7PR10MB373530F0723816214FA93B07C63F0@AM7PR10MB3735.EURPRD10.PROD.OUTLOOK.COM>

Dear Friends,

I am trying to add two time series curves into one plot. I don't get any error but the lines are not added to my plot.
I am trying the following code;

1) df <- as.data.frame (read_excel("C:/Users/NO2.xlsx", "trend))

2) plot(df$year, df$Nation, type="o", col="blue", lty=1, ylab="change" )

3) lines(df$year, df$East, col="red",lty=2)

4) lines(df$year, df$center, col="dark red", lty=3)

I need to mention that Nation, East and Center are some probability values.
And year, is a sequence of years. Lines 1 and 2 are run properly but lines 3 and 4 are not added.

I would appreciate any idea.

Regards,

Peri

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 18 02:21:22 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 18 Sep 2020 10:21:22 +1000
Subject: [R] multiple time series plots
In-Reply-To: <AM7PR10MB373530F0723816214FA93B07C63F0@AM7PR10MB3735.EURPRD10.PROD.OUTLOOK.COM>
References: <AM7PR10MB373530F0723816214FA93B07C63F0@AM7PR10MB3735.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fW40_qL=Baz1ko-d_it-QXC8NV=6JBn5R0i5A-T71P5Qg@mail.gmail.com>

Hi Peri,
Without the data this is only a guess, but are the values of East and
center within the limits of the plot generated by Nation?

Jim

On Fri, Sep 18, 2020 at 10:12 AM peri He <statistics84 at hotmail.com> wrote:
>
> Dear Friends,
>
> I am trying to add two time series curves into one plot. I don't get any error but the lines are not added to my plot.
> I am trying the following code;
>
> 1) df <- as.data.frame (read_excel("C:/Users/NO2.xlsx", "trend))
>
> 2) plot(df$year, df$Nation, type="o", col="blue", lty=1, ylab="change" )
>
> 3) lines(df$year, df$East, col="red",lty=2)
>
> 4) lines(df$year, df$center, col="dark red", lty=3)
>
> I need to mention that Nation, East and Center are some probability values.
> And year, is a sequence of years. Lines 1 and 2 are run properly but lines 3 and 4 are not added.
>
> I would appreciate any idea.
>
> Regards,
>
> Peri
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Sep 18 02:39:12 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 17 Sep 2020 19:39:12 -0500
Subject: [R] how to overlay two histograms
In-Reply-To: <CA+8X3fWLsE0krPfAn9YmF-eXue1Dbi1-xr=uLY0QY7WR4y+_7Q@mail.gmail.com>
References: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>
 <CA+8X3fWLsE0krPfAn9YmF-eXue1Dbi1-xr=uLY0QY7WR4y+_7Q@mail.gmail.com>
Message-ID: <CAF9-5jN+PchHk7DR4ehXxXB8FzAMe_rmmYfFkGr_M=+seqsfxw@mail.gmail.com>

HI Jim,

fantastic solution!
Thank you so much!!!

Ana

On Thu, Sep 17, 2020 at 6:01 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> Sorry it's not in ggplot, but it may help:
>
> d<-read.table(text="CHR counts name
>   1 193554  old
>   2 220816  old
>   3 174350  old
>   4 163112  old
>   5 168125  old
>   6 182366  old
>   7 143023  old
>   8 147410  old
>   9 122112  old
>  10 138394  old
>  11 130069  old
>  12 124850  old
>  13 104119  old
>  14  83931  old
>  15  72287  old
>  16  71550  old
>  17  58380  old
>  18  76812  old
>  19  37040  old
>  20  63407  old
>  21  33863  old
>  22  33812  old
>   1 202783  new
>   2 252124  new
>   3 213337  new
>   4 201001  new
>   5 207606  new
>   6 228133  new
>   7 147218  new
>   8 177518  new
>   9 121276  new
>  10 163447  new
>  11 158724  new
>  12 142183  new
>  13 111189  new
>  14  83043  new
>  15  61063  new
>  16  55439  new
>  17  32883  new
>  18  69135  new
>  19  16624  new
>  20  48541  new
>  21  25479  new
>  22  19698  new",
> header=TRUE,stingsAsFactors=FALSE)
> barpos<-barplot(counts~name+CHR,data=d,beside=TRUE,names.arg=rep("",22))
> legend(40,220000,c("new","old"),fill=c("gray20","gray80"))
> library(plotrix)
> staxlab(1,at=colMeans(barpos),labels=1:22)
>
> Jim
>
> On Fri, Sep 18, 2020 at 8:05 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I am trying to overlay two histograms with this:
> >
> > p <- ggplot(d, aes(CHR, counts, fill = name)) + geom_bar(position = "dodge")
> > p
> >
> > but I am getting this error:
> > Error: stat_count() can only have an x or y aesthetic.
> > Run `rlang::last_error()` to see where the error occurred.
> >
> > my data is this:
> >
> > > d
> >    CHR counts name
> > 1    1 193554  old
> > 2    2 220816  old
> > 3    3 174350  old
> > 4    4 163112  old
> > 5    5 168125  old
> > 6    6 182366  old
> > 7    7 143023  old
> > 8    8 147410  old
> > 9    9 122112  old
> > 10  10 138394  old
> > 11  11 130069  old
> > 12  12 124850  old
> > 13  13 104119  old
> > 14  14  83931  old
> > 15  15  72287  old
> > 16  16  71550  old
> > 17  17  58380  old
> > 18  18  76812  old
> > 19  19  37040  old
> > 20  20  63407  old
> > 21  21  33863  old
> > 22  22  33812  old
> > 23   1 202783  new
> > 24   2 252124  new
> > 25   3 213337  new
> > 26   4 201001  new
> > 27   5 207606  new
> > 28   6 228133  new
> > 29   7 147218  new
> > 30   8 177518  new
> > 31   9 121276  new
> > 32  10 163447  new
> > 33  11 158724  new
> > 34  12 142183  new
> > 35  13 111189  new
> > 36  14  83043  new
> > 37  15  61063  new
> > 38  16  55439  new
> > 39  17  32883  new
> > 40  18  69135  new
> > 41  19  16624  new
> > 42  20  48541  new
> > 43  21  25479  new
> > 44  22  19698  new
> >
> > Basically I need to show counts per CHR in "old" and "new" side by side.
> >
> > Please advise,
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 18 03:41:44 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 18 Sep 2020 11:41:44 +1000
Subject: [R] multiple time series plots
In-Reply-To: <AM7PR10MB37351FA389EBD5E4D0BCA5FFC63F0@AM7PR10MB3735.EURPRD10.PROD.OUTLOOK.COM>
References: <AM7PR10MB373530F0723816214FA93B07C63F0@AM7PR10MB3735.EURPRD10.PROD.OUTLOOK.COM>
 <CA+8X3fW40_qL=Baz1ko-d_it-QXC8NV=6JBn5R0i5A-T71P5Qg@mail.gmail.com>
 <AM7PR10MB37351FA389EBD5E4D0BCA5FFC63F0@AM7PR10MB3735.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fUWKWxUTH1eDn03SOW5bU7FLDiHNgXnjXFgrRao5nOO7A@mail.gmail.com>

Hi Peri,
In that case, try this:

ylim<-range(c(df$Nation,df$East,df$Center),na.rm=TRUE)
plot(df$year, df$Nation, type="o", col="blue", lty=1, ylab="change",ylim=ylim)

Jim

On Fri, Sep 18, 2020 at 11:10 AM peri He <statistics84 at hotmail.com> wrote:
>
> Hi Jim,
>
> Thank you for your reply.
>
> Sorry I am messaging you instead of asking publicly.
> Actually Nation, center and East are like medium and confidence intervals.
> So no, they are not in the limit of each other.
> I am trying to find a way to plot them in one chart. Most of the codes give me error.
>
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Friday, September 18, 2020 12:21 AM
> To: peri He <statistics84 at hotmail.com>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] multiple time series plots
>
> Hi Peri,
> Without the data this is only a guess, but are the values of East and
> center within the limits of the plot generated by Nation?
>
> Jim
>
> On Fri, Sep 18, 2020 at 10:12 AM peri He <statistics84 at hotmail.com> wrote:
> >
> > Dear Friends,
> >
> > I am trying to add two time series curves into one plot. I don't get any error but the lines are not added to my plot.
> > I am trying the following code;
> >
> > 1) df <- as.data.frame (read_excel("C:/Users/NO2.xlsx", "trend))
> >
> > 2) plot(df$year, df$Nation, type="o", col="blue", lty=1, ylab="change" )
> >
> > 3) lines(df$year, df$East, col="red",lty=2)
> >
> > 4) lines(df$year, df$center, col="dark red", lty=3)
> >
> > I need to mention that Nation, East and Center are some probability values.
> > And year, is a sequence of years. Lines 1 and 2 are run properly but lines 3 and 4 are not added.
> >
> > I would appreciate any idea.
> >
> > Regards,
> >
> > Peri
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Fri Sep 18 04:17:33 2020
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Thu, 17 Sep 2020 22:17:33 -0400
Subject: [R] Mapping 2D to 3D
Message-ID: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>

I am trying to understand how to map 2D to 3D using ggplot() and eventually plot_gg(). I am, however, stuck on understanding how to express the third variable to be mapped. This example:

ggdiamonds = ggplot(diamonds, aes(x, depth)) +
stat_density_2d(aes(fill = stat(nlevel)),
geom = "polygon", n = 100, bins = 10,contour = TRUE) +
facet_wrap(clarity~.) +
scale_fill_viridis_c(option = "A")

uses a variable nlevel that I now understand is calculated during the building of the ggplot but I have not figured out from where it is calculated or how to specify a variable of my choosing.

Does anyone have a good reference for understanding how to specify this variable? Most examples on the 'net seem to use the same dataset but do not specify this particular aspect...


From @purd|e@@ @end|ng |rom gm@||@com  Fri Sep 18 08:00:27 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 18 Sep 2020 18:00:27 +1200
Subject: [R] Mapping 2D to 3D
In-Reply-To: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
Message-ID: <CAB8pepzdPR3OabYUF79Eyvrhsi6ud7kxSarjrFdhgv+qWc=acw@mail.gmail.com>

I'm not familiar with the gg graphics system.
However, I am familiar with density estimation, and density visualization.

There is *no* third variable, as such.
But rather, density estimates, which in this context, would usually be a matrix.
(And are computed inside the plotting or density estimation functions).

The documentation for the function you've used, says it uses  MASS::kde2d().
This does just that, returns an object, which contains a density matrix.
(Refer to the help file for kde2d).

Of course, there's no reason why one can't create a third variable,
from a mathematical perspective.
e.g. d, z, h, fv, or whatever you prefer...
And then set z = fh (x, y).

But there's no reason for the user to do that when using the plotting function.

Note that there are situations where one might want to set the limits
of the plot.
And set the breaks, colors, and color key.
e.g. Creating two or more plots, and putting them next to each other,
for comparison purposes.


On Fri, Sep 18, 2020 at 2:17 PM H <agents at meddatainc.com> wrote:
>
> I am trying to understand how to map 2D to 3D using ggplot() and eventually plot_gg(). I am, however, stuck on understanding how to express the third variable to be mapped. This example:
>
> ggdiamonds = ggplot(diamonds, aes(x, depth)) +
> stat_density_2d(aes(fill = stat(nlevel)),
> geom = "polygon", n = 100, bins = 10,contour = TRUE) +
> facet_wrap(clarity~.) +
> scale_fill_viridis_c(option = "A")
>
> uses a variable nlevel that I now understand is calculated during the building of the ggplot but I have not figured out from where it is calculated or how to specify a variable of my choosing.
>
> Does anyone have a good reference for understanding how to specify this variable? Most examples on the 'net seem to use the same dataset but do not specify this particular aspect...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Fri Sep 18 08:13:07 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 18 Sep 2020 18:13:07 +1200
Subject: [R] Mapping 2D to 3D
In-Reply-To: <CAB8pepzdPR3OabYUF79Eyvrhsi6ud7kxSarjrFdhgv+qWc=acw@mail.gmail.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <CAB8pepzdPR3OabYUF79Eyvrhsi6ud7kxSarjrFdhgv+qWc=acw@mail.gmail.com>
Message-ID: <CAB8pepw3NPXak5KzW-D02zxizXfrb2AeAZGuRsuZwLbXAUsNBw@mail.gmail.com>

> But there's no reason for the user to do that when using the plotting function.

I should amend the above.
There's no reason for the user to do that (compute a third "variable"
representing density), if using a high level plotting function, that's
designed to compute the density for you.

It is possible to do it in two or more steps.
(Compute the density matrix, then plot it).

Again, refer to the help file for kde2d.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 18 08:26:08 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 17 Sep 2020 23:26:08 -0700
Subject: [R] Mapping 2D to 3D
In-Reply-To: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
Message-ID: <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>

No, but fortunately you are off in the weeds. Density has an internally-computed "z" coordinate... you should be looking at ?geom_contour.

On September 17, 2020 7:17:33 PM PDT, H <agents at meddatainc.com> wrote:
>I am trying to understand how to map 2D to 3D using ggplot() and
>eventually plot_gg(). I am, however, stuck on understanding how to
>express the third variable to be mapped. This example:
>
>ggdiamonds = ggplot(diamonds, aes(x, depth)) +
>stat_density_2d(aes(fill = stat(nlevel)),
>geom = "polygon", n = 100, bins = 10,contour = TRUE) +
>facet_wrap(clarity~.) +
>scale_fill_viridis_c(option = "A")
>
>uses a variable nlevel that I now understand is calculated during the
>building of the ggplot but I have not figured out from where it is
>calculated or how to specify a variable of my choosing.
>
>Does anyone have a good reference for understanding how to specify this
>variable? Most examples on the 'net seem to use the same dataset but do
>not specify this particular aspect...
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From co|or|e @end|ng |rom gm@||@com  Fri Sep 18 09:08:51 2020
From: co|or|e @end|ng |rom gm@||@com (Carlos Ortega)
Date: Fri, 18 Sep 2020 09:08:51 +0200
Subject: [R] Mapping 2D to 3D
In-Reply-To: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
Message-ID: <CAFKNbkJos64PuEjpbswhP_+NuRy3_2QfwnWs4iyEo9JqbeBQ2Q@mail.gmail.com>

Hi,

There are some further references in the own "RStudio Community" and in
StackOverflow:

   - https://community.rstudio.com/t/options-to-stat-density-2d/792/4
   -
   https://stackoverflow.com/questions/32206623/what-does-level-mean-in-ggplotstat-density2d

Kind Regards,
Carlos.


On Fri, Sep 18, 2020 at 4:17 AM H <agents at meddatainc.com> wrote:

> I am trying to understand how to map 2D to 3D using ggplot() and
> eventually plot_gg(). I am, however, stuck on understanding how to express
> the third variable to be mapped. This example:
>
> ggdiamonds = ggplot(diamonds, aes(x, depth)) +
> stat_density_2d(aes(fill = stat(nlevel)),
> geom = "polygon", n = 100, bins = 10,contour = TRUE) +
> facet_wrap(clarity~.) +
> scale_fill_viridis_c(option = "A")
>
> uses a variable nlevel that I now understand is calculated during the
> building of the ggplot but I have not figured out from where it is
> calculated or how to specify a variable of my choosing.
>
> Does anyone have a good reference for understanding how to specify this
> variable? Most examples on the 'net seem to use the same dataset but do not
> specify this particular aspect...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ph@edru@v @end|ng |rom gm@||@com  Fri Sep 18 09:31:46 2020
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Fri, 18 Sep 2020 08:31:46 +0100
Subject: [R] 
 How to reduce the sparseness in a TDM to make a cluster plot
 readable?
In-Reply-To: <CAB8pepxx+6kAg5E37w7t7+MChf5xLxE-E9RqRXR3Q-kvCocH8Q@mail.gmail.com>
References: <c6722f2d-e4a7-f981-0624-4a9a517b76f9@gmail.com>
 <CAB8pepxx+6kAg5E37w7t7+MChf5xLxE-E9RqRXR3Q-kvCocH8Q@mail.gmail.com>
Message-ID: <6db46d62-c6d7-4f65-7e88-b5b68f0a2cc7@gmail.com>

Hi Abby

Many thanks for reaching out with an offer of help. Very much appreciated.

(1) The packages I'm using are 'tm' for text-mining and the TDM and for 
the clustering it is 'cluster'
(2) Not sure where the problem is happening as it doesn't show up as an 
error. Where it manifests is in the plotting, however logic would 
suggest that it concerns the removal of sparse terms, so that would be 
in the TDM process
(3) I don't think I can provide a reproducible example. When I practice 
using data sets that packages provide, all is fine. The trouble is when 
I apply it to my own data sets which are five documents, etc., as described.

I think the nub of it is really to find a way that I can subset the TDM 
to return the twenty or thirty most frequently used words, and then to 
plot those using hclust. However, when searching on-line I haven't been 
able to find any suggestions on how to do that, nor is there any mention 
of using that approach in the books and tutorials I have.

If you (or someone on this list) can advise on how I can sort the terms 
in the TDM from most to least frequent, and then to subset the top 
twenty or thirty most frequently occurring terms (preferably using tf as 
well as tf-idf) and then I can plot that sub-set, then I think that that 
would do the trick, and the terms would be plotted clearly and legibly.

Thanks again for your offer of help. I hope that my reply helps clarify 
rather than muddy the situation.

Best wishes
Andy


On 17/09/2020 08:43, Abby Spurdle wrote:
> I'm not familiar with these subjects.
> And hopefully, someone who is, will offer some better suggestions.
>
> But to get things started, maybe...
> (1) What packages are you using (re: tdm)?
> (2) Where does the problem happen, in dist, hclust, the plot method
> for hclust, or in the package(s) you are using?
> (3) Do you think you could produce a small reproducible example,
> showing what is wrong, and explaining you would like it to do instead?
>
> Note that if the problem relates to hclust, or the plot method, then
> you should be able to produce a much simpler example.
> e.g.
>
>      mycount.matrix <- matrix (rpois (25000, 20),, 5)
>      head (mycount.matrix, 3)
>      tail (mycount.matrix, 3)
>
>      plot (hclust (dist (mycount.matrix) ) )
>
> On Tue, Sep 15, 2020 at 6:54 AM Andrew <phaedrusv at gmail.com> wrote:
>> Hello all
>>
>> I am doing some text mining on a set of five plain text files and have
>> run into a snag when I run hclust in that there are just too many leaves
>> for anything to be read. It returns a solid black line.
>>
>> The texts have been converted into a TDM which has a dim of 5,292 and 5
>> (as per 5 docs).
>>
>> My code for removing sparsity is as follows:
>>
>>   > tdm2 <- removeSparseTerms(tdm, sparse=0.99999)
>>
>>   > inspect(tdm2)
>>
>> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
>> Non-/sparse entries: 10415/16045
>> Sparsity           : 61%
>> Maximal term length: 22
>> Weighting          : term frequency (tf)
>>
>> While the tf-idf weighting returns this when 0.99999 sparseness is removed:
>>
>>   > inspect(tdm.tfidf)
>> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
>> Non-/sparse entries: 7915/18545
>> Sparsity           : 70%
>> Maximal term length: 22
>> Weighting          : term frequency - inverse document frequency
>> (normalized) (tf-idf)
>>
>> I have experimented by decreasing the value I use for decreasing
>> sparseness, and that helps a bit, for example:
>>
>>   > tdm2 <- removeSparseTerms(tdm, sparse=0.215)
>>   > inspect(tdm2)
>> <<TermDocumentMatrix (terms: 869, documents: 5)>>
>> Non-/sparse entries: 3976/369
>> Sparsity           : 8%
>> Maximal term length: 14
>> Weighting          : term frequency (tf)
>>
>> But, no matter what I do, the resulting plot is unreadable. The code for
>> plotting the cluster is:
>>
>>   > hc <- hclust(dist(tdm2, method = "euclidean"), method = "complete")
>>   > plot(hc, yaxt = 'n', main = "Hierarchical clustering")
>>
>> Can someone kindly either advise me what I am doing wrong and/ or
>> signpost me to some detailed info on how to fix this.
>>
>> Many thanks in anticipation.
>>
>> Andy
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 18 10:18:25 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 18 Sep 2020 18:18:25 +1000
Subject: [R] 
 How to reduce the sparseness in a TDM to make a cluster plot
 readable?
In-Reply-To: <6db46d62-c6d7-4f65-7e88-b5b68f0a2cc7@gmail.com>
References: <c6722f2d-e4a7-f981-0624-4a9a517b76f9@gmail.com>
 <CAB8pepxx+6kAg5E37w7t7+MChf5xLxE-E9RqRXR3Q-kvCocH8Q@mail.gmail.com>
 <6db46d62-c6d7-4f65-7e88-b5b68f0a2cc7@gmail.com>
Message-ID: <CA+8X3fXqNqayZOLwtkw3knjFN_wdQ7x58Do=fC_dAD1mYuE8Gg@mail.gmail.com>

Hi Andrew,
>From your last email the answer to your problem may be the
findFreqTerms() function. Just increase the number of times a term has
to appear and check the result until you get the matrix size that you
want.

Jim

On Fri, Sep 18, 2020 at 5:32 PM Andrew <phaedrusv at gmail.com> wrote:
>
> Hi Abby
>
> Many thanks for reaching out with an offer of help. Very much appreciated.
>
> (1) The packages I'm using are 'tm' for text-mining and the TDM and for
> the clustering it is 'cluster'
> (2) Not sure where the problem is happening as it doesn't show up as an
> error. Where it manifests is in the plotting, however logic would
> suggest that it concerns the removal of sparse terms, so that would be
> in the TDM process
> (3) I don't think I can provide a reproducible example. When I practice
> using data sets that packages provide, all is fine. The trouble is when
> I apply it to my own data sets which are five documents, etc., as described.
>
> I think the nub of it is really to find a way that I can subset the TDM
> to return the twenty or thirty most frequently used words, and then to
> plot those using hclust. However, when searching on-line I haven't been
> able to find any suggestions on how to do that, nor is there any mention
> of using that approach in the books and tutorials I have.
>
> If you (or someone on this list) can advise on how I can sort the terms
> in the TDM from most to least frequent, and then to subset the top
> twenty or thirty most frequently occurring terms (preferably using tf as
> well as tf-idf) and then I can plot that sub-set, then I think that that
> would do the trick, and the terms would be plotted clearly and legibly.
>
> Thanks again for your offer of help. I hope that my reply helps clarify
> rather than muddy the situation.
>
> Best wishes
> Andy
>
>
> On 17/09/2020 08:43, Abby Spurdle wrote:
> > I'm not familiar with these subjects.
> > And hopefully, someone who is, will offer some better suggestions.
> >
> > But to get things started, maybe...
> > (1) What packages are you using (re: tdm)?
> > (2) Where does the problem happen, in dist, hclust, the plot method
> > for hclust, or in the package(s) you are using?
> > (3) Do you think you could produce a small reproducible example,
> > showing what is wrong, and explaining you would like it to do instead?
> >
> > Note that if the problem relates to hclust, or the plot method, then
> > you should be able to produce a much simpler example.
> > e.g.
> >
> >      mycount.matrix <- matrix (rpois (25000, 20),, 5)
> >      head (mycount.matrix, 3)
> >      tail (mycount.matrix, 3)
> >
> >      plot (hclust (dist (mycount.matrix) ) )
> >
> > On Tue, Sep 15, 2020 at 6:54 AM Andrew <phaedrusv at gmail.com> wrote:
> >> Hello all
> >>
> >> I am doing some text mining on a set of five plain text files and have
> >> run into a snag when I run hclust in that there are just too many leaves
> >> for anything to be read. It returns a solid black line.
> >>
> >> The texts have been converted into a TDM which has a dim of 5,292 and 5
> >> (as per 5 docs).
> >>
> >> My code for removing sparsity is as follows:
> >>
> >>   > tdm2 <- removeSparseTerms(tdm, sparse=0.99999)
> >>
> >>   > inspect(tdm2)
> >>
> >> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
> >> Non-/sparse entries: 10415/16045
> >> Sparsity           : 61%
> >> Maximal term length: 22
> >> Weighting          : term frequency (tf)
> >>
> >> While the tf-idf weighting returns this when 0.99999 sparseness is removed:
> >>
> >>   > inspect(tdm.tfidf)
> >> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
> >> Non-/sparse entries: 7915/18545
> >> Sparsity           : 70%
> >> Maximal term length: 22
> >> Weighting          : term frequency - inverse document frequency
> >> (normalized) (tf-idf)
> >>
> >> I have experimented by decreasing the value I use for decreasing
> >> sparseness, and that helps a bit, for example:
> >>
> >>   > tdm2 <- removeSparseTerms(tdm, sparse=0.215)
> >>   > inspect(tdm2)
> >> <<TermDocumentMatrix (terms: 869, documents: 5)>>
> >> Non-/sparse entries: 3976/369
> >> Sparsity           : 8%
> >> Maximal term length: 14
> >> Weighting          : term frequency (tf)
> >>
> >> But, no matter what I do, the resulting plot is unreadable. The code for
> >> plotting the cluster is:
> >>
> >>   > hc <- hclust(dist(tdm2, method = "euclidean"), method = "complete")
> >>   > plot(hc, yaxt = 'n', main = "Hierarchical clustering")
> >>
> >> Can someone kindly either advise me what I am doing wrong and/ or
> >> signpost me to some detailed info on how to fix this.
> >>
> >> Many thanks in anticipation.
> >>
> >> Andy
> >>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @y|v@|n@weber @end|ng |rom he@ge@ch  Fri Sep 18 12:08:21 2020
From: @y|v@|n@weber @end|ng |rom he@ge@ch (Weber Sylvain (HES))
Date: Fri, 18 Sep 2020 10:08:21 +0000
Subject: [R] Seasonal adjustment with seas - Error: X-13 has returned a
 non-zero exist status
In-Reply-To: <CAHqSRuTU9k7YdOTsB=1Np2LmNQsYKo0t+BOT3HPMks_ayyW+Jg@mail.gmail.com>
References: <451340d0d7254861a2546b4b9177d7fb@hesge.ch>
 <CAHqSRuTU9k7YdOTsB=1Np2LmNQsYKo0t+BOT3HPMks_ayyW+Jg@mail.gmail.com>
Message-ID: <91d01c58baba48728480dd9ebdf946d8@hesge.ch>

Dear Bill, Jeff, and Bert,

Thanks so much for the replies.
Bill is absolutely right. The problem came from the UNC path. 
I could solve the issue by adding the following lines to my Rprofile:
myPaths <- .libPaths()
myPaths <- c('M:/R/win-library/4.0', myPaths[2])  # where 'M:/R/win-library/4.0' is the traditional DOS path corresponding to the UNC path \\... 
.libPaths(myPaths)

Thanks again!

Sylvain


De?: Bill Dunlap <williamwdunlap at gmail.com> 
Envoy??: jeudi, 17 septembre 2020 18:35
??: Weber Sylvain (HES) <sylvain.weber at hesge.ch>
Cc?: r-help at R-project.org
Objet?: Re: [R] Seasonal adjustment with seas - Error: X-13 has returned a non-zero exist status

The problem might to due to using an UNC path (//machine//blah/...) instead of the traditional DOS path ("H:/blah/...").

E.g., if my working directory has a UNC path, cmd.exe will not work as expected:
> getwd()
[1] "\\\\server/dept/devel/bill-sandbox"
> system("C:\\WINDOWS\\SYSTEM32\\cmd.exe /c echo foo bar", intern=TRUE)
[1] "'\\\\server\\dept\\devel\\bill-sandbox'" ? ? ? ? ? ? ? ? ? ? ? ? ? 
[2] "CMD.EXE was started with the above path as the current directory."
[3] "UNC paths are not supported.? Defaulting to Windows directory." ? 
[4] "foo bar"? ? ? ? ? ? ? ? ? ? ? ? ??

You can test that by mapping "\\http://hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe" to a driver letter and using letter-colon everywhere instead of "\\...".

-Bill

On Thu, Sep 17, 2020 at 8:46 AM Weber Sylvain (HES) <mailto:sylvain.weber at hesge.ch> wrote:
Dear all,

I am using function "seas" from package "seasonal" for seasonal adjustment of time series. I am using the latest version of R (4.0.2, 64-bit).
The following lines provide a small working example:
## EXAMPLE ##
library(seasonal)
m <- seas(AirPassengers)
m

On my private laptop, everything is going smoothly, and I obtain the following output:
## OUTPUT ##
Call:
seas(x = AirPassengers)

Coefficients:
? ? ? ? ? Weekday? ? ? ? ? Easter[1]? ? ? ? ?AO1951.May? MA-Nonseasonal-01? 
? ? ? ? ?-0.00295? ? ? ? ? ? 0.01777? ? ? ? ? ? 0.10016? ? ? ? ? ? 0.11562? 
? ?MA-Seasonal-12? 
? ? ? ? ? 0.49736? 

But on my office computer, I receive the following error message after issuing " m <- seas(AirPassengers)":
## ERROR ##
Error: X-13 has returned a non-zero exist status, which means that the current spec file cannot be processed for an unknown reason.
In addition: Warning message:
In system(cmd, intern = intern, wait = wait | intern, show.output.on.console = wait,? :
? running command 'C:\Windows\system32\cmd.exe /c "\\http://hes-nas-prairie.hes.adhes.hesge.ch/Home_S/sylvain.weber/Documents/R/win-library/4.0/x13binary/bin/x13ashtml.exe" C:\Users\SYLVAI~1.WEB\AppData\Local\Temp\Rtmpe0MDE7\x132d0cb8579b9/iofile -n -s' had status 1

A similar issue has been already mentioned in various blogs, for instance:
https://rdrr.io/github/christophsax/seasonal/src/travis/test-x13messages.R
http://freerangestats.info/blog/2015/12/21/m3-and-x13
https://github.com/christophsax/seasonal/issues/154
but I couldn't find any solution yet.

Does anyone have any idea why this issue is occurring?

Thanks very much.

Sylvain

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ph@edru@v @end|ng |rom gm@||@com  Fri Sep 18 14:02:31 2020
From: ph@edru@v @end|ng |rom gm@||@com (Andrew)
Date: Fri, 18 Sep 2020 13:02:31 +0100
Subject: [R] 
 How to reduce the sparseness in a TDM to make a cluster plot
 readable?
In-Reply-To: <CA+8X3fXqNqayZOLwtkw3knjFN_wdQ7x58Do=fC_dAD1mYuE8Gg@mail.gmail.com>
References: <c6722f2d-e4a7-f981-0624-4a9a517b76f9@gmail.com>
 <CAB8pepxx+6kAg5E37w7t7+MChf5xLxE-E9RqRXR3Q-kvCocH8Q@mail.gmail.com>
 <6db46d62-c6d7-4f65-7e88-b5b68f0a2cc7@gmail.com>
 <CA+8X3fXqNqayZOLwtkw3knjFN_wdQ7x58Do=fC_dAD1mYuE8Gg@mail.gmail.com>
Message-ID: <ba9d2b8a-801c-7d08-28c8-66aadac634c6@gmail.com>

Hello Jim

Thanks for that. I'll read up on it and will give it a go, either later 
today or tomorrow. I am assuming this will work for both tf and tf-idf 
weighted TDMs?

Much appreciated. :-)

Best wishes
Andy


On 18/09/2020 09:18, Jim Lemon wrote:
> Hi Andrew,
> >From your last email the answer to your problem may be the
> findFreqTerms() function. Just increase the number of times a term has
> to appear and check the result until you get the matrix size that you
> want.
>
> Jim
>
> On Fri, Sep 18, 2020 at 5:32 PM Andrew <phaedrusv at gmail.com> wrote:
>> Hi Abby
>>
>> Many thanks for reaching out with an offer of help. Very much appreciated.
>>
>> (1) The packages I'm using are 'tm' for text-mining and the TDM and for
>> the clustering it is 'cluster'
>> (2) Not sure where the problem is happening as it doesn't show up as an
>> error. Where it manifests is in the plotting, however logic would
>> suggest that it concerns the removal of sparse terms, so that would be
>> in the TDM process
>> (3) I don't think I can provide a reproducible example. When I practice
>> using data sets that packages provide, all is fine. The trouble is when
>> I apply it to my own data sets which are five documents, etc., as described.
>>
>> I think the nub of it is really to find a way that I can subset the TDM
>> to return the twenty or thirty most frequently used words, and then to
>> plot those using hclust. However, when searching on-line I haven't been
>> able to find any suggestions on how to do that, nor is there any mention
>> of using that approach in the books and tutorials I have.
>>
>> If you (or someone on this list) can advise on how I can sort the terms
>> in the TDM from most to least frequent, and then to subset the top
>> twenty or thirty most frequently occurring terms (preferably using tf as
>> well as tf-idf) and then I can plot that sub-set, then I think that that
>> would do the trick, and the terms would be plotted clearly and legibly.
>>
>> Thanks again for your offer of help. I hope that my reply helps clarify
>> rather than muddy the situation.
>>
>> Best wishes
>> Andy
>>
>>
>> On 17/09/2020 08:43, Abby Spurdle wrote:
>>> I'm not familiar with these subjects.
>>> And hopefully, someone who is, will offer some better suggestions.
>>>
>>> But to get things started, maybe...
>>> (1) What packages are you using (re: tdm)?
>>> (2) Where does the problem happen, in dist, hclust, the plot method
>>> for hclust, or in the package(s) you are using?
>>> (3) Do you think you could produce a small reproducible example,
>>> showing what is wrong, and explaining you would like it to do instead?
>>>
>>> Note that if the problem relates to hclust, or the plot method, then
>>> you should be able to produce a much simpler example.
>>> e.g.
>>>
>>>       mycount.matrix <- matrix (rpois (25000, 20),, 5)
>>>       head (mycount.matrix, 3)
>>>       tail (mycount.matrix, 3)
>>>
>>>       plot (hclust (dist (mycount.matrix) ) )
>>>
>>> On Tue, Sep 15, 2020 at 6:54 AM Andrew <phaedrusv at gmail.com> wrote:
>>>> Hello all
>>>>
>>>> I am doing some text mining on a set of five plain text files and have
>>>> run into a snag when I run hclust in that there are just too many leaves
>>>> for anything to be read. It returns a solid black line.
>>>>
>>>> The texts have been converted into a TDM which has a dim of 5,292 and 5
>>>> (as per 5 docs).
>>>>
>>>> My code for removing sparsity is as follows:
>>>>
>>>>    > tdm2 <- removeSparseTerms(tdm, sparse=0.99999)
>>>>
>>>>    > inspect(tdm2)
>>>>
>>>> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
>>>> Non-/sparse entries: 10415/16045
>>>> Sparsity           : 61%
>>>> Maximal term length: 22
>>>> Weighting          : term frequency (tf)
>>>>
>>>> While the tf-idf weighting returns this when 0.99999 sparseness is removed:
>>>>
>>>>    > inspect(tdm.tfidf)
>>>> <<TermDocumentMatrix (terms: 5292, documents: 5)>>
>>>> Non-/sparse entries: 7915/18545
>>>> Sparsity           : 70%
>>>> Maximal term length: 22
>>>> Weighting          : term frequency - inverse document frequency
>>>> (normalized) (tf-idf)
>>>>
>>>> I have experimented by decreasing the value I use for decreasing
>>>> sparseness, and that helps a bit, for example:
>>>>
>>>>    > tdm2 <- removeSparseTerms(tdm, sparse=0.215)
>>>>    > inspect(tdm2)
>>>> <<TermDocumentMatrix (terms: 869, documents: 5)>>
>>>> Non-/sparse entries: 3976/369
>>>> Sparsity           : 8%
>>>> Maximal term length: 14
>>>> Weighting          : term frequency (tf)
>>>>
>>>> But, no matter what I do, the resulting plot is unreadable. The code for
>>>> plotting the cluster is:
>>>>
>>>>    > hc <- hclust(dist(tdm2, method = "euclidean"), method = "complete")
>>>>    > plot(hc, yaxt = 'n', main = "Hierarchical clustering")
>>>>
>>>> Can someone kindly either advise me what I am doing wrong and/ or
>>>> signpost me to some detailed info on how to fix this.
>>>>
>>>> Many thanks in anticipation.
>>>>
>>>> Andy
>>>>
>>>>
>>>>           [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jrkr|de@u @end|ng |rom gm@||@com  Fri Sep 18 14:52:28 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 18 Sep 2020 08:52:28 -0400
Subject: [R] how to overlay two histograms
In-Reply-To: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>
References: <CAF9-5jMXRQx3Rio7qgcLn8LGEMHfq363Wm4FQtzkBbYYua-vrA@mail.gmail.com>
Message-ID: <CAKZQJMD4MvikwMh+_wQyvQVDQPHDB+EjSKopR8rAbou=8pBsyA@mail.gmail.com>

Is this what you want?

ggplot(d, aes(counts, fill = name)) +
      geom_bar(stat = "bin", position = "dodge")

Note: You probably should play around with the "bin" width.

On Thu, 17 Sep 2020 at 18:05, Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I am trying to overlay two histograms with this:
>
> p <- ggplot(d, aes(CHR, counts, fill = name)) + geom_bar(position =
> "dodge")
> p
>
> but I am getting this error:
> Error: stat_count() can only have an x or y aesthetic.
> Run `rlang::last_error()` to see where the error occurred.
>
> my data is this:
>
> > d
>    CHR counts name
> 1    1 193554  old
> 2    2 220816  old
> 3    3 174350  old
> 4    4 163112  old
> 5    5 168125  old
> 6    6 182366  old
> 7    7 143023  old
> 8    8 147410  old
> 9    9 122112  old
> 10  10 138394  old
> 11  11 130069  old
> 12  12 124850  old
> 13  13 104119  old
> 14  14  83931  old
> 15  15  72287  old
> 16  16  71550  old
> 17  17  58380  old
> 18  18  76812  old
> 19  19  37040  old
> 20  20  63407  old
> 21  21  33863  old
> 22  22  33812  old
> 23   1 202783  new
> 24   2 252124  new
> 25   3 213337  new
> 26   4 201001  new
> 27   5 207606  new
> 28   6 228133  new
> 29   7 147218  new
> 30   8 177518  new
> 31   9 121276  new
> 32  10 163447  new
> 33  11 158724  new
> 34  12 142183  new
> 35  13 111189  new
> 36  14  83043  new
> 37  15  61063  new
> 38  16  55439  new
> 39  17  32883  new
> 40  18  69135  new
> 41  19  16624  new
> 42  20  48541  new
> 43  21  25479  new
> 44  22  19698  new
>
> Basically I need to show counts per CHR in "old" and "new" side by side.
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Sep 18 17:26:50 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 18 Sep 2020 10:26:50 -0500
Subject: [R] Creating animation in R Notebooks
References: <000001d68dd0$21f29bb0$65d7d310$.ref@sbcglobal.net>
Message-ID: <000001d68dd0$21f29bb0$65d7d310$@sbcglobal.net>

r-help forum

 

Has anyone created an animations within a R-Notebook. I'm trying to create
an animation within a R -Notebook and while my code works outside of a
notebook (Console) but inside the R-Notebook framework I only get a list of
the  *.png files. Any suggestions?

 

path.animate.plot <- mymap.paths +

  transition_reveal(along = date) +

  labs(title = 'Date: {frame_along}')  # Add a label on top to say what date
each frame is

 

animate(path.animate.plot,

        fps = 3, # frames per second

        nframes = 200) # default is 100 frames

 

  [1] "./gganim_plot0001.png" "./gganim_plot0002.png"
"./gganim_plot0003.png" "./gganim_plot0004.png"

  [5] "./gganim_plot0005.png" "./gganim_plot0006.png"
"./gganim_plot0007.png" "./gganim_plot0008.png"

  [9] "./gganim_plot0009.png" "./gganim_plot0010.png"
"./gganim_plot0011.png" "./gganim_plot0012.png" ..

 

Jeff Reichman


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 18 18:55:30 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 18 Sep 2020 09:55:30 -0700
Subject: [R] Creating animation in R Notebooks
In-Reply-To: <000001d68dd0$21f29bb0$65d7d310$@sbcglobal.net>
References: <000001d68dd0$21f29bb0$65d7d310$.ref@sbcglobal.net>
 <000001d68dd0$21f29bb0$65d7d310$@sbcglobal.net>
Message-ID: <CAGxFJbSArrKjKE9LGvLNiHqnGU54UzXU_RGNL4GxNYzcF1cLzA@mail.gmail.com>

Maybe better asked here: https://community.rstudio.com/
as this is largely an RStudio product.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 18, 2020 at 8:27 AM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> r-help forum
>
>
>
> Has anyone created an animations within a R-Notebook. I'm trying to create
> an animation within a R -Notebook and while my code works outside of a
> notebook (Console) but inside the R-Notebook framework I only get a list of
> the  *.png files. Any suggestions?
>
>
>
> path.animate.plot <- mymap.paths +
>
>   transition_reveal(along = date) +
>
>   labs(title = 'Date: {frame_along}')  # Add a label on top to say what
> date
> each frame is
>
>
>
> animate(path.animate.plot,
>
>         fps = 3, # frames per second
>
>         nframes = 200) # default is 100 frames
>
>
>
>   [1] "./gganim_plot0001.png" "./gganim_plot0002.png"
> "./gganim_plot0003.png" "./gganim_plot0004.png"
>
>   [5] "./gganim_plot0005.png" "./gganim_plot0006.png"
> "./gganim_plot0007.png" "./gganim_plot0008.png"
>
>   [9] "./gganim_plot0009.png" "./gganim_plot0010.png"
> "./gganim_plot0011.png" "./gganim_plot0012.png" ..
>
>
>
> Jeff Reichman
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jho|tm@n @end|ng |rom gm@||@com  Fri Sep 18 19:52:42 2020
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Fri, 18 Sep 2020 10:52:42 -0700
Subject: [R] fusion of two matrices (numerical and logical)
In-Reply-To: <CAGxFJbSKvodBk1kvP5DQmdFN+kNihgKOr_szPYRykMQaoPABwA@mail.gmail.com>
References: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
 <CAGxFJbSKvodBk1kvP5DQmdFN+kNihgKOr_szPYRykMQaoPABwA@mail.gmail.com>
Message-ID: <CAAxdm-7WQ5F1WT5H6R-_nNJOY8vG_oeZ1=6VfXNAsAJrJEYpAg@mail.gmail.com>

Here is a way of doing it using the 'arr.ind' option in 'which'

> A <- 1:20
> B <- matrix(A,nrow=5,ncol=4)
> B
     [,1] [,2] [,3] [,4]
[1,]    1    6   11   16
[2,]    2    7   12   17
[3,]    3    8   13   18
[4,]    4    9   14   19
[5,]    5   10   15   20
> # B is a numerical matrix
> C <- B<7
> C[4,4] <- TRUE
> C
     [,1]  [,2]  [,3]  [,4]
[1,] TRUE  TRUE FALSE FALSE
[2,] TRUE FALSE FALSE FALSE
[3,] TRUE FALSE FALSE FALSE
[4,] TRUE FALSE FALSE  TRUE
[5,] TRUE FALSE FALSE FALSE
>
> # initialize a 'result' with zeros
> result <- array(0, dim = dim(B))
>
> # get the indices of values to replace
> indx <- which(C, arr.ind = TRUE)
>
> result[indx] <- B[indx]
>
> result
     [,1] [,2] [,3] [,4]
[1,]    1    6    0    0
[2,]    2    0    0    0
[3,]    3    0    0    0
[4,]    4    0    0   19
[5,]    5    0    0    0
>


Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Sat, Sep 5, 2020 at 11:51 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> A is not a matrix. I presume you meant B. If so:
>
> > B[!C] <- 0
> > B
>      [,1] [,2] [,3] [,4]
> [1,]    1    6    0    0
> [2,]    2    0    0    0
> [3,]    3    0    0    0
> [4,]    4    0    0   19
> [5,]    5    0    0    0
>
> Cheers,
> Bert
>
>
>
>
>
> On Sat, Sep 5, 2020 at 11:18 AM Vivek Sutradhara <viveksutra at gmail.com>
> wrote:
>
> > Hi
> > I would like to get help in combining two matrices. Here is my example:
> > A <- 1:20
> > B <- matrix(A,nrow=5,ncol=4)
> > # B is a numerical matrix
> > C <- B<7
> > C[4,4] <- TRUE
> > # C is a logical matrix
> > # if I combine A and C, I get a vector
> > D1 <- A[C==TRUE]
> > D1
> > D2 <- A[C==FALSE]
> > D2
> >
> > I want to get a matrix with the same dimensions as matrix A. At the
> > coordinates given by the vector D1, I want to retain the values in
> > matrix A. At the locations in D2, I want a zero value.
> > I want to know if I can do this without using any loops.
> > Thanks, Vivek
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 18 20:19:04 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 18 Sep 2020 11:19:04 -0700
Subject: [R] Creating animation in R Notebooks
In-Reply-To: <000001d68dd0$21f29bb0$65d7d310$@sbcglobal.net>
References: <000001d68dd0$21f29bb0$65d7d310$.ref@sbcglobal.net>
 <000001d68dd0$21f29bb0$65d7d310$@sbcglobal.net>
Message-ID: <76b935b0-fa5f-bb66-fad0-36bed609a467@comcast.net>

https://bookdown.org/yihui/rmarkdown-cookbook/animation.html

On 9/18/20 8:26 AM, Jeff Reichman wrote:
> r-help forum
>
>   
>
> Has anyone created an animations within a R-Notebook. I'm trying to create
> an animation within a R -Notebook and while my code works outside of a
> notebook (Console) but inside the R-Notebook framework I only get a list of
> the  *.png files. Any suggestions?
>
>   
>
> path.animate.plot <- mymap.paths +
>
>    transition_reveal(along = date) +
>
>    labs(title = 'Date: {frame_along}')  # Add a label on top to say what date
> each frame is
>
>   
>
> animate(path.animate.plot,
>
>          fps = 3, # frames per second
>
>          nframes = 200) # default is 100 frames
>
>   
>
>    [1] "./gganim_plot0001.png" "./gganim_plot0002.png"
> "./gganim_plot0003.png" "./gganim_plot0004.png"
>
>    [5] "./gganim_plot0005.png" "./gganim_plot0006.png"
> "./gganim_plot0007.png" "./gganim_plot0008.png"
>
>    [9] "./gganim_plot0009.png" "./gganim_plot0010.png"
> "./gganim_plot0011.png" "./gganim_plot0012.png" ..
>
>   
>
> Jeff Reichman
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 18 20:22:07 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 18 Sep 2020 11:22:07 -0700
Subject: [R] Creating animation in R Notebooks
In-Reply-To: <CAGxFJbSArrKjKE9LGvLNiHqnGU54UzXU_RGNL4GxNYzcF1cLzA@mail.gmail.com>
References: <000001d68dd0$21f29bb0$65d7d310$.ref@sbcglobal.net>
 <000001d68dd0$21f29bb0$65d7d310$@sbcglobal.net>
 <CAGxFJbSArrKjKE9LGvLNiHqnGU54UzXU_RGNL4GxNYzcF1cLzA@mail.gmail.com>
Message-ID: <D4617CDD-4BDC-4E1E-B35B-DA6569175797@dcn.davis.ca.us>

It is part of a CRAN package rmarkdown, but major contributed packages are indeed outside the scope of this list regardless of where they come from.

Google is as always your friend: https://community.rstudio.com/t/make-an-rstudio-notebook-inline-animation-that-loops-with-gganimate/27489/2

On September 18, 2020 9:55:30 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Maybe better asked here: https://community.rstudio.com/
>as this is largely an RStudio product.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Fri, Sep 18, 2020 at 8:27 AM Jeff Reichman <reichmanj at sbcglobal.net>
>wrote:
>
>> r-help forum
>>
>>
>>
>> Has anyone created an animations within a R-Notebook. I'm trying to
>create
>> an animation within a R -Notebook and while my code works outside of
>a
>> notebook (Console) but inside the R-Notebook framework I only get a
>list of
>> the  *.png files. Any suggestions?
>>
>>
>>
>> path.animate.plot <- mymap.paths +
>>
>>   transition_reveal(along = date) +
>>
>>   labs(title = 'Date: {frame_along}')  # Add a label on top to say
>what
>> date
>> each frame is
>>
>>
>>
>> animate(path.animate.plot,
>>
>>         fps = 3, # frames per second
>>
>>         nframes = 200) # default is 100 frames
>>
>>
>>
>>   [1] "./gganim_plot0001.png" "./gganim_plot0002.png"
>> "./gganim_plot0003.png" "./gganim_plot0004.png"
>>
>>   [5] "./gganim_plot0005.png" "./gganim_plot0006.png"
>> "./gganim_plot0007.png" "./gganim_plot0008.png"
>>
>>   [9] "./gganim_plot0009.png" "./gganim_plot0010.png"
>> "./gganim_plot0011.png" "./gganim_plot0012.png" ..
>>
>>
>>
>> Jeff Reichman
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Sep 18 22:21:06 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 18 Sep 2020 15:21:06 -0500
Subject: [R] Creating animation in R Notebooks
In-Reply-To: <76b935b0-fa5f-bb66-fad0-36bed609a467@comcast.net>
References: <000001d68dd0$21f29bb0$65d7d310$.ref@sbcglobal.net>
 <000001d68dd0$21f29bb0$65d7d310$@sbcglobal.net>
 <76b935b0-fa5f-bb66-fad0-36bed609a467@comcast.net>
Message-ID: <001101d68df9$3e33e5d0$ba9bb170$@sbcglobal.net>

David

The reference helped thank you. The "gifski" library corrected the issue

Jeff

-----Original Message-----
From: David Winsemius <dwinsemius at comcast.net> 
Sent: Friday, September 18, 2020 1:19 PM
To: reichmanj at sbcglobal.net; r-help at r-project.org
Subject: Re: [R] Creating animation in R Notebooks

https://bookdown.org/yihui/rmarkdown-cookbook/animation.html

On 9/18/20 8:26 AM, Jeff Reichman wrote:
> r-help forum
>
>   
>
> Has anyone created an animations within a R-Notebook. I'm trying to 
> create an animation within a R -Notebook and while my code works 
> outside of a notebook (Console) but inside the R-Notebook framework I 
> only get a list of the  *.png files. Any suggestions?
>
>   
>
> path.animate.plot <- mymap.paths +
>
>    transition_reveal(along = date) +
>
>    labs(title = 'Date: {frame_along}')  # Add a label on top to say 
> what date each frame is
>
>   
>
> animate(path.animate.plot,
>
>          fps = 3, # frames per second
>
>          nframes = 200) # default is 100 frames
>
>   
>
>    [1] "./gganim_plot0001.png" "./gganim_plot0002.png"
> "./gganim_plot0003.png" "./gganim_plot0004.png"
>
>    [5] "./gganim_plot0005.png" "./gganim_plot0006.png"
> "./gganim_plot0007.png" "./gganim_plot0008.png"
>
>    [9] "./gganim_plot0009.png" "./gganim_plot0010.png"
> "./gganim_plot0011.png" "./gganim_plot0012.png" ..
>
>   
>
> Jeff Reichman
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Sat Sep 19 03:34:43 2020
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Fri, 18 Sep 2020 21:34:43 -0400
Subject: [R] Mapping 2D to 3D
In-Reply-To: <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
Message-ID: <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>

On 09/18/2020 02:26 AM, Jeff Newmiller wrote:
> No, but fortunately you are off in the weeds. Density has an internally-computed "z" coordinate... you should be looking at ?geom_contour.
>
> On September 17, 2020 7:17:33 PM PDT, H <agents at meddatainc.com> wrote:
>> I am trying to understand how to map 2D to 3D using ggplot() and
>> eventually plot_gg(). I am, however, stuck on understanding how to
>> express the third variable to be mapped. This example:
>>
>> ggdiamonds = ggplot(diamonds, aes(x, depth)) +
>> stat_density_2d(aes(fill = stat(nlevel)),
>> geom = "polygon", n = 100, bins = 10,contour = TRUE) +
>> facet_wrap(clarity~.) +
>> scale_fill_viridis_c(option = "A")
>>
>> uses a variable nlevel that I now understand is calculated during the
>> building of the ggplot but I have not figured out from where it is
>> calculated or how to specify a variable of my choosing.
>>
>> Does anyone have a good reference for understanding how to specify this
>> variable? Most examples on the 'net seem to use the same dataset but do
>> not specify this particular aspect...
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

But looking at the code in my message above, how does one know what stat(nlevel) refers to? What if I wanted to map another variable in this particular dataset??


From @gent@ @end|ng |rom medd@t@|nc@com  Sat Sep 19 02:25:10 2020
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Fri, 18 Sep 2020 20:25:10 -0400
Subject: [R] Mapping 2D to 3D
In-Reply-To: <CAFKNbkJos64PuEjpbswhP_+NuRy3_2QfwnWs4iyEo9JqbeBQ2Q@mail.gmail.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <CAFKNbkJos64PuEjpbswhP_+NuRy3_2QfwnWs4iyEo9JqbeBQ2Q@mail.gmail.com>
Message-ID: <05bd4e60-cb7a-7124-4d73-291f70d30a7e@meddatainc.com>

On 09/18/2020 03:08 AM, Carlos Ortega wrote:
> Hi,
>
> There are some further references in the own "RStudio Community" and in StackOverflow:
>
>   * https://community.rstudio.com/t/options-to-stat-density-2d/792/4
>   * https://stackoverflow.com/questions/32206623/what-does-level-mean-in-ggplotstat-density2d
>
> Kind Regards,
> Carlos.
>
>
> On Fri, Sep 18, 2020 at 4:17 AM H <agents at meddatainc.com <mailto:agents at meddatainc.com>> wrote:
>
>     I am trying to understand how to map 2D to 3D using ggplot() and eventually plot_gg(). I am, however, stuck on understanding how to express the third variable to be mapped. This example:
>
>     ggdiamonds = ggplot(diamonds, aes(x, depth)) +
>     stat_density_2d(aes(fill = stat(nlevel)),
>     geom = "polygon", n = 100, bins = 10,contour = TRUE) +
>     facet_wrap(clarity~.) +
>     scale_fill_viridis_c(option = "A")
>
>     uses a variable nlevel that I now understand is calculated during the building of the ggplot but I have not figured out from where it is calculated or how to specify a variable of my choosing.
>
>     Does anyone have a good reference for understanding how to specify this variable? Most examples on the 'net seem to use the same dataset but do not specify this particular aspect...
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
Yes, these are two of the links I found but unfortunately they do not explain enough. In the second link there is the reference to an internal dataframe etc. but I can still not figure out how to specify a z-variable of my choosing when I am creating this type of plot...


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep 19 06:42:46 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 18 Sep 2020 21:42:46 -0700
Subject: [R] Mapping 2D to 3D
In-Reply-To: <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
 <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>
Message-ID: <27781FDA-86C0-4773-8174-F1D6E55FBCCA@dcn.davis.ca.us>

When dealing with a 2-d density plot, the z variable is a predefined function of your x and y data, it is not something you can specify. If you want to specify z, then you need to use geom_contour. You appear to need to study the theory of kernel density estimates, which is off topic here. (Technically contributed packages like ggplot2 are off topic here also, though sometimes people will answer questions about them anyway.)

On September 18, 2020 6:34:43 PM PDT, H <agents at meddatainc.com> wrote:
>On 09/18/2020 02:26 AM, Jeff Newmiller wrote:
>> No, but fortunately you are off in the weeds. Density has an
>internally-computed "z" coordinate... you should be looking at
>?geom_contour.
>>
>> On September 17, 2020 7:17:33 PM PDT, H <agents at meddatainc.com>
>wrote:
>>> I am trying to understand how to map 2D to 3D using ggplot() and
>>> eventually plot_gg(). I am, however, stuck on understanding how to
>>> express the third variable to be mapped. This example:
>>>
>>> ggdiamonds = ggplot(diamonds, aes(x, depth)) +
>>> stat_density_2d(aes(fill = stat(nlevel)),
>>> geom = "polygon", n = 100, bins = 10,contour = TRUE) +
>>> facet_wrap(clarity~.) +
>>> scale_fill_viridis_c(option = "A")
>>>
>>> uses a variable nlevel that I now understand is calculated during
>the
>>> building of the ggplot but I have not figured out from where it is
>>> calculated or how to specify a variable of my choosing.
>>>
>>> Does anyone have a good reference for understanding how to specify
>this
>>> variable? Most examples on the 'net seem to use the same dataset but
>do
>>> not specify this particular aspect...
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>But looking at the code in my message above, how does one know what
>stat(nlevel) refers to? What if I wanted to map another variable in
>this particular dataset??
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From erh@||@m96 @end|ng |rom gm@||@com  Fri Sep 18 19:19:48 2020
From: erh@||@m96 @end|ng |rom gm@||@com (Raija Hallam)
Date: Fri, 18 Sep 2020 18:19:48 +0100
Subject: [R] Stats help for dissertation project
Message-ID: <CAKKSomRQxLxOyASmqjtR4dGdtmOjc7Tj36e1F+a+NkyYn-932A@mail.gmail.com>

Hello,

I am a conservation Masters student who is new to R and in need of some
confirmation of my methods/ stats help!

My dissertation project is looking at the micronutrient intake (iron, zinc,
calcium, magnesium and folic acid/folate) of 18 female monkeys, 14 of which
are reproductively 'successful' (their infant survived past 1 year) and 4
of which are reproductively 'unsuccessful' (their infant did not survive to
1 year). The females go through a number of stages throughout their
pregnancy, and I would like to focus on 2 of these stages, early gestation
and early lactation, as these appear in the literature to be important
stages in terms of nutrition. Each stage is broken down into 4 week periods
so I have G1, G2 and G3 as early gestation and L1, L2, L3 and L4 as early
lactation. These could also be combined into just 2 reproductive stages;
early gestation (EG) and early lactation (EL), to make the model a bit
simpler.


*I first would like to investigate how micronutrient intake is affected by
the reproductive stage of females.*

To investigate this I am thinking of doing a multivariate multiple
regression general linear model, controlling for Female ID:
ironintake ~ repphase + (1/FemaleID)
zincintake ~ repphase + (1/FemaleID)
etc.


*I would also like to investigate how the micronutrients they intake affect
reproductive 'successfulness'.*

To investigate this I am thinking of doing a binomial logistic regression
generalised linear model, again controlling for Female ID:
Repsuccess ~ ironintake + zincintake + calciumintake etc... +(1/FemaleID)


As I'm new to R and a bit rusty with my stats knowledge I would be very
grateful for any comments on my current stats tests and methods outlined
above. If there are other tests that would fit my data better then I'm all
ears!

Thank you!

	[[alternative HTML version deleted]]


From peter@w@g|ey09 @end|ng |rom gm@||@com  Sat Sep 19 10:28:56 2020
From: peter@w@g|ey09 @end|ng |rom gm@||@com (Peter Wagey)
Date: Sat, 19 Sep 2020 01:28:56 -0700
Subject: [R] How can we get a predicted value that are used to plot the
 figure using a plot_model function of sjPlot?
Message-ID: <CAA7XnHfDMri9ewEhtDm5mLsy7gmWh6DA0KpZJxsOhwO7H9t3KQ@mail.gmail.com>

Hi R users,
I was trying to create a figure of three-way-interactions. There is a
function "plot-model" but I was wondering whether we can extract the
predicted value before we run the "plot-model" function.
For example:
in this example,
plot_model(fit, type = "pred", terms = c("c12hour", "barthtot [30,50,70]",
"c161sex"))
How can we see the predicted values that are used to plot the figure? If we
can see the data (predicted values), we could use other functions to create
another type of figures.
Thank you very much for your suggestions.

Thanks,

Peter
#############
library(sjPlot)
library(sjmisc)
library(ggplot2)
data(efc)
theme_set(theme_sjplot())

# make categorical
efc$c161sex <- to_factor(efc$c161sex)

# fit model with 3-way-interaction
fit <- lm(neg_c_7 ~ c12hour * barthtot * c161sex, data = efc)

# select only levels 30, 50 and 70 from continuous variable Barthel-Index
plot_model(fit, type = "pred", terms = c("c12hour", "barthtot [30,50,70]",
"c161sex"))

How can we get the predicted value that is used to plot the graph? we would
like to see the predicted value using three groups of barthtot
[30,50,70].Is there any way we can extract the data (predicted value) so
that we can use other graphic functions to create figures?

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sat Sep 19 10:54:43 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 19 Sep 2020 20:54:43 +1200
Subject: [R] fusion of two matrices (numerical and logical)
In-Reply-To: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
References: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
Message-ID: <CABcYAdL_cXGkNV05=Zyz21PBSjHVXaO05jXtphpzJt19FrfFjg@mail.gmail.com>

(1) Using 'C == TRUE' (when you know C is logical)
    is equivalent to just plain C, only obscure.
    Similarly, 'C == FALSE' is more confusing than !C.

(2) Consider B[C].  The rows of C have 2, 1, 1, 2, 1 TRUE.
    entries, so the result here *cannot* be a rectangular array.
    And whatever it is, it contains only the elements where C
    is true.

(3) You probably already knew that 'ifelse' is vectorised.
    What you may not have realised is that it preserves
    array dimensions as well.

> A <- cbind(c(1,2), c(3,4))
> B <- cbind(c(5,6), c(7,8))
> C <- cbind(c(FALSE,TRUE), c(TRUE,FALSE))
> ifelse(C, A, B)
     [,1] [,2]
[1,]    5    3
[2,]    2    8
> ifelse(C, A, 0)
     [,1] [,2]
[1,]    0    3
[2,]    2    0

Isn't it nice when the obvious code just works?


On Sun, 6 Sep 2020 at 06:18, Vivek Sutradhara <viveksutra at gmail.com> wrote:

> Hi
> I would like to get help in combining two matrices. Here is my example:
> A <- 1:20
> B <- matrix(A,nrow=5,ncol=4)
> # B is a numerical matrix
> C <- B<7
> C[4,4] <- TRUE
> # C is a logical matrix
> # if I combine A and C, I get a vector
> D1 <- A[C==TRUE]
> D1
> D2 <- A[C==FALSE]
> D2
>
> I want to get a matrix with the same dimensions as matrix A. At the
> coordinates given by the vector D1, I want to retain the values in
> matrix A. At the locations in D2, I want a zero value.
> I want to know if I can do this without using any loops.
> Thanks, Vivek
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sat Sep 19 12:29:45 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sat, 19 Sep 2020 11:29:45 +0100
Subject: [R] Stats help for dissertation project
In-Reply-To: <CAKKSomRQxLxOyASmqjtR4dGdtmOjc7Tj36e1F+a+NkyYn-932A@mail.gmail.com>
References: <CAKKSomRQxLxOyASmqjtR4dGdtmOjc7Tj36e1F+a+NkyYn-932A@mail.gmail.com>
Message-ID: <e905eccd-24c2-74e9-8a7c-3bf5ba0283ef@dewey.myzen.co.uk>

Dear Raija

This list is primarily for R programming questions so most of your post 
is off-topic here. If you are registered for a degree presumably someone 
is paying a fee to your institution and someone there is being paid to 
supervise your project so I would have thought they would be the first 
port of call. If they fail to meet their obligations then there is a 
site Cross Validated where you may have better luck.

Michael

On 18/09/2020 18:19, Raija Hallam wrote:
> Hello,
> 
> I am a conservation Masters student who is new to R and in need of some
> confirmation of my methods/ stats help!
> 
> My dissertation project is looking at the micronutrient intake (iron, zinc,
> calcium, magnesium and folic acid/folate) of 18 female monkeys, 14 of which
> are reproductively 'successful' (their infant survived past 1 year) and 4
> of which are reproductively 'unsuccessful' (their infant did not survive to
> 1 year). The females go through a number of stages throughout their
> pregnancy, and I would like to focus on 2 of these stages, early gestation
> and early lactation, as these appear in the literature to be important
> stages in terms of nutrition. Each stage is broken down into 4 week periods
> so I have G1, G2 and G3 as early gestation and L1, L2, L3 and L4 as early
> lactation. These could also be combined into just 2 reproductive stages;
> early gestation (EG) and early lactation (EL), to make the model a bit
> simpler.
> 
> 
> *I first would like to investigate how micronutrient intake is affected by
> the reproductive stage of females.*
> 
> To investigate this I am thinking of doing a multivariate multiple
> regression general linear model, controlling for Female ID:
> ironintake ~ repphase + (1/FemaleID)
> zincintake ~ repphase + (1/FemaleID)
> etc.
> 
> 
> *I would also like to investigate how the micronutrients they intake affect
> reproductive 'successfulness'.*
> 
> To investigate this I am thinking of doing a binomial logistic regression
> generalised linear model, again controlling for Female ID:
> Repsuccess ~ ironintake + zincintake + calciumintake etc... +(1/FemaleID)
> 
> 
> As I'm new to R and a bit rusty with my stats knowledge I would be very
> grateful for any comments on my current stats tests and methods outlined
> above. If there are other tests that would fit my data better then I'm all
> ears!
> 
> Thank you!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From r@oknz @end|ng |rom gm@||@com  Sat Sep 19 13:32:58 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 19 Sep 2020 23:32:58 +1200
Subject: [R] Stats help for dissertation project
In-Reply-To: <e905eccd-24c2-74e9-8a7c-3bf5ba0283ef@dewey.myzen.co.uk>
References: <CAKKSomRQxLxOyASmqjtR4dGdtmOjc7Tj36e1F+a+NkyYn-932A@mail.gmail.com>
 <e905eccd-24c2-74e9-8a7c-3bf5ba0283ef@dewey.myzen.co.uk>
Message-ID: <CABcYAdLEspmhfELEZwRU=DRgbMeJzRA_TtU9A==UN1ycQ1y-CQ@mail.gmail.com>

In fairness to Raija Hallam, I've met masters and doctoral students whose
supervisors hadn't a clue.  (Heck, I once worked at a University where the
staff evaluation process involved taking the means of 5-point ordinal
variables...)  Two of these cases stick in my mind: one where the student
had more observed variables than cases, and one where the student was
controlling for the effect of the order in which the treatments were
applied by applying the treatments in the same order to every subject.

To Raija Hallam, do web searches for "linear regression in R" and "logistic
regression in R".  Look at the R web site r-project.org, specifically at
https://www.r-project.org/doc/bib/R-books.html
Print off a copy of that list of books, go to your University library, and
borrow a couple, maybe an introductory book and "An R Companion to Applied
Regression".

It is incredibly important that you have a very clear idea of your research
question, your experiment structure, and the nature of your data.
Here's one point which even your supervisor is very likely to miss:
the micronutrient analysis *MAY* best be regarded as COMPOSITIONAL DATA.
R has a package called "compositions" that may be helpful.  The description
says "Regression, classification, contour plots, hypothesis testing and
fitting of distributions for compositional data are some of the functions
included. The standard text-book for such data is John Aitchison's (1986)
``The statistical analysis of compositional data''. Chapman & Hall."

If I am right about this, then analysing your data using "standard"
techniques may be *seriously* misleading.  Ask your supervisor to
find a statistician who can talk to you about your problem; at my former
university we'd probably suggest inviting co-supervision to make sure
your statistical analyses are credible.


On Sat, 19 Sep 2020 at 22:30, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Raija
>
> This list is primarily for R programming questions so most of your post
> is off-topic here. If you are registered for a degree presumably someone
> is paying a fee to your institution and someone there is being paid to
> supervise your project so I would have thought they would be the first
> port of call. If they fail to meet their obligations then there is a
> site Cross Validated where you may have better luck.
>
> Michael
>
> On 18/09/2020 18:19, Raija Hallam wrote:
> > Hello,
> >
> > I am a conservation Masters student who is new to R and in need of some
> > confirmation of my methods/ stats help!
> >
> > My dissertation project is looking at the micronutrient intake (iron,
> zinc,
> > calcium, magnesium and folic acid/folate) of 18 female monkeys, 14 of
> which
> > are reproductively 'successful' (their infant survived past 1 year) and 4
> > of which are reproductively 'unsuccessful' (their infant did not survive
> to
> > 1 year). The females go through a number of stages throughout their
> > pregnancy, and I would like to focus on 2 of these stages, early
> gestation
> > and early lactation, as these appear in the literature to be important
> > stages in terms of nutrition. Each stage is broken down into 4 week
> periods
> > so I have G1, G2 and G3 as early gestation and L1, L2, L3 and L4 as early
> > lactation. These could also be combined into just 2 reproductive stages;
> > early gestation (EG) and early lactation (EL), to make the model a bit
> > simpler.
> >
> >
> > *I first would like to investigate how micronutrient intake is affected
> by
> > the reproductive stage of females.*
> >
> > To investigate this I am thinking of doing a multivariate multiple
> > regression general linear model, controlling for Female ID:
> > ironintake ~ repphase + (1/FemaleID)
> > zincintake ~ repphase + (1/FemaleID)
> > etc.
> >
> >
> > *I would also like to investigate how the micronutrients they intake
> affect
> > reproductive 'successfulness'.*
> >
> > To investigate this I am thinking of doing a binomial logistic regression
> > generalised linear model, again controlling for Female ID:
> > Repsuccess ~ ironintake + zincintake + calciumintake etc... +(1/FemaleID)
> >
> >
> > As I'm new to R and a bit rusty with my stats knowledge I would be very
> > grateful for any comments on my current stats tests and methods outlined
> > above. If there are other tests that would fit my data better then I'm
> all
> > ears!
> >
> > Thank you!
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eeor@@h@p|r@ @end|ng |rom c|t|@com  Fri Sep 18 19:39:27 2020
From: |eeor@@h@p|r@ @end|ng |rom c|t|@com (Shapira, Leeor )
Date: Fri, 18 Sep 2020 17:39:27 +0000
Subject: [R] CRAN R For Windows 3.6.3
Message-ID: <2aaa2b0a3a55492e9add7fd3d5385872@imcnam.ssmb.com>

Can you please let me know the End of Life and End of Vendor Support dates for CRAN R for Windows 3.6.3? Thank you.


	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep 19 19:44:10 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 19 Sep 2020 13:44:10 -0400
Subject: [R] CRAN R For Windows 3.6.3
In-Reply-To: <2aaa2b0a3a55492e9add7fd3d5385872@imcnam.ssmb.com>
References: <2aaa2b0a3a55492e9add7fd3d5385872@imcnam.ssmb.com>
Message-ID: <c7a4e353-88b8-d2d9-86ce-1246d4993e54@gmail.com>

On 18/09/2020 1:39 p.m., Shapira, Leeor via R-help wrote:
> Can you please let me know the End of Life and End of Vendor Support dates for CRAN R for Windows 3.6.3? Thank you.

R doesn't have either of those.  There is no vendor support ever.  It is 
free software; it is up to its users to support it.  On the other hand, 
it is free software, so you can use it forever.

In practice, there is de facto support from its authors in that they are 
very responsive to bug reports.  That ends with the next release, so 
3.6.3 support ended in April, 2020 when R 4.0.0 was released.

Another way to think of support and end of life equivalents is to ask 
how long CRAN will provide the source code to packages for it.  There 
are no time limits on that, though it can be some work to find a set and 
tools to build them if you are using older releases.

And finally, you might want to know how long CRAN will keep updating 
binary packages for R 3.6.3.  I think that should continue until the 
release of R 4.1.0, sometime around April 2021.

Duncan Murdoch


From @gent@ @end|ng |rom medd@t@|nc@com  Sat Sep 19 19:50:24 2020
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Sat, 19 Sep 2020 13:50:24 -0400
Subject: [R] Mapping 2D to 3D
In-Reply-To: <27781FDA-86C0-4773-8174-F1D6E55FBCCA@dcn.davis.ca.us>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
 <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>
 <27781FDA-86C0-4773-8174-F1D6E55FBCCA@dcn.davis.ca.us>
Message-ID: <1ba072c9-b07c-a6ad-21e9-7f33ec20ea00@meddatainc.com>

On 09/19/2020 12:42 AM, Jeff Newmiller wrote:
> When dealing with a 2-d density plot, the z variable is a predefined function of your x and y data, it is not something you can specify. If you want to specify z, then you need to use geom_contour. You appear to need to study the theory of kernel density estimates, which is off topic here. (Technically contributed packages like ggplot2 are off topic here also, though sometimes people will answer questions about them anyway.)
>
> On September 18, 2020 6:34:43 PM PDT, H <agents at meddatainc.com> wrote:
>> On 09/18/2020 02:26 AM, Jeff Newmiller wrote:
>>> No, but fortunately you are off in the weeds. Density has an
>> internally-computed "z" coordinate... you should be looking at
>> ?geom_contour.
>>> On September 17, 2020 7:17:33 PM PDT, H <agents at meddatainc.com>
>> wrote:
>>>> I am trying to understand how to map 2D to 3D using ggplot() and
>>>> eventually plot_gg(). I am, however, stuck on understanding how to
>>>> express the third variable to be mapped. This example:
>>>>
>>>> ggdiamonds = ggplot(diamonds, aes(x, depth)) +
>>>> stat_density_2d(aes(fill = stat(nlevel)),
>>>> geom = "polygon", n = 100, bins = 10,contour = TRUE) +
>>>> facet_wrap(clarity~.) +
>>>> scale_fill_viridis_c(option = "A")
>>>>
>>>> uses a variable nlevel that I now understand is calculated during
>> the
>>>> building of the ggplot but I have not figured out from where it is
>>>> calculated or how to specify a variable of my choosing.
>>>>
>>>> Does anyone have a good reference for understanding how to specify
>> this
>>>> variable? Most examples on the 'net seem to use the same dataset but
>> do
>>>> not specify this particular aspect...
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> But looking at the code in my message above, how does one know what
>> stat(nlevel) refers to? What if I wanted to map another variable in
>> this particular dataset??
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

Understood, I just began looking at the volcano dataset which uses geom_contour. I now realize that the function stat_density_2d really maps a heatmap of a computed variable.


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sat Sep 19 20:07:20 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sat, 19 Sep 2020 13:07:20 -0500
Subject: [R] CRAN R For Windows 3.6.3
In-Reply-To: <c7a4e353-88b8-d2d9-86ce-1246d4993e54@gmail.com>
References: <2aaa2b0a3a55492e9add7fd3d5385872@imcnam.ssmb.com>
 <c7a4e353-88b8-d2d9-86ce-1246d4993e54@gmail.com>
Message-ID: <dbf35daf-5a4f-b8c6-222f-6f1d3af15815@effectivedefense.org>

	  If you have production code written in R that make it expensive to 
even consider upgrading to the latest R, it may be worth paying the 
support fees of an organization like RStudio.


	  Otherwise, I think it make sense to upgrade to the latest version and 
hope for the best.  If you encounter problems, you can ask someplace on 
StackExchange or one of the R email lists like this or a package 
maintainer, as Duncan said.


	  Spencer


On 2020-09-19 12:44, Duncan Murdoch wrote:
> On 18/09/2020 1:39 p.m., Shapira, Leeor via R-help wrote:
>> Can you please let me know the End of Life and End of Vendor Support 
>> dates for CRAN R for Windows 3.6.3? Thank you.
> 
> R doesn't have either of those.? There is no vendor support ever.? It is 
> free software; it is up to its users to support it.? On the other hand, 
> it is free software, so you can use it forever.
> 
> In practice, there is de facto support from its authors in that they are 
> very responsive to bug reports.? That ends with the next release, so 
> 3.6.3 support ended in April, 2020 when R 4.0.0 was released.
> 
> Another way to think of support and end of life equivalents is to ask 
> how long CRAN will provide the source code to packages for it.? There 
> are no time limits on that, though it can be some work to find a set and 
> tools to build them if you are using older releases.
> 
> And finally, you might want to know how long CRAN will keep updating 
> binary packages for R 3.6.3.? I think that should continue until the 
> release of R 4.1.0, sometime around April 2021.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 19 20:29:34 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 19 Sep 2020 11:29:34 -0700
Subject: [R] How can we get a predicted value that are used to plot the
 figure using a plot_model function of sjPlot?
In-Reply-To: <CAA7XnHfDMri9ewEhtDm5mLsy7gmWh6DA0KpZJxsOhwO7H9t3KQ@mail.gmail.com>
References: <CAA7XnHfDMri9ewEhtDm5mLsy7gmWh6DA0KpZJxsOhwO7H9t3KQ@mail.gmail.com>
Message-ID: <CAGxFJbSy+dJp_9iVSCcCu1sCZbJWh4zzitKw70SRBcABkcnfeg@mail.gmail.com>

As no one has responded. Typically,
> ?predict
so
> predict(fit)
should give you fitted values for the class of fit, whatever it is.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 19, 2020 at 1:29 AM Peter Wagey <peter.wagley09 at gmail.com>
wrote:

> Hi R users,
> I was trying to create a figure of three-way-interactions. There is a
> function "plot-model" but I was wondering whether we can extract the
> predicted value before we run the "plot-model" function.
> For example:
> in this example,
> plot_model(fit, type = "pred", terms = c("c12hour", "barthtot [30,50,70]",
> "c161sex"))
> How can we see the predicted values that are used to plot the figure? If we
> can see the data (predicted values), we could use other functions to create
> another type of figures.
> Thank you very much for your suggestions.
>
> Thanks,
>
> Peter
> #############
> library(sjPlot)
> library(sjmisc)
> library(ggplot2)
> data(efc)
> theme_set(theme_sjplot())
>
> # make categorical
> efc$c161sex <- to_factor(efc$c161sex)
>
> # fit model with 3-way-interaction
> fit <- lm(neg_c_7 ~ c12hour * barthtot * c161sex, data = efc)
>
> # select only levels 30, 50 and 70 from continuous variable Barthel-Index
> plot_model(fit, type = "pred", terms = c("c12hour", "barthtot [30,50,70]",
> "c161sex"))
>
> How can we get the predicted value that is used to plot the graph? we would
> like to see the predicted value using three groups of barthtot
> [30,50,70].Is there any way we can extract the data (predicted value) so
> that we can use other graphic functions to create figures?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Sat Sep 19 20:31:12 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Sat, 19 Sep 2020 14:31:12 -0400
Subject: [R] CRAN R For Windows 3.6.3
In-Reply-To: <c7a4e353-88b8-d2d9-86ce-1246d4993e54@gmail.com>
References: <2aaa2b0a3a55492e9add7fd3d5385872@imcnam.ssmb.com>
 <c7a4e353-88b8-d2d9-86ce-1246d4993e54@gmail.com>
Message-ID: <21D9A905-F5E9-4A14-85C3-634D3396F961@me.com>


> On Sep 19, 2020, at 1:44 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 18/09/2020 1:39 p.m., Shapira, Leeor via R-help wrote:
>> Can you please let me know the End of Life and End of Vendor Support dates for CRAN R for Windows 3.6.3? Thank you.
> 
> R doesn't have either of those.  There is no vendor support ever.  It is free software; it is up to its users to support it.  On the other hand, it is free software, so you can use it forever.
> 
> In practice, there is de facto support from its authors in that they are very responsive to bug reports.  That ends with the next release, so 3.6.3 support ended in April, 2020 when R 4.0.0 was released.
> 
> Another way to think of support and end of life equivalents is to ask how long CRAN will provide the source code to packages for it.  There are no time limits on that, though it can be some work to find a set and tools to build them if you are using older releases.
> 
> And finally, you might want to know how long CRAN will keep updating binary packages for R 3.6.3.  I think that should continue until the release of R 4.1.0, sometime around April 2021.
> 
> Duncan Murdoch


Hi,

Just to add on to Duncan's comments, you may want to read the Software Development Life Cycle (SDLC) document here:

  https://www.r-project.org/certification.html

That will give you insights into R's development, release and maintenance timelines.

Regards,

Marc Schwartz


From @purd|e@@ @end|ng |rom gm@||@com  Sat Sep 19 22:33:23 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 20 Sep 2020 08:33:23 +1200
Subject: [R] Mapping 2D to 3D
In-Reply-To: <1ba072c9-b07c-a6ad-21e9-7f33ec20ea00@meddatainc.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
 <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>
 <27781FDA-86C0-4773-8174-F1D6E55FBCCA@dcn.davis.ca.us>
 <1ba072c9-b07c-a6ad-21e9-7f33ec20ea00@meddatainc.com>
Message-ID: <CAB8pepzwFOJyMNi-R5weiCS=zY8rWSkUR1TzRfEpZxV4u0t=Pw@mail.gmail.com>

> Understood

I'd recommend you try to be more precise.

> I just began looking at the volcano dataset which uses geom_contour.

The volcano dataset does *not* use geom_contour.
However, the help file for the volcano dataset, does use the
filled.contour function, in its example.

> I now realize that the function stat_density_2d really maps a heatmap

If I hadn't read the rest of this thread, I wouldn't know what you
meant by "maps" a heatmap.

The kde2d function returns a list, containing a density matrix.
(As per my previous post).

The plotting functions, compute the density via the above density
estimation function, and then plot that density, in some form.

I suppose you could say the plotting functions map observations to
density estimates, then map the density estimates to contours and/or
other graphic data, and then map the graphic data to a plot, which is
seen by a user...
...but it's probably easier to just say plot the density.

>of a computed variable.

It's rare in probability theory to refer to density as a "variable".
(Which is relevant because density estimates are estimates of
probability distributions).

However, it is common in computer graphics and geometry, to use "z"
for a "third variable".
And in applied statistics and data science, "variable" could mean anything...
So, be careful there...

Based on your posts, I take it you want to plot a function of two
variables (or plot a matrix of values), using a 2d plot.

There are a number of options here.

Contour plots.
Filled contour plots.
Heatmaps.
Plots using hex/other binning.
Maybe others...?

Additionally, there are 3d plots, such as surface plots.

And I note that it's possible to plot contour lines on top of
color-filled contours or heatmaps.


From @tyen @end|ng |rom ntu@edu@tw  Sun Sep 20 12:11:25 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sun, 20 Sep 2020 18:11:25 +0800
Subject: [R] Calling a procedure
Message-ID: <7e0d7c25-c398-61bc-c7ac-e717b701ace7@ntu.edu.tw>

Can someone tell me a proper call to a procedure, in this case, pnorm. 
In what follows, I had expected a = b, but they are not equal. What are 
wrong with first call and second call? Thank you!

try<-function(x,log.p=FALSE){
a<-pnorm(x,log.p)?????? # first call
b<-pnorm(x,log.p=log.p) # second call
list(a=a,b=b)
}

try(x=1.2,log.p=TRUE)$a
try(x=1.2,log.p=TRUE)$b


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep 20 12:36:01 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 20 Sep 2020 11:36:01 +0100
Subject: [R] Calling a procedure
In-Reply-To: <7e0d7c25-c398-61bc-c7ac-e717b701ace7@ntu.edu.tw>
References: <7e0d7c25-c398-61bc-c7ac-e717b701ace7@ntu.edu.tw>
Message-ID: <b4cb348f-27da-2adc-a079-3af368019508@sapo.pt>

Hello,

You are making a confusion between

1. the formal argument log.p
2. the variable log.p

In the function body, log.p is a variable that exists in the function's 
frame, not the formal argument of pnorm.
The first and the 3rd calls that follow output the same value.

try(x = 1.2, log.p = TRUE)$a
try(x = 1.2, log.p = TRUE)$b
try(x = 1.2, 1)$a

This is because in the function

   a<-pnorm(x,log.p)       # first call

passes log.p as the *second* argument, not as a value for pnorm's formal 
argument log.p. Unless when named, the arguments are passed in the order 
they appear in the function's definition:

pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)

and that becomes

   a<-pnorm(x,TRUE)       # first call
   a<-pnorm(x,1)          # first call, coerced to numeric.


Let me give another example. In the function that follows the default is 
z = FALSE.

In the first call the name z is not the name of the argument, it's the 
name of a variable that exists in the .GlobalEnv.

In the second call, z = z assign the formal argument z the value of the 
variable z.


f <- function(x, y = 0, z = FALSE){
   a <- x
   b <- y
   d <- z
   list(a = a, b = b, d = d)
}
z <- 2
f(1, z)
f(1, z = z)


Hope this helps,

Rui Barradas

?s 11:11 de 20/09/20, Steven Yen escreveu:
> Can someone tell me a proper call to a procedure, in this case, pnorm. 
> In what follows, I had expected a = b, but they are not equal. What are 
> wrong with first call and second call? Thank you!
> 
> try<-function(x,log.p=FALSE){
> a<-pnorm(x,log.p)?????? # first call
> b<-pnorm(x,log.p=log.p) # second call
> list(a=a,b=b)
> }
> 
> try(x=1.2,log.p=TRUE)$a
> try(x=1.2,log.p=TRUE)$b
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Sun Sep 20 13:23:06 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sun, 20 Sep 2020 19:23:06 +0800
Subject: [R] Calling a procedure
In-Reply-To: <b4cb348f-27da-2adc-a079-3af368019508@sapo.pt>
References: <7e0d7c25-c398-61bc-c7ac-e717b701ace7@ntu.edu.tw>
 <b4cb348f-27da-2adc-a079-3af368019508@sapo.pt>
Message-ID: <85891d37-4742-95a7-eaba-15737125145f@ntu.edu.tw>

Thanks. So, to be safe, always a good idea to give the argument, e.g., 
q=1.96, log.p=FALSE, skipping mean=0 and sd=1 if not needed. Thanks.

pnorm(q=1.96, log.p = FALSE)

On 2020/9/20 ?? 06:36, Rui Barradas wrote:
> Hello,
>
> You are making a confusion between
>
> 1. the formal argument log.p
> 2. the variable log.p
>
> In the function body, log.p is a variable that exists in the 
> function's frame, not the formal argument of pnorm.
> The first and the 3rd calls that follow output the same value.
>
> try(x = 1.2, log.p = TRUE)$a
> try(x = 1.2, log.p = TRUE)$b
> try(x = 1.2, 1)$a
>
> This is because in the function
>
> ? a<-pnorm(x,log.p)?????? # first call
>
> passes log.p as the *second* argument, not as a value for pnorm's 
> formal argument log.p. Unless when named, the arguments are passed in 
> the order they appear in the function's definition:
>
> pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
>
> and that becomes
>
> ? a<-pnorm(x,TRUE)?????? # first call
> ? a<-pnorm(x,1)????????? # first call, coerced to numeric.
>
>
> Let me give another example. In the function that follows the default 
> is z = FALSE.
>
> In the first call the name z is not the name of the argument, it's the 
> name of a variable that exists in the .GlobalEnv.
>
> In the second call, z = z assign the formal argument z the value of 
> the variable z.
>
>
> f <- function(x, y = 0, z = FALSE){
> ? a <- x
> ? b <- y
> ? d <- z
> ? list(a = a, b = b, d = d)
> }
> z <- 2
> f(1, z)
> f(1, z = z)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 11:11 de 20/09/20, Steven Yen escreveu:
>> Can someone tell me a proper call to a procedure, in this case, 
>> pnorm. In what follows, I had expected a = b, but they are not equal. 
>> What are wrong with first call and second call? Thank you!
>>
>> try<-function(x,log.p=FALSE){
>> a<-pnorm(x,log.p)?????? # first call
>> b<-pnorm(x,log.p=log.p) # second call
>> list(a=a,b=b)
>> }
>>
>> try(x=1.2,log.p=TRUE)$a
>> try(x=1.2,log.p=TRUE)$b
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From m@rk|eed@2 @end|ng |rom gm@||@com  Sun Sep 20 17:56:47 2020
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Sun, 20 Sep 2020 11:56:47 -0400
Subject: [R] Calling a procedure
In-Reply-To: <85891d37-4742-95a7-eaba-15737125145f@ntu.edu.tw>
References: <7e0d7c25-c398-61bc-c7ac-e717b701ace7@ntu.edu.tw>
 <b4cb348f-27da-2adc-a079-3af368019508@sapo.pt>
 <85891d37-4742-95a7-eaba-15737125145f@ntu.edu.tw>
Message-ID: <CAHz+bWYyVpJ3sj7AL1+8XnStTgS5n8CrX51pMQ1Zfe2eCF2FsA@mail.gmail.com>

Hi Steven: Rui's detailed explanation was great.  The way I think of it is,
if you don't
want to send the  variables in with the same  order as the formal
arguments, then you
better  name them as you send them in.





On Sun, Sep 20, 2020 at 7:23 AM Steven Yen <styen at ntu.edu.tw> wrote:

> Thanks. So, to be safe, always a good idea to give the argument, e.g.,
> q=1.96, log.p=FALSE, skipping mean=0 and sd=1 if not needed. Thanks.
>
> pnorm(q=1.96, log.p = FALSE)
>
> On 2020/9/20 ?? 06:36, Rui Barradas wrote:
> > Hello,
> >
> > You are making a confusion between
> >
> > 1. the formal argument log.p
> > 2. the variable log.p
> >
> > In the function body, log.p is a variable that exists in the
> > function's frame, not the formal argument of pnorm.
> > The first and the 3rd calls that follow output the same value.
> >
> > try(x = 1.2, log.p = TRUE)$a
> > try(x = 1.2, log.p = TRUE)$b
> > try(x = 1.2, 1)$a
> >
> > This is because in the function
> >
> >   a<-pnorm(x,log.p)       # first call
> >
> > passes log.p as the *second* argument, not as a value for pnorm's
> > formal argument log.p. Unless when named, the arguments are passed in
> > the order they appear in the function's definition:
> >
> > pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
> >
> > and that becomes
> >
> >   a<-pnorm(x,TRUE)       # first call
> >   a<-pnorm(x,1)          # first call, coerced to numeric.
> >
> >
> > Let me give another example. In the function that follows the default
> > is z = FALSE.
> >
> > In the first call the name z is not the name of the argument, it's the
> > name of a variable that exists in the .GlobalEnv.
> >
> > In the second call, z = z assign the formal argument z the value of
> > the variable z.
> >
> >
> > f <- function(x, y = 0, z = FALSE){
> >   a <- x
> >   b <- y
> >   d <- z
> >   list(a = a, b = b, d = d)
> > }
> > z <- 2
> > f(1, z)
> > f(1, z = z)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 11:11 de 20/09/20, Steven Yen escreveu:
> >> Can someone tell me a proper call to a procedure, in this case,
> >> pnorm. In what follows, I had expected a = b, but they are not equal.
> >> What are wrong with first call and second call? Thank you!
> >>
> >> try<-function(x,log.p=FALSE){
> >> a<-pnorm(x,log.p)       # first call
> >> b<-pnorm(x,log.p=log.p) # second call
> >> list(a=a,b=b)
> >> }
> >>
> >> try(x=1.2,log.p=TRUE)$a
> >> try(x=1.2,log.p=TRUE)$b
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep 20 18:26:32 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 20 Sep 2020 09:26:32 -0700
Subject: [R] Calling a procedure
In-Reply-To: <CAHz+bWYyVpJ3sj7AL1+8XnStTgS5n8CrX51pMQ1Zfe2eCF2FsA@mail.gmail.com>
References: <7e0d7c25-c398-61bc-c7ac-e717b701ace7@ntu.edu.tw>
 <b4cb348f-27da-2adc-a079-3af368019508@sapo.pt>
 <85891d37-4742-95a7-eaba-15737125145f@ntu.edu.tw>
 <CAHz+bWYyVpJ3sj7AL1+8XnStTgS5n8CrX51pMQ1Zfe2eCF2FsA@mail.gmail.com>
Message-ID: <CAGxFJbSfacR-UwW-VCMgfhVbWzpe=sBhnSxwMJ7sra2uLy42_A@mail.gmail.com>

Argument passing is fundamental, even more so when you write your own
functions, which any half-serious R user will want to do. What has
heretofore been discussed in this thread is not the whole story (e.g. there
are ... arguments and functions as binary operators, among other things).
See section 10 of the "Introduction to R" document that ships with R or any
other decent R tutorial of your choice. The R language definition is the
definitive reference (section 4 especially for this).

All imo of course.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Sep 20, 2020 at 8:57 AM Mark Leeds <markleeds2 at gmail.com> wrote:

> Hi Steven: Rui's detailed explanation was great.  The way I think of it is,
> if you don't
> want to send the  variables in with the same  order as the formal
> arguments, then you
> better  name them as you send them in.
>
>
>
>
>
> On Sun, Sep 20, 2020 at 7:23 AM Steven Yen <styen at ntu.edu.tw> wrote:
>
> > Thanks. So, to be safe, always a good idea to give the argument, e.g.,
> > q=1.96, log.p=FALSE, skipping mean=0 and sd=1 if not needed. Thanks.
> >
> > pnorm(q=1.96, log.p = FALSE)
> >
> > On 2020/9/20 ?? 06:36, Rui Barradas wrote:
> > > Hello,
> > >
> > > You are making a confusion between
> > >
> > > 1. the formal argument log.p
> > > 2. the variable log.p
> > >
> > > In the function body, log.p is a variable that exists in the
> > > function's frame, not the formal argument of pnorm.
> > > The first and the 3rd calls that follow output the same value.
> > >
> > > try(x = 1.2, log.p = TRUE)$a
> > > try(x = 1.2, log.p = TRUE)$b
> > > try(x = 1.2, 1)$a
> > >
> > > This is because in the function
> > >
> > >   a<-pnorm(x,log.p)       # first call
> > >
> > > passes log.p as the *second* argument, not as a value for pnorm's
> > > formal argument log.p. Unless when named, the arguments are passed in
> > > the order they appear in the function's definition:
> > >
> > > pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
> > >
> > > and that becomes
> > >
> > >   a<-pnorm(x,TRUE)       # first call
> > >   a<-pnorm(x,1)          # first call, coerced to numeric.
> > >
> > >
> > > Let me give another example. In the function that follows the default
> > > is z = FALSE.
> > >
> > > In the first call the name z is not the name of the argument, it's the
> > > name of a variable that exists in the .GlobalEnv.
> > >
> > > In the second call, z = z assign the formal argument z the value of
> > > the variable z.
> > >
> > >
> > > f <- function(x, y = 0, z = FALSE){
> > >   a <- x
> > >   b <- y
> > >   d <- z
> > >   list(a = a, b = b, d = d)
> > > }
> > > z <- 2
> > > f(1, z)
> > > f(1, z = z)
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > ?s 11:11 de 20/09/20, Steven Yen escreveu:
> > >> Can someone tell me a proper call to a procedure, in this case,
> > >> pnorm. In what follows, I had expected a = b, but they are not equal.
> > >> What are wrong with first call and second call? Thank you!
> > >>
> > >> try<-function(x,log.p=FALSE){
> > >> a<-pnorm(x,log.p)       # first call
> > >> b<-pnorm(x,log.p=log.p) # second call
> > >> list(a=a,b=b)
> > >> }
> > >>
> > >> try(x=1.2,log.p=TRUE)$a
> > >> try(x=1.2,log.p=TRUE)$b
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @gent@ @end|ng |rom medd@t@|nc@com  Mon Sep 21 03:44:19 2020
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Sun, 20 Sep 2020 21:44:19 -0400
Subject: [R] Mapping 2D to 3D
In-Reply-To: <CAB8pepzwFOJyMNi-R5weiCS=zY8rWSkUR1TzRfEpZxV4u0t=Pw@mail.gmail.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
 <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>
 <27781FDA-86C0-4773-8174-F1D6E55FBCCA@dcn.davis.ca.us>
 <1ba072c9-b07c-a6ad-21e9-7f33ec20ea00@meddatainc.com>
 <CAB8pepzwFOJyMNi-R5weiCS=zY8rWSkUR1TzRfEpZxV4u0t=Pw@mail.gmail.com>
Message-ID: <4ab1cbe9-4cf1-4712-a272-12182d2a80b3@meddatainc.com>

On 09/19/2020 04:33 PM, Abby Spurdle wrote:
>> Understood
> I'd recommend you try to be more precise.
>
>> I just began looking at the volcano dataset which uses geom_contour.
> The volcano dataset does *not* use geom_contour.
> However, the help file for the volcano dataset, does use the
> filled.contour function, in its example.
>
>> I now realize that the function stat_density_2d really maps a heatmap
> If I hadn't read the rest of this thread, I wouldn't know what you
> meant by "maps" a heatmap.
>
> The kde2d function returns a list, containing a density matrix.
> (As per my previous post).
>
> The plotting functions, compute the density via the above density
> estimation function, and then plot that density, in some form.
>
> I suppose you could say the plotting functions map observations to
> density estimates, then map the density estimates to contours and/or
> other graphic data, and then map the graphic data to a plot, which is
> seen by a user...
> ...but it's probably easier to just say plot the density.
>
>> of a computed variable.
> It's rare in probability theory to refer to density as a "variable".
> (Which is relevant because density estimates are estimates of
> probability distributions).
>
> However, it is common in computer graphics and geometry, to use "z"
> for a "third variable".
> And in applied statistics and data science, "variable" could mean anything...
> So, be careful there...
>
> Based on your posts, I take it you want to plot a function of two
> variables (or plot a matrix of values), using a 2d plot.
>
> There are a number of options here.
>
> Contour plots.
> Filled contour plots.
> Heatmaps.
> Plots using hex/other binning.
> Maybe others...?
>
> Additionally, there are 3d plots, such as surface plots.
>
> And I note that it's possible to plot contour lines on top of
> color-filled contours or heatmaps.

I was looking at this example which uses geom_contour():

ggvolcano = volcano %>%
?reshape2::melt() %>%
?ggplot() +
?geom_tile(aes(x=Var1,y=Var2,fill=value)) +
?geom_contour(aes(x=Var1,y=Var2,z=value),color="black") +
?scale_x_continuous("X",expand = c(0,0)) +
?scale_y_continuous("Y",expand = c(0,0)) +
?scale_fill_gradientn("Z",colours = terrain.colors(10)) +
?coord_fixed()
print(ggvolcano)


From @tyen @end|ng |rom ntu@edu@tw  Mon Sep 21 04:32:50 2020
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 21 Sep 2020 10:32:50 +0800
Subject: [R] Calling a procedure
In-Reply-To: <CAGxFJbSfacR-UwW-VCMgfhVbWzpe=sBhnSxwMJ7sra2uLy42_A@mail.gmail.com>
References: <7e0d7c25-c398-61bc-c7ac-e717b701ace7@ntu.edu.tw>
 <b4cb348f-27da-2adc-a079-3af368019508@sapo.pt>
 <85891d37-4742-95a7-eaba-15737125145f@ntu.edu.tw>
 <CAHz+bWYyVpJ3sj7AL1+8XnStTgS5n8CrX51pMQ1Zfe2eCF2FsA@mail.gmail.com>
 <CAGxFJbSfacR-UwW-VCMgfhVbWzpe=sBhnSxwMJ7sra2uLy42_A@mail.gmail.com>
Message-ID: <933a8b25-7e4a-6bc8-6108-accdb8757040@ntu.edu.tw>

Thanks to all for educating me about procedures and argument. Those were 
very helpful!!

On 2020/9/21 ?? 12:26, Bert Gunter wrote:
> Argument passing is fundamental, even more so when you write your own 
> functions, which any half-serious R user will want to do. What has 
> heretofore been discussed in this thread is not the whole story (e.g. 
> there are ... arguments and functions as binary operators, among other 
> things).? See section 10 of the "Introduction to R" document that 
> ships with R or any other decent R tutorial of your choice. The R 
> language definition is the definitive reference (section 4 especially 
> for this).
>
> All imo of course.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Sep 20, 2020 at 8:57 AM Mark Leeds <markleeds2 at gmail.com 
> <mailto:markleeds2 at gmail.com>> wrote:
>
>     Hi Steven: Rui's detailed explanation was great.? The way I think
>     of it is,
>     if you don't
>     want to send the? variables in with the same? order as the formal
>     arguments, then you
>     better? name them as you send them in.
>
>
>
>
>
>     On Sun, Sep 20, 2020 at 7:23 AM Steven Yen <styen at ntu.edu.tw
>     <mailto:styen at ntu.edu.tw>> wrote:
>
>     > Thanks. So, to be safe, always a good idea to give the argument,
>     e.g.,
>     > q=1.96, log.p=FALSE, skipping mean=0 and sd=1 if not needed. Thanks.
>     >
>     > pnorm(q=1.96, log.p = FALSE)
>     >
>     > On 2020/9/20 ?? 06:36, Rui Barradas wrote:
>     > > Hello,
>     > >
>     > > You are making a confusion between
>     > >
>     > > 1. the formal argument log.p
>     > > 2. the variable log.p
>     > >
>     > > In the function body, log.p is a variable that exists in the
>     > > function's frame, not the formal argument of pnorm.
>     > > The first and the 3rd calls that follow output the same value.
>     > >
>     > > try(x = 1.2, log.p = TRUE)$a
>     > > try(x = 1.2, log.p = TRUE)$b
>     > > try(x = 1.2, 1)$a
>     > >
>     > > This is because in the function
>     > >
>     > >? ?a<-pnorm(x,log.p)? ? ? ?# first call
>     > >
>     > > passes log.p as the *second* argument, not as a value for pnorm's
>     > > formal argument log.p. Unless when named, the arguments are
>     passed in
>     > > the order they appear in the function's definition:
>     > >
>     > > pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
>     > >
>     > > and that becomes
>     > >
>     > >? ?a<-pnorm(x,TRUE)? ? ? ?# first call
>     > >? ?a<-pnorm(x,1)? ? ? ? ? # first call, coerced to numeric.
>     > >
>     > >
>     > > Let me give another example. In the function that follows the
>     default
>     > > is z = FALSE.
>     > >
>     > > In the first call the name z is not the name of the argument,
>     it's the
>     > > name of a variable that exists in the .GlobalEnv.
>     > >
>     > > In the second call, z = z assign the formal argument z the
>     value of
>     > > the variable z.
>     > >
>     > >
>     > > f <- function(x, y = 0, z = FALSE){
>     > >? ?a <- x
>     > >? ?b <- y
>     > >? ?d <- z
>     > >? ?list(a = a, b = b, d = d)
>     > > }
>     > > z <- 2
>     > > f(1, z)
>     > > f(1, z = z)
>     > >
>     > >
>     > > Hope this helps,
>     > >
>     > > Rui Barradas
>     > >
>     > > ?s 11:11 de 20/09/20, Steven Yen escreveu:
>     > >> Can someone tell me a proper call to a procedure, in this case,
>     > >> pnorm. In what follows, I had expected a = b, but they are
>     not equal.
>     > >> What are wrong with first call and second call? Thank you!
>     > >>
>     > >> try<-function(x,log.p=FALSE){
>     > >> a<-pnorm(x,log.p)? ? ? ?# first call
>     > >> b<-pnorm(x,log.p=log.p) # second call
>     > >> list(a=a,b=b)
>     > >> }
>     > >>
>     > >> try(x=1.2,log.p=TRUE)$a
>     > >> try(x=1.2,log.p=TRUE)$b
>     > >>
>     > >> ______________________________________________
>     > >> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     list -- To UNSUBSCRIBE and more, see
>     > >> https://stat.ethz.ch/mailman/listinfo/r-help
>     > >> PLEASE do read the posting guide
>     > >> http://www.R-project.org/posting-guide.html
>     > >> and provide commented, minimal, self-contained, reproducible
>     code.
>     >
>     >? ? ? ? ?[[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Sep 21 07:07:09 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 21 Sep 2020 17:07:09 +1200
Subject: [R] Mapping 2D to 3D
In-Reply-To: <4ab1cbe9-4cf1-4712-a272-12182d2a80b3@meddatainc.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
 <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>
 <27781FDA-86C0-4773-8174-F1D6E55FBCCA@dcn.davis.ca.us>
 <1ba072c9-b07c-a6ad-21e9-7f33ec20ea00@meddatainc.com>
 <CAB8pepzwFOJyMNi-R5weiCS=zY8rWSkUR1TzRfEpZxV4u0t=Pw@mail.gmail.com>
 <4ab1cbe9-4cf1-4712-a272-12182d2a80b3@meddatainc.com>
Message-ID: <CAB8pepxRSMqvhNmb9ZLAS9QMMkuFdaDYMF7Y9mVW5+2hG-X2HQ@mail.gmail.com>

> I was looking at this example which uses geom_contour():
>
> ggvolcano = volcano %>%
>  reshape2::melt() %>%
>  ggplot() +
>  geom_tile(aes(x=Var1,y=Var2,fill=value)) +
>  geom_contour(aes(x=Var1,y=Var2,z=value),color="black") +
>  scale_x_continuous("X",expand = c(0,0)) +
>  scale_y_continuous("Y",expand = c(0,0)) +
>  scale_fill_gradientn("Z",colours = terrain.colors(10)) +
>  coord_fixed()
> print(ggvolcano)

Yesturday, I watched the movie Tenet.

WARNING: SPOILER ALERT

Everything's going forwards and backwards at the same time.
This code reminds me of that movie.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Sep 21 10:43:02 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 21 Sep 2020 20:43:02 +1200
Subject: [R] Mapping 2D to 3D
In-Reply-To: <4ab1cbe9-4cf1-4712-a272-12182d2a80b3@meddatainc.com>
References: <9b6a6a92-febf-50fd-3d90-549adda260b0@meddatainc.com>
 <BFF9F133-E681-4EC0-8216-4E240184522A@dcn.davis.ca.us>
 <00d57864-7fe6-0025-9a5b-7a9723c68f8e@meddatainc.com>
 <27781FDA-86C0-4773-8174-F1D6E55FBCCA@dcn.davis.ca.us>
 <1ba072c9-b07c-a6ad-21e9-7f33ec20ea00@meddatainc.com>
 <CAB8pepzwFOJyMNi-R5weiCS=zY8rWSkUR1TzRfEpZxV4u0t=Pw@mail.gmail.com>
 <4ab1cbe9-4cf1-4712-a272-12182d2a80b3@meddatainc.com>
Message-ID: <CAB8pepw-KeGBtu9SFCipEY2fJapUbuUXLmrP2dyRUJZrF2Zp+Q@mail.gmail.com>

Hi H,

I probably owe you an apology.
I was just reading the geom_contour documentation.
It's difficult to follow.

Base R functions, my functions, and pretty much everyone's functions,
take a matrix as input.
But as far as I can tell, geom_contour wants a data.frame with three
{x, y and z} coordinates.
It's not clear how the data in the data.frame is mapped onto the {x,
y, and z} coordinate system.

Also, it uses density estimation in *all* its examples.
Making it difficult for inexperienced users to tell the difference
between contour plots (generally) and density visualization.

I would suggest base R functions as a better starting point:

contour
filled.contour
image
heatmap
persp

I have a package named barsurf, with (almost) density-free examples:
https://cran.r-project.org/web/packages/barsurf/vignettes/barsurf.pdf

Additionally, there are functions in the lattice package, and possibly
the rgl package.


From rkoenker @end|ng |rom ||||no|@@edu  Mon Sep 21 10:52:48 2020
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Mon, 21 Sep 2020 08:52:48 +0000
Subject: [R] formula wrangling
Message-ID: <C8AD2C5C-535A-4106-B88F-9849B1176EF2@illinois.edu>

I need some help with a formula processing problem that arose from a seemingly innocuous  request
that I add a ?subset? argument to the additive modeling function ?rqss? in my quantreg package.

I?ve tried to boil the relevant code down to something simpler as illustrated below.  The formulae in
question involve terms called ?qss? that construct sparse matrix objects, but I?ve replaced all that with
a much simpler BoxCox construction that I hope illustrates the basic difficulty.  What is supposed to happen
is that xss objects are evaluated and cbind?d to the design matrix, subject to the same subset restriction
as the rest of the model frame.  However, this doesn?t happen, instead the xss vectors are evaluated
on the full sample and the cbind operation generates a warning which probably should be an error.
I?ve inserted a browser() to make it easy to verify that the length of xss[[[1]] doesn?t match dim(X).

Any suggestions would be most welcome, including other simplifications of the code.  Note that
the function untangle.specials() is adapted, or perhaps I should say adopted form the survival 
package so you would need the quantreg package to run the attached code.

Thanks,
Roger



fit <- function(formula, subset, data, ...){
    call <- match.call()
    m <- match.call(expand.dots = FALSE)
    tmp <- c("", "formula", "subset", "data")
    m <- m[match(tmp, names(m), nomatch = 0)]
    m[[1]] <- as.name("model.frame")
    Terms <- if(missing(data)) terms(formula,special = "qss")
	    else terms(formula, special = "qss", data = data)
    qssterms <- attr(Terms, "specials")$qss
    if (length(qssterms)) {
        tmpc <- untangle.specials(Terms, "qss")
        dropx <- tmpc$terms
        if (length(dropx)) 
            Terms <- Terms[-dropx]
        attr(Terms, "specials") <- tmpc$vars
	fnames <- function(x) {
            fy <- all.names(x[[2]])
            if (fy[1] == "cbind") 
                fy <- fy[-1]
            fy
        }
        fqssnames <- unlist(lapply(parse(text = tmpc$vars), fnames))
        qssnames <- unlist(lapply(parse(text = tmpc$vars), function(x) deparse(x[[2]])))
    }
    if (exists("fqssnames")) {
        ffqss <- paste(fqssnames, collapse = "+")
        ff <- as.formula(paste(deparse(formula), "+", ffqss))
    }
    m$formula <- Terms
    m <- eval(m, parent.frame())
    Y <- model.extract(m, "response")
    X <- model.matrix(Terms, m)
    ef <- environment(formula)
    qss <- function(x, lambda) (x^lambda - 1)/lambda
    if (length(qssterms) > 0) {
        xss <- lapply(tmpc$vars, function(u) eval(parse(text = u), m, enclos = ef))
	for(i in 1:length(xss)){
	    X <- cbind(X, xss[[i]]) # Here is the problem
	}
    }
    browser()
    z <- lm.fit(X,Y) # The dreaded least squares fit
    z
}
# Test case
n <- 200
x <- sort(rchisq(n,4))
z <- rnorm(n)
s <- sample(1:n, n/2)
y <- log(x) + rnorm(n)/5
D = data.frame(y = y, x = x, z = z, s = (1:n) %in% s)
plot(x, y)
lam = 0.2
#f0 <- fit(y ~ qss(x,lambda = lam) + z, subset = s)
f1 <- fit(y ~ qss(x, lambda = lam) + z, subset = s, data = D)

From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Mon Sep 21 11:28:23 2020
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 21 Sep 2020 12:28:23 +0300
Subject: [R] Quadratic programming
Message-ID: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>

Hi!

I was wondering if someone could help me out. I'm minimizing a following
function:

\begin{equation}
$$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
\text{subject to}
$$m_{j-1}\leq m_{j}-\delta_{1}$$
$$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq \frac{1}{Q_{j}-Q_{j-1}}
(m_{j-1}-m_{j})-\delta_{2} $$
\end{equation}

I have tried quadratic programming, but something is off. Does anyone have
an idea how to approach this?

Thanks in advance!

Q <- rep(0,J)
for(j in 1:(length(Price))){
  Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
}

Dmat <- matrix(0,nrow= J, ncol=J)
diag(Dmat) <- 1
dvec <- -hs
Aeq <- 0
beq <- 0
Amat <- matrix(0,J,2*J-3)
bvec <- matrix(0,2*J-3,1)

for(j in 2:nrow(Amat)){
  Amat[j-1,j-1] = -1
  Amat[j,j-1] = 1
}
for(j in 3:nrow(Amat)){
  Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
  Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
  Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
}
for(j in 2:ncol(bvec)) {
  bvec[j-1] = Delta1
}
for(j in 3:ncol(bvec)) {
  bvec[J-1+j-2] = Delta2
}
solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Sep 21 12:05:24 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 21 Sep 2020 22:05:24 +1200
Subject: [R] Quadratic programming
In-Reply-To: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
Message-ID: <CAB8pepzj2nG-9Lwh5x9Qp0jUrCnv9Xf18KqNsAzLrHcZDhfE9w@mail.gmail.com>

Are you using the quadprog package?
If I can take a random shot in the dark, should bvec be -bvec?


On Mon, Sep 21, 2020 at 9:28 PM Maija Sirkj?rvi
<maija.sirkjarvi at gmail.com> wrote:
>
> Hi!
>
> I was wondering if someone could help me out. I'm minimizing a following
> function:
>
> \begin{equation}
> $$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
> \text{subject to}
> $$m_{j-1}\leq m_{j}-\delta_{1}$$
> $$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq \frac{1}{Q_{j}-Q_{j-1}}
> (m_{j-1}-m_{j})-\delta_{2} $$
> \end{equation}
>
> I have tried quadratic programming, but something is off. Does anyone have
> an idea how to approach this?
>
> Thanks in advance!
>
> Q <- rep(0,J)
> for(j in 1:(length(Price))){
>   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> }
>
> Dmat <- matrix(0,nrow= J, ncol=J)
> diag(Dmat) <- 1
> dvec <- -hs
> Aeq <- 0
> beq <- 0
> Amat <- matrix(0,J,2*J-3)
> bvec <- matrix(0,2*J-3,1)
>
> for(j in 2:nrow(Amat)){
>   Amat[j-1,j-1] = -1
>   Amat[j,j-1] = 1
> }
> for(j in 3:nrow(Amat)){
>   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
>   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
>   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> }
> for(j in 2:ncol(bvec)) {
>   bvec[j-1] = Delta1
> }
> for(j in 3:ncol(bvec)) {
>   bvec[J-1+j-2] = Delta2
> }
> solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Sep 21 12:09:16 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 21 Sep 2020 22:09:16 +1200
Subject: [R] Quadratic programming
In-Reply-To: <CAB8pepzj2nG-9Lwh5x9Qp0jUrCnv9Xf18KqNsAzLrHcZDhfE9w@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepzj2nG-9Lwh5x9Qp0jUrCnv9Xf18KqNsAzLrHcZDhfE9w@mail.gmail.com>
Message-ID: <CAB8pepzOigvAOxaJk1jAgsTFBQgZ-FzY_5g4vK0HubAAv+NzAw@mail.gmail.com>

Sorry, ignore the last part.
What I should have said, is the inequality has the opposite sign.
>= bvec (not <= bvec)


On Mon, Sep 21, 2020 at 10:05 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Are you using the quadprog package?
> If I can take a random shot in the dark, should bvec be -bvec?
>
>
> On Mon, Sep 21, 2020 at 9:28 PM Maija Sirkj?rvi
> <maija.sirkjarvi at gmail.com> wrote:
> >
> > Hi!
> >
> > I was wondering if someone could help me out. I'm minimizing a following
> > function:
> >
> > \begin{equation}
> > $$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
> > \text{subject to}
> > $$m_{j-1}\leq m_{j}-\delta_{1}$$
> > $$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq \frac{1}{Q_{j}-Q_{j-1}}
> > (m_{j-1}-m_{j})-\delta_{2} $$
> > \end{equation}
> >
> > I have tried quadratic programming, but something is off. Does anyone have
> > an idea how to approach this?
> >
> > Thanks in advance!
> >
> > Q <- rep(0,J)
> > for(j in 1:(length(Price))){
> >   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> > }
> >
> > Dmat <- matrix(0,nrow= J, ncol=J)
> > diag(Dmat) <- 1
> > dvec <- -hs
> > Aeq <- 0
> > beq <- 0
> > Amat <- matrix(0,J,2*J-3)
> > bvec <- matrix(0,2*J-3,1)
> >
> > for(j in 2:nrow(Amat)){
> >   Amat[j-1,j-1] = -1
> >   Amat[j,j-1] = 1
> > }
> > for(j in 3:nrow(Amat)){
> >   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
> >   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
> >   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> > }
> > for(j in 2:ncol(bvec)) {
> >   bvec[j-1] = Delta1
> > }
> > for(j in 3:ncol(bvec)) {
> >   bvec[J-1+j-2] = Delta2
> > }
> > solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Sep 21 12:19:37 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 21 Sep 2020 22:19:37 +1200
Subject: [R] Quadratic programming
In-Reply-To: <CAB8pepzOigvAOxaJk1jAgsTFBQgZ-FzY_5g4vK0HubAAv+NzAw@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepzj2nG-9Lwh5x9Qp0jUrCnv9Xf18KqNsAzLrHcZDhfE9w@mail.gmail.com>
 <CAB8pepzOigvAOxaJk1jAgsTFBQgZ-FzY_5g4vK0HubAAv+NzAw@mail.gmail.com>
Message-ID: <CAB8pepw2FwHg7NcCHBSJhuHg+ovNuHn8utziq4xQGiAV5UWxMw@mail.gmail.com>

One more thing, is bvec supposed to be a matrix?

Note you may need to provide a reproducible example, for better help...

On Mon, Sep 21, 2020 at 10:09 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Sorry, ignore the last part.
> What I should have said, is the inequality has the opposite sign.
> >= bvec (not <= bvec)
>
>
> On Mon, Sep 21, 2020 at 10:05 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > Are you using the quadprog package?
> > If I can take a random shot in the dark, should bvec be -bvec?
> >
> >
> > On Mon, Sep 21, 2020 at 9:28 PM Maija Sirkj?rvi
> > <maija.sirkjarvi at gmail.com> wrote:
> > >
> > > Hi!
> > >
> > > I was wondering if someone could help me out. I'm minimizing a following
> > > function:
> > >
> > > \begin{equation}
> > > $$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
> > > \text{subject to}
> > > $$m_{j-1}\leq m_{j}-\delta_{1}$$
> > > $$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq \frac{1}{Q_{j}-Q_{j-1}}
> > > (m_{j-1}-m_{j})-\delta_{2} $$
> > > \end{equation}
> > >
> > > I have tried quadratic programming, but something is off. Does anyone have
> > > an idea how to approach this?
> > >
> > > Thanks in advance!
> > >
> > > Q <- rep(0,J)
> > > for(j in 1:(length(Price))){
> > >   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> > > }
> > >
> > > Dmat <- matrix(0,nrow= J, ncol=J)
> > > diag(Dmat) <- 1
> > > dvec <- -hs
> > > Aeq <- 0
> > > beq <- 0
> > > Amat <- matrix(0,J,2*J-3)
> > > bvec <- matrix(0,2*J-3,1)
> > >
> > > for(j in 2:nrow(Amat)){
> > >   Amat[j-1,j-1] = -1
> > >   Amat[j,j-1] = 1
> > > }
> > > for(j in 3:nrow(Amat)){
> > >   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
> > >   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
> > >   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> > > }
> > > for(j in 2:ncol(bvec)) {
> > >   bvec[j-1] = Delta1
> > > }
> > > for(j in 3:ncol(bvec)) {
> > >   bvec[J-1+j-2] = Delta2
> > > }
> > > solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Mon Sep 21 12:36:56 2020
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 21 Sep 2020 13:36:56 +0300
Subject: [R] Quadratic programming
In-Reply-To: <CAB8pepw2FwHg7NcCHBSJhuHg+ovNuHn8utziq4xQGiAV5UWxMw@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepzj2nG-9Lwh5x9Qp0jUrCnv9Xf18KqNsAzLrHcZDhfE9w@mail.gmail.com>
 <CAB8pepzOigvAOxaJk1jAgsTFBQgZ-FzY_5g4vK0HubAAv+NzAw@mail.gmail.com>
 <CAB8pepw2FwHg7NcCHBSJhuHg+ovNuHn8utziq4xQGiAV5UWxMw@mail.gmail.com>
Message-ID: <CAJxz9NbifddmWYG0KUOKTS7kMDDoC72Q5Y-ZQzMSTLeRkgq0wQ@mail.gmail.com>

Thank you for your response!

Bvec is supposed to be a matxit. I'm following the solve.QP (
https://www.rdocumentation.org/packages/quadprog/versions/1.5-8/topics/solve.QP
).

I'm not sure what would be the best way to solve a quadratic programming
problem in R.


ma 21. syysk. 2020 klo 13.20 Abby Spurdle (spurdle.a at gmail.com) kirjoitti:

> One more thing, is bvec supposed to be a matrix?
>
> Note you may need to provide a reproducible example, for better help...
>
> On Mon, Sep 21, 2020 at 10:09 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > Sorry, ignore the last part.
> > What I should have said, is the inequality has the opposite sign.
> > >= bvec (not <= bvec)
> >
> >
> > On Mon, Sep 21, 2020 at 10:05 PM Abby Spurdle <spurdle.a at gmail.com>
> wrote:
> > >
> > > Are you using the quadprog package?
> > > If I can take a random shot in the dark, should bvec be -bvec?
> > >
> > >
> > > On Mon, Sep 21, 2020 at 9:28 PM Maija Sirkj?rvi
> > > <maija.sirkjarvi at gmail.com> wrote:
> > > >
> > > > Hi!
> > > >
> > > > I was wondering if someone could help me out. I'm minimizing a
> following
> > > > function:
> > > >
> > > > \begin{equation}
> > > > $$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
> > > > \text{subject to}
> > > > $$m_{j-1}\leq m_{j}-\delta_{1}$$
> > > > $$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq
> \frac{1}{Q_{j}-Q_{j-1}}
> > > > (m_{j-1}-m_{j})-\delta_{2} $$
> > > > \end{equation}
> > > >
> > > > I have tried quadratic programming, but something is off. Does
> anyone have
> > > > an idea how to approach this?
> > > >
> > > > Thanks in advance!
> > > >
> > > > Q <- rep(0,J)
> > > > for(j in 1:(length(Price))){
> > > >   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> > > > }
> > > >
> > > > Dmat <- matrix(0,nrow= J, ncol=J)
> > > > diag(Dmat) <- 1
> > > > dvec <- -hs
> > > > Aeq <- 0
> > > > beq <- 0
> > > > Amat <- matrix(0,J,2*J-3)
> > > > bvec <- matrix(0,2*J-3,1)
> > > >
> > > > for(j in 2:nrow(Amat)){
> > > >   Amat[j-1,j-1] = -1
> > > >   Amat[j,j-1] = 1
> > > > }
> > > > for(j in 3:nrow(Amat)){
> > > >   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
> > > >   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
> > > >   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> > > > }
> > > > for(j in 2:ncol(bvec)) {
> > > >   bvec[j-1] = Delta1
> > > > }
> > > > for(j in 3:ncol(bvec)) {
> > > >   bvec[J-1+j-2] = Delta2
> > > > }
> > > > solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
> > > >
> > > >         [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chr|@ho|d @end|ng |rom p@yctc@org  Mon Sep 21 14:12:53 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Mon, 21 Sep 2020 13:12:53 +0100 (BST)
Subject: [R] Is there a simple way to analyse all the data using dplyr?
Message-ID: <1861671568.4441269.1600690373199.JavaMail.zimbra@psyctc.org>

I am sure the answer is "yes" and I'm also sure the question may sound mad. Here's a reprex that I think captures what I'm doing 

n <- 500 
gender <- sample(c("Man","Woman","Other"), n, replace = TRUE) 
GPC_score <- rnorm(n) 
scaleMeasures <- runif(n) 
bind_cols(gender = gender, 
GPC_score = GPC_score, 
scaleMeasures = scaleMeasures) -> tibUse 

### let's have the correlation between the two variables broken down by gender 
tibUse %>% 
  filter(gender != "Other") %>% 
  select(gender, GPC_score, scaleMeasures) %>% 
  na.omit() %>% 
  group_by(gender) %>% 
  summarise(cor = cor(cur_data())[1,2]) -> tmp1 

### but I'd also like the correlation for the whole dataset, not by gender 
### this is a kludge to achieve that which I am using partly because I cant' 
### find the equivalent of cur_data() for an ungrouped tibble/df 
tibUse %>% 
  mutate(gender = "All") %>% # nasty kludge to get all the data! 
  select(gender, GPC_score, scaleMeasures) %>% 
  na.omit() %>% 
  group_by(gender) %>% # ditto! 
  summarise(cor = cor(cur_data())[1,2]) -> tmp2 

bind_rows(tmp1, 
  tmp2) 

### gets me what I want:
# A tibble: 3 x 2 
gender cor 
<chr> <dbl> 
1 Man 0.0225 
2 Woman 0.0685 
3 All 0.0444

In reality I have some functions that are more complex than cor()[2,1] (sorry about that particular kludge) that digest dataframes and I'd love to have a simpler way of doing this.

So two questions: 
1) I am sure there a term/function that works on an ungrouped tibble in dplyr as cur_data() does for a grouped tibble ... but I can't find it.
2) I suspect someone has automated a way to get the analysis of the complete data after the analyses of the groups within a single dplyr run ... it seems an obvious and common use case, but I can't find that either.

Sorry, I'm over 99% sure I'm being stupid and missing the obvious here ... but that's the recurrent problem I have with my wetware and searchware doesn't seem to being fixing this!

TIA,

Chris

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From @ugu@t|nu@y@ntj@mb@ @end|ng |rom gm@||@com  Mon Sep 21 02:47:10 2020
From: @ugu@t|nu@y@ntj@mb@ @end|ng |rom gm@||@com (augustinus ntjamba)
Date: Mon, 21 Sep 2020 02:47:10 +0200
Subject: [R] 
 How to model multiple categorical variable in r, using gee model
Message-ID: <CAOS8xUYWr8YpXvGf-b9M1oncnFHJ-U2p7AzZWsYrDPedbqFNJQ@mail.gmail.com>

Good morning.
I'm a student at present working on my final year project.
Kindly asking for help on how to model longitudinal categorical data.

In my data set I have the following variables :type of crime,year,   month,
date and time.treating type of crime as the response variable and there's
12 levels  (Type of crime), while the rest of the variables are
independent.
What model will best fit my data?

I have tried using geeglm And this does show differences in correlation
matrix that should be selected as the best model, secondly I tried using
multgee package "multLORgee" which never have me outputs and lastly I tried
using multnom the function returns the same AIC in the working correction
matrix,
How do i solve this problem
Thank you.

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Sep 21 15:03:44 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 21 Sep 2020 16:03:44 +0300
Subject: [R] Is there a simple way to analyse all the data using dplyr?
In-Reply-To: <1861671568.4441269.1600690373199.JavaMail.zimbra@psyctc.org>
References: <1861671568.4441269.1600690373199.JavaMail.zimbra@psyctc.org>
Message-ID: <CAGgJW779g3w8Drr01naoPNfqPsy8DQWiAzP=F4mx6RB9EKYuGw@mail.gmail.com>

Hi,
I am not sure if the request is about a 'simple way' or requires
dplyr. Here's an approach without using dplyr that is just 2 lines
(not counting creating the data or outputting the result).

n <- 500
myDf <- data.frame( gender=sample(c("Man","Woman","Other"), n, replace = TRUE),
                    GPC_score=rnorm(n), scaleMeasures=runif(n))
aL   <- list(Man="Man",Woman="Woman",All=c("Man","Woman","Other"))
z    <- sapply( 1:length(aL), function(i) { x=myDf[ myDf$gender %in%
aL[[i]], ]; cor(x[,2],x[,3]) } )
names(z) <- names(aL)
z

HTH,
Eric


On Mon, Sep 21, 2020 at 3:13 PM Chris Evans <chrishold at psyctc.org> wrote:
>
> I am sure the answer is "yes" and I'm also sure the question may sound mad. Here's a reprex that I think captures what I'm doing
>
> n <- 500
> gender <- sample(c("Man","Woman","Other"), n, replace = TRUE)
> GPC_score <- rnorm(n)
> scaleMeasures <- runif(n)
> bind_cols(gender = gender,
> GPC_score = GPC_score,
> scaleMeasures = scaleMeasures) -> tibUse
>
> ### let's have the correlation between the two variables broken down by gender
> tibUse %>%
>   filter(gender != "Other") %>%
>   select(gender, GPC_score, scaleMeasures) %>%
>   na.omit() %>%
>   group_by(gender) %>%
>   summarise(cor = cor(cur_data())[1,2]) -> tmp1
>
> ### but I'd also like the correlation for the whole dataset, not by gender
> ### this is a kludge to achieve that which I am using partly because I cant'
> ### find the equivalent of cur_data() for an ungrouped tibble/df
> tibUse %>%
>   mutate(gender = "All") %>% # nasty kludge to get all the data!
>   select(gender, GPC_score, scaleMeasures) %>%
>   na.omit() %>%
>   group_by(gender) %>% # ditto!
>   summarise(cor = cor(cur_data())[1,2]) -> tmp2
>
> bind_rows(tmp1,
>   tmp2)
>
> ### gets me what I want:
> # A tibble: 3 x 2
> gender cor
> <chr> <dbl>
> 1 Man 0.0225
> 2 Woman 0.0685
> 3 All 0.0444
>
> In reality I have some functions that are more complex than cor()[2,1] (sorry about that particular kludge) that digest dataframes and I'd love to have a simpler way of doing this.
>
> So two questions:
> 1) I am sure there a term/function that works on an ungrouped tibble in dplyr as cur_data() does for a grouped tibble ... but I can't find it.
> 2) I suspect someone has automated a way to get the analysis of the complete data after the analyses of the groups within a single dplyr run ... it seems an obvious and common use case, but I can't find that either.
>
> Sorry, I'm over 99% sure I'm being stupid and missing the obvious here ... but that's the recurrent problem I have with my wetware and searchware doesn't seem to being fixing this!
>
> TIA,
>
> Chris
>
> --
> Small contribution in our coronavirus rigours:
> https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/
>
> Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
> I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
> but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
>    https://www.psyctc.org/psyctc/
> and a site I manage for CORE and CORE system trust at:
>    http://www.coresystemtrust.org.uk/
> I have "semigrated" to France, see:
>    https://www.psyctc.org/pelerinage2016/semigrating-to-france/
>    https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/
>
> If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
>    https://www.psyctc.org/pelerinage2016/ceworkdiary/
> Beware: French time, generally an hour ahead of UK.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rk@c|ement@ @end|ng |rom k|@@e  Mon Sep 21 14:41:01 2020
From: m@rk@c|ement@ @end|ng |rom k|@@e (Mark Clements)
Date: Mon, 21 Sep 2020 12:41:01 +0000
Subject: [R] [R-pkgs] ascii package returns to CRAN
Message-ID: <1cb16c76-a692-4153-9c4e-961ea7ccabc2@email.android.com>

The ascii package provides formatted tables and lists in a number of markup formats (Asciidoc, Org mode, Pandoc markdown, ReStructured text, Txt2tags and Textile). Documents in Rmarkdown and Org mode can include R code blocks that produce markup output. Sweave drivers are also available for all six markup formats, including caching through weaver. Finally, the package supports R scripting to export reports to a variety of formats.

Changes from the previous CRAN release include: removal of cacheSweave functionality; internal implementation of weaver; additional examples; and a number of bug fixes.




N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI kommer att behandla dina personuppgifter. H?r finns information om hur KI behandlar personuppgifter<https://ki.se/medarbetare/integritetsskyddspolicy>.


Sending email to Karolinska Institutet (KI) will result in KI processing your personal data. You can read more about KI?s processing of personal data here<https://ki.se/en/staff/data-protection-policy>.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From rkoenker @end|ng |rom ||||no|@@edu  Mon Sep 21 15:40:29 2020
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Mon, 21 Sep 2020 13:40:29 +0000
Subject: [R] formula wrangling
In-Reply-To: <C8AD2C5C-535A-4106-B88F-9849B1176EF2@illinois.edu>
References: <C8AD2C5C-535A-4106-B88F-9849B1176EF2@illinois.edu>
Message-ID: <D6FBD413-467A-430E-9FDD-40BE06C4A5FD@illinois.edu>

Here is a revised snippet that seems to work the way that was intended.  Apologies to anyone
who wasted time looking at the original post.  Of course my interest in simpler or more efficient
solutions remains unabated.

if (exists("fqssnames")) {
	mff <- m
	mff$formula <- Terms
        ffqss <- paste(fqssnames, collapse = "+")
        mff$formula <- as.formula(paste(deparse(mff$formula), "+", ffqss))
    }
    m$formula <- Terms
    m <- eval(m, parent.frame())
    mff <- eval(mff, parent.frame())
    Y <- model.extract(m, "response")
    X <- model.matrix(Terms, m)
    ef <- environment(formula)
    qss <- function(x, lambda) (x^lambda - 1)/lambda
    if (length(qssterms) > 0) {
        xss <- lapply(tmpc$vars, function(u) eval(parse(text = u), mff))
	for(i in 1:length(xss)){
	    X <- cbind(X, xss[[i]]) # Here is the problem
	}
    }


> On Sep 21, 2020, at 9:52 AM, Koenker, Roger W <rkoenker at illinois.edu> wrote:
> 
> I need some help with a formula processing problem that arose from a seemingly innocuous  request
> that I add a ?subset? argument to the additive modeling function ?rqss? in my quantreg package.
> 
> I?ve tried to boil the relevant code down to something simpler as illustrated below.  The formulae in
> question involve terms called ?qss? that construct sparse matrix objects, but I?ve replaced all that with
> a much simpler BoxCox construction that I hope illustrates the basic difficulty.  What is supposed to happen
> is that xss objects are evaluated and cbind?d to the design matrix, subject to the same subset restriction
> as the rest of the model frame.  However, this doesn?t happen, instead the xss vectors are evaluated
> on the full sample and the cbind operation generates a warning which probably should be an error.
> I?ve inserted a browser() to make it easy to verify that the length of xss[[[1]] doesn?t match dim(X).
> 
> Any suggestions would be most welcome, including other simplifications of the code.  Note that
> the function untangle.specials() is adapted, or perhaps I should say adopted form the survival 
> package so you would need the quantreg package to run the attached code.
> 
> Thanks,
> Roger
> 
> 
> 
> fit <- function(formula, subset, data, ...){
>    call <- match.call()
>    m <- match.call(expand.dots = FALSE)
>    tmp <- c("", "formula", "subset", "data")
>    m <- m[match(tmp, names(m), nomatch = 0)]
>    m[[1]] <- as.name("model.frame")
>    Terms <- if(missing(data)) terms(formula,special = "qss")
> 	    else terms(formula, special = "qss", data = data)
>    qssterms <- attr(Terms, "specials")$qss
>    if (length(qssterms)) {
>        tmpc <- untangle.specials(Terms, "qss")
>        dropx <- tmpc$terms
>        if (length(dropx)) 
>            Terms <- Terms[-dropx]
>        attr(Terms, "specials") <- tmpc$vars
> 	fnames <- function(x) {
>            fy <- all.names(x[[2]])
>            if (fy[1] == "cbind") 
>                fy <- fy[-1]
>            fy
>        }
>        fqssnames <- unlist(lapply(parse(text = tmpc$vars), fnames))
>        qssnames <- unlist(lapply(parse(text = tmpc$vars), function(x) deparse(x[[2]])))
>    }
>    if (exists("fqssnames")) {
>        ffqss <- paste(fqssnames, collapse = "+")
>        ff <- as.formula(paste(deparse(formula), "+", ffqss))
>    }
>    m$formula <- Terms
>    m <- eval(m, parent.frame())
>    Y <- model.extract(m, "response")
>    X <- model.matrix(Terms, m)
>    ef <- environment(formula)
>    qss <- function(x, lambda) (x^lambda - 1)/lambda
>    if (length(qssterms) > 0) {
>        xss <- lapply(tmpc$vars, function(u) eval(parse(text = u), m, enclos = ef))
> 	for(i in 1:length(xss)){
> 	    X <- cbind(X, xss[[i]]) # Here is the problem
> 	}
>    }
>    browser()
>    z <- lm.fit(X,Y) # The dreaded least squares fit
>    z
> }
> # Test case
> n <- 200
> x <- sort(rchisq(n,4))
> z <- rnorm(n)
> s <- sample(1:n, n/2)
> y <- log(x) + rnorm(n)/5
> D = data.frame(y = y, x = x, z = z, s = (1:n) %in% s)
> plot(x, y)
> lam = 0.2
> #f0 <- fit(y ~ qss(x,lambda = lam) + z, subset = s)
> f1 <- fit(y ~ qss(x, lambda = lam) + z, subset = s, data = D)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Sep 21 16:30:04 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 21 Sep 2020 14:30:04 +0000
Subject: [R] aggregate semi-hourly data not 00-24 but 9-9
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809F88B7@ESINO.regionemarche.intra>

Dear R-list members,
I have semi-hourly snowfall data.
I should sum the semi-hourly increments (only the positive ones, but this is not described in my example) day by day, not from 00 to 24 but from 9 to 9.

I am able to use the diff function, create a list of days and use the function aggregate, but it works only from 0 to 24. Any suggestion for an efficient way to do it?
Here my code:
day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
df1$hs <- rnorm(nrows(df1), 40, 10)
df1$diff[2:nrow(df1)] <- diff(df1$hs)
df1$day <- format(df$data_POSIX,"%y-%m-%d")
df2 <- aggregate(diff ~ day, df, sum)

Thank you for your help
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Sep 21 17:06:51 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 21 Sep 2020 18:06:51 +0300
Subject: [R] aggregate semi-hourly data not 00-24 but 9-9
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809F88B7@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809F88B7@ESINO.regionemarche.intra>
Message-ID: <CAGgJW77j81F45QUHvbM32VZi=6HKwaAPsqt8B63=C6WoPt60_A@mail.gmail.com>

Hi Stefano,
If you mean from 9am on one day to 9am on the following day, you can
do a trick. Simply subtract 9hrs from each timestamp and then you want
midnight to midnight for these adjusted times, which you can get using
the method you followed.

I googled and found that lubridate::hours() can be used to add or
subtract hours from a POSIXct.

library(lubridate)

day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
df1$hs <- rnorm(nrow(df1), 40, 10)
df1$diff[2:nrow(df1)] <- diff(df1$hs)

df1$data_POSIXminus9 <- df1$data_POSIX - lubridate::hours(9)
df1$dayX <- format(df1$data_POSIXminus9,"%y-%m-%d")
df2X <- aggregate(diff ~ dayX, df1, sum)
df2X

HTH,
Eric

On Mon, Sep 21, 2020 at 5:30 PM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear R-list members,
> I have semi-hourly snowfall data.
> I should sum the semi-hourly increments (only the positive ones, but this is not described in my example) day by day, not from 00 to 24 but from 9 to 9.
>
> I am able to use the diff function, create a list of days and use the function aggregate, but it works only from 0 to 24. Any suggestion for an efficient way to do it?
> Here my code:
> day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
> df1$hs <- rnorm(nrows(df1), 40, 10)
> df1$diff[2:nrow(df1)] <- diff(df1$hs)
> df1$day <- format(df$data_POSIX,"%y-%m-%d")
> df2 <- aggregate(diff ~ day, df, sum)
>
> Thank you for your help
> Stefano
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@ho|d @end|ng |rom p@yctc@org  Mon Sep 21 18:05:14 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Mon, 21 Sep 2020 17:05:14 +0100 (BST)
Subject: [R] Is there a simple way to analyse all the data using dplyr?
In-Reply-To: <CAGgJW779g3w8Drr01naoPNfqPsy8DQWiAzP=F4mx6RB9EKYuGw@mail.gmail.com>
References: <1861671568.4441269.1600690373199.JavaMail.zimbra@psyctc.org>
 <CAGgJW779g3w8Drr01naoPNfqPsy8DQWiAzP=F4mx6RB9EKYuGw@mail.gmail.com>
Message-ID: <2053406566.5018001.1600704314331.JavaMail.zimbra@psyctc.org>

Thanks Eric,

That's very neat!  Sort of fits my belief about base R and telegrams (that's not knocking it, I really do respect it, my wetware is just not good at it).

For many reasons, particularly the convenience for formatting and passing on results from the real function I'm applying, I am really keen to find tidyverse/dplyr answers/options.  Any offers?!

TIA (all),

Chris

----- Original Message -----
> From: "Eric Berger" <ericjberger at gmail.com>
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: "r-help" <r-help at r-project.org>
> Sent: Monday, 21 September, 2020 15:03:44
> Subject: Re: [R] Is there a simple way to analyse all the data using dplyr?

> Hi,
> I am not sure if the request is about a 'simple way' or requires
> dplyr. Here's an approach without using dplyr that is just 2 lines
> (not counting creating the data or outputting the result).
> 
> n <- 500
> myDf <- data.frame( gender=sample(c("Man","Woman","Other"), n, replace = TRUE),
>                    GPC_score=rnorm(n), scaleMeasures=runif(n))
> aL   <- list(Man="Man",Woman="Woman",All=c("Man","Woman","Other"))
> z    <- sapply( 1:length(aL), function(i) { x=myDf[ myDf$gender %in%
> aL[[i]], ]; cor(x[,2],x[,3]) } )
> names(z) <- names(aL)
> z
> 
> HTH,
> Eric
> 
> 
> On Mon, Sep 21, 2020 at 3:13 PM Chris Evans <chrishold at psyctc.org> wrote:
>>
>> I am sure the answer is "yes" and I'm also sure the question may sound mad.
>> Here's a reprex that I think captures what I'm doing
>>
>> n <- 500
>> gender <- sample(c("Man","Woman","Other"), n, replace = TRUE)
>> GPC_score <- rnorm(n)
>> scaleMeasures <- runif(n)
>> bind_cols(gender = gender,
>> GPC_score = GPC_score,
>> scaleMeasures = scaleMeasures) -> tibUse
>>
>> ### let's have the correlation between the two variables broken down by gender
>> tibUse %>%
>>   filter(gender != "Other") %>%
>>   select(gender, GPC_score, scaleMeasures) %>%
>>   na.omit() %>%
>>   group_by(gender) %>%
>>   summarise(cor = cor(cur_data())[1,2]) -> tmp1
>>
>> ### but I'd also like the correlation for the whole dataset, not by gender
>> ### this is a kludge to achieve that which I am using partly because I cant'
>> ### find the equivalent of cur_data() for an ungrouped tibble/df
>> tibUse %>%
>>   mutate(gender = "All") %>% # nasty kludge to get all the data!
>>   select(gender, GPC_score, scaleMeasures) %>%
>>   na.omit() %>%
>>   group_by(gender) %>% # ditto!
>>   summarise(cor = cor(cur_data())[1,2]) -> tmp2
>>
>> bind_rows(tmp1,
>>   tmp2)
>>
>> ### gets me what I want:
>> # A tibble: 3 x 2
>> gender cor
>> <chr> <dbl>
>> 1 Man 0.0225
>> 2 Woman 0.0685
>> 3 All 0.0444
>>
>> In reality I have some functions that are more complex than cor()[2,1] (sorry
>> about that particular kludge) that digest dataframes and I'd love to have a
>> simpler way of doing this.
>>
>> So two questions:
>> 1) I am sure there a term/function that works on an ungrouped tibble in dplyr as
>> cur_data() does for a grouped tibble ... but I can't find it.
>> 2) I suspect someone has automated a way to get the analysis of the complete
>> data after the analyses of the groups within a single dplyr run ... it seems an
>> obvious and common use case, but I can't find that either.
>>
>> Sorry, I'm over 99% sure I'm being stupid and missing the obvious here ... but
>> that's the recurrent problem I have with my wetware and searchware doesn't seem
>> to being fixing this!
>>
>> TIA,
>>
>> Chris
>>
>> --
>> Small contribution in our coronavirus rigours:
>> https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/
>>
>> Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield
>> <chris.evans at sheffield.ac.uk>
>> I do some consultation work for the University of Roehampton
>> <chris.evans at roehampton.ac.uk> and other places
>> but <chris at psyctc.org> remains my main Email address.  I have a work web site
>> at:
>>    https://www.psyctc.org/psyctc/
>> and a site I manage for CORE and CORE system trust at:
>>    http://www.coresystemtrust.org.uk/
>> I have "semigrated" to France, see:
>>    https://www.psyctc.org/pelerinage2016/semigrating-to-france/
>>    https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/
>>
>> If you want an Emeeting, I am trying to keep them to Thursdays and my diary is
>> at:
>>    https://www.psyctc.org/pelerinage2016/ceworkdiary/
>> Beware: French time, generally an hour ahead of UK.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep 21 19:06:52 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 21 Sep 2020 10:06:52 -0700
Subject: [R] aggregate semi-hourly data not 00-24 but 9-9
In-Reply-To: <CAGgJW77j81F45QUHvbM32VZi=6HKwaAPsqt8B63=C6WoPt60_A@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F809F88B7@ESINO.regionemarche.intra>
 <CAGgJW77j81F45QUHvbM32VZi=6HKwaAPsqt8B63=C6WoPt60_A@mail.gmail.com>
Message-ID: <6FA20CB0-7DC1-407F-8A3F-A618D7483EEE@dcn.davis.ca.us>

The base R as.difftime function is perfectly usable to create this offset without pulling in lubridate.

On September 21, 2020 8:06:51 AM PDT, Eric Berger <ericjberger at gmail.com> wrote:
>Hi Stefano,
>If you mean from 9am on one day to 9am on the following day, you can
>do a trick. Simply subtract 9hrs from each timestamp and then you want
>midnight to midnight for these adjusted times, which you can get using
>the method you followed.
>
>I googled and found that lubridate::hours() can be used to add or
>subtract hours from a POSIXct.
>
>library(lubridate)
>
>day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M",
>tz="Etc/GMT-1")
>day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M",
>tz="Etc/GMT-1")
>df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
>df1$hs <- rnorm(nrow(df1), 40, 10)
>df1$diff[2:nrow(df1)] <- diff(df1$hs)
>
>df1$data_POSIXminus9 <- df1$data_POSIX - lubridate::hours(9)
>df1$dayX <- format(df1$data_POSIXminus9,"%y-%m-%d")
>df2X <- aggregate(diff ~ dayX, df1, sum)
>df2X
>
>HTH,
>Eric
>
>On Mon, Sep 21, 2020 at 5:30 PM Stefano Sofia
><stefano.sofia at regione.marche.it> wrote:
>>
>> Dear R-list members,
>> I have semi-hourly snowfall data.
>> I should sum the semi-hourly increments (only the positive ones, but
>this is not described in my example) day by day, not from 00 to 24 but
>from 9 to 9.
>>
>> I am able to use the diff function, create a list of days and use the
>function aggregate, but it works only from 0 to 24. Any suggestion for
>an efficient way to do it?
>> Here my code:
>> day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M",
>tz="Etc/GMT-1")
>> day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M",
>tz="Etc/GMT-1")
>> df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
>> df1$hs <- rnorm(nrows(df1), 40, 10)
>> df1$diff[2:nrow(df1)] <- diff(df1$hs)
>> df1$day <- format(df$data_POSIX,"%y-%m-%d")
>> df2 <- aggregate(diff ~ day, df, sum)
>>
>> Thank you for your help
>> Stefano
>>
>>          (oo)
>> --oOO--( )--OOo----------------
>> Stefano Sofia PhD
>> Civil Protection - Marche Region
>> Meteo Section
>> Snow Section
>> Via del Colle Ameno 5
>> 60126 Torrette di Ancona, Ancona
>> Uff: 071 806 7743
>> E-mail: stefano.sofia at regione.marche.it
>> ---Oo---------oO----------------
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>contenere informazioni confidenziali, pertanto ? destinato solo a
>persone autorizzate alla ricezione. I messaggi di posta elettronica per
>i client di Regione Marche possono contenere informazioni confidenziali
>e con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>>
>> --
>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>> This message was scanned by Libra ESVA and is believed to be clean.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From g|err@z29 @end|ng |rom gm@||@com  Mon Sep 21 20:24:16 2020
From: g|err@z29 @end|ng |rom gm@||@com (=?utf-8?Q?Gon=C3=A7alo_Ferraz?=)
Date: Mon, 21 Sep 2020 15:24:16 -0300
Subject: [R] open file on R GUI results in spinning wheel and frozen R - Mac
 OS
Message-ID: <1306BFEA-EB5B-42DE-B353-E0F860A023C9@gmail.com>

Hello,

I?ve been using R-studio for a while and today I needed to try something directly on the R-GUI.

But when I try to open any *.R file I get a spinning wheel and R freezes. I can only shut it down with ?force quit?.

I have deleted and re-installed R three times, each time trying to run a more thorough uninstall, but the problem persists.

I am using Mac OS Catalina 10.15.6 and the latest version of R ->  R 4.0.2 GUI 1.72 Catalina build (7847)

Strangely, as this problem was happening on the R GUI, I was still able to open R scripts on RStudio. But now I uninstalled RStudio as well, in the latest attempt to start from scratch.

Is this problem familiar to anyone?

Thanks for any help,

Gon?alo

From v@|kremk @end|ng |rom gm@||@com  Mon Sep 21 20:37:12 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Mon, 21 Sep 2020 13:37:12 -0500
Subject: [R] date
Message-ID: <CAJOiR6bzBK5qZUoND_i6U0uAVxu82-ibg9cOTmvDrEZV75LEtw@mail.gmail.com>

Hi All,

I am trying to sort dates within a group. My sample data is

df <-read.table(text="ID date
A1   09/17/04
A1   01/27/05
A1   05/07/03
A2   05/21/17
A2   09/12/16
A3   01/25/13
A4   09/27/19",header=TRUE,stringsAsFactors=F)
df$date2 = as.Date(strptime(df$date,format="%m/%d/%y"))
df$date =NULL

I want to sort  date2  from recent to oldest.  within the ID group and
I used this,
df <- df[order(df$ID, rev((df$date2))),]. It did not work and teh
output is  shown below.

ID      date2
2 A1 2005-01-27
3 A1 2003-05-07
1 A1 2004-09-17
5 A2 2016-09-12
4 A2 2017-05-21
6 A3 2013-01-25
7 A4 2019-09-27
What am I missing?
Thank you.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Sep 21 20:42:18 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 21 Sep 2020 14:42:18 -0400
Subject: [R] formula wrangling
In-Reply-To: <22572_1600695669_08LDf9eB012973_D6FBD413-467A-430E-9FDD-40BE06C4A5FD@illinois.edu>
References: <C8AD2C5C-535A-4106-B88F-9849B1176EF2@illinois.edu>
 <22572_1600695669_08LDf9eB012973_D6FBD413-467A-430E-9FDD-40BE06C4A5FD@illinois.edu>
Message-ID: <2579a63a-8ff5-4683-1efb-344dcad13ae9@mcmaster.ca>

Dear Roger,

This is an interesting puzzle and I started to look at it when your 
second message arrived. I can simplify your code slightly in two places, 
here:

   if (exists("fqssnames")) {
     mff <- m
     ffqss <- paste(fqssnames, collapse = "+")
     mff$formula <- as.formula(paste(deparse(Terms), "+", ffqss))
   }

and here:

   if (length(qssterms) > 0) {
     X <- do.call(cbind,
                  c(list(X),
                    lapply(tmpc$vars, function(u) eval(parse(text = u), 
mff))))
     }

and the following line is extraneous:

    ef <- environment(formula)

That doesn't amount to much, and I haven't tested my substitute code 
beyond your example.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-09-21 9:40 a.m., Koenker, Roger W wrote:
> Here is a revised snippet that seems to work the way that was intended.  Apologies to anyone
> who wasted time looking at the original post.  Of course my interest in simpler or more efficient
> solutions remains unabated.
> 
> if (exists("fqssnames")) {
> 	mff <- m
> 	mff$formula <- Terms
>          ffqss <- paste(fqssnames, collapse = "+")
>          mff$formula <- as.formula(paste(deparse(mff$formula), "+", ffqss))
>      }
>      m$formula <- Terms
>      m <- eval(m, parent.frame())
>      mff <- eval(mff, parent.frame())
>      Y <- model.extract(m, "response")
>      X <- model.matrix(Terms, m)
>      ef <- environment(formula)
>      qss <- function(x, lambda) (x^lambda - 1)/lambda
>      if (length(qssterms) > 0) {
>          xss <- lapply(tmpc$vars, function(u) eval(parse(text = u), mff))
> 	for(i in 1:length(xss)){
> 	    X <- cbind(X, xss[[i]]) # Here is the problem
> 	}
>      }
> 
> 
>> On Sep 21, 2020, at 9:52 AM, Koenker, Roger W <rkoenker at illinois.edu> wrote:
>>
>> I need some help with a formula processing problem that arose from a seemingly innocuous  request
>> that I add a ?subset? argument to the additive modeling function ?rqss? in my quantreg package.
>>
>> I?ve tried to boil the relevant code down to something simpler as illustrated below.  The formulae in
>> question involve terms called ?qss? that construct sparse matrix objects, but I?ve replaced all that with
>> a much simpler BoxCox construction that I hope illustrates the basic difficulty.  What is supposed to happen
>> is that xss objects are evaluated and cbind?d to the design matrix, subject to the same subset restriction
>> as the rest of the model frame.  However, this doesn?t happen, instead the xss vectors are evaluated
>> on the full sample and the cbind operation generates a warning which probably should be an error.
>> I?ve inserted a browser() to make it easy to verify that the length of xss[[[1]] doesn?t match dim(X).
>>
>> Any suggestions would be most welcome, including other simplifications of the code.  Note that
>> the function untangle.specials() is adapted, or perhaps I should say adopted form the survival
>> package so you would need the quantreg package to run the attached code.
>>
>> Thanks,
>> Roger
>>
>>
>>
>> fit <- function(formula, subset, data, ...){
>>     call <- match.call()
>>     m <- match.call(expand.dots = FALSE)
>>     tmp <- c("", "formula", "subset", "data")
>>     m <- m[match(tmp, names(m), nomatch = 0)]
>>     m[[1]] <- as.name("model.frame")
>>     Terms <- if(missing(data)) terms(formula,special = "qss")
>> 	    else terms(formula, special = "qss", data = data)
>>     qssterms <- attr(Terms, "specials")$qss
>>     if (length(qssterms)) {
>>         tmpc <- untangle.specials(Terms, "qss")
>>         dropx <- tmpc$terms
>>         if (length(dropx))
>>             Terms <- Terms[-dropx]
>>         attr(Terms, "specials") <- tmpc$vars
>> 	fnames <- function(x) {
>>             fy <- all.names(x[[2]])
>>             if (fy[1] == "cbind")
>>                 fy <- fy[-1]
>>             fy
>>         }
>>         fqssnames <- unlist(lapply(parse(text = tmpc$vars), fnames))
>>         qssnames <- unlist(lapply(parse(text = tmpc$vars), function(x) deparse(x[[2]])))
>>     }
>>     if (exists("fqssnames")) {
>>         ffqss <- paste(fqssnames, collapse = "+")
>>         ff <- as.formula(paste(deparse(formula), "+", ffqss))
>>     }
>>     m$formula <- Terms
>>     m <- eval(m, parent.frame())
>>     Y <- model.extract(m, "response")
>>     X <- model.matrix(Terms, m)
>>     ef <- environment(formula)
>>     qss <- function(x, lambda) (x^lambda - 1)/lambda
>>     if (length(qssterms) > 0) {
>>         xss <- lapply(tmpc$vars, function(u) eval(parse(text = u), m, enclos = ef))
>> 	for(i in 1:length(xss)){
>> 	    X <- cbind(X, xss[[i]]) # Here is the problem
>> 	}
>>     }
>>     browser()
>>     z <- lm.fit(X,Y) # The dreaded least squares fit
>>     z
>> }
>> # Test case
>> n <- 200
>> x <- sort(rchisq(n,4))
>> z <- rnorm(n)
>> s <- sample(1:n, n/2)
>> y <- log(x) + rnorm(n)/5
>> D = data.frame(y = y, x = x, z = z, s = (1:n) %in% s)
>> plot(x, y)
>> lam = 0.2
>> #f0 <- fit(y ~ qss(x,lambda = lam) + z, subset = s)
>> f1 <- fit(y ~ qss(x, lambda = lam) + z, subset = s, data = D)
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 21 21:03:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 21 Sep 2020 12:03:54 -0700
Subject: [R] 
 open file on R GUI results in spinning wheel and frozen R - Mac OS
In-Reply-To: <1306BFEA-EB5B-42DE-B353-E0F860A023C9@gmail.com>
References: <1306BFEA-EB5B-42DE-B353-E0F860A023C9@gmail.com>
Message-ID: <CAGxFJbTngmoTNPTUEd5uFhrzR8fpOn9arznAOYv+VZdw8m+hQw@mail.gmail.com>

You might do better on r-sig-mac  for this.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 21, 2020 at 11:24 AM Gon?alo Ferraz <gferraz29 at gmail.com> wrote:

> Hello,
>
> I?ve been using R-studio for a while and today I needed to try something
> directly on the R-GUI.
>
> But when I try to open any *.R file I get a spinning wheel and R freezes.
> I can only shut it down with ?force quit?.
>
> I have deleted and re-installed R three times, each time trying to run a
> more thorough uninstall, but the problem persists.
>
> I am using Mac OS Catalina 10.15.6 and the latest version of R ->  R 4.0.2
> GUI 1.72 Catalina build (7847)
>
> Strangely, as this problem was happening on the R GUI, I was still able to
> open R scripts on RStudio. But now I uninstalled RStudio as well, in the
> latest attempt to start from scratch.
>
> Is this problem familiar to anyone?
>
> Thanks for any help,
>
> Gon?alo
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Mon Sep 21 21:41:33 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Mon, 21 Sep 2020 15:41:33 -0400
Subject: [R] date
In-Reply-To: <CAJOiR6bzBK5qZUoND_i6U0uAVxu82-ibg9cOTmvDrEZV75LEtw@mail.gmail.com>
References: <CAJOiR6bzBK5qZUoND_i6U0uAVxu82-ibg9cOTmvDrEZV75LEtw@mail.gmail.com>
Message-ID: <CAM_vjumGCweCcbxsGj21ikuSF-Uz4pKn8HG_TXv_wZTtza116A@mail.gmail.com>

Hi,

Nice reproducible example.

rev(df$date2) isn't doing what you think it's doing - try looking at
it by itself.

Some digging into ?order will get you what you are after:

df[order(df$ID, df$date2, decreasing=c(FALSE, TRUE), method="radix"),]

> df[order(df$ID, df$date2, decreasing=c(FALSE, TRUE), method="radix"),]
  ID      date2
2 A1 2005-01-27
1 A1 2004-09-17
3 A1 2003-05-07
4 A2 2017-05-21
5 A2 2016-09-12
6 A3 2013-01-25
7 A4 2019-09-27

Sarah

On Mon, Sep 21, 2020 at 2:41 PM Val <valkremk at gmail.com> wrote:
>
> Hi All,
>
> I am trying to sort dates within a group. My sample data is
>
> df <-read.table(text="ID date
> A1   09/17/04
> A1   01/27/05
> A1   05/07/03
> A2   05/21/17
> A2   09/12/16
> A3   01/25/13
> A4   09/27/19",header=TRUE,stringsAsFactors=F)
> df$date2 = as.Date(strptime(df$date,format="%m/%d/%y"))
> df$date =NULL
>
> I want to sort  date2  from recent to oldest.  within the ID group and
> I used this,
> df <- df[order(df$ID, rev((df$date2))),]. It did not work and teh
> output is  shown below.
>
> ID      date2
> 2 A1 2005-01-27
> 3 A1 2003-05-07
> 1 A1 2004-09-17
> 5 A2 2016-09-12
> 4 A2 2017-05-21
> 6 A3 2013-01-25
> 7 A4 2019-09-27
> What am I missing?
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From bhh @end|ng |rom x@4@||@n|  Mon Sep 21 21:43:02 2020
From: bhh @end|ng |rom x@4@||@n| (Berend Hasselman)
Date: Mon, 21 Sep 2020 21:43:02 +0200
Subject: [R] 
 open file on R GUI results in spinning wheel and frozen R - Mac OS
In-Reply-To: <1306BFEA-EB5B-42DE-B353-E0F860A023C9@gmail.com>
References: <1306BFEA-EB5B-42DE-B353-E0F860A023C9@gmail.com>
Message-ID: <905502A1-8AA0-4D88-8CF7-2B4F334A0DE9@xs4all.nl>



> On 21 Sep 2020, at 20:24, Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
> 
> Hello,
> 
> I?ve been using R-studio for a while and today I needed to try something directly on the R-GUI.
> 
> But when I try to open any *.R file I get a spinning wheel and R freezes. I can only shut it down with ?force quit?.
> 
> I have deleted and re-installed R three times, each time trying to run a more thorough uninstall, but the problem persists.
> 
> I am using Mac OS Catalina 10.15.6 and the latest version of R ->  R 4.0.2 GUI 1.72 Catalina build (7847)
> 
> Strangely, as this problem was happening on the R GUI, I was still able to open R scripts on RStudio. But now I uninstalled RStudio as well, in the latest attempt to start from scratch.
> 
> Is this problem familiar to anyone?
> 

See this thread on the R-SIG-Mac list: https://stat.ethz.ch/pipermail/r-sig-mac/2020-June/013575.html
and her for a solution (sequel of above): https://stat.ethz.ch/pipermail/r-sig-mac/2020-July/013641.html

Go to https://mac.r-project.org/ and get the latest revision of the R GUI which is noe https://mac.r-project.org/high-sierra/R-4.0-branch/R-GUI-7884-4.0-high-sierra-Release.dmg

I have revision 7849; if the above does not work I can mail you the dmg of revision 7849.

Berend



> Thanks for any help,
> 
> Gon?alo
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ch@kr@r@hu| @end|ng |rom gm@||@com  Mon Sep 21 21:55:01 2020
From: ch@kr@r@hu| @end|ng |rom gm@||@com (Rahul Chakraborty)
Date: Tue, 22 Sep 2020 01:25:01 +0530
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
Message-ID: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>

Hello everyone,

I am using *mlogit* to analyse my choice experiment data. I have *3
alternatives* for each individual and for each individual I have *9
questions*. I have a response from *516 individuals*. So it is a panel of
9*516 observations. I have arranged the data in long format (it contains
100 columns indicating different variables and identifiers).

In mlogit I tried the following command---

*mldata<- mlogit.data(mydata, shape = "long", alt.var = "Alt_name", choice
= "Choice_binary", id.var = "IND")*

It is giving me the following error message- Error in 1:nchid : result
would be too long a vector

Could you please help me with this? I don't think it is too big a data 100
ROWS*13932 columns. I faced no issue in Excel. I am stuck due to this issue.
Thanks in advance.

-- Best Regards,
Rahul Chakraborty
Research Fellow
National Institute of Public Finance and Policy
New Delhi- 110067

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Sep 21 22:12:32 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 22 Sep 2020 08:12:32 +1200
Subject: [R] Quadratic programming
In-Reply-To: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
Message-ID: <CAB8pepwwT3sqmnYt43bE3VrSUMjxnSAdrFV9LoiLHXwSjWSM5Q@mail.gmail.com>

Hi,

Sorry, for my rushed responses, last night.
(Shouldn't post when I'm about to log out).

I haven't used the quadprog package for nearly a decade.
And I was hoping that an expert using optimization in finance in
economics would reply.

Some comments:
(1) I don't know why you think bvec should be a matrix. The
documentation clearly says it should be a vector (implying not a
matrix).
The only arguments that should be matrices are Dmat and Amat.
(2) I'm having some difficulty following your quadratic program, even
after rendering it.
Perhaps you could rewrite your expressions, in a form that is
consistent with the input to solve.QP. That's a math problem, not an R
programming problem, as such.
(3) If that fails, then you'll need to produce a minimal reproducible example.
I strongly recommend that the R code matches the quadratic program, as
closely as possible.


On Mon, Sep 21, 2020 at 9:28 PM Maija Sirkj?rvi
<maija.sirkjarvi at gmail.com> wrote:
>
> Hi!
>
> I was wondering if someone could help me out. I'm minimizing a following
> function:
>
> \begin{equation}
> $$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
> \text{subject to}
> $$m_{j-1}\leq m_{j}-\delta_{1}$$
> $$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq \frac{1}{Q_{j}-Q_{j-1}}
> (m_{j-1}-m_{j})-\delta_{2} $$
> \end{equation}
>
> I have tried quadratic programming, but something is off. Does anyone have
> an idea how to approach this?
>
> Thanks in advance!
>
> Q <- rep(0,J)
> for(j in 1:(length(Price))){
>   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> }
>
> Dmat <- matrix(0,nrow= J, ncol=J)
> diag(Dmat) <- 1
> dvec <- -hs
> Aeq <- 0
> beq <- 0
> Amat <- matrix(0,J,2*J-3)
> bvec <- matrix(0,2*J-3,1)
>
> for(j in 2:nrow(Amat)){
>   Amat[j-1,j-1] = -1
>   Amat[j,j-1] = 1
> }
> for(j in 3:nrow(Amat)){
>   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
>   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
>   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> }
> for(j in 2:ncol(bvec)) {
>   bvec[j-1] = Delta1
> }
> for(j in 3:ncol(bvec)) {
>   bvec[J-1+j-2] = Delta2
> }
> solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Sep 21 22:14:54 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 21 Sep 2020 13:14:54 -0700
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
Message-ID: <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>

If you had included output of summary(mydata) we might be more capable 
of giving a fact-based answer but I'm guessing that you have a lot of 
catagorical variables with multiple levels and some sort of combinatoric 
explosion is resulting in too many levels of a constructed factor.


-- 

David.

On 9/21/20 12:55 PM, Rahul Chakraborty wrote:
> Hello everyone,
>
> I am using *mlogit* to analyse my choice experiment data. I have *3
> alternatives* for each individual and for each individual I have *9
> questions*. I have a response from *516 individuals*. So it is a panel of
> 9*516 observations. I have arranged the data in long format (it contains
> 100 columns indicating different variables and identifiers).
>
> In mlogit I tried the following command---
>
> *mldata<- mlogit.data(mydata, shape = "long", alt.var = "Alt_name", choice
> = "Choice_binary", id.var = "IND")*
>
> It is giving me the following error message- Error in 1:nchid : result
> would be too long a vector
>
> Could you please help me with this? I don't think it is too big a data 100
> ROWS*13932 columns. I faced no issue in Excel. I am stuck due to this issue.
> Thanks in advance.
>
> -- Best Regards,
> Rahul Chakraborty
> Research Fellow
> National Institute of Public Finance and Policy
> New Delhi- 110067
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ch@kr@r@hu| @end|ng |rom gm@||@com  Mon Sep 21 22:37:53 2020
From: ch@kr@r@hu| @end|ng |rom gm@||@com (Rahul Chakraborty)
Date: Tue, 22 Sep 2020 02:07:53 +0530
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
Message-ID: <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>

Hello,

Here is the result of summary(mydata)

summary(mydata)
      IND            Block            QES         STR             ALT
 Min.   :  1.0   Min.   :1.000   Min.   :1   Min.   :  101   Min.   :1
 1st Qu.:129.8   1st Qu.:1.000   1st Qu.:3   1st Qu.:12978   1st Qu.:1
 Median :258.5   Median :2.000   Median :5   Median :25855   Median :2
 Mean   :258.5   Mean   :2.467   Mean   :5   Mean   :25855   Mean   :2
 3rd Qu.:387.2   3rd Qu.:4.000   3rd Qu.:7   3rd Qu.:38732   3rd Qu.:3
 Max.   :516.0   Max.   :4.000   Max.   :9   Max.   :51609   Max.   :3
   ALT_name              ASC             Choice      Choice_binary
 Length:13932       Min.   :0.0000   Min.   :1.000   Min.   :0.0000
 Class :character   1st Qu.:0.0000   1st Qu.:1.000   1st Qu.:0.0000
 Mode  :character   Median :1.0000   Median :1.000   Median :0.0000
                    Mean   :0.6667   Mean   :1.626   Mean   :0.3333
                    3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.:1.0000
                    Max.   :1.0000   Max.   :3.000   Max.   :1.0000
     Price       Refuel_availability Registration_charges  Running_cost
 Min.   : 9.00   Min.   :0.25        Min.   :0.00000      Min.   :115.0
 1st Qu.:10.00   1st Qu.:0.75        1st Qu.:0.04000      1st Qu.:192.0
 Median :10.00   Median :0.90        Median :0.06000      Median :268.0
 Mean   :10.33   Mean   :0.80        Mean   :0.05333      Mean   :268.2
 3rd Qu.:11.00   3rd Qu.:1.00        3rd Qu.:0.08000      3rd Qu.:383.0
 Max.   :12.00   Max.   :1.00        Max.   :0.08000      Max.   :383.0
  Market_share    Friends_share     Refuel_time       Emission
 Min.   :0.0500   Min.   :0.0000   Min.   : 5.00   Min.   :0.0000
 1st Qu.:0.1500   1st Qu.:0.1500   1st Qu.: 5.00   1st Qu.:0.0000
 Median :0.2500   Median :0.3000   Median : 5.00   Median :0.7500
 Mean   :0.3333   Mean   :0.3333   Mean   :13.33   Mean   :0.5833
 3rd Qu.:0.6000   3rd Qu.:0.5500   3rd Qu.:30.00   3rd Qu.:1.0000
 Max.   :0.9000   Max.   :1.0000   Max.   :30.00   Max.   :1.0000
      Sex              Age2             Age3             Age4
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
 Median :1.0000   Median :0.0000   Median :0.0000   Median :0.0000
 Mean   :0.7791   Mean   :0.4574   Mean   :0.2326   Mean   :0.1531
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
     Edu_PG          Edu_Oth          Occu_Pvt        Occu_Pub
 Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.0000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000
 Median :0.0000   Median :0.0000   Median :0.000   Median :0.0000
 Mean   :0.4147   Mean   :0.1841   Mean   :0.376   Mean   :0.2733
 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.000   Max.   :1.0000
    Occu_SE       Location_metro   Location_majorcity      Ahm
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000     Min.   :0.00000
 1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000     1st Qu.:0.00000
 Median :0.0000   Median :1.0000   Median :0.0000     Median :0.00000
 Mean   :0.2655   Mean   :0.7655   Mean   :0.1453     Mean   :0.04457
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000     3rd Qu.:0.00000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000     Max.   :1.00000
      Ben               Chen              NCR              Hyd
 Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000
 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000
 Median :0.00000   Median :0.00000   Median :0.0000   Median :0.00000
 Mean   :0.06977   Mean   :0.04651   Mean   :0.2558   Mean   :0.03682
 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.00000
 Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000
      Kol              Mum            MajCity          HH_size
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 3.000
 Median :0.0000   Median :0.0000   Median :0.0000   Median : 5.000
 Mean   :0.2016   Mean   :0.1105   Mean   :0.1453   Mean   : 4.463
 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 6.000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :10.000
    Children           IG2              IG3              IG4
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
 Median :1.0000   Median :0.0000   Median :0.0000   Median :0.0000
 Mean   :0.8721   Mean   :0.3818   Mean   :0.4109   Mean   :0.1841
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000
 Max.   :4.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
    HH_cars       PPC_morethan10      PPC_gr1         PPC_gr2
 Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.00000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.00000
 Median :0.0000   Median :0.0000   Median :0.000   Median :0.00000
 Mean   :0.4864   Mean   :0.4516   Mean   :0.405   Mean   :0.04651
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:0.00000
 Max.   :3.0000   Max.   :1.0000   Max.   :1.000   Max.   :1.00000
   Body_Sedan        Body_SUV      Daily_travel_medium Daily_travel_long
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000      Min.   :0.00000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000      1st Qu.:0.00000
 Median :0.0000   Median :0.0000   Median :0.0000      Median :0.00000
 Mean   :0.3178   Mean   :0.2364   Mean   :0.3702      Mean   :0.02713
 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000      3rd Qu.:0.00000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000      Max.   :1.00000
   Long_drive       Mode_Carpool        Mode_PB          Mode_PV
 Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000
 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000
 Median :0.00000   Median :0.00000   Median :0.0000   Median :0.0000
 Mean   :0.03488   Mean   :0.02519   Mean   :0.2907   Mean   :0.4419
 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:1.0000
 Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000
    Mode_WRC           Garage_y           DL_y          Own_accom
 Min.   :0.000000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
 1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
 Median :0.000000   Median :1.0000   Median :1.0000   Median :1.0000
 Mean   :0.007752   Mean   :0.7267   Mean   :0.6357   Mean   :0.6647
 3rd Qu.:0.000000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000
 Max.   :1.000000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
 Freerider_water_electricity Freerider_tot   Freerider_avg
Satisfaction_tot
 Min.   :1.000               Min.   :2.000   Min.   :1.000   Min.   : 2.000

 1st Qu.:2.000               1st Qu.:2.000   1st Qu.:1.000   1st Qu.: 3.000

 Median :3.000               Median :2.000   Median :1.000   Median : 4.000

 Mean   :3.002               Mean   :2.244   Mean   :1.122   Mean   : 4.264

 3rd Qu.:4.000               3rd Qu.:2.000   3rd Qu.:1.000   3rd Qu.: 5.000

 Max.   :5.000               Max.   :8.000   Max.   :4.000   Max.   :10.000

 Satisfaction_avg Political_view  Meet_friends       Meet_colleagues
 Min.   :1.000    Min.   :1.000   Length:13932       Length:13932
 1st Qu.:1.500    1st Qu.:3.000   Class :character   Class :character
 Median :2.000    Median :3.000   Mode  :character   Mode  :character
 Mean   :2.132    Mean   :3.258
 3rd Qu.:2.500    3rd Qu.:4.000
 Max.   :5.000    Max.   :5.000
 Meet_relatives     Invite_colleagues  Invite_friends     Invite_relatives
 Length:13932       Length:13932       Length:13932       Length:13932
 Class :character   Class :character   Class :character   Class :character
 Mode  :character   Mode  :character   Mode  :character   Mode  :character



 Lending_relatives  Lending_friends    Lending_colleagues
 Length:13932       Length:13932       Length:13932
 Class :character   Class :character   Class :character
 Mode  :character   Mode  :character   Mode  :character



 Willingness_Purchase_Env_frnd EVuse_pollution  WTP_env_tot
 WTP_env_avg
 Min.   :1.000                 Min.   :1.000   Min.   : 2.000   Min.
:1.000
 1st Qu.:4.000                 1st Qu.:3.000   1st Qu.: 7.000   1st
Qu.:3.500
 Median :4.000                 Median :4.000   Median : 8.000   Median
:4.000
 Mean   :4.132                 Mean   :3.992   Mean   : 8.124   Mean
:4.062
 3rd Qu.:5.000                 3rd Qu.:5.000   3rd Qu.: 9.000   3rd
Qu.:4.500
 Max.   :5.000                 Max.   :5.000   Max.   :10.000   Max.
:5.000
 Social_recognition Car_social_status  Warmglow_tot    Warmglow_avg
 Min.   :1.000      Min.   :1.00      Min.   : 2.00   Min.   :1.000
 1st Qu.:3.000      1st Qu.:4.00      1st Qu.: 6.00   1st Qu.:3.000
 Median :4.000      Median :4.00      Median : 8.00   Median :4.000
 Mean   :3.541      Mean   :4.07      Mean   : 7.61   Mean   :3.805
 3rd Qu.:4.000      3rd Qu.:5.00      3rd Qu.: 9.00   3rd Qu.:4.500
 Max.   :5.000      Max.   :5.00      Max.   :10.00   Max.   :5.000
    Standout     Acceptance_new Climate_perception    Env_pref
 Tech_leader
 Min.   :1.000   Min.   :1.0    Min.   :1.000      Min.   :1.000   Min.
:1.0
 1st Qu.:2.000   1st Qu.:2.0    1st Qu.:4.000      1st Qu.:2.000   1st
Qu.:2.0
 Median :3.000   Median :3.0    Median :5.000      Median :3.000   Median
:2.0
 Mean   :2.657   Mean   :2.8    Mean   :4.483      Mean   :3.093   Mean
:2.5
 3rd Qu.:3.000   3rd Qu.:4.0    3rd Qu.:5.000      3rd Qu.:4.000   3rd
Qu.:3.0
 Max.   :5.000   Max.   :5.0    Max.   :5.000      Max.   :5.000   Max.
:5.0
 Social_motivation_tot Social_motivation_avg Social_motivation_median
 Min.   : 3.00         Min.   :1.000         Min.   :1.000
 1st Qu.: 9.00         1st Qu.:3.000         1st Qu.:3.000
 Median :11.00         Median :3.667         Median :3.000
 Mean   :10.62         Mean   :3.539         Mean   :3.514
 3rd Qu.:12.00         3rd Qu.:4.000         3rd Qu.:4.000
 Max.   :15.00         Max.   :5.000         Max.   :5.000
  EV_risk_tot      EV_risk_avg      EV_price     EV_awareness_tot
EV_awareness_avg
 Min.   : 2.000   Min.   :1.00   Min.   :1.000   Min.   : 3.000   Min.
:1.000
 1st Qu.: 8.000   1st Qu.:4.00   1st Qu.:1.000   1st Qu.: 4.000   1st
Qu.:1.333
 Median : 9.000   Median :4.50   Median :2.000   Median : 5.000   Median
:1.667
 Mean   : 8.661   Mean   :4.33   Mean   :2.244   Mean   : 5.419   Mean
:1.806
 3rd Qu.:10.000   3rd Qu.:5.00   3rd Qu.:3.000   3rd Qu.: 6.000   3rd
Qu.:2.000
 Max.   :10.000   Max.   :5.00   Max.   :5.000   Max.   :15.000   Max.
:5.000
 EV_awareness_median    Lost_env     Investment_trust   Lottery1
 Min.   :1.000       Min.   :1.000   Min.   :     0   Length:13932
 1st Qu.:1.000       1st Qu.:5.000   1st Qu.:     0   Class :character
 Median :2.000       Median :5.000   Median :     0   Mode  :character
 Mean   :1.806       Mean   :4.913   Mean   :  1345
 3rd Qu.:2.000       3rd Qu.:5.000   3rd Qu.:     0
 Max.   :5.000       Max.   :5.000   Max.   :100000
    Time1             Lottery2            Time2
 Length:13932       Length:13932       Length:13932
 Class :character   Class :character   Class :character
 Mode  :character   Mode  :character   Mode  :character



Yes, I have many Likert items and many dummy variables. How do I solve this
issue?

Best regards,

On Tue, Sep 22, 2020 at 1:45 AM David Winsemius <dwinsemius at comcast.net>
wrote:

> If you had included output of summary(mydata) we might be more capable
> of giving a fact-based answer but I'm guessing that you have a lot of
> catagorical variables with multiple levels and some sort of combinatoric
> explosion is resulting in too many levels of a constructed factor.
>
>
> --
>
> David.
>
> On 9/21/20 12:55 PM, Rahul Chakraborty wrote:
> > Hello everyone,
> >
> > I am using *mlogit* to analyse my choice experiment data. I have *3
> > alternatives* for each individual and for each individual I have *9
> > questions*. I have a response from *516 individuals*. So it is a panel of
> > 9*516 observations. I have arranged the data in long format (it contains
> > 100 columns indicating different variables and identifiers).
> >
> > In mlogit I tried the following command---
> >
> > *mldata<- mlogit.data(mydata, shape = "long", alt.var = "Alt_name",
> choice
> > = "Choice_binary", id.var = "IND")*
> >
> > It is giving me the following error message- Error in 1:nchid : result
> > would be too long a vector
> >
> > Could you please help me with this? I don't think it is too big a data
> 100
> > ROWS*13932 columns. I faced no issue in Excel. I am stuck due to this
> issue.
> > Thanks in advance.
> >
> > -- Best Regards,
> > Rahul Chakraborty
> > Research Fellow
> > National Institute of Public Finance and Policy
> > New Delhi- 110067
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Rahul Chakraborty
Research Fellow
National Institute of Public Finance and Policy
New Delhi- 110067

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Sep 21 22:38:07 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 22 Sep 2020 08:38:07 +1200
Subject: [R] Quadratic programming
In-Reply-To: <CAB8pepwwT3sqmnYt43bE3VrSUMjxnSAdrFV9LoiLHXwSjWSM5Q@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepwwT3sqmnYt43bE3VrSUMjxnSAdrFV9LoiLHXwSjWSM5Q@mail.gmail.com>
Message-ID: <CAB8pepwZQ1=q25DkT859Fo-EBYjiCA9GJGfP739+QC=NgAfw6g@mail.gmail.com>

I was wondering if you're trying to fit a curve, subject to
monotonicity/convexity constraints...
If you are, this is a challenging topic, best of luck...


On Tue, Sep 22, 2020 at 8:12 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Hi,
>
> Sorry, for my rushed responses, last night.
> (Shouldn't post when I'm about to log out).
>
> I haven't used the quadprog package for nearly a decade.
> And I was hoping that an expert using optimization in finance in
> economics would reply.
>
> Some comments:
> (1) I don't know why you think bvec should be a matrix. The
> documentation clearly says it should be a vector (implying not a
> matrix).
> The only arguments that should be matrices are Dmat and Amat.
> (2) I'm having some difficulty following your quadratic program, even
> after rendering it.
> Perhaps you could rewrite your expressions, in a form that is
> consistent with the input to solve.QP. That's a math problem, not an R
> programming problem, as such.
> (3) If that fails, then you'll need to produce a minimal reproducible example.
> I strongly recommend that the R code matches the quadratic program, as
> closely as possible.
>
>
> On Mon, Sep 21, 2020 at 9:28 PM Maija Sirkj?rvi
> <maija.sirkjarvi at gmail.com> wrote:
> >
> > Hi!
> >
> > I was wondering if someone could help me out. I'm minimizing a following
> > function:
> >
> > \begin{equation}
> > $$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
> > \text{subject to}
> > $$m_{j-1}\leq m_{j}-\delta_{1}$$
> > $$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq \frac{1}{Q_{j}-Q_{j-1}}
> > (m_{j-1}-m_{j})-\delta_{2} $$
> > \end{equation}
> >
> > I have tried quadratic programming, but something is off. Does anyone have
> > an idea how to approach this?
> >
> > Thanks in advance!
> >
> > Q <- rep(0,J)
> > for(j in 1:(length(Price))){
> >   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> > }
> >
> > Dmat <- matrix(0,nrow= J, ncol=J)
> > diag(Dmat) <- 1
> > dvec <- -hs
> > Aeq <- 0
> > beq <- 0
> > Amat <- matrix(0,J,2*J-3)
> > bvec <- matrix(0,2*J-3,1)
> >
> > for(j in 2:nrow(Amat)){
> >   Amat[j-1,j-1] = -1
> >   Amat[j,j-1] = 1
> > }
> > for(j in 3:nrow(Amat)){
> >   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
> >   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
> >   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> > }
> > for(j in 2:ncol(bvec)) {
> >   bvec[j-1] = Delta1
> > }
> > for(j in 3:ncol(bvec)) {
> >   bvec[J-1+j-2] = Delta2
> > }
> > solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 21 22:45:21 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 21 Sep 2020 16:45:21 -0400
Subject: [R] date
In-Reply-To: <CAM_vjumGCweCcbxsGj21ikuSF-Uz4pKn8HG_TXv_wZTtza116A@mail.gmail.com>
References: <CAJOiR6bzBK5qZUoND_i6U0uAVxu82-ibg9cOTmvDrEZV75LEtw@mail.gmail.com>
 <CAM_vjumGCweCcbxsGj21ikuSF-Uz4pKn8HG_TXv_wZTtza116A@mail.gmail.com>
Message-ID: <90469294-5ae7-e87b-e792-800a25b518bb@gmail.com>

Another way to do this is to use the xtfrm() function.  That function 
creates numerical values from many different starting types, so you can 
just change the sign to change the sort order:

df[order(df$ID, -xtfrm(df$date2)),]

I never did figure out where the name came from.

Duncan Murdoch

On 21/09/2020 3:41 p.m., Sarah Goslee wrote:
> Hi,
> 
> Nice reproducible example.
> 
> rev(df$date2) isn't doing what you think it's doing - try looking at
> it by itself.
> 
> Some digging into ?order will get you what you are after:
> 
> df[order(df$ID, df$date2, decreasing=c(FALSE, TRUE), method="radix"),]
> 
>> df[order(df$ID, df$date2, decreasing=c(FALSE, TRUE), method="radix"),]
>    ID      date2
> 2 A1 2005-01-27
> 1 A1 2004-09-17
> 3 A1 2003-05-07
> 4 A2 2017-05-21
> 5 A2 2016-09-12
> 6 A3 2013-01-25
> 7 A4 2019-09-27
> 
> Sarah
> 
> On Mon, Sep 21, 2020 at 2:41 PM Val <valkremk at gmail.com> wrote:
>>
>> Hi All,
>>
>> I am trying to sort dates within a group. My sample data is
>>
>> df <-read.table(text="ID date
>> A1   09/17/04
>> A1   01/27/05
>> A1   05/07/03
>> A2   05/21/17
>> A2   09/12/16
>> A3   01/25/13
>> A4   09/27/19",header=TRUE,stringsAsFactors=F)
>> df$date2 = as.Date(strptime(df$date,format="%m/%d/%y"))
>> df$date =NULL
>>
>> I want to sort  date2  from recent to oldest.  within the ID group and
>> I used this,
>> df <- df[order(df$ID, rev((df$date2))),]. It did not work and teh
>> output is  shown below.
>>
>> ID      date2
>> 2 A1 2005-01-27
>> 3 A1 2003-05-07
>> 1 A1 2004-09-17
>> 5 A2 2016-09-12
>> 4 A2 2017-05-21
>> 6 A3 2013-01-25
>> 7 A4 2019-09-27
>> What am I missing?
>> Thank you.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From ch@kr@r@hu| @end|ng |rom gm@||@com  Mon Sep 21 23:19:12 2020
From: ch@kr@r@hu| @end|ng |rom gm@||@com (Rahul Chakraborty)
Date: Tue, 22 Sep 2020 02:49:12 +0530
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
 <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
Message-ID: <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>

Hello,

I tried to reduce the size of my dataframe. Now I have 57 columns of which
29 are already dummy coded. If I run   *mldata1<- mlogit.data(mydata1,
shape = "long", alt.var = "Alt_name", choice = "Choice_binary", id.var =
"IND") *it still gives me the same error message-* Error in 1:nchid :
result would be too long a vector. *

I will not use all of those variables in one regression model, but I need
those for different model specifications. The Excel file I created from my
survey looks like the attached file. The main data is a panel of 516
individuals each answering 9 questions over 3 alternatives.

Following is the output of the summary of the dataframe.

summary(mydata1)
      IND             QES         STR          ALT_name
Choice_binary
 Min.   :  1.0   Min.   :1   Min.   :  101   Length:13932       Min.
:0.0000
 1st Qu.:129.8   1st Qu.:3   1st Qu.:12978   Class :character   1st
Qu.:0.0000
 Median :258.5   Median :5   Median :25855   Mode  :character   Median
:0.0000
 Mean   :258.5   Mean   :5   Mean   :25855                      Mean
:0.3333
 3rd Qu.:387.2   3rd Qu.:7   3rd Qu.:38732                      3rd
Qu.:1.0000
 Max.   :516.0   Max.   :9   Max.   :51609                      Max.
:1.0000
     Price       Refuel_availability Registration_charges  Running_cost
 Min.   : 9.00   Min.   :0.25        Min.   :0.00000      Min.   :115.0
 1st Qu.:10.00   1st Qu.:0.75        1st Qu.:0.04000      1st Qu.:192.0
 Median :10.00   Median :0.90        Median :0.06000      Median :268.0
 Mean   :10.33   Mean   :0.80        Mean   :0.05333      Mean   :268.2
 3rd Qu.:11.00   3rd Qu.:1.00        3rd Qu.:0.08000      3rd Qu.:383.0
 Max.   :12.00   Max.   :1.00        Max.   :0.08000      Max.   :383.0
  Market_share    Friends_share     Refuel_time       Emission
 Min.   :0.0500   Min.   :0.0000   Min.   : 5.00   Min.   :0.0000
 1st Qu.:0.1500   1st Qu.:0.1500   1st Qu.: 5.00   1st Qu.:0.0000
 Median :0.2500   Median :0.3000   Median : 5.00   Median :0.7500
 Mean   :0.3333   Mean   :0.3333   Mean   :13.33   Mean   :0.5833
 3rd Qu.:0.6000   3rd Qu.:0.5500   3rd Qu.:30.00   3rd Qu.:1.0000
 Max.   :0.9000   Max.   :1.0000   Max.   :30.00   Max.   :1.0000
      Sex              Age2             Age3             Age4
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
 Median :1.0000   Median :0.0000   Median :0.0000   Median :0.0000
 Mean   :0.7791   Mean   :0.4574   Mean   :0.2326   Mean   :0.1531
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
     Edu_PG          Edu_Oth          Occu_Pvt        Occu_Pub
 Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.0000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000
 Median :0.0000   Median :0.0000   Median :0.000   Median :0.0000
 Mean   :0.4147   Mean   :0.1841   Mean   :0.376   Mean   :0.2733
 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.000   Max.   :1.0000
    Occu_SE       Location_metro   Location_majorcity      Ahm
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000     Min.   :0.00000
 1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000     1st Qu.:0.00000
 Median :0.0000   Median :1.0000   Median :0.0000     Median :0.00000
 Mean   :0.2655   Mean   :0.7655   Mean   :0.1453     Mean   :0.04457
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000     3rd Qu.:0.00000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000     Max.   :1.00000
      Ben               Chen              NCR              Hyd
 Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000
 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000
 Median :0.00000   Median :0.00000   Median :0.0000   Median :0.00000
 Mean   :0.06977   Mean   :0.04651   Mean   :0.2558   Mean   :0.03682
 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.00000
 Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000
      Kol              Mum            MajCity          HH_size
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 3.000
 Median :0.0000   Median :0.0000   Median :0.0000   Median : 5.000
 Mean   :0.2016   Mean   :0.1105   Mean   :0.1453   Mean   : 4.463
 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 6.000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :10.000
    Children           IG2              IG3              IG4
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
 Median :1.0000   Median :0.0000   Median :0.0000   Median :0.0000
 Mean   :0.8721   Mean   :0.3818   Mean   :0.4109   Mean   :0.1841
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000
 Max.   :4.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
    HH_cars       PPC_morethan10   Daily_travel_medium Daily_travel_long
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000      Min.   :0.00000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000      1st Qu.:0.00000
 Median :0.0000   Median :0.0000   Median :0.0000      Median :0.00000
 Mean   :0.4864   Mean   :0.4516   Mean   :0.3702      Mean   :0.02713
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000      3rd Qu.:0.00000
 Max.   :3.0000   Max.   :1.0000   Max.   :1.0000      Max.   :1.00000
    Garage_y           DL_y          Own_accom      Freerider_tot
 Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :2.000
 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:2.000
 Median :1.0000   Median :1.0000   Median :1.0000   Median :2.000
 Mean   :0.7267   Mean   :0.6357   Mean   :0.6647   Mean   :2.244
 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:2.000
 Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :8.000
 Satisfaction_tot Political_view   WTP_env_tot      Warmglow_tot
 Standout
 Min.   : 2.000   Min.   :1.000   Min.   : 2.000   Min.   : 2.00   Min.
:1.000
 1st Qu.: 3.000   1st Qu.:3.000   1st Qu.: 7.000   1st Qu.: 6.00   1st
Qu.:2.000
 Median : 4.000   Median :3.000   Median : 8.000   Median : 8.00   Median
:3.000
 Mean   : 4.264   Mean   :3.258   Mean   : 8.124   Mean   : 7.61   Mean
:2.657
 3rd Qu.: 5.000   3rd Qu.:4.000   3rd Qu.: 9.000   3rd Qu.: 9.00   3rd
Qu.:3.000
 Max.   :10.000   Max.   :5.000   Max.   :10.000   Max.   :10.00   Max.
:5.000
 Acceptance_new Climate_perception    Env_pref      Tech_leader
 Min.   :1.0    Min.   :1.000      Min.   :1.000   Min.   :1.0
 1st Qu.:2.0    1st Qu.:4.000      1st Qu.:2.000   1st Qu.:2.0
 Median :3.0    Median :5.000      Median :3.000   Median :2.0
 Mean   :2.8    Mean   :4.483      Mean   :3.093   Mean   :2.5
 3rd Qu.:4.0    3rd Qu.:5.000      3rd Qu.:4.000   3rd Qu.:3.0
 Max.   :5.0    Max.   :5.000      Max.   :5.000   Max.   :5.0
 Social_motivation_tot  EV_risk_tot     EV_awareness_tot
 Min.   : 3.00         Min.   : 2.000   Min.   : 3.000
 1st Qu.: 9.00         1st Qu.: 8.000   1st Qu.: 4.000
 Median :11.00         Median : 9.000   Median : 5.000
 Mean   :10.62         Mean   : 8.661   Mean   : 5.419
 3rd Qu.:12.00         3rd Qu.:10.000   3rd Qu.: 6.000
 Max.   :15.00         Max.   :10.000   Max.   :15.000

On Tue, Sep 22, 2020 at 2:07 AM Rahul Chakraborty <chakrarahul at gmail.com>
wrote:

> Hello,
>
> Here is the result of summary(mydata)
>
> summary(mydata)
>       IND            Block            QES         STR             ALT
>  Min.   :  1.0   Min.   :1.000   Min.   :1   Min.   :  101   Min.   :1
>  1st Qu.:129.8   1st Qu.:1.000   1st Qu.:3   1st Qu.:12978   1st Qu.:1
>  Median :258.5   Median :2.000   Median :5   Median :25855   Median :2
>  Mean   :258.5   Mean   :2.467   Mean   :5   Mean   :25855   Mean   :2
>  3rd Qu.:387.2   3rd Qu.:4.000   3rd Qu.:7   3rd Qu.:38732   3rd Qu.:3
>  Max.   :516.0   Max.   :4.000   Max.   :9   Max.   :51609   Max.   :3
>    ALT_name              ASC             Choice      Choice_binary
>  Length:13932       Min.   :0.0000   Min.   :1.000   Min.   :0.0000
>  Class :character   1st Qu.:0.0000   1st Qu.:1.000   1st Qu.:0.0000
>  Mode  :character   Median :1.0000   Median :1.000   Median :0.0000
>                     Mean   :0.6667   Mean   :1.626   Mean   :0.3333
>                     3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.:1.0000
>                     Max.   :1.0000   Max.   :3.000   Max.   :1.0000
>      Price       Refuel_availability Registration_charges  Running_cost
>  Min.   : 9.00   Min.   :0.25        Min.   :0.00000      Min.   :115.0
>  1st Qu.:10.00   1st Qu.:0.75        1st Qu.:0.04000      1st Qu.:192.0
>  Median :10.00   Median :0.90        Median :0.06000      Median :268.0
>  Mean   :10.33   Mean   :0.80        Mean   :0.05333      Mean   :268.2
>  3rd Qu.:11.00   3rd Qu.:1.00        3rd Qu.:0.08000      3rd Qu.:383.0
>  Max.   :12.00   Max.   :1.00        Max.   :0.08000      Max.   :383.0
>   Market_share    Friends_share     Refuel_time       Emission
>  Min.   :0.0500   Min.   :0.0000   Min.   : 5.00   Min.   :0.0000
>  1st Qu.:0.1500   1st Qu.:0.1500   1st Qu.: 5.00   1st Qu.:0.0000
>  Median :0.2500   Median :0.3000   Median : 5.00   Median :0.7500
>  Mean   :0.3333   Mean   :0.3333   Mean   :13.33   Mean   :0.5833
>  3rd Qu.:0.6000   3rd Qu.:0.5500   3rd Qu.:30.00   3rd Qu.:1.0000
>  Max.   :0.9000   Max.   :1.0000   Max.   :30.00   Max.   :1.0000
>       Sex              Age2             Age3             Age4
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
>  1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
>  Median :1.0000   Median :0.0000   Median :0.0000   Median :0.0000
>  Mean   :0.7791   Mean   :0.4574   Mean   :0.2326   Mean   :0.1531
>  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000
>  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
>      Edu_PG          Edu_Oth          Occu_Pvt        Occu_Pub
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.0000
>  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000
>  Median :0.0000   Median :0.0000   Median :0.000   Median :0.0000
>  Mean   :0.4147   Mean   :0.1841   Mean   :0.376   Mean   :0.2733
>  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000
>  Max.   :1.0000   Max.   :1.0000   Max.   :1.000   Max.   :1.0000
>     Occu_SE       Location_metro   Location_majorcity      Ahm
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000     Min.   :0.00000
>  1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000     1st Qu.:0.00000
>  Median :0.0000   Median :1.0000   Median :0.0000     Median :0.00000
>  Mean   :0.2655   Mean   :0.7655   Mean   :0.1453     Mean   :0.04457
>  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000     3rd Qu.:0.00000
>  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000     Max.   :1.00000
>       Ben               Chen              NCR              Hyd
>  Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000
>  1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000
>  Median :0.00000   Median :0.00000   Median :0.0000   Median :0.00000
>  Mean   :0.06977   Mean   :0.04651   Mean   :0.2558   Mean   :0.03682
>  3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.00000
>  Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000
>       Kol              Mum            MajCity          HH_size
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000
>  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 3.000
>  Median :0.0000   Median :0.0000   Median :0.0000   Median : 5.000
>  Mean   :0.2016   Mean   :0.1105   Mean   :0.1453   Mean   : 4.463
>  3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 6.000
>  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :10.000
>     Children           IG2              IG3              IG4
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
>  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
>  Median :1.0000   Median :0.0000   Median :0.0000   Median :0.0000
>  Mean   :0.8721   Mean   :0.3818   Mean   :0.4109   Mean   :0.1841
>  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000
>  Max.   :4.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
>     HH_cars       PPC_morethan10      PPC_gr1         PPC_gr2
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.00000
>  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.00000
>  Median :0.0000   Median :0.0000   Median :0.000   Median :0.00000
>  Mean   :0.4864   Mean   :0.4516   Mean   :0.405   Mean   :0.04651
>  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:0.00000
>  Max.   :3.0000   Max.   :1.0000   Max.   :1.000   Max.   :1.00000
>    Body_Sedan        Body_SUV      Daily_travel_medium Daily_travel_long
>  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000      Min.   :0.00000
>  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000      1st Qu.:0.00000
>  Median :0.0000   Median :0.0000   Median :0.0000      Median :0.00000
>  Mean   :0.3178   Mean   :0.2364   Mean   :0.3702      Mean   :0.02713
>  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000      3rd Qu.:0.00000
>  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000      Max.   :1.00000
>    Long_drive       Mode_Carpool        Mode_PB          Mode_PV
>  Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000
>  1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000
>  Median :0.00000   Median :0.00000   Median :0.0000   Median :0.0000
>  Mean   :0.03488   Mean   :0.02519   Mean   :0.2907   Mean   :0.4419
>  3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:1.0000
>  Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000
>     Mode_WRC           Garage_y           DL_y          Own_accom
>  Min.   :0.000000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000
>  1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000
>  Median :0.000000   Median :1.0000   Median :1.0000   Median :1.0000
>  Mean   :0.007752   Mean   :0.7267   Mean   :0.6357   Mean   :0.6647
>  3rd Qu.:0.000000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000
>  Max.   :1.000000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
>  Freerider_water_electricity Freerider_tot   Freerider_avg
> Satisfaction_tot
>  Min.   :1.000               Min.   :2.000   Min.   :1.000   Min.   :
> 2.000
>  1st Qu.:2.000               1st Qu.:2.000   1st Qu.:1.000   1st Qu.:
> 3.000
>  Median :3.000               Median :2.000   Median :1.000   Median :
> 4.000
>  Mean   :3.002               Mean   :2.244   Mean   :1.122   Mean   :
> 4.264
>  3rd Qu.:4.000               3rd Qu.:2.000   3rd Qu.:1.000   3rd Qu.:
> 5.000
>  Max.   :5.000               Max.   :8.000   Max.   :4.000   Max.
> :10.000
>  Satisfaction_avg Political_view  Meet_friends       Meet_colleagues
>  Min.   :1.000    Min.   :1.000   Length:13932       Length:13932
>  1st Qu.:1.500    1st Qu.:3.000   Class :character   Class :character
>  Median :2.000    Median :3.000   Mode  :character   Mode  :character
>  Mean   :2.132    Mean   :3.258
>  3rd Qu.:2.500    3rd Qu.:4.000
>  Max.   :5.000    Max.   :5.000
>  Meet_relatives     Invite_colleagues  Invite_friends     Invite_relatives
>
>  Length:13932       Length:13932       Length:13932       Length:13932
>
>  Class :character   Class :character   Class :character   Class :character
>
>  Mode  :character   Mode  :character   Mode  :character   Mode  :character
>
>
>
>
>
>
>
>  Lending_relatives  Lending_friends    Lending_colleagues
>  Length:13932       Length:13932       Length:13932
>  Class :character   Class :character   Class :character
>  Mode  :character   Mode  :character   Mode  :character
>
>
>
>  Willingness_Purchase_Env_frnd EVuse_pollution  WTP_env_tot
>  WTP_env_avg
>  Min.   :1.000                 Min.   :1.000   Min.   : 2.000   Min.
> :1.000
>  1st Qu.:4.000                 1st Qu.:3.000   1st Qu.: 7.000   1st
> Qu.:3.500
>  Median :4.000                 Median :4.000   Median : 8.000   Median
> :4.000
>  Mean   :4.132                 Mean   :3.992   Mean   : 8.124   Mean
> :4.062
>  3rd Qu.:5.000                 3rd Qu.:5.000   3rd Qu.: 9.000   3rd
> Qu.:4.500
>  Max.   :5.000                 Max.   :5.000   Max.   :10.000   Max.
> :5.000
>  Social_recognition Car_social_status  Warmglow_tot    Warmglow_avg
>  Min.   :1.000      Min.   :1.00      Min.   : 2.00   Min.   :1.000
>  1st Qu.:3.000      1st Qu.:4.00      1st Qu.: 6.00   1st Qu.:3.000
>  Median :4.000      Median :4.00      Median : 8.00   Median :4.000
>  Mean   :3.541      Mean   :4.07      Mean   : 7.61   Mean   :3.805
>  3rd Qu.:4.000      3rd Qu.:5.00      3rd Qu.: 9.00   3rd Qu.:4.500
>  Max.   :5.000      Max.   :5.00      Max.   :10.00   Max.   :5.000
>     Standout     Acceptance_new Climate_perception    Env_pref
>  Tech_leader
>  Min.   :1.000   Min.   :1.0    Min.   :1.000      Min.   :1.000   Min.
> :1.0
>  1st Qu.:2.000   1st Qu.:2.0    1st Qu.:4.000      1st Qu.:2.000   1st
> Qu.:2.0
>  Median :3.000   Median :3.0    Median :5.000      Median :3.000   Median
> :2.0
>  Mean   :2.657   Mean   :2.8    Mean   :4.483      Mean   :3.093   Mean
> :2.5
>  3rd Qu.:3.000   3rd Qu.:4.0    3rd Qu.:5.000      3rd Qu.:4.000   3rd
> Qu.:3.0
>  Max.   :5.000   Max.   :5.0    Max.   :5.000      Max.   :5.000   Max.
> :5.0
>  Social_motivation_tot Social_motivation_avg Social_motivation_median
>  Min.   : 3.00         Min.   :1.000         Min.   :1.000
>  1st Qu.: 9.00         1st Qu.:3.000         1st Qu.:3.000
>  Median :11.00         Median :3.667         Median :3.000
>  Mean   :10.62         Mean   :3.539         Mean   :3.514
>  3rd Qu.:12.00         3rd Qu.:4.000         3rd Qu.:4.000
>  Max.   :15.00         Max.   :5.000         Max.   :5.000
>   EV_risk_tot      EV_risk_avg      EV_price     EV_awareness_tot
> EV_awareness_avg
>  Min.   : 2.000   Min.   :1.00   Min.   :1.000   Min.   : 3.000   Min.
> :1.000
>  1st Qu.: 8.000   1st Qu.:4.00   1st Qu.:1.000   1st Qu.: 4.000   1st
> Qu.:1.333
>  Median : 9.000   Median :4.50   Median :2.000   Median : 5.000   Median
> :1.667
>  Mean   : 8.661   Mean   :4.33   Mean   :2.244   Mean   : 5.419   Mean
> :1.806
>  3rd Qu.:10.000   3rd Qu.:5.00   3rd Qu.:3.000   3rd Qu.: 6.000   3rd
> Qu.:2.000
>  Max.   :10.000   Max.   :5.00   Max.   :5.000   Max.   :15.000   Max.
> :5.000
>  EV_awareness_median    Lost_env     Investment_trust   Lottery1
>  Min.   :1.000       Min.   :1.000   Min.   :     0   Length:13932
>  1st Qu.:1.000       1st Qu.:5.000   1st Qu.:     0   Class :character
>  Median :2.000       Median :5.000   Median :     0   Mode  :character
>  Mean   :1.806       Mean   :4.913   Mean   :  1345
>  3rd Qu.:2.000       3rd Qu.:5.000   3rd Qu.:     0
>  Max.   :5.000       Max.   :5.000   Max.   :100000
>     Time1             Lottery2            Time2
>  Length:13932       Length:13932       Length:13932
>  Class :character   Class :character   Class :character
>  Mode  :character   Mode  :character   Mode  :character
>
>
>
> Yes, I have many Likert items and many dummy variables. How do I solve
> this issue?
>
> Best regards,
>
> On Tue, Sep 22, 2020 at 1:45 AM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>> If you had included output of summary(mydata) we might be more capable
>> of giving a fact-based answer but I'm guessing that you have a lot of
>> catagorical variables with multiple levels and some sort of combinatoric
>> explosion is resulting in too many levels of a constructed factor.
>>
>>
>> --
>>
>> David.
>>
>> On 9/21/20 12:55 PM, Rahul Chakraborty wrote:
>> > Hello everyone,
>> >
>> > I am using *mlogit* to analyse my choice experiment data. I have *3
>> > alternatives* for each individual and for each individual I have *9
>> > questions*. I have a response from *516 individuals*. So it is a panel
>> of
>> > 9*516 observations. I have arranged the data in long format (it contains
>> > 100 columns indicating different variables and identifiers).
>> >
>> > In mlogit I tried the following command---
>> >
>> > *mldata<- mlogit.data(mydata, shape = "long", alt.var = "Alt_name",
>> choice
>> > = "Choice_binary", id.var = "IND")*
>> >
>> > It is giving me the following error message- Error in 1:nchid : result
>> > would be too long a vector
>> >
>> > Could you please help me with this? I don't think it is too big a data
>> 100
>> > ROWS*13932 columns. I faced no issue in Excel. I am stuck due to this
>> issue.
>> > Thanks in advance.
>> >
>> > -- Best Regards,
>> > Rahul Chakraborty
>> > Research Fellow
>> > National Institute of Public Finance and Policy
>> > New Delhi- 110067
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Rahul Chakraborty
> Research Fellow
> National Institute of Public Finance and Policy
> New Delhi- 110067
>


-- 
Rahul Chakraborty
Research Fellow
National Institute of Public Finance and Policy
New Delhi- 110067

From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 22 01:20:54 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 21 Sep 2020 16:20:54 -0700
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
 <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
 <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>
Message-ID: <d7118822-f3a2-c6c2-df72-917089691de0@comcast.net>

@Rahul;


You need to learn to post in plain text and attachments may not be xls 
or xlsx. They need to be text files. And even if they are comma 
separated files and text, they still need to be named with a txt extension.


I'm the only one who got the xlsx file. I got the error regardless of 
how many column I omitted, so my gues was possibly incorrect. But I did 
RTFM. See ?mlogit.datadfi The mlogit.data function is deprecated and you 
are told to use the dfidx function. Trying that you now get an error 
saying: " the two indexes don't define unique observations".


 > sum(duplicated( dfrm[,1:2]))
[1] 12
 > length(dfrm[,1])
[1] 18

So of your 18 lines in the example file, most of them appear to be 
duplicated in their first two rows and apparently that is not allowed by 
dfidx.


Caveat: I'm not a user of the mlogit package so I'm just reading the 
manual and possibly coming up with informed speculation.

Please read the Posting Guide. You have been warned. Repeated violations 
of the policies laid down in that hallowed document will possibly result 
in postings being ignored.

-- 


David

On 9/21/20 2:19 PM, Rahul Chakraborty wrote:
> Hello,
>
> I tried to reduce the size of my dataframe. Now I have 57 columns of 
> which 29 are already dummy coded. If I run *mldata1<- 
> mlogit.data(mydata1, shape = "long", alt.var = "Alt_name", choice = 
> "Choice_binary", id.var = "IND") *it still gives me the same error 
> message-*?Error in 1:nchid : result would be too long a vector. *
> *
> *
> I will not use all of those variables in one regression model, but I 
> need those for different model specifications. The Excel file I 
> created from my survey looks like the attached?file. The main data is 
> a panel of 516 individuals each answering 9 questions over 3 alternatives.
>
> Following is the output of the summary of the dataframe.
>
> summary(mydata1)
> ? ? ? IND ? ? ? ? ? ? QES ? ? ? ? STR ? ? ? ? ?ALT_name ? Choice_binary
> ?Min. ? : ?1.0 ? Min. ? :1 ? Min. ? : ?101 ? Length:13932 ? Min. ? 
> :0.0000
> ?1st Qu.:129.8 ? 1st Qu.:3 ? 1st Qu.:12978 ? Class :character ? 1st 
> Qu.:0.0000
> ?Median :258.5 ? Median :5 ? Median :25855 ? Mode ?:character ? Median 
> :0.0000
> ?Mean ? :258.5 ? Mean ? :5 ? Mean ? :25855 ?Mean ? :0.3333
> ?3rd Qu.:387.2 ? 3rd Qu.:7 ? 3rd Qu.:38732 ?3rd Qu.:1.0000
> ?Max. ? :516.0 ? Max. ? :9 ? Max. ? :51609 ?Max. ? :1.0000
> ? ? ?Price ? ? ? Refuel_availability Registration_charges ?Running_cost
> ?Min. ? : 9.00 ? Min. ? :0.25 ? ? ? ?Min. ? :0.00000 ? ? ?Min. ? :115.0
> ?1st Qu.:10.00 ? 1st Qu.:0.75 ? ? ? ?1st Qu.:0.04000 ? ? ?1st Qu.:192.0
> ?Median :10.00 ? Median :0.90 ? ? ? ?Median :0.06000 ?Median :268.0
> ?Mean ? :10.33 ? Mean ? :0.80 ? ? ? ?Mean ? :0.05333 ? ? ?Mean ? :268.2
> ?3rd Qu.:11.00 ? 3rd Qu.:1.00 ? ? ? ?3rd Qu.:0.08000 ? ? ?3rd Qu.:383.0
> ?Max. ? :12.00 ? Max. ? :1.00 ? ? ? ?Max. ? :0.08000 ? ? ?Max. ? :383.0
> ? Market_share ? ?Friends_share ? ? Refuel_time ? ? ? Emission
> ?Min. ? :0.0500 ? Min. ? :0.0000 ? Min. ? : 5.00 ? Min. :0.0000
> ?1st Qu.:0.1500 ? 1st Qu.:0.1500 ? 1st Qu.: 5.00 ? 1st Qu.:0.0000
> ?Median :0.2500 ? Median :0.3000 ? Median : 5.00 ? Median :0.7500
> ?Mean ? :0.3333 ? Mean ? :0.3333 ? Mean ? :13.33 ? Mean :0.5833
> ?3rd Qu.:0.6000 ? 3rd Qu.:0.5500 ? 3rd Qu.:30.00 ? 3rd Qu.:1.0000
> ?Max. ? :0.9000 ? Max. ? :1.0000 ? Max. ? :30.00 ? Max. :1.0000
> ? ? ? Sex ? ? ? ? ? ? ?Age2 ? ? ? ? ? ? Age3 ? ? ? ? ? ? Age4
> ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. :0.0000
> ?1st Qu.:1.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000
> ?Median :1.0000 ? Median :0.0000 ? Median :0.0000 ? Median :0.0000
> ?Mean ? :0.7791 ? Mean ? :0.4574 ? Mean ? :0.2326 ? Mean :0.1531
> ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.:0.0000
> ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. :1.0000
> ? ? ?Edu_PG ? ? ? ? ?Edu_Oth ? ? ? ? ?Occu_Pvt ? ? ? ?Occu_Pub
> ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.000 ? Min. :0.0000
> ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.000 ? 1st Qu.:0.0000
> ?Median :0.0000 ? Median :0.0000 ? Median :0.000 ? Median :0.0000
> ?Mean ? :0.4147 ? Mean ? :0.1841 ? Mean ? :0.376 ? Mean :0.2733
> ?3rd Qu.:1.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.:1.000 ? 3rd Qu.:1.0000
> ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.000 ? Max. :1.0000
> ? ? Occu_SE ? ? ? Location_metro ? Location_majorcity ? ? ?Ahm
> ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? ? Min. :0.00000
> ?1st Qu.:0.0000 ? 1st Qu.:1.0000 ? 1st Qu.:0.0000 ? ? 1st Qu.:0.00000
> ?Median :0.0000 ? Median :1.0000 ? Median :0.0000 ? ? Median :0.00000
> ?Mean ? :0.2655 ? Mean ? :0.7655 ? Mean ? :0.1453 ? ? Mean :0.04457
> ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.0000 ? ? 3rd Qu.:0.00000
> ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? ? Max. :1.00000
> ? ? ? Ben ? ? ? ? ? ? ? Chen ? ? ? ? ? ? ?NCR ? ? ? ? ? ? ?Hyd
> ?Min. ? :0.00000 ? Min. ? :0.00000 ? Min. ? :0.0000 ? Min. :0.00000
> ?1st Qu.:0.00000 ? 1st Qu.:0.00000 ? 1st Qu.:0.0000 ? 1st Qu.:0.00000
> ?Median :0.00000 ? Median :0.00000 ? Median :0.0000 ? Median :0.00000
> ?Mean ? :0.06977 ? Mean ? :0.04651 ? Mean ? :0.2558 ? Mean :0.03682
> ?3rd Qu.:0.00000 ? 3rd Qu.:0.00000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.00000
> ?Max. ? :1.00000 ? Max. ? :1.00000 ? Max. ? :1.0000 ? Max. :1.00000
> ? ? ? Kol ? ? ? ? ? ? ?Mum ? ? ? ? ? ?MajCity ? ? ? ? ?HH_size
> ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? : 1.000
> ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.: 3.000
> ?Median :0.0000 ? Median :0.0000 ? Median :0.0000 ? Median : 5.000
> ?Mean ? :0.2016 ? Mean ? :0.1105 ? Mean ? :0.1453 ? Mean ? : 4.463
> ?3rd Qu.:0.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.: 6.000
> ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. :10.000
> ? ? Children ? ? ? ? ? IG2 ? ? ? ? ? ? ?IG3 ? ? ? ? ? ? ?IG4
> ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. :0.0000
> ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000
> ?Median :1.0000 ? Median :0.0000 ? Median :0.0000 ? Median :0.0000
> ?Mean ? :0.8721 ? Mean ? :0.3818 ? Mean ? :0.4109 ? Mean :0.1841
> ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.0000
> ?Max. ? :4.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. :1.0000
> ? ? HH_cars ? ? ? PPC_morethan10 ? Daily_travel_medium Daily_travel_long
> ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? ? ?Min. :0.00000
> ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? ? ?1st Qu.:0.00000
> ?Median :0.0000 ? Median :0.0000 ? Median :0.0000 ? ? ?Median :0.00000
> ?Mean ? :0.4864 ? Mean ? :0.4516 ? Mean ? :0.3702 ? ? ?Mean :0.02713
> ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? ? ?3rd Qu.:0.00000
> ?Max. ? :3.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? ? ?Max. :1.00000
> ? ? Garage_y ? ? ? ? ? DL_y ? ? ? ? ?Own_accom ?Freerider_tot
> ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. :2.000
> ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:2.000
> ?Median :1.0000 ? Median :1.0000 ? Median :1.0000 ? Median :2.000
> ?Mean ? :0.7267 ? Mean ? :0.6357 ? Mean ? :0.6647 ? Mean :2.244
> ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:2.000
> ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. :8.000
> ?Satisfaction_tot Political_view ? WTP_env_tot ?Warmglow_tot ? ? 
> ?Standout
> ?Min. ? : 2.000 ? Min. ? :1.000 ? Min. ? : 2.000 ? Min. ? : 2.00 ? 
> Min. ? :1.000
> ?1st Qu.: 3.000 ? 1st Qu.:3.000 ? 1st Qu.: 7.000 ? 1st Qu.: 6.00 ? 1st 
> Qu.:2.000
> ?Median : 4.000 ? Median :3.000 ? Median : 8.000 ? Median : 8.00 ? 
> Median :3.000
> ?Mean ? : 4.264 ? Mean ? :3.258 ? Mean ? : 8.124 ? Mean ? : 7.61 ? 
> Mean ? :2.657
> ?3rd Qu.: 5.000 ? 3rd Qu.:4.000 ? 3rd Qu.: 9.000 ? 3rd Qu.: 9.00 ? 3rd 
> Qu.:3.000
> ?Max. ? :10.000 ? Max. ? :5.000 ? Max. ? :10.000 ? Max. :10.00 ? Max. 
> ? :5.000
> ?Acceptance_new Climate_perception ? ?Env_pref ?Tech_leader
> ?Min. ? :1.0 ? ?Min. ? :1.000 ? ? ?Min. ? :1.000 ? Min. ? :1.0
> ?1st Qu.:2.0 ? ?1st Qu.:4.000 ? ? ?1st Qu.:2.000 ? 1st Qu.:2.0
> ?Median :3.0 ? ?Median :5.000 ? ? ?Median :3.000 ? Median :2.0
> ?Mean ? :2.8 ? ?Mean ? :4.483 ? ? ?Mean ? :3.093 ? Mean ? :2.5
> ?3rd Qu.:4.0 ? ?3rd Qu.:5.000 ? ? ?3rd Qu.:4.000 ? 3rd Qu.:3.0
> ?Max. ? :5.0 ? ?Max. ? :5.000 ? ? ?Max. ? :5.000 ? Max. ? :5.0
> ?Social_motivation_tot ?EV_risk_tot ? ? EV_awareness_tot
> ?Min. ? : 3.00 ? ? ? ? Min. ? : 2.000 ? Min. ? : 3.000
> ?1st Qu.: 9.00 ? ? ? ? 1st Qu.: 8.000 ? 1st Qu.: 4.000
> ?Median :11.00 ? ? ? ? Median : 9.000 ? Median : 5.000
> ?Mean ? :10.62 ? ? ? ? Mean ? : 8.661 ? Mean ? : 5.419
> ?3rd Qu.:12.00 ? ? ? ? 3rd Qu.:10.000 ? 3rd Qu.: 6.000
> ?Max. ? :15.00 ? ? ? ? Max. ? :10.000 ? Max. ? :15.000
>
> On Tue, Sep 22, 2020 at 2:07 AM Rahul Chakraborty 
> <chakrarahul at gmail.com <mailto:chakrarahul at gmail.com>> wrote:
>
>     Hello,
>
>     Here is the result of summary(mydata)
>
>     summary(mydata)
>     ? ? ? IND ? ? ? ? ? ?Block ? ? ? ? ? ?QES ? ? ? ? STR ? ? ? ? ALT
>     ?Min. ? : ?1.0 ? Min. ? :1.000 ? Min. ? :1 ? Min. ? : ?101 ? Min.
>     ? :1
>     ?1st Qu.:129.8 ? 1st Qu.:1.000 ? 1st Qu.:3 ? 1st Qu.:12978 ? 1st
>     Qu.:1
>     ?Median :258.5 ? Median :2.000 ? Median :5 ? Median :25855 ?
>     Median :2
>     ?Mean ? :258.5 ? Mean ? :2.467 ? Mean ? :5 ? Mean ? :25855 ? Mean
>     ? :2
>     ?3rd Qu.:387.2 ? 3rd Qu.:4.000 ? 3rd Qu.:7 ? 3rd Qu.:38732 ? 3rd
>     Qu.:3
>     ?Max. ? :516.0 ? Max. ? :4.000 ? Max. ? :9 ? Max. ? :51609 ? Max.
>     ? :3
>     ? ?ALT_name ? ? ? ? ? ? ?ASC ? ? ? ? ? ? Choice ?Choice_binary
>     ?Length:13932 ? ? ? Min. ? :0.0000 ? Min. ? :1.000 ? Min. ? :0.0000
>     ?Class :character ? 1st Qu.:0.0000 ? 1st Qu.:1.000 ? 1st Qu.:0.0000
>     ?Mode ?:character ? Median :1.0000 ? Median :1.000 Median :0.0000
>     ? ? ? ? ? ? ? ? ? ? Mean ? :0.6667 ? Mean ? :1.626 ? Mean ? :0.3333
>     ? ? ? ? ? ? ? ? ? ? 3rd Qu.:1.0000 ? 3rd Qu.:2.000 ? 3rd Qu.:1.0000
>     ? ? ? ? ? ? ? ? ? ? Max. ? :1.0000 ? Max. ? :3.000 ? Max. ? :1.0000
>     ? ? ?Price ? ? ? Refuel_availability Registration_charges
>     ?Running_cost
>     ?Min. ? : 9.00 ? Min. ? :0.25 ? ? ? ?Min. ? :0.00000 ?Min. ? :115.0
>     ?1st Qu.:10.00 ? 1st Qu.:0.75 ? ? ? ?1st Qu.:0.04000 ?1st Qu.:192.0
>     ?Median :10.00 ? Median :0.90 ? ? ? ?Median :0.06000 ?Median :268.0
>     ?Mean ? :10.33 ? Mean ? :0.80 ? ? ? ?Mean ? :0.05333 ?Mean ? :268.2
>     ?3rd Qu.:11.00 ? 3rd Qu.:1.00 ? ? ? ?3rd Qu.:0.08000 ?3rd Qu.:383.0
>     ?Max. ? :12.00 ? Max. ? :1.00 ? ? ? ?Max. ? :0.08000 ?Max. ? :383.0
>     ? Market_share ? ?Friends_share ? ? Refuel_time Emission
>     ?Min. ? :0.0500 ? Min. ? :0.0000 ? Min. ? : 5.00 ? Min. :0.0000
>     ?1st Qu.:0.1500 ? 1st Qu.:0.1500 ? 1st Qu.: 5.00 ? 1st Qu.:0.0000
>     ?Median :0.2500 ? Median :0.3000 ? Median : 5.00 ? Median :0.7500
>     ?Mean ? :0.3333 ? Mean ? :0.3333 ? Mean ? :13.33 ? Mean :0.5833
>     ?3rd Qu.:0.6000 ? 3rd Qu.:0.5500 ? 3rd Qu.:30.00 ? 3rd Qu.:1.0000
>     ?Max. ? :0.9000 ? Max. ? :1.0000 ? Max. ? :30.00 ? Max. :1.0000
>     ? ? ? Sex ? ? ? ? ? ? ?Age2 ? ? ? ? ? ? Age3 Age4
>     ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. :0.0000
>     ?1st Qu.:1.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000
>     ?Median :1.0000 ? Median :0.0000 ? Median :0.0000 ? Median :0.0000
>     ?Mean ? :0.7791 ? Mean ? :0.4574 ? Mean ? :0.2326 ? Mean :0.1531
>     ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.:0.0000
>     ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. :1.0000
>     ? ? ?Edu_PG ? ? ? ? ?Edu_Oth ? ? ? ? ?Occu_Pvt ?Occu_Pub
>     ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.000 ? Min. :0.0000
>     ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.000 ? 1st Qu.:0.0000
>     ?Median :0.0000 ? Median :0.0000 ? Median :0.000 ? Median :0.0000
>     ?Mean ? :0.4147 ? Mean ? :0.1841 ? Mean ? :0.376 ? Mean :0.2733
>     ?3rd Qu.:1.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.:1.000 ? 3rd Qu.:1.0000
>     ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.000 ? Max. :1.0000
>     ? ? Occu_SE ? ? ? Location_metro ? Location_majorcity ?Ahm
>     ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? ? Min. ? :0.00000
>     ?1st Qu.:0.0000 ? 1st Qu.:1.0000 ? 1st Qu.:0.0000 ? ? 1st Qu.:0.00000
>     ?Median :0.0000 ? Median :1.0000 ? Median :0.0000 Median :0.00000
>     ?Mean ? :0.2655 ? Mean ? :0.7655 ? Mean ? :0.1453 ? ? Mean ? :0.04457
>     ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.0000 ? ? 3rd Qu.:0.00000
>     ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? ? Max. ? :1.00000
>     ? ? ? Ben ? ? ? ? ? ? ? Chen ? ? ? ? ? ? ?NCR ?Hyd
>     ?Min. ? :0.00000 ? Min. ? :0.00000 ? Min. ? :0.0000 ? Min. ? :0.00000
>     ?1st Qu.:0.00000 ? 1st Qu.:0.00000 ? 1st Qu.:0.0000 ? 1st Qu.:0.00000
>     ?Median :0.00000 ? Median :0.00000 ? Median :0.0000 Median :0.00000
>     ?Mean ? :0.06977 ? Mean ? :0.04651 ? Mean ? :0.2558 ? Mean ? :0.03682
>     ?3rd Qu.:0.00000 ? 3rd Qu.:0.00000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.00000
>     ?Max. ? :1.00000 ? Max. ? :1.00000 ? Max. ? :1.0000 ? Max. ? :1.00000
>     ? ? ? Kol ? ? ? ? ? ? ?Mum ? ? ? ? ? ?MajCity ?HH_size
>     ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. : 1.000
>     ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.: 3.000
>     ?Median :0.0000 ? Median :0.0000 ? Median :0.0000 ? Median : 5.000
>     ?Mean ? :0.2016 ? Mean ? :0.1105 ? Mean ? :0.1453 ? Mean : 4.463
>     ?3rd Qu.:0.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.: 6.000
>     ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. :10.000
>     ? ? Children ? ? ? ? ? IG2 ? ? ? ? ? ? ?IG3 ?IG4
>     ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. :0.0000
>     ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000
>     ?Median :1.0000 ? Median :0.0000 ? Median :0.0000 ? Median :0.0000
>     ?Mean ? :0.8721 ? Mean ? :0.3818 ? Mean ? :0.4109 ? Mean :0.1841
>     ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:0.0000
>     ?Max. ? :4.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. :1.0000
>     ? ? HH_cars ? ? ? PPC_morethan10 ? ? ?PPC_gr1 PPC_gr2
>     ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.000 ? Min. :0.00000
>     ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.000 ? 1st Qu.:0.00000
>     ?Median :0.0000 ? Median :0.0000 ? Median :0.000 ? Median :0.00000
>     ?Mean ? :0.4864 ? Mean ? :0.4516 ? Mean ? :0.405 ? Mean :0.04651
>     ?3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.000 ? 3rd Qu.:0.00000
>     ?Max. ? :3.0000 ? Max. ? :1.0000 ? Max. ? :1.000 ? Max. :1.00000
>     ? ?Body_Sedan ? ? ? ?Body_SUV ? ? ?Daily_travel_medium
>     Daily_travel_long
>     ?Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000 ?Min. ? :0.00000
>     ?1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? ? ?1st
>     Qu.:0.00000
>     ?Median :0.0000 ? Median :0.0000 ? Median :0.0000 ?Median :0.00000
>     ?Mean ? :0.3178 ? Mean ? :0.2364 ? Mean ? :0.3702 ?Mean ? :0.02713
>     ?3rd Qu.:1.0000 ? 3rd Qu.:0.0000 ? 3rd Qu.:1.0000 ? ? ?3rd
>     Qu.:0.00000
>     ?Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000 ?Max. ? :1.00000
>     ? ?Long_drive ? ? ? Mode_Carpool ? ? ? ?Mode_PB ?Mode_PV
>     ?Min. ? :0.00000 ? Min. ? :0.00000 ? Min. ? :0.0000 ? Min. ? :0.0000
>     ?1st Qu.:0.00000 ? 1st Qu.:0.00000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000
>     ?Median :0.00000 ? Median :0.00000 ? Median :0.0000 Median :0.0000
>     ?Mean ? :0.03488 ? Mean ? :0.02519 ? Mean ? :0.2907 ? Mean ? :0.4419
>     ?3rd Qu.:0.00000 ? 3rd Qu.:0.00000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.0000
>     ?Max. ? :1.00000 ? Max. ? :1.00000 ? Max. ? :1.0000 ? Max. ? :1.0000
>     ? ? Mode_WRC ? ? ? ? ? Garage_y ? ? ? ? ? DL_y ?Own_accom
>     ?Min. ? :0.000000 ? Min. ? :0.0000 ? Min. ? :0.0000 ? Min. ? :0.0000
>     ?1st Qu.:0.000000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000 ? 1st Qu.:0.0000
>     ?Median :0.000000 ? Median :1.0000 ? Median :1.0000 Median :1.0000
>     ?Mean ? :0.007752 ? Mean ? :0.7267 ? Mean ? :0.6357 ? Mean ? :0.6647
>     ?3rd Qu.:0.000000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.0000 ? 3rd Qu.:1.0000
>     ?Max. ? :1.000000 ? Max. ? :1.0000 ? Max. ? :1.0000 ? Max. ? :1.0000
>     ?Freerider_water_electricity Freerider_tot ? Freerider_avg ?
>     Satisfaction_tot
>     ?Min. ? :1.000 ? ? ? ? ? ? ? Min. ? :2.000 ? Min. ? :1.000 ? Min.
>     ? : 2.000
>     ?1st Qu.:2.000 ? ? ? ? ? ? ? 1st Qu.:2.000 ? 1st Qu.:1.000 ? 1st
>     Qu.: 3.000
>     ?Median :3.000 ? ? ? ? ? ? ? Median :2.000 ? Median :1.000 ?
>     Median : 4.000
>     ?Mean ? :3.002 ? ? ? ? ? ? ? Mean ? :2.244 ? Mean ? :1.122 ? Mean
>     ? : 4.264
>     ?3rd Qu.:4.000 ? ? ? ? ? ? ? 3rd Qu.:2.000 ? 3rd Qu.:1.000 ? 3rd
>     Qu.: 5.000
>     ?Max. ? :5.000 ? ? ? ? ? ? ? Max. ? :8.000 ? Max. ? :4.000 ? Max.
>     ? :10.000
>     ?Satisfaction_avg Political_view ?Meet_friends Meet_colleagues
>     ?Min. ? :1.000 ? ?Min. ? :1.000 ? Length:13932 Length:13932
>     ?1st Qu.:1.500 ? ?1st Qu.:3.000 ? Class :character ? Class :character
>     ?Median :2.000 ? ?Median :3.000 ? Mode ?:character ? Mode ?:character
>     ?Mean ? :2.132 ? ?Mean ? :3.258
>     ?3rd Qu.:2.500 ? ?3rd Qu.:4.000
>     ?Max. ? :5.000 ? ?Max. ? :5.000
>     ?Meet_relatives ? ? Invite_colleagues ?Invite_friends
>     Invite_relatives
>     ?Length:13932 ? ? ? Length:13932 ? ? ? Length:13932 Length:13932
>     ?Class :character ? Class :character ? Class :character Class
>     :character
>     ?Mode ?:character ? Mode ?:character ? Mode ?:character Mode
>     ?:character
>
>
>
>     ?Lending_relatives ?Lending_friends ? ?Lending_colleagues
>     ?Length:13932 ? ? ? Length:13932 ? ? ? Length:13932
>     ?Class :character ? Class :character ? Class :character
>     ?Mode ?:character ? Mode ?:character ? Mode ?:character
>
>
>
>     ?Willingness_Purchase_Env_frnd EVuse_pollution ?WTP_env_tot ? ?
>     ?WTP_env_avg
>     ?Min. ? :1.000 ? ? ? ? ? ? ? ? Min. ? :1.000 ? Min. ? : 2.000 ?
>     Min. ? :1.000
>     ?1st Qu.:4.000 ? ? ? ? ? ? ? ? 1st Qu.:3.000 ? 1st Qu.: 7.000 ?
>     1st Qu.:3.500
>     ?Median :4.000 ? ? ? ? ? ? ? ? Median :4.000 ? Median : 8.000 ?
>     Median :4.000
>     ?Mean ? :4.132 ? ? ? ? ? ? ? ? Mean ? :3.992 ? Mean ? : 8.124 ?
>     Mean ? :4.062
>     ?3rd Qu.:5.000 ? ? ? ? ? ? ? ? 3rd Qu.:5.000 ? 3rd Qu.: 9.000 ?
>     3rd Qu.:4.500
>     ?Max. ? :5.000 ? ? ? ? ? ? ? ? Max. ? :5.000 ? Max. :10.000 ? Max.
>     ? :5.000
>     ?Social_recognition Car_social_status ?Warmglow_tot ?Warmglow_avg
>     ?Min. ? :1.000 ? ? ?Min. ? :1.00 ? ? ?Min. ? : 2.00 ? Min. ? :1.000
>     ?1st Qu.:3.000 ? ? ?1st Qu.:4.00 ? ? ?1st Qu.: 6.00 ? 1st Qu.:3.000
>     ?Median :4.000 ? ? ?Median :4.00 ? ? ?Median : 8.00 Median :4.000
>     ?Mean ? :3.541 ? ? ?Mean ? :4.07 ? ? ?Mean ? : 7.61 ? Mean ? :3.805
>     ?3rd Qu.:4.000 ? ? ?3rd Qu.:5.00 ? ? ?3rd Qu.: 9.00 ? 3rd Qu.:4.500
>     ?Max. ? :5.000 ? ? ?Max. ? :5.00 ? ? ?Max. ? :10.00 ? Max. ? :5.000
>     ? ? Standout ? ? Acceptance_new Climate_perception ?Env_pref ? ?
>     ?Tech_leader
>     ?Min. ? :1.000 ? Min. ? :1.0 ? ?Min. ? :1.000 ? ? ?Min. :1.000 ?
>     Min. ? :1.0
>     ?1st Qu.:2.000 ? 1st Qu.:2.0 ? ?1st Qu.:4.000 ? ? ?1st Qu.:2.000 ?
>     1st Qu.:2.0
>     ?Median :3.000 ? Median :3.0 ? ?Median :5.000 ? ? ?Median :3.000 ?
>     Median :2.0
>     ?Mean ? :2.657 ? Mean ? :2.8 ? ?Mean ? :4.483 ? ? ?Mean :3.093 ?
>     Mean ? :2.5
>     ?3rd Qu.:3.000 ? 3rd Qu.:4.0 ? ?3rd Qu.:5.000 ? ? ?3rd Qu.:4.000 ?
>     3rd Qu.:3.0
>     ?Max. ? :5.000 ? Max. ? :5.0 ? ?Max. ? :5.000 ? ? ?Max. :5.000 ?
>     Max. ? :5.0
>     ?Social_motivation_tot Social_motivation_avg Social_motivation_median
>     ?Min. ? : 3.00 ? ? ? ? Min. ? :1.000 ? ? ? ? Min. ? :1.000
>     ?1st Qu.: 9.00 ? ? ? ? 1st Qu.:3.000 ? ? ? ? 1st Qu.:3.000
>     ?Median :11.00 ? ? ? ? Median :3.667 ? ? ? ? Median :3.000
>     ?Mean ? :10.62 ? ? ? ? Mean ? :3.539 ? ? ? ? Mean ? :3.514
>     ?3rd Qu.:12.00 ? ? ? ? 3rd Qu.:4.000 ? ? ? ? 3rd Qu.:4.000
>     ?Max. ? :15.00 ? ? ? ? Max. ? :5.000 ? ? ? ? Max. ? :5.000
>     ? EV_risk_tot ? ? ?EV_risk_avg ? ? ?EV_price EV_awareness_tot
>     EV_awareness_avg
>     ?Min. ? : 2.000 ? Min. ? :1.00 ? Min. ? :1.000 ? Min. ? : 3.000 ?
>     Min. ? :1.000
>     ?1st Qu.: 8.000 ? 1st Qu.:4.00 ? 1st Qu.:1.000 ? 1st Qu.: 4.000 ?
>     1st Qu.:1.333
>     ?Median : 9.000 ? Median :4.50 ? Median :2.000 ? Median : 5.000 ?
>     Median :1.667
>     ?Mean ? : 8.661 ? Mean ? :4.33 ? Mean ? :2.244 ? Mean ? : 5.419 ?
>     Mean ? :1.806
>     ?3rd Qu.:10.000 ? 3rd Qu.:5.00 ? 3rd Qu.:3.000 ? 3rd Qu.: 6.000 ?
>     3rd Qu.:2.000
>     ?Max. ? :10.000 ? Max. ? :5.00 ? Max. ? :5.000 ? Max. :15.000 ?
>     Max. ? :5.000
>     ?EV_awareness_median ? ?Lost_env ? ? Investment_trust Lottery1
>     ?Min. ? :1.000 ? ? ? Min. ? :1.000 ? Min. ? : ? ? 0 Length:13932
>     ?1st Qu.:1.000 ? ? ? 1st Qu.:5.000 ? 1st Qu.: ? ? 0 Class :character
>     ?Median :2.000 ? ? ? Median :5.000 ? Median : ? ? 0 ? Mode
>     ?:character
>     ?Mean ? :1.806 ? ? ? Mean ? :4.913 ? Mean ? : ?1345
>     ?3rd Qu.:2.000 ? ? ? 3rd Qu.:5.000 ? 3rd Qu.: ? ? 0
>     ?Max. ? :5.000 ? ? ? Max. ? :5.000 ? Max. ? :100000
>     ? ? Time1 ? ? ? ? ? ? Lottery2 ? ? ? ? ? ?Time2
>     ?Length:13932 ? ? ? Length:13932 ? ? ? Length:13932
>     ?Class :character ? Class :character ? Class :character
>     ?Mode ?:character ? Mode ?:character ? Mode ?:character
>
>
>
>     Yes, I have many Likert items and many dummy variables. How do I
>     solve this issue?
>
>     Best regards,
>
>     On Tue, Sep 22, 2020 at 1:45 AM David Winsemius
>     <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>
>         If you had included output of summary(mydata) we might be more
>         capable
>         of giving a fact-based answer but I'm guessing that you have a
>         lot of
>         catagorical variables with multiple levels and some sort of
>         combinatoric
>         explosion is resulting in too many levels of a constructed factor.
>
>
>         -- 
>
>         David.
>
>         On 9/21/20 12:55 PM, Rahul Chakraborty wrote:
>         > Hello everyone,
>         >
>         > I am using *mlogit* to analyse my choice experiment data. I
>         have *3
>         > alternatives* for each individual and for each individual I
>         have *9
>         > questions*. I have a response from *516 individuals*. So it
>         is a panel of
>         > 9*516 observations. I have arranged the data in long format
>         (it contains
>         > 100 columns indicating different variables and identifiers).
>         >
>         > In mlogit I tried the following command---
>         >
>         > *mldata<- mlogit.data(mydata, shape = "long", alt.var =
>         "Alt_name", choice
>         > = "Choice_binary", id.var = "IND")*
>         >
>         > It is giving me the following error message- Error in
>         1:nchid : result
>         > would be too long a vector
>         >
>         > Could you please help me with this? I don't think it is too
>         big a data 100
>         > ROWS*13932 columns. I faced no issue in Excel. I am stuck
>         due to this issue.
>         > Thanks in advance.
>         >
>         > -- Best Regards,
>         > Rahul Chakraborty
>         > Research Fellow
>         > National Institute of Public Finance and Policy
>         > New Delhi- 110067
>         >
>         >? ? ? ?[[alternative HTML version deleted]]
>         >
>         > ______________________________________________
>         > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         > https://stat.ethz.ch/mailman/listinfo/r-help
>         > PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         > and provide commented, minimal, self-contained, reproducible
>         code.
>
>
>
>     -- 
>     Rahul Chakraborty
>     Research Fellow
>     National Institute of Public Finance and Policy
>     New Delhi- 110067
>
>
>
> -- 
> Rahul Chakraborty
> Research Fellow
> National Institute of Public Finance and Policy
> New Delhi- 110067


From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 22 01:35:33 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 22 Sep 2020 09:35:33 +1000
Subject: [R] 
 How to model multiple categorical variable in r, using gee model
In-Reply-To: <CAOS8xUYWr8YpXvGf-b9M1oncnFHJ-U2p7AzZWsYrDPedbqFNJQ@mail.gmail.com>
References: <CAOS8xUYWr8YpXvGf-b9M1oncnFHJ-U2p7AzZWsYrDPedbqFNJQ@mail.gmail.com>
Message-ID: <CA+8X3fXUFQ-ZmdHkdA2gA04=dA5SRBE1uwqjK+qdywxVEizsQQ@mail.gmail.com>

Hi Augustinius,
You have been set a problem that requires a lot more information than
is in your request. Also, you have flagged it as a "homework" problem,
so you are unlikely to get much help on this list. Sadly, this sort of
problem sometimes arises when being nice to the instructor is more
important than having the relevant knowledge and I can't help you with
that.

Jim

On Mon, Sep 21, 2020 at 10:39 PM augustinus ntjamba
<augustinusyantjamba at gmail.com> wrote:
>
> Good morning.
> I'm a student at present working on my final year project.
> Kindly asking for help on how to model longitudinal categorical data.
>
> In my data set I have the following variables :type of crime,year,   month,
> date and time.treating type of crime as the response variable and there's
> 12 levels  (Type of crime), while the rest of the variables are
> independent.
> What model will best fit my data?
>
> I have tried using geeglm And this does show differences in correlation
> matrix that should be selected as the best model, secondly I tried using
> multgee package "multLORgee" which never have me outputs and lastly I tried
> using multnom the function returns the same AIC in the working correction
> matrix,
> How do i solve this problem
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 22 02:47:31 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 22 Sep 2020 10:47:31 +1000
Subject: [R] 
 How to model multiple categorical variable in r, using gee model
In-Reply-To: <CAOS8xUbodEG+bD6AMov1rjo6Hjy7=ex1eto_LgVqG9fzTw_HJw@mail.gmail.com>
References: <CAOS8xUYWr8YpXvGf-b9M1oncnFHJ-U2p7AzZWsYrDPedbqFNJQ@mail.gmail.com>
 <CA+8X3fXUFQ-ZmdHkdA2gA04=dA5SRBE1uwqjK+qdywxVEizsQQ@mail.gmail.com>
 <CAOS8xUb+LH5aJK71hGsKGDuEXjbJ0S2Aw3Tf_KBMbK+8eK9LjQ@mail.gmail.com>
 <CAOS8xUbodEG+bD6AMov1rjo6Hjy7=ex1eto_LgVqG9fzTw_HJw@mail.gmail.com>
Message-ID: <CA+8X3fX+U-_RfAt3XDDNDp4Vwk_zo_nqXvBZmX02uuAYEog+ow@mail.gmail.com>

Hi Augustinius,
You are probably familiar with some of these:

http://finzi.psych.upenn.edu/R/library/geepack/html/geeglm.html
https://faculty.washington.edu/heagerty/Courses/b571/homework/geepack-paper.pdf
https://rdrr.io/cran/geex/f/vignettes/articles/mestimation_bib.Rmd

Good luck with it.

Jim

On Tue, Sep 22, 2020 at 9:52 AM augustinus ntjamba
<augustinusyantjamba at gmail.com> wrote:
>
> even a source perhaps that you may refer me too, so I get some idea's tht will be appreciated as well.
>
> On Tue, 22 Sep 2020, 01:50 augustinus ntjamba <augustinusyantjamba at gmail.com> wrote:
>>
>> Thank you for the feedback.
>> actually its not a "home work", it's a "project" that I'm working on and I'm challenged as which function in generalized estimating equations to use, i try using geeglm ,multgee, multinom to model the data, however; I'm unable to determine as which working correction matrix will better fit the model (model selection ) for the fact that all the model with different correlation structure keeps returning the same outputs (I do not observe an difference) hence my concern as it supposed not be the case.
>>
>> This is one of the reason I'm asking for help, like how do I go about it?
>> Your gguidelines will be highly appreciated.
>> My regards,


From @ugu@t|nu@y@ntj@mb@ @end|ng |rom gm@||@com  Tue Sep 22 02:57:40 2020
From: @ugu@t|nu@y@ntj@mb@ @end|ng |rom gm@||@com (augustinus ntjamba)
Date: Tue, 22 Sep 2020 02:57:40 +0200
Subject: [R] 
 How to model multiple categorical variable in r, using gee model
In-Reply-To: <CA+8X3fX+U-_RfAt3XDDNDp4Vwk_zo_nqXvBZmX02uuAYEog+ow@mail.gmail.com>
References: <CAOS8xUYWr8YpXvGf-b9M1oncnFHJ-U2p7AzZWsYrDPedbqFNJQ@mail.gmail.com>
 <CA+8X3fXUFQ-ZmdHkdA2gA04=dA5SRBE1uwqjK+qdywxVEizsQQ@mail.gmail.com>
 <CAOS8xUb+LH5aJK71hGsKGDuEXjbJ0S2Aw3Tf_KBMbK+8eK9LjQ@mail.gmail.com>
 <CAOS8xUbodEG+bD6AMov1rjo6Hjy7=ex1eto_LgVqG9fzTw_HJw@mail.gmail.com>
 <CA+8X3fX+U-_RfAt3XDDNDp4Vwk_zo_nqXvBZmX02uuAYEog+ow@mail.gmail.com>
Message-ID: <CAOS8xUZUNg6wsCwN6ReDDNLDsmc6wpyH0AramX2VNp4Ht8VwDQ@mail.gmail.com>

Thanks for coming through sir. I will check it out.

On Tue, Sep 22, 2020 at 2:47 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Augustinius,
> You are probably familiar with some of these:
>
> http://finzi.psych.upenn.edu/R/library/geepack/html/geeglm.html
>
> https://faculty.washington.edu/heagerty/Courses/b571/homework/geepack-paper.pdf
> https://rdrr.io/cran/geex/f/vignettes/articles/mestimation_bib.Rmd
>
> Good luck with it.
>
> Jim
>
> On Tue, Sep 22, 2020 at 9:52 AM augustinus ntjamba
> <augustinusyantjamba at gmail.com> wrote:
> >
> > even a source perhaps that you may refer me too, so I get some idea's
> tht will be appreciated as well.
> >
> > On Tue, 22 Sep 2020, 01:50 augustinus ntjamba <
> augustinusyantjamba at gmail.com> wrote:
> >>
> >> Thank you for the feedback.
> >> actually its not a "home work", it's a "project" that I'm working on
> and I'm challenged as which function in generalized estimating equations to
> use, i try using geeglm ,multgee, multinom to model the data, however; I'm
> unable to determine as which working correction matrix will better fit the
> model (model selection ) for the fact that all the model with different
> correlation structure keeps returning the same outputs (I do not observe an
> difference) hence my concern as it supposed not be the case.
> >>
> >> This is one of the reason I'm asking for help, like how do I go about
> it?
> >> Your gguidelines will be highly appreciated.
> >> My regards,
>

	[[alternative HTML version deleted]]


From ch@kr@r@hu| @end|ng |rom gm@||@com  Tue Sep 22 07:20:46 2020
From: ch@kr@r@hu| @end|ng |rom gm@||@com (Rahul Chakraborty)
Date: Tue, 22 Sep 2020 10:50:46 +0530
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <d7118822-f3a2-c6c2-df72-917089691de0@comcast.net>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
 <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
 <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>
 <d7118822-f3a2-c6c2-df72-917089691de0@comcast.net>
Message-ID: <CAEmZPSmKKLxS3=dwW2aGHK1JQqO1+WpbtiX6kGcf8Wp=J605NQ@mail.gmail.com>

Hello David and everyone,

I am really sorry for not abiding by the specific guidelines in my
prior communications. I tried to convert the present email in plain
text format (at least it is showing me so in my gmail client). I have
also converted the xlsx file into a csv format with .txt extension.

So, my problem is I need to run panel mixed logit regression for a
choice model. There are 3 alternatives, 9 questions for each
individual and 516 individuals in data. I have created a csv file in
long format from the survey questionnaire. Apart from the alternative
specific variables I have many individual specific variables and most
of these are dummies (dummy coded). I will use subsets of these in my
alternative model specifications. So, in my data I have 100 columns
with 13932 rows (3*9*516). After reading the csv file and creating a
dataframe 'mydata' I used the following command for mlogit.

mldata1<- mlogit.data(mydata, shape = "long", alt.var = "Alt_name",
choice = "Choice_binary", id.var = "IND")

It gives me the same error message- Error in 1:nchid : result would be
too long a vector.

The attached file (csv file with .txt extension) is an example of 2
individuals each with 3 questions. I have also reduced the number of
columns to 57. Now, there are 18 rows. But still if I use the same
command on my new data I get the same error message. Can anyone please
help me out with this? Because of this error I am stuck at the
dataframe level.


Thanks in advance.


Regards,
Rahul Chakraborty

On Tue, Sep 22, 2020 at 4:50 AM David Winsemius <dwinsemius at comcast.net> wrote:
>
> @Rahul;
>
>
> You need to learn to post in plain text and attachments may not be xls
> or xlsx. They need to be text files. And even if they are comma
> separated files and text, they still need to be named with a txt extension.
>
>
> I'm the only one who got the xlsx file. I got the error regardless of
> how many column I omitted, so my gues was possibly incorrect. But I did
> RTFM. See ?mlogit.datadfi The mlogit.data function is deprecated and you
> are told to use the dfidx function. Trying that you now get an error
> saying: " the two indexes don't define unique observations".
>
>
>  > sum(duplicated( dfrm[,1:2]))
> [1] 12
>  > length(dfrm[,1])
> [1] 18
>
> So of your 18 lines in the example file, most of them appear to be
> duplicated in their first two rows and apparently that is not allowed by
> dfidx.
>
>
> Caveat: I'm not a user of the mlogit package so I'm just reading the
> manual and possibly coming up with informed speculation.
>
> Please read the Posting Guide. You have been warned. Repeated violations
> of the policies laid down in that hallowed document will possibly result
> in postings being ignored.
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: example2.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200922/52cb1a83/attachment.txt>

From j@zh@o @end|ng |rom ye@h@net  Tue Sep 22 10:10:54 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Tue, 22 Sep 2020 16:10:54 +0800 (CST)
Subject: [R] text on curve
Message-ID: <504e0268.660b8.174b4dd9425.Coremail.jszhao@yeah.net>

Hi there,

I write a simple function that could place text along a curve. Since I am not familiar with the operation of rotating graphical elements, e.g., text, rectangle, etc., I hope you could give suggestions or hints on how to improve it. Thanks in advance.

# Here is the code:

getCurrentAspect <- function() {
   uy <- diff(grconvertY(1:2,"user","inches"))
   ux <- diff(grconvertX(1:2,"user","inches"))
   uy/ux
}

r.xy <- function(o.x, o.y, theta) {
   r.x <- o.x * cos(theta) - o.y * sin(theta)
   r.y <- o.x * sin(theta) + o.y * cos(theta)
   c(r.x, r.y)
}

text.on.curve <- function(x, y, x.s, str, ...) {

   l <- nchar(str)

   fun <- approxfun(x, y, rule = 2)

   for(i in 1:l) {
      w <- strwidth(substr(str, i, i))
      h <- strheight(substr(str, i, i)) 

      x.l <- x.s
      x.r <- x.s + w
      y.l <- fun(x.l)
      y.r <- fun(x.r)
      theta <- atan((y.r - y.l)/(x.r - x.l) * getCurrentAspect())

      lb.xy <- c(x.s, fun(x.s))
      rb.xy <- lb.xy + r.xy(w, 0, theta)
      lt.xy <- lb.xy + r.xy(0, h, theta)
      rt.xy <- lb.xy + r.xy(w, h, theta)
      c.xy <- lb.xy + r.xy(w/2, h/2, theta)

      while(i > 1 && lt.xy[1] < rt.xy.old[1]) {
         x.s <- x.s + 0.05 * w
         x.l <- x.s
         x.r <- x.s + w
         y.l <- fun(x.l)
         y.r <- fun(x.r)
         theta <- atan((y.r - y.l)/(x.r - x.l) * getCurrentAspect())

         lb.xy <- c(x.s, fun(x.s))
         rb.xy <- lb.xy + r.xy(w, 0, theta)
         lt.xy <- lb.xy + r.xy(0, h, theta)
         rt.xy <- lb.xy + r.xy(w, h, theta)
         c.xy <- lb.xy + r.xy(w/2, h/2, theta)
      }

      x.s <- rb.xy[1]
      rt.xy.old <- rt.xy

      text(c.xy[1], c.xy[2], substr(str, i, i), srt = theta * 180 / pi, ...)
   }
}

# A simple demo:

x <- seq(-5, 5, length.out = 100)
y <- x^2
plot(x,y, type = "l")
text.on.curve(x, y, -2 ,"a demo of text on curve", col = "red")

Best,
Jinsong
 
	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 22 10:47:06 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 22 Sep 2020 18:47:06 +1000
Subject: [R] text on curve
In-Reply-To: <504e0268.660b8.174b4dd9425.Coremail.jszhao@yeah.net>
References: <504e0268.660b8.174b4dd9425.Coremail.jszhao@yeah.net>
Message-ID: <CA+8X3fWwsuG+dQEeQ3disf30phoM-ObC9QhAqMUDeaWPC-O2qQ@mail.gmail.com>

Hi Jinsong,
This is similar to the "arctext" function in plotrix. I don't want to
do all the trig right now, but I would suggest placing the characters
on the curve and then offsetting them a constant amount at right
angles to the slope of the curve at each letter. I would first try
having a "minspace" argument to deal with crowding at small radii and
you would probably have to start at the middle and work out to each
end. A tough problem and you have made a good start on it.  Check the
fragment below for a suggestion on how to avoid calling "substr"
repeatedly.

# get a vector of the characters in str
   # rather than call substr all the time
   strbits<-unlist(strsplit(str,""))

   for(i in 1:l) {
      w <- strwidth(strbits[i])
      h <- strheight(strbits[i])

Jim

On Tue, Sep 22, 2020 at 6:11 PM Jinsong Zhao <jszhao at yeah.net> wrote:
>
> Hi there,
>
> I write a simple function that could place text along a curve. Since I am not familiar with the operation of rotating graphical elements, e.g., text, rectangle, etc., I hope you could give suggestions or hints on how to improve it. Thanks in advance.
>
> # Here is the code:
>
> getCurrentAspect <- function() {
>    uy <- diff(grconvertY(1:2,"user","inches"))
>    ux <- diff(grconvertX(1:2,"user","inches"))
>    uy/ux
> }
>
> r.xy <- function(o.x, o.y, theta) {
>    r.x <- o.x * cos(theta) - o.y * sin(theta)
>    r.y <- o.x * sin(theta) + o.y * cos(theta)
>    c(r.x, r.y)
> }
>
> text.on.curve <- function(x, y, x.s, str, ...) {
>
>    l <- nchar(str)
>
>    fun <- approxfun(x, y, rule = 2)
>
>    for(i in 1:l) {
>       w <- strwidth(substr(str, i, i))
>       h <- strheight(substr(str, i, i))
>
>       x.l <- x.s
>       x.r <- x.s + w
>       y.l <- fun(x.l)
>       y.r <- fun(x.r)
>       theta <- atan((y.r - y.l)/(x.r - x.l) * getCurrentAspect())
>
>       lb.xy <- c(x.s, fun(x.s))
>       rb.xy <- lb.xy + r.xy(w, 0, theta)
>       lt.xy <- lb.xy + r.xy(0, h, theta)
>       rt.xy <- lb.xy + r.xy(w, h, theta)
>       c.xy <- lb.xy + r.xy(w/2, h/2, theta)
>
>       while(i > 1 && lt.xy[1] < rt.xy.old[1]) {
>          x.s <- x.s + 0.05 * w
>          x.l <- x.s
>          x.r <- x.s + w
>          y.l <- fun(x.l)
>          y.r <- fun(x.r)
>          theta <- atan((y.r - y.l)/(x.r - x.l) * getCurrentAspect())
>
>          lb.xy <- c(x.s, fun(x.s))
>          rb.xy <- lb.xy + r.xy(w, 0, theta)
>          lt.xy <- lb.xy + r.xy(0, h, theta)
>          rt.xy <- lb.xy + r.xy(w, h, theta)
>          c.xy <- lb.xy + r.xy(w/2, h/2, theta)
>       }
>
>       x.s <- rb.xy[1]
>       rt.xy.old <- rt.xy
>
>       text(c.xy[1], c.xy[2], substr(str, i, i), srt = theta * 180 / pi, ...)
>    }
> }
>
> # A simple demo:
>
> x <- seq(-5, 5, length.out = 100)
> y <- x^2
> plot(x,y, type = "l")
> text.on.curve(x, y, -2 ,"a demo of text on curve", col = "red")
>
> Best,
> Jinsong
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Tue Sep 22 11:00:54 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 22 Sep 2020 12:00:54 +0300
Subject: [R] aggregate semi-hourly data not 00-24 but 9-9
In-Reply-To: <6FA20CB0-7DC1-407F-8A3F-A618D7483EEE@dcn.davis.ca.us>
References: <8B435C9568170B469AE31E8891E8CC4F809F88B7@ESINO.regionemarche.intra>
 <CAGgJW77j81F45QUHvbM32VZi=6HKwaAPsqt8B63=C6WoPt60_A@mail.gmail.com>
 <6FA20CB0-7DC1-407F-8A3F-A618D7483EEE@dcn.davis.ca.us>
Message-ID: <CAGgJW741-1M3PJbVuLA75N2sKzH_cwsNNpYC9pBA8Rh=aqPk=g@mail.gmail.com>

Thanks Jeff.
Stefano, per Jeff's comment, you can replace the line

df1$data_POSIXminus9 <- df1$data_POSIX - lubridate::hours(9)

by

df1$data_POSIXminus9 <- df1$data_POSIX - as.difftime(9,units="hours")

On Mon, Sep 21, 2020 at 8:06 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> The base R as.difftime function is perfectly usable to create this offset without pulling in lubridate.
>
> On September 21, 2020 8:06:51 AM PDT, Eric Berger <ericjberger at gmail.com> wrote:
> >Hi Stefano,
> >If you mean from 9am on one day to 9am on the following day, you can
> >do a trick. Simply subtract 9hrs from each timestamp and then you want
> >midnight to midnight for these adjusted times, which you can get using
> >the method you followed.
> >
> >I googled and found that lubridate::hours() can be used to add or
> >subtract hours from a POSIXct.
> >
> >library(lubridate)
> >
> >day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
> >df1$hs <- rnorm(nrow(df1), 40, 10)
> >df1$diff[2:nrow(df1)] <- diff(df1$hs)
> >
> >df1$data_POSIXminus9 <- df1$data_POSIX - lubridate::hours(9)
> >df1$dayX <- format(df1$data_POSIXminus9,"%y-%m-%d")
> >df2X <- aggregate(diff ~ dayX, df1, sum)
> >df2X
> >
> >HTH,
> >Eric
> >
> >On Mon, Sep 21, 2020 at 5:30 PM Stefano Sofia
> ><stefano.sofia at regione.marche.it> wrote:
> >>
> >> Dear R-list members,
> >> I have semi-hourly snowfall data.
> >> I should sum the semi-hourly increments (only the positive ones, but
> >this is not described in my example) day by day, not from 00 to 24 but
> >from 9 to 9.
> >>
> >> I am able to use the diff function, create a list of days and use the
> >function aggregate, but it works only from 0 to 24. Any suggestion for
> >an efficient way to do it?
> >> Here my code:
> >> day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >> day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >> df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
> >> df1$hs <- rnorm(nrows(df1), 40, 10)
> >> df1$diff[2:nrow(df1)] <- diff(df1$hs)
> >> df1$day <- format(df$data_POSIX,"%y-%m-%d")
> >> df2 <- aggregate(diff ~ day, df, sum)
> >>
> >> Thank you for your help
> >> Stefano
> >>
> >>          (oo)
> >> --oOO--( )--OOo----------------
> >> Stefano Sofia PhD
> >> Civil Protection - Marche Region
> >> Meteo Section
> >> Snow Section
> >> Via del Colle Ameno 5
> >> 60126 Torrette di Ancona, Ancona
> >> Uff: 071 806 7743
> >> E-mail: stefano.sofia at regione.marche.it
> >> ---Oo---------oO----------------
> >>
> >> ________________________________
> >>
> >> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
> >contenere informazioni confidenziali, pertanto ? destinato solo a
> >persone autorizzate alla ricezione. I messaggi di posta elettronica per
> >i client di Regione Marche possono contenere informazioni confidenziali
> >e con privilegi legali. Se non si ? il destinatario specificato, non
> >leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
> >ricevuto questo messaggio per errore, inoltrarlo al mittente ed
> >eliminarlo completamente dal sistema del proprio computer. Ai sensi
> >dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
> >ed urgenza, la risposta al presente messaggio di posta elettronica pu?
> >essere visionata da persone estranee al destinatario.
> >> IMPORTANT NOTICE: This e-mail message is intended to be received only
> >by persons entitled to receive the confidential information it may
> >contain. E-mail messages to clients of Regione Marche may contain
> >information that is confidential and legally privileged. Please do not
> >read, copy, forward, or store this message unless you are an intended
> >recipient of it. If you have received this message in error, please
> >forward it to the sender and delete it completely from your computer
> >system.
> >>
> >> --
> >> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
> >infetto.
> >> This message was scanned by Libra ESVA and is believed to be clean.
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Tue Sep 22 11:29:54 2020
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 22 Sep 2020 12:29:54 +0300
Subject: [R] Quadratic programming
In-Reply-To: <CAB8pepwZQ1=q25DkT859Fo-EBYjiCA9GJGfP739+QC=NgAfw6g@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepwwT3sqmnYt43bE3VrSUMjxnSAdrFV9LoiLHXwSjWSM5Q@mail.gmail.com>
 <CAB8pepwZQ1=q25DkT859Fo-EBYjiCA9GJGfP739+QC=NgAfw6g@mail.gmail.com>
Message-ID: <CAJxz9NYoeM_eYqVOg6g65TgHenoANNrkMfDB+whddrT5hYXgmg@mail.gmail.com>

I really appreciate you helping me with this! I just don't seem to figure
it out.

(1) I don't know why you think bvec should be a matrix. The
documentation clearly says it should be a vector (implying not a
matrix).

- I've written it in a form of a matrix with one row and 2*J-3
columns. (0,2*J-3,1). I thought that it would pass as a vector. I made it a
vector now.

The thing is that I'm trying to replicate a C++ code with R. The C++ code
imposes shape restrictions on the function and works perfectly. The C++
code is attached and after that the same for R. You said you haven't used
the QP package for a decade. Is there a better/another package for these
types of problems?

Thanks again!

C++ code:

int main()
{
Print("Begin");

/* Bootstrap Parameters */
long RandomSeed = -98345; // Set random seed
const int S = 100; // Number of bootstrap replications

/* Housing Demand Parameters */
const double Beta =  1.1613;
const double v    =  0.7837;
const double Eta  = -0.5140;

/* Quadratic Programming Tolerance Parameters */
const double Delta1 =  0.000001;
const double Delta2 =  0.0001;

/* Read in Dataset */
DataFileDelim d("K:\\Data\\Local Jurisdictions\\AEJ Data.dat",'\t');
d.SortBy<double>("AfterTaxPrice");
int J = d.NumObs();
Vector<double> Price = d.Get<double>("AfterTaxPrice");
Vector<double> Educ  = d.Get<double>("EducAll");
Vector<double> Crime = d.Get<double>("CrimeIndex");
Vector<double> Dist  = d.Get<double>("RushTrav");

/* Adjust Crime Data */
for(int j=0; j<J; j++) if(Crime[j] < 0.005) Crime[j] = 0.0025;  // Set
crime to half of minimum community to avoid log(0)
for(int j=0; j<J; j++) Crime[j] = log(Crime[j]);

/* Compute Ranks */
Vector<double> Rank1(J);
for(int j=0; j<J; j++) Rank1[j] = (One + j) / (double)J;

/* Data for Non-parametric Regression */
Vector<double> X(J);
Matrix<double> Y(J,2);
Vector<double> Z(J);
for(int j=0; j<J; j++)
{
X(j)   = Rank1(j);
Y(j,0) = Crime(j);
Y(j,1) = Dist(j);
Z(j)   = Educ(j);
}

/* Constrained Estimates */
int RhoK1 = 12;
Vector<double> RhoGrid1 = Grid(-1.2,-0.1,RhoK1);
Matrix<double> gTrans(J,RhoK1);
for(int rk=0; rk<RhoK1; rk++)
{
/* Loop Over Rho */
double Rho = RhoGrid1(rk);

/* Print Progress */
cout << Rho << " ";
cout.flush();

/* Set Up Quadratic Programing Problem */
Vector<double> hSmooth(J);
for(int j=0; j<J; j++) hSmooth(j) = -pow(kr.Phi(j),Rho);
Vector<double> Q(J);
for(int j=0; j<J; j++) Q(j) = exp(-Rho * (Beta * pow(Price(j),Eta + One) -
One) / (One + Eta));
SymmetricMatrix<double> H(J,Zero);
Vector<double> c(J,Zero);
Matrix<double> Aeq(0,J);
Vector<double> beq(0);
Matrix<double> Aneq(2*J-3,J,Zero);
Vector<double> bneq(2*J-3);
Vector<double> lb(J,-Inf);
Vector<double> ub(J,Inf);
for(int j=0; j<J; j++) H(j,j) = One;
for(int j=0; j<J; j++) c(j) = -hSmooth(j);
for(int j=1; j<J; j++)
{
Aneq(j-1,j-1) = -One;
Aneq(j-1,j)   = One;
bneq[j-1]     = Delta1;
}
for(int j=2; j<J; j++)
{
Aneq(J-1+j-2,j)   = -One / (Q(j) - Q(j-1));
Aneq(J-1+j-2,j-1) = One / (Q(j) - Q(j-1)) + One / (Q(j-1) - Q(j-2));
Aneq(J-1+j-2,j-2) = -One / (Q(j-1) - Q(j-2));
bneq[J-1+j-2]     = Delta2;
}

/* Solve Constrained Optimization Problem Using Quadratic Programming */
MinQuadProg qp(c,H,Aeq,beq,Aneq,bneq,lb,ub);
qp.PrintLevel = 0;
qp.Solve();

/* Constrained Estimate */
for(int j=0; j<J; j++) gTrans(j,rk) = pow(-qp.Solution(j),One / Rho);


And my version for R:

Beta =  1.1613;
v    =  0.7837;
Eta  = -0.5140;
Delta1 =  0.000001;
Delta2 =  0.0001;

newdata <- AEJData[order(AEJData$AfterTaxPrice),]
View(newdata)
Price = (newdata$AfterTaxPrice)
Educ  = (newdata$EducAll)
Crime = (newdata$CrimeIndex)
Dist  = (newdata$RushTrav)

install.packages("sp")
install.packages("rgdal")
install.packages("raster")
install.packages("calibrate")
install.packages("zeros")
install.packages("quadprog")
library(sp)
library(rgdal)
library(raster)
library(calibrate)
library(quadprog)


J <- length(Price)
hs <- numeric(J)
for(j in 1:J){
  hs[j] <-(-(gEst$KernelRegPartLin..Phi[j]^(-0.1)))
}
hs

Q <- rep(0,J)
for(j in 1:(length(Price))){
  Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
}
Q
plot(Q)


Dmat <- matrix(0,nrow= J, ncol=J)
diag(Dmat) <- 1
dvec <- -hs
Aeq <- 0
beq <- 0
Amat <- matrix(0,J,2*J-3)
bvec <- rep(0,2*J-3)

bv <- t(bvec)
bv

for(j in 2:nrow(Amat)){
  Amat[j-1,j-1] = -1
  Amat[j,j-1] = 1
}

for(j in 3:nrow(Amat)){
  Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
  Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
  Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
}

for(j in 2:ncol(bv)) {
  bv[j-1] = Delta1
}
for(j in 3:ncol(bv)) {
  bv[J-1+j-2] = Delta2
}

solution <- solve.QP(Dmat,dvec,Amat,bvec)

solution

gt <- matrix(0,J,1)
gt

Rho <- c(-1.2,-1.1,-1.0,-0.9,-0.8,-0.7,-0.6,-0.5,-0.4,-0.3,-0.2,-0.1)

Rh <- t(Rho)

gt= (-solution)^(1/(Rh))
gt


ma 21. syysk. 2020 klo 23.38 Abby Spurdle (spurdle.a at gmail.com) kirjoitti:

> I was wondering if you're trying to fit a curve, subject to
> monotonicity/convexity constraints...
> If you are, this is a challenging topic, best of luck...
>
>
> On Tue, Sep 22, 2020 at 8:12 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > Hi,
> >
> > Sorry, for my rushed responses, last night.
> > (Shouldn't post when I'm about to log out).
> >
> > I haven't used the quadprog package for nearly a decade.
> > And I was hoping that an expert using optimization in finance in
> > economics would reply.
> >
> > Some comments:
> > (1) I don't know why you think bvec should be a matrix. The
> > documentation clearly says it should be a vector (implying not a
> > matrix).
> > The only arguments that should be matrices are Dmat and Amat.
> > (2) I'm having some difficulty following your quadratic program, even
> > after rendering it.
> > Perhaps you could rewrite your expressions, in a form that is
> > consistent with the input to solve.QP. That's a math problem, not an R
> > programming problem, as such.
> > (3) If that fails, then you'll need to produce a minimal reproducible
> example.
> > I strongly recommend that the R code matches the quadratic program, as
> > closely as possible.
> >
> >
> > On Mon, Sep 21, 2020 at 9:28 PM Maija Sirkj?rvi
> > <maija.sirkjarvi at gmail.com> wrote:
> > >
> > > Hi!
> > >
> > > I was wondering if someone could help me out. I'm minimizing a
> following
> > > function:
> > >
> > > \begin{equation}
> > > $$\sum_{j=1}^{J}(m_{j} -\hat{m_{j}})^2,$$
> > > \text{subject to}
> > > $$m_{j-1}\leq m_{j}-\delta_{1}$$
> > > $$\frac{1}{Q_{j-1}-Q_{j-2}} (m_{j-2}-m_{j-1}) \leq
> \frac{1}{Q_{j}-Q_{j-1}}
> > > (m_{j-1}-m_{j})-\delta_{2} $$
> > > \end{equation}
> > >
> > > I have tried quadratic programming, but something is off. Does anyone
> have
> > > an idea how to approach this?
> > >
> > > Thanks in advance!
> > >
> > > Q <- rep(0,J)
> > > for(j in 1:(length(Price))){
> > >   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> > > }
> > >
> > > Dmat <- matrix(0,nrow= J, ncol=J)
> > > diag(Dmat) <- 1
> > > dvec <- -hs
> > > Aeq <- 0
> > > beq <- 0
> > > Amat <- matrix(0,J,2*J-3)
> > > bvec <- matrix(0,2*J-3,1)
> > >
> > > for(j in 2:nrow(Amat)){
> > >   Amat[j-1,j-1] = -1
> > >   Amat[j,j-1] = 1
> > > }
> > > for(j in 3:nrow(Amat)){
> > >   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
> > >   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
> > >   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> > > }
> > > for(j in 2:ncol(bvec)) {
> > >   bvec[j-1] = Delta1
> > > }
> > > for(j in 3:ncol(bvec)) {
> > >   bvec[J-1+j-2] = Delta2
> > > }
> > > solution <- solve.QP(Dmat,dvec,Amat,bvec=bvec)
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Tue Sep 22 16:07:06 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Tue, 22 Sep 2020 14:07:06 +0000
Subject: [R] aggregate semi-hourly data not 00-24 but 9-9
In-Reply-To: <CAGgJW741-1M3PJbVuLA75N2sKzH_cwsNNpYC9pBA8Rh=aqPk=g@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F809F88B7@ESINO.regionemarche.intra>
 <CAGgJW77j81F45QUHvbM32VZi=6HKwaAPsqt8B63=C6WoPt60_A@mail.gmail.com>
 <6FA20CB0-7DC1-407F-8A3F-A618D7483EEE@dcn.davis.ca.us>,
 <CAGgJW741-1M3PJbVuLA75N2sKzH_cwsNNpYC9pBA8Rh=aqPk=g@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809F8B6C@ESINO.regionemarche.intra>

Yes, thank you so much.

Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________________
Da: Eric Berger [ericjberger at gmail.com]
Inviato: marted? 22 settembre 2020 11.00
A: Jeff Newmiller
Cc: Stefano Sofia; r-help mailing list
Oggetto: Re: [R] aggregate semi-hourly data not 00-24 but 9-9

Thanks Jeff.
Stefano, per Jeff's comment, you can replace the line

df1$data_POSIXminus9 <- df1$data_POSIX - lubridate::hours(9)

by

df1$data_POSIXminus9 <- df1$data_POSIX - as.difftime(9,units="hours")

On Mon, Sep 21, 2020 at 8:06 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> The base R as.difftime function is perfectly usable to create this offset without pulling in lubridate.
>
> On September 21, 2020 8:06:51 AM PDT, Eric Berger <ericjberger at gmail.com> wrote:
> >Hi Stefano,
> >If you mean from 9am on one day to 9am on the following day, you can
> >do a trick. Simply subtract 9hrs from each timestamp and then you want
> >midnight to midnight for these adjusted times, which you can get using
> >the method you followed.
> >
> >I googled and found that lubridate::hours() can be used to add or
> >subtract hours from a POSIXct.
> >
> >library(lubridate)
> >
> >day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
> >df1$hs <- rnorm(nrow(df1), 40, 10)
> >df1$diff[2:nrow(df1)] <- diff(df1$hs)
> >
> >df1$data_POSIXminus9 <- df1$data_POSIX - lubridate::hours(9)
> >df1$dayX <- format(df1$data_POSIXminus9,"%y-%m-%d")
> >df2X <- aggregate(diff ~ dayX, df1, sum)
> >df2X
> >
> >HTH,
> >Eric
> >
> >On Mon, Sep 21, 2020 at 5:30 PM Stefano Sofia
> ><stefano.sofia at regione.marche.it> wrote:
> >>
> >> Dear R-list members,
> >> I have semi-hourly snowfall data.
> >> I should sum the semi-hourly increments (only the positive ones, but
> >this is not described in my example) day by day, not from 00 to 24 but
> >from 9 to 9.
> >>
> >> I am able to use the diff function, create a list of days and use the
> >function aggregate, but it works only from 0 to 24. Any suggestion for
> >an efficient way to do it?
> >> Here my code:
> >> day_1 <- as.POSIXct("2020-02-19-00-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >> day_2 <- as.POSIXct("2020-02-24-12-00", format="%Y-%m-%d-%H-%M",
> >tz="Etc/GMT-1")
> >> df1 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
> >> df1$hs <- rnorm(nrows(df1), 40, 10)
> >> df1$diff[2:nrow(df1)] <- diff(df1$hs)
> >> df1$day <- format(df$data_POSIX,"%y-%m-%d")
> >> df2 <- aggregate(diff ~ day, df, sum)
> >>
> >> Thank you for your help
> >> Stefano
> >>
> >>          (oo)
> >> --oOO--( )--OOo----------------
> >> Stefano Sofia PhD
> >> Civil Protection - Marche Region
> >> Meteo Section
> >> Snow Section
> >> Via del Colle Ameno 5
> >> 60126 Torrette di Ancona, Ancona
> >> Uff: 071 806 7743
> >> E-mail: stefano.sofia at regione.marche.it
> >> ---Oo---------oO----------------
> >>
> >> ________________________________
> >>
> >> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
> >contenere informazioni confidenziali, pertanto ? destinato solo a
> >persone autorizzate alla ricezione. I messaggi di posta elettronica per
> >i client di Regione Marche possono contenere informazioni confidenziali
> >e con privilegi legali. Se non si ? il destinatario specificato, non
> >leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
> >ricevuto questo messaggio per errore, inoltrarlo al mittente ed
> >eliminarlo completamente dal sistema del proprio computer. Ai sensi
> >dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
> >ed urgenza, la risposta al presente messaggio di posta elettronica pu?
> >essere visionata da persone estranee al destinatario.
> >> IMPORTANT NOTICE: This e-mail message is intended to be received only
> >by persons entitled to receive the confidential information it may
> >contain. E-mail messages to clients of Regione Marche may contain
> >information that is confidential and legally privileged. Please do not
> >read, copy, forward, or store this message unless you are an intended
> >recipient of it. If you have received this message in error, please
> >forward it to the sender and delete it completely from your computer
> >system.
> >>
> >> --
> >> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
> >infetto.
> >> This message was scanned by Libra ESVA and is believed to be clean.
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> >> PLEASE do read the posting guide
> > https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> >PLEASE do read the posting guide
> > https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 22 17:15:40 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 22 Sep 2020 08:15:40 -0700
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <CAEmZPSmKKLxS3=dwW2aGHK1JQqO1+WpbtiX6kGcf8Wp=J605NQ@mail.gmail.com>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
 <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
 <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>
 <d7118822-f3a2-c6c2-df72-917089691de0@comcast.net>
 <CAEmZPSmKKLxS3=dwW2aGHK1JQqO1+WpbtiX6kGcf8Wp=J605NQ@mail.gmail.com>
Message-ID: <ec59d668-2935-f829-ae63-c0418fcab34f@comcast.net>

You were told two things about your code:


1) mlogit.data is deprecated by the package authors, so use dfidx.

2) dfidx does not allow duplicate ids in the first two columns.


Which one of those are you asserting is not accurate?


-- 

David.

On 9/21/20 10:20 PM, Rahul Chakraborty wrote:
> Hello David and everyone,
>
> I am really sorry for not abiding by the specific guidelines in my
> prior communications. I tried to convert the present email in plain
> text format (at least it is showing me so in my gmail client). I have
> also converted the xlsx file into a csv format with .txt extension.
>
> So, my problem is I need to run panel mixed logit regression for a
> choice model. There are 3 alternatives, 9 questions for each
> individual and 516 individuals in data. I have created a csv file in
> long format from the survey questionnaire. Apart from the alternative
> specific variables I have many individual specific variables and most
> of these are dummies (dummy coded). I will use subsets of these in my
> alternative model specifications. So, in my data I have 100 columns
> with 13932 rows (3*9*516). After reading the csv file and creating a
> dataframe 'mydata' I used the following command for mlogit.
>
> mldata1<- mlogit.data(mydata, shape = "long", alt.var = "Alt_name",
> choice = "Choice_binary", id.var = "IND")
>
> It gives me the same error message- Error in 1:nchid : result would be
> too long a vector.
>
> The attached file (csv file with .txt extension) is an example of 2
> individuals each with 3 questions. I have also reduced the number of
> columns to 57. Now, there are 18 rows. But still if I use the same
> command on my new data I get the same error message. Can anyone please
> help me out with this? Because of this error I am stuck at the
> dataframe level.
>
>
> Thanks in advance.
>
>
> Regards,
> Rahul Chakraborty
>
> On Tue, Sep 22, 2020 at 4:50 AM David Winsemius <dwinsemius at comcast.net> wrote:
>> @Rahul;
>>
>>
>> You need to learn to post in plain text and attachments may not be xls
>> or xlsx. They need to be text files. And even if they are comma
>> separated files and text, they still need to be named with a txt extension.
>>
>>
>> I'm the only one who got the xlsx file. I got the error regardless of
>> how many column I omitted, so my gues was possibly incorrect. But I did
>> RTFM. See ?mlogit.datadfi The mlogit.data function is deprecated and you
>> are told to use the dfidx function. Trying that you now get an error
>> saying: " the two indexes don't define unique observations".
>>
>>
>>   > sum(duplicated( dfrm[,1:2]))
>> [1] 12
>>   > length(dfrm[,1])
>> [1] 18
>>
>> So of your 18 lines in the example file, most of them appear to be
>> duplicated in their first two rows and apparently that is not allowed by
>> dfidx.
>>
>>
>> Caveat: I'm not a user of the mlogit package so I'm just reading the
>> manual and possibly coming up with informed speculation.
>>
>> Please read the Posting Guide. You have been warned. Repeated violations
>> of the policies laid down in that hallowed document will possibly result
>> in postings being ignored.
>>


From ccberry @end|ng |rom he@|th@uc@d@edu  Tue Sep 22 19:06:51 2020
From: ccberry @end|ng |rom he@|th@uc@d@edu (Berry, Charles)
Date: Tue, 22 Sep 2020 17:06:51 +0000
Subject: [R] text on curve
In-Reply-To: <504e0268.660b8.174b4dd9425.Coremail.jszhao@yeah.net>
References: <504e0268.660b8.174b4dd9425.Coremail.jszhao@yeah.net>
Message-ID: <23FE7931-9151-43AC-8F52-8DA526A77E16@health.ucsd.edu>



> On Sep 22, 2020, at 1:10 AM, Jinsong Zhao <jszhao at yeah.net> wrote:
> 
> Hi there,
> 
> I write a simple function that could place text along a curve. Since I am not familiar with the operation of rotating graphical elements, e.g., text, rectangle, etc., I hope you could give suggestions or hints on how to improve it. Thanks in advance.
> 
> # Here is the code:
> 


[code deleted]

For this kind of operation you might want to use tikz. 

R has the ability to produce tikz directives and to insert raw tikz into a 'tikzDevice'.

If you search rseek.org for 'tikz' you will get plenty of good hits. 

The tikz/pgf manual has examples of flowing text, IIRC.

HTH,

Chuck

p.s. this is a plain text list. Do not submit html.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 22 19:30:18 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 22 Sep 2020 18:30:18 +0100
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <ec59d668-2935-f829-ae63-c0418fcab34f@comcast.net>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
 <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
 <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>
 <d7118822-f3a2-c6c2-df72-917089691de0@comcast.net>
 <CAEmZPSmKKLxS3=dwW2aGHK1JQqO1+WpbtiX6kGcf8Wp=J605NQ@mail.gmail.com>
 <ec59d668-2935-f829-ae63-c0418fcab34f@comcast.net>
Message-ID: <dd66e9fc-0daf-73ab-96ce-37d70c4162bc@sapo.pt>

Hello,

I apologize if the rest of quotes prior to David's email are missing, 
for some reason today my mail client is not including them.

As for the question, there are two other problems:

1) Alt_name is misspelled, it should be ALT_name;

2) the data is in wide, not long, format.

A 3rd, problem is that in ?dfidx it says

alt.var	
the name of the variable that contains the alternative index (for a long 
data.frame only) or the name under which the alternative index will be 
stored (the default name is alt)


So if shape = "wide", alt.var is not needed.
But I am not a user of package mlogit, I'm just guessing.

The following seems to fix it (it doesn't throw errors).


mldata1 <- dfidx(mydata, shape = "wide",
                  #alt.var = "ALT_name",
                  choice = "Choice_binary",
                  id.var = "IND")


Hope this helps,

Rui Barradas


?s 16:15 de 22/09/20, David Winsemius escreveu:
> You were told two things about your code:
> 
> 
> 1) mlogit.data is deprecated by the package authors, so use dfidx.
> 
> 2) dfidx does not allow duplicate ids in the first two columns.
> 
> 
> Which one of those are you asserting is not accurate?
> 
>


From ch@kr@r@hu| @end|ng |rom gm@||@com  Tue Sep 22 19:51:43 2020
From: ch@kr@r@hu| @end|ng |rom gm@||@com (Rahul Chakraborty)
Date: Tue, 22 Sep 2020 23:21:43 +0530
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <ec59d668-2935-f829-ae63-c0418fcab34f@comcast.net>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
 <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
 <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>
 <d7118822-f3a2-c6c2-df72-917089691de0@comcast.net>
 <CAEmZPSmKKLxS3=dwW2aGHK1JQqO1+WpbtiX6kGcf8Wp=J605NQ@mail.gmail.com>
 <ec59d668-2935-f829-ae63-c0418fcab34f@comcast.net>
Message-ID: <CAEmZPSmyqMmDn6eo3DZAMYmBVYES6kfRX_D+doYKgbgsEWix9w@mail.gmail.com>

David,

My apologies with the first one. I was checking different tutorials on
mlogit where they were using mlogit.data, so I ended up using it.

I am not getting what you are saying by the "duplicates in first two
columns". See, my first column is IND which identifies my individuals,
second column is QES which identifies the question number each
individual faces, 3rd column is a stratification code that can be
ignored. Columns 6-13 are alternative specific variables and rest are
individual specific. So 1st 3 rows indicate 1st question faced by 1st
individual containing 3 alternatives, and so on. So, I have already
arranged the data in long format. Here, I could not get what the
"duplicate in first two columns" mean.


And I am really sorry that there was an error in my code as Rui has
pointed out. The correct code is
mldata1 <- dfidx(mydata, shape = "long",
                  alt.var = "ALT_name",
                  choice = "Choice_binary",
                  id.var = "IND")

It still shows the error-  "the two indexes don't define unique observations"
It would be really helpful if you kindly help.

Regards,


On Tue, Sep 22, 2020 at 8:46 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
> You were told two things about your code:
>
>
> 1) mlogit.data is deprecated by the package authors, so use dfidx.
>
> 2) dfidx does not allow duplicate ids in the first two columns.
>
>
> Which one of those are you asserting is not accurate?
>
>
> --
>
> David.
>
> On 9/21/20 10:20 PM, Rahul Chakraborty wrote:
> > Hello David and everyone,
> >
> > I am really sorry for not abiding by the specific guidelines in my
> > prior communications. I tried to convert the present email in plain
> > text format (at least it is showing me so in my gmail client). I have
> > also converted the xlsx file into a csv format with .txt extension.
> >
> > So, my problem is I need to run panel mixed logit regression for a
> > choice model. There are 3 alternatives, 9 questions for each
> > individual and 516 individuals in data. I have created a csv file in
> > long format from the survey questionnaire. Apart from the alternative
> > specific variables I have many individual specific variables and most
> > of these are dummies (dummy coded). I will use subsets of these in my
> > alternative model specifications. So, in my data I have 100 columns
> > with 13932 rows (3*9*516). After reading the csv file and creating a
> > dataframe 'mydata' I used the following command for mlogit.
> >
> > mldata1<- mlogit.data(mydata, shape = "long", alt.var = "Alt_name",
> > choice = "Choice_binary", id.var = "IND")
> >
> > It gives me the same error message- Error in 1:nchid : result would be
> > too long a vector.
> >
> > The attached file (csv file with .txt extension) is an example of 2
> > individuals each with 3 questions. I have also reduced the number of
> > columns to 57. Now, there are 18 rows. But still if I use the same
> > command on my new data I get the same error message. Can anyone please
> > help me out with this? Because of this error I am stuck at the
> > dataframe level.
> >
> >
> > Thanks in advance.
> >
> >
> > Regards,
> > Rahul Chakraborty
> >
> > On Tue, Sep 22, 2020 at 4:50 AM David Winsemius <dwinsemius at comcast.net> wrote:
> >> @Rahul;
> >>
> >>
> >> You need to learn to post in plain text and attachments may not be xls
> >> or xlsx. They need to be text files. And even if they are comma
> >> separated files and text, they still need to be named with a txt extension.
> >>
> >>
> >> I'm the only one who got the xlsx file. I got the error regardless of
> >> how many column I omitted, so my gues was possibly incorrect. But I did
> >> RTFM. See ?mlogit.datadfi The mlogit.data function is deprecated and you
> >> are told to use the dfidx function. Trying that you now get an error
> >> saying: " the two indexes don't define unique observations".
> >>
> >>
> >>   > sum(duplicated( dfrm[,1:2]))
> >> [1] 12
> >>   > length(dfrm[,1])
> >> [1] 18
> >>
> >> So of your 18 lines in the example file, most of them appear to be
> >> duplicated in their first two rows and apparently that is not allowed by
> >> dfidx.
> >>
> >>
> >> Caveat: I'm not a user of the mlogit package so I'm just reading the
> >> manual and possibly coming up with informed speculation.
> >>
> >> Please read the Posting Guide. You have been warned. Repeated violations
> >> of the policies laid down in that hallowed document will possibly result
> >> in postings being ignored.
> >>



-- 
Rahul Chakraborty
Research Fellow
National Institute of Public Finance and Policy
New Delhi- 110067


From v@|kremk @end|ng |rom gm@||@com  Tue Sep 22 20:55:33 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Tue, 22 Sep 2020 13:55:33 -0500
Subject: [R] Split
Message-ID: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>

HI All,

I am trying to create   new columns based on another column string
content. First I want to identify rows that contain a particular
string.  If it contains, I want to split the string and create two
variables.

Here is my sample of data.
F1<-read.table(text="ID1  ID2  text
A1 B1   NONE
A1 B1   cf_12
A1 B1   NONE
A2 B2   X2_25
A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
If the variable "text" contains this "_" I want to create an indicator
variable as shown below

F1$Y1 <- ifelse(grepl("_", F1$text),1,0)


Then I want to split that string in to two, before "_" and after "_"
and create two variables as shown below
x1= strsplit(as.character(F1$text),'_',2)

My problem is how to combine this with the original data frame. The
desired  output is shown   below,


ID1 ID2  Y1   X1    X2
A1  B1    0   NONE   .
A1  B1   1    cf        12
A1  B1   0  NONE   .
A2  B2   1    X2    25
A2  B3   1    fd    15

Any help?
Thank you.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 22 21:07:31 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 22 Sep 2020 20:07:31 +0100
Subject: [R] Split
In-Reply-To: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
Message-ID: <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>

Hello,

Something like this?


F1$Y1 <- +grepl("_", F1$text)
F1 <- F1[c(1, 2, 4, 3)]
F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill = 
"right")
F1


Hope this helps,

Rui Barradas

?s 19:55 de 22/09/20, Val escreveu:
> HI All,
> 
> I am trying to create   new columns based on another column string
> content. First I want to identify rows that contain a particular
> string.  If it contains, I want to split the string and create two
> variables.
> 
> Here is my sample of data.
> F1<-read.table(text="ID1  ID2  text
> A1 B1   NONE
> A1 B1   cf_12
> A1 B1   NONE
> A2 B2   X2_25
> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
> If the variable "text" contains this "_" I want to create an indicator
> variable as shown below
> 
> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
> 
> 
> Then I want to split that string in to two, before "_" and after "_"
> and create two variables as shown below
> x1= strsplit(as.character(F1$text),'_',2)
> 
> My problem is how to combine this with the original data frame. The
> desired  output is shown   below,
> 
> 
> ID1 ID2  Y1   X1    X2
> A1  B1    0   NONE   .
> A1  B1   1    cf        12
> A1  B1   0  NONE   .
> A2  B2   1    X2    25
> A2  B3   1    fd    15
> 
> Any help?
> Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 22 21:16:37 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 22 Sep 2020 20:16:37 +0100
Subject: [R] Split
In-Reply-To: <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
Message-ID: <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>

Hello,

A base R solution with strsplit, like in your code.

F1$Y1 <- +grepl("_", F1$text)

tmp <- strsplit(as.character(F1$text), "_")
tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
tmp <- do.call(rbind, tmp)
colnames(tmp) <- c("X1", "X2")
F1 <- cbind(F1[-3], tmp)    # remove the original column
rm(tmp)

F1
#  ID1 ID2 Y1   X1 X2
#1  A1  B1  0 NONE  .
#2  A1  B1  1   cf 12
#3  A1  B1  0 NONE  .
#4  A2  B2  1   X2 25
#5  A2  B3  1   fd 15


Note that cbind dispatches on F1, an object of class "data.frame".
Therefore it's the method cbind.data.frame that is called and the result 
is also a df, though tmp is a "matrix".


Hope this helps,

Rui Barradas


?s 20:07 de 22/09/20, Rui Barradas escreveu:
> Hello,
> 
> Something like this?
> 
> 
> F1$Y1 <- +grepl("_", F1$text)
> F1 <- F1[c(1, 2, 4, 3)]
> F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill = 
> "right")
> F1
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 19:55 de 22/09/20, Val escreveu:
>> HI All,
>>
>> I am trying to create?? new columns based on another column string
>> content. First I want to identify rows that contain a particular
>> string.? If it contains, I want to split the string and create two
>> variables.
>>
>> Here is my sample of data.
>> F1<-read.table(text="ID1? ID2? text
>> A1 B1?? NONE
>> A1 B1?? cf_12
>> A1 B1?? NONE
>> A2 B2?? X2_25
>> A2 B3?? fd_15? ",header=TRUE,stringsAsFactors=F)
>> If the variable "text" contains this "_" I want to create an indicator
>> variable as shown below
>>
>> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
>>
>>
>> Then I want to split that string in to two, before "_" and after "_"
>> and create two variables as shown below
>> x1= strsplit(as.character(F1$text),'_',2)
>>
>> My problem is how to combine this with the original data frame. The
>> desired? output is shown?? below,
>>
>>
>> ID1 ID2? Y1?? X1??? X2
>> A1? B1??? 0?? NONE?? .
>> A1? B1?? 1??? cf??????? 12
>> A1? B1?? 0? NONE?? .
>> A2? B2?? 1??? X2??? 25
>> A2? B3?? 1??? fd??? 15
>>
>> Any help?
>> Thank you.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |mh_u@er@-group@ @end|ng |rom mo|conn@com  Tue Sep 22 23:31:31 2020
From: |mh_u@er@-group@ @end|ng |rom mo|conn@com (LMH)
Date: Tue, 22 Sep 2020 17:31:31 -0400
Subject: [R] Split
In-Reply-To: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
Message-ID: <fa723ac2-d86e-db23-bea7-6139b33c3110@molconn.com>

Sometimes it just makes more sense to pre-process your data and get it into the format you need. It
just depends on whether you are more comfortable programing in R or in some other text manipulation
language like bash/sed/awk/grep etc.

If you know how to do this with other tools, you could write a script and probably call the script
from R. I could post a sample if you are interested.

LMH


Val wrote:
> HI All,
> 
> I am trying to create   new columns based on another column string
> content. First I want to identify rows that contain a particular
> string.  If it contains, I want to split the string and create two
> variables.
> 
> Here is my sample of data.
> F1<-read.table(text="ID1  ID2  text
> A1 B1   NONE
> A1 B1   cf_12
> A1 B1   NONE
> A2 B2   X2_25
> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
> If the variable "text" contains this "_" I want to create an indicator
> variable as shown below
> 
> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
> 
> 
> Then I want to split that string in to two, before "_" and after "_"
> and create two variables as shown below
> x1= strsplit(as.character(F1$text),'_',2)
> 
> My problem is how to combine this with the original data frame. The
> desired  output is shown   below,
> 
> 
> ID1 ID2  Y1   X1    X2
> A1  B1    0   NONE   .
> A1  B1   1    cf        12
> A1  B1   0  NONE   .
> A2  B2   1    X2    25
> A2  B3   1    fd    15
> 
> Any help?
> Thank you.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 22 23:53:18 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 22 Sep 2020 22:53:18 +0100
Subject: [R] Help with the Error Message in R "Error in 1:nchid : result
 would be too long a vector"
In-Reply-To: <CAEmZPSnU===bm=ZdVVDmJx-a-Qd955yxjnDBHZkRFUyoUASyvQ@mail.gmail.com>
References: <CAEmZPSmcJ10tMEv+4-9QQX-yXLbbau2sp55cOT6a76s4B6wcPw@mail.gmail.com>
 <e1b0bc48-4f5d-7cc2-4de9-b0321e8e35b7@comcast.net>
 <CAEmZPSnPRjFQBfk5GQGYxaqKaqtHqf=12GeAPtJ3aFOM3QxbUA@mail.gmail.com>
 <CAEmZPSntN9SXwY8z0vRVDXKciazcFviYZQvyrUrXEBJCs3cnUg@mail.gmail.com>
 <d7118822-f3a2-c6c2-df72-917089691de0@comcast.net>
 <CAEmZPSmKKLxS3=dwW2aGHK1JQqO1+WpbtiX6kGcf8Wp=J605NQ@mail.gmail.com>
 <ec59d668-2935-f829-ae63-c0418fcab34f@comcast.net>
 <dd66e9fc-0daf-73ab-96ce-37d70c4162bc@sapo.pt>
 <CAEmZPSnU===bm=ZdVVDmJx-a-Qd955yxjnDBHZkRFUyoUASyvQ@mail.gmail.com>
Message-ID: <c220d8b2-96f9-e112-8f8c-fcb63a5ec274@sapo.pt>

Hello,

Please keep this on the list so that others can give their contribution.

If you have reshaped your data can you post the code you ran to reshape 
it? Right now we only have the original attachment, in wide format, not 
the long format data.

Rui Barradas

?s 21:55 de 22/09/20, Rahul Chakraborty escreveu:
> Hi,
> 
> Thank you so much for your reply.
> Yes, thank you for pointing that out, I apologise for that error in
> the variable name. However, my data is in long format.
> 
> See, my first column is IND which identifies my individuals,
> second column is QES which identifies the question number each
> individual faces, 3rd column is a stratification code that can be
> ignored. Columns 6-13 are alternative specific variables and rest are
> individual specific. So 1st 3 rows indicate 1st question faced by 1st
> individual containing 3 alternatives, and so on. So, I have already
> arranged the data in long format.
> 
> With that in mind if I use shape="long" it still gives me error.
> 
> Best  regards,
> 
> On Tue, Sep 22, 2020 at 11:00 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> I apologize if the rest of quotes prior to David's email are missing,
>> for some reason today my mail client is not including them.
>>
>> As for the question, there are two other problems:
>>
>> 1) Alt_name is misspelled, it should be ALT_name;
>>
>> 2) the data is in wide, not long, format.
>>
>> A 3rd, problem is that in ?dfidx it says
>>
>> alt.var
>> the name of the variable that contains the alternative index (for a long
>> data.frame only) or the name under which the alternative index will be
>> stored (the default name is alt)
>>
>>
>> So if shape = "wide", alt.var is not needed.
>> But I am not a user of package mlogit, I'm just guessing.
>>
>> The following seems to fix it (it doesn't throw errors).
>>
>>
>> mldata1 <- dfidx(mydata, shape = "wide",
>>                    #alt.var = "ALT_name",
>>                    choice = "Choice_binary",
>>                    id.var = "IND")
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> ?s 16:15 de 22/09/20, David Winsemius escreveu:
>>> You were told two things about your code:
>>>
>>>
>>> 1) mlogit.data is deprecated by the package authors, so use dfidx.
>>>
>>> 2) dfidx does not allow duplicate ids in the first two columns.
>>>
>>>
>>> Which one of those are you asserting is not accurate?
>>>
>>>
> 
> 
>


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 23 01:25:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 22 Sep 2020 16:25:13 -0700
Subject: [R] Split
In-Reply-To: <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
Message-ID: <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>

To be clear, I think Rui's solution is perfectly fine and probably better
than what I offer below. But just for fun, I wanted to do it without the
lapply().  Here is one way. I think my comments suffice to explain.

> ## which are the  non "_" indices?
> wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
> ## paste "_." to these
> F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
> ## Now strsplit() and unlist() them to get a vector
> z <- unlist(strsplit(F1$text, "_"))
> ## now cbind() to the data frame
> F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
> F1
  ID1 ID2   text    1  2
1  A1  B1 NONE_. NONE  .
2  A1  B1  cf_12   cf 12
3  A1  B1 NONE_. NONE  .
4  A2  B2  X2_25   X2 25
5  A2  B3  fd_15   fd 15
>## You can change the names of the 2 columns yourself

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> A base R solution with strsplit, like in your code.
>
> F1$Y1 <- +grepl("_", F1$text)
>
> tmp <- strsplit(as.character(F1$text), "_")
> tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
> tmp <- do.call(rbind, tmp)
> colnames(tmp) <- c("X1", "X2")
> F1 <- cbind(F1[-3], tmp)    # remove the original column
> rm(tmp)
>
> F1
> #  ID1 ID2 Y1   X1 X2
> #1  A1  B1  0 NONE  .
> #2  A1  B1  1   cf 12
> #3  A1  B1  0 NONE  .
> #4  A2  B2  1   X2 25
> #5  A2  B3  1   fd 15
>
>
> Note that cbind dispatches on F1, an object of class "data.frame".
> Therefore it's the method cbind.data.frame that is called and the result
> is also a df, though tmp is a "matrix".
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 20:07 de 22/09/20, Rui Barradas escreveu:
> > Hello,
> >
> > Something like this?
> >
> >
> > F1$Y1 <- +grepl("_", F1$text)
> > F1 <- F1[c(1, 2, 4, 3)]
> > F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill =
> > "right")
> > F1
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 19:55 de 22/09/20, Val escreveu:
> >> HI All,
> >>
> >> I am trying to create   new columns based on another column string
> >> content. First I want to identify rows that contain a particular
> >> string.  If it contains, I want to split the string and create two
> >> variables.
> >>
> >> Here is my sample of data.
> >> F1<-read.table(text="ID1  ID2  text
> >> A1 B1   NONE
> >> A1 B1   cf_12
> >> A1 B1   NONE
> >> A2 B2   X2_25
> >> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
> >> If the variable "text" contains this "_" I want to create an indicator
> >> variable as shown below
> >>
> >> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
> >>
> >>
> >> Then I want to split that string in to two, before "_" and after "_"
> >> and create two variables as shown below
> >> x1= strsplit(as.character(F1$text),'_',2)
> >>
> >> My problem is how to combine this with the original data frame. The
> >> desired  output is shown   below,
> >>
> >>
> >> ID1 ID2  Y1   X1    X2
> >> A1  B1    0   NONE   .
> >> A1  B1   1    cf        12
> >> A1  B1   0  NONE   .
> >> A2  B2   1    X2    25
> >> A2  B3   1    fd    15
> >>
> >> Any help?
> >> Thank you.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@|kremk @end|ng |rom gm@||@com  Wed Sep 23 02:00:29 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Tue, 22 Sep 2020 19:00:29 -0500
Subject: [R] Split
In-Reply-To: <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
Message-ID: <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>

Thank you all for the help!

LMH, Yes I would like to see the alternative.  I am using this for a
large data set and if the  alternative is more efficient than this
then I would be happy.

On Tue, Sep 22, 2020 at 6:25 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> To be clear, I think Rui's solution is perfectly fine and probably better than what I offer below. But just for fun, I wanted to do it without the lapply().  Here is one way. I think my comments suffice to explain.
>
> > ## which are the  non "_" indices?
> > wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
> > ## paste "_." to these
> > F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
> > ## Now strsplit() and unlist() them to get a vector
> > z <- unlist(strsplit(F1$text, "_"))
> > ## now cbind() to the data frame
> > F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
> > F1
>   ID1 ID2   text    1  2
> 1  A1  B1 NONE_. NONE  .
> 2  A1  B1  cf_12   cf 12
> 3  A1  B1 NONE_. NONE  .
> 4  A2  B2  X2_25   X2 25
> 5  A2  B3  fd_15   fd 15
> >## You can change the names of the 2 columns yourself
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> A base R solution with strsplit, like in your code.
>>
>> F1$Y1 <- +grepl("_", F1$text)
>>
>> tmp <- strsplit(as.character(F1$text), "_")
>> tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
>> tmp <- do.call(rbind, tmp)
>> colnames(tmp) <- c("X1", "X2")
>> F1 <- cbind(F1[-3], tmp)    # remove the original column
>> rm(tmp)
>>
>> F1
>> #  ID1 ID2 Y1   X1 X2
>> #1  A1  B1  0 NONE  .
>> #2  A1  B1  1   cf 12
>> #3  A1  B1  0 NONE  .
>> #4  A2  B2  1   X2 25
>> #5  A2  B3  1   fd 15
>>
>>
>> Note that cbind dispatches on F1, an object of class "data.frame".
>> Therefore it's the method cbind.data.frame that is called and the result
>> is also a df, though tmp is a "matrix".
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> ?s 20:07 de 22/09/20, Rui Barradas escreveu:
>> > Hello,
>> >
>> > Something like this?
>> >
>> >
>> > F1$Y1 <- +grepl("_", F1$text)
>> > F1 <- F1[c(1, 2, 4, 3)]
>> > F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill =
>> > "right")
>> > F1
>> >
>> >
>> > Hope this helps,
>> >
>> > Rui Barradas
>> >
>> > ?s 19:55 de 22/09/20, Val escreveu:
>> >> HI All,
>> >>
>> >> I am trying to create   new columns based on another column string
>> >> content. First I want to identify rows that contain a particular
>> >> string.  If it contains, I want to split the string and create two
>> >> variables.
>> >>
>> >> Here is my sample of data.
>> >> F1<-read.table(text="ID1  ID2  text
>> >> A1 B1   NONE
>> >> A1 B1   cf_12
>> >> A1 B1   NONE
>> >> A2 B2   X2_25
>> >> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
>> >> If the variable "text" contains this "_" I want to create an indicator
>> >> variable as shown below
>> >>
>> >> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
>> >>
>> >>
>> >> Then I want to split that string in to two, before "_" and after "_"
>> >> and create two variables as shown below
>> >> x1= strsplit(as.character(F1$text),'_',2)
>> >>
>> >> My problem is how to combine this with the original data frame. The
>> >> desired  output is shown   below,
>> >>
>> >>
>> >> ID1 ID2  Y1   X1    X2
>> >> A1  B1    0   NONE   .
>> >> A1  B1   1    cf        12
>> >> A1  B1   0  NONE   .
>> >> A2  B2   1    X2    25
>> >> A2  B3   1    fd    15
>> >>
>> >> Any help?
>> >> Thank you.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 23 02:19:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 22 Sep 2020 17:19:26 -0700
Subject: [R] Split
In-Reply-To: <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
 <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>
Message-ID: <CAGxFJbQVyMDd7NRAEB=BvCGPmg08fvfOoijUea5DgTNJqM6myw@mail.gmail.com>

Oh, if efficiency is a consideration, then my code is about 15 times as
fast as Rui's:
> F2 <- F1[rep(1:5,1e6),]  ## 5 million rows
##Rui's
> system.time({
+     F2$Y1 <- +grepl("_", F2$text)
+     tmp <- strsplit(as.character(F2$text), "_")
+     tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
+     tmp <- do.call(rbind, tmp)
+     colnames(tmp) <- c("X1", "X2")
+     F2 <- cbind(F2[-3], tmp)    # remove the original column
+ })
   user  system elapsed
 20.072   0.625  20.786

## my version
> system.time({
+     wh <- grep("_",F2$text, fixed = TRUE, invert = TRUE)
+     F2[wh,"text"] <- paste(F2[wh,"text"],".",sep = "_")
+     z <- unlist(strsplit(F1$text,"_"))
+     F2 <- cbind(F2, matrix(z, ncol = 2, byrow = TRUE))
+     F2
+ })
   user  system elapsed
  1.256   0.019   1.281

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 22, 2020 at 5:04 PM Val <valkremk at gmail.com> wrote:

> Thank you all for the help!
>
> LMH, Yes I would like to see the alternative.  I am using this for a
> large data set and if the  alternative is more efficient than this
> then I would be happy.
>
> On Tue, Sep 22, 2020 at 6:25 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > To be clear, I think Rui's solution is perfectly fine and probably
> better than what I offer below. But just for fun, I wanted to do it without
> the lapply().  Here is one way. I think my comments suffice to explain.
> >
> > > ## which are the  non "_" indices?
> > > wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
> > > ## paste "_." to these
> > > F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
> > > ## Now strsplit() and unlist() them to get a vector
> > > z <- unlist(strsplit(F1$text, "_"))
> > > ## now cbind() to the data frame
> > > F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
> > > F1
> >   ID1 ID2   text    1  2
> > 1  A1  B1 NONE_. NONE  .
> > 2  A1  B1  cf_12   cf 12
> > 3  A1  B1 NONE_. NONE  .
> > 4  A2  B2  X2_25   X2 25
> > 5  A2  B3  fd_15   fd 15
> > >## You can change the names of the 2 columns yourself
> >
> > Cheers,
> > Bert
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >>
> >> Hello,
> >>
> >> A base R solution with strsplit, like in your code.
> >>
> >> F1$Y1 <- +grepl("_", F1$text)
> >>
> >> tmp <- strsplit(as.character(F1$text), "_")
> >> tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
> >> tmp <- do.call(rbind, tmp)
> >> colnames(tmp) <- c("X1", "X2")
> >> F1 <- cbind(F1[-3], tmp)    # remove the original column
> >> rm(tmp)
> >>
> >> F1
> >> #  ID1 ID2 Y1   X1 X2
> >> #1  A1  B1  0 NONE  .
> >> #2  A1  B1  1   cf 12
> >> #3  A1  B1  0 NONE  .
> >> #4  A2  B2  1   X2 25
> >> #5  A2  B3  1   fd 15
> >>
> >>
> >> Note that cbind dispatches on F1, an object of class "data.frame".
> >> Therefore it's the method cbind.data.frame that is called and the result
> >> is also a df, though tmp is a "matrix".
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> ?s 20:07 de 22/09/20, Rui Barradas escreveu:
> >> > Hello,
> >> >
> >> > Something like this?
> >> >
> >> >
> >> > F1$Y1 <- +grepl("_", F1$text)
> >> > F1 <- F1[c(1, 2, 4, 3)]
> >> > F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill
> =
> >> > "right")
> >> > F1
> >> >
> >> >
> >> > Hope this helps,
> >> >
> >> > Rui Barradas
> >> >
> >> > ?s 19:55 de 22/09/20, Val escreveu:
> >> >> HI All,
> >> >>
> >> >> I am trying to create   new columns based on another column string
> >> >> content. First I want to identify rows that contain a particular
> >> >> string.  If it contains, I want to split the string and create two
> >> >> variables.
> >> >>
> >> >> Here is my sample of data.
> >> >> F1<-read.table(text="ID1  ID2  text
> >> >> A1 B1   NONE
> >> >> A1 B1   cf_12
> >> >> A1 B1   NONE
> >> >> A2 B2   X2_25
> >> >> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
> >> >> If the variable "text" contains this "_" I want to create an
> indicator
> >> >> variable as shown below
> >> >>
> >> >> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
> >> >>
> >> >>
> >> >> Then I want to split that string in to two, before "_" and after "_"
> >> >> and create two variables as shown below
> >> >> x1= strsplit(as.character(F1$text),'_',2)
> >> >>
> >> >> My problem is how to combine this with the original data frame. The
> >> >> desired  output is shown   below,
> >> >>
> >> >>
> >> >> ID1 ID2  Y1   X1    X2
> >> >> A1  B1    0   NONE   .
> >> >> A1  B1   1    cf        12
> >> >> A1  B1   0  NONE   .
> >> >> A2  B2   1    X2    25
> >> >> A2  B3   1    fd    15
> >> >>
> >> >> Any help?
> >> >> Thank you.
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Wed Sep 23 02:45:04 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 22 Sep 2020 17:45:04 -0700
Subject: [R] Split
In-Reply-To: <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
Message-ID: <CAHqSRuSi+ZhX9JU5GmdpYwxVaOBTPvz48AWAo2bjP=xBPnYDNA@mail.gmail.com>

Another way to make columns out of the stuff before and after the
underscore, with NAs if there is no underscore, is

utils::strcapture("([^_]*)_(.*)", F1$text,
proto=data.frame(Before_=character(), After_=character()))

-Bill

On Tue, Sep 22, 2020 at 4:25 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> To be clear, I think Rui's solution is perfectly fine and probably better
> than what I offer below. But just for fun, I wanted to do it without the
> lapply().  Here is one way. I think my comments suffice to explain.
>
> > ## which are the  non "_" indices?
> > wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
> > ## paste "_." to these
> > F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
> > ## Now strsplit() and unlist() them to get a vector
> > z <- unlist(strsplit(F1$text, "_"))
> > ## now cbind() to the data frame
> > F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
> > F1
>   ID1 ID2   text    1  2
> 1  A1  B1 NONE_. NONE  .
> 2  A1  B1  cf_12   cf 12
> 3  A1  B1 NONE_. NONE  .
> 4  A2  B2  X2_25   X2 25
> 5  A2  B3  fd_15   fd 15
> >## You can change the names of the 2 columns yourself
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
>
> > Hello,
> >
> > A base R solution with strsplit, like in your code.
> >
> > F1$Y1 <- +grepl("_", F1$text)
> >
> > tmp <- strsplit(as.character(F1$text), "_")
> > tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
> > tmp <- do.call(rbind, tmp)
> > colnames(tmp) <- c("X1", "X2")
> > F1 <- cbind(F1[-3], tmp)    # remove the original column
> > rm(tmp)
> >
> > F1
> > #  ID1 ID2 Y1   X1 X2
> > #1  A1  B1  0 NONE  .
> > #2  A1  B1  1   cf 12
> > #3  A1  B1  0 NONE  .
> > #4  A2  B2  1   X2 25
> > #5  A2  B3  1   fd 15
> >
> >
> > Note that cbind dispatches on F1, an object of class "data.frame".
> > Therefore it's the method cbind.data.frame that is called and the result
> > is also a df, though tmp is a "matrix".
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ?s 20:07 de 22/09/20, Rui Barradas escreveu:
> > > Hello,
> > >
> > > Something like this?
> > >
> > >
> > > F1$Y1 <- +grepl("_", F1$text)
> > > F1 <- F1[c(1, 2, 4, 3)]
> > > F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill =
> > > "right")
> > > F1
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > ?s 19:55 de 22/09/20, Val escreveu:
> > >> HI All,
> > >>
> > >> I am trying to create   new columns based on another column string
> > >> content. First I want to identify rows that contain a particular
> > >> string.  If it contains, I want to split the string and create two
> > >> variables.
> > >>
> > >> Here is my sample of data.
> > >> F1<-read.table(text="ID1  ID2  text
> > >> A1 B1   NONE
> > >> A1 B1   cf_12
> > >> A1 B1   NONE
> > >> A2 B2   X2_25
> > >> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
> > >> If the variable "text" contains this "_" I want to create an indicator
> > >> variable as shown below
> > >>
> > >> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
> > >>
> > >>
> > >> Then I want to split that string in to two, before "_" and after "_"
> > >> and create two variables as shown below
> > >> x1= strsplit(as.character(F1$text),'_',2)
> > >>
> > >> My problem is how to combine this with the original data frame. The
> > >> desired  output is shown   below,
> > >>
> > >>
> > >> ID1 ID2  Y1   X1    X2
> > >> A1  B1    0   NONE   .
> > >> A1  B1   1    cf        12
> > >> A1  B1   0  NONE   .
> > >> A2  B2   1    X2    25
> > >> A2  B3   1    fd    15
> > >>
> > >> Any help?
> > >> Thank you.
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 23 03:47:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 22 Sep 2020 18:47:21 -0700
Subject: [R] Split
In-Reply-To: <CAHqSRuSi+ZhX9JU5GmdpYwxVaOBTPvz48AWAo2bjP=xBPnYDNA@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
 <CAHqSRuSi+ZhX9JU5GmdpYwxVaOBTPvz48AWAo2bjP=xBPnYDNA@mail.gmail.com>
Message-ID: <CAGxFJbRh+XECXWQL=Snz2BepUp+DG+SbdGVRFiprgbFqKFhG=Q@mail.gmail.com>

That was still slower and doesn't quite give what was requested:

> cbind(F1,utils::strcapture("([^_]*)_(.*)", F1$text,
proto=data.frame(Before_=character(), After_=character())))
  ID1 ID2  text Before_ After_
1  A1  B1  NONE    <NA>   <NA>
2  A1  B1 cf_12      cf     12
3  A1  B1  NONE    <NA>   <NA>
4  A2  B2 X2_25      X2     25
5  A2  B3 fd_15      fd     15

> system.time({
+ cbind(F2,utils::strcapture("([^_]*)_(.*)", F2$text,
proto=data.frame(Before_=character(), After_=character())))
+ }
+ )
   user  system elapsed
 32.712   0.736  33.587

Cheers,
Bert




On Tue, Sep 22, 2020 at 5:45 PM Bill Dunlap <williamwdunlap at gmail.com>
wrote:

> Another way to make columns out of the stuff before and after the
> underscore, with NAs if there is no underscore, is
>
> utils::strcapture("([^_]*)_(.*)", F1$text,
> proto=data.frame(Before_=character(), After_=character()))
>
> -Bill
>
> On Tue, Sep 22, 2020 at 4:25 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> To be clear, I think Rui's solution is perfectly fine and probably better
>> than what I offer below. But just for fun, I wanted to do it without the
>> lapply().  Here is one way. I think my comments suffice to explain.
>>
>> > ## which are the  non "_" indices?
>> > wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
>> > ## paste "_." to these
>> > F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
>> > ## Now strsplit() and unlist() them to get a vector
>> > z <- unlist(strsplit(F1$text, "_"))
>> > ## now cbind() to the data frame
>> > F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
>> > F1
>>   ID1 ID2   text    1  2
>> 1  A1  B1 NONE_. NONE  .
>> 2  A1  B1  cf_12   cf 12
>> 3  A1  B1 NONE_. NONE  .
>> 4  A2  B2  X2_25   X2 25
>> 5  A2  B3  fd_15   fd 15
>> >## You can change the names of the 2 columns yourself
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>>
>> > Hello,
>> >
>> > A base R solution with strsplit, like in your code.
>> >
>> > F1$Y1 <- +grepl("_", F1$text)
>> >
>> > tmp <- strsplit(as.character(F1$text), "_")
>> > tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
>> > tmp <- do.call(rbind, tmp)
>> > colnames(tmp) <- c("X1", "X2")
>> > F1 <- cbind(F1[-3], tmp)    # remove the original column
>> > rm(tmp)
>> >
>> > F1
>> > #  ID1 ID2 Y1   X1 X2
>> > #1  A1  B1  0 NONE  .
>> > #2  A1  B1  1   cf 12
>> > #3  A1  B1  0 NONE  .
>> > #4  A2  B2  1   X2 25
>> > #5  A2  B3  1   fd 15
>> >
>> >
>> > Note that cbind dispatches on F1, an object of class "data.frame".
>> > Therefore it's the method cbind.data.frame that is called and the result
>> > is also a df, though tmp is a "matrix".
>> >
>> >
>> > Hope this helps,
>> >
>> > Rui Barradas
>> >
>> >
>> > ?s 20:07 de 22/09/20, Rui Barradas escreveu:
>> > > Hello,
>> > >
>> > > Something like this?
>> > >
>> > >
>> > > F1$Y1 <- +grepl("_", F1$text)
>> > > F1 <- F1[c(1, 2, 4, 3)]
>> > > F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill
>> =
>> > > "right")
>> > > F1
>> > >
>> > >
>> > > Hope this helps,
>> > >
>> > > Rui Barradas
>> > >
>> > > ?s 19:55 de 22/09/20, Val escreveu:
>> > >> HI All,
>> > >>
>> > >> I am trying to create   new columns based on another column string
>> > >> content. First I want to identify rows that contain a particular
>> > >> string.  If it contains, I want to split the string and create two
>> > >> variables.
>> > >>
>> > >> Here is my sample of data.
>> > >> F1<-read.table(text="ID1  ID2  text
>> > >> A1 B1   NONE
>> > >> A1 B1   cf_12
>> > >> A1 B1   NONE
>> > >> A2 B2   X2_25
>> > >> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
>> > >> If the variable "text" contains this "_" I want to create an
>> indicator
>> > >> variable as shown below
>> > >>
>> > >> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
>> > >>
>> > >>
>> > >> Then I want to split that string in to two, before "_" and after "_"
>> > >> and create two variables as shown below
>> > >> x1= strsplit(as.character(F1$text),'_',2)
>> > >>
>> > >> My problem is how to combine this with the original data frame. The
>> > >> desired  output is shown   below,
>> > >>
>> > >>
>> > >> ID1 ID2  Y1   X1    X2
>> > >> A1  B1    0   NONE   .
>> > >> A1  B1   1    cf        12
>> > >> A1  B1   0  NONE   .
>> > >> A2  B2   1    X2    25
>> > >> A2  B3   1    fd    15
>> > >>
>> > >> Any help?
>> > >> Thank you.
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >>
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Wed Sep 23 08:11:22 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 23 Sep 2020 18:11:22 +1200
Subject: [R] Quadratic programming
In-Reply-To: <CAJxz9NYoeM_eYqVOg6g65TgHenoANNrkMfDB+whddrT5hYXgmg@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepwwT3sqmnYt43bE3VrSUMjxnSAdrFV9LoiLHXwSjWSM5Q@mail.gmail.com>
 <CAB8pepwZQ1=q25DkT859Fo-EBYjiCA9GJGfP739+QC=NgAfw6g@mail.gmail.com>
 <CAJxz9NYoeM_eYqVOg6g65TgHenoANNrkMfDB+whddrT5hYXgmg@mail.gmail.com>
Message-ID: <CAB8pepxwY6HidhOhhxXya997wJdkOPk-X6z9fY7mrAACB6VSTQ@mail.gmail.com>

> I'm trying to replicate a C++ code with R.

Notes:
(1) I'd recommend you make the code more modular.
i.e. One function for initial data prep/modelling, one function for
setting up and solving the QP, etc.
This should be easier to debug.
(However, you would probably have to do it to the C++ code first).
(2) Your R code is not completely reproducible.
i.e. AEJData
(3) For the purposes of a reproducible example, your code can be simplified.
i.e. Only one contributed R package should be attached.

Regardless of (1) above, you should be able to identify at what point
the C++ and R code becomes inconsistent.
The simplest approach is to add print-based functions into both the
C++ and R code, and print out state data, at each major step.
Then all you need to do is compare the output for both.

> Is there a better/another package for these types of problems?

I'm not sure.
After a quick search, this is the best I found:

scam::scam
scam::shape.constrained.smooth.terms


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 23 12:58:58 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 23 Sep 2020 11:58:58 +0100
Subject: [R] Split
In-Reply-To: <CAGxFJbRh+XECXWQL=Snz2BepUp+DG+SbdGVRFiprgbFqKFhG=Q@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
 <CAHqSRuSi+ZhX9JU5GmdpYwxVaOBTPvz48AWAo2bjP=xBPnYDNA@mail.gmail.com>
 <CAGxFJbRh+XECXWQL=Snz2BepUp+DG+SbdGVRFiprgbFqKFhG=Q@mail.gmail.com>
Message-ID: <d8400a05-1a71-2c0b-653c-b12831d4fc70@sapo.pt>

Hello,

If speed is important, and following the previous discussion and Bert's 
tests, here are two other alternatives, both faster.

1. Bert2 is Bert's original but with scan(., sep = "_") substituted for 
unlist/strsplit.
2. A package data.table solution. These are always fast, many times the 
fastest. But have the inconvenience of coercing the data to class 
"data.table" and the rest of the code needs to be adapted to handle 
data.tables. Namely, the second index in dt[i, j] is no longer a column 
index.

Unlike Bert, I time my first code, the one with package tidyr and its 
performance clearly beats the second one.
I define a test function, running several input sizes. It doesn't take 
much time to complete, only several minutes. The times' differences are 
not as impressive as Bert's, probably due to be on a different OS. I'm 
running R 4.0.2 on Ubuntu 20.04, sessionInfo at the end.

Also, I find X$Y1 <- as.integer(grepl("_", X$text)) more readable than 
coercion to numeric with +grepl(.).



library(data.table)
library(microbenchmark)
library(ggplot2)

Rui1 <- function(X){
   #X$Y1 <- as.integer(grepl("_", X$text))
   tidyr::separate(X, text, into = c("X1", "X2"), sep = "_", fill = "right")
}
Bert <- function(X){
   ## which are the  non "_" indices?
   wh <- grep("_",X$text, fixed = TRUE, invert = TRUE)
   ## paste "_." to these
   X[wh,"text"] <- paste(X[wh,"text"],".",sep = "_")
   ## Now strsplit() and unlist() them to get a vector
   z <- unlist(strsplit(X$text, "_"))
   ## now cbind() to the data frame
   cbind(X, matrix(z, ncol = 2, byrow = TRUE))
}
Bert2 <- function(X){
   wh <- grep("_",X$text, fixed = TRUE, invert = TRUE)
   X[wh,"text"] <- paste(X[wh,"text"],".",sep = "_")
   z <- scan(what = character(), text = X$text, sep = "_")
   cbind(X, matrix(z, ncol = 2, byrow = TRUE))
}
DT <- function(X){
   Y <- as.data.table(X)
   Y[, c("X1", "X2") := tstrsplit(text, "_", fixed = TRUE)]
}

testSeparate <- function(X, size = 0:6, times = 10){
   row_nums <- seq_len(nrow(X))
   res <- lapply(size, function(s){
     Y <- X[rep(row_nums, 10^s), ]
     mb <- microbenchmark(
       Rui = Rui1(Y),
       Bert = Bert(Y),
       Bert2 = Bert2(Y),
       DT = DT(Y),
       times = times
     )
     mb$size <- s
     mb
   })
   # return median times
   res <- do.call(rbind, res)
   aggregate(time ~ size + expr, res, median)
}

F1 <- read.table(text="ID1  ID2  text
A1 B1   NONE
A1 B1   cf_12
A1 B1   NONE
A2 B2   X2_25
A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)

agg <- testSeparate(F1, times = 5)

ggplot(agg, aes(size, time, color = expr)) +
   geom_line() + geom_point() +
   scale_y_continuous(trans = "log10") +
   xlab(expression(log[10] ~ "(size)")) +
   ylab(expression(log[10] ~ "(time)"))


sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.1 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_3.3.2        microbenchmark_1.4-7 data.table_1.12.8

loaded via a namespace (and not attached):
  [1] Rcpp_1.0.5       magrittr_1.5     tidyselect_1.1.0 munsell_0.5.0
  [5] colorspace_1.4-1 R6_2.4.1         rlang_0.4.7      dplyr_1.0.2
  [9] tools_4.0.2      grid_4.0.2       gtable_0.3.0     withr_2.2.0
[13] ellipsis_0.3.1   digest_0.6.25    tibble_3.0.3     lifecycle_0.2.0
[17] crayon_1.3.4     purrr_0.3.4      farver_2.0.3     tidyr_1.0.2
[21] vctrs_0.3.4      glue_1.4.2       labeling_0.3     stringi_1.4.6
[25] compiler_4.0.2   pillar_1.4.6     generics_0.0.2   scales_1.1.0
[29] pkgconfig_2.0.3


Hope this helps,

Rui Barradas


?s 02:47 de 23/09/20, Bert Gunter escreveu:
> That was still slower and doesn't quite give what was requested:
> 
>  > cbind(F1,utils::strcapture("([^_]*)_(.*)", F1$text, 
> proto=data.frame(Before_=character(), After_=character())))
>  ? ID1 ID2 ?text Before_ After_
> 1 ?A1 ?B1 ?NONE ? ?<NA> ? <NA>
> 2 ?A1 ?B1 cf_12 ? ? ?cf ? ? 12
> 3 ?A1 ?B1 ?NONE ? ?<NA> ? <NA>
> 4 ?A2 ?B2 X2_25 ? ? ?X2 ? ? 25
> 5 ?A2 ?B3 fd_15 ? ? ?fd ? ? 15
> 
>  > system.time({
> + cbind(F2,utils::strcapture("([^_]*)_(.*)", F2$text, 
> proto=data.frame(Before_=character(), After_=character())))
> + }
> + )
>  ? ?user ?system elapsed
>  ?32.712 ? 0.736 ?33.587
> 
> Cheers,
> Bert
> 
> 
> 
> 
> On Tue, Sep 22, 2020 at 5:45 PM Bill Dunlap <williamwdunlap at gmail.com 
> <mailto:williamwdunlap at gmail.com>> wrote:
> 
>     Another way to make columns out of the stuff before and after the
>     underscore, with NAs if there is no underscore, is
> 
>     utils::strcapture("([^_]*)_(.*)", F1$text,
>     proto=data.frame(Before_=character(), After_=character()))
> 
>     -Bill
> 
>     On Tue, Sep 22, 2020 at 4:25 PM Bert Gunter <bgunter.4567 at gmail.com
>     <mailto:bgunter.4567 at gmail.com>> wrote:
> 
>         To be clear, I think Rui's solution is perfectly fine and
>         probably better
>         than what I offer below. But just for fun, I wanted to do it
>         without the
>         lapply().? Here is one way. I think my comments suffice to explain.
> 
>          > ## which are the? non "_" indices?
>          > wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
>          > ## paste "_." to these
>          > F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
>          > ## Now strsplit() and unlist() them to get a vector
>          > z <- unlist(strsplit(F1$text, "_"))
>          > ## now cbind() to the data frame
>          > F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
>          > F1
>          ? ID1 ID2? ?text? ? 1? 2
>         1? A1? B1 NONE_. NONE? .
>         2? A1? B1? cf_12? ?cf 12
>         3? A1? B1 NONE_. NONE? .
>         4? A2? B2? X2_25? ?X2 25
>         5? A2? B3? fd_15? ?fd 15
>          >## You can change the names of the 2 columns yourself
> 
>         Cheers,
>         Bert
> 
>         Bert Gunter
> 
>         "The trouble with having an open mind is that people keep coming
>         along and
>         sticking things into it."
>         -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>         On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas
>         <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>          > Hello,
>          >
>          > A base R solution with strsplit, like in your code.
>          >
>          > F1$Y1 <- +grepl("_", F1$text)
>          >
>          > tmp <- strsplit(as.character(F1$text), "_")
>          > tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".")
>         else x)
>          > tmp <- do.call(rbind, tmp)
>          > colnames(tmp) <- c("X1", "X2")
>          > F1 <- cbind(F1[-3], tmp)? ? # remove the original column
>          > rm(tmp)
>          >
>          > F1
>          > #? ID1 ID2 Y1? ?X1 X2
>          > #1? A1? B1? 0 NONE? .
>          > #2? A1? B1? 1? ?cf 12
>          > #3? A1? B1? 0 NONE? .
>          > #4? A2? B2? 1? ?X2 25
>          > #5? A2? B3? 1? ?fd 15
>          >
>          >
>          > Note that cbind dispatches on F1, an object of class
>         "data.frame".
>          > Therefore it's the method cbind.data.frame that is called and
>         the result
>          > is also a df, though tmp is a "matrix".
>          >
>          >
>          > Hope this helps,
>          >
>          > Rui Barradas
>          >
>          >
>          > ?s 20:07 de 22/09/20, Rui Barradas escreveu:
>          > > Hello,
>          > >
>          > > Something like this?
>          > >
>          > >
>          > > F1$Y1 <- +grepl("_", F1$text)
>          > > F1 <- F1[c(1, 2, 4, 3)]
>          > > F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep =
>         "_", fill =
>          > > "right")
>          > > F1
>          > >
>          > >
>          > > Hope this helps,
>          > >
>          > > Rui Barradas
>          > >
>          > > ?s 19:55 de 22/09/20, Val escreveu:
>          > >> HI All,
>          > >>
>          > >> I am trying to create? ?new columns based on another
>         column string
>          > >> content. First I want to identify rows that contain a
>         particular
>          > >> string.? If it contains, I want to split the string and
>         create two
>          > >> variables.
>          > >>
>          > >> Here is my sample of data.
>          > >> F1<-read.table(text="ID1? ID2? text
>          > >> A1 B1? ?NONE
>          > >> A1 B1? ?cf_12
>          > >> A1 B1? ?NONE
>          > >> A2 B2? ?X2_25
>          > >> A2 B3? ?fd_15? ",header=TRUE,stringsAsFactors=F)
>          > >> If the variable "text" contains this "_" I want to create
>         an indicator
>          > >> variable as shown below
>          > >>
>          > >> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
>          > >>
>          > >>
>          > >> Then I want to split that string in to two, before "_" and
>         after "_"
>          > >> and create two variables as shown below
>          > >> x1= strsplit(as.character(F1$text),'_',2)
>          > >>
>          > >> My problem is how to combine this with the original data
>         frame. The
>          > >> desired? output is shown? ?below,
>          > >>
>          > >>
>          > >> ID1 ID2? Y1? ?X1? ? X2
>          > >> A1? B1? ? 0? ?NONE? ?.
>          > >> A1? B1? ?1? ? cf? ? ? ? 12
>          > >> A1? B1? ?0? NONE? ?.
>          > >> A2? B2? ?1? ? X2? ? 25
>          > >> A2? B3? ?1? ? fd? ? 15
>          > >>
>          > >> Any help?
>          > >> Thank you.
>          > >>
>          > >> ______________________________________________
>          > >> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>          > >> https://stat.ethz.ch/mailman/listinfo/r-help
>          > >> PLEASE do read the posting guide
>          > >> http://www.R-project.org/posting-guide.html
>          > >> and provide commented, minimal, self-contained,
>         reproducible code.
>          > >>
>          > >
>          > > ______________________________________________
>          > > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>          > > https://stat.ethz.ch/mailman/listinfo/r-help
>          > > PLEASE do read the posting guide
>          > > http://www.R-project.org/posting-guide.html
>          > > and provide commented, minimal, self-contained,
>         reproducible code.
>          >
>          > ______________________________________________
>          > R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>          > https://stat.ethz.ch/mailman/listinfo/r-help
>          > PLEASE do read the posting guide
>          > http://www.R-project.org/posting-guide.html
>          > and provide commented, minimal, self-contained, reproducible
>         code.
>          >
> 
>          ? ? ? ? [[alternative HTML version deleted]]
> 
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible code.
>


From pd@|gd @end|ng |rom gm@||@com  Wed Sep 23 13:28:49 2020
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Wed, 23 Sep 2020 13:28:49 +0200
Subject: [R] 
 open file on R GUI results in spinning wheel and frozen R - Mac OS
In-Reply-To: <905502A1-8AA0-4D88-8CF7-2B4F334A0DE9@xs4all.nl>
References: <1306BFEA-EB5B-42DE-B353-E0F860A023C9@gmail.com>
 <905502A1-8AA0-4D88-8CF7-2B4F334A0DE9@xs4all.nl>
Message-ID: <E35F7824-BC70-424F-9B62-69C1BEA05D4E@gmail.com>

...or try R-patched, which I'm told has the newer GUI.

-pd

> On 21 Sep 2020, at 21:43 , Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
> 
>> On 21 Sep 2020, at 20:24, Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
>> 
>> Hello,
>> 
>> I?ve been using R-studio for a while and today I needed to try something directly on the R-GUI.
>> 
>> But when I try to open any *.R file I get a spinning wheel and R freezes. I can only shut it down with ?force quit?.
>> 
>> I have deleted and re-installed R three times, each time trying to run a more thorough uninstall, but the problem persists.
>> 
>> I am using Mac OS Catalina 10.15.6 and the latest version of R ->  R 4.0.2 GUI 1.72 Catalina build (7847)
>> 
>> Strangely, as this problem was happening on the R GUI, I was still able to open R scripts on RStudio. But now I uninstalled RStudio as well, in the latest attempt to start from scratch.
>> 
>> Is this problem familiar to anyone?
>> 
> 
> See this thread on the R-SIG-Mac list: https://stat.ethz.ch/pipermail/r-sig-mac/2020-June/013575.html
> and her for a solution (sequel of above): https://stat.ethz.ch/pipermail/r-sig-mac/2020-July/013641.html
> 
> Go to https://mac.r-project.org/ and get the latest revision of the R GUI which is noe https://mac.r-project.org/high-sierra/R-4.0-branch/R-GUI-7884-4.0-high-sierra-Release.dmg
> 
> I have revision 7849; if the above does not work I can mail you the dmg of revision 7849.
> 
> Berend
> 
> 
> 
>> Thanks for any help,
>> 
>> Gon?alo
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Sep 23 14:47:34 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 23 Sep 2020 14:47:34 +0200
Subject: [R] package plotrix: how to account for two two z categories
Message-ID: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>

Hello,
I have an experiment measuring optical density (OD) when comparing
three parameters:
a) concentration of the target
b) concentration of the probe
c) concentration of the reporter antibody.
Using plotrix I can nicely draw the first two into clusters, but I
can't get separation for the third parameter. is there a way in
plotrix to custer data according to two, let's say, z parameters (I
call the second high-level parameter as w)? For instance, two
clusters, each separated into two subclusters. Or is this more a job
for lattice?
Thank you.

```
x = rep(c(rep("1000 pmol", 4), rep("0 pmol", 4)),2)
z =  rep(c(rep("Treated", 2), rep("Untreated", 2), rep("Treated", 2),
rep("Untreated", 2)))
w = c(rep("1:1000", 8), rep("1:2000", 8))
y = c(1.18, 1.22, 1.52, 2.37, 0.97, 1.08, 1.17, 1.58, 1.16, 1.16, 2.27, 2.24,
      1.26, 1.28, 1.39, 1.77)
Q = data.frame(x, z, w, y, stringsAsFactors = FALSE)
names(Q) = c("[Target]", "Enzyme", "[Antibody]", "OD")
names(Q) = c("x", "z", "w", "y") # for ease, I'll use single letters
library(plotrix)
brkdn.plot(y~x+z, data=Q,
           pch = c(1, 16), cex = 1.5, type="p",
           main="Single Measurement",
           xlab=expression(bold("S1 nuclease")),
           ylab=expression(bold("Optical density")))
brkdn.plot(y~x+z+w, data=Q,
           pch = c(1, 16), cex = 1.5, type="p",
           main="Double Measurement",
           xlab=expression(bold("S1 nuclease")),
           ylab=expression(bold("Optical density")))
```


From m@rt|n@ke||er-re@@e| @end|ng |rom tu-dre@den@de  Wed Sep 23 12:32:40 2020
From: m@rt|n@ke||er-re@@e| @end|ng |rom tu-dre@den@de (Martin Keller-Ressel)
Date: Wed, 23 Sep 2020 10:32:40 +0000
Subject: [R] jitter-bug? problematic behaviour of the jitter function
Message-ID: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>

Dear all,

i have noticed some strange behaviour in the ?jitter? function in R.
On the help page for jitter it is stated that

"The result, say r, is r <- x + runif(n, -a, a) where n <- length(x) and a is the amount argument (if specified).?

and

"If amount is NULL (default), we set a <- factor * d/5 where d is the smallest difference between adjacent unique (apart from fuzz) x values.?

This works fine as long as there is no (very) large outlier

> jitter(c(1,2,10^4))  # desired behaviour
[1]    1.083243    1.851571 9999.942716

But for very large outliers the added noise suddenly ?jumps? to a much larger scale:

> jitter(c(1,2,10^5)) # bad behaviour
[1] -19535.649   9578.702 115693.854
# Noise should be of order (2-1)/5  = 0.2 but is of much larger order.

This probably does not matter much when jitter is used for plotting, but it can cause problems when jitter is used to break ties.

best regards,
Martin

--------------------------------
Martin Keller-Ressel
Professor f?r Stochastische Analysis und Finanzmathematik
Technische Universit?t Dresden
Institut f?r Mathematische Stochastik
Willersbau B 316, Zellescher Weg 12-14
01062 Dresden
--------------------------------


	[[alternative HTML version deleted]]


From kev|neg@n31 @end|ng |rom gm@||@com  Wed Sep 23 16:32:30 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Wed, 23 Sep 2020 15:32:30 +0100
Subject: [R] Issues with lapply and for loop Compared to Running Function
Message-ID: <F5360C06-3BF6-482B-86C5-5DC62B0E7556@gmail.com>

Hello,

I?d like to apologise as I understand that this is a significant amount of code, but I am struggling to understand why my code develops an error when running. I have been able to obtain results for the list of matrices named xdot and ydot but am struggling with zdot as I keep getting the error "Error in seq.default(sbeta) : 'from' must be a finite number ? when trying to run either a for loop or lapply through the list of matrices. However, when I run the the bootstrap function on one of the many matrices it provides results. Is there a way to fix this issue? I?m confused as to why it works normally but not when running lapply or a for loop

set.seed(123)    # seed for reproducibility
library(boot)
library(np) # used for b.star
library(dplyr) # Used for Centering and Standardizing
library(deSolve) # ODE
library(lars)

# linear 3D system
Linear3D_derivative <- function(n, eta, polyorder){
 n <- round(n, 0)
 # n = number of time points rounded to nearest integer
 # noise = noise to be added
 # polyorder = degree of polynomial
 times.3D <- seq(0, ((n)-1)*0.01, by = 0.01)
 A.linear3D <- matrix(c(-0.1, -2, 0,
                        2, -0.1, 0, 
                        0, 0, -0.3), 3, 3) 
 state.linear3D <- c(X = 2, Y = 0, Z = 1) 
 linear3D <- function(t, A, b) {
   with(as.list(c(A, b)), {
     dX <- A %*% b
     list(c(dX))
   })
 }
 out.linear3D <- ode(y = state.linear3D, times = times.3D, 
                     func = linear3D, parms = A.linear3D)

 out.linear3D <- out.linear3D[,-1]
 out.linear3D.sorted <- data.frame(out.linear3D)[-1]
 out.linear3D.sorted <- out.linear3D[,c(3,2,1)] # Rearrange for Theta matrix: X0.0.1 = x, X0.1.0 = y, X1.0.0 = z

 # Polynomial Expansion
 expanded.theta <- polym(as.matrix(out.linear3D.sorted), degree = polyorder, raw = T)

 # Order by degree using as.numeric_version
 # numeric_version allows to convert names of variables and expand without limit
 ordered.results <- order(attr(expanded.theta, "degree"),
                          as.numeric_version(colnames(expanded.theta)))

 # Sort Theta Matrix
 sorted.theta <- expanded.theta[,ordered.results]
 sorted.theta <- data.frame(sorted.theta)
 # Change Variable Names
 s <- strsplit(substring(colnames(sorted.theta), 2), "\\.")
 colnames(sorted.theta) <- sapply(s, function(x){
   vec <- c("x", "y", "z")[seq_along(x)]
   x <- as.integer(x)
   y <- rep(vec, rev(x))
   paste(y, collapse = "")
 })

 # Add ones column to theta matrix
 sorted.theta <- data.frame(1, sorted.theta)
 # That lost the attributes, so put them back
 attr(sorted.theta, "degree") <- c(0, attr(expanded.theta, "degree")[ordered.results])
 sorted.theta <- sorted.theta[,order(attr(sorted.theta, "degree"), colnames(sorted.theta))]
 # That lost the attributes again, so put them back
 attr(sorted.theta, "degree") <- c(0, attr(expanded.theta, "degree")[ordered.results])

 # Create Derivative matrix
 dx <- matrix(NA, nrow = nrow(out.linear3D.sorted), ncol = ncol(out.linear3D.sorted))
 for (i in 1:nrow(out.linear3D.sorted)){
   # lorenz returns a list with one element. To assign to dx you have extract the list element using [[1]]
   dx[i,] <- linear3D(0, A.linear3D, out.linear3D[i,])[[1]]
 }
 # Add Noise
 length <- nrow(dx) * ncol(dx)
 dx <- dx + eta*matrix(rnorm(length, mean = 0, sd = 1), nrow(dx))

 # Derivative Variables
 xdot <- dx[,1]
 ydot <- dx[,2]
 zdot <- dx[,3]

 # Combine Matrices
 xdot.df <- data.frame(cbind(xdot, sorted.theta))
 ydot.df  <- data.frame(cbind(ydot, sorted.theta))
 zdot.df <- data.frame(cbind(zdot, sorted.theta))

 # Center y, X will be standardized in the modelling function
 y.xdot <- xdot.df %>% dplyr::select(xdot) %>% scale(center = TRUE, scale = FALSE) %>% as.matrix()
 X.xdot <- xdot.df %>% dplyr::select(-xdot) %>% as.matrix()
 xdot.matrix <- as.matrix(cbind(y.xdot,X.xdot))
 colnames(xdot.matrix)[which(colnames(xdot.matrix) == "X1")] <- "1"

 y.ydot <- ydot.df %>% dplyr::select(ydot) %>% scale(center = TRUE, scale = FALSE) %>% as.matrix()
 X.ydot <- ydot.df %>% dplyr::select(-ydot) %>% as.matrix()
 ydot.matrix <- as.matrix(cbind(y.ydot,X.ydot))
 colnames(ydot.matrix)[which(colnames(ydot.matrix) == "X1")] <- "1"

 y.zdot <- zdot.df %>% dplyr::select(zdot) %>% scale(center = TRUE, scale = FALSE) %>% as.matrix()
 X.zdot <- zdot.df %>% dplyr::select(-zdot) %>% as.matrix()
 zdot.matrix <- as.matrix(cbind(y.zdot,X.zdot))
 colnames(zdot.matrix)[which(colnames(zdot.matrix) == "X1")] <- "1"

 return(list(xdot.matrix=xdot.matrix, ydot.matrix = ydot.matrix, zdot.matrix = zdot.matrix, col.names = colnames(X.xdot), 
             degree.theta = attr(sorted.theta, "degree")))
}
# lars alasso step BIC with OLS weights
lars_alasso_OLSweights_fn <- function(data,index){ #index is the bootstrap sample index
 x <- data[index,-1]
 y <- data[index,1]
 m <-ncol(x)
 n <-nrow(x)
 x <- as.matrix(x)
 #  standardize variables like lars does 
 one <- rep(1, n)
 meanx <- drop(one %*% x)/n
 xc <- scale(x, meanx, FALSE)         # first subtracts mean
 xc[,1] <- 1
 normx <- sqrt(drop(one %*% (xc^2)))
 names(normx) <- NULL
 xs <- scale(xc, FALSE, normx)  
 xs[,1] <- 1
 # Perform OLS for weights vector
 out.ls<-lm(y~xs)                      # ols fit on standardized
 beta.ols<-out.ls$coeff[2:(m+1)]       # ols except for intercept
 # Some Coefficients may be NA so make them 0
 beta.ols[is.na(beta.ols)] <- 0
 w<-abs(beta.ols)      
 # Scale x using weights vector
 xs2 <- scale(xs,center=FALSE,scale=1/w)
 xs2[,1] <- 1
 object <- lars(xs2,y,type="lasso",normalize=FALSE)
 bic <- ((log(n)/(n))*object$df)+(as.vector(object$RSS)/(n)) # Tibshirani On the degrees of freedom
 step.bic <- which.min(bic)
 #bic <- log(n)*object$df+n*log(as.vector(object$RSS)/n)
 coeff <- as.vector(coef(object, s = step.bic, mode= "step"))
 # coeff <- predict.lars(object,xs2,s=step.bic,type="coef",mode="step")$coefficients
 # get back in right scale by multiplying by weights vector
 coeff <- coeff*w/normx                 
 coeff[is.na(coeff)] <- 0
 coef <- as.vector(coeff)
 return(coef)
}
# lars alasso step BIC with OLS weights plus OLS post selection
lars_alassoOLS_OLSweights_fn <- function(data,index){ #index is the bootstrap sample index
 x <- data[index,-1]
 y <- data[index,1]
 m <-ncol(x)
 n <-nrow(x)
 x <- as.matrix(x)
 #  standardize variables like lars does 
 one <- rep(1, n)
 meanx <- drop(one %*% x)/n
 xc <- scale(x, meanx, FALSE)         # first subtracts mean
 xc[,1] <- 1
 normx <- sqrt(drop(one %*% (xc^2)))
 names(normx) <- NULL
 xs <- scale(xc, FALSE, normx)  
 xs[,1] <- 1
 # Perform OLS for weights vector
 out.ls<-lm(y~xs)                      # ols fit on standardized
 beta.ols<-out.ls$coeff[2:(m+1)]       # ols except for intercept
 # Some Coefficients may be NA so make them 0
 beta.ols[is.na(beta.ols)] <- 0
 w <- abs(beta.ols)      
 # Scale xs using weights vector
 xs2 <- scale(xs,center=FALSE,scale=1/w)
 xs2[,1] <- 1
 object <- lars(xs2,y,type="lasso",normalize=FALSE)
 bic <- ((log(n)/(n))*object$df)+(as.vector(object$RSS)/(n)) # Tibshirani On the degrees of freedom
 # bic <- log(n)*object$df+n*log(as.vector(object$RSS)/n)
 step.bic <- which.min(bic)
 coeff <- as.vector(coef(object,s=step.bic,mode="step"))
 # coeff <- predict.lars(object,xs2,s=step.bic,type="coef",mode="step")$coefficients
 coeff <- coeff*w/normx                 # get back in right scale by multiplying by weights vector
 coeff[is.na(coeff)] <- 0
 coef_nonzero <- as.vector(coeff) != 0
 if(all(coef_nonzero == F)){
   ls_coef <- coeff
 } else{
   ls.obj <- glm(y~x[, coef_nonzero, drop = FALSE])
   ls_coef <- (ls.obj$coefficients)[-1]
 }
 vect_coef <- rep(0,length(coef_nonzero))
 vect_coef[coef_nonzero] <- ls_coef
 return(vect_coef)
}
### Non-parametric bootstrap
# Determine block length using b.star function
bootstrap_function <- function(data, alpha, polynomial.orders){
 # polynomial.orders <- attr(expanded.theta, "degree")[ordered.results] degree of variables 

 bstar <- b.star(data[,1], round = TRUE) # Block length for derivative variable
 blocklength <- bstar[,2] # Select Block Length of cirular block result

 # tsboot Function on Original Dataframe
 # Run tsboot on function using blocklength of derivative variable
 alasso.boot.ts <- tsboot(data,lars_alasso_OLSweights_fn, R=1000, 
                          sim = "fixed", l = blocklength)
 alasso.boot.t0<- alasso.boot.ts$t0 # the estimator from original data set
 alasso.boot.t <- alasso.boot.ts$t # Matrix of coefficients from bootstrap samples

 # Determine number of variables with polynomial degree less than or equal to 
 ## largest non-zero column polynomial degree
 alasso.boot.t.nonzero <- apply(alasso.boot.t, 2, function(c)sum(c!=0))
 alasso.boot.t.nz.max <- max(which(alasso.boot.t.nonzero!=0))
 #add 1 for ones column
 new.theta.order <- sum(polynomial.orders<=polynomial.orders[alasso.boot.t.nz.max]) 

 # Rerun Bootstrap with Truncated Matrix
 post.boot.matrix <- data[,0:new.theta.order+1] # adding 1 to include derivative variable
 alassoOLS.boot.ts <- tsboot(post.boot.matrix,lars_alassoOLS_OLSweights_fn,
                             R=1000, sim = "fixed", l = blocklength)
 alassoOLS.boot.t0<- alassoOLS.boot.ts$t0 # the estimator from iterative data set
 alassoOLS.boot.t <- alassoOLS.boot.ts$t

 variables <- length(alassoOLS.boot.t0) # Number of Variables considered
 coef.nonzero <- length(which(alassoOLS.boot.t0 != 0)) # variables selected
 q <- (alpha*coef.nonzero)/variables # q = alpha
 B <- alassoOLS.boot.ts$R # Number of bootstraps
 q1 <- (B*q)/2 # Lower bound
 q2 <- B-q1+1 # Upper bound
 # Sort and determine value of lower and upper bound 
 bound.percentile <- apply(alassoOLS.boot.t,2, function(u){CI = sort(u)[c(round(q1,0),round(q2,0))]})
 # See if variables are within confidence intervals
 within.ci.check <- (alassoOLS.boot.t0 >=  bound.percentile[1,] & alassoOLS.boot.t0 <=  bound.percentile[2,])

 iterative.df.colnames <- colnames(post.boot.matrix)
 iterative.theta.colnames <- iterative.df.colnames[-c(1)]

 return(list(ci=bound.percentile, point.estimates = alassoOLS.boot.t0, within.ci.check = within.ci.check, point.estimate.colnames = iterative.theta.colnames))
}

s <- seq(4.77, 5, by = 0.01)
k <- 10^s

systems <- lapply(k, eta = 0,  polyorder = 3, Linear3D_derivative)

xdot <- lapply(systems, `[[`, 1) 
ydot <- lapply(systems, `[[`, 2)
zdot <- lapply(systems, `[[`, 3)

zdot.results <- lapply(zdot, alpha = 0.05, polynomial.orders = systems[[1]]$degree.theta, bootstrap_function)

I?ve also tried to use mclapply to speed up the process.

Thanks

From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep 23 16:57:02 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 23 Sep 2020 10:57:02 -0400
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
Message-ID: <3479921d-f144-6188-def1-4791dbf49107@gmail.com>

On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
> Dear all,
> 
> i have noticed some strange behaviour in the ?jitter? function in R.
> On the help page for jitter it is stated that
> 
> "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x) and a is the amount argument (if specified).?
> 
> and
> 
> "If amount is NULL (default), we set a <- factor * d/5 where d is the smallest difference between adjacent unique (apart from fuzz) x values.?
> 
> This works fine as long as there is no (very) large outlier
> 
>> jitter(c(1,2,10^4))  # desired behaviour
> [1]    1.083243    1.851571 9999.942716
> 
> But for very large outliers the added noise suddenly ?jumps? to a much larger scale:
> 
>> jitter(c(1,2,10^5)) # bad behaviour
> [1] -19535.649   9578.702 115693.854
> # Noise should be of order (2-1)/5  = 0.2 but is of much larger order.
> 
> This probably does not matter much when jitter is used for plotting, but it can cause problems when jitter is used to break ties.

I think this is kind of documented:  "apart from fuzz" is what counts. 
If you look at the code for jitter, you'll see this important line:

  d <- diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))

By the time you get here, z is the length of the rante of the data, so 
it's 99999 in your example.  The rounding changes your values to 
0,0,1e5, so the smallest difference is 1e5.

Duncan Murdoch


From |mh_u@er@-group@ @end|ng |rom mo|conn@com  Wed Sep 23 17:37:24 2020
From: |mh_u@er@-group@ @end|ng |rom mo|conn@com (LMH)
Date: Wed, 23 Sep 2020 11:37:24 -0400
Subject: [R] Split
In-Reply-To: <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
 <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>
Message-ID: <cc9903ac-59fa-a01f-41c7-49b28e56f499@molconn.com>

What is the delimiter is in the input data? Is it tab, space, etc?

Is this going to be the same for the output data that you will use for R input?

LMH


Val wrote:
> Thank you all for the help!
> 
> LMH, Yes I would like to see the alternative.  I am using this for a
> large data set and if the  alternative is more efficient than this
> then I would be happy.
> 
> On Tue, Sep 22, 2020 at 6:25 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> To be clear, I think Rui's solution is perfectly fine and probably better than what I offer below. But just for fun, I wanted to do it without the lapply().  Here is one way. I think my comments suffice to explain.
>>
>>> ## which are the  non "_" indices?
>>> wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
>>> ## paste "_." to these
>>> F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
>>> ## Now strsplit() and unlist() them to get a vector
>>> z <- unlist(strsplit(F1$text, "_"))
>>> ## now cbind() to the data frame
>>> F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
>>> F1
>>   ID1 ID2   text    1  2
>> 1  A1  B1 NONE_. NONE  .
>> 2  A1  B1  cf_12   cf 12
>> 3  A1  B1 NONE_. NONE  .
>> 4  A2  B2  X2_25   X2 25
>> 5  A2  B3  fd_15   fd 15
>>> ## You can change the names of the 2 columns yourself
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>
>>> Hello,
>>>
>>> A base R solution with strsplit, like in your code.
>>>
>>> F1$Y1 <- +grepl("_", F1$text)
>>>
>>> tmp <- strsplit(as.character(F1$text), "_")
>>> tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
>>> tmp <- do.call(rbind, tmp)
>>> colnames(tmp) <- c("X1", "X2")
>>> F1 <- cbind(F1[-3], tmp)    # remove the original column
>>> rm(tmp)
>>>
>>> F1
>>> #  ID1 ID2 Y1   X1 X2
>>> #1  A1  B1  0 NONE  .
>>> #2  A1  B1  1   cf 12
>>> #3  A1  B1  0 NONE  .
>>> #4  A2  B2  1   X2 25
>>> #5  A2  B3  1   fd 15
>>>
>>>
>>> Note that cbind dispatches on F1, an object of class "data.frame".
>>> Therefore it's the method cbind.data.frame that is called and the result
>>> is also a df, though tmp is a "matrix".
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>> ?s 20:07 de 22/09/20, Rui Barradas escreveu:
>>>> Hello,
>>>>
>>>> Something like this?
>>>>
>>>>
>>>> F1$Y1 <- +grepl("_", F1$text)
>>>> F1 <- F1[c(1, 2, 4, 3)]
>>>> F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill =
>>>> "right")
>>>> F1
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> ?s 19:55 de 22/09/20, Val escreveu:
>>>>> HI All,
>>>>>
>>>>> I am trying to create   new columns based on another column string
>>>>> content. First I want to identify rows that contain a particular
>>>>> string.  If it contains, I want to split the string and create two
>>>>> variables.
>>>>>
>>>>> Here is my sample of data.
>>>>> F1<-read.table(text="ID1  ID2  text
>>>>> A1 B1   NONE
>>>>> A1 B1   cf_12
>>>>> A1 B1   NONE
>>>>> A2 B2   X2_25
>>>>> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
>>>>> If the variable "text" contains this "_" I want to create an indicator
>>>>> variable as shown below
>>>>>
>>>>> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
>>>>>
>>>>>
>>>>> Then I want to split that string in to two, before "_" and after "_"
>>>>> and create two variables as shown below
>>>>> x1= strsplit(as.character(F1$text),'_',2)
>>>>>
>>>>> My problem is how to combine this with the original data frame. The
>>>>> desired  output is shown   below,
>>>>>
>>>>>
>>>>> ID1 ID2  Y1   X1    X2
>>>>> A1  B1    0   NONE   .
>>>>> A1  B1   1    cf        12
>>>>> A1  B1   0  NONE   .
>>>>> A2  B2   1    X2    25
>>>>> A2  B3   1    fd    15
>>>>>
>>>>> Any help?
>>>>> Thank you.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Sep 23 18:43:42 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 23 Sep 2020 11:43:42 -0500
Subject: [R] help with nesting if else statements
Message-ID: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>

Hello,

I have a data frame as shown bellow.
I want to create a new column PHENO which will be defined as follows:
if CURRELIG==1 -> PHENO==1
in the above subset those that have:
PLASER==2 -> PHENO==2
and
those where RTNPTHY==1 -> PHENO==1

I tried doing this:
a$PHENO=ifelse(a$CURRELIG==1 | a$RTNPTHY==1  ,1,ifelse(a$PLASER==2 |
a$RTNPTHY==2,2,NA))

but this give me some lines where I am not seeing results that I want,
for example:
FID           IID CURRELIG PLASER RTNPTHY PHENO
fam5628 G5628        1                 2       2                1

here the PHENO should be =2 because RTNPTHY==2 and PLASER==2
PHENO should be ==2 when either RTNPTHY==2 or PLASER==2

another wrong line is this:
FID              IID CURRELIG PLASER RTNPTHY PHENO
fam5706    G5706        1            1                 2             1

again RTNPTHY ==2 and PHENO==1 instead of 2.

My data looks like this:
FID  IID CURRELIG PLASER RTNPTHY
fam5610 G5610        1      1       1
fam5614 G5614        1      2       2
fam5615 G5615        1      1       1
fam5618 G5618        1      1       2
fam5621 G5621        1      1       1
fam5624 G5624        1      1       2
fam5625 G5625        1      1       1
fam5628 G5628        1      2       2
fam5633 G5633        1      2       2
fam5634 G5634        1      1       1
fam5635 G5635        2      2       2
fam5636 G5636        1      1       1
fam5641 G5641        1      1       1
fam5645 G5645        2      1       2
fam5646 G5646        2      2       2
fam5654 G5654        1      2       2
fam5655 G5655        1      2       2
fam5656 G5656        2      2       2
fam5658 G5658        1      1       1
fam5659 G5659        2      2       2
fam5660 G5660        1      1       1
fam5661 G5661        2      2       2
fam5664 G5664        1      1       1
fam5666 G5666        1      1       1
fam5667 G5667        1      1       2
fam5670 G5670        1      1       1
fam5671 G5671        1      1       2
fam5672 G5672        1      1       2
fam5673 G5673        1      1       1
fam5680 G5680        1      2       2
fam5686 G5686        1      2       2
fam5687 G5687        1      2       2
fam5688 G5688        1      1       2
fam5693 G5693        2      1       1
fam5695 G5695        1      1       1
fam5697 G5697        1      1       1
fam5700 G5700        1      2       2
fam5701 G5701        1      1       1
fam5706 G5706        1      1       2
fam5709 G5709        1      1       1
fam5713 G5713        1      1       1
fam5715 G5715        1      1       1
fam5718 G5718        1      1       1

Please advise,
Ana


From |mh_u@er@-group@ @end|ng |rom mo|conn@com  Wed Sep 23 18:51:26 2020
From: |mh_u@er@-group@ @end|ng |rom mo|conn@com (LMH)
Date: Wed, 23 Sep 2020 12:51:26 -0400
Subject: [R] Split
In-Reply-To: <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
 <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>
Message-ID: <719b237e-ff0c-3a19-ced8-cf9dad65815f@molconn.com>

Below is a script in bash the uses the awk tokenizer to do the work.

This assumes that your input and output delimiter is space. The number of consecutive delimiters in
the input is not important. This also assumes that the input file does not have a header row. That
is easy to modify if you want. I always keep header rows in my data files as I think that removing
them is asking for trouble down the road.

I added a NULL for cases where there is no value for the last field. You could use "." if you want.

You should be able to find how to run this from inside R if you want. You will, of course, need a
bash environment to run this, so if you are not in linux you will need cygwin or something similar.

This should be very fast, but let me know if needs to be faster. If the X1_X2 variant occurs less
frequently than not then we should switch the order in which the logic evaluates the options.

LMH


#! /bin/bash

# input filename
input_file=$1

# output filename
output_file=$2

# make sure the input file exists
if [ ! -f $input_file ]; then
   echo $input_file "  cannot be found"
   exit 0
fi

# create the output file
touch $output_file

# make sure the output was created
if [ ! -f $output_file ]; then
   echo $output_file "  was not created"
   exit 0
fi

# write the header row
echo "ID1 ID2 Y1 X1 X2" >> $output_file

# character to find in the third token
look_for='_'

# process with awk
# if the 3rd token contains '_'
#   split the third token on '_' into F[1] and F[2]
#   print the first two tokens, the indicator value of 1, and the split fields F[1] and F[2]
# otherwise,
#   print the first two tokens, the indicator value of 0, the 3rd token, and NULL

cat $input_file | \
awk -v find_char=$look_for '{ if($3 ~ find_char) { { split ($3, F, "_") }
                                                   { print $1, $2, "1", F[1], F[2] }
                                                 }
                              else { print $1, $2, "0", $3, "NULL" }
                            }' >> $output_file







Val wrote:
> Thank you all for the help!
> 
> LMH, Yes I would like to see the alternative.  I am using this for a
> large data set and if the  alternative is more efficient than this
> then I would be happy.
> 
> On Tue, Sep 22, 2020 at 6:25 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> To be clear, I think Rui's solution is perfectly fine and probably better than what I offer below. But just for fun, I wanted to do it without the lapply().  Here is one way. I think my comments suffice to explain.
>>
>>> ## which are the  non "_" indices?
>>> wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
>>> ## paste "_." to these
>>> F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
>>> ## Now strsplit() and unlist() them to get a vector
>>> z <- unlist(strsplit(F1$text, "_"))
>>> ## now cbind() to the data frame
>>> F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
>>> F1
>>   ID1 ID2   text    1  2
>> 1  A1  B1 NONE_. NONE  .
>> 2  A1  B1  cf_12   cf 12
>> 3  A1  B1 NONE_. NONE  .
>> 4  A2  B2  X2_25   X2 25
>> 5  A2  B3  fd_15   fd 15
>>> ## You can change the names of the 2 columns yourself
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>
>>> Hello,
>>>
>>> A base R solution with strsplit, like in your code.
>>>
>>> F1$Y1 <- +grepl("_", F1$text)
>>>
>>> tmp <- strsplit(as.character(F1$text), "_")
>>> tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
>>> tmp <- do.call(rbind, tmp)
>>> colnames(tmp) <- c("X1", "X2")
>>> F1 <- cbind(F1[-3], tmp)    # remove the original column
>>> rm(tmp)
>>>
>>> F1
>>> #  ID1 ID2 Y1   X1 X2
>>> #1  A1  B1  0 NONE  .
>>> #2  A1  B1  1   cf 12
>>> #3  A1  B1  0 NONE  .
>>> #4  A2  B2  1   X2 25
>>> #5  A2  B3  1   fd 15
>>>
>>>
>>> Note that cbind dispatches on F1, an object of class "data.frame".
>>> Therefore it's the method cbind.data.frame that is called and the result
>>> is also a df, though tmp is a "matrix".
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>> ?s 20:07 de 22/09/20, Rui Barradas escreveu:
>>>> Hello,
>>>>
>>>> Something like this?
>>>>
>>>>
>>>> F1$Y1 <- +grepl("_", F1$text)
>>>> F1 <- F1[c(1, 2, 4, 3)]
>>>> F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill =
>>>> "right")
>>>> F1
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> ?s 19:55 de 22/09/20, Val escreveu:
>>>>> HI All,
>>>>>
>>>>> I am trying to create   new columns based on another column string
>>>>> content. First I want to identify rows that contain a particular
>>>>> string.  If it contains, I want to split the string and create two
>>>>> variables.
>>>>>
>>>>> Here is my sample of data.
>>>>> F1<-read.table(text="ID1  ID2  text
>>>>> A1 B1   NONE
>>>>> A1 B1   cf_12
>>>>> A1 B1   NONE
>>>>> A2 B2   X2_25
>>>>> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
>>>>> If the variable "text" contains this "_" I want to create an indicator
>>>>> variable as shown below
>>>>>
>>>>> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
>>>>>
>>>>>
>>>>> Then I want to split that string in to two, before "_" and after "_"
>>>>> and create two variables as shown below
>>>>> x1= strsplit(as.character(F1$text),'_',2)
>>>>>
>>>>> My problem is how to combine this with the original data frame. The
>>>>> desired  output is shown   below,
>>>>>
>>>>>
>>>>> ID1 ID2  Y1   X1    X2
>>>>> A1  B1    0   NONE   .
>>>>> A1  B1   1    cf        12
>>>>> A1  B1   0  NONE   .
>>>>> A2  B2   1    X2    25
>>>>> A2  B3   1    fd    15
>>>>>
>>>>> Any help?
>>>>> Thank you.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Sep 23 19:06:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 23 Sep 2020 12:06:03 -0500
Subject: [R] help with nesting if else statements
In-Reply-To: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
References: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
Message-ID: <CAF9-5jNTD0FqjZuN+YpAa1rXxfD4cvST4zNPvrC=g=JoXYASKg@mail.gmail.com>

I tried doing this:
a$PHENO=ifelse(a$PLASER==2 | a$RTNPTHY==2,2,ifelse(a$CURRELIG==1 |
a$RTNPTHY==1,1,NA))

which brought be closer to the solution, but now I have lines like this:
FID           IID CURRELIG PLASER RTNPTHY PHENO
fam3151 G3151        1      1      NA    NA
fam3149 G3149        2      1      NA    NA
fam3151 G3151        1      1      NA    NA
fam0637  G637        2     NA      NA    NA
fam4483 G4483        1     NA      NA    NA

I would like these lines to look like this:

FID           IID CURRELIG PLASER RTNPTHY PHENO
fam3151 G3151        1      1      NA    1
fam3149 G3149        2      1      NA    2
fam3151 G3151        1      1      NA   1
fam0637  G637        2     NA      NA    2
fam4483 G4483        1     NA      NA    1

in addition to what this command does
a$PHENO=ifelse(a$PLASER==2 | a$RTNPTHY==2,2,ifelse(a$CURRELIG==1 |
a$RTNPTHY==1,1,NA))

On Wed, Sep 23, 2020 at 11:43 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have a data frame as shown bellow.
> I want to create a new column PHENO which will be defined as follows:
> if CURRELIG==1 -> PHENO==1
> in the above subset those that have:
> PLASER==2 -> PHENO==2
> and
> those where RTNPTHY==1 -> PHENO==1
>
> I tried doing this:
> a$PHENO=ifelse(a$CURRELIG==1 | a$RTNPTHY==1  ,1,ifelse(a$PLASER==2 |
> a$RTNPTHY==2,2,NA))
>
> but this give me some lines where I am not seeing results that I want,
> for example:
> FID           IID CURRELIG PLASER RTNPTHY PHENO
> fam5628 G5628        1                 2       2                1
>
> here the PHENO should be =2 because RTNPTHY==2 and PLASER==2
> PHENO should be ==2 when either RTNPTHY==2 or PLASER==2
>
> another wrong line is this:
> FID              IID CURRELIG PLASER RTNPTHY PHENO
> fam5706    G5706        1            1                 2             1
>
> again RTNPTHY ==2 and PHENO==1 instead of 2.
>
> My data looks like this:
> FID  IID CURRELIG PLASER RTNPTHY
> fam5610 G5610        1      1       1
> fam5614 G5614        1      2       2
> fam5615 G5615        1      1       1
> fam5618 G5618        1      1       2
> fam5621 G5621        1      1       1
> fam5624 G5624        1      1       2
> fam5625 G5625        1      1       1
> fam5628 G5628        1      2       2
> fam5633 G5633        1      2       2
> fam5634 G5634        1      1       1
> fam5635 G5635        2      2       2
> fam5636 G5636        1      1       1
> fam5641 G5641        1      1       1
> fam5645 G5645        2      1       2
> fam5646 G5646        2      2       2
> fam5654 G5654        1      2       2
> fam5655 G5655        1      2       2
> fam5656 G5656        2      2       2
> fam5658 G5658        1      1       1
> fam5659 G5659        2      2       2
> fam5660 G5660        1      1       1
> fam5661 G5661        2      2       2
> fam5664 G5664        1      1       1
> fam5666 G5666        1      1       1
> fam5667 G5667        1      1       2
> fam5670 G5670        1      1       1
> fam5671 G5671        1      1       2
> fam5672 G5672        1      1       2
> fam5673 G5673        1      1       1
> fam5680 G5680        1      2       2
> fam5686 G5686        1      2       2
> fam5687 G5687        1      2       2
> fam5688 G5688        1      1       2
> fam5693 G5693        2      1       1
> fam5695 G5695        1      1       1
> fam5697 G5697        1      1       1
> fam5700 G5700        1      2       2
> fam5701 G5701        1      1       1
> fam5706 G5706        1      1       2
> fam5709 G5709        1      1       1
> fam5713 G5713        1      1       1
> fam5715 G5715        1      1       1
> fam5718 G5718        1      1       1
>
> Please advise,
> Ana


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 23 21:09:29 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 23 Sep 2020 12:09:29 -0700
Subject: [R] help with nesting if else statements
In-Reply-To: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
References: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
Message-ID: <CAGxFJbThr7sh+3BKQMxjPFajv2tdS_9eMz-pM4ZrX6qaaSEtmA@mail.gmail.com>

Nested ifelse()'s are confusing and invite error.

Just use ?within and subscript with your conditions:

dat$PHENO <- NA  ## initialize PHENO
> dat <-  ## to return the modified result
within(dat, {
+     PHENO[CURRELIG ==1] <- 1
+     PHENO[CURRELIG == 1 & PLASER == 2] <- 2
+     PHENO[CURRELIG == 1 & RTNPTHY == 1] <- 1
+ })
> dat
       FID   IID CURRELIG PLASER RTNPTHY PHENO
1  fam5610 G5610        1      1       1     1
2  fam5614 G5614        1      2       2     2
3  fam5615 G5615        1      1       1     1
4  fam5618 G5618        1      1       2     1
5  fam5621 G5621        1      1       1     1
6  fam5624 G5624        1      1       2     1
7  fam5625 G5625        1      1       1     1
8  fam5628 G5628        1      2       2     2
9  fam5633 G5633        1      2       2     2
10 fam5634 G5634        1      1       1     1
11 fam5635 G5635        2      2       2    NA
12 fam5636 G5636        1      1       1     1
13 fam5641 G5641        1      1       1     1
14 fam5645 G5645        2      1       2    NA
15 fam5646 G5646        2      2       2    NA
16 fam5654 G5654        1      2       2     2
17 fam5655 G5655        1      2       2     2
18 fam5656 G5656        2      2       2    NA
19 fam5658 G5658        1      1       1     1
20 fam5659 G5659        2      2       2    NA
21 fam5660 G5660        1      1       1     1
22 fam5661 G5661        2      2       2    NA
23 fam5664 G5664        1      1       1     1
24 fam5666 G5666        1      1       1     1
25 fam5667 G5667        1      1       2     1
26 fam5670 G5670        1      1       1     1
27 fam5671 G5671        1      1       2     1
28 fam5672 G5672        1      1       2     1
29 fam5673 G5673        1      1       1     1
30 fam5680 G5680        1      2       2     2
31 fam5686 G5686        1      2       2     2
32 fam5687 G5687        1      2       2     2
33 fam5688 G5688        1      1       2     1
34 fam5693 G5693        2      1       1    NA
35 fam5695 G5695        1      1       1     1
36 fam5697 G5697        1      1       1     1
37 fam5700 G5700        1      2       2     2
38 fam5701 G5701        1      1       1     1
39 fam5706 G5706        1      1       2     1
40 fam5709 G5709        1      1       1     1
41 fam5713 G5713        1      1       1     1
42 fam5715 G5715        1      1       1     1
43 fam5718 G5718        1      1       1     1


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 23, 2020 at 9:44 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a data frame as shown bellow.
> I want to create a new column PHENO which will be defined as follows:
> if CURRELIG==1 -> PHENO==1
> in the above subset those that have:
> PLASER==2 -> PHENO==2
> and
> those where RTNPTHY==1 -> PHENO==1
>
> I tried doing this:
> a$PHENO=ifelse(a$CURRELIG==1 | a$RTNPTHY==1  ,1,ifelse(a$PLASER==2 |
> a$RTNPTHY==2,2,NA))
>
> but this give me some lines where I am not seeing results that I want,
> for example:
> FID           IID CURRELIG PLASER RTNPTHY PHENO
> fam5628 G5628        1                 2       2                1
>
> here the PHENO should be =2 because RTNPTHY==2 and PLASER==2
> PHENO should be ==2 when either RTNPTHY==2 or PLASER==2
>
> another wrong line is this:
> FID              IID CURRELIG PLASER RTNPTHY PHENO
> fam5706    G5706        1            1                 2             1
>
> again RTNPTHY ==2 and PHENO==1 instead of 2.
>
> My data looks like this:
> FID  IID CURRELIG PLASER RTNPTHY
> fam5610 G5610        1      1       1
> fam5614 G5614        1      2       2
> fam5615 G5615        1      1       1
> fam5618 G5618        1      1       2
> fam5621 G5621        1      1       1
> fam5624 G5624        1      1       2
> fam5625 G5625        1      1       1
> fam5628 G5628        1      2       2
> fam5633 G5633        1      2       2
> fam5634 G5634        1      1       1
> fam5635 G5635        2      2       2
> fam5636 G5636        1      1       1
> fam5641 G5641        1      1       1
> fam5645 G5645        2      1       2
> fam5646 G5646        2      2       2
> fam5654 G5654        1      2       2
> fam5655 G5655        1      2       2
> fam5656 G5656        2      2       2
> fam5658 G5658        1      1       1
> fam5659 G5659        2      2       2
> fam5660 G5660        1      1       1
> fam5661 G5661        2      2       2
> fam5664 G5664        1      1       1
> fam5666 G5666        1      1       1
> fam5667 G5667        1      1       2
> fam5670 G5670        1      1       1
> fam5671 G5671        1      1       2
> fam5672 G5672        1      1       2
> fam5673 G5673        1      1       1
> fam5680 G5680        1      2       2
> fam5686 G5686        1      2       2
> fam5687 G5687        1      2       2
> fam5688 G5688        1      1       2
> fam5693 G5693        2      1       1
> fam5695 G5695        1      1       1
> fam5697 G5697        1      1       1
> fam5700 G5700        1      2       2
> fam5701 G5701        1      1       1
> fam5706 G5706        1      1       2
> fam5709 G5709        1      1       1
> fam5713 G5713        1      1       1
> fam5715 G5715        1      1       1
> fam5718 G5718        1      1       1
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 23 21:32:32 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 23 Sep 2020 20:32:32 +0100
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
Message-ID: <b8995bee-55e5-abc5-cd1e-6fea3d3094a7@sapo.pt>

Hello,

R 4.0.2 on Ubuntu 20.04, sessionInfo at end.
This came up in r-help, I'm answering to the OP and also posting to 
r-devel since I believe it is more appropriate there.

I can confirm this. The original instructions are the first and the 
last, but even with smaller numbers the error shows up.


set.seed(2020)

jitter(c(1,2,10^4))  # desired behaviour
#[1]     1.058761     1.957690 10000.047401

jitter(c(0,1,10^4))  # bad behaviour
#[1]   -92.43546 -1454.61126  8269.53754

jitter(c(-1,0,10^4))  # bad behaviour
#[1] -1484.3895  -427.5283  8010.3308

jitter(c(1,2,10^5))  # bad behaviour
#[1]   4809.238  10578.561 109753.430


To the OP: I am cc-ing this to r-devel at r-project.org.
Questions like this are about R itself and should be posted there.


sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.1 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.2


Hope this helps,

Rui Barradas

?s 11:32 de 23/09/20, Martin Keller-Ressel escreveu:
> Dear all,
> 
> i have noticed some strange behaviour in the ?jitter? function in R.
> On the help page for jitter it is stated that
> 
> "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x) and a is the amount argument (if specified).?
> 
> and
> 
> "If amount is NULL (default), we set a <- factor * d/5 where d is the smallest difference between adjacent unique (apart from fuzz) x values.?
> 
> This works fine as long as there is no (very) large outlier
> 
>> jitter(c(1,2,10^4))  # desired behaviour
> [1]    1.083243    1.851571 9999.942716
> 
> But for very large outliers the added noise suddenly ?jumps? to a much larger scale:
> 
>> jitter(c(1,2,10^5)) # bad behaviour
> [1] -19535.649   9578.702 115693.854
> # Noise should be of order (2-1)/5  = 0.2 but is of much larger order.
> 
> This probably does not matter much when jitter is used for plotting, but it can cause problems when jitter is used to break ties.
> 
> best regards,
> Martin
> 
> --------------------------------
> Martin Keller-Ressel
> Professor f?r Stochastische Analysis und Finanzmathematik
> Technische Universit?t Dresden
> Institut f?r Mathematische Stochastik
> Willersbau B 316, Zellescher Weg 12-14
> 01062 Dresden
> --------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jerem|eju@te @end|ng |rom gm@||@com  Wed Sep 23 21:48:55 2020
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Wed, 23 Sep 2020 21:48:55 +0200
Subject: [R] help with nesting if else statements
In-Reply-To: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
 (Ana Marija's message of "Wed, 23 Sep 2020 11:43:42 -0500")
References: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
Message-ID: <87tuvoxoig.fsf@gmail.com>


Hello Ana Marija,

I cannot reproduce your error,

with a$PHENO=ifelse(a$PLASER==2 |a$RTNPTHY==2, 2, ifelse(a$CURRELIG==1 | a$RTNPTHY==1,1,NA))
For instance I have the expected PHENO=2

>     FID      IID   CURRELIG  PLASER  RTNPTHY PHENO
> 39: fam5706 G5706        1      1       2     2

In general I find nested ifelse to be difficult to work with especially
when I am tired :-). I would suggest this alternative way instead. It uses
data.table and you can investigate each step if you need to.

library(data.table)
setDT(a)
a[,PHENO:=NA]
a[PLASER==2|RTNPTHY==2,PHENO:=2]
a[is.na(PHENO)&(CURRELIG==1|RTNPTHY==1),PHENO:=1]


HTH,
Jeremie

a <- read.table(text="FID,IID,CURRELIG,PLASER,RTNPTHY
fam5610,G5610,1,1,1
fam5614,G5614,1,2,2
fam5615,G5615,1,1,1
fam5618,G5618,1,1,2
fam5621,G5621,1,1,1
fam5624,G5624,1,1,2
fam5625,G5625,1,1,1
fam5628,G5628,1,2,2
fam5633,G5633,1,2,2
fam5634,G5634,1,1,1
fam5635,G5635,2,2,2
fam5636,G5636,1,1,1
fam5641,G5641,1,1,1
fam5645,G5645,2,1,2
fam5646,G5646,2,2,2
fam5654,G5654,1,2,2
fam5655,G5655,1,2,2
fam5656,G5656,2,2,2
fam5658,G5658,1,1,1
fam5659,G5659,2,2,2
fam5660,G5660,1,1,1
fam5661,G5661,2,2,2
fam5664,G5664,1,1,1
fam5666,G5666,1,1,1
fam5667,G5667,1,1,2
fam5670,G5670,1,1,1
fam5671,G5671,1,1,2
fam5672,G5672,1,1,2
fam5673,G5673,1,1,1
fam5680,G5680,1,2,2
fam5686,G5686,1,2,2
fam5687,G5687,1,2,2
fam5688,G5688,1,1,2
fam5693,G5693,2,1,1
fam5695,G5695,1,1,1
fam5697,G5697,1,1,1
fam5700,G5700,1,2,2
fam5701,G5701,1,1,1
fam5706,G5706,1,1,2
fam5709,G5709,1,1,1
fam5713,G5713,1,1,1
fam5715,G5715,1,1,1
fam5718,G5718,1,1,1",sep=",", header=TRUE)


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 23 22:03:08 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 23 Sep 2020 21:03:08 +0100
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
 <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
Message-ID: <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>

Hello,

I believe that though Duncan's explanation is right it is also not 
explaining the value of the digits argument. round makes the first 2 
numbers 0 but why? The function below prints the digits argument and 
then outputs d. The code is taken from jitter.


f <- function(x){
   z <- diff(r <- range(x[is.finite(x)]))
   cat("digits:", 3 - floor(log10(z)), "\n")
   diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
}


Now see what cat outputs for 'digits'.


f(c(1,2,10^4))  # desired behaviour
#digits: 0
#[1]    1 9998
f(c(0,1,10^4))  # bad behaviour
#digits: -1
#[1] 10000
f(c(-1,0,10^4))  # bad behaviour
#digits: -1
#[1] 10000
f(c(1,2,10^5))  # bad behaviour
#digits: -1
#[1] 1e+05



And according to the documentation of ?round, negative digits are allowed:


Rounding to a negative number of digits means rounding to a power of 
ten, so for example round(x, digits = -2) rounds to the nearest hundred.


But in this case two of the numbers are closer to 0 than they are of 10. 
And unique keeps only 0 and the largest, then diff is big.


round(c(1,2,10^4),0)  # desired behaviour
#[1]     1     2 10000
round(c(0,1,10^4),-1)  # bad behaviour
#[1]     0     0 10000
round(c(-1,0,10^4),-1)  # bad behaviour
#[1]     0     0 10000
round(c(1,2,10^5),-1)  # bad behaviour
#[1] 0e+00 0e+00 1e+05



Isn't it still a bug?

Rui Barradas


?s 15:57 de 23/09/20, Duncan Murdoch escreveu:
> On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
>> Dear all,
>>
>> i have noticed some strange behaviour in the ?jitter? function in R.
>> On the help page for jitter it is stated that
>>
>> "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x) 
>> and a is the amount argument (if specified).?
>>
>> and
>>
>> "If amount is NULL (default), we set a <- factor * d/5 where d is the 
>> smallest difference between adjacent unique (apart from fuzz) x values.?
>>
>> This works fine as long as there is no (very) large outlier
>>
>>> jitter(c(1,2,10^4))? # desired behaviour
>> [1]??? 1.083243??? 1.851571 9999.942716
>>
>> But for very large outliers the added noise suddenly ?jumps? to a much 
>> larger scale:
>>
>>> jitter(c(1,2,10^5)) # bad behaviour
>> [1] -19535.649?? 9578.702 115693.854
>> # Noise should be of order (2-1)/5? = 0.2 but is of much larger order.
>>
>> This probably does not matter much when jitter is used for plotting, 
>> but it can cause problems when jitter is used to break ties.
> 
> I think this is kind of documented:? "apart from fuzz" is what counts. 
> If you look at the code for jitter, you'll see this important line:
> 
>  ?d <- diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
> 
> By the time you get here, z is the length of the rante of the data, so 
> it's 99999 in your example.? The rounding changes your values to 
> 0,0,1e5, so the smallest difference is 1e5.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep 23 22:25:36 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 23 Sep 2020 16:25:36 -0400
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
 <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
 <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>
Message-ID: <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>

On 23/09/2020 4:03 p.m., Rui Barradas wrote:
> Hello,
> 
> I believe that though Duncan's explanation is right it is also not
> explaining the value of the digits argument. round makes the first 2
> numbers 0 but why?

If there had been rounding in their computation, you might see a 
difference like 1e-15.  You wouldn't want to use that for the scale of 
jittering, so some rounding is needed.

I think the documentation for the function is poor, but the intention 
was probably to use the function in graphics (as the references did), 
and in that case, any values too close together should be treated as 
equal and jittering should separate them.  The particular computation 
used says that if the range is in [1, 10), values equal to 3 decimal 
places will be too close and need separation.

So I don't think this is a bug, but it might be a valid wishlist item: 
document what "apart from fuzz" means, and perhaps allow it to be 
controlled by the user.

Duncan Murdoch



  The function below prints the digits argument and
> then outputs d. The code is taken from jitter.
> 
> 
> f <- function(x){
>     z <- diff(r <- range(x[is.finite(x)]))
>     cat("digits:", 3 - floor(log10(z)), "\n")
>     diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
> }
> 
> 
> Now see what cat outputs for 'digits'.
> 
> 
> f(c(1,2,10^4))  # desired behaviour
> #digits: 0
> #[1]    1 9998
> f(c(0,1,10^4))  # bad behaviour
> #digits: -1
> #[1] 10000
> f(c(-1,0,10^4))  # bad behaviour
> #digits: -1
> #[1] 10000
> f(c(1,2,10^5))  # bad behaviour
> #digits: -1
> #[1] 1e+05
> 
> 
> 
> And according to the documentation of ?round, negative digits are allowed:
> 
> 
> Rounding to a negative number of digits means rounding to a power of
> ten, so for example round(x, digits = -2) rounds to the nearest hundred.
> 
> 
> But in this case two of the numbers are closer to 0 than they are of 10.
> And unique keeps only 0 and the largest, then diff is big.
> 
> 
> round(c(1,2,10^4),0)  # desired behaviour
> #[1]     1     2 10000
> round(c(0,1,10^4),-1)  # bad behaviour
> #[1]     0     0 10000
> round(c(-1,0,10^4),-1)  # bad behaviour
> #[1]     0     0 10000
> round(c(1,2,10^5),-1)  # bad behaviour
> #[1] 0e+00 0e+00 1e+05
> 
> 
> 
> Isn't it still a bug?
> 
> Rui Barradas
> 
> 
> ?s 15:57 de 23/09/20, Duncan Murdoch escreveu:
>> On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
>>> Dear all,
>>>
>>> i have noticed some strange behaviour in the ?jitter? function in R.
>>> On the help page for jitter it is stated that
>>>
>>> "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x)
>>> and a is the amount argument (if specified).?
>>>
>>> and
>>>
>>> "If amount is NULL (default), we set a <- factor * d/5 where d is the
>>> smallest difference between adjacent unique (apart from fuzz) x values.?
>>>
>>> This works fine as long as there is no (very) large outlier
>>>
>>>> jitter(c(1,2,10^4))? # desired behaviour
>>> [1]??? 1.083243??? 1.851571 9999.942716
>>>
>>> But for very large outliers the added noise suddenly ?jumps? to a much
>>> larger scale:
>>>
>>>> jitter(c(1,2,10^5)) # bad behaviour
>>> [1] -19535.649?? 9578.702 115693.854
>>> # Noise should be of order (2-1)/5? = 0.2 but is of much larger order.
>>>
>>> This probably does not matter much when jitter is used for plotting,
>>> but it can cause problems when jitter is used to break ties.
>>
>> I think this is kind of documented:? "apart from fuzz" is what counts.
>> If you look at the code for jitter, you'll see this important line:
>>
>>   ?d <- diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
>>
>> By the time you get here, z is the length of the rante of the data, so
>> it's 99999 in your example.? The rounding changes your values to
>> 0,0,1e5, so the smallest difference is 1e5.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 23 22:57:48 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 23 Sep 2020 21:57:48 +0100
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
 <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
 <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>
 <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>
Message-ID: <38add531-641b-a6a1-befc-904301b6f679@sapo.pt>

Hello,

Thanks for the further explanation.
I believe that yes, it  would be a good idea to document a bit better 
that "apart from fuzz" is a rounding operation, it is said en passant, 
and its meaning is not clear.

Rui Barradas

?s 21:25 de 23/09/20, Duncan Murdoch escreveu:
> On 23/09/2020 4:03 p.m., Rui Barradas wrote:
>> Hello,
>>
>> I believe that though Duncan's explanation is right it is also not
>> explaining the value of the digits argument. round makes the first 2
>> numbers 0 but why?
> 
> If there had been rounding in their computation, you might see a 
> difference like 1e-15.? You wouldn't want to use that for the scale of 
> jittering, so some rounding is needed.
> 
> I think the documentation for the function is poor, but the intention 
> was probably to use the function in graphics (as the references did), 
> and in that case, any values too close together should be treated as 
> equal and jittering should separate them.? The particular computation 
> used says that if the range is in [1, 10), values equal to 3 decimal 
> places will be too close and need separation.
> 
> So I don't think this is a bug, but it might be a valid wishlist item: 
> document what "apart from fuzz" means, and perhaps allow it to be 
> controlled by the user.
> 
> Duncan Murdoch
> 
> 
> 
>  ?The function below prints the digits argument and
>> then outputs d. The code is taken from jitter.
>>
>>
>> f <- function(x){
>> ??? z <- diff(r <- range(x[is.finite(x)]))
>> ??? cat("digits:", 3 - floor(log10(z)), "\n")
>> ??? diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
>> }
>>
>>
>> Now see what cat outputs for 'digits'.
>>
>>
>> f(c(1,2,10^4))? # desired behaviour
>> #digits: 0
>> #[1]??? 1 9998
>> f(c(0,1,10^4))? # bad behaviour
>> #digits: -1
>> #[1] 10000
>> f(c(-1,0,10^4))? # bad behaviour
>> #digits: -1
>> #[1] 10000
>> f(c(1,2,10^5))? # bad behaviour
>> #digits: -1
>> #[1] 1e+05
>>
>>
>>
>> And according to the documentation of ?round, negative digits are 
>> allowed:
>>
>>
>> Rounding to a negative number of digits means rounding to a power of
>> ten, so for example round(x, digits = -2) rounds to the nearest hundred.
>>
>>
>> But in this case two of the numbers are closer to 0 than they are of 10.
>> And unique keeps only 0 and the largest, then diff is big.
>>
>>
>> round(c(1,2,10^4),0)? # desired behaviour
>> #[1]???? 1???? 2 10000
>> round(c(0,1,10^4),-1)? # bad behaviour
>> #[1]???? 0???? 0 10000
>> round(c(-1,0,10^4),-1)? # bad behaviour
>> #[1]???? 0???? 0 10000
>> round(c(1,2,10^5),-1)? # bad behaviour
>> #[1] 0e+00 0e+00 1e+05
>>
>>
>>
>> Isn't it still a bug?
>>
>> Rui Barradas
>>
>>
>> ?s 15:57 de 23/09/20, Duncan Murdoch escreveu:
>>> On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
>>>> Dear all,
>>>>
>>>> i have noticed some strange behaviour in the ?jitter? function in R.
>>>> On the help page for jitter it is stated that
>>>>
>>>> "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x)
>>>> and a is the amount argument (if specified).?
>>>>
>>>> and
>>>>
>>>> "If amount is NULL (default), we set a <- factor * d/5 where d is the
>>>> smallest difference between adjacent unique (apart from fuzz) x 
>>>> values.?
>>>>
>>>> This works fine as long as there is no (very) large outlier
>>>>
>>>>> jitter(c(1,2,10^4))? # desired behaviour
>>>> [1]??? 1.083243??? 1.851571 9999.942716
>>>>
>>>> But for very large outliers the added noise suddenly ?jumps? to a much
>>>> larger scale:
>>>>
>>>>> jitter(c(1,2,10^5)) # bad behaviour
>>>> [1] -19535.649?? 9578.702 115693.854
>>>> # Noise should be of order (2-1)/5? = 0.2 but is of much larger order.
>>>>
>>>> This probably does not matter much when jitter is used for plotting,
>>>> but it can cause problems when jitter is used to break ties.
>>>
>>> I think this is kind of documented:? "apart from fuzz" is what counts.
>>> If you look at the code for jitter, you'll see this important line:
>>>
>>> ? ?d <- diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
>>>
>>> By the time you get here, z is the length of the rante of the data, so
>>> it's 99999 in your example.? The rounding changes your values to
>>> 0,0,1e5, so the smallest difference is 1e5.
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Sep 24 02:35:19 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 23 Sep 2020 19:35:19 -0500
Subject: [R] help with nesting if else statements
In-Reply-To: <87tuvoxoig.fsf@gmail.com>
References: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
 <87tuvoxoig.fsf@gmail.com>
Message-ID: <CAF9-5jMJvJxzTsgHTqY8uw3u+gwFi1QXNHwMyQM1ct9R2bua0Q@mail.gmail.com>

Hi Jeremie,

when I try to reproduce your code this is what I get:

> a=setDT(a)
> head(a)
       FID  IID CURRELIG PLASER RTNPTHY
1: fam0110 G110        2      2       2
2: fam0113 G113        2      2       2
3: fam0114 G114        2      2       2
4: fam0117 G117        2      2       2
5: fam0118 G118        2     NA       2
6: fam0119 G119        2      1       2
> a=a[,PHENO:=NA]
> head(a)
       FID  IID CURRELIG PLASER RTNPTHY PHENO
1: fam0110 G110        2      2       2    NA
2: fam0113 G113        2      2       2    NA
3: fam0114 G114        2      2       2    NA
4: fam0117 G117        2      2       2    NA
5: fam0118 G118        2     NA       2    NA
6: fam0119 G119        2      1       2    NA
> a=a[PLASER==2|RTNPTHY==2,PHENO:=2]
Warning message:
In `[.data.table`(a, PLASER == 2 | RTNPTHY == 2, `:=`(PHENO, 2)) :
  2.000000 (type 'double') at RHS position 1 taken as TRUE when
assigning to type 'logical' (column 6 named 'PHENO')

Please advise,
Ana

On Wed, Sep 23, 2020 at 2:48 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>
>
> Hello Ana Marija,
>
> I cannot reproduce your error,
>
> with a$PHENO=ifelse(a$PLASER==2 |a$RTNPTHY==2, 2, ifelse(a$CURRELIG==1 | a$RTNPTHY==1,1,NA))
> For instance I have the expected PHENO=2
>
> >     FID      IID   CURRELIG  PLASER  RTNPTHY PHENO
> > 39: fam5706 G5706        1      1       2     2
>
> In general I find nested ifelse to be difficult to work with especially
> when I am tired :-). I would suggest this alternative way instead. It uses
> data.table and you can investigate each step if you need to.
>
> library(data.table)
> setDT(a)
> a[,PHENO:=NA]
> a[PLASER==2|RTNPTHY==2,PHENO:=2]
> a[is.na(PHENO)&(CURRELIG==1|RTNPTHY==1),PHENO:=1]
>
>
> HTH,
> Jeremie
>
> a <- read.table(text="FID,IID,CURRELIG,PLASER,RTNPTHY
> fam5610,G5610,1,1,1
> fam5614,G5614,1,2,2
> fam5615,G5615,1,1,1
> fam5618,G5618,1,1,2
> fam5621,G5621,1,1,1
> fam5624,G5624,1,1,2
> fam5625,G5625,1,1,1
> fam5628,G5628,1,2,2
> fam5633,G5633,1,2,2
> fam5634,G5634,1,1,1
> fam5635,G5635,2,2,2
> fam5636,G5636,1,1,1
> fam5641,G5641,1,1,1
> fam5645,G5645,2,1,2
> fam5646,G5646,2,2,2
> fam5654,G5654,1,2,2
> fam5655,G5655,1,2,2
> fam5656,G5656,2,2,2
> fam5658,G5658,1,1,1
> fam5659,G5659,2,2,2
> fam5660,G5660,1,1,1
> fam5661,G5661,2,2,2
> fam5664,G5664,1,1,1
> fam5666,G5666,1,1,1
> fam5667,G5667,1,1,2
> fam5670,G5670,1,1,1
> fam5671,G5671,1,1,2
> fam5672,G5672,1,1,2
> fam5673,G5673,1,1,1
> fam5680,G5680,1,2,2
> fam5686,G5686,1,2,2
> fam5687,G5687,1,2,2
> fam5688,G5688,1,1,2
> fam5693,G5693,2,1,1
> fam5695,G5695,1,1,1
> fam5697,G5697,1,1,1
> fam5700,G5700,1,2,2
> fam5701,G5701,1,1,1
> fam5706,G5706,1,1,2
> fam5709,G5709,1,1,1
> fam5713,G5713,1,1,1
> fam5715,G5715,1,1,1
> fam5718,G5718,1,1,1",sep=",", header=TRUE)
>
>
>
>
>
>


From v@|kremk @end|ng |rom gm@||@com  Thu Sep 24 03:20:29 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Wed, 23 Sep 2020 20:20:29 -0500
Subject: [R] Split
In-Reply-To: <719b237e-ff0c-3a19-ced8-cf9dad65815f@molconn.com>
References: <CAJOiR6a9+u5xZtDzfe2adridd_T251SAyAfqAgxtkfK6zK=+tg@mail.gmail.com>
 <cf7cdd86-400e-8b8b-231c-61b6ef1ff27a@sapo.pt>
 <57c1362d-b67a-f804-9969-fbf8f2b00cd9@sapo.pt>
 <CAGxFJbQVqhUksnwGCheBptuOSez+8zJ8uUskV0REa3kDvLPUYw@mail.gmail.com>
 <CAJOiR6aDGTjvN_s4DOK_3qGJjEQ=N55SY1cX-mee5KswrB_nnQ@mail.gmail.com>
 <719b237e-ff0c-3a19-ced8-cf9dad65815f@molconn.com>
Message-ID: <CAJOiR6b-iQfzhvBGzOGAY=ZbdArnwN=kft-JUdpFXPXQ-kFZxg@mail.gmail.com>

Thank you again for your help  and giving me the opportunity to choose
the efficient method.  For a small data set there is no discernable
difference between the different approaches.  I will carry out a
comparison using  the large data set.


On Wed, Sep 23, 2020 at 11:52 AM LMH <lmh_users-groups at molconn.com> wrote:
>
> Below is a script in bash the uses the awk tokenizer to do the work.
>
> This assumes that your input and output delimiter is space. The number of consecutive delimiters in
> the input is not important. This also assumes that the input file does not have a header row. That
> is easy to modify if you want. I always keep header rows in my data files as I think that removing
> them is asking for trouble down the road.
>
> I added a NULL for cases where there is no value for the last field. You could use "." if you want.
>
> You should be able to find how to run this from inside R if you want. You will, of course, need a
> bash environment to run this, so if you are not in linux you will need cygwin or something similar.
>
> This should be very fast, but let me know if needs to be faster. If the X1_X2 variant occurs less
> frequently than not then we should switch the order in which the logic evaluates the options.
>
> LMH
>
>
> #! /bin/bash
>
> # input filename
> input_file=$1
>
> # output filename
> output_file=$2
>
> # make sure the input file exists
> if [ ! -f $input_file ]; then
>    echo $input_file "  cannot be found"
>    exit 0
> fi
>
> # create the output file
> touch $output_file
>
> # make sure the output was created
> if [ ! -f $output_file ]; then
>    echo $output_file "  was not created"
>    exit 0
> fi
>
> # write the header row
> echo "ID1 ID2 Y1 X1 X2" >> $output_file
>
> # character to find in the third token
> look_for='_'
>
> # process with awk
> # if the 3rd token contains '_'
> #   split the third token on '_' into F[1] and F[2]
> #   print the first two tokens, the indicator value of 1, and the split fields F[1] and F[2]
> # otherwise,
> #   print the first two tokens, the indicator value of 0, the 3rd token, and NULL
>
> cat $input_file | \
> awk -v find_char=$look_for '{ if($3 ~ find_char) { { split ($3, F, "_") }
>                                                    { print $1, $2, "1", F[1], F[2] }
>                                                  }
>                               else { print $1, $2, "0", $3, "NULL" }
>                             }' >> $output_file
>
>
>
>
>
>
>
> Val wrote:
> > Thank you all for the help!
> >
> > LMH, Yes I would like to see the alternative.  I am using this for a
> > large data set and if the  alternative is more efficient than this
> > then I would be happy.
> >
> > On Tue, Sep 22, 2020 at 6:25 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >>
> >> To be clear, I think Rui's solution is perfectly fine and probably better than what I offer below. But just for fun, I wanted to do it without the lapply().  Here is one way. I think my comments suffice to explain.
> >>
> >>> ## which are the  non "_" indices?
> >>> wh <- grep("_",F1$text, fixed = TRUE, invert = TRUE)
> >>> ## paste "_." to these
> >>> F1[wh,"text"] <- paste(F1[wh,"text"],".",sep = "_")
> >>> ## Now strsplit() and unlist() them to get a vector
> >>> z <- unlist(strsplit(F1$text, "_"))
> >>> ## now cbind() to the data frame
> >>> F1 <- cbind(F1, matrix(z, ncol = 2, byrow = TRUE))
> >>> F1
> >>   ID1 ID2   text    1  2
> >> 1  A1  B1 NONE_. NONE  .
> >> 2  A1  B1  cf_12   cf 12
> >> 3  A1  B1 NONE_. NONE  .
> >> 4  A2  B2  X2_25   X2 25
> >> 5  A2  B3  fd_15   fd 15
> >>> ## You can change the names of the 2 columns yourself
> >>
> >> Cheers,
> >> Bert
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Tue, Sep 22, 2020 at 12:19 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >>>
> >>> Hello,
> >>>
> >>> A base R solution with strsplit, like in your code.
> >>>
> >>> F1$Y1 <- +grepl("_", F1$text)
> >>>
> >>> tmp <- strsplit(as.character(F1$text), "_")
> >>> tmp <- lapply(tmp, function(x) if(length(x) == 1) c(x, ".") else x)
> >>> tmp <- do.call(rbind, tmp)
> >>> colnames(tmp) <- c("X1", "X2")
> >>> F1 <- cbind(F1[-3], tmp)    # remove the original column
> >>> rm(tmp)
> >>>
> >>> F1
> >>> #  ID1 ID2 Y1   X1 X2
> >>> #1  A1  B1  0 NONE  .
> >>> #2  A1  B1  1   cf 12
> >>> #3  A1  B1  0 NONE  .
> >>> #4  A2  B2  1   X2 25
> >>> #5  A2  B3  1   fd 15
> >>>
> >>>
> >>> Note that cbind dispatches on F1, an object of class "data.frame".
> >>> Therefore it's the method cbind.data.frame that is called and the result
> >>> is also a df, though tmp is a "matrix".
> >>>
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>>
> >>> ?s 20:07 de 22/09/20, Rui Barradas escreveu:
> >>>> Hello,
> >>>>
> >>>> Something like this?
> >>>>
> >>>>
> >>>> F1$Y1 <- +grepl("_", F1$text)
> >>>> F1 <- F1[c(1, 2, 4, 3)]
> >>>> F1 <- tidyr::separate(F1, text, into = c("X1", "X2"), sep = "_", fill =
> >>>> "right")
> >>>> F1
> >>>>
> >>>>
> >>>> Hope this helps,
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>> ?s 19:55 de 22/09/20, Val escreveu:
> >>>>> HI All,
> >>>>>
> >>>>> I am trying to create   new columns based on another column string
> >>>>> content. First I want to identify rows that contain a particular
> >>>>> string.  If it contains, I want to split the string and create two
> >>>>> variables.
> >>>>>
> >>>>> Here is my sample of data.
> >>>>> F1<-read.table(text="ID1  ID2  text
> >>>>> A1 B1   NONE
> >>>>> A1 B1   cf_12
> >>>>> A1 B1   NONE
> >>>>> A2 B2   X2_25
> >>>>> A2 B3   fd_15  ",header=TRUE,stringsAsFactors=F)
> >>>>> If the variable "text" contains this "_" I want to create an indicator
> >>>>> variable as shown below
> >>>>>
> >>>>> F1$Y1 <- ifelse(grepl("_", F1$text),1,0)
> >>>>>
> >>>>>
> >>>>> Then I want to split that string in to two, before "_" and after "_"
> >>>>> and create two variables as shown below
> >>>>> x1= strsplit(as.character(F1$text),'_',2)
> >>>>>
> >>>>> My problem is how to combine this with the original data frame. The
> >>>>> desired  output is shown   below,
> >>>>>
> >>>>>
> >>>>> ID1 ID2  Y1   X1    X2
> >>>>> A1  B1    0   NONE   .
> >>>>> A1  B1   1    cf        12
> >>>>> A1  B1   0  NONE   .
> >>>>> A2  B2   1    X2    25
> >>>>> A2  B3   1    fd    15
> >>>>>
> >>>>> Any help?
> >>>>> Thank you.
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From jerem|eju@te @end|ng |rom gm@||@com  Thu Sep 24 08:07:11 2020
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Thu, 24 Sep 2020 08:07:11 +0200
Subject: [R] help with nesting if else statements
In-Reply-To: <CAF9-5jMJvJxzTsgHTqY8uw3u+gwFi1QXNHwMyQM1ct9R2bua0Q@mail.gmail.com>
 (Ana Marija's message of "Wed, 23 Sep 2020 19:35:19 -0500")
References: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
 <87tuvoxoig.fsf@gmail.com>
 <CAF9-5jMJvJxzTsgHTqY8uw3u+gwFi1QXNHwMyQM1ct9R2bua0Q@mail.gmail.com>
Message-ID: <87mu1fyagg.fsf@gmail.com>


Hello Ana Marija,

Apologies, the warning escaped me. When Pheno is assigned NA .
> a=a[,PHENO:=NA]
It is assigned a NA of type logical  by default. We just have to make
sure it is an NA of type numeric

> a[,PHENO:=1.0*NA]

So the full set of commands is:

library(data.table)
setDT(a)
a[,PHENO:=1.0*NA]
a[PLASER==2|RTNPTHY==2,PHENO:=2]
a[is.na(PHENO)&(CURRELIG==1|RTNPTHY==1),PHENO:=1]

Best regards,
Jeremie



Ana Marija <sokovic.anamarija at gmail.com> writes:

> Hi Jeremie,
>
> when I try to reproduce your code this is what I get:
>
>> a=setDT(a)
>> head(a)
>        FID  IID CURRELIG PLASER RTNPTHY
> 1: fam0110 G110        2      2       2
> 2: fam0113 G113        2      2       2
> 3: fam0114 G114        2      2       2
> 4: fam0117 G117        2      2       2
> 5: fam0118 G118        2     NA       2
> 6: fam0119 G119        2      1       2
>> a=a[,PHENO:=NA]
>> head(a)
>        FID  IID CURRELIG PLASER RTNPTHY PHENO
> 1: fam0110 G110        2      2       2    NA
> 2: fam0113 G113        2      2       2    NA
> 3: fam0114 G114        2      2       2    NA
> 4: fam0117 G117        2      2       2    NA
> 5: fam0118 G118        2     NA       2    NA
> 6: fam0119 G119        2      1       2    NA
>> a=a[PLASER==2|RTNPTHY==2,PHENO:=2]
> Warning message:
> In `[.data.table`(a, PLASER == 2 | RTNPTHY == 2, `:=`(PHENO, 2)) :
>   2.000000 (type 'double') at RHS position 1 taken as TRUE when
> assigning to type 'logical' (column 6 named 'PHENO')
>
> Please advise,
> Ana
>
> On Wed, Sep 23, 2020 at 2:48 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>>
>>
>> Hello Ana Marija,
>>
>> I cannot reproduce your error,
>>
>> with a$PHENO=ifelse(a$PLASER==2 |a$RTNPTHY==2, 2, ifelse(a$CURRELIG==1 | a$RTNPTHY==1,1,NA))
>> For instance I have the expected PHENO=2
>>
>> >     FID      IID   CURRELIG  PLASER  RTNPTHY PHENO
>> > 39: fam5706 G5706        1      1       2     2
>>
>> In general I find nested ifelse to be difficult to work with especially
>> when I am tired :-). I would suggest this alternative way instead. It uses
>> data.table and you can investigate each step if you need to.
>>
>> library(data.table)
>> setDT(a)
>> a[,PHENO:=NA]
>> a[PLASER==2|RTNPTHY==2,PHENO:=2]
>> a[is.na(PHENO)&(CURRELIG==1|RTNPTHY==1),PHENO:=1]
>>
>>
>> HTH,
>> Jeremie
>>
>> a <- read.table(text="FID,IID,CURRELIG,PLASER,RTNPTHY
>> fam5610,G5610,1,1,1
>> fam5614,G5614,1,2,2
>> fam5615,G5615,1,1,1
>> fam5618,G5618,1,1,2
>> fam5621,G5621,1,1,1
>> fam5624,G5624,1,1,2
>> fam5625,G5625,1,1,1
>> fam5628,G5628,1,2,2
>> fam5633,G5633,1,2,2
>> fam5634,G5634,1,1,1
>> fam5635,G5635,2,2,2
>> fam5636,G5636,1,1,1
>> fam5641,G5641,1,1,1
>> fam5645,G5645,2,1,2
>> fam5646,G5646,2,2,2
>> fam5654,G5654,1,2,2
>> fam5655,G5655,1,2,2
>> fam5656,G5656,2,2,2
>> fam5658,G5658,1,1,1
>> fam5659,G5659,2,2,2
>> fam5660,G5660,1,1,1
>> fam5661,G5661,2,2,2
>> fam5664,G5664,1,1,1
>> fam5666,G5666,1,1,1
>> fam5667,G5667,1,1,2
>> fam5670,G5670,1,1,1
>> fam5671,G5671,1,1,2
>> fam5672,G5672,1,1,2
>> fam5673,G5673,1,1,1
>> fam5680,G5680,1,2,2
>> fam5686,G5686,1,2,2
>> fam5687,G5687,1,2,2
>> fam5688,G5688,1,1,2
>> fam5693,G5693,2,1,1
>> fam5695,G5695,1,1,1
>> fam5697,G5697,1,1,1
>> fam5700,G5700,1,2,2
>> fam5701,G5701,1,1,1
>> fam5706,G5706,1,1,2
>> fam5709,G5709,1,1,1
>> fam5713,G5713,1,1,1
>> fam5715,G5715,1,1,1
>> fam5718,G5718,1,1,1",sep=",", header=TRUE)
>>
>>
>>
>>
>>
>>


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 24 09:13:15 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 24 Sep 2020 07:13:15 +0000
Subject: [R] help with nesting if else statements
In-Reply-To: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
References: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
Message-ID: <025e76b05fb24e6eb1ed313e329bcbea@SRVEXCHCM1302.precheza.cz>

Hi

instead of complicated ifelse construction  I would try perform the task in
several steps

# make a new column
test$new <- NA

# select CURRELIG and RTNPTHY and set new to 1
test$new[which(test$CURRELIG==1 & test$RTNPTHY==1)] <- 1

# select CURRELIG and PLASER and set new to 2
test$new[which(test$CURRELIG==1 & test$PLASER==2)] <- 2

> test
       FID   IID CURRELIG PLASER RTNPTHY new
1  fam5610 G5610        1      1       1   1
2  fam5614 G5614        1      2       2   2
3  fam5615 G5615        1      1       1   1
4  fam5618 G5618        1      1       2  NA
5  fam5621 G5621        1      1       1   1
6  fam5624 G5624        1      1       2  NA
7  fam5625 G5625        1      1       1   1
8  fam5628 G5628        1      2       2   2
9  fam5633 G5633        1      2       2   2
10 fam5634 G5634        1      1       1   1
11 fam5635 G5635        2      2       2  NA
12 fam5636 G5636        1      1       1   1
13 fam5641 G5641        1      1       1   1
14 fam5645 G5645        2      1       2  NA
15 fam5646 G5646        2      2       2  NA
16 fam5654 G5654        1      2       2   2
17 fam5655 G5655        1      2       2   2
18 fam5656 G5656        2      2       2  NA
19 fam5658 G5658        1      1       1   1
20 fam5659 G5659        2      2       2  NA

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ana Marija
> Sent: Wednesday, September 23, 2020 6:44 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] help with nesting if else statements
> 
> Hello,
> 
> I have a data frame as shown bellow.
> I want to create a new column PHENO which will be defined as follows:
> if CURRELIG==1 -> PHENO==1
> in the above subset those that have:
> PLASER==2 -> PHENO==2
> and
> those where RTNPTHY==1 -> PHENO==1
> 
> I tried doing this:
> a$PHENO=ifelse(a$CURRELIG==1 | a$RTNPTHY==1  ,1,ifelse(a$PLASER==2 |
> a$RTNPTHY==2,2,NA))
> 
> but this give me some lines where I am not seeing results that I want, for
> example:
> FID           IID CURRELIG PLASER RTNPTHY PHENO
> fam5628 G5628        1                 2       2                1
> 
> here the PHENO should be =2 because RTNPTHY==2 and PLASER==2 PHENO
> should be ==2 when either RTNPTHY==2 or PLASER==2
> 
> another wrong line is this:
> FID              IID CURRELIG PLASER RTNPTHY PHENO
> fam5706    G5706        1            1                 2             1
> 
> again RTNPTHY ==2 and PHENO==1 instead of 2.
> 
> My data looks like this:
> FID  IID CURRELIG PLASER RTNPTHY
> fam5610 G5610        1      1       1
> fam5614 G5614        1      2       2
> fam5615 G5615        1      1       1
> fam5618 G5618        1      1       2
> fam5621 G5621        1      1       1
> fam5624 G5624        1      1       2
> fam5625 G5625        1      1       1
> fam5628 G5628        1      2       2
> fam5633 G5633        1      2       2
> fam5634 G5634        1      1       1
> fam5635 G5635        2      2       2
> fam5636 G5636        1      1       1
> fam5641 G5641        1      1       1
> fam5645 G5645        2      1       2
> fam5646 G5646        2      2       2
> fam5654 G5654        1      2       2
> fam5655 G5655        1      2       2
> fam5656 G5656        2      2       2
> fam5658 G5658        1      1       1
> fam5659 G5659        2      2       2
> fam5660 G5660        1      1       1
> fam5661 G5661        2      2       2
> fam5664 G5664        1      1       1
> fam5666 G5666        1      1       1
> fam5667 G5667        1      1       2
> fam5670 G5670        1      1       1
> fam5671 G5671        1      1       2
> fam5672 G5672        1      1       2
> fam5673 G5673        1      1       1
> fam5680 G5680        1      2       2
> fam5686 G5686        1      2       2
> fam5687 G5687        1      2       2
> fam5688 G5688        1      1       2
> fam5693 G5693        2      1       1
> fam5695 G5695        1      1       1
> fam5697 G5697        1      1       1
> fam5700 G5700        1      2       2
> fam5701 G5701        1      1       1
> fam5706 G5706        1      1       2
> fam5709 G5709        1      1       1
> fam5713 G5713        1      1       1
> fam5715 G5715        1      1       1
> fam5718 G5718        1      1       1
> 
> Please advise,
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 24 09:29:22 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 24 Sep 2020 17:29:22 +1000
Subject: [R] package plotrix: how to account for two two z categories
In-Reply-To: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
References: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
Message-ID: <CA+8X3fVgNC_yUyFFkV3Li+o_k6S5J7ZKBdf_ktVc84fZECMxrg@mail.gmail.com>

Hi Luigi,
To display a nested breakdown like this I would suggest barNest. This
is one way to display the nesting. Note that if you change the order
of the factors in the formula you will get a different plot, so think
about how you want the summaries nested. Error bars can only be
displayed on the final breakdown.

# because you have fairly long labels, use a wide plot
x11(width=10)
barcol<-list("lightgray",c("#ff00ff","#ff99ff"),
 c("#00ff00","#66ff66"),c("#aaaa00","#888800"))
barNest(y~x+z+w,Q,main="Double Measurement",
 ylab="Response",col=barcol,errbars=TRUE)

Jim

On Wed, Sep 23, 2020 at 10:48 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have an experiment measuring optical density (OD) when comparing
> three parameters:
> a) concentration of the target
> b) concentration of the probe
> c) concentration of the reporter antibody.
> Using plotrix I can nicely draw the first two into clusters, but I
> can't get separation for the third parameter. is there a way in
> plotrix to custer data according to two, let's say, z parameters (I
> call the second high-level parameter as w)? For instance, two
> clusters, each separated into two subclusters. Or is this more a job
> for lattice?
> Thank you.
>
> ```
> x = rep(c(rep("1000 pmol", 4), rep("0 pmol", 4)),2)
> z =  rep(c(rep("Treated", 2), rep("Untreated", 2), rep("Treated", 2),
> rep("Untreated", 2)))
> w = c(rep("1:1000", 8), rep("1:2000", 8))
> y = c(1.18, 1.22, 1.52, 2.37, 0.97, 1.08, 1.17, 1.58, 1.16, 1.16, 2.27, 2.24,
>       1.26, 1.28, 1.39, 1.77)
> Q = data.frame(x, z, w, y, stringsAsFactors = FALSE)
> names(Q) = c("[Target]", "Enzyme", "[Antibody]", "OD")
> names(Q) = c("x", "z", "w", "y") # for ease, I'll use single letters
> library(plotrix)
> brkdn.plot(y~x+z, data=Q,
>            pch = c(1, 16), cex = 1.5, type="p",
>            main="Single Measurement",
>            xlab=expression(bold("S1 nuclease")),
>            ylab=expression(bold("Optical density")))
> brkdn.plot(y~x+z+w, data=Q,
>            pch = c(1, 16), cex = 1.5, type="p",
>            main="Double Measurement",
>            xlab=expression(bold("S1 nuclease")),
>            ylab=expression(bold("Optical density")))
> ```
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From djbo@|o14 @end|ng |rom gm@||@com  Wed Sep 23 23:00:11 2020
From: djbo@|o14 @end|ng |rom gm@||@com (Dan Bosio)
Date: Wed, 23 Sep 2020 17:00:11 -0400
Subject: [R] Help with for loops and if statements
Message-ID: <4555233F-DD76-4309-8999-CA60A90E4376@gmail.com>

Hi there

I am in an intro to R course and the professor has not been much help. One of the questions on the latest homework has me stumped. The question is below, along with my answers so far.

8. [15 points] Given the following code,
#
# x <- rnorm(10)
#
# Do the following.
#
# (1) create a count vector named "count" of four elements and set each to 0 using the rep function.
# (2) using a for loop to process each value in the vector x, count how many times each of the following values occur in the vector x using an if statement.
# a. "value is between -1 and 1 inclusive"
# b. "value is between -2 and 2 inclusive, but not between -1 and 1",
# c. "value is between -3 and 3 inclusive, but not between -2 and -2", or
# d. "value is greater than 3 or less than -3".
# (3) print each of the four counts in the count vector using a while loop.
#
# For example, if the vector x contains the following ten values,
#
# 1.1478911  1.6183994 -2.3790632 -0.2566993  0.8923735
# -0.7523441 -0.7559083  0.9836396  1.0994189  2.5519972
#
# Then, the output should be as below.
#
# count[1] is 5
# count[2] is 3
# count[3] is 2
# count[4] is 0

x <- rnorm(10)

My answers:

(1) count <- c(rep(0,4))

(2) for (count in x) {
            if (x > -1 & x < 1) {
                 print(count[1])
  }

I know there is something wrong with my code for part one but we haven't gone over anything like this in class and I have struggled to find a video for something like this. Please point me in the right direction and let me know what mistakes I have made, thanks so much!
	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 24 10:32:58 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 24 Sep 2020 18:32:58 +1000
Subject: [R] package plotrix: how to account for two two z categories
In-Reply-To: <CAMk+s2Rtk=ujC-1AmzwJ9o3foH+DcdpuJmB2MFDKJTGA_i593A@mail.gmail.com>
References: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
 <CA+8X3fVgNC_yUyFFkV3Li+o_k6S5J7ZKBdf_ktVc84fZECMxrg@mail.gmail.com>
 <CAMk+s2Rtk=ujC-1AmzwJ9o3foH+DcdpuJmB2MFDKJTGA_i593A@mail.gmail.com>
Message-ID: <CA+8X3fUyrMKgFNXj+Ok5AX_aU02emktM1WtgSSvxoOYx5sDKzA@mail.gmail.com>

Hi Luigi,
I thought a lot about that when I was writing the function. The only
way I could think of to show the nesting was dots with horizontal
lines and it looked messy and was quite hard to visualize the nesting.
If you do have any great ideas I always welcome contributions to
plotrix.

Jim

On Thu, Sep 24, 2020 at 6:25 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you Jim, that is really nice!
> But is there a way to use dots instead of boxes? and how do I control
> the colours?
> Best regards
> Luigi
>
> On Thu, Sep 24, 2020 at 9:29 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > To display a nested breakdown like this I would suggest barNest. This
> > is one way to display the nesting. Note that if you change the order
> > of the factors in the formula you will get a different plot, so think
> > about how you want the summaries nested. Error bars can only be
> > displayed on the final breakdown.
> >
> > # because you have fairly long labels, use a wide plot
> > x11(width=10)
> > barcol<-list("lightgray",c("#ff00ff","#ff99ff"),
> >  c("#00ff00","#66ff66"),c("#aaaa00","#888800"))
> > barNest(y~x+z+w,Q,main="Double Measurement",
> >  ylab="Response",col=barcol,errbars=TRUE)
> >
> > Jim
> >
> > On Wed, Sep 23, 2020 at 10:48 PM Luigi Marongiu
> > <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I have an experiment measuring optical density (OD) when comparing
> > > three parameters:
> > > a) concentration of the target
> > > b) concentration of the probe
> > > c) concentration of the reporter antibody.
> > > Using plotrix I can nicely draw the first two into clusters, but I
> > > can't get separation for the third parameter. is there a way in
> > > plotrix to custer data according to two, let's say, z parameters (I
> > > call the second high-level parameter as w)? For instance, two
> > > clusters, each separated into two subclusters. Or is this more a job
> > > for lattice?
> > > Thank you.
> > >
> > > ```
> > > x = rep(c(rep("1000 pmol", 4), rep("0 pmol", 4)),2)
> > > z =  rep(c(rep("Treated", 2), rep("Untreated", 2), rep("Treated", 2),
> > > rep("Untreated", 2)))
> > > w = c(rep("1:1000", 8), rep("1:2000", 8))
> > > y = c(1.18, 1.22, 1.52, 2.37, 0.97, 1.08, 1.17, 1.58, 1.16, 1.16, 2.27, 2.24,
> > >       1.26, 1.28, 1.39, 1.77)
> > > Q = data.frame(x, z, w, y, stringsAsFactors = FALSE)
> > > names(Q) = c("[Target]", "Enzyme", "[Antibody]", "OD")
> > > names(Q) = c("x", "z", "w", "y") # for ease, I'll use single letters
> > > library(plotrix)
> > > brkdn.plot(y~x+z, data=Q,
> > >            pch = c(1, 16), cex = 1.5, type="p",
> > >            main="Single Measurement",
> > >            xlab=expression(bold("S1 nuclease")),
> > >            ylab=expression(bold("Optical density")))
> > > brkdn.plot(y~x+z+w, data=Q,
> > >            pch = c(1, 16), cex = 1.5, type="p",
> > >            main="Double Measurement",
> > >            xlab=expression(bold("S1 nuclease")),
> > >            ylab=expression(bold("Optical density")))
> > > ```
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 24 10:34:51 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 24 Sep 2020 18:34:51 +1000
Subject: [R] package plotrix: how to account for two two z categories
In-Reply-To: <CA+8X3fUyrMKgFNXj+Ok5AX_aU02emktM1WtgSSvxoOYx5sDKzA@mail.gmail.com>
References: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
 <CA+8X3fVgNC_yUyFFkV3Li+o_k6S5J7ZKBdf_ktVc84fZECMxrg@mail.gmail.com>
 <CAMk+s2Rtk=ujC-1AmzwJ9o3foH+DcdpuJmB2MFDKJTGA_i593A@mail.gmail.com>
 <CA+8X3fUyrMKgFNXj+Ok5AX_aU02emktM1WtgSSvxoOYx5sDKzA@mail.gmail.com>
Message-ID: <CA+8X3fVCAKEmRjGYq30-kPEDtsxBXWH6GD+Krfp=W+bAF7K66g@mail.gmail.com>

Oh, sorry, forgot about the colors. A list beginning with the color
for the overall summary, then colors for the first factor and so on.
See the help page for examples.

Jim

On Thu, Sep 24, 2020 at 6:32 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> I thought a lot about that when I was writing the function. The only
> way I could think of to show the nesting was dots with horizontal
> lines and it looked messy and was quite hard to visualize the nesting.
> If you do have any great ideas I always welcome contributions to
> plotrix.
>
> Jim
>
> On Thu, Sep 24, 2020 at 6:25 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Thank you Jim, that is really nice!
> > But is there a way to use dots instead of boxes? and how do I control
> > the colours?
> > Best regards
> > Luigi
> >
> > On Thu, Sep 24, 2020 at 9:29 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > To display a nested breakdown like this I would suggest barNest. This
> > > is one way to display the nesting. Note that if you change the order
> > > of the factors in the formula you will get a different plot, so think
> > > about how you want the summaries nested. Error bars can only be
> > > displayed on the final breakdown.
> > >
> > > # because you have fairly long labels, use a wide plot
> > > x11(width=10)
> > > barcol<-list("lightgray",c("#ff00ff","#ff99ff"),
> > >  c("#00ff00","#66ff66"),c("#aaaa00","#888800"))
> > > barNest(y~x+z+w,Q,main="Double Measurement",
> > >  ylab="Response",col=barcol,errbars=TRUE)
> > >
> > > Jim
> > >
> > > On Wed, Sep 23, 2020 at 10:48 PM Luigi Marongiu
> > > <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I have an experiment measuring optical density (OD) when comparing
> > > > three parameters:
> > > > a) concentration of the target
> > > > b) concentration of the probe
> > > > c) concentration of the reporter antibody.
> > > > Using plotrix I can nicely draw the first two into clusters, but I
> > > > can't get separation for the third parameter. is there a way in
> > > > plotrix to custer data according to two, let's say, z parameters (I
> > > > call the second high-level parameter as w)? For instance, two
> > > > clusters, each separated into two subclusters. Or is this more a job
> > > > for lattice?
> > > > Thank you.
> > > >
> > > > ```
> > > > x = rep(c(rep("1000 pmol", 4), rep("0 pmol", 4)),2)
> > > > z =  rep(c(rep("Treated", 2), rep("Untreated", 2), rep("Treated", 2),
> > > > rep("Untreated", 2)))
> > > > w = c(rep("1:1000", 8), rep("1:2000", 8))
> > > > y = c(1.18, 1.22, 1.52, 2.37, 0.97, 1.08, 1.17, 1.58, 1.16, 1.16, 2.27, 2.24,
> > > >       1.26, 1.28, 1.39, 1.77)
> > > > Q = data.frame(x, z, w, y, stringsAsFactors = FALSE)
> > > > names(Q) = c("[Target]", "Enzyme", "[Antibody]", "OD")
> > > > names(Q) = c("x", "z", "w", "y") # for ease, I'll use single letters
> > > > library(plotrix)
> > > > brkdn.plot(y~x+z, data=Q,
> > > >            pch = c(1, 16), cex = 1.5, type="p",
> > > >            main="Single Measurement",
> > > >            xlab=expression(bold("S1 nuclease")),
> > > >            ylab=expression(bold("Optical density")))
> > > > brkdn.plot(y~x+z+w, data=Q,
> > > >            pch = c(1, 16), cex = 1.5, type="p",
> > > >            main="Double Measurement",
> > > >            xlab=expression(bold("S1 nuclease")),
> > > >            ylab=expression(bold("Optical density")))
> > > > ```
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 24 11:01:48 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 24 Sep 2020 19:01:48 +1000
Subject: [R] Help with for loops and if statements
In-Reply-To: <4555233F-DD76-4309-8999-CA60A90E4376@gmail.com>
References: <4555233F-DD76-4309-8999-CA60A90E4376@gmail.com>
Message-ID: <CA+8X3fVbpfYPvUkXtSaLR+O3qv25RKVvkRBNs_dnFShDa56k9w@mail.gmail.com>

Hi Dan,
This list has a "no homework" policy, but as you really do seem to be
struggling, I'll suggest that you read the help page for "abs"
carefully and learn about "<-" (assign a value). Perhaps these will
give you a start.

Jim

On Thu, Sep 24, 2020 at 6:19 PM Dan Bosio <djbosio14 at gmail.com> wrote:
>
> Hi there
>
> I am in an intro to R course and the professor has not been much help. One of the questions on the latest homework has me stumped. The question is below, along with my answers so far.
>
> 8. [15 points] Given the following code,
> #
> # x <- rnorm(10)
> #
> # Do the following.
> #
> # (1) create a count vector named "count" of four elements and set each to 0 using the rep function.
> # (2) using a for loop to process each value in the vector x, count how many times each of the following values occur in the vector x using an if statement.
> # a. "value is between -1 and 1 inclusive"
> # b. "value is between -2 and 2 inclusive, but not between -1 and 1",
> # c. "value is between -3 and 3 inclusive, but not between -2 and -2", or
> # d. "value is greater than 3 or less than -3".
> # (3) print each of the four counts in the count vector using a while loop.
> #
> # For example, if the vector x contains the following ten values,
> #
> # 1.1478911  1.6183994 -2.3790632 -0.2566993  0.8923735
> # -0.7523441 -0.7559083  0.9836396  1.0994189  2.5519972
> #
> # Then, the output should be as below.
> #
> # count[1] is 5
> # count[2] is 3
> # count[3] is 2
> # count[4] is 0
>
> x <- rnorm(10)
>
> My answers:
>
> (1) count <- c(rep(0,4))
>
> (2) for (count in x) {
>             if (x > -1 & x < 1) {
>                  print(count[1])
>   }
>
> I know there is something wrong with my code for part one but we haven't gone over anything like this in class and I have struggled to find a video for something like this. Please point me in the right direction and let me know what mistakes I have made, thanks so much!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 24 11:29:08 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 24 Sep 2020 09:29:08 +0000
Subject: [R] Help with for loops and if statements
In-Reply-To: <4555233F-DD76-4309-8999-CA60A90E4376@gmail.com>
References: <4555233F-DD76-4309-8999-CA60A90E4376@gmail.com>
Message-ID: <8ea174da75074873b1b6e1d120ca03aa@SRVEXCHCM1302.precheza.cz>

Hi 

And above what Jim suggested, count is only a placeholder for results of
tasks a-d.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dan Bosio
> Sent: Wednesday, September 23, 2020 11:00 PM
> To: r-help at r-project.org
> Subject: [R] Help with for loops and if statements
> 
> Hi there
> 
> I am in an intro to R course and the professor has not been much help. One
of
> the questions on the latest homework has me stumped. The question is
> below, along with my answers so far.
> 
> 8. [15 points] Given the following code, # # x <- rnorm(10) # # Do the
> following.
> #
> # (1) create a count vector named "count" of four elements and set each to
0
> using the rep function.
> # (2) using a for loop to process each value in the vector x, count how
many
> times each of the following values occur in the vector x using an if
statement.
> # a. "value is between -1 and 1 inclusive"
> # b. "value is between -2 and 2 inclusive, but not between -1 and 1", # c.
> "value is between -3 and 3 inclusive, but not between -2 and -2", or # d.
> "value is greater than 3 or less than -3".
> # (3) print each of the four counts in the count vector using a while
loop.
> #
> # For example, if the vector x contains the following ten values, # #
1.1478911
> 1.6183994 -2.3790632 -0.2566993  0.8923735 # -0.7523441 -0.7559083
> 0.9836396  1.0994189  2.5519972 # # Then, the output should be as below.
> #
> # count[1] is 5
> # count[2] is 3
> # count[3] is 2
> # count[4] is 0
> 
> x <- rnorm(10)
> 
> My answers:
> 
> (1) count <- c(rep(0,4))
> 
> (2) for (count in x) {
>             if (x > -1 & x < 1) {
>                  print(count[1])
>   }
> 
> I know there is something wrong with my code for part one but we haven't
> gone over anything like this in class and I have struggled to find a video
for
> something like this. Please point me in the right direction and let me
know
> what mistakes I have made, thanks so much!
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Thu Sep 24 13:14:52 2020
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Thu, 24 Sep 2020 14:14:52 +0300
Subject: [R] Quadratic programming
In-Reply-To: <CAB8pepxwY6HidhOhhxXya997wJdkOPk-X6z9fY7mrAACB6VSTQ@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepwwT3sqmnYt43bE3VrSUMjxnSAdrFV9LoiLHXwSjWSM5Q@mail.gmail.com>
 <CAB8pepwZQ1=q25DkT859Fo-EBYjiCA9GJGfP739+QC=NgAfw6g@mail.gmail.com>
 <CAJxz9NYoeM_eYqVOg6g65TgHenoANNrkMfDB+whddrT5hYXgmg@mail.gmail.com>
 <CAB8pepxwY6HidhOhhxXya997wJdkOPk-X6z9fY7mrAACB6VSTQ@mail.gmail.com>
Message-ID: <CAJxz9NY6Xz058j0AEbsQbG0JNacM=+-bmJSNKgOEXUxscLu_9A@mail.gmail.com>

Thank you for giving me your time!

The problem is the quadratic optimization part. Something goes wrong along
the way. In C++ loops run from 0 and in R they run from 1, and I've tried
to take that into account. Still I'm having hard time figuring out the
mistake I make, cause I get a result from my R code. It's just not the same
that I get with the C++.

Here are the quadratic optimization parts for both codes.

C++

  /* Set Up Quadratic Programing Problem */
Vector<double> hSmooth(J);
for(int j=0; j<J; j++) hSmooth(j) = -pow(kr.Phi(j),Rho);
Vector<double> Q(J);
for(int j=0; j<J; j++) Q(j) = exp(-Rho * (Beta * pow(Price(j),Eta + One) -
One) / (One + Eta));
SymmetricMatrix<double> H(J,Zero);
Vector<double> c(J,Zero);
Matrix<double> Aeq(0,J);
Vector<double> beq(0);
Matrix<double> Aneq(2*J-3,J,Zero);
Vector<double> bneq(2*J-3);
Vector<double> lb(J,-Inf);
Vector<double> ub(J,Inf);
for(int j=0; j<J; j++) H(j,j) = One;
for(int j=0; j<J; j++) c(j) = -hSmooth(j);

for(int j=1; j<J; j++)
{
Aneq(j-1,j-1) = -One;
Aneq(j-1,j)   = One;
bneq[j-1]     = Delta1;
}
for(int j=2; j<J; j++)
{
Aneq(J-1+j-2,j)   = -One / (Q(j) - Q(j-1));
Aneq(J-1+j-2,j-1) = One / (Q(j) - Q(j-1)) + One / (Q(j-1) - Q(j-2));
Aneq(J-1+j-2,j-2) = -One / (Q(j-1) - Q(j-2));
bneq[J-1+j-2]     = Delta2;
}

/* Solve Constrained Optimization Problem Using Quadratic Programming */
MinQuadProg qp(c,H,Aeq,beq,Aneq,bneq,lb,ub);
qp.PrintLevel = 0;
qp.Solve();

And R

J <- length(Price)
hs <- numeric(J)
for(j in 1:J){
  hs[j] <-(-(gEst$KernelRegPartLin..Phi[j]^(-0.1)))
}
hs

Q <- rep(0,J)
for(j in 1:(length(Price))){
  Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
}
Q
plot(Q)
Dmat <- matrix(0,nrow= J, ncol=J)
diag(Dmat) <- 1
dvec <- -hs
Aeq <- 0
beq <- 0
Amat <- matrix(0,J,2*J-3)
bvec <- rep(0,2*J-3)

for(j in 2:nrow(Amat)){
  Amat[j-1,j-1] = -1
  Amat[j,j-1] = 1
}

for(j in 3:nrow(Amat)){
  Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
  Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
  Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
}

for(j in 2:nrow(bvec)) {
  bvec[j-1] = Delta1
}
for(j in 3:nrow(bvec)) {
  bvec[J-1+j-2] = Delta2
}

solution <- solve.QP(Dmat,dvec,Amat,bvec)





ke 23. syysk. 2020 klo 9.12 Abby Spurdle (spurdle.a at gmail.com) kirjoitti:

> > I'm trying to replicate a C++ code with R.
>
> Notes:
> (1) I'd recommend you make the code more modular.
> i.e. One function for initial data prep/modelling, one function for
> setting up and solving the QP, etc.
> This should be easier to debug.
> (However, you would probably have to do it to the C++ code first).
> (2) Your R code is not completely reproducible.
> i.e. AEJData
> (3) For the purposes of a reproducible example, your code can be
> simplified.
> i.e. Only one contributed R package should be attached.
>
> Regardless of (1) above, you should be able to identify at what point
> the C++ and R code becomes inconsistent.
> The simplest approach is to add print-based functions into both the
> C++ and R code, and print out state data, at each major step.
> Then all you need to do is compare the output for both.
>
> > Is there a better/another package for these types of problems?
>
> I'm not sure.
> After a quick search, this is the best I found:
>
> scam::scam
> scam::shape.constrained.smooth.terms
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Thu Sep 24 14:05:57 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 24 Sep 2020 08:05:57 -0400
Subject: [R] R Implementation of the James and/or Bang RCT Blinding
 Assessment Indices
Message-ID: <705A1A1F-301F-4331-A8DB-75A908B6559D@me.com>

Hi All,

I am wondering if anyone has an R implementation of the James (1996) and/or Bang (2004) blinding assessment indices for randomized, controlled clinical trials. Ideally, I am looking for both.

I have Googled, search using rseek.org, and checked the CRAN clinical trials task view and came up empty handed.

Thanks in advance for any leads!

Regards,

Marc Schwartz


From dr|go@@nge|o @end|ng |rom gm@||@com  Wed Sep 23 19:08:48 2020
From: dr|go@@nge|o @end|ng |rom gm@||@com (=?UTF-8?Q?Rodrigo_=C3=82ngelo?=)
Date: Wed, 23 Sep 2020 14:08:48 -0300
Subject: [R] help with nesting if else statements
In-Reply-To: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
References: <CAF9-5jP5eEs9qPccO4c4WZNhPSSSFwS7kr8cF=pobf4tsqgPDw@mail.gmail.com>
Message-ID: <CANsnirWoDEELTz60C+ifR64OtEmKfB8rWby9h4zn4hoZ6ss2Fg@mail.gmail.com>

Hi Ana,

The ifelse function works like this:

*ifelse(condition, if.true, if.false)*

it will check the condition, and if, and only if, condition is true, it
will execute whatever is in if.true,

and if condition is false (and only if the condition is false) it will
execute what's in if.false.

when nesting it, you should establish an order of priorities of your rules,
and put the one with most priority first.

In your case, it seems that the rule

*PLASER==2 -> PHENO==2*

has greater priority over

*CURRELIG==1 -> PHENO==1*

so the order should be the opposite.

On Wed, Sep 23, 2020, 13:44 Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Hello,
>
> I have a data frame as shown bellow.
> I want to create a new column PHENO which will be defined as follows:
> if CURRELIG==1 -> PHENO==1
> in the above subset those that have:
> PLASER==2 -> PHENO==2
> and
> those where RTNPTHY==1 -> PHENO==1
>
> I tried doing this:
> a$PHENO=ifelse(a$CURRELIG==1 | a$RTNPTHY==1  ,1,ifelse(a$PLASER==2 |
> a$RTNPTHY==2,2,NA))
>
> but this give me some lines where I am not seeing results that I want,
> for example:
> FID           IID CURRELIG PLASER RTNPTHY PHENO
> fam5628 G5628        1                 2       2                1
>
> here the PHENO should be =2 because RTNPTHY==2 and PLASER==2
> PHENO should be ==2 when either RTNPTHY==2 or PLASER==2
>
> another wrong line is this:
> FID              IID CURRELIG PLASER RTNPTHY PHENO
> fam5706    G5706        1            1                 2             1
>
> again RTNPTHY ==2 and PHENO==1 instead of 2.
>
> My data looks like this:
> FID  IID CURRELIG PLASER RTNPTHY
> fam5610 G5610        1      1       1
> fam5614 G5614        1      2       2
> fam5615 G5615        1      1       1
> fam5618 G5618        1      1       2
> fam5621 G5621        1      1       1
> fam5624 G5624        1      1       2
> fam5625 G5625        1      1       1
> fam5628 G5628        1      2       2
> fam5633 G5633        1      2       2
> fam5634 G5634        1      1       1
> fam5635 G5635        2      2       2
> fam5636 G5636        1      1       1
> fam5641 G5641        1      1       1
> fam5645 G5645        2      1       2
> fam5646 G5646        2      2       2
> fam5654 G5654        1      2       2
> fam5655 G5655        1      2       2
> fam5656 G5656        2      2       2
> fam5658 G5658        1      1       1
> fam5659 G5659        2      2       2
> fam5660 G5660        1      1       1
> fam5661 G5661        2      2       2
> fam5664 G5664        1      1       1
> fam5666 G5666        1      1       1
> fam5667 G5667        1      1       2
> fam5670 G5670        1      1       1
> fam5671 G5671        1      1       2
> fam5672 G5672        1      1       2
> fam5673 G5673        1      1       1
> fam5680 G5680        1      2       2
> fam5686 G5686        1      2       2
> fam5687 G5687        1      2       2
> fam5688 G5688        1      1       2
> fam5693 G5693        2      1       1
> fam5695 G5695        1      1       1
> fam5697 G5697        1      1       1
> fam5700 G5700        1      2       2
> fam5701 G5701        1      1       1
> fam5706 G5706        1      1       2
> fam5709 G5709        1      1       1
> fam5713 G5713        1      1       1
> fam5715 G5715        1      1       1
> fam5718 G5718        1      1       1
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rt|n@ke||er-re@@e| @end|ng |rom tu-dre@den@de  Thu Sep 24 09:08:24 2020
From: m@rt|n@ke||er-re@@e| @end|ng |rom tu-dre@den@de (Martin Keller-Ressel)
Date: Thu, 24 Sep 2020 07:08:24 +0000
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
 <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
 <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>
 <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>
Message-ID: <C06017CA-827E-43BA-A581-729AE46AC032@tu-dresden.de>

Dear Duncan, Dear Rui,

thanks for the responses and for pointing out that it is the ?fuzz? part that is causing the problem. I agree that this is not a bug, but could be undesirable/surprising behaviour, since it causes a large ?discontinuity? in the jitter functions output depending on the input data.

I was (ab?)using the jitter function to break ties, where the desired behaviour would be to add noise just small enough to make all values unique. (Such a function can easily be hand coded of course.)

best regards,
Martin

Am 23.09.2020 um 22:25 schrieb Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>>:

On 23/09/2020 4:03 p.m., Rui Barradas wrote:
Hello,
I believe that though Duncan's explanation is right it is also not
explaining the value of the digits argument. round makes the first 2
numbers 0 but why?

If there had been rounding in their computation, you might see a difference like 1e-15.  You wouldn't want to use that for the scale of jittering, so some rounding is needed.

I think the documentation for the function is poor, but the intention was probably to use the function in graphics (as the references did), and in that case, any values too close together should be treated as equal and jittering should separate them.  The particular computation used says that if the range is in [1, 10), values equal to 3 decimal places will be too close and need separation.

So I don't think this is a bug, but it might be a valid wishlist item: document what "apart from fuzz" means, and perhaps allow it to be controlled by the user.

Duncan Murdoch



The function below prints the digits argument and
then outputs d. The code is taken from jitter.
f <- function(x){
   z <- diff(r <- range(x[is.finite(x)]))
   cat("digits:", 3 - floor(log10(z)), "\n")
   diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
}
Now see what cat outputs for 'digits'.
f(c(1,2,10^4))  # desired behaviour
#digits: 0
#[1]    1 9998
f(c(0,1,10^4))  # bad behaviour
#digits: -1
#[1] 10000
f(c(-1,0,10^4))  # bad behaviour
#digits: -1
#[1] 10000
f(c(1,2,10^5))  # bad behaviour
#digits: -1
#[1] 1e+05
And according to the documentation of ?round, negative digits are allowed:
Rounding to a negative number of digits means rounding to a power of
ten, so for example round(x, digits = -2) rounds to the nearest hundred.
But in this case two of the numbers are closer to 0 than they are of 10.
And unique keeps only 0 and the largest, then diff is big.
round(c(1,2,10^4),0)  # desired behaviour
#[1]     1     2 10000
round(c(0,1,10^4),-1)  # bad behaviour
#[1]     0     0 10000
round(c(-1,0,10^4),-1)  # bad behaviour
#[1]     0     0 10000
round(c(1,2,10^5),-1)  # bad behaviour
#[1] 0e+00 0e+00 1e+05
Isn't it still a bug?
Rui Barradas
?s 15:57 de 23/09/20, Duncan Murdoch escreveu:
On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
Dear all,

i have noticed some strange behaviour in the ?jitter? function in R.
On the help page for jitter it is stated that

"The result, say r, is r <- x + runif(n, -a, a) where n <- length(x)
and a is the amount argument (if specified).?

and

"If amount is NULL (default), we set a <- factor * d/5 where d is the
smallest difference between adjacent unique (apart from fuzz) x values.?

This works fine as long as there is no (very) large outlier

jitter(c(1,2,10^4))  # desired behaviour
[1]    1.083243    1.851571 9999.942716

But for very large outliers the added noise suddenly ?jumps? to a much
larger scale:

jitter(c(1,2,10^5)) # bad behaviour
[1] -19535.649   9578.702 115693.854
# Noise should be of order (2-1)/5  = 0.2 but is of much larger order.

This probably does not matter much when jitter is used for plotting,
but it can cause problems when jitter is used to break ties.

I think this is kind of documented:  "apart from fuzz" is what counts.
If you look at the code for jitter, you'll see this important line:

  d <- diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))

By the time you get here, z is the length of the rante of the data, so
it's 99999 in your example.  The rounding changes your values to
0,0,1e5, so the smallest difference is 1e5.

Duncan Murdoch

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From rkoenker @end|ng |rom ||||no|@@edu  Thu Sep 24 17:53:02 2020
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Thu, 24 Sep 2020 15:53:02 +0000
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <C06017CA-827E-43BA-A581-729AE46AC032@tu-dresden.de>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
 <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
 <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>
 <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>
 <C06017CA-827E-43BA-A581-729AE46AC032@tu-dresden.de>
Message-ID: <F9322D7D-1ABF-48F1-B216-1A57E7DFCFF2@illinois.edu>

FWIW, there is a similar function called ?dither? in the quantreg package.

> On Sep 24, 2020, at 8:08 AM, Martin Keller-Ressel <martin.keller-ressel at tu-dresden.de> wrote:
> 
> Dear Duncan, Dear Rui,
> 
> thanks for the responses and for pointing out that it is the ?fuzz? part that is causing the problem. I agree that this is not a bug, but could be undesirable/surprising behaviour, since it causes a large ?discontinuity? in the jitter functions output depending on the input data.
> 
> I was (ab?)using the jitter function to break ties, where the desired behaviour would be to add noise just small enough to make all values unique. (Such a function can easily be hand coded of course.)
> 
> best regards,
> Martin
> 
> Am 23.09.2020 um 22:25 schrieb Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>>:
> 
> On 23/09/2020 4:03 p.m., Rui Barradas wrote:
> Hello,
> I believe that though Duncan's explanation is right it is also not
> explaining the value of the digits argument. round makes the first 2
> numbers 0 but why?
> 
> If there had been rounding in their computation, you might see a difference like 1e-15.  You wouldn't want to use that for the scale of jittering, so some rounding is needed.
> 
> I think the documentation for the function is poor, but the intention was probably to use the function in graphics (as the references did), and in that case, any values too close together should be treated as equal and jittering should separate them.  The particular computation used says that if the range is in [1, 10), values equal to 3 decimal places will be too close and need separation.
> 
> So I don't think this is a bug, but it might be a valid wishlist item: document what "apart from fuzz" means, and perhaps allow it to be controlled by the user.
> 
> Duncan Murdoch
> 
> 
> 
> The function below prints the digits argument and
> then outputs d. The code is taken from jitter.
> f <- function(x){
>   z <- diff(r <- range(x[is.finite(x)]))
>   cat("digits:", 3 - floor(log10(z)), "\n")
>   diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
> }
> Now see what cat outputs for 'digits'.
> f(c(1,2,10^4))  # desired behaviour
> #digits: 0
> #[1]    1 9998
> f(c(0,1,10^4))  # bad behaviour
> #digits: -1
> #[1] 10000
> f(c(-1,0,10^4))  # bad behaviour
> #digits: -1
> #[1] 10000
> f(c(1,2,10^5))  # bad behaviour
> #digits: -1
> #[1] 1e+05
> And according to the documentation of ?round, negative digits are allowed:
> Rounding to a negative number of digits means rounding to a power of
> ten, so for example round(x, digits = -2) rounds to the nearest hundred.
> But in this case two of the numbers are closer to 0 than they are of 10.
> And unique keeps only 0 and the largest, then diff is big.
> round(c(1,2,10^4),0)  # desired behaviour
> #[1]     1     2 10000
> round(c(0,1,10^4),-1)  # bad behaviour
> #[1]     0     0 10000
> round(c(-1,0,10^4),-1)  # bad behaviour
> #[1]     0     0 10000
> round(c(1,2,10^5),-1)  # bad behaviour
> #[1] 0e+00 0e+00 1e+05
> Isn't it still a bug?
> Rui Barradas
> ?s 15:57 de 23/09/20, Duncan Murdoch escreveu:
> On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
> Dear all,
> 
> i have noticed some strange behaviour in the ?jitter? function in R.
> On the help page for jitter it is stated that
> 
> "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x)
> and a is the amount argument (if specified).?
> 
> and
> 
> "If amount is NULL (default), we set a <- factor * d/5 where d is the
> smallest difference between adjacent unique (apart from fuzz) x values.?
> 
> This works fine as long as there is no (very) large outlier
> 
> jitter(c(1,2,10^4))  # desired behaviour
> [1]    1.083243    1.851571 9999.942716
> 
> But for very large outliers the added noise suddenly ?jumps? to a much
> larger scale:
> 
> jitter(c(1,2,10^5)) # bad behaviour
> [1] -19535.649   9578.702 115693.854
> # Noise should be of order (2-1)/5  = 0.2 but is of much larger order.
> 
> This probably does not matter much when jitter is used for plotting,
> but it can cause problems when jitter is used to break ties.
> 
> I think this is kind of documented:  "apart from fuzz" is what counts.
> If you look at the code for jitter, you'll see this important line:
> 
>  d <- diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
> 
> By the time you get here, z is the length of the rante of the data, so
> it's 99999 in your example.  The rounding changes your values to
> 0,0,1e5, so the smallest difference is 1e5.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 24 19:03:41 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 24 Sep 2020 10:03:41 -0700
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <C06017CA-827E-43BA-A581-729AE46AC032@tu-dresden.de>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
 <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
 <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>
 <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>
 <C06017CA-827E-43BA-A581-729AE46AC032@tu-dresden.de>
Message-ID: <CAGxFJbRf0MguyS+-pb7HiFWPZg_axyaYoWyKDLzPpBBdkfvw-Q@mail.gmail.com>

Folks: Please note:

There is *no* way to "jitter" the 3 values 1,2, and 1e5 so that:

a) the jittered values differ from the original ones by a fraction of their
original value;
b) the plotting symbols for the jittered values will be distinguishable on
a linear scale holding all 3 values.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 24, 2020 at 8:39 AM Martin Keller-Ressel <
martin.keller-ressel at tu-dresden.de> wrote:

> Dear Duncan, Dear Rui,
>
> thanks for the responses and for pointing out that it is the ?fuzz? part
> that is causing the problem. I agree that this is not a bug, but could be
> undesirable/surprising behaviour, since it causes a large ?discontinuity?
> in the jitter functions output depending on the input data.
>
> I was (ab?)using the jitter function to break ties, where the desired
> behaviour would be to add noise just small enough to make all values
> unique. (Such a function can easily be hand coded of course.)
>
> best regards,
> Martin
>
> Am 23.09.2020 um 22:25 schrieb Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>:
>
> On 23/09/2020 4:03 p.m., Rui Barradas wrote:
> Hello,
> I believe that though Duncan's explanation is right it is also not
> explaining the value of the digits argument. round makes the first 2
> numbers 0 but why?
>
> If there had been rounding in their computation, you might see a
> difference like 1e-15.  You wouldn't want to use that for the scale of
> jittering, so some rounding is needed.
>
> I think the documentation for the function is poor, but the intention was
> probably to use the function in graphics (as the references did), and in
> that case, any values too close together should be treated as equal and
> jittering should separate them.  The particular computation used says that
> if the range is in [1, 10), values equal to 3 decimal places will be too
> close and need separation.
>
> So I don't think this is a bug, but it might be a valid wishlist item:
> document what "apart from fuzz" means, and perhaps allow it to be
> controlled by the user.
>
> Duncan Murdoch
>
>
>
> The function below prints the digits argument and
> then outputs d. The code is taken from jitter.
> f <- function(x){
>    z <- diff(r <- range(x[is.finite(x)]))
>    cat("digits:", 3 - floor(log10(z)), "\n")
>    diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
> }
> Now see what cat outputs for 'digits'.
> f(c(1,2,10^4))  # desired behaviour
> #digits: 0
> #[1]    1 9998
> f(c(0,1,10^4))  # bad behaviour
> #digits: -1
> #[1] 10000
> f(c(-1,0,10^4))  # bad behaviour
> #digits: -1
> #[1] 10000
> f(c(1,2,10^5))  # bad behaviour
> #digits: -1
> #[1] 1e+05
> And according to the documentation of ?round, negative digits are allowed:
> Rounding to a negative number of digits means rounding to a power of
> ten, so for example round(x, digits = -2) rounds to the nearest hundred.
> But in this case two of the numbers are closer to 0 than they are of 10.
> And unique keeps only 0 and the largest, then diff is big.
> round(c(1,2,10^4),0)  # desired behaviour
> #[1]     1     2 10000
> round(c(0,1,10^4),-1)  # bad behaviour
> #[1]     0     0 10000
> round(c(-1,0,10^4),-1)  # bad behaviour
> #[1]     0     0 10000
> round(c(1,2,10^5),-1)  # bad behaviour
> #[1] 0e+00 0e+00 1e+05
> Isn't it still a bug?
> Rui Barradas
> ?s 15:57 de 23/09/20, Duncan Murdoch escreveu:
> On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
> Dear all,
>
> i have noticed some strange behaviour in the ?jitter? function in R.
> On the help page for jitter it is stated that
>
> "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x)
> and a is the amount argument (if specified).?
>
> and
>
> "If amount is NULL (default), we set a <- factor * d/5 where d is the
> smallest difference between adjacent unique (apart from fuzz) x values.?
>
> This works fine as long as there is no (very) large outlier
>
> jitter(c(1,2,10^4))  # desired behaviour
> [1]    1.083243    1.851571 9999.942716
>
> But for very large outliers the added noise suddenly ?jumps? to a much
> larger scale:
>
> jitter(c(1,2,10^5)) # bad behaviour
> [1] -19535.649   9578.702 115693.854
> # Noise should be of order (2-1)/5  = 0.2 but is of much larger order.
>
> This probably does not matter much when jitter is used for plotting,
> but it can cause problems when jitter is used to break ties.
>
> I think this is kind of documented:  "apart from fuzz" is what counts.
> If you look at the code for jitter, you'll see this important line:
>
>   d <- diff(xx <- unique(sort.int(round(x, 3 - floor(log10(z))))))
>
> By the time you get here, z is the length of the rante of the data, so
> it's 99999 in your example.  The rounding changes your values to
> 0,0,1e5, so the smallest difference is 1e5.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep 24 19:24:20 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 24 Sep 2020 13:24:20 -0400
Subject: [R] jitter-bug? problematic behaviour of the jitter function
In-Reply-To: <CAGxFJbRf0MguyS+-pb7HiFWPZg_axyaYoWyKDLzPpBBdkfvw-Q@mail.gmail.com>
References: <73603450-9515-46F0-B369-A26F5BF9D0A4@tu-dresden.de>
 <3479921d-f144-6188-def1-4791dbf49107@gmail.com>
 <d3e14a06-91d8-2589-14ba-dce89ba0be47@sapo.pt>
 <3eb9fe6b-76fe-db2a-24ec-7c50fce5f4fe@gmail.com>
 <C06017CA-827E-43BA-A581-729AE46AC032@tu-dresden.de>
 <CAGxFJbRf0MguyS+-pb7HiFWPZg_axyaYoWyKDLzPpBBdkfvw-Q@mail.gmail.com>
Message-ID: <e8c2cd29-5e2e-ecbb-afc8-f044822f17c3@gmail.com>

Those seem like useful properties if jitter() is used in plotting (as it 
was originally intended), but that use isn't even mentioned in the help 
page.  Martin wanted to "add a small amount of noise to a numeric 
vector" "in order to break ties" (quoting from that help page).

For Martin's use, it sounds as though quantreg::dither might be a better 
solution (though I think it won't work when numerical error splits ties, 
so some differences are extremely small, if the scale of the values 
varies too much, but I'd guess that's a fairly rare circumstance).

Duncan Murdoch

On 24/09/2020 1:03 p.m., Bert Gunter wrote:
> Folks: Please note:
> 
> There is *no* way to "jitter" the 3 values 1,2, and 1e5 so that:
> 
> a) the jittered values differ from the original ones by a fraction of 
> their original value;
> b) the plotting symbols for the jittered values will be distinguishable 
> on a linear scale holding all 3 values.
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Sep 24, 2020 at 8:39 AM Martin Keller-Ressel 
> <martin.keller-ressel at tu-dresden.de 
> <mailto:martin.keller-ressel at tu-dresden.de>> wrote:
> 
>     Dear Duncan, Dear Rui,
> 
>     thanks for the responses and for pointing out that it is the ?fuzz?
>     part that is causing the problem. I agree that this is not a bug,
>     but could be undesirable/surprising behaviour, since it causes a
>     large ?discontinuity? in the jitter functions output depending on
>     the input data.
> 
>     I was (ab?)using the jitter function to break ties, where the
>     desired behaviour would be to add noise just small enough to make
>     all values unique. (Such a function can easily be hand coded of course.)
> 
>     best regards,
>     Martin
> 
>     Am 23.09.2020 um 22:25 schrieb Duncan Murdoch
>     <murdoch.duncan at gmail.com
>     <mailto:murdoch.duncan at gmail.com><mailto:murdoch.duncan at gmail.com
>     <mailto:murdoch.duncan at gmail.com>>>:
> 
>     On 23/09/2020 4:03 p.m., Rui Barradas wrote:
>     Hello,
>     I believe that though Duncan's explanation is right it is also not
>     explaining the value of the digits argument. round makes the first 2
>     numbers 0 but why?
> 
>     If there had been rounding in their computation, you might see a
>     difference like 1e-15.? You wouldn't want to use that for the scale
>     of jittering, so some rounding is needed.
> 
>     I think the documentation for the function is poor, but the
>     intention was probably to use the function in graphics (as the
>     references did), and in that case, any values too close together
>     should be treated as equal and jittering should separate them.? The
>     particular computation used says that if the range is in [1, 10),
>     values equal to 3 decimal places will be too close and need separation.
> 
>     So I don't think this is a bug, but it might be a valid wishlist
>     item: document what "apart from fuzz" means, and perhaps allow it to
>     be controlled by the user.
> 
>     Duncan Murdoch
> 
> 
> 
>     The function below prints the digits argument and
>     then outputs d. The code is taken from jitter.
>     f <- function(x){
>      ? ?z <- diff(r <- range(x[is.finite(x)]))
>      ? ?cat("digits:", 3 - floor(log10(z)), "\n")
>      ? ?diff(xx <- unique(sort.int <http://sort.int>(round(x, 3 -
>     floor(log10(z))))))
>     }
>     Now see what cat outputs for 'digits'.
>     f(c(1,2,10^4))? # desired behaviour
>     #digits: 0
>     #[1]? ? 1 9998
>     f(c(0,1,10^4))? # bad behaviour
>     #digits: -1
>     #[1] 10000
>     f(c(-1,0,10^4))? # bad behaviour
>     #digits: -1
>     #[1] 10000
>     f(c(1,2,10^5))? # bad behaviour
>     #digits: -1
>     #[1] 1e+05
>     And according to the documentation of ?round, negative digits are
>     allowed:
>     Rounding to a negative number of digits means rounding to a power of
>     ten, so for example round(x, digits = -2) rounds to the nearest hundred.
>     But in this case two of the numbers are closer to 0 than they are of 10.
>     And unique keeps only 0 and the largest, then diff is big.
>     round(c(1,2,10^4),0)? # desired behaviour
>     #[1]? ? ?1? ? ?2 10000
>     round(c(0,1,10^4),-1)? # bad behaviour
>     #[1]? ? ?0? ? ?0 10000
>     round(c(-1,0,10^4),-1)? # bad behaviour
>     #[1]? ? ?0? ? ?0 10000
>     round(c(1,2,10^5),-1)? # bad behaviour
>     #[1] 0e+00 0e+00 1e+05
>     Isn't it still a bug?
>     Rui Barradas
>     ?s 15:57 de 23/09/20, Duncan Murdoch escreveu:
>     On 23/09/2020 6:32 a.m., Martin Keller-Ressel wrote:
>     Dear all,
> 
>     i have noticed some strange behaviour in the ?jitter? function in R.
>     On the help page for jitter it is stated that
> 
>     "The result, say r, is r <- x + runif(n, -a, a) where n <- length(x)
>     and a is the amount argument (if specified).?
> 
>     and
> 
>     "If amount is NULL (default), we set a <- factor * d/5 where d is the
>     smallest difference between adjacent unique (apart from fuzz) x values.?
> 
>     This works fine as long as there is no (very) large outlier
> 
>     jitter(c(1,2,10^4))? # desired behaviour
>     [1]? ? 1.083243? ? 1.851571 9999.942716
> 
>     But for very large outliers the added noise suddenly ?jumps? to a much
>     larger scale:
> 
>     jitter(c(1,2,10^5)) # bad behaviour
>     [1] -19535.649? ?9578.702 115693.854
>     # Noise should be of order (2-1)/5? = 0.2 but is of much larger order.
> 
>     This probably does not matter much when jitter is used for plotting,
>     but it can cause problems when jitter is used to break ties.
> 
>     I think this is kind of documented:? "apart from fuzz" is what counts.
>     If you look at the code for jitter, you'll see this important line:
> 
>      ? d <- diff(xx <- unique(sort.int <http://sort.int>(round(x, 3 -
>     floor(log10(z))))))
> 
>     By the time you get here, z is the length of the rante of the data, so
>     it's 99999 in your example.? The rounding changes your values to
>     0,0,1e5, so the smallest difference is 1e5.
> 
>     Duncan Murdoch
> 
>     ______________________________________________
>     R-help at r-project.org
>     <mailto:R-help at r-project.org><mailto:R-help at r-project.org
>     <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and
>     more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
>      ? ? ? ? [[alternative HTML version deleted]]
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From @purd|e@@ @end|ng |rom gm@||@com  Thu Sep 24 23:24:22 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 25 Sep 2020 09:24:22 +1200
Subject: [R] Quadratic programming
In-Reply-To: <CAJxz9NY6Xz058j0AEbsQbG0JNacM=+-bmJSNKgOEXUxscLu_9A@mail.gmail.com>
References: <CAJxz9NYYqNf8Ty5BSRhkwvRKY1jcCdg1Uig5HhkjrN7nRLfdNg@mail.gmail.com>
 <CAB8pepwwT3sqmnYt43bE3VrSUMjxnSAdrFV9LoiLHXwSjWSM5Q@mail.gmail.com>
 <CAB8pepwZQ1=q25DkT859Fo-EBYjiCA9GJGfP739+QC=NgAfw6g@mail.gmail.com>
 <CAJxz9NYoeM_eYqVOg6g65TgHenoANNrkMfDB+whddrT5hYXgmg@mail.gmail.com>
 <CAB8pepxwY6HidhOhhxXya997wJdkOPk-X6z9fY7mrAACB6VSTQ@mail.gmail.com>
 <CAJxz9NY6Xz058j0AEbsQbG0JNacM=+-bmJSNKgOEXUxscLu_9A@mail.gmail.com>
Message-ID: <CAB8pepwFRML81TzMBbxjxZtxmNLRW-XD3OGHpPOMuxnxrZr_PA@mail.gmail.com>

Before going any further, I have to check, what is:
MinQuadProg qp

Also, if I'm following the C++ code correctly, H, is an identity matrix.
This implies the input to the C++ solver, requires the QP in a
different form to the R solver.
In which case, the C++ inputs and the R inputs, should be different...?

(A)
It may be worthwhile comparing the solver output (for C++ and R) using
a *much* simpler example.
e.g. the examples from the quadprog package.

(B)
If they produce the same output (using a simple example), then that
implies there's a difference in your inputs.
So, you just need to work out which input values are different.
Expanding on my previous post, just print them out.
But check (A) above first.









On Thu, Sep 24, 2020 at 11:15 PM Maija Sirkj?rvi
<maija.sirkjarvi at gmail.com> wrote:
>
> Thank you for giving me your time!
>
> The problem is the quadratic optimization part. Something goes wrong along the way. In C++ loops run from 0 and in R they run from 1, and I've tried to take that into account. Still I'm having hard time figuring out the mistake I make, cause I get a result from my R code. It's just not the same that I get with the C++.
>
> Here are the quadratic optimization parts for both codes.
>
> C++
>
>   /* Set Up Quadratic Programing Problem */
> Vector<double> hSmooth(J);
> for(int j=0; j<J; j++) hSmooth(j) = -pow(kr.Phi(j),Rho);
> Vector<double> Q(J);
> for(int j=0; j<J; j++) Q(j) = exp(-Rho * (Beta * pow(Price(j),Eta + One) - One) / (One + Eta));
> SymmetricMatrix<double> H(J,Zero);
> Vector<double> c(J,Zero);
> Matrix<double> Aeq(0,J);
> Vector<double> beq(0);
> Matrix<double> Aneq(2*J-3,J,Zero);
> Vector<double> bneq(2*J-3);
> Vector<double> lb(J,-Inf);
> Vector<double> ub(J,Inf);
> for(int j=0; j<J; j++) H(j,j) = One;
> for(int j=0; j<J; j++) c(j) = -hSmooth(j);
>
> for(int j=1; j<J; j++)
> {
> Aneq(j-1,j-1) = -One;
> Aneq(j-1,j)   = One;
> bneq[j-1]     = Delta1;
> }
> for(int j=2; j<J; j++)
> {
> Aneq(J-1+j-2,j)   = -One / (Q(j) - Q(j-1));
> Aneq(J-1+j-2,j-1) = One / (Q(j) - Q(j-1)) + One / (Q(j-1) - Q(j-2));
> Aneq(J-1+j-2,j-2) = -One / (Q(j-1) - Q(j-2));
> bneq[J-1+j-2]     = Delta2;
> }
>
> /* Solve Constrained Optimization Problem Using Quadratic Programming */
> MinQuadProg qp(c,H,Aeq,beq,Aneq,bneq,lb,ub);
> qp.PrintLevel = 0;
> qp.Solve();
>
> And R
>
> J <- length(Price)
> hs <- numeric(J)
> for(j in 1:J){
>   hs[j] <-(-(gEst$KernelRegPartLin..Phi[j]^(-0.1)))
> }
> hs
>
> Q <- rep(0,J)
> for(j in 1:(length(Price))){
>   Q[j] <- exp((-0.1) * (Beta *Price[j]^(Eta + 1) - 1) / (1 + Eta))
> }
> Q
> plot(Q)
> Dmat <- matrix(0,nrow= J, ncol=J)
> diag(Dmat) <- 1
> dvec <- -hs
> Aeq <- 0
> beq <- 0
> Amat <- matrix(0,J,2*J-3)
> bvec <- rep(0,2*J-3)
>
> for(j in 2:nrow(Amat)){
>   Amat[j-1,j-1] = -1
>   Amat[j,j-1] = 1
> }
>
> for(j in 3:nrow(Amat)){
>   Amat[j,J+j-3] = -1/(Q[j]-Q[j-1])
>   Amat[j-1,J+j-3] = 1/(Q[j]-Q[j-1])
>   Amat[j-2,J+j-3] = -1/(Q[j-1]-Q[j-2])
> }
>
> for(j in 2:nrow(bvec)) {
>   bvec[j-1] = Delta1
> }
> for(j in 3:nrow(bvec)) {
>   bvec[J-1+j-2] = Delta2
> }
>
> solution <- solve.QP(Dmat,dvec,Amat,bvec)
>
>
>
>
>
> ke 23. syysk. 2020 klo 9.12 Abby Spurdle (spurdle.a at gmail.com) kirjoitti:
>>
>> > I'm trying to replicate a C++ code with R.
>>
>> Notes:
>> (1) I'd recommend you make the code more modular.
>> i.e. One function for initial data prep/modelling, one function for
>> setting up and solving the QP, etc.
>> This should be easier to debug.
>> (However, you would probably have to do it to the C++ code first).
>> (2) Your R code is not completely reproducible.
>> i.e. AEJData
>> (3) For the purposes of a reproducible example, your code can be simplified.
>> i.e. Only one contributed R package should be attached.
>>
>> Regardless of (1) above, you should be able to identify at what point
>> the C++ and R code becomes inconsistent.
>> The simplest approach is to add print-based functions into both the
>> C++ and R code, and print out state data, at each major step.
>> Then all you need to do is compare the output for both.
>>
>> > Is there a better/another package for these types of problems?
>>
>> I'm not sure.
>> After a quick search, this is the best I found:
>>
>> scam::scam
>> scam::shape.constrained.smooth.terms


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 25 13:43:37 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 25 Sep 2020 21:43:37 +1000
Subject: [R] package plotrix: how to account for two two z categories
In-Reply-To: <CA+8X3fVCAKEmRjGYq30-kPEDtsxBXWH6GD+Krfp=W+bAF7K66g@mail.gmail.com>
References: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
 <CA+8X3fVgNC_yUyFFkV3Li+o_k6S5J7ZKBdf_ktVc84fZECMxrg@mail.gmail.com>
 <CAMk+s2Rtk=ujC-1AmzwJ9o3foH+DcdpuJmB2MFDKJTGA_i593A@mail.gmail.com>
 <CA+8X3fUyrMKgFNXj+Ok5AX_aU02emktM1WtgSSvxoOYx5sDKzA@mail.gmail.com>
 <CA+8X3fVCAKEmRjGYq30-kPEDtsxBXWH6GD+Krfp=W+bAF7K66g@mail.gmail.com>
Message-ID: <CA+8X3fVKfRE-YtRvEkWG__H4c_GK-vJ_2G_OazijhD57Q-SYmg@mail.gmail.com>

Hi Luigi,
Here is a quick example of how points would look in the same
configuration. Perhaps with end caps to show the nesting it may be
more like what you want.

Jim

On Thu, Sep 24, 2020 at 6:34 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Oh, sorry, forgot about the colors. A list beginning with the color
> for the overall summary, then colors for the first factor and so on.
> See the help page for examples.
>
> Jim
>
> On Thu, Sep 24, 2020 at 6:32 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > I thought a lot about that when I was writing the function. The only
> > way I could think of to show the nesting was dots with horizontal
> > lines and it looked messy and was quite hard to visualize the nesting.
> > If you do have any great ideas I always welcome contributions to
> > plotrix.
> >
> > Jim
> >
> > On Thu, Sep 24, 2020 at 6:25 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Thank you Jim, that is really nice!
> > > But is there a way to use dots instead of boxes? and how do I control
> > > the colours?
> > > Best regards
> > > Luigi
> > >
> > > On Thu, Sep 24, 2020 at 9:29 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >
> > > > Hi Luigi,
> > > > To display a nested breakdown like this I would suggest barNest. This
> > > > is one way to display the nesting. Note that if you change the order
> > > > of the factors in the formula you will get a different plot, so think
> > > > about how you want the summaries nested. Error bars can only be
> > > > displayed on the final breakdown.
> > > >
> > > > # because you have fairly long labels, use a wide plot
> > > > x11(width=10)
> > > > barcol<-list("lightgray",c("#ff00ff","#ff99ff"),
> > > >  c("#00ff00","#66ff66"),c("#aaaa00","#888800"))
> > > > barNest(y~x+z+w,Q,main="Double Measurement",
> > > >  ylab="Response",col=barcol,errbars=TRUE)
> > > >
> > > > Jim
> > > >
> > > > On Wed, Sep 23, 2020 at 10:48 PM Luigi Marongiu
> > > > <marongiu.luigi at gmail.com> wrote:
> > > > >
> > > > > Hello,
> > > > > I have an experiment measuring optical density (OD) when comparing
> > > > > three parameters:
> > > > > a) concentration of the target
> > > > > b) concentration of the probe
> > > > > c) concentration of the reporter antibody.
> > > > > Using plotrix I can nicely draw the first two into clusters, but I
> > > > > can't get separation for the third parameter. is there a way in
> > > > > plotrix to custer data according to two, let's say, z parameters (I
> > > > > call the second high-level parameter as w)? For instance, two
> > > > > clusters, each separated into two subclusters. Or is this more a job
> > > > > for lattice?
> > > > > Thank you.
> > > > >
> > > > > ```
> > > > > x = rep(c(rep("1000 pmol", 4), rep("0 pmol", 4)),2)
> > > > > z =  rep(c(rep("Treated", 2), rep("Untreated", 2), rep("Treated", 2),
> > > > > rep("Untreated", 2)))
> > > > > w = c(rep("1:1000", 8), rep("1:2000", 8))
> > > > > y = c(1.18, 1.22, 1.52, 2.37, 0.97, 1.08, 1.17, 1.58, 1.16, 1.16, 2.27, 2.24,
> > > > >       1.26, 1.28, 1.39, 1.77)
> > > > > Q = data.frame(x, z, w, y, stringsAsFactors = FALSE)
> > > > > names(Q) = c("[Target]", "Enzyme", "[Antibody]", "OD")
> > > > > names(Q) = c("x", "z", "w", "y") # for ease, I'll use single letters
> > > > > library(plotrix)
> > > > > brkdn.plot(y~x+z, data=Q,
> > > > >            pch = c(1, 16), cex = 1.5, type="p",
> > > > >            main="Single Measurement",
> > > > >            xlab=expression(bold("S1 nuclease")),
> > > > >            ylab=expression(bold("Optical density")))
> > > > > brkdn.plot(y~x+z+w, data=Q,
> > > > >            pch = c(1, 16), cex = 1.5, type="p",
> > > > >            main="Double Measurement",
> > > > >            xlab=expression(bold("S1 nuclease")),
> > > > >            ylab=expression(bold("Optical density")))
> > > > > ```
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi

-------------- next part --------------
A non-text attachment was scrubbed...
Name: lm_plot.png
Type: image/png
Size: 18874 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200925/6681962e/attachment.png>

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 25 13:53:58 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 25 Sep 2020 13:53:58 +0200
Subject: [R] package plotrix: how to account for two two z categories
In-Reply-To: <CA+8X3fVKfRE-YtRvEkWG__H4c_GK-vJ_2G_OazijhD57Q-SYmg@mail.gmail.com>
References: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
 <CA+8X3fVgNC_yUyFFkV3Li+o_k6S5J7ZKBdf_ktVc84fZECMxrg@mail.gmail.com>
 <CAMk+s2Rtk=ujC-1AmzwJ9o3foH+DcdpuJmB2MFDKJTGA_i593A@mail.gmail.com>
 <CA+8X3fUyrMKgFNXj+Ok5AX_aU02emktM1WtgSSvxoOYx5sDKzA@mail.gmail.com>
 <CA+8X3fVCAKEmRjGYq30-kPEDtsxBXWH6GD+Krfp=W+bAF7K66g@mail.gmail.com>
 <CA+8X3fVKfRE-YtRvEkWG__H4c_GK-vJ_2G_OazijhD57Q-SYmg@mail.gmail.com>
Message-ID: <CAMk+s2TJy5doemtiiYLE90c+TfeB1=tdr7BZ6wZKJJC=NOi-7g@mail.gmail.com>

Thanks! looks nicer already.
I am attaching the figure I temporarily made with normal brkdn.plot
but yours has more information.
Best regards
Luigi

On Fri, Sep 25, 2020 at 1:43 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> Here is a quick example of how points would look in the same
> configuration. Perhaps with end caps to show the nesting it may be
> more like what you want.
>
> Jim
>
> On Thu, Sep 24, 2020 at 6:34 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Oh, sorry, forgot about the colors. A list beginning with the color
> > for the overall summary, then colors for the first factor and so on.
> > See the help page for examples.
> >
> > Jim
> >
> > On Thu, Sep 24, 2020 at 6:32 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > I thought a lot about that when I was writing the function. The only
> > > way I could think of to show the nesting was dots with horizontal
> > > lines and it looked messy and was quite hard to visualize the nesting.
> > > If you do have any great ideas I always welcome contributions to
> > > plotrix.
> > >
> > > Jim
> > >
> > > On Thu, Sep 24, 2020 at 6:25 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Thank you Jim, that is really nice!
> > > > But is there a way to use dots instead of boxes? and how do I control
> > > > the colours?
> > > > Best regards
> > > > Luigi
> > > >
> > > > On Thu, Sep 24, 2020 at 9:29 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > > >
> > > > > Hi Luigi,
> > > > > To display a nested breakdown like this I would suggest barNest. This
> > > > > is one way to display the nesting. Note that if you change the order
> > > > > of the factors in the formula you will get a different plot, so think
> > > > > about how you want the summaries nested. Error bars can only be
> > > > > displayed on the final breakdown.
> > > > >
> > > > > # because you have fairly long labels, use a wide plot
> > > > > x11(width=10)
> > > > > barcol<-list("lightgray",c("#ff00ff","#ff99ff"),
> > > > >  c("#00ff00","#66ff66"),c("#aaaa00","#888800"))
> > > > > barNest(y~x+z+w,Q,main="Double Measurement",
> > > > >  ylab="Response",col=barcol,errbars=TRUE)
> > > > >
> > > > > Jim
> > > > >
> > > > > On Wed, Sep 23, 2020 at 10:48 PM Luigi Marongiu
> > > > > <marongiu.luigi at gmail.com> wrote:
> > > > > >
> > > > > > Hello,
> > > > > > I have an experiment measuring optical density (OD) when comparing
> > > > > > three parameters:
> > > > > > a) concentration of the target
> > > > > > b) concentration of the probe
> > > > > > c) concentration of the reporter antibody.
> > > > > > Using plotrix I can nicely draw the first two into clusters, but I
> > > > > > can't get separation for the third parameter. is there a way in
> > > > > > plotrix to custer data according to two, let's say, z parameters (I
> > > > > > call the second high-level parameter as w)? For instance, two
> > > > > > clusters, each separated into two subclusters. Or is this more a job
> > > > > > for lattice?
> > > > > > Thank you.
> > > > > >
> > > > > > ```
> > > > > > x = rep(c(rep("1000 pmol", 4), rep("0 pmol", 4)),2)
> > > > > > z =  rep(c(rep("Treated", 2), rep("Untreated", 2), rep("Treated", 2),
> > > > > > rep("Untreated", 2)))
> > > > > > w = c(rep("1:1000", 8), rep("1:2000", 8))
> > > > > > y = c(1.18, 1.22, 1.52, 2.37, 0.97, 1.08, 1.17, 1.58, 1.16, 1.16, 2.27, 2.24,
> > > > > >       1.26, 1.28, 1.39, 1.77)
> > > > > > Q = data.frame(x, z, w, y, stringsAsFactors = FALSE)
> > > > > > names(Q) = c("[Target]", "Enzyme", "[Antibody]", "OD")
> > > > > > names(Q) = c("x", "z", "w", "y") # for ease, I'll use single letters
> > > > > > library(plotrix)
> > > > > > brkdn.plot(y~x+z, data=Q,
> > > > > >            pch = c(1, 16), cex = 1.5, type="p",
> > > > > >            main="Single Measurement",
> > > > > >            xlab=expression(bold("S1 nuclease")),
> > > > > >            ylab=expression(bold("Optical density")))
> > > > > > brkdn.plot(y~x+z+w, data=Q,
> > > > > >            pch = c(1, 16), cex = 1.5, type="p",
> > > > > >            main="Double Measurement",
> > > > > >            xlab=expression(bold("S1 nuclease")),
> > > > > >            ylab=expression(bold("Optical density")))
> > > > > > ```
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > > >
> > > > --
> > > > Best regards,
> > > > Luigi



-- 
Best regards,
Luigi

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 10203 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200925/63705b08/attachment.png>

From m|ch@e|@john@ton@em@|| @end|ng |rom gm@||@com  Fri Sep 25 06:55:22 2020
From: m|ch@e|@john@ton@em@|| @end|ng |rom gm@||@com (Michael Johnston)
Date: Thu, 24 Sep 2020 21:55:22 -0700
Subject: [R] R for mac
In-Reply-To: <24428.50447.534836.688752@rob.eddelbuettel.com>
References: <CAOCRzLALo65NJbQi_TW97biiDqN8-PNTDiWnKEKs2BY=tmOT-g@mail.gmail.com>
 <24428.50447.534836.688752@rob.eddelbuettel.com>
Message-ID: <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>

Hi

I am club mentor for a group of high school students learning R. The Vice
President of Information Technology is hoping to broaden and deepen her
skill set so she can help others. She is doing well in helping students
install R on the Windows operating system. However, a few have problems
installing R on mac and one student is struggling to install R on
Chromebook. Is there someone who would be willing to provide some pointers?

Thank you for considering this request,
Michael


On Thu, Sep 24, 2020 at 9:10 AM Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 23 September 2020 at 15:32, Michael Johnston wrote:
> | Hi
> | I am club mentor for a group of high school students learning R. A few
> have
> | problems installing R on mac. The Vp of information technology is hoping
> | for training so she can help others. Could you recommend someone to help
> | her?
> | Thank you for considering this request
>
> I have nothing to do with R on macOS -- but this mailing list is the place
> for mac-focussed discussion.  Maybe try that, and you likely need to
> subscribe before you can post.
>
> Dirk
>
> | Michael
>
> --
> https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Fri Sep 25 18:43:18 2020
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Fri, 25 Sep 2020 16:43:18 +0000
Subject: [R] R for mac
In-Reply-To: <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
References: <CAOCRzLALo65NJbQi_TW97biiDqN8-PNTDiWnKEKs2BY=tmOT-g@mail.gmail.com>
 <24428.50447.534836.688752@rob.eddelbuettel.com>
 <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
Message-ID: <EA691D83-41D4-4582-A762-266262A995D2@utoronto.ca>

For Mac specific issues the list R-SIG-Mac might be better. To my knowledge, R cannot be installed on a chromebook.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
 

?On 2020-09-25, 12:00 PM, "R-help on behalf of Michael Johnston" <r-help-bounces at r-project.org on behalf of michael.johnston.email at gmail.com> wrote:

    Hi

    I am club mentor for a group of high school students learning R. The Vice
    President of Information Technology is hoping to broaden and deepen her
    skill set so she can help others. She is doing well in helping students
    install R on the Windows operating system. However, a few have problems
    installing R on mac and one student is struggling to install R on
    Chromebook. Is there someone who would be willing to provide some pointers?

    Thank you for considering this request,
    Michael


    On Thu, Sep 24, 2020 at 9:10 AM Dirk Eddelbuettel <edd at debian.org> wrote:

    >
    > On 23 September 2020 at 15:32, Michael Johnston wrote:
    > | Hi
    > | I am club mentor for a group of high school students learning R. A few
    > have
    > | problems installing R on mac. The Vp of information technology is hoping
    > | for training so she can help others. Could you recommend someone to help
    > | her?
    > | Thank you for considering this request
    >
    > I have nothing to do with R on macOS -- but this mailing list is the place
    > for mac-focussed discussion.  Maybe try that, and you likely need to
    > subscribe before you can post.
    >
    > Dirk
    >
    > | Michael
    >
    > --
    > https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
    >

    	[[alternative HTML version deleted]]

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From c@d|@gne @end|ng |rom |c|oud@com  Fri Sep 25 18:54:51 2020
From: c@d|@gne @end|ng |rom |c|oud@com (Cheikh Tidiane DIAGNE)
Date: Fri, 25 Sep 2020 18:54:51 +0200
Subject: [R] R for mac
In-Reply-To: <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
References: <CAOCRzLALo65NJbQi_TW97biiDqN8-PNTDiWnKEKs2BY=tmOT-g@mail.gmail.com>
 <24428.50447.534836.688752@rob.eddelbuettel.com>
 <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
Message-ID: <1FEE5D04-B5CA-4D5D-BD60-2BBCED340736@icloud.com>

Hi Michael,
You have different specific R versions compatible for each OS.
For Mac version please find the link here: https://cran.r-project.org <https://cran.r-project.org/>

HTH,

Cheikh Tidiane DIAGNE
Public Health Entomologist



> On Sep 25, 2020, at 06:55, Michael Johnston <michael.johnston.email at gmail.com> wrote:
> 
> Hi
> 
> I am club mentor for a group of high school students learning R. The Vice
> President of Information Technology is hoping to broaden and deepen her
> skill set so she can help others. She is doing well in helping students
> install R on the Windows operating system. However, a few have problems
> installing R on mac and one student is struggling to install R on
> Chromebook. Is there someone who would be willing to provide some pointers?
> 
> Thank you for considering this request,
> Michael
> 
> 
> On Thu, Sep 24, 2020 at 9:10 AM Dirk Eddelbuettel <edd at debian.org> wrote:
> 
>> 
>> On 23 September 2020 at 15:32, Michael Johnston wrote:
>> | Hi
>> | I am club mentor for a group of high school students learning R. A few
>> have
>> | problems installing R on mac. The Vp of information technology is hoping
>> | for training so she can help others. Could you recommend someone to help
>> | her?
>> | Thank you for considering this request
>> 
>> I have nothing to do with R on macOS -- but this mailing list is the place
>> for mac-focussed discussion.  Maybe try that, and you likely need to
>> subscribe before you can post.
>> 
>> Dirk
>> 
>> | Michael
>> 
>> --
>> https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 25 21:24:21 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 25 Sep 2020 12:24:21 -0700
Subject: [R] R for mac
In-Reply-To: <EA691D83-41D4-4582-A762-266262A995D2@utoronto.ca>
References: <CAOCRzLALo65NJbQi_TW97biiDqN8-PNTDiWnKEKs2BY=tmOT-g@mail.gmail.com>
 <24428.50447.534836.688752@rob.eddelbuettel.com>
 <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
 <EA691D83-41D4-4582-A762-266262A995D2@utoronto.ca>
Message-ID: <68E260DD-2FE6-401F-B51E-206544FDB77A@dcn.davis.ca.us>

Some models of Chromebooks support limited use of Linux (via the approved "Crostini" project, for personal machines, via the developer-mode "Crouton" project). I use R in Crostini regularly.

In an educational setting it may be more prudent to suggest https://rstudio.cloud/

On September 25, 2020 9:43:18 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>For Mac specific issues the list R-SIG-Mac might be better. To my
>knowledge, R cannot be installed on a chromebook.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Fri Sep 25 23:50:49 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 26 Sep 2020 09:50:49 +1200
Subject: [R] R for mac
In-Reply-To: <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
References: <CAOCRzLALo65NJbQi_TW97biiDqN8-PNTDiWnKEKs2BY=tmOT-g@mail.gmail.com>
 <24428.50447.534836.688752@rob.eddelbuettel.com>
 <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
Message-ID: <CAB8pepxiCE9DoXt72PkK4n84eoV5CYYQSEkF-t=2d-Oc60dEGQ@mail.gmail.com>

Running R on Chromebook, is contrary to the way Chromebook is designed to work.
In theory, R can be run off a server.
Then people/students can not only access it from Chromebook, but from
their phones.

Unfortunately, this is not a topic I'm familiar with, so can't offer specifics.
But, from an educational perspective, under the presumption of
training students for the (emerging) "real world", the mobile/web
based approach would seem more useful...


On Sat, Sep 26, 2020 at 4:00 AM Michael Johnston
<michael.johnston.email at gmail.com> wrote:
>
> Hi
>
> I am club mentor for a group of high school students learning R. The Vice
> President of Information Technology is hoping to broaden and deepen her
> skill set so she can help others. She is doing well in helping students
> install R on the Windows operating system. However, a few have problems
> installing R on mac and one student is struggling to install R on
> Chromebook. Is there someone who would be willing to provide some pointers?
>
> Thank you for considering this request,
> Michael
>
>
> On Thu, Sep 24, 2020 at 9:10 AM Dirk Eddelbuettel <edd at debian.org> wrote:
>
> >
> > On 23 September 2020 at 15:32, Michael Johnston wrote:
> > | Hi
> > | I am club mentor for a group of high school students learning R. A few
> > have
> > | problems installing R on mac. The Vp of information technology is hoping
> > | for training so she can help others. Could you recommend someone to help
> > | her?
> > | Thank you for considering this request
> >
> > I have nothing to do with R on macOS -- but this mailing list is the place
> > for mac-focussed discussion.  Maybe try that, and you likely need to
> > subscribe before you can post.
> >
> > Dirk
> >
> > | Michael
> >
> > --
> > https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Sep 26 00:20:42 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 26 Sep 2020 08:20:42 +1000
Subject: [R] package plotrix: how to account for two two z categories
In-Reply-To: <CAMk+s2TJy5doemtiiYLE90c+TfeB1=tdr7BZ6wZKJJC=NOi-7g@mail.gmail.com>
References: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
 <CA+8X3fVgNC_yUyFFkV3Li+o_k6S5J7ZKBdf_ktVc84fZECMxrg@mail.gmail.com>
 <CAMk+s2Rtk=ujC-1AmzwJ9o3foH+DcdpuJmB2MFDKJTGA_i593A@mail.gmail.com>
 <CA+8X3fUyrMKgFNXj+Ok5AX_aU02emktM1WtgSSvxoOYx5sDKzA@mail.gmail.com>
 <CA+8X3fVCAKEmRjGYq30-kPEDtsxBXWH6GD+Krfp=W+bAF7K66g@mail.gmail.com>
 <CA+8X3fVKfRE-YtRvEkWG__H4c_GK-vJ_2G_OazijhD57Q-SYmg@mail.gmail.com>
 <CAMk+s2TJy5doemtiiYLE90c+TfeB1=tdr7BZ6wZKJJC=NOi-7g@mail.gmail.com>
Message-ID: <CA+8X3fWfvncX+Hvbg1wb2erHrzRvM36MRL9Z4k1o4RLaKyoJTw@mail.gmail.com>

Hi Luigi,
Good illustration. Maybe if I can integrate vertical lines to show the
nesting instead of bars it would work better. While it makes the
nesting much clearer, some people may still accuse you of using a bar
plot.

# new functions with the modifications
source("barNest.R")
source("drawNestedSpans.R")
png("lm_plot.png",width=600)
barNest(y~w+z+x,Q,main="Double Measurement",
 ylab="Response",col=barcol,errbars=TRUE)
dev.off()


Jim

On Fri, Sep 25, 2020 at 9:54 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thanks! looks nicer already.
> I am attaching the figure I temporarily made with normal brkdn.plot
> but yours has more information.
> Best regards
> Luigi
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: lm_plot.png
Type: image/png
Size: 19913 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200926/73719d81/attachment.png>

From drj|m|emon @end|ng |rom gm@||@com  Sat Sep 26 00:51:20 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 26 Sep 2020 08:51:20 +1000
Subject: [R] package plotrix: how to account for two two z categories
In-Reply-To: <CA+8X3fWfvncX+Hvbg1wb2erHrzRvM36MRL9Z4k1o4RLaKyoJTw@mail.gmail.com>
References: <CAMk+s2TWMU0QOLxCrNYdbRAM1PVgJBAJib_x3Jna=FRR3wDBfQ@mail.gmail.com>
 <CA+8X3fVgNC_yUyFFkV3Li+o_k6S5J7ZKBdf_ktVc84fZECMxrg@mail.gmail.com>
 <CAMk+s2Rtk=ujC-1AmzwJ9o3foH+DcdpuJmB2MFDKJTGA_i593A@mail.gmail.com>
 <CA+8X3fUyrMKgFNXj+Ok5AX_aU02emktM1WtgSSvxoOYx5sDKzA@mail.gmail.com>
 <CA+8X3fVCAKEmRjGYq30-kPEDtsxBXWH6GD+Krfp=W+bAF7K66g@mail.gmail.com>
 <CA+8X3fVKfRE-YtRvEkWG__H4c_GK-vJ_2G_OazijhD57Q-SYmg@mail.gmail.com>
 <CAMk+s2TJy5doemtiiYLE90c+TfeB1=tdr7BZ6wZKJJC=NOi-7g@mail.gmail.com>
 <CA+8X3fWfvncX+Hvbg1wb2erHrzRvM36MRL9Z4k1o4RLaKyoJTw@mail.gmail.com>
Message-ID: <CA+8X3fUzQQ-PFberv_4q65j5uwCGARqdoJXEuo72pP4WrVQFDQ@mail.gmail.com>

Hmmm, maybe without the caps...

Jim

On Sat, Sep 26, 2020 at 8:20 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> Good illustration. Maybe if I can integrate vertical lines to show the
> nesting instead of bars it would work better. While it makes the
> nesting much clearer, some people may still accuse you of using a bar
> plot.
>
> # new functions with the modifications
> source("barNest.R")
> source("drawNestedSpans.R")
> png("lm_plot.png",width=600)
> barNest(y~w+z+x,Q,main="Double Measurement",
>  ylab="Response",col=barcol,errbars=TRUE)
> dev.off()
>
>
> Jim
>
> On Fri, Sep 25, 2020 at 9:54 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Thanks! looks nicer already.
> > I am attaching the figure I temporarily made with normal brkdn.plot
> > but yours has more information.
> > Best regards
> > Luigi
> >

-------------- next part --------------
A non-text attachment was scrubbed...
Name: lm_plot.png
Type: image/png
Size: 18859 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200926/bcaaf4e8/attachment.png>

From no@p@m @end|ng |rom ||@@e@NA  Mon Sep 28 13:21:45 2020
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Mon, 28 Sep 2020 13:21:45 +0200
Subject: [R] R for mac
In-Reply-To: <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
References: <CAOCRzLALo65NJbQi_TW97biiDqN8-PNTDiWnKEKs2BY=tmOT-g@mail.gmail.com>
 <24428.50447.534836.688752@rob.eddelbuettel.com>
 <CAOCRzLA3JNciFvd4rtcce-t8V8NU2m5G_wxWeOUxa32Ci36syQ@mail.gmail.com>
Message-ID: <rksh0b$1193$1@ciao.gmane.io>

Michael,

I would propose the easiest way (and appropriate in a student setting is
via Homebrew (https://brew.sh/)

	 /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"

	 brew install R
	 brew cask install Rstudio

and thereafter once in a while

	 brew upgrade
	 brew upgrade --cask
	 brew cleanup -s

and from within Rstudio

	 Tools -> Check for Package Updates...
	 Select All

el

On 25/09/2020 06:55, Michael Johnston wrote:
> Hi
> 
> I am club mentor for a group of high school students learning R. The Vice
> President of Information Technology is hoping to broaden and deepen her
> skill set so she can help others. She is doing well in helping students
> install R on the Windows operating system. However, a few have problems
> installing R on mac and one student is struggling to install R on
> Chromebook. Is there someone who would be willing to provide some pointers?
> 
> Thank you for considering this request,
> Michael
[...]


-- 
If you want to email me, replace nospam with el


From p@u|@b|v@nd @end|ng |rom gm@||@com  Mon Sep 28 15:41:06 2020
From: p@u|@b|v@nd @end|ng |rom gm@||@com (Paul Bivand)
Date: Mon, 28 Sep 2020 14:41:06 +0100
Subject: [R] How can we get a predicted value that are used to plot the
 figure using a plot_model function of sjPlot?
In-Reply-To: <CAGxFJbSy+dJp_9iVSCcCu1sCZbJWh4zzitKw70SRBcABkcnfeg@mail.gmail.com>
References: <CAA7XnHfDMri9ewEhtDm5mLsy7gmWh6DA0KpZJxsOhwO7H9t3KQ@mail.gmail.com>
 <CAGxFJbSy+dJp_9iVSCcCu1sCZbJWh4zzitKw70SRBcABkcnfeg@mail.gmail.com>
Message-ID: <CAC=KSNhJtF1iezp-BVVibiWxy3vLroB_xUNZ-PgN8Vf0KLLCbQ@mail.gmail.com>

If you read ?plot_model() there is a description of type="pred" that
suggests fuller details are found under ?ggeffect() from the ggeffects
package.

This in turn suggests that if you use 'ggpredict()' with arguments
that replicate those you used in plot_model(), you get a data.frame
with the values that get passed to plot_model().

As these functions can handle many different fitted models, the help
pages are large and have subsections for different model classes.
However, the information requested is (as is not uncommon) in the help
pages.

Paul Bivand

On Sat, 19 Sep 2020 at 19:30, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> As no one has responded. Typically,
> > ?predict
> so
> > predict(fit)
> should give you fitted values for the class of fit, whatever it is.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Sep 19, 2020 at 1:29 AM Peter Wagey <peter.wagley09 at gmail.com>
> wrote:
>
> > Hi R users,
> > I was trying to create a figure of three-way-interactions. There is a
> > function "plot-model" but I was wondering whether we can extract the
> > predicted value before we run the "plot-model" function.
> > For example:
> > in this example,
> > plot_model(fit, type = "pred", terms = c("c12hour", "barthtot [30,50,70]",
> > "c161sex"))
> > How can we see the predicted values that are used to plot the figure? If we
> > can see the data (predicted values), we could use other functions to create
> > another type of figures.
> > Thank you very much for your suggestions.
> >
> > Thanks,
> >
> > Peter
> > #############
> > library(sjPlot)
> > library(sjmisc)
> > library(ggplot2)
> > data(efc)
> > theme_set(theme_sjplot())
> >
> > # make categorical
> > efc$c161sex <- to_factor(efc$c161sex)
> >
> > # fit model with 3-way-interaction
> > fit <- lm(neg_c_7 ~ c12hour * barthtot * c161sex, data = efc)
> >
> > # select only levels 30, 50 and 70 from continuous variable Barthel-Index
> > plot_model(fit, type = "pred", terms = c("c12hour", "barthtot [30,50,70]",
> > "c161sex"))
> >
> > How can we get the predicted value that is used to plot the graph? we would
> > like to see the predicted value using three groups of barthtot
> > [30,50,70].Is there any way we can extract the data (predicted value) so
> > that we can use other graphic functions to create figures?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From he|mut@@chuetz @end|ng |rom beb@c@@t  Mon Sep 28 21:05:31 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Mon, 28 Sep 2020 21:05:31 +0200
Subject: [R] Problem with contour()
Message-ID: <d042b085-4d5e-3feb-0a77-69a1ae079345@bebac.at>

Dear all,

I can't get my head around how contour lines are drawn.
Working example(x and y are parameters of a certain test and z the 
resulting power):

library(PowerTOST)
x??? <- 0.90
y??? <- 0.35
res? <- as.numeric(sampleN.TOST(theta0 = x, CV = y, design = "2x2x4",
 ??????????????????????????????? method = "central", details = FALSE,
 ??????????????????????????????? print = FALSE)[7:8])
mesh <- 28
ys?? <- unique(sort(c(y, seq(y*.8, y*1.2, length.out = mesh))))
xs?? <- unique(sort(c(x, seq(x*0.95, 1, length.out = mesh))))
z??? <- matrix(nrow = length(ys), ncol = length(xs),
 ?????????????? dimnames = list(paste0("y.", signif(ys, 5)),
 ?????????????????????????????? paste0("x.", signif(xs, 5))))
for (i in seq_along(ys)) {
 ? for (j in seq_along(xs)) {
 ??? z[i, j] <- suppressMessages(
 ???????????????? power.TOST(CV = ys[i], theta0 = xs[j], design = "2x2x4",
 ??????????????????????????? method = "central", n = res[1]))
 ? }
}
z??? <- z[nrow(z):1, ncol(z):1]????????? # reverse rows & columns
z[paste0("y.", y), paste0("x.", x)] == res[2] # should be TRUE
contour(xs, ys, z, nlevels = 20, las = 1, labcex = 1,
 ??????? xlab = "x", ylab = "y", main = paste("n =", n))
abline(h = y, v = x, lty = 2)
points(x, y, col = "red", cex = 1.5)
text(x, y, labels = signif(z[paste0("y.", y), paste0("x.", x)], 6),
 ???? col = "red", adj = c(-0.1, 1.5))

At x = 0.9 and y = 0.35 z = 0.8130092. Obviously this does not agree 
with the contour-lines.
I'm sure that I screwed up - but where?

All the best,
Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
E helmut.schuetz at bebac.at
W https://bebac.at/
F https://forum.bebac.at/


From he|mut@@chuetz @end|ng |rom beb@c@@t  Mon Sep 28 21:08:49 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Mon, 28 Sep 2020 21:08:49 +0200
Subject: [R] Problem with contour(): typo
Message-ID: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>

Dear all,

sorry, my last message contained a typo. Correct:

library(PowerTOST)
x??? <- 0.90
y??? <- 0.35
res? <- as.numeric(sampleN.TOST(theta0 = x, CV = y, design = "2x2x4",
  ??????????????????????????????? method = "central", details = FALSE,
  ??????????????????????????????? print = FALSE)[7:8])
mesh <- 28
ys?? <- unique(sort(c(y, seq(y*.8, y*1.2, length.out = mesh))))
xs?? <- unique(sort(c(x, seq(x*0.95, 1, length.out = mesh))))
z??? <- matrix(nrow = length(ys), ncol = length(xs),
  ?????????????? dimnames = list(paste0("y.", signif(ys, 5)),
  ?????????????????????????????? paste0("x.", signif(xs, 5))))
for (i in seq_along(ys)) {
  ? for (j in seq_along(xs)) {
  ??? z[i, j] <- suppressMessages(
  ???????????????? power.TOST(CV = ys[i], theta0 = xs[j], design = "2x2x4",
  ??????????????????????????? method = "central", n = res[1]))
  ? }
}
z??? <- z[nrow(z):1, ncol(z):1]?????????      # reverse rows & columns
z[paste0("y.", y), paste0("x.", x)] == res[2] # should be TRUE
contour(xs, ys, z, nlevels = 20, las = 1, labcex = 1,
  ??????? xlab = "x", ylab = "y", main = paste("n =", res[1]))
abline(h = y, v = x, lty = 2)
points(x, y, col = "red", cex = 1.5)
text(x, y, labels = signif(z[paste0("y.", y), paste0("x.", x)], 6),
  ???? col = "red", adj = c(-0.1, 1.5))


Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
E helmut.schuetz at bebac.at
W https://bebac.at/
F https://forum.bebac.at/


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 28 21:47:40 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 28 Sep 2020 15:47:40 -0400
Subject: [R] Problem with contour(): typo
In-Reply-To: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
Message-ID: <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>

You're doing a lot of manipulation of the z matrix; I haven't followed 
all of it, but that's where I'd look for problems.  Generally if you 
keep your calculation of the z matrix very simple you are better off. 
For example, once you have xs and ys in the form you want, calculate z as

z <- outer(x,y, function(x,y) ...)

and then plot it using contour(x, y, z, ...)

The only tricky issue here is that the function needs to be vectorized, 
so if your power.TOST function doesn't accept vectors for CV and theta0,
you'll need to put it in a wrapper that does (perhaps using the 
Vectorize function).

Duncan Murdoch



On 28/09/2020 3:08 p.m., Helmut Sch?tz wrote:
> Dear all,
> 
> sorry, my last message contained a typo. Correct:
> 
> library(PowerTOST)
> x??? <- 0.90
> y??? <- 0.35
> res? <- as.numeric(sampleN.TOST(theta0 = x, CV = y, design = "2x2x4",
>    ??????????????????????????????? method = "central", details = FALSE,
>    ??????????????????????????????? print = FALSE)[7:8])
> mesh <- 28
> ys?? <- unique(sort(c(y, seq(y*.8, y*1.2, length.out = mesh))))
> xs?? <- unique(sort(c(x, seq(x*0.95, 1, length.out = mesh))))
> z??? <- matrix(nrow = length(ys), ncol = length(xs),
>    ?????????????? dimnames = list(paste0("y.", signif(ys, 5)),
>    ?????????????????????????????? paste0("x.", signif(xs, 5))))
> for (i in seq_along(ys)) {
>    ? for (j in seq_along(xs)) {
>    ??? z[i, j] <- suppressMessages(
>    ???????????????? power.TOST(CV = ys[i], theta0 = xs[j], design = "2x2x4",
>    ??????????????????????????? method = "central", n = res[1]))
>    ? }
> }
> z??? <- z[nrow(z):1, ncol(z):1]?????????      # reverse rows & columns
> z[paste0("y.", y), paste0("x.", x)] == res[2] # should be TRUE
> contour(xs, ys, z, nlevels = 20, las = 1, labcex = 1,
>    ??????? xlab = "x", ylab = "y", main = paste("n =", res[1]))
> abline(h = y, v = x, lty = 2)
> points(x, y, col = "red", cex = 1.5)
> text(x, y, labels = signif(z[paste0("y.", y), paste0("x.", x)], 6),
>    ???? col = "red", adj = c(-0.1, 1.5))
> 
> 
> Helmut
>


From @rr@ypro|||e @end|ng |rom y@hoo@com  Tue Sep 29 02:33:23 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Tue, 29 Sep 2020 00:33:23 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
Message-ID: <2002394729.15283.1601339603771@mail.yahoo.com>

Hello,

Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:?

https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing

Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:

plot(fit1, col=1:2)
lines(fit2,col=1:2)

Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):

https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing

Can anyone have a strategy to make this kind of plot happen?

Thanks,

John


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Tue Sep 29 09:59:09 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Tue, 29 Sep 2020 07:59:09 +0000
Subject: [R] merged data frame with <NA>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809F95D9@ESINO.regionemarche.intra>

Dear R users,
I'm struggling with a simple "merge".

I have an external file called df.txt like

data_POSIX, event
2005-11-14 02:30:00, "start"
2005-11-14 11:30:00, "end"

I load it with

df1 <- read.table(file="df.txt", header=TRUE, sep=",", dec = ".", stringsAsFactors=FALSE)
df1$data_POSIX <- as.POSIXct(df1$data_POSIX, format="%Y-%m-%d %H:%M:%S", tz="Etc/GMT-1")

Then I create a new data frame df2:

day_1 <- as.POSIXct("2005-11-14-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
day_2 <- as.POSIXct("2005-11-14-12-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
df2 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))

Finally

df3 <- merge(df2, df1, by=c("data_POSIX"), all.x=TRUE)

gives

           data_POSIX event
1  2005-11-14 00:00:00    <NA>
2  2005-11-14 00:30:00    <NA>
3  2005-11-14 01:00:00    <NA>
4  2005-11-14 01:30:00    <NA>
5  2005-11-14 02:00:00    <NA>
6  2005-11-14 02:30:00  start
7  2005-11-14 03:00:00    <NA>
8  2005-11-14 03:30:00    <NA>
9  2005-11-14 04:00:00    <NA>
10 2005-11-14 04:30:00    <NA>
11 2005-11-14 05:00:00    <NA>
12 2005-11-14 05:30:00    <NA>
13 2005-11-14 06:00:00    <NA>
14 2005-11-14 06:30:00    <NA>
15 2005-11-14 07:00:00    <NA>
16 2005-11-14 07:30:00    <NA>
17 2005-11-14 08:00:00    <NA>
18 2005-11-14 08:30:00    <NA>
19 2005-11-14 09:00:00    <NA>
20 2005-11-14 09:30:00    <NA>
21 2005-11-14 10:00:00    <NA>
22 2005-11-14 10:30:00    <NA>
23 2005-11-14 11:00:00    <NA>
24 2005-11-14 11:30:00    end
25 2005-11-14 12:00:00    <NA>

Why there is <NA> instead of NA?
And why

df3$pch[df3$event == "start"] <- 24

gives a whole column of NA and not 24 at row 6?


         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Tue Sep 29 10:09:53 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 29 Sep 2020 10:09:53 +0200
Subject: [R] merged data frame with <NA>
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809F95D9@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809F95D9@ESINO.regionemarche.intra>
Message-ID: <cdf972f9-0a24-74e5-47e2-2d04890f3576@rgzm.de>

Hi Stefano,

For the merge() part, I'll leave it to more expert users (I rarely use 
merge(), and every time I need it, it's painful...).

To know why <NA> instead of NA, check the results with str(df3); I guess 
it is not the mode you expected.

For more details, you should provide the file, or better a reproducible 
example using dput().

For the second part, your syntax was not correct (subsetting a column 
for elements based on a column that is not part of the subset!). And 
there is no column "pch" in your example. Try:
df3[df3$event == "start", "event"] <- 24

HTH,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 29/09/2020 9:59, Stefano Sofia wrote:
> Dear R users,
> I'm struggling with a simple "merge".
>
> I have an external file called df.txt like
>
> data_POSIX, event
> 2005-11-14 02:30:00, "start"
> 2005-11-14 11:30:00, "end"
>
> I load it with
>
> df1 <- read.table(file="df.txt", header=TRUE, sep=",", dec = ".", stringsAsFactors=FALSE)
> df1$data_POSIX <- as.POSIXct(df1$data_POSIX, format="%Y-%m-%d %H:%M:%S", tz="Etc/GMT-1")
>
> Then I create a new data frame df2:
>
> day_1 <- as.POSIXct("2005-11-14-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> day_2 <- as.POSIXct("2005-11-14-12-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> df2 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
>
> Finally
>
> df3 <- merge(df2, df1, by=c("data_POSIX"), all.x=TRUE)
>
> gives
>
>             data_POSIX event
> 1  2005-11-14 00:00:00    <NA>
> 2  2005-11-14 00:30:00    <NA>
> 3  2005-11-14 01:00:00    <NA>
> 4  2005-11-14 01:30:00    <NA>
> 5  2005-11-14 02:00:00    <NA>
> 6  2005-11-14 02:30:00  start
> 7  2005-11-14 03:00:00    <NA>
> 8  2005-11-14 03:30:00    <NA>
> 9  2005-11-14 04:00:00    <NA>
> 10 2005-11-14 04:30:00    <NA>
> 11 2005-11-14 05:00:00    <NA>
> 12 2005-11-14 05:30:00    <NA>
> 13 2005-11-14 06:00:00    <NA>
> 14 2005-11-14 06:30:00    <NA>
> 15 2005-11-14 07:00:00    <NA>
> 16 2005-11-14 07:30:00    <NA>
> 17 2005-11-14 08:00:00    <NA>
> 18 2005-11-14 08:30:00    <NA>
> 19 2005-11-14 09:00:00    <NA>
> 20 2005-11-14 09:30:00    <NA>
> 21 2005-11-14 10:00:00    <NA>
> 22 2005-11-14 10:30:00    <NA>
> 23 2005-11-14 11:00:00    <NA>
> 24 2005-11-14 11:30:00    end
> 25 2005-11-14 12:00:00    <NA>
>
> Why there is <NA> instead of NA?
> And why
>
> df3$pch[df3$event == "start"] <- 24
>
> gives a whole column of NA and not 24 at row 6?
>
>
>           (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 29 10:35:35 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 29 Sep 2020 18:35:35 +1000
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <2002394729.15283.1601339603771@mail.yahoo.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
Message-ID: <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>

Hi John,
Perhaps the most direct way would be:

plot(fit1, col=1:2)
xylim<-par("usr")
clip(4,xylim[2],xylim[3],xylim[4])
lines(fit2,col=1:2)

Remember that the new clipping rectangle will persist until you or
something else resets it.

Jim

On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
>
> https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
>
> Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
>
> plot(fit1, col=1:2)
> lines(fit2,col=1:2)
>
> Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
>
> https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
>
> Can anyone have a strategy to make this kind of plot happen?
>
> Thanks,
>
> John
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From co|or|e @end|ng |rom gm@||@com  Tue Sep 29 10:57:59 2020
From: co|or|e @end|ng |rom gm@||@com (Carlos Ortega)
Date: Tue, 29 Sep 2020 10:57:59 +0200
Subject: [R] merged data frame with <NA>
In-Reply-To: <cdf972f9-0a24-74e5-47e2-2d04890f3576@rgzm.de>
References: <8B435C9568170B469AE31E8891E8CC4F809F95D9@ESINO.regionemarche.intra>
 <cdf972f9-0a24-74e5-47e2-2d04890f3576@rgzm.de>
Message-ID: <CAFKNbk+s5MtUVFZx4MysS_5ORCoBOMf1CAn+kcNL1PF_o4aUKQ@mail.gmail.com>

Hi All,

I recreated a new "sintetic" df1 based on df2 and I could merge:

> day_1 <- as.POSIXct("2005-11-14-00-00", format="%Y-%m-%d-%H-%M",
tz="Etc/GMT-1")
> day_2 <- as.POSIXct("2005-11-14-12-00", format="%Y-%m-%d-%H-%M",
tz="Etc/GMT-1")
> df2 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
>
>
>
> df1 <- data.frame(
+                   data_POSIX = df2[sample(1:nrow(df2), 15, replace =
FALSE),],
+                   event = sample(c('start', 'end'), 15, replace = TRUE)
+ )
>
> df3 <- merge(df2, df1, by=c("data_POSIX"), all.x=TRUE)
> df3
            data_POSIX event
1  2005-11-14 00:00:00   end
2  2005-11-14 00:30:00 start
3  2005-11-14 01:00:00  <NA>
4  2005-11-14 01:30:00   end
5  2005-11-14 02:00:00   end
6  2005-11-14 02:30:00 start
7  2005-11-14 03:00:00   end
8  2005-11-14 03:30:00   end
9  2005-11-14 04:00:00 start
10 2005-11-14 04:30:00 start
11 2005-11-14 05:00:00  <NA>
12 2005-11-14 05:30:00  <NA>
13 2005-11-14 06:00:00  <NA>
14 2005-11-14 06:30:00 start
15 2005-11-14 07:00:00  <NA>
16 2005-11-14 07:30:00  <NA>
17 2005-11-14 08:00:00  <NA>
18 2005-11-14 08:30:00  <NA>
19 2005-11-14 09:00:00 start
20 2005-11-14 09:30:00 start
21 2005-11-14 10:00:00  <NA>
22 2005-11-14 10:30:00   end
23 2005-11-14 11:00:00  <NA>
24 2005-11-14 11:30:00   end
25 2005-11-14 12:00:00 start

Regards,
Carlos Ortega

On Tue, Sep 29, 2020 at 10:13 AM Ivan Calandra <calandra at rgzm.de> wrote:

> Hi Stefano,
>
> For the merge() part, I'll leave it to more expert users (I rarely use
> merge(), and every time I need it, it's painful...).
>
> To know why <NA> instead of NA, check the results with str(df3); I guess
> it is not the mode you expected.
>
> For more details, you should provide the file, or better a reproducible
> example using dput().
>
> For the second part, your syntax was not correct (subsetting a column
> for elements based on a column that is not part of the subset!). And
> there is no column "pch" in your example. Try:
> df3[df3$event == "start", "event"] <- 24
>
> HTH,
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 29/09/2020 9:59, Stefano Sofia wrote:
> > Dear R users,
> > I'm struggling with a simple "merge".
> >
> > I have an external file called df.txt like
> >
> > data_POSIX, event
> > 2005-11-14 02:30:00, "start"
> > 2005-11-14 11:30:00, "end"
> >
> > I load it with
> >
> > df1 <- read.table(file="df.txt", header=TRUE, sep=",", dec = ".",
> stringsAsFactors=FALSE)
> > df1$data_POSIX <- as.POSIXct(df1$data_POSIX, format="%Y-%m-%d %H:%M:%S",
> tz="Etc/GMT-1")
> >
> > Then I create a new data frame df2:
> >
> > day_1 <- as.POSIXct("2005-11-14-00-00", format="%Y-%m-%d-%H-%M",
> tz="Etc/GMT-1")
> > day_2 <- as.POSIXct("2005-11-14-12-00", format="%Y-%m-%d-%H-%M",
> tz="Etc/GMT-1")
> > df2 <- data.frame(data_POSIX=seq(day_1, day_2, by="30 min"))
> >
> > Finally
> >
> > df3 <- merge(df2, df1, by=c("data_POSIX"), all.x=TRUE)
> >
> > gives
> >
> >             data_POSIX event
> > 1  2005-11-14 00:00:00    <NA>
> > 2  2005-11-14 00:30:00    <NA>
> > 3  2005-11-14 01:00:00    <NA>
> > 4  2005-11-14 01:30:00    <NA>
> > 5  2005-11-14 02:00:00    <NA>
> > 6  2005-11-14 02:30:00  start
> > 7  2005-11-14 03:00:00    <NA>
> > 8  2005-11-14 03:30:00    <NA>
> > 9  2005-11-14 04:00:00    <NA>
> > 10 2005-11-14 04:30:00    <NA>
> > 11 2005-11-14 05:00:00    <NA>
> > 12 2005-11-14 05:30:00    <NA>
> > 13 2005-11-14 06:00:00    <NA>
> > 14 2005-11-14 06:30:00    <NA>
> > 15 2005-11-14 07:00:00    <NA>
> > 16 2005-11-14 07:30:00    <NA>
> > 17 2005-11-14 08:00:00    <NA>
> > 18 2005-11-14 08:30:00    <NA>
> > 19 2005-11-14 09:00:00    <NA>
> > 20 2005-11-14 09:30:00    <NA>
> > 21 2005-11-14 10:00:00    <NA>
> > 22 2005-11-14 10:30:00    <NA>
> > 23 2005-11-14 11:00:00    <NA>
> > 24 2005-11-14 11:30:00    end
> > 25 2005-11-14 12:00:00    <NA>
> >
> > Why there is <NA> instead of NA?
> > And why
> >
> > df3$pch[df3$event == "start"] <- 24
> >
> > gives a whole column of NA and not 24 at row 6?
> >
> >
> >           (oo)
> > --oOO--( )--OOo----------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona
> > Uff: 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
> infetto.
> > This message was scanned by Libra ESVA and is believed to be clean.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From he|mut@@chuetz @end|ng |rom beb@c@@t  Tue Sep 29 11:37:09 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Tue, 29 Sep 2020 11:37:09 +0200
Subject: [R] Problem with contour(): typo
In-Reply-To: <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
Message-ID: <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>

Dear Duncan,

Duncan Murdoch wrote on 2020-09-28 21:47:
> You're doing a lot of manipulation of the z matrix; I haven't followed 
> all of it, but that's where I'd look for problems.? Generally if you 
> keep your calculation of the z matrix very simple you are better off. 
> For example, once you have xs and ys in the form you want, calculate z as
>
> z <- outer(x,y, function(x,y) ...)
>
> and then plot it using contour(x, y, z, ...)
>
> The only tricky issue here is that the function needs to be 
> vectorized, so if your power.TOST function doesn't accept vectors for 
> CV and theta0,
> you'll need to put it in a wrapper that does (perhaps using the 
> Vectorize function).

Here I'm lost. power.TOST(theta0, CV, ...) vectorizes properly for 
theta0 _or_ CV but no _both_. Hence
library(PowerTOST)
power.TOST(theta0 = c(0.9, 0.95, 1), CV = 0.25, n = 28)
and
power.TOST(theta0 = 0.95, CV = c(0.2, 0.25, 0.3), n = 28)
work, whereas
power.TOST(theta0 = c(0.9, 0.95, 1), 0.95, CV = c(0.2, 0.25, 0.3), n = 28)
not. Of note, we will throw an error in the next release if both 
arguments are vectors.
I tried
f <- function(x, y) {
 ? power.TOST(theta0 = x, CV = y, n = 28)
}
x <- unique(sort(c(0.95, seq(0.95*0.95, 1, length.out = 28))))
y <- unique(sort(c(0.25, seq(0.25*0.8, 0.25*1.2, length.out = 28))))
Vectorize(f, c("x, y"), SIMPLIFY = "array")
which is obviously not correct.

Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
E helmut.schuetz at bebac.at
W https://bebac.at/
F https://forum.bebac.at/


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep 29 11:57:09 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 29 Sep 2020 05:57:09 -0400
Subject: [R] Problem with contour(): typo
In-Reply-To: <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
Message-ID: <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>

On 29/09/2020 5:37 a.m., Helmut Sch?tz wrote:
> Dear Duncan,
> 
> Duncan Murdoch wrote on 2020-09-28 21:47:
>> You're doing a lot of manipulation of the z matrix; I haven't followed
>> all of it, but that's where I'd look for problems.? Generally if you
>> keep your calculation of the z matrix very simple you are better off.
>> For example, once you have xs and ys in the form you want, calculate z as
>>
>> z <- outer(x,y, function(x,y) ...)
 >>
 >> and then plot it using contour(x, y, z, ...)

Sorry, that was a typo, should have been

   z <- outer(xs,ys, function(x,y) ...)
   contour(xs, ys, z)

>>
>> The only tricky issue here is that the function needs to be
>> vectorized, so if your power.TOST function doesn't accept vectors for
>> CV and theta0,
>> you'll need to put it in a wrapper that does (perhaps using the
>> Vectorize function).
> 
> Here I'm lost. power.TOST(theta0, CV, ...) vectorizes properly for
> theta0 _or_ CV but no _both_. Hence
> library(PowerTOST)
> power.TOST(theta0 = c(0.9, 0.95, 1), CV = 0.25, n = 28)
> and
> power.TOST(theta0 = 0.95, CV = c(0.2, 0.25, 0.3), n = 28)
> work, whereas
> power.TOST(theta0 = c(0.9, 0.95, 1), 0.95, CV = c(0.2, 0.25, 0.3), n = 28)
> not. Of note, we will throw an error in the next release if both
> arguments are vectors.

I wouldn't do that, because it doesn't fit the usual R style.  It's very 
common for functions to allow vector inputs in several arguments, and 
match up corresponding values to form a vector result.

> I tried
> f <- function(x, y) {
>   ? power.TOST(theta0 = x, CV = y, n = 28)
> }
> x <- unique(sort(c(0.95, seq(0.95*0.95, 1, length.out = 28))))
> y <- unique(sort(c(0.25, seq(0.25*0.8, 0.25*1.2, length.out = 28))))
> Vectorize(f, c("x, y"), SIMPLIFY = "array")
> which is obviously not correct.

If you want to use Vectorize, the command would be

   power.TOST.vectorized <- Vectorize(power.TOST, c("theta0", "CV"))

A roughly equivalent version (without the recycling that Vectorize does) 
would be

   power.TOST.vectorized <- function(theta0, CV, ...) {
     result <- length(theta0)
     for (i in seq_along(theta0))
       result[i] <- power.TOST(theta0[i], CV[i], ...)
     result
   }

Duncan Murdoch


From he|mut@@chuetz @end|ng |rom beb@c@@t  Tue Sep 29 12:43:29 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Tue, 29 Sep 2020 12:43:29 +0200
Subject: [R] Problem with contour(): typo
In-Reply-To: <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
 <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
Message-ID: <e3209411-02a5-f913-0668-3663b838d545@bebac.at>

Dear Duncan,

Duncan Murdoch wrote on 2020-09-29 11:57:
> On 29/09/2020 5:37 a.m., Helmut Sch?tz wrote:
>> Here I'm lost. power.TOST(theta0, CV, ...) vectorizes properly for
>> theta0 _or_ CV but no _both_. Hence
>> library(PowerTOST)
>> power.TOST(theta0 = c(0.9, 0.95, 1), CV = 0.25, n = 28)
>> and
>> power.TOST(theta0 = 0.95, CV = c(0.2, 0.25, 0.3), n = 28)
>> work, whereas
>> power.TOST(theta0 = c(0.9, 0.95, 1), 0.95, CV = c(0.2, 0.25, 0.3), n 
>> = 28)
>> not. Of note, we will throw an error in the next release if both
>> arguments are vectors.
>
> I wouldn't do that, because it doesn't fit the usual R style. It's 
> very common for functions to allow vector inputs in several arguments, 
> and match up corresponding values to form a vector result.

I see. Here it would require to give the result as a matrix, 
data.frame,... Substantial change in the code though doable.

> If you want to use Vectorize, the command would be
>
> ? power.TOST.vectorized <- Vectorize(power.TOST, c("theta0", "CV"))

library(PowerTOST)
theta0 <- unique(sort(c(0.95, seq(0.95*0.95, 1, length.out = 10))))
CV???? <- unique(sort(c(0.25, seq(0.25*0.8, 0.25*1.2, length.out = 10))))
power.TOST.vectorized <- Vectorize(power.TOST, c("theta0", "CV", "n"))
and
power.TOST.vectorized(theta0 = theta0, CV = CV, n = 28)
gives the diagonal elements of the desired 11*11 matrix:
z <- matrix(ncol = length(theta0), nrow = length(CV))
for (i in seq_along(CV)) {
 ? z[i, ] <- power.TOST(theta0 = theta0, CV = CV[i], n = 28)
}

Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
E helmut.schuetz at bebac.at
W https://bebac.at/
F https://forum.bebac.at/


From he|mut@@chuetz @end|ng |rom beb@c@@t  Tue Sep 29 14:11:06 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Tue, 29 Sep 2020 14:11:06 +0200
Subject: [R] Problem with contour(): typo
In-Reply-To: <690C1EE8-EE77-44FC-8265-83838AF88DBB@psych.mpg.de>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
 <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
 <e3209411-02a5-f913-0668-3663b838d545@bebac.at>
 <690C1EE8-EE77-44FC-8265-83838AF88DBB@psych.mpg.de>
Message-ID: <519be2c7-704e-a507-4f2c-ac27ec894295@bebac.at>

Dear Benno,

THX, you made my day! Case closed.

Helmut

Puetz, Benno wrote on 2020-09-29 13:14:
> I would assume the following snippet does what you want - note the use 
> of outer with anonymous function wrapping powerTOST:
>
> z <- outer(xs, ys, function(x, y)power.TOST(CV = y, theta0 = x, design 
> = "2x2x4", method = "central", n = res[1]))
> contour(xs, ys, z)

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
E helmut.schuetz at bebac.at
W https://bebac.at/
F https://forum.bebac.at/


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep 29 15:12:38 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 29 Sep 2020 09:12:38 -0400
Subject: [R] Problem with contour(): typo
In-Reply-To: <519be2c7-704e-a507-4f2c-ac27ec894295@bebac.at>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
 <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
 <e3209411-02a5-f913-0668-3663b838d545@bebac.at>
 <690C1EE8-EE77-44FC-8265-83838AF88DBB@psych.mpg.de>
 <519be2c7-704e-a507-4f2c-ac27ec894295@bebac.at>
Message-ID: <351ec099-1ed0-03f8-c580-1f69780cfad2@gmail.com>

That won't work unless power.TOST is vectorized.  outer() will pass it 
vectors of x and y values.

Duncan Murdoch

On 29/09/2020 8:11 a.m., Helmut Sch?tz wrote:
> Dear Benno,
> 
> THX, you made my day! Case closed.
> 
> Helmut
> 
> Puetz, Benno wrote on 2020-09-29 13:14:
>> I would assume the following snippet does what you want - note the use
>> of outer with anonymous function wrapping powerTOST:
>>
>> z <- outer(xs, ys, function(x, y)power.TOST(CV = y, theta0 = x, design
>> = "2x2x4", method = "central", n = res[1]))
>> contour(xs, ys, z)
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep 29 15:21:46 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 29 Sep 2020 09:21:46 -0400
Subject: [R] Problem with contour(): typo
In-Reply-To: <0FDD0E32-22E0-40DD-B76C-E81FC79A5239@psych.mpg.de>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
 <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
 <e3209411-02a5-f913-0668-3663b838d545@bebac.at>
 <690C1EE8-EE77-44FC-8265-83838AF88DBB@psych.mpg.de>
 <519be2c7-704e-a507-4f2c-ac27ec894295@bebac.at>
 <351ec099-1ed0-03f8-c580-1f69780cfad2@gmail.com>
 <0FDD0E32-22E0-40DD-B76C-E81FC79A5239@psych.mpg.de>
Message-ID: <fdd3d540-5f03-d3bc-1de3-b65a59785032@gmail.com>

On 29/09/2020 9:16 a.m., Puetz, Benno wrote:
> As I noted in my earlier post, it does - had checked that ;-)

Great!

Duncan Murdoch

> It works by taking corresponding pair fo the input vectors (after possible recycling, as eluded by Helmut in his remark on working on only one vector) as needed for outer.
> 
> Thanks for the reminder, though,
> 
> 	Benno
> 
>> On 29. Sep 2020, at 15:12, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> That won't work unless power.TOST is vectorized.  outer() will pass it vectors of x and y values.
>>
>> Duncan Murdoch
>>
>> On 29/09/2020 8:11 a.m., Helmut Sch?tz wrote:
>>> Dear Benno,
>>> THX, you made my day! Case closed.
>>> Helmut
>>> Puetz, Benno wrote on 2020-09-29 13:14:
>>>> I would assume the following snippet does what you want - note the use
>>>> of outer with anonymous function wrapping powerTOST:
>>>>
>>>> z <- outer(xs, ys, function(x, y)power.TOST(CV = y, theta0 = x, design
>>>> = "2x2x4", method = "central", n = res[1]))
>>>> contour(xs, ys, z)
>>
>


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Sep 29 16:08:37 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 29 Sep 2020 10:08:37 -0400
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <2002394729.15283.1601339603771@mail.yahoo.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
Message-ID: <71A01F13-773D-438A-9EFE-C396F4055E36@me.com>

Hi John,

From the looks of the first plot, it would appear that perhaps you are engaged in a landmark analysis in an oncology setting, with the landmark time set at 5 years. On the off chance that you are not familiar with the pros and cons of that methodology, Google "landmark analysis", which should yield a number of references.

With respect to the plot itself, here is one approach, in addition to the one that Jim suggested. This will use a 1 x 2 matrix of plot regions, and adjust the various axes accordingly.

library(survival)

## Create two models with the same data for this use, the second adding 150 to the event times
## to mimic a landmark time at 150 weeks

fit <- survfit(Surv(time, status) ~ x, data = aml)
fit2 <- survfit(Surv(time, status) ~ x, data = aml)
fit2$time <- fit2$time + 150

## create the x 1 x 2 plot matrix
par(mfrow = c(1, 2))

## Set the plot region margins so there is no space to the right
par(mar = c(4, 4, 4, 0))

## Fix the plot limits for consistency
## xaxs = "i" removes the default 4% extensions to the plot region limits
plot(fit, axes = FALSE, xlim = c(0, 150), ylim = c(0, 1), xaxs = "i")

axis(1, at = seq(0, 150, 50), line = -1)
axis(2, las = 1)

## Set the plot region margins so there is no space to the left
par(mar = c(4, 0, 4, 4))

## Set the plot limits for the second time interval
plot(fit2, axes = FALSE, xlim = c(150, 300), ylim = c(0, 1), xaxs = "i")

axis(1, at = seq(150, 300, 50), line = -1)
axis(4, las = 1)

## Draw the vertical line at 150 weeks
axis(2, at = seq(0, 1, 0.2), labels = FALSE, lty = "dashed")


Regards,

Marc Schwartz


> On Sep 28, 2020, at 8:33 PM, array chip via R-help <r-help at r-project.org> wrote:
> 
> Hello,
> 
> Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one: 
> 
> https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> 
> Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> 
> plot(fit1, col=1:2)
> lines(fit2,col=1:2)
> 
> Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> 
> https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> 
> Can anyone have a strategy to make this kind of plot happen?
> 
> Thanks,
> 
> John
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From he|mut@@chuetz @end|ng |rom beb@c@@t  Tue Sep 29 16:33:20 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Tue, 29 Sep 2020 16:33:20 +0200
Subject: [R] Problem with contour(): typo
In-Reply-To: <fdd3d540-5f03-d3bc-1de3-b65a59785032@gmail.com>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
 <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
 <e3209411-02a5-f913-0668-3663b838d545@bebac.at>
 <690C1EE8-EE77-44FC-8265-83838AF88DBB@psych.mpg.de>
 <519be2c7-704e-a507-4f2c-ac27ec894295@bebac.at>
 <351ec099-1ed0-03f8-c580-1f69780cfad2@gmail.com>
 <0FDD0E32-22E0-40DD-B76C-E81FC79A5239@psych.mpg.de>
 <fdd3d540-5f03-d3bc-1de3-b65a59785032@gmail.com>
Message-ID: <f6f26cce-d290-7a33-9e35-4cff44caf2b0@bebac.at>

Dear Duncan and Benno,

Duncan Murdoch wrote on 2020-09-29 15:21:
> On 29/09/2020 9:16 a.m., Puetz, Benno wrote:
>> As I noted in my earlier post, it does - had checked that ;-)
>
> Great!

The result in all of its "beauty": 
https://forum.bebac.at/mix_entry.php?id=21930#top21939

THX again!

Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
E helmut.schuetz at bebac.at
W https://bebac.at/
F https://forum.bebac.at/


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Sep 29 18:18:49 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 29 Sep 2020 11:18:49 -0500
Subject: [R] how to turn column into column names and fill it with values
Message-ID: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>

Hello,

I have a data frame like this:

> head(mc)
      FID  IID   PLATE
1 fam0110 G110 4RWG569
2 fam0113 G113  cherry
3 fam0114 G114  cherry
4 fam0117 G117 4RWG569
5 fam0118 G118 5XAV049
6 fam0119 G119  cherry
...
> dim(mc)
[1] 1625    4
> length(unique(mc$PLATE))
[1] 34

I am trying to make a new data frame which would look like this:
      FID  IID   PLATE   4RWG569  cherry 5XAV049 ...
1 fam0110 G110 4RWG569  2  1  1
2 fam0113 G113  cherry   1  2  1
3 fam0114 G114  cherry   1  2  1
4 fam0117 G117 4RWG569  2  1  1
5 fam0118 G118 5XAV049   2  1  1
6 fam0119 G119  cherry   1  2  1
...

so the new data frame would have an additional 34 columns (for every
unique mc$PLATE) and if in the row of PLATE column the value is ==to
that column name I would have 2 otherwise 1

I tried to do this with:

library(reshape2)
>  m2=dcast(mc, IID ~ PLATE)
Using PLATE as value column: use value.var to override.

Please advise,
Ana


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 29 18:46:29 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 29 Sep 2020 09:46:29 -0700
Subject: [R] 
 how to turn column into column names and fill it with values
In-Reply-To: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
References: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
Message-ID: <CAGxFJbTfLzqWUidzu441qKkWvEFUO_KpJ8pGWkmJyFQTH6p2DQ@mail.gmail.com>

I am not sure reshape2 is appropriate for this task, but, assuming I
understand correctly, it's quite easy without it. The following is one way,
which probably can be done more elegantly and efficiently, but I think it
does what you want.

"dat" is your example data frame, in which the columns were read in with
"stringsAsFactors" = FALSE (this is important!)

dat <- cbind(dat, matrix(0,ncol = 3)) ## change 3 to 34 for your full data
names(dat) <- c(names(dat)[1:3], unique(dat$PLATE))
for(i in 4:ncol(dat)) dat[,i] <- 1 + (names(dat)[i]== dat$PLATE)
dat

Result:

      FID  IID   PLATE 4RWG569 cherry 5XAV049
1 fam0110 G110 4RWG569       2      1       1
2 fam0113 G113  cherry       1      2       1
3 fam0114 G114  cherry       1      2       1
4 fam0117 G117 4RWG569       2      1       1
5 fam0118 G118 5XAV049       1      1       2
6 fam0119 G119  cherry       1      2       1


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 29, 2020 at 9:19 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a data frame like this:
>
> > head(mc)
>       FID  IID   PLATE
> 1 fam0110 G110 4RWG569
> 2 fam0113 G113  cherry
> 3 fam0114 G114  cherry
> 4 fam0117 G117 4RWG569
> 5 fam0118 G118 5XAV049
> 6 fam0119 G119  cherry
> ...
> > dim(mc)
> [1] 1625    4
> > length(unique(mc$PLATE))
> [1] 34
>
> I am trying to make a new data frame which would look like this:
>       FID  IID   PLATE   4RWG569  cherry 5XAV049 ...
> 1 fam0110 G110 4RWG569  2  1  1
> 2 fam0113 G113  cherry   1  2  1
> 3 fam0114 G114  cherry   1  2  1
> 4 fam0117 G117 4RWG569  2  1  1
> 5 fam0118 G118 5XAV049   2  1  1
> 6 fam0119 G119  cherry   1  2  1
> ...
>
> so the new data frame would have an additional 34 columns (for every
> unique mc$PLATE) and if in the row of PLATE column the value is ==to
> that column name I would have 2 otherwise 1
>
> I tried to do this with:
>
> library(reshape2)
> >  m2=dcast(mc, IID ~ PLATE)
> Using PLATE as value column: use value.var to override.
>
> Please advise,
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @rr@ypro|||e @end|ng |rom y@hoo@com  Tue Sep 29 19:04:02 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Tue, 29 Sep 2020 17:04:02 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
Message-ID: <1707499353.277236.1601399042873@mail.yahoo.com>

Thank you very much Jim, this is great!!

John


On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote: 





Hi John,
Perhaps the most direct way would be:

plot(fit1, col=1:2)
xylim<-par("usr")
clip(4,xylim[2],xylim[3],xylim[4])
lines(fit2,col=1:2)

Remember that the new clipping rectangle will persist until you or
something else resets it.

Jim

On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
>
> https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
>
> Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
>
> plot(fit1, col=1:2)
> lines(fit2,col=1:2)
>
> Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
>
> https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
>
> Can anyone have a strategy to make this kind of plot happen?
>
> Thanks,
>
> John
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @rr@ypro|||e @end|ng |rom y@hoo@com  Tue Sep 29 19:05:56 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Tue, 29 Sep 2020 17:05:56 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <71A01F13-773D-438A-9EFE-C396F4055E36@me.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <71A01F13-773D-438A-9EFE-C396F4055E36@me.com>
Message-ID: <1477890501.295771.1601399156899@mail.yahoo.com>

Thank you Marc as well! I'll try both ways! Yes this is an oncology study with time set at 5

John


On Tuesday, September 29, 2020, 07:08:39 AM PDT, Marc Schwartz <marc_schwartz at me.com> wrote: 





Hi John,

>From the looks of the first plot, it would appear that perhaps you are engaged in a landmark analysis in an oncology setting, with the landmark time set at 5 years. On the off chance that you are not familiar with the pros and cons of that methodology, Google "landmark analysis", which should yield a number of references.

With respect to the plot itself, here is one approach, in addition to the one that Jim suggested. This will use a 1 x 2 matrix of plot regions, and adjust the various axes accordingly.

library(survival)

## Create two models with the same data for this use, the second adding 150 to the event times
## to mimic a landmark time at 150 weeks

fit <- survfit(Surv(time, status) ~ x, data = aml)
fit2 <- survfit(Surv(time, status) ~ x, data = aml)
fit2$time <- fit2$time + 150

## create the x 1 x 2 plot matrix
par(mfrow = c(1, 2))

## Set the plot region margins so there is no space to the right
par(mar = c(4, 4, 4, 0))

## Fix the plot limits for consistency
## xaxs = "i" removes the default 4% extensions to the plot region limits
plot(fit, axes = FALSE, xlim = c(0, 150), ylim = c(0, 1), xaxs = "i")

axis(1, at = seq(0, 150, 50), line = -1)
axis(2, las = 1)

## Set the plot region margins so there is no space to the left
par(mar = c(4, 0, 4, 4))

## Set the plot limits for the second time interval
plot(fit2, axes = FALSE, xlim = c(150, 300), ylim = c(0, 1), xaxs = "i")

axis(1, at = seq(150, 300, 50), line = -1)
axis(4, las = 1)

## Draw the vertical line at 150 weeks
axis(2, at = seq(0, 1, 0.2), labels = FALSE, lty = "dashed")


Regards,

Marc Schwartz


> On Sep 28, 2020, at 8:33 PM, array chip via R-help <r-help at r-project.org> wrote:
> 
> Hello,
> 
> Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one: 
> 
> https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> 
> Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> 
> plot(fit1, col=1:2)
> lines(fit2,col=1:2)
> 
> Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> 
> https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> 
> Can anyone have a strategy to make this kind of plot happen?
> 
> Thanks,
> 
> John

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Sep 29 19:08:23 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 29 Sep 2020 12:08:23 -0500
Subject: [R] 
 how to turn column into column names and fill it with values
In-Reply-To: <CAGxFJbTfLzqWUidzu441qKkWvEFUO_KpJ8pGWkmJyFQTH6p2DQ@mail.gmail.com>
References: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
 <CAGxFJbTfLzqWUidzu441qKkWvEFUO_KpJ8pGWkmJyFQTH6p2DQ@mail.gmail.com>
Message-ID: <CAF9-5jNOYfU1kHDkRhWoJkVHJqRd2yj3=Rc0Xoy7Hkxk8TOeiw@mail.gmail.com>

HI Bert,

thank you for getting back to me.
I tried this:

> dat <- cbind(mc, matrix(0,ncol = 34))
> head(dat)
      FID  IID   PLATE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
1 fam0110 G110 4RWG569 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
2 fam0113 G113  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
3 fam0114 G114  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
4 fam0117 G117 4RWG569 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
5 fam0118 G118 5XAV049 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
6 fam0119 G119  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
  23 24 25 26 27 28 29 30 31 32 33 34
1  0  0  0  0  0  0  0  0  0  0  0  0
2  0  0  0  0  0  0  0  0  0  0  0  0
3  0  0  0  0  0  0  0  0  0  0  0  0
4  0  0  0  0  0  0  0  0  0  0  0  0
5  0  0  0  0  0  0  0  0  0  0  0  0
6  0  0  0  0  0  0  0  0  0  0  0  0
> names(dat) <- c(names(dat)[1:34], unique(dat$PLATE))
Error in names(dat) <- c(names(dat)[1:34], unique(dat$PLATE)) :
  'names' attribute [68] must be the same length as the vector [37]

so names should include FID,IID,PLATE  plus unique dat$PLATE
how do I fix that so the code works?

Also I tried a bit on my own:

> head(mc)
      FID  IID   PLATE
1 fam0110 G110 4RWG569
2 fam0113 G113  cherry
3 fam0114 G114  cherry
4 fam0117 G117 4RWG569
5 fam0118 G118 5XAV049
6 fam0119 G119  cherry
...

m2=tapply(mc$IID, list(FID=mc$FID, PLATE=mc$PLATE), mean)
m2=as.data.frame(m2)
library(data.table)
m3=setDT(m2, keep.rownames = TRUE)[]
colnames(m3)[1] <- "FID"
mt=merge(mc,m3,by="FID")

> head(mt)
      FID  IID   PLATE 0VXC556 1CNF297 1CWO500 1DXJ626 1LTX827 1SHK635 1TNP840
1 fam0110 G110 4RWG569      NA      NA      NA      NA      NA      NA      NA
2 fam0113 G113  cherry      NA      NA      NA      NA      NA      NA      NA
3 fam0114 G114  cherry      NA      NA      NA      NA      NA      NA      NA
4 fam0117 G117 4RWG569      NA      NA      NA      NA      NA      NA      NA
5 fam0118 G118 5XAV049      NA      NA      NA      NA      NA      NA      NA
6 fam0119 G119  cherry      NA      NA      NA      NA      NA      NA      NA
  1URP242 2BKX529 2PAG415 3DEF425 3ECO791 3FQM386 3KYJ479 3XHK903 4RWG569
1      NA      NA      NA      NA      NA      NA      NA      NA      NA
2      NA      NA      NA      NA      NA      NA      NA      NA      NA
3      NA      NA      NA      NA      NA      NA      NA      NA      NA
4      NA      NA      NA      NA      NA      NA      NA      NA      NA
5      NA      NA      NA      NA      NA      NA      NA      NA      NA
6      NA      NA      NA      NA      NA      NA      NA      NA      NA
...

so this gives me the correct columns. Now is the question of how to
replace NA with 2 id column name matches the rownname in PLATE column
with 2 otherwise it is 1.

Cheers,
Ana

On Tue, Sep 29, 2020 at 11:46 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I am not sure reshape2 is appropriate for this task, but, assuming I understand correctly, it's quite easy without it. The following is one way, which probably can be done more elegantly and efficiently, but I think it does what you want.
>
> "dat" is your example data frame, in which the columns were read in with "stringsAsFactors" = FALSE (this is important!)
>
> dat <- cbind(dat, matrix(0,ncol = 3)) ## change 3 to 34 for your full data
> names(dat) <- c(names(dat)[1:3], unique(dat$PLATE))
> for(i in 4:ncol(dat)) dat[,i] <- 1 + (names(dat)[i]== dat$PLATE)
> dat
>
> Result:
>
>       FID  IID   PLATE 4RWG569 cherry 5XAV049
> 1 fam0110 G110 4RWG569       2      1       1
> 2 fam0113 G113  cherry       1      2       1
> 3 fam0114 G114  cherry       1      2       1
> 4 fam0117 G117 4RWG569       2      1       1
> 5 fam0118 G118 5XAV049       1      1       2
> 6 fam0119 G119  cherry       1      2       1
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Sep 29, 2020 at 9:19 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hello,
>>
>> I have a data frame like this:
>>
>> > head(mc)
>>       FID  IID   PLATE
>> 1 fam0110 G110 4RWG569
>> 2 fam0113 G113  cherry
>> 3 fam0114 G114  cherry
>> 4 fam0117 G117 4RWG569
>> 5 fam0118 G118 5XAV049
>> 6 fam0119 G119  cherry
>> ...
>> > dim(mc)
>> [1] 1625    4
>> > length(unique(mc$PLATE))
>> [1] 34
>>
>> I am trying to make a new data frame which would look like this:
>>       FID  IID   PLATE   4RWG569  cherry 5XAV049 ...
>> 1 fam0110 G110 4RWG569  2  1  1
>> 2 fam0113 G113  cherry   1  2  1
>> 3 fam0114 G114  cherry   1  2  1
>> 4 fam0117 G117 4RWG569  2  1  1
>> 5 fam0118 G118 5XAV049   2  1  1
>> 6 fam0119 G119  cherry   1  2  1
>> ...
>>
>> so the new data frame would have an additional 34 columns (for every
>> unique mc$PLATE) and if in the row of PLATE column the value is ==to
>> that column name I would have 2 otherwise 1
>>
>> I tried to do this with:
>>
>> library(reshape2)
>> >  m2=dcast(mc, IID ~ PLATE)
>> Using PLATE as value column: use value.var to override.
>>
>> Please advise,
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Sep 29 19:39:59 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 29 Sep 2020 12:39:59 -0500
Subject: [R] 
 how to turn column into column names and fill it with values
In-Reply-To: <CAF9-5jNOYfU1kHDkRhWoJkVHJqRd2yj3=Rc0Xoy7Hkxk8TOeiw@mail.gmail.com>
References: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
 <CAGxFJbTfLzqWUidzu441qKkWvEFUO_KpJ8pGWkmJyFQTH6p2DQ@mail.gmail.com>
 <CAF9-5jNOYfU1kHDkRhWoJkVHJqRd2yj3=Rc0Xoy7Hkxk8TOeiw@mail.gmail.com>
Message-ID: <CAF9-5jPFG7ySsc1mHe4KBbQnNwES74Vbfzm0e-dqax_dyEeMsQ@mail.gmail.com>

oh it seems that I can just use your last line of code and solve my problem:
m2=tapply(mc$IID, list(FID=mc$FID, PLATE=mc$PLATE), mean)
m2=as.data.frame(m2)
library(data.table)
m3=setDT(m2, keep.rownames = TRUE)[]
colnames(m3)[1] <- "FID"
mt=merge(mc,m3,by="FID"
for(i in 4:ncol(mt)) mt[,i] <- 1 + (names(mt)[i]== mt$PLATE)

Thanks!

On Tue, Sep 29, 2020 at 12:08 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> HI Bert,
>
> thank you for getting back to me.
> I tried this:
>
> > dat <- cbind(mc, matrix(0,ncol = 34))
> > head(dat)
>       FID  IID   PLATE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
> 1 fam0110 G110 4RWG569 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
> 2 fam0113 G113  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
> 3 fam0114 G114  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
> 4 fam0117 G117 4RWG569 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
> 5 fam0118 G118 5XAV049 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
> 6 fam0119 G119  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0  0  0
>   23 24 25 26 27 28 29 30 31 32 33 34
> 1  0  0  0  0  0  0  0  0  0  0  0  0
> 2  0  0  0  0  0  0  0  0  0  0  0  0
> 3  0  0  0  0  0  0  0  0  0  0  0  0
> 4  0  0  0  0  0  0  0  0  0  0  0  0
> 5  0  0  0  0  0  0  0  0  0  0  0  0
> 6  0  0  0  0  0  0  0  0  0  0  0  0
> > names(dat) <- c(names(dat)[1:34], unique(dat$PLATE))
> Error in names(dat) <- c(names(dat)[1:34], unique(dat$PLATE)) :
>   'names' attribute [68] must be the same length as the vector [37]
>
> so names should include FID,IID,PLATE  plus unique dat$PLATE
> how do I fix that so the code works?
>
> Also I tried a bit on my own:
>
> > head(mc)
>       FID  IID   PLATE
> 1 fam0110 G110 4RWG569
> 2 fam0113 G113  cherry
> 3 fam0114 G114  cherry
> 4 fam0117 G117 4RWG569
> 5 fam0118 G118 5XAV049
> 6 fam0119 G119  cherry
> ...
>
> m2=tapply(mc$IID, list(FID=mc$FID, PLATE=mc$PLATE), mean)
> m2=as.data.frame(m2)
> library(data.table)
> m3=setDT(m2, keep.rownames = TRUE)[]
> colnames(m3)[1] <- "FID"
> mt=merge(mc,m3,by="FID")
>
> > head(mt)
>       FID  IID   PLATE 0VXC556 1CNF297 1CWO500 1DXJ626 1LTX827 1SHK635 1TNP840
> 1 fam0110 G110 4RWG569      NA      NA      NA      NA      NA      NA      NA
> 2 fam0113 G113  cherry      NA      NA      NA      NA      NA      NA      NA
> 3 fam0114 G114  cherry      NA      NA      NA      NA      NA      NA      NA
> 4 fam0117 G117 4RWG569      NA      NA      NA      NA      NA      NA      NA
> 5 fam0118 G118 5XAV049      NA      NA      NA      NA      NA      NA      NA
> 6 fam0119 G119  cherry      NA      NA      NA      NA      NA      NA      NA
>   1URP242 2BKX529 2PAG415 3DEF425 3ECO791 3FQM386 3KYJ479 3XHK903 4RWG569
> 1      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 2      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 3      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 4      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 5      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 6      NA      NA      NA      NA      NA      NA      NA      NA      NA
> ...
>
> so this gives me the correct columns. Now is the question of how to
> replace NA with 2 id column name matches the rownname in PLATE column
> with 2 otherwise it is 1.
>
> Cheers,
> Ana
>
> On Tue, Sep 29, 2020 at 11:46 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > I am not sure reshape2 is appropriate for this task, but, assuming I understand correctly, it's quite easy without it. The following is one way, which probably can be done more elegantly and efficiently, but I think it does what you want.
> >
> > "dat" is your example data frame, in which the columns were read in with "stringsAsFactors" = FALSE (this is important!)
> >
> > dat <- cbind(dat, matrix(0,ncol = 3)) ## change 3 to 34 for your full data
> > names(dat) <- c(names(dat)[1:3], unique(dat$PLATE))
> > for(i in 4:ncol(dat)) dat[,i] <- 1 + (names(dat)[i]== dat$PLATE)
> > dat
> >
> > Result:
> >
> >       FID  IID   PLATE 4RWG569 cherry 5XAV049
> > 1 fam0110 G110 4RWG569       2      1       1
> > 2 fam0113 G113  cherry       1      2       1
> > 3 fam0114 G114  cherry       1      2       1
> > 4 fam0117 G117 4RWG569       2      1       1
> > 5 fam0118 G118 5XAV049       1      1       2
> > 6 fam0119 G119  cherry       1      2       1
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Sep 29, 2020 at 9:19 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >>
> >> Hello,
> >>
> >> I have a data frame like this:
> >>
> >> > head(mc)
> >>       FID  IID   PLATE
> >> 1 fam0110 G110 4RWG569
> >> 2 fam0113 G113  cherry
> >> 3 fam0114 G114  cherry
> >> 4 fam0117 G117 4RWG569
> >> 5 fam0118 G118 5XAV049
> >> 6 fam0119 G119  cherry
> >> ...
> >> > dim(mc)
> >> [1] 1625    4
> >> > length(unique(mc$PLATE))
> >> [1] 34
> >>
> >> I am trying to make a new data frame which would look like this:
> >>       FID  IID   PLATE   4RWG569  cherry 5XAV049 ...
> >> 1 fam0110 G110 4RWG569  2  1  1
> >> 2 fam0113 G113  cherry   1  2  1
> >> 3 fam0114 G114  cherry   1  2  1
> >> 4 fam0117 G117 4RWG569  2  1  1
> >> 5 fam0118 G118 5XAV049   2  1  1
> >> 6 fam0119 G119  cherry   1  2  1
> >> ...
> >>
> >> so the new data frame would have an additional 34 columns (for every
> >> unique mc$PLATE) and if in the row of PLATE column the value is ==to
> >> that column name I would have 2 otherwise 1
> >>
> >> I tried to do this with:
> >>
> >> library(reshape2)
> >> >  m2=dcast(mc, IID ~ PLATE)
> >> Using PLATE as value column: use value.var to override.
> >>
> >> Please advise,
> >> Ana
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 29 19:41:14 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 29 Sep 2020 10:41:14 -0700
Subject: [R] 
 how to turn column into column names and fill it with values
In-Reply-To: <CAF9-5jNOYfU1kHDkRhWoJkVHJqRd2yj3=Rc0Xoy7Hkxk8TOeiw@mail.gmail.com>
References: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
 <CAGxFJbTfLzqWUidzu441qKkWvEFUO_KpJ8pGWkmJyFQTH6p2DQ@mail.gmail.com>
 <CAF9-5jNOYfU1kHDkRhWoJkVHJqRd2yj3=Rc0Xoy7Hkxk8TOeiw@mail.gmail.com>
Message-ID: <CAGxFJbT67usGzLpr=4q0hGgNWyUK4mBMgZ-BLzzx17Bc_knmrA@mail.gmail.com>

You should be able to figure this out yourself!

The number of new columns you add **must agree with the number of unique
id's PLATE** !

Here is the general approach, slightly more efficient, probably:

PL = dat$PLATE
nm<- unique(PL)
len <- length(nm)
m <- matrix(0, ncol = len, nrow = nrow(dat), dimnames = list(NULL, nm))
for(i in 1:len) m[,i] <- 1 + (nm[i] == PL)
dat <- cbind(dat, m)

This code works. If you change it, don't ask me to account for errors.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 29, 2020 at 10:08 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> HI Bert,
>
> thank you for getting back to me.
> I tried this:
>
> > dat <- cbind(mc, matrix(0,ncol = 34))
> > head(dat)
>       FID  IID   PLATE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
> 21 22
> 1 fam0110 G110 4RWG569 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0
> 0  0
> 2 fam0113 G113  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0
> 0  0
> 3 fam0114 G114  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0
> 0  0
> 4 fam0117 G117 4RWG569 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0
> 0  0
> 5 fam0118 G118 5XAV049 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0
> 0  0
> 6 fam0119 G119  cherry 0 0 0 0 0 0 0 0 0  0  0  0  0  0  0  0  0  0  0  0
> 0  0
>   23 24 25 26 27 28 29 30 31 32 33 34
> 1  0  0  0  0  0  0  0  0  0  0  0  0
> 2  0  0  0  0  0  0  0  0  0  0  0  0
> 3  0  0  0  0  0  0  0  0  0  0  0  0
> 4  0  0  0  0  0  0  0  0  0  0  0  0
> 5  0  0  0  0  0  0  0  0  0  0  0  0
> 6  0  0  0  0  0  0  0  0  0  0  0  0
> > names(dat) <- c(names(dat)[1:34], unique(dat$PLATE))
> Error in names(dat) <- c(names(dat)[1:34], unique(dat$PLATE)) :
>   'names' attribute [68] must be the same length as the vector [37]
>
> so names should include FID,IID,PLATE  plus unique dat$PLATE
> how do I fix that so the code works?
>
> Also I tried a bit on my own:
>
> > head(mc)
>       FID  IID   PLATE
> 1 fam0110 G110 4RWG569
> 2 fam0113 G113  cherry
> 3 fam0114 G114  cherry
> 4 fam0117 G117 4RWG569
> 5 fam0118 G118 5XAV049
> 6 fam0119 G119  cherry
> ...
>
> m2=tapply(mc$IID, list(FID=mc$FID, PLATE=mc$PLATE), mean)
> m2=as.data.frame(m2)
> library(data.table)
> m3=setDT(m2, keep.rownames = TRUE)[]
> colnames(m3)[1] <- "FID"
> mt=merge(mc,m3,by="FID")
>
> > head(mt)
>       FID  IID   PLATE 0VXC556 1CNF297 1CWO500 1DXJ626 1LTX827 1SHK635
> 1TNP840
> 1 fam0110 G110 4RWG569      NA      NA      NA      NA      NA      NA
>   NA
> 2 fam0113 G113  cherry      NA      NA      NA      NA      NA      NA
>   NA
> 3 fam0114 G114  cherry      NA      NA      NA      NA      NA      NA
>   NA
> 4 fam0117 G117 4RWG569      NA      NA      NA      NA      NA      NA
>   NA
> 5 fam0118 G118 5XAV049      NA      NA      NA      NA      NA      NA
>   NA
> 6 fam0119 G119  cherry      NA      NA      NA      NA      NA      NA
>   NA
>   1URP242 2BKX529 2PAG415 3DEF425 3ECO791 3FQM386 3KYJ479 3XHK903 4RWG569
> 1      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 2      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 3      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 4      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 5      NA      NA      NA      NA      NA      NA      NA      NA      NA
> 6      NA      NA      NA      NA      NA      NA      NA      NA      NA
> ...
>
> so this gives me the correct columns. Now is the question of how to
> replace NA with 2 id column name matches the rownname in PLATE column
> with 2 otherwise it is 1.
>
> Cheers,
> Ana
>
> On Tue, Sep 29, 2020 at 11:46 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > I am not sure reshape2 is appropriate for this task, but, assuming I
> understand correctly, it's quite easy without it. The following is one way,
> which probably can be done more elegantly and efficiently, but I think it
> does what you want.
> >
> > "dat" is your example data frame, in which the columns were read in with
> "stringsAsFactors" = FALSE (this is important!)
> >
> > dat <- cbind(dat, matrix(0,ncol = 3)) ## change 3 to 34 for your full
> data
> > names(dat) <- c(names(dat)[1:3], unique(dat$PLATE))
> > for(i in 4:ncol(dat)) dat[,i] <- 1 + (names(dat)[i]== dat$PLATE)
> > dat
> >
> > Result:
> >
> >       FID  IID   PLATE 4RWG569 cherry 5XAV049
> > 1 fam0110 G110 4RWG569       2      1       1
> > 2 fam0113 G113  cherry       1      2       1
> > 3 fam0114 G114  cherry       1      2       1
> > 4 fam0117 G117 4RWG569       2      1       1
> > 5 fam0118 G118 5XAV049       1      1       2
> > 6 fam0119 G119  cherry       1      2       1
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Sep 29, 2020 at 9:19 AM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >>
> >> Hello,
> >>
> >> I have a data frame like this:
> >>
> >> > head(mc)
> >>       FID  IID   PLATE
> >> 1 fam0110 G110 4RWG569
> >> 2 fam0113 G113  cherry
> >> 3 fam0114 G114  cherry
> >> 4 fam0117 G117 4RWG569
> >> 5 fam0118 G118 5XAV049
> >> 6 fam0119 G119  cherry
> >> ...
> >> > dim(mc)
> >> [1] 1625    4
> >> > length(unique(mc$PLATE))
> >> [1] 34
> >>
> >> I am trying to make a new data frame which would look like this:
> >>       FID  IID   PLATE   4RWG569  cherry 5XAV049 ...
> >> 1 fam0110 G110 4RWG569  2  1  1
> >> 2 fam0113 G113  cherry   1  2  1
> >> 3 fam0114 G114  cherry   1  2  1
> >> 4 fam0117 G117 4RWG569  2  1  1
> >> 5 fam0118 G118 5XAV049   2  1  1
> >> 6 fam0119 G119  cherry   1  2  1
> >> ...
> >>
> >> so the new data frame would have an additional 34 columns (for every
> >> unique mc$PLATE) and if in the row of PLATE column the value is ==to
> >> that column name I would have 2 otherwise 1
> >>
> >> I tried to do this with:
> >>
> >> library(reshape2)
> >> >  m2=dcast(mc, IID ~ PLATE)
> >> Using PLATE as value column: use value.var to override.
> >>
> >> Please advise,
> >> Ana
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 29 20:19:45 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 29 Sep 2020 19:19:45 +0100
Subject: [R] 
 how to turn column into column names and fill it with values
In-Reply-To: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
References: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
Message-ID: <9e402ba4-ca29-5872-deb9-387dcf2a47f8@sapo.pt>

Hello,

Something like this?

mc <- read.table(text = "
       FID  IID   PLATE
1 fam0110 G110 4RWG569
2 fam0113 G113  cherry
3 fam0114 G114  cherry
4 fam0117 G117 4RWG569
5 fam0118 G118 5XAV049
6 fam0119 G119  cherry
", header = TRUE)



library(dplyr)
library(tidyr)

mc %>%
   group_by(PLATE) %>%
   mutate(counts = n()) %>%
   pivot_wider(
     id_cols = c("FID", "IID"),
     names_from = "PLATE",
     values_from = counts,
     values_fill = list(counts = 0)
   )


Hope this helps,

Rui Barradas

?s 17:18 de 29/09/20, Ana Marija escreveu:
> Hello,
> 
> I have a data frame like this:
> 
>> head(mc)
>        FID  IID   PLATE
> 1 fam0110 G110 4RWG569
> 2 fam0113 G113  cherry
> 3 fam0114 G114  cherry
> 4 fam0117 G117 4RWG569
> 5 fam0118 G118 5XAV049
> 6 fam0119 G119  cherry
> ...
>> dim(mc)
> [1] 1625    4
>> length(unique(mc$PLATE))
> [1] 34
> 
> I am trying to make a new data frame which would look like this:
>        FID  IID   PLATE   4RWG569  cherry 5XAV049 ...
> 1 fam0110 G110 4RWG569  2  1  1
> 2 fam0113 G113  cherry   1  2  1
> 3 fam0114 G114  cherry   1  2  1
> 4 fam0117 G117 4RWG569  2  1  1
> 5 fam0118 G118 5XAV049   2  1  1
> 6 fam0119 G119  cherry   1  2  1
> ...
> 
> so the new data frame would have an additional 34 columns (for every
> unique mc$PLATE) and if in the row of PLATE column the value is ==to
> that column name I would have 2 otherwise 1
> 
> I tried to do this with:
> 
> library(reshape2)
>>   m2=dcast(mc, IID ~ PLATE)
> Using PLATE as value column: use value.var to override.
> 
> Please advise,
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep 29 20:31:37 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 29 Sep 2020 19:31:37 +0100
Subject: [R] 
 how to turn column into column names and fill it with values
In-Reply-To: <9e402ba4-ca29-5872-deb9-387dcf2a47f8@sapo.pt>
References: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
 <9e402ba4-ca29-5872-deb9-387dcf2a47f8@sapo.pt>
Message-ID: <fbecdfc0-71c5-6c58-50bd-53c493950115@sapo.pt>

Hello,

Sorry, I didn't understand that 1 and 2 are the final values, I thought 
they would be counts of PLATE. I have changed the auxiliary column 
'counts' to 'flag'.


mc %>%
   group_by(PLATE) %>%
   mutate(flag = 2) %>%
   pivot_wider(
     id_cols = c("FID", "IID"),
     names_from = "PLATE",
     values_from = flag,
     values_fill = list(flag = 1)
   )


Hope this helps,

Rui Barradas

?s 19:19 de 29/09/20, Rui Barradas escreveu:
> Hello,
> 
> Something like this?
> 
> mc <- read.table(text = "
>  ????? FID? IID?? PLATE
> 1 fam0110 G110 4RWG569
> 2 fam0113 G113? cherry
> 3 fam0114 G114? cherry
> 4 fam0117 G117 4RWG569
> 5 fam0118 G118 5XAV049
> 6 fam0119 G119? cherry
> ", header = TRUE)
> 
> 
> 
> library(dplyr)
> library(tidyr)
> 
> mc %>%
>  ? group_by(PLATE) %>%
>  ? mutate(counts = n()) %>%
>  ? pivot_wider(
>  ??? id_cols = c("FID", "IID"),
>  ??? names_from = "PLATE",
>  ??? values_from = counts,
>  ??? values_fill = list(counts = 0)
>  ? )
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 17:18 de 29/09/20, Ana Marija escreveu:
>> Hello,
>>
>> I have a data frame like this:
>>
>>> head(mc)
>> ?????? FID? IID?? PLATE
>> 1 fam0110 G110 4RWG569
>> 2 fam0113 G113? cherry
>> 3 fam0114 G114? cherry
>> 4 fam0117 G117 4RWG569
>> 5 fam0118 G118 5XAV049
>> 6 fam0119 G119? cherry
>> ...
>>> dim(mc)
>> [1] 1625??? 4
>>> length(unique(mc$PLATE))
>> [1] 34
>>
>> I am trying to make a new data frame which would look like this:
>> ?????? FID? IID?? PLATE?? 4RWG569? cherry 5XAV049 ...
>> 1 fam0110 G110 4RWG569? 2? 1? 1
>> 2 fam0113 G113? cherry?? 1? 2? 1
>> 3 fam0114 G114? cherry?? 1? 2? 1
>> 4 fam0117 G117 4RWG569? 2? 1? 1
>> 5 fam0118 G118 5XAV049?? 2? 1? 1
>> 6 fam0119 G119? cherry?? 1? 2? 1
>> ...
>>
>> so the new data frame would have an additional 34 columns (for every
>> unique mc$PLATE) and if in the row of PLATE column the value is ==to
>> that column name I would have 2 otherwise 1
>>
>> I tried to do this with:
>>
>> library(reshape2)
>>> ? m2=dcast(mc, IID ~ PLATE)
>> Using PLATE as value column: use value.var to override.
>>
>> Please advise,
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 29 21:18:07 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 29 Sep 2020 12:18:07 -0700
Subject: [R] 
 how to turn column into column names and fill it with values
In-Reply-To: <9e402ba4-ca29-5872-deb9-387dcf2a47f8@sapo.pt>
References: <CAF9-5jPdquMk67o2QCcEavtt__7-Uk1s0+CXrMJ7q8_7Zwxnkg@mail.gmail.com>
 <9e402ba4-ca29-5872-deb9-387dcf2a47f8@sapo.pt>
Message-ID: <CAGxFJbR_pNcBt98ABK2ceGHni8WV3XCeE34K7KnWu95GHVFwOQ@mail.gmail.com>

A simpler, cleaner, and maybe faster approach is to use outer():

nm <- unique(dat$PLATE)
dat <- cbind(dat, 1+outer(dat$PLATE,nm,  "=="))
names(dat)[-(1:3)] <- nm

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 29, 2020 at 11:20 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Something like this?
>
> mc <- read.table(text = "
>        FID  IID   PLATE
> 1 fam0110 G110 4RWG569
> 2 fam0113 G113  cherry
> 3 fam0114 G114  cherry
> 4 fam0117 G117 4RWG569
> 5 fam0118 G118 5XAV049
> 6 fam0119 G119  cherry
> ", header = TRUE)
>
>
>
> library(dplyr)
> library(tidyr)
>
> mc %>%
>    group_by(PLATE) %>%
>    mutate(counts = n()) %>%
>    pivot_wider(
>      id_cols = c("FID", "IID"),
>      names_from = "PLATE",
>      values_from = counts,
>      values_fill = list(counts = 0)
>    )
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 17:18 de 29/09/20, Ana Marija escreveu:
> > Hello,
> >
> > I have a data frame like this:
> >
> >> head(mc)
> >        FID  IID   PLATE
> > 1 fam0110 G110 4RWG569
> > 2 fam0113 G113  cherry
> > 3 fam0114 G114  cherry
> > 4 fam0117 G117 4RWG569
> > 5 fam0118 G118 5XAV049
> > 6 fam0119 G119  cherry
> > ...
> >> dim(mc)
> > [1] 1625    4
> >> length(unique(mc$PLATE))
> > [1] 34
> >
> > I am trying to make a new data frame which would look like this:
> >        FID  IID   PLATE   4RWG569  cherry 5XAV049 ...
> > 1 fam0110 G110 4RWG569  2  1  1
> > 2 fam0113 G113  cherry   1  2  1
> > 3 fam0114 G114  cherry   1  2  1
> > 4 fam0117 G117 4RWG569  2  1  1
> > 5 fam0118 G118 5XAV049   2  1  1
> > 6 fam0119 G119  cherry   1  2  1
> > ...
> >
> > so the new data frame would have an additional 34 columns (for every
> > unique mc$PLATE) and if in the row of PLATE column the value is ==to
> > that column name I would have 2 otherwise 1
> >
> > I tried to do this with:
> >
> > library(reshape2)
> >>   m2=dcast(mc, IID ~ PLATE)
> > Using PLATE as value column: use value.var to override.
> >
> > Please advise,
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @ndr|u|@ @end|ng |rom u@|bert@@c@  Tue Sep 29 22:23:47 2020
From: @ndr|u|@ @end|ng |rom u@|bert@@c@ (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 29 Sep 2020 17:23:47 -0300
Subject: [R] Help with strings
Message-ID: <CAHxKz8a2MZWcN6N1QisGn34uF7Z1+Co2pvCszKbwm+w3h2RvuQ@mail.gmail.com>

Dear all,

I have had difficulties copying the word "alcohol" in the "vehicle" column
to replace the string in the column "accident_type". It is a huge list but
I have prepared a workable and simple example below and the desired
output.  I am sure you guys can give me some advice on how to deal with
this.

 sapply( all_files, function(x) dim(x))
      [,1]  [,2]  [,3]  [,4]
[1,] 89563 69295 67446 39709
[2,]    33    33    33    33



###Simple List

A= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "byke", "alcohol",
"motocycle"), c("alcohol", "cell_phone", "some_string", "fog"))
colnames(A) <- c("id", "km","vehicle","accident_cause")
A


B= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
"motocycle"), c("alcohol", "some_string", "rain", "fog"))
colnames(B) <- c("id", "km", "vehicle", "accident_type")
B


C= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
"alcohol"), c("alcohol", "some_string", "rain", "some_string"))
colnames(C) <- c("id", "km", "vehicle", "accident_type")
C

mylist <- list(A=A,B=B,C=C)
mylist


###Desired output

A= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "byke", "alcohol",
"motocycle"), c("alcohol", "cell_phone", "alcohol", "fog"))
colnames(A) <- c("id", "km","vehicle","accident_cause")
A


B= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
"motocycle"), c("alcohol", "alcohol", "rain", "fog"))
colnames(B) <- c("id", "km", "vehicle", "accident_type")
B


C= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
"alcohol"), c("alcohol", "alcohol", "rain", "alcohol"))
colnames(C) <- c("id", "km", "vehicle", "accident_type")
C

mylist <- list(A=A,B=B,C=C)
mylist


##Thank you very much,

-- 
Andre

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Sep 29 22:58:27 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 29 Sep 2020 16:58:27 -0400
Subject: [R] Help with strings
In-Reply-To: <CAHxKz8a2MZWcN6N1QisGn34uF7Z1+Co2pvCszKbwm+w3h2RvuQ@mail.gmail.com>
References: <CAHxKz8a2MZWcN6N1QisGn34uF7Z1+Co2pvCszKbwm+w3h2RvuQ@mail.gmail.com>
Message-ID: <CAM_vjuk33Y6BdgyVZ2xVF6wsWr43ENsKtHa1yf1N6Q_-S84rKg@mail.gmail.com>

Your desired output seems to be the same as your desired input in your
example, and your data frames have different column names.

Nonetheless, this bit of code will find rows with "alcohol" in column
3, and for those rows replace the contents of column 4 with column 3.
That may not be exactly what you're after, but should get you started.

lapply(mylist, function(x){
x[grepl("alcohol", x[, 3]), 4] <- x[grepl("alcohol", x[, 3]), 3]
x
})

Sarah

On Tue, Sep 29, 2020 at 4:24 PM Andr? Luis Neves <andrluis at ualberta.ca> wrote:
>
> Dear all,
>
> I have had difficulties copying the word "alcohol" in the "vehicle" column
> to replace the string in the column "accident_type". It is a huge list but
> I have prepared a workable and simple example below and the desired
> output.  I am sure you guys can give me some advice on how to deal with
> this.
>
>  sapply( all_files, function(x) dim(x))
>       [,1]  [,2]  [,3]  [,4]
> [1,] 89563 69295 67446 39709
> [2,]    33    33    33    33
>
>
>
> ###Simple List
>
> A= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "byke", "alcohol",
> "motocycle"), c("alcohol", "cell_phone", "some_string", "fog"))
> colnames(A) <- c("id", "km","vehicle","accident_cause")
> A
>
>
> B= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> "motocycle"), c("alcohol", "some_string", "rain", "fog"))
> colnames(B) <- c("id", "km", "vehicle", "accident_type")
> B
>
>
> C= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> "alcohol"), c("alcohol", "some_string", "rain", "some_string"))
> colnames(C) <- c("id", "km", "vehicle", "accident_type")
> C
>
> mylist <- list(A=A,B=B,C=C)
> mylist
>
>
> ###Desired output
>
> A= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "byke", "alcohol",
> "motocycle"), c("alcohol", "cell_phone", "alcohol", "fog"))
> colnames(A) <- c("id", "km","vehicle","accident_cause")
> A
>
>
> B= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> "motocycle"), c("alcohol", "alcohol", "rain", "fog"))
> colnames(B) <- c("id", "km", "vehicle", "accident_type")
> B
>
>
> C= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> "alcohol"), c("alcohol", "alcohol", "rain", "alcohol"))
> colnames(C) <- c("id", "km", "vehicle", "accident_type")
> C
>
> mylist <- list(A=A,B=B,C=C)
> mylist
>
>
> ##Thank you very much,
>
> --
> Andre
>


-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From @ndr|u|@ @end|ng |rom u@|bert@@c@  Tue Sep 29 23:07:58 2020
From: @ndr|u|@ @end|ng |rom u@|bert@@c@ (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 29 Sep 2020 18:07:58 -0300
Subject: [R] Help with strings
In-Reply-To: <CAM_vjuk33Y6BdgyVZ2xVF6wsWr43ENsKtHa1yf1N6Q_-S84rKg@mail.gmail.com>
References: <CAHxKz8a2MZWcN6N1QisGn34uF7Z1+Co2pvCszKbwm+w3h2RvuQ@mail.gmail.com>
 <CAM_vjuk33Y6BdgyVZ2xVF6wsWr43ENsKtHa1yf1N6Q_-S84rKg@mail.gmail.com>
Message-ID: <CAHxKz8YvLE0dmCn=i8n5mA6rxmDDiG2AuW7jr3oNf4uZecH-pw@mail.gmail.com>

Hi, Sarah,

There is a mistake in the column name and the desired output is pretty much
the same as the input data frames except for the replacement of
'some_string' by the word 'alcohol' in the column I specified above.
Yet, your code is what I am looking for and helped me to get started and
figure out how to move forward.

Thank you very much!

Andre

On Tue, Sep 29, 2020 at 5:58 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Your desired output seems to be the same as your desired input in your
> example, and your data frames have different column names.
>
> Nonetheless, this bit of code will find rows with "alcohol" in column
> 3, and for those rows replace the contents of column 4 with column 3.
> That may not be exactly what you're after, but should get you started.
>
> lapply(mylist, function(x){
> x[grepl("alcohol", x[, 3]), 4] <- x[grepl("alcohol", x[, 3]), 3]
> x
> })
>
> Sarah
>
> On Tue, Sep 29, 2020 at 4:24 PM Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
> >
> > Dear all,
> >
> > I have had difficulties copying the word "alcohol" in the "vehicle"
> column
> > to replace the string in the column "accident_type". It is a huge list
> but
> > I have prepared a workable and simple example below and the desired
> > output.  I am sure you guys can give me some advice on how to deal with
> > this.
> >
> >  sapply( all_files, function(x) dim(x))
> >       [,1]  [,2]  [,3]  [,4]
> > [1,] 89563 69295 67446 39709
> > [2,]    33    33    33    33
> >
> >
> >
> > ###Simple List
> >
> > A= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "byke", "alcohol",
> > "motocycle"), c("alcohol", "cell_phone", "some_string", "fog"))
> > colnames(A) <- c("id", "km","vehicle","accident_cause")
> > A
> >
> >
> > B= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> > "motocycle"), c("alcohol", "some_string", "rain", "fog"))
> > colnames(B) <- c("id", "km", "vehicle", "accident_type")
> > B
> >
> >
> > C= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> > "alcohol"), c("alcohol", "some_string", "rain", "some_string"))
> > colnames(C) <- c("id", "km", "vehicle", "accident_type")
> > C
> >
> > mylist <- list(A=A,B=B,C=C)
> > mylist
> >
> >
> > ###Desired output
> >
> > A= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "byke", "alcohol",
> > "motocycle"), c("alcohol", "cell_phone", "alcohol", "fog"))
> > colnames(A) <- c("id", "km","vehicle","accident_cause")
> > A
> >
> >
> > B= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> > "motocycle"), c("alcohol", "alcohol", "rain", "fog"))
> > colnames(B) <- c("id", "km", "vehicle", "accident_type")
> > B
> >
> >
> > C= data.frame(c("1", "2", "3", "4"),c(4:7),c("car", "alcohol", "car",
> > "alcohol"), c("alcohol", "alcohol", "rain", "alcohol"))
> > colnames(C) <- c("id", "km", "vehicle", "accident_type")
> > C
> >
> > mylist <- list(A=A,B=B,C=C)
> > mylist
> >
> >
> > ##Thank you very much,
> >
> > --
> > Andre
> >
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>


-- 
Andre

	[[alternative HTML version deleted]]


From @rr@ypro|||e @end|ng |rom y@hoo@com  Wed Sep 30 04:26:46 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Wed, 30 Sep 2020 02:26:46 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
Message-ID: <1722291974.141481.1601432806327@mail.yahoo.com>

Hi Jim,

I tried the clip() function below, surprisingly it did not work! I read the R help file and feel your script should work. To have a workable example, I used the ovarian dataset in the survival package as an example:

ovarian1<-ovarian
ovarian1$fustat[ovarian$futime>450]<-0
ovarian1$futime[ovarian$futime>450]<-450

ovarian2<-subset(ovarian,futime>450)

fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)

plot(fit1, xlim=c(0,1200), col = 1:2)
abline(v=450)
xylim<-par("usr")
clip(450,xylim[2],xylim[3],xylim[4])
lines(fit2, col = 3:4,lty=2)

I can still see that the extra horizontal line on the top.?

Can you or anyone have any suggestion what went wrong?

Thanks,

John


On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote: 





Hi John,
Perhaps the most direct way would be:

plot(fit1, col=1:2)
xylim<-par("usr")
clip(4,xylim[2],xylim[3],xylim[4])
lines(fit2,col=1:2)

Remember that the new clipping rectangle will persist until you or
something else resets it.

Jim

On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
>
> https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
>
> Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
>
> plot(fit1, col=1:2)
> lines(fit2,col=1:2)
>
> Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
>
> https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
>
> Can anyone have a strategy to make this kind of plot happen?
>
> Thanks,
>
> John

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 30 04:58:41 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 30 Sep 2020 12:58:41 +1000
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <1722291974.141481.1601432806327@mail.yahoo.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
 <1722291974.141481.1601432806327@mail.yahoo.com>
Message-ID: <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>

Hi John,
I should have remembered this. For some reason, the clip() function
doesn't operate until you have issued a graphics command. Try:

points(-1,-1)

before calling lines()

Jim

On Wed, Sep 30, 2020 at 12:26 PM array chip <arrayprofile at yahoo.com> wrote:
>
> Hi Jim,
>
> I tried the clip() function below, surprisingly it did not work! I read the R help file and feel your script should work. To have a workable example, I used the ovarian dataset in the survival package as an example:
>
> ovarian1<-ovarian
> ovarian1$fustat[ovarian$futime>450]<-0
> ovarian1$futime[ovarian$futime>450]<-450
>
> ovarian2<-subset(ovarian,futime>450)
>
> fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
>
> plot(fit1, xlim=c(0,1200), col = 1:2)
> abline(v=450)
> xylim<-par("usr")
> clip(450,xylim[2],xylim[3],xylim[4])
> lines(fit2, col = 3:4,lty=2)
>
> I can still see that the extra horizontal line on the top.
>
> Can you or anyone have any suggestion what went wrong?
>
> Thanks,
>
> John
>
>
> On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
>
>
>
> Hi John,
> Perhaps the most direct way would be:
>
> plot(fit1, col=1:2)
> xylim<-par("usr")
> clip(4,xylim[2],xylim[3],xylim[4])
> lines(fit2,col=1:2)
>
> Remember that the new clipping rectangle will persist until you or
> something else resets it.
>
> Jim
>
> On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello,
> >
> > Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
> >
> > https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> >
> > Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> >
> > plot(fit1, col=1:2)
> > lines(fit2,col=1:2)
> >
> > Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> >
> > https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> >
> > Can anyone have a strategy to make this kind of plot happen?
> >
> > Thanks,
> >
> > John
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From @rr@ypro|||e @end|ng |rom y@hoo@com  Wed Sep 30 05:45:38 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Wed, 30 Sep 2020 03:45:38 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
 <1722291974.141481.1601432806327@mail.yahoo.com>
 <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>
Message-ID: <677945138.159381.1601437538977@mail.yahoo.com>

Hi Jim,

I tried points(-1,-1) before lines() and before clip(), but either way, it still shows everything, :-(

It's interesting that the examples with hist() provided by the R help of clip function works nicely.

I also tried a simple linear regression plots below, clip() works, too.

dat<-data.frame(x=1:10,y=1:10)
fit<-lm(y~x,dat)
plot(1:10)
abline(fit)
xylim<-par("usr")
clip(6,xylim[2],xylim[3],xylim[4])
abline(fit,col=2)? ? ## yes, it only shows the fit line from 6 to the right
lines(c(2,8),c(5,5))? ? ## yes, it only shows the line from 6 to the right

So it's puzzling that only when using lines() with a survfit() object (ovarian example below), somehow clip() doesn't work

John




On Tuesday, September 29, 2020, 07:58:53 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote: 

Hi John,
I should have remembered this. For some reason, the clip() function
doesn't operate until you have issued a graphics command. Try:

points(-1,-1)

before calling lines()

Jim

On Wed, Sep 30, 2020 at 12:26 PM array chip <arrayprofile at yahoo.com> wrote:
>
> Hi Jim,
>
> I tried the clip() function below, surprisingly it did not work! I read the R help file and feel your script should work. To have a workable example, I used the ovarian dataset in the survival package as an example:
>
> ovarian1<-ovarian
> ovarian1$fustat[ovarian$futime>450]<-0
> ovarian1$futime[ovarian$futime>450]<-450
>
> ovarian2<-subset(ovarian,futime>450)
>
> fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
>
> plot(fit1, xlim=c(0,1200), col = 1:2)
> abline(v=450)
> xylim<-par("usr")
> clip(450,xylim[2],xylim[3],xylim[4])
> lines(fit2, col = 3:4,lty=2)
>
> I can still see that the extra horizontal line on the top.
>
> Can you or anyone have any suggestion what went wrong?
>
> Thanks,
>
> John
>
>
> On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
>
>
>
> Hi John,
> Perhaps the most direct way would be:
>
> plot(fit1, col=1:2)
> xylim<-par("usr")
> clip(4,xylim[2],xylim[3],xylim[4])
> lines(fit2,col=1:2)
>
> Remember that the new clipping rectangle will persist until you or
> something else resets it.
>
> Jim
>
> On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello,
> >
> > Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
> >
> > https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> >
> > Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> >
> > plot(fit1, col=1:2)
> > lines(fit2,col=1:2)
> >
> > Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> >
> > https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> >
> > Can anyone have a strategy to make this kind of plot happen?
> >
> > Thanks,
> >
> > John
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From @rr@ypro|||e @end|ng |rom y@hoo@com  Wed Sep 30 05:57:43 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Wed, 30 Sep 2020 03:57:43 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
 <1722291974.141481.1601432806327@mail.yahoo.com>
 <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>
Message-ID: <2061719555.161645.1601438263925@mail.yahoo.com>

Jim,

I tried a few things, I found that clip() works if I just do some regular graphing tasks. But as long as I run lines(fit) with "fit" object is a survfit object, this would reset to default plot region. See the ovarian example below:

library(survival)
ovarian1<-ovarian
ovarian1$fustat[ovarian$futime>450]<-0
ovarian1$futime[ovarian$futime>450]<-450
ovarian2<-subset(ovarian,futime>450)

fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)

plot(fit1, xlim=c(0,1200), col = 1:2)
abline(v=450)
xylim<-par("usr")
points(-1,-1)
clip(450,xylim[2],xylim[3],xylim[4])
abline(h=0.5,col=2)? ? ? ### YES, clipping() works!

lines(fit2, col = 3:4,lty=2)? ### clipping does not work! reset to default plot region
abline(h=0.4,col=2)? ? ? ?### NO, clipping() does not work!

So disappointed with this, otherwise this would be such a simple method to do what I want.

Thanks,

John

On Tuesday, September 29, 2020, 07:58:53 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:?

Hi John,
I should have remembered this. For some reason, the clip() function
doesn't operate until you have issued a graphics command. Try:

points(-1,-1)

before calling lines()

Jim

On Wed, Sep 30, 2020 at 12:26 PM array chip <arrayprofile at yahoo.com> wrote:
>
> Hi Jim,
>
> I tried the clip() function below, surprisingly it did not work! I read the R help file and feel your script should work. To have a workable example, I used the ovarian dataset in the survival package as an example:
>
> ovarian1<-ovarian
> ovarian1$fustat[ovarian$futime>450]<-0
> ovarian1$futime[ovarian$futime>450]<-450
>
> ovarian2<-subset(ovarian,futime>450)
>
> fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
>
> plot(fit1, xlim=c(0,1200), col = 1:2)
> abline(v=450)
> xylim<-par("usr")
> clip(450,xylim[2],xylim[3],xylim[4])
> lines(fit2, col = 3:4,lty=2)
>
> I can still see that the extra horizontal line on the top.
>
> Can you or anyone have any suggestion what went wrong?
>
> Thanks,
>
> John
>
>
> On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
>
>
>
> Hi John,
> Perhaps the most direct way would be:
>
> plot(fit1, col=1:2)
> xylim<-par("usr")
> clip(4,xylim[2],xylim[3],xylim[4])
> lines(fit2,col=1:2)
>
> Remember that the new clipping rectangle will persist until you or
> something else resets it.
>
> Jim
>
> On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello,
> >
> > Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
> >
> > https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> >
> > Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> >
> > plot(fit1, col=1:2)
> > lines(fit2,col=1:2)
> >
> > Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> >
> > https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> >
> > Can anyone have a strategy to make this kind of plot happen?
> >
> > Thanks,
> >
> > John
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From peter@w@g|ey09 @end|ng |rom gm@||@com  Wed Sep 30 06:35:01 2020
From: peter@w@g|ey09 @end|ng |rom gm@||@com (Peter Wagey)
Date: Tue, 29 Sep 2020 21:35:01 -0700
Subject: [R] help to create a simulated dataset
Message-ID: <CAA7XnHf1XMM=Eh1ygbyFo-q3=3mAOEQOWa3Z5mBA7acffUoi1w@mail.gmail.com>

Hi R User,
I was trying to create a data matrix with four columns: height, locations
(three locations), temperature (three levels) and slope (three classes) and
used the following code, but it did not work.  I basically wanted to have
20 rows for each class (I have a total of 9 classes). Can you help me to
fix the following code so that I can create the data frame?

daT<-data.frame(height=c(5:15))

minHeight=min(daT$height)

maxHeight=max(daT$height)

height.value= minHeight +(0:20)*(maxHeight-minHeight)/20


daT<-data.frame(height=height.value, location=rep(c("SiteA", "SiteB",
"SiteC"), 20), temperature=rep(c(10,20,30)), slope=rep(c("5deg", "10deg",
"15deg")))


Thanks

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep 30 06:52:35 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 29 Sep 2020 21:52:35 -0700
Subject: [R] help to create a simulated dataset
In-Reply-To: <CAA7XnHf1XMM=Eh1ygbyFo-q3=3mAOEQOWa3Z5mBA7acffUoi1w@mail.gmail.com>
References: <CAA7XnHf1XMM=Eh1ygbyFo-q3=3mAOEQOWa3Z5mBA7acffUoi1w@mail.gmail.com>
Message-ID: <CAGxFJbSmdrmVQSGRUetaeFxYae-k_+dpituDyQ-MKn5zifM4qA@mail.gmail.com>

Is this a for a homework assignment? We try to avoid doing others' homework
on this list.

To learn more about how to do simulations in R, search on "how to simulate
data in R" or similar. This brought up many tutorials that should be
helpful.

If this is not homework, maybe someone else can make sense of your query
and can help. I could not.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 29, 2020 at 9:36 PM Peter Wagey <peter.wagley09 at gmail.com>
wrote:

> Hi R User,
> I was trying to create a data matrix with four columns: height, locations
> (three locations), temperature (three levels) and slope (three classes) and
> used the following code, but it did not work.  I basically wanted to have
> 20 rows for each class (I have a total of 9 classes). Can you help me to
> fix the following code so that I can create the data frame?
>
> daT<-data.frame(height=c(5:15))
>
> minHeight=min(daT$height)
>
> maxHeight=max(daT$height)
>
> height.value= minHeight +(0:20)*(maxHeight-minHeight)/20
>
>
> daT<-data.frame(height=height.value, location=rep(c("SiteA", "SiteB",
> "SiteC"), 20), temperature=rep(c(10,20,30)), slope=rep(c("5deg", "10deg",
> "15deg")))
>
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From puetz @end|ng |rom p@ych@mpg@de  Tue Sep 29 13:14:22 2020
From: puetz @end|ng |rom p@ych@mpg@de (Puetz, Benno)
Date: Tue, 29 Sep 2020 13:14:22 +0200
Subject: [R] Problem with contour(): typo
In-Reply-To: <e3209411-02a5-f913-0668-3663b838d545@bebac.at>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
 <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
 <e3209411-02a5-f913-0668-3663b838d545@bebac.at>
Message-ID: <690C1EE8-EE77-44FC-8265-83838AF88DBB@psych.mpg.de>

I would assume the following snippet does what you want - note the use of outer with anonymous function wrapping powerTOST:

z <- outer(xs, ys, function(x, y)power.TOST(CV = y, theta0 = x, design = "2x2x4", method = "central", n = res[1]))
contour(xs, ys, z)

	Benno

> On 29. Sep 2020, at 12:43, Helmut Sch?tz <helmut.schuetz at bebac.at> wrote:
> 
> Dear Duncan,
> 
> Duncan Murdoch wrote on 2020-09-29 11:57:
>> On 29/09/2020 5:37 a.m., Helmut Sch?tz wrote:
>>> Here I'm lost. power.TOST(theta0, CV, ...) vectorizes properly for
>>> theta0 _or_ CV but no _both_. Hence
>>> library(PowerTOST)
>>> power.TOST(theta0 = c(0.9, 0.95, 1), CV = 0.25, n = 28)
>>> and
>>> power.TOST(theta0 = 0.95, CV = c(0.2, 0.25, 0.3), n = 28)
>>> work, whereas
>>> power.TOST(theta0 = c(0.9, 0.95, 1), 0.95, CV = c(0.2, 0.25, 0.3), n = 28)
>>> not. Of note, we will throw an error in the next release if both
>>> arguments are vectors.
>> 
>> I wouldn't do that, because it doesn't fit the usual R style. It's very common for functions to allow vector inputs in several arguments, and match up corresponding values to form a vector result.
> 
> I see. Here it would require to give the result as a matrix, data.frame,... Substantial change in the code though doable.
> 
>> If you want to use Vectorize, the command would be
>> 
>>   power.TOST.vectorized <- Vectorize(power.TOST, c("theta0", "CV"))
> 
> library(PowerTOST)
> theta0 <- unique(sort(c(0.95, seq(0.95*0.95, 1, length.out = 10))))
> CV     <- unique(sort(c(0.25, seq(0.25*0.8, 0.25*1.2, length.out = 10))))
> power.TOST.vectorized <- Vectorize(power.TOST, c("theta0", "CV", "n"))
> and
> power.TOST.vectorized(theta0 = theta0, CV = CV, n = 28)
> gives the diagonal elements of the desired 11*11 matrix:
> z <- matrix(ncol = length(theta0), nrow = length(CV))
> for (i in seq_along(CV)) {
>   z[i, ] <- power.TOST(theta0 = theta0, CV = CV[i], n = 28)
> }
> 
> Helmut
> 
> -- 
> Ing. Helmut Sch?tz
> BEBAC ? Consultancy Services for
> Bioequivalence and Bioavailability Studies
> Neubaugasse 36/11
> 1070 Vienna, Austria
> E helmut.schuetz at bebac.at
> W https://bebac.at/
> F https://forum.bebac.at/
> 
> 


From puetz @end|ng |rom p@ych@mpg@de  Tue Sep 29 15:16:27 2020
From: puetz @end|ng |rom p@ych@mpg@de (Puetz, Benno)
Date: Tue, 29 Sep 2020 15:16:27 +0200
Subject: [R] Problem with contour(): typo
In-Reply-To: <351ec099-1ed0-03f8-c580-1f69780cfad2@gmail.com>
References: <a733d312-f688-5253-9af8-70fa2e4d4fc8@bebac.at>
 <7717ffc7-9e31-565f-72b6-e77b360348e1@gmail.com>
 <e51b93ff-2453-aae6-343c-79c177ee6e13@bebac.at>
 <1e92d34d-ce90-cbcc-20d6-f015336e33d9@gmail.com>
 <e3209411-02a5-f913-0668-3663b838d545@bebac.at>
 <690C1EE8-EE77-44FC-8265-83838AF88DBB@psych.mpg.de>
 <519be2c7-704e-a507-4f2c-ac27ec894295@bebac.at>
 <351ec099-1ed0-03f8-c580-1f69780cfad2@gmail.com>
Message-ID: <0FDD0E32-22E0-40DD-B76C-E81FC79A5239@psych.mpg.de>

As I noted in my earlier post, it does - had checked that ;-)
It works by taking corresponding pair fo the input vectors (after possible recycling, as eluded by Helmut in his remark on working on only one vector) as needed for outer.

Thanks for the reminder, though,

	Benno

> On 29. Sep 2020, at 15:12, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> That won't work unless power.TOST is vectorized.  outer() will pass it vectors of x and y values.
> 
> Duncan Murdoch
> 
> On 29/09/2020 8:11 a.m., Helmut Sch?tz wrote:
>> Dear Benno,
>> THX, you made my day! Case closed.
>> Helmut
>> Puetz, Benno wrote on 2020-09-29 13:14:
>>> I would assume the following snippet does what you want - note the use
>>> of outer with anonymous function wrapping powerTOST:
>>> 
>>> z <- outer(xs, ys, function(x, y)power.TOST(CV = y, theta0 = x, design
>>> = "2x2x4", method = "central", n = res[1]))
>>> contour(xs, ys, z)
> 


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 30 10:47:42 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 30 Sep 2020 18:47:42 +1000
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <2061719555.161645.1601438263925@mail.yahoo.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
 <1722291974.141481.1601432806327@mail.yahoo.com>
 <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>
 <2061719555.161645.1601438263925@mail.yahoo.com>
Message-ID: <CA+8X3fW0qJruksWxJnwJvY13L0FcVcM2U9w0OS-Lvy1Ck4FKvw@mail.gmail.com>

Hi John,
Hmmm, this works:

plot(1:10)
xylim<-par("usr")
clip(5,xylim[2],xylim[3],xylim[4])
lines(10:1)

so I suspect that there is a "lines" method that resets the clipping
region out of sight. Fortunately Mark Schwartz provided a way to get
your plot so I will give the wall against which I have been banging my
head a break.

Jim

On Wed, Sep 30, 2020 at 1:57 PM array chip <arrayprofile at yahoo.com> wrote:
>
> Jim,
>
> I tried a few things, I found that clip() works if I just do some regular graphing tasks. But as long as I run lines(fit) with "fit" object is a survfit object, this would reset to default plot region. See the ovarian example below:
>
> library(survival)
> ovarian1<-ovarian
> ovarian1$fustat[ovarian$futime>450]<-0
> ovarian1$futime[ovarian$futime>450]<-450
> ovarian2<-subset(ovarian,futime>450)
>
> fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
>
> plot(fit1, xlim=c(0,1200), col = 1:2)
> abline(v=450)
> xylim<-par("usr")
> points(-1,-1)
> clip(450,xylim[2],xylim[3],xylim[4])
> abline(h=0.5,col=2)      ### YES, clipping() works!
>
> lines(fit2, col = 3:4,lty=2)  ### clipping does not work! reset to default plot region
> abline(h=0.4,col=2)       ### NO, clipping() does not work!
>
> So disappointed with this, otherwise this would be such a simple method to do what I want.
>
> Thanks,
>
> John
>
> On Tuesday, September 29, 2020, 07:58:53 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi John,
> I should have remembered this. For some reason, the clip() function
> doesn't operate until you have issued a graphics command. Try:
>
> points(-1,-1)
>
> before calling lines()
>
> Jim
>
> On Wed, Sep 30, 2020 at 12:26 PM array chip <arrayprofile at yahoo.com> wrote:
> >
> > Hi Jim,
> >
> > I tried the clip() function below, surprisingly it did not work! I read the R help file and feel your script should work. To have a workable example, I used the ovarian dataset in the survival package as an example:
> >
> > ovarian1<-ovarian
> > ovarian1$fustat[ovarian$futime>450]<-0
> > ovarian1$futime[ovarian$futime>450]<-450
> >
> > ovarian2<-subset(ovarian,futime>450)
> >
> > fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> > fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
> >
> > plot(fit1, xlim=c(0,1200), col = 1:2)
> > abline(v=450)
> > xylim<-par("usr")
> > clip(450,xylim[2],xylim[3],xylim[4])
> > lines(fit2, col = 3:4,lty=2)
> >
> > I can still see that the extra horizontal line on the top.
> >
> > Can you or anyone have any suggestion what went wrong?
> >
> > Thanks,
> >
> > John
> >
> >
> > On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >
> >
> >
> >
> > Hi John,
> > Perhaps the most direct way would be:
> >
> > plot(fit1, col=1:2)
> > xylim<-par("usr")
> > clip(4,xylim[2],xylim[3],xylim[4])
> > lines(fit2,col=1:2)
> >
> > Remember that the new clipping rectangle will persist until you or
> > something else resets it.
> >
> > Jim
> >
> > On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
> > <r-help at r-project.org> wrote:
> > >
> > > Hello,
> > >
> > > Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
> > >
> > > https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> > >
> > > Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> > >
> > > plot(fit1, col=1:2)
> > > lines(fit2,col=1:2)
> > >
> > > Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> > >
> > > https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> > >
> > > Can anyone have a strategy to make this kind of plot happen?
> > >
> > > Thanks,
> > >
> > > John
> >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >


From m@|||P@dpo@t @end|ng |rom gm@||@com  Wed Sep 30 17:05:49 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Wed, 30 Sep 2020 18:05:49 +0300
Subject: [R] How to decrease size of points?
Message-ID: <CAH6117KskFv5aQ7ygejn+iQoa9f-q=8HRpz2bRaWDyw1DVeqkQ@mail.gmail.com>

The code works as I want, but the points are too big. How to decrease
them? (Where to insert: size = 0.8?)
p1 <- p + geom_point(aes(size = Stage), alpha = 1/3) + xlab ("X") +
ylab("Y") + geom_smooth()


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 30 17:33:53 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 30 Sep 2020 16:33:53 +0100
Subject: [R] How to decrease size of points?
In-Reply-To: <CAH6117KskFv5aQ7ygejn+iQoa9f-q=8HRpz2bRaWDyw1DVeqkQ@mail.gmail.com>
References: <CAH6117KskFv5aQ7ygejn+iQoa9f-q=8HRpz2bRaWDyw1DVeqkQ@mail.gmail.com>
Message-ID: <9f5dcc30-dac9-f703-bb57-a2abea2cbaf1@sapo.pt>

Hello,

Your example is not reproducible but here it goes.

Data:

df1 <- iris[c(1, 2, 5)]

Use scale_size_manual.

1. If Stage is a factor or character



df1$Stage <- "a"

p <- ggplot(df1, aes(Sepal.Length, Sepal.Width, color = Species))
p1 <- p +
   geom_point(aes(size = Stage), alpha = 1/3) +
   xlab ("X") +
   ylab("Y") +
   geom_smooth(method = 'loess', formula = y ~ x)



2. If Stage is numeric, coerce to factor manually


df1$Stage <- 5

p <- ggplot(df1, aes(Sepal.Length, Sepal.Width, color = Species))
p1 <- p +
   geom_point(aes(size = factor(Stage)), alpha = 1/3) +
   xlab ("X") +
   ylab("Y") +
   geom_smooth(method = 'loess', formula = y ~ x)


Then add the scale_size


p1 + scale_size_manual(values = 0.8)


Hope this helps,

Rui Barradas

?s 16:05 de 30/09/20, Medic escreveu:
> The code works as I want, but the points are too big. How to decrease
> them? (Where to insert: size = 0.8?)
> p1 <- p + geom_point(aes(size = Stage), alpha = 1/3) + xlab ("X") +
> ylab("Y") + geom_smooth()
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ko@t@kt m@iii@g oii be@j@mi@schiegei@ch  Tue Sep 29 19:09:12 2020
From: ko@t@kt m@iii@g oii be@j@mi@schiegei@ch (ko@t@kt m@iii@g oii be@j@mi@schiegei@ch)
Date: Tue, 29 Sep 2020 19:09:12 +0200
Subject: [R] [R-pkgs] New version of package brant on CRAN
Message-ID: <00cf01d69683$415b4130$c411c390$@benjaminschlegel.ch>

Dear R community

 

The new version of the package brant (0.3-0) is now available on CRAN. It
contains the function brant() to test the parallel regression assumption for
ordinal logistic regression models.

 

I this version I fixed a bug which led in some situations to an error
message and I added support for interaction terms. 

 

Let me know if you have any questions, still get an error message in any
situation or have suggestions.

 

Best,

 

Benjamin Schlegel

Assistent Lehrstuhl f?r Methoden

 

Unversit?t Z?rich

Institut f?r Politikwissenschaften

Affolternstrasse 56

8050 Z?rich

 

+41 44 634 62 08

kontakt at benjaminschlegel.ch <mailto:kontakt at benjaminschlegel.ch> 


	[[alternative HTML version deleted]]


-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From @rr@ypro|||e @end|ng |rom y@hoo@com  Wed Sep 30 18:09:10 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Wed, 30 Sep 2020 16:09:10 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <CA+8X3fW0qJruksWxJnwJvY13L0FcVcM2U9w0OS-Lvy1Ck4FKvw@mail.gmail.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
 <1722291974.141481.1601432806327@mail.yahoo.com>
 <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>
 <2061719555.161645.1601438263925@mail.yahoo.com>
 <CA+8X3fW0qJruksWxJnwJvY13L0FcVcM2U9w0OS-Lvy1Ck4FKvw@mail.gmail.com>
Message-ID: <1183810721.353782.1601482150803@mail.yahoo.com>

Thank you Jim for helping! Yes, I will try Mark's method.

John


On Wednesday, September 30, 2020, 01:47:55 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote: 

Hi John,
Hmmm, this works:

plot(1:10)
xylim<-par("usr")
clip(5,xylim[2],xylim[3],xylim[4])
lines(10:1)

so I suspect that there is a "lines" method that resets the clipping
region out of sight. Fortunately Mark Schwartz provided a way to get
your plot so I will give the wall against which I have been banging my
head a break.

Jim

On Wed, Sep 30, 2020 at 1:57 PM array chip <arrayprofile at yahoo.com> wrote:
>
> Jim,
>
> I tried a few things, I found that clip() works if I just do some regular graphing tasks. But as long as I run lines(fit) with "fit" object is a survfit object, this would reset to default plot region. See the ovarian example below:
>
> library(survival)
> ovarian1<-ovarian
> ovarian1$fustat[ovarian$futime>450]<-0
> ovarian1$futime[ovarian$futime>450]<-450
> ovarian2<-subset(ovarian,futime>450)
>
> fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
>
> plot(fit1, xlim=c(0,1200), col = 1:2)
> abline(v=450)
> xylim<-par("usr")
> points(-1,-1)
> clip(450,xylim[2],xylim[3],xylim[4])
> abline(h=0.5,col=2)? ? ? ### YES, clipping() works!
>
> lines(fit2, col = 3:4,lty=2)? ### clipping does not work! reset to default plot region
> abline(h=0.4,col=2)? ? ? ### NO, clipping() does not work!
>
> So disappointed with this, otherwise this would be such a simple method to do what I want.
>
> Thanks,
>
> John
>
> On Tuesday, September 29, 2020, 07:58:53 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi John,
> I should have remembered this. For some reason, the clip() function
> doesn't operate until you have issued a graphics command. Try:
>
> points(-1,-1)
>
> before calling lines()
>
> Jim
>
> On Wed, Sep 30, 2020 at 12:26 PM array chip <arrayprofile at yahoo.com> wrote:
> >
> > Hi Jim,
> >
> > I tried the clip() function below, surprisingly it did not work! I read the R help file and feel your script should work. To have a workable example, I used the ovarian dataset in the survival package as an example:
> >
> > ovarian1<-ovarian
> > ovarian1$fustat[ovarian$futime>450]<-0
> > ovarian1$futime[ovarian$futime>450]<-450
> >
> > ovarian2<-subset(ovarian,futime>450)
> >
> > fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> > fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
> >
> > plot(fit1, xlim=c(0,1200), col = 1:2)
> > abline(v=450)
> > xylim<-par("usr")
> > clip(450,xylim[2],xylim[3],xylim[4])
> > lines(fit2, col = 3:4,lty=2)
> >
> > I can still see that the extra horizontal line on the top.
> >
> > Can you or anyone have any suggestion what went wrong?
> >
> > Thanks,
> >
> > John
> >
> >
> > On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >
> >
> >
> >
> > Hi John,
> > Perhaps the most direct way would be:
> >
> > plot(fit1, col=1:2)
> > xylim<-par("usr")
> > clip(4,xylim[2],xylim[3],xylim[4])
> > lines(fit2,col=1:2)
> >
> > Remember that the new clipping rectangle will persist until you or
> > something else resets it.
> >
> > Jim
> >
> > On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
> > <r-help at r-project.org> wrote:
> > >
> > > Hello,
> > >
> > > Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
> > >
> > > https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> > >
> > > Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> > >
> > > plot(fit1, col=1:2)
> > > lines(fit2,col=1:2)
> > >
> > > Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> > >
> > > https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> > >
> > > Can anyone have a strategy to make this kind of plot happen?
> > >
> > > Thanks,
> > >
> > > John
> >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >


From @rr@ypro|||e @end|ng |rom y@hoo@com  Wed Sep 30 18:47:25 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Wed, 30 Sep 2020 16:47:25 +0000 (UTC)
Subject: [R] 2 KM curves on the same plot
In-Reply-To: <CA+8X3fW0qJruksWxJnwJvY13L0FcVcM2U9w0OS-Lvy1Ck4FKvw@mail.gmail.com>
References: <2002394729.15283.1601339603771.ref@mail.yahoo.com>
 <2002394729.15283.1601339603771@mail.yahoo.com>
 <CA+8X3fW8ZzeUD1-JcBPXTxHpoHgttWwLO5_g2CbjExOUrTigtg@mail.gmail.com>
 <1722291974.141481.1601432806327@mail.yahoo.com>
 <CA+8X3fV+Q9ag=AJjs-Hcn_L+fEPr6a+=P3f=LjKboDXBHAEFjw@mail.gmail.com>
 <2061719555.161645.1601438263925@mail.yahoo.com>
 <CA+8X3fW0qJruksWxJnwJvY13L0FcVcM2U9w0OS-Lvy1Ck4FKvw@mail.gmail.com>
Message-ID: <1576196209.374733.1601484445685@mail.yahoo.com>

Hi Jim,

I found out why clip() does not work with lines(survfit.object)!

If you look at code of function survival:::lines.survfit, in th middle of the code:

? ? do.clip <- getOption("plot.survfit")
? ? if (!is.null(xx <- do.clip$plotclip))?
? ? ? ? clip(xx[1], xx[2], xx[3], xx[4])

This will reset the clipping to the defualt plot region!

So I just comment out the last 2 lines of the above 3 lines, and created a customized lines2 function. Now it works!

It's fun to learn clip().

Thanks,

John


On Wednesday, September 30, 2020, 01:47:55 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote: 


Hi John,
Hmmm, this works:

plot(1:10)
xylim<-par("usr")
clip(5,xylim[2],xylim[3],xylim[4])
lines(10:1)

so I suspect that there is a "lines" method that resets the clipping
region out of sight. Fortunately Mark Schwartz provided a way to get
your plot so I will give the wall against which I have been banging my
head a break.

Jim

On Wed, Sep 30, 2020 at 1:57 PM array chip <arrayprofile at yahoo.com> wrote:
>
> Jim,
>
> I tried a few things, I found that clip() works if I just do some regular graphing tasks. But as long as I run lines(fit) with "fit" object is a survfit object, this would reset to default plot region. See the ovarian example below:
>
> library(survival)
> ovarian1<-ovarian
> ovarian1$fustat[ovarian$futime>450]<-0
> ovarian1$futime[ovarian$futime>450]<-450
> ovarian2<-subset(ovarian,futime>450)
>
> fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
>
> plot(fit1, xlim=c(0,1200), col = 1:2)
> abline(v=450)
> xylim<-par("usr")
> points(-1,-1)
> clip(450,xylim[2],xylim[3],xylim[4])
> abline(h=0.5,col=2)? ? ? ### YES, clipping() works!
>
> lines(fit2, col = 3:4,lty=2)? ### clipping does not work! reset to default plot region
> abline(h=0.4,col=2)? ? ? ### NO, clipping() does not work!
>
> So disappointed with this, otherwise this would be such a simple method to do what I want.
>
> Thanks,
>
> John
>
> On Tuesday, September 29, 2020, 07:58:53 PM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi John,
> I should have remembered this. For some reason, the clip() function
> doesn't operate until you have issued a graphics command. Try:
>
> points(-1,-1)
>
> before calling lines()
>
> Jim
>
> On Wed, Sep 30, 2020 at 12:26 PM array chip <arrayprofile at yahoo.com> wrote:
> >
> > Hi Jim,
> >
> > I tried the clip() function below, surprisingly it did not work! I read the R help file and feel your script should work. To have a workable example, I used the ovarian dataset in the survival package as an example:
> >
> > ovarian1<-ovarian
> > ovarian1$fustat[ovarian$futime>450]<-0
> > ovarian1$futime[ovarian$futime>450]<-450
> >
> > ovarian2<-subset(ovarian,futime>450)
> >
> > fit1 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian1)
> > fit2 <- survfit(Surv(futime, fustat) ~ rx, data = ovarian2)
> >
> > plot(fit1, xlim=c(0,1200), col = 1:2)
> > abline(v=450)
> > xylim<-par("usr")
> > clip(450,xylim[2],xylim[3],xylim[4])
> > lines(fit2, col = 3:4,lty=2)
> >
> > I can still see that the extra horizontal line on the top.
> >
> > Can you or anyone have any suggestion what went wrong?
> >
> > Thanks,
> >
> > John
> >
> >
> > On Tuesday, September 29, 2020, 01:35:48 AM PDT, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >
> >
> >
> >
> > Hi John,
> > Perhaps the most direct way would be:
> >
> > plot(fit1, col=1:2)
> > xylim<-par("usr")
> > clip(4,xylim[2],xylim[3],xylim[4])
> > lines(fit2,col=1:2)
> >
> > Remember that the new clipping rectangle will persist until you or
> > something else resets it.
> >
> > Jim
> >
> > On Tue, Sep 29, 2020 at 10:34 AM array chip via R-help
> > <r-help at r-project.org> wrote:
> > >
> > > Hello,
> > >
> > > Can anyone suggest a simple way to generate a Kaplan-Meier plot with 2 survfit objects, just like this one:
> > >
> > > https://drive.google.com/file/d/1fEcpdIdE2xYtA6LBQN9ck3JkL6-goabX/view?usp=sharing
> > >
> > > Suppose I have 2 survfit objects: fit1 is for the curve on the left (survtime has been truncated to the cutoff line: year 5), fit2 is for the curve on the right (minimum survival time is at the cutoff line: year 5), but if I do the following:
> > >
> > > plot(fit1, col=1:2)
> > > lines(fit2,col=1:2)
> > >
> > > Then I will have an horizontal line on the top that connect from 0 to 4 years, which I do not want that to be drawn (see blue arrow below):
> > >
> > > https://drive.google.com/file/d/178mQGlhnaOg9PA-oE-W_W5CtrGD03ljH/view?usp=sharing
> > >
> > > Can anyone have a strategy to make this kind of plot happen?
> > >
> > > Thanks,
> > >
> > > John
> >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >


From m@|||P@dpo@t @end|ng |rom gm@||@com  Wed Sep 30 18:58:47 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Wed, 30 Sep 2020 19:58:47 +0300
Subject: [R] How to decrease size of points?
Message-ID: <CAH6117JZieBDvB2VDCrrAQJ7WzCR=0yr2a5BFoHZhfz8HH1obA@mail.gmail.com>

The code works as I want, but the points (circles) on the plot are too
big. How to decrease them? Where to insert (for instance) size = 0.8
for points (circles) on plot?
p1 <- p + geom_point(aes(size = Stage), alpha = 1/3) + xlab ("X") +
ylab("Y") + geom_smooth()
Stage is factor, x and y - continuous

<Rui Barradas: add the scale_size
p1 + scale_size_manual(values = 0.8)>

Thanks Rui, but I got:
Error: Insufficient values in manual scale. 12 needed but only 1 provided.
(or Error: Continuous value supplied to discrete scale)


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 30 20:06:28 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 30 Sep 2020 19:06:28 +0100
Subject: [R] How to decrease size of points?
In-Reply-To: <CAH6117JZieBDvB2VDCrrAQJ7WzCR=0yr2a5BFoHZhfz8HH1obA@mail.gmail.com>
References: <CAH6117JZieBDvB2VDCrrAQJ7WzCR=0yr2a5BFoHZhfz8HH1obA@mail.gmail.com>
Message-ID: <91b886ad-4759-7743-c097-3b41da4113c7@sapo.pt>

Hello,

That's the problem of not having a reproducible example, you only gave 
us one value for size.
Try

nsize <- length(unique(df1$Stage))

before the plot and then

p1 + scale_size_manual(values = rep(0.8, nsize))


Hope this helps,

Rui Barradas


?s 17:58 de 30/09/20, Medic escreveu:
> The code works as I want, but the points (circles) on the plot are too
> big. How to decrease them? Where to insert (for instance) size = 0.8
> for points (circles) on plot?
> p1 <- p + geom_point(aes(size = Stage), alpha = 1/3) + xlab ("X") +
> ylab("Y") + geom_smooth()
> Stage is factor, x and y - continuous
> 
> <Rui Barradas: add the scale_size
> p1 + scale_size_manual(values = 0.8)>
> 
> Thanks Rui, but I got:
> Error: Insufficient values in manual scale. 12 needed but only 1 provided.
> (or Error: Continuous value supplied to discrete scale)
>


From m@|||P@dpo@t @end|ng |rom gm@||@com  Wed Sep 30 21:01:10 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Wed, 30 Sep 2020 22:01:10 +0300
Subject: [R] How to decrease size of points?
In-Reply-To: <91b886ad-4759-7743-c097-3b41da4113c7@sapo.pt>
References: <CAH6117JZieBDvB2VDCrrAQJ7WzCR=0yr2a5BFoHZhfz8HH1obA@mail.gmail.com>
 <91b886ad-4759-7743-c097-3b41da4113c7@sapo.pt>
Message-ID: <CAH6117LmQ3Wpi3VRkEhzCEkncRiWHwYMfJoqY8BrfkA8-yO7dw@mail.gmail.com>

?1 Medic:
The code works as I want, but the points (circles) on the plot are too
big. How to decrease them? Where to insert (for instance) size = 0.8
for points (circles) on plot?

p1 <- p + geom_point(aes(size = Stage), alpha = 1/3) + xlab ("X") +
ylab("Y") + geom_smooth()

Stage is factor, x and y - continuous
===
?2 Rui Barradas:
add the scale_size
p1 + scale_size_manual(values = 0.8)
===
?3 Medic:
Thanks Rui, but I got:
Error: Insufficient values in manual scale. 12 needed but only 1 provided.
(or Error: Continuous value supplied to discrete scale)
===
?4 Rui Barradas:
Try
nsize <- length(unique(df1$Stage))
before the plot and then
p1 + scale_size_manual(values = rep(0.8, nsize))
===
?5 Medic:
Rui, your example is very good!
Now your code works, but not as I want.

Why did I use:
geom_point(aes(size = Stage)...?
In order to receive points of DIFFERENT size!

And what does your code do?
It assigns the same fixed size to ALL points.

I don't need this.
I sincerely thank you and closing the topic!


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 30 21:35:37 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 30 Sep 2020 20:35:37 +0100
Subject: [R] How to decrease size of points?
In-Reply-To: <CAH6117LmQ3Wpi3VRkEhzCEkncRiWHwYMfJoqY8BrfkA8-yO7dw@mail.gmail.com>
References: <CAH6117JZieBDvB2VDCrrAQJ7WzCR=0yr2a5BFoHZhfz8HH1obA@mail.gmail.com>
 <91b886ad-4759-7743-c097-3b41da4113c7@sapo.pt>
 <CAH6117LmQ3Wpi3VRkEhzCEkncRiWHwYMfJoqY8BrfkA8-yO7dw@mail.gmail.com>
Message-ID: <87aec622-8675-a962-dd46-b0fb8d729997@sapo.pt>

Hello,

Inline.

?s 20:01 de 30/09/20, Medic escreveu:
> ?1 Medic:
> The code works as I want, but the points (circles) on the plot are too
> big. How to decrease them? Where to insert (for instance) size = 0.8
> for points (circles) on plot?
> 
> p1 <- p + geom_point(aes(size = Stage), alpha = 1/3) + xlab ("X") +
> ylab("Y") + geom_smooth()
> 
> Stage is factor, x and y - continuous
> ===
> ?2 Rui Barradas:
> add the scale_size
> p1 + scale_size_manual(values = 0.8)
> ===
> ?3 Medic:
> Thanks Rui, but I got:
> Error: Insufficient values in manual scale. 12 needed but only 1 provided.
> (or Error: Continuous value supplied to discrete scale)
> ===
> ?4 Rui Barradas:
> Try
> nsize <- length(unique(df1$Stage))
> before the plot and then
> p1 + scale_size_manual(values = rep(0.8, nsize))
> ===
> ?5 Medic:
> Rui, your example is very good!
> Now your code works, but not as I want.
> 
> Why did I use:
> geom_point(aes(size = Stage)...?
> In order to receive points of DIFFERENT size!
> 
> And what does your code do?
> It assigns the same fixed size to ALL points.

If you want different sizes, the main idea is the same, assign the sizes 
in scale_size_manual.

Stage is a factor so it has a certain number of levels. Create a numeric 
variable, Sizes, from the minimum to the maximum size, set names to its 
values and use that vector.
With 0.4 and 0.8 as min and max size, something like


Sizes <- seq(0.4, 0.8, length.out = length(levels(df1$Stage)))
Sizes <- setNames(Sizes, levels(df1$Stage))

p1 + scale_size_manual(values = Sizes)


Hope this helps,

Rui Barradas

> 
> I don't need this.
> I sincerely thank you and closing the topic!
>


From m@|||P@dpo@t @end|ng |rom gm@||@com  Wed Sep 30 22:39:47 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Wed, 30 Sep 2020 23:39:47 +0300
Subject: [R] How to decrease size of points?
Message-ID: <CAH6117LOdRwsr2QGoX77Cxp91zGsaVy4RWmCYLE-XUiDkfOWeA@mail.gmail.com>

Yes, I just wanted to decrease the STARTING point size!
Sorry for not being able to formulate
Thank you very much, Rui and Avi!
That's all for now. I need to comprehend information.
Medic


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Sep 30 21:59:22 2020
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 30 Sep 2020 15:59:22 -0400
Subject: [R] How to decrease size of points?
In-Reply-To: <CAH6117LmQ3Wpi3VRkEhzCEkncRiWHwYMfJoqY8BrfkA8-yO7dw@mail.gmail.com>
References: <CAH6117JZieBDvB2VDCrrAQJ7WzCR=0yr2a5BFoHZhfz8HH1obA@mail.gmail.com>
 <91b886ad-4759-7743-c097-3b41da4113c7@sapo.pt>
 <CAH6117LmQ3Wpi3VRkEhzCEkncRiWHwYMfJoqY8BrfkA8-yO7dw@mail.gmail.com>
Message-ID: <03b401d69764$31108ba0$9331a2e0$@verizon.net>

It is better to understand the requirements before suggesting a way to do it.

My GUESS is that the questioner  wants the circles of different sizes based on a factor but the natural choices start too high for their needs/taste. So they want a base size of 0.8 that is either the minimum or maximum size. I offer a verbal solution but end with possibly a simple solution using other functionality.

So I am proposing a solution but only if the above is what you want. If it is something else, state it clearly.

So say you want the sizes to go from 0.8 to 1.2. The approach offered can be tweaked to do the following in English.

Calculate the number of unique levels of the factor in the data. Make sure the factor is (re)ordered to have those N levels and in the right order.

Create a vector of N values but they should not all be 0.8. They should have the first one be 0.8, and the second would have added to that something like  (1.2 - 0.8)/N and the next has double that added and so on. With the proper calculations, you get a smoothly increasing value for a size for the circles in a vector of the right size. Many other methods can be used like multiplying the preceding size by 1.1 and you can play rounding games or anything else. In the end, you have a_vector looking a bit like c(0.8, 0.84, 0.88, 0.92, ... 1.16, 1.20) or whatever.

Now note the word "manual" in scale_size_manual(values = a_vector)

It means you are doing things manually rather than allowing ggplot to choose them automatically. Saying size=variable is now not useful or even wanted. You are choosing manually.

Just give it the vector of increasing sizes you wanted and it should use them in that order as long as the factor you use is in the order you want. If it is a categorical variable with your required order, there are ways to get what you want either by making it ordered or re-ordering the factors so the hidden index values of 1,2,3 ... correspond.

I have not tried this and am not supplying actual code, just the concept.  But this approach feels too long and cumbersome given how common a need like the one I think you want might be.

A much better solution would be a way to specify a baseline minimum and perhaps maximum and let the underlying ggplot print method figure things out. If the manual pages are correct, it may make sense to use other "scale" functions that allow you to specify a minimum and maximum size 

	https://www.rdocumentation.org/packages/ggplot2/versions/1.0.1/topics/scale_size

	scale_size_continuous(..., range = c(1, 6))
	scale_size(..., range = c(1, 6))
	scale_size_discrete(..., range = c(1, 6))

I see examples that suggest it works the way I want:

	(p <- qplot(mpg, cyl, data=mtcars, size=cyl))
	...
	p + scale_size(range = c(0, 10))
	p + scale_size(range = c(1, 2))

In the above you both ask ggplot to adjust the size to match the variable/column called cylinder and also provide a range for those values to be distributed between.

Sounds like a plan to try?

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Medic
Sent: Wednesday, September 30, 2020 3:01 PM
To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
Subject: Re: [R] How to decrease size of points?

?1 Medic:
The code works as I want, but the points (circles) on the plot are too big. How to decrease them? Where to insert (for instance) size = 0.8 for points (circles) on plot?

p1 <- p + geom_point(aes(size = Stage), alpha = 1/3) + xlab ("X") +
ylab("Y") + geom_smooth()

Stage is factor, x and y - continuous
===
?2 Rui Barradas:
add the scale_size
p1 + scale_size_manual(values = 0.8)
===
?3 Medic:
Thanks Rui, but I got:
Error: Insufficient values in manual scale. 12 needed but only 1 provided.
(or Error: Continuous value supplied to discrete scale) ===
?4 Rui Barradas:
Try
nsize <- length(unique(df1$Stage))
before the plot and then
p1 + scale_size_manual(values = rep(0.8, nsize)) ===
?5 Medic:
Rui, your example is very good!
Now your code works, but not as I want.

Why did I use:
geom_point(aes(size = Stage)...?
In order to receive points of DIFFERENT size!

And what does your code do?
It assigns the same fixed size to ALL points.

I don't need this.
I sincerely thank you and closing the topic!

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


