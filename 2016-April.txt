From bgunter.4567 at gmail.com  Fri Apr  1 01:22:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 31 Mar 2016 16:22:22 -0700
Subject: [R] reduced set of alternatives in package mlogit
In-Reply-To: <GRUPR80MB04443F1875EAF793C2385609E2990@GRUPR80MB0444.lamprd80.prod.outlook.com>
References: <GRUPR80MB04443F1875EAF793C2385609E2990@GRUPR80MB0444.lamprd80.prod.outlook.com>
Message-ID: <CAGxFJbRGPWZv3hhDiUV4cuzg5xHoihfb+FjaZ0cJCeMVx33ATw@mail.gmail.com>

code? example data?  We can only guess based on your vague post.

"PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code."

Moreover, this sounds like a statistical question, not a question
about R programming, and so might be more appropriate for a
statistical list like stats.stackexchange.com  .

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 31, 2016 at 2:51 PM, Jose Marcos Ferraro
<jose.ferraro at logiteng.com> wrote:
> I'm trying to estimate a multinomial logit model  but in some choices only alternatives from a subset of all possible alternatives can be chosen.
> At the moment I get around it by creating "dummy" variables to mean the alternative is not available and let it estimate this coefficient as highly negative. Is there a better way to do it?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Apr  1 01:26:29 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 31 Mar 2016 16:26:29 -0700
Subject: [R] Ask if an object will respond to a function or method
In-Reply-To: <CAErODj-uQBo3MXOacFvfgd68QER2X0vgRUMDvR1JO6EsbxmwAg@mail.gmail.com>
References: <CAErODj-uQBo3MXOacFvfgd68QER2X0vgRUMDvR1JO6EsbxmwAg@mail.gmail.com>
Message-ID: <E4048460-2A2F-4BBB-8716-C1CBE5F8AECB@comcast.net>


> On Mar 31, 2016, at 1:00 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> 
> In the rockchalk package, I want to provide functions for regression
> objects that are "well behaved." If an object responds to the methods
> that lm or glm objects can handle, like coef(), nobs(), and summary(),
> I want to be able to handle the same thing.
> 
> It is more difficult than expected to ask a given fitted model object
> "do you respond to these functions: coef(), nobs(), summary()." How
> would you do it?
> 
> I tried this with the methods() function but learned that all methods
> that a class can perform are not listed.  I'll demonstrate with a
> regression "zz" that is created by the example in the plm package.
> The coef() function succeeds on the zz object, but coef is not listed
> in the list of methods that the function can carry out.
> 
>> library(plm)
>> example(plm)
> 
>> class(zz)
> [1] "plm"        "panelmodel"
>> methods(class = "plm")
> [1] ercomp          fixef           has.intercept   model.matrix
> [5] pFtest          plmtest         plot            pmodel.response
> [9] pooltest        predict         residuals       summary
> [13] vcovBK          vcovDC          vcovG           vcovHC
> [17] vcovNW          vcovSCC
> see '?methods' for accessing help and source code
>> methods(class = "panelmodel")
> [1] deviance      df.residual   fitted        has.intercept index
> [6] nobs          pbgtest       pbsytest      pcdtest       pdim
> [11] pdwtest       phtest        print         pwartest      pwfdtest
> [16] pwtest        residuals     terms         update        vcov
> see '?methods' for accessing help and source code
>> coef(zz)
>   log(pcap)      log(pc)     log(emp)        unemp
> -0.026149654  0.292006925  0.768159473 -0.005297741
> 
> I don't understand why coef(zz) succeeds but coef is not listed as a method.

There is a coef.default method. (Also an S$  coef,ANY-method )

> 
> Right now, I'm contemplating this:
> 
> zz1 < - try(coef(zz))
> if (inherits(zz1, "try-error")) stop("Your model has no coef method")
> 
> This seems like a bad workaround because I have to actually run the
> function in order to find out if the function exists. That might be
> time consuming for some summary() methods.
> 
> pj
> 
> -- 
> Paul E. Johnson
> Professor, Political Science        Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org              http://crmda.ku.edu
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marine.regis at hotmail.fr  Fri Apr  1 02:11:38 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Fri, 1 Apr 2016 00:11:38 +0000
Subject: [R] Compute the Gini coefficient
In-Reply-To: <alpine.DEB.2.20.1603301203320.6554@paninaro>
References: <AMSPR07MB470B0BB75B152E879FD30C5E2980@AMSPR07MB470.eurprd07.prod.outlook.com>
	<04863639-C891-49C8-B210-ADD5BBCE518F@univie.ac.at>,
	<alpine.DEB.2.20.1603301203320.6554@paninaro>
Message-ID: <AMSPR07MB470DF18CE58731BA7275FD6E2990@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,

Thank you very much for your help. 

How can I draw a Lorenz curve with several replications ?

Here is an example with 4 replications:

hosts=c(23,31,19,10,7,7,3,
        39,40,8,3,6,2,2,
        47,17,8,10,6,11,1,
        30,30,10,0,15,15,0)
parasites=rep(seq(from=0,to=6,by=1),4)
replications=c(rep(1,7),rep(2,7),rep(3,7),rep(4,7))
test <- cbind(parasites,hosts,replications)

Should I calculate the average frequency of hosts (replication mean values) and next calculate the cumulative percentage of hosts from the average frequency ? 

Thank you very much for your time.
Have a nice day.
Marine 
________________________________________
De : Achim Zeileis <Achim.Zeileis at uibk.ac.at>
Envoy? : mercredi 30 mars 2016 12:05
? : Erich Neuwirth
Cc : Marine Regis; r-help at r-project.org
Objet : Re: [R] Compute the Gini coefficient

On Wed, 30 Mar 2016, Erich Neuwirth wrote:

>
>> On 30 Mar 2016, at 02:53, Marine Regis <marine.regis at hotmail.fr> wrote:
>>
>> Hello,
>>
>> I would like to build a Lorenz curve and calculate a Gini coefficient in order to find how much parasites does the top 20% most infected hosts support.
>>
>> Here is my data set:
>>
>> Number of parasites per host:
>> parasites = c(0,1,2,3,4,5,6,7,8,9,10)
>>
>> Number of hosts associated with each number of parasites given above:
>> hosts = c(18,20,28,19,16,10,3,1,0,0,0)
>>
>> To represent the Lorenz curve:
>> I manually calculated the cumulative percentage of parasites and hosts:
>>
>> cumul_parasites <- cumsum(parasites)/max(cumsum(parasites))
>> cumul_hosts <- cumsum(hosts)/max(cumsum(hosts))
>> plot(cumul_hosts, cumul_parasites, type= "l?)
>
>
> Your values in hosts are frequencies. So you need to calculate
>
> cumul_hosts = cumsum(hosts)/sum(hosts)
> cumul_parasites = cumsum(hosts*parasites)/sum(parasites)

That's what I thought as well but Marine explicitly said that the 'host'
are _not_ weights. Hence I was confused what this would actually mean.

Using the "ineq" package you can also do
plot(Lc(parasites, hosts))

> The Lorenz curves starts at (0,0), so to draw it, you need to extend these vectors
>
> cumul_hosts = c(0,cumul_hosts)
> cumul_parasites = c(0,cumul_parasites)
>
> plot(cumul_hosts,cum9l_parasites,type=?l?)
>
>
> The Gini coefficient can be calculated as
> library(reldist)
> gini(parasites,hosts)
>
>
> If you want to check, you can ?recreate? the original data (number of parasited for each host) with
>
> num_parasites = rep(parasites,hosts)
>
> and
> gini(num_parasites)
>
> will also give you the Gini coefficient you want.
>
>
>
>>
>
>>> From this Lorenz curve, how can I calculate the Gini coefficient with the function "gini" in R (package reldist) given that the vector "hosts" is not a vector of weights ?
>>
>> Thank you very much for your help.
>> Have a nice day
>> Marine
>>
>>
>>      [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From farnoosh_81 at yahoo.com  Fri Apr  1 00:37:58 2016
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Thu, 31 Mar 2016 22:37:58 +0000 (UTC)
Subject: [R] Filtering based on the occurrence
In-Reply-To: <CA+8X3fWcO0OL1EHgtEDEKa8Mfd851EUk=efttgkFBKwmVy4+og@mail.gmail.com>
References: <CA+8X3fWcO0OL1EHgtEDEKa8Mfd851EUk=efttgkFBKwmVy4+og@mail.gmail.com>
Message-ID: <1988600464.693834.1459463878999.JavaMail.yahoo@mail.yahoo.com>

Hi Jim,?
Thank you tons for your help. The code worked perfectly :)?Best,Farnoosh

 

    On Wednesday, March 30, 2016 1:13 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Farnoosh,
Despite my deep suspicion that this answer will solve a useless
problem, try this:

last_subject<-0
keep_deps<-c("B","D","F")
keep_rows<-NULL
for(rowindex in 1:dim(df)[1]) {
 if(df[rowindex,"Subject"] != last_subject) {
? last_subject<-df[rowindex,"Subject"]
? start_keeping<-0
 }
 if(df[rowindex,"deps"] %in% keep_deps) start_keeping<-1
 if(start_keeping) keep_rows<-c(keep_rows,rowindex)
}
final<-matrix(unlist(lapply(df[keep_rows,],as.character)),ncol=3)

I find it terribly hard to ignore puzzles.

Jim


On Wed, Mar 30, 2016 at 10:52 AM, Farnoosh Sheikhi via R-help
<r-help at r-project.org> wrote:
> Hello,
> I have a data set similar to below and I wanted to keep the observations after the first occurrence of these department: "B", "D", "F".For example for ID=2, the observation with deps=B and anything after will be kept in the data. For ID=3, observations with deps=D and anything after will be included.
> Subject<- c("2", "2", "2", "3", "3", "3", "4", "4", "5", "5", "5", "5")dates<-seq(as.Date('2011-01-01'),as.Date('2011-01-12'),by = 1) deps<-c("A", "B", "C", "C", "D", "A", "F", "G", "A", "F", "A", "D")df <- data.frame(Subject, dates, deps)df
> The final data should look like this:final<-c("2 2011-01-02? ? B","2 2011-01-03? ? C","3 2011-01-05? ? D","3 2011-01-06? ? A","4 2011-01-07? ? F","4 2011-01-08? ? G","5 2011-01-10? ? F","5 2011-01-11? ? A","5 2011-01-12? ? D") Thank you tons for your help.
> Farnoosh
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From Jin.Li at ga.gov.au  Fri Apr  1 05:43:29 2016
From: Jin.Li at ga.gov.au (Li Jin)
Date: Fri, 1 Apr 2016 03:43:29 +0000
Subject: [R] [DKIM]  Batch Installer for R [SEC=UNCLASSIFIED]
Message-ID: <550245579fa6453fb50d8ec96bf9ef43@win-exch-prod01.prod.lan>

Hi Tobias,
Here is something I acquired from this mailing list some years ago. It works well for me:

#---run in previous version (e.g. R 3.1.0)
packages <- installed.packages()[,"Package"]
save(packages, file="Rpackages_R3.1.0")

#---run in new version
load("Rpackages_R3.1.0")

for (p in setdiff(packages, installed.packages()[,"Package"]))
install.packages(p)

Hope this helps.

Jin

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tobias Knuth
Sent: Friday, 1 April 2016 12:05 AM
To: r-help at r-project.org
Subject: [DKIM] [R] Batch Installer for R

Hi everyone,

in Python, you can run pip install -r filename to install all packages listed in the file. Is there something similar to R? If not, isn't it quite easy to write?

For me, it would be much easier to work on projects with other people if I could just install all dependencies with one line in a generalised manner.

Did anybody try something like that before me?

Best,
Tobias

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Geoscience Australia Disclaimer: This e-mail (and files transmitted with it) is intended only for the person or entity to which it is addressed. If you are not the intended recipient, then you have received this e-mail by mistake and any use, dissemination, forwarding, printing or copying of this e-mail and its file attachments is prohibited. The security of emails transmitted cannot be guaranteed; by forwarding or replying to this email, you acknowledge and accept these risks.


From ragia11 at hotmail.com  Fri Apr  1 10:01:45 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Fri, 1 Apr 2016 10:01:45 +0200
Subject: [R] How to speed up my program
Message-ID: <DUB125-W1520480E7951984E5BB1C5B39A0@phx.gbl>



Dear group
I had a R ? program that was to slow, I mad it multi core prog..to speed up, its a simulation when the runs are 100 its very fast..raising the runs to 10k mad it in the first fast then it slow down
I checked the HW usafe and here is the top command results


%Cpu0 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
%Cpu1 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
%Cpu2 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
%Cpu3 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
%Cpu4 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
%Cpu5 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
%Cpu6 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
%Cpu7 ?:100.0 us, ?0.0 sy, ?0.0 ni, ?0.0 id, ?0.0 wa, ?0.0 hi, ?0.0 si, ?0.0 st
KiB Mem: ?65863948 total, 13940104 used, 51923844 free, ? 231084 buffers
KiB Swap: ?1046520 total, ? ? ? ?0 used, ?1046520 free. ?4418180 cached Mem

what should I do to speed it up?
thanks in advance 		 	   		  

From mail at tobiasknuth.de  Fri Apr  1 12:24:55 2016
From: mail at tobiasknuth.de (Tobias Knuth)
Date: Fri, 1 Apr 2016 12:24:55 +0200
Subject: [R] [DKIM]  Batch Installer for R [SEC=UNCLASSIFIED]
In-Reply-To: <550245579fa6453fb50d8ec96bf9ef43@win-exch-prod01.prod.lan>
References: <550245579fa6453fb50d8ec96bf9ef43@win-exch-prod01.prod.lan>
Message-ID: <CAOLnNg7AEs9BmXYxkh3BxB9UEMRX0mz940Ux59C+VNdLEqN50A@mail.gmail.com>

Hi Douglas,

That is exactly what I was looking for. Thank you very much!

Hi Jin,

Thank you for your solution. It worked for me, but packrat (see below)
seems like a more refined approach. You might want to look at it ...

Best,
Tobias

On 1 April 2016 at 05:43, Li Jin <Jin.Li at ga.gov.au> wrote:

> Hi Tobias,
> Here is something I acquired from this mailing list some years ago. It
> works well for me:
>
> #---run in previous version (e.g. R 3.1.0)
> packages <- installed.packages()[,"Package"]
> save(packages, file="Rpackages_R3.1.0")
>
> #---run in new version
> load("Rpackages_R3.1.0")
>
> for (p in setdiff(packages, installed.packages()[,"Package"]))
> install.packages(p)
>
> Hope this helps.
>
> Jin
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tobias
> Knuth
> Sent: Friday, 1 April 2016 12:05 AM
> To: r-help at r-project.org
> Subject: [DKIM] [R] Batch Installer for R
>
> Hi everyone,
>
> in Python, you can run pip install -r filename to install all packages
> listed in the file. Is there something similar to R? If not, isn't it quite
> easy to write?
>
> For me, it would be much easier to work on projects with other people if I
> could just install all dependencies with one line in a generalised manner.
>
> Did anybody try something like that before me?
>
> Best,
> Tobias
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> Geoscience Australia Disclaimer: This e-mail (and files transmitted with
> it) is intended only for the person or entity to which it is addressed. If
> you are not the intended recipient, then you have received this e-mail by
> mistake and any use, dissemination, forwarding, printing or copying of this
> e-mail and its file attachments is prohibited. The security of emails
> transmitted cannot be guaranteed; by forwarding or replying to this email,
> you acknowledge and accept these risks.
>
> -------------------------------------------------------------------------------------------------------------------------
>
>

	[[alternative HTML version deleted]]


From rsherry8 at comcast.net  Fri Apr  1 14:19:39 2016
From: rsherry8 at comcast.net (Robert Sherry)
Date: Fri, 1 Apr 2016 08:19:39 -0400
Subject: [R] How to speed up my program
In-Reply-To: <DUB125-W1520480E7951984E5BB1C5B39A0@phx.gbl>
References: <DUB125-W1520480E7951984E5BB1C5B39A0@phx.gbl>
Message-ID: <56FE675B.5080400@comcast.net>

Hi Ragia,

First, when you wrote mad, I assume you mean made.  Also, when you say 
it is a multi core prog, does that mean it is using threads? running two 
or more items in parallel? By any chance are you using this package?
https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf
If not, maybe you should. There is also a new version of R called pqR. 
It is multi thread and that maybe exactly what you need.

Also R is interpreted not compiled. Therefore if speed is important 
rewriting it in a compiled language like C or C++ could be a whole lot 
faster. I suspect that this would also be a lot of work and probably not 
worth it.

Bob

On 4/1/2016 4:01 AM, Ragia . wrote:
>
> Dear group
> I had a R   program that was to slow, I mad it multi core prog..to speed up, its a simulation when the runs are 100 its very fast..raising the runs to 10k mad it in the first fast then it slow down
> I checked the HW usafe and here is the top command results
>
>
> %Cpu0  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> %Cpu1  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> %Cpu2  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> %Cpu3  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> %Cpu4  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> %Cpu5  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> %Cpu6  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> %Cpu7  :100.0 us,  0.0 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
> KiB Mem:  65863948 total, 13940104 used, 51923844 free,   231084 buffers
> KiB Swap:  1046520 total,        0 used,  1046520 free.  4418180 cached Mem
>
> what should I do to speed it up?
> thanks in advance 		 	   		
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jose.ferraro at LOGITeng.com  Fri Apr  1 15:40:57 2016
From: jose.ferraro at LOGITeng.com (Jose Marcos Ferraro)
Date: Fri, 1 Apr 2016 13:40:57 +0000
Subject: [R] reduced set of alternatives in package mlogit
In-Reply-To: <CAGxFJbRGPWZv3hhDiUV4cuzg5xHoihfb+FjaZ0cJCeMVx33ATw@mail.gmail.com>
References: <GRUPR80MB04443F1875EAF793C2385609E2990@GRUPR80MB0444.lamprd80.prod.outlook.com>
	<CAGxFJbRGPWZv3hhDiUV4cuzg5xHoihfb+FjaZ0cJCeMVx33ATw@mail.gmail.com>
Message-ID: <GRUPR80MB0444F78421CA9EC09BA00859E29A0@GRUPR80MB0444.lamprd80.prod.outlook.com>

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: quinta-feira, 31 de mar?o de 2016 20:22
To: Jose Marcos Ferraro <jose.ferraro at LOGITeng.com>
Cc: r-help at r-project.org
Subject: Re: [R] reduced set of alternatives in package mlogit

code? example data?  We can only guess based on your vague post.

"PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code."

Moreover, this sounds like a statistical question, not a question about R programming, and so might be more appropriate for a statistical list like stats.stackexchange.com  .

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 31, 2016 at 2:51 PM, Jose Marcos Ferraro <jose.ferraro at logiteng.com> wrote:
> I'm trying to estimate a multinomial logit model  but in some choices only alternatives from a subset of all possible alternatives can be chosen.
> At the moment I get around it by creating "dummy" variables to mean the alternative is not available and let it estimate this coefficient as highly negative. Is there a better way to do it?
>

Sorry if I was not clear enough, but  there is hardly any code to show. 
The problem is that a parameter or function is lacking (or , mostly likely, I can't find it), so in some sense the problem itself is that  there is no code to show.

In what follows choice situations , alternatives, wide, and variables have the same meaning that they have on the mlogit documentation. All variables are alternative specific.

1)I want to estimate a multinomial Logit  using the mlogit package

2)I have a dataset, made of choice situations

3)There is a set of alternatives

4)in some choice situations, not all alternatives were available, but only a subset of them. So there are no variables for the unavailable alternatives and the chosen alternative evidently  belongs to the set of available ones.

5)I use mlogit.data to prepare the dataset from a "wide" dataframe . There is no option to have only a subset of alternatives and the resulting object will have them all , that is, there will be a line for every alternative and every choice situation, even if in reality some of them were not available. The variables of these alternatives did not exist, so must be filled with 0s or any other made up value

6) If ones estimate a model from this data it will be wrong

7) It is possible to get an "almost right" model by using a dummy variable marking which alternatives are unavailable, for as it is only used in alternatives that are never chosen, its coefficient will get negative with big absolute value, in practice giving almost 0% probability for them

8)this is a workaround because it obligates the model to estimate a number that should be -infinity and this is known in advance, so it's ugly and difficult to know what the numeric consequences are as the coefficient can never converge. In fact, I don't use it the way I described for these reasons, preferring a more complex but almost equivalent formulation. The important point is that I want a clean solution, not a workaround

9)I demand simply if mlogit package has such functionality



From MBroeks at kza.nl  Fri Apr  1 16:05:58 2016
From: MBroeks at kza.nl (Martijn Broeks)
Date: Fri, 1 Apr 2016 14:05:58 +0000
Subject: [R] Using R for cURL commands
Message-ID: <VI1PR07MB16162AF1124668329419FE70C99A0@VI1PR07MB1616.eurprd07.prod.outlook.com>

Hello,


I'm looking for a way in which R can make my live easier.

Currently i'm using R convert data from a dataframe to json's and then sending these json's to a rest api using a curl command in the terminal (i'm on a mac).


I've been looking for a way to use R for sending data from R to the rest api. My primairy focus was on using R for executing the curl command, however, I'm open to other approaches. The method I've been using so far:



I found some information online suggesting i'd use this code:

*js is a json from my R environment


Library(RCurl)

postForm("https://MYWEBSITE.eu/api/v2/organisations/abc/projects/cosson/datasets/DATABASE",

.opts = list(postfields = js,

httpheader = c('Content-Type' = 'application/json', Accept = 'application/json'),

userpwd = "name:pwd",

ssl.verifypeer = FALSE))

(userpwd and url have been changed to hide sensitive information)


This leads to the following error: "Error: Unauthorized". I've filled out the correct username and password, but I can't figure out why I'm getting this error. This is the curl command I'm using:


curl -X POST -s --user "USERNAME:PASSWORD" -H "Content-type: application/xml" -d at test.json "https://MYWEBSITE.eu/api/v2/organisations/abc/projects/cosson/datasets/DATABASE"

(userpwd and url have been changed to hide sensitive information)


The json file is build up like this:

{\n    \"ID\": 601,\n    \"100-100\": 0 }

But this is a small part, the actual json contains 555 variables


Thanks in advance for the help and let me know if something is unclear.



Disclaimer | The information transmitted is intended only for use by the addressee and may contain confidential and/or privileged material. Any review, retransmission, dissemination or other use of it, or the taking of any action in reliance upon this information by persons and/or entities other than the intended recipient is prohibited. If you received this in error, please inform the sender and/or addressee immediately and delete the material. Thank you.

	[[alternative HTML version deleted]]


From cdesjard at umn.edu  Fri Apr  1 16:54:47 2016
From: cdesjard at umn.edu (Christopher Desjardins)
Date: Fri, 1 Apr 2016 09:54:47 -0500
Subject: [R] reduced set of alternatives in package mlogit
In-Reply-To: <GRUPR80MB0444F78421CA9EC09BA00859E29A0@GRUPR80MB0444.lamprd80.prod.outlook.com>
References: <GRUPR80MB04443F1875EAF793C2385609E2990@GRUPR80MB0444.lamprd80.prod.outlook.com>
	<CAGxFJbRGPWZv3hhDiUV4cuzg5xHoihfb+FjaZ0cJCeMVx33ATw@mail.gmail.com>
	<GRUPR80MB0444F78421CA9EC09BA00859E29A0@GRUPR80MB0444.lamprd80.prod.outlook.com>
Message-ID: <CAOGrcjqjAXXwUK_jNp1Qv4oxSJr5PTVgRaUUsgatrukAcQk0RQ@mail.gmail.com>

Hi Jose,

You're referring to your response variable when you're saying it's missing
some of the choices, right? Are your response choices ever known or do they
just occur with extremely low frequency? Either way, I think the mlogit
package would be inappropriate for you. I imagine you would have much
better luck using MCMCpack or writing a model with rstan or something
Bayesian. Unless I'm missing something.

Chris



On Fri, Apr 1, 2016 at 8:40 AM, Jose Marcos Ferraro <
jose.ferraro at logiteng.com> wrote:

> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: quinta-feira, 31 de mar?o de 2016 20:22
> To: Jose Marcos Ferraro <jose.ferraro at LOGITeng.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] reduced set of alternatives in package mlogit
>
> code? example data?  We can only guess based on your vague post.
>
> "PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code."
>
> Moreover, this sounds like a statistical question, not a question about R
> programming, and so might be more appropriate for a statistical list like
> stats.stackexchange.com  .
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Mar 31, 2016 at 2:51 PM, Jose Marcos Ferraro <
> jose.ferraro at logiteng.com> wrote:
> > I'm trying to estimate a multinomial logit model  but in some choices
> only alternatives from a subset of all possible alternatives can be chosen.
> > At the moment I get around it by creating "dummy" variables to mean the
> alternative is not available and let it estimate this coefficient as highly
> negative. Is there a better way to do it?
> >
>
> Sorry if I was not clear enough, but  there is hardly any code to show.
> The problem is that a parameter or function is lacking (or , mostly
> likely, I can't find it), so in some sense the problem itself is that
> there is no code to show.
>
> In what follows choice situations , alternatives, wide, and variables have
> the same meaning that they have on the mlogit documentation. All variables
> are alternative specific.
>
> 1)I want to estimate a multinomial Logit  using the mlogit package
>
> 2)I have a dataset, made of choice situations
>
> 3)There is a set of alternatives
>
> 4)in some choice situations, not all alternatives were available, but only
> a subset of them. So there are no variables for the unavailable
> alternatives and the chosen alternative evidently  belongs to the set of
> available ones.
>
> 5)I use mlogit.data to prepare the dataset from a "wide" dataframe . There
> is no option to have only a subset of alternatives and the resulting object
> will have them all , that is, there will be a line for every alternative
> and every choice situation, even if in reality some of them were not
> available. The variables of these alternatives did not exist, so must be
> filled with 0s or any other made up value
>
> 6) If ones estimate a model from this data it will be wrong
>
> 7) It is possible to get an "almost right" model by using a dummy variable
> marking which alternatives are unavailable, for as it is only used in
> alternatives that are never chosen, its coefficient will get negative with
> big absolute value, in practice giving almost 0% probability for them
>
> 8)this is a workaround because it obligates the model to estimate a number
> that should be -infinity and this is known in advance, so it's ugly and
> difficult to know what the numeric consequences are as the coefficient can
> never converge. In fact, I don't use it the way I described for these
> reasons, preferring a more complex but almost equivalent formulation. The
> important point is that I want a clean solution, not a workaround
>
> 9)I demand simply if mlogit package has such functionality
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Fri Apr  1 17:28:12 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 1 Apr 2016 11:28:12 -0400
Subject: [R] Using R for cURL commands
In-Reply-To: <VI1PR07MB16162AF1124668329419FE70C99A0@VI1PR07MB1616.eurprd07.prod.outlook.com>
References: <VI1PR07MB16162AF1124668329419FE70C99A0@VI1PR07MB1616.eurprd07.prod.outlook.com>
Message-ID: <0CD06215-0F99-4411-8C0A-EBCAD18E475E@bigelow.org>

Hi,

Have you looked at httr?  I have been very happy using it with RESTful systems.

https://cran.r-project.org/web/packages/httr/index.html


Cheers,
Ben

> On Apr 1, 2016, at 10:05 AM, Martijn Broeks <MBroeks at kza.nl> wrote:
> 
> Hello,
> 
> 
> I'm looking for a way in which R can make my live easier.
> 
> Currently i'm using R convert data from a dataframe to json's and then sending these json's to a rest api using a curl command in the terminal (i'm on a mac).
> 
> 
> I've been looking for a way to use R for sending data from R to the rest api. My primairy focus was on using R for executing the curl command, however, I'm open to other approaches. The method I've been using so far:
> 
> 
> 
> I found some information online suggesting i'd use this code:
> 
> *js is a json from my R environment
> 
> 
> Library(RCurl)
> 
> postForm("https://MYWEBSITE.eu/api/v2/organisations/abc/projects/cosson/datasets/DATABASE",
> 
> .opts = list(postfields = js,
> 
> httpheader = c('Content-Type' = 'application/json', Accept = 'application/json'),
> 
> userpwd = "name:pwd",
> 
> ssl.verifypeer = FALSE))
> 
> (userpwd and url have been changed to hide sensitive information)
> 
> 
> This leads to the following error: "Error: Unauthorized". I've filled out the correct username and password, but I can't figure out why I'm getting this error. This is the curl command I'm using:
> 
> 
> curl -X POST -s --user "USERNAME:PASSWORD" -H "Content-type: application/xml" -d at test.json "https://MYWEBSITE.eu/api/v2/organisations/abc/projects/cosson/datasets/DATABASE"
> 
> (userpwd and url have been changed to hide sensitive information)
> 
> 
> The json file is build up like this:
> 
> {\n    \"ID\": 601,\n    \"100-100\": 0 }
> 
> But this is a small part, the actual json contains 555 variables
> 
> 
> Thanks in advance for the help and let me know if something is unclear.
> 
> 
> 
> Disclaimer | The information transmitted is intended only for use by the addressee and may contain confidential and/or privileged material. Any review, retransmission, dissemination or other use of it, or the taking of any action in reliance upon this information by persons and/or entities other than the intended recipient is prohibited. If you received this in error, please inform the sender and/or addressee immediately and delete the material. Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From axel.urbiz at gmail.com  Fri Apr  1 18:32:16 2016
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Fri, 1 Apr 2016 10:32:16 -0600
Subject: [R] TensorFlow in R
Message-ID: <CAAyVsXJdHHLABAm_T++6c3h7z=Y4n3WOWqX=NM_LuaDPP70C6A@mail.gmail.com>

Hi All,

I didn't have much success through my Google search in finding any active
R-related projects to create a wrapper around TensorFlow in R. Anyone know
if this is on the go?

Thanks,
Axel.

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Fri Apr  1 18:40:43 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Fri, 1 Apr 2016 11:40:43 -0500
Subject: [R] TensorFlow in R
In-Reply-To: <CAAyVsXJdHHLABAm_T++6c3h7z=Y4n3WOWqX=NM_LuaDPP70C6A@mail.gmail.com>
References: <CAAyVsXJdHHLABAm_T++6c3h7z=Y4n3WOWqX=NM_LuaDPP70C6A@mail.gmail.com>
Message-ID: <CAKxd1KPw6x5GFyB9Dc3m6SGgRqzq=94SMmqoTxzd96F_GZQ4QQ@mail.gmail.com>

Hi Axel,

Looks like the only thing right now is rflow (
https://github.com/terrytangyuan/rflow).  It appears to simply wrap around
the python bindings.  I am not aware of any others.  Be interesting to keep
an eye on.

Regards,
Charles


On Fri, Apr 1, 2016 at 11:32 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Hi All,
>
> I didn't have much success through my Google search in finding any active
> R-related projects to create a wrapper around TensorFlow in R. Anyone know
> if this is on the go?
>
> Thanks,
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From JSorkin at grecc.umaryland.edu  Sat Apr  2 00:14:34 2016
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 01 Apr 2016 18:14:34 -0400
Subject: [R] p values from GLM
Message-ID: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>

How can I get the p values from a glm ? I want to get the p values so I can add them to a custom report
 
 
 fitwean<- glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
 summary(fitwean)             # This lists the coefficeints, SEs, z and p values, but I can't isolate the pvalues.
 names(summary(fitwean))  # I see the coefficients, but not the p values
 names(fitmens)                  # p values are not found here.
 
Thank you!
John
 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From murdoch.duncan at gmail.com  Sat Apr  2 00:26:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 1 Apr 2016 18:26:06 -0400
Subject: [R] p values from GLM
In-Reply-To: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
Message-ID: <56FEF57E.8090401@gmail.com>

On 01/04/2016 6:14 PM, John Sorkin wrote:
 > How can I get the p values from a glm ? I want to get the p values so 
I can add them to a custom report
 >
 >
 >   fitwean<- 
glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
 >   summary(fitwean)             # This lists the coefficeints, SEs, z 
and p values, but I can't isolate the pvalues.
 >   names(summary(fitwean))  # I see the coefficients, but not the p values
 >   names(fitmens)                  # p values are not found here.

Doesn't summary(fitwean) give a matrix? Then it's 
colnames(summary(fitwean)$coefficients) you want, not names(fitwean).

Duncan Murdoch

P.S. If you had given a reproducible example, I'd try it myself.


 >
 > Thank you!
 > John
 >
 > John David Sorkin M.D., Ph.D.
 > Professor of Medicine
 > Chief, Biostatistics and Informatics
 > University of Maryland School of Medicine Division of Gerontology and 
Geriatric Medicine
 > Baltimore VA Medical Center
 > 10 North Greene Street
 > GRECC (BT/18/GR)
 > Baltimore, MD 21201-1524
 > (Phone) 410-605-7119
 > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
 >
 > Confidentiality Statement:
 > This email message, including any attachments, is for the sole use of 
the intended recipient(s) and may contain confidential and privileged 
information. Any unauthorized use, disclosure or distribution is 
prohibited. If you are not the intended recipient, please contact the 
sender by reply email and destroy all copies of the original message.
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.
 >


From bgunter.4567 at gmail.com  Sat Apr  2 00:46:01 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 1 Apr 2016 15:46:01 -0700
Subject: [R] p values from GLM
In-Reply-To: <56FEF57E.8090401@gmail.com>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
Message-ID: <CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>

... of course, whether one **should** get them is questionable...

http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503#/ref-link-1


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 1, 2016 at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 01/04/2016 6:14 PM, John Sorkin wrote:
>> How can I get the p values from a glm ? I want to get the p values so I
>> can add them to a custom report
>>
>>
>>   fitwean<-
>> glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
>>   summary(fitwean)             # This lists the coefficeints, SEs, z and p
>> values, but I can't isolate the pvalues.
>>   names(summary(fitwean))  # I see the coefficients, but not the p values
>>   names(fitmens)                  # p values are not found here.
>
> Doesn't summary(fitwean) give a matrix? Then it's
> colnames(summary(fitwean)$coefficients) you want, not names(fitwean).
>
> Duncan Murdoch
>
> P.S. If you had given a reproducible example, I'd try it myself.
>
>
>
>>
>> Thank you!
>> John
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the
>> intended recipient(s) and may contain confidential and privileged
>> information. Any unauthorized use, disclosure or distribution is prohibited.
>> If you are not the intended recipient, please contact the sender by reply
>> email and destroy all copies of the original message.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Apr  2 02:01:12 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 1 Apr 2016 20:01:12 -0400
Subject: [R] p values from GLM
In-Reply-To: <CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
Message-ID: <56FF0BC8.30501@gmail.com>

On 01/04/2016 6:46 PM, Bert Gunter wrote:
> ... of course, whether one **should** get them is questionable...

They're just statistics.  How could it hurt to look at them?

Duncan Murdoch

>
> http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503#/ref-link-1
>
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Apr 1, 2016 at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 01/04/2016 6:14 PM, John Sorkin wrote:
>>> How can I get the p values from a glm ? I want to get the p values so I
>>> can add them to a custom report
>>>
>>>
>>>    fitwean<-
>>> glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
>>>    summary(fitwean)             # This lists the coefficeints, SEs, z and p
>>> values, but I can't isolate the pvalues.
>>>    names(summary(fitwean))  # I see the coefficients, but not the p values
>>>    names(fitmens)                  # p values are not found here.
>>
>> Doesn't summary(fitwean) give a matrix? Then it's
>> colnames(summary(fitwean)$coefficients) you want, not names(fitwean).
>>
>> Duncan Murdoch
>>
>> P.S. If you had given a reproducible example, I'd try it myself.
>>
>>
>>
>>>
>>> Thank you!
>>> John
>>>
>>> John David Sorkin M.D., Ph.D.
>>> Professor of Medicine
>>> Chief, Biostatistics and Informatics
>>> University of Maryland School of Medicine Division of Gerontology and
>>> Geriatric Medicine
>>> Baltimore VA Medical Center
>>> 10 North Greene Street
>>> GRECC (BT/18/GR)
>>> Baltimore, MD 21201-1524
>>> (Phone) 410-605-7119
>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>
>>> Confidentiality Statement:
>>> This email message, including any attachments, is for the sole use of the
>>> intended recipient(s) and may contain confidential and privileged
>>> information. Any unauthorized use, disclosure or distribution is prohibited.
>>> If you are not the intended recipient, please contact the sender by reply
>>> email and destroy all copies of the original message.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sat Apr  2 02:21:14 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 2 Apr 2016 13:21:14 +1300
Subject: [R] [FORGED] Re:  p values from GLM
In-Reply-To: <56FF0BC8.30501@gmail.com>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
	<56FF0BC8.30501@gmail.com>
Message-ID: <56FF107A.8030808@auckland.ac.nz>

On 02/04/16 13:01, Duncan Murdoch wrote:
> On 01/04/2016 6:46 PM, Bert Gunter wrote:
>> ... of course, whether one **should** get them is questionable...
>
> They're just statistics.  How could it hurt to look at them?

Fortune nomination.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewmil at dcn.davis.ca.us  Sat Apr  2 02:30:47 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 01 Apr 2016 17:30:47 -0700
Subject: [R] p values from GLM
In-Reply-To: <56FF0BC8.30501@gmail.com>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
	<56FF0BC8.30501@gmail.com>
Message-ID: <6078D009-F2C8-4A73-A8A0-CFFBE921FA99@dcn.davis.ca.us>

Because they are Medusa statistics? 
-- 
Sent from my phone. Please excuse my brevity.

On April 1, 2016 5:01:12 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 01/04/2016 6:46 PM, Bert Gunter wrote:
>> ... of course, whether one **should** get them is questionable...
>
>They're just statistics.  How could it hurt to look at them?
>
>Duncan Murdoch
>
>>
>>
>http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503#/ref-link-1
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Apr 1, 2016 at 3:26 PM, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
>>> On 01/04/2016 6:14 PM, John Sorkin wrote:
>>>> How can I get the p values from a glm ? I want to get the p values
>so I
>>>> can add them to a custom report
>>>>
>>>>
>>>>    fitwean<-
>>>> glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link
>="logit"))
>>>>    summary(fitwean)             # This lists the coefficeints, SEs,
>z and p
>>>> values, but I can't isolate the pvalues.
>>>>    names(summary(fitwean))  # I see the coefficients, but not the p
>values
>>>>    names(fitmens)                  # p values are not found here.
>>>
>>> Doesn't summary(fitwean) give a matrix? Then it's
>>> colnames(summary(fitwean)$coefficients) you want, not
>names(fitwean).
>>>
>>> Duncan Murdoch
>>>
>>> P.S. If you had given a reproducible example, I'd try it myself.
>>>
>>>
>>>
>>>>
>>>> Thank you!
>>>> John
>>>>
>>>> John David Sorkin M.D., Ph.D.
>>>> Professor of Medicine
>>>> Chief, Biostatistics and Informatics
>>>> University of Maryland School of Medicine Division of Gerontology
>and
>>>> Geriatric Medicine
>>>> Baltimore VA Medical Center
>>>> 10 North Greene Street
>>>> GRECC (BT/18/GR)
>>>> Baltimore, MD 21201-1524
>>>> (Phone) 410-605-7119
>>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>>
>>>> Confidentiality Statement:
>>>> This email message, including any attachments, is for the sole use
>of the
>>>> intended recipient(s) and may contain confidential and privileged
>>>> information. Any unauthorized use, disclosure or distribution is
>prohibited.
>>>> If you are not the intended recipient, please contact the sender by
>reply
>>>> email and destroy all copies of the original message.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bernd_bischl at gmx.net  Fri Apr  1 21:43:26 2016
From: bernd_bischl at gmx.net (Bernd Bischl)
Date: Fri, 1 Apr 2016 21:43:26 +0200
Subject: [R] [Rd] TensorFlow in R
In-Reply-To: <CAAyVsXJdHHLABAm_T++6c3h7z=Y4n3WOWqX=NM_LuaDPP70C6A@mail.gmail.com>
References: <CAAyVsXJdHHLABAm_T++6c3h7z=Y4n3WOWqX=NM_LuaDPP70C6A@mail.gmail.com>
Message-ID: <56FECF5E.7070208@gmx.net>

Hi,

from what I know there is a current GSOC 2016 project proposal.
(but not accepted yet)

https://github.com/rstats-gsoc/gsoc2016/wiki
https://github.com/rstats-gsoc/gsoc2016/wiki/DeepLearnR-tensorFlow-Object-system-for-R


Is that of interest?

Best,

Bernd


On 01.04.2016 18:32, Axel Urbiz wrote:
> Hi All,
>
> I didn't have much success through my Google search in finding any active
> R-related projects to create a wrapper around TensorFlow in R. Anyone know
> if this is on the go?
>
> Thanks,
> Axel.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From meherdivya4 at gmail.com  Fri Apr  1 17:44:24 2016
From: meherdivya4 at gmail.com (MEHER DIVYA BARATAM)
Date: Fri, 1 Apr 2016 21:14:24 +0530
Subject: [R] (no subject)
Message-ID: <CAOOMz7MT3QWVD8QxOGhZAose50Cn+wrCoVfi7kTr_y8QOkhzAA@mail.gmail.com>

dear sir/madam,


                    while i am trying to convert the data into timeseries
using xts command.i am getting this error. please help me to resolve this
issue

 xts(mydata$MCP, as.Date(rdate, format='%d-%m-%Y')
+ xts(mydata$MCP, as.Date(rdate, format='%d-%m-%Y')
Error: unexpected symbol in:
"xts(mydata$MCP, as.Date(rdate, format='%d-%m-%Y')
xts"


thanks and regards
divya

	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Fri Apr  1 18:08:03 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Fri, 1 Apr 2016 16:08:03 +0000
Subject: [R] How to convert XML file to R Data Frame?
Message-ID: <DB5PR07MB1109052DBC6D3B8EB6A5AB32DB9A0@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi All,


I'm new to R and wants to read XML file as R data frame. Is there any package that could be used for this purpose.


I will really appreciate your response.


Many Thanks and


Kind Regards

--
Muhammad Bilal
Research Assistant and PhD Student,
Bristol Enterprise, Research and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat Apr  2 12:45:30 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 2 Apr 2016 06:45:30 -0400
Subject: [R] (no subject)
In-Reply-To: <CAOOMz7MT3QWVD8QxOGhZAose50Cn+wrCoVfi7kTr_y8QOkhzAA@mail.gmail.com>
References: <CAOOMz7MT3QWVD8QxOGhZAose50Cn+wrCoVfi7kTr_y8QOkhzAA@mail.gmail.com>
Message-ID: <CAM_vju=jOu0-Aqpngbx2mJnRxOXV9WsxBFvAxrU86kzL-9XtEw@mail.gmail.com>

You don't have enough closing parentheses.

Using a text editor written for programmers helps a lot because it will
highlight that kind of error.

Sarah

On Friday, April 1, 2016, MEHER DIVYA BARATAM <meherdivya4 at gmail.com> wrote:

> dear sir/madam,
>
>
>                     while i am trying to convert the data into timeseries
> using xts command.i am getting this error. please help me to resolve this
> issue
>
>  xts(mydata$MCP, as.Date(rdate, format='%d-%m-%Y')
> + xts(mydata$MCP, as.Date(rdate, format='%d-%m-%Y')
> Error: unexpected symbol in:
> "xts(mydata$MCP, as.Date(rdate, format='%d-%m-%Y')
> xts"
>
>
> thanks and regards
> divya
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sat Apr  2 13:16:44 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 2 Apr 2016 07:16:44 -0400
Subject: [R] How to convert XML file to R Data Frame?
In-Reply-To: <DB5PR07MB1109052DBC6D3B8EB6A5AB32DB9A0@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109052DBC6D3B8EB6A5AB32DB9A0@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <CAAxdm-4EKbaeZ5kfp4wTVAKdYZNS7tXW6YicordMbnsdARFizw@mail.gmail.com>

Check out the XML package for complete information, and the xml2 package
for extracting data from XML.

I don't think you can directly read the XML into a dataframe because of the
hierarchical structure of the data.  There are functions to read an HTML
table into a dataframe.  I think you have to take a close look at your data
and determine what you want from it, then extract the data and put it into
the appropriate structure.  It would have been nice if you at least showed
a sample of the XML was and what you were expecting to get from it.

I have used both of the packages to extract data from moderate files
(~16,000 lines in length).


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Apr 1, 2016 at 12:08 PM, Muhammad Bilal <
Muhammad2.Bilal at live.uwe.ac.uk> wrote:

> Hi All,
>
>
> I'm new to R and wants to read XML file as R data frame. Is there any
> package that could be used for this purpose.
>
>
> I will really appreciate your response.
>
>
> Many Thanks and
>
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Assistant and PhD Student,
> Bristol Enterprise, Research and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Apr  2 18:07:05 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 2 Apr 2016 09:07:05 -0700
Subject: [R] p values from GLM
In-Reply-To: <56FF0BC8.30501@gmail.com>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
	<56FF0BC8.30501@gmail.com>
Message-ID: <CCD9F93D-7ADA-4569-B939-FA3D4042D800@comcast.net>


> On Apr 1, 2016, at 5:01 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 01/04/2016 6:46 PM, Bert Gunter wrote:
>> ... of course, whether one **should** get them is questionable...
> 
> They're just statistics.  How could it hurt to look at them?

Like Rolf, I thought that this utterance on April 1 deserved fortune enshrinement. It reminded me of one of my favorite articles: "P-Values are Random Variables". 

Unfortunately a legal copy of that paper is still behind a corporate firewall for which you would need to fork over USD 50.00, but a google search for "P-Values are Random Variables The American Statistician" should yield options for the less squeamish. (My copy was obtained when I did have legal access.)

-- 
David.
> 
> Duncan Murdoch
> 
>> 
>> http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503#/ref-link-1
>> 
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Fri, Apr 1, 2016 at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> On 01/04/2016 6:14 PM, John Sorkin wrote:
>>>> How can I get the p values from a glm ? I want to get the p values so I
>>>> can add them to a custom report
>>>> 
>>>> 
>>>>   fitwean<-
>>>> glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
>>>>   summary(fitwean)             # This lists the coefficeints, SEs, z and p
>>>> values, but I can't isolate the pvalues.
>>>>   names(summary(fitwean))  # I see the coefficients, but not the p values
>>>>   names(fitmens)                  # p values are not found here.
>>> 
>>> Doesn't summary(fitwean) give a matrix? Then it's
>>> colnames(summary(fitwean)$coefficients) you want, not names(fitwean).
>>> 
>>> Duncan Murdoch
>>> 
>>> P.S. If you had given a reproducible example, I'd try it myself.
>>> 
>>> 
>>> 
>>>> 
>>>> Thank you!
>>>> John
>>>> 
>>>> John David Sorkin M.D., Ph.D.
>>>> Professor of Medicine
>>>> Chief, Biostatistics and Informatics
>>>> University of Maryland School of Medicine Division of Gerontology and
>>>> Geriatric Medicine
>>>> Baltimore VA Medical Center
>>>> 10 North Greene Street
>>>> GRECC (BT/18/GR)
>>>> Baltimore, MD 21201-1524
>>>> (Phone) 410-605-7119
>>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> 
>>>> Confidentiality Statement:
>>>> This email message, including any attachments, is for the sole use of the
>>>> intended recipient(s) and may contain confidential and privileged
>>>> information. Any unauthorized use, disclosure or distribution is prohibited.
>>>> If you are not the intended recipient, please contact the sender by reply
>>>> email and destroy all copies of the original message.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pd.mes at cbs.dk  Sat Apr  2 17:58:20 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Sat, 2 Apr 2016 15:58:20 +0000
Subject: [R] Extending the beta period for R 3.3.0 till  April 25,
	Final release	on May 3
Message-ID: <BE005488-BD9F-4CE5-87E3-9D061DEC585D@cbs.dk>

Due to delays in implementing an updated Windows toolchain for CRAN, R Core has found it unsafe to go with our usual 1-week beta testing period. Combined with other scheduling issues, we have decided to postpone the transition to 3.3.0 RC until April 26, with the final release happening on May 3. 

Apologies for any inconvenience, but it is really rather important to get this right before the release of 3.3.0. One cannot mix and match binaries from different toolchains - CRAN packages binaries for 3.3.x must be all of the same kind. Accordingly, if we have too little time to fix issues discovered in the beta period, we might have to back out and be stuck with the old tools for another year.

Web site updates will happen shortly.

For the Core Team 
Peter Dalgaard

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From spencer.graves at effectivedefense.org  Sat Apr  2 18:51:20 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sat, 2 Apr 2016 11:51:20 -0500
Subject: [R] p values from GLM
In-Reply-To: <CCD9F93D-7ADA-4569-B939-FA3D4042D800@comcast.net>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
	<56FF0BC8.30501@gmail.com>
	<CCD9F93D-7ADA-4569-B939-FA3D4042D800@comcast.net>
Message-ID: <56FFF888.9020004@effectivedefense.org>



On 4/2/2016 11:07 AM, David Winsemius wrote:
>> On Apr 1, 2016, at 5:01 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 01/04/2016 6:46 PM, Bert Gunter wrote:
>>> ... of course, whether one **should** get them is questionable...
>> They're just statistics.  How could it hurt to look at them?
> Like Rolf, I thought that this utterance on April 1 deserved fortune enshrinement. It reminded me of one of my favorite articles: "P-Values are Random Variables".
>
> Unfortunately a legal copy of that paper is still behind a corporate firewall for which you would need to fork over USD 50.00, but a google search for "P-Values are Random Variables The American Statistician" should yield options for the less squeamish. (My copy was obtained when I did have legal access.)


       How much did money or do the authors of that paper receive in 
royalties?


       That's important, because the purpose of US copyright law is, "To 
promote the Progress of Science and useful Arts, by securing for limited 
Times to Authors and Inventors the exclusive Right to their respective 
Writings and Discoveries."  (E.g., Wikipedia, "Copyright law of the 
United States", 
"https://en.wikipedia.org/wiki/Copyright_law_of_the_United_States") Very 
few if any refereed academic papers are written for financial gain:  
Lawrence Lessig said that congressional representatives rarely hear 
counterarguments to the garbage they get from corporate lobbyists.  The 
Trans Pacific Partnership (TPP, and probably also the Transatlantic 
Trade and Investment Partnership) will strengthen the rights of 
corporations in this area.  If you think that will limit the progress of 
science and the useful arts, as I do, I suggest you contact your elected 
representatives and tell them so -- if you are a citizen of a country 
with elected representatives.  I think we should also ask the American 
Statistical Association how much money they make from that and what it 
would take to put all that material in the public domain.  I think 
professional organizations should come out strongly against these 
provisions of US copyright law and trade agreements that strengthen 
rather than weaken the stranglehold that major corporations have on the 
intellectual heritage of humanity.


       This relates to R, because R is based on an assumption that the 
dissemination of publications, articles and software, for which the 
authors are not remunerated from copyright proceeds should not be 
limited by pre-internet rules that stifle unnecessarily the distribution 
of knowledge and with it improvements in productivity and economic growth.


       Best Wishes,
       Spencer Graves


From michaeleartz at gmail.com  Sat Apr  2 20:19:33 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Sat, 2 Apr 2016 13:19:33 -0500
Subject: [R] p values from GLM
In-Reply-To: <56FFF888.9020004@effectivedefense.org>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
	<56FF0BC8.30501@gmail.com>
	<CCD9F93D-7ADA-4569-B939-FA3D4042D800@comcast.net>
	<56FFF888.9020004@effectivedefense.org>
Message-ID: <CA+pG8eMRDFir3CqWO69dha3oU-4qYxEf7Nq_QXLnaBhXFt--dw@mail.gmail.com>

Maybe it's not the article itself for sale.  Sometimes a company will
charge a fee to have access to its knowledge base.  Not because it owns all
of the content, but because the articles, publications, etc have been
tracked down and centralized.  This is also the whole idea behind paying a
company a few dollars to do a semi-extensive background check.


On Sat, Apr 2, 2016 at 11:51 AM, Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>
>
> On 4/2/2016 11:07 AM, David Winsemius wrote:
>
>> On Apr 1, 2016, at 5:01 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>>> wrote:
>>>
>>> On 01/04/2016 6:46 PM, Bert Gunter wrote:
>>>
>>>> ... of course, whether one **should** get them is questionable...
>>>>
>>> They're just statistics.  How could it hurt to look at them?
>>>
>> Like Rolf, I thought that this utterance on April 1 deserved fortune
>> enshrinement. It reminded me of one of my favorite articles: "P-Values are
>> Random Variables".
>>
>> Unfortunately a legal copy of that paper is still behind a corporate
>> firewall for which you would need to fork over USD 50.00, but a google
>> search for "P-Values are Random Variables The American Statistician" should
>> yield options for the less squeamish. (My copy was obtained when I did have
>> legal access.)
>>
>
>
>       How much did money or do the authors of that paper receive in
> royalties?
>
>
>       That's important, because the purpose of US copyright law is, "To
> promote the Progress of Science and useful Arts, by securing for limited
> Times to Authors and Inventors the exclusive Right to their respective
> Writings and Discoveries."  (E.g., Wikipedia, "Copyright law of the United
> States", "https://en.wikipedia.org/wiki/Copyright_law_of_the_United_States")
> Very few if any refereed academic papers are written for financial gain:
> Lawrence Lessig said that congressional representatives rarely hear
> counterarguments to the garbage they get from corporate lobbyists.  The
> Trans Pacific Partnership (TPP, and probably also the Transatlantic Trade
> and Investment Partnership) will strengthen the rights of corporations in
> this area.  If you think that will limit the progress of science and the
> useful arts, as I do, I suggest you contact your elected representatives
> and tell them so -- if you are a citizen of a country with elected
> representatives.  I think we should also ask the American Statistical
> Association how much money they make from that and what it would take to
> put all that material in the public domain.  I think professional
> organizations should come out strongly against these provisions of US
> copyright law and trade agreements that strengthen rather than weaken the
> stranglehold that major corporations have on the intellectual heritage of
> humanity.
>
>
>       This relates to R, because R is based on an assumption that the
> dissemination of publications, articles and software, for which the authors
> are not remunerated from copyright proceeds should not be limited by
> pre-internet rules that stifle unnecessarily the distribution of knowledge
> and with it improvements in productivity and economic growth.
>
>
>       Best Wishes,
>       Spencer Graves
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mardones.p at gmail.com  Sat Apr  2 20:46:52 2016
From: mardones.p at gmail.com (Pedro Mardones)
Date: Sat, 2 Apr 2016 15:46:52 -0300
Subject: [R] apply mean function to a subset of data
Message-ID: <CAEd7G2duUqevXy2d+A=aeL6ECH=+sQhEY5FTrUdsO_0yrNbA0w@mail.gmail.com>

Dear all;

This must have a rather simple answer but haven't been able to figure it
out: I have a data frame with say 2 groups (group 1 & 2). I want to select
from group 1 say "n" rows and calculate the mean; then select "m" rows from
group 2 and calculate the mean as well. So far I've been using a for loop
for doing it but when it comes to a large data set is rather inefficient.
Any hint to vectorize this would be appreciated.

toy = data.frame(group = c(rep(1,10),rep(2,8)), diam =
c(rnorm(10),rnorm(8)))
nsel = c(6,4)
smean <- c(0,0)
for (i in 1:2)  smean[i] <- mean(toy$diam[1:nsel[i]])

Thanks

Pedro

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Sat Apr  2 20:47:08 2016
From: varinsacha at yahoo.fr (varin sacha)
Date: Sat, 2 Apr 2016 18:47:08 +0000 (UTC)
Subject: [R] BCa Bootstrap confidence intervals
References: <1065640372.2545251.1459622828077.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1065640372.2545251.1459622828077.JavaMail.yahoo@mail.yahoo.com>

Dear R-Experts,

Thanks to Prof. Bonnett, I have got an R script working to calculate confidence intervals around the semipartial correlation coefficients.
Now, I would like to calculate BCa bootstrap CIs using the boot library and the boot.ci(results, type="all") function. How could I modify my R script (here below reproducible example) to get the BCa bootstrap CIs ?



CIsemipartcorr <- function(alpha, part, mult, n) {
# Computes a confidence interval for a semipartial correlation
# Arguments: 
#   alpha: alpha value for 1-alpha confidence
#   part:  sample semipartial correlation 
#   mult:  sample squared multiple correlation in full model
#   n:  sample size
# Returns:
#   confidence interval
z <- qnorm(1 - alpha/2)
mult0 <- mult - part^2
zr <- log((1 + part)/(1 - part))/2
a <- (mult^2 - 2*mult + mult0 - mult0^2 + 1)/(1 - part^2)^2
se <- sqrt(a/(n - 3))
LL0 <- zr - z*se
UL0 <- zr + z*se
LL <- (exp(2*LL0) - 1)/(exp(2*LL0) + 1)
UL <- (exp(2*UL0) - 1)/(exp(2*UL0) + 1)
CI <- c(LL, UL)
return(CI)
}
CIsemipartcorr(.05, .3638, .7803, 22)

Thanks for your time,


From boris.steipe at utoronto.ca  Sat Apr  2 21:48:30 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 2 Apr 2016 15:48:30 -0400
Subject: [R] apply mean function to a subset of data
In-Reply-To: <CAEd7G2duUqevXy2d+A=aeL6ECH=+sQhEY5FTrUdsO_0yrNbA0w@mail.gmail.com>
References: <CAEd7G2duUqevXy2d+A=aeL6ECH=+sQhEY5FTrUdsO_0yrNbA0w@mail.gmail.com>
Message-ID: <4B62B650-47EF-44DF-ABD8-5A385E9EB71C@utoronto.ca>

Your toy code does not reproduce what you describe: mean(toy$diam[1:nsel[i]]) both times selects from elements of group 1. YOu probably want to subset like toy$diam[toy$group == i]. Also, if there is any real inefficiency here, it is _not_ because you are executing a for-loop for two iterations. What makes you think you have an efficiency problem?


B.

On Apr 2, 2016, at 2:46 PM, Pedro Mardones <mardones.p at gmail.com> wrote:

> Dear all;
> 
> This must have a rather simple answer but haven't been able to figure it
> out: I have a data frame with say 2 groups (group 1 & 2). I want to select
> from group 1 say "n" rows and calculate the mean; then select "m" rows from
> group 2 and calculate the mean as well. So far I've been using a for loop
> for doing it but when it comes to a large data set is rather inefficient.
> Any hint to vectorize this would be appreciated.
> 
> toy = data.frame(group = c(rep(1,10),rep(2,8)), diam =
> c(rnorm(10),rnorm(8)))
> nsel = c(6,4)
> smean <- c(0,0)
> for (i in 1:2)  smean[i] <- mean(toy$diam[1:nsel[i]])
> 
> Thanks
> 
> Pedro
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tuechler at gmx.at  Sun Apr  3 01:00:50 2016
From: tuechler at gmx.at (Heinz Tuechler)
Date: Sun, 3 Apr 2016 00:00:50 +0100
Subject: [R] p values from GLM
In-Reply-To: <CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
Message-ID: <57004F22.6060603@gmx.at>


Bert Gunter wrote on 01.04.2016 23:46:
> ... of course, whether one **should** get them is questionable...
>
> http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503#/ref-link-1
>
This paper repeats the common place statement that a small p-value does 
not necessarily indicate an important finding. Agreed, but maybe I 
overlooked examples of important findings with large p-values.
If there are some, I would be happy to get to know some of them. 
Otherwise a small p-value is no guarantee of importance, but a prerequisite.

best regards,

Heinz

>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Apr 1, 2016 at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 01/04/2016 6:14 PM, John Sorkin wrote:
>>> How can I get the p values from a glm ? I want to get the p values so I
>>> can add them to a custom report
>>>
>>>
>>>    fitwean<-
>>> glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
>>>    summary(fitwean)             # This lists the coefficeints, SEs, z and p
>>> values, but I can't isolate the pvalues.
>>>    names(summary(fitwean))  # I see the coefficients, but not the p values
>>>    names(fitmens)                  # p values are not found here.
>>
>> Doesn't summary(fitwean) give a matrix? Then it's
>> colnames(summary(fitwean)$coefficients) you want, not names(fitwean).
>>
>> Duncan Murdoch
>>
>> P.S. If you had given a reproducible example, I'd try it myself.
>>
>>
>>
>>>
>>> Thank you!
>>> John
>>>
>>> John David Sorkin M.D., Ph.D.
>>> Professor of Medicine
>>> Chief, Biostatistics and Informatics
>>> University of Maryland School of Medicine Division of Gerontology and
>>> Geriatric Medicine
>>> Baltimore VA Medical Center
>>> 10 North Greene Street
>>> GRECC (BT/18/GR)
>>> Baltimore, MD 21201-1524
>>> (Phone) 410-605-7119
>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>
>>> Confidentiality Statement:
>>> This email message, including any attachments, is for the sole use of the
>>> intended recipient(s) and may contain confidential and privileged
>>> information. Any unauthorized use, disclosure or distribution is prohibited.
>>> If you are not the intended recipient, please contact the sender by reply
>>> email and destroy all copies of the original message.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Apr  3 01:13:57 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 3 Apr 2016 09:13:57 +1000
Subject: [R] apply mean function to a subset of data
In-Reply-To: <CAEd7G2duUqevXy2d+A=aeL6ECH=+sQhEY5FTrUdsO_0yrNbA0w@mail.gmail.com>
References: <CAEd7G2duUqevXy2d+A=aeL6ECH=+sQhEY5FTrUdsO_0yrNbA0w@mail.gmail.com>
Message-ID: <CA+8X3fWno6dwO1VKXRxbRGOUb2pRL_KjHnDUraDGVPctPUZANw@mail.gmail.com>

Hi Pedro,
This may not be much of an improvement, but it was a challenge.

selvec<-as.vector(matrix(c(nsel,unlist(by(toy$diam,toy$group,length))-nsel),
 ncol=2,byrow=TRUE))
TFvec<-rep(c(TRUE,FALSE),length.out=length(selvec))
toynsel<-rep(TFvec,selvec)
by(toy[toynsel,]$diam,toy[toynsel,]$group,mean)

Jim

On 4/3/16, Pedro Mardones <mardones.p at gmail.com> wrote:
> Dear all;
>
> This must have a rather simple answer but haven't been able to figure it
> out: I have a data frame with say 2 groups (group 1 & 2). I want to select
> from group 1 say "n" rows and calculate the mean; then select "m" rows from
> group 2 and calculate the mean as well. So far I've been using a for loop
> for doing it but when it comes to a large data set is rather inefficient.
> Any hint to vectorize this would be appreciated.
>
> toy = data.frame(group = c(rep(1,10),rep(2,8)), diam =
> c(rnorm(10),rnorm(8)))
> nsel = c(6,4)
> smean <- c(0,0)
> for (i in 1:2)  smean[i] <- mean(toy$diam[1:nsel[i]])
>
> Thanks
>
> Pedro
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Sun Apr  3 02:54:10 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 2 Apr 2016 20:54:10 -0400
Subject: [R] row.names(), rownames(), colnames(), names() ...?
Message-ID: <34E210A3-D204-4123-A084-DD453D461D9A@utoronto.ca>

The help text for row+colnames {base} states:

  "For a data frame, rownames and colnames eventually call row.names
   and names respectively, but the latter are preferred."

Why are they "preferred"?
Why is it names(), not col.names()?
I have only ever used names() for vectors - I'm surprised it works on data.frames... IMO this is not great for code readability, thus thinking to require rownames(), colnames() for all 2D objects, names() for vectors and lists. Any problems with this approach?


Thanks for some insight!
Boris

From jdnewmil at dcn.davis.ca.us  Sun Apr  3 03:11:07 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 02 Apr 2016 18:11:07 -0700
Subject: [R] row.names(), rownames(), colnames(), names() ...?
In-Reply-To: <34E210A3-D204-4123-A084-DD453D461D9A@utoronto.ca>
References: <34E210A3-D204-4123-A084-DD453D461D9A@utoronto.ca>
Message-ID: <C6AEF188-0C29-4503-9B4D-5DB6ECB8DD0C@dcn.davis.ca.us>

Data frames are lists of columns. The names() function is appropriate for lists. 

It doesn't pay to fall into the trap of thinking that data frames are truly symmetric between columns and rows, because there is a performance penalty for accessing rows that is greater than the cost of accessing columns. With that in mind, thinking of data frames as lists is preferred, so names is preferred over colnames.
-- 
Sent from my phone. Please excuse my brevity.

On April 2, 2016 5:54:10 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>The help text for row+colnames {base} states:
>
>  "For a data frame, rownames and colnames eventually call row.names
>   and names respectively, but the latter are preferred."
>
>Why are they "preferred"?
>Why is it names(), not col.names()?
>I have only ever used names() for vectors - I'm surprised it works on
>data.frames... IMO this is not great for code readability, thus
>thinking to require rownames(), colnames() for all 2D objects, names()
>for vectors and lists. Any problems with this approach?
>
>
>Thanks for some insight!
>Boris
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Apr  3 03:20:06 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 2 Apr 2016 21:20:06 -0400
Subject: [R] row.names(), rownames(), colnames(), names() ...?
In-Reply-To: <C6AEF188-0C29-4503-9B4D-5DB6ECB8DD0C@dcn.davis.ca.us>
References: <34E210A3-D204-4123-A084-DD453D461D9A@utoronto.ca>
	<C6AEF188-0C29-4503-9B4D-5DB6ECB8DD0C@dcn.davis.ca.us>
Message-ID: <ECD1DCFB-7D85-4C8A-A842-7A3D46653DB6@utoronto.ca>

Ah, that makes immediate sense.

On Apr 2, 2016, at 9:11 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Data frames are lists of columns. The names() function is appropriate for lists. 
> 
> It doesn't pay to fall into the trap of thinking that data frames are truly symmetric between columns and rows, because there is a performance penalty for accessing rows that is greater than the cost of accessing columns.
Interesting, I didn't know that.


> With that in mind, thinking of data frames as lists is preferred, so names is preferred over colnames.

I see. Thinking about data frames like that has the added benefit that this matches how we describe entities in relational datamodels. Both then turn out to be the transpose of the typical spreadsheet.

Thanks Jeff



> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On April 2, 2016 5:54:10 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> The help text for row+colnames {base} states:
> 
>   "For a data frame, rownames and colnames eventually call row.names
>    and names respectively, but the latter are preferred."
> 
> Why are they "preferred"?
> Why is it names(), not col.names()?
> I have only ever used names() for vectors - I'm surprised it works on data.frames... IMO this is not great for code readability, thus thinking to require rownames(), colnames() for all 2D objects, names() for vectors and lists. Any problems with this approach?
> 
> 
> Thanks for some insight!
> Boris
> 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained,
> reproducible code.
> 


From pdalgd at gmail.com  Sun Apr  3 11:59:05 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 3 Apr 2016 11:59:05 +0200
Subject: [R] p values from GLM
In-Reply-To: <57004F22.6060603@gmx.at>
References: <56FEBA8A020000CB0014F37F@smtp.medicine.umaryland.edu>
	<56FEF57E.8090401@gmail.com>
	<CAGxFJbQB54sozaRkHRbNWCvSo-gBK_eQo6U+jdugR49uAgf2-A@mail.gmail.com>
	<57004F22.6060603@gmx.at>
Message-ID: <C889A626-E255-480B-95BF-9AF71F797B91@gmail.com>


> On 03 Apr 2016, at 01:00 , Heinz Tuechler <tuechler at gmx.at> wrote:
> 
> 
> Bert Gunter wrote on 01.04.2016 23:46:
>> ... of course, whether one **should** get them is questionable...
>> 
>> http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503#/ref-link-1
>> 
> This paper repeats the common place statement that a small p-value does not necessarily indicate an important finding. Agreed, but maybe I overlooked examples of important findings with large p-values.
> If there are some, I would be happy to get to know some of them. Otherwise a small p-value is no guarantee of importance, but a prerequisite.

This is getting seriously off-topic, but lots of underdimensioned studies would qualify. However, the effects found are almost indistiguishable from Type I errors. Later, larger, studies would be required to confirm that the effect is really there. (Like, halving or doubling the risk of some cancer is hardly unimportant, but knowing that that is often the detection limit in medium-scaled epidemiological studies may make you a bit jaded when hearing such reports.)

-pd

> 
> best regards,
> 
> Heinz
> 
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Fri, Apr 1, 2016 at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> On 01/04/2016 6:14 PM, John Sorkin wrote:
>>>> How can I get the p values from a glm ? I want to get the p values so I
>>>> can add them to a custom report
>>>> 
>>>> 
>>>>   fitwean<-
>>>> glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
>>>>   summary(fitwean)             # This lists the coefficeints, SEs, z and p
>>>> values, but I can't isolate the pvalues.
>>>>   names(summary(fitwean))  # I see the coefficients, but not the p values
>>>>   names(fitmens)                  # p values are not found here.
>>> 
>>> Doesn't summary(fitwean) give a matrix? Then it's
>>> colnames(summary(fitwean)$coefficients) you want, not names(fitwean).
>>> 
>>> Duncan Murdoch
>>> 
>>> P.S. If you had given a reproducible example, I'd try it myself.
>>> 
>>> 
>>> 
>>>> 
>>>> Thank you!
>>>> John
>>>> 
>>>> John David Sorkin M.D., Ph.D.
>>>> Professor of Medicine
>>>> Chief, Biostatistics and Informatics
>>>> University of Maryland School of Medicine Division of Gerontology and
>>>> Geriatric Medicine
>>>> Baltimore VA Medical Center
>>>> 10 North Greene Street
>>>> GRECC (BT/18/GR)
>>>> Baltimore, MD 21201-1524
>>>> (Phone) 410-605-7119
>>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> 
>>>> Confidentiality Statement:
>>>> This email message, including any attachments, is for the sole use of the
>>>> intended recipient(s) and may contain confidential and privileged
>>>> information. Any unauthorized use, disclosure or distribution is prohibited.
>>>> If you are not the intended recipient, please contact the sender by reply
>>>> email and destroy all copies of the original message.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From normanmath at gmail.com  Sat Apr  2 23:40:57 2016
From: normanmath at gmail.com (Norman Polozka)
Date: Sun, 3 Apr 2016 07:40:57 +1000
Subject: [R] R model developing & validating - Open to Discussion
Message-ID: <CAPN1DfxGx-0h4qaT2Y-3YaL4a-KWRf+VePxuoK1f1aq3xm4rEg@mail.gmail.com>

Throughout my R journey I have noticed the way we can use given data to
develop and validate a model.

Assume that you have given data for a problem

1. train.csv
2. test.csv

*Method A*

*Combine train+test data* and develop a model using the combined data. Then
use test.data to validate the model based on predicted error analysis.

*Method B*

Use *train data* to develop the model and then use *test data* to validate
the model based on predicted error analysis.

*Method C*

Sub divided 75% as training data and 25% test data on *train.csv *file and
use new training data for developing the model. Then use new test data to
validate the model.
After that use initial given test data to double check the performance of
the model.

I have identified 3 methods so it is bit confusing which one to use.

*Are there any other methods other than these methods?*

I need opinions from R experts on

1. What is the best practice?

2. Does that depend on the scale of the problem (smaller data or big data)?

3. a) Confusion matrix is the only way that can we use to check the
performance of a model?

    b) Is there any other matrices to check the performance?

    c) Does it depend on the type of the model(lm(),glm(),tree(),svm()
etc..)?

    d) Do we have different matrices for different models to evaluate the
model?


PS: I have asked this question in stack but no response so I thought to ask
from you guys

Many thanks

	[[alternative HTML version deleted]]


From Florian_Schwendinger at gmx.at  Sun Apr  3 03:17:29 2016
From: Florian_Schwendinger at gmx.at (Florian Schwendinger)
Date: Sun, 3 Apr 2016 03:17:29 +0200
Subject: [R] [Rd] TensorFlow in R
In-Reply-To: <CAAyVsXJdHHLABAm_T++6c3h7z=Y4n3WOWqX=NM_LuaDPP70C6A@mail.gmail.com>
References: <CAAyVsXJdHHLABAm_T++6c3h7z=Y4n3WOWqX=NM_LuaDPP70C6A@mail.gmail.com>
Message-ID: <57006F29.7050201@gmx.at>

Hi Axel,

Maybe the following works for you.
https://bitbucket.org/Floooo/tensorflow-r-examples/src/

Florian Schwendinger

On 2016-04-01 18:32, Axel Urbiz wrote:
> Hi All,
>
> I didn't have much success through my Google search in finding any active
> R-related projects to create a wrapper around TensorFlow in R. Anyone know
> if this is on the go?
>
> Thanks,
> Axel.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mwmorrison93 at gmail.com  Sun Apr  3 04:40:36 2016
From: mwmorrison93 at gmail.com (Michael Morrison)
Date: Sat, 2 Apr 2016 21:40:36 -0500
Subject: [R] File 1 is not in sorted order Error
Message-ID: <CANGs2ysqsbieiL2TqfGe1YTab1y1JdapFggcZQAyvu8iDEP6pg@mail.gmail.com>

Hi, I'm trying to build R on windows and i'm getting the following error
when i run the "make all recommended" command:

C:/Rtools/mingw_64/bin/windres -F pe-x86-64   -i dllversion.rc -o
dllversion.o
comm: file 1 is not in sorted order
make[4]: *** [Rgraphapp.def] Error 1
make[3]: *** [rlibs] Error 1
make[2]: *** [../../bin/x64/R.dll] Error 2
make[1]: *** [rbuild] Error 2
make: *** [all] Error 2


Can someone please help me figure out this error. I've tried researching on
my own but i'm out of options. Thanks in advance.

Michael Morrison

	[[alternative HTML version deleted]]


From zatulmahfuz at hotmail.com  Sun Apr  3 08:24:32 2016
From: zatulmahfuz at hotmail.com (MAHFUZATUL IZYAN)
Date: Sun, 3 Apr 2016 06:24:32 +0000
Subject: [R] =?utf-8?q?before-after_control-impact_analysis_with_R?=
Message-ID: <BLU405-EAS321C2607B134506B558DEDFB49C0@phx.gbl>

Hi! I?m Zatul from Malaysia. I?m currently doing simple task on BACI approach in ecology study. I?m a newbie in ecology study. Perhaps, I can get link and some idea regarding how to analyse BACI data. Tq. 





Regards. 


Sent from Windows Mail
	[[alternative HTML version deleted]]


From heshamibb at yahoo.com  Sun Apr  3 16:44:39 2016
From: heshamibb at yahoo.com (hehsham alpukhity)
Date: Sun, 3 Apr 2016 14:44:39 +0000 (UTC)
Subject: [R] use one way ANOVA to select genes
References: <1823966439.1969138.1459694679517.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1823966439.1969138.1459694679517.JavaMail.yahoo@mail.yahoo.com>

i want to select the significant genes form ?5 clusters (groups) by one way ANOVA ?in r#######################################################################################
# i want use One way ANOVA to select the siginificant from the clusters above?
selectgene <- function(GropuData,pvalue=0.05, na.rm=TRUE, file=1:5){# if each gruop in one ?txt file ?? ??? ? ??? ? fdata <- list.files(data,full.names = TRUE)? ??? ??? ??? ? for(i in file)?{? ? ? ??anova()?
? ? ? ? }??}######################################

Hisham AL-bukhaiti Ph.D Student (Information system ) China, changsha,Hunan university. Mobile: 0068-15 111 4246 91.
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Apr  3 19:19:58 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 03 Apr 2016 10:19:58 -0700
Subject: [R] File 1 is not in sorted order Error
In-Reply-To: <CANGs2ysqsbieiL2TqfGe1YTab1y1JdapFggcZQAyvu8iDEP6pg@mail.gmail.com>
References: <CANGs2ysqsbieiL2TqfGe1YTab1y1JdapFggcZQAyvu8iDEP6pg@mail.gmail.com>
Message-ID: <7BB2FEC1-D1F3-49D2-87A8-573EC4CC770B@dcn.davis.ca.us>

This question belongs on R-devel.
-- 
Sent from my phone. Please excuse my brevity.

On April 2, 2016 7:40:36 PM PDT, Michael Morrison <mwmorrison93 at gmail.com> wrote:
>Hi, I'm trying to build R on windows and i'm getting the following
>error
>when i run the "make all recommended" command:
>
>C:/Rtools/mingw_64/bin/windres -F pe-x86-64   -i dllversion.rc -o
>dllversion.o
>comm: file 1 is not in sorted order
>make[4]: *** [Rgraphapp.def] Error 1
>make[3]: *** [rlibs] Error 1
>make[2]: *** [../../bin/x64/R.dll] Error 2
>make[1]: *** [rbuild] Error 2
>make: *** [all] Error 2
>
>
>Can someone please help me figure out this error. I've tried
>researching on
>my own but i'm out of options. Thanks in advance.
>
>Michael Morrison
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Apr  3 19:24:32 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 3 Apr 2016 10:24:32 -0700
Subject: [R] R model developing & validating - Open to Discussion
In-Reply-To: <CAPN1DfxGx-0h4qaT2Y-3YaL4a-KWRf+VePxuoK1f1aq3xm4rEg@mail.gmail.com>
References: <CAPN1DfxGx-0h4qaT2Y-3YaL4a-KWRf+VePxuoK1f1aq3xm4rEg@mail.gmail.com>
Message-ID: <CAGxFJbTc4Wue1A9FccS0dr7TGTv=4J7yOJ5VZFydbgDs+yhHqQ@mail.gmail.com>

This is way OT for this list, and really has nothing to do with R.
Post on a statistical list like stats.stackexchange.com if you want to
repeat a discussion that has gone on for decades and has no
resolution.

You really should be spending time with the literature, though. Have
you? "Cross validation" and "penalized regression" might be a couple
of terms to start you off, although they are far from sufficient, and
others might suggest better ones.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 2, 2016 at 2:40 PM, Norman Polozka <normanmath at gmail.com> wrote:
> Throughout my R journey I have noticed the way we can use given data to
> develop and validate a model.
>
> Assume that you have given data for a problem
>
> 1. train.csv
> 2. test.csv
>
> *Method A*
>
> *Combine train+test data* and develop a model using the combined data. Then
> use test.data to validate the model based on predicted error analysis.
>
> *Method B*
>
> Use *train data* to develop the model and then use *test data* to validate
> the model based on predicted error analysis.
>
> *Method C*
>
> Sub divided 75% as training data and 25% test data on *train.csv *file and
> use new training data for developing the model. Then use new test data to
> validate the model.
> After that use initial given test data to double check the performance of
> the model.
>
> I have identified 3 methods so it is bit confusing which one to use.
>
> *Are there any other methods other than these methods?*
>
> I need opinions from R experts on
>
> 1. What is the best practice?
>
> 2. Does that depend on the scale of the problem (smaller data or big data)?
>
> 3. a) Confusion matrix is the only way that can we use to check the
> performance of a model?
>
>     b) Is there any other matrices to check the performance?
>
>     c) Does it depend on the type of the model(lm(),glm(),tree(),svm()
> etc..)?
>
>     d) Do we have different matrices for different models to evaluate the
> model?
>
>
> PS: I have asked this question in stack but no response so I thought to ask
> from you guys
>
> Many thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Apr  3 19:30:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 3 Apr 2016 10:30:38 -0700
Subject: [R] before-after control-impact analysis with R
In-Reply-To: <BLU405-EAS321C2607B134506B558DEDFB49C0@phx.gbl>
References: <BLU405-EAS321C2607B134506B558DEDFB49C0@phx.gbl>
Message-ID: <CAGxFJbT0M3N+GWZKM6gBzNLKg+Hk6aDW-7NDaqaTDWNQrwgm+w@mail.gmail.com>

This has nothing to do with R. Post on an ecology list or talk with
your teachers.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 2, 2016 at 11:24 PM, MAHFUZATUL IZYAN
<zatulmahfuz at hotmail.com> wrote:
> Hi! I?m Zatul from Malaysia. I?m currently doing simple task on BACI approach in ecology study. I?m a newbie in ecology study. Perhaps, I can get link and some idea regarding how to analyse BACI data. Tq.
>
>
>
>
>
> Regards.
>
>
> Sent from Windows Mail
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sun Apr  3 22:44:47 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 3 Apr 2016 20:44:47 +0000
Subject: [R] apply mean function to a subset of data
In-Reply-To: <CA+8X3fWno6dwO1VKXRxbRGOUb2pRL_KjHnDUraDGVPctPUZANw@mail.gmail.com>
References: <CAEd7G2duUqevXy2d+A=aeL6ECH=+sQhEY5FTrUdsO_0yrNbA0w@mail.gmail.com>
	<CA+8X3fWno6dwO1VKXRxbRGOUb2pRL_KjHnDUraDGVPctPUZANw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D728D4C@mb02.ads.tamu.edu>

Here are several ways to get there, but your original loop is fine once it is corrected:

> for (i in 1:2)  smean[i] <- mean(toy$diam[toy$group==i][1:nsel[i]])
> smean
[1] 0.271489 1.117015

Using sapply() to hide the loop:
> smean <- sapply(1:2, function(x) mean((toy$diam[toy$group==x])[1:nsel[x]]))
> smean
[1] 0.271489 1.117015

Or use head()
> smean <- sapply(1:2, function(x) mean(head(toy$diam[toy$group==x], nsel[x])))
> smean
[1] 0.271489 1.117015

Or mapply() instead of sapply
> smean <- mapply(function(x, y) mean(head(x, y)) , x=split(toy$diam, toy$group), y=nsel)
> smean
       1        2 
0.271489 1.117015

------------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Saturday, April 2, 2016 6:14 PM
To: Pedro Mardones <mardones.p at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] apply mean function to a subset of data

Hi Pedro,
This may not be much of an improvement, but it was a challenge.

selvec<-as.vector(matrix(c(nsel,unlist(by(toy$diam,toy$group,length))-nsel),
 ncol=2,byrow=TRUE))
TFvec<-rep(c(TRUE,FALSE),length.out=length(selvec))
toynsel<-rep(TFvec,selvec)
by(toy[toynsel,]$diam,toy[toynsel,]$group,mean)

Jim

On 4/3/16, Pedro Mardones <mardones.p at gmail.com> wrote:
> Dear all;
>
> This must have a rather simple answer but haven't been able to figure it
> out: I have a data frame with say 2 groups (group 1 & 2). I want to select
> from group 1 say "n" rows and calculate the mean; then select "m" rows from
> group 2 and calculate the mean as well. So far I've been using a for loop
> for doing it but when it comes to a large data set is rather inefficient.
> Any hint to vectorize this would be appreciated.
>
> toy = data.frame(group = c(rep(1,10),rep(2,8)), diam =
> c(rnorm(10),rnorm(8)))
> nsel = c(6,4)
> smean <- c(0,0)
> for (i in 1:2)  smean[i] <- mean(toy$diam[1:nsel[i]])
>
> Thanks
>
> Pedro
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From john.maindonald at anu.edu.au  Mon Apr  4 00:22:29 2016
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sun, 3 Apr 2016 22:22:29 +0000
Subject: [R] p values from GLM
In-Reply-To: <mailman.2.1459677601.23229.r-help@r-project.org>
References: <mailman.2.1459677601.23229.r-help@r-project.org>
Message-ID: <8F9521CD-8583-4221-9E70-3E8F09C69AD9@anu.edu.au>

How small does a p-value need to be to warrant attention, however?

Witness Fisher?s comment that:
?. . . we may, if we prefer it, draw the line at one in fifty (the 2 per cent point), or one in a hundred (the 1 per cent point). Personally, the writer prefers to set a low standard of significance at the 5 per cent point, and ignore entirely all results which fail to reach this level. A scientific fact should be regarded as experimentally established only if a properly designed experiment rarely fails to give this level of significance.?
[Fisher RA (1926), ?The Arrangement of Field Experiments,? Journal of the Ministry of Agriculture of Great Britain, 33, 503-513.]

See the selection of Fisher quotes at http://www.jerrydallal.com/lhsp/p05.htm .

In contexts where a p <= 0.05 becomes more likely under the NULL (not the case if the experiment might just as well have been a random number generator), small P-values shift the weight of evidence.  An alternative that is apriori highly unlikely takes a lot of shifting.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 3/04/2016, at 22:00, r-help-request at r-project.org<mailto:r-help-request at r-project.org> wrote:

From: Heinz Tuechler <tuechler at gmx.at<mailto:tuechler at gmx.at>>
Subject: Re: [R] p values from GLM
Date: 3 April 2016 11:00:50 NZST
To: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>, Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>>
Cc: r-help <R-help at r-project.org<mailto:R-help at r-project.org>>



Bert Gunter wrote on 01.04.2016 23:46:
... of course, whether one **should** get them is questionable...

http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503#/ref-link-1

This paper repeats the common place statement that a small p-value does not necessarily indicate an important finding. Agreed, but maybe I overlooked examples of important findings with large p-values.
If there are some, I would be happy to get to know some of them. Otherwise a small p-value is no guarantee of importance, but a prerequisite.

best regards,

Heinz


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 1, 2016 at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>> wrote:
On 01/04/2016 6:14 PM, John Sorkin wrote:
How can I get the p values from a glm ? I want to get the p values so I
can add them to a custom report


  fitwean<-
glm(data[,"JWean"]~data[,"Group"],data=data,family=binomial(link ="logit"))
  summary(fitwean)             # This lists the coefficeints, SEs, z and p
values, but I can't isolate the pvalues.
  names(summary(fitwean))  # I see the coefficients, but not the p values
  names(fitmens)                  # p values are not found here.

Doesn't summary(fitwean) give a matrix? Then it's
colnames(summary(fitwean)$coefficients) you want, not names(fitwean).

Duncan Murdoch

P.S. If you had given a reproducible example, I'd try it myself.




Thank you!
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the
intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is prohibited.
If you are not the intended recipient, please contact the sender by reply
email and destroy all copies of the original message.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Apr  4 09:28:55 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 4 Apr 2016 07:28:55 +0000
Subject: [R] use one way ANOVA to select genes
In-Reply-To: <1823966439.1969138.1459694679517.JavaMail.yahoo@mail.yahoo.com>
References: <1823966439.1969138.1459694679517.JavaMail.yahoo.ref@mail.yahoo.com>
	<1823966439.1969138.1459694679517.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50216CC@SRVEXCHMBX.precheza.cz>

Hi

Your message is scrambled by using HTML post and if I deciphered it correctly you just want to use anova for some data.

What is preventing you from doing it?

Cheers
Petr

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of hehsham alpukhity via R-help
Sent: Sunday, April 3, 2016 4:45 PM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] use one way ANOVA to select genes

i want to select the significant genes form  5 clusters (groups) by one way ANOVA  in r#######################################################################################
# i want use One way ANOVA to select the siginificant from the clusters above selectgene <- function(GropuData,pvalue=0.05, na.rm=TRUE, file=1:5){# if each gruop in one  txt file                fdata <- list.files(data,full.names = TRUE)                for(i in file) {        anova()
        }  }######################################

Hisham AL-bukhaiti Ph.D Student (Information system ) China, changsha,Hunan university. Mobile: 0068-15 111 4246 91.
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From javanmard.majid at gmail.com  Mon Apr  4 12:16:05 2016
From: javanmard.majid at gmail.com (Majid Javanmard)
Date: Mon, 4 Apr 2016 14:46:05 +0430
Subject: [R] Does this code execute the bagging correctly ?!
Message-ID: <CAA0OCntSJGaoqmCtEomcKmdZfr+AQDx25Ete94Uez4FvkDcpng@mail.gmail.com>

Hello
the code :

set.seed(10)
y<-c(1:1000)
x1<-c(1:1000)*runif(1000,min=0,max=2)
x2<-c(1:1000)*runif(1000,min=0,max=2)
x3<-c(1:1000)*runif(1000,min=0,max=2)

lm_fit<-lm(y~x1+x2+x3)
summary(lm_fit)

set.seed(10)
all_data<-data.frame(y,x1,x2,x3)
positions <- sample(nrow(all_data),size=floor((nrow(all_data)/4)*3))
training<- all_data[positions,]
testing<- all_data[-positions,]

lm_fit<-lm(y~x1+x2+x3,data=training)
predictions<-predict(lm_fit,newdata=testing)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))

library(foreach)
length_divisor<-4
iterations<-1000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
  training_positions <- sample(nrow(training),
size=floor((nrow(training)/length_divisor)))
  train_pos<-1:nrow(training) %in% training_positions
  lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
  predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))



Does it execute bagging correctly ?

if yes , How to rank in sequence  Training and Testing in a column ?! and ow
can I have prediction interval for each predicted value ?!

Thanks for your attention

	[[alternative HTML version deleted]]


From mardones.p at gmail.com  Mon Apr  4 14:07:45 2016
From: mardones.p at gmail.com (Pedro Mardones)
Date: Mon, 4 Apr 2016 09:07:45 -0300
Subject: [R] apply mean function to a subset of data
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D728D4C@mb02.ads.tamu.edu>
References: <CAEd7G2duUqevXy2d+A=aeL6ECH=+sQhEY5FTrUdsO_0yrNbA0w@mail.gmail.com>
	<CA+8X3fWno6dwO1VKXRxbRGOUb2pRL_KjHnDUraDGVPctPUZANw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D728D4C@mb02.ads.tamu.edu>
Message-ID: <3E127004-32F8-4D0E-A00C-F28F6BEB06C8@gmail.com>

Thanks David
It works perfectly
Pedro

Sent from my iPhone

> On Apr 3, 2016, at 17:44, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Here are several ways to get there, but your original loop is fine once it is corrected:
> 
>> for (i in 1:2)  smean[i] <- mean(toy$diam[toy$group==i][1:nsel[i]])
>> smean
> [1] 0.271489 1.117015
> 
> Using sapply() to hide the loop:
>> smean <- sapply(1:2, function(x) mean((toy$diam[toy$group==x])[1:nsel[x]]))
>> smean
> [1] 0.271489 1.117015
> 
> Or use head()
>> smean <- sapply(1:2, function(x) mean(head(toy$diam[toy$group==x], nsel[x])))
>> smean
> [1] 0.271489 1.117015
> 
> Or mapply() instead of sapply
>> smean <- mapply(function(x, y) mean(head(x, y)) , x=split(toy$diam, toy$group), y=nsel)
>> smean
>       1        2 
> 0.271489 1.117015
> 
> ------------------------------
> David L. Carlson
> Department of Anthropology
> Texas A&M University
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Saturday, April 2, 2016 6:14 PM
> To: Pedro Mardones <mardones.p at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] apply mean function to a subset of data
> 
> Hi Pedro,
> This may not be much of an improvement, but it was a challenge.
> 
> selvec<-as.vector(matrix(c(nsel,unlist(by(toy$diam,toy$group,length))-nsel),
> ncol=2,byrow=TRUE))
> TFvec<-rep(c(TRUE,FALSE),length.out=length(selvec))
> toynsel<-rep(TFvec,selvec)
> by(toy[toynsel,]$diam,toy[toynsel,]$group,mean)
> 
> Jim
> 
>> On 4/3/16, Pedro Mardones <mardones.p at gmail.com> wrote:
>> Dear all;
>> 
>> This must have a rather simple answer but haven't been able to figure it
>> out: I have a data frame with say 2 groups (group 1 & 2). I want to select
>> from group 1 say "n" rows and calculate the mean; then select "m" rows from
>> group 2 and calculate the mean as well. So far I've been using a for loop
>> for doing it but when it comes to a large data set is rather inefficient.
>> Any hint to vectorize this would be appreciated.
>> 
>> toy = data.frame(group = c(rep(1,10),rep(2,8)), diam =
>> c(rnorm(10),rnorm(8)))
>> nsel = c(6,4)
>> smean <- c(0,0)
>> for (i in 1:2)  smean[i] <- mean(toy$diam[1:nsel[i]])
>> 
>> Thanks
>> 
>> Pedro
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Apr  4 14:56:58 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 4 Apr 2016 07:56:58 -0500
Subject: [R] before-after control-impact analysis with R
In-Reply-To: <BLU405-EAS321C2607B134506B558DEDFB49C0@phx.gbl>
References: <BLU405-EAS321C2607B134506B558DEDFB49C0@phx.gbl>
Message-ID: <CAN5YmCEon9GP94iarEyY9OpBpTgTo-bNFr2o1BDMjNXQVfYU_Q@mail.gmail.com>

I searched for
     analyze BACI data in R
and found a couple things that you might find helpful.

http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/MyPrograms/BACI/BACITalk-2012-10-15-UBC/baci.pdf
http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/PDFbigbook-R/R-part013.pdf

Jean

On Sun, Apr 3, 2016 at 1:24 AM, MAHFUZATUL IZYAN <zatulmahfuz at hotmail.com>
wrote:

> Hi! I?m Zatul from Malaysia. I?m currently doing simple task on BACI
> approach in ecology study. I?m a newbie in ecology study. Perhaps, I can
> get link and some idea regarding how to analyse BACI data. Tq.
>
>
>
>
>
> Regards.
>
>
> Sent from Windows Mail
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Mon Apr  4 15:17:33 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 04 Apr 2016 08:17:33 -0500
Subject: [R] Using R for cURL commands,Message-ID:
In-Reply-To: <mailman.3.1459591202.2451.r-help@r-project.org>
References: <mailman.3.1459591202.2451.r-help@r-project.org>
Message-ID: <519743$2p390h@ironport10.mayo.edu>



On 04/02/2016 05:00 AM, r-help-request at r-project.org wrote:
> Hello,
>
>
> I'm looking for a way in which R can make my live easier.
>
> Currently i'm using R convert data from a dataframe to json's and then sending these json's to a rest api using a curl command in the terminal (i'm on a mac).
>
>
> I've been looking for a way to use R for sending data from R to the rest api. My primairy focus was on using R for executing the curl command, however, I'm open to other approaches. The method I've been using so far:


-----------------
These are lines snipped from a working application.  I make use of the httr package.  The 
parameters of the call are assembled as a nested list "xlist" prior to this section.  The 
set of errors I check for is unique to the API I'm talking to, an internal one that's a 
bit odd in its return codes, but still it gives you the idea.

     auth <- authenticate(id$lanid, id$password, type="basic")
     query <- POST(url=control$posturl, body= xlist, auth, encode="json")

     if (status_code(query) >= 300) handle_reset(control$posturl)
     if (status_code(query) == 401)
             stop("invalid lanid/password for this application")
     else if (status_code(query) == 400)
              stop("internal error from dart package: 'syntax of request'")
     else stop_for_status(query)  #other query errors, e.g. server down


From Stephen.Bond at cibc.com  Mon Apr  4 16:18:16 2016
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Mon, 4 Apr 2016 14:18:16 +0000
Subject: [R] minimal attributes to get se.fit
Message-ID: <624EC9773CAB044ABA65327271BED9B6186BAA81@CBMCC-X10-MA01.ad.cibc.com>

Does anybody know what are the attributes of a glm fit object that will allow the "predict call" to produce an se.fit?

I am deleting most of the attributes as the size of the final object is 5Gb and I want to reduce it to under 20Mb, but that causes as error when I ask for an se.fit .

mod.b$fitted.values <- 1:10
mod.b$prior.weights <- 1:10
mod.b$data <-mod.b$data[1:10,]
mod.b$residuals <- 1:10
mod.b$linear.predictors <- 1:10
mod.b$qr$qr <- mod.b$qr$qr[1:10,]
mod.b$effects <- mod.b$effects[1:100]
mod.b$weights <- mod.b$weights[1:100]
mod.b$model <- mod.b$model[1:10,]
mod.b$y <- mod.b$y[1:10]

p1 <- predict(mod.b,new=newdata,type="link",se.fit=T)
Error in Qr$qr[p1, p1, drop = FALSE] : subscript out of bounds

I believe the covariance matrix of the coefficients is all that should be needed and that is quite small. However, the covariance matrix is not an attribute of the model object.

Thanks everybody.

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Apr  4 16:32:24 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 4 Apr 2016 15:32:24 +0100
Subject: [R] minimal attributes to get se.fit
In-Reply-To: <624EC9773CAB044ABA65327271BED9B6186BAA81@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B6186BAA81@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D134CF8F@GBTEDVPEXCMB04.corp.lgc-group.com>

> Does anybody know what are the attributes of a glm fit object that will allow
> the "predict call" to produce an se.fit?
> 
>....
> 
> I believe the covariance matrix of the coefficients is all that should be needed
> and that is quite small. However, the covariance matrix is not an attribute of
> the model object.

Try saving the summary object? That includes the covariances (scaled and unscaled). See ?summary.glm. It might also leave you with a smaller object, though I'm not sure about that.

Also note that on this list, when prediction from glm comes up, there's a strong likelihood that someone will point out that the covariances are not necessarily sufficient for reliable confidence intervals on prediction (and look! that just happened). You might want to hunt around for more authoritative comment on that if the intervals/standard errors  are critical for something .


S Ellison





*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From tea3rd at gmail.com  Mon Apr  4 17:19:53 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Mon, 4 Apr 2016 10:19:53 -0500
Subject: [R] question about probplot in e1071 package
Message-ID: <CAGxgkWgrHJSEtNXmSJudsJYSYTd-TPfZ0uk=fGapKqZFsDGH_w@mail.gmail.com>

Hello!

I am using probplot in the e1071 package and want to do something like the
following, only with the the 2nd plot overlaying the first. I can't seem to
make it work. Any suggestions?

*library(e1071)
**x <- rnorm(100, mean=5)*

*y <- rnorm(100, mean=3)*

*probplot(x, line=FALSE)
*

*probplot(y, line=FALSE)
*

*Regards,*
*Tom*

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Mon Apr  4 18:00:14 2016
From: tea3rd at gmail.com (Thomas Adams)
Date: Mon, 4 Apr 2016 11:00:14 -0500
Subject: [R] question about probplot in e1071 package
In-Reply-To: <A4BA5778-7D36-426B-B835-A13B03C7945D@yahoo.es>
References: <CAGxgkWgrHJSEtNXmSJudsJYSYTd-TPfZ0uk=fGapKqZFsDGH_w@mail.gmail.com>
	<A4BA5778-7D36-426B-B835-A13B03C7945D@yahoo.es>
Message-ID: <CAGxgkWjgYdKciajXnymgdupj27gaecVfzk=MXPRrmc4rF637bg@mail.gmail.com>

Luisfo,

Thank you so much! That does what I need.

Best regards,
Tom

On Mon, Apr 4, 2016 at 10:51 AM, Luisfo Chiroque <luisfo89 at yahoo.es> wrote:

> Dear Thomas,
>
> Reading the probplot?s help page, it looks like it is using qqplot
> underneath.
> Thus, I think this is what you need.
> probplot(x, line=FALSE)
> #probplot(y, line=FALSE)
> qq.y <- qqnorm(y, plot=F)
> points(qq.y$y, qq.y$x)
>
> I hope this is useful for you.
>
> Best Regards,
>
> Luisfo Chiroque
>
> PhD Student
> IMDEA Networks Institute
>
> http://fourier.networks.imdea.org/people/~luis_nunez/
>
>
> El 4 abr 2016, a las 18:19, Thomas Adams <tea3rd at gmail.com> escribi?:
>
> Hello!
>
> I am using probplot in the e1071 package and want to do something like the
> following, only with the the 2nd plot overlaying the first. I can't seem to
> make it work. Any suggestions?
>
> *library(e1071)
> **x <- rnorm(100, mean=5)*
>
> *y <- rnorm(100, mean=3)*
>
> *probplot(x, line=FALSE)
> *
>
> *probplot(y, line=FALSE)
> *
>
> *Regards,*
> *Tom*
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From sdeepakrhelp at gmail.com  Mon Apr  4 10:40:06 2016
From: sdeepakrhelp at gmail.com (Deepak Singh)
Date: Mon, 4 Apr 2016 14:10:06 +0530
Subject: [R] Test for Homoscedesticity in R Without BP Test
Message-ID: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>

Respected Sir,
I am doing a project on multiple linear model fitting and in that project I
have to test Homoscedesticity of errors I have google for the same and
found bptest for the same but in R version 3.2.4 bp test is not available.
So please suggest me a test on homoscedesticity ASAP as we have to submit
our report on 7-04-2016.

P.S. : I have plotted residuals against fitted values and it is less or
more random.

Thank You !

	[[alternative HTML version deleted]]


From ld...... at .......com  Mon Apr  4 12:29:20 2016
From: ld...... at .......com (Louise D......)
Date: Mon, 4 Apr 2016 12:29:20 +0200 (CEST)
Subject: [R] Rcmdr loading issue
Message-ID: <40900915.188.1459765760779.JavaMail.zimbra@.......com>

Hi, 

I have a issue loading Rcmdr today. It is very strange, as I could get it to work last week on the same computer. 
I have tried restarting the computer, and re-installing R and XQuartz, but nothing changes. 

This is what I get: 





sessionInfo() 


R version 3.2.4 (2016-03-10) 
Platform: x86_64-apple-darwin13.4.0 (64-bit) 
Running under: OS X 10.11.4 (El Capitan) 

locale: 
[1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/fr_FR.UTF-8/fr_FR.UTF-8 

attached base packages: 
[1] stats graphics grDevices utils datasets methods base 

BQ_BEGIN
library(Rcmdr) 

BQ_END
Le chargement a n?cessit? le package : splines 
Le chargement a n?cessit? le package : RcmdrMisc 
Le chargement a n?cessit? le package : car 
Le chargement a n?cessit? le package : sandwich 
Error : .onAttach a ?chou? dans attachNamespace() pour 'Rcmdr', d?tails : 
appel : structure(.External(.C_dotTclObjv, objv), class = "tclObj") 
erreur : [tcl] invalid command name "image". 

De plus : Warning message: 
In fun(libname, pkgname) : couldn't connect to display ":0" 
Erreur : le chargement du package ou de l'espace de noms a ?chou? pour ?Rcmdr' 



Would you have a idea of what could be wrong ? 

Many thanks in advance, 
Louise 

	[[alternative HTML version deleted]]


From luisfo89 at yahoo.es  Mon Apr  4 17:51:51 2016
From: luisfo89 at yahoo.es (Luisfo Chiroque)
Date: Mon, 4 Apr 2016 18:51:51 +0300
Subject: [R] question about probplot in e1071 package
In-Reply-To: <CAGxgkWgrHJSEtNXmSJudsJYSYTd-TPfZ0uk=fGapKqZFsDGH_w@mail.gmail.com>
References: <CAGxgkWgrHJSEtNXmSJudsJYSYTd-TPfZ0uk=fGapKqZFsDGH_w@mail.gmail.com>
Message-ID: <A4BA5778-7D36-426B-B835-A13B03C7945D@yahoo.es>

Dear Thomas,

Reading the probplot?s help page, it looks like it is using qqplot underneath.
Thus, I think this is what you need.
	probplot(x, line=FALSE)
	#probplot(y, line=FALSE)
	qq.y <- qqnorm(y, plot=F)
	points(qq.y$y, qq.y$x)

I hope this is useful for you.

Best Regards,
Luisfo Chiroque
PhD Student
IMDEA Networks Institute
http://fourier.networks.imdea.org/people/~luis_nunez/ <http://fourier.networks.imdea.org/people/~luis_nunez/>
> El 4 abr 2016, a las 18:19, Thomas Adams <tea3rd at gmail.com> escribi?:
> 
> Hello!
> 
> I am using probplot in the e1071 package and want to do something like the
> following, only with the the 2nd plot overlaying the first. I can't seem to
> make it work. Any suggestions?
> 
> *library(e1071)
> **x <- rnorm(100, mean=5)*
> 
> *y <- rnorm(100, mean=3)*
> 
> *probplot(x, line=FALSE)
> *
> 
> *probplot(y, line=FALSE)
> *
> 
> *Regards,*
> *Tom*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From derek.janszen at precisionformedicine.com  Mon Apr  4 18:22:53 2016
From: derek.janszen at precisionformedicine.com (Janszen, Derek)
Date: Mon, 4 Apr 2016 16:22:53 +0000
Subject: [R] Evaluating an expression
Message-ID: <BE76EF5A817CD944A46453986593090B0637C8@465778-EXCHVM1.phmain.com>

Hi,

I want to create a data frame similar to the following, but greatly scaled up:
df <- data.frame(aaa= c("a","b","c"), integer(3), integer(3))
names(df)[2:3] <- paste("var",1:2,sep="")
which yields
  aaa  var1  var2
1   a     0     0
2   b     0     0
3   c     0     0

I would not relish having to paste 'integer(3)' 5000 times :(

So (I figure) there must be a way to do this programmatically, something akin to
exp1 <- paste(rep("integer(3)",2),collapse=',')
which looks like it might work:     "integer(3),integer(3)" , as in the following
df <- data.frame(aaa=xxx, eval(parse(text=exp1)))
but this yields

Error in parse(text = exp1) : <text>:1:11: unexpected ','

1: integer(3),

              ^


Not sure just why this doesn't work (?parse does not help), but it's not important right now.

I have used eval and parse in the past, but not in a way similar to what I'm trying to do now.



exp1 <- rep("integer(3)",2) gives "integer(3)" "integer(3)"

and upon parse(text=exp1) gives expression(integer(3), integer(3))

which appears to be promising, and does not give an error in the following

        df <- data.frame(aaa=xxx, eval(parse(text=exp1)))

but alas, does not give the desired result
  aaa eval.parse.text...exp1..
1   a                        0
2   b                        0
3   c                        0




I'm guessing that only the last evaluation of the expression is being evaluated, which I can understand.

I feel certain that what I want to accomplish can be done programmatically, but am at a loss as to just how to do that.
Chances are this has been covered before. If so, apologies.
If not, can anyone point me to references with more info than the help pages, or suggest a solution? :)

Thanks,
Derek

Derek Janszen, PhD
Statistician, Analytics

Precision for Medicine<http://www.precisionformedicine.com/>
8425 Progress Drive, Suite M | Frederick, MD 21701
+1 240 415 6004 office



The information contained in this email and any attachments is confidential and may be subject to copyright or other intellectual property protection. If you are not the intended recipient, you are not authorized to use or disclose this information, and we request that you notify us by reply mail or telephone and delete the original message from your mail system.

	[[alternative HTML version deleted]]


From jfzeac at gmail.com  Mon Apr  4 06:01:12 2016
From: jfzeac at gmail.com (=?UTF-8?Q?Jos=C3=A9_Fernando_Zea?=)
Date: Sun, 3 Apr 2016 23:01:12 -0500
Subject: [R] Using final sample weight in survey package
Message-ID: <CAM52pHyvz82kyV38ZPSHdunjXHUVRW7BdCAwgUcOeJ+Pb4-q8A@mail.gmail.com>

I have the final sample weight (expansion factor) from a socieconomic
survey. I don't know the exact design used in the study ( (probably is a
stratified two-stage design).

To illustrate my problem I will use the next dataset which have a sample
weight (but the design is not specified) and incorporate the design with
svydesign and create some bootstrap replicates in order to be able to
produce estimations.

Is that correct?:


load(url("http://knutur.at/wsmt/R/RData/small.RData"))
library(survey)
small.w <- svydesign(ids = ~1, data = small, weights = small$weight)
design<-as.svrepdesign(small.w,type="bootstrap", replicates=100)



Cordialmente
Jose F. Zea

	[[alternative HTML version deleted]]


From attenka at utu.fi  Mon Apr  4 06:45:30 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Mon, 04 Apr 2016 07:45:30 +0300
Subject: [R] Question about function DrawDensity3D {VecStatGraphs3D}
Message-ID: <5701F16A.5000502@utu.fi>

Hi,

Here is the function DrawDensity3D in package VecStatGraphs3D. My 
question is: if we use more layers than one, could we change the 
function in a way that in the final plot only the outmost layer is drawn 
(the inner layers omitted)?

Best regards,

Atte Tenkanen

function (vectors, Div = 40, Layers = 3, DrawAxes = FALSE)
{
     open3d(windowRect = c(100, 100, 800, 800))
     bg3d("white")
     Cx = vectors[, 1]
     Cy = vectors[, 2]
     Cz = vectors[, 3]
     Cr <- kde3d(x = Cx, y = Cy, z = Cz, n = Div)
     th <- seq(min(Cr$d), max(Cr$d), len = Layers + 2)
     ramp <- colorRamp(c("white", "yellow", "red"))
     colo <- rgb(ramp(seq(0, 1, length = Layers)), maxColorValue = 255)
     al <- seq(0.1, 0.6, len = Layers)
     module = sqrt(Cx * Cx + Cy * Cy + Cz * Cz)
     spheres3d(0, 0, 0, radius = max(module), color = "black",
         front = "line", back = "line", lwd = 1, smooth = TRUE,
         lit = TRUE, line_antialias = FALSE, alpha = 0.2)
     x <- c(0, max(module), 0, 0)
     y <- c(0, 0, max(module), 0)
     z <- c(0, 0, 0, max(module))
     labels <- c("", "X", "Y", "Z")
     i <- c(1, 2, 1, 3, 1, 4)
     text3d(x, y, z, labels, adj = 0.8, cex = 1.5, font = 2, color = 
"black")
     segments3d(x[i], y[i], z[i], lwd = 3)
     rgl.points(x = Cx, y = Cy, z = Cz, size = 3, color = "black")
     contour3d(Cr$d, level = th[c(-1, -(Layers + 2))], x = Cr$x,
         y = Cr$y, z = Cr$z, alpha = al, color = colo, add = TRUE,
         engine = "rgl", fill = TRUE, smooth = 2, material = "shiny")
     if (DrawAxes == TRUE) {
         axes3d()
     }
}


From normanmath1 at gmail.com  Mon Apr  4 06:57:02 2016
From: normanmath1 at gmail.com (Norman Pat)
Date: Mon, 4 Apr 2016 14:57:02 +1000
Subject: [R] R cases on predictive maintenance
Message-ID: <CACCLHAh9kDq7YFK8=zydM_y_GO7ygZt13N1KvgrGov18wcF_Ug@mail.gmail.com>

Hi Team,
      Can you please suggest me some good cases where we can use
R programming to tackle predictive maintenance problems

Many thanks

	[[alternative HTML version deleted]]


From emeline.mourocq at uzh.ch  Mon Apr  4 11:48:07 2016
From: emeline.mourocq at uzh.ch (emeline mourocq)
Date: Mon, 4 Apr 2016 11:48:07 +0200
Subject: [R] Fligner-Killeen test on binary data
Message-ID: <009301d18e57$1b08b730$511a2590$@uzh.ch>

Hello,

 

I investigate survival until the following year (0,1) and I wish to test if
the variance in survival for two or more groups are significantly different
from each other.

 

I read that the Fligner-Killeen test is a non-parametric test which is very
robust against departures from normality but is it correct (valuable
technique for publication) to use it on binary data?

 

In other words, can I use
fligner.test(survival~categorical_predictor,data=mydata) when survival is
binary (0,1)?

 

Best regards

Emeline

 



---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From letter at openmailbox.org  Mon Apr  4 13:00:01 2016
From: letter at openmailbox.org (message)
Date: Mon, 04 Apr 2016 11:00:01 +0000
Subject: [R] multiple bar plot annotation text labelling
Message-ID: <130efe144c2b73775f9d465cd84215d1@openmailbox.org>

Readers,

The attempt is to create a bar plot with text labels adjacent to each 
datum value.

Data file:
1,3,A
1,8,B
1,1,C
1,9,D
2,5,C
2,4,E
2,2,F
2,0,G

testbarplot<-read.csv('data1.csv', header=FALSE)
barplot(axes=FALSE, ann=FALSE, horiz=TRUE, testbarplot[,2], ylab= 
'group', xlab= '(x values)', space=c(1,0,0,0, 1,0,0,0))
text(testbarplot[,2], testbarplot[,1], c('a', 'b', 'c', 'd', 'c', 'e', 
'f', 'g'), pos=4)

Why does the text labels only appear for the lower half group of bar 
plot values?

Below is an example of the type of graph that is being sought. It is svg 
text exported from libreoffice calc that should be saved as a separate 
file and viewable in any svg viewer such as a web browser or a tool such 
as 'eye of gnome'.

<?xml version="1.0" encoding="UTF-8"?>

<svg version="1.2" baseProfile="tiny" width="115.01mm" height="126.01mm" 
viewBox="1200 2000 11501 12601" preserveAspectRatio="xMidYMid" 
fill-rule="evenodd" stroke-width="28.222" stroke-linejoin="round" 
xmlns="http://www.w3.org/2000/svg" 
xmlns:ooo="http://xml.openoffice.org/svg/export" 
xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve">
  <defs class="ClipPathGroup">
   <clipPath id="presentation_clip_path" clipPathUnits="userSpaceOnUse">
    <rect x="1200" y="2000" width="11501" height="12601"/>
   </clipPath>
  </defs>
  <defs>
   <font id="EmbeddedFont_1" horiz-adv-x="2048">
    <font-face font-family="Liberation Sans embedded" units-per-em="2048" 
font-weight="normal" font-style="normal" ascent="1852" descent="423"/>
    <missing-glyph horiz-adv-x="2048" d="M 0,0 L 2047,0 2047,2047 0,2047 
0,0 Z"/>
    <glyph unicode="1" horiz-adv-x="927" d="M 156,0 L 156,153 515,153 
515,1237 197,1010 197,1180 530,1409 696,1409 696,153 1039,153 1039,0 
156,0 Z"/>
   </font>
  </defs>
  <defs class="TextShapeIndex">
   <g ooo:slide="id1" ooo:id-list="id3 id4 id5 id6 id7 id8 id9 id10 id11 
id12 id13 id14 id15 id16 id17 id18 id19 id20 id21"/>
  </defs>
  <defs class="EmbeddedBulletChars">
   <g id="bullet-char-template(57356)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 580,1141 L 1163,571 580,0 -4,571 580,1141 Z"/>
   </g>
   <g id="bullet-char-template(57354)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 8,1128 L 1137,1128 1137,0 8,0 8,1128 Z"/>
   </g>
   <g id="bullet-char-template(10146)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 174,0 L 602,739 174,1481 1456,739 174,0 Z M 1358,739 L 
309,1346 659,739 1358,739 Z"/>
   </g>
   <g id="bullet-char-template(10132)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 2015,739 L 1276,0 717,0 1260,543 174,543 174,936 1260,936 
717,1481 1274,1481 2015,739 Z"/>
   </g>
   <g id="bullet-char-template(10007)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 0,-2 C -7,14 -16,27 -25,37 L 356,567 C 262,823 215,952 
215,954 215,979 228,992 255,992 264,992 276,990 289,987 310,991 331,999 
354,1012 L 381,999 492,748 772,1049 836,1024 860,1049 C 881,1039 
901,1025 922,1006 886,937 835,863 770,784 769,783 710,716 594,584 L 
774,223 C 774,196 753,168 711,139 L 727,119 C 717,90 699,76 672,76 
641,76 570,178 457,381 L 164,-76 C 142,-110 111,-127 72,-127 30,-127 
9,-110 8,-76 1,-67 -2,-52 -2,-32 -2,-23 -1,-13 0,-2 Z"/>
   </g>
   <g id="bullet-char-template(10004)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 285,-33 C 182,-33 111,30 74,156 52,228 41,333 41,471 
41,549 55,616 82,672 116,743 169,778 240,778 293,778 328,747 346,684 L 
369,508 C 377,444 397,411 428,410 L 1163,1116 C 1174,1127 1196,1133 
1229,1133 1271,1133 1292,1118 1292,1087 L 1292,965 C 1292,929 1282,901 
1262,881 L 442,47 C 390,-6 338,-33 285,-33 Z"/>
   </g>
   <g id="bullet-char-template(9679)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 813,0 C 632,0 489,54 383,161 276,268 223,411 223,592 
223,773 276,916 383,1023 489,1130 632,1184 813,1184 992,1184 1136,1130 
1245,1023 1353,916 1407,772 1407,592 1407,412 1353,268 1245,161 1136,54 
992,0 813,0 Z"/>
   </g>
   <g id="bullet-char-template(8226)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 346,457 C 273,457 209,483 155,535 101,586 74,649 74,723 
74,796 101,859 155,911 209,963 273,989 346,989 419,989 480,963 531,910 
582,859 608,796 608,723 608,648 583,586 532,535 482,483 420,457 346,457 
Z"/>
   </g>
   <g id="bullet-char-template(8211)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M -4,459 L 1135,459 1135,606 -4,606 -4,459 Z"/>
   </g>
  </defs>
  <defs class="TextEmbeddedBitmaps"/>
  <g class="SlideGroup">
   <g>
    <g id="id1" class="Slide" clip-path="url(#presentation_clip_path)">
     <g class="Page">
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id3">
        <path fill="rgb(114,159,207)" stroke="none" d="M 4350,3000 L 
3000,3000 3000,2100 5700,2100 5700,3000 4350,3000 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 4350,3000 L 
3000,3000 3000,2100 5700,2100 5700,3000 4350,3000 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id4">
        <path fill="rgb(114,159,207)" stroke="none" d="M 5350,3900 L 
3000,3900 3000,3000 7700,3000 7700,3900 5350,3900 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 5350,3900 L 
3000,3900 3000,3000 7700,3000 7700,3900 5350,3900 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id5">
        <path fill="rgb(114,159,207)" stroke="none" d="M 3800,4800 L 
3000,4800 3000,3900 4600,3900 4600,4800 3800,4800 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 3800,4800 L 
3000,4800 3000,3900 4600,3900 4600,4800 3800,4800 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id6">
        <path fill="rgb(114,159,207)" stroke="none" d="M 7850,5700 L 
3000,5700 3000,4800 12700,4800 12700,5700 7850,5700 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 7850,5700 L 
3000,5700 3000,4800 12700,4800 12700,5700 7850,5700 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id7">
        <path fill="rgb(114,159,207)" stroke="none" d="M 4350,7500 L 
3000,7500 3000,6600 5700,6600 5700,7500 4350,7500 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 4350,7500 L 
3000,7500 3000,6600 5700,6600 5700,7500 4350,7500 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id8">
        <path fill="rgb(114,159,207)" stroke="none" d="M 5350,8400 L 
3000,8400 3000,7500 7700,7500 7700,8400 5350,8400 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 5350,8400 L 
3000,8400 3000,7500 7700,7500 7700,8400 5350,8400 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id9">
        <path fill="rgb(114,159,207)" stroke="none" d="M 3800,9300 L 
3000,9300 3000,8400 4600,8400 4600,9300 3800,9300 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 3800,9300 L 
3000,9300 3000,8400 4600,8400 4600,9300 3800,9300 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id10">
        <path fill="rgb(114,159,207)" stroke="none" d="M 7850,10200 L 
3000,10200 3000,9300 12700,9300 12700,10200 7850,10200 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 7850,10200 L 
3000,10200 3000,9300 12700,9300 12700,10200 7850,10200 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id11">
        <path fill="rgb(114,159,207)" stroke="none" d="M 4350,11900 L 
3000,11900 3000,11000 5700,11000 5700,11900 4350,11900 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 4350,11900 L 
3000,11900 3000,11000 5700,11000 5700,11900 4350,11900 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id12">
        <path fill="rgb(114,159,207)" stroke="none" d="M 5350,12800 L 
3000,12800 3000,11900 7700,11900 7700,12800 5350,12800 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 5350,12800 L 
3000,12800 3000,11900 7700,11900 7700,12800 5350,12800 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id13">
        <path fill="rgb(114,159,207)" stroke="none" d="M 3800,13700 L 
3000,13700 3000,12800 4600,12800 4600,13700 3800,13700 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 3800,13700 L 
3000,13700 3000,12800 4600,12800 4600,13700 3800,13700 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id14">
        <path fill="rgb(114,159,207)" stroke="none" d="M 7850,14600 L 
3000,14600 3000,13700 12700,13700 12700,14600 7850,14600 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 7850,14600 L 
3000,14600 3000,13700 12700,13700 12700,14600 7850,14600 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id15">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2500,2000 L 
2400,14600"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id16">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2500,3900 L 
2000,3900"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id17">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2450,8400 L 
1950,8400"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id18">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2450,12900 L 
1950,12900"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.TextShape">
       <g id="id19">
        <text class="TextShape"><tspan class="TextParagraph" 
font-family="Liberation Sans, sans-serif" font-size="635px" 
font-weight="400"><tspan class="TextPosition" x="1450" y="4201"/><tspan 
class="TextPosition" x="1450" y="4201"><tspan fill="rgb(0,0,0)" 
stroke="none">1</tspan></tspan></tspan></text>
       </g>
      </g>
      <g class="com.sun.star.drawing.TextShape">
       <g id="id20">
        <text class="TextShape"><tspan class="TextParagraph" 
font-family="Liberation Sans, sans-serif" font-size="635px" 
font-weight="400"><tspan class="TextPosition" x="1451" y="8701"/><tspan 
class="TextPosition" x="1451" y="8701"><tspan fill="rgb(0,0,0)" 
stroke="none">1</tspan></tspan></tspan></text>
       </g>
      </g>
      <g class="com.sun.star.drawing.TextShape">
       <g id="id21">
        <text class="TextShape"><tspan class="TextParagraph" 
font-family="Liberation Sans, sans-serif" font-size="635px" 
font-weight="400"><tspan class="TextPosition" x="1452" y="13201"/><tspan 
class="TextPosition" x="1452" y="13201"><tspan fill="rgb(0,0,0)" 
stroke="none">1</tspan></tspan></tspan></text>
       </g>
      </g>
     </g>
    </g>
   </g>
  </g>
</svg>


From ajdamico at gmail.com  Mon Apr  4 18:35:39 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Mon, 4 Apr 2016 12:35:39 -0400
Subject: [R] Using final sample weight in survey package
In-Reply-To: <CAM52pHyvz82kyV38ZPSHdunjXHUVRW7BdCAwgUcOeJ+Pb4-q8A@mail.gmail.com>
References: <CAM52pHyvz82kyV38ZPSHdunjXHUVRW7BdCAwgUcOeJ+Pb4-q8A@mail.gmail.com>
Message-ID: <CAOwvMDy5uwA8xVpQi+gVSP4Phtou6QiP3naGTuUrovyRb85byA@mail.gmail.com>

hi, probably not..  if your survey dataset has a complex design (like
clusters/strata), you need to include them in the `svydesign` call.
coercing an incorrect survey design into a replicate-weighted design will
not fix the problem of failing to account for the sampling strategy

On Mon, Apr 4, 2016 at 12:01 AM, Jos? Fernando Zea <jfzeac at gmail.com> wrote:

> I have the final sample weight (expansion factor) from a socieconomic
> survey. I don't know the exact design used in the study ( (probably is a
> stratified two-stage design).
>
> To illustrate my problem I will use the next dataset which have a sample
> weight (but the design is not specified) and incorporate the design with
> svydesign and create some bootstrap replicates in order to be able to
> produce estimations.
>
> Is that correct?:
>
>
> load(url("http://knutur.at/wsmt/R/RData/small.RData"))
> library(survey)
> small.w <- svydesign(ids = ~1, data = small, weights = small$weight)
> design<-as.svrepdesign(small.w,type="bootstrap", replicates=100)
>
>
>
> Cordialmente
> Jose F. Zea
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Apr  4 18:50:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 4 Apr 2016 09:50:44 -0700
Subject: [R] Evaluating an expression
In-Reply-To: <BE76EF5A817CD944A46453986593090B0637C8@465778-EXCHVM1.phmain.com>
References: <BE76EF5A817CD944A46453986593090B0637C8@465778-EXCHVM1.phmain.com>
Message-ID: <2B7C565C-0BD8-40BE-B24B-B9CE74308901@comcast.net>


> On Apr 4, 2016, at 9:22 AM, Janszen, Derek <derek.janszen at precisionformedicine.com> wrote:
> 
> Hi,
> 
> I want to create a data frame similar to the following, but greatly scaled up:
> df <- data.frame(aaa= c("a","b","c"), integer(3), integer(3))
> names(df)[2:3] <- paste("var",1:2,sep="")
> which yields
>  aaa  var1  var2
> 1   a     0     0
> 2   b     0     0
> 3   c     0     0
> 

> setNames( data.frame( rep(list( 1:3), 5) ) , paste0("V", 1:5) )
  V1 V2 V3 V4 V5
1  1  1  1  1  1
2  2  2  2  2  2
3  3  3  3  3  3

Or:

> data.frame( c( list( 'a'=letters[1:3] ), rep(list('x'=integer(3) ), 5) ))
  a x x.1 x.2 x.3 x.4
1 a 0   0   0   0   0
2 b 0   0   0   0   0
3 c 0   0   0   0   0


Just replace the 3's and 5's with a number (possibly delivered via a named numeric vector of length-1) of your choosing.

-- 
David.

> I would not relish having to paste 'integer(3)' 5000 times :(
> 
> So (I figure) there must be a way to do this programmatically, something akin to
> exp1 <- paste(rep("integer(3)",2),collapse=',')
> which looks like it might work:     "integer(3),integer(3)" , as in the following
> df <- data.frame(aaa=xxx, eval(parse(text=exp1)))
> but this yields
> 
> Error in parse(text = exp1) : <text>:1:11: unexpected ','
> 
> 1: integer(3),
> 
>              ^
> 
> 
> Not sure just why this doesn't work (?parse does not help), but it's not important right now.
> 
> I have used eval and parse in the past, but not in a way similar to what I'm trying to do now.
> 
> 
> 
> exp1 <- rep("integer(3)",2) gives "integer(3)" "integer(3)"
> 
> and upon parse(text=exp1) gives expression(integer(3), integer(3))
> 
> which appears to be promising, and does not give an error in the following
> 
>        df <- data.frame(aaa=xxx, eval(parse(text=exp1)))
> 
> but alas, does not give the desired result
>  aaa eval.parse.text...exp1..
> 1   a                        0
> 2   b                        0
> 3   c                        0
> 
> 
> 
> 
> I'm guessing that only the last evaluation of the expression is being evaluated, which I can understand.
> 
> I feel certain that what I want to accomplish can be done programmatically, but am at a loss as to just how to do that.
> Chances are this has been covered before. If so, apologies.
> If not, can anyone point me to references with more info than the help pages, or suggest a solution? :)
> 
> Thanks,
> Derek
> 
> Derek Janszen, PhD
> Statistician, Analytics
> 
> Precision for Medicine<http://www.precisionformedicine.com/>
> 8425 Progress Drive, Suite M | Frederick, MD 21701
> +1 240 415 6004 office
> 
> 
> 
> The information contained in this email and any attachments is confidential and may be subject to copyright or other intellectual property protection. If you are not the intended recipient, you are not authorized to use or disclose this information, and we request that you notify us by reply mail or telephone and delete the original message from your mail system.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Mon Apr  4 18:51:39 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 4 Apr 2016 09:51:39 -0700
Subject: [R] Evaluating an expression
In-Reply-To: <BE76EF5A817CD944A46453986593090B0637C8@465778-EXCHVM1.phmain.com>
References: <BE76EF5A817CD944A46453986593090B0637C8@465778-EXCHVM1.phmain.com>
Message-ID: <CAGxFJbQV_RXu105uEGmKdLSrS6Y7Pq7Lc8jJJT+EnC_m1pKNNA@mail.gmail.com>

I think you need to spend some time with an R tutorial or two to learn
how to handle such basics yourself.

However, if I understand correctly, probably the easiest way to do it
is by converting a matrix of 0's to a data frame -- which you
shouldn't do at all if you can do your analysis directly with the
matrix (it's almost always faster, sometimes considerably so). e.g.

adf <- data.frame(matrix(0, nrow=10,ncol=20))

Of course, you may then wish to provide more informative names for
your columns via the names() function.

Also, I would question whether you need to do any of this in the first
place. It is rarely necessary in R to initialize a data frame or
matrix.

Finally, you should almost never need the eval(parse()) construction,
which treats R as a macro language instead of taking advantage of its
functional programming paradigm. Again, the of sort thing that good R
tutorials can help you with. There are many on the web. Some good
recommendations can be found here:

https://www.rstudio.com/online-learning/#R

HTH,

Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 4, 2016 at 9:22 AM, Janszen, Derek
<derek.janszen at precisionformedicine.com> wrote:
> Hi,
>
> I want to create a data frame similar to the following, but greatly scaled up:
> df <- data.frame(aaa= c("a","b","c"), integer(3), integer(3))
> names(df)[2:3] <- paste("var",1:2,sep="")
> which yields
>   aaa  var1  var2
> 1   a     0     0
> 2   b     0     0
> 3   c     0     0
>
> I would not relish having to paste 'integer(3)' 5000 times :(
>
> So (I figure) there must be a way to do this programmatically, something akin to
> exp1 <- paste(rep("integer(3)",2),collapse=',')
> which looks like it might work:     "integer(3),integer(3)" , as in the following
> df <- data.frame(aaa=xxx, eval(parse(text=exp1)))
> but this yields
>
> Error in parse(text = exp1) : <text>:1:11: unexpected ','
>
> 1: integer(3),
>
>               ^
>
>
> Not sure just why this doesn't work (?parse does not help), but it's not important right now.
>
> I have used eval and parse in the past, but not in a way similar to what I'm trying to do now.
>
>
>
> exp1 <- rep("integer(3)",2) gives "integer(3)" "integer(3)"
>
> and upon parse(text=exp1) gives expression(integer(3), integer(3))
>
> which appears to be promising, and does not give an error in the following
>
>         df <- data.frame(aaa=xxx, eval(parse(text=exp1)))
>
> but alas, does not give the desired result
>   aaa eval.parse.text...exp1..
> 1   a                        0
> 2   b                        0
> 3   c                        0
>
>
>
>
> I'm guessing that only the last evaluation of the expression is being evaluated, which I can understand.
>
> I feel certain that what I want to accomplish can be done programmatically, but am at a loss as to just how to do that.
> Chances are this has been covered before. If so, apologies.
> If not, can anyone point me to references with more info than the help pages, or suggest a solution? :)
>
> Thanks,
> Derek
>
> Derek Janszen, PhD
> Statistician, Analytics
>
> Precision for Medicine<http://www.precisionformedicine.com/>
> 8425 Progress Drive, Suite M | Frederick, MD 21701
> +1 240 415 6004 office
>
>
>
> The information contained in this email and any attachments is confidential and may be subject to copyright or other intellectual property protection. If you are not the intended recipient, you are not authorized to use or disclose this information, and we request that you notify us by reply mail or telephone and delete the original message from your mail system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Apr  4 18:55:21 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 4 Apr 2016 09:55:21 -0700
Subject: [R] Using final sample weight in survey package
In-Reply-To: <CAOwvMDy5uwA8xVpQi+gVSP4Phtou6QiP3naGTuUrovyRb85byA@mail.gmail.com>
References: <CAM52pHyvz82kyV38ZPSHdunjXHUVRW7BdCAwgUcOeJ+Pb4-q8A@mail.gmail.com>
	<CAOwvMDy5uwA8xVpQi+gVSP4Phtou6QiP3naGTuUrovyRb85byA@mail.gmail.com>
Message-ID: <CAGxFJbQLxwZV2kQ4LF=pNaJA=c2m0cd42d=hw9tqzLOukwRH7g@mail.gmail.com>

On Mon, Apr 4, 2016 at 9:35 AM, Anthony Damico <ajdamico at gmail.com> wrote:
> hi, probably not..  if your survey dataset has a complex design (like
> clusters/strata), you need to include them in the `svydesign` call.


> Coercing an incorrect survey design into a replicate-weighted design will
> not fix the problem of failing to account for the sampling strategy.

Amen, Anthony!

I would say **Fortune Nomination!** -- except that this may be a bit
too technical and statistical. But it's well said, nevertheless.

Thanks.

-- Bert



>
> On Mon, Apr 4, 2016 at 12:01 AM, Jos? Fernando Zea <jfzeac at gmail.com> wrote:
>
>> I have the final sample weight (expansion factor) from a socieconomic
>> survey. I don't know the exact design used in the study ( (probably is a
>> stratified two-stage design).
>>
>> To illustrate my problem I will use the next dataset which have a sample
>> weight (but the design is not specified) and incorporate the design with
>> svydesign and create some bootstrap replicates in order to be able to
>> produce estimations.
>>
>> Is that correct?:
>>
>>
>> load(url("http://knutur.at/wsmt/R/RData/small.RData"))
>> library(survey)
>> small.w <- svydesign(ids = ~1, data = small, weights = small$weight)
>> design<-as.svrepdesign(small.w,type="bootstrap", replicates=100)
>>
>>
>>
>> Cordialmente
>> Jose F. Zea
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Apr  4 19:10:58 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 4 Apr 2016 19:10:58 +0200
Subject: [R] Fligner-Killeen test on binary data
In-Reply-To: <009301d18e57$1b08b730$511a2590$@uzh.ch>
References: <009301d18e57$1b08b730$511a2590$@uzh.ch>
Message-ID: <D9116C24-F04D-43FD-8C1F-895D036F5207@gmail.com>

That's not an R question but a stats question, but I wouldn't do it. For one thing: The variance of binary data is a function of the mean, so the research question is dubious in the first place. Secondly, the test is based on ranking and comparing absolute differences from the group median, which for binary data is generally 0 or 1, so all absolute differences will be 1.... Put differently, the results are more than likely to be complet rubbish.

-pd 

> On 04 Apr 2016, at 11:48 , emeline mourocq <emeline.mourocq at uzh.ch> wrote:
> 
> Hello,
> 
> 
> 
> I investigate survival until the following year (0,1) and I wish to test if
> the variance in survival for two or more groups are significantly different
> from each other.
> 
> 
> 
> I read that the Fligner-Killeen test is a non-parametric test which is very
> robust against departures from normality but is it correct (valuable
> technique for publication) to use it on binary data?
> 
> 
> 
> In other words, can I use
> fligner.test(survival~categorical_predictor,data=mydata) when survival is
> binary (0,1)?
> 
> 
> 
> Best regards
> 
> Emeline
> 
> 
> 
> 
> 
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter.4567 at gmail.com  Mon Apr  4 19:48:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 4 Apr 2016 10:48:14 -0700
Subject: [R] Fligner-Killeen test on binary data
In-Reply-To: <D9116C24-F04D-43FD-8C1F-895D036F5207@gmail.com>
References: <009301d18e57$1b08b730$511a2590$@uzh.ch>
	<D9116C24-F04D-43FD-8C1F-895D036F5207@gmail.com>
Message-ID: <CAGxFJbSrFXeyqR5tVsz=JCyS5mV2eDDwgJ0r+45T+uFEUzUurQ@mail.gmail.com>

Peter: Bravo!


On Mon, Apr 4, 2016 at 10:10 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> That's not an R question but a stats question, but I wouldn't do it. For one thing: The variance of binary data is a function of the mean, so the research question is dubious in the first place. Secondly, the test is based on ranking and comparing absolute differences from the group median, which for binary data is generally 0 or 1, so all absolute differences will be 1....



"Put differently, the results are more than likely to be complete rubbish."

Again, probably not appropriate, but anyway:
Fortune Nomination!

Cheers,
Bert


>
> -pd
>
>> On 04 Apr 2016, at 11:48 , emeline mourocq <emeline.mourocq at uzh.ch> wrote:
>>
>> Hello,
>>
>>
>>
>> I investigate survival until the following year (0,1) and I wish to test if
>> the variance in survival for two or more groups are significantly different
>> from each other.
>>
>>
>>
>> I read that the Fligner-Killeen test is a non-parametric test which is very
>> robust against departures from normality but is it correct (valuable
>> technique for publication) to use it on binary data?
>>
>>
>>
>> In other words, can I use
>> fligner.test(survival~categorical_predictor,data=mydata) when survival is
>> binary (0,1)?
>>
>>
>>
>> Best regards
>>
>> Emeline
>>
>>
>>
>>
>>
>> ---
>> This email has been checked for viruses by Avast antivirus software.
>> https://www.avast.com/antivirus
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From emeline.mourocq at uzh.ch  Mon Apr  4 19:25:32 2016
From: emeline.mourocq at uzh.ch (emeline mourocq)
Date: Mon, 4 Apr 2016 19:25:32 +0200
Subject: [R] Fligner-Killeen test on binary data
In-Reply-To: <D9116C24-F04D-43FD-8C1F-895D036F5207@gmail.com>
References: <009301d18e57$1b08b730$511a2590$@uzh.ch>
	<D9116C24-F04D-43FD-8C1F-895D036F5207@gmail.com>
Message-ID: <004e01d18e96$ff27c4d0$fd774e70$@uzh.ch>

Thanks for all those information. I then have to find another way to test
difference in variance between my two groups.

-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: Monday, 4 April, 2016 7:11 PM
To: emeline mourocq <emeline.mourocq at uzh.ch>
Cc: r-help at r-project.org
Subject: Re: [R] Fligner-Killeen test on binary data

That's not an R question but a stats question, but I wouldn't do it. For one
thing: The variance of binary data is a function of the mean, so the
research question is dubious in the first place. Secondly, the test is based
on ranking and comparing absolute differences from the group median, which
for binary data is generally 0 or 1, so all absolute differences will be
1.... Put differently, the results are more than likely to be complet
rubbish.

-pd 

> On 04 Apr 2016, at 11:48 , emeline mourocq <emeline.mourocq at uzh.ch> wrote:
> 
> Hello,
> 
> 
> 
> I investigate survival until the following year (0,1) and I wish to 
> test if the variance in survival for two or more groups are 
> significantly different from each other.
> 
> 
> 
> I read that the Fligner-Killeen test is a non-parametric test which is 
> very robust against departures from normality but is it correct 
> (valuable technique for publication) to use it on binary data?
> 
> 
> 
> In other words, can I use
> fligner.test(survival~categorical_predictor,data=mydata) when survival 
> is binary (0,1)?
> 
> 
> 
> Best regards
> 
> Emeline
> 
> 
> 
> 
> 
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com











---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From dcarlson at tamu.edu  Mon Apr  4 19:57:52 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 4 Apr 2016 17:57:52 +0000
Subject: [R] multiple bar plot annotation text labelling
In-Reply-To: <130efe144c2b73775f9d465cd84215d1@openmailbox.org>
References: <130efe144c2b73775f9d465cd84215d1@openmailbox.org>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D729126@mb02.ads.tamu.edu>

Use only plain text emails. Don't attach file types that will be stripped. See the footer at the bottom of your email for more information.

Do give us the data using dput():
> dput(testbarplot)
structure(list(V1 = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L), V2 = c(3L, 
8L, 1L, 9L, 5L, 4L, 2L, 0L), V3 = structure(c(1L, 2L, 3L, 4L, 
3L, 5L, 6L, 7L), .Label = c("A", "B", "C", "D", "E", "F", "G"
), class = "factor")), .Names = c("V1", "V2", "V3"), class = "data.frame", row.names = c(NA, 
-8L))

I think this will get you what you want:

> barplot(testbarplot[,2], axes=FALSE, ann=FALSE, horiz=TRUE, ylab= 'group',
+ xlab= '(x values)', space=c(1,0,0,0, 1,0,0,0), names.arg=testbarplot[, 3],
+ las=1)


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of message
Sent: Monday, April 4, 2016 6:00 AM
To: r-help at r-project.org
Subject: [R] multiple bar plot annotation text labelling

Readers,

The attempt is to create a bar plot with text labels adjacent to each 
datum value.

Data file:
1,3,A
1,8,B
1,1,C
1,9,D
2,5,C
2,4,E
2,2,F
2,0,G

testbarplot<-read.csv('data1.csv', header=FALSE)
barplot(axes=FALSE, ann=FALSE, horiz=TRUE, testbarplot[,2], ylab= 
'group', xlab= '(x values)', space=c(1,0,0,0, 1,0,0,0))
text(testbarplot[,2], testbarplot[,1], c('a', 'b', 'c', 'd', 'c', 'e', 
'f', 'g'), pos=4)

Why does the text labels only appear for the lower half group of bar 
plot values?

Below is an example of the type of graph that is being sought. It is svg 
text exported from libreoffice calc that should be saved as a separate 
file and viewable in any svg viewer such as a web browser or a tool such 
as 'eye of gnome'.

<?xml version="1.0" encoding="UTF-8"?>

<svg version="1.2" baseProfile="tiny" width="115.01mm" height="126.01mm" 
viewBox="1200 2000 11501 12601" preserveAspectRatio="xMidYMid" 
fill-rule="evenodd" stroke-width="28.222" stroke-linejoin="round" 
xmlns="http://www.w3.org/2000/svg" 
xmlns:ooo="http://xml.openoffice.org/svg/export" 
xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve">
  <defs class="ClipPathGroup">
   <clipPath id="presentation_clip_path" clipPathUnits="userSpaceOnUse">
    <rect x="1200" y="2000" width="11501" height="12601"/>
   </clipPath>
  </defs>
  <defs>
   <font id="EmbeddedFont_1" horiz-adv-x="2048">
    <font-face font-family="Liberation Sans embedded" units-per-em="2048" 
font-weight="normal" font-style="normal" ascent="1852" descent="423"/>
    <missing-glyph horiz-adv-x="2048" d="M 0,0 L 2047,0 2047,2047 0,2047 
0,0 Z"/>
    <glyph unicode="1" horiz-adv-x="927" d="M 156,0 L 156,153 515,153
515,1237 197,1010 197,1180 530,1409 696,1409 696,153 1039,153 1039,0 
156,0 Z"/>
   </font>
  </defs>
  <defs class="TextShapeIndex">
   <g ooo:slide="id1" ooo:id-list="id3 id4 id5 id6 id7 id8 id9 id10 id11 
id12 id13 id14 id15 id16 id17 id18 id19 id20 id21"/>
  </defs>
  <defs class="EmbeddedBulletChars">
   <g id="bullet-char-template(57356)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 580,1141 L 1163,571 580,0 -4,571 580,1141 Z"/>
   </g>
   <g id="bullet-char-template(57354)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 8,1128 L 1137,1128 1137,0 8,0 8,1128 Z"/>
   </g>
   <g id="bullet-char-template(10146)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 174,0 L 602,739 174,1481 1456,739 174,0 Z M 1358,739 L 
309,1346 659,739 1358,739 Z"/>
   </g>
   <g id="bullet-char-template(10132)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 2015,739 L 1276,0 717,0 1260,543 174,543 174,936 1260,936
717,1481 1274,1481 2015,739 Z"/>
   </g>
   <g id="bullet-char-template(10007)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 0,-2 C -7,14 -16,27 -25,37 L 356,567 C 262,823 215,952 
215,954 215,979 228,992 255,992 264,992 276,990 289,987 310,991 331,999 
354,1012 L 381,999 492,748 772,1049 836,1024 860,1049 C 881,1039 
901,1025 922,1006 886,937 835,863 770,784 769,783 710,716 594,584 L 
774,223 C 774,196 753,168 711,139 L 727,119 C 717,90 699,76 672,76 
641,76 570,178 457,381 L 164,-76 C 142,-110 111,-127 72,-127 30,-127 
9,-110 8,-76 1,-67 -2,-52 -2,-32 -2,-23 -1,-13 0,-2 Z"/>
   </g>
   <g id="bullet-char-template(10004)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 285,-33 C 182,-33 111,30 74,156 52,228 41,333 41,471 
41,549 55,616 82,672 116,743 169,778 240,778 293,778 328,747 346,684 L 
369,508 C 377,444 397,411 428,410 L 1163,1116 C 1174,1127 1196,1133 
1229,1133 1271,1133 1292,1118 1292,1087 L 1292,965 C 1292,929 1282,901 
1262,881 L 442,47 C 390,-6 338,-33 285,-33 Z"/>
   </g>
   <g id="bullet-char-template(9679)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 813,0 C 632,0 489,54 383,161 276,268 223,411 223,592 
223,773 276,916 383,1023 489,1130 632,1184 813,1184 992,1184 1136,1130 
1245,1023 1353,916 1407,772 1407,592 1407,412 1353,268 1245,161 1136,54 
992,0 813,0 Z"/>
   </g>
   <g id="bullet-char-template(8226)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M 346,457 C 273,457 209,483 155,535 101,586 74,649 74,723 
74,796 101,859 155,911 209,963 273,989 346,989 419,989 480,963 531,910 
582,859 608,796 608,723 608,648 583,586 532,535 482,483 420,457 346,457 
Z"/>
   </g>
   <g id="bullet-char-template(8211)" 
transform="scale(0.00048828125,-0.00048828125)">
    <path d="M -4,459 L 1135,459 1135,606 -4,606 -4,459 Z"/>
   </g>
  </defs>
  <defs class="TextEmbeddedBitmaps"/>
  <g class="SlideGroup">
   <g>
    <g id="id1" class="Slide" clip-path="url(#presentation_clip_path)">
     <g class="Page">
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id3">
        <path fill="rgb(114,159,207)" stroke="none" d="M 4350,3000 L
3000,3000 3000,2100 5700,2100 5700,3000 4350,3000 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 4350,3000 L 
3000,3000 3000,2100 5700,2100 5700,3000 4350,3000 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id4">
        <path fill="rgb(114,159,207)" stroke="none" d="M 5350,3900 L
3000,3900 3000,3000 7700,3000 7700,3900 5350,3900 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 5350,3900 L 
3000,3900 3000,3000 7700,3000 7700,3900 5350,3900 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id5">
        <path fill="rgb(114,159,207)" stroke="none" d="M 3800,4800 L
3000,4800 3000,3900 4600,3900 4600,4800 3800,4800 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 3800,4800 L 
3000,4800 3000,3900 4600,3900 4600,4800 3800,4800 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id6">
        <path fill="rgb(114,159,207)" stroke="none" d="M 7850,5700 L
3000,5700 3000,4800 12700,4800 12700,5700 7850,5700 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 7850,5700 L 
3000,5700 3000,4800 12700,4800 12700,5700 7850,5700 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id7">
        <path fill="rgb(114,159,207)" stroke="none" d="M 4350,7500 L
3000,7500 3000,6600 5700,6600 5700,7500 4350,7500 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 4350,7500 L 
3000,7500 3000,6600 5700,6600 5700,7500 4350,7500 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id8">
        <path fill="rgb(114,159,207)" stroke="none" d="M 5350,8400 L
3000,8400 3000,7500 7700,7500 7700,8400 5350,8400 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 5350,8400 L 
3000,8400 3000,7500 7700,7500 7700,8400 5350,8400 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id9">
        <path fill="rgb(114,159,207)" stroke="none" d="M 3800,9300 L
3000,9300 3000,8400 4600,8400 4600,9300 3800,9300 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 3800,9300 L 
3000,9300 3000,8400 4600,8400 4600,9300 3800,9300 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id10">
        <path fill="rgb(114,159,207)" stroke="none" d="M 7850,10200 L
3000,10200 3000,9300 12700,9300 12700,10200 7850,10200 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 7850,10200 L
3000,10200 3000,9300 12700,9300 12700,10200 7850,10200 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id11">
        <path fill="rgb(114,159,207)" stroke="none" d="M 4350,11900 L
3000,11900 3000,11000 5700,11000 5700,11900 4350,11900 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 4350,11900 L
3000,11900 3000,11000 5700,11000 5700,11900 4350,11900 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id12">
        <path fill="rgb(114,159,207)" stroke="none" d="M 5350,12800 L
3000,12800 3000,11900 7700,11900 7700,12800 5350,12800 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 5350,12800 L
3000,12800 3000,11900 7700,11900 7700,12800 5350,12800 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id13">
        <path fill="rgb(114,159,207)" stroke="none" d="M 3800,13700 L
3000,13700 3000,12800 4600,12800 4600,13700 3800,13700 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 3800,13700 L
3000,13700 3000,12800 4600,12800 4600,13700 3800,13700 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.CustomShape">
       <g id="id14">
        <path fill="rgb(114,159,207)" stroke="none" d="M 7850,14600 L
3000,14600 3000,13700 12700,13700 12700,14600 7850,14600 Z"/>
        <path fill="none" stroke="rgb(52,101,164)" d="M 7850,14600 L
3000,14600 3000,13700 12700,13700 12700,14600 7850,14600 Z"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id15">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2500,2000 L 
2400,14600"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id16">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2500,3900 L 
2000,3900"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id17">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2450,8400 L 
1950,8400"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.LineShape">
       <g id="id18">
        <path fill="none" stroke="rgb(0,0,0)" d="M 2450,12900 L 
1950,12900"/>
       </g>
      </g>
      <g class="com.sun.star.drawing.TextShape">
       <g id="id19">
        <text class="TextShape"><tspan class="TextParagraph" 
font-family="Liberation Sans, sans-serif" font-size="635px" 
font-weight="400"><tspan class="TextPosition" x="1450" y="4201"/><tspan 
class="TextPosition" x="1450" y="4201"><tspan fill="rgb(0,0,0)" 
stroke="none">1</tspan></tspan></tspan></text>
       </g>
      </g>
      <g class="com.sun.star.drawing.TextShape">
       <g id="id20">
        <text class="TextShape"><tspan class="TextParagraph" 
font-family="Liberation Sans, sans-serif" font-size="635px" 
font-weight="400"><tspan class="TextPosition" x="1451" y="8701"/><tspan 
class="TextPosition" x="1451" y="8701"><tspan fill="rgb(0,0,0)" 
stroke="none">1</tspan></tspan></tspan></text>
       </g>
      </g>
      <g class="com.sun.star.drawing.TextShape">
       <g id="id21">
        <text class="TextShape"><tspan class="TextParagraph" 
font-family="Liberation Sans, sans-serif" font-size="635px" 
font-weight="400"><tspan class="TextPosition" x="1452" y="13201"/><tspan 
class="TextPosition" x="1452" y="13201"><tspan fill="rgb(0,0,0)" 
stroke="none">1</tspan></tspan></tspan></text>
       </g>
      </g>
     </g>
    </g>
   </g>
  </g>
</svg>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Apr  4 20:05:05 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 4 Apr 2016 14:05:05 -0400
Subject: [R] Extending the beta period for R 3.3.0 till April 25,
	Final	release on May 3
In-Reply-To: <BE005488-BD9F-4CE5-87E3-9D061DEC585D@cbs.dk>
References: <BE005488-BD9F-4CE5-87E3-9D061DEC585D@cbs.dk>
Message-ID: <5702ACD1.5060102@gmail.com>

On 02/04/2016 11:58 AM, Peter Dalgaard wrote:
> Due to delays in implementing an updated Windows toolchain for CRAN, R Core has found it unsafe to go with our usual 1-week beta testing period. Combined with other scheduling issues, we have decided to postpone the transition to 3.3.0 RC until April 26, with the final release happening on May 3.
>
> Apologies for any inconvenience, but it is really rather important to get this right before the release of 3.3.0. One cannot mix and match binaries from different toolchains - CRAN packages binaries for 3.3.x must be all of the same kind. Accordingly, if we have too little time to fix issues discovered in the beta period, we might have to back out and be stuck with the old tools for another year.
>
> Web site updates will happen shortly.

I have  finally added a public link to the binary build of the 3.3.0 
beta.  (It may take a few hours before it makes it to the visible 
machines on CRAN.)  It will work with binary builds of many packages, 
but definitely not with those that use C++ unless they were built with 
the same toolchain.

In case you want to get it before the link is visible, here it is on one 
mirror:

http://cran.rstudio.com/bin/windows/base/rtest.html

Duncan Murdoch

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From frainj at gmail.com  Mon Apr  4 21:06:18 2016
From: frainj at gmail.com (John C Frain)
Date: Mon, 4 Apr 2016 20:06:18 +0100
Subject: [R] Test for Homoscedesticity in R Without BP Test
In-Reply-To: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
References: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
Message-ID: <CAHrK515CpP1zLB9sk2PEZT1YgmkXexNz7w4HhSn7pTep-2mJNQ@mail.gmail.com>

You might "google Breusch Pagan test r" and find that the test is
implemented in lmtest package.
On 4 Apr 2016 17:28, "Deepak Singh" <sdeepakrhelp at gmail.com> wrote:

> Respected Sir,
> I am doing a project on multiple linear model fitting and in that project I
> have to test Homoscedesticity of errors I have google for the same and
> found bptest for the same but in R version 3.2.4 bp test is not available.
> So please suggest me a test on homoscedesticity ASAP as we have to submit
> our report on 7-04-2016.
>
> P.S. : I have plotted residuals against fitted values and it is less or
> more random.
>
> Thank You !
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Mon Apr  4 21:10:34 2016
From: varinsacha at yahoo.fr (varin sacha)
Date: Mon, 4 Apr 2016 19:10:34 +0000 (UTC)
Subject: [R] Test for Homoscedesticity in R Without BP Test
In-Reply-To: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
References: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
Message-ID: <940638845.4301867.1459797034236.JavaMail.yahoo@mail.yahoo.com>

Hi Deepak,

In econometrics there is another test very often used : the white test.
The white test is based on the comparison of the estimated variances of residuals when the model is estimated by OLS under the assumption of homoscedasticity and when the model is estimated by OLS under the assumption of heteroscedastic.


The White test with R

install.packages("bstats")
library(bstats)
white.test(LinearModel)



Hope this helps.

Sacha





________________________________
De : Deepak Singh <sdeepakrhelp at gmail.com>
? : r-help at r-project.org 
Envoy? le : Lundi 4 avril 2016 10h40
Objet : [R] Test for Homoscedesticity in R Without BP Test


Respected Sir,
I am doing a project on multiple linear model fitting and in that project I
have to test Homoscedesticity of errors I have google for the same and
found bptest for the same but in R version 3.2.4 bp test is not available.
So please suggest me a test on homoscedesticity ASAP as we have to submit
our report on 7-04-2016.

P.S. : I have plotted residuals against fitted values and it is less or
more random.

Thank You !

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dutangc at gmail.com  Mon Apr  4 21:19:20 2016
From: dutangc at gmail.com (Christophe Dutang)
Date: Mon, 4 Apr 2016 21:19:20 +0200
Subject: [R] Find the dataset(s) that contain(s) non-ASCII characters
Message-ID: <E41E45D2-E5A3-402E-B3F8-00C4EA63B15B@gmail.com>

Dear list,

I?m maintainsing a package containing only datasets (152): http://dutangc.free.fr/pub/RRepos/web/CASdatasets-index.html <http://dutangc.free.fr/pub/RRepos/web/CASdatasets-index.html> 

When R CMD checking the package, I get the following NOTE
* checking data for non-ASCII characters ... NOTE
 Note: found 4 marked UTF-8 strings

I wonder how to find which dataset(s) (all recorded as rda files) contain(s) non-ASCII characters. 

Using the iconv function let us to find or replace non-ASCII characters 
iconv(x, "UTF-8", "ASCII", sub="I_WAS_NOT_ASCII")

I use the following function to detect non-ASCII characters.

testASCII <- function(idata)
{
 col <- (1:NCOL(idata))[sapply(idata, is.factor)]
 col <- c(col, (1:NCOL(idata))[sapply(idata, is.character)])
 for(i in col)
 {
   x <- idata[, i]
   cat(colnames(idata)[i], "\n")
   res <- grep("I_WAS_NOT_ASCII", iconv(x, "latin1", "ASCII", sub="I_WAS_NOT_ASCII"))
   res <- c(res, grep("I_WAS_NOT_ASCII", iconv(x, "UTF-8", "ASCII", sub="I_WAS_NOT_ASCII")))
   if(any(length(res) > 0))
     cat(res, "\n")
 }
}

Unfortunately, I did not find yet which rda file contains non-ASCII characters among 56 most recent datasets. Is there a faster way to detect non-ASCII characters than to manually load and testASCII()? for example directly on rda files?

Any comment is welcome.

Regards, Christophe


> sessionInfo()
R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.5 (Yosemite)

locale:
[1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/fr_FR.UTF-8/fr_FR.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
---------------------------------------
Christophe Dutang
LMM, UdM, Le Mans, France
web: http://dutangc.free.fr <http://dutangc.free.fr/>

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Mon Apr  4 21:20:32 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 4 Apr 2016 21:20:32 +0200 (CEST)
Subject: [R] Test for Homoscedesticity in R Without BP Test
In-Reply-To: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
References: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1604042118400.8729@paninaro>

On Mon, 4 Apr 2016, Deepak Singh wrote:

> Respected Sir,
> I am doing a project on multiple linear model fitting and in that project I
> have to test Homoscedesticity of errors I have google for the same and
> found bptest for the same but in R version 3.2.4 bp test is not available.

The function is called bptest() and is implemented in package "lmtest" 
which is available for current versions of R, see
https://CRAN.R-project.org/package=lmtest

To install it, run:
install.packages("lmtest")

And then to load the package and try the function:
library("lmtest")
example("bptest")

> So please suggest me a test on homoscedesticity ASAP as we have to submit
> our report on 7-04-2016.
>
> P.S. : I have plotted residuals against fitted values and it is less or
> more random.
>
> Thank You !
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Achim.Zeileis at uibk.ac.at  Mon Apr  4 21:28:00 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 4 Apr 2016 21:28:00 +0200 (CEST)
Subject: [R] Test for Homoscedesticity in R Without BP Test
In-Reply-To: <940638845.4301867.1459797034236.JavaMail.yahoo@mail.yahoo.com>
References: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
	<940638845.4301867.1459797034236.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.DEB.2.20.1604042121140.8729@paninaro>

On Mon, 4 Apr 2016, varin sacha via R-help wrote:

> Hi Deepak,
>
> In econometrics there is another test very often used : the white test. 
> The white test is based on the comparison of the estimated variances of 
> residuals when the model is estimated by OLS under the assumption of 
> homoscedasticity and when the model is estimated by OLS under the 
> assumption of heteroscedastic.

The White test is a special case of the Breusch-Pagan test using a 
particular specification of the auxiliary regressors: namely all 
regressors, their squares and their cross-products. As this specification 
makes only sense if all regressors are continuous, many implementations 
have problems if there are already dummy variables, interactions, etc. in 
the regressor matrix. This is also the reason why bptest() from "lmtest" 
uses a different specification by default. However, you can utilize the 
function to carry out the White test as illustrated in:

example("CigarettesB", package = "AER")

(Of course, the AER package needs to be installed first.)

> The White test with R
>
> install.packages("bstats")
> library(bstats)
> white.test(LinearModel)

That package is no longer on CRAN as it took the code from bptest() 
without crediting its original authors and released it in a package that 
conflicted with the original license. Also, the implementation did not 
check for potential problems with dummy variables or interactions 
mentioned above.

So the bptest() implementation from "lmtest" is really recommend. Or 
alternatively ncvTest() from package "car".

> Hope this helps.
>
> Sacha
>
>
>
>
>
> ________________________________
> De : Deepak Singh <sdeepakrhelp at gmail.com>
> ? : r-help at r-project.org 
> Envoy? le : Lundi 4 avril 2016 10h40
> Objet : [R] Test for Homoscedesticity in R Without BP Test
>
>
> Respected Sir,
> I am doing a project on multiple linear model fitting and in that project I
> have to test Homoscedesticity of errors I have google for the same and
> found bptest for the same but in R version 3.2.4 bp test is not available.
> So please suggest me a test on homoscedesticity ASAP as we have to submit
> our report on 7-04-2016.
>
> P.S. : I have plotted residuals against fitted values and it is less or
> more random.
>
> Thank You !
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From sdeepakrhelp at gmail.com  Mon Apr  4 22:03:59 2016
From: sdeepakrhelp at gmail.com (Deepak Singh)
Date: Tue, 5 Apr 2016 01:33:59 +0530
Subject: [R] Test for Homoscedesticity in R Without BP Test
In-Reply-To: <alpine.DEB.2.20.1604042121140.8729@paninaro>
References: <CAMpSevTDaXznYZ=uNfQCf=KumkT-95q4XkU6EGOtSWQ--gvxHQ@mail.gmail.com>
	<940638845.4301867.1459797034236.JavaMail.yahoo@mail.yahoo.com>
	<alpine.DEB.2.20.1604042121140.8729@paninaro>
Message-ID: <CAMpSevTvh=eigTJMbi7fWgSuFLPP-iVi8qOEJphpFUJ65AsMxA@mail.gmail.com>

I have tried and got the result.
Thank you every one.


On Tue, Apr 5, 2016 at 12:58 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

> On Mon, 4 Apr 2016, varin sacha via R-help wrote:
>
> Hi Deepak,
>>
>> In econometrics there is another test very often used : the white test.
>> The white test is based on the comparison of the estimated variances of
>> residuals when the model is estimated by OLS under the assumption of
>> homoscedasticity and when the model is estimated by OLS under the
>> assumption of heteroscedastic.
>>
>
> The White test is a special case of the Breusch-Pagan test using a
> particular specification of the auxiliary regressors: namely all
> regressors, their squares and their cross-products. As this specification
> makes only sense if all regressors are continuous, many implementations
> have problems if there are already dummy variables, interactions, etc. in
> the regressor matrix. This is also the reason why bptest() from "lmtest"
> uses a different specification by default. However, you can utilize the
> function to carry out the White test as illustrated in:
>
> example("CigarettesB", package = "AER")
>
> (Of course, the AER package needs to be installed first.)
>
> The White test with R
>>
>> install.packages("bstats")
>> library(bstats)
>> white.test(LinearModel)
>>
>
> That package is no longer on CRAN as it took the code from bptest()
> without crediting its original authors and released it in a package that
> conflicted with the original license. Also, the implementation did not
> check for potential problems with dummy variables or interactions mentioned
> above.
>
> So the bptest() implementation from "lmtest" is really recommend. Or
> alternatively ncvTest() from package "car".
>
>
> Hope this helps.
>>
>> Sacha
>>
>>
>>
>>
>>
>> ________________________________
>> De : Deepak Singh <sdeepakrhelp at gmail.com>
>> ? : r-help at r-project.org Envoy? le : Lundi 4 avril 2016 10h40
>> Objet : [R] Test for Homoscedesticity in R Without BP Test
>>
>>
>> Respected Sir,
>> I am doing a project on multiple linear model fitting and in that project
>> I
>> have to test Homoscedesticity of errors I have google for the same and
>> found bptest for the same but in R version 3.2.4 bp test is not available.
>> So please suggest me a test on homoscedesticity ASAP as we have to submit
>> our report on 7-04-2016.
>>
>> P.S. : I have plotted residuals against fitted values and it is less or
>> more random.
>>
>> Thank You !
>>
>>    [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Apr  4 23:59:28 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 5 Apr 2016 07:59:28 +1000
Subject: [R] multiple bar plot annotation text labelling
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D729126@mb02.ads.tamu.edu>
References: <130efe144c2b73775f9d465cd84215d1@openmailbox.org>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D729126@mb02.ads.tamu.edu>
Message-ID: <CA+8X3fVfgeOE0yGp=QPOodfs9MYKXJhuf6W9bGHV_KBB0mZx7Q@mail.gmail.com>

Hi message,
What you can do is this:

barpos<-barplot(axes=FALSE, ann=FALSE, horiz=TRUE,
 testbarplot[,2], ylab='group', xlab= '(x values)',
 xlim=c(0,10),space=c(1,0,0,0, 1,0,0,0))
text(testbarplot[,2],barpos,
 c('a', 'b', 'c', 'd', 'c', 'e','f', 'g'), pos=4)

as I think you want the values displayed just to the right of the
bars. The "xlim" argument is needed to provide space for the label on
the longest bar.

Jim

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of message
> Sent: Monday, April 4, 2016 6:00 AM
> To: r-help at r-project.org
> Subject: [R] multiple bar plot annotation text labelling
>
> Readers,
>
> The attempt is to create a bar plot with text labels adjacent to each
> datum value.
>
> Data file:
> 1,3,A
> 1,8,B
> 1,1,C
> 1,9,D
> 2,5,C
> 2,4,E
> 2,2,F
> 2,0,G
>
> testbarplot<-read.csv('data1.csv', header=FALSE)
> barplot(axes=FALSE, ann=FALSE, horiz=TRUE, testbarplot[,2], ylab=
> 'group', xlab= '(x values)', space=c(1,0,0,0, 1,0,0,0))
> text(testbarplot[,2], testbarplot[,1], c('a', 'b', 'c', 'd', 'c', 'e',
> 'f', 'g'), pos=4)
>
> Why does the text labels only appear for the lower half group of bar
> plot values?
>
> Below is an example of the type of graph that is being sought. It is svg
> text exported from libreoffice calc that should be saved as a separate
> file and viewable in any svg viewer such as a web browser or a tool such
> as 'eye of gnome'.
>
> <?xml version="1.0" encoding="UTF-8"?>
>
> <svg version="1.2" baseProfile="tiny" width="115.01mm" height="126.01mm"
> viewBox="1200 2000 11501 12601" preserveAspectRatio="xMidYMid"
> fill-rule="evenodd" stroke-width="28.222" stroke-linejoin="round"
> xmlns="http://www.w3.org/2000/svg"
> xmlns:ooo="http://xml.openoffice.org/svg/export"
> xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve">
>   <defs class="ClipPathGroup">
>    <clipPath id="presentation_clip_path" clipPathUnits="userSpaceOnUse">
>     <rect x="1200" y="2000" width="11501" height="12601"/>
>    </clipPath>
>   </defs>
>   <defs>
>    <font id="EmbeddedFont_1" horiz-adv-x="2048">
>     <font-face font-family="Liberation Sans embedded" units-per-em="2048"
> font-weight="normal" font-style="normal" ascent="1852" descent="423"/>
>     <missing-glyph horiz-adv-x="2048" d="M 0,0 L 2047,0 2047,2047 0,2047
> 0,0 Z"/>
>     <glyph unicode="1" horiz-adv-x="927" d="M 156,0 L 156,153 515,153
> 515,1237 197,1010 197,1180 530,1409 696,1409 696,153 1039,153 1039,0
> 156,0 Z"/>
>    </font>
>   </defs>
>   <defs class="TextShapeIndex">
>    <g ooo:slide="id1" ooo:id-list="id3 id4 id5 id6 id7 id8 id9 id10 id11
> id12 id13 id14 id15 id16 id17 id18 id19 id20 id21"/>
>   </defs>
>   <defs class="EmbeddedBulletChars">
>    <g id="bullet-char-template(57356)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 580,1141 L 1163,571 580,0 -4,571 580,1141 Z"/>
>    </g>
>    <g id="bullet-char-template(57354)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 8,1128 L 1137,1128 1137,0 8,0 8,1128 Z"/>
>    </g>
>    <g id="bullet-char-template(10146)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 174,0 L 602,739 174,1481 1456,739 174,0 Z M 1358,739 L
> 309,1346 659,739 1358,739 Z"/>
>    </g>
>    <g id="bullet-char-template(10132)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 2015,739 L 1276,0 717,0 1260,543 174,543 174,936 1260,936
> 717,1481 1274,1481 2015,739 Z"/>
>    </g>
>    <g id="bullet-char-template(10007)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 0,-2 C -7,14 -16,27 -25,37 L 356,567 C 262,823 215,952
> 215,954 215,979 228,992 255,992 264,992 276,990 289,987 310,991 331,999
> 354,1012 L 381,999 492,748 772,1049 836,1024 860,1049 C 881,1039
> 901,1025 922,1006 886,937 835,863 770,784 769,783 710,716 594,584 L
> 774,223 C 774,196 753,168 711,139 L 727,119 C 717,90 699,76 672,76
> 641,76 570,178 457,381 L 164,-76 C 142,-110 111,-127 72,-127 30,-127
> 9,-110 8,-76 1,-67 -2,-52 -2,-32 -2,-23 -1,-13 0,-2 Z"/>
>    </g>
>    <g id="bullet-char-template(10004)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 285,-33 C 182,-33 111,30 74,156 52,228 41,333 41,471
> 41,549 55,616 82,672 116,743 169,778 240,778 293,778 328,747 346,684 L
> 369,508 C 377,444 397,411 428,410 L 1163,1116 C 1174,1127 1196,1133
> 1229,1133 1271,1133 1292,1118 1292,1087 L 1292,965 C 1292,929 1282,901
> 1262,881 L 442,47 C 390,-6 338,-33 285,-33 Z"/>
>    </g>
>    <g id="bullet-char-template(9679)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 813,0 C 632,0 489,54 383,161 276,268 223,411 223,592
> 223,773 276,916 383,1023 489,1130 632,1184 813,1184 992,1184 1136,1130
> 1245,1023 1353,916 1407,772 1407,592 1407,412 1353,268 1245,161 1136,54
> 992,0 813,0 Z"/>
>    </g>
>    <g id="bullet-char-template(8226)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M 346,457 C 273,457 209,483 155,535 101,586 74,649 74,723
> 74,796 101,859 155,911 209,963 273,989 346,989 419,989 480,963 531,910
> 582,859 608,796 608,723 608,648 583,586 532,535 482,483 420,457 346,457
> Z"/>
>    </g>
>    <g id="bullet-char-template(8211)"
> transform="scale(0.00048828125,-0.00048828125)">
>     <path d="M -4,459 L 1135,459 1135,606 -4,606 -4,459 Z"/>
>    </g>
>   </defs>
>   <defs class="TextEmbeddedBitmaps"/>
>   <g class="SlideGroup">
>    <g>
>     <g id="id1" class="Slide" clip-path="url(#presentation_clip_path)">
>      <g class="Page">
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id3">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 4350,3000 L
> 3000,3000 3000,2100 5700,2100 5700,3000 4350,3000 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 4350,3000 L
> 3000,3000 3000,2100 5700,2100 5700,3000 4350,3000 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id4">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 5350,3900 L
> 3000,3900 3000,3000 7700,3000 7700,3900 5350,3900 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 5350,3900 L
> 3000,3900 3000,3000 7700,3000 7700,3900 5350,3900 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id5">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 3800,4800 L
> 3000,4800 3000,3900 4600,3900 4600,4800 3800,4800 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 3800,4800 L
> 3000,4800 3000,3900 4600,3900 4600,4800 3800,4800 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id6">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 7850,5700 L
> 3000,5700 3000,4800 12700,4800 12700,5700 7850,5700 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 7850,5700 L
> 3000,5700 3000,4800 12700,4800 12700,5700 7850,5700 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id7">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 4350,7500 L
> 3000,7500 3000,6600 5700,6600 5700,7500 4350,7500 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 4350,7500 L
> 3000,7500 3000,6600 5700,6600 5700,7500 4350,7500 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id8">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 5350,8400 L
> 3000,8400 3000,7500 7700,7500 7700,8400 5350,8400 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 5350,8400 L
> 3000,8400 3000,7500 7700,7500 7700,8400 5350,8400 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id9">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 3800,9300 L
> 3000,9300 3000,8400 4600,8400 4600,9300 3800,9300 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 3800,9300 L
> 3000,9300 3000,8400 4600,8400 4600,9300 3800,9300 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id10">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 7850,10200 L
> 3000,10200 3000,9300 12700,9300 12700,10200 7850,10200 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 7850,10200 L
> 3000,10200 3000,9300 12700,9300 12700,10200 7850,10200 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id11">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 4350,11900 L
> 3000,11900 3000,11000 5700,11000 5700,11900 4350,11900 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 4350,11900 L
> 3000,11900 3000,11000 5700,11000 5700,11900 4350,11900 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id12">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 5350,12800 L
> 3000,12800 3000,11900 7700,11900 7700,12800 5350,12800 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 5350,12800 L
> 3000,12800 3000,11900 7700,11900 7700,12800 5350,12800 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id13">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 3800,13700 L
> 3000,13700 3000,12800 4600,12800 4600,13700 3800,13700 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 3800,13700 L
> 3000,13700 3000,12800 4600,12800 4600,13700 3800,13700 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.CustomShape">
>        <g id="id14">
>         <path fill="rgb(114,159,207)" stroke="none" d="M 7850,14600 L
> 3000,14600 3000,13700 12700,13700 12700,14600 7850,14600 Z"/>
>         <path fill="none" stroke="rgb(52,101,164)" d="M 7850,14600 L
> 3000,14600 3000,13700 12700,13700 12700,14600 7850,14600 Z"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.LineShape">
>        <g id="id15">
>         <path fill="none" stroke="rgb(0,0,0)" d="M 2500,2000 L
> 2400,14600"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.LineShape">
>        <g id="id16">
>         <path fill="none" stroke="rgb(0,0,0)" d="M 2500,3900 L
> 2000,3900"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.LineShape">
>        <g id="id17">
>         <path fill="none" stroke="rgb(0,0,0)" d="M 2450,8400 L
> 1950,8400"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.LineShape">
>        <g id="id18">
>         <path fill="none" stroke="rgb(0,0,0)" d="M 2450,12900 L
> 1950,12900"/>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.TextShape">
>        <g id="id19">
>         <text class="TextShape"><tspan class="TextParagraph"
> font-family="Liberation Sans, sans-serif" font-size="635px"
> font-weight="400"><tspan class="TextPosition" x="1450" y="4201"/><tspan
> class="TextPosition" x="1450" y="4201"><tspan fill="rgb(0,0,0)"
> stroke="none">1</tspan></tspan></tspan></text>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.TextShape">
>        <g id="id20">
>         <text class="TextShape"><tspan class="TextParagraph"
> font-family="Liberation Sans, sans-serif" font-size="635px"
> font-weight="400"><tspan class="TextPosition" x="1451" y="8701"/><tspan
> class="TextPosition" x="1451" y="8701"><tspan fill="rgb(0,0,0)"
> stroke="none">1</tspan></tspan></tspan></text>
>        </g>
>       </g>
>       <g class="com.sun.star.drawing.TextShape">
>        <g id="id21">
>         <text class="TextShape"><tspan class="TextParagraph"
> font-family="Liberation Sans, sans-serif" font-size="635px"
> font-weight="400"><tspan class="TextPosition" x="1452" y="13201"/><tspan
> class="TextPosition" x="1452" y="13201"><tspan fill="rgb(0,0,0)"
> stroke="none">1</tspan></tspan></tspan></text>
>        </g>
>       </g>
>      </g>
>     </g>
>    </g>
>   </g>
> </svg>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Apr  5 00:08:24 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 5 Apr 2016 08:08:24 +1000
Subject: [R] Fligner-Killeen test on binary data
In-Reply-To: <009301d18e57$1b08b730$511a2590$@uzh.ch>
References: <009301d18e57$1b08b730$511a2590$@uzh.ch>
Message-ID: <CA+8X3fWHfcVtTT3m40yHKDnsE2gADmjaju3KNjfkSrCqdoL9og@mail.gmail.com>

Hi emeline,
I think there may be a minor language problem. If you mean the
"variation" rather than the "variance" in survival, you may simply
want a test of proportions.

Jim

On Mon, Apr 4, 2016 at 7:48 PM, emeline mourocq <emeline.mourocq at uzh.ch> wrote:
> Hello,
>
>
>
> I investigate survival until the following year (0,1) and I wish to test if
> the variance in survival for two or more groups are significantly different
> from each other.
>
>
>
> I read that the Fligner-Killeen test is a non-parametric test which is very
> robust against departures from normality but is it correct (valuable
> technique for publication) to use it on binary data?
>
>
>
> In other words, can I use
> fligner.test(survival~categorical_predictor,data=mydata) when survival is
> binary (0,1)?
>
>
>
> Best regards
>
> Emeline
>
>
>
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sj_style_1125 at outlook.com  Tue Apr  5 03:15:13 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Tue, 5 Apr 2016 01:15:13 +0000
Subject: [R] R-dvel [robustness Simulation study of 2 sample test on several
 combination of factors ]
Message-ID: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>

hi, i am new in this field.


do
favorite<http://stackoverflow.com/questions/36404707/simulation-study-of-2-sample-test-on-different-combination-of-factors#>


If I wish to conduct a simulation on the robustness of two sample test by using R language, is that any ways in writing the code?
There are several factors
(sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100))

(standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50))
distribution of gamma distribution with unequal skewness and equal skewness

I wish to test the pooled variance t test and welch t test and mann whitney by using the above combination of factors. But how can I combine them by using for loop or apply function??
I am intending to use apply function but i am stucking. If i use for loop function, can i use for loop with vectors ?
for (a in c(25,50,100)) #first group of sample sizes
{ for (b in c(25,50,100)) #second group of sample sizes
{ for (d in c(4,4.4,5,6,8)) #different SDs of first sample
the above code is an example that I would like to modified but I found I have different sets of sample sizes.

So if for loop with vectors, as shown in the code above, will the computer run from part (a) 25, to part(b) 25, then to the part (d) 4? then again the rotation 50->50->4.4?

?I hope can hear any news from this website ....please..thanks you.

Regards
sst


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Apr  5 04:38:29 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 5 Apr 2016 12:38:29 +1000
Subject: [R] R-dvel [robustness Simulation study of 2 sample test on
 several combination of factors ]
In-Reply-To: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fWqRijLtXxXfi33A_iZ-AF0wAwGbKEw6EBtvRkJQ6XtWg@mail.gmail.com>

Hi sst,
You could set up your sample sizes as a matrix if you don't want all
of the combinations:

sample_sizes<-matrix(c(10,10,10,25,25,25,...),nrow=2)

and then use one loop for the sample sizes:

for(ss in 1:dim(sample_sizes)[2]) {
 ss1<-sample_sizes[1,ss]
 ss2<-sample_sizes[2,ss]

then step through your SDs:

for(ssd in  c(4,4.4,5,6,8)) {

Jim

On Tue, Apr 5, 2016 at 11:15 AM, tan sj <sj_style_1125 at outlook.com> wrote:
> hi, i am new in this field.
>
>
> do
> favorite<http://stackoverflow.com/questions/36404707/simulation-study-of-2-sample-test-on-different-combination-of-factors#>
>
>
> If I wish to conduct a simulation on the robustness of two sample test by using R language, is that any ways in writing the code?
> There are several factors
> (sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100))
>
> (standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50))
> distribution of gamma distribution with unequal skewness and equal skewness
>
> I wish to test the pooled variance t test and welch t test and mann whitney by using the above combination of factors. But how can I combine them by using for loop or apply function??
> I am intending to use apply function but i am stucking. If i use for loop function, can i use for loop with vectors ?
> for (a in c(25,50,100)) #first group of sample sizes
> { for (b in c(25,50,100)) #second group of sample sizes
> { for (d in c(4,4.4,5,6,8)) #different SDs of first sample
> the above code is an example that I would like to modified but I found I have different sets of sample sizes.
>
> So if for loop with vectors, as shown in the code above, will the computer run from part (a) 25, to part(b) 25, then to the part (d) 4? then again the rotation 50->50->4.4?
>
> ?I hope can hear any news from this website ....please..thanks you.
>
> Regards
> sst
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giorgio.garziano at ericsson.com  Tue Apr  5 10:24:40 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Tue, 5 Apr 2016 08:24:40 +0000
Subject: [R] R cases on predictive maintenance
Message-ID: <248E6FA047A8C746BA491485764190F53D3994CE@ESESSMB207.ericsson.se>

Generically:

http://rseek.org/?q=predictive+maintenance

and among those:

https://rpubs.com/Simionsv/97830

http://blog.revolutionanalytics.com/2016/03/predictive-maintenance.html


--

Best,

GG

This Communication is Ericsson Confidential.
We only send and receive email on the basis of the term set out at http://www.ericsson.com/email_disclaimer




	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Apr  5 12:45:29 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 Apr 2016 10:45:29 +0000
Subject: [R] use one way ANOVA to select genes
In-Reply-To: <1169941500.3188462.1459850623520.JavaMail.yahoo@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50216CC@SRVEXCHMBX.precheza.cz>
	<1169941500.3188462.1459850623520.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5024C78@SRVEXCHMBX.precheza.cz>

Hi

Others can have better insight in your question so i tis preferable to post your mails to the Rhelp list too.

I hope your datafile is all numeric. If not after t(datafile) can be character.

AFAIK your pvalue is not propagated to aov function.

Based on artificial data your construction arrives to result, which in this case tells you that there is almost no difference in those 5 groups..

m <- data.frame(groups, data = rnorm(length(groups)))

>   anova(aov(data ~ groups, m))
Analysis of Variance Table

Response: data
           Df Sum Sq Mean Sq F value  Pr(>F)
groups      4   9.20  2.2999  2.2117 0.06751 .
Residuals 326 338.99  1.0399
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>

So I still wonder what is the problem. If you want to know whether anova(aov(?)) is appropriate for your case you shall consult local statistician or post your question e.g. on stackexchange or hope that somebody with deeper statistical knowledge from R help subscribers can help you.

But you probably need to post some more info.

Cheers
Petr

From: hehsham alpukhity [mailto:heshamibb at yahoo.com]
Sent: Tuesday, April 5, 2016 12:04 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] use one way ANOVA to select genes

thanks Petr
 Actually , i have wrote code for One way ANOVA ,but still i am sure is it true or not  for analysis data  , because I have 5 groups i want to  select the significant gene from this groups , .
 this code
#######################################################################################################
datafile <- read.csv("brcaResultsclust.csv",header = T,row.names = 1)

datafile <- t(datafile)

groups <- factor(rep(c("c1","c2","c3","c4","c5"),c(116,83,28,80,24))) # here one factor with 5 groups

# define ANOVA function

aoftest <- function(data  ,pvalue=0.05) {

  m<-data.frame(groups, data);
  anova(aov(data ~ groups, m))
}

anovaresultstest <- apply(datafile, 1, aoftest)
 #############################################################################################
is the design factor and the function for ANOVA test is true ?

thank
hesham

On Monday, April 4, 2016 3:29 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

Your message is scrambled by using HTML post and if I deciphered it correctly you just want to use anova for some data.

What is preventing you from doing it?

Cheers
Petr

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of hehsham alpukhity via R-help
Sent: Sunday, April 3, 2016 4:45 PM
To: R-help Mailing List <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: [R] use one way ANOVA to select genes

i want to select the significant genes form  5 clusters (groups) by one way ANOVA  in r#######################################################################################
# i want use One way ANOVA to select the siginificant from the clusters above selectgene <- function(GropuData,pvalue=0.05, na.rm=TRUE, file=1:5){# if each gruop in one  txt file                fdata <- list.files(data,full.names = TRUE)                for(i in file) {        anova()
        }  }######################################

Hisham AL-bukhaiti Ph.D Student (Information system ) China, changsha,Hunan university. Mobile: 0068-15 111 4246 91.
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.





________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Apr  5 13:00:59 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 5 Apr 2016 21:00:59 +1000
Subject: [R] R-dvel [robustness Simulation study of 2 sample test on
 several combination of factors ]
In-Reply-To: <KL1PR01MB08878FE8EBB3022261E88148B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
	<CA+8X3fWqRijLtXxXfi33A_iZ-AF0wAwGbKEw6EBtvRkJQ6XtWg@mail.gmail.com>
	<KL1PR01MB08878FE8EBB3022261E88148B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fX2Muc5nVbcsEJ0+jhv=-_yrWcEt3bqvEzyBzUoRUSfew@mail.gmail.com>

Okay, here is a more complete example:

sample_sizes<-
 matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
 nrow=2)
# see what it looks like
sample_sizes
ssds<-c(4,4.4,5,6,8)
nssds<-length(ssds)
results<-list()
# first loop steps through the sample
for(ss in 1:dim(sample_sizes)[2]) {
 # get the two sample sizes
 ss1<-sample_sizes[1,ss]
 ss2<-sample_sizes[2,ss]
 then step through your SDs:
 ssd_index<-1
 for(ssd in  ssds) {
  # generate the two samples with the SDs
  sample1<-rnorm(ss1,ssd)
  sample2<-rnorm(ss2,ssd)
  # here run your tests, recording the results that you want
  results[[(ss-1)*nssds+ssd_index]]<-<your_test>
  ssd_index<-ssd_index+1
 }
}

The list "results" should now contain the results of whatever test you
run. Be careful to get the order right.

Jim


On Tue, Apr 5, 2016 at 8:07 PM, tan sj <sj_style_1125 at outlook.com> wrote:
> hi, Jim,
> i am not very clear about yours idea.
> How can i able to test them under the combination of factors?
> I am now trying to do three for loops....but i am stucking ....
> Please, I need help ....
> ________________________________________


From Johannes.Rainer at eurac.edu  Tue Apr  5 13:34:27 2016
From: Johannes.Rainer at eurac.edu (Rainer Johannes)
Date: Tue, 5 Apr 2016 11:34:27 +0000
Subject: [R] Problem with <= (less than or equal): not giving the expected
	result
Message-ID: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>

Dear All,

I have the following problem:

I have a function in which I check if the difference between values is smaller or equal to a certain threshold. I however realized that I might get there some unexpected results:

> abs(1 - 0.95) >= 0.05
[1] TRUE
## So that?s fine, but:
> abs(1 - 0.95) <= 0.05
[1] FALSE

Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite disturbing.

Along these lines:
> abs(0.95 - 1) > 0.05
[1] TRUE
> abs(0.95 - 1) < 0.05
[1] FALSE

I guess that has to do with the floating point representation of the data?

Is there something I miss or is there any solution to this?
Thanks for any help!

cheers, jo



I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The R-version I used for the code above is:

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base   

From rini.john3 at yahoo.com  Tue Apr  5 14:14:55 2016
From: rini.john3 at yahoo.com (=?UTF-8?Q?=E2=80=AARini_John=E2=80=AC_=E2=80=AA?=)
Date: Tue, 5 Apr 2016 12:14:55 +0000 (UTC)
Subject: [R] RWeka Error
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>


When I use any function of RWeka Package in Rstudio I get an error, "Error in .jnew (name): java.lang.ClassFormatError." can anyone guide me in this?

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr  5 14:30:31 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 5 Apr 2016 14:30:31 +0200
Subject: [R] Problem with <= (less than or equal): not giving the
	expected result
In-Reply-To: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
Message-ID: <CAJuCY5x+1JksiO_hMetepHsfsR7z+m=Ohoun51E96C3YJ6pX8w@mail.gmail.com>

FAQ 7.31

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-05 13:34 GMT+02:00 Rainer Johannes <Johannes.Rainer at eurac.edu>:

> Dear All,
>
> I have the following problem:
>
> I have a function in which I check if the difference between values is
> smaller or equal to a certain threshold. I however realized that I might
> get there some unexpected results:
>
> > abs(1 - 0.95) >= 0.05
> [1] TRUE
> ## So that?s fine, but:
> > abs(1 - 0.95) <= 0.05
> [1] FALSE
>
> Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite
> disturbing.
>
> Along these lines:
> > abs(0.95 - 1) > 0.05
> [1] TRUE
> > abs(0.95 - 1) < 0.05
> [1] FALSE
>
> I guess that has to do with the floating point representation of the data?
>
> Is there something I miss or is there any solution to this?
> Thanks for any help!
>
> cheers, jo
>
>
>
> I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The
> R-version I used for the code above is:
>
> > sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Tue Apr  5 14:31:20 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Tue, 5 Apr 2016 15:31:20 +0300
Subject: [R] Problem with <= (less than or equal): not giving the
	expected result
In-Reply-To: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
Message-ID: <CAJ=0CtDzz3MaYyktUHMdOafYbL_JYpcn2nN+OpC4uUogqEJQvw@mail.gmail.com>

Yes, that does have to do with floating point representation.
I use this function for these types of comparisons (works with values as
well as with vectors):

check.equal <- function(x, y) {
    check.vector <- as.logical(unlist(lapply(x, all.equal, y)))
    check.vector[is.na(check.vector)] <- FALSE
    return(check.vector)
}

See:
?all.equal

Hth,
Adrian

On Tue, Apr 5, 2016 at 2:34 PM, Rainer Johannes <Johannes.Rainer at eurac.edu>
wrote:

> Dear All,
>
> I have the following problem:
>
> I have a function in which I check if the difference between values is
> smaller or equal to a certain threshold. I however realized that I might
> get there some unexpected results:
>
> > abs(1 - 0.95) >= 0.05
> [1] TRUE
> ## So that?s fine, but:
> > abs(1 - 0.95) <= 0.05
> [1] FALSE
>
> Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite
> disturbing.
>
> Along these lines:
> > abs(0.95 - 1) > 0.05
> [1] TRUE
> > abs(0.95 - 1) < 0.05
> [1] FALSE
>
> I guess that has to do with the floating point representation of the data?
>
> Is there something I miss or is there any solution to this?
> Thanks for any help!
>
> cheers, jo
>
>
>
> I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The
> R-version I used for the code above is:
>
> > sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From Johannes.Rainer at eurac.edu  Tue Apr  5 14:46:17 2016
From: Johannes.Rainer at eurac.edu (Rainer Johannes)
Date: Tue, 5 Apr 2016 12:46:17 +0000
Subject: [R] Problem with <= (less than or equal): not giving the
 expected result
In-Reply-To: <CAJ=0CtDzz3MaYyktUHMdOafYbL_JYpcn2nN+OpC4uUogqEJQvw@mail.gmail.com>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
	<CAJ=0CtDzz3MaYyktUHMdOafYbL_JYpcn2nN+OpC4uUogqEJQvw@mail.gmail.com>
Message-ID: <7916FA1C-F9A8-4CA3-916E-4C0959E94025@eurac.edu>

Thanks Adrian and Thierry (from the previous answer).

I was aware of the all.equal function, but there is nothing similar for <= (e.g. all.smallerEqual)?

cheers, jo

On 05 Apr 2016, at 14:31, Adrian Du?a <dusa.adrian at unibuc.ro<mailto:dusa.adrian at unibuc.ro>> wrote:

Yes, that does have to do with floating point representation.
I use this function for these types of comparisons (works with values as well as with vectors):

check.equal <- function(x, y) {
    check.vector <- as.logical(unlist(lapply(x, all.equal, y)))
    check.vector[is.na<http://is.na/>(check.vector)] <- FALSE
    return(check.vector)
}

See:
?all.equal

Hth,
Adrian

On Tue, Apr 5, 2016 at 2:34 PM, Rainer Johannes <Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu>> wrote:
Dear All,

I have the following problem:

I have a function in which I check if the difference between values is smaller or equal to a certain threshold. I however realized that I might get there some unexpected results:

> abs(1 - 0.95) >= 0.05
[1] TRUE
## So that?s fine, but:
> abs(1 - 0.95) <= 0.05
[1] FALSE

Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite disturbing.

Along these lines:
> abs(0.95 - 1) > 0.05
[1] TRUE
> abs(0.95 - 1) < 0.05
[1] FALSE

I guess that has to do with the floating point representation of the data?

Is there something I miss or is there any solution to this?
Thanks for any help!

cheers, jo



I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The R-version I used for the code above is:

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Apr  5 15:00:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 05 Apr 2016 06:00:26 -0700
Subject: [R] RWeka Error
In-Reply-To: <1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
	<1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <F1826B54-53CF-42B9-81C6-00FD6D1C3FB4@dcn.davis.ca.us>

Read the Posting Guide mentioned at the bottom of this email. Highlights you should be sure to address:

* HTML formatted email gets messed up on the R mailing lists, so post in plain text. Yes,  you can and need to do this. 

* Make sure the problem occurs in R by trying it without RStudio. Sometimes RStudio interferes with R, and you have to ask elsewhere about such problems. 

* Give us details about your setup and the exact commands you used. The sessionInfo function is helpful here, as is a sample of what you entered into a clean R session to get that error (for completeness). Make sure you are clear in your post about what operating system you are using, and what Java runtime (version and 32/64 bitness) is installed. 
-- 
Sent from my phone. Please excuse my brevity.

On April 5, 2016 5:14:55 AM PDT, "?Rini John? ? via R-help" <r-help at r-project.org> wrote:
>
>When I use any function of RWeka Package in Rstudio I get an error,
>"Error in .jnew (name): java.lang.ClassFormatError." can anyone guide
>me in this?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Apr  5 16:07:32 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 5 Apr 2016 16:07:32 +0200
Subject: [R] Problem with <= (less than or equal): not giving the
	expected result
In-Reply-To: <7916FA1C-F9A8-4CA3-916E-4C0959E94025@eurac.edu>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
	<CAJ=0CtDzz3MaYyktUHMdOafYbL_JYpcn2nN+OpC4uUogqEJQvw@mail.gmail.com>
	<7916FA1C-F9A8-4CA3-916E-4C0959E94025@eurac.edu>
Message-ID: <CAJuCY5zVt9xw=Kfq6QuJvhfYgv-aCQXkipWGUTaWDAeP3zXGqA@mail.gmail.com>

You could use something like this

x <- abs(0.95 - 1)
treshold <- 0.05
x < treshold | abs(x - treshold) < 1e-6


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-05 14:46 GMT+02:00 Rainer Johannes <Johannes.Rainer at eurac.edu>:

> Thanks Adrian and Thierry (from the previous answer).
>
> I was aware of the all.equal function, but there is nothing similar for <=
> (e.g. all.smallerEqual)?
>
> cheers, jo
>
> On 05 Apr 2016, at 14:31, Adrian Du?a <dusa.adrian at unibuc.ro<mailto:
> dusa.adrian at unibuc.ro>> wrote:
>
> Yes, that does have to do with floating point representation.
> I use this function for these types of comparisons (works with values as
> well as with vectors):
>
> check.equal <- function(x, y) {
>     check.vector <- as.logical(unlist(lapply(x, all.equal, y)))
>     check.vector[is.na<http://is.na/>(check.vector)] <- FALSE
>     return(check.vector)
> }
>
> See:
> ?all.equal
>
> Hth,
> Adrian
>
> On Tue, Apr 5, 2016 at 2:34 PM, Rainer Johannes <Johannes.Rainer at eurac.edu
> <mailto:Johannes.Rainer at eurac.edu>> wrote:
> Dear All,
>
> I have the following problem:
>
> I have a function in which I check if the difference between values is
> smaller or equal to a certain threshold. I however realized that I might
> get there some unexpected results:
>
> > abs(1 - 0.95) >= 0.05
> [1] TRUE
> ## So that?s fine, but:
> > abs(1 - 0.95) <= 0.05
> [1] FALSE
>
> Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite
> disturbing.
>
> Along these lines:
> > abs(0.95 - 1) > 0.05
> [1] TRUE
> > abs(0.95 - 1) < 0.05
> [1] FALSE
>
> I guess that has to do with the floating point representation of the data?
>
> Is there something I miss or is there any solution to this?
> Thanks for any help!
>
> cheers, jo
>
>
>
> I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The
> R-version I used for the code above is:
>
> > sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html<
> http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Johannes.Rainer at eurac.edu  Tue Apr  5 16:32:31 2016
From: Johannes.Rainer at eurac.edu (Rainer Johannes)
Date: Tue, 5 Apr 2016 14:32:31 +0000
Subject: [R] Problem with <= (less than or equal): not giving the
 expected result
In-Reply-To: <CAJuCY5zVt9xw=Kfq6QuJvhfYgv-aCQXkipWGUTaWDAeP3zXGqA@mail.gmail.com>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
	<CAJ=0CtDzz3MaYyktUHMdOafYbL_JYpcn2nN+OpC4uUogqEJQvw@mail.gmail.com>
	<7916FA1C-F9A8-4CA3-916E-4C0959E94025@eurac.edu>
	<CAJuCY5zVt9xw=Kfq6QuJvhfYgv-aCQXkipWGUTaWDAeP3zXGqA@mail.gmail.com>
Message-ID: <878F614C-D35F-4410-859A-AA74B745CFAF@eurac.edu>

Thanks!

On 05 Apr 2016, at 16:07, Thierry Onkelinx <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:

You could use something like this

x <- abs(0.95 - 1)
treshold <- 0.05
x < treshold | abs(x - treshold) < 1e-6


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

2016-04-05 14:46 GMT+02:00 Rainer Johannes <Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu>>:
Thanks Adrian and Thierry (from the previous answer).

I was aware of the all.equal function, but there is nothing similar for <= (e.g. all.smallerEqual)?

cheers, jo

On 05 Apr 2016, at 14:31, Adrian Du?a <dusa.adrian at unibuc.ro<mailto:dusa.adrian at unibuc.ro><mailto:dusa.adrian at unibuc.ro<mailto:dusa.adrian at unibuc.ro>>> wrote:

Yes, that does have to do with floating point representation.
I use this function for these types of comparisons (works with values as well as with vectors):

check.equal <- function(x, y) {
    check.vector <- as.logical(unlist(lapply(x, all.equal, y)))
    check.vector[is.na<http://is.na/><http://is.na/>(check.vector)] <- FALSE
    return(check.vector)
}

See:
?all.equal

Hth,
Adrian

On Tue, Apr 5, 2016 at 2:34 PM, Rainer Johannes <Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu><mailto:Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu>>> wrote:
Dear All,

I have the following problem:

I have a function in which I check if the difference between values is smaller or equal to a certain threshold. I however realized that I might get there some unexpected results:

> abs(1 - 0.95) >= 0.05
[1] TRUE
## So that?s fine, but:
> abs(1 - 0.95) <= 0.05
[1] FALSE

Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite disturbing.

Along these lines:
> abs(0.95 - 1) > 0.05
[1] TRUE
> abs(0.95 - 1) < 0.05
[1] FALSE

I guess that has to do with the floating point representation of the data?

Is there something I miss or is there any solution to this?
Thanks for any help!

cheers, jo



I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The R-version I used for the code above is:

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html><http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Apr  5 16:38:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 Apr 2016 07:38:44 -0700
Subject: [R] Problem with <= (less than or equal): not giving the
	expected result
In-Reply-To: <7916FA1C-F9A8-4CA3-916E-4C0959E94025@eurac.edu>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
	<CAJ=0CtDzz3MaYyktUHMdOafYbL_JYpcn2nN+OpC4uUogqEJQvw@mail.gmail.com>
	<7916FA1C-F9A8-4CA3-916E-4C0959E94025@eurac.edu>
Message-ID: <877156A4-22C7-4B0F-8EF9-D49E0BDA85DD@comcast.net>


> On Apr 5, 2016, at 5:46 AM, Rainer Johannes <Johannes.Rainer at eurac.edu> wrote:
> 
> Thanks Adrian and Thierry (from the previous answer).
> 
> I was aware of the all.equal function, but there is nothing similar for <= (e.g. all.smallerEqual)?

Perhaps you will gain understanding by looking at this:

> abs(1 - 0.95) - 0.05
[1] 4.163336e-17

Perhaps you want to make your own `all.<=`

> '%all.<=%'   <- function (e1,e2){ e1 < e2 | abs(e1-e2) < .Machine$double.eps^0.5 }
> abs(1 - 0.95) %all.<=% 0.05
[1] TRUE


-- 
David.
> 
> cheers, jo
> 
> On 05 Apr 2016, at 14:31, Adrian Du?a <dusa.adrian at unibuc.ro<mailto:dusa.adrian at unibuc.ro>> wrote:
> 
> Yes, that does have to do with floating point representation.
> I use this function for these types of comparisons (works with values as well as with vectors):
> 
> check.equal <- function(x, y) {
>    check.vector <- as.logical(unlist(lapply(x, all.equal, y)))
>    check.vector[is.na<http://is.na/>(check.vector)] <- FALSE
>    return(check.vector)
> }
> 
> See:
> ?all.equal
> 
> Hth,
> Adrian
> 
> On Tue, Apr 5, 2016 at 2:34 PM, Rainer Johannes <Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu>> wrote:
> Dear All,
> 
> I have the following problem:
> 
> I have a function in which I check if the difference between values is smaller or equal to a certain threshold. I however realized that I might get there some unexpected results:
> 
>> abs(1 - 0.95) >= 0.05
> [1] TRUE
> ## So that?s fine, but:
>> abs(1 - 0.95) <= 0.05
> [1] FALSE
> 
> Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite disturbing.
> 
> Along these lines:
>> abs(0.95 - 1) > 0.05
> [1] TRUE
>> abs(0.95 - 1) < 0.05
> [1] FALSE
> 
> I guess that has to do with the floating point representation of the data?
> 
> Is there something I miss or is there any solution to this?
> Thanks for any help!
> 
> cheers, jo
> 
> 
> 
> I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The R-version I used for the code above is:
> 
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jsorkin at grecc.umaryland.edu  Tue Apr  5 19:23:11 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 05 Apr 2016 13:23:11 -0400
Subject: [R] Specifying path to a windows server
Message-ID: <5703BC3F020000CB0014F9A3@smtp.medicine.umaryland.edu>

Windows 7 (local computer)
Windows server (server I am trying to reach)
 
I need to read a file whose windows path is of the form
 
\\Theserver\mydirectory\data.csv
 
You will note that as per windows standards the server name is preceded by two backslashes.
 
I am not sure how to specify this in R.  One usually needs to specify an escape characters in a path new which would suggest my path should be
 
 
\\\Theserver\\mydirectory\\data.csv
 
This does not work; the file is not found.
 
What is the correct way to specify a path to a server
 
Thanks,
John

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From bgunter.4567 at gmail.com  Tue Apr  5 19:31:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 5 Apr 2016 10:31:22 -0700
Subject: [R] Specifying path to a windows server
In-Reply-To: <5703BC3F020000CB0014F9A3@smtp.medicine.umaryland.edu>
References: <5703BC3F020000CB0014F9A3@smtp.medicine.umaryland.edu>
Message-ID: <CAGxFJbQSW=TZ3bjsZtnOX2qfndwXXrzeEy4pCbkZ7LoAYSg7GQ@mail.gmail.com>

almost ...

\\\\Theserver\\mydirectory\\data.csv

## should do it


-- Bert




On Tue, Apr 5, 2016 at 10:23 AM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> Windows 7 (local computer)
> Windows server (server I am trying to reach)
>
> I need to read a file whose windows path is of the form
>
> \\Theserver\mydirectory\data.csv
>
> You will note that as per windows standards the server name is preceded by two backslashes.
>
> I am not sure how to specify this in R.  One usually needs to specify an escape characters in a path new which would suggest my path should be
>
>
> \\\Theserver\\mydirectory\\data.csv
>
> This does not work; the file is not found.
>
> What is the correct way to specify a path to a server
>
> Thanks,
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From jdnewmil at dcn.davis.ca.us  Tue Apr  5 19:42:01 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 05 Apr 2016 10:42:01 -0700
Subject: [R] Specifying path to a windows server
In-Reply-To: <5703BC3F020000CB0014F9A3@smtp.medicine.umaryland.edu>
References: <5703BC3F020000CB0014F9A3@smtp.medicine.umaryland.edu>
Message-ID: <E29EA628-55F6-41B5-81D4-8BE53ABA6D82@dcn.davis.ca.us>

Each \ has to be escaped. Two becomes four, not three. 
-- 
Sent from my phone. Please excuse my brevity.

On April 5, 2016 10:23:11 AM PDT, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>Windows 7 (local computer)
>Windows server (server I am trying to reach)
> 
>I need to read a file whose windows path is of the form
> 
>\\Theserver\mydirectory\data.csv
> 
>You will note that as per windows standards the server name is preceded
>by two backslashes.
> 
>I am not sure how to specify this in R.  One usually needs to specify
>an escape characters in a path new which would suggest my path should
>be
> 
> 
>\\\Theserver\\mydirectory\\data.csv
> 
>This does not work; the file is not found.
> 
>What is the correct way to specify a path to a server
> 
>Thanks,
>John
>
> 
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>
>Confidentiality Statement:
>This email message, including any attachments, is for t...{{dropped:15}}


From francisco.mcfb at hotmail.com  Tue Apr  5 17:26:06 2016
From: francisco.mcfb at hotmail.com (Francisco Banha)
Date: Tue, 5 Apr 2016 16:26:06 +0100
Subject: [R] Good pointers for understanding the R language implementation
Message-ID: <DUB130-W48100CFC680EC9C720BDB7859E0@phx.gbl>

Dear All,

I'm currently working on a project with the purpose of remotely executing R code, which requires me to have to work with the code of R itself. I've searched the Internet for good information that will help me understand how R is implemented but what I've got so far isn't detailed enough.
I've looked specifically at CRAN's manuals on the official website but they only address this issue briefly. I've also looked at other contents online but so far nothing has turned up that has the level of detail that I need to properly understand the inner workings of R.
For example, I need to understand how exactly an expression is parsed and evaluated, because I will need to intervene in the process to decide whether to execute it remotely or not.
Does anyone know of good pointers that would help me understand this?
Thanks for any help!

Best regards,
Francisco
 		 	   		  
	[[alternative HTML version deleted]]


From kikx_francisco at hotmail.com  Tue Apr  5 17:31:59 2016
From: kikx_francisco at hotmail.com (Francisco Banha)
Date: Tue, 5 Apr 2016 16:31:59 +0100
Subject: [R] Good pointers for understanding the R language implementation
Message-ID: <DUB130-W53F4F6D1F1A77E5C1195DA859E0@phx.gbl>

Dear All,

I'm currently working on a project with 
the purpose of remotely executing R code, which requires me to have to 
work with the code of R itself. I've searched the Internet for good 
information that will help me understand how R is implemented but what 
I've got so far isn't detailed enough.
I've looked specifically at 
CRAN's manuals on the official website but they only address this issue 
briefly. I've also looked at other contents online but so far nothing 
has turned up that has the level of detail that I need to properly 
understand the inner workings of R.
For example, I need to understand
 how exactly an expression is parsed and evaluated, because I will need 
to intervene in the process to decide whether to execute it remotely or 
not.
Does anyone know of good pointers that would help me understand this?
Thanks for any help!

Best regards,
Francisco 		 	   		  
	[[alternative HTML version deleted]]


From heyao at pku.edu.cn  Tue Apr  5 19:27:48 2016
From: heyao at pku.edu.cn (=?UTF-8?B?5L2V5bCn?=)
Date: Wed, 06 Apr 2016 01:27:48 +0800
Subject: [R] Is that an efficient way to find the overlapped ,
 upstream and downstream ranges for a bunch of ranges
Message-ID: <305EBB12-4F96-4985-B04D-C74D45FBC260@pku.edu.cn>

I do have a bunch of genes ( nearly ~50000)  from the whole genome, which read in genomic ranges

A range(gene) can be seem as an observation has three columns chromosome, start and end, like that

       seqnames start end width strand

gene1     chr1     1   5     5      +

gene2     chr1    10  15     6      +

gene3     chr1    12  17     6      +

gene4     chr1    20  25     6      +

gene5     chr1    30  40    11      +

I just wondering is there an efficient way to find overlapped, upstream and downstream genes for each gene in the granges

For example, assuming all_genes_gr is a ~50000 genes genomic range, the result I want like belows:

gene_nameupstream_genedownstream_geneoverlapped_gene
gene1NAgene2NA
gene2gene1gene4gene3
gene3gene1gene4gene2
gene4gene3gene5NA

Currently ,  the strategy I use is like that,  
library(GenomicRanges)
find_overlapped_gene <- function(idx, all_genes_gr) {
  #cat(idx, "\n")
  curr_gene <- all_genes_gr[idx]
  other_genes <- all_genes_gr[-idx]
  n <- countOverlaps(curr_gene, other_genes)
  gene <- subsetByOverlaps(curr_gene, other_genes)
  return(list(n, gene))
}?

system.time(lapply(1:100, function(idx)  find_overlapped_gene(idx, all_genes_gr)))
However, for 100 genes, it use nearly ~8s by system.time().That means if I had 50000 genes, nearly one hour for just find overlapped gene. 

I am just wondering any algorithm or strategy to do that efficiently, perhaps 50000 genes in ~10min or even less

 



	[[alternative HTML version deleted]]


From yao.h.1988 at gmail.com  Tue Apr  5 19:29:36 2016
From: yao.h.1988 at gmail.com (Yao He)
Date: Wed, 6 Apr 2016 01:29:36 +0800
Subject: [R] Is that an efficient way to find the overlapped ,
 upstream and downstream rangess for a bunch of rangess
Message-ID: <CAKK5bs9kNF2s54aYHbyfAZ36mq2QYKqzYVLby9VtZeASGYwpFw@mail.gmail.com>

I do have a bunch of genes ( nearly ~50000)  from the whole genome, which
read in genomic ranges

A range(gene) can be seem as an observation has three columns chromosome,
start and end, like that

       seqnames start end width strand

gene1     chr1     1   5     5      +

gene2     chr1    10  15     6      +

gene3     chr1    12  17     6      +

gene4     chr1    20  25     6      +

gene5     chr1    30  40    11      +

I just wondering is there an efficient way to find *overlapped, upstream
and downstream genes for each gene in the granges*

For example, assuming all_genes_gr is a ~50000 genes genomic range, the
result I want like belows:
gene_name upstream_gene downstream_gene overlapped_gene
gene1 NA gene2 NA
gene2 gene1 gene4 gene3
gene3 gene1 gene4 gene2
gene4 gene3 gene5 NA

Currently ,  the strategy I use is like that,

library(GenomicRanges)

find_overlapped_gene <- function(idx, all_genes_gr) {
  #cat(idx, "\n")
  curr_gene <- all_genes_gr[idx]
  other_genes <- all_genes_gr[-idx]
  n <- countOverlaps(curr_gene, other_genes)
  gene <- subsetByOverlaps(curr_gene, other_genes)
  return(list(n, gene))
}?

system.time(lapply(1:100, function(idx)  find_overlapped_gene(idx,
all_genes_gr)))

However, for 100 genes, it use nearly ~8s by system.time().That means if I
had 50000 genes, nearly one hour for just find overlapped gene.

I am just wondering any algorithm or strategy to do that efficiently,
perhaps 50000 genes in ~10min or even less

Yao He

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Wed Apr  6 01:53:56 2016
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Tue, 5 Apr 2016 18:53:56 -0500
Subject: [R] Fwd: as.Date gives NAs when transforming from factor
In-Reply-To: <56084f96728f4ea39c4e034a95ed7aa8@EMED3EXMD03S16.global.publicisgroupe.net>
References: <56084f96728f4ea39c4e034a95ed7aa8@EMED3EXMD03S16.global.publicisgroupe.net>
Message-ID: <CAM-xyZhDT+ND=zr4p3QMiu-yqpRACknF3K52YueAv4yG2w+npg@mail.gmail.com>

Hi,

I would appreciate your help.

I?m having problems when transforming  a column from ?factor? to ?date?.



It does not convert just: 31/03/2016 correctly, it out puts: NA.



04/04/2016  turns out as: 2016-04-04



02/04/2016 turns out as: 2016-02-04



31/03/2016 turns out as: NA

03/04/2016 turns out as: 2016-03-04.







Code:

a <- read.csv("dates.csv", stringsAsFactors = F)



a$Date <- as.Date(a$Date, format = "%m/%d/%Y")




Posible Solutions:



I?ve read here that it has to do with the Sys Locale, and the solution was
using: ?LC_TIME?, ?C?. But I didn?t have success.

http://stackoverflow.com/questions/15566875/as-date-returning-na-in-r






# Sys.getlocale("LC_TIME")

#

# Sys.setlocale("LC_TIME", "C")












Slds,











------------------------------------------------------------------------
> Disclaimer The information in this email and any attachments may contain
proprietary and privileged information that is intended for the
addressee(s) only. If you are not the intended recipient, you are hereby
notified that any disclosure, copying, distribution, retention or use of
the contents of this information is prohibited. When addressed to our
clients or vendors, any information contained in this e-mail or any
attachments is subject to the terms and conditions in any governing
contract. If you have received this e-mail in error, please immediately
contact the sender and delete the e-mail..

From jdnewmil at dcn.davis.ca.us  Wed Apr  6 02:05:29 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 05 Apr 2016 17:05:29 -0700
Subject: [R] Fwd: as.Date gives NAs when transforming from factor
In-Reply-To: <CAM-xyZhDT+ND=zr4p3QMiu-yqpRACknF3K52YueAv4yG2w+npg@mail.gmail.com>
References: <56084f96728f4ea39c4e034a95ed7aa8@EMED3EXMD03S16.global.publicisgroupe.net>
	<CAM-xyZhDT+ND=zr4p3QMiu-yqpRACknF3K52YueAv4yG2w+npg@mail.gmail.com>
Message-ID: <6828947E-2B02-40EF-A426-966CFE7A3BDA@dcn.davis.ca.us>

Don't give a factor to as.Date. Convert it to character first, or avoid letting it become a factor in the first place by using the stringsAsFactors =FALSE option to the read.table function or its related functions. 
-- 
Sent from my phone. Please excuse my brevity.

On April 5, 2016 4:53:56 PM PDT, "Omar Andr? Gonz?les D?az" <oma.gonzales at gmail.com> wrote:
>Hi,
>
>I would appreciate your help.
>
>I?m having problems when transforming  a column from ?factor? to
>?date?.
>
>
>
>It does not convert just: 31/03/2016 correctly, it out puts: NA.
>
>
>
>04/04/2016  turns out as: 2016-04-04
>
>
>
>02/04/2016 turns out as: 2016-02-04
>
>
>
>31/03/2016 turns out as: NA
>
>03/04/2016 turns out as: 2016-03-04.
>
>
>
>
>
>
>
>Code:
>
>a <- read.csv("dates.csv", stringsAsFactors = F)
>
>
>
>a$Date <- as.Date(a$Date, format = "%m/%d/%Y")
>
>
>
>
>Posible Solutions:
>
>
>
>I?ve read here that it has to do with the Sys Locale, and the solution
>was
>using: ?LC_TIME?, ?C?. But I didn?t have success.
>
>http://stackoverflow.com/questions/15566875/as-date-returning-na-in-r
>
>
>
>
>
>
># Sys.getlocale("LC_TIME")
>
>#
>
># Sys.setlocale("LC_TIME", "C")
>
>
>
>
>
>
>
>
>
>
>
>
>Slds,
>
>
>
>
>
>
>
>
>
>
>
>------------------------------------------------------------------------
>> Disclaimer The information in this email and any attachments may
>contain
>proprietary and privileged information that is intended for the
>addressee(s) only. If you are not the intended recipient, you are
>hereby
>notified that any disclosure, copying, distribution, retention or use
>of
>the contents of this information is prohibited. When addressed to our
>clients or vendors, any information contained in this e-mail or any
>attachments is subject to the terms and conditions in any governing
>contract. If you have received this e-mail in error, please immediately
>contact the sender and delete the e-mail..
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr  6 02:19:14 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 5 Apr 2016 20:19:14 -0400
Subject: [R] Fwd: as.Date gives NAs when transforming from factor
In-Reply-To: <CAM-xyZhDT+ND=zr4p3QMiu-yqpRACknF3K52YueAv4yG2w+npg@mail.gmail.com>
References: <56084f96728f4ea39c4e034a95ed7aa8@EMED3EXMD03S16.global.publicisgroupe.net>
	<CAM-xyZhDT+ND=zr4p3QMiu-yqpRACknF3K52YueAv4yG2w+npg@mail.gmail.com>
Message-ID: <57045602.4020504@gmail.com>

On 05/04/2016 7:53 PM, Omar Andr? Gonz?les D?az wrote:
> Hi,
>
> I would appreciate your help.
>
> I?m having problems when transforming  a column from ?factor? to ?date?.
>
>
>
> It does not convert just: 31/03/2016 correctly, it out puts: NA.
>
>
>
> 04/04/2016  turns out as: 2016-04-04
>
>
>
> 02/04/2016 turns out as: 2016-02-04
>
>
>
> 31/03/2016 turns out as: NA
>
> 03/04/2016 turns out as: 2016-03-04.
>
>
>
>
>
>
>
> Code:
>
> a <- read.csv("dates.csv", stringsAsFactors = F)
>
>
>
> a$Date <- as.Date(a$Date, format = "%m/%d/%Y")


You are specifying month/day/year format. There's no month 31.
You probably want

a$Date <- as.Date(a$Date, format = "%d/%m/%Y")


Duncan Murdoch

>
>
>
>
> Posible Solutions:
>
>
>
> I?ve read here that it has to do with the Sys Locale, and the solution was
> using: ?LC_TIME?, ?C?. But I didn?t have success.
>
> http://stackoverflow.com/questions/15566875/as-date-returning-na-in-r
>
>
>
>
>
>
> # Sys.getlocale("LC_TIME")
>
> #
>
> # Sys.setlocale("LC_TIME", "C")
>
>
>
>
>
>
>
>
>
>
>
>
> Slds,
>
>
>
>
>
>
>
>
>
>
>
> ------------------------------------------------------------------------
>> Disclaimer The information in this email and any attachments may contain
> proprietary and privileged information that is intended for the
> addressee(s) only. If you are not the intended recipient, you are hereby
> notified that any disclosure, copying, distribution, retention or use of
> the contents of this information is prohibited. When addressed to our
> clients or vendors, any information contained in this e-mail or any
> attachments is subject to the terms and conditions in any governing
> contract. If you have received this e-mail in error, please immediately
> contact the sender and delete the e-mail..
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 2040684K at student.gla.ac.uk  Wed Apr  6 01:58:52 2016
From: 2040684K at student.gla.ac.uk (Nils Korte)
Date: Wed, 6 Apr 2016 00:58:52 +0100
Subject: [R] Heatmap Colnames
Message-ID: <237DF621D87E8E4EBF5CA9CB5C8DA8F9EBB9ABBD0F@CMS04.campus.gla.ac.uk>

Hello,
please see below my code for a heatmap. Unfortunately my column names do not completely appear. Can you please send me the appropriate code to visualise them?
Many Thanks!
Nils


library(GMD)

dat<-data.frame(EntryA=as.numeric(c(4.24,3,1.66,1.28,1.2,-1.32,-1.88)), EntryB=as.numeric(c(4.16,4.82,-1.82,-3.02,0.99,1.1,-3.31)))

rownames(dat)=c("hsa-miR-200c","hsa-miR-520b","hsa-miR-199a-3p","mmu-miR-124a","hsa-miR-302a","hsa-miR-454","mmu-miR-137") 

colnames(dat)=c("24", "72")

heatmap.3(dat, srtCol=70)

ndat<-as.matrix(dat)

heatmap.3(ndat, Rowv=FALSE, Colv=FALSE)


From drjimlemon at gmail.com  Wed Apr  6 02:48:49 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 6 Apr 2016 10:48:49 +1000
Subject: [R] Heatmap Colnames
In-Reply-To: <237DF621D87E8E4EBF5CA9CB5C8DA8F9EBB9ABBD0F@CMS04.campus.gla.ac.uk>
References: <237DF621D87E8E4EBF5CA9CB5C8DA8F9EBB9ABBD0F@CMS04.campus.gla.ac.uk>
Message-ID: <CA+8X3fXrrceXT34rYV-dUogJ-yHi8QKqX=eEz7Rt_YmnaeO4NA@mail.gmail.com>

Hi Nils,
I don't have the GMD library, but this looks like some axis labels are
being ignored to avoid overlapping. If heatmap.3 uses base graphics
you can probably get your labels by passing empty strings to heatmap.3
and then displaying the axis with staxlab (plotrix).

Jim


On Wed, Apr 6, 2016 at 9:58 AM, Nils Korte <2040684K at student.gla.ac.uk> wrote:
> Hello,
> please see below my code for a heatmap. Unfortunately my column names do not completely appear. Can you please send me the appropriate code to visualise them?
> Many Thanks!
> Nils
>
>
> library(GMD)
>
> dat<-data.frame(EntryA=as.numeric(c(4.24,3,1.66,1.28,1.2,-1.32,-1.88)), EntryB=as.numeric(c(4.16,4.82,-1.82,-3.02,0.99,1.1,-3.31)))
>
> rownames(dat)=c("hsa-miR-200c","hsa-miR-520b","hsa-miR-199a-3p","mmu-miR-124a","hsa-miR-302a","hsa-miR-454","mmu-miR-137")
>
> colnames(dat)=c("24", "72")
>
> heatmap.3(dat, srtCol=70)
>
> ndat<-as.matrix(dat)
>
> heatmap.3(ndat, Rowv=FALSE, Colv=FALSE)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Apr  6 03:10:41 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 5 Apr 2016 21:10:41 -0400
Subject: [R] File 1 is not in sorted order Error
In-Reply-To: <CANGs2ysqsbieiL2TqfGe1YTab1y1JdapFggcZQAyvu8iDEP6pg@mail.gmail.com>
References: <CANGs2ysqsbieiL2TqfGe1YTab1y1JdapFggcZQAyvu8iDEP6pg@mail.gmail.com>
Message-ID: <57046211.5030708@gmail.com>

On 02/04/2016 10:40 PM, Michael Morrison wrote:
> Hi, I'm trying to build R on windows and i'm getting the following error
> when i run the "make all recommended" command:
>
> C:/Rtools/mingw_64/bin/windres -F pe-x86-64   -i dllversion.rc -o
> dllversion.o
> comm: file 1 is not in sorted order
> make[4]: *** [Rgraphapp.def] Error 1
> make[3]: *** [rlibs] Error 1
> make[2]: *** [../../bin/x64/R.dll] Error 2
> make[1]: *** [rbuild] Error 2
> make: *** [all] Error 2
>
>
> Can someone please help me figure out this error. I've tried researching on
> my own but i'm out of options. Thanks in advance.
>

Set the environment variable LC_COLLATE equal to C.  Some parts of the R 
build system do this, and some parts use your locale's collation 
sequence.  You need to make sure they're all consistent.

Duncan Murdoch


From dwinsemius at comcast.net  Wed Apr  6 03:21:03 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 Apr 2016 18:21:03 -0700
Subject: [R] Is that an efficient way to find the overlapped ,
	upstream and downstream ranges for a bunch of ranges
In-Reply-To: <305EBB12-4F96-4985-B04D-C74D45FBC260@pku.edu.cn>
References: <305EBB12-4F96-4985-B04D-C74D45FBC260@pku.edu.cn>
Message-ID: <8D38875D-9DD6-4F29-AB83-E95DD0F2DC8E@comcast.net>


> On Apr 5, 2016, at 10:27 AM, ?? <heyao at pku.edu.cn> wrote:
> 
> I do have a bunch of genes ( nearly ~50000)  from the whole genome, which read in genomic ranges
> 
> A range(gene) can be seem as an observation has three columns chromosome, start and end, like that
> 
>       seqnames start end width strand
> 
> gene1     chr1     1   5     5      +
> 
> gene2     chr1    10  15     6      +
> 
> gene3     chr1    12  17     6      +
> 
> gene4     chr1    20  25     6      +
> 
> gene5     chr1    30  40    11      +
> 
> I just wondering is there an efficient way to find overlapped, upstream and downstream genes for each gene in the granges

The data.table package (in CRAN) and the iRanges package (in bioC) have formalized efficient approaches to those problems.


> 
> For example, assuming all_genes_gr is a ~50000 genes genomic range, the result I want like belows:
> 
> gene_nameupstream_genedownstream_geneoverlapped_gene
> gene1NAgene2NA
> gene2gene1gene4gene3
> gene3gene1gene4gene2
> gene4gene3gene5NA
> 
> Currently ,  the strategy I use is like that,  
> library(GenomicRanges)
> find_overlapped_gene <- function(idx, all_genes_gr) {
>  #cat(idx, "\n")
>  curr_gene <- all_genes_gr[idx]
>  other_genes <- all_genes_gr[-idx]
>  n <- countOverlaps(curr_gene, other_genes)
>  gene <- subsetByOverlaps(curr_gene, other_genes)
>  return(list(n, gene))
> }?
> 
> system.time(lapply(1:100, function(idx)  find_overlapped_gene(idx, all_genes_gr)))
> However, for 100 genes, it use nearly ~8s by system.time().That means if I had 50000 genes, nearly one hour for just find overlapped gene. 
> 
> I am just wondering any algorithm or strategy to do that efficiently, perhaps 50000 genes in ~10min or even less
> 
I suspect this would happen on a much faster basis for such a small dataset.

-- 
David.



> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Apr  6 03:33:56 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 Apr 2016 18:33:56 -0700
Subject: [R] Good pointers for understanding the R language
	implementation
In-Reply-To: <DUB130-W48100CFC680EC9C720BDB7859E0@phx.gbl>
References: <DUB130-W48100CFC680EC9C720BDB7859E0@phx.gbl>
Message-ID: <2064D326-2704-4B36-8474-F7147DC12FD7@comcast.net>


> On Apr 5, 2016, at 8:26 AM, Francisco Banha <francisco.mcfb at hotmail.com> wrote:
> 
> Dear All,
> 
> I'm currently working on a project with the purpose of remotely executing R code, which requires me to have to work with the code of R itself. I've searched the Internet for good information that will help me understand how R is implemented but what I've got so far isn't detailed enough.

This is too vague for commentary. If you claim that you have digested  all of "The R Language Definition", "R Internals", and "R Installation and Administration", (all of which are shipped with the standard R distro) then I suggest you are either the wisest man on Earth, or you should be evaluated by a psychiatrist who is also a skilled R programmer. (Are there any such?) 

> I've looked specifically at CRAN's manuals on the official website but they only address this issue briefly. I've also looked at other contents online but so far nothing has turned up that has the level of detail that I need to properly understand the inner workings of R.
> For example, I need to understand how exactly an expression is parsed and evaluated, because I will need to intervene in the process to decide whether to execute it remotely or not.
> Does anyone know of good pointers that would help me understand this?

If you run candidate text through the `parse`-function you can determine whether it is syntactically evaluable. But then what? Are you trying to filter expressions on the basis of some sort of "safety index"?


> Thanks for any help!
> 
> Best regards,
> Francisco
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Wed Apr  6 06:00:24 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 6 Apr 2016 14:00:24 +1000
Subject: [R] R-dvel [robustness Simulation study of 2 sample test on
 several combination of factors ]
In-Reply-To: <KL1PR01MB08871DA5DB29B6DB8C78579CB59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
	<CA+8X3fWqRijLtXxXfi33A_iZ-AF0wAwGbKEw6EBtvRkJQ6XtWg@mail.gmail.com>
	<KL1PR01MB08871DA5DB29B6DB8C78579CB59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fUd185i2__Yx8KpnnhhUXakuC_bjCgYvVhX7F4kFSXF5Q@mail.gmail.com>

You have quite a few mistakes in your example. The code below works
for me - you can wrap it in a function if you like. I think you will
need a lot more practice before you can write something like this in R
as you are missing close braces and haven't really worked out the
difference between the number of calculations you are doing for each
replication and the number of replications. It takes 5-10 minutes to
run.

 ## Put the samples sizes into matrix then use a loop for sample sizes
sample_sizes<-
 matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
 nrow=2)

#create vector to combine all std deviations
sds<-c(4,6,8,10,12,14)
# this number is needed below
nsds<-length(sds)
set.seed(8)

#number of simulations
nSims<-10000
#set significance level,alpha for the whole simulatio
alpha<-0.05

#set empty vector of length no.of _calculations_ to store p-values
# Note: you have 54 calculations, not 10000
ncalcs<-dim(sample_sizes)[2]*nsds
t_equal <-c(rep(0,length=ncalcs))
t_unequal <-c(rep(0,length=ncalcs))
mann <-c(rep(0,length=ncalcs))

#set up matrix for storing data from the vectors
# but you do want 10000 replications of each calculation
matrix_Equal<-matrix(rep(NA,ncalcs*nSims),nrow=nSims)
matrix_Unequal<-matrix(rep(NA,ncalcs*nSims),nrow=nSims)
matrix_mann<-matrix(rep(NA,ncalcs*nSims),nrow=nSims)

############Simulations

for (sim in 1:nSims){
 # this loop steps through the sample sizes
 for(ss in 1:dim(sample_sizes)[2]) {
  m<-sample_sizes[1,ss]
  n<-sample_sizes[2,ss]
  # initialize the index for results
  i<-1
  for (sd in sds) {  #first group's standard deviation
   #generate random samples from 2 normal distribution
   x_norm1<-rnorm(m,5,sds)
   y_norm2<-rnorm(n,5,4)
   #extract p-value out and store it in vectors
   t_equal[(ss-1)*nsds+i]<-t.test(x_norm1,y_norm2,var.equal=TRUE)$p.value
   t_unequal[(ss-1)*nsds+i]<-t.test(x_norm1,y_norm2,var.equal=FALSE)$p.value
   mann[(ss-1)*nsds+i] <-wilcox.test(x_norm1,y_norm2)$p.value
   i<-i+1
  }
 }
 #store the current result into matrices by rows
 matrix_Equal[sim,]<-t_equal
 matrix_Unequal[sim,]<-t_unequal
 matrix_mann[sim,]<-mann
}
##print results
matrix_Equal
matrix_Unequal
matrix_mann

Jim

On Wed, Apr 6, 2016 at 12:43 AM, tan sj <sj_style_1125 at outlook.com> wrote:
> Hi, Jim, i read through your example,
> I tried to write a code modified yours example and my ideas ...
> In last email, you replied that "results[[(ss-1)*nssds+ssd_index]]<-<your_test>" ,can i know further about this ? Because i am not very understand about this .
> I am sorry that i am really a new bird in this field...
> but the code turn out it have some error ...
> Below shown my attempt...
>
>  ## Put the samples sizes into matrix then use a loop for sample sizes
> sample_sizes<-
>  matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
>  nrow=2)
>
> #create vector to combine all std deviations
> sds<-c(4,6,8,10,12,14)
>
> set.seed(8)
>
> #number of simulations
> nSims<-10000
> #set significance level,alpha for the whole simulatio
> alpha<-0.05
>
> #set empty vector of length no.of simulation(10000) to store p-value
> t_equal <-c(length=nSims)
> t_unequal <-c(length=nSims)
> mann <-c(length=nSims)
>
> #set up matrix for storing data from the vectors
> matrix_Equal<-matrix(t_equal,nrow=nSims)
> matrix_Unequal<-matrix(t_unequal,nrow=nSims)
> matrix_mann<-matrix(mann,nrow=nSims)
>
> ############Simulations
>
> #BULID A FUNCTION for a collection of statement
> f<-function(m,n,sd)
> {
> for (i in 1:nSims){
>
> # this loop steps through the sample sizes
> for(ss in 1:dim(sample_sizes)[2])
> {
> m<-sample_sizes[1,ss]
> n<-sample_sizes[2,ss]
> {
> for (sd in sds)   #first group's standard deviation
> {
> #generate random samples from 2 normal distribution
> x_norm1<-rnorm(m,5,sds)
> y_norm2<-rnorm(n,5,4)
>
> #extract p-value out and store it in vectors
> t_equal[i]<-t.test(x_norm1,y_norm2,var.equal=TRUE)$p.value
> t_unequal[i]<-t.test(x_norm1,y_norm2,var.equal=FALSE)$p.value
> mann[i] <-wilcox.test(x_norm1,y_norm2)$p.value
>
> ##store the result into matrix defined before
> matrix_Equal<-t_equal
> matrix_Unequal<-t_unequal
> matrix_mann<-mann
>
> ##print results
> matrix_Equal
> matrix_Unequal
> matrix_mann
>
> }
>  }
>   }
> }
> }
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, April 5, 2016 2:38 AM
> To: tan sj
> Cc: r-help at r-project.org
> Subject: Re: [R] R-dvel [robustness Simulation study of 2 sample test on several combination of factors ]
>
> Hi sst,
> You could set up your sample sizes as a matrix if you don't want all
> of the combinations:
>
> sample_sizes<-matrix(c(10,10,10,25,25,25,...),nrow=2)
>
> and then use one loop for the sample sizes:
>
> for(ss in 1:dim(sample_sizes)[2]) {
>  ss1<-sample_sizes[1,ss]
>  ss2<-sample_sizes[2,ss]
>
> then step through your SDs:
>
> for(ssd in  c(4,4.4,5,6,8)) {
>
> Jim
>
> On Tue, Apr 5, 2016 at 11:15 AM, tan sj <sj_style_1125 at outlook.com> wrote:
>> hi, i am new in this field.
>>
>>
>> do
>> favorite<http://stackoverflow.com/questions/36404707/simulation-study-of-2-sample-test-on-different-combination-of-factors#>
>>
>>
>> If I wish to conduct a simulation on the robustness of two sample test by using R language, is that any ways in writing the code?
>> There are several factors
>> (sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100))
>>
>> (standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50))
>> distribution of gamma distribution with unequal skewness and equal skewness
>>
>> I wish to test the pooled variance t test and welch t test and mann whitney by using the above combination of factors. But how can I combine them by using for loop or apply function??
>> I am intending to use apply function but i am stucking. If i use for loop function, can i use for loop with vectors ?
>> for (a in c(25,50,100)) #first group of sample sizes
>> { for (b in c(25,50,100)) #second group of sample sizes
>> { for (d in c(4,4.4,5,6,8)) #different SDs of first sample
>> the above code is an example that I would like to modified but I found I have different sets of sample sizes.
>>
>> So if for loop with vectors, as shown in the code above, will the computer run from part (a) 25, to part(b) 25, then to the part (d) 4? then again the rotation 50->50->4.4?
>>
>> ?I hope can hear any news from this website ....please..thanks you.
>>
>> Regards
>> sst
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Apr  6 06:27:32 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 6 Apr 2016 04:27:32 +0000
Subject: [R] Fwd: as.Date gives NAs when transforming from factor
In-Reply-To: <6828947E-2B02-40EF-A426-966CFE7A3BDA@dcn.davis.ca.us>
References: <56084f96728f4ea39c4e034a95ed7aa8@EMED3EXMD03S16.global.publicisgroupe.net>
	<CAM-xyZhDT+ND=zr4p3QMiu-yqpRACknF3K52YueAv4yG2w+npg@mail.gmail.com>
	<6828947E-2B02-40EF-A426-966CFE7A3BDA@dcn.davis.ca.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5024DC0@SRVEXCHMBX.precheza.cz>

Hi

I did not have problems transforming factors to dates, only when trying to transform nonexistent date.

> as.Date(factor(c("31.3.2015", "29.2.2015")), format="%d.%m.%Y")
[1] "2015-03-31" NA
>
Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> Newmiller
> Sent: Wednesday, April 6, 2016 2:05 AM
> To: Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com>; r-help at R-
> project.org
> Subject: Re: [R] Fwd: as.Date gives NAs when transforming from factor
>
> Don't give a factor to as.Date. Convert it to character first, or avoid letting it
> become a factor in the first place by using the stringsAsFactors =FALSE option
> to the read.table function or its related functions.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 5, 2016 4:53:56 PM PDT, "Omar Andr? Gonz?les D?az"
> <oma.gonzales at gmail.com> wrote:
> >Hi,
> >
> >I would appreciate your help.
> >
> >I?m having problems when transforming  a column from ?factor? to
> >?date?.
> >
> >
> >
> >It does not convert just: 31/03/2016 correctly, it out puts: NA.
> >
> >
> >
> >04/04/2016  turns out as: 2016-04-04
> >
> >
> >
> >02/04/2016 turns out as: 2016-02-04
> >
> >
> >
> >31/03/2016 turns out as: NA
> >
> >03/04/2016 turns out as: 2016-03-04.
> >
> >
> >
> >
> >
> >
> >
> >Code:
> >
> >a <- read.csv("dates.csv", stringsAsFactors = F)
> >
> >
> >
> >a$Date <- as.Date(a$Date, format = "%m/%d/%Y")
> >
> >
> >
> >
> >Posible Solutions:
> >
> >
> >
> >I?ve read here that it has to do with the Sys Locale, and the solution
> >was
> >using: ?LC_TIME?, ?C?. But I didn?t have success.
> >
> >http://stackoverflow.com/questions/15566875/as-date-returning-na-in-r
> >
> >
> >
> >
> >
> >
> ># Sys.getlocale("LC_TIME")
> >
> >#
> >
> ># Sys.setlocale("LC_TIME", "C")
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >Slds,
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >-----------------------------------------------------------------------
> >-
> >> Disclaimer The information in this email and any attachments may
> >contain
> >proprietary and privileged information that is intended for the
> >addressee(s) only. If you are not the intended recipient, you are
> >hereby notified that any disclosure, copying, distribution, retention
> >or use of the contents of this information is prohibited. When
> >addressed to our clients or vendors, any information contained in this
> >e-mail or any attachments is subject to the terms and conditions in any
> >governing contract. If you have received this e-mail in error, please
> >immediately contact the sender and delete the e-mail..
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Apr  6 06:42:41 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 6 Apr 2016 04:42:41 +0000
Subject: [R] Problem with <= (less than or equal): not giving the
 expected result
In-Reply-To: <878F614C-D35F-4410-859A-AA74B745CFAF@eurac.edu>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
	<CAJ=0CtDzz3MaYyktUHMdOafYbL_JYpcn2nN+OpC4uUogqEJQvw@mail.gmail.com>
	<7916FA1C-F9A8-4CA3-916E-4C0959E94025@eurac.edu>
	<CAJuCY5zVt9xw=Kfq6QuJvhfYgv-aCQXkipWGUTaWDAeP3zXGqA@mail.gmail.com>
	<878F614C-D35F-4410-859A-AA74B745CFAF@eurac.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5024E18@SRVEXCHMBX.precheza.cz>

Hi

Or some rounding when comparing results with threshold exactly.

> round(abs(0.95 - 1),2) > 0.05
[1] FALSE
> round(abs(0.95 - 1),2) < 0.05
[1] FALSE
>
Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rainer
> Johannes
> Sent: Tuesday, April 5, 2016 4:33 PM
> To: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Cc: r-help at r-project.org; Adrian Du?a <dusa.adrian at unibuc.ro>
> Subject: Re: [R] Problem with <= (less than or equal): not giving the expected
> result
>
> Thanks!
>
> On 05 Apr 2016, at 16:07, Thierry Onkelinx
> <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>> wrote:
>
> You could use something like this
>
> x <- abs(0.95 - 1)
> treshold <- 0.05
> x < treshold | abs(x - treshold) < 1e-6
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of
> anecdote is not data. ~ Roger Brinner The combination of some data and an
> aching desire for an answer does not ensure that a reasonable answer can be
> extracted from a given body of data. ~ John Tukey
>
> 2016-04-05 14:46 GMT+02:00 Rainer Johannes
> <Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu>>:
> Thanks Adrian and Thierry (from the previous answer).
>
> I was aware of the all.equal function, but there is nothing similar for <= (e.g.
> all.smallerEqual)?
>
> cheers, jo
>
> On 05 Apr 2016, at 14:31, Adrian Du?a
> <dusa.adrian at unibuc.ro<mailto:dusa.adrian at unibuc.ro><mailto:dusa.adria
> n at unibuc.ro<mailto:dusa.adrian at unibuc.ro>>> wrote:
>
> Yes, that does have to do with floating point representation.
> I use this function for these types of comparisons (works with values as well
> as with vectors):
>
> check.equal <- function(x, y) {
>     check.vector <- as.logical(unlist(lapply(x, all.equal, y)))
>     check.vector[is.na<http://is.na/><http://is.na/>(check.vector)] <- FALSE
>     return(check.vector)
> }
>
> See:
> ?all.equal
>
> Hth,
> Adrian
>
> On Tue, Apr 5, 2016 at 2:34 PM, Rainer Johannes
> <Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu><mailto:
> Johannes.Rainer at eurac.edu<mailto:Johannes.Rainer at eurac.edu>>> wrote:
> Dear All,
>
> I have the following problem:
>
> I have a function in which I check if the difference between values is smaller
> or equal to a certain threshold. I however realized that I might get there
> some unexpected results:
>
> > abs(1 - 0.95) >= 0.05
> [1] TRUE
> ## So that?s fine, but:
> > abs(1 - 0.95) <= 0.05
> [1] FALSE
>
> Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite
> disturbing.
>
> Along these lines:
> > abs(0.95 - 1) > 0.05
> [1] TRUE
> > abs(0.95 - 1) < 0.05
> [1] FALSE
>
> I guess that has to do with the floating point representation of the data?
>
> Is there something I miss or is there any solution to this?
> Thanks for any help!
>
> cheers, jo
>
>
>
> I tried this on different R-version (including 3.2.3 and 3.3.0 alpha); The R-
> version I used for the code above is:
>
> > sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-
> project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE
> and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html<http://www.r-project.org/posting-guide.html><http://www.r-
> project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From james.hirschorn at hotmail.com  Wed Apr  6 04:17:58 2016
From: james.hirschorn at hotmail.com (James Hirschorn)
Date: Tue, 5 Apr 2016 22:17:58 -0400
Subject: [R] Is this a bug in quantmod::OpCl?
Message-ID: <BLU403-EAS3183309E369A19BBF1F610EE99F0@phx.gbl>


OpCl works on xts objects but not on quantmod.OHLC objects. Is this a bug?

Example error:

x.Date <- as.Date("2003-02-01") + c(1, 3, 7, 9, 14) - 1
set.seed(1)
x <- zoo(matrix(runif(20, 0, 1), nrow=5, ncol=4), x.Date)
q <- as.quantmod.OHLC(x,c("Open","High","Low","Close"))

# error
OpCl(q)
#> Error in `colnames<-`(`*tmp*`, value = "OpCl.q") : 
#>  attempt to set 'colnames' on an object with less than two dimensions

# OK
OpCl(as.xts(q))

	[[alternative HTML version deleted]]


From hhoeflin at gmail.com  Wed Apr  6 10:17:15 2016
From: hhoeflin at gmail.com (Holger Hoefling)
Date: Wed, 6 Apr 2016 10:17:15 +0200
Subject: [R] HTML help -- as a single document for the entire package
Message-ID: <CAFDswJtgksXw=2jyW9PpHMk6M=gVEh+vNxJvFTKHKGhhY9FXUQ@mail.gmail.com>

Hi,

I was wondering if there was an equivalent to the pdf-manual for
R-packages, but rendered as a single html page? I am looking for this as it
would make reading easier as
- no restriction to the standard paper width, but flowing to the browser
window size
- no page breaks
- full text search across the entire manual.

Thanks

Holger

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Wed Apr  6 11:07:20 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Wed, 6 Apr 2016 09:07:20 +0000
Subject: [R] Good pointers for understanding the R language
 implementation
Message-ID: <248E6FA047A8C746BA491485764190F53D399C15@ESESSMB207.ericsson.se>

Guessing that you may want to take a look at:

http://adv-r.had.co.nz/Expressions.html


https://www.opencpu.org/


Anyway, as David wrote, that it is too vague for specific hints.


--

Best,

GG



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Apr  6 11:37:30 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 6 Apr 2016 05:37:30 -0400
Subject: [R] HTML help -- as a single document for the entire package
In-Reply-To: <CAFDswJtgksXw=2jyW9PpHMk6M=gVEh+vNxJvFTKHKGhhY9FXUQ@mail.gmail.com>
References: <CAFDswJtgksXw=2jyW9PpHMk6M=gVEh+vNxJvFTKHKGhhY9FXUQ@mail.gmail.com>
Message-ID: <5704D8DA.40108@gmail.com>

On 06/04/2016 4:17 AM, Holger Hoefling wrote:
> Hi,
>
> I was wondering if there was an equivalent to the pdf-manual for
> R-packages, but rendered as a single html page? I am looking for this as it
> would make reading easier as
> - no restriction to the standard paper width, but flowing to the browser
> window size
> - no page breaks
> - full text search across the entire manual.

No, there isn't.

Duncan Murdoch


From S.Ellison at LGCGroup.com  Wed Apr  6 12:34:38 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 6 Apr 2016 11:34:38 +0100
Subject: [R] Problem with <= (less than or equal): not giving the
	expected	result
In-Reply-To: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
Message-ID: <1A8C1289955EF649A09086A153E2672403D134D3BF@GBTEDVPEXCMB04.corp.lgc-group.com>

> Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however quite
> disturbing.

It's normal.* See R FAQ 7.31 in the html help system.

S Ellison

*... and common to all computers that use binary. 



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From amelia_marsh08 at yahoo.com  Wed Apr  6 13:39:59 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Wed, 6 Apr 2016 11:39:59 +0000 (UTC)
Subject: [R] Memory problem
References: <1776207391.150876.1459942799106.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1776207391.150876.1459942799106.JavaMail.yahoo@mail.yahoo.com>

Dear R Forum,

I have about 2000+ FX forward transactions and I am trying to run 1000 simulations. If I use less no of simulations, I am able to get the desired results. However, when I try to use more than 1000 simulations, I get following error.

> sorted2 <- ddply(sorted, .(currency_from_exch, id), mutate, change_in_mtm_bc = mtm_bc - mtm_bc[1]) 

Error: cannot allocate vector of size 15.6 Mb 


In addition: Warning messages: 
1: Reached total allocation of 3583Mb: see help(memory.size) 
2: Reached total allocation of 3583Mb: see help(memory.size) 
3: In output[[var]][rng] <- df[[var]] : 
Reached total allocation of 3583Mb: see help(memory.size) 
4: In output[[var]][rng] <- df[[var]] : 
Reached total allocation of 3583Mb: see help(memory.size) 
5: In output[[var]][rng] <- df[[var]] : 
Reached total allocation of 3583Mb: see help(memory.size) 
6: In output[[var]][rng] <- df[[var]] : 
Reached total allocation of 3583Mb: see help(memory.size) 
7: In output[[var]][rng] <- df[[var]] : 
Reached total allocation of 3583Mb: see help(memory.size) 
8: In output[[var]][rng] <- df[[var]] : 
Reached total allocation of 3583Mb: see help(memory.size)


When I checked -

> memory.size() 
[1] 846.83 
> memory.limit() 
[1] 3583


The code is bit lengthy and unfortunately can't be shared.

Kindly guide how this memory probelm can be tackled? I am using R x64 3.2.0

Regards

Amelia


From sabasehrish at yahoo.com  Wed Apr  6 13:50:42 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Wed, 6 Apr 2016 04:50:42 -0700
Subject: [R] Descriptive Statistics of time series data
Message-ID: <1459943442.82730.YahooMailAndroidMobile@web121804.mail.ne1.yahoo.com>

Hi

I have four variables and the time series data for each variable consists of values for past 10 years on monthly basis. I want to get descriptive stats for these four variables separately (mean, median, sd, min, max).

The data I import to R consists of different columns, where each column gives values for one month of a particular year (e.g. March 31st, 2010). Right now R gives descriptive results for each column, whereas I need it collectively for all the years ( one mean, one sd, one min, one max and one median) for each variable.

Kindly guide me in this regard.

Thanks.
Saba

Sent from Yahoo Mail on Android


	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Apr  6 14:18:16 2016
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Apr 2016 08:18:16 -0400
Subject: [R] Memory problem
In-Reply-To: <1776207391.150876.1459942799106.JavaMail.yahoo@mail.yahoo.com>
References: <1776207391.150876.1459942799106.JavaMail.yahoo.ref@mail.yahoo.com>
	<1776207391.150876.1459942799106.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-4wrZP4O8b8hOaG2ZQEKCGAgZOQRYvyVf3C-eur0L-1FQ@mail.gmail.com>

It is hard to tell from the information that you have provided.  Do you
have a list of the sizes of all the objects that you have in memory?  Are
you releasing large objects at the end of each simulation run?  Are you
using 'gc' to garbage collect any memory after deallocating objects?
Collect some additional information with a simple function like below:

f_mem_stats <- function(memo='') cat(memo, proc.time(), memory.size(), '\n')


> f_mem_stats(2)
2 2.85 11.59 85444.93 NA NA 39.08

This will print out what you pass in as a parameter, e.g., the iteration
number, and then outputs the amount of CPU and memory used so far.  I use
this all the time to keep track of resource consumption in long running
scripts.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Apr 6, 2016 at 7:39 AM, Amelia Marsh via R-help <
r-help at r-project.org> wrote:

> Dear R Forum,
>
> I have about 2000+ FX forward transactions and I am trying to run 1000
> simulations. If I use less no of simulations, I am able to get the desired
> results. However, when I try to use more than 1000 simulations, I get
> following error.
>
> > sorted2 <- ddply(sorted, .(currency_from_exch, id), mutate,
> change_in_mtm_bc = mtm_bc - mtm_bc[1])
>
> Error: cannot allocate vector of size 15.6 Mb
>
>
> In addition: Warning messages:
> 1: Reached total allocation of 3583Mb: see help(memory.size)
> 2: Reached total allocation of 3583Mb: see help(memory.size)
> 3: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 4: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 5: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 6: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 7: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 8: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
>
>
> When I checked -
>
> > memory.size()
> [1] 846.83
> > memory.limit()
> [1] 3583
>
>
> The code is bit lengthy and unfortunately can't be shared.
>
> Kindly guide how this memory probelm can be tackled? I am using R x64 3.2.0
>
> Regards
>
> Amelia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Wed Apr  6 15:03:29 2016
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 6 Apr 2016 09:03:29 -0400
Subject: [R] R-dvel [robustness Simulation study of 2 sample test on
 several combination of factors ]
In-Reply-To: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <57050921.3060602@yorku.ca>

On 4/4/2016 9:15 PM, tan sj wrote:
> hi, i am new in this field.
>
>
> do
> favorite<http://stackoverflow.com/questions/36404707/simulation-study-of-2-sample-test-on-different-combination-of-factors#>
>
>
> If I wish to conduct a simulation on the robustness of two sample test by using R language, is that any ways in writing the code?
> There are several factors
> (sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100))
>
> (standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50))
> distribution of gamma distribution with unequal skewness and equal skewness
>
> I wish to test the pooled variance t test and welch t test and mann whitney by using the above combination of factors. But how can I combine them by using for loop or apply function??
> I am intending to use apply function but i am stucking. If i use for loop function, can i use for loop with vectors ?
> for (a in c(25,50,100)) #first group of sample sizes
> { for (b in c(25,50,100)) #second group of sample sizes
> { for (d in c(4,4.4,5,6,8)) #different SDs of first sample
> the above code is an example that I would like to modified but I found I have different sets of sample sizes.
>

Don't try to code this yourself-- you'll run into a mess.  Instead, use 
the lovely SimDesign package, https://github.com/philchalmers/SimDesign
designed for just this purpose.

There are also some nice tutorial examples on a wiki,
https://github.com/philchalmers/SimDesign/wiki

best,
-Michael


From cdesjard at umn.edu  Wed Apr  6 15:11:35 2016
From: cdesjard at umn.edu (Christopher Desjardins)
Date: Wed, 6 Apr 2016 08:11:35 -0500
Subject: [R] Good pointers for understanding the R language
	implementation
In-Reply-To: <DUB130-W53F4F6D1F1A77E5C1195DA859E0@phx.gbl>
References: <DUB130-W53F4F6D1F1A77E5C1195DA859E0@phx.gbl>
Message-ID: <CAOGrcjp4hOTcR6vr6M1V4LiF3SVs1DNj6HWq-tKgT5k9AXq_VQ@mail.gmail.com>

This might be useful: http://adv-r.had.co.nz/

On Tue, Apr 5, 2016 at 10:31 AM, Francisco Banha <kikx_francisco at hotmail.com
> wrote:

> Dear All,
>
> I'm currently working on a project with
> the purpose of remotely executing R code, which requires me to have to
> work with the code of R itself. I've searched the Internet for good
> information that will help me understand how R is implemented but what
> I've got so far isn't detailed enough.
> I've looked specifically at
> CRAN's manuals on the official website but they only address this issue
> briefly. I've also looked at other contents online but so far nothing
> has turned up that has the level of detail that I need to properly
> understand the inner workings of R.
> For example, I need to understand
>  how exactly an expression is parsed and evaluated, because I will need
> to intervene in the process to decide whether to execute it remotely or
> not.
> Does anyone know of good pointers that would help me understand this?
> Thanks for any help!
>
> Best regards,
> Francisco
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Apr  6 15:57:19 2016
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Apr 2016 09:57:19 -0400
Subject: [R] Memory problem
In-Reply-To: <1564373130.163843.1459946659764.JavaMail.yahoo@mail.yahoo.com>
References: <CAAxdm-4wrZP4O8b8hOaG2ZQEKCGAgZOQRYvyVf3C-eur0L-1FQ@mail.gmail.com>
	<1564373130.163843.1459946659764.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-6a6GnVoe2kMUaX2RpQGzVW_r8vKkd+dxkUVd48pTXjNw@mail.gmail.com>

You say it is "getting stored"; is this in memory or on disk?  How are you
processing the results of the 1,000 simulations?

So some more insight into the actual process would be useful.  For example,
how are the simulations being done, are the results stored in memory, or
out to a file, what are you doing with the results at the end, etc.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Apr 6, 2016 at 8:44 AM, Amelia Marsh <amelia_marsh08 at yahoo.com>
wrote:

> Dear Sir,
>
> Thanks for the guidance. Will check. And yes, at the end of each
> simulation, a large result is getting stored.
>
> Regards
>
> Amelia
>
>
> On Wednesday, 6 April 2016 5:48 PM, jim holtman <jholtman at gmail.com>
> wrote:
>
>
> It is hard to tell from the information that you have provided.  Do you
> have a list of the sizes of all the objects that you have in memory?  Are
> you releasing large objects at the end of each simulation run?  Are you
> using 'gc' to garbage collect any memory after deallocating objects?
> Collect some additional information with a simple function like below:
>
> f_mem_stats <- function(memo='') cat(memo, proc.time(), memory.size(),
> '\n')
>
>
> > f_mem_stats(2)
> 2 2.85 11.59 85444.93 NA NA 39.08
>
> This will print out what you pass in as a parameter, e.g., the iteration
> number, and then outputs the amount of CPU and memory used so far.  I use
> this all the time to keep track of resource consumption in long running
> scripts.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Wed, Apr 6, 2016 at 7:39 AM, Amelia Marsh via R-help <
> r-help at r-project.org> wrote:
>
> Dear R Forum,
>
> I have about 2000+ FX forward transactions and I am trying to run 1000
> simulations. If I use less no of simulations, I am able to get the desired
> results. However, when I try to use more than 1000 simulations, I get
> following error.
>
> > sorted2 <- ddply(sorted, .(currency_from_exch, id), mutate,
> change_in_mtm_bc = mtm_bc - mtm_bc[1])
>
> Error: cannot allocate vector of size 15.6 Mb
>
>
> In addition: Warning messages:
> 1: Reached total allocation of 3583Mb: see help(memory.size)
> 2: Reached total allocation of 3583Mb: see help(memory.size)
> 3: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 4: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 5: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 6: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 7: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
> 8: In output[[var]][rng] <- df[[var]] :
> Reached total allocation of 3583Mb: see help(memory.size)
>
>
> When I checked -
>
> > memory.size()
> [1] 846.83
> > memory.limit()
> [1] 3583
>
>
> The code is bit lengthy and unfortunately can't be shared.
>
> Kindly guide how this memory probelm can be tackled? I am using R x64 3.2.0
>
> Regards
>
> Amelia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Apr  6 16:13:15 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 06 Apr 2016 07:13:15 -0700
Subject: [R] Memory problem
In-Reply-To: <1776207391.150876.1459942799106.JavaMail.yahoo@mail.yahoo.com>
References: <1776207391.150876.1459942799106.JavaMail.yahoo.ref@mail.yahoo.com>
	<1776207391.150876.1459942799106.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <4BB00C74-78D6-4244-8A18-506FEF3B1317@dcn.davis.ca.us>

As Jim has indicated, memory usage problems can require very specific diagnostics and code changes,  so generic help is tough to give. 

However, in most cases I have found the dplyr package to be more memory efficient than plyr, so you could consider that. Also, you can be explicit about only saving the minimum results you want to keep rather than making a list of complete results and extracting results later. 
-- 
Sent from my phone. Please excuse my brevity.

On April 6, 2016 4:39:59 AM PDT, Amelia Marsh via R-help <r-help at r-project.org> wrote:
>Dear R Forum,
>
>I have about 2000+ FX forward transactions and I am trying to run 1000
>simulations. If I use less no of simulations, I am able to get the
>desired results. However, when I try to use more than 1000 simulations,
>I get following error.
>
>> sorted2 <- ddply(sorted, .(currency_from_exch, id), mutate,
>change_in_mtm_bc = mtm_bc - mtm_bc[1]) 
>
>Error: cannot allocate vector of size 15.6 Mb 
>
>
>In addition: Warning messages: 
>1: Reached total allocation of 3583Mb: see help(memory.size) 
>2: Reached total allocation of 3583Mb: see help(memory.size) 
>3: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>4: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>5: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>6: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>7: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>8: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size)
>
>
>When I checked -
>
>> memory.size() 
>[1] 846.83 
>> memory.limit() 
>[1] 3583
>
>
>The code is bit lengthy and unfortunately can't be shared.
>
>Kindly guide how this memory probelm can be tackled? I am using R x64
>3.2.0
>
>Regards
>
>Amelia
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From zaid_golwala at persistent.com  Wed Apr  6 10:05:16 2016
From: zaid_golwala at persistent.com (Zaid Golwala)
Date: Wed, 6 Apr 2016 08:05:16 +0000
Subject: [R] Issue while building xtable on R on Ubuntu 15.04
Message-ID: <EC52F5F46B02B64EAECF93259BDB59F4212939CA@HJ-MBX1.persistent.co.in>

Hi,

I am trying to build xtable on R  on Ubuntu 15.04 but I get following error :


+ R CMD check --no-vignettes --timings xtable_1.8-2.tar.gz

* using log directory '/home/jenkins/workspace/Rlang_xtable_Ubuntu15.04/xtable.Rcheck'

* using R version 3.2.3 (2015-12-10)

* using platform: powerpc64le-unknown-linux-gnu (64-bit)

* using session charset: UTF-8

* using option '--no-vignettes

'* checking for file 'xtable/DESCRIPTION' ... OK

* this is package 'xtable' version '1.8-2'

* checking package namespace information ... OK

* checking package dependencies ...Error in .build_vignette_index(vigns) :   In 'inst' vignettes 'xtableGallery.Rnw' and 'xtableGallery.snw' have the same vignette name

Can someone please help me regarding the same.

Regards
Zaid Golwala

DISCLAIMER\ ==========\ This e-mail ...{{dropped:14}}


From phiroc at free.fr  Wed Apr  6 11:20:11 2016
From: phiroc at free.fr (phiroc at free.fr)
Date: Wed, 6 Apr 2016 11:20:11 +0200 (CEST)
Subject: [R] Plotting data on a map
In-Reply-To: <110748493.102677300.1459933283547.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <1322838587.102759157.1459934411212.JavaMail.root@zimbra65-e11.priv.proxad.net>

Hello,

I would like to generate a small map (say 10cm x 10cm) of France showing cumulative numbers by Distribution Center
stored in a database:

DISTRIBUTION_CENTER                 COUNT
Paris                               122
Paris                               3
Paris                               21
Lyon                                12
Lyon                                4444
Lyon                                33
Grenoble                            55
Grenoble                            999
Grenoble                            99
...

I have looked at different graphing packages such as 'sp', 'raster' and 'ggplot2', but am not sure which one is most
appropriate for my purposes. Furthermore, I don't understand how you retrieve city coordinates from shp, gadm, etc., maps
generated, or downloaded from the web and then processed, with those packages (SHP, GADM, etc.), and plot data at those coordinates.

Any help would be much appreciated.

Many thanks.

Philippe


From amelia_marsh08 at yahoo.com  Wed Apr  6 14:44:19 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Wed, 6 Apr 2016 12:44:19 +0000 (UTC)
Subject: [R] Memory problem
In-Reply-To: <CAAxdm-4wrZP4O8b8hOaG2ZQEKCGAgZOQRYvyVf3C-eur0L-1FQ@mail.gmail.com>
References: <CAAxdm-4wrZP4O8b8hOaG2ZQEKCGAgZOQRYvyVf3C-eur0L-1FQ@mail.gmail.com>
Message-ID: <1564373130.163843.1459946659764.JavaMail.yahoo@mail.yahoo.com>

Dear Sir,
Thanks for the guidance. Will check. And yes, at the end of each simulation, a large result is getting stored.?
Regards
Amelia 

    On Wednesday, 6 April 2016 5:48 PM, jim holtman <jholtman at gmail.com> wrote:
 

 It is hard to tell from the information that you have provided.? Do you have a list of the sizes of all the objects that you have in memory?? Are you releasing large objects at the end of each simulation run?? Are you using 'gc' to garbage collect any memory after deallocating objects?? Collect some additional information with a simple function like below:
f_mem_stats <- function(memo='') cat(memo, proc.time(), memory.size(), '\n')

> f_mem_stats(2)2 2.85 11.59 85444.93 NA NA 39.08?
This will print out what you pass in as a parameter, e.g., the iteration number, and then outputs the amount of CPU and memory used so far.? I use this all the time to keep track of resource consumption in long running scripts.

Jim Holtman
Data Munger Guru
?
What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.
On Wed, Apr 6, 2016 at 7:39 AM, Amelia Marsh via R-help <r-help at r-project.org> wrote:

Dear R Forum,

I have about 2000+ FX forward transactions and I am trying to run 1000 simulations. If I use less no of simulations, I am able to get the desired results. However, when I try to use more than 1000 simulations, I get following error.

> sorted2 <- ddply(sorted, .(currency_from_exch, id), mutate, change_in_mtm_bc = mtm_bc - mtm_bc[1])

Error: cannot allocate vector of size 15.6 Mb


In addition: Warning messages:
1: Reached total allocation of 3583Mb: see help(memory.size)
2: Reached total allocation of 3583Mb: see help(memory.size)
3: In output[[var]][rng] <- df[[var]] :
Reached total allocation of 3583Mb: see help(memory.size)
4: In output[[var]][rng] <- df[[var]] :
Reached total allocation of 3583Mb: see help(memory.size)
5: In output[[var]][rng] <- df[[var]] :
Reached total allocation of 3583Mb: see help(memory.size)
6: In output[[var]][rng] <- df[[var]] :
Reached total allocation of 3583Mb: see help(memory.size)
7: In output[[var]][rng] <- df[[var]] :
Reached total allocation of 3583Mb: see help(memory.size)
8: In output[[var]][rng] <- df[[var]] :
Reached total allocation of 3583Mb: see help(memory.size)


When I checked -

> memory.size()
[1] 846.83
> memory.limit()
[1] 3583


The code is bit lengthy and unfortunately can't be shared.

Kindly guide how this memory probelm can be tackled? I am using R x64 3.2.0

Regards

Amelia

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




  
	[[alternative HTML version deleted]]


From maettuw at students.unibe.ch  Wed Apr  6 16:27:33 2016
From: maettuw at students.unibe.ch (maettuw at students.unibe.ch)
Date: Wed, 6 Apr 2016 14:27:33 +0000
Subject: [R] Extracting windows from time series
Message-ID: <E9DA6CABC0F0734A9980C6E78E9024BA0708BD8F@aai-exch-mbx8.campus.unibe.ch>

Dear R Users

Thanks for the help in advance and lets get straight to the problem:
I have a 400 year long temperature time series and I am looking for decades that show a linear trend decrease of approximately -0.1 Kelvin or degrees. --> What I would like to program: A loop/function / command line that prints the values of all the trends (can also be overlapping) into a matrix that could have the following structure :

                Year 1 (of Trend1)     Year 2 ( ... 2)     Year 3 .....     .....     .....
Trend 1:
Trend 2:
Trend 3:
...
.
.

 I  first tried to solve the task with a loop but ended up doing it with function but got stuck. Here is what I did so far:

Puls <- Surface_temperature_MA10[10:394] + 1 # give all values in the TS a positive value. Like that
## I can easier extract the trends that fullfill the searched condition (decrease of 0.1 Kelvin) --> look  next line

Difference <- diff(Puls,lag=10) # x[(1+lag):n] - x[1:(n-lag)] --> time step 20 - timestep 10 for first calculation --> does that for whole time series
ID <- c(1:375)
melted_Difference <- melt(data.frame(Difference,ID),id.vars="ID")

Hiatus <- subset(melted_Difference,value < -0.1)

here the result :
23   23 Difference -0.1184901
24   24 Difference -0.1723032
25   25 Difference -0.1366112
26   26 Difference -0.1745479
27   27 Difference -0.1805964
28   28 Difference -0.2285250
29   29 Difference -0.2449096
30   30 Difference -0.1052558
44   44 Difference -0.1172029

-->23,24,25 etc. corresponds to the first years of the trends that shows a decrease of at least -0.1 Kelvin/decade. So far my method works. The purpose of that was that I could then use the window() function to extract
the original values from Puls.
This works, but only for one decade at one time -->

List_Hiatus <- window(Puls,1,start = c(23), end =  c(34))
> List_Hiatus
 [1] 1.125813 1.143880 1.123572 1.139369 1.134410 1.137944 1.139320 1.055780 1.026300 1.042695 1.007323 0.971577
attr(,"tsp")
[1] 23 34  1

Tried but failed with the following approaches:

Start_H <- as.numeric(Hiatus[,1:1])
End_H <- as.numeric(Start_H + 10)
List_Hiatus <- window(Puls,1,start = "Start_H", end =  "End_H")

OR :
List_Hiatus <- window(Puls,1,start = c(23,24), end =  c(33,34))   # where c could of course be expanded

Or
apply(Puls,2,window(start=c(Start_H),end=c(End_H)))

Thanks again for your time.

Best Matthias



	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Apr  6 17:57:43 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Apr 2016 08:57:43 -0700
Subject: [R] HTML help -- as a single document for the entire package
In-Reply-To: <5704D8DA.40108@gmail.com>
References: <CAFDswJtgksXw=2jyW9PpHMk6M=gVEh+vNxJvFTKHKGhhY9FXUQ@mail.gmail.com>
	<5704D8DA.40108@gmail.com>
Message-ID: <8B37A763-B6B3-4E56-B366-0F8755E51A3C@comcast.net>


> On Apr 6, 2016, at 2:37 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 06/04/2016 4:17 AM, Holger Hoefling wrote:
>> Hi,
>> 
>> I was wondering if there was an equivalent to the pdf-manual for
>> R-packages, but rendered as a single html page? I am looking for this as it
>> would make reading easier as
>> - no restriction to the standard paper width, but flowing to the browser
>> window size
>> - no page breaks
>> - full text search across the entire manual.
> 
> No, there isn't.

My somewhat different understanding may simply be a reflection of a different operating system (given my inferior knowledge of the R ecosystems to that of Duncan). I run R in the R.app GUI on a Mac and the Help menu dropdown choice brings up links (in browser form) to local versions of the documents that I thought were  shipped with every new installation. Assuming your request is for an html version of "Writing R Extensions", then I get one with:

http://127.0.0.1:15834/doc/manual/R-exts.html

-- 
David.


> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Wed Apr  6 18:37:12 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 6 Apr 2016 12:37:12 -0400
Subject: [R] HTML help -- as a single document for the entire package
In-Reply-To: <CAFDswJtuuVswCxgG9xngTHE=F+GrVqeOTj_MyZHvP=mtBy0pFA@mail.gmail.com>
References: <CAFDswJtgksXw=2jyW9PpHMk6M=gVEh+vNxJvFTKHKGhhY9FXUQ@mail.gmail.com>
	<5704D8DA.40108@gmail.com>
	<8B37A763-B6B3-4E56-B366-0F8755E51A3C@comcast.net>
	<CAFDswJtuuVswCxgG9xngTHE=F+GrVqeOTj_MyZHvP=mtBy0pFA@mail.gmail.com>
Message-ID: <57053B38.8030802@gmail.com>

On 06/04/2016 12:06 PM, Holger Hoefling wrote:
> Hi David,
>
> thanks - I do have that as well. That is a good chance to clarify. The 
> regular help gives a *separate* page for every single function. The 
> regular pdf-manual gives one document for *all* functions in a package.
>
> The nice thing about having a single html page for all functions in a 
> package would be that it is easily searchable in the browser, it is 
> more lightweight than a pdf and wouldn't be restricted by formatting 
> based on the notion that it has to be printable to a page on paper.
>
> I was wondering if something like this exists ... and Duncan very 
> quickly answered that for me.

If you wanted to write it yourself, you would need to modify the 
tools::Rd2HTML function, and write a wrapper that called it for every Rd 
page.  This would be mostly straightforward:  instead of working for 
just one file, it would need to loop over all of them; it would also 
need to handle links between topics differently than it currently does, 
because some of them would be internal links, others would be external.

The source for the function is in 
https://svn.r-project.org/R/trunk/src/library/tools/R/Rd2HTML.R.

Duncan Murdoch

>
> Thanks
>
> Holger
>
> On Wed, Apr 6, 2016 at 5:57 PM, David Winsemius 
> <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     > On Apr 6, 2016, at 2:37 AM, Duncan Murdoch
>     <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>     >
>     > On 06/04/2016 4:17 AM, Holger Hoefling wrote:
>     >> Hi,
>     >>
>     >> I was wondering if there was an equivalent to the pdf-manual for
>     >> R-packages, but rendered as a single html page? I am looking
>     for this as it
>     >> would make reading easier as
>     >> - no restriction to the standard paper width, but flowing to
>     the browser
>     >> window size
>     >> - no page breaks
>     >> - full text search across the entire manual.
>     >
>     > No, there isn't.
>
>     My somewhat different understanding may simply be a reflection of
>     a different operating system (given my inferior knowledge of the R
>     ecosystems to that of Duncan). I run R in the R.app GUI on a Mac
>     and the Help menu dropdown choice brings up links (in browser
>     form) to local versions of the documents that I thought were 
>     shipped with every new installation. Assuming your request is for
>     an html version of "Writing R Extensions", then I get one with:
>
>     http://127.0.0.1:15834/doc/manual/R-exts.html
>
>     --
>     David.
>
>
>     > Duncan Murdoch
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     David Winsemius
>     Alameda, CA, USA
>
>


From dcarlson at tamu.edu  Wed Apr  6 18:40:39 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 6 Apr 2016 16:40:39 +0000
Subject: [R] HTML help -- as a single document for the entire package
In-Reply-To: <5704D8DA.40108@gmail.com>
References: <CAFDswJtgksXw=2jyW9PpHMk6M=gVEh+vNxJvFTKHKGhhY9FXUQ@mail.gmail.com>
	<5704D8DA.40108@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D729A5F@mb02.ads.tamu.edu>

It is not quite what you are asking for, but there are several online pdf to html conversion websites. I tried a simple package pdf file and it converted fine. The page numbers are still there, but it is a single continuous page.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Wednesday, April 6, 2016 4:38 AM
To: Holger Hoefling; R-Help mailing list
Subject: Re: [R] HTML help -- as a single document for the entire package

On 06/04/2016 4:17 AM, Holger Hoefling wrote:
> Hi,
>
> I was wondering if there was an equivalent to the pdf-manual for
> R-packages, but rendered as a single html page? I am looking for this as it
> would make reading easier as
> - no restriction to the standard paper width, but flowing to the browser
> window size
> - no page breaks
> - full text search across the entire manual.

No, there isn't.

Duncan Murdoch

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sj_style_1125 at outlook.com  Wed Apr  6 17:54:04 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Wed, 6 Apr 2016 15:54:04 +0000
Subject: [R] R simulation help pls
Message-ID: <KL1PR01MB0887B3D3585826A65B7D41F4B59F0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>


Hi, i am student from malaysia, i am new in r programming field, now i am trying to conduct a robustness study on 2 sample test under several combination of factors such as sample sizes ,standard deviation ratio and  also distribution..

but now i am stucking in how to use for loop or apply function to conduct the simulation ?
Then how can i test the test in the combined combination of factors?



Sent from my phone

	[[alternative HTML version deleted]]


From sj_style_1125 at outlook.com  Wed Apr  6 17:54:09 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Wed, 6 Apr 2016 15:54:09 +0000
Subject: [R] R-dvel [robustness Simulation study of 2 sample test on
 several combination of factors ]
In-Reply-To: <CA+8X3fUD+z-0cOO0RvsztxenYOXWKgz99ucS7gNOb6KwoReH_w@mail.gmail.com>
References: <KL1PR01MB088768027DC6EFCA397FECD5B59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
	<CA+8X3fWqRijLtXxXfi33A_iZ-AF0wAwGbKEw6EBtvRkJQ6XtWg@mail.gmail.com>
	<KL1PR01MB08871DA5DB29B6DB8C78579CB59E0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
	<CA+8X3fUd185i2__Yx8KpnnhhUXakuC_bjCgYvVhX7F4kFSXF5Q@mail.gmail.com>
	<KL1PR01MB0887B237080EAE2B9155405BB59F0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>,
	<CA+8X3fUD+z-0cOO0RvsztxenYOXWKgz99ucS7gNOb6KwoReH_w@mail.gmail.com>
Message-ID: <KL1PR01MB08872A0BD1039A2213E63C5EB59F0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>


Hi, i think i have figured the purpose of using this index (i-1)*5+j in the previous example that you gave.

It is because that i have to consider the outer loop and inner loop also... so the iterative for i need to minus one because it have ran one times simulation already ,then times the number of sizes of inner loop, then plus the iterative of j....

then for the simulation, i think there will be ((ss-1)*nsds +sim) for the index in the body of for loop...
Is it correct?

Sent from my phone

On Jim Lemon <drjimlemon at gmail.com>, Apr 6, 2016 6:52 PM wrote:
You are running through two loops and putting the output into a
vector. Without this calculation you will overwrite the same elements
of the output vector instead of advancing through it. Try this
example:

# like your 54 element vector of calculations for one condition
testmat1<-rep(0,25)
testmat2<-rep(0,25)
# now try to fill it with the inner loop index
for(i in 1:5) {
 for(j in 1:5) {
  testmat1[j]<-i+j
 }
}
# do it again using a calculation similar to your question
for(i in 1:5) {
 for(j in 1:5) {
  testmat2[(i-1)*5+j]<-i+j
 }
}
testmat1
testmat2

Try out some other things with this. It will give you an idea of how
to index elements of vectors. You could also use a matrix and then
convert it into a vector using as.vector:

testmat3<-matrix(0,nrow=5,ncol=5)
for(i in 1:5) {
 for(j in 1:5) {
  testmat3[i,j]<-i+j
 }
}
as.vector(testmat3)

Jim

On Wed, Apr 6, 2016 at 8:04 PM, tan sj <sj_style_1125 at outlook.com> wrote:
> Hi, i am sorry to interrupt, can I ask about this few problems?
>
>   t_equal[(ss-1)*nsds+i]<-t.test(x_norm1,y_norm2,var.equal=TRUE)$p.value
> 1. From above, what do "[(ss-1)*nsds+i]" brings to the code?
>
> 2. what is the purpose of having i (the iterative) here ? I see that dr. have set the sim as the iterative then why need to set i <-1 and set it as i<-i+1?
>
> they are confusing me.....
> I am sorry if these are very simple problem....
>
>
> ________________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Wednesday, April 6, 2016 4:00 AM
> To: tan sj; r-help mailing list
> Subject: Re: [R] R-dvel [robustness Simulation study of 2 sample test on several combination of factors ]
>
> You have quite a few mistakes in your example. The code below works
> for me - you can wrap it in a function if you like. I think you will
> need a lot more practice before you can write something like this in R
> as you are missing close braces and haven't really worked out the
> difference between the number of calculations you are doing for each
> replication and the number of replications. It takes 5-10 minutes to
> run.
>
>  ## Put the samples sizes into matrix then use a loop for sample sizes
> sample_sizes<-
>  matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
>  nrow=2)
>
> #create vector to combine all std deviations
> sds<-c(4,6,8,10,12,14)
> # this number is needed below
> nsds<-length(sds)
> set.seed(8)
>
> #number of simulations
> nSims<-10000
> #set significance level,alpha for the whole simulatio
> alpha<-0.05
>
> #set empty vector of length no.of _calculations_ to store p-values
> # Note: you have 54 calculations, not 10000
> ncalcs<-dim(sample_sizes)[2]*nsds
> t_equal <-c(rep(0,length=ncalcs))
> t_unequal <-c(rep(0,length=ncalcs))
> mann <-c(rep(0,length=ncalcs))
>
> #set up matrix for storing data from the vectors
> # but you do want 10000 replications of each calculation
> matrix_Equal<-matrix(rep(NA,ncalcs*nSims),nrow=nSims)
> matrix_Unequal<-matrix(rep(NA,ncalcs*nSims),nrow=nSims)
> matrix_mann<-matrix(rep(NA,ncalcs*nSims),nrow=nSims)
>
> ############Simulations
>
> for (sim in 1:nSims){
>  # this loop steps through the sample sizes
>  for(ss in 1:dim(sample_sizes)[2]) {
>   m<-sample_sizes[1,ss]
>   n<-sample_sizes[2,ss]
>   # initialize the index for results
>   i<-1
>   for (sd in sds) {  #first group's standard deviation
>    #generate random samples from 2 normal distribution
>    x_norm1<-rnorm(m,5,sds)
>    y_norm2<-rnorm(n,5,4)
>    #extract p-value out and store it in vectors
>    t_equal[(ss-1)*nsds+i]<-t.test(x_norm1,y_norm2,var.equal=TRUE)$p.value
>    t_unequal[(ss-1)*nsds+i]<-t.test(x_norm1,y_norm2,var.equal=FALSE)$p.value
>    mann[(ss-1)*nsds+i] <-wilcox.test(x_norm1,y_norm2)$p.value
>    i<-i+1
>   }
>  }
>  #store the current result into matrices by rows
>  matrix_Equal[sim,]<-t_equal
>  matrix_Unequal[sim,]<-t_unequal
>  matrix_mann[sim,]<-mann
> }
> ##print results
> matrix_Equal
> matrix_Unequal
> matrix_mann
>
> Jim
>
> On Wed, Apr 6, 2016 at 12:43 AM, tan sj <sj_style_1125 at outlook.com> wrote:
>> Hi, Jim, i read through your example,
>> I tried to write a code modified yours example and my ideas ...
>> In last email, you replied that "results[[(ss-1)*nssds+ssd_index]]<-<your_test>" ,can i know further about this ? Because i am not very understand about this .
>> I am sorry that i am really a new bird in this field...
>> but the code turn out it have some error ...
>> Below shown my attempt...
>>
>>  ## Put the samples sizes into matrix then use a loop for sample sizes
>> sample_sizes<-
>>  matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
>>  nrow=2)
>>
>> #create vector to combine all std deviations
>> sds<-c(4,6,8,10,12,14)
>>
>> set.seed(8)
>>
>> #number of simulations
>> nSims<-10000
>> #set significance level,alpha for the whole simulatio
>> alpha<-0.05
>>
>> #set empty vector of length no.of simulation(10000) to store p-value
>> t_equal <-c(length=nSims)
>> t_unequal <-c(length=nSims)
>> mann <-c(length=nSims)
>>
>> #set up matrix for storing data from the vectors
>> matrix_Equal<-matrix(t_equal,nrow=nSims)
>> matrix_Unequal<-matrix(t_unequal,nrow=nSims)
>> matrix_mann<-matrix(mann,nrow=nSims)
>>
>> ############Simulations
>>
>> #BULID A FUNCTION for a collection of statement
>> f<-function(m,n,sd)
>> {
>> for (i in 1:nSims){
>>
>> # this loop steps through the sample sizes
>> for(ss in 1:dim(sample_sizes)[2])
>> {
>> m<-sample_sizes[1,ss]
>> n<-sample_sizes[2,ss]
>> {
>> for (sd in sds)   #first group's standard deviation
>> {
>> #generate random samples from 2 normal distribution
>> x_norm1<-rnorm(m,5,sds)
>> y_norm2<-rnorm(n,5,4)
>>
>> #extract p-value out and store it in vectors
>> t_equal[i]<-t.test(x_norm1,y_norm2,var.equal=TRUE)$p.value
>> t_unequal[i]<-t.test(x_norm1,y_norm2,var.equal=FALSE)$p.value
>> mann[i] <-wilcox.test(x_norm1,y_norm2)$p.value
>>
>> ##store the result into matrix defined before
>> matrix_Equal<-t_equal
>> matrix_Unequal<-t_unequal
>> matrix_mann<-mann
>>
>> ##print results
>> matrix_Equal
>> matrix_Unequal
>> matrix_mann
>>
>> }
>>  }
>>   }
>> }
>> }
>> ________________________________________
>> From: Jim Lemon <drjimlemon at gmail.com>
>> Sent: Tuesday, April 5, 2016 2:38 AM
>> To: tan sj
>> Cc: r-help at r-project.org
>> Subject: Re: [R] R-dvel [robustness Simulation study of 2 sample test on several combination of factors ]
>>
>> Hi sst,
>> You could set up your sample sizes as a matrix if you don't want all
>> of the combinations:
>>
>> sample_sizes<-matrix(c(10,10,10,25,25,25,...),nrow=2)
>>
>> and then use one loop for the sample sizes:
>>
>> for(ss in 1:dim(sample_sizes)[2]) {
>>  ss1<-sample_sizes[1,ss]
>>  ss2<-sample_sizes[2,ss]
>>
>> then step through your SDs:
>>
>> for(ssd in  c(4,4.4,5,6,8)) {
>>
>> Jim
>>
>> On Tue, Apr 5, 2016 at 11:15 AM, tan sj <sj_style_1125 at outlook.com> wrote:
>>> hi, i am new in this field.
>>>
>>>
>>> do
>>> favorite<http://stackoverflow.com/questions/36404707/simulation-study-of-2-sample-test-on-different-combination-of-factors#>
>>>
>>>
>>> If I wish to conduct a simulation on the robustness of two sample test by using R language, is that any ways in writing the code?
>>> There are several factors
>>> (sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100))
>>>
>>> (standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50))
>>> distribution of gamma distribution with unequal skewness and equal skewness
>>>
>>> I wish to test the pooled variance t test and welch t test and mann whitney by using the above combination of factors. But how can I combine them by using for loop or apply function??
>>> I am intending to use apply function but i am stucking. If i use for loop function, can i use for loop with vectors ?
>>> for (a in c(25,50,100)) #first group of sample sizes
>>> { for (b in c(25,50,100)) #second group of sample sizes
>>> { for (d in c(4,4.4,5,6,8)) #different SDs of first sample
>>> the above code is an example that I would like to modified but I found I have different sets of sample sizes.
>>>
>>> So if for loop with vectors, as shown in the code above, will the computer run from part (a) 25, to part(b) 25, then to the part (d) 4? then again the rotation 50->50->4.4?
>>>
>>> ?I hope can hear any news from this website ....please..thanks you.
>>>
>>> Regards
>>> sst
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From hhoeflin at gmail.com  Wed Apr  6 18:06:01 2016
From: hhoeflin at gmail.com (Holger Hoefling)
Date: Wed, 6 Apr 2016 18:06:01 +0200
Subject: [R] HTML help -- as a single document for the entire package
In-Reply-To: <8B37A763-B6B3-4E56-B366-0F8755E51A3C@comcast.net>
References: <CAFDswJtgksXw=2jyW9PpHMk6M=gVEh+vNxJvFTKHKGhhY9FXUQ@mail.gmail.com>
	<5704D8DA.40108@gmail.com>
	<8B37A763-B6B3-4E56-B366-0F8755E51A3C@comcast.net>
Message-ID: <CAFDswJtuuVswCxgG9xngTHE=F+GrVqeOTj_MyZHvP=mtBy0pFA@mail.gmail.com>

Hi David,

thanks - I do have that as well. That is a good chance to clarify. The
regular help gives a *separate* page for every single function. The regular
pdf-manual gives one document for *all* functions in a package.

The nice thing about having a single html page for all functions in a
package would be that it is easily searchable in the browser, it is more
lightweight than a pdf and wouldn't be restricted by formatting based on
the notion that it has to be printable to a page on paper.

I was wondering if something like this exists ... and Duncan very quickly
answered that for me.

Thanks

Holger

On Wed, Apr 6, 2016 at 5:57 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 6, 2016, at 2:37 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> >
> > On 06/04/2016 4:17 AM, Holger Hoefling wrote:
> >> Hi,
> >>
> >> I was wondering if there was an equivalent to the pdf-manual for
> >> R-packages, but rendered as a single html page? I am looking for this
> as it
> >> would make reading easier as
> >> - no restriction to the standard paper width, but flowing to the browser
> >> window size
> >> - no page breaks
> >> - full text search across the entire manual.
> >
> > No, there isn't.
>
> My somewhat different understanding may simply be a reflection of a
> different operating system (given my inferior knowledge of the R ecosystems
> to that of Duncan). I run R in the R.app GUI on a Mac and the Help menu
> dropdown choice brings up links (in browser form) to local versions of the
> documents that I thought were  shipped with every new installation.
> Assuming your request is for an html version of "Writing R Extensions",
> then I get one with:
>
> http://127.0.0.1:15834/doc/manual/R-exts.html
>
> --
> David.
>
>
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Wed Apr  6 18:12:03 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Wed, 6 Apr 2016 16:12:03 +0000
Subject: [R] Plotting data on a map
Message-ID: <248E6FA047A8C746BA491485764190F53D399EFB@ESESSMB207.ericsson.se>

Some tutorials and examples may help.

http://www.zoology.ubc.ca/~kgilbert/mysite/Miscellaneous_files/R_MakingMaps.pdf

http://coulmont.com/cartes/rcarto.pdf

https://pakillo.github.io/R-GIS-tutorial/

http://www.milanor.net/blog/maps-in-r-plotting-data-points-on-a-map/

https://www.youtube.com/watch?v=PTti7OMbURo

https://www.nceas.ucsb.edu/scicomp/usecases/CreateMapsWithRGraphics


--

Best,

GG



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Apr  6 19:16:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 6 Apr 2016 10:16:18 -0700
Subject: [R] Plotting data on a map
In-Reply-To: <1322838587.102759157.1459934411212.JavaMail.root@zimbra65-e11.priv.proxad.net>
References: <110748493.102677300.1459933283547.JavaMail.root@zimbra65-e11.priv.proxad.net>
	<1322838587.102759157.1459934411212.JavaMail.root@zimbra65-e11.priv.proxad.net>
Message-ID: <CAGxFJbQWRvMvKHjyqs18Ovvt1rkZzH6HjEJs8m=qC27BuizqLg@mail.gmail.com>

Did you check the "Spatial" task view page?

https://cran.r-project.org/web/views/Spatial.html

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 6, 2016 at 2:20 AM,  <phiroc at free.fr> wrote:
> Hello,
>
> I would like to generate a small map (say 10cm x 10cm) of France showing cumulative numbers by Distribution Center
> stored in a database:
>
> DISTRIBUTION_CENTER                 COUNT
> Paris                               122
> Paris                               3
> Paris                               21
> Lyon                                12
> Lyon                                4444
> Lyon                                33
> Grenoble                            55
> Grenoble                            999
> Grenoble                            99
> ...
>
> I have looked at different graphing packages such as 'sp', 'raster' and 'ggplot2', but am not sure which one is most
> appropriate for my purposes. Furthermore, I don't understand how you retrieve city coordinates from shp, gadm, etc., maps
> generated, or downloaded from the web and then processed, with those packages (SHP, GADM, etc.), and plot data at those coordinates.
>
> Any help would be much appreciated.
>
> Many thanks.
>
> Philippe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From frainj at gmail.com  Wed Apr  6 19:44:24 2016
From: frainj at gmail.com (John C Frain)
Date: Wed, 6 Apr 2016 18:44:24 +0100
Subject: [R] Descriptive Statistics of time series data
In-Reply-To: <1459943442.82730.YahooMailAndroidMobile@web121804.mail.ne1.yahoo.com>
References: <1459943442.82730.YahooMailAndroidMobile@web121804.mail.ne1.yahoo.com>
Message-ID: <CAHrK5150wW5mUw0R8XtzbpZQNYSA3FZj+pvi5U=ArrJ=MwAsYQ@mail.gmail.com>

Use the r function scan() to read the entire file into a vector and then
extract the observations for each series (possible using loops?)

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 6 April 2016 at 12:50, Saba Sehrish via R-help <r-help at r-project.org>
wrote:

> Hi
>
> I have four variables and the time series data for each variable consists
> of values for past 10 years on monthly basis. I want to get descriptive
> stats for these four variables separately (mean, median, sd, min, max).
>
> The data I import to R consists of different columns, where each column
> gives values for one month of a particular year (e.g. March 31st, 2010).
> Right now R gives descriptive results for each column, whereas I need it
> collectively for all the years ( one mean, one sd, one min, one max and one
> median) for each variable.
>
> Kindly guide me in this regard.
>
> Thanks.
> Saba
>
> Sent from Yahoo Mail on Android
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alaasindi at gmail.com  Wed Apr  6 20:31:25 2016
From: alaasindi at gmail.com (Alaa Sindi)
Date: Wed, 6 Apr 2016 14:31:25 -0400
Subject: [R] Optimization max likelihood problem
Message-ID: <53C1C5B3-72A4-4982-A911-D94F6E282EE7@gmail.com>

hello all,

I am getting wrong estimates from this code. do you know what could be the problem. 

thanks


x<- c(1.6, 1.7, 1.7, 1.7, 1.8, 1.8, 1.8, 1.8)
y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
n <- c(59, 60, 62, 56, 63, 59, 62, 60)

DF <- data.frame(x, y, n)

# note: there is no need to have the choose(n, y) term in the likelihood
fn <- function(p, DF) {
  z <- p[1]+p[2]*DF$x
  sum( - (DF$y*z) - DF$n*log(1+exp(z)))
  
  #sum( - (y*(p[1]+p[2]*x) - n*log(1+exp(p[1]+p[2]*x))) )
}
out <- nlm(fn, p = c(1,1),DF, hessian = TRUE, print.level=2)
print(out)
eigen(out$hessian)

From dcarlson at tamu.edu  Wed Apr  6 20:50:40 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 6 Apr 2016 18:50:40 +0000
Subject: [R] Descriptive Statistics of time series data
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D729AE3@mb02.ads.tamu.edu>

For mean() and sd() you need to convert the data frame to a matrix (I'm guessing here since you did not show us the structure of your data). The min() and max() functions should work on the data frame just fine. If you have other columns in the data frame, extract the monthly columns first.

> set.seed(42)
> x <- data.frame(matrix(rnorm(100), 20, 5))
> str(x)
'data.frame':   20 obs. of  5 variables:
 $ X1: num  1.371 -0.565 0.363 0.633 0.404 ...
 $ X2: num  -0.307 -1.781 -0.172 1.215 1.895 ...
 $ X3: num  0.206 -0.361 0.758 -0.727 -1.368 ...
 $ X4: num  -0.367 0.185 0.582 1.4 -0.727 ...
 $ X5: num  1.5127 0.2579 0.0884 -0.1209 -1.1943 ...
> mean(as.matrix(x))
[1] 0.03251482
> sd(as.matrix(x))
[1] 1.041357
> min(x)
[1] -2.99309
> max(x)
[1] 2.286645

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Saba Sehrish via R-help
Sent: Wednesday, April 6, 2016 6:51 AM
To: r-help at r-project.org
Subject: [R] Descriptive Statistics of time series data

Hi

I have four variables and the time series data for each variable consists of values for past 10 years on monthly basis. I want to get descriptive stats for these four variables separately (mean, median, sd, min, max).

The data I import to R consists of different columns, where each column gives values for one month of a particular year (e.g. March 31st, 2010). Right now R gives descriptive results for each column, whereas I need it collectively for all the years ( one mean, one sd, one min, one max and one median) for each variable.

Kindly guide me in this regard.

Thanks.
Saba

Sent from Yahoo Mail on Android


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Wed Apr  6 21:02:46 2016
From: davidsmi at microsoft.com (David Smith)
Date: Wed, 6 Apr 2016 19:02:46 +0000
Subject: [R] Revolutions blog: March 2016 Roundup
Message-ID: <DM2PR0301MB0848BE79E762181DB5D803E8C89F0@DM2PR0301MB0848.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of March:

Reviews of new CRAN packages RtutoR, lavaan.shiny, dCovTS, glmmsr, GLMMRR, MultivariateRandomForest, genie, kmlShape,
deepboost and rEDM: http://blog.revolutionanalytics.com/2016/03/whats-new-on-cran.html

You can now create and host Jupyter notebooks based on R, for free, in Azure ML Studio:
http://blog.revolutionanalytics.com/2016/03/jupyter-notebooks.html

Calculating learning curves for predictive models with doParallel:
http://blog.revolutionanalytics.com/2016/03/learning-from-learning-curves.html

An amusing look at some of R's quirks: http://blog.revolutionanalytics.com/2016/03/about-those-weird-things-in-r.html

A recording of a recent talk I gave on real-time predictive analytics, featuring R:
http://blog.revolutionanalytics.com/2016/03/introductions-to-r-and-predictive-analytics.html

A preview of the New York R Conference: http://blog.revolutionanalytics.com/2016/03/get-ready-for-nyr.html

The R Consortium has funded seven community projects and two working groups for R projects:
http://blog.revolutionanalytics.com/2016/03/r-consortium-announces-new-grants-for-r-projects-and-working-groups.html

A look at several methods for computing http://blog.revolutionanalytics.com/2016/03/com_class_eval_metrics_r.html and
assessing the performance of classification models, with R:
http://blog.revolutionanalytics.com/2016/03/classification-models.html

An application to help airlines prevent unexpected maintenance delays, based on predictive models created with R:
http://blog.revolutionanalytics.com/2016/03/predictive-maintenance.html

Using R to predict the winning basketball team in the March Madness competition:
http://blog.revolutionanalytics.com/2016/03/march-madness.html

How to call an R function published to Azure ML from an Excel worksheet:
http://blog.revolutionanalytics.com/2016/03/scoring-r-models-with-excel.html

You can now use magrittr pipes with the out-of-memory XDF data files used by Microsoft R Server:
http://blog.revolutionanalytics.com/2016/03/dplyrxdf-update.html

Watch the recorded webinar "Data Preparation Techniques with R", and download the free e-book by Nina Zumel:
http://blog.revolutionanalytics.com/2016/03/data-preparation-webinar.html

An R-based application to automatically classify galaxies in the World Wide Telescope was featured in a keynote at
Microsoft's Data Driven event: http://blog.revolutionanalytics.com/2016/03/sql-server-2016-launch.html

Microsoft R Server is now available in the Azure Marketplace:
http://blog.revolutionanalytics.com/2016/03/r-server-azure-mkt.html

R 3.2.4 was released by the R Core Group on March 10: http://blog.revolutionanalytics.com/2016/03/r-324-released.html

Previews of some talks at the Bay Area R Users Group:
http://blog.revolutionanalytics.com/2016/03/barug-at-strata-and-paw.html

R Tools for Visual Studio, which lets you edit and debug R code within Visual Studio, is now available:
http://blog.revolutionanalytics.com/2016/03/rtvs-preview.html

A tutorial on creating election maps with R, from ComputerWorld:
http://blog.revolutionanalytics.com/2016/03/interactive-election-maps.html

A history of the R project since the release of version 1.0.0:
http://blog.revolutionanalytics.com/2016/03/16-years-of-r-history.html

Calculating confidence intervals for Random Forest predictions based on a corrected jackknife estimator:
http://blog.revolutionanalytics.com/2016/03/confidence-intervals-for-random-forest.html

Microsoft's Data Science Virtual Machine now includes Microsoft R Server:
http://blog.revolutionanalytics.com/2016/03/ds-vm-update.html

Using a pet tracker and R to map the movements of a cat:
http://blog.revolutionanalytics.com/2016/03/analysing-the-movements-of-a-cat.html

General interest stories (not related to R) in the past month included: typography in movies
(http://blog.revolutionanalytics.com/2016/03/fonts-from-the-future.html), rubiks cube juggling
(http://blog.revolutionanalytics.com/2016/03/because-its-friday-juggle-solve.html), pianograms
(http://blog.revolutionanalytics.com/2016/03/because-its-friday-pianograms.html) and a robot rebellion
(http://blog.revolutionanalytics.com/2016/03/our-robot-overlords.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the
updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html
If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From profjcnash at gmail.com  Wed Apr  6 21:53:46 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Wed, 6 Apr 2016 15:53:46 -0400
Subject: [R] Optimization max likelihood problem
In-Reply-To: <53C1C5B3-72A4-4982-A911-D94F6E282EE7@gmail.com>
References: <53C1C5B3-72A4-4982-A911-D94F6E282EE7@gmail.com>
Message-ID: <5705694A.3060806@gmail.com>

At the "solution" -- which nlm seems to find OK -- you have a very
nasty scaling issue. exp(z) has value > 10^300.

Better transform your problem somehow to avoid that. You are taking
log of this except for adding 1, so effectively have just z. But you
should look at it carefully and do a number of checks to actually
evaluate the function.

And I would not trust the results if you cannot get analytic gradient of
your function. If you have the gradient, then you can do just a Jacobian
of it numerically to get the Hessian. numDeriv has a jacobian() function
that works nicely for this, and you are then doing only 1 level of
numerical approximation.

However, if that language doesn't mean anything to you, you probably
should not be attempting this problem yourself.

JN


On 16-04-06 02:31 PM, Alaa Sindi wrote:
> hello all,
> 
> I am getting wrong estimates from this code. do you know what could be the problem. 
> 
> thanks
> 
> 
> x<- c(1.6, 1.7, 1.7, 1.7, 1.8, 1.8, 1.8, 1.8)
> y <- c( 6, 13, 18, 28, 52, 53, 61, 60)
> n <- c(59, 60, 62, 56, 63, 59, 62, 60)
> 
> DF <- data.frame(x, y, n)
> 
> # note: there is no need to have the choose(n, y) term in the likelihood
> fn <- function(p, DF) {
>   z <- p[1]+p[2]*DF$x
>   sum( - (DF$y*z) - DF$n*log(1+exp(z)))
>   
>   #sum( - (y*(p[1]+p[2]*x) - n*log(1+exp(p[1]+p[2]*x))) )
> }
> out <- nlm(fn, p = c(1,1),DF, hessian = TRUE, print.level=2)
> print(out)
> eigen(out$hessian)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From josh.m.ulrich at gmail.com  Thu Apr  7 01:58:49 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 6 Apr 2016 18:58:49 -0500
Subject: [R] Is this a bug in quantmod::OpCl?
In-Reply-To: <BLU403-EAS3183309E369A19BBF1F610EE99F0@phx.gbl>
References: <BLU403-EAS3183309E369A19BBF1F610EE99F0@phx.gbl>
Message-ID: <CAPPM_gS5+==W_4+Cp4Jax=G5fhcB2dCDsY5rZx0zy_=yTVLq5w@mail.gmail.com>

On Tue, Apr 5, 2016 at 9:17 PM, James Hirschorn
<james.hirschorn at hotmail.com> wrote:
>
> OpCl works on xts objects but not on quantmod.OHLC objects. Is this a bug?
>
Thanks for the minimal, reproducible example.

Looks like a bug.  There's no as.quantmod.OHLC.xts method, so the zoo
method is dispatched.  Calling Op() or Cl() on this zoo-based object
results in a vector (since zoo will drop dimensions, like a matrix or
data.frame), and you can't set column names on a vector.

I'm not sure whether it makes more sense to check for dims in all the
combination transformations (consisting of combined Op, Hi, Lo, Cl) or
to create a as.quantmod.OHLC.xts method.

Can you provide some details about your use case?

> Example error:
>
> x.Date <- as.Date("2003-02-01") + c(1, 3, 7, 9, 14) - 1
> set.seed(1)
> x <- zoo(matrix(runif(20, 0, 1), nrow=5, ncol=4), x.Date)
> q <- as.quantmod.OHLC(x,c("Open","High","Low","Close"))
>
> # error
> OpCl(q)
> #> Error in `colnames<-`(`*tmp*`, value = "OpCl.q") :
> #>  attempt to set 'colnames' on an object with less than two dimensions
>
> # OK
> OpCl(as.xts(q))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From drjimlemon at gmail.com  Thu Apr  7 02:19:01 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 7 Apr 2016 10:19:01 +1000
Subject: [R] Extracting windows from time series
In-Reply-To: <E9DA6CABC0F0734A9980C6E78E9024BA0708BD8F@aai-exch-mbx8.campus.unibe.ch>
References: <E9DA6CABC0F0734A9980C6E78E9024BA0708BD8F@aai-exch-mbx8.campus.unibe.ch>
Message-ID: <CA+8X3fVyQ=zHfwde69fTyvYWpfTSfmZ7shQ=bsfAvOw=6Pu5vw@mail.gmail.com>

Hi Matthias,
It looks to me as though you could do this with a couple of loops:

temps<-rnorm(400,14,0.05)
ttind<-NULL
for(ti in 1:(length(temps)-9)) {
 if(temps[ti]-temps[ti+9] >= 0.1 && max(temps[ti]-temps[ti+1:9]) > -0.05)
  ttind<-c(ttind,ti)
}
cat("\t\t",paste("Year",1:10,sep=""),"\n")
for(ti in 1:length(ttind)) {
 cat("Trend ",ti,":\t",sep="")
 cat(round(temps[ttind[ti]:(ttind[ti]+9)],3),sep="\t","\n")
}

Whether my criteria for determining a trend is correct is another matter.

Jim

On Thu, Apr 7, 2016 at 12:27 AM,  <maettuw at students.unibe.ch> wrote:
> Dear R Users
>
> Thanks for the help in advance and lets get straight to the problem:
> I have a 400 year long temperature time series and I am looking for decades that show a linear trend decrease of approximately -0.1 Kelvin or degrees. --> What I would like to program: A loop/function / command line that prints the values of all the trends (can also be overlapping) into a matrix that could have the following structure :
>
>                 Year 1 (of Trend1)     Year 2 ( ... 2)     Year 3 .....     .....     .....
> Trend 1:
> Trend 2:
> Trend 3:
> ...
> .
> .
>
>  I  first tried to solve the task with a loop but ended up doing it with function but got stuck. Here is what I did so far:
>
> Puls <- Surface_temperature_MA10[10:394] + 1 # give all values in the TS a positive value. Like that
> ## I can easier extract the trends that fullfill the searched condition (decrease of 0.1 Kelvin) --> look  next line
>
> Difference <- diff(Puls,lag=10) # x[(1+lag):n] - x[1:(n-lag)] --> time step 20 - timestep 10 for first calculation --> does that for whole time series
> ID <- c(1:375)
> melted_Difference <- melt(data.frame(Difference,ID),id.vars="ID")
>
> Hiatus <- subset(melted_Difference,value < -0.1)
>
> here the result :
> 23   23 Difference -0.1184901
> 24   24 Difference -0.1723032
> 25   25 Difference -0.1366112
> 26   26 Difference -0.1745479
> 27   27 Difference -0.1805964
> 28   28 Difference -0.2285250
> 29   29 Difference -0.2449096
> 30   30 Difference -0.1052558
> 44   44 Difference -0.1172029
>
> -->23,24,25 etc. corresponds to the first years of the trends that shows a decrease of at least -0.1 Kelvin/decade. So far my method works. The purpose of that was that I could then use the window() function to extract
> the original values from Puls.
> This works, but only for one decade at one time -->
>
> List_Hiatus <- window(Puls,1,start = c(23), end =  c(34))
>> List_Hiatus
>  [1] 1.125813 1.143880 1.123572 1.139369 1.134410 1.137944 1.139320 1.055780 1.026300 1.042695 1.007323 0.971577
> attr(,"tsp")
> [1] 23 34  1
>
> Tried but failed with the following approaches:
>
> Start_H <- as.numeric(Hiatus[,1:1])
> End_H <- as.numeric(Start_H + 10)
> List_Hiatus <- window(Puls,1,start = "Start_H", end =  "End_H")
>
> OR :
> List_Hiatus <- window(Puls,1,start = c(23,24), end =  c(33,34))   # where c could of course be expanded
>
> Or
> apply(Puls,2,window(start=c(Start_H),end=c(End_H)))
>
> Thanks again for your time.
>
> Best Matthias
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tgs77m at yahoo.com  Thu Apr  7 06:09:54 2016
From: tgs77m at yahoo.com (Thomas Subia)
Date: Wed, 6 Apr 2016 21:09:54 -0700
Subject: [R]  identifying outliers
Message-ID: <000001d19083$58191790$084b46b0$@yahoo.com>

Thanks for writing this great piece of code.

 

x = rnorm(100)

boxplot(x) # you shouldn't see any outliers here although sometimes yow will

 

# lets add some outliers intentionally

x = c(21, 20, 25, x) # now 10, 15 and 20 are outliers

 

myboxplot <- boxplot(x) # now you should see your three outliers

 

myboxplot$out # it will print the values of the outliers

 

How does one amend this code to produce the outliers by a group?

 

All the best,

 

Thomas Subia


	[[alternative HTML version deleted]]


From amelia_marsh08 at yahoo.com  Thu Apr  7 08:08:01 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 7 Apr 2016 06:08:01 +0000 (UTC)
Subject: [R] Memory problem
In-Reply-To: <4BB00C74-78D6-4244-8A18-506FEF3B1317@dcn.davis.ca.us>
References: <4BB00C74-78D6-4244-8A18-506FEF3B1317@dcn.davis.ca.us>
Message-ID: <957798103.457461.1460009281291.JavaMail.yahoo@mail.yahoo.com>

Dear Sir,


Yes I am using the plyr and in the end I am writing the output to the data.frame. Earlier I had the problem of process time and hence I made some changes in the code and now I am fetching all the required inputs needed for valuation purpose using ddply, store the results in a data.frame and once that is over, I am carrying out the calculations.

Here is part of my R code-


library(plyr)
library(reshape)


tx <- read.csv('transaction_fxdeal.csv')
tx$id  <-  as.character(tx$id)

n        <- max(unique(simulated_exchange$id))

result <- NULL
current  <- 1
rcount   <- 0
current1 <- 1
rcount1  <- 0
current2 <- 1
rcount2  <- 0
for (env in 0:n) {
  
  if (rcount == 0) rcount <- nrow(subset(simulated_interest, id==env))
  temp <- current+rcount-1
  env_rates  <- simulated_interest[current:temp,]
  env_rates  <- env_rates[order(env_rates$curve, env_rates$day_count), ]
  if (rcount1 == 0)rcount1 <- nrow(subset(simulated_exchange, id==env))
  temp <- current1+rcount1-1
  exch_rates <- simulated_exchange[current1:temp,]
  if (rcount2 == 0)rcount2 <- nrow(subset(simulated_instruments, id==env))
  temp <- current2+rcount2-1
  instr_rates<- simulated_instruments[current2:temp,]
  current <- current+rcount
  current1 <- current1+rcount1
  current2 <- current2+rcount2
  
  curve       <- daply(env_rates, 'curve', function(x) {
    return(approxfun(x$day_count, x$rate, rule = 2))
  })
  
result <- rbind(result, ddply(tx, 'id', function(x) {

intrate_from <- curve[[x$currency_from]](x$maturity_from)
intrate_to   <- curve[[x$currency_to]](x$maturity_to)
cross_rate   <- subset(exch_rates, key==paste(x$currency_from_exch, x$currency_to_exch, sep='_'))$rate
base_rate    <- subset(exch_rates, key==paste(x$currency_to_exch, x$currency_base, sep='_'))$rate

return(data.frame(env=env, intrate_from=intrate_from, intrate_to=intrate_to, cross_rate=cross_rate, base_rate=base_rate))


  }))
}

sorted <- result[order(result$id, result$env),]

sorted$currency_from_exch <- rep(tx$currency_from_exch, each = length(unique(sorted$env)))
sorted$currency_to_exch <- rep(tx$currency_to_exch, each = length(unique(sorted$env)))
sorted$currency_base <- rep(tx$currency_base, each = length(unique(sorted$env)))
sorted$transaction_type <- rep(tx$transaction_type, each = length(unique(sorted$env)))
sorted$amount_fromccy <- rep(tx$amount_fromccy, each = length(unique(sorted$env)))
sorted$amount_toccy <- rep(tx$amount_toccy, each = length(unique(sorted$env)))
sorted$intbasis_fromccy <- rep(tx$intbasis_fromccy, each = length(unique(sorted$env)))
sorted$intbasis_toccy <- rep(tx$intbasis_toccy, each = length(unique(sorted$env)))
sorted$maturity_from <- rep(tx$maturity_from, each = length(unique(sorted$env)))
sorted$maturity_to <- rep(tx$maturity_to, each = length(unique(sorted$env)))
sorted$currency_from <- rep(tx$currency_from, each = length(unique(sorted$env))) 
sorted$currency_to <- rep(tx$currency_to, each = length(unique(sorted$env))) 

sorted$from_mtm <- sorted$cross_rate * (sorted$amount_fromccy / ((1 + (sorted$intrate_from/100))^(sorted$maturity_from / sorted$intbasis_fromccy)))

sorted$to_mtm       <- (sorted$amount_toccy   / ((1 + (sorted$intrate_to/100))^(sorted$maturity_to / sorted$intbasis_toccy)))

mtm_base <- function(from_mtm, to_mtm, base_rate)
{
mtm <- (from_mtm + to_mtm)
mtm_bc = mtm*base_rate[1]

return(data.frame(mtm_bc = mtm_bc))
}

sorted1 <- ddply(.data=sorted, .variables = "id", .fun=function(x) mtm_base(from_mtm = x$from_mtm, to_mtm = x$to_mtm, base_rate = x$base_rate))

sorted$mtm <- sorted1$mtm
sorted$mtm_bc <- sorted1$mtm_bc

sorted2 <- ddply(sorted, .(currency_from_exch, id), mutate, change_in_mtm_bc = mtm_bc - mtm_bc[1])

sorted$change_in_mtm_bc <- sorted2$change_in_mtm_bc

sorted <- sorted[order(sorted$id, sorted$env),]

write.csv(data.frame(sorted), file='MC_result_fxdeal.csv', row.names=FALSE)

# ________________________________________________________

# END of Code



With regards

Amelia







On Wednesday, 6 April 2016 7:43 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:



As Jim has indicated, memory usage problems can require very specific diagnostics and code changes,  so generic help is tough to give. 

However, in most cases I have found the dplyr package to be more memory efficient than plyr, so you could consider that. Also, you can be explicit about only saving the minimum results you want to keep rather than making a list of complete results and extracting results later. 
-- 
Sent from my phone. Please excuse my brevity.


On April 6, 2016 4:39:59 AM PDT, Amelia Marsh via R-help <r-help at r-project.org> wrote:
Dear R Forum,
>
>I have about 2000+ FX forward transactions and I am trying to run 1000 simulations. If I use less no of simulations, I am able to get the desired results. However, when I try to use more than 1000 simulations, I get following error.
>
>
>sorted2 <- ddply(sorted, .(currency_from_exch, id), mutate, change_in_mtm_bc = mtm_bc - mtm_bc[1]) 
>>
>Error: cannot allocate vector of size 15.6 Mb 
>
>
>In addition: Warning messages: 
>1: Reached total allocation of 3583Mb: see help(memory.size) 
>2: Reached total allocation of 3583Mb: see help(memory.size) 
>3: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>4: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>5: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>6: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>7: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size) 
>8: In output[[var]][rng] <- df[[var]] : 
>Reached total allocation of 3583Mb: see help(memory.size)
>
>
>When I checked -
>
>
>memory.size() 
>>[1] 846.83 
>
>memory.limit() 
>>[1] 3583
>
>
>The code is bit lengthy and unfortunately can't be shared.
>
>Kindly guide how this memory probelm can be tackled? I am using R x64 3.2.0
>
>Regards
>
>Amelia
>
>>________________________________
>
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Thu Apr  7 10:43:44 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 7 Apr 2016 08:43:44 +0000
Subject: [R] Problem with <= (less than or equal): not giving
	the	expected	result
In-Reply-To: <1A8C1289955EF649A09086A153E2672403D134D3BF@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <297A3F22-5DDB-4DB7-954C-CBA80351E557@eurac.edu>
	<1A8C1289955EF649A09086A153E2672403D134D3BF@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50250D0@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of S Ellison
> Sent: Wednesday, April 6, 2016 12:35 PM
> To: Rainer Johannes <Johannes.Rainer at eurac.edu>; r-help at r-project.org
> Subject: Re: [R] Problem with <= (less than or equal): not giving the expected
> result
>
> > Apparently, abs(1 - 0.95) is not equal to 0.05, which I find however
> > quite disturbing.
>
> It's normal.* See R FAQ 7.31 in the html help system.
>
> S Ellison
>
> *... and common to all computers that use binary.

The main issue is that when using Excel you do not experience normally such issues, probably because Excel silently decide how to express precision of decimal values.

=+ABS(1-0.995) is equal to 0.005, however
=+ABS(1-0.9995) is not equal to 0.0005

So it when Excel (Excel 2016) users do not use numbers smaller than 0.005 they do not find this behaviour.

Cheers
Petr



>
>
>
> **********************************************************
> *********
> This email and any attachments are confidential. Any use, copying or
> disclosure other than by the intended recipient is unauthorised. If you have
> received this message in error, please notify the sender immediately via
> +44(0)20 8943 7000 or notify postmaster at lgcgroup.com and delete this
> message and any copies from your computer and network.
> LGC Limited. Registered in England 2991879.
> Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Apr  7 10:56:14 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 7 Apr 2016 08:56:14 +0000
Subject: [R] identifying outliers
In-Reply-To: <000001d19083$58191790$084b46b0$@yahoo.com>
References: <000001d19083$58191790$084b46b0$@yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5025107@SRVEXCHMBX.precheza.cz>

Hi

You can check boxplot output by str

> iris[1,1] <- 10
> iris[2,1] <- 8
> bbb <- boxplot(split(iris[,1], iris$Species))
> str(bbb)
List of 6
 $ stats: num [1:5, 1:3] 4.3 4.8 5 5.3 5.8 4.9 5.6 5.9 6.3 7 ...
 $ n    : num [1:3] 50 50 50
 $ conf : num [1:2, 1:3] 4.89 5.11 5.74 6.06 6.34 ...
 $ out  : num [1:3] 10 8 4.9
 $ group: num [1:3] 1 1 3
 $ names: chr [1:3] "setosa" "versicolor" "virginica"
>
and you can find that result is list with out vector containing all outliers and group vector of indication to which group outliers belong.

Getting the output depends on what you want to do with it.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
> Subia via R-help
> Sent: Thursday, April 7, 2016 6:10 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] identifying outliers
>
> Thanks for writing this great piece of code.
>
>
>
> x = rnorm(100)
>
> boxplot(x) # you shouldn't see any outliers here although sometimes yow
> will
>
>
>
> # lets add some outliers intentionally
>
> x = c(21, 20, 25, x) # now 10, 15 and 20 are outliers
>
>
>
> myboxplot <- boxplot(x) # now you should see your three outliers
>
>
>
> myboxplot$out # it will print the values of the outliers
>
>
>
> How does one amend this code to produce the outliers by a group?
>
>
>
> All the best,
>
>
>
> Thomas Subia
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From michaeleartz at gmail.com  Thu Apr  7 13:41:30 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 06:41:30 -0500
Subject: [R] simple question on data frames assignment
Message-ID: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>

Hi I'm not sure how to ask this, but its a very easy question to answer for
an R person.

What is an easy way to check for a column value and then assigne a new
column a value based on that old column value?

For example, Im doing
 colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
"green", "blue", "orange"))
 for (i in 1:nrow(colordata)){
   colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
 }

which works,  but I don't want to use the for loop I want to "vecotrize"
this.  How would this be implemented?

	[[alternative HTML version deleted]]


From dnbarron at gmail.com  Thu Apr  7 13:52:22 2016
From: dnbarron at gmail.com (David Barron)
Date: Thu, 7 Apr 2016 12:52:22 +0100
Subject: [R] simple question on data frames assignment
In-Reply-To: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
Message-ID: <CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>

ifelse is vectorised, so just use that without the loop.

colordata$response <- ifelse(colordata$color == 'blue', 1, 0)

David

On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:

> Hi I'm not sure how to ask this, but its a very easy question to answer for
> an R person.
>
> What is an easy way to check for a column value and then assigne a new
> column a value based on that old column value?
>
> For example, Im doing
>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
> "green", "blue", "orange"))
>  for (i in 1:nrow(colordata)){
>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
>  }
>
> which works,  but I don't want to use the for loop I want to "vecotrize"
> this.  How would this be implemented?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Thu Apr  7 13:57:04 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 06:57:04 -0500
Subject: [R] simple question on data frames assignment
In-Reply-To: <CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
Message-ID: <CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>

Thaks so much!  And how would you incorporate lapply() here?

On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com> wrote:

> ifelse is vectorised, so just use that without the loop.
>
> colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>
> David
>
> On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
>
>> Hi I'm not sure how to ask this, but its a very easy question to answer
>> for
>> an R person.
>>
>> What is an easy way to check for a column value and then assigne a new
>> column a value based on that old column value?
>>
>> For example, Im doing
>>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
>> "green", "blue", "orange"))
>>  for (i in 1:nrow(colordata)){
>>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
>>  }
>>
>> which works,  but I don't want to use the for loop I want to "vecotrize"
>> this.  How would this be implemented?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From art_med_ahmed at yahoo.fr  Thu Apr  7 11:26:40 2016
From: art_med_ahmed at yahoo.fr (Mohamed Benahmed)
Date: Thu, 7 Apr 2016 09:26:40 +0000 (UTC)
Subject: [R] Analyze a file
References: <949875611.1273290.1460021200673.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <949875611.1273290.1460021200673.JavaMail.yahoo@mail.yahoo.com>


hi all,How to analyze a file.txt with R to obtain the corresponding graph.What is the script ?
Please help me!
Thanks,
	[[alternative HTML version deleted]]


From paladini at trustindata.de  Thu Apr  7 13:32:29 2016
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Thu, 07 Apr 2016 13:32:29 +0200
Subject: [R] dynamic reports with sweave: error when compiling the tex-file
Message-ID: <20160407133229.Horde.TdfuzyC26IElzC5TdYNsYA1@webmail.df.eu>

Hello,
I took my first steps in dynamic reports with Gnu R and used sweave().  
I therefore run Sweave() with an example of Friedrich Leisch, starting  
like this:

\ documentclass [ a4paper ]{ article }
\ title { Sweave Example 1}
\ author { Friedrich Leisch }
\ begin { document }
\ maketitle
and so on.

It worked very well but when I tried to compile the latex file I get  
this error message: ! LaTeX Error: Missing \begin{document}."


But clearly there is a "begin{document}"

I looked for a clue searching the internet and read that maybe my  
editor writes invisible signs, so called boms, so that "\begin  
{document} " is not really at the beginninng but these boms.

Unfortunatly I have not the faintest how to solve the problem.

(I am using GNU R 3.01 and windows10 and installed MiKTex.)

It would be really nice if someone could help me!


Best  regards and thanking you in anticipation.

Claudia


From petr.pikal at precheza.cz  Thu Apr  7 14:38:27 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 7 Apr 2016 12:38:27 +0000
Subject: [R] Analyze a file
In-Reply-To: <949875611.1273290.1460021200673.JavaMail.yahoo@mail.yahoo.com>
References: <949875611.1273290.1460021200673.JavaMail.yahoo.ref@mail.yahoo.com>
	<949875611.1273290.1460021200673.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50251A9@SRVEXCHMBX.precheza.cz>

Hi

myfile <- read.table("file.txt")
plot(myfile)

If it does not work, you have wrong file.txt

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mohamed
> Benahmed via R-help
> Sent: Thursday, April 7, 2016 11:27 AM
> To: r-help at r-project.org
> Subject: [R] Analyze a file
>
>
> hi all,How to analyze a file.txt with R to obtain the corresponding graph.What
> is the script ?
> Please help me!
> Thanks,
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Thu Apr  7 14:42:57 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 07 Apr 2016 05:42:57 -0700
Subject: [R] dynamic reports with sweave: error when compiling the
	tex-file
In-Reply-To: <20160407133229.Horde.TdfuzyC26IElzC5TdYNsYA1@webmail.df.eu>
References: <20160407133229.Horde.TdfuzyC26IElzC5TdYNsYA1@webmail.df.eu>
Message-ID: <B62AAA48-80CC-4D2E-B4BA-953BAFD3779B@dcn.davis.ca.us>

Did you really put spaces between the backslashes and the keywords? That would be a problem...
-- 
Sent from my phone. Please excuse my brevity.

On April 7, 2016 4:32:29 AM PDT, paladini at trustindata.de wrote:
>Hello,
>I took my first steps in dynamic reports with Gnu R and used sweave(). 
>
>I therefore run Sweave() with an example of Friedrich Leisch, starting 
>
>like this:
>
>\ documentclass [ a4paper ]{ article }
>\ title { Sweave Example 1}
>\ author { Friedrich Leisch }
>\ begin { document }
>\ maketitle
>and so on.
>
>It worked very well but when I tried to compile the latex file I get  
>this error message: ! LaTeX Error: Missing \begin{document}."
>
>
>But clearly there is a "begin{document}"
>
>I looked for a clue searching the internet and read that maybe my  
>editor writes invisible signs, so called boms, so that "\begin  
>{document} " is not really at the beginninng but these boms.
>
>Unfortunatly I have not the faintest how to solve the problem.
>
>(I am using GNU R 3.01 and windows10 and installed MiKTex.)
>
>It would be really nice if someone could help me!
>
>
>Best  regards and thanking you in anticipation.
>
>Claudia
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Apr  7 14:44:50 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 7 Apr 2016 12:44:50 +0000
Subject: [R] simple question on data frames assignment
In-Reply-To: <CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50251C5@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Artz
> Sent: Thursday, April 7, 2016 1:57 PM
> To: David Barron <dnbarron at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] simple question on data frames assignment
>
> Thaks so much!  And how would you incorporate lapply() here?

Why do you want to use lapply? What is a result you want to achieve?

Actually color is factor and it has a numeric value "inside".

> as.numeric(colordata$color)
[1] 1 4 2 1 3

Cheers
Petr

>
> On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com> wrote:
>
> > ifelse is vectorised, so just use that without the loop.
> >
> > colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
> >
> > David
> >
> > On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
> >
> >> Hi I'm not sure how to ask this, but its a very easy question to
> >> answer for an R person.
> >>
> >> What is an easy way to check for a column value and then assigne a
> >> new column a value based on that old column value?
> >>
> >> For example, Im doing
> >>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
> >> "green", "blue", "orange"))  for (i in 1:nrow(colordata)){
> >>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1,
> >> 0)  }
> >>
> >> which works,  but I don't want to use the for loop I want to "vecotrize"
> >> this.  How would this be implemented?
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Thu Apr  7 15:17:33 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 07 Apr 2016 06:17:33 -0700
Subject: [R] simple question on data frames assignment
In-Reply-To: <CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
Message-ID: <F99BF285-A479-4BA7-B6A6-BF04F458D211@dcn.davis.ca.us>

Lapply is not a vectorized function. It is compact to read, but it would not be worth using for this calculation. 

However, if your data frame had multiple color columns in your data frame that you wanted to make responses for then you might want to use lapply as a more compact version of a for loop to repeat this operation. 

colordata2 <- data.frame(id = c(1,2,3,4,5), color1 = c("blue", "red",
"green", "blue", "orange"), color2 = c("orange", "green",
"blue", "red", "red"))
responses <- lapply( colordata2[ -1 ], function(col) { ifelse(col == 'blue', 1, 0) } )
names(responses) <- names( colordata2 )[-1]

where each of the columns other than the first is handed in turn to the anonymous function that does the response calculation. The result is a data frame (list of columns) with no column names, so I give the new columns names based on the old column names. You could choose different names,  e.g.

names(responses) <- paste0( "response", 1:2 )

but you have to be careful to fix that code whenever you change the colordata2 data frame to have more columns. 
-- 
Sent from my phone. Please excuse my brevity.

On April 7, 2016 4:57:04 AM PDT, Michael Artz <michaeleartz at gmail.com> wrote:
>Thaks so much!  And how would you incorporate lapply() here?
>
>On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com>
>wrote:
>
>> ifelse is vectorised, so just use that without the loop.
>>
>> colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>>
>> David
>>
>> On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com>
>wrote:
>>
>>> Hi I'm not sure how to ask this, but its a very easy question to
>answer
>>> for
>>> an R person.
>>>
>>> What is an easy way to check for a column value and then assigne a
>new
>>> column a value based on that old column value?
>>>
>>> For example, Im doing
>>>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
>>> "green", "blue", "orange"))
>>>  for (i in 1:nrow(colordata)){
>>>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue",
>1, 0)
>>>  }
>>>
>>> which works,  but I don't want to use the for loop I want to
>"vecotrize"
>>> this.  How would this be implemented?
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu Apr  7 15:41:14 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 7 Apr 2016 08:41:14 -0500
Subject: [R] simple question on data frames assignment
In-Reply-To: <CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
Message-ID: <CABdHhvGxHZw75xHDmHpg=_DQ3+fLc_kz1dE14YBMKCH0ZNXxFQ@mail.gmail.com>

== is also vectorised, and you're better off with TRUE and FALSE
rather than 1 and 0, so I'd recommend:

colordata$response <- colordata$color == 'blue'

Hadley

On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com> wrote:
> ifelse is vectorised, so just use that without the loop.
>
> colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>
> David
>
> On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
>
>> Hi I'm not sure how to ask this, but its a very easy question to answer for
>> an R person.
>>
>> What is an easy way to check for a column value and then assigne a new
>> column a value based on that old column value?
>>
>> For example, Im doing
>>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
>> "green", "blue", "orange"))
>>  for (i in 1:nrow(colordata)){
>>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
>>  }
>>
>> which works,  but I don't want to use the for loop I want to "vecotrize"
>> this.  How would this be implemented?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From ruipbarradas at sapo.pt  Thu Apr  7 15:43:58 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 07 Apr 2016 14:43:58 +0100
Subject: [R] simple question on data frames assignment
In-Reply-To: <CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
Message-ID: <20160407144358.Horde.3O5tfMlj8M6KXvIZBYJBeNV@mail.sapo.pt>

Hello,

Or even simpler, without ifelse,

colordata$response <- colordata$color == 'blue' + 0

Hope this helps,

Rui Barradas
?

Citando David Barron <dnbarron at gmail.com>:

> ifelse is vectorised, so just use that without the loop.
>
> colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>
> David
>
> On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
>> Hi I'm not sure how to ask this, but its a very easy question to answer for
>> an R person.
>>
>> What is an easy way to check for a column value and then assigne a new
>> column a value based on that old column value?
>>
>> For example, Im doing
>> colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
>> "green", "blue", "orange"))
>> for (i in 1:nrow(colordata)){
>> ? ?colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
>> }
>>
>> which works,? but I don't want to use the for loop I want to "vecotrize"
>> this.? How would this be implemented?
>>
>> ? ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Thu Apr  7 16:31:18 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 09:31:18 -0500
Subject: [R] simple question on data frames assignment
In-Reply-To: <F99BF285-A479-4BA7-B6A6-BF04F458D211@dcn.davis.ca.us>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
	<F99BF285-A479-4BA7-B6A6-BF04F458D211@dcn.davis.ca.us>
Message-ID: <CA+pG8eOtU7z4tOi6CZdATpvZHUWqx73gB=vQyETZZqizM55b2g@mail.gmail.com>

If you are not using an anonymous function and say you had written the
function out

The below gives me the error > 'f(colordata2$color1)' is not a function,
character or symbol'  But then how is the anonymous function working?


f <- function(col){
  ifelse(col == 'blue', 1, 0)
}
responses <- lapply(colordata2[ -1 ], f(colordata2$color1) )

'f(colordata2$color1)' is not a function, character or symbol'

then how could you then use this fuction in lapply if not for the anonymous
function?

On Thu, Apr 7, 2016 at 8:17 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Lapply is not a vectorized function. It is compact to read, but it would
> not be worth using for this calculation.
>
> However, if your data frame had multiple color columns in your data frame
> that you wanted to make responses for then you might want to use lapply as
> a more compact version of a for loop to repeat this operation.
>
> colordata2 <- data.frame(id = c(1,2,3,4,5), color1 = c("blue", "red",
> "green", "blue", "orange"), color2 = c("orange", "green",
> "blue", "red", "red"))
> responses <- lapply( colordata2[ -1 ], function(col) { ifelse(col ==
> 'blue', 1, 0) } )
> names(responses) <- names( colordata2 )[-1]
>
> where each of the columns other than the first is handed in turn to the
> anonymous function that does the response calculation. The result is a data
> frame (list of columns) with no column names, so I give the new columns
> names based on the old column names. You could choose different names, e.g.
>
> names(responses) <- paste0( "response", 1:2 )
>
> but you have to be careful to fix that code whenever you change the
> colordata2 data frame to have more columns.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 7, 2016 4:57:04 AM PDT, Michael Artz <michaeleartz at gmail.com>
> wrote:
>>
>> Thaks so much!  And how would you incorporate lapply() here?
>>
>> On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com> wrote:
>>
>>  ifelse is vectorised, so just use that without the loop.
>>>
>>>  colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>>>
>>>  David
>>>
>>>  On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
>>>
>>>  Hi I'm not sure how to ask this, but its a very easy question to answer
>>>>  for
>>>>  an R person.
>>>>
>>>>  What is an easy way to check for a column value and then assigne a new
>>>>  column a value based on that old column value?
>>>>
>>>>  For example, Im doing
>>>>   colordata <- data.frame(id = c(1,2,3,4,5),
>>>> color = c("blue", "red",
>>>>  "green", "blue", "orange"))
>>>>   for (i in 1:nrow(colordata)){
>>>>     colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
>>>>   }
>>>>
>>>>  which works,  but I don't want to use the for loop I want to "vecotrize"
>>>>  this.  How would this be implemented?
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ------------------------------
>>>>
>>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>  PLEASE do read the posting guide
>>>>  http://www.R-project.org/posting-guide.html
>>>>  and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Apr  7 16:57:48 2016
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 7 Apr 2016 06:57:48 -0800
Subject: [R] dynamic reports with sweave: error when compiling the
 tex-file
In-Reply-To: <B62AAA48-80CC-4D2E-B4BA-953BAFD3779B@dcn.davis.ca.us>
References: <20160407133229.horde.tdfuzyc26ielzc5tdynsya1@webmail.df.eu>
Message-ID: <EB1EE07B585.000009EDjrkrideau@inbox.com>

Definitely yes I just tried a one line latex document and it bombed with \begin{ document } but is fine with \begin{document} .

I think the spaces within the {} must all be removed. Latex does not like spaces

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jdnewmil at dcn.davis.ca.us
> Sent: Thu, 07 Apr 2016 05:42:57 -0700
> To: paladini at trustindata.de, r-help at r-project.org
> Subject: Re: [R] dynamic reports with sweave: error when compiling the
> tex-file
> 
> Did you really put spaces between the backslashes and the keywords? That
> would be a problem...
> --
> Sent from my phone. Please excuse my brevity.
> 
> On April 7, 2016 4:32:29 AM PDT, paladini at trustindata.de wrote:
> >Hello,
> >I took my first steps in dynamic reports with Gnu R and used sweave().
>> 
> >I therefore run Sweave() with an example of Friedrich Leisch, starting
>> 
> >like this:
>> 
> >\ documentclass [ a4paper ]{ article }
> >\ title { Sweave Example 1}
> >\ author { Friedrich Leisch }
> >\ begin { document }
> >\ maketitle
> >and so on.
>> 
> >It worked very well but when I tried to compile the latex file I get
> >this error message: ! LaTeX Error: Missing \begin{document}."
>> 
>> 
> >But clearly there is a "begin{document}"
>> 
> >I looked for a clue searching the internet and read that maybe my
> >editor writes invisible signs, so called boms, so that "\begin
> >{document} " is not really at the beginninng but these boms.
>> 
> >Unfortunatly I have not the faintest how to solve the problem.
>> 
> >(I am using GNU R 3.01 and windows10 and installed MiKTex.)
>> 
> >It would be really nice if someone could help me!
>> 
>> 
> >Best  regards and thanking you in anticipation.
>> 
> >Claudia
>> 
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jdnewmil at dcn.davis.ca.us  Thu Apr  7 17:04:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 07 Apr 2016 08:04:48 -0700
Subject: [R] simple question on data frames assignment
In-Reply-To: <CA+pG8eOtU7z4tOi6CZdATpvZHUWqx73gB=vQyETZZqizM55b2g@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
	<F99BF285-A479-4BA7-B6A6-BF04F458D211@dcn.davis.ca.us>
	<CA+pG8eOtU7z4tOi6CZdATpvZHUWqx73gB=vQyETZZqizM55b2g@mail.gmail.com>
Message-ID: <9749425F-B61E-44C5-9575-F9270E225019@dcn.davis.ca.us>

lapply(colordata2[ -1 ], f )

When you put the parentheses on, you are calling the function yourself before lapply gets a chance. The error pops up because you are giving a vector of numbers (the answer f gave you) to the second argument of lapply instead of a function. 
-- 
Sent from my phone. Please excuse my brevity.

On April 7, 2016 7:31:18 AM PDT, Michael Artz <michaeleartz at gmail.com> wrote:
>If you are not using an anonymous function and say you had written the
>function out
>
>The below gives me the error > 'f(colordata2$color1)' is not a
>function,
>character or symbol'  But then how is the anonymous function working?
>
>
>f <- function(col){
>  ifelse(col == 'blue', 1, 0)
>}
>responses <- lapply(colordata2[ -1 ], f(colordata2$color1) )
>
>'f(colordata2$color1)' is not a function, character or symbol'
>
>then how could you then use this fuction in lapply if not for the
>anonymous
>function?
>
>On Thu, Apr 7, 2016 at 8:17 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Lapply is not a vectorized function. It is compact to read, but it
>would
>> not be worth using for this calculation.
>>
>> However, if your data frame had multiple color columns in your data
>frame
>> that you wanted to make responses for then you might want to use
>lapply as
>> a more compact version of a for loop to repeat this operation.
>>
>> colordata2 <- data.frame(id = c(1,2,3,4,5), color1 = c("blue", "red",
>> "green", "blue", "orange"), color2 = c("orange", "green",
>> "blue", "red", "red"))
>> responses <- lapply( colordata2[ -1 ], function(col) { ifelse(col ==
>> 'blue', 1, 0) } )
>> names(responses) <- names( colordata2 )[-1]
>>
>> where each of the columns other than the first is handed in turn to
>the
>> anonymous function that does the response calculation. The result is
>a data
>> frame (list of columns) with no column names, so I give the new
>columns
>> names based on the old column names. You could choose different
>names, e.g.
>>
>> names(responses) <- paste0( "response", 1:2 )
>>
>> but you have to be careful to fix that code whenever you change the
>> colordata2 data frame to have more columns.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 7, 2016 4:57:04 AM PDT, Michael Artz
><michaeleartz at gmail.com>
>> wrote:
>>>
>>> Thaks so much!  And how would you incorporate lapply() here?
>>>
>>> On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com>
>wrote:
>>>
>>>  ifelse is vectorised, so just use that without the loop.
>>>>
>>>>  colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>>>>
>>>>  David
>>>>
>>>>  On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com>
>wrote:
>>>>
>>>>  Hi I'm not sure how to ask this, but its a very easy question to
>answer
>>>>>  for
>>>>>  an R person.
>>>>>
>>>>>  What is an easy way to check for a column value and then assigne
>a new
>>>>>  column a value based on that old column value?
>>>>>
>>>>>  For example, Im doing
>>>>>   colordata <- data.frame(id = c(1,2,3,4,5),
>>>>> color = c("blue", "red",
>>>>>  "green", "blue", "orange"))
>>>>>   for (i in 1:nrow(colordata)){
>>>>>     colordata$response[i] <- ifelse(colordata[i,"color"] ==
>"blue", 1, 0)
>>>>>   }
>>>>>
>>>>>  which works,  but I don't want to use the for loop I want to
>"vecotrize"
>>>>>  this.  How would this be implemented?
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ------------------------------
>>>>>
>>>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>  PLEASE do read the posting guide
>>>>>  http://www.R-project.org/posting-guide.html
>>>>>  and provide commented, minimal, self-contained, reproducible
>code.
>>>>
>>>>
>>>>
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Thu Apr  7 17:29:30 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 10:29:30 -0500
Subject: [R] simple question on data frames assignment
In-Reply-To: <9749425F-B61E-44C5-9575-F9270E225019@dcn.davis.ca.us>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
	<F99BF285-A479-4BA7-B6A6-BF04F458D211@dcn.davis.ca.us>
	<CA+pG8eOtU7z4tOi6CZdATpvZHUWqx73gB=vQyETZZqizM55b2g@mail.gmail.com>
	<9749425F-B61E-44C5-9575-F9270E225019@dcn.davis.ca.us>
Message-ID: <CA+pG8eNtEfOawdyw9THebG_4svGwBOiiavPu_NADN5RhXgPWsQ@mail.gmail.com>

It all makes so much sense now

On Thu, Apr 7, 2016 at 10:04 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> lapply(colordata2[ -1 ], f )
>
> When you put the parentheses on, you are calling the function yourself
> before lapply gets a chance. The error pops up because you are giving a
> vector of numbers (the answer f gave you) to the second argument of lapply
> instead of a function.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 7, 2016 7:31:18 AM PDT, Michael Artz <michaeleartz at gmail.com>
> wrote:
>>
>> If you are not using an anonymous function and say you had written the
>> function out
>>
>> The below gives me the error > 'f(colordata2$color1)' is not a function,
>> character or symbol'  But then how is the anonymous function working?
>>
>>
>> f <- function(col){
>>   ifelse(col == 'blue', 1, 0)
>> }
>> responses <- lapply(colordata2[ -1 ], f(colordata2$color1) )
>>
>> 'f(colordata2$color1)' is not a function, character or symbol'
>>
>> then how could you then use this fuction in lapply if not for the
>> anonymous function?
>>
>> On Thu, Apr 7, 2016 at 8:17 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> Lapply is not a vectorized function. It is compact to read, but it would
>>> not be worth using for this calculation.
>>>
>>> However, if your data frame had multiple color columns in your data
>>> frame that you wanted to make responses for then you might want to use
>>> lapply as a more compact version of a for loop to repeat this operation.
>>>
>>> colordata2 <- data.frame(id = c(1,2,3,4,5), color1 = c("blue", "red",
>>> "green", "blue", "orange"), color2 = c("orange", "green",
>>> "blue", "red", "red"))
>>> responses <- lapply( colordata2[ -1 ], function(col) { ifelse(col ==
>>> 'blue', 1, 0) } )
>>> names(responses) <- names( colordata2 )[-1]
>>>
>>> where each of the columns other than the first is handed in turn to the
>>> anonymous function that does the response calculation. The result is a data
>>> frame (list of columns) with no column names, so I give the new columns
>>> names based on the old column names. You could choose different names, e.g.
>>>
>>> names(responses) <- paste0( "response", 1:2 )
>>>
>>> but you have to be careful to fix that code whenever you change the
>>> colordata2 data frame to have more columns.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On April 7, 2016 4:57:04 AM PDT, Michael Artz <michaeleartz at gmail.com>
>>> wrote:
>>>>
>>>> Thaks so much!  And how would you incorporate lapply() here?
>>>>
>>>> On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com> wrote:
>>>>
>>>>  ifelse is vectorised, so just use that without the loop.
>>>>>
>>>>>  colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>>>>>
>>>>>  David
>>>>>
>>>>>  On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
>>>>>
>>>>>  Hi I'm not sure how to ask this, but its a very easy question to answer
>>>>>>  for
>>>>>>  an R person.
>>>>>>
>>>>>>  What is an easy way to check for a column value and
>>>>>> then assigne a new
>>>>>>  column a value based on that old column value?
>>>>>>
>>>>>>  For example, Im doing
>>>>>>   colordata <- data.frame(id = c(1,2,3,4,5),
>>>>>> color = c("blue", "red",
>>>>>>  "green", "blue", "orange"))
>>>>>>   for (i in 1:nrow(colordata)){
>>>>>>     colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
>>>>>>   }
>>>>>>
>>>>>>  which works,  but I don't want to use the for loop I want to "vecotrize"
>>>>>>  this.  How would this be implemented?
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ------------------------------
>>>>>>
>>>>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>  PLEASE do read the posting guide
>>>>>>  http://www.R-project.org/posting-guide.html
>>>>>>  and provide commented, minimal, self-contained, reproducible
>>>>>> code.
>>>>>
>>>>>
>>>>>
>>>>
>>>>  [[alternative HTML version deleted]]
>>>>
>>>> ------------------------------
>>>>
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>

	[[alternative HTML version deleted]]


From maettuw at students.unibe.ch  Thu Apr  7 18:09:07 2016
From: maettuw at students.unibe.ch (maettuw at students.unibe.ch)
Date: Thu, 7 Apr 2016 16:09:07 +0000
Subject: [R] Storing output of loop into list()
Message-ID: <E9DA6CABC0F0734A9980C6E78E9024BA0708D6B8@aai-exch-mbx8.campus.unibe.ch>

Hello. I am trying to store the output from a loop into a matrix. Failed so far, thanks for the help.

What I want to store into a new matrix: (just run the code once):

temps<-rnorm(400,14,0.05)
ttind<-NULL
for(ti in 1:(length(temps)-9)) {
  if(temps[ti]-temps[ti+9] >= 0.1 && max(temps[ti]-temps[ti+1:9]) > -0.05)
    ttind<-c(ttind,ti)
}
for(ti in 1:length(ttind)) {

 print(round(temps[ttind[ti]:(ttind[ti]+9)],3))

  }







My (failed) soultion attempt:

temps<-rnorm(400,14,0.05)
ttind<-NULL
for(ti in 1:(length(temps)-9)) {
  if(temps[ti]-temps[ti+9] >= 0.1 && max(temps[ti]-temps[ti+1:9]) > -0.05)
    ttind<-c(ttind,ti)
}

outputList = list()
counter = 1

for(ti in 1:length(ttind)) {

  outputList[i] <-  print(round(temps[ttind[ti]:(ttind[ti]+9)],3))
counter= counter+1
  }

print(outputList)


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Apr  7 18:17:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 7 Apr 2016 09:17:53 -0700
Subject: [R] Storing output of loop into list()
In-Reply-To: <E9DA6CABC0F0734A9980C6E78E9024BA0708D6B8@aai-exch-mbx8.campus.unibe.ch>
References: <E9DA6CABC0F0734A9980C6E78E9024BA0708D6B8@aai-exch-mbx8.campus.unibe.ch>
Message-ID: <CAGxFJbSi_enfsRZQj=cXnYxdXBuozBLj9Y-dY79c=bfbO5=2FA@mail.gmail.com>

Have a look at ?lapply, which will do this for you.

Have you spent time with an R tutorial or two. There are many good
ones on the web that discuss this sort of thig.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 7, 2016 at 9:09 AM,  <maettuw at students.unibe.ch> wrote:
> Hello. I am trying to store the output from a loop into a matrix. Failed so far, thanks for the help.
>
> What I want to store into a new matrix: (just run the code once):
>
> temps<-rnorm(400,14,0.05)
> ttind<-NULL
> for(ti in 1:(length(temps)-9)) {
>   if(temps[ti]-temps[ti+9] >= 0.1 && max(temps[ti]-temps[ti+1:9]) > -0.05)
>     ttind<-c(ttind,ti)
> }
> for(ti in 1:length(ttind)) {
>
>  print(round(temps[ttind[ti]:(ttind[ti]+9)],3))
>
>   }
>
>
>
>
>
>
>
> My (failed) soultion attempt:
>
> temps<-rnorm(400,14,0.05)
> ttind<-NULL
> for(ti in 1:(length(temps)-9)) {
>   if(temps[ti]-temps[ti+9] >= 0.1 && max(temps[ti]-temps[ti+1:9]) > -0.05)
>     ttind<-c(ttind,ti)
> }
>
> outputList = list()
> counter = 1
>
> for(ti in 1:length(ttind)) {
>
>   outputList[i] <-  print(round(temps[ttind[ti]:(ttind[ti]+9)],3))
> counter= counter+1
>   }
>
> print(outputList)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Thirumurugan.Rajamoorthy-CW at otsuka-us.com  Thu Apr  7 17:31:28 2016
From: Thirumurugan.Rajamoorthy-CW at otsuka-us.com (Rajamoorthy-CW, Thirumurugan 8361)
Date: Thu, 7 Apr 2016 15:31:28 +0000
Subject: [R] Question about R Ver.2.7.2 compatible with JAVA 8
Message-ID: <85E3CBACDFDA9C49B49B22CC0C21FA4D4FDB93F3@z1exch06>

Hi Team,

We (Otsuka IT team) are planning to upgrade JAVA 8 to Biometrics department servers. On account of this, we want to make sure R Ver.2.7.2 is working fine in JAVA 8?
Please let us know if R Ver.2.7.2 is compatible with JAVA 8?




Regards

Thirumurugan Rajamoorthy |Thirumurugan.Rajamoorthy-CW at otsuka-us.com<mailto:Thirumurugan.Rajamoorthy-CW at otsuka-us.com>| ?: (240)780-4194
Managed Service Provider, Biometrics Support Member, HCL Technologies.
A Member of the Otsuka Information Technology (OIT) Network.
In Support of Global R&D IT Services.


	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Apr  7 19:09:47 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 7 Apr 2016 12:09:47 -0500
Subject: [R] Storing output of loop into list()
In-Reply-To: <E9DA6CABC0F0734A9980C6E78E9024BA0708D6B8@aai-exch-mbx8.campus.unibe.ch>
References: <E9DA6CABC0F0734A9980C6E78E9024BA0708D6B8@aai-exch-mbx8.campus.unibe.ch>
Message-ID: <CAN5YmCHvbMzfVcDTJhLrsNYH=LFaY=F2hd2MGx6ZHG1Cf6kokA@mail.gmail.com>

You don't need a for loop for the first part.  You can do it like this:

Notice that I used unchanging data for the temps vector so that you could
tell us what output you expect to see, in case what I provide is not
adequate.

temps <- c(13.988, 13.932, 14.039, 14.082, 13.998, 13.93, 14.028, 14.015,
  14.06, 14.092, 14.089, 13.971, 14.062, 14.001, 13.959, 14.046,
  14.034, 14.089, 13.991, 13.982, 14.038, 14.001, 13.973, 13.966,
  13.995, 13.934, 14.101, 14.087, 14.064, 14.06, 14.027, 13.996,
  14.037, 14.024, 14.032, 14.052, 13.986, 14.021, 13.988, 13.98,
  13.968, 13.959, 14.055, 13.978, 14.105, 14.005, 13.996, 14.027,
  13.99, 13.966, 14.047, 13.903, 13.953, 14.02, 13.969, 14.051,
  14.027, 14.03, 14.078, 13.988, 14.007, 13.899, 14.023, 13.991,
  13.993, 13.973, 14.035, 14.091, 14.033, 13.943, 14.08, 14, 14.015,
  14.042, 13.993, 14.064, 14.039, 13.939, 13.95, 14.017, 13.984,
  14.075, 14.006, 14.029, 14.004, 13.974, 14.003, 14.073, 13.991,
  13.973, 14.029, 14.02, 14.032, 14.036, 14.021, 13.983, 13.981,
  13.977, 13.94, 14.014)

tempdif9 <- -diff(temps, lag=9)
L <- length(tempdif9)
sel <- tempdif9[-L] >= 0.1 & tempdif9[-1] > -0.05
ttind <- cbind(tempdif9, index=1:L)[sel, ]
ttind

     tempdif9 index
[1,]    0.101    10
[2,]    0.100    17
[3,]    0.101    28
[4,]    0.152    43

I'm not sure what you are trying to achieve with the second part.  I
suspect that what you really wanted is to see the temperatures that
contributed to the output in ttind.  If that's the case, then perhaps this
will help.

contrib <- t(sapply(ttind[, "index"], function(i) temps[i + 0:8]))
contrib

       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]   [,9]
[1,] 14.092 14.089 13.971 14.062 14.001 13.959 14.046 14.034 14.089
[2,] 14.034 14.089 13.991 13.982 14.038 14.001 13.973 13.966 13.995
[3,] 14.087 14.064 14.060 14.027 13.996 14.037 14.024 14.032 14.052
[4,] 14.055 13.978 14.105 14.005 13.996 14.027 13.990 13.966 14.047

Jean


On Thu, Apr 7, 2016 at 11:09 AM, <maettuw at students.unibe.ch> wrote:

> Hello. I am trying to store the output from a loop into a matrix. Failed
> so far, thanks for the help.
>
> What I want to store into a new matrix: (just run the code once):
>
> temps<-rnorm(400,14,0.05)
> ttind<-NULL
> for(ti in 1:(length(temps)-9)) {
>   if(temps[ti]-temps[ti+9] >= 0.1 && max(temps[ti]-temps[ti+1:9]) > -0.05)
>     ttind<-c(ttind,ti)
> }
> for(ti in 1:length(ttind)) {
>
>  print(round(temps[ttind[ti]:(ttind[ti]+9)],3))
>
>   }
>
>
>
>
>
>
>
> My (failed) soultion attempt:
>
> temps<-rnorm(400,14,0.05)
> ttind<-NULL
> for(ti in 1:(length(temps)-9)) {
>   if(temps[ti]-temps[ti+9] >= 0.1 && max(temps[ti]-temps[ti+1:9]) > -0.05)
>     ttind<-c(ttind,ti)
> }
>
> outputList = list()
> counter = 1
>
> for(ti in 1:length(ttind)) {
>
>   outputList[i] <-  print(round(temps[ttind[ti]:(ttind[ti]+9)],3))
> counter= counter+1
>   }
>
> print(outputList)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Apr  7 19:13:27 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 7 Apr 2016 13:13:27 -0400
Subject: [R] Question about R Ver.2.7.2 compatible with JAVA 8
In-Reply-To: <85E3CBACDFDA9C49B49B22CC0C21FA4D4FDB93F3@z1exch06>
References: <85E3CBACDFDA9C49B49B22CC0C21FA4D4FDB93F3@z1exch06>
Message-ID: <57069537.9080307@gmail.com>

On 07/04/2016 11:31 AM, Rajamoorthy-CW, Thirumurugan 8361 wrote:
> Hi Team,
>
> We (Otsuka IT team) are planning to upgrade JAVA 8 to Biometrics department servers. On account of this, we want to make sure R Ver.2.7.2 is working fine in JAVA 8?
> Please let us know if R Ver.2.7.2 is compatible with JAVA 8?

R 2.7.2 is very old --- it was released nearly 8 years ago.   I think 
you're going to have to do the testing yourself, unless you're very 
lucky that someone remembers.

Duncan Murdoch

>
>
>
>
> Regards
>
> Thirumurugan Rajamoorthy |Thirumurugan.Rajamoorthy-CW at otsuka-us.com<mailto:Thirumurugan.Rajamoorthy-CW at otsuka-us.com>| ?: (240)780-4194
> Managed Service Provider, Biometrics Support Member, HCL Technologies.
> A Member of the Otsuka Information Technology (OIT) Network.
> In Support of Global R&D IT Services.
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From JSorkin at grecc.umaryland.edu  Thu Apr  7 22:25:22 2016
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 07 Apr 2016 16:25:22 -0400
Subject: [R] using apply to a data frame
In-Reply-To: <1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
	<1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>


??I would like to apply a function, fract, to the columns of a
dataframe. I tried the following 
apply(data5NonEventEpochs,2,fract)
but, no surprise it did not work as apply works on matrices not data
frames. How can I apply a fuction to the columns of a data frame? (I
can't covert data5NonEventsEpochs to a matrix as it contains character
data).
Thank you,
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From luisfo89 at yahoo.es  Thu Apr  7 22:34:38 2016
From: luisfo89 at yahoo.es (Luisfo Chiroque)
Date: Thu, 7 Apr 2016 23:34:38 +0300
Subject: [R] using apply to a data frame
In-Reply-To: <570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
	<1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
	<570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
Message-ID: <DAFD4B68-13C0-4225-A318-BFB5EAE08616@yahoo.es>

Dear John,

Try using
	sapply(data5NonEventEpochs, fract)

HTH

Best,
Luisfo Chiroque
PhD Student
IMDEA Networks Institute
http://fourier.networks.imdea.org/people/~luis_nunez/ <http://fourier.networks.imdea.org/people/~luis_nunez/>
> El 7 abr 2016, a las 23:25, John Sorkin <JSorkin at grecc.umaryland.edu> escribi?:
> 
> 
> ??I would like to apply a function, fract, to the columns of a
> dataframe. I tried the following 
> apply(data5NonEventEpochs,2,fract)
> but, no surprise it did not work as apply works on matrices not data
> frames. How can I apply a fuction to the columns of a data frame? (I
> can't covert data5NonEventsEpochs to a matrix as it contains character
> data).
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From bgunter.4567 at gmail.com  Thu Apr  7 22:51:06 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 7 Apr 2016 13:51:06 -0700
Subject: [R] using apply to a data frame
In-Reply-To: <570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
	<1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
	<570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
Message-ID: <CAGxFJbQq29UEQFdUksWBbhTjUFuS6QWYNnc-t9vU2GxorcZ+tw@mail.gmail.com>

Inline.

-- Bert
Bert Gunter




On Thu, Apr 7, 2016 at 1:25 PM, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
>
> ??I would like to apply a function, fract, to the columns of a
> dataframe. I tried the following
> apply(data5NonEventEpochs,2,fract)
> but, no surprise it did not work as apply works on matrices not data
> frames.

That is false! From ?apply:

"If X is not an array but an object of a class with a non-null dim
value (such as a data frame), apply attempts to coerce it to an array
via as.matrix if it is two-dimensional (e.g., a data frame) or via
as.array."

Your apply() call would not have worked with a matrix either, as your
syntax was wrong.  Here is a corrected example:

> X <- data.frame(a=1:5,b=6:10)

> apply(X,2,function(x)mean(sqrt(x)))
       a        b
1.676466 2.817189






 How can I apply a fuction to the columns of a data frame? (I
> can't covert data5NonEventsEpochs to a matrix as it contains character
> data).
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From murray.efford at otago.ac.nz  Thu Apr  7 23:21:53 2016
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Thu, 7 Apr 2016 21:21:53 +0000
Subject: [R] R.squared in summary.lm with weights
Message-ID: <1460064106032.30358@otago.ac.nz>

Following some old advice on this list, I have been reading the code for summary.lm to understand the computation of R-squared from a weighted regression. Usually weights in lm are applied to squared residuals, but I see that the weighted mean of the observations is calculated as if the weights are on the original scale:

[...]
    f <- z$fitted.values
    w <- z$weights
[...]
            m <- sum(w * f/sum(w))
            [mss <-]  sum(w * (f - m)^2)
[...]

This seems inconsistent to me. What am I missing?

Murray Efford

From peter.langfelder at gmail.com  Fri Apr  8 00:06:01 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 7 Apr 2016 15:06:01 -0700
Subject: [R] using apply to a data frame
In-Reply-To: <570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
	<1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
	<570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
Message-ID: <CA+hbrhWcqfxaibE8Y7QeOnwQHo21afO0u2QgEAAAN5k4YpLp2A@mail.gmail.com>

Use lapply or sapply. A data frame is also a list with each component
representing one column; lapply/sapply will apply the function to each
column.

Peter

On Thu, Apr 7, 2016 at 1:25 PM, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
>
> ??I would like to apply a function, fract, to the columns of a
> dataframe. I tried the following
> apply(data5NonEventEpochs,2,fract)
> but, no surprise it did not work as apply works on matrices not data
> frames. How can I apply a fuction to the columns of a data frame? (I
> can't covert data5NonEventsEpochs to a matrix as it contains character
> data).
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From jsorkin at grecc.umaryland.edu  Fri Apr  8 00:39:37 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 07 Apr 2016 18:39:37 -0400
Subject: [R] Using a function with apply Error: undefined columns selected
Message-ID: <5706A969020000CB0014FE8B@smtp.medicine.umaryland.edu>

I am trying to write a function that can be used to apply to process all the columns of a data.frame. If you will run the code below, you will get the error message undefined columns selected. I hope someone will be able to teach me what I am doing wrong.
Thank you,
John 
 
# create data frame.
guppy
 
fract2 <- function(col,data) {
  cat("Prove we have passed the data frame\n")
  print(data)
  
  # Get the name of the column being processed.
  zz<-deparse(substitute(col))
  cat("Column being processed\n")
  print(zz)
  p<-sum(data[,zz]!="")/length(data[,zz])
  return(p)
}
 
apply(guppy,2,fract2,data=guppy)
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From drjimlemon at gmail.com  Fri Apr  8 01:44:45 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 8 Apr 2016 09:44:45 +1000
Subject: [R] Using a function with apply Error: undefined columns
	selected
In-Reply-To: <5706A969020000CB0014FE8B@smtp.medicine.umaryland.edu>
References: <5706A969020000CB0014FE8B@smtp.medicine.umaryland.edu>
Message-ID: <CA+8X3fXVaDKgr9XN-Xe9=9u2d4VbKtVzM4xKZW+nwATjD0qwHA@mail.gmail.com>

Hi John,
First, apply isn't guaranteed to work on data frames. There are two
easy ways to do something like this, but we had better have a data
frame:

guppy<-data.frame(taste=rnorm(10,5),
 crunch=rnorm(10,5),satiety=rnorm(10,5))

If you just want to apply a function to all or a subset of columns of
a data frame, a for loop can be used:

fract2.1<-function(col,data) {
 p<-sum(data[,col],na.rm=TRUE)/sum(!is.na(data[,col]))
 return(p)
}
for(col in 1:ncol(guppy)) print(fract2.1(col,guppy))

If you really do want to use an "*apply" function, then the function
has to be written for each column, not the entire data frame:

fract2.2<-function(x) return(sum(x,na.rm=TRUE)/sum(!is.na(x)))
sapply(guppy,fract2.2)

and if you want a subset of the columns, you will have to do it before
you let sapply get into it.

Jim



On Fri, Apr 8, 2016 at 8:39 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> I am trying to write a function that can be used to apply to process all the columns of a data.frame. If you will run the code below, you will get the error message undefined columns selected. I hope someone will be able to teach me what I am doing wrong.
> Thank you,
> John
>
> # create data frame.
> guppy
>
> fract2 <- function(col,data) {
>   cat("Prove we have passed the data frame\n")
>   print(data)
>
>   # Get the name of the column being processed.
>   zz<-deparse(substitute(col))
>   cat("Column being processed\n")
>   print(zz)
>   p<-sum(data[,zz]!="")/length(data[,zz])
>   return(p)
> }
>
> apply(guppy,2,fract2,data=guppy)
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From michaeleartz at gmail.com  Fri Apr  8 03:46:25 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 20:46:25 -0500
Subject: [R] why data frame's logical index isnt working
Message-ID: <CA+pG8ePag+jdx+ZOEjEnjH47Vf5aEGC8w1DeSsTjMHNZ=CT1jQ@mail.gmail.com>

data.frame.$columnToAdd["CurrentColumnName" == "ConditionMet"] <- 1

Can someone please explain to me why the above command gives all NAs to
columnToAdd?  I thought this was possible in R to do logical expression in
the index of a data frame

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Fri Apr  8 03:49:33 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 20:49:33 -0500
Subject: [R] simple question on data frames assignment
In-Reply-To: <20160407144358.Horde.3O5tfMlj8M6KXvIZBYJBeNV@mail.sapo.pt>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<20160407144358.Horde.3O5tfMlj8M6KXvIZBYJBeNV@mail.sapo.pt>
Message-ID: <CA+pG8eOmYUXSTtba9umtgx7Efh9NQF66sYTzGJ+RhnSVGH=0-w@mail.gmail.com>

Fyi, This statement returned the following error

'Error in "Yes" + 0 : non-numeric argument to binary operator'

On Thu, Apr 7, 2016 at 8:43 AM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Or even simpler, without ifelse,
>
> colordata$response <- colordata$color == 'blue' + 0
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando David Barron <dnbarron at gmail.com>:
>
> ifelse is vectorised, so just use that without the loop.
>
> colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>
> David
>
> On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
>
> Hi I'm not sure how to ask this, but its a very easy question to answer for
> an R person.
>
> What is an easy way to check for a column value and then assigne a new
> column a value based on that old column value?
>
> For example, Im doing
> colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
> "green", "blue", "orange"))
> for (i in 1:nrow(colordata)){
>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
> }
>
> which works,  but I don't want to use the for loop I want to "vecotrize"
> this.  How would this be implemented?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.htmland provide commented,
> minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Fri Apr  8 03:50:02 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 20:50:02 -0500
Subject: [R] simple question on data frames assignment
In-Reply-To: <CABdHhvGxHZw75xHDmHpg=_DQ3+fLc_kz1dE14YBMKCH0ZNXxFQ@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CABdHhvGxHZw75xHDmHpg=_DQ3+fLc_kz1dE14YBMKCH0ZNXxFQ@mail.gmail.com>
Message-ID: <CA+pG8eMzs-x+jTdnzNq3=n1tMYQJ+iZBMGX=6mUV2c=CpyGMBQ@mail.gmail.com>

Why am I better off with true and false?

On Thu, Apr 7, 2016 at 8:41 AM, Hadley Wickham <h.wickham at gmail.com> wrote:

> == is also vectorised, and you're better off with TRUE and FALSE
> rather than 1 and 0, so I'd recommend:
>
> colordata$response <- colordata$color == 'blue'
>
> Hadley
>
> On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com> wrote:
> > ifelse is vectorised, so just use that without the loop.
> >
> > colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
> >
> > David
> >
> > On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
> >
> >> Hi I'm not sure how to ask this, but its a very easy question to answer
> for
> >> an R person.
> >>
> >> What is an easy way to check for a column value and then assigne a new
> >> column a value based on that old column value?
> >>
> >> For example, Im doing
> >>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
> >> "green", "blue", "orange"))
> >>  for (i in 1:nrow(colordata)){
> >>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1, 0)
> >>  }
> >>
> >> which works,  but I don't want to use the for loop I want to "vecotrize"
> >> this.  How would this be implemented?
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> http://hadley.nz
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Fri Apr  8 03:54:53 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 7 Apr 2016 21:54:53 -0400
Subject: [R] why data frame's logical index isnt working
In-Reply-To: <CA+pG8ePag+jdx+ZOEjEnjH47Vf5aEGC8w1DeSsTjMHNZ=CT1jQ@mail.gmail.com>
References: <CA+pG8ePag+jdx+ZOEjEnjH47Vf5aEGC8w1DeSsTjMHNZ=CT1jQ@mail.gmail.com>
Message-ID: <CAGx1TMCXr8HxL94TTA2a2z+4RfiECHqrGBMwcQ2zGNbzrje-yQ@mail.gmail.com>

you probably mean something like this

data.frame.$columnToAdd <- (data.frame.$CurrentColumnName ==
data.frame.$ConditionMet)

what you did is compare two character strings.  They are not the same.
Therefore a new column
is created with the default value NA.

> tmp <- data.frame(A=1:4, B=c(1,3,4,5))
> tmp
  A B
1 1 1
2 2 3
3 3 4
4 4 5
> tmp$C <- tmp$A == tmp$B
> tmp
  A B     C
1 1 1  TRUE
2 2 3 FALSE
3 3 4 FALSE
4 4 5 FALSE
> tmp$D["A" == "B"] <- 1
> tmp
  A B     C  D
1 1 1  TRUE NA
2 2 3 FALSE NA
3 3 4 FALSE NA
4 4 5 FALSE NA
>

On Thu, Apr 7, 2016 at 9:46 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> data.frame.$columnToAdd["CurrentColumnName" == "ConditionMet"] <- 1
>
> Can someone please explain to me why the above command gives all NAs to
> columnToAdd?  I thought this was possible in R to do logical expression in
> the index of a data frame
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Apr  8 04:21:43 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Apr 2016 19:21:43 -0700
Subject: [R] using apply to a data frame
In-Reply-To: <570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
	<1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
	<570689F2020000CB0014FE58@smtp.medicine.umaryland.edu>
Message-ID: <420AB3C6-1F25-4646-8371-82756684B6F7@comcast.net>


> On Apr 7, 2016, at 1:25 PM, John Sorkin <JSorkin at grecc.umaryland.edu> wrote:
> 
> 
> ??I would like to apply a function, fract, to the columns of a
> dataframe. I tried the following 
> apply(data5NonEventEpochs,2,fract)
> but, no surprise it did not work as apply works on matrices not data
> frames.

As Bert pointed out your analsysis is incorrect. If `fract` is  function that takes a single vector then you should have gotten back a list or a matrix with as many entries or columns as the data5NonEventEpochs had columns.

So to do anything further, please post the output of dput(fract)

-- 
David.

> How can I apply a fuction to the columns of a data frame? (I
> can't covert data5NonEventsEpochs to a matrix as it contains character
> data).
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From dwinsemius at comcast.net  Fri Apr  8 04:29:04 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Apr 2016 19:29:04 -0700
Subject: [R] why data frame's logical index isnt working
In-Reply-To: <CA+pG8ePag+jdx+ZOEjEnjH47Vf5aEGC8w1DeSsTjMHNZ=CT1jQ@mail.gmail.com>
References: <CA+pG8ePag+jdx+ZOEjEnjH47Vf5aEGC8w1DeSsTjMHNZ=CT1jQ@mail.gmail.com>
Message-ID: <0F066E14-863B-4E5D-B97E-D589050C9958@comcast.net>


> On Apr 7, 2016, at 6:46 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> 
> data.frame.$columnToAdd["CurrentColumnName" == "ConditionMet"] <- 1
> 
> Can someone please explain to me why the above command gives all NAs to
> columnToAdd?  I thought this was possible in R to do logical expression in
> the index of a data frame

It is possible, but please execute this at a console line and then read ?"[" to see what is happening:

"CurrentColumnName" == "ConditionMet"  # almost surely FALSE

Let's assume your dataframe were named 'dat'.

Perhaps you meant to write:

dat$colToAdd[ dat[["CurrentColumnName"]] == dat[["ConditionMet"]] ] <- 1

And do please stop naming your dataframes "data.frame".


> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hd625b at gmail.com  Thu Apr  7 23:51:33 2016
From: hd625b at gmail.com (hd625b)
Date: Thu, 7 Apr 2016 14:51:33 -0700
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <1460064106032.30358@otago.ac.nz>
References: <1460064106032.30358@otago.ac.nz>
Message-ID: <5706D665.2040203@gmail.com>

Do you mean w <-  z$residuals ?
Type names(z) to see the list of item in your model.

I ran your code on a lm and it work fine.
You don't need the brackets around mss <-

Michael Long



On 04/07/2016 02:21 PM, Murray Efford wrote:
> Following some old advice on this list, I have been reading the code for summary.lm to understand the computation of R-squared from a weighted regression. Usually weights in lm are applied to squared residuals, but I see that the weighted mean of the observations is calculated as if the weights are on the original scale:
>
> [...]
>      f <- z$fitted.values
>      w <- z$weights
> [...]
>              m <- sum(w * f/sum(w))
>              [mss <-]  sum(w * (f - m)^2)
> [...]
>
> This seems inconsistent to me. What am I missing?
>
> Murray Efford
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murray.efford at otago.ac.nz  Fri Apr  8 04:40:26 2016
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Fri, 8 Apr 2016 02:40:26 +0000
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <5706D665.2040203@gmail.com>
References: <1460064106032.30358@otago.ac.nz>,<5706D665.2040203@gmail.com>
Message-ID: <1460083217866.99049@otago.ac.nz>

Perhaps I did not make clear that this is not my code - it is the code in summary.lm. I used square brackets to try to make my edited version of the text intelligible - print summary.lm and you will see where my version fits in.
________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of hd625b <hd625b at gmail.com>
Sent: Friday, 8 April 2016 9:51 a.m.
To: r-help at r-project.org
Subject: Re: [R] R.squared in summary.lm with weights

Do you mean w <-  z$residuals ?
Type names(z) to see the list of item in your model.

I ran your code on a lm and it work fine.
You don't need the brackets around mss <-

Michael Long



On 04/07/2016 02:21 PM, Murray Efford wrote:
> Following some old advice on this list, I have been reading the code for summary.lm to understand the computation of R-squared from a weighted regression. Usually weights in lm are applied to squared residuals, but I see that the weighted mean of the observations is calculated as if the weights are on the original scale:
>
> [...]
>      f <- z$fitted.values
>      w <- z$weights
> [...]
>              m <- sum(w * f/sum(w))
>              [mss <-]  sum(w * (f - m)^2)
> [...]
>
> This seems inconsistent to me. What am I missing?
>
> Murray Efford
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From michaeleartz at gmail.com  Fri Apr  8 04:44:19 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Thu, 7 Apr 2016 21:44:19 -0500
Subject: [R] why data frame's logical index isnt working
In-Reply-To: <0F066E14-863B-4E5D-B97E-D589050C9958@comcast.net>
References: <CA+pG8ePag+jdx+ZOEjEnjH47Vf5aEGC8w1DeSsTjMHNZ=CT1jQ@mail.gmail.com>
	<0F066E14-863B-4E5D-B97E-D589050C9958@comcast.net>
Message-ID: <CA+pG8eMq8SauinbLbrUdxn4pkm2MHWhNiUfSR_XAvN4hyQpb6w@mail.gmail.com>

I don't get it, I thought the double index was to indicate and individual
element within a column(vector)?
I will stop using data.frame, thanks a lot!

On Thu, Apr 7, 2016 at 9:29 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 7, 2016, at 6:46 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> >
> > data.frame.$columnToAdd["CurrentColumnName" == "ConditionMet"] <- 1
> >
> > Can someone please explain to me why the above command gives all NAs to
> > columnToAdd?  I thought this was possible in R to do logical expression
> in
> > the index of a data frame
>
> It is possible, but please execute this at a console line and then read
> ?"[" to see what is happening:
>
> "CurrentColumnName" == "ConditionMet"  # almost surely FALSE
>
> Let's assume your dataframe were named 'dat'.
>
> Perhaps you meant to write:
>
> dat$colToAdd[ dat[["CurrentColumnName"]] == dat[["ConditionMet"]] ] <- 1
>
> And do please stop naming your dataframes "data.frame".
>
>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Apr  8 04:45:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Apr 2016 19:45:26 -0700
Subject: [R] Using a function with apply Error: undefined columns
	selected
In-Reply-To: <5706A969020000CB0014FE8B@smtp.medicine.umaryland.edu>
References: <5706A969020000CB0014FE8B@smtp.medicine.umaryland.edu>
Message-ID: <C0CF18ED-B8E1-46D8-92BD-404EBE7FA2DA@comcast.net>


> On Apr 7, 2016, at 3:39 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> I am trying to write a function that can be used to apply to process all the columns of a data.frame. If you will run the code below, you will get the error message undefined columns selected. I hope someone will be able to teach me what I am doing wrong.
> Thank you,
> John 
> 
> # create data frame.
> guppy
> 
> fract2 <- function(col,data) {
>  cat("Prove we have passed the data frame\n")
>  print(data)
> 
>  # Get the name of the column being processed.
>  zz<-deparse(substitute(col))
>  cat("Column being processed\n")
>  print(zz)
>  p<-sum(data[,zz]!="")/length(data[,zz])
>  return(p)
> }
> 
> apply(guppy,2,fract2,data=guppy)

At the point where the error is about to occur during the first column being processed, this is what had been printed:

Column being processed
[1] "newX[, i]"

So it should be no surprise that the actual error was:

Error in `[.data.frame`(data, , zz) : undefined columns selected

It occurred at one of the two points where you tried `data[,zz]`

You need to pass colnames(guppy) to fract2 and work with the character values.

All of the *apply function pass only values so they do not pass the column names for testing. A possible exception might be the colnames of a vector being avaialble when using apply with an index of 1.

-- 



> John David Sorkin M.D., Ph.D.
> 
Snipped

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Apr  8 05:03:39 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Apr 2016 20:03:39 -0700
Subject: [R] why data frame's logical index isnt working
In-Reply-To: <CA+pG8eMq8SauinbLbrUdxn4pkm2MHWhNiUfSR_XAvN4hyQpb6w@mail.gmail.com>
References: <CA+pG8ePag+jdx+ZOEjEnjH47Vf5aEGC8w1DeSsTjMHNZ=CT1jQ@mail.gmail.com>
	<0F066E14-863B-4E5D-B97E-D589050C9958@comcast.net>
	<CA+pG8eMq8SauinbLbrUdxn4pkm2MHWhNiUfSR_XAvN4hyQpb6w@mail.gmail.com>
Message-ID: <5372B778-5C50-4C04-81B1-9FAB9BF542FC@comcast.net>


> On Apr 7, 2016, at 7:44 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> 

> I don't get it, I thought the double index was to indicate and individual element within a column(vector)?

Character values by themselves either quoted or not are not assumed to refer to column names unless you use `with` or `within`.


> I will stop using data.frame, thanks a lot!

You will have a lot of problems using R if you stop using data.frames.

-- 
David.
> 
> On Thu, Apr 7, 2016 at 9:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Apr 7, 2016, at 6:46 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> >
> > data.frame.$columnToAdd["CurrentColumnName" == "ConditionMet"] <- 1
> >
> > Can someone please explain to me why the above command gives all NAs to
> > columnToAdd?  I thought this was possible in R to do logical expression in
> > the index of a data frame
> 
> It is possible, but please execute this at a console line and then read ?"[" to see what is happening:
> 
> "CurrentColumnName" == "ConditionMet"  # almost surely FALSE
> 
> Let's assume your dataframe were named 'dat'.
> 
> Perhaps you meant to write:
> 
> dat$colToAdd[ dat[["CurrentColumnName"]] == dat[["ConditionMet"]] ] <- 1
> 
> And do please stop naming your dataframes "data.frame".
> 
> 
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From sj_style_1125 at outlook.com  Fri Apr  8 07:13:12 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Fri, 8 Apr 2016 05:13:12 +0000
Subject: [R] [R ] help in if else in connect the simulation in normal and
 gamma distribution.
Message-ID: <KL1PR01MB0887E5633A7CF32ADAE6FCB7B5910@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>

I am new in R. I have to conduct simulation study on the robustness of 2 sample tests on several combination of factors (sample sizes ,variance and distribution).


I have been completed write a code in normal distribution, and now i wish to add if -else in the code so that the code can simulated result for gamma distribution also.

But i am stucking again as how can i connect both of them by using if -else?

Can anyone just give me a brief idea on it ?


(i am sorry if this is no related )This is additional question,for gamma, since the mean and variance are dependent on each other, so as i assume the null hypothesis is TRUE, then do I need to minus the sample mean and add the overall mean as well ?in order to make sure that the null hypothesis is TRUE...


Thanks in advance and i am sorry if this is a silly question ....


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Apr  8 09:40:03 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 8 Apr 2016 07:40:03 +0000
Subject: [R] simple question on data frames assignment
In-Reply-To: <CA+pG8eMpM8sCKks=QWHgH1DW9GmPAha7y0OGoF30m_=aYiA4vQ@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CA+pG8eNBKRYWxogAZ5=176paU0WA9f-6DWB758-uSbdT0xtFBA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50251C5@SRVEXCHMBX.precheza.cz>
	<CA+pG8eMpM8sCKks=QWHgH1DW9GmPAha7y0OGoF30m_=aYiA4vQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502557C@SRVEXCHMBX.precheza.cz>

Hi

The question does not make much sense so as your code. Maybe you shall spend some time with R tutorials.


1.       lapply or sapply is basically hidden cycle

2.       function shall return something, yours does not

So if you want some binary outcome from a vector you can use e.g.

f <- function(vector, token) {
response <- vector==token
response
}

So with your colordata

> colordata
  id  color
1  1   blue
2  2    red
3  3  green
4  4   blue
5  5 orange

You can get this

> colordata$result <- f(colordata$color, "blue")
> colordata
  id  color result
1  1   blue   TRUE
2  2    red  FALSE
3  3  green  FALSE
4  4   blue   TRUE
5  5 orange  FALSE

or if you insist on numbers you can transfer it easily.

> colordata$result*1
[1] 1 0 0 1 0

But why do you want to use lapply or sapply is a mystery to me.

Do you have several columns and you want to use same function to those columns? This is probably the only case I can think of using lapply with such function.

Or you want to change each colour name to some corresponding number? If column colour is a factor it already consists from unique numbers (as I mentioned in previous response).

Maybe you shall use dput(yourdata) output together with desired result to help us better understand your task.

Cheers
Petr


From: Michael Artz [mailto:michaeleartz at gmail.com]
Sent: Thursday, April 7, 2016 4:17 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] simple question on data frames assignment

what about sapply?   I guess I am not sure how to iterate with sapply() and a function like the following

>>The below function does not work, I want to have a function that  I can use for sapply() later
f <- function(x) {
  response <- ifelse(x[,"Churn"] == "blue", 1, 0)
}

sapply(colordata$color, f(x))

does that question make sense?  I just want to have a function that I can pass to sapply()

On Thu, Apr 7, 2016 at 7:44 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Michael
> Artz
> Sent: Thursday, April 7, 2016 1:57 PM
> To: David Barron <dnbarron at gmail.com<mailto:dnbarron at gmail.com>>
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] simple question on data frames assignment
>
> Thaks so much!  And how would you incorporate lapply() here?

Why do you want to use lapply? What is a result you want to achieve?

Actually color is factor and it has a numeric value "inside".

> as.numeric(colordata$color)
[1] 1 4 2 1 3

Cheers
Petr

>
> On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com<mailto:dnbarron at gmail.com>> wrote:
>
> > ifelse is vectorised, so just use that without the loop.
> >
> > colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
> >
> > David
> >
> > On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com<mailto:michaeleartz at gmail.com>> wrote:
> >
> >> Hi I'm not sure how to ask this, but its a very easy question to
> >> answer for an R person.
> >>
> >> What is an easy way to check for a column value and then assigne a
> >> new column a value based on that old column value?
> >>
> >> For example, Im doing
> >>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue", "red",
> >> "green", "blue", "orange"))  for (i in 1:nrow(colordata)){
> >>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue", 1,
> >> 0)  }
> >>
> >> which works,  but I don't want to use the for loop I want to "vecotrize"
> >> this.  How would this be implemented?
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Apr  8 09:43:31 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 8 Apr 2016 07:43:31 +0000
Subject: [R] simple question on data frames assignment
In-Reply-To: <CA+pG8eMzs-x+jTdnzNq3=n1tMYQJ+iZBMGX=6mUV2c=CpyGMBQ@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<CABdHhvGxHZw75xHDmHpg=_DQ3+fLc_kz1dE14YBMKCH0ZNXxFQ@mail.gmail.com>
	<CA+pG8eMzs-x+jTdnzNq3=n1tMYQJ+iZBMGX=6mUV2c=CpyGMBQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502558F@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Artz
> Sent: Friday, April 8, 2016 3:50 AM
> To: Hadley Wickham <h.wickham at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] simple question on data frames assignment
>
> Why am I better off with true and false?

I believe that because logical values can be transfered to numbers easily and you can use them directly to subset your object without any issue with numerical precision.

Cheers
Petr


>
> On Thu, Apr 7, 2016 at 8:41 AM, Hadley Wickham <h.wickham at gmail.com>
> wrote:
>
> > == is also vectorised, and you're better off with TRUE and FALSE
> > rather than 1 and 0, so I'd recommend:
> >
> > colordata$response <- colordata$color == 'blue'
> >
> > Hadley
> >
> > On Thu, Apr 7, 2016 at 6:52 AM, David Barron <dnbarron at gmail.com>
> wrote:
> > > ifelse is vectorised, so just use that without the loop.
> > >
> > > colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
> > >
> > > David
> > >
> > > On 7 April 2016 at 12:41, Michael Artz <michaeleartz at gmail.com> wrote:
> > >
> > >> Hi I'm not sure how to ask this, but its a very easy question to
> > >> answer
> > for
> > >> an R person.
> > >>
> > >> What is an easy way to check for a column value and then assigne a
> > >> new column a value based on that old column value?
> > >>
> > >> For example, Im doing
> > >>  colordata <- data.frame(id = c(1,2,3,4,5), color = c("blue",
> > >> "red", "green", "blue", "orange"))  for (i in 1:nrow(colordata)){
> > >>    colordata$response[i] <- ifelse(colordata[i,"color"] == "blue",
> > >> 1, 0)  }
> > >>
> > >> which works,  but I don't want to use the for loop I want to "vecotrize"
> > >> this.  How would this be implemented?
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > http://hadley.nz
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Fri Apr  8 12:57:27 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 8 Apr 2016 06:57:27 -0400
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <1460064106032.30358@otago.ac.nz>
References: <1460064106032.30358@otago.ac.nz>
Message-ID: <57078E97.1@gmail.com>

On 07/04/2016 5:21 PM, Murray Efford wrote:
> Following some old advice on this list, I have been reading the code for summary.lm to understand the computation of R-squared from a weighted regression. Usually weights in lm are applied to squared residuals, but I see that the weighted mean of the observations is calculated as if the weights are on the original scale:
>
> [...]
>      f <- z$fitted.values
>      w <- z$weights
> [...]
>              m <- sum(w * f/sum(w))
>              [mss <-]  sum(w * (f - m)^2)
> [...]
>
> This seems inconsistent to me. What am I missing?

I think you are expecting consistency where there needn't be any.  Why 
do you see an inconsistency here?  Those are different calculations. 
You get expressions like these if you assume observations have variance 
sigma^2/w, and you're trying to estimate sigma^2.

Duncan Murdoch


From ruipbarradas at sapo.pt  Fri Apr  8 12:58:14 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 08 Apr 2016 11:58:14 +0100
Subject: [R] simple question on data frames assignment
In-Reply-To: <CA+pG8eOmYUXSTtba9umtgx7Efh9NQF66sYTzGJ+RhnSVGH=0-w@mail.gmail.com>
References: <CA+pG8ePfxfx=ZN_gf52rYuOV6H_WWkZDw_kavEZ74KBY7XtjKg@mail.gmail.com>
	<CAHuze_Je8JfvrHm7Ptiu2AzJPkP5kjM5fkh9H4AhfaUSBhYedg@mail.gmail.com>
	<20160407144358.Horde.3O5tfMlj8M6KXvIZBYJBeNV@mail.sapo.pt>
	<CA+pG8eOmYUXSTtba9umtgx7Efh9NQF66sYTzGJ+RhnSVGH=0-w@mail.gmail.com>
Message-ID: <20160408115814.Horde.a1LHO7L3wnVXB47GtT430kA@mail.sapo.pt>

Hello,

   You're right, sorry, I missed the parenthesis:

   colordata$response <- (colordata$color == 'blue') + 0

   Rui Barradas

Quoting Michael Artz <michaeleartz at gmail.com>:
> Fyi, This statement returned the following error   ?
> 'Error in "Yes" + 0 : non-numeric argument to binary operator'
>
>
> On Thu, Apr 7, 2016 at 8:43 AM, <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>>        Or even simpler, without ifelse,
>>
>>        colordata$response <- colordata$color == 'blue' + 0
>>
>>        Hope this helps,
>>
>>        Rui Barradas
>>        ?
>>
>> Citando David Barron <dnbarron at gmail.com>:
>>>
>>> ifelse is vectorised, so just use that without the loop.
>>>
>>>           colordata$response <- ifelse(colordata$color == 'blue', 1, 0)
>>>
>>>           David
>>>
>>>           On 7 April 2016 at 12:41, Michael Artz  
>>> <michaeleartz at gmail.com> wrote:
>>>>
>>>> Hi I'm not sure how to ask this, but its a very easy question to  
>>>> answer for
>>>>            an R person.
>>>>
>>>>            What is an easy way to check for a column value and  
>>>> then assigne a new
>>>>            column a value based on that old column value?
>>>>
>>>>            For example, Im doing
>>>>            colordata <- data.frame(id = c(1,2,3,4,5), color =  
>>>> c("blue", "red",
>>>>            "green", "blue", "orange"))
>>>>            for (i in 1:nrow(colordata)){
>>>>            ? ?colordata$response[i] <-  
>>>> ifelse(colordata[i,"color"] == "blue", 1, 0)
>>>>            }
>>>>
>>>>            which works,? but I don't want to use the for loop I  
>>>> want to "vecotrize"
>>>>            this.? How would this be implemented?
>>>>
>>>>            ? ? ? ? [[alternative HTML version deleted]]
>>>>
>>>>            ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>            PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>            and provide commented, minimal, self-contained,  
>>>> reproducible code.
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>>          ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>
>>>        PLEASE do read the posting guide  
>>> http://www.R-project.org/posting-guide.htmland provide commented,  
>>> minimal, self-contained, reproducible code.
>>
>>
>>        ?
>>
>>
>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Apr  8 13:28:01 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Apr 2016 13:28:01 +0200
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <57078E97.1@gmail.com>
References: <1460064106032.30358@otago.ac.nz> <57078E97.1@gmail.com>
Message-ID: <A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>


On 08 Apr 2016, at 12:57 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 07/04/2016 5:21 PM, Murray Efford wrote:
>> Following some old advice on this list, I have been reading the code for summary.lm to understand the computation of R-squared from a weighted regression. Usually weights in lm are applied to squared residuals, but I see that the weighted mean of the observations is calculated as if the weights are on the original scale:
>> 
>> [...]
>>     f <- z$fitted.values
>>     w <- z$weights
>> [...]
>>             m <- sum(w * f/sum(w))
>>             [mss <-]  sum(w * (f - m)^2)
>> [...]
>> 
>> This seems inconsistent to me. What am I missing?
> 
> I think you are expecting consistency where there needn't be any.  Why do you see an inconsistency here?  Those are different calculations. You get expressions like these if you assume observations have variance sigma^2/w, and you're trying to estimate sigma^2.
> 


It's also perfectly consistent that m is the minimizer of mss:

d/dm sum(w*(f-m)^2) = -2 sum(w*(f-m)) = 0 => m = sum(w*f) / sum(w)

However, beware the distiction between inverse variance weights, replication weights, and sampling weights. 


> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From michael.griffiths at news.co.uk  Fri Apr  8 14:23:05 2016
From: michael.griffiths at news.co.uk (Griffiths, Michael)
Date: Fri, 8 Apr 2016 13:23:05 +0100
Subject: [R] Subject: tcl-tk error on Suse Linux R install
Message-ID: <CANOihi_ErvM+3LwKq87LGJ-ou-b8Nky2S6-4hE6wqCEwDsNPLw@mail.gmail.com>

Dear R Forum,

I have R installed on a SUSE Linux server. The version of R is 3.2.4
Revised. I have been trying to install R commander on the server to provide
a GUI for code development, however when I come to install Rcmdr via

install.packages(?<package-name>?,repos=c(?
http://cran.revolutionanalytics.com?),dependencies=TRUE,type=?source?)

I have a series of non-zero exit status messages for several packages,
including tcltk2. After a little digging round, it seems that tcltk is not
available to my R install.

Now if I offer the command capabilities inside R I am then told that tcltk
is FALSE.

However the zypper in tk tcl command, says that tk and tcl are both
installed and are present in the Linux install.

My question is this: how do I make both tk and tcl available to R so that I
can download and install the R commander package?

Many thanks as always for the R communities time

Mike Griffiths

-- 


--

"Please consider the environment before printing this e-mail"

Newsworks - bringing advertisers and newsbrands together

www.newsworks.org.uk

This e-mail and any attachments are confidential, may be

legally privileged and are the property of News Corp UK & Ireland

Limited on whose systems they were generated. News Corp UK

& Ireland Limited is the holding company for the News UK group,

is registered in England & Wales under number 81701, has its 

registered office at 1 London Bridge Street, London, SE1 9GF and 

is registered with VAT number GB 243 8054 69. If you have received 

this e-mail in error, please notify the sender immediately and do not

use, distribute, store or copy it in any way. Statements or opinions in

this e-mail or any attachment are those of the author and are not 
necessarily agreed or authorised by News Corp UK & Ireland Limited 

or any member of its group. News Corp UK & Ireland Limited may

monitor outgoing or incoming emails as permitted by law.  It accepts
no liability for viruses introduced by this e-mail or attachments. 

News Corp UK & Ireland Limited and its titles are committed to abiding by 
IPSO's regulations and the Editors' Code of Practice that IPSO enforces.

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Fri Apr  8 14:24:38 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Fri, 8 Apr 2016 14:24:38 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
Message-ID: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>

I am trying to draw maps for the world using:

library(rworldmap)
library(maptools)
library(RColorBrewer)


tmp2<- dput(head(pece,10))
structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
"CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
NA, 1.44414067268372, 2.34257817268372, 2.89687490463257, 2.15937495231628
), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
c(13.4375638961792,
8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
2016 17:43", .Names = c("iso3",
"eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
"%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
"(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
rd_in_va"
), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
    c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
    c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
    "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
    ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
    "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
    ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
    ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
    "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
    "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
    "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
    ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
    "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
    ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
"+1.0000000000000X+000"
    ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
    c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
n <- n[-which(row.names(n)=='Antarctica'),]

# EPS
colourPalette <- rev(brewer.pal(7, "RdYlGn"))

eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
Score",colourPalette=colourPalette,
                      catMethod="fixedWidth", missingCountryCol = "white",
addLegend=FALSE)
do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))

Instead of adding numeric based legend, I would like to add a two-headed
arrow with some text. I would be grateful for any help. Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From elopomorph at hotmail.com  Fri Apr  8 15:54:34 2016
From: elopomorph at hotmail.com (Michael)
Date: Fri, 8 Apr 2016 13:54:34 +0000
Subject: [R] Generating Hotelling's T squared statistic with hclust
Message-ID: <BLUPR13MB00654AF0416DEB973A6709E0DE910@BLUPR13MB0065.namprd13.prod.outlook.com>

I am doing a cluster analysis with hclust.  I want to get hclust to output the Hotelling's T squared statistic for each cluster so I can evaluate is data points should be in a cluster or not.  My research to answer this question has been unsuccessful.  Does anyone know how to get hclust to output the Hotelling's T squared statistic for each cluster?


Mike



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Apr  8 16:48:04 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 8 Apr 2016 07:48:04 -0700
Subject: [R] Generating Hotelling's T squared statistic with hclust
In-Reply-To: <BLUPR13MB00654AF0416DEB973A6709E0DE910@BLUPR13MB0065.namprd13.prod.outlook.com>
References: <BLUPR13MB00654AF0416DEB973A6709E0DE910@BLUPR13MB0065.namprd13.prod.outlook.com>
Message-ID: <CAGxFJbRfL3pcOEv0PAoD18fy4kSsF3s=F3h24PpAOXS5sza2Tw@mail.gmail.com>

1. Where did you get the idea that this was a good thing to do?

2. Don't do it.

3. Do not reply to r-help: my comments are about statistics, not R,
and so further discussion is off topic here. Either ignore me or post
follow up to a statistics list like stats.stackexchange.com  .

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 8, 2016 at 6:54 AM, Michael <elopomorph at hotmail.com> wrote:
> I am doing a cluster analysis with hclust.  I want to get hclust to output the Hotelling's T squared statistic for each cluster so I can evaluate is data points should be in a cluster or not.  My research to answer this question has been unsuccessful.  Does anyone know how to get hclust to output the Hotelling's T squared statistic for each cluster?
>
>
> Mike
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alaasindi at gmail.com  Fri Apr  8 17:46:29 2016
From: alaasindi at gmail.com (Alaa Sindi)
Date: Fri, 8 Apr 2016 11:46:29 -0400
Subject: [R] p-value or the t-test value
Message-ID: <386AF840-51F7-4CF5-83FD-F8381F63712A@gmail.com>

Hello,

How can I print out the p-value or the t-test value for coefficients estimated from a likelihood function. 

Thanks

From josh.m.ulrich at gmail.com  Fri Apr  8 18:12:47 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 8 Apr 2016 11:12:47 -0500
Subject: [R] Is this a bug in quantmod::OpCl?
In-Reply-To: <BLU436-SMTP32E04EDC5F1C01CF25CD92E9910@phx.gbl>
References: <BLU403-EAS3183309E369A19BBF1F610EE99F0@phx.gbl>
	<CAPPM_gS5+==W_4+Cp4Jax=G5fhcB2dCDsY5rZx0zy_=yTVLq5w@mail.gmail.com>
	<BLU436-SMTP32E04EDC5F1C01CF25CD92E9910@phx.gbl>
Message-ID: <CAPPM_gTwYsk4dFgPqMvN-rA=V3Pi2d3JMGZQUriBTihQUHX2SQ@mail.gmail.com>

On Fri, Apr 8, 2016 at 10:51 AM, James Hirschorn
<james.hirschorn at hotmail.com> wrote:
>
>
> On 04/06/2016 07:58 PM, Joshua Ulrich wrote:
>>
>> On Tue, Apr 5, 2016 at 9:17 PM, James Hirschorn
>> <james.hirschorn at hotmail.com> wrote:
>>>
>>> OpCl works on xts objects but not on quantmod.OHLC objects. Is this a
>>> bug?
>>>
>> Thanks for the minimal, reproducible example.
>>
>> Looks like a bug.  There's no as.quantmod.OHLC.xts method, so the zoo
>> method is dispatched.  Calling Op() or Cl() on this zoo-based object
>> results in a vector (since zoo will drop dimensions, like a matrix or
>> data.frame), and you can't set column names on a vector.
>>
>> I'm not sure whether it makes more sense to check for dims in all the
>> combination transformations (consisting of combined Op, Hi, Lo, Cl) or
>> to create a as.quantmod.OHLC.xts method.
>>
>> Can you provide some details about your use case?
>
> At this stage, my use case is making some custom indicators. I've not used
> quantmod much in the past, but I just assumed that quantmod.OHLC was the
> class I should be using with quantmod.
>
> Some details: The starting point was tick data, for example
>
> # n seconds of tick data
> n <- 600
> tick.data.timestamp <- as.POSIXct("2016-04-06 00:00:00", tz = 'GMT') + 1:n
> set.seed(1)
> tick.data <- xts(cbind(Price = runif(n, 0, 1),
>                        Volume = sample(1:100, replace = T, n)),
>                  tick.data.timestamp)
>
> Then aggregating to minute OHLC data as quantmod.OHLC:
>
> minute.data <- as.quantmod.OHLC(to.minutes(tick.data),
> c("Open","High","Low","Close","Volume"),
>                                 name = 'Sym')
>
> or alternatively as xts:
>
> minute.data.xts <- as.xts(minute.data)
>
> OpCl is naturally useful for indicators, since it shows whether we have a
> red or green candlestick. xts is working fine for my indicators for now, but
> I don't know if not using quantmod.OHLC will be a problem for backtesting.
>
Using xts should be fine.  I'm not sure whether there's much
functionality in quantmod that depends on the quantmod.OHLC class.

> There are other differences I noticed too. For example, the Lag function
> (maybe a different bug?):
>
> # OK
> Lag(minute.data)
>
The result of the above command only has 1 column, though the input
data has 5 columns.  So it's "OK" in the sense that it doesn't throw
an error, but the output is a bit surprising.

> # error
> Lag(minute.data.xts)
>
Looks like a different bug.  The 11x5 matrix is being converted to a
55-element vector, and that vector is used to attempt to create an xts
object with an 11-element index.

> And lag shifts in the opposite direction!
>
Yes, that's the default behavior of stats::lag, and zoo::lag.zoo
follows that convention for consistency.  xts::lag.xts breaks the
convention because we thought it was too surprising/confusing to most
users (even though it's documented in the *Note* section in
?stats::lag).

I recommend you use xts and the lag generic, and avoid using Lag() and
quantmod.OHLC objects.

>> lag(minute.data)[1:4]
>                      Sym.Open  Sym.High    Sym.Low  Sym.Close Sym.Volume
> 2016-04-06 00:00:59 0.4068302 0.9926841 0.01307758 0.44628435       3133
> 2016-04-06 00:01:59 0.6401010 0.9918386 0.03554058 0.60530345       2896
> 2016-04-06 00:02:59 0.9030816 0.9614099 0.04646089 0.42962441       3323
> 2016-04-06 00:03:59 0.4527201 0.9815635 0.02778712 0.05043966       2657
>
>> lag(minute.data.xts)[1:4]
>                      Sym.Open  Sym.High    Sym.Low Sym.Close Sym.Volume
> 2016-04-06 00:00:59        NA        NA         NA NA         NA
> 2016-04-06 00:01:59 0.2655087 0.9919061 0.01339033 0.6620051 3136
> 2016-04-06 00:02:59 0.4068302 0.9926841 0.01307758 0.4462843 3133
> 2016-04-06 00:03:59 0.6401010 0.9918386 0.03554058 0.6053034 2896
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From hd625b at gmail.com  Fri Apr  8 16:55:48 2016
From: hd625b at gmail.com (hd625b)
Date: Fri, 8 Apr 2016 07:55:48 -0700
Subject: [R] Generating Hotelling's T squared statistic with hclust
In-Reply-To: <BLUPR13MB00654AF0416DEB973A6709E0DE910@BLUPR13MB0065.namprd13.prod.outlook.com>
References: <BLUPR13MB00654AF0416DEB973A6709E0DE910@BLUPR13MB0065.namprd13.prod.outlook.com>
Message-ID: <5707C674.3070408@gmail.com>

I believe the package "rattle" can do this.
If not, see page 5 of the PDF below.

https://cran.r-project.org/web/packages/Hotelling/Hotelling.pdf


On 04/08/2016 06:54 AM, Michael wrote:
> I am doing a cluster analysis with hclust.  I want to get hclust to output the Hotelling's T squared statistic for each cluster so I can evaluate is data points should be in a cluster or not.  My research to answer this question has been unsuccessful.  Does anyone know how to get hclust to output the Hotelling's T squared statistic for each cluster?
>
>
> Mike
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mahmoudfarid30 at yahoo.com  Fri Apr  8 15:54:46 2016
From: mahmoudfarid30 at yahoo.com (mahmoudfarid30 at yahoo.com)
Date: Fri, 8 Apr 2016 13:54:46 +0000 (UTC)
Subject: [R] write a function inside the summation in a more condensed form
References: <64637103.134972.1460123686728.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <64637103.134972.1460123686728.JavaMail.yahoo@mail.yahoo.com>

Dear R Experts
that's my original equation

> x=c(2,4)

> Y1=sum(sapply(1:2,function(i){sum(sapply(1:i,function(j){(3^(x[i]+x[j]))}))})) 
> y1 
[1] 7371 
 I want to write the inside function (3^(x[i]+x[j])) in a more condensed form cause this will help me when the multiple summations are more than two 

I've tried the following form

> y2=sum(sapply(1:2,function(i){sum(sapply(1:i,function(j){(3^(sum(sapply(i:j,function(l){x[l]}))))}))})) 
> y2 
[1] 819 


But it didn't work, it gave another solution 
Any help or recommendations


From james.hirschorn at hotmail.com  Fri Apr  8 19:17:16 2016
From: james.hirschorn at hotmail.com (James Hirschorn)
Date: Fri, 8 Apr 2016 13:17:16 -0400
Subject: [R] Is this a bug in quantmod::OpCl?
In-Reply-To: <5707D395.2010307@hotmail.com>
References: <5707D395.2010307@hotmail.com>
Message-ID: <BLU437-SMTP3234D0F293F44668F1F08E9910@phx.gbl>


On 04/06/2016 07:58 PM, Joshua Ulrich wrote:
> On Tue, Apr 5, 2016 at 9:17 PM, James Hirschorn
> <james.hirschorn at hotmail.com> wrote:
>> OpCl works on xts objects but not on quantmod.OHLC objects. Is this a bug?
>>
> Thanks for the minimal, reproducible example.
>
> Looks like a bug.  There's no as.quantmod.OHLC.xts method, so the zoo
> method is dispatched.  Calling Op() or Cl() on this zoo-based object
> results in a vector (since zoo will drop dimensions, like a matrix or
> data.frame), and you can't set column names on a vector.
>
> I'm not sure whether it makes more sense to check for dims in all the
> combination transformations (consisting of combined Op, Hi, Lo, Cl) or
> to create a as.quantmod.OHLC.xts method.
>
> Can you provide some details about your use case?
At this stage, my use case is making some custom indicators. I've not
used quantmod much in the past, but I just assumed that quantmod.OHLC
was the class I should be using with quantmod.

Some details: The starting point was tick data, for example

# n seconds of tick data
n <- 600
tick.data.timestamp <- as.POSIXct("2016-04-06 00:00:00", tz = 'GMT') + 1:n
set.seed(1)
tick.data <- xts(cbind(Price = runif(n, 0, 1),
                        Volume = sample(1:100, replace = T, n)),
                  tick.data.timestamp)

Then aggregating to minute OHLC data as quantmod.OHLC:

minute.data <- as.quantmod.OHLC(to.minutes(tick.data),
c("Open","High","Low","Close","Volume"),
                                 name = 'Sym')

or alternatively as xts:

minute.data.xts <- as.xts(minute.data)

OpCl is naturally useful for indicators, since it shows whether we have
a red or green candlestick. xts is working fine for my indicators for
now, but I don't know if not using quantmod.OHLC will be a problem for
backtesting.

There are other differences I noticed too. For example, the Lag function
(maybe a different bug?):

# OK
Lag(minute.data)

# error
Lag(minute.data.xts)

And lag shifts in the opposite direction!

> lag(minute.data)[1:4]
                      Sym.Open  Sym.High    Sym.Low  Sym.Close Sym.Volume
2016-04-06 00:00:59 0.4068302 0.9926841 0.01307758 0.44628435       3133
2016-04-06 00:01:59 0.6401010 0.9918386 0.03554058 0.60530345       2896
2016-04-06 00:02:59 0.9030816 0.9614099 0.04646089 0.42962441       3323
2016-04-06 00:03:59 0.4527201 0.9815635 0.02778712 0.05043966       2657

> lag(minute.data.xts)[1:4]
                      Sym.Open  Sym.High    Sym.Low Sym.Close Sym.Volume
2016-04-06 00:00:59        NA        NA         NA NA         NA
2016-04-06 00:01:59 0.2655087 0.9919061 0.01339033 0.6620051 3136
2016-04-06 00:02:59 0.4068302 0.9926841 0.01307758 0.4462843 3133
2016-04-06 00:03:59 0.6401010 0.9918386 0.03554058 0.6053034 2896


From dcarlson at tamu.edu  Fri Apr  8 20:13:09 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 8 Apr 2016 18:13:09 +0000
Subject: [R] Generating Hotelling's T squared statistic with hclust
In-Reply-To: <BLUPR13MB00654AF0416DEB973A6709E0DE910@BLUPR13MB0065.namprd13.prod.outlook.com>
References: <BLUPR13MB00654AF0416DEB973A6709E0DE910@BLUPR13MB0065.namprd13.prod.outlook.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72A242@mb02.ads.tamu.edu>

As Burt pointed out, your plan is not advisable (that is putting it diplomatically) and not about R, but we can use R to show you why it is not advisable. What you are doing is inherently circular. You use the data to create groups and then you test the groups against the data you used to create them. The null hypothesis in Hotelling's T is that the groups are completely independent of the data.

> set.seed(42)
> x <- matrix(rnorm(25*4), 25, 4)
> x.hcl <- hclust(dist(x), method="ward.D2")
> plot(x.hcl)

Now you have a dendrogram showing three nice looking clusters that are based on completely random numbers. Unless the pseudo random number function is flawed, there is no structure in these data, but the dendrogram looks plausible. We need 2 groups for Hotelling's T:

> grps <- cutree(x.hcl, 2)
> library(DescTools)
> HotellingsT2Test(x~grps)

        Hotelling's two sample T2-test

data:  x by grps
T.2 = 8.3476, df1 = 4, df2 = 20, p-value = 0.0003947
alternative hypothesis: true location difference is not equal to c(0,0,0,0)

No surprise. There is a significant difference between the groups. That just tells us the hclust() is working properly. It tells us exactly nothing about any structure or pattern in the data (there is none). An equally bad (but surprisingly common) approach is to use linear discriminant analysis. Here we will use 3 groups:

> grps <- cutree(x.hcl, 3)
> library(MASS)
> x.lda <- lda(x, grps)
> x.pre <- predict(x.lda)
> plot(x.lda)
> for (i in 1:3) { segments(centers[i, 2], centers[i, 3], 
+      x.pre$x[grps==i, 1], x.pre$x[grps==i, 2], lty=2)
+ }

Now we have 3 well-separated clusters created from completely random data. Hierarchical clustering always creates clusters. It does not question the data you provide and it does not stop and refuse to continue if there are no clusters in the data.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
Sent: Friday, April 8, 2016 8:55 AM
To: r-help at r-project.org
Subject: [R] Generating Hotelling's T squared statistic with hclust

I am doing a cluster analysis with hclust.  I want to get hclust to output the Hotelling's T squared statistic for each cluster so I can evaluate is data points should be in a cluster or not.  My research to answer this question has been unsuccessful.  Does anyone know how to get hclust to output the Hotelling's T squared statistic for each cluster?


Mike



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murray.efford at otago.ac.nz  Fri Apr  8 20:45:33 2016
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Fri, 8 Apr 2016 18:45:33 +0000
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>
References: <1460064106032.30358@otago.ac.nz>
	<57078E97.1@gmail.com>, <A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>
Message-ID: <1460141125051.21413@otago.ac.nz>

Thanks for these perfectly consistent replies - I didn't understand the purpose of m = sum(w * f/sum(w)) and saw it merely as a weighted average of the fitted values.

My ultimate concern is how to compute an appropriate weighted TSS (or equivalently, MSS) for PRESS-R^2 = 1 - PRESS/TSS = 1 - PRESS/ (MSS + PRESS). Do you think it then makes sense to substitute the vector of leave-one-out fitted values for f here?

m <- sum(w * f/sum(w))
mss <-  sum(w * (f - m)^2)

Murray
________________________________________
From: peter dalgaard <pdalgd at gmail.com>
Sent: Friday, 8 April 2016 11:28 p.m.
To: Duncan Murdoch
Cc: Murray Efford; r-help at r-project.org
Subject: Re: [R] R.squared in summary.lm with weights

On 08 Apr 2016, at 12:57 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 07/04/2016 5:21 PM, Murray Efford wrote:
>> Following some old advice on this list, I have been reading the code for summary.lm to understand the computation of R-squared from a weighted regression. Usually weights in lm are applied to squared residuals, but I see that the weighted mean of the observations is calculated as if the weights are on the original scale:
>>
>> [...]
>>     f <- z$fitted.values
>>     w <- z$weights
>> [...]
>>             m <- sum(w * f/sum(w))
>>             [mss <-]  sum(w * (f - m)^2)
>> [...]
>>
>> This seems inconsistent to me. What am I missing?
>
> I think you are expecting consistency where there needn't be any.  Why do you see an inconsistency here?  Those are different calculations. You get expressions like these if you assume observations have variance sigma^2/w, and you're trying to estimate sigma^2.
>


It's also perfectly consistent that m is the minimizer of mss:

d/dm sum(w*(f-m)^2) = -2 sum(w*(f-m)) = 0 => m = sum(w*f) / sum(w)

However, beware the distiction between inverse variance weights, replication weights, and sampling weights.


> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From Muhammad2.Bilal at live.uwe.ac.uk  Fri Apr  8 20:57:24 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Fri, 8 Apr 2016 18:57:24 +0000
Subject: [R] Generating random data with non-linear correlation between two
 variables
Message-ID: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi All,

I am new to R and don't know how to achieve it.

I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
1. The range of v1 is 500-1500.
2. The mean of v1 is say 1100
3. The range of v2 is 300-950.
4. The mean of v2 is say 400
5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
6. But the trend should be slightly non-linear. i.e., curved line.

Is it possible to automatically generate through functions like rnorm.

Any help will be highly appreciated.

Many Thanks and

Kind Regards

--
Muhammad Bilal
Research Assistant and Doctoral Researcher,
Bristol Enterprise, Research and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


	[[alternative HTML version deleted]]


From Kyra.Uwate at colorado.edu  Fri Apr  8 20:44:47 2016
From: Kyra.Uwate at colorado.edu (Kyra Suzuyo Uwate)
Date: Fri, 8 Apr 2016 12:44:47 -0600
Subject: [R] Rcmdr will not load
Message-ID: <CADRdNy-dFF1a1V8RLS-ofn8xr3ggbBRpUsQWsMm3irsUFyc67g@mail.gmail.com>

Hi,
I use Rcmdr for a lot of data analysis, but within the last month my
computer had just shut down. It took a couple of days to get it up and
running, but then R and Rstudio wouldn't load. I had to reinstall it but
now whenever I try to access Rcmdr I get an error message.

> library(Rcmdr)
Loading required package: splines
Loading required package: RcmdrMisc
Loading required package: car
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
= vI[[j]]) :
  there is no package called ?pbkrtest?
Error: package ?car? could not be loaded

When I use the package manager/installer in the R console and try to load
car it won't load either.

-Kyra

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Apr  8 21:49:35 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Apr 2016 21:49:35 +0200
Subject: [R] Rcmdr will not load
In-Reply-To: <CADRdNy-dFF1a1V8RLS-ofn8xr3ggbBRpUsQWsMm3irsUFyc67g@mail.gmail.com>
References: <CADRdNy-dFF1a1V8RLS-ofn8xr3ggbBRpUsQWsMm3irsUFyc67g@mail.gmail.com>
Message-ID: <3D02344F-1394-453D-AB6C-F8FD53FAFEFE@gmail.com>

Yes, that's annoying. I'm 99% sure that the root cause is that pbkrtest got upgraded and the new version depends on R >= 3.2.3. Since Rcmdr depends on car which imports pbkrtest, you get in trouble if your R is not at least at 3.2.3. The easiest way out is probably to upgrade R.

-pd

> On 08 Apr 2016, at 20:44 , Kyra Suzuyo Uwate <Kyra.Uwate at colorado.edu> wrote:
> 
> Hi,
> I use Rcmdr for a lot of data analysis, but within the last month my
> computer had just shut down. It took a couple of days to get it up and
> running, but then R and Rstudio wouldn't load. I had to reinstall it but
> now whenever I try to access Rcmdr I get an error message.
> 
>> library(Rcmdr)
> Loading required package: splines
> Loading required package: RcmdrMisc
> Loading required package: car
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>  there is no package called ?pbkrtest?
> Error: package ?car? could not be loaded
> 
> When I use the package manager/installer in the R console and try to load
> car it won't load either.
> 
> -Kyra
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From valkremk at gmail.com  Sat Apr  9 04:21:06 2016
From: valkremk at gmail.com (Val)
Date: Fri, 8 Apr 2016 21:21:06 -0500
Subject: [R] assign
Message-ID: <CAJOiR6Zy1Lns3PxR3Wx3OT37yzsee2tfh=W0hGtaeYnrupTJ4g@mail.gmail.com>

Hi all
 I am trying t extract  a variable from a column

      ASk/20005-01-45/90

     Alldatk/25-17-4567/990

I want to assign  a variable to the numbers coming the first"-"

x=01 for the first and
x=17  for teh second

I tried using gsub but did not work

x=gsub("-")

any help?

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sat Apr  9 04:53:35 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 9 Apr 2016 02:53:35 +0000
Subject: [R] assign
In-Reply-To: <CAJOiR6Zy1Lns3PxR3Wx3OT37yzsee2tfh=W0hGtaeYnrupTJ4g@mail.gmail.com>
References: <CAJOiR6Zy1Lns3PxR3Wx3OT37yzsee2tfh=W0hGtaeYnrupTJ4g@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F6A08A@FHSDB2D11-2.csu.mcmaster.ca>

Dear Val,

Your question isn't entirely clear (to me), but this is what I think you want to do:

------------------ snip ----------------

> strings <- c("ASk/20005-01-45/90", "Alldatk/25-17-4567/990")
> location <- regexpr("-[0-9]*", strings)
> x
[1] "01" "17"
> x <- substring(strings, location + 1, location + attr(location, "match.length") - 1)
> as.numeric(x)
[1]  1 17

------------------ snip ----------------

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Val [valkremk at gmail.com]
Sent: April 8, 2016 10:21 PM
To: r-help at R-project.org (r-help at r-project.org)
Subject: [R] assign

Hi all
 I am trying t extract  a variable from a column

      ASk/20005-01-45/90

     Alldatk/25-17-4567/990

I want to assign  a variable to the numbers coming the first"-"

x=01 for the first and
x=17  for teh second

I tried using gsub but did not work

x=gsub("-")

any help?

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Apr  9 05:12:40 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 08 Apr 2016 20:12:40 -0700
Subject: [R] assign
In-Reply-To: <CAJOiR6Zy1Lns3PxR3Wx3OT37yzsee2tfh=W0hGtaeYnrupTJ4g@mail.gmail.com>
References: <CAJOiR6Zy1Lns3PxR3Wx3OT37yzsee2tfh=W0hGtaeYnrupTJ4g@mail.gmail.com>
Message-ID: <A768D0F3-A022-4155-A61D-0218854E021E@dcn.davis.ca.us>

You are not using that function as it was designed to be used.  You should read the help for gsub...

?gsub

And if you don't know what the term "regular expression pattern" that is mentioned there means then you will probably need to study one of the many fine tutorials that are available on the Web on that topic to understand how

gsub( "^.*-([^-]+)-.*$", "\\1", c( "junk-01-more", "stuff-17-" ) )

matches the entire string (^ to $) while capturing (parentheses) one or more non-dash characters ([^-]+) between the first dash and the second dash and substituting that "first capture" in place of the entire string. 

Note that the regular expression only needs one \ before the 1 but the R parser requires you to "escape" that with another \ to get that one \ into memory.

And while you are studying,  be sure to read and heed the R Mailing Lists Posting Guide mentioned in every post on this list,  because you used HTML format which tends to mess up R code examples. 
-- 
Sent from my phone. Please excuse my brevity.

On April 8, 2016 7:21:06 PM PDT, Val <valkremk at gmail.com> wrote:
>Hi all
> I am trying t extract  a variable from a column
>
>      ASk/20005-01-45/90
>
>     Alldatk/25-17-4567/990
>
>I want to assign  a variable to the numbers coming the first"-"
>
>x=01 for the first and
>x=17  for teh second
>
>I tried using gsub but did not work
>
>x=gsub("-")
>
>any help?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Apr  9 05:46:08 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 9 Apr 2016 15:46:08 +1200
Subject: [R] [FORGED] Generating random data with non-linear correlation
 between two variables
In-Reply-To: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <57087B00.7080002@auckland.ac.nz>

On 09/04/16 06:57, Muhammad Bilal wrote:
> Hi All,
>
> I am new to R and don't know how to achieve it.
>
> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
> 1. The range of v1 is 500-1500.
> 2. The mean of v1 is say 1100
> 3. The range of v2 is 300-950.
> 4. The mean of v2 is say 400
> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
> 6. But the trend should be slightly non-linear. i.e., curved line.
>
> Is it possible to automatically generate through functions like rnorm.
>
> Any help will be highly appreciated.

This sounds to me very much like a homework problem.  We don't do 
people's homework for them on this list.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From begemotche at gmail.com  Fri Apr  8 23:18:40 2016
From: begemotche at gmail.com (Maria Ninova)
Date: Fri, 8 Apr 2016 14:18:40 -0700
Subject: [R] sorting of files using system
Message-ID: <57082030.1050009@gmail.com>

Hello, I came across the following oddity when it comes to file order 
using the system command: different system commands return files in a 
different order:
This is a real filenames example:

 > system("ls gw1kb_tables/rpkm_47*", intern=T)
[1] "gw1kb_tables/rpkm_479_Input.tab"
[2] "gw1kb_tables/rpkm_479_IP.tab"

 > system("for file in gw1kb_tables/rpkm_4*; do echo $file;done" )
gw1kb_tables/rpkm_479_IP.tab
gw1kb_tables/rpkm_479_Input.tab

As you see, in the first case, the "Input" comes first, while in the 
second, the IP comes first; I was surprised by this result and not sure 
if it's expected?
I am using R version 3.2.2 (2015-08-14) on Ubuntu 15.04

Thank you in advance,

Maria


From apa at stowers.org  Sat Apr  9 00:24:31 2016
From: apa at stowers.org (Paulson, Ariel)
Date: Fri, 8 Apr 2016 22:24:31 +0000
Subject: [R] identical() versus sapply()
Message-ID: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>

Sorry if this has been answered elsewhere, but I can't find any discussion of it.

Wondering why the following situation occurs (duplicated on 3.2.2 CentOS6 and 3.0.1 Win2k, so I don't think it is a bug):

> sapply(1, identical, 1)
[1] TRUE

> sapply(1:2, identical, 1)
[1] FALSE FALSE

> sapply(1:2, function(i) identical(as.numeric(i),1) )
[1]  TRUE FALSE

> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
[1] FALSE FALSE

I have been unable to find anything different about the versions of "1" that identical() is not finding identical.

Thanks,
Ariel



	[[alternative HTML version deleted]]


From hd625b at gmail.com  Sat Apr  9 00:43:56 2016
From: hd625b at gmail.com (hd625b)
Date: Fri, 8 Apr 2016 15:43:56 -0700
Subject: [R] Generating random data with non-linear correlation between
 two variables
In-Reply-To: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <5708342C.9010909@gmail.com>

Hello,


I changed the last 3 lines from v1 and v2 to myData$v1 and myData$v2.

Creating the vectors in not a problem.
Where you will run into issues is when you create the data.frame.
The length of v1 is 1001 and the length of v2 is 651.
The warning message below is telling us that the lengths of v1 and v2 
are different.
"Shorter vectors are recycled as often as need be until they match the 
length of the longest vector."

See section 2.2 of this document for more on recycling.
https://cran.r-project.org/doc/manuals/R-intro.pdf

    v1 <- sort(rnorm(500:1500, mean = 1100, sd = 1), decreasing = F)
    v2 <- sort(rnorm(300:950, mean = 400, sd = 1), decreasing = F)
    length(v1)
    length(v2)
    myData <- data.frame(cbind(v1, v2))

         Warning message:
          In cbind(v1, v2) :
         number of rows of result is not a multiple of vector length (arg 2)

    plot(myData$v1, myData$v2, type = "l")

    cor(myData$v1, myData$v2, method = "pearson")

    plot(myData, type = 'l')

Michael Long


On 04/08/2016 11:57 AM, Muhammad Bilal wrote:
> Hi All,
>
> I am new to R and don't know how to achieve it.
>
> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
> 1. The range of v1 is 500-1500.
> 2. The mean of v1 is say 1100
> 3. The range of v2 is 300-950.
> 4. The mean of v2 is say 400
> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
> 6. But the trend should be slightly non-linear. i.e., curved line.
>
> Is it possible to automatically generate through functions like rnorm.
>
> Any help will be highly appreciated.
>
> Many Thanks and
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Assistant and Doctoral Researcher,
> Bristol Enterprise, Research and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Apr  9 06:18:16 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 08 Apr 2016 21:18:16 -0700
Subject: [R] sorting of files using system
In-Reply-To: <57082030.1050009@gmail.com>
References: <57082030.1050009@gmail.com>
Message-ID: <A7975C01-8335-4F53-A150-ABFEE3D4182E@dcn.davis.ca.us>

Wrong list. This is not the Ubuntu shell support mailing list.  The fact that you are using R to get at the operating system command line doesn't make this an R question. 
-- 
Sent from my phone. Please excuse my brevity.

On April 8, 2016 2:18:40 PM PDT, Maria Ninova <begemotche at gmail.com> wrote:
>Hello, I came across the following oddity when it comes to file order 
>using the system command: different system commands return files in a 
>different order:
>This is a real filenames example:
>
> > system("ls gw1kb_tables/rpkm_47*", intern=T)
>[1] "gw1kb_tables/rpkm_479_Input.tab"
>[2] "gw1kb_tables/rpkm_479_IP.tab"
>
> > system("for file in gw1kb_tables/rpkm_4*; do echo $file;done" )
>gw1kb_tables/rpkm_479_IP.tab
>gw1kb_tables/rpkm_479_Input.tab
>
>As you see, in the first case, the "Input" comes first, while in the 
>second, the IP comes first; I was surprised by this result and not sure
>
>if it's expected?
>I am using R version 3.2.2 (2015-08-14) on Ubuntu 15.04
>
>Thank you in advance,
>
>Maria
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Apr  9 06:24:08 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 08 Apr 2016 21:24:08 -0700
Subject: [R] identical() versus sapply()
In-Reply-To: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
Message-ID: <3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>

I highly recommend making friends with the str function. Try

str( 1 )
str( 1:2 )

for the clue you need, and then

sapply( 1:2, identical, 1L )

-- 
Sent from my phone. Please excuse my brevity.

On April 8, 2016 3:24:31 PM PDT, "Paulson, Ariel" <apa at stowers.org> wrote:
>Sorry if this has been answered elsewhere, but I can't find any
>discussion of it.
>
>Wondering why the following situation occurs (duplicated on 3.2.2
>CentOS6 and 3.0.1 Win2k, so I don't think it is a bug):
>
>> sapply(1, identical, 1)
>[1] TRUE
>
>> sapply(1:2, identical, 1)
>[1] FALSE FALSE
>
>> sapply(1:2, function(i) identical(as.numeric(i),1) )
>[1]  TRUE FALSE
>
>> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
>[1] FALSE FALSE
>
>I have been unable to find anything different about the versions of "1"
>that identical() is not finding identical.
>
>Thanks,
>Ariel
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Sat Apr  9 11:44:32 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Sat, 9 Apr 2016 12:44:32 +0300
Subject: [R] sorting of files using system
In-Reply-To: <57082030.1050009@gmail.com>
References: <57082030.1050009@gmail.com>
Message-ID: <CAJ=0CtAJ1=uwBPNSK5fW48g_uKs=iYXP6Egp3g1TYk87PfXr_g@mail.gmail.com>

I suspect it is a problem related to locales: R and the base Ubuntu might
be using different locales, hence the source of the different sorting.
Can't say if this is the problem in your case, but it might be.
Adrian

On Sat, Apr 9, 2016 at 12:18 AM, Maria Ninova <begemotche at gmail.com> wrote:

> Hello, I came across the following oddity when it comes to file order
> using the system command: different system commands return files in a
> different order:
> This is a real filenames example:
>
> > system("ls gw1kb_tables/rpkm_47*", intern=T)
> [1] "gw1kb_tables/rpkm_479_Input.tab"
> [2] "gw1kb_tables/rpkm_479_IP.tab"
>
> > system("for file in gw1kb_tables/rpkm_4*; do echo $file;done" )
> gw1kb_tables/rpkm_479_IP.tab
> gw1kb_tables/rpkm_479_Input.tab
>
> As you see, in the first case, the "Input" comes first, while in the
> second, the IP comes first; I was surprised by this result and not sure if
> it's expected?
> I am using R version 3.2.2 (2015-08-14) on Ubuntu 15.04
>
> Thank you in advance,
>
> Maria
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Sat Apr  9 11:57:13 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sat, 9 Apr 2016 09:57:13 +0000
Subject: [R] [FORGED] Generating random data with non-linear correlation
 between two variables
In-Reply-To: <57087B00.7080002@auckland.ac.nz>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<57087B00.7080002@auckland.ac.nz>
Message-ID: <DB5PR07MB110985EA5F88847C00D15061DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi Rolf Turner,

Firstly, I really appreciate your help.

Is it possible to give the number of entries I need so that rnorm function generates only that number of rows?

Also is it possible to generate the points with spread randomly such that they don't overlap each other too much.

Many Thanks and 

Kind Regards
--
Muhammad Bilal
Research Assistant and PhD Student,
Bristol Enterprise, Research and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk


________________________________________
From: Rolf Turner <r.turner at auckland.ac.nz>
Sent: 09 April 2016 04:46
To: Muhammad Bilal
Cc: r-help at r-project.org
Subject: Re: [FORGED] [R] Generating random data with non-linear correlation between two variables

On 09/04/16 06:57, Muhammad Bilal wrote:
> Hi All,
>
> I am new to R and don't know how to achieve it.
>
> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
> 1. The range of v1 is 500-1500.
> 2. The mean of v1 is say 1100
> 3. The range of v2 is 300-950.
> 4. The mean of v2 is say 400
> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
> 6. But the trend should be slightly non-linear. i.e., curved line.
>
> Is it possible to automatically generate through functions like rnorm.
>
> Any help will be highly appreciated.

This sounds to me very much like a homework problem.  We don't do
people's homework for them on this list.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From Muhammad2.Bilal at live.uwe.ac.uk  Sat Apr  9 12:08:02 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sat, 9 Apr 2016 10:08:02 +0000
Subject: [R] [FORGED] Generating random data with non-linear correlation
 between two variables
In-Reply-To: <57087B00.7080002@auckland.ac.nz>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<57087B00.7080002@auckland.ac.nz>
Message-ID: <DB5PR07MB1109E44B77D500AA79E3C319DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>

No its not. I am doing all these experiments for my own learning purpose. I am Oracle SQL & PLSQL programmer and  I can do these things with Oracle analytical functions.

However at present I am keen to learn R, with no other interest right now.

Thanks
--
Muhammad Bilal
Research Assistant and PhD Student,
Bristol Enterprise, Research and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk


________________________________________
From: Rolf Turner <r.turner at auckland.ac.nz>
Sent: 09 April 2016 04:46
To: Muhammad Bilal
Cc: r-help at r-project.org
Subject: Re: [FORGED] [R] Generating random data with non-linear correlation between two variables

On 09/04/16 06:57, Muhammad Bilal wrote:
> Hi All,
>
> I am new to R and don't know how to achieve it.
>
> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
> 1. The range of v1 is 500-1500.
> 2. The mean of v1 is say 1100
> 3. The range of v2 is 300-950.
> 4. The mean of v2 is say 400
> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
> 6. But the trend should be slightly non-linear. i.e., curved line.
>
> Is it possible to automatically generate through functions like rnorm.
>
> Any help will be highly appreciated.

This sounds to me very much like a homework problem.  We don't do
people's homework for them on this list.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

From drjimlemon at gmail.com  Sat Apr  9 12:20:05 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 9 Apr 2016 20:20:05 +1000
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
Message-ID: <CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>

Hi Miluji,
Try this:

arrows(-100,-140,100,-140,code=3)

Jim


On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
> I am trying to draw maps for the world using:
>
> library(rworldmap)
> library(maptools)
> library(RColorBrewer)
>
>
> tmp2<- dput(head(pece,10))
> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257, 2.15937495231628
> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
> 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
> c(13.4375638961792,
> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
> 2016 17:43", .Names = c("iso3",
> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
> rd_in_va"
> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
>     c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
>     c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
>     "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
>     ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
>     "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
>     ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
>     ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
>     "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
>     "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
>     "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
>     ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
>     "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
>     ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> "+1.0000000000000X+000"
>     ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
>     c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
> n <- n[-which(row.names(n)=='Antarctica'),]
>
> # EPS
> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
>
> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> Score",colourPalette=colourPalette,
>                       catMethod="fixedWidth", missingCountryCol = "white",
> addLegend=FALSE)
> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
>
> Instead of adding numeric based legend, I would like to add a two-headed
> arrow with some text. I would be grateful for any help. Thank you!
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sat Apr  9 12:27:04 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 9 Apr 2016 22:27:04 +1200
Subject: [R] [FORGED] Re:  identical() versus sapply()
In-Reply-To: <3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
Message-ID: <5708D8F8.3020701@auckland.ac.nz>

On 09/04/16 16:24, Jeff Newmiller wrote:
> I highly recommend making friends with the str function. Try
>
> str( 1 )
> str( 1:2 )

Interesting.  But to me counter-intuitive.  Since R makes no distinction 
between scalars and vectors of length 1 (or more accurately I think, 
since in R there is *no such thing as a scalar*, only a vector of length 
1) I don't see why "1" should be treated in a manner that is 
categorically different from the way in which "1:2" is treated.

Can you, or someone else with deep insight into R and its rationale, 
explain the basis for this difference in treatment?

> for the clue you need, and then
>
> sapply( 1:2, identical, 1L )

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drf at vims.edu  Sat Apr  9 12:48:48 2016
From: drf at vims.edu (David R Forrest)
Date: Sat, 9 Apr 2016 10:48:48 +0000
Subject: [R] [FORGED] Generating random data with non-linear correlation
 between two variables
In-Reply-To: <DB5PR07MB1109E44B77D500AA79E3C319DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<57087B00.7080002@auckland.ac.nz>,
	<DB5PR07MB1109E44B77D500AA79E3C319DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <FD006F51-4DB6-4D68-A9DD-28AA973F6CD9@vims.edu>

Please specify your goal in the oracle/psql analytical functions you know or specify what you mean by nonlinear correlation 

Sent from my iPhone

> On Apr 9, 2016, at 6:09 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
> 
> No its not. I am doing all these experiments for my own learning purpose. I am Oracle SQL & PLSQL programmer and  I can do these things with Oracle analytical functions.
> 
> However at present I am keen to learn R, with no other interest right now.
> 
> Thanks
> --
> Muhammad Bilal
> Research Assistant and PhD Student,
> Bristol Enterprise, Research and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
> 
> muhammad2.bilal at live.uwe.ac.uk
> 
> 
> ________________________________________
> From: Rolf Turner <r.turner at auckland.ac.nz>
> Sent: 09 April 2016 04:46
> To: Muhammad Bilal
> Cc: r-help at r-project.org
> Subject: Re: [FORGED] [R] Generating random data with non-linear correlation between two variables
> 
>> On 09/04/16 06:57, Muhammad Bilal wrote:
>> Hi All,
>> 
>> I am new to R and don't know how to achieve it.
>> 
>> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
>> 1. The range of v1 is 500-1500.
>> 2. The mean of v1 is say 1100
>> 3. The range of v2 is 300-950.
>> 4. The mean of v2 is say 400
>> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
>> 6. But the trend should be slightly non-linear. i.e., curved line.
>> 
>> Is it possible to automatically generate through functions like rnorm.
>> 
>> Any help will be highly appreciated.
> 
> This sounds to me very much like a homework problem.  We don't do
> people's homework for them on this list.
> 
> cheers,
> 
> Rolf Turner
> 
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Muhammad2.Bilal at live.uwe.ac.uk  Sat Apr  9 13:09:17 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sat, 9 Apr 2016 11:09:17 +0000
Subject: [R] [FORGED] Generating random data with non-linear correlation
 between two variables
In-Reply-To: <FD006F51-4DB6-4D68-A9DD-28AA973F6CD9@vims.edu>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<57087B00.7080002@auckland.ac.nz>,
	<DB5PR07MB1109E44B77D500AA79E3C319DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<FD006F51-4DB6-4D68-A9DD-28AA973F6CD9@vims.edu>
Message-ID: <DB5PR07MB1109308F611A8395DE5A1A8ADB920@DB5PR07MB1109.eurprd07.prod.outlook.com>

The goal is to test a developed model against two sets of hypothetical data, where the relationship between on data set is linear whereas non-linear (e.g., polynomial) with another. However, the distributions of the v1 and v2 should not be other than normal or slightly positively skewed or slightly negatively skewed. 

In Oracle, random data is generated with packaged function dbms_random.value(lowerbound, upperbound), which can be called from SQL query with where clause (level <= no_of_rows) for the number of rows you want.

After the rows are generated, we can write custom functions to spread the data points along the y-axis, so that they wouldn't overlap. 

I hope this may clear the use case further.

Many Thanks and 

Kind Regards
--
Muhammad Bilal


Research Assistant and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY 


muhammad2.bilal at live.uwe.ac.uk

    
________________________________________
From: David R Forrest <drf at vims.edu>
Sent: 09 April 2016 11:48
To: Muhammad Bilal
Cc: Rolf Turner; r-help at r-project.org
Subject: Re: [R] [FORGED] Generating random data with non-linear correlation between two variables

Please specify your goal in the oracle/psql analytical functions you know or specify what you mean by nonlinear correlation

Sent from my iPhone

> On Apr 9, 2016, at 6:09 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>
> No its not. I am doing all these experiments for my own learning purpose. I am Oracle SQL & PLSQL programmer and  I can do these things with Oracle analytical functions.
>
> However at present I am keen to learn R, with no other interest right now.
>
> Thanks
> --
> Muhammad Bilal
> Research Assistant and PhD Student,
> Bristol Enterprise, Research and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk
>
>
> ________________________________________
> From: Rolf Turner <r.turner at auckland.ac.nz>
> Sent: 09 April 2016 04:46
> To: Muhammad Bilal
> Cc: r-help at r-project.org
> Subject: Re: [FORGED] [R] Generating random data with non-linear correlation between two variables
>
>> On 09/04/16 06:57, Muhammad Bilal wrote:
>> Hi All,
>>
>> I am new to R and don't know how to achieve it.
>>
>> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
>> 1. The range of v1 is 500-1500.
>> 2. The mean of v1 is say 1100
>> 3. The range of v2 is 300-950.
>> 4. The mean of v2 is say 400
>> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
>> 6. But the trend should be slightly non-linear. i.e., curved line.
>>
>> Is it possible to automatically generate through functions like rnorm.
>>
>> Any help will be highly appreciated.
>
> This sounds to me very much like a homework problem.  We don't do
> people's homework for them on this list.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From murdoch.duncan at gmail.com  Sat Apr  9 13:40:41 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 9 Apr 2016 07:40:41 -0400
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <5708D8F8.3020701@auckland.ac.nz>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
Message-ID: <5708EA39.9070005@gmail.com>

On 09/04/2016 6:27 AM, Rolf Turner wrote:
> On 09/04/16 16:24, Jeff Newmiller wrote:
>> I highly recommend making friends with the str function. Try
>>
>> str( 1 )
>> str( 1:2 )
>
> Interesting.  But to me counter-intuitive.  Since R makes no distinction
> between scalars and vectors of length 1 (or more accurately I think,
> since in R there is *no such thing as a scalar*, only a vector of length
> 1) I don't see why "1" should be treated in a manner that is
> categorically different from the way in which "1:2" is treated.
>
> Can you, or someone else with deep insight into R and its rationale,
> explain the basis for this difference in treatment?

It's not the fact that one is a vector, it's just that the : function 
returns an integer result when given whole number arguments.  The 
literal 1 is stored in floating point, the result of 1:2 is integer.

I think the rationale is that sequences of whole numbers are often used 
as integers (e.g. in "for (i in 1:2)", whereas constants are often used 
in floating point expressions, so this reduces the number of conversions 
that are needed.  If you really mean your 1 to be stored as an integer, 
write it as 1L.  If you want it as floating point, write it as 1.

Duncan Murdoch


From Muhammad2.Bilal at live.uwe.ac.uk  Sat Apr  9 14:06:53 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sat, 9 Apr 2016 12:06:53 +0000
Subject: [R] [FORGED] Generating random data with non-linear correlation
 between two variables
In-Reply-To: <FD006F51-4DB6-4D68-A9DD-28AA973F6CD9@vims.edu>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<57087B00.7080002@auckland.ac.nz>,
	<DB5PR07MB1109E44B77D500AA79E3C319DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<FD006F51-4DB6-4D68-A9DD-28AA973F6CD9@vims.edu>
Message-ID: <DB5PR07MB110995F1FA165FA05DE0F92EDB920@DB5PR07MB1109.eurprd07.prod.outlook.com>

By non linear correlation I mean that the trend or relationship between two variables is not a straight line. It is slightly curved like the one shared in the first replies.



--
Muhammad Bilal


Research Assistant and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY 


muhammad2.bilal at live.uwe.ac.uk

    
________________________________________
From: David R Forrest <drf at vims.edu>
Sent: 09 April 2016 11:48
To: Muhammad Bilal
Cc: Rolf Turner; r-help at r-project.org
Subject: Re: [R] [FORGED] Generating random data with non-linear correlation between two variables

Please specify your goal in the oracle/psql analytical functions you know or specify what you mean by nonlinear correlation

Sent from my iPhone

> On Apr 9, 2016, at 6:09 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>
> No its not. I am doing all these experiments for my own learning purpose. I am Oracle SQL & PLSQL programmer and  I can do these things with Oracle analytical functions.
>
> However at present I am keen to learn R, with no other interest right now.
>
> Thanks
> --
> Muhammad Bilal
> Research Assistant and PhD Student,
> Bristol Enterprise, Research and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk
>
>
> ________________________________________
> From: Rolf Turner <r.turner at auckland.ac.nz>
> Sent: 09 April 2016 04:46
> To: Muhammad Bilal
> Cc: r-help at r-project.org
> Subject: Re: [FORGED] [R] Generating random data with non-linear correlation between two variables
>
>> On 09/04/16 06:57, Muhammad Bilal wrote:
>> Hi All,
>>
>> I am new to R and don't know how to achieve it.
>>
>> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
>> 1. The range of v1 is 500-1500.
>> 2. The mean of v1 is say 1100
>> 3. The range of v2 is 300-950.
>> 4. The mean of v2 is say 400
>> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
>> 6. But the trend should be slightly non-linear. i.e., curved line.
>>
>> Is it possible to automatically generate through functions like rnorm.
>>
>> Any help will be highly appreciated.
>
> This sounds to me very much like a homework problem.  We don't do
> people's homework for them on this list.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From joseclaudio.faria at gmail.com  Sat Apr  9 14:14:13 2016
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Sat, 9 Apr 2016 09:14:13 -0300
Subject: [R] Arguments to utils:::menuInstallPkgs
Message-ID: <CAN+Emd86Z-hXAG=ZHkoSB96C8qx0RVr38mDmva=MSR30p_2Puw@mail.gmail.com>

Dears,

Is it possible (in any viable way) to pass arguments to the base function
(install.packages I think) using the utils:::menu?

For example:

> utils:::menuInstallPkgs(loc=.libPaths()[2])

> utils:::menuInstallLocal(loc=.libPaths()[2])

Thanks,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)99100.7351 - TIM
55(73)98817.6159 - OI
55(73)98129.9942 - CLARO
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Apr  9 14:37:31 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 9 Apr 2016 08:37:31 -0400
Subject: [R] Arguments to utils:::menuInstallPkgs
In-Reply-To: <CAN+Emd86Z-hXAG=ZHkoSB96C8qx0RVr38mDmva=MSR30p_2Puw@mail.gmail.com>
References: <CAN+Emd86Z-hXAG=ZHkoSB96C8qx0RVr38mDmva=MSR30p_2Puw@mail.gmail.com>
Message-ID: <5708F78B.1030905@gmail.com>

On 09/04/2016 8:14 AM, Jose Claudio Faria wrote:
> Dears,
>
> Is it possible (in any viable way) to pass arguments to the base function
> (install.packages I think) using the utils:::menu?

No, but why not just call install.packages directly?  (If you are using 
Rgui in Windows, you can add menu items using winMenuAddItem).

Duncan Murdoch
> For example:
>
> > utils:::menuInstallPkgs(loc=.libPaths()[2])
>
> > utils:::menuInstallLocal(loc=.libPaths()[2])
>
> Thanks,
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
> Jose Claudio Faria
> Estatistica
> UESC/DCET/Brasil
> joseclaudio.faria at gmail.com
> Telefones:
> 55(73)3680.5545 - UESC
> 55(73)99966.9100 - VIVO
> 55(73)99100.7351 - TIM
> 55(73)98817.6159 - OI
> 55(73)98129.9942 - CLARO
> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Apr  9 14:42:13 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 9 Apr 2016 14:42:13 +0200
Subject: [R] [FORGED] Generating random data with non-linear correlation
	between two variables
In-Reply-To: <DB5PR07MB1109308F611A8395DE5A1A8ADB920@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<57087B00.7080002@auckland.ac.nz>
	<DB5PR07MB1109E44B77D500AA79E3C319DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<FD006F51-4DB6-4D68-A9DD-28AA973F6CD9@vims.edu>
	<DB5PR07MB1109308F611A8395DE5A1A8ADB920@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <FD995F14-18E5-417E-A22B-CB16723E318B@gmail.com>


> On 09 Apr 2016, at 13:09 , Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
> 
> The goal is to test a developed model against two sets of hypothetical data, where the relationship between on data set is linear whereas non-linear (e.g., polynomial) with another. However, the distributions of the v1 and v2 should not be other than normal or slightly positively skewed or slightly negatively skewed. 
> 
> In Oracle, random data is generated with packaged function dbms_random.value(lowerbound, upperbound), which can be called from SQL query with where clause (level <= no_of_rows) for the number of rows you want.
> 
> After the rows are generated, we can write custom functions to spread the data points along the y-axis, so that they wouldn't overlap. 
> 
> I hope this may clear the use case further.

Not really...

You can do lots of stuff with random number generation in R, but it is not clear to what extent we should take your requirements seriously. E.g., you say you want the range of v1 to be 500-1500 and the mean to be 1100. It is easy enough to generate uniform random numbers between 500 and 1500: 

> v1 <- runif(1000,500,1500)

but the theoretical mean of v1 is 1000, not 1100:

> mean(v1)
[1] 985.7375

To increase the mean, on could play around with scaled beta distributions, e.g.

> v1 <- 500 + 1000 * rbeta(1000, 1.2, 0.8)
> mean(v1)
[1] 1093.685

but it is not clear how you ever passed the same requirement to Oracle. 

Next, you wanted v2 with the following requirements

v2 between 300 and 850
mean(v2) == 400
v2 nonlinearly related to v1

If we postulate a relation where the conditional expectation is, like, 
E(v2 | v1) = a0 + a1 * v1 - a2 * v1^2, and v1 is as above, then the constants can be twiddled to satisfy E(v2) = 400. Then to generate random output with that mean and range, one could again use a scaled beta distribution. 

It is, however, not at all clear that this is in fact the kind of solution that you want....

-pd

> 
> Many Thanks and 
> 
> Kind Regards
> --
> Muhammad Bilal
> 
> 
> Research Assistant and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY 
> 
> 
> muhammad2.bilal at live.uwe.ac.uk
> 
> 
> ________________________________________
> From: David R Forrest <drf at vims.edu>
> Sent: 09 April 2016 11:48
> To: Muhammad Bilal
> Cc: Rolf Turner; r-help at r-project.org
> Subject: Re: [R] [FORGED] Generating random data with non-linear correlation between two variables
> 
> Please specify your goal in the oracle/psql analytical functions you know or specify what you mean by nonlinear correlation
> 
> Sent from my iPhone
> 
>> On Apr 9, 2016, at 6:09 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>> 
>> No its not. I am doing all these experiments for my own learning purpose. I am Oracle SQL & PLSQL programmer and  I can do these things with Oracle analytical functions.
>> 
>> However at present I am keen to learn R, with no other interest right now.
>> 
>> Thanks
>> --
>> Muhammad Bilal
>> Research Assistant and PhD Student,
>> Bristol Enterprise, Research and Innovation Centre (BERIC),
>> University of the West of England (UWE),
>> Frenchay Campus,
>> Bristol,
>> BS16 1QY
>> 
>> muhammad2.bilal at live.uwe.ac.uk
>> 
>> 
>> ________________________________________
>> From: Rolf Turner <r.turner at auckland.ac.nz>
>> Sent: 09 April 2016 04:46
>> To: Muhammad Bilal
>> Cc: r-help at r-project.org
>> Subject: Re: [FORGED] [R] Generating random data with non-linear correlation between two variables
>> 
>>> On 09/04/16 06:57, Muhammad Bilal wrote:
>>> Hi All,
>>> 
>>> I am new to R and don't know how to achieve it.
>>> 
>>> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
>>> 1. The range of v1 is 500-1500.
>>> 2. The mean of v1 is say 1100
>>> 3. The range of v2 is 300-950.
>>> 4. The mean of v2 is say 400
>>> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
>>> 6. But the trend should be slightly non-linear. i.e., curved line.
>>> 
>>> Is it possible to automatically generate through functions like rnorm.
>>> 
>>> Any help will be highly appreciated.
>> 
>> This sounds to me very much like a homework problem.  We don't do
>> people's homework for them on this list.
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Muhammad2.Bilal at live.uwe.ac.uk  Sat Apr  9 16:01:37 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Sat, 9 Apr 2016 14:01:37 +0000
Subject: [R] [FORGED] Generating random data with non-linear correlation
 between two variables
In-Reply-To: <FD995F14-18E5-417E-A22B-CB16723E318B@gmail.com>
References: <DB5PR07MB1109B0CC95C40D9587067A89DB910@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<57087B00.7080002@auckland.ac.nz>
	<DB5PR07MB1109E44B77D500AA79E3C319DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>
	<FD006F51-4DB6-4D68-A9DD-28AA973F6CD9@vims.edu>
	<DB5PR07MB1109308F611A8395DE5A1A8ADB920@DB5PR07MB1109.eurprd07.prod.outlook.com>,
	<FD995F14-18E5-417E-A22B-CB16723E318B@gmail.com>
Message-ID: <DB5PR07MB11095DA75885CB1746F80843DB920@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi Peter,

Many thanks for the response.

This is exactly what is wanted. I can now use this example to create data for my own purpose.

Thanks for everybody who contributed.

Warmest Regards,
--
Muhammad Bilal


Research Assistant and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY 


muhammad2.bilal at live.uwe.ac.uk

    
________________________________________
From: peter dalgaard <pdalgd at gmail.com>
Sent: 09 April 2016 13:42
To: Muhammad Bilal
Cc: David R Forrest; r-help at r-project.org
Subject: Re: [R] [FORGED] Generating random data with non-linear correlation between two variables

> On 09 Apr 2016, at 13:09 , Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>
> The goal is to test a developed model against two sets of hypothetical data, where the relationship between on data set is linear whereas non-linear (e.g., polynomial) with another. However, the distributions of the v1 and v2 should not be other than normal or slightly positively skewed or slightly negatively skewed.
>
> In Oracle, random data is generated with packaged function dbms_random.value(lowerbound, upperbound), which can be called from SQL query with where clause (level <= no_of_rows) for the number of rows you want.
>
> After the rows are generated, we can write custom functions to spread the data points along the y-axis, so that they wouldn't overlap.
>
> I hope this may clear the use case further.

Not really...

You can do lots of stuff with random number generation in R, but it is not clear to what extent we should take your requirements seriously. E.g., you say you want the range of v1 to be 500-1500 and the mean to be 1100. It is easy enough to generate uniform random numbers between 500 and 1500:

> v1 <- runif(1000,500,1500)

but the theoretical mean of v1 is 1000, not 1100:

> mean(v1)
[1] 985.7375

To increase the mean, on could play around with scaled beta distributions, e.g.

> v1 <- 500 + 1000 * rbeta(1000, 1.2, 0.8)
> mean(v1)
[1] 1093.685

but it is not clear how you ever passed the same requirement to Oracle.

Next, you wanted v2 with the following requirements

v2 between 300 and 850
mean(v2) == 400
v2 nonlinearly related to v1

If we postulate a relation where the conditional expectation is, like,
E(v2 | v1) = a0 + a1 * v1 - a2 * v1^2, and v1 is as above, then the constants can be twiddled to satisfy E(v2) = 400. Then to generate random output with that mean and range, one could again use a scaled beta distribution.

It is, however, not at all clear that this is in fact the kind of solution that you want....

-pd

>
> Many Thanks and
>
> Kind Regards
> --
> Muhammad Bilal
>
>
> Research Assistant and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
>
> muhammad2.bilal at live.uwe.ac.uk
>
>
> ________________________________________
> From: David R Forrest <drf at vims.edu>
> Sent: 09 April 2016 11:48
> To: Muhammad Bilal
> Cc: Rolf Turner; r-help at r-project.org
> Subject: Re: [R] [FORGED] Generating random data with non-linear correlation between two variables
>
> Please specify your goal in the oracle/psql analytical functions you know or specify what you mean by nonlinear correlation
>
> Sent from my iPhone
>
>> On Apr 9, 2016, at 6:09 AM, Muhammad Bilal <Muhammad2.Bilal at live.uwe.ac.uk> wrote:
>>
>> No its not. I am doing all these experiments for my own learning purpose. I am Oracle SQL & PLSQL programmer and  I can do these things with Oracle analytical functions.
>>
>> However at present I am keen to learn R, with no other interest right now.
>>
>> Thanks
>> --
>> Muhammad Bilal
>> Research Assistant and PhD Student,
>> Bristol Enterprise, Research and Innovation Centre (BERIC),
>> University of the West of England (UWE),
>> Frenchay Campus,
>> Bristol,
>> BS16 1QY
>>
>> muhammad2.bilal at live.uwe.ac.uk
>>
>>
>> ________________________________________
>> From: Rolf Turner <r.turner at auckland.ac.nz>
>> Sent: 09 April 2016 04:46
>> To: Muhammad Bilal
>> Cc: r-help at r-project.org
>> Subject: Re: [FORGED] [R] Generating random data with non-linear correlation between two variables
>>
>>> On 09/04/16 06:57, Muhammad Bilal wrote:
>>> Hi All,
>>>
>>> I am new to R and don't know how to achieve it.
>>>
>>> I am interested in generating a hypothetical dataframe that is consisted of say two variables named v1 and v2, based on the following constraints:
>>> 1. The range of v1 is 500-1500.
>>> 2. The mean of v1 is say 1100
>>> 3. The range of v2 is 300-950.
>>> 4. The mean of v2 is say 400
>>> 5. There exists a positive trend between these two variables, meaning that as v1 increases, v2 be also increase.
>>> 6. But the trend should be slightly non-linear. i.e., curved line.
>>>
>>> Is it possible to automatically generate through functions like rnorm.
>>>
>>> Any help will be highly appreciated.
>>
>> This sounds to me very much like a homework problem.  We don't do
>> people's homework for them on this list.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From milujisb at gmail.com  Sat Apr  9 17:13:54 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sat, 9 Apr 2016 17:13:54 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
Message-ID: <CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>

Forgot to copy the list

Dear Jim,

Thank you for your reply. I must be doing something wrong, If this is my
command to plot a map of Europe:

eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
Score - Europe",colourPalette=colourPalette,
                             catMethod="fixedWidth", missingCountryCol =
"white", mapRegion="Europe", addLegend=FALSE)

The following command does not seem to add the arrow. What am I doing wrong?

do.call(addMapLegend, c(eps_europe, legendLabels="none",
arrows(-100,-140,100,-140,code=3)))

Thank you again. I really appreciate it.

Sincerely,

Milu

On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Miluji,
> Try this:
>
> arrows(-100,-140,100,-140,code=3)
>
> Jim
>
>
> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
> > I am trying to draw maps for the world using:
> >
> > library(rworldmap)
> > library(maptools)
> > library(RColorBrewer)
> >
> >
> > tmp2<- dput(head(pece,10))
> > structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> > "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> > 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> > NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> 2.15937495231628
> > ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
> > 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
> > 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
> > c(13.4375638961792,
> > 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> > 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
> > ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
> > 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> > 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
> > 2016 17:43", .Names = c("iso3",
> > "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
> > "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> > 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
> > "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
> > rd_in_va"
> > ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> >     c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> >     c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
> >     "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> >     ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
> >     "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> >     ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> >     ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> >     "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
> >     "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> >     "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
> >     ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> >     "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> >     ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> > "+1.0000000000000X+000"
> >     ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> >     c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> > "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> > n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
> > n <- n[-which(row.names(n)=='Antarctica'),]
> >
> > # EPS
> > colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> >
> > eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> > Score",colourPalette=colourPalette,
> >                       catMethod="fixedWidth", missingCountryCol =
> "white",
> > addLegend=FALSE)
> > do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
> >
> > Instead of adding numeric based legend, I would like to add a two-headed
> > arrow with some text. I would be grateful for any help. Thank you!
> >
> > Sincerely,
> >
> > Milu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Sat Apr  9 18:07:18 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 9 Apr 2016 18:07:18 +0200
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <1460141125051.21413@otago.ac.nz>
References: <1460064106032.30358@otago.ac.nz> <57078E97.1@gmail.com>
	<A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>
	<1460141125051.21413@otago.ac.nz>
Message-ID: <22281.10422.170427.867866@stat.math.ethz.ch>

>>>>> Murray Efford <murray.efford at otago.ac.nz>
>>>>>     on Fri, 8 Apr 2016 18:45:33 +0000 writes:

    > Thanks for these perfectly consistent replies - I didn't
    > understand the purpose of m = sum(w * f/sum(w)) and saw it
    > merely as a weighted average of the fitted values.  My
    > ultimate concern is how to compute an appropriate weighted
    > TSS (or equivalently, MSS) for PRESS-R^2 = 1 - PRESS/TSS =
    > 1 - PRESS/ (MSS + PRESS). Do you think it then makes sense
    > to substitute the vector of leave-one-out fitted values
    > for f here?

--> A new topic really.

I think you should find the answer on the help pages (and in the
source) of

     ? influence.measures  (which documents a host of such functions)
    and
     ? influence

Note that influence is S3 generic and

   methods(influence)

indicates that the 'lm' and 'glm' methods are hidden.
Of course I do recommend reading the real R source code (which
   also contains the comments and has some logical order in all the
   function definitions),
but you can use   stats ::: influence.lm
to show a version of the function that looks not too different
from the source.

Martin Maechler, ETH Zurich


From joseclaudio.faria at gmail.com  Sat Apr  9 18:33:43 2016
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Sat, 9 Apr 2016 13:33:43 -0300
Subject: [R] Arguments to utils:::menuInstallPkgs
In-Reply-To: <5708F78B.1030905@gmail.com>
References: <CAN+Emd86Z-hXAG=ZHkoSB96C8qx0RVr38mDmva=MSR30p_2Puw@mail.gmail.com>
	<5708F78B.1030905@gmail.com>
Message-ID: <CAN+Emd_o0rKO1MqcLR4On2+mctoQ_k=iGx_0Qn2be=9o7a9fiA@mail.gmail.com>

OK, many thanks Duncan!

///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)99966.9100 - VIVO
55(73)99100.7351 - TIM
55(73)98817.6159 - OI
55(73)98129.9942 - CLARO
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\

On Sat, Apr 9, 2016 at 9:37 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 09/04/2016 8:14 AM, Jose Claudio Faria wrote:
>
>> Dears,
>>
>> Is it possible (in any viable way) to pass arguments to the base function
>> (install.packages I think) using the utils:::menu?
>>
>
> No, but why not just call install.packages directly?  (If you are using
> Rgui in Windows, you can add menu items using winMenuAddItem).
>
> Duncan Murdoch
>
>> For example:
>>
>> > utils:::menuInstallPkgs(loc=.libPaths()[2])
>>
>> > utils:::menuInstallLocal(loc=.libPaths()[2])
>>
>> Thanks,
>> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>> Jose Claudio Faria
>> Estatistica
>> UESC/DCET/Brasil
>> joseclaudio.faria at gmail.com
>> Telefones:
>> 55(73)3680.5545 - UESC
>> 55(73)99966.9100 - VIVO
>> 55(73)99100.7351 - TIM
>> 55(73)98817.6159 - OI
>> 55(73)98129.9942 - CLARO
>> ///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Apr  9 19:34:59 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 Apr 2016 10:34:59 -0700
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
Message-ID: <2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>


> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Forgot to copy the list
> 
> Dear Jim,
> 
> Thank you for your reply. I must be doing something wrong, If this is my
> command to plot a map of Europe:
> 
> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> Score - Europe",colourPalette=colourPalette,
>                             catMethod="fixedWidth", missingCountryCol =
> "white", mapRegion="Europe", addLegend=FALSE)
> 
> The following command does not seem to add the arrow. What am I doing wrong?
> 
> do.call(addMapLegend, c(eps_europe, legendLabels="none",
> arrows(-100,-140,100,-140,code=3)))
> 

Your earlier question had a full world map. That was the context for Jim's reply, which did plot a two headed arrow above the legend in your earlier question. Now you have restricted the plot region to Europe so the coordinates of -100,-140,100,-140 no longer are on the visible plot area. You need to decide where you want the arrows using sensible coordinates.

-- 
David.


> Thank you again. I really appreciate it.
> 
> Sincerely,
> 
> Milu
> 
> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi Miluji,
>> Try this:
>> 
>> arrows(-100,-140,100,-140,code=3)
>> 
>> Jim
>> 
>> 
>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
>>> I am trying to draw maps for the world using:
>>> 
>>> library(rworldmap)
>>> library(maptools)
>>> library(RColorBrewer)
>>> 
>>> 
>>> tmp2<- dput(head(pece,10))
>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
>>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
>> 2.15937495231628
>>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
>>> 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
>>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
>>> c(13.4375638961792,
>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
>>> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
>>> 2016 17:43", .Names = c("iso3",
>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
>>> rd_in_va"
>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
>>>    c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
>>>    c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
>>>    "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
>>>    ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
>>>    "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
>>>    ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
>>>    ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
>>>    "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
>>>    "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
>>>    "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
>>>    ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
>>>    "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
>>>    ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
>>> "+1.0000000000000X+000"
>>>    ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
>>>    c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
>>> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
>>> n <- n[-which(row.names(n)=='Antarctica'),]
>>> 
>>> # EPS
>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
>>> 
>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
>>> Score",colourPalette=colourPalette,
>>>                      catMethod="fixedWidth", missingCountryCol =
>> "white",
>>> addLegend=FALSE)
>>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
>>> 
>>> Instead of adding numeric based legend, I would like to add a two-headed
>>> arrow with some text. I would be grateful for any help. Thank you!
>>> 
>>> Sincerely,
>>> 
>>> Milu
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From n4fbz at tampabay.rr.com  Sat Apr  9 18:11:15 2016
From: n4fbz at tampabay.rr.com (Robert D. Bowers)
Date: Sat, 9 Apr 2016 12:11:15 -0400
Subject: [R] Solution to communicating with UDP and other interfaces (under
 Linux) using R
Message-ID: <570929A3.1000101@tampabay.rr.com>

I'd spent hours with Google trying to find how to control a separate 
software package from R via a UDP interface (I could run the package 
under a "system" command, but that was too slow).  I finally figured out 
a way to communicate with UDP through R, and it works fine (using the 
"system" command) - it's also fast.

(1) install software "socat" (available on most of the Linux 
repositories).  It's potent software for communication stuff, btw.

(2) set up the UDP 'port' to communicate with (like in a separate 
software package for passing commands and responses back and forth).

(3) use the "system" command to send messages - as an example:
system("echo \"quit\"| socat - UDP4-DATAGRAM:0.0.0.0:19004")

I haven't tried receiving data from that software yet... but according 
to the writeup on socat, it should be no problem.
You can also use the socat software to redirect from one type of 
connection to another.

(I'm studying R - both for programming/running 'real world' interfaces 
and then doing the statistics on the data.)

Hope this helps someone - the (tiny) few messages I've found indicated 
that it couldn't be done (they were old).  It can be done and rather simply.

Bob


From bob at rudis.net  Sat Apr  9 19:45:30 2016
From: bob at rudis.net (boB Rudis)
Date: Sat, 9 Apr 2016 13:45:30 -0400
Subject: [R] Solution to communicating with UDP and other interfaces
 (under Linux) using R
In-Reply-To: <570929A3.1000101@tampabay.rr.com>
References: <570929A3.1000101@tampabay.rr.com>
Message-ID: <CAJ4QxaON5K2CQmniq9Z4Xn=Ncarp4TWAYyZ3vmErehmLMk=sZQ@mail.gmail.com>

Hey Bob,

If you're interested, I'd be glad to see what I can do to make doing
UDP comms from R accessible across platforms without the need for a
`system()` call. Mind shooting me a private e-mail to see what your
needs are so I can try to generalize a solution from them?

-Bob

On Sat, Apr 9, 2016 at 12:11 PM, Robert D. Bowers <n4fbz at tampabay.rr.com> wrote:
> I'd spent hours with Google trying to find how to control a separate
> software package from R via a UDP interface (I could run the package under a
> "system" command, but that was too slow).  I finally figured out a way to
> communicate with UDP through R, and it works fine (using the "system"
> command) - it's also fast.
>
> (1) install software "socat" (available on most of the Linux repositories).
> It's potent software for communication stuff, btw.
>
> (2) set up the UDP 'port' to communicate with (like in a separate software
> package for passing commands and responses back and forth).
>
> (3) use the "system" command to send messages - as an example:
> system("echo \"quit\"| socat - UDP4-DATAGRAM:0.0.0.0:19004")
>
> I haven't tried receiving data from that software yet... but according to
> the writeup on socat, it should be no problem.
> You can also use the socat software to redirect from one type of connection
> to another.
>
> (I'm studying R - both for programming/running 'real world' interfaces and
> then doing the statistics on the data.)
>
> Hope this helps someone - the (tiny) few messages I've found indicated that
> it couldn't be done (they were old).  It can be done and rather simply.
>
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From milujisb at gmail.com  Sat Apr  9 19:46:50 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sat, 9 Apr 2016 19:46:50 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
Message-ID: <CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>

Dear David,

Thank you for your answer. Sorry for the embarrassing mistake. However,
even with when I generate a map for the whole world using:

 eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
Score",colourPalette=colourPalette,
                      catMethod="fixedWidth", missingCountryCol = "white",
addLegend=FALSE)

And then use:

do.call(addMapLegend, c(eps, legendLabels="none",
arrows(-100,-140,100,-140,code=3)))

Only a legend with the colours is generated, no arrows. My session info is
below. Thanks again!

R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.2 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2 foreign_0.8-66
    maptools_0.8-39    rworldmap_1.3-6
[7] sp_1.2-0

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3
gtable_0.2.0     spam_1.3-0
 [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0
fields_8.3-6     colorspace_1.2-6

On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Forgot to copy the list
> >
> > Dear Jim,
> >
> > Thank you for your reply. I must be doing something wrong, If this is my
> > command to plot a map of Europe:
> >
> > eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS
> > Score - Europe",colourPalette=colourPalette,
> >                             catMethod="fixedWidth", missingCountryCol =
> > "white", mapRegion="Europe", addLegend=FALSE)
> >
> > The following command does not seem to add the arrow. What am I doing
> wrong?
> >
> > do.call(addMapLegend, c(eps_europe, legendLabels="none",
> > arrows(-100,-140,100,-140,code=3)))
> >
>
> Your earlier question had a full world map. That was the context for Jim's
> reply, which did plot a two headed arrow above the legend in your earlier
> question. Now you have restricted the plot region to Europe so the
> coordinates of -100,-140,100,-140 no longer are on the visible plot area.
> You need to decide where you want the arrows using sensible coordinates.
>
> --
> David.
>
>
> > Thank you again. I really appreciate it.
> >
> > Sincerely,
> >
> > Milu
> >
> > On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Miluji,
> >> Try this:
> >>
> >> arrows(-100,-140,100,-140,code=3)
> >>
> >> Jim
> >>
> >>
> >> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
> >>> I am trying to draw maps for the world using:
> >>>
> >>> library(rworldmap)
> >>> library(maptools)
> >>> library(RColorBrewer)
> >>>
> >>>
> >>> tmp2<- dput(head(pece,10))
> >>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> >>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> >>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> >>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> >> 2.15937495231628
> >>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
> >>> 1.88416666785876, 1.99181815710935, 1.21499997377396,
> 0.865833342075348,
> >>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
> >>> c(13.4375638961792,
> >>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> >>> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
> >>> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
> >>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> >>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9
> Mar
> >>> 2016 17:43", .Names = c("iso3",
> >>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
> >>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> >>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
> >>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
> >>> rd_in_va"
> >>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> >>>    c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> >>>    c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
> >>>    "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> >>>    ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
> >>>    "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> >>>    ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> >>>    ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> >>>    "__XijVarLablp", "Percentage of Primary"), c("_dta",
> "__XijVarLablh",
> >>>    "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> >>>    "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of
> Secondary"
> >>>    ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> >>>    "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> >>>    ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> >>> "+1.0000000000000X+000"
> >>>    ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> >>>    c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> >>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> >>> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
> >>> n <- n[-which(row.names(n)=='Antarctica'),]
> >>>
> >>> # EPS
> >>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> >>>
> >>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> >>> Score",colourPalette=colourPalette,
> >>>                      catMethod="fixedWidth", missingCountryCol =
> >> "white",
> >>> addLegend=FALSE)
> >>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
> >>>
> >>> Instead of adding numeric based legend, I would like to add a
> two-headed
> >>> arrow with some text. I would be grateful for any help. Thank you!
> >>>
> >>> Sincerely,
> >>>
> >>> Milu
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Apr  9 20:18:03 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 Apr 2016 11:18:03 -0700
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
Message-ID: <CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>


> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear David,
> 
> Thank you for your answer. Sorry for the embarrassing mistake. However, even with when I generate a map for the whole world using:
> 
>  eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS Score",colourPalette=colourPalette, 
>                       catMethod="fixedWidth", missingCountryCol = "white", addLegend=FALSE)
> 
> And then use:
> 
> do.call(addMapLegend, c(eps, legendLabels="none", arrows(-100,-140,100,-140,code=3)))

I do get an arrow using same version of R and OSX. See attached. (I think that png images will be accepted by the mailserver.)



-- 
David.
> 
> Only a legend with the colours is generated, no arrows. My session info is below. Thanks again!
> 
> R version 3.2.4 (2016-03-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.2 (El Capitan)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> other attached packages:
> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2 foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6   
> [7] sp_1.2-0          
> 
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3       gtable_0.2.0     spam_1.3-0      
>  [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0       fields_8.3-6     colorspace_1.2-6
> 
> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Forgot to copy the list
> >
> > Dear Jim,
> >
> > Thank you for your reply. I must be doing something wrong, If this is my
> > command to plot a map of Europe:
> >
> > eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> > Score - Europe",colourPalette=colourPalette,
> >                             catMethod="fixedWidth", missingCountryCol =
> > "white", mapRegion="Europe", addLegend=FALSE)
> >
> > The following command does not seem to add the arrow. What am I doing wrong?
> >
> > do.call(addMapLegend, c(eps_europe, legendLabels="none",
> > arrows(-100,-140,100,-140,code=3)))
> >
> 
> Your earlier question had a full world map. That was the context for Jim's reply, which did plot a two headed arrow above the legend in your earlier question. Now you have restricted the plot region to Europe so the coordinates of -100,-140,100,-140 no longer are on the visible plot area. You need to decide where you want the arrows using sensible coordinates.
> 
> --
> David.
> 
> 
> > Thank you again. I really appreciate it.
> >
> > Sincerely,
> >
> > Milu
> >
> > On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Miluji,
> >> Try this:
> >>
> >> arrows(-100,-140,100,-140,code=3)
> >>
> >> Jim
> >>
> >>
> >> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
> >>> I am trying to draw maps for the world using:
> >>>
> >>> library(rworldmap)
> >>> library(maptools)
> >>> library(RColorBrewer)
> >>>
> >>>
> >>> tmp2<- dput(head(pece,10))
> >>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> >>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> >>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> >>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> >> 2.15937495231628
> >>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
> >>> 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
> >>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
> >>> c(13.4375638961792,
> >>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> >>> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
> >>> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
> >>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> >>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
> >>> 2016 17:43", .Names = c("iso3",
> >>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
> >>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> >>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
> >>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
> >>> rd_in_va"
> >>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> >>>    c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> >>>    c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
> >>>    "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> >>>    ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
> >>>    "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> >>>    ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> >>>    ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> >>>    "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
> >>>    "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> >>>    "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
> >>>    ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> >>>    "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> >>>    ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> >>> "+1.0000000000000X+000"
> >>>    ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> >>>    c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> >>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> >>> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
> >>> n <- n[-which(row.names(n)=='Antarctica'),]
> >>>
> >>> # EPS
> >>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> >>>
> >>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> >>> Score",colourPalette=colourPalette,
> >>>                      catMethod="fixedWidth", missingCountryCol =
> >> "white",
> >>> addLegend=FALSE)
> >>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
> >>>
> >>> Instead of adding numeric based legend, I would like to add a two-headed
> >>> arrow with some text. I would be grateful for any help. Thank you!
> >>>
> >>> Sincerely,
> >>>
> >>> Milu
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From georges.monette at gmail.com  Sat Apr  9 21:04:29 2016
From: georges.monette at gmail.com (Georges Monette)
Date: Sat, 9 Apr 2016 15:04:29 -0400
Subject: [R] assign
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F6A08A@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAJOiR6Zy1Lns3PxR3Wx3OT37yzsee2tfh=W0hGtaeYnrupTJ4g@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F6A08A@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <5709523D.9020600@gmail.com>

Hi,

I couldn't resist these two suggestions:

strings <- c("ASk/20005-01-45/90", "Alldatk/25-17-4567/990")

x <- as.numeric(gsub("^[^-]*-|-.*$","",strings))

or

x <- as.numeric(sub("^[^-]*-([0-9]+)-.*$","\\1",strings))

Best,
Georges

---------------------
Georges Monette, York University, Toronto

On 08/04/2016 10:53 PM, Fox, John wrote:
> Dear Val,
>
> Your question isn't entirely clear (to me), but this is what I think you want to do:
>
> ------------------ snip ----------------
>
>> strings <- c("ASk/20005-01-45/90", "Alldatk/25-17-4567/990")
>> location <- regexpr("-[0-9]*", strings)
>> x
> [1] "01" "17"
>> x <- substring(strings, location + 1, location + attr(location, "match.length") - 1)
>> as.numeric(x)
> [1]  1 17
>
> ------------------ snip ----------------
>
> I hope this helps,
>   John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> web: socserv.mcmaster.ca/jfox
>
>
> ________________________________________
> From: R-help [r-help-bounces at r-project.org] on behalf of Val [valkremk at gmail.com]
> Sent: April 8, 2016 10:21 PM
> To: r-help at R-project.org (r-help at r-project.org)
> Subject: [R] assign
>
> Hi all
>   I am trying t extract  a variable from a column
>
>        ASk/20005-01-45/90
>
>       Alldatk/25-17-4567/990
>
> I want to assign  a variable to the numbers coming the first"-"
>
> x=01 for the first and
> x=17  for teh second
>
> I tried using gsub but did not work
>
> x=gsub("-")
>
> any help?
>
>          [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgnumis at gmail.com  Sat Apr  9 21:14:10 2016
From: bgnumis at gmail.com (bgnumis bgnum)
Date: Sat, 9 Apr 2016 21:14:10 +0200
Subject: [R] Quantmod abline and axis configuration
Message-ID: <CAN25tHSpCAUWfrD0UJ1jX82o2wquDd2pBP7Nk9hxwhL7vzxSjA@mail.gmail.com>

Hi all,

I have this code


I want to add two ablines like this

abline(h=2400, lty=3, col="lightgrey")

abline(h=400, lty=3, col="lightgrey")

But doesnt wotk.

I alo try to set ylim from 0 to max "Foa"+1000 but I?m not able ?Is it
posible?



require(latticeExtra)
require(ggplot2)
require(reshape2)
suppressPackageStartupMessages(require(googleVis))
require(quantmod)
require(PerformanceAnalytics)
require(xtsExtra)
require(rCharts)





Foa<-as.xts(read.zoo("fa.txt",col.names=c("Date","LAST"), sep="",dec=",",
format="%d/%m/%Y"))

chartSeries(Foa,theme="white",TA = c(addBBands(50,2), addBBands(100,2),
addBBands(250,2), ylim(0,4000))
)

t=chartTheme()
t$BBands$fill="#ff666633"
reChart(theme="white")
t$BBands$col=c('red','blue','green')
t$BBands$col='blue'
reChart(theme="t")

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Apr  9 22:27:23 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 Apr 2016 13:27:23 -0700
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
Message-ID: <2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>


> On Apr 9, 2016, at 11:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
>> 
>> Dear David,
>> 
>> Thank you for your answer. Sorry for the embarrassing mistake. However, even with when I generate a map for the whole world using:
>> 
>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS Score",colourPalette=colourPalette, 
>>                      catMethod="fixedWidth", missingCountryCol = "white", addLegend=FALSE)
>> 
>> And then use:
>> 
>> do.call(addMapLegend, c(eps, legendLabels="none", arrows(-100,-140,100,-140,code=3)))
> 
> I do get an arrow using same version of R and OSX. See attached. (I think that png images will be accepted by the mailserver.)

Nope I was wrong, but the copy to Milugi did arrive.

Here's a pdf:


-- 
David
> 
> 
> 
> -- 
> David.
>> 
>> Only a legend with the colours is generated, no arrows. My session info is below. Thanks again!
>> 
>> R version 3.2.4 (2016-03-10)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: OS X 10.11.2 (El Capitan)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base     
>> 
>> other attached packages:
>> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2 foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6   
>> [7] sp_1.2-0          
>> 
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3       gtable_0.2.0     spam_1.3-0      
>> [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0       fields_8.3-6     colorspace_1.2-6
>> 
>> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>> 
>>> Forgot to copy the list
>>> 
>>> Dear Jim,
>>> 
>>> Thank you for your reply. I must be doing something wrong, If this is my
>>> command to plot a map of Europe:
>>> 
>>> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
>>> Score - Europe",colourPalette=colourPalette,
>>>                            catMethod="fixedWidth", missingCountryCol =
>>> "white", mapRegion="Europe", addLegend=FALSE)
>>> 
>>> The following command does not seem to add the arrow. What am I doing wrong?
>>> 
>>> do.call(addMapLegend, c(eps_europe, legendLabels="none",
>>> arrows(-100,-140,100,-140,code=3)))
>>> 
>> 
>> Your earlier question had a full world map. That was the context for Jim's reply, which did plot a two headed arrow above the legend in your earlier question. Now you have restricted the plot region to Europe so the coordinates of -100,-140,100,-140 no longer are on the visible plot area. You need to decide where you want the arrows using sensible coordinates.
>> 
>> --
>> David.
>> 
>> 
>>> Thank you again. I really appreciate it.
>>> 
>>> Sincerely,
>>> 
>>> Milu
>>> 
>>> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>> 
>>>> Hi Miluji,
>>>> Try this:
>>>> 
>>>> arrows(-100,-140,100,-140,code=3)
>>>> 
>>>> Jim
>>>> 
>>>> 
>>>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
>>>>> I am trying to draw maps for the world using:
>>>>> 
>>>>> library(rworldmap)
>>>>> library(maptools)
>>>>> library(RColorBrewer)
>>>>> 
>>>>> 
>>>>> tmp2<- dput(head(pece,10))
>>>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
>>>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
>>>>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
>>>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
>>>> 2.15937495231628
>>>>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
>>>>> 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
>>>>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
>>>>> c(13.4375638961792,
>>>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
>>>>> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
>>>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
>>>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
>>>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
>>>>> 2016 17:43", .Names = c("iso3",
>>>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
>>>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
>>>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
>>>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
>>>>> rd_in_va"
>>>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
>>>>>   c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
>>>>>   c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
>>>>>   "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
>>>>>   ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
>>>>>   "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
>>>>>   ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
>>>>>   ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
>>>>>   "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
>>>>>   "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
>>>>>   "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
>>>>>   ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
>>>>>   "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
>>>>>   ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
>>>>> "+1.0000000000000X+000"
>>>>>   ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
>>>>>   c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
>>>>> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
>>>>> n <- n[-which(row.names(n)=='Antarctica'),]
>>>>> 
>>>>> # EPS
>>>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
>>>>> 
>>>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
>>>>> Score",colourPalette=colourPalette,
>>>>>                     catMethod="fixedWidth", missingCountryCol =
>>>> "white",
>>>>> addLegend=FALSE)
>>>>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
>>>>> 
>>>>> Instead of adding numeric based legend, I would like to add a two-headed
>>>>> arrow with some text. I would be grateful for any help. Thank you!
>>>>> 
>>>>> Sincerely,
>>>>> 
>>>>> Milu
>>>>> 
>>>>>       [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Apr  9 22:29:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 Apr 2016 13:29:26 -0700
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
Message-ID: <9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>


> On Apr 9, 2016, at 1:27 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Apr 9, 2016, at 11:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> 
>>> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>> 
>>> Dear David,
>>> 
>>> Thank you for your answer. Sorry for the embarrassing mistake. However, even with when I generate a map for the whole world using:
>>> 
>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS Score",colourPalette=colourPalette, 
>>>                     catMethod="fixedWidth", missingCountryCol = "white", addLegend=FALSE)
>>> 
>>> And then use:
>>> 
>>> do.call(addMapLegend, c(eps, legendLabels="none", arrows(-100,-140,100,-140,code=3)))
>> 
>> I do get an arrow using same version of R and OSX. See attached. (I think that png images will be accepted by the mailserver.)
> 
> Nope I was wrong, but the copy to Milugi did arrive.
> 
> Here's a (somewhat larger) pdf:

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.pdf
Type: application/pdf
Size: 115266 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160409/bd2b60f1/attachment.pdf>
-------------- next part --------------


> 
> 
> -- 
> David
>> 
>> 
>> 
>> -- 
>> David.
>>> 
>>> Only a legend with the colours is generated, no arrows. My session info is below. Thanks again!
>>> 
>>> R version 3.2.4 (2016-03-10)
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> Running under: OS X 10.11.2 (El Capitan)
>>> 
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base     
>>> 
>>> other attached packages:
>>> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2 foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6   
>>> [7] sp_1.2-0          
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3       gtable_0.2.0     spam_1.3-0      
>>> [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0       fields_8.3-6     colorspace_1.2-6
>>> 
>>> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>>> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>>> 
>>>> Forgot to copy the list
>>>> 
>>>> Dear Jim,
>>>> 
>>>> Thank you for your reply. I must be doing something wrong, If this is my
>>>> command to plot a map of Europe:
>>>> 
>>>> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
>>>> Score - Europe",colourPalette=colourPalette,
>>>>                           catMethod="fixedWidth", missingCountryCol =
>>>> "white", mapRegion="Europe", addLegend=FALSE)
>>>> 
>>>> The following command does not seem to add the arrow. What am I doing wrong?
>>>> 
>>>> do.call(addMapLegend, c(eps_europe, legendLabels="none",
>>>> arrows(-100,-140,100,-140,code=3)))
>>>> 
>>> 
>>> Your earlier question had a full world map. That was the context for Jim's reply, which did plot a two headed arrow above the legend in your earlier question. Now you have restricted the plot region to Europe so the coordinates of -100,-140,100,-140 no longer are on the visible plot area. You need to decide where you want the arrows using sensible coordinates.
>>> 
>>> --
>>> David.
>>> 
>>> 
>>>> Thank you again. I really appreciate it.
>>>> 
>>>> Sincerely,
>>>> 
>>>> Milu
>>>> 
>>>> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>> 
>>>>> Hi Miluji,
>>>>> Try this:
>>>>> 
>>>>> arrows(-100,-140,100,-140,code=3)
>>>>> 
>>>>> Jim
>>>>> 
>>>>> 
>>>>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
>>>>>> I am trying to draw maps for the world using:
>>>>>> 
>>>>>> library(rworldmap)
>>>>>> library(maptools)
>>>>>> library(RColorBrewer)
>>>>>> 
>>>>>> 
>>>>>> tmp2<- dput(head(pece,10))
>>>>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
>>>>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
>>>>>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
>>>>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
>>>>> 2.15937495231628
>>>>>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
>>>>>> 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
>>>>>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
>>>>>> c(13.4375638961792,
>>>>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
>>>>>> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
>>>>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
>>>>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
>>>>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
>>>>>> 2016 17:43", .Names = c("iso3",
>>>>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
>>>>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
>>>>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
>>>>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
>>>>>> rd_in_va"
>>>>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
>>>>>>  c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
>>>>>>  c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
>>>>>>  "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
>>>>>>  ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
>>>>>>  "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
>>>>>>  ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
>>>>>>  ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
>>>>>>  "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
>>>>>>  "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
>>>>>>  "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
>>>>>>  ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
>>>>>>  "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
>>>>>>  ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
>>>>>> "+1.0000000000000X+000"
>>>>>>  ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
>>>>>>  c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
>>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
>>>>>> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
>>>>>> n <- n[-which(row.names(n)=='Antarctica'),]
>>>>>> 
>>>>>> # EPS
>>>>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
>>>>>> 
>>>>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
>>>>>> Score",colourPalette=colourPalette,
>>>>>>                    catMethod="fixedWidth", missingCountryCol =
>>>>> "white",
>>>>>> addLegend=FALSE)
>>>>>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
>>>>>> 
>>>>>> Instead of adding numeric based legend, I would like to add a two-headed
>>>>>> arrow with some text. I would be grateful for any help. Thank you!
>>>>>> 
>>>>>> Sincerely,
>>>>>> 
>>>>>> Milu
>>>>>> 
>>>>>>      [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>>     [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From jfox at mcmaster.ca  Sat Apr  9 22:47:47 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 9 Apr 2016 20:47:47 +0000
Subject: [R] assign
In-Reply-To: <5709523D.9020600@gmail.com>
References: <CAJOiR6Zy1Lns3PxR3Wx3OT37yzsee2tfh=W0hGtaeYnrupTJ4g@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F6A08A@FHSDB2D11-2.csu.mcmaster.ca>
	<5709523D.9020600@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F6A325@FHSDB2D11-2.csu.mcmaster.ca>

Hi Georges,

Very clever, and your first solution isn't much more complicated in the regular expression than my solution -- and simpler in the sense that it's all done in one command.  

I think that your solutions are a little more fragile in that they assume a somewhat more consistent structure to the strings (a second dash, which may be implied by the original question).

Best,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Georges
> Monette
> Sent: April 9, 2016 3:04 PM
> To: r-help at r-project.org
> Subject: Re: [R] assign
> 
> Hi,
> 
> I couldn't resist these two suggestions:
> 
> strings <- c("ASk/20005-01-45/90", "Alldatk/25-17-4567/990")
> 
> x <- as.numeric(gsub("^[^-]*-|-.*$","",strings))
> 
> or
> 
> x <- as.numeric(sub("^[^-]*-([0-9]+)-.*$","\\1",strings))
> 
> Best,
> Georges
> 
> ---------------------
> Georges Monette, York University, Toronto
> 
> On 08/04/2016 10:53 PM, Fox, John wrote:
> > Dear Val,
> >
> > Your question isn't entirely clear (to me), but this is what I think you want
> to do:
> >
> > ------------------ snip ----------------
> >
> >> strings <- c("ASk/20005-01-45/90", "Alldatk/25-17-4567/990") location
> >> <- regexpr("-[0-9]*", strings) x
> > [1] "01" "17"
> >> x <- substring(strings, location + 1, location + attr(location,
> >> "match.length") - 1)
> >> as.numeric(x)
> > [1]  1 17
> >
> > ------------------ snip ----------------
> >
> > I hope this helps,
> >   John
> >
> > -----------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > web: socserv.mcmaster.ca/jfox
> >
> >
> > ________________________________________
> > From: R-help [r-help-bounces at r-project.org] on behalf of Val
> > [valkremk at gmail.com]
> > Sent: April 8, 2016 10:21 PM
> > To: r-help at R-project.org (r-help at r-project.org)
> > Subject: [R] assign
> >
> > Hi all
> >   I am trying t extract  a variable from a column
> >
> >        ASk/20005-01-45/90
> >
> >       Alldatk/25-17-4567/990
> >
> > I want to assign  a variable to the numbers coming the first"-"
> >
> > x=01 for the first and
> > x=17  for teh second
> >
> > I tried using gsub but did not work
> >
> > x=gsub("-")
> >
> > any help?
> >
> >          [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From miaojpm at gmail.com  Sat Apr  9 23:58:12 2016
From: miaojpm at gmail.com (jpm miao)
Date: Sat, 9 Apr 2016 14:58:12 -0700
Subject: [R] How to print the graphs in landscape/portrait orientation
Message-ID: <CABcx46Dj6RUiro01pMNBdONPu=SqvqNTY9TBh3s_TEaR-tjmgg@mail.gmail.com>

Hi,

   I made a few graphs by ggplot. The following codes produce a pdf file
with graphs in landscape orientation on my Windows PC, while they produce a
pdf file with the same graphs, but in portrait orientation:

*p2 <- lapply(1:(2*n), function(.x) xyz_outl[.x][[1]])  #a sequence of
graphs made by ggplot*
*m2 <- marrangeGrob(p2, nrow=3, ncol=2)  *

*ggsave("xyz.pdf", m2)*

    Question: how can I let the graphs printed in landscape orientation on
my Mac? I try to add the following line before the above code, but it does
not work.

*pdf(paper = "Usr")*

   Thanks!

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Apr 10 00:06:58 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 9 Apr 2016 18:06:58 -0400
Subject: [R] How to print the graphs in landscape/portrait orientation
In-Reply-To: <CABcx46Dj6RUiro01pMNBdONPu=SqvqNTY9TBh3s_TEaR-tjmgg@mail.gmail.com>
References: <CABcx46Dj6RUiro01pMNBdONPu=SqvqNTY9TBh3s_TEaR-tjmgg@mail.gmail.com>
Message-ID: <57097D02.8060205@gmail.com>

On 09/04/2016 5:58 PM, jpm miao wrote:
> Hi,
>
>     I made a few graphs by ggplot. The following codes produce a pdf file
> with graphs in landscape orientation on my Windows PC, while they produce a
> pdf file with the same graphs, but in portrait orientation:
>
> *p2 <- lapply(1:(2*n), function(.x) xyz_outl[.x][[1]])  #a sequence of
> graphs made by ggplot*
> *m2 <- marrangeGrob(p2, nrow=3, ncol=2)  *
>
> *ggsave("xyz.pdf", m2)*
>
>      Question: how can I let the graphs printed in landscape orientation on
> my Mac? I try to add the following line before the above code, but it does
> not work.
>
> *pdf(paper = "Usr")*
>
>     Thanks!
>
> 	[[alternative HTML version deleted]]

None of that is runnable by anyone else.  If you want help, please make 
an effort to be considerate of the people who are trying to help you.

  - Don't post in HTML.  Those asterisks make your code unusable.

  - Do post self-contained examples.  Even if I spent the time to edit 
your post into something I could run, it would fail, because I don't 
have copies of all the variables it uses.

Duncan Murdoch


From josh.m.ulrich at gmail.com  Sun Apr 10 01:09:41 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 9 Apr 2016 18:09:41 -0500
Subject: [R] Quantmod abline and axis configuration
In-Reply-To: <CAN25tHSpCAUWfrD0UJ1jX82o2wquDd2pBP7Nk9hxwhL7vzxSjA@mail.gmail.com>
References: <CAN25tHSpCAUWfrD0UJ1jX82o2wquDd2pBP7Nk9hxwhL7vzxSjA@mail.gmail.com>
Message-ID: <CAPPM_gTtKgKS4zwUnPU+gL2V8XDU=qYMG+MK3qvzKaB1v8b-4Q@mail.gmail.com>

On Sat, Apr 9, 2016 at 2:14 PM, bgnumis bgnum <bgnumis at gmail.com> wrote:
> Hi all,
>
> I have this code
>
>
> I want to add two ablines like this
>
> abline(h=2400, lty=3, col="lightgrey")
>
> abline(h=400, lty=3, col="lightgrey")
>
> But doesnt wotk.
>
Use addLines().  It does what abline() does, although you cannot specify lty.

> I alo try to set ylim from 0 to max "Foa"+1000 but I?m not able ?Is it
> posible?
>
Yes, use the yrange argument.

>
>
> require(latticeExtra)
> require(ggplot2)
> require(reshape2)
> suppressPackageStartupMessages(require(googleVis))
> require(quantmod)
> require(PerformanceAnalytics)
> require(xtsExtra)
> require(rCharts)
>
>
>
>
>
> Foa<-as.xts(read.zoo("fa.txt",col.names=c("Date","LAST"), sep="",dec=",",
> format="%d/%m/%Y"))
>
> chartSeries(Foa,theme="white",TA = c(addBBands(50,2), addBBands(100,2),
> addBBands(250,2), ylim(0,4000))
> )
>
> t=chartTheme()
> t$BBands$fill="#ff666633"
> reChart(theme="white")
> t$BBands$col=c('red','blue','green')
> t$BBands$col='blue'
> reChart(theme="t")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From fabien.tarrade at gmail.com  Sat Apr  9 23:44:47 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Sat, 9 Apr 2016 23:44:47 +0200
Subject: [R] fast way to search for a pattern in a few million entries data
	frame
Message-ID: <570977CF.1080100@gmail.com>

Hi there,

I have a data frame DF with 40 millions strings and their frequency. I 
am searching for strings with a given pattern and I am trying to speed 
up this part of my code. I try many options but so far I am not 
satisfied. I tried:
- grepl and subset are equivalent in term of processing time
    grepl(paste0("^",pattern),df$Strings)
    subset(df, grepl(paste0("^",pattern), df$Strings))

- lookup(pattern,df) is not what I am looking for since it is doing an 
exact matching

- I tried to convert my data frame in a data table but it didn't improve 
things (probably read/write of this DT will be much faster)

- the only way I found was to remove 1/3 of the data frame with the 
strings of lowest frequency which speed up the process by a factor x10 !

- didn't try yet parRapply and with a machine with multicore I can get 
another factor.
    I did use parLapply for some other code but I had many issue with 
memory (crashing my Mac).
    I had to sub-divide the dataset to have it working correctly but I 
didn't manage to fully understand the issue.

I am sure their is some other smart way to do that. Any good 
article/blogs or suggestion that can give me some guidance ?

Thanks a lot
Cheers
Fabien
-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>

From art_med_ahmed at yahoo.fr  Sun Apr 10 01:51:35 2016
From: art_med_ahmed at yahoo.fr (Mohamed Benahmed)
Date: Sat, 9 Apr 2016 23:51:35 +0000 (UTC)
Subject: [R] Run script R
References: <2071405573.54290.1460245895197.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2071405573.54290.1460245895197.JavaMail.yahoo@mail.yahoo.com>

hi all ,?
i have an problem in script R . But when I execute the script R I face this error . can you help me please ???error:-----------------------------------------
Error in FUN(X[[i]], ...) :?? Theme element 'text' has NULL property: margin, debugIn addition: Warning messages:1: Removed 361 rows containing non-finite values (stat_smooth).?2: Removed 361 rows containing missing values (geom_path).?3: Removed 6 rows containing missing values (geom_smooth).?-------------------------------------------------------------script R:

suppressMessages (library(ggplot2))

source ("graph-style.R")
input = "graphs/figure-3-data-propagation-vs-time/car-relay-jump-distance.txt.gz2"output = "graphs/pdfs/figure-3-data-propagation-vs-time.pdf"
data <- read.table (bzfile(input, "r"), header=TRUE)data$Run = as.factor(data$Run)data$DistanceFromSource = data$NodeId * data$Distance
data = subset(data, Distance %in% c(10, 50, 90, 130, 170))data$Distance = as.factor(data$Distance)

g <- ggplot(data, aes(x=Time-2, y=DistanceFromSource, colour=Distance, linetype=Distance)) +? geom_line (aes(group=paste(Distance, Run, fill=Distance)), show_guide=FALSE, size=0.2) +
? ## stat_summary(aes(group=Distance, colour=Distance), fun.y="mean", geom="line", size = 2) +? ## geom_line (aes(group=Distance, y=mean(DistanceFromSource/1000))) +? geom_smooth (aes(fill=Distance), show_guide=TRUE, method="lm", colour='black', n=20, size=0.3) +
? scale_y_continuous ("Distance from source, km", limits=c(-500,10000), labels=function(x){x/1000}) +? scale_x_continuous ("Time, seconds", limits=c(0,2)) +? scale_colour_brewer("Distance between cars, m", palette="Dark2", guide = "none") +? scale_fill_brewer("Distance between cars, m", palette="Dark2") +? scale_linetype_manual("Distance between cars, m", values=c(1,2,3,4,5,6,7,8)) +? theme_custom () +? theme (legend.position = c(0.99,-0.05), legend.justification=c(1.0,0), legend.direction = "horizontal")
if (!file.exists ("graphs/pdfs")) {? dir.create ("graphs/pdfs")}
pdf (output, width=5, height=3.5)gx = dev.off ()----------------------------------------------------------------------------------------------------------------------script( graph-style.R) :
library(grid)
theme_custom <- function (base_size = 10, base_family = "serif") {? theme_grey(base_size = base_size, base_family = base_family) %+replace%? ? theme(? ? ? line = ? ? ? ? ? ? ? element_line(colour = "black", size = 0.5, linetype = 1, lineend = "butt"),? ? ? rect = ? ? ? ? ? ? ? element_rect(fill = "white", colour = "black", size = 0.5, linetype = 1),? ? ? text = ? ? ? ? ? ? ? element_text(family = base_family, face = "plain", colour = "black", size = base_size, hjust = 0.5, vjust = 0.5, angle = 0, lineheight = 0.9),? ? ? axis.text = ? ? ? ? ?element_text(size = rel(0.8), colour = "grey50"),? ? ? strip.text = ? ? ? ? element_text(size = rel(0.8)),
? ? ? axis.line = ? ? ? ? ?element_blank(),? ? ? axis.text.x = ? ? ? ?element_text(family = base_family, size = base_size * 0.7, lineheight = 0.8, vjust = 1.2),? ? ? axis.text.y = ? ? ? ?element_text(family = base_family, size = base_size * 0.7, lineheight = 0.8, hjust = 1.2),? ? ? axis.ticks = ? ? ? ? element_line(colour = "black", size=0.2),? ? ? axis.title.x = ? ? ? element_text(family = base_family, size = base_size, vjust = 0.5),? ? ? axis.title.y = ? ? ? element_text(family = base_family, size = base_size, angle = 90, vjust = 0.5),? ? ? axis.ticks.length = ?unit(0.15, "cm"),? ? ? axis.ticks.margin = ?unit(0.1, "cm"),
? ? ? legend.background = ?element_rect (fill=NA, colour=NA, size=0.1),? ? ? legend.margin = ? ? ?unit(0.2, "cm"),? ? ? legend.key = ? ? ? ? element_rect(fill = "grey95", colour = "white"),? ? ? legend.key.size = ? ?unit(1.2, "lines"),? ? ? legend.key.height = ?NULL,? ? ? legend.key.width = ? NULL,? ? ? legend.text = ? ? ? ?element_text(family = base_family, size = base_size * 0.8),? ? ? legend.text.align = ?NULL,? ? ? legend.title = ? ? ? element_text(family = base_family, size = base_size * 0.8, face = "bold", hjust = 1),? ? ? legend.title.align = NULL,? ? ? legend.position = ? ?"right",? ? ? legend.direction = ? NULL,? ? ? legend.justification = "center",? ? ? legend.box = ? ? ? ? NULL,
? ? ? panel.background = ? element_rect(fill = "white", colour = NA),? ? ? panel.border = ? ? ? element_rect(fill = NA, colour = "grey50"),? ? ? panel.grid.major = ? element_line(colour = "grey60", size = 0.1),? ? ? panel.grid.minor = ? element_line(colour = "grey70", size = 0.1, linetype="dotted"),? ? ? ## panel.margin = ? ? ? unit(c(0.1, 0.1, 0.1, 0.1), "lines"),
? ? ? strip.background = ? element_rect(fill = NA, colour = NA),? ? ? strip.text.x = ? ? ? element_text(family = base_family, size = base_size * 0.8),? ? ? strip.text.y = ? ? ? element_text(family = base_family, size = base_size * 0.8, angle = -90),
? ? ? plot.background = ? ?element_rect(colour = NA, fill = "white"),? ? ? plot.title = ? ? ? ? element_text(family = base_family, size = base_size),? ? ? plot.margin = ? ? ? ?unit(c(0.1, 0.1, 0.1, 0.1), "lines")? ? )}

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Sun Apr 10 02:20:23 2016
From: miaojpm at gmail.com (jpm miao)
Date: Sat, 9 Apr 2016 17:20:23 -0700
Subject: [R] How to print the graphs in landscape/portrait orientation
	(revised)
Message-ID: <CABcx46C78JpF=CZ=JPkX_zmk0h7_gU31eFnqyYfsWxWKKXMq6g@mail.gmail.com>

Hi,



      I made a few graphs by ggplot. The following codes produce a pdf file
with graphs, sometimes in landscape orientation, sometimes in portrait
orientation.  I am using both Mac and Windows PC.



    Question: how can I control the orientation of the pdf file? I try to
add a line pdf(paper = ?USr?) (or pdf(paper="letter")) in the following
code, but it does not work.



   Thanks!!



#################

library(ggplot2)

library(grid)

library(gridExtra)    # Output graphs to files

n<-100

p2<-array(list(NA),dim=n)

# pdf(paper = "Usr")

# pdf(paper = "letter")

for(i in 1:n)

{

  p2[i][[1]]<-ggplot(data.frame(x=1:(i+1), y=seq(2,2*(i+1),2)), aes(x=x,
y=y))+ geom_line(color="blue")

}

m2 <- marrangeGrob(p2, nrow=3, ncol=2)

ggsave("test_160409xyz.pdf", m2)

##################

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sun Apr 10 07:17:25 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 10 Apr 2016 07:17:25 +0200
Subject: [R] Run script R
In-Reply-To: <2071405573.54290.1460245895197.JavaMail.yahoo@mail.yahoo.com>
References: <2071405573.54290.1460245895197.JavaMail.yahoo.ref@mail.yahoo.com>
	<2071405573.54290.1460245895197.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <C7BB59C7-1B93-4A75-8447-69C329E0CF05@xs4all.nl>


Please do NOT post in html as the posting guide tells you. Post in plain text.
Your R code is a complete mess and unreadable.

Berend

> On 10 Apr 2016, at 01:51, Mohamed Benahmed via R-help <r-help at r-project.org> wrote:
> 
> hi all , 
> i have an problem in script R . But when I execute the script R I face this error . can you help me please ?? error:-----------------------------------------
> Error in FUN(X[[i]], ...) :   Theme element 'text' has NULL property: margin, debugIn addition: Warning messages:1: Removed 361 rows containing non-finite values (stat_smooth). 2: Removed 361 rows containing missing values (geom_path). 3: Removed 6 rows containing missing values (geom_smooth). -------------------------------------------------------------script R:
> 
> suppressMessages (library(ggplot2))
> 
> source ("graph-style.R")
> input = "graphs/figure-3-data-propagation-vs-time/car-relay-jump-distance.txt.gz2"output = "graphs/pdfs/figure-3-data-propagation-vs-time.pdf"
> data <- read.table (bzfile(input, "r"), header=TRUE)data$Run = as.factor(data$Run)data$DistanceFromSource = data$NodeId * data$Distance
> data = subset(data, Distance %in% c(10, 50, 90, 130, 170))data$Distance = as.factor(data$Distance)
> 
> g <- ggplot(data, aes(x=Time-2, y=DistanceFromSource, colour=Distance, linetype=Distance)) +  geom_line (aes(group=paste(Distance, Run, fill=Distance)), show_guide=FALSE, size=0.2) +
>   ## stat_summary(aes(group=Distance, colour=Distance), fun.y="mean", geom="line", size = 2) +  ## geom_line (aes(group=Distance, y=mean(DistanceFromSource/1000))) +  geom_smooth (aes(fill=Distance), show_guide=TRUE, method="lm", colour='black', n=20, size=0.3) +
>   scale_y_continuous ("Distance from source, km", limits=c(-500,10000), labels=function(x){x/1000}) +  scale_x_continuous ("Time, seconds", limits=c(0,2)) +  scale_colour_brewer("Distance between cars, m", palette="Dark2", guide = "none") +  scale_fill_brewer("Distance between cars, m", palette="Dark2") +  scale_linetype_manual("Distance between cars, m", values=c(1,2,3,4,5,6,7,8)) +  theme_custom () +  theme (legend.position = c(0.99,-0.05), legend.justification=c(1.0,0), legend.direction = "horizontal")
> if (!file.exists ("graphs/pdfs")) {  dir.create ("graphs/pdfs")}
> pdf (output, width=5, height=3.5)gx = dev.off ()----------------------------------------------------------------------------------------------------------------------script( graph-style.R) :
> library(grid)
> theme_custom <- function (base_size = 10, base_family = "serif") {  theme_grey(base_size = base_size, base_family = base_family) %+replace%    theme(      line =               element_line(colour = "black", size = 0.5, linetype = 1, lineend = "butt"),      rect =               element_rect(fill = "white", colour = "black", size = 0.5, linetype = 1),      text =               element_text(family = base_family, face = "plain", colour = "black", size = base_size, hjust = 0.5, vjust = 0.5, angle = 0, lineheight = 0.9),      axis.text =          element_text(size = rel(0.8), colour = "grey50"),      strip.text =         element_text(size = rel(0.8)),
>       axis.line =          element_blank(),      axis.text.x =        element_text(family = base_family, size = base_size * 0.7, lineheight = 0.8, vjust = 1.2),      axis.text.y =        element_text(family = base_family, size = base_size * 0.7, lineheight = 0.8, hjust = 1.2),      axis.ticks =         element_line(colour = "black", size=0.2),      axis.title.x =       element_text(family = base_family, size = base_size, vjust = 0.5),      axis.title.y =       element_text(family = base_family, size = base_size, angle = 90, vjust = 0.5),      axis.ticks.length =  unit(0.15, "cm"),      axis.ticks.margin =  unit(0.1, "cm"),
>       legend.background =  element_rect (fill=NA, colour=NA, size=0.1),      legend.margin =      unit(0.2, "cm"),      legend.key =         element_rect(fill = "grey95", colour = "white"),      legend.key.size =    unit(1.2, "lines"),      legend.key.height =  NULL,      legend.key.width =   NULL,      legend.text =        element_text(family = base_family, size = base_size * 0.8),      legend.text.align =  NULL,      legend.title =       element_text(family = base_family, size = base_size * 0.8, face = "bold", hjust = 1),      legend.title.align = NULL,      legend.position =    "right",      legend.direction =   NULL,      legend.justification = "center",      legend.box =         NULL,
>       panel.background =   element_rect(fill = "white", colour = NA),      panel.border =       element_rect(fill = NA, colour = "grey50"),      panel.grid.major =   element_line(colour = "grey60", size = 0.1),      panel.grid.minor =   element_line(colour = "grey70", size = 0.1, linetype="dotted"),      ## panel.margin =       unit(c(0.1, 0.1, 0.1, 0.1), "lines"),
>       strip.background =   element_rect(fill = NA, colour = NA),      strip.text.x =       element_text(family = base_family, size = base_size * 0.8),      strip.text.y =       element_text(family = base_family, size = base_size * 0.8, angle = -90),
>       plot.background =    element_rect(colour = NA, fill = "white"),      plot.title =         element_text(family = base_family, size = base_size),      plot.margin =        unit(c(0.1, 0.1, 0.1, 0.1), "lines")    )}
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murray.efford at otago.ac.nz  Sun Apr 10 12:11:33 2016
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Sun, 10 Apr 2016 10:11:33 +0000
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <22281.10422.170427.867866@stat.math.ethz.ch>
References: <1460064106032.30358@otago.ac.nz>	<57078E97.1@gmail.com>
	<A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>
	<1460141125051.21413@otago.ac.nz>,
	<22281.10422.170427.867866@stat.math.ethz.ch>
Message-ID: <1460283084042.53401@otago.ac.nz>

Martin -
Thanks, but although hatvalues() is useful for calculating PRESS, I can't find anything directly relevant to my question in the influence help pages. After some burrowing in the literature I'm doubting there is an answer out there (PRESS R^2 is always presented in a fairly ad hoc way).
This is a new topic, as you say, and perhaps better handled on a statistics list.
Murray Efford

[BTW
 stats ::: influence.lm
just gets me
function (model, do.coef = TRUE, ...) 
lm.influence(model, do.coef = do.coef, ...)
<bytecode: 0x00000000081023b8>
<environment: namespace:stats>
which is not very helpful]

________________________________________
From: Martin Maechler <maechler at stat.math.ethz.ch>
Sent: Sunday, 10 April 2016 4:07 a.m.
To: Murray Efford
Cc: peter dalgaard; Duncan Murdoch; r-help at r-project.org
Subject: Re: [R] R.squared in summary.lm with weights

>>>>> Murray Efford <murray.efford at otago.ac.nz>
>>>>>     on Fri, 8 Apr 2016 18:45:33 +0000 writes:

    > Thanks for these perfectly consistent replies - I didn't
    > understand the purpose of m = sum(w * f/sum(w)) and saw it
    > merely as a weighted average of the fitted values.  My
    > ultimate concern is how to compute an appropriate weighted
    > TSS (or equivalently, MSS) for PRESS-R^2 = 1 - PRESS/TSS =
    > 1 - PRESS/ (MSS + PRESS). Do you think it then makes sense
    > to substitute the vector of leave-one-out fitted values
    > for f here?

--> A new topic really.

I think you should find the answer on the help pages (and in the
source) of

     ? influence.measures  (which documents a host of such functions)
    and
     ? influence

Note that influence is S3 generic and

   methods(influence)

indicates that the 'lm' and 'glm' methods are hidden.
Of course I do recommend reading the real R source code (which
   also contains the comments and has some logical order in all the
   function definitions),
but you can use   stats ::: influence.lm
to show a version of the function that looks not too different
from the source.

Martin Maechler, ETH Zurich



From sabasehrish at yahoo.com  Sun Apr 10 12:57:13 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Sun, 10 Apr 2016 10:57:13 +0000 (UTC)
Subject: [R] unbalanced number of rows
References: <983927952.162927.1460285833698.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <983927952.162927.1460285833698.JavaMail.yahoo@mail.yahoo.com>

HiI have a data frame with rows specifying companies (codes are assigned to companies) and columns specify months (monthly data). The data is based on male (M) and female (F) information for each month. Following is an example of how data looks like:
 01 02 03 04001 na M M M001 M M M F002 M F F na003 M na na M003 F M M F003 F F M M
na= no male/female.
Now, I want to firstly add rows with similar codes to see total number of Male and Female in each month. Secondly, I need to calculate fraction of Female in each month (F/ M+F) for these three companies.
Kindly guide me in this regard.
ThanksSaba
	[[alternative HTML version deleted]]


From milujisb at gmail.com  Sun Apr 10 13:12:45 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 10 Apr 2016 13:12:45 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
Message-ID: <CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>

Hello David,

This is exactly what I want but I still can't get the arrows. R and R
studio is updated. Thanks again!

Sincerely,

Milu

On Sat, Apr 9, 2016 at 10:29 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 9, 2016, at 1:27 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> >> On Apr 9, 2016, at 11:18 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >>
> >>
> >>> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >>>
> >>> Dear David,
> >>>
> >>> Thank you for your answer. Sorry for the embarrassing mistake.
> However, even with when I generate a map for the whole world using:
> >>>
> >>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> Score",colourPalette=colourPalette,
> >>>                     catMethod="fixedWidth", missingCountryCol =
> "white", addLegend=FALSE)
> >>>
> >>> And then use:
> >>>
> >>> do.call(addMapLegend, c(eps, legendLabels="none",
> arrows(-100,-140,100,-140,code=3)))
> >>
> >> I do get an arrow using same version of R and OSX. See attached. (I
> think that png images will be accepted by the mailserver.)
> >
> > Nope I was wrong, but the copy to Milugi did arrive.
> >
> > Here's a (somewhat larger) pdf:
>
>
>
>
> >
> >
> > --
> > David
> >>
> >>
> >>
> >> --
> >> David.
> >>>
> >>> Only a legend with the colours is generated, no arrows. My session
> info is below. Thanks again!
> >>>
> >>> R version 3.2.4 (2016-03-10)
> >>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> >>> Running under: OS X 10.11.2 (El Capitan)
> >>>
> >>> locale:
> >>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >>>
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>> other attached packages:
> >>> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2
> foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6
> >>> [7] sp_1.2-0
> >>>
> >>> loaded via a namespace (and not attached):
> >>> [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3
>  gtable_0.2.0     spam_1.3-0
> >>> [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0
>  fields_8.3-6     colorspace_1.2-6
> >>>
> >>> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> >>>
> >>>> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >>>>
> >>>> Forgot to copy the list
> >>>>
> >>>> Dear Jim,
> >>>>
> >>>> Thank you for your reply. I must be doing something wrong, If this is
> my
> >>>> command to plot a map of Europe:
> >>>>
> >>>> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS
> >>>> Score - Europe",colourPalette=colourPalette,
> >>>>                           catMethod="fixedWidth", missingCountryCol =
> >>>> "white", mapRegion="Europe", addLegend=FALSE)
> >>>>
> >>>> The following command does not seem to add the arrow. What am I doing
> wrong?
> >>>>
> >>>> do.call(addMapLegend, c(eps_europe, legendLabels="none",
> >>>> arrows(-100,-140,100,-140,code=3)))
> >>>>
> >>>
> >>> Your earlier question had a full world map. That was the context for
> Jim's reply, which did plot a two headed arrow above the legend in your
> earlier question. Now you have restricted the plot region to Europe so the
> coordinates of -100,-140,100,-140 no longer are on the visible plot area.
> You need to decide where you want the arrows using sensible coordinates.
> >>>
> >>> --
> >>> David.
> >>>
> >>>
> >>>> Thank you again. I really appreciate it.
> >>>>
> >>>> Sincerely,
> >>>>
> >>>> Milu
> >>>>
> >>>> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>>
> >>>>> Hi Miluji,
> >>>>> Try this:
> >>>>>
> >>>>> arrows(-100,-140,100,-140,code=3)
> >>>>>
> >>>>> Jim
> >>>>>
> >>>>>
> >>>>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com>
> wrote:
> >>>>>> I am trying to draw maps for the world using:
> >>>>>>
> >>>>>> library(rworldmap)
> >>>>>> library(maptools)
> >>>>>> library(RColorBrewer)
> >>>>>>
> >>>>>>
> >>>>>> tmp2<- dput(head(pece,10))
> >>>>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> >>>>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> >>>>>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> >>>>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> >>>>> 2.15937495231628
> >>>>>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
> >>>>>> 1.88416666785876, 1.99181815710935, 1.21499997377396,
> 0.865833342075348,
> >>>>>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
> >>>>>> c(13.4375638961792,
> >>>>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> >>>>>> 13.5679216384888, 9.67090892791748, 10.5978908538818,
> 8.34146690368652
> >>>>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187,
> 2.53955459594727,
> >>>>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> >>>>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = "
> 9 Mar
> >>>>>> 2016 17:43", .Names = c("iso3",
> >>>>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats =
> c("%9s",
> >>>>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> >>>>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
> >>>>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
> >>>>>> rd_in_va"
> >>>>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> >>>>>>  c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> >>>>>>  c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
> >>>>>>  "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> >>>>>>  ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
> >>>>>>  "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> >>>>>>  ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> >>>>>>  ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> >>>>>>  "__XijVarLablp", "Percentage of Primary"), c("_dta",
> "__XijVarLablh",
> >>>>>>  "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> >>>>>>  "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of
> Secondary"
> >>>>>>  ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> >>>>>>  "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> >>>>>>  ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> >>>>>> "+1.0000000000000X+000"
> >>>>>>  ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> >>>>>>  c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> >>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> >>>>>> n <- joinCountryData2Map(pece, joinCode="ISO3",
> nameJoinColumn="iso3")
> >>>>>> n <- n[-which(row.names(n)=='Antarctica'),]
> >>>>>>
> >>>>>> # EPS
> >>>>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> >>>>>>
> >>>>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> >>>>>> Score",colourPalette=colourPalette,
> >>>>>>                    catMethod="fixedWidth", missingCountryCol =
> >>>>> "white",
> >>>>>> addLegend=FALSE)
> >>>>>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
> >>>>>>
> >>>>>> Instead of adding numeric based legend, I would like to add a
> two-headed
> >>>>>> arrow with some text. I would be grateful for any help. Thank you!
> >>>>>>
> >>>>>> Sincerely,
> >>>>>>
> >>>>>> Milu
> >>>>>>
> >>>>>>      [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>     [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> David Winsemius
> >>> Alameda, CA, USA
> >>>
> >>>
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
>
> David Winsemius
> Alameda, CA, USA
>
>
>

	[[alternative HTML version deleted]]


From sabasehrish at yahoo.com  Sun Apr 10 13:26:43 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Sun, 10 Apr 2016 11:26:43 +0000 (UTC)
Subject: [R] working with unequal rows
References: <826830477.151492.1460287603441.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <826830477.151492.1460287603441.JavaMail.yahoo@mail.yahoo.com>

Hi 
I have a data frame with rows specifying companies (codes are assigned to companies) and columns specify months (monthly data). The data is based on male (M) and female (F) information for each month. Following is an example of how my data looks like: 


    01   02   03   04 
001   M   M   M   na 
001   F   M   M   M 
002   M   na   F   F 
003   F   F   F   M 
003   F   F   M   na 
003   M   M   M   M 


na= no male/female. 
Now, I want to firstly add rows with similar codes to see total number of Male and Female in each month for each company. Secondly, I need to calculate fraction of Female in each month (F/ M+F) for each one of these companies. For example, in first month of company 001, there is a male and a female working, so in this month the fraction of female is 0.5. I need to know the coding to get this fraction for my whole data.

Kindly guide me in this regard. 

Thanks 
Saba


From lists at dewey.myzen.co.uk  Sun Apr 10 14:56:42 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 10 Apr 2016 13:56:42 +0100
Subject: [R] working with unequal rows
In-Reply-To: <826830477.151492.1460287603441.JavaMail.yahoo@mail.yahoo.com>
References: <826830477.151492.1460287603441.JavaMail.yahoo.ref@mail.yahoo.com>
	<826830477.151492.1460287603441.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <570A4D8A.1050909@dewey.myzen.co.uk>

Dear Saba

I think the aggregate function is what you need

?aggregate

should help you on the next step

On 10/04/2016 12:26, Saba Sehrish via R-help wrote:
> Hi
> I have a data frame with rows specifying companies (codes are assigned to companies) and columns specify months (monthly data). The data is based on male (M) and female (F) information for each month. Following is an example of how my data looks like:
>
>
>      01   02   03   04
> 001   M   M   M   na
> 001   F   M   M   M
> 002   M   na   F   F
> 003   F   F   F   M
> 003   F   F   M   na
> 003   M   M   M   M
>
>
> na= no male/female.
> Now, I want to firstly add rows with similar codes to see total number of Male and Female in each month for each company. Secondly, I need to calculate fraction of Female in each month (F/ M+F) for each one of these companies. For example, in first month of company 001, there is a male and a female working, so in this month the fraction of female is 0.5. I need to know the coding to get this fraction for my whole data.
>
> Kindly guide me in this regard.
>
> Thanks
> Saba
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jrkrideau at inbox.com  Sun Apr 10 15:16:56 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 10 Apr 2016 05:16:56 -0800
Subject: [R] How to print the graphs in landscape/portrait orientation
In-Reply-To: <CABcx46Dj6RUiro01pMNBdONPu=SqvqNTY9TBh3s_TEaR-tjmgg@mail.gmail.com>
Message-ID: <0FF55CCD04E.000000E8jrkrideau@inbox.com>

There really is nothing there to work with.  Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html


John Kane
Kingston ON Canada


> -----Original Message-----
> From: miaojpm at gmail.com
> Sent: Sat, 9 Apr 2016 14:58:12 -0700
> To: r-help at r-project.org
> Subject: [R] How to print the graphs in landscape/portrait orientation
> 
> Hi,
> 
>    I made a few graphs by ggplot. The following codes produce a pdf file
> with graphs in landscape orientation on my Windows PC, while they produce
> a
> pdf file with the same graphs, but in portrait orientation:
> 
> *p2 <- lapply(1:(2*n), function(.x) xyz_outl[.x][[1]])  #a sequence of
> graphs made by ggplot*
> *m2 <- marrangeGrob(p2, nrow=3, ncol=2)  *
> 
> *ggsave("xyz.pdf", m2)*
> 
>     Question: how can I let the graphs printed in landscape orientation
> on
> my Mac? I try to add the following line before the above code, but it
> does
> not work.
> 
> *pdf(paper = "Usr")*
> 
>    Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Sun Apr 10 15:23:33 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 10 Apr 2016 05:23:33 -0800
Subject: [R] unbalanced number of rows
In-Reply-To: <983927952.162927.1460285833698.JavaMail.yahoo@mail.yahoo.com>
References: <983927952.162927.1460285833698.javamail.yahoo.ref@mail.yahoo.com>
Message-ID: <100428A0A6E.000000F7jrkrideau@inbox.com>

Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html

It looks like you have posted in HTML and the post is close to unreadable.

The data is welcome but we really should have in in dput() form. Do ?dput() for more information.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Sun, 10 Apr 2016 10:57:13 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] unbalanced number of rows
> 
> HiI have a data frame with rows specifying companies (codes are assigned
> to companies) and columns specify months (monthly data). The data is
> based on male (M) and female (F) information for each month. Following is
> an example of how data looks like:
>  01 02 03 04001 na M M M001 M M M F002 M F F na003 M na na M003 F M M
> F003 F F M M
> na= no male/female.
> Now, I want to firstly add rows with similar codes to see total number of
> Male and Female in each month. Secondly, I need to calculate fraction of
> Female in each month (F/ M+F) for these three companies.
> Kindly guide me in this regard.
> ThanksSaba
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From dwinsemius at comcast.net  Sun Apr 10 18:38:34 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 Apr 2016 09:38:34 -0700
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <1460283084042.53401@otago.ac.nz>
References: <1460064106032.30358@otago.ac.nz> <57078E97.1@gmail.com>
	<A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>
	<1460141125051.21413@otago.ac.nz>
	<22281.10422.170427.867866@stat.math.ethz.ch>
	<1460283084042.53401@otago.ac.nz>
Message-ID: <41C35194-1F34-4E62-A46D-F943CFE11BC3@comcast.net>


> On Apr 10, 2016, at 3:11 AM, Murray Efford <murray.efford at otago.ac.nz> wrote:
> 
> Martin -
> Thanks, but although hatvalues() is useful for calculating PRESS, I can't find anything directly relevant to my question in the influence help pages. After some burrowing in the literature I'm doubting there is an answer out there (PRESS R^2 is always presented in a fairly ad hoc way).
> This is a new topic, as you say, and perhaps better handled on a statistics list.
> Murray Efford
> 
> [BTW
> stats ::: influence.lm
> just gets me
> function (model, do.coef = TRUE, ...) 
> lm.influence(model, do.coef = do.coef, ...)
> <bytecode: 0x00000000081023b8>
> <environment: namespace:stats>
> which is not very helpful]

influence.lm is just saying you should be looking at lm.influence

#Try typing:
lm.influence    

Admittedly the meat of that function is probably encapsulated in C with the results delivered by:

      res <- .Call(C_influence, mqr, do.coef, e, tol)

Perhaps looking at:

https://svn.r-project.org/R/trunk/src/library/stats/src/influence.c


I haven't been following the rest of the thread so this is just commenting on your difficulties reading R code.

-- 

David.


> 
> ________________________________________
> From: Martin Maechler <maechler at stat.math.ethz.ch>
> Sent: Sunday, 10 April 2016 4:07 a.m.
> To: Murray Efford
> Cc: peter dalgaard; Duncan Murdoch; r-help at r-project.org
> Subject: Re: [R] R.squared in summary.lm with weights
> 
>>>>>> Murray Efford <murray.efford at otago.ac.nz>
>>>>>>    on Fri, 8 Apr 2016 18:45:33 +0000 writes:
> 
>> Thanks for these perfectly consistent replies - I didn't
>> understand the purpose of m = sum(w * f/sum(w)) and saw it
>> merely as a weighted average of the fitted values.  My
>> ultimate concern is how to compute an appropriate weighted
>> TSS (or equivalently, MSS) for PRESS-R^2 = 1 - PRESS/TSS =
>> 1 - PRESS/ (MSS + PRESS). Do you think it then makes sense
>> to substitute the vector of leave-one-out fitted values
>> for f here?
> 
> --> A new topic really.
> 
> I think you should find the answer on the help pages (and in the
> source) of
> 
>     ? influence.measures  (which documents a host of such functions)
>    and
>     ? influence
> 
> Note that influence is S3 generic and
> 
>   methods(influence)
> 
> indicates that the 'lm' and 'glm' methods are hidden.
> Of course I do recommend reading the real R source code (which
>   also contains the comments and has some logical order in all the
>   function definitions),
> but you can use   stats ::: influence.lm
> to show a version of the function that looks not too different
> from the source.
> 
> Martin Maechler, ETH Zurich
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Apr 10 18:50:13 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 Apr 2016 09:50:13 -0700
Subject: [R] How to print the graphs in landscape/portrait orientation
In-Reply-To: <CABcx46Dj6RUiro01pMNBdONPu=SqvqNTY9TBh3s_TEaR-tjmgg@mail.gmail.com>
References: <CABcx46Dj6RUiro01pMNBdONPu=SqvqNTY9TBh3s_TEaR-tjmgg@mail.gmail.com>
Message-ID: <DF20B980-9661-4E72-A0F2-4105479F867B@comcast.net>


> On Apr 9, 2016, at 2:58 PM, jpm miao <miaojpm at gmail.com> wrote:
> 
> Hi,
> 
>   I made a few graphs by ggplot. The following codes produce a pdf file
> with graphs in landscape orientation on my Windows PC, while they produce a
> pdf file with the same graphs, but in portrait orientation:
> 
> *p2 <- lapply(1:(2*n), function(.x) xyz_outl[.x][[1]])  #a sequence of
> graphs made by ggplot*
> *m2 <- marrangeGrob(p2, nrow=3, ncol=2)  *
> 
> *ggsave("xyz.pdf", m2)*
> 
>    Question: how can I let the graphs printed in landscape orientation on
> my Mac? I try to add the following line before the above code, but it does
> not work.
> 
> *pdf(paper = "Usr")*

The orientation of saved pdf files is determined by the device doing the printing, typically Preview.app on a Mac, and not a feature of the pdf file itself and not specified by ggplot2 functions or by R. So this really is not an R question at all and you should direct subsequent questions to SuperUser.com.


>   Thanks!
> 
> 	[[alternative HTML version deleted]]

And do learn to post in plain text. It's really very easy in gmail.

______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Apr 10 19:10:02 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 Apr 2016 10:10:02 -0700
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
Message-ID: <0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>


> On Apr 10, 2016, at 4:12 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Hello David,
> 
> This is exactly what I want but I still can't get the arrows. R and R studio is updated. Thanks again!

I didn't try it in Rstudio until just now (and I don't remember that you ever mentioned RStudio as a possible issue.) The plotting I see in the default graphics Rstudio window is rather different than what I see in the default plotting window for the R.app GUI. I'm guessing you are reporting results from viewing plots in that IDE's viewing window.

I would try plotting with the png() or pdf() devices and see if the results are more predictable. I just tried with pdf() from RStudio and the results were much closer to what I was seeing with saving from R.app. The `quartz()` device seems to deliver consistent results for me. The RStudio device is something they call RStudioGD, and I don't have sufficient experience to explain its quirks.

-- 
David.

> 
> Sincerely,
> 
> Milu
> 
> On Sat, Apr 9, 2016 at 10:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Apr 9, 2016, at 1:27 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> >
> >> On Apr 9, 2016, at 11:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> >>
> >>
> >>> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >>>
> >>> Dear David,
> >>>
> >>> Thank you for your answer. Sorry for the embarrassing mistake. However, even with when I generate a map for the whole world using:
> >>>
> >>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS Score",colourPalette=colourPalette,
> >>>                     catMethod="fixedWidth", missingCountryCol = "white", addLegend=FALSE)
> >>>
> >>> And then use:
> >>>
> >>> do.call(addMapLegend, c(eps, legendLabels="none", arrows(-100,-140,100,-140,code=3)))
> >>
> >> I do get an arrow using same version of R and OSX. See attached. (I think that png images will be accepted by the mailserver.)
> >
> > Nope I was wrong, but the copy to Milugi did arrive.
> >
> > Here's a (somewhat larger) pdf:
> 
> 
> 
> 
> >
> >
> > --
> > David
> >>
> >>
> >>
> >> --
> >> David.
> >>>
> >>> Only a legend with the colours is generated, no arrows. My session info is below. Thanks again!
> >>>
> >>> R version 3.2.4 (2016-03-10)
> >>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> >>> Running under: OS X 10.11.2 (El Capitan)
> >>>
> >>> locale:
> >>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >>>
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>> other attached packages:
> >>> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2 foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6
> >>> [7] sp_1.2-0
> >>>
> >>> loaded via a namespace (and not attached):
> >>> [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3       gtable_0.2.0     spam_1.3-0
> >>> [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0       fields_8.3-6     colorspace_1.2-6
> >>>
> >>> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >>>
> >>>> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >>>>
> >>>> Forgot to copy the list
> >>>>
> >>>> Dear Jim,
> >>>>
> >>>> Thank you for your reply. I must be doing something wrong, If this is my
> >>>> command to plot a map of Europe:
> >>>>
> >>>> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> >>>> Score - Europe",colourPalette=colourPalette,
> >>>>                           catMethod="fixedWidth", missingCountryCol =
> >>>> "white", mapRegion="Europe", addLegend=FALSE)
> >>>>
> >>>> The following command does not seem to add the arrow. What am I doing wrong?
> >>>>
> >>>> do.call(addMapLegend, c(eps_europe, legendLabels="none",
> >>>> arrows(-100,-140,100,-140,code=3)))
> >>>>
> >>>
> >>> Your earlier question had a full world map. That was the context for Jim's reply, which did plot a two headed arrow above the legend in your earlier question. Now you have restricted the plot region to Europe so the coordinates of -100,-140,100,-140 no longer are on the visible plot area. You need to decide where you want the arrows using sensible coordinates.
> >>>
> >>> --
> >>> David.
> >>>
> >>>
> >>>> Thank you again. I really appreciate it.
> >>>>
> >>>> Sincerely,
> >>>>
> >>>> Milu
> >>>>
> >>>> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>>>
> >>>>> Hi Miluji,
> >>>>> Try this:
> >>>>>
> >>>>> arrows(-100,-140,100,-140,code=3)
> >>>>>
> >>>>> Jim
> >>>>>
> >>>>>
> >>>>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
> >>>>>> I am trying to draw maps for the world using:
> >>>>>>
> >>>>>> library(rworldmap)
> >>>>>> library(maptools)
> >>>>>> library(RColorBrewer)
> >>>>>>
> >>>>>>
> >>>>>> tmp2<- dput(head(pece,10))
> >>>>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> >>>>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> >>>>>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> >>>>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> >>>>> 2.15937495231628
> >>>>>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
> >>>>>> 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
> >>>>>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
> >>>>>> c(13.4375638961792,
> >>>>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> >>>>>> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
> >>>>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
> >>>>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> >>>>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
> >>>>>> 2016 17:43", .Names = c("iso3",
> >>>>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
> >>>>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> >>>>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
> >>>>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
> >>>>>> rd_in_va"
> >>>>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> >>>>>>  c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> >>>>>>  c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
> >>>>>>  "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> >>>>>>  ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
> >>>>>>  "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> >>>>>>  ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> >>>>>>  ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> >>>>>>  "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
> >>>>>>  "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> >>>>>>  "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
> >>>>>>  ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> >>>>>>  "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> >>>>>>  ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> >>>>>> "+1.0000000000000X+000"
> >>>>>>  ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> >>>>>>  c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> >>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> >>>>>> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
> >>>>>> n <- n[-which(row.names(n)=='Antarctica'),]
> >>>>>>
> >>>>>> # EPS
> >>>>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> >>>>>>
> >>>>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> >>>>>> Score",colourPalette=colourPalette,
> >>>>>>                    catMethod="fixedWidth", missingCountryCol =
> >>>>> "white",
> >>>>>> addLegend=FALSE)
> >>>>>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
> >>>>>>
> >>>>>> Instead of adding numeric based legend, I would like to add a two-headed
> >>>>>> arrow with some text. I would be grateful for any help. Thank you!
> >>>>>>
> >>>>>> Sincerely,
> >>>>>>
> >>>>>> Milu
> >>>>>>
> 
> 
> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Apr 10 19:31:05 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 Apr 2016 10:31:05 -0700
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <41C35194-1F34-4E62-A46D-F943CFE11BC3@comcast.net>
References: <1460064106032.30358@otago.ac.nz> <57078E97.1@gmail.com>
	<A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>
	<1460141125051.21413@otago.ac.nz>
	<22281.10422.170427.867866@stat.math.ethz.ch>
	<1460283084042.53401@otago.ac.nz>
	<41C35194-1F34-4E62-A46D-F943CFE11BC3@comcast.net>
Message-ID: <8A101937-9C78-4F70-9BE6-D8ED56A871A4@comcast.net>


> On Apr 10, 2016, at 9:38 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Apr 10, 2016, at 3:11 AM, Murray Efford <murray.efford at otago.ac.nz> wrote:
>> 
>> Martin -
>> Thanks, but although hatvalues() is useful for calculating PRESS, I can't find anything directly relevant to my question in the influence help pages. After some burrowing in the literature I'm doubting there is an answer out there (PRESS R^2 is always presented in a fairly ad hoc way).
>> This is a new topic, as you say, and perhaps better handled on a statistics list.
>> Murray Efford
>> 
>> [BTW
>> stats ::: influence.lm
>> just gets me
>> function (model, do.coef = TRUE, ...) 
>> lm.influence(model, do.coef = do.coef, ...)
>> <bytecode: 0x00000000081023b8>
>> <environment: namespace:stats>
>> which is not very helpful]
> 
> influence.lm is just saying you should be looking at lm.influence
> 
> #Try typing:
> lm.influence    
> 
> Admittedly the meat of that function is probably encapsulated in C with the results delivered by:
> 
>      res <- .Call(C_influence, mqr, do.coef, e, tol)
> 
> Perhaps looking at:
> 
> https://svn.r-project.org/R/trunk/src/library/stats/src/influence.c
> 
> 
> I haven't been following the rest of the thread so this is just commenting on your difficulties reading R code.

When I do attempt filling in blanks in my knowledge regarding PRESS, I am reminded by MarkMail that this question came up 5-6 years ago and I went looking for an answer:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+PRESS#query:list%3Aorg.r-project.r-help%20PRESS+page:1+mid:k2mbz5sov5eo5ejw+state:results

I also see that other packages have implemented PRESS at least as reported by others:

Subject: [R] I need help computing PRESS statistics (qpcR package) of...:
From:	Francisco Goes (xico... at hotmail.com)
Date:	Jun 4, 2014 4:05:03 pm

I tried a current search, although I admit that the fact that "press" is an acronym shared by other topics does seem to complicate that process. I counted 9 packages with PRESS functions even after excluding the ones related to "the Press" and "protein residues" when I did a search with:

sos::findFn("PRESS")

-- 
David.



> 
> -- 
> 
> David.
> 
> 
>> 
>> ________________________________________
>> From: Martin Maechler <maechler at stat.math.ethz.ch>
>> Sent: Sunday, 10 April 2016 4:07 a.m.
>> To: Murray Efford
>> Cc: peter dalgaard; Duncan Murdoch; r-help at r-project.org
>> Subject: Re: [R] R.squared in summary.lm with weights
>> 
>>>>>>> Murray Efford <murray.efford at otago.ac.nz>
>>>>>>>   on Fri, 8 Apr 2016 18:45:33 +0000 writes:
>> 
>>> Thanks for these perfectly consistent replies - I didn't
>>> understand the purpose of m = sum(w * f/sum(w)) and saw it
>>> merely as a weighted average of the fitted values.  My
>>> ultimate concern is how to compute an appropriate weighted
>>> TSS (or equivalently, MSS) for PRESS-R^2 = 1 - PRESS/TSS =
>>> 1 - PRESS/ (MSS + PRESS). Do you think it then makes sense
>>> to substitute the vector of leave-one-out fitted values
>>> for f here?
>> 
>> --> A new topic really.
>> 
>> I think you should find the answer on the help pages (and in the
>> source) of
>> 
>>    ? influence.measures  (which documents a host of such functions)
>>   and
>>    ? influence
>> 
>> Note that influence is S3 generic and
>> 
>>  methods(influence)
>> 
>> indicates that the 'lm' and 'glm' methods are hidden.
>> Of course I do recommend reading the real R source code (which
>>  also contains the comments and has some logical order in all the
>>  function definitions),
>> but you can use   stats ::: influence.lm
>> to show a version of the function that looks not too different
>> from the source.
>> 
>> Martin Maechler, ETH Zurich
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From fabien.tarrade at gmail.com  Sun Apr 10 20:03:23 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Sun, 10 Apr 2016 20:03:23 +0200
Subject: [R] what is the faster way to search for a pattern in a few million
 entries data frame ?
Message-ID: <570A956B.7080305@gmail.com>

Hi there,

I have a data frame DF with 40 millions strings and their frequency. I 
am searching for strings with a given pattern and I am trying to speed 
up this part of my code. I try many options but so far I am not 
satisfied. I tried:
- grepl and subset are equivalent in term of processing time
    grepl(paste0("^",pattern),df$Strings)
    subset(df, grepl(paste0("^",pattern), df$Strings))

- lookup(pattern,df) is not what I am looking for since it is doing an 
exact matching

- I tried to convert my data frame in a data table but it didn't improve 
things (probably read/write of this DT will be much faster)

- the only way I found was to remove 1/3 of the data frame with the 
strings of lowest frequency which speed up the process by a factor x10 !

- didn't try yet parRapply and with a machine with multicore I can get 
another factor.
    I did use parLapply for some other code but I had many issue with 
memory (crashing my Mac).
    I had to sub-divide the dataset to have it working correctly but I 
didn't manage to fully understand the issue.

I am sure their is some other smart way to do that. Any good 
article/blogs or suggestion that can give me some guidance ?

Thanks a lot
Cheers
Fabien

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>


From murdoch.duncan at gmail.com  Sun Apr 10 20:40:24 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Apr 2016 14:40:24 -0400
Subject: [R] what is the faster way to search for a pattern in a few
 million entries data frame ?
In-Reply-To: <570A956B.7080305@gmail.com>
References: <570A956B.7080305@gmail.com>
Message-ID: <570A9E18.5020402@gmail.com>

On 10/04/2016 2:03 PM, Fabien Tarrade wrote:
> Hi there,
>
> I have a data frame DF with 40 millions strings and their frequency. I
> am searching for strings with a given pattern and I am trying to speed
> up this part of my code. I try many options but so far I am not
> satisfied. I tried:
> - grepl and subset are equivalent in term of processing time
>      grepl(paste0("^",pattern),df$Strings)
>      subset(df, grepl(paste0("^",pattern), df$Strings))
>
> - lookup(pattern,df) is not what I am looking for since it is doing an
> exact matching
>
> - I tried to convert my data frame in a data table but it didn't improve
> things (probably read/write of this DT will be much faster)
>
> - the only way I found was to remove 1/3 of the data frame with the
> strings of lowest frequency which speed up the process by a factor x10 !
>
> - didn't try yet parRapply and with a machine with multicore I can get
> another factor.
>      I did use parLapply for some other code but I had many issue with
> memory (crashing my Mac).
>      I had to sub-divide the dataset to have it working correctly but I
> didn't manage to fully understand the issue.
>
> I am sure their is some other smart way to do that. Any good
> article/blogs or suggestion that can give me some guidance ?

Didn't you post the same question yesterday?  Perhaps nobody answered 
because your question is unanswerable.  You need to describe what the 
strings are like and what the patterns are like if you want advice on 
speeding things up.

Duncan Murdoch


From milujisb at gmail.com  Sun Apr 10 22:45:15 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 10 Apr 2016 22:45:15 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
Message-ID: <CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>

Dear David,

The device was the issue. The quartz() device works fine but pdf() does
not. Now I just need to figure out the limits for map for Europe. Thanks
for all your help and patience.

Sincerely,

Milu

On Sun, Apr 10, 2016 at 7:10 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 10, 2016, at 4:12 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Hello David,
> >
> > This is exactly what I want but I still can't get the arrows. R and R
> studio is updated. Thanks again!
>
> I didn't try it in Rstudio until just now (and I don't remember that you
> ever mentioned RStudio as a possible issue.) The plotting I see in the
> default graphics Rstudio window is rather different than what I see in the
> default plotting window for the R.app GUI. I'm guessing you are reporting
> results from viewing plots in that IDE's viewing window.
>
> I would try plotting with the png() or pdf() devices and see if the
> results are more predictable. I just tried with pdf() from RStudio and the
> results were much closer to what I was seeing with saving from R.app. The
> `quartz()` device seems to deliver consistent results for me. The RStudio
> device is something they call RStudioGD, and I don't have sufficient
> experience to explain its quirks.
>
> --
> David.
>
> >
> > Sincerely,
> >
> > Milu
> >
> > On Sat, Apr 9, 2016 at 10:29 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Apr 9, 2016, at 1:27 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> > >
> > >
> > >> On Apr 9, 2016, at 11:18 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> > >>
> > >>
> > >>> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > >>>
> > >>> Dear David,
> > >>>
> > >>> Thank you for your answer. Sorry for the embarrassing mistake.
> However, even with when I generate a map for the whole world using:
> > >>>
> > >>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> Score",colourPalette=colourPalette,
> > >>>                     catMethod="fixedWidth", missingCountryCol =
> "white", addLegend=FALSE)
> > >>>
> > >>> And then use:
> > >>>
> > >>> do.call(addMapLegend, c(eps, legendLabels="none",
> arrows(-100,-140,100,-140,code=3)))
> > >>
> > >> I do get an arrow using same version of R and OSX. See attached. (I
> think that png images will be accepted by the mailserver.)
> > >
> > > Nope I was wrong, but the copy to Milugi did arrive.
> > >
> > > Here's a (somewhat larger) pdf:
> >
> >
> >
> >
> > >
> > >
> > > --
> > > David
> > >>
> > >>
> > >>
> > >> --
> > >> David.
> > >>>
> > >>> Only a legend with the colours is generated, no arrows. My session
> info is below. Thanks again!
> > >>>
> > >>> R version 3.2.4 (2016-03-10)
> > >>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > >>> Running under: OS X 10.11.2 (El Capitan)
> > >>>
> > >>> locale:
> > >>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> > >>>
> > >>> attached base packages:
> > >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> > >>>
> > >>> other attached packages:
> > >>> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2
> foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6
> > >>> [7] sp_1.2-0
> > >>>
> > >>> loaded via a namespace (and not attached):
> > >>> [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3
>    gtable_0.2.0     spam_1.3-0
> > >>> [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0
>    fields_8.3-6     colorspace_1.2-6
> > >>>
> > >>> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > >>>
> > >>>> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > >>>>
> > >>>> Forgot to copy the list
> > >>>>
> > >>>> Dear Jim,
> > >>>>
> > >>>> Thank you for your reply. I must be doing something wrong, If this
> is my
> > >>>> command to plot a map of Europe:
> > >>>>
> > >>>> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS
> > >>>> Score - Europe",colourPalette=colourPalette,
> > >>>>                           catMethod="fixedWidth", missingCountryCol
> =
> > >>>> "white", mapRegion="Europe", addLegend=FALSE)
> > >>>>
> > >>>> The following command does not seem to add the arrow. What am I
> doing wrong?
> > >>>>
> > >>>> do.call(addMapLegend, c(eps_europe, legendLabels="none",
> > >>>> arrows(-100,-140,100,-140,code=3)))
> > >>>>
> > >>>
> > >>> Your earlier question had a full world map. That was the context for
> Jim's reply, which did plot a two headed arrow above the legend in your
> earlier question. Now you have restricted the plot region to Europe so the
> coordinates of -100,-140,100,-140 no longer are on the visible plot area.
> You need to decide where you want the arrows using sensible coordinates.
> > >>>
> > >>> --
> > >>> David.
> > >>>
> > >>>
> > >>>> Thank you again. I really appreciate it.
> > >>>>
> > >>>> Sincerely,
> > >>>>
> > >>>> Milu
> > >>>>
> > >>>> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > >>>>
> > >>>>> Hi Miluji,
> > >>>>> Try this:
> > >>>>>
> > >>>>> arrows(-100,-140,100,-140,code=3)
> > >>>>>
> > >>>>> Jim
> > >>>>>
> > >>>>>
> > >>>>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com>
> wrote:
> > >>>>>> I am trying to draw maps for the world using:
> > >>>>>>
> > >>>>>> library(rworldmap)
> > >>>>>> library(maptools)
> > >>>>>> library(RColorBrewer)
> > >>>>>>
> > >>>>>>
> > >>>>>> tmp2<- dput(head(pece,10))
> > >>>>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> > >>>>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> > >>>>>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> > >>>>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> > >>>>> 2.15937495231628
> > >>>>>> ), gov_eff = c(1.76499999562899, 1.85666667421659,
> 1.74500000476837,
> > >>>>>> 1.88416666785876, 1.99181815710935, 1.21499997377396,
> 0.865833342075348,
> > >>>>>> 1.64999999602636, 2.15416664878527, 1.36833332975705),
> sh_va_enint =
> > >>>>>> c(13.4375638961792,
> > >>>>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> > >>>>>> 13.5679216384888, 9.67090892791748, 10.5978908538818,
> 8.34146690368652
> > >>>>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187,
> 2.53955459594727,
> > >>>>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> > >>>>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp =
> " 9 Mar
> > >>>>>> 2016 17:43", .Names = c("iso3",
> > >>>>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats =
> c("%9s",
> > >>>>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> > >>>>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels =
> c("",
> > >>>>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint",
> "(mean)
> > >>>>>> rd_in_va"
> > >>>>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> > >>>>>>  c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> > >>>>>>  c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
> > >>>>>>  "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> > >>>>>>  ), c("_dta", "__XijVarLabp", "Value"), c("_dta",
> "__XijVarLabpop",
> > >>>>>>  "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> > >>>>>>  ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> > >>>>>>  ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> > >>>>>>  "__XijVarLablp", "Percentage of Primary"), c("_dta",
> "__XijVarLablh",
> > >>>>>>  "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> > >>>>>>  "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of
> Secondary"
> > >>>>>>  ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> > >>>>>>  "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> > >>>>>>  ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> > >>>>>> "+1.0000000000000X+000"
> > >>>>>>  ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> > >>>>>>  c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> > >>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class =
> "data.frame")
> > >>>>>> n <- joinCountryData2Map(pece, joinCode="ISO3",
> nameJoinColumn="iso3")
> > >>>>>> n <- n[-which(row.names(n)=='Antarctica'),]
> > >>>>>>
> > >>>>>> # EPS
> > >>>>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> > >>>>>>
> > >>>>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS
> > >>>>>> Score",colourPalette=colourPalette,
> > >>>>>>                    catMethod="fixedWidth", missingCountryCol =
> > >>>>> "white",
> > >>>>>> addLegend=FALSE)
> > >>>>>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
> > >>>>>>
> > >>>>>> Instead of adding numeric based legend, I would like to add a
> two-headed
> > >>>>>> arrow with some text. I would be grateful for any help. Thank you!
> > >>>>>>
> > >>>>>> Sincerely,
> > >>>>>>
> > >>>>>> Milu
> > >>>>>>
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Apr 11 00:00:36 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 Apr 2016 15:00:36 -0700
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
Message-ID: <3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>



> On Apr 10, 2016, at 1:45 PM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear David,
> 
> The device was the issue. The quartz() device works fine but pdf() does not. Now I just need to figure out the limits for map for Europe. Thanks for all your help and patience. 


After plotting a map of Europe with base graphics the coordinates of the lower-left and upper-right corners are obtained by par('usr')

> par('usr')
[1] -12.20000  47.20000  25.89375  79.10625

-- 
David.


> 
> Sincerely,
> 
> Milu
> 
> On Sun, Apr 10, 2016 at 7:10 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Apr 10, 2016, at 4:12 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Hello David,
> >
> > This is exactly what I want but I still can't get the arrows. R and R studio is updated. Thanks again!
> 
> I didn't try it in Rstudio until just now (and I don't remember that you ever mentioned RStudio as a possible issue.) The plotting I see in the default graphics Rstudio window is rather different than what I see in the default plotting window for the R.app GUI. I'm guessing you are reporting results from viewing plots in that IDE's viewing window.
> 
> I would try plotting with the png() or pdf() devices and see if the results are more predictable. I just tried with pdf() from RStudio and the results were much closer to what I was seeing with saving from R.app. The `quartz()` device seems to deliver consistent results for me. The RStudio device is something they call RStudioGD, and I don't have sufficient experience to explain its quirks.
> 
> --
> David.
> 
> >
> > Sincerely,
> >
> > Milu
> >
> > On Sat, Apr 9, 2016 at 10:29 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Apr 9, 2016, at 1:27 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > >
> > >
> > >> On Apr 9, 2016, at 11:18 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> > >>
> > >>
> > >>> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > >>>
> > >>> Dear David,
> > >>>
> > >>> Thank you for your answer. Sorry for the embarrassing mistake. However, even with when I generate a map for the whole world using:
> > >>>
> > >>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS Score",colourPalette=colourPalette,
> > >>>                     catMethod="fixedWidth", missingCountryCol = "white", addLegend=FALSE)
> > >>>
> > >>> And then use:
> > >>>
> > >>> do.call(addMapLegend, c(eps, legendLabels="none", arrows(-100,-140,100,-140,code=3)))
> > >>
> > >> I do get an arrow using same version of R and OSX. See attached. (I think that png images will be accepted by the mailserver.)
> > >
> > > Nope I was wrong, but the copy to Milugi did arrive.
> > >
> > > Here's a (somewhat larger) pdf:
> >
> >
> >
> >
> > >
> > >
> > > --
> > > David
> > >>
> > >>
> > >>
> > >> --
> > >> David.
> > >>>
> > >>> Only a legend with the colours is generated, no arrows. My session info is below. Thanks again!
> > >>>
> > >>> R version 3.2.4 (2016-03-10)
> > >>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > >>> Running under: OS X 10.11.2 (El Capitan)
> > >>>
> > >>> locale:
> > >>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> > >>>
> > >>> attached base packages:
> > >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> > >>>
> > >>> other attached packages:
> > >>> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2 foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6
> > >>> [7] sp_1.2-0
> > >>>
> > >>> loaded via a namespace (and not attached):
> > >>> [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3       gtable_0.2.0     spam_1.3-0
> > >>> [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0       fields_8.3-6     colorspace_1.2-6
> > >>>
> > >>> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > >>>
> > >>>> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > >>>>
> > >>>> Forgot to copy the list
> > >>>>
> > >>>> Dear Jim,
> > >>>>
> > >>>> Thank you for your reply. I must be doing something wrong, If this is my
> > >>>> command to plot a map of Europe:
> > >>>>
> > >>>> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> > >>>> Score - Europe",colourPalette=colourPalette,
> > >>>>                           catMethod="fixedWidth", missingCountryCol =
> > >>>> "white", mapRegion="Europe", addLegend=FALSE)
> > >>>>
> > >>>> The following command does not seem to add the arrow. What am I doing wrong?
> > >>>>
> > >>>> do.call(addMapLegend, c(eps_europe, legendLabels="none",
> > >>>> arrows(-100,-140,100,-140,code=3)))
> > >>>>
> > >>>
> > >>> Your earlier question had a full world map. That was the context for Jim's reply, which did plot a two headed arrow above the legend in your earlier question. Now you have restricted the plot region to Europe so the coordinates of -100,-140,100,-140 no longer are on the visible plot area. You need to decide where you want the arrows using sensible coordinates.
> > >>>
> > >>> --
> > >>> David.
> > >>>
> > >>>
> > >>>> Thank you again. I really appreciate it.
> > >>>>
> > >>>> Sincerely,
> > >>>>
> > >>>> Milu
> > >>>>
> > >>>> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > >>>>
> > >>>>> Hi Miluji,
> > >>>>> Try this:
> > >>>>>
> > >>>>> arrows(-100,-140,100,-140,code=3)
> > >>>>>
> > >>>>> Jim
> > >>>>>
> > >>>>>
> > >>>>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com> wrote:
> > >>>>>> I am trying to draw maps for the world using:
> > >>>>>>
> > >>>>>> library(rworldmap)
> > >>>>>> library(maptools)
> > >>>>>> library(RColorBrewer)
> > >>>>>>
> > >>>>>>
> > >>>>>> tmp2<- dput(head(pece,10))
> > >>>>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE", "CHL",
> > >>>>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> > >>>>>> 2.68984365463257, 1.31406247615814, 1.98046875, 2.61666655540466,
> > >>>>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> > >>>>> 2.15937495231628
> > >>>>>> ), gov_eff = c(1.76499999562899, 1.85666667421659, 1.74500000476837,
> > >>>>>> 1.88416666785876, 1.99181815710935, 1.21499997377396, 0.865833342075348,
> > >>>>>> 1.64999999602636, 2.15416664878527, 1.36833332975705), sh_va_enint =
> > >>>>>> c(13.4375638961792,
> > >>>>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> > >>>>>> 13.5679216384888, 9.67090892791748, 10.5978908538818, 8.34146690368652
> > >>>>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187, 2.53955459594727,
> > >>>>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> > >>>>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp = " 9 Mar
> > >>>>>> 2016 17:43", .Names = c("iso3",
> > >>>>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats = c("%9s",
> > >>>>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> > >>>>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels = c("",
> > >>>>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint", "(mean)
> > >>>>>> rd_in_va"
> > >>>>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> > >>>>>>  c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> > >>>>>>  c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"), c("_dta",
> > >>>>>>  "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> > >>>>>>  ), c("_dta", "__XijVarLabp", "Value"), c("_dta", "__XijVarLabpop",
> > >>>>>>  "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> > >>>>>>  ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> > >>>>>>  ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> > >>>>>>  "__XijVarLablp", "Percentage of Primary"), c("_dta", "__XijVarLablh",
> > >>>>>>  "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> > >>>>>>  "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of Secondary"
> > >>>>>>  ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> > >>>>>>  "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> > >>>>>>  ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> > >>>>>> "+1.0000000000000X+000"
> > >>>>>>  ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> > >>>>>>  c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> > >>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "data.frame")
> > >>>>>> n <- joinCountryData2Map(pece, joinCode="ISO3", nameJoinColumn="iso3")
> > >>>>>> n <- n[-which(row.names(n)=='Antarctica'),]
> > >>>>>>
> > >>>>>> # EPS
> > >>>>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> > >>>>>>
> > >>>>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> > >>>>>> Score",colourPalette=colourPalette,
> > >>>>>>                    catMethod="fixedWidth", missingCountryCol =
> > >>>>> "white",
> > >>>>>> addLegend=FALSE)
> > >>>>>> do.call(addMapLegend, c(eps, legendLabels="all", legendWidth=0.5))
> > >>>>>>
> > >>>>>> Instead of adding numeric based legend, I would like to add a two-headed
> > >>>>>> arrow with some text. I would be grateful for any help. Thank you!
> > >>>>>>
> > >>>>>> Sincerely,
> > >>>>>>
> > >>>>>> Milu
> > >>>>>>
> >
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From fabien.tarrade at gmail.com  Sun Apr 10 21:27:16 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Sun, 10 Apr 2016 21:27:16 +0200
Subject: [R] what is the faster way to search for a pattern in a few
 million entries data frame ?
In-Reply-To: <570A9E18.5020402@gmail.com>
References: <570A956B.7080305@gmail.com> <570A9E18.5020402@gmail.com>
Message-ID: <570AA914.90303@gmail.com>

Hi Duncan,
> Didn't you post the same question yesterday?  Perhaps nobody answered 
> because your question is unanswerable.
sorry, I got a email that my message was waiting for approval and when I 
look at the forum I didn't see my message and this is why  I sent it 
again and this time I did check that the format of my message was text 
only. Sorry for the noise.
> You need to describe what the strings are like and what the patterns 
> are like if you want advice on speeding things up.
my strings are 1-gram up to 5-grams (sequence of 1 work up to 5 words) 
and I am searching for the frequency in my DF of the strings starting 
with a sequence of few words.

I guess these days it is standard to use DF with millions of entries so 
I was wondering how people are doing that in the faster way.

Thanks
Cheers
Fabien

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : <mailto:contact at fabien-tarrade.eu>contact at fabien-tarrade.eu
Phone : <http://www.fabien-tarrade.eu>www.fabien-tarrade.eu
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>

From antoviral at gmail.com  Mon Apr 11 00:32:27 2016
From: antoviral at gmail.com (Antonello Preti)
Date: Mon, 11 Apr 2016 00:32:27 +0200
Subject: [R] logistic regression with package 'mice'
Message-ID: <CAPmpGDt=8RXy4dC7wC8dKj9v+WHEsrBBmzW_akAfE-tQ_=rd9g@mail.gmail.com>

Dear all, I request your help to solve a problem I've encountered in using
'mice' for multiple imputation.
I want to apply a logistic regression model.
I need to extract information on the fit of the model.
Is there any way to calculate a likelihood ratio or the McFadden-pseudoR2
from the results of the logistic model?
I mean, as it is possible to extract pooled averaging and odds ratio...

Thank you in advance,
Antonello

Here an example of logistic regression on imputed data:


library(mice)

imp <- mice(nhanes)

# logistic regression on the imputed data

fit <- glm.mids((hyp==2)~bmi+chl, data=imp, family = binomial)

summary(fit)

summary(pool(fit)) ### pool averaging across all imputed dataset

summary(pool(fit, method = "rubin1987"))    ### pool across all imputed
dataset

### odds ratio

su <- summary(pool(fit, method = "rubin1987"))[,c(1,6,7)]

stime <- data.frame(exp(su))

names(stime) <- c("OR", "95% low", "95% high")

options(scipen=999)
stime
options(scipen=1)

	[[alternative HTML version deleted]]


From murray.efford at otago.ac.nz  Mon Apr 11 00:39:47 2016
From: murray.efford at otago.ac.nz (Murray Efford)
Date: Sun, 10 Apr 2016 22:39:47 +0000
Subject: [R] R.squared in summary.lm with weights
In-Reply-To: <8A101937-9C78-4F70-9BE6-D8ED56A871A4@comcast.net>
References: <1460064106032.30358@otago.ac.nz> <57078E97.1@gmail.com>
	<A34BDEC1-D385-449E-93E4-4F955561BF2C@gmail.com>
	<1460141125051.21413@otago.ac.nz>
	<22281.10422.170427.867866@stat.math.ethz.ch>
	<1460283084042.53401@otago.ac.nz>
	<41C35194-1F34-4E62-A46D-F943CFE11BC3@comcast.net>,
	<8A101937-9C78-4F70-9BE6-D8ED56A871A4@comcast.net>
Message-ID: <1460327978923.13781@otago.ac.nz>


Among the 6547 matches for 'PRESS' in an sos search I find 7 packages (asbio, DAAG, qpcR, CombMSC, rknn, MPV, mixlm) with a relevant 'press' or 'PRESS' function. Of these only qpcR (PRESS), mixlm (R2pred), and rknn (rqsp) attempt to calculate PRESS R^2, as far as I can tell. None of these confronts the possibility of weights explicitly.

By way of example:

## generate a simple dataset and fit weighted regression
x <- 1:20
df <- data.frame(x = x, y = 2*x + 10* rnorm(20), wt = runif(20) * 10)
fitwt <- lm(y~x, data = df, weights = wt)
fitnowt <- lm(y~x, data = df)

## apply PRESS R^2 methods from 3 packages
otherpressR2 <- function (fit) {
    require(mixlm)
    require(qpcR)
    require(rknn)
    c(qpcR = qpcR::PRESS(fit, verbose = FALSE)$P.square,
      mixlm = mixlm::R2pred(fit),
      rknn = rknn::rsqp(fit))
}
otherpressR2(fitwt)
# qpcR   mixlm    rknn 
# 0.42865 0.56124 0.56124 
# There were 21 warnings (use warnings() to see them)

otherpressR2(fitnowt)
# qpcR   mixlm    rknn 
# 0.59391 0.59391 0.59391 
# There were 21 warnings (use warnings() to see them)

(The warnings from qpcR are not material).

Two different versions of PRESS-R^2 are implemented, and I see no reason to trust either version in the case of weighted regression. The key issue is the appropriate calculation of MSS or TSS as indicated before.

Murray Efford
________________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: Monday, 11 April 2016 5:31 a.m.
To: Murray Efford
Cc: r-help at r-project.org; Martin Maechler; peter dalgaard
Subject: Re: [R] R.squared in summary.lm with weights

> On Apr 10, 2016, at 9:38 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>>
>> On Apr 10, 2016, at 3:11 AM, Murray Efford <murray.efford at otago.ac.nz> wrote:
>>
>> Martin -
>> Thanks, but although hatvalues() is useful for calculating PRESS, I can't find anything directly relevant to my question in the influence help pages. After some burrowing in the literature I'm doubting there is an answer out there (PRESS R^2 is always presented in a fairly ad hoc way).
>> This is a new topic, as you say, and perhaps better handled on a statistics list.
>> Murray Efford
>>
>> [BTW
>> stats ::: influence.lm
>> just gets me
>> function (model, do.coef = TRUE, ...)
>> lm.influence(model, do.coef = do.coef, ...)
>> <bytecode: 0x00000000081023b8>
>> <environment: namespace:stats>
>> which is not very helpful]
>
> influence.lm is just saying you should be looking at lm.influence
>
> #Try typing:
> lm.influence
>
> Admittedly the meat of that function is probably encapsulated in C with the results delivered by:
>
>      res <- .Call(C_influence, mqr, do.coef, e, tol)
>
> Perhaps looking at:
>
> https://svn.r-project.org/R/trunk/src/library/stats/src/influence.c
>
>
> I haven't been following the rest of the thread so this is just commenting on your difficulties reading R code.

When I do attempt filling in blanks in my knowledge regarding PRESS, I am reminded by MarkMail that this question came up 5-6 years ago and I went looking for an answer:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+PRESS#query:list%3Aorg.r-project.r-help%20PRESS+page:1+mid:k2mbz5sov5eo5ejw+state:results

I also see that other packages have implemented PRESS at least as reported by others:

Subject: [R] I need help computing PRESS statistics (qpcR package) of...:
From:   Francisco Goes (xico... at hotmail.com)
Date:   Jun 4, 2014 4:05:03 pm

I tried a current search, although I admit that the fact that "press" is an acronym shared by other topics does seem to complicate that process. I counted 9 packages with PRESS functions even after excluding the ones related to "the Press" and "protein residues" when I did a search with:

sos::findFn("PRESS")

--
David.



>
> --
>
> David.
>
>
>>
>> ________________________________________
>> From: Martin Maechler <maechler at stat.math.ethz.ch>
>> Sent: Sunday, 10 April 2016 4:07 a.m.
>> To: Murray Efford
>> Cc: peter dalgaard; Duncan Murdoch; r-help at r-project.org
>> Subject: Re: [R] R.squared in summary.lm with weights
>>
>>>>>>> Murray Efford <murray.efford at otago.ac.nz>
>>>>>>>   on Fri, 8 Apr 2016 18:45:33 +0000 writes:
>>
>>> Thanks for these perfectly consistent replies - I didn't
>>> understand the purpose of m = sum(w * f/sum(w)) and saw it
>>> merely as a weighted average of the fitted values.  My
>>> ultimate concern is how to compute an appropriate weighted
>>> TSS (or equivalently, MSS) for PRESS-R^2 = 1 - PRESS/TSS =
>>> 1 - PRESS/ (MSS + PRESS). Do you think it then makes sense
>>> to substitute the vector of leave-one-out fitted values
>>> for f here?
>>
>> --> A new topic really.
>>
>> I think you should find the answer on the help pages (and in the
>> source) of
>>
>>    ? influence.measures  (which documents a host of such functions)
>>   and
>>    ? influence
>>
>> Note that influence is S3 generic and
>>
>>  methods(influence)
>>
>> indicates that the 'lm' and 'glm' methods are hidden.
>> Of course I do recommend reading the real R source code (which
>>  also contains the comments and has some logical order in all the
>>  function definitions),
>> but you can use   stats ::: influence.lm
>> to show a version of the function that looks not too different
>> from the source.
>>
>> Martin Maechler, ETH Zurich
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From bgunter.4567 at gmail.com  Mon Apr 11 00:41:10 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 10 Apr 2016 15:41:10 -0700
Subject: [R] what is the faster way to search for a pattern in a few
 million entries data frame ?
In-Reply-To: <570AA914.90303@gmail.com>
References: <570A956B.7080305@gmail.com> <570A9E18.5020402@gmail.com>
	<570AA914.90303@gmail.com>
Message-ID: <CAGxFJbQqcHApifhdpZ2d4fSpVX4uUkASDnMirXTsrDyD+uFVaA@mail.gmail.com>

Fabien:

I was unable to make any sense of your latest response (maybe I'm just
dense). If others have similar difficulties, and you fail to get a
satisfactory response, I suggest that you read and follow the posting
guide's request for a **small, reproducible example* (perhaps the
first few dozen rows of your data frame) in which you show the code
you tried and your desired result.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 10, 2016 at 12:27 PM, Fabien Tarrade
<fabien.tarrade at gmail.com> wrote:
> Hi Duncan,
>>
>> Didn't you post the same question yesterday?  Perhaps nobody answered
>> because your question is unanswerable.
>
> sorry, I got a email that my message was waiting for approval and when I
> look at the forum I didn't see my message and this is why  I sent it again
> and this time I did check that the format of my message was text only. Sorry
> for the noise.
>>
>> You need to describe what the strings are like and what the patterns are
>> like if you want advice on speeding things up.
>
> my strings are 1-gram up to 5-grams (sequence of 1 work up to 5 words) and I
> am searching for the frequency in my DF of the strings starting with a
> sequence of few words.
>
> I guess these days it is standard to use DF with millions of entries so I
> was wondering how people are doing that in the faster way.
>
> Thanks
> Cheers
> Fabien
>
> --
> Dr Fabien Tarrade
>
> Quantitative Analyst/Developer - Data Scientist
>
> Senior data analyst specialised in the modelling, processing and statistical
> treatment of data.
> PhD in Physics, 10 years of experience as researcher at the forefront of
> international scientific research.
> Fascinated by finance and data modelling.
>
> Geneva, Switzerland
>
> Email : <mailto:contact at fabien-tarrade.eu>contact at fabien-tarrade.eu
> Phone : <http://www.fabien-tarrade.eu>www.fabien-tarrade.eu
> Phone : +33 (0)6 14 78 70 90
>
> LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter
> <https://twitter.com/fabtar> Google
> <https://plus.google.com/+FabienTarradeProfile/posts> Facebook
> <https://www.facebook.com/fabien.tarrade.eu> Google <skype:fabtarhiggs?call>
> Xing <https://www.xing.com/profile/Fabien_Tarrade>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Apr 11 00:51:51 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 11 Apr 2016 08:51:51 +1000
Subject: [R] what is the faster way to search for a pattern in a few
 million entries data frame ?
In-Reply-To: <570AA914.90303@gmail.com>
References: <570A956B.7080305@gmail.com> <570A9E18.5020402@gmail.com>
	<570AA914.90303@gmail.com>
Message-ID: <CA+8X3fUnRS7UThLHN9YCASRBDatnZ-qoH+Sh1A3WcrWK_rzcZQ@mail.gmail.com>

Hi Fabien,
I was going to send this last night, but I thought it was too simple.
Runs in about one millisecond.

df<-data.frame(freq=runif(1000),
 strings=apply(matrix(sample(LETTERS,10000,TRUE),ncol=10),
 1,paste,collapse=""))
match.ind<-grep("DF",df$strings)
match.ind
 [1]   2  11  91 133 169 444 547 605 734 943

Jim


On Mon, Apr 11, 2016 at 5:27 AM, Fabien Tarrade
<fabien.tarrade at gmail.com> wrote:
> Hi Duncan,
>>
>> Didn't you post the same question yesterday?  Perhaps nobody answered
>> because your question is unanswerable.
>
> sorry, I got a email that my message was waiting for approval and when I
> look at the forum I didn't see my message and this is why  I sent it again
> and this time I did check that the format of my message was text only. Sorry
> for the noise.
>>
>> You need to describe what the strings are like and what the patterns are
>> like if you want advice on speeding things up.
>
> my strings are 1-gram up to 5-grams (sequence of 1 work up to 5 words) and I
> am searching for the frequency in my DF of the strings starting with a
> sequence of few words.
>
> I guess these days it is standard to use DF with millions of entries so I
> was wondering how people are doing that in the faster way.
>
> Thanks
> Cheers
> Fabien
>
> --
> Dr Fabien Tarrade
>
> Quantitative Analyst/Developer - Data Scientist
>
> Senior data analyst specialised in the modelling, processing and statistical
> treatment of data.
> PhD in Physics, 10 years of experience as researcher at the forefront of
> international scientific research.
> Fascinated by finance and data modelling.
>
> Geneva, Switzerland
>
> Email : <mailto:contact at fabien-tarrade.eu>contact at fabien-tarrade.eu
> Phone : <http://www.fabien-tarrade.eu>www.fabien-tarrade.eu
> Phone : +33 (0)6 14 78 70 90
>
> LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter
> <https://twitter.com/fabtar> Google
> <https://plus.google.com/+FabienTarradeProfile/posts> Facebook
> <https://www.facebook.com/fabien.tarrade.eu> Google <skype:fabtarhiggs?call>
> Xing <https://www.xing.com/profile/Fabien_Tarrade>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fabien.tarrade at gmail.com  Mon Apr 11 00:59:24 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Mon, 11 Apr 2016 00:59:24 +0200
Subject: [R] what is the faster way to search for a pattern in a few
 million entries data frame ?
In-Reply-To: <CA+8X3fUnRS7UThLHN9YCASRBDatnZ-qoH+Sh1A3WcrWK_rzcZQ@mail.gmail.com>
References: <570A956B.7080305@gmail.com> <570A9E18.5020402@gmail.com>
	<570AA914.90303@gmail.com>
	<CA+8X3fUnRS7UThLHN9YCASRBDatnZ-qoH+Sh1A3WcrWK_rzcZQ@mail.gmail.com>
Message-ID: <570ADACC.6010306@gmail.com>

Hi Jim,

I didn't know this one. I will have a look.

Thanks
Cheers
Fabien
> Hi Fabien,
> I was going to send this last night, but I thought it was too simple.
> Runs in about one millisecond.
>
> df<-data.frame(freq=runif(1000),
>   strings=apply(matrix(sample(LETTERS,10000,TRUE),ncol=10),
>   1,paste,collapse=""))
> match.ind<-grep("DF",df$strings)
> match.ind
>   [1]   2  11  91 133 169 444 547 605 734 943
>
> Jim

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>


From martin.morgan at roswellpark.org  Mon Apr 11 01:32:08 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Sun, 10 Apr 2016 19:32:08 -0400
Subject: [R] what is the faster way to search for a pattern in a few
 million entries data frame ?
In-Reply-To: <570AA914.90303@gmail.com>
References: <570A956B.7080305@gmail.com> <570A9E18.5020402@gmail.com>
	<570AA914.90303@gmail.com>
Message-ID: <570AE278.7090407@roswellpark.org>



On 04/10/2016 03:27 PM, Fabien Tarrade wrote:
> Hi Duncan,
>> Didn't you post the same question yesterday?  Perhaps nobody answered
>> because your question is unanswerable.
> sorry, I got a email that my message was waiting for approval and when I
> look at the forum I didn't see my message and this is why  I sent it
> again and this time I did check that the format of my message was text
> only. Sorry for the noise.
>> You need to describe what the strings are like and what the patterns
>> are like if you want advice on speeding things up.
> my strings are 1-gram up to 5-grams (sequence of 1 work up to 5 words)
> and I am searching for the frequency in my DF of the strings starting
> with a sequence of few words.
>
> I guess these days it is standard to use DF with millions of entries so
> I was wondering how people are doing that in the faster way.

I did this to generate and search 40 million unique strings

 > grams <- as.character(1:4e7)        ## a long time passes...
 > system.time(grep("^900001", grams)) ## similar times to grepl
    user  system elapsed
  10.384   0.168  10.543

Is that the basic task you're trying to accomplish? grep(l) goes quickly 
to C, so I don't think data.table or other will be markedly faster if 
you're looking for an arbitrary regular expression (use fixed=TRUE if 
looking for an exact match).

If you're looking for strings that start with a pattern, then in R-3.3.0 
there is

 > system.time(res0 <- startsWith(grams, "900001"))
    user  system elapsed
   0.658   0.012   0.669

which returns the same result as grepl

 > identical(res0, res1 <- grepl("^900001", grams))
[1] TRUE

One can also parallelize the already vectorized grepl function with 
parallel::pvec, with some opportunity for gain (compared to grepl) on 
non-Windows

 > system.time(res2 <- pvec(seq_along(grams), function(i) 
grepl("^900001", grams[i]), mc.cores=8))
    user  system elapsed
  24.996   1.709   3.974
 > identical(res0, res2)
[[1]] TRUE

I think anything else would require pre-processing of some kind, and 
then some more detail about what your data looks like is required.

Martin Morgan

>
> Thanks
> Cheers
> Fabien
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From stefano.sofia at regione.marche.it  Mon Apr 11 09:22:21 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Mon, 11 Apr 2016 07:22:21 +0000
Subject: [R] Query about use of format in strptime
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>

Dear R-list users,
I need to use strptime because I have to deal with date with hours and minutes.
I read the manual for strptime and I also looked at many examples, but when I try to apply it to my code, I always encounter some problems.
I try to change the default format, with no success. Why? How can I change the format?

1.
init_day <- as.factor("2015-02-24-00-30")
strptime(init_day, format="%Y-%m-%d-%H-%M")
[1] "2015-02-24 00:30:00"
It works, but why also seconds are shown if in format seconds are not specified?

2.
init_day <- as.factor("2015-02-24-0-00")
strptime(init_day, format="%Y-%m-%d-%H-%M")
[1] "2015-02-24"
Again, the specified format is not applied. Why?

Thank you for your attention and your help
Stefano


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Apr 11 09:47:55 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 11 Apr 2016 17:47:55 +1000
Subject: [R] Query about use of format in strptime
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>
Message-ID: <CA+8X3fWnb5+eZG1WhaVCwOsrzYZHFjGrN4umxK-18EFLqpkxng@mail.gmail.com>

Hi Stefano,
As the help page says:

"The default for the format methods is "%Y-%m-%d %H:%M:%S" if any
element has a time component which is not midnight, and "%Y-%m-%d"
otherwise. This is because when the result is printed, it uses the
default format. If you want a specified output representation:

format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%M-%d %H:%M")
[1] "2015-30-24 00:30"

For the "midnight" case:

format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%m-%d %H:%M")
[1] "2015-02-24 00:00"

Jim


On Mon, Apr 11, 2016 at 5:22 PM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I need to use strptime because I have to deal with date with hours and minutes.
> I read the manual for strptime and I also looked at many examples, but when I try to apply it to my code, I always encounter some problems.
> I try to change the default format, with no success. Why? How can I change the format?
>
> 1.
> init_day <- as.factor("2015-02-24-00-30")
> strptime(init_day, format="%Y-%m-%d-%H-%M")
> [1] "2015-02-24 00:30:00"
> It works, but why also seconds are shown if in format seconds are not specified?
>
> 2.
> init_day <- as.factor("2015-02-24-0-00")
> strptime(init_day, format="%Y-%m-%d-%H-%M")
> [1] "2015-02-24"
> Again, the specified format is not applied. Why?
>
> Thank you for your attention and your help
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From es at enricoschumann.net  Mon Apr 11 09:55:41 2016
From: es at enricoschumann.net (Enrico Schumann)
Date: Mon, 11 Apr 2016 09:55:41 +0200
Subject: [R] Query about use of format in strptime
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>
	(Stefano Sofia's message of "Mon, 11 Apr 2016 07:22:21 +0000")
References: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>
Message-ID: <878u0k60le.fsf@enricoschumann.net>

On Mon, 11 Apr 2016, Stefano Sofia <stefano.sofia at regione.marche.it> writes:

> Dear R-list users,
> I need to use strptime because I have to deal with date with hours and minutes.
> I read the manual for strptime and I also looked at many examples, but when I try to apply it to my code, I always encounter some problems.
> I try to change the default format, with no success. Why? How can I change the format?
>
> 1.
> init_day <- as.factor("2015-02-24-00-30")
> strptime(init_day, format="%Y-%m-%d-%H-%M")
> [1] "2015-02-24 00:30:00"
> It works, but why also seconds are shown if in format seconds are not specified?
>
> 2.
> init_day <- as.factor("2015-02-24-0-00")
> strptime(init_day, format="%Y-%m-%d-%H-%M")
> [1] "2015-02-24"
> Again, the specified format is not applied. Why?
>
> Thank you for your attention and your help
> Stefano


strptime creates a POSIXlt object, and the specified format
tells it how to interpret the string you pass in. (Your
factor is converted to character by strptime.)

If you want to have the POSIXlt object printed in a
particular way, use ?strftime or ?format.

  > format(strptime(init_day, format="%Y-%m-%d-%H-%M"), "%Y-%m-%d-%H-%M")
  ## [1] "2015-02-24-00-00"


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From stefano.sofia at regione.marche.it  Mon Apr 11 10:48:47 2016
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Mon, 11 Apr 2016 08:48:47 +0000
Subject: [R] Query about use of format in strptime
In-Reply-To: <CA+8X3fWnb5+eZG1WhaVCwOsrzYZHFjGrN4umxK-18EFLqpkxng@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>,
	<CA+8X3fWnb5+eZG1WhaVCwOsrzYZHFjGrN4umxK-18EFLqpkxng@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3DBA7253@ESINO.regionemarche.intra>

Dear Jim and dear Enrico,
thank you for your replies.
Unfortunately your hints didn't solve my problem, and I am getting mad.
Can I show you my whole process? I will be as quick as possible.
I start from a data frame called Snow of the form

year month day hh mm hs
2007 11 19 0 0 0.00
2007 11 19 0 30 0.00
2007 11 19 1 0 0.00
2007 11 19 1 30 0.00
2007 11 19 2 0 0.00
2007 11 19 2 30 0.00
2007 11 19 3 0 0.00
2007 11 19 3 30 0.00
2007 11 19 4 0 0.00
2007 11 19 4 30 0.00
...

whth semi-hourly data.
I need to deal with date so I used strptime:

Snow$data_factor <- as.factor(paste(Snow$year, Snow$month, Snow$day, Snow$hh, Snow$mm, sep="-"))
Snow$data_strptime <- strptime(Snow$data_factor, format = "%Y-%m-%d-%H-%M")

It gives me

year month day hh mm hs  data_factor  data_strptime
1     2007    11  19  0  0  0  2007-11-19-0-0 2007-11-19 00:00:00
2     2007    11  19  0 30  0  2007-11-19-0-30  2007-11-19 00:30:00
3     2007    11  19  1  0  0  2007-11-19-1-0  2007-11-19 01:00:00
4     2007    11  19  1 30  0  2007-11-19-1-30  2007-11-19 01:30:00
5     2007    11  19  2  0  0  2007-11-19-2-0  2007-11-19 02:00:00
6     2007    11  19  2 30  0  2007-11-19-2-30  2007-11-19 02:30:00
7     2007    11  19  3  0  0  2007-11-19-3-0  2007-11-19 03:00:00
8     2007    11  19  3 30  0  2007-11-19-3-30  2007-11-19 03:30:00
9     2007    11  19  4  0  0  2007-11-19-4-0  2007-11-19 04:00:00
10   2007    11  19  4 30  0  2007-11-19-4-30  2007-11-19 04:30:00
...

The type of the column data_strptime is
$data_strptime
[1] "POSIXlt" "POSIXt"

Because of some days (or part of them) might be missing, given a time interval I want to create a new data frame with all time-steps and then merge the new data frame with the old one.
In order to create a new data frame with all time-steps, I thought to use

df_new <- data.frame(data_strptime=seq(init_day, fin_day, by="30 mins"))

and then

Snow_all <- merge(df_new, Snow, by=("data_strptime"), all.x=TRUE)

My problem is in dealing with init_day and fin_day, respectively for example "200711190000" and "200711210000".
I am not able to create a sequence of class "POSIXlt" "POSIXt", in order to merge the two data frames.

Could you please help me in this?
Thank you again for your attention
Stefano


________________________________________
Da: Jim Lemon [drjimlemon at gmail.com]
Inviato: luned? 11 aprile 2016 9.47
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: Re: [R] Query about use of format in strptime

Hi Stefano,
As the help page says:

"The default for the format methods is "%Y-%m-%d %H:%M:%S" if any
element has a time component which is not midnight, and "%Y-%m-%d"
otherwise. This is because when the result is printed, it uses the
default format. If you want a specified output representation:

format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%M-%d %H:%M")
[1] "2015-30-24 00:30"

For the "midnight" case:

format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%m-%d %H:%M")
[1] "2015-02-24 00:00"

Jim


On Mon, Apr 11, 2016 at 5:22 PM, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
> Dear R-list users,
> I need to use strptime because I have to deal with date with hours and minutes.
> I read the manual for strptime and I also looked at many examples, but when I try to apply it to my code, I always encounter some problems.
> I try to change the default format, with no success. Why? How can I change the format?
>
> 1.
> init_day <- as.factor("2015-02-24-00-30")
> strptime(init_day, format="%Y-%m-%d-%H-%M")
> [1] "2015-02-24 00:30:00"
> It works, but why also seconds are shown if in format seconds are not specified?
>
> 2.
> init_day <- as.factor("2015-02-24-0-00")
> strptime(init_day, format="%Y-%m-%d-%H-%M")
> [1] "2015-02-24"
> Again, the specified format is not applied. Why?
>
> Thank you for your attention and your help
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.


From dwinsemius at comcast.net  Mon Apr 11 11:05:02 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 11 Apr 2016 02:05:02 -0700
Subject: [R] Query about use of format in strptime
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBA7253@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>
	<CA+8X3fWnb5+eZG1WhaVCwOsrzYZHFjGrN4umxK-18EFLqpkxng@mail.gmail.com>
	<8B435C9568170B469AE31E8891E8CC4F3DBA7253@ESINO.regionemarche.intra>
Message-ID: <DC0097F1-7DFD-4705-AE55-8023377B0EAB@comcast.net>


> On Apr 11, 2016, at 1:48 AM, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
> 
> Dear Jim and dear Enrico,
> thank you for your replies.
> Unfortunately your hints didn't solve my problem, and I am getting mad.
> Can I show you my whole process? I will be as quick as possible.
> I start from a data frame called Snow of the form
> 
> year month day hh mm hs
> 2007 11 19 0 0 0.00
> 2007 11 19 0 30 0.00
> 2007 11 19 1 0 0.00
> 2007 11 19 1 30 0.00
> 2007 11 19 2 0 0.00
> 2007 11 19 2 30 0.00
> 2007 11 19 3 0 0.00
> 2007 11 19 3 30 0.00
> 2007 11 19 4 0 0.00
> 2007 11 19 4 30 0.00
> ...
> 
> whth semi-hourly data.
> I need to deal with date so I used strptime:
> 
> Snow$data_factor <- as.factor(paste(Snow$year, Snow$month, Snow$day, Snow$hh, Snow$mm, sep="-"))
> Snow$data_strptime <- strptime(Snow$data_factor, format = "%Y-%m-%d-%H-%M")
> 
> It gives me
> 
> year month day hh mm hs  data_factor  data_strptime
> 1     2007    11  19  0  0  0  2007-11-19-0-0 2007-11-19 00:00:00
> 2     2007    11  19  0 30  0  2007-11-19-0-30  2007-11-19 00:30:00
> 3     2007    11  19  1  0  0  2007-11-19-1-0  2007-11-19 01:00:00
> 4     2007    11  19  1 30  0  2007-11-19-1-30  2007-11-19 01:30:00
> 5     2007    11  19  2  0  0  2007-11-19-2-0  2007-11-19 02:00:00
> 6     2007    11  19  2 30  0  2007-11-19-2-30  2007-11-19 02:30:00
> 7     2007    11  19  3  0  0  2007-11-19-3-0  2007-11-19 03:00:00
> 8     2007    11  19  3 30  0  2007-11-19-3-30  2007-11-19 03:30:00
> 9     2007    11  19  4  0  0  2007-11-19-4-0  2007-11-19 04:00:00
> 10   2007    11  19  4 30  0  2007-11-19-4-30  2007-11-19 04:30:00
> ...
> 
> The type of the column data_strptime is
> $data_strptime
> [1] "POSIXlt" "POSIXt"
> 
> Because of some days (or part of them) might be missing, given a time interval I want to create a new data frame with all time-steps and then merge the new data frame with the old one.
> In order to create a new data frame with all time-steps, I thought to use
> 
> df_new <- data.frame(data_strptime=seq(init_day, fin_day, by="30 mins"))
> 
> and then
> 
> Snow_all <- merge(df_new, Snow, by=("data_strptime"), all.x=TRUE)
> 
> My problem is in dealing with  and , respectively for example "200711190000" and "200711210000".
> I am not able to create a sequence of class "POSIXlt" "POSIXt", in order to merge the two data frames.



First you asked about character values with dashes in them and now you want no dashes. Make up our mind:


init_day="200711190000" 
 fin_day="200711210000".
df_new <- data.frame(data_strptime=seq(as.POSIXct(init_day, %Y%M%D%H%M"), 
                                       as.POSIXct(fin_day, %Y%M%D%H%M"), by="30 mins"))

Do NOT use POSIXlt for dataframe columns.

-- 
David.


> 
> Could you please help me in this?
> Thank you again for your attention
> Stefano
> 
> 
> ________________________________________
> Da: Jim Lemon [drjimlemon at gmail.com]
> Inviato: luned? 11 aprile 2016 9.47
> A: Stefano Sofia
> Cc: r-help at r-project.org
> Oggetto: Re: [R] Query about use of format in strptime
> 
> Hi Stefano,
> As the help page says:
> 
> "The default for the format methods is "%Y-%m-%d %H:%M:%S" if any
> element has a time component which is not midnight, and "%Y-%m-%d"
> otherwise. This is because when the result is printed, it uses the
> default format. If you want a specified output representation:
> 
> format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%M-%d %H:%M")
> [1] "2015-30-24 00:30"
> 
> For the "midnight" case:
> 
> format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%m-%d %H:%M")
> [1] "2015-02-24 00:00"
> 
> Jim
> 
> 
> On Mon, Apr 11, 2016 at 5:22 PM, Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
>> Dear R-list users,
>> I need to use strptime because I have to deal with date with hours and minutes.
>> I read the manual for strptime and I also looked at many examples, but when I try to apply it to my code, I always encounter some problems.
>> I try to change the default format, with no success. Why? How can I change the format?
>> 
>> 1.
>> init_day <- as.factor("2015-02-24-00-30")
>> strptime(init_day, format="%Y-%m-%d-%H-%M")
>> [1] "2015-02-24 00:30:00"
>> It works, but why also seconds are shown if in format seconds are not specified?
>> 
>> 2.
>> init_day <- as.factor("2015-02-24-0-00")
>> strptime(init_day, format="%Y-%m-%d-%H-%M")
>> [1] "2015-02-24"
>> Again, the specified format is not applied. Why?
>> 
>> Thank you for your attention and your help
>> Stefano
>> 
>> 
>> ________________________________
>> 
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> 
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Jijo.Sunny at ibsplc.com  Mon Apr 11 12:12:02 2016
From: Jijo.Sunny at ibsplc.com (Jijo Sunny George)
Date: Mon, 11 Apr 2016 10:12:02 +0000
Subject: [R] R cannot allocate a vector of size 5.4mb
Message-ID: <15DCB9C6F4C4BE409E06EE4D88CCE57C016947B237@PBOX2.ibsplc.com>

Hi,

I am trying to do mixed integer programming using R & Java. My input is a list of flight legs which is proportional to the number of times the loop is executed. The input is fed from java to R.
I cannot avoid the for loops as it is part of the logic. I am running into a "cannot allocate a vector of size 5.4mb" error.
The system memory available 16Gb and nearly 11Gb of it is used. I checked on the memory.limit() in R and it is showing as 16Gb.

Can someone guide me with this.

package used to connect r and java  - Rserve
I checked with Rserve developers to reduce the execution time of my loop but after doing that i ran into the above mentioned error

Thanks & Regards
Jijo Sunny


DISCLAIMER: "The information in this e-mail and any atta...{{dropped:12}}


From milujisb at gmail.com  Mon Apr 11 15:50:51 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Mon, 11 Apr 2016 15:50:51 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
	<3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
Message-ID: <CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>

Dear David,

Thank you very much for your replies! I didn't know about par('usr').

I get different coordinates though:

[1] -19.75966  54.75966  33.60000  71.40000

But the arrow is not at the bottom of the map. I will keep playing with
this. Thanks again!

Sincerely,

Milu

On Mon, Apr 11, 2016 at 12:00 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
>
> > On Apr 10, 2016, at 1:45 PM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear David,
> >
> > The device was the issue. The quartz() device works fine but pdf() does
> not. Now I just need to figure out the limits for map for Europe. Thanks
> for all your help and patience.
>
>
> After plotting a map of Europe with base graphics the coordinates of the
> lower-left and upper-right corners are obtained by par('usr')
>
> > par('usr')
> [1] -12.20000  47.20000  25.89375  79.10625
>
> --
> David.
>
>
> >
> > Sincerely,
> >
> > Milu
> >
> > On Sun, Apr 10, 2016 at 7:10 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Apr 10, 2016, at 4:12 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > >
> > > Hello David,
> > >
> > > This is exactly what I want but I still can't get the arrows. R and R
> studio is updated. Thanks again!
> >
> > I didn't try it in Rstudio until just now (and I don't remember that you
> ever mentioned RStudio as a possible issue.) The plotting I see in the
> default graphics Rstudio window is rather different than what I see in the
> default plotting window for the R.app GUI. I'm guessing you are reporting
> results from viewing plots in that IDE's viewing window.
> >
> > I would try plotting with the png() or pdf() devices and see if the
> results are more predictable. I just tried with pdf() from RStudio and the
> results were much closer to what I was seeing with saving from R.app. The
> `quartz()` device seems to deliver consistent results for me. The RStudio
> device is something they call RStudioGD, and I don't have sufficient
> experience to explain its quirks.
> >
> > --
> > David.
> >
> > >
> > > Sincerely,
> > >
> > > Milu
> > >
> > > On Sat, Apr 9, 2016 at 10:29 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > >
> > > > On Apr 9, 2016, at 1:27 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> > > >
> > > >
> > > >> On Apr 9, 2016, at 11:18 AM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > >>
> > > >>
> > > >>> On Apr 9, 2016, at 10:46 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > > >>>
> > > >>> Dear David,
> > > >>>
> > > >>> Thank you for your answer. Sorry for the embarrassing mistake.
> However, even with when I generate a map for the whole world using:
> > > >>>
> > > >>> eps <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS Score",colourPalette=colourPalette,
> > > >>>                     catMethod="fixedWidth", missingCountryCol =
> "white", addLegend=FALSE)
> > > >>>
> > > >>> And then use:
> > > >>>
> > > >>> do.call(addMapLegend, c(eps, legendLabels="none",
> arrows(-100,-140,100,-140,code=3)))
> > > >>
> > > >> I do get an arrow using same version of R and OSX. See attached. (I
> think that png images will be accepted by the mailserver.)
> > > >
> > > > Nope I was wrong, but the copy to Milugi did arrive.
> > > >
> > > > Here's a (somewhat larger) pdf:
> > >
> > >
> > >
> > >
> > > >
> > > >
> > > > --
> > > > David
> > > >>
> > > >>
> > > >>
> > > >> --
> > > >> David.
> > > >>>
> > > >>> Only a legend with the colours is generated, no arrows. My session
> info is below. Thanks again!
> > > >>>
> > > >>> R version 3.2.4 (2016-03-10)
> > > >>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > > >>> Running under: OS X 10.11.2 (El Capitan)
> > > >>>
> > > >>> locale:
> > > >>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> > > >>>
> > > >>> attached base packages:
> > > >>> [1] stats     graphics  grDevices utils     datasets  methods
>  base
> > > >>>
> > > >>> other attached packages:
> > > >>> [1] countrycode_0.18   ggplot2_2.1.0      RColorBrewer_1.1-2
> foreign_0.8-66     maptools_0.8-39    rworldmap_1.3-6
> > > >>> [7] sp_1.2-0
> > > >>>
> > > >>> loaded via a namespace (and not attached):
> > > >>> [1] Rcpp_0.12.4      lattice_0.20-33  grid_3.2.4       plyr_1.8.3
>      gtable_0.2.0     spam_1.3-0
> > > >>> [7] scales_0.4.0     tools_3.2.4      munsell_0.4.3    maps_3.1.0
>      fields_8.3-6     colorspace_1.2-6
> > > >>>
> > > >>> On Sat, Apr 9, 2016 at 7:34 PM, David Winsemius <
> dwinsemius at comcast.net> wrote:
> > > >>>
> > > >>>> On Apr 9, 2016, at 8:13 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > > >>>>
> > > >>>> Forgot to copy the list
> > > >>>>
> > > >>>> Dear Jim,
> > > >>>>
> > > >>>> Thank you for your reply. I must be doing something wrong, If
> this is my
> > > >>>> command to plot a map of Europe:
> > > >>>>
> > > >>>> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS
> > > >>>> Score - Europe",colourPalette=colourPalette,
> > > >>>>                           catMethod="fixedWidth",
> missingCountryCol =
> > > >>>> "white", mapRegion="Europe", addLegend=FALSE)
> > > >>>>
> > > >>>> The following command does not seem to add the arrow. What am I
> doing wrong?
> > > >>>>
> > > >>>> do.call(addMapLegend, c(eps_europe, legendLabels="none",
> > > >>>> arrows(-100,-140,100,-140,code=3)))
> > > >>>>
> > > >>>
> > > >>> Your earlier question had a full world map. That was the context
> for Jim's reply, which did plot a two headed arrow above the legend in your
> earlier question. Now you have restricted the plot region to Europe so the
> coordinates of -100,-140,100,-140 no longer are on the visible plot area.
> You need to decide where you want the arrows using sensible coordinates.
> > > >>>
> > > >>> --
> > > >>> David.
> > > >>>
> > > >>>
> > > >>>> Thank you again. I really appreciate it.
> > > >>>>
> > > >>>> Sincerely,
> > > >>>>
> > > >>>> Milu
> > > >>>>
> > > >>>> On Sat, Apr 9, 2016 at 12:20 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > > >>>>
> > > >>>>> Hi Miluji,
> > > >>>>> Try this:
> > > >>>>>
> > > >>>>> arrows(-100,-140,100,-140,code=3)
> > > >>>>>
> > > >>>>> Jim
> > > >>>>>
> > > >>>>>
> > > >>>>> On Fri, Apr 8, 2016 at 10:24 PM, Miluji Sb <milujisb at gmail.com>
> wrote:
> > > >>>>>> I am trying to draw maps for the world using:
> > > >>>>>>
> > > >>>>>> library(rworldmap)
> > > >>>>>> library(maptools)
> > > >>>>>> library(RColorBrewer)
> > > >>>>>>
> > > >>>>>>
> > > >>>>>> tmp2<- dput(head(pece,10))
> > > >>>>>> structure(list(iso3 = c("AUS", "AUT", "BEL", "CAN", "CHE",
> "CHL",
> > > >>>>>> "CZE", "DEU", "DNK", "ESP"), eps_score = c(0.877343773841858,
> > > >>>>>> 2.68984365463257, 1.31406247615814, 1.98046875,
> 2.61666655540466,
> > > >>>>>> NA, 1.44414067268372, 2.34257817268372, 2.89687490463257,
> > > >>>>> 2.15937495231628
> > > >>>>>> ), gov_eff = c(1.76499999562899, 1.85666667421659,
> 1.74500000476837,
> > > >>>>>> 1.88416666785876, 1.99181815710935, 1.21499997377396,
> 0.865833342075348,
> > > >>>>>> 1.64999999602636, 2.15416664878527, 1.36833332975705),
> sh_va_enint =
> > > >>>>>> c(13.4375638961792,
> > > >>>>>> 8.90904521942139, 10.368335723877, 14.0469560623169, NA, NA,
> > > >>>>>> 13.5679216384888, 9.67090892791748, 10.5978908538818,
> 8.34146690368652
> > > >>>>>> ), rd_in_va = c(2.17547988891602, 2.47147130966187,
> 2.53955459594727,
> > > >>>>>> 2.01138758659363, NA, NA, 1.49587619304657, 2.72330951690674,
> > > >>>>>> 2.5316367149353, 1.48551619052887)), datalabel = "", time.stamp
> = " 9 Mar
> > > >>>>>> 2016 17:43", .Names = c("iso3",
> > > >>>>>> "eps_score", "gov_eff", "sh_va_enint", "rd_in_va"), formats =
> c("%9s",
> > > >>>>>> "%8.0g", "%10.0g", "%9.0g", "%9.0g"), types = c(6L, 254L, 255L,
> > > >>>>>> 254L, 254L), val.labels = c("", "", "", "", ""), var.labels =
> c("",
> > > >>>>>> "(mean) eps_score", "(mean) gov_eff", "(mean) sh_va_enint",
> "(mean)
> > > >>>>>> rd_in_va"
> > > >>>>>> ), expansion.fields = list(c("_dta", "ReS_i", "countrycode"),
> > > >>>>>>  c("_dta", "ReS_ver", "v.2"), c("_dta", "ReS_j", "year"),
> > > >>>>>>  c("_dta", "ReS_str", "0"), c("_dta", "ReS_Xij", "a_"),
> c("_dta",
> > > >>>>>>  "__JVarLab", "ACT"), c("_dta", "__XijVarLabrdd_", "(sum) rdd"
> > > >>>>>>  ), c("_dta", "__XijVarLabp", "Value"), c("_dta",
> "__XijVarLabpop",
> > > >>>>>>  "Population"), c("_dta", "__XijVarLabest_lu_f", "Source of lu"
> > > >>>>>>  ), c("_dta", "__XijVarLablu", "Percentage of No Schooling"
> > > >>>>>>  ), c("_dta", "__XijVarLabest_lp_f", "Source of lp"), c("_dta",
> > > >>>>>>  "__XijVarLablp", "Percentage of Primary"), c("_dta",
> "__XijVarLablh",
> > > >>>>>>  "Percentage of Tertiary"), c("_dta", "__XijVarLabest_lh_f",
> > > >>>>>>  "Source of lh"), c("_dta", "__XijVarLabls", "Percentage of
> Secondary"
> > > >>>>>>  ), c("_dta", "__XijVarLabest_ls_f", "Source of ls"), c("_dta",
> > > >>>>>>  "__XijVarLabvalue", "Value"), c("_dta", "_TStvar", "year"
> > > >>>>>>  ), c("_dta", "_TSpanel", "id2"), c("_dta", "_TSdelta",
> > > >>>>>> "+1.0000000000000X+000"
> > > >>>>>>  ), c("_dta", "_TSitrvl", "1"), c("_dta", "tis", "year"),
> > > >>>>>>  c("_dta", "iis", "id2")), version = 12L, row.names = c("1",
> > > >>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10"), class =
> "data.frame")
> > > >>>>>> n <- joinCountryData2Map(pece, joinCode="ISO3",
> nameJoinColumn="iso3")
> > > >>>>>> n <- n[-which(row.names(n)=='Antarctica'),]
> > > >>>>>>
> > > >>>>>> # EPS
> > > >>>>>> colourPalette <- rev(brewer.pal(7, "RdYlGn"))
> > > >>>>>>
> > > >>>>>> eps <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS
> > > >>>>>> Score",colourPalette=colourPalette,
> > > >>>>>>                    catMethod="fixedWidth", missingCountryCol =
> > > >>>>> "white",
> > > >>>>>> addLegend=FALSE)
> > > >>>>>> do.call(addMapLegend, c(eps, legendLabels="all",
> legendWidth=0.5))
> > > >>>>>>
> > > >>>>>> Instead of adding numeric based legend, I would like to add a
> two-headed
> > > >>>>>> arrow with some text. I would be grateful for any help. Thank
> you!
> > > >>>>>>
> > > >>>>>> Sincerely,
> > > >>>>>>
> > > >>>>>> Milu
> > > >>>>>>
> > >
> > >
> > >
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From fabio.monteiro1992 at gmail.com  Mon Apr 11 15:20:47 2016
From: fabio.monteiro1992 at gmail.com (Fabio Monteiro)
Date: Mon, 11 Apr 2016 14:20:47 +0100
Subject: [R] Correlation between package output
Message-ID: <CAG0T74qaxW5QezD-mw+WHjoHatUq2thVp0yHp0g07T0V9WPQQg@mail.gmail.com>

Hello

I'm currently using the dbFD function of the FD package and i'm having some
things that I can't do.

Is there any way to check the relations between dbFD indexes?

Function cor for example? I can't manage to put the informations correctly

dbFD function gives a lot of output (indexes - nbsp, sing.sp, FRic, FEve,
FDiv, FDis and RaoQ). I want to see the relationships between the dbFD
output (nbsp, sing.sp, FRic, FEve, FDiv, FDis and RaoQ)

How should I type it?

Thank you

F?bio

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Mon Apr 11 16:57:15 2016
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Mon, 11 Apr 2016 07:57:15 -0700
Subject: [R] Is that an efficient way to find the overlapped ,
 upstream and downstream ranges for a bunch of ranges
In-Reply-To: <305EBB12-4F96-4985-B04D-C74D45FBC260@pku.edu.cn>
References: <305EBB12-4F96-4985-B04D-C74D45FBC260@pku.edu.cn>
Message-ID: <CAOQ5Nyeu6=cmf-BW6V27X5C86J4czOaJZFdss92ue+NpCBMD=g@mail.gmail.com>

For the sake of prosterity, this question was asked and answered here:
https://support.bioconductor.org/p/80448

On Tue, Apr 5, 2016 at 10:27 AM, ?? <heyao at pku.edu.cn> wrote:
> I do have a bunch of genes ( nearly ~50000)  from the whole genome, which read in genomic ranges
>
> A range(gene) can be seem as an observation has three columns chromosome, start and end, like that
>
>        seqnames start end width strand
>
> gene1     chr1     1   5     5      +
>
> gene2     chr1    10  15     6      +
>
> gene3     chr1    12  17     6      +
>
> gene4     chr1    20  25     6      +
>
> gene5     chr1    30  40    11      +
>
> I just wondering is there an efficient way to find overlapped, upstream and downstream genes for each gene in the granges
>
> For example, assuming all_genes_gr is a ~50000 genes genomic range, the result I want like belows:
>
> gene_nameupstream_genedownstream_geneoverlapped_gene
> gene1NAgene2NA
> gene2gene1gene4gene3
> gene3gene1gene4gene2
> gene4gene3gene5NA
>
> Currently ,  the strategy I use is like that,
> library(GenomicRanges)
> find_overlapped_gene <- function(idx, all_genes_gr) {
>   #cat(idx, "\n")
>   curr_gene <- all_genes_gr[idx]
>   other_genes <- all_genes_gr[-idx]
>   n <- countOverlaps(curr_gene, other_genes)
>   gene <- subsetByOverlaps(curr_gene, other_genes)
>   return(list(n, gene))
> }
>
> system.time(lapply(1:100, function(idx)  find_overlapped_gene(idx, all_genes_gr)))
> However, for 100 genes, it use nearly ~8s by system.time().That means if I had 50000 genes, nearly one hour for just find overlapped gene.
>
> I am just wondering any algorithm or strategy to do that efficiently, perhaps 50000 genes in ~10min or even less
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Mon Apr 11 17:27:38 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 11 Apr 2016 16:27:38 +0100
Subject: [R] write a function inside the summation in a more condensed
 form
In-Reply-To: <64637103.134972.1460123686728.JavaMail.yahoo@mail.yahoo.com>
References: <64637103.134972.1460123686728.JavaMail.yahoo.ref@mail.yahoo.com>
	<64637103.134972.1460123686728.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403D134DD45@GBTEDVPEXCMB04.corp.lgc-group.com>

>  I want to write the inside function (3^(x[i]+x[j])) in a more condensed form
> cause this will help me when the multiple summations are more than two

indices<-c(i,j) #or whatever you want
3^sum( x[indices] )

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From mikedeanza at outlook.com  Mon Apr 11 17:03:27 2016
From: mikedeanza at outlook.com (Mike Deanza)
Date: Mon, 11 Apr 2016 15:03:27 +0000
Subject: [R] [VC++ calling R] How to create a real-time interactive ticking
 time-series chart using dygraph via RInside?
Message-ID: <CY1PR0201MB1818D3AEBC4F2B87B0A9C328C3940@CY1PR0201MB1818.namprd02.prod.outlook.com>

Hi all,


I am trying to figure out how to do this in R and I need your help.


My journey started from something like the following:


http://stackoverflow.com/questions/11365857/real-time-auto-updating-incremental-plot-in-r/1#1


n=1000
df=data.frame(time=1:n,y=runif(n))
window=100
for(i in 1:(n?\window)) {
flush.console()
plot(df$time,df$y,type='l',xlim=c(i,i+window))
Sys.sleep(.09)
}


Then I wanted to make it nicer looking so I went to dygraph.


And then, I would like to be able to live send tick data from within Visual C++ so I started to investigate RInside.


Following the example code here:


http://dirk.eddelbuettel.com/papers/useR2009RcppRInside.pdf


I can open an RInside object in VC++, and then send some data to it, and then execute some command in it, and then get data back.


It is really great.


However, is there a way to have the real-time updating ticking plots to be drawn on dygraph inside RInside?


It turns out the dygraph package tends to draw onto a browser. That makes the real-time updating pretty slow.


Is there a way to set the dygraph to plot to a GUI window in VC++? For example, a QT or MFC GUI window?


My working environment is Win7 64bit ,with VS 2013 and VS2015, QT 5.3 32bit.


Could anybody please shed some lights on me?


Thanks a lot!







	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Mon Apr 11 17:10:46 2016
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 11 Apr 2016 10:10:46 -0500
Subject: [R] [R-SIG-Finance] [VC++ calling R] How to create a real-time
 interactive ticking time-series chart using dygraph via RInside?
In-Reply-To: <CY1PR0201MB1818D3AEBC4F2B87B0A9C328C3940@CY1PR0201MB1818.namprd02.prod.outlook.com>
References: <CY1PR0201MB1818D3AEBC4F2B87B0A9C328C3940@CY1PR0201MB1818.namprd02.prod.outlook.com>
Message-ID: <CAPPM_gSXWwYSY+s8iwaa5G3jxM=72aGwOy3p_+aA7tidZ8qP4g@mail.gmail.com>

Please choose *one* _relevant_ mailing list.  Spamming 5 (!!!!!)
mailing lists fragments the conversation and makes things difficult
for everyone involved.

On Mon, Apr 11, 2016 at 10:03 AM, Mike Deanza <mikedeanza at outlook.com> wrote:
> Hi all,
>
>
> I am trying to figure out how to do this in R and I need your help.
>
>
> My journey started from something like the following:
>
>
> http://stackoverflow.com/questions/11365857/real-time-auto-updating-incremental-plot-in-r/1#1
>
>
> n=1000
> df=data.frame(time=1:n,y=runif(n))
> window=100
> for(i in 1:(n?\window)) {
> flush.console()
> plot(df$time,df$y,type='l',xlim=c(i,i+window))
> Sys.sleep(.09)
> }
>
>
> Then I wanted to make it nicer looking so I went to dygraph.
>
>
> And then, I would like to be able to live send tick data from within Visual C++ so I started to investigate RInside.
>
>
> Following the example code here:
>
>
> http://dirk.eddelbuettel.com/papers/useR2009RcppRInside.pdf
>
>
> I can open an RInside object in VC++, and then send some data to it, and then execute some command in it, and then get data back.
>
>
> It is really great.
>
>
> However, is there a way to have the real-time updating ticking plots to be drawn on dygraph inside RInside?
>
>
> It turns out the dygraph package tends to draw onto a browser. That makes the real-time updating pretty slow.
>
>
> Is there a way to set the dygraph to plot to a GUI window in VC++? For example, a QT or MFC GUI window?
>
>
> My working environment is Win7 64bit ,with VS 2013 and VS2015, QT 5.3 32bit.
>
>
> Could anybody please shed some lights on me?
>
>
> Thanks a lot!
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-SIG-Finance at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance
> -- Subscriber-posting only. If you want to post, subscribe first.
> -- Also note that this is not the r-help list where general R questions should go.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2016 | www.rinfinance.com


From macqueen1 at llnl.gov  Mon Apr 11 18:20:48 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 11 Apr 2016 16:20:48 +0000
Subject: [R] Query about use of format in strptime
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3DBA7253@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3DBA7224@ESINO.regionemarche.intra>
	<CA+8X3fWnb5+eZG1WhaVCwOsrzYZHFjGrN4umxK-18EFLqpkxng@mail.gmail.com>
	<8B435C9568170B469AE31E8891E8CC4F3DBA7253@ESINO.regionemarche.intra>
Message-ID: <D3311BAC.16A019%macqueen1@llnl.gov>

First I added one row to your data, to illustrate a case with missing
times:

year month day hh mm hs
2007 11 19 0 0 0.00
2007 11 19 0 30 0.00
2007 11 19 1 0 0.00
2007 11 19 1 30 0.00
2007 11 19 2 0 0.00
2007 11 19 2 30 0.00
2007 11 19 3 0 0.00
2007 11 19 3 30 0.00
2007 11 19 4 0 0.00
2007 11 19 4 30 0.00
2007 11 19 6 30 0.00

(and I put it in a separate file named snowday.dat)

Then try this:

sd <- read.table('snowday.dat', sep=' ', head=TRUE)
sd$tm <- as.POSIXct( paste(sd$year, sd$month, sd$day, sd$hh, sd$mm,
sep='-'), format='%Y-%m-%d-%H-%M')
dft <- data.frame( tm=seq(min(sd$tm), max(sd$tm), by='30 min') )
sd <- merge(sd, dft, all=TRUE)



This appears to do what you are asking for (if I understand correctly).

> sd
                    tm year month day hh mm hs
1  2007-11-19 00:00:00 2007    11  19  0  0  0
2  2007-11-19 00:30:00 2007    11  19  0 30  0
3  2007-11-19 01:00:00 2007    11  19  1  0  0
4  2007-11-19 01:30:00 2007    11  19  1 30  0
5  2007-11-19 02:00:00 2007    11  19  2  0  0
6  2007-11-19 02:30:00 2007    11  19  2 30  0
7  2007-11-19 03:00:00 2007    11  19  3  0  0
8  2007-11-19 03:30:00 2007    11  19  3 30  0
9  2007-11-19 04:00:00 2007    11  19  4  0  0
10 2007-11-19 04:30:00 2007    11  19  4 30  0
11 2007-11-19 05:00:00   NA    NA  NA NA NA NA
12 2007-11-19 05:30:00   NA    NA  NA NA NA NA
13 2007-11-19 06:00:00   NA    NA  NA NA NA NA
14 2007-11-19 06:30:00 2007    11  19  6 30  0



Notes:
There is no need to use factor()
As David said, don't use POSIXlt. Use POSIXct instead.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/11/16, 1:48 AM, "R-help on behalf of Stefano Sofia"
<r-help-bounces at r-project.org on behalf of
stefano.sofia at regione.marche.it> wrote:

>Dear Jim and dear Enrico,
>thank you for your replies.
>Unfortunately your hints didn't solve my problem, and I am getting mad.
>Can I show you my whole process? I will be as quick as possible.
>I start from a data frame called Snow of the form
>
>year month day hh mm hs
>2007 11 19 0 0 0.00
>2007 11 19 0 30 0.00
>2007 11 19 1 0 0.00
>2007 11 19 1 30 0.00
>2007 11 19 2 0 0.00
>2007 11 19 2 30 0.00
>2007 11 19 3 0 0.00
>2007 11 19 3 30 0.00
>2007 11 19 4 0 0.00
>2007 11 19 4 30 0.00
>...
>
>whth semi-hourly data.
>I need to deal with date so I used strptime:
>
>Snow$data_factor <- as.factor(paste(Snow$year, Snow$month, Snow$day,
>Snow$hh, Snow$mm, sep="-"))
>Snow$data_strptime <- strptime(Snow$data_factor, format =
>"%Y-%m-%d-%H-%M")
>
>It gives me
>
>year month day hh mm hs  data_factor  data_strptime
>1     2007    11  19  0  0  0  2007-11-19-0-0 2007-11-19 00:00:00
>2     2007    11  19  0 30  0  2007-11-19-0-30  2007-11-19 00:30:00
>3     2007    11  19  1  0  0  2007-11-19-1-0  2007-11-19 01:00:00
>4     2007    11  19  1 30  0  2007-11-19-1-30  2007-11-19 01:30:00
>5     2007    11  19  2  0  0  2007-11-19-2-0  2007-11-19 02:00:00
>6     2007    11  19  2 30  0  2007-11-19-2-30  2007-11-19 02:30:00
>7     2007    11  19  3  0  0  2007-11-19-3-0  2007-11-19 03:00:00
>8     2007    11  19  3 30  0  2007-11-19-3-30  2007-11-19 03:30:00
>9     2007    11  19  4  0  0  2007-11-19-4-0  2007-11-19 04:00:00
>10   2007    11  19  4 30  0  2007-11-19-4-30  2007-11-19 04:30:00
>...
>
>The type of the column data_strptime is
>$data_strptime
>[1] "POSIXlt" "POSIXt"
>
>Because of some days (or part of them) might be missing, given a time
>interval I want to create a new data frame with all time-steps and then
>merge the new data frame with the old one.
>In order to create a new data frame with all time-steps, I thought to use
>
>df_new <- data.frame(data_strptime=seq(init_day, fin_day, by="30 mins"))
>
>and then
>
>Snow_all <- merge(df_new, Snow, by=("data_strptime"), all.x=TRUE)
>
>My problem is in dealing with init_day and fin_day, respectively for
>example "200711190000" and "200711210000".
>I am not able to create a sequence of class "POSIXlt" "POSIXt", in order
>to merge the two data frames.
>
>Could you please help me in this?
>Thank you again for your attention
>Stefano
>
>
>________________________________________
>Da: Jim Lemon [drjimlemon at gmail.com]
>Inviato: luned? 11 aprile 2016 9.47
>A: Stefano Sofia
>Cc: r-help at r-project.org
>Oggetto: Re: [R] Query about use of format in strptime
>
>Hi Stefano,
>As the help page says:
>
>"The default for the format methods is "%Y-%m-%d %H:%M:%S" if any
>element has a time component which is not midnight, and "%Y-%m-%d"
>otherwise. This is because when the result is printed, it uses the
>default format. If you want a specified output representation:
>
>format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%M-%d %H:%M")
>[1] "2015-30-24 00:30"
>
>For the "midnight" case:
>
>format(strptime(init_day, format="%Y-%m-%d-%H-%M"),"%Y-%m-%d %H:%M")
>[1] "2015-02-24 00:00"
>
>Jim
>
>
>On Mon, Apr 11, 2016 at 5:22 PM, Stefano Sofia
><stefano.sofia at regione.marche.it> wrote:
>> Dear R-list users,
>> I need to use strptime because I have to deal with date with hours and
>>minutes.
>> I read the manual for strptime and I also looked at many examples, but
>>when I try to apply it to my code, I always encounter some problems.
>> I try to change the default format, with no success. Why? How can I
>>change the format?
>>
>> 1.
>> init_day <- as.factor("2015-02-24-00-30")
>> strptime(init_day, format="%Y-%m-%d-%H-%M")
>> [1] "2015-02-24 00:30:00"
>> It works, but why also seconds are shown if in format seconds are not
>>specified?
>>
>> 2.
>> init_day <- as.factor("2015-02-24-0-00")
>> strptime(init_day, format="%Y-%m-%d-%H-%M")
>> [1] "2015-02-24"
>> Again, the specified format is not applied. Why?
>>
>> Thank you for your attention and your help
>> Stefano
>>
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>>informazioni confidenziali, pertanto ? destinato solo a persone
>>autorizzate alla ricezione. I messaggi di posta elettronica per i client
>>di Regione Marche possono contenere informazioni confidenziali e con
>>privilegi legali. Se non si ? il destinatario specificato, non leggere,
>>copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto
>>questo messaggio per errore, inoltrarlo al mittente ed eliminarlo
>>completamente dal sistema del proprio computer. Ai sensi dell?art. 6
>>della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza,
>>la risposta al presente messaggio di posta elettronica pu? essere
>>visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>>by persons entitled to receive the confidential information it may
>>contain. E-mail messages to clients of Regione Marche may contain
>>information that is confidential and legally privileged. Please do not
>>read, copy, forward, or store this message unless you are an intended
>>recipient of it. If you have received this message in error, please
>>forward it to the sender and delete it completely from your computer
>>system.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate alla ricezione. I messaggi di posta elettronica per i client
>di Regione Marche possono contenere informazioni confidenziali e con
>privilegi legali. Se non si ? il destinatario specificato, non leggere,
>copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo
>messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente
>dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n.
>1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al
>presente messaggio di posta elettronica pu? essere visionata da persone
>estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only by
>persons entitled to receive the confidential information it may contain.
>E-mail messages to clients of Regione Marche may contain information that
>is confidential and legally privileged. Please do not read, copy,
>forward, or store this message unless you are an intended recipient of
>it. If you have received this message in error, please forward it to the
>sender and delete it completely from your computer system.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From apa at stowers.org  Mon Apr 11 18:30:29 2016
From: apa at stowers.org (Paulson, Ariel)
Date: Mon, 11 Apr 2016 16:30:29 +0000
Subject: [R] [FORGED] Re:  identical() versus sapply()
In-Reply-To: <5708D8F8.3020701@auckland.ac.nz>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
Message-ID: <6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>

Ok, I see the difference between 1 and 1:2, I'll just leave it as one of those "only in R" things.

But it seems then, that as.numeric() should guarantee a FALSE outcome, yet it does not. 

To build on what Rolf pointed out, I would really love for someone to explain this one:

> str(1)
 num 1

> str(1:2)
 int [1:2] 1 2

> str(as.numeric(1:2))
 num [1:2] 1 2

> str(as(1:2,"numeric"))
 int [1:2] 1 2

Which doubly makes no sense.  1) Either the class is "numeric" or it isn't; I did not call as.integer() here.  2) method of recasting should not affect final class.

Thanks,
Ariel


-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz] 
Sent: Saturday, April 09, 2016 5:27 AM
To: Jeff Newmiller
Cc: Paulson, Ariel; 'r-help at r-project.org'
Subject: Re: [FORGED] Re: [R] identical() versus sapply()

On 09/04/16 16:24, Jeff Newmiller wrote:
> I highly recommend making friends with the str function. Try
>
> str( 1 )
> str( 1:2 )

Interesting.  But to me counter-intuitive.  Since R makes no distinction between scalars and vectors of length 1 (or more accurately I think, since in R there is *no such thing as a scalar*, only a vector of length
1) I don't see why "1" should be treated in a manner that is categorically different from the way in which "1:2" is treated.

Can you, or someone else with deep insight into R and its rationale, explain the basis for this difference in treatment?

> for the clue you need, and then
>
> sapply( 1:2, identical, 1L )

cheers,

Rolf

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Mon Apr 11 21:36:56 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 11 Apr 2016 12:36:56 -0700
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
Message-ID: <CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>

Indeed!

Slightly simplified to emphasize your point:

> class(as(1:2,"numeric"))
[1] "integer"

> class(as.numeric(1:2))
[1] "numeric"

whereas in ?as it says:

"Methods are pre-defined for coercing any object to one of the basic
datatypes. For example, as(x, "numeric") uses the existing as.numeric
function. "

I suspect this is related to my ignorance of S4 classes (i.e. as() )
and how they relate to S3 classes, but I certainly don't get it
either.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org> wrote:
> Ok, I see the difference between 1 and 1:2, I'll just leave it as one of those "only in R" things.
>
> But it seems then, that as.numeric() should guarantee a FALSE outcome, yet it does not.
>
> To build on what Rolf pointed out, I would really love for someone to explain this one:
>
>> str(1)
>  num 1
>
>> str(1:2)
>  int [1:2] 1 2
>
>> str(as.numeric(1:2))
>  num [1:2] 1 2
>
>> str(as(1:2,"numeric"))
>  int [1:2] 1 2
>
> Which doubly makes no sense.  1) Either the class is "numeric" or it isn't; I did not call as.integer() here.  2) method of recasting should not affect final class.
>
> Thanks,
> Ariel
>
>
> -----Original Message-----
> From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
> Sent: Saturday, April 09, 2016 5:27 AM
> To: Jeff Newmiller
> Cc: Paulson, Ariel; 'r-help at r-project.org'
> Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>
> On 09/04/16 16:24, Jeff Newmiller wrote:
>> I highly recommend making friends with the str function. Try
>>
>> str( 1 )
>> str( 1:2 )
>
> Interesting.  But to me counter-intuitive.  Since R makes no distinction between scalars and vectors of length 1 (or more accurately I think, since in R there is *no such thing as a scalar*, only a vector of length
> 1) I don't see why "1" should be treated in a manner that is categorically different from the way in which "1:2" is treated.
>
> Can you, or someone else with deep insight into R and its rationale, explain the basis for this difference in treatment?
>
>> for the clue you need, and then
>>
>> sapply( 1:2, identical, 1L )
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Apr 11 23:48:22 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 12 Apr 2016 07:48:22 +1000
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
	<3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
	<CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>
Message-ID: <CA+8X3fXaHp6aiZ0K+B3Wv_zw=s1gW0neD_QDt7kW5LunHE5WLg@mail.gmail.com>

Hi Milu,
I just realized that by "the bottom of the map" you may mean "beneath
the map", in which case you should use:

par(xpd=TRUE)
arrows(...)
par(xpd=FALSE)

Jim

On Mon, Apr 11, 2016 at 11:50 PM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear David,
>
> Thank you very much for your replies! I didn't know about par('usr').
>
> I get different coordinates though:
>
> [1] -19.75966  54.75966  33.60000  71.40000
>
> But the arrow is not at the bottom of the map. I will keep playing with
> this. Thanks again!
>
> Sincerely,
>
> Milu
>


From highstat at highstat.com  Tue Apr 12 00:44:11 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 11 Apr 2016 23:44:11 +0100
Subject: [R] Intro GAM and GAMM course: Singapore
Message-ID: <570C28BB.1050903@highstat.com>



There are 4 remaining seats on the following statistics course:

Course: Introduction to GAM and GAMM with R
When: 30 May-3 June 2016
Where: Tropical Marine Science Institute, National University of 
Singapore, Singapore
Course website: http://highstat.com/statscourse.htm
Course flyer: http://highstat.com/Courses/Flyers/Flyer2016_05Singapore.pdf



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From jdnewmil at dcn.davis.ca.us  Tue Apr 12 01:49:39 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 11 Apr 2016 16:49:39 -0700
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
Message-ID: <D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>

Hypothesis regarding the thought process: integer is a perfect subset of numeric, so why split hairs? 
-- 
Sent from my phone. Please excuse my brevity.

On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Indeed!
>
>Slightly simplified to emphasize your point:
>
>> class(as(1:2,"numeric"))
>[1] "integer"
>
>> class(as.numeric(1:2))
>[1] "numeric"
>
>whereas in ?as it says:
>
>"Methods are pre-defined for coercing any object to one of the basic
>datatypes. For example, as(x, "numeric") uses the existing as.numeric
>function. "
>
>I suspect this is related to my ignorance of S4 classes (i.e. as() )
>and how they relate to S3 classes, but I certainly don't get it
>either.
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org>
>wrote:
>> Ok, I see the difference between 1 and 1:2, I'll just leave it as one
>of those "only in R" things.
>>
>> But it seems then, that as.numeric() should guarantee a FALSE
>outcome, yet it does not.
>>
>> To build on what Rolf pointed out, I would really love for someone to
>explain this one:
>>
>>> str(1)
>>  num 1
>>
>>> str(1:2)
>>  int [1:2] 1 2
>>
>>> str(as.numeric(1:2))
>>  num [1:2] 1 2
>>
>>> str(as(1:2,"numeric"))
>>  int [1:2] 1 2
>>
>> Which doubly makes no sense.  1) Either the class is "numeric" or it
>isn't; I did not call as.integer() here.  2) method of recasting should
>not affect final class.
>>
>> Thanks,
>> Ariel
>>
>>
>> -----Original Message-----
>> From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>> Sent: Saturday, April 09, 2016 5:27 AM
>> To: Jeff Newmiller
>> Cc: Paulson, Ariel; 'r-help at r-project.org'
>> Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>>
>> On 09/04/16 16:24, Jeff Newmiller wrote:
>>> I highly recommend making friends with the str function. Try
>>>
>>> str( 1 )
>>> str( 1:2 )
>>
>> Interesting.  But to me counter-intuitive.  Since R makes no
>distinction between scalars and vectors of length 1 (or more accurately
>I think, since in R there is *no such thing as a scalar*, only a vector
>of length
>> 1) I don't see why "1" should be treated in a manner that is
>categorically different from the way in which "1:2" is treated.
>>
>> Can you, or someone else with deep insight into R and its rationale,
>explain the basis for this difference in treatment?
>>
>>> for the clue you need, and then
>>>
>>> sapply( 1:2, identical, 1L )
>>
>> cheers,
>>
>> Rolf
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From apa at stowers.org  Tue Apr 12 02:25:09 2016
From: apa at stowers.org (Paulson, Ariel)
Date: Tue, 12 Apr 2016 00:25:09 +0000
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>,
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
Message-ID: <1460420710420.50418@stowers.org>

Hi Jeff,


We are splitting hairs because R is splitting hairs, and causing us problems.  Integer and numeric are different R classes with different properties, mathematical relationships notwithstanding.  For instance, the counterintuitive result:


> identical(as.integer(1), as.numeric(1))
[1] FALSE


Unfortunately the reply-to chain doesn't extend far enough -- here is the original problem:


> sapply(1, identical, 1)
[1] TRUE

> sapply(1:2, identical, 1)
[1] FALSE FALSE

> sapply(1:2, function(i) identical(as.numeric(i),1) )
[1]  TRUE FALSE

> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
[1] FALSE FALSE

These are the results of R's hair-splitting!

Ariel

________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Monday, April 11, 2016 6:49 PM
To: Bert Gunter; Paulson, Ariel
Cc: Rolf Turner; r-help at r-project.org
Subject: Re: [R] [FORGED] Re: identical() versus sapply()

Hypothesis regarding the thought process: integer is a perfect subset of numeric, so why split hairs?
--
Sent from my phone. Please excuse my brevity.

On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:

Indeed!

Slightly simplified to emphasize your point:

 class(as(1:2,"numeric"))
[1] "integer"

 class(as.numeric(1:2))
[1] "numeric"

whereas in ?as it says:

"Methods are pre-defined for coercing any object to one of the basic
datatypes. For example, as(x, "numeric") uses the existing as.numeric
function. "

I suspect this is related to my ignorance of S4 classes (i.e. as() )
and how they relate to S3 classes, but I certainly don't get it
either.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things
into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org> wrote:
 Ok, I see the difference between 1 and 1:2, I'll just leave it as one of those "only in R" things.

 But it seems then, that as.numeric() should guarantee a FALSE outcome, yet it does not.

 To build on what Rolf pointed out, I would really love for someone to explain this one:

 str(1)
  num 1

 str(1:2)
  int [1:2] 1 2

 str(as.numeric(1:2))
  num [1:2] 1 2

 str(as(1:2,"numeric"))
  int [1:2] 1 2

 Which doubly makes no sense.  1) Either the class is "numeric" or it isn't; I did not call as.integer() here.  2) method of recasting should not affect final class.

 Thanks,
 Ariel


 -----Original Message-----
 From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
 Sent: Saturday, April 09, 2016 5:27 AM
 To: Jeff Newmiller
 Cc: Paulson, Ariel; 'r-help at r-project.org'
 Subject: Re: [FORGED] Re: [R] identical() versus sapply()

 On 09/04/16 16:24, Jeff Newmiller wrote:
 I highly
recommend making friends with the str function. Try

 str( 1 )
 str( 1:2 )

 Interesting.  But to me counter-intuitive.  Since R makes no distinction between scalars and vectors of length 1 (or more accurately I think, since in R there is *no such thing as a scalar*, only a vector of length
 1) I don't see why "1" should be treated in a manner that is categorically different from the way in which "1:2" is treated.

 Can you, or someone else with deep insight into R and its rationale, explain the basis for this difference in treatment?

 for the clue you need, and then

 sapply( 1:2, identical, 1L )

 cheers,

 Rolf

 --
 Technical Editor ANZJS
 Department of Statistics
 University of Auckland
 Phone: +64-9-373-7599 ext. 88276

________________________________

 R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Apr 12 02:37:40 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Apr 2016 17:37:40 -0700
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <1460420710420.50418@stowers.org>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org>
Message-ID: <CAF8bMcb21BBS=3Yuk3=VtcgbDMrzKCyg1nFf_y+AaPq3muUSQw@mail.gmail.com>

Use all.equal instead of identical if you want to gloss over
integer/numeric class differences and minor floating point differences (and
a host of others).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Apr 11, 2016 at 5:25 PM, Paulson, Ariel <apa at stowers.org> wrote:

> Hi Jeff,
>
>
> We are splitting hairs because R is splitting hairs, and causing us
> problems.  Integer and numeric are different R classes with different
> properties, mathematical relationships notwithstanding.  For instance, the
> counterintuitive result:
>
>
> > identical(as.integer(1), as.numeric(1))
> [1] FALSE
>
>
> Unfortunately the reply-to chain doesn't extend far enough -- here is the
> original problem:
>
>
> > sapply(1, identical, 1)
> [1] TRUE
>
> > sapply(1:2, identical, 1)
> [1] FALSE FALSE
>
> > sapply(1:2, function(i) identical(as.numeric(i),1) )
> [1]  TRUE FALSE
>
> > sapply(1:2, function(i) identical(as(i,"numeric"),1) )
> [1] FALSE FALSE
>
> These are the results of R's hair-splitting!
>
> Ariel
>
> ________________________________
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Monday, April 11, 2016 6:49 PM
> To: Bert Gunter; Paulson, Ariel
> Cc: Rolf Turner; r-help at r-project.org
> Subject: Re: [R] [FORGED] Re: identical() versus sapply()
>
> Hypothesis regarding the thought process: integer is a perfect subset of
> numeric, so why split hairs?
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> Indeed!
>
> Slightly simplified to emphasize your point:
>
>  class(as(1:2,"numeric"))
> [1] "integer"
>
>  class(as.numeric(1:2))
> [1] "numeric"
>
> whereas in ?as it says:
>
> "Methods are pre-defined for coercing any object to one of the basic
> datatypes. For example, as(x, "numeric") uses the existing as.numeric
> function. "
>
> I suspect this is related to my ignorance of S4 classes (i.e. as() )
> and how they relate to S3 classes, but I certainly don't get it
> either.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things
> into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org> wrote:
>  Ok, I see the difference between 1 and 1:2, I'll just leave it as one of
> those "only in R" things.
>
>  But it seems then, that as.numeric() should guarantee a FALSE outcome,
> yet it does not.
>
>  To build on what Rolf pointed out, I would really love for someone to
> explain this one:
>
>  str(1)
>   num 1
>
>  str(1:2)
>   int [1:2] 1 2
>
>  str(as.numeric(1:2))
>   num [1:2] 1 2
>
>  str(as(1:2,"numeric"))
>   int [1:2] 1 2
>
>  Which doubly makes no sense.  1) Either the class is "numeric" or it
> isn't; I did not call as.integer() here.  2) method of recasting should not
> affect final class.
>
>  Thanks,
>  Ariel
>
>
>  -----Original Message-----
>  From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>  Sent: Saturday, April 09, 2016 5:27 AM
>  To: Jeff Newmiller
>  Cc: Paulson, Ariel; 'r-help at r-project.org'
>  Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>
>  On 09/04/16 16:24, Jeff Newmiller wrote:
>  I highly
> recommend making friends with the str function. Try
>
>  str( 1 )
>  str( 1:2 )
>
>  Interesting.  But to me counter-intuitive.  Since R makes no distinction
> between scalars and vectors of length 1 (or more accurately I think, since
> in R there is *no such thing as a scalar*, only a vector of length
>  1) I don't see why "1" should be treated in a manner that is
> categorically different from the way in which "1:2" is treated.
>
>  Can you, or someone else with deep insight into R and its rationale,
> explain the basis for this difference in treatment?
>
>  for the clue you need, and then
>
>  sapply( 1:2, identical, 1L )
>
>  cheers,
>
>  Rolf
>
>  --
>  Technical Editor ANZJS
>  Department of Statistics
>  University of Auckland
>  Phone: +64-9-373-7599 ext. 88276
>
> ________________________________
>
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>  and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 12 03:09:22 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Apr 2016 21:09:22 -0400
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <1460420710420.50418@stowers.org>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org>
Message-ID: <570C4AC2.5040408@gmail.com>

On 11/04/2016 8:25 PM, Paulson, Ariel wrote:
> Hi Jeff,
>
>
> We are splitting hairs because R is splitting hairs, and causing us problems.  Integer and numeric are different R classes with different properties, mathematical relationships notwithstanding.  For instance, the counterintuitive result:

The issue here is that R has grown.  The as() function is newer than the 
as.numeric() function, it's part of the methods package.  It is a much 
more complicated thing, and there are cases where they differ.

In this case, the problem is that is(1L, "numeric") evaluates to TRUE, 
and nobody has written a coerce method that specifically converts 
"integer" to "numeric".  So the as() function defaults to doing nothing.
It takes a while to do nothing, approximately 360 times longer than 
as.numeric() takes to actually do the conversion:

 > microbenchmark(as.numeric(1L), as(1L, "numeric"))
Unit: nanoseconds
               expr   min    lq      mean  median       uq     max neval
     as.numeric(1L)   133   210    516.92   273.5    409.5    9444   100
  as(1L, "numeric") 51464 64501 119294.31 99768.5 138321.0 1313669   100

R performance is not always simple and easy to predict, but I think 
anyone who had experience with R would never use as(x, "numeric").  So 
this just isn't a problem worth fixing.

Now, you might object that the documentation claims they are equivalent, 
but it certainly doesn't.  The documentation aims to be accurate, not 
necessarily clear.

Duncan Murdoch

>
>> identical(as.integer(1), as.numeric(1))
> [1] FALSE
>
>
> Unfortunately the reply-to chain doesn't extend far enough -- here is the original problem:
>
>
>> sapply(1, identical, 1)
> [1] TRUE
>
>> sapply(1:2, identical, 1)
> [1] FALSE FALSE
>
>> sapply(1:2, function(i) identical(as.numeric(i),1) )
> [1]  TRUE FALSE
>
>> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
> [1] FALSE FALSE
>
> These are the results of R's hair-splitting!


>
> Ariel
>
> ________________________________
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Monday, April 11, 2016 6:49 PM
> To: Bert Gunter; Paulson, Ariel
> Cc: Rolf Turner; r-help at r-project.org
> Subject: Re: [R] [FORGED] Re: identical() versus sapply()
>
> Hypothesis regarding the thought process: integer is a perfect subset of numeric, so why split hairs?
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Indeed!
>
> Slightly simplified to emphasize your point:
>
>   class(as(1:2,"numeric"))
> [1] "integer"
>
>   class(as.numeric(1:2))
> [1] "numeric"
>
> whereas in ?as it says:
>
> "Methods are pre-defined for coercing any object to one of the basic
> datatypes. For example, as(x, "numeric") uses the existing as.numeric
> function. "
>
> I suspect this is related to my ignorance of S4 classes (i.e. as() )
> and how they relate to S3 classes, but I certainly don't get it
> either.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things
> into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org> wrote:
>   Ok, I see the difference between 1 and 1:2, I'll just leave it as one of those "only in R" things.
>
>   But it seems then, that as.numeric() should guarantee a FALSE outcome, yet it does not.
>
>   To build on what Rolf pointed out, I would really love for someone to explain this one:
>
>   str(1)
>    num 1
>
>   str(1:2)
>    int [1:2] 1 2
>
>   str(as.numeric(1:2))
>    num [1:2] 1 2
>
>   str(as(1:2,"numeric"))
>    int [1:2] 1 2
>
>   Which doubly makes no sense.  1) Either the class is "numeric" or it isn't; I did not call as.integer() here.  2) method of recasting should not affect final class.
>
>   Thanks,
>   Ariel
>
>
>   -----Original Message-----
>   From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>   Sent: Saturday, April 09, 2016 5:27 AM
>   To: Jeff Newmiller
>   Cc: Paulson, Ariel; 'r-help at r-project.org'
>   Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>
>   On 09/04/16 16:24, Jeff Newmiller wrote:
>   I highly
> recommend making friends with the str function. Try
>
>   str( 1 )
>   str( 1:2 )
>
>   Interesting.  But to me counter-intuitive.  Since R makes no distinction between scalars and vectors of length 1 (or more accurately I think, since in R there is *no such thing as a scalar*, only a vector of length
>   1) I don't see why "1" should be treated in a manner that is categorically different from the way in which "1:2" is treated.
>
>   Can you, or someone else with deep insight into R and its rationale, explain the basis for this difference in treatment?
>
>   for the clue you need, and then
>
>   sapply( 1:2, identical, 1L )
>
>   cheers,
>
>   Rolf
>
>   --
>   Technical Editor ANZJS
>   Department of Statistics
>   University of Auckland
>   Phone: +64-9-373-7599 ext. 88276
>
> ________________________________
>
>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>   https://stat.ethz.ch/mailman/listinfo/r-help
>   PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>   and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michaeleartz at gmail.com  Tue Apr 12 03:30:38 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Mon, 11 Apr 2016 20:30:38 -0500
Subject: [R] Dissimilarity matrix and number clusters determination
Message-ID: <CA+pG8eNVyCDyZ5-zyjG=Bqyqb2=J8Zu7XtLBeBuBhKB_KoE2Bw@mail.gmail.com>

Hi,
  I already have a dissimilarity matrix and I am submitting the results to
the elbow.obj method to get an optimal number of clusters.  Am I reading
the below output correctly that I should have 17 clusters?

code:
top150 <- sampleset[1:150,]
{cluster1 <- daisy(top150
                   , metric = c("gower")
                   , stand = TRUE
                   , type = list(symm = 1))
}

dist.obj <- dist(cluster1)
hclust.obj <- hclust(dist.obj)
css.obj <- css.hclust(dist.obj,hclust.obj)
elbow.obj <- elbow.batch(css.obj)

[1] "A \"good\" k=17 (EV=0.80) is detected when the EV is no less than
0.8\nand the increment of EV is no more than 0.01 for a bigger k.\n"
attr(,"class")

	[[alternative HTML version deleted]]


From apa at stowers.org  Tue Apr 12 03:59:05 2016
From: apa at stowers.org (Paulson, Ariel)
Date: Tue, 12 Apr 2016 01:59:05 +0000
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <CAF8bMcb21BBS=3Yuk3=VtcgbDMrzKCyg1nFf_y+AaPq3muUSQw@mail.gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org>,
	<CAF8bMcb21BBS=3Yuk3=VtcgbDMrzKCyg1nFf_y+AaPq3muUSQw@mail.gmail.com>
Message-ID: <1460426346090.71968@stowers.org>

?Perfect!


Thanks,

Ariel

________________________________
From: William Dunlap <wdunlap at tibco.com>
Sent: Monday, April 11, 2016 7:37 PM
To: Paulson, Ariel
Cc: Jeff Newmiller; Bert Gunter; r-help at r-project.org
Subject: Re: [R] [FORGED] Re: identical() versus sapply()

Use all.equal instead of identical if you want to gloss over integer/numeric class differences and minor floating point differences (and a host of others).

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Mon, Apr 11, 2016 at 5:25 PM, Paulson, Ariel <apa at stowers.org<mailto:apa at stowers.org>> wrote:
Hi Jeff,


We are splitting hairs because R is splitting hairs, and causing us problems.  Integer and numeric are different R classes with different properties, mathematical relationships notwithstanding.  For instance, the counterintuitive result:


> identical(as.integer(1), as.numeric(1))
[1] FALSE


Unfortunately the reply-to chain doesn't extend far enough -- here is the original problem:


> sapply(1, identical, 1)
[1] TRUE

> sapply(1:2, identical, 1)
[1] FALSE FALSE

> sapply(1:2, function(i) identical(as.numeric(i),1) )
[1]  TRUE FALSE

> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
[1] FALSE FALSE

These are the results of R's hair-splitting!

Ariel

________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>>
Sent: Monday, April 11, 2016 6:49 PM
To: Bert Gunter; Paulson, Ariel
Cc: Rolf Turner; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] [FORGED] Re: identical() versus sapply()

Hypothesis regarding the thought process: integer is a perfect subset of numeric, so why split hairs?
--
Sent from my phone. Please excuse my brevity.

On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:

Indeed!

Slightly simplified to emphasize your point:

 class(as(1:2,"numeric"))
[1] "integer"

 class(as.numeric(1:2))
[1] "numeric"

whereas in ?as it says:

"Methods are pre-defined for coercing any object to one of the basic
datatypes. For example, as(x, "numeric") uses the existing as.numeric
function. "

I suspect this is related to my ignorance of S4 classes (i.e. as() )
and how they relate to S3 classes, but I certainly don't get it
either.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things
into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org<mailto:apa at stowers.org>> wrote:
 Ok, I see the difference between 1 and 1:2, I'll just leave it as one of those "only in R" things.

 But it seems then, that as.numeric() should guarantee a FALSE outcome, yet it does not.

 To build on what Rolf pointed out, I would really love for someone to explain this one:

 str(1)
  num 1

 str(1:2)
  int [1:2] 1 2

 str(as.numeric(1:2))
  num [1:2] 1 2

 str(as(1:2,"numeric"))
  int [1:2] 1 2

 Which doubly makes no sense.  1) Either the class is "numeric" or it isn't; I did not call as.integer() here.  2) method of recasting should not affect final class.

 Thanks,
 Ariel


 -----Original Message-----
 From: Rolf Turner [mailto:r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>]
 Sent: Saturday, April 09, 2016 5:27 AM
 To: Jeff Newmiller
 Cc: Paulson, Ariel; 'r-help at r-project.org<mailto:r-help at r-project.org>'
 Subject: Re: [FORGED] Re: [R] identical() versus sapply()

 On 09/04/16 16:24, Jeff Newmiller wrote:
 I highly
recommend making friends with the str function. Try

 str( 1 )
 str( 1:2 )

 Interesting.  But to me counter-intuitive.  Since R makes no distinction between scalars and vectors of length 1 (or more accurately I think, since in R there is *no such thing as a scalar*, only a vector of length
 1) I don't see why "1" should be treated in a manner that is categorically different from the way in which "1:2" is treated.

 Can you, or someone else with deep insight into R and its rationale, explain the basis for this difference in treatment?

 for the clue you need, and then

 sapply( 1:2, identical, 1L )

 cheers,

 Rolf

 --
 Technical Editor ANZJS
 Department of Statistics
 University of Auckland
 Phone: +64-9-373-7599 ext. 88276

________________________________

 R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From apa at stowers.org  Tue Apr 12 04:06:12 2016
From: apa at stowers.org (Paulson, Ariel)
Date: Tue, 12 Apr 2016 02:06:12 +0000
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <570C4AC2.5040408@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org>,<570C4AC2.5040408@gmail.com>
Message-ID: <1460426773294.84755@stowers.org>

Hi Duncan,

That explains it, thanks!

I rarely use as(), but had thought in this case, replacing identical(x, y) with identical(x, as(y,class(x))) could be an sapply-friendly way to iron out class differences -- then noticed the inexplicable result.  But now I know about all.equal().

Thanks,
Ariel 

________________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Monday, April 11, 2016 8:09 PM
To: Paulson, Ariel; Jeff Newmiller; Bert Gunter
Cc: r-help at r-project.org
Subject: Re: [R] [FORGED] Re: identical() versus sapply()

On 11/04/2016 8:25 PM, Paulson, Ariel wrote:
> Hi Jeff,
>
>
> We are splitting hairs because R is splitting hairs, and causing us problems.  Integer and numeric are different R classes with different properties, mathematical relationships notwithstanding.  For instance, the counterintuitive result:

The issue here is that R has grown.  The as() function is newer than the
as.numeric() function, it's part of the methods package.  It is a much
more complicated thing, and there are cases where they differ.

In this case, the problem is that is(1L, "numeric") evaluates to TRUE,
and nobody has written a coerce method that specifically converts
"integer" to "numeric".  So the as() function defaults to doing nothing.
It takes a while to do nothing, approximately 360 times longer than
as.numeric() takes to actually do the conversion:

 > microbenchmark(as.numeric(1L), as(1L, "numeric"))
Unit: nanoseconds
               expr   min    lq      mean  median       uq     max neval
     as.numeric(1L)   133   210    516.92   273.5    409.5    9444   100
  as(1L, "numeric") 51464 64501 119294.31 99768.5 138321.0 1313669   100

R performance is not always simple and easy to predict, but I think
anyone who had experience with R would never use as(x, "numeric").  So
this just isn't a problem worth fixing.

Now, you might object that the documentation claims they are equivalent,
but it certainly doesn't.  The documentation aims to be accurate, not
necessarily clear.

Duncan Murdoch

>
>> identical(as.integer(1), as.numeric(1))
> [1] FALSE
>
>
> Unfortunately the reply-to chain doesn't extend far enough -- here is the original problem:
>
>
>> sapply(1, identical, 1)
> [1] TRUE
>
>> sapply(1:2, identical, 1)
> [1] FALSE FALSE
>
>> sapply(1:2, function(i) identical(as.numeric(i),1) )
> [1]  TRUE FALSE
>
>> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
> [1] FALSE FALSE
>
> These are the results of R's hair-splitting!


>
> Ariel
>
> ________________________________
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Monday, April 11, 2016 6:49 PM
> To: Bert Gunter; Paulson, Ariel
> Cc: Rolf Turner; r-help at r-project.org
> Subject: Re: [R] [FORGED] Re: identical() versus sapply()
>
> Hypothesis regarding the thought process: integer is a perfect subset of numeric, so why split hairs?
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Indeed!
>
> Slightly simplified to emphasize your point:
>
>   class(as(1:2,"numeric"))
> [1] "integer"
>
>   class(as.numeric(1:2))
> [1] "numeric"
>
> whereas in ?as it says:
>
> "Methods are pre-defined for coercing any object to one of the basic
> datatypes. For example, as(x, "numeric") uses the existing as.numeric
> function. "
>
> I suspect this is related to my ignorance of S4 classes (i.e. as() )
> and how they relate to S3 classes, but I certainly don't get it
> either.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things
> into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org> wrote:
>   Ok, I see the difference between 1 and 1:2, I'll just leave it as one of those "only in R" things.
>
>   But it seems then, that as.numeric() should guarantee a FALSE outcome, yet it does not.
>
>   To build on what Rolf pointed out, I would really love for someone to explain this one:
>
>   str(1)
>    num 1
>
>   str(1:2)
>    int [1:2] 1 2
>
>   str(as.numeric(1:2))
>    num [1:2] 1 2
>
>   str(as(1:2,"numeric"))
>    int [1:2] 1 2
>
>   Which doubly makes no sense.  1) Either the class is "numeric" or it isn't; I did not call as.integer() here.  2) method of recasting should not affect final class.
>
>   Thanks,
>   Ariel
>
>
>   -----Original Message-----
>   From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>   Sent: Saturday, April 09, 2016 5:27 AM
>   To: Jeff Newmiller
>   Cc: Paulson, Ariel; 'r-help at r-project.org'
>   Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>
>   On 09/04/16 16:24, Jeff Newmiller wrote:
>   I highly
> recommend making friends with the str function. Try
>
>   str( 1 )
>   str( 1:2 )
>
>   Interesting.  But to me counter-intuitive.  Since R makes no distinction between scalars and vectors of length 1 (or more accurately I think, since in R there is *no such thing as a scalar*, only a vector of length
>   1) I don't see why "1" should be treated in a manner that is categorically different from the way in which "1:2" is treated.
>
>   Can you, or someone else with deep insight into R and its rationale, explain the basis for this difference in treatment?
>
>   for the clue you need, and then
>
>   sapply( 1:2, identical, 1L )
>
>   cheers,
>
>   Rolf
>
>   --
>   Technical Editor ANZJS
>   Department of Statistics
>   University of Auckland
>   Phone: +64-9-373-7599 ext. 88276
>
> ________________________________
>
>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>   https://stat.ethz.ch/mailman/listinfo/r-help
>   PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>   and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bgunter.4567 at gmail.com  Tue Apr 12 04:18:39 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 11 Apr 2016 19:18:39 -0700
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <570C4AC2.5040408@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
Message-ID: <CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>

"The documentation aims to be accurate, not necessarily clear."

!!!

I hope that is not the case! Accurate documentation that is confusing
is not very useful. I understand that it is challenging to write docs
that are both clear and accurate; but I hope that is always the goal.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 11, 2016 at 6:09 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 11/04/2016 8:25 PM, Paulson, Ariel wrote:
>>
>> Hi Jeff,
>>
>>
>> We are splitting hairs because R is splitting hairs, and causing us
>> problems.  Integer and numeric are different R classes with different
>> properties, mathematical relationships notwithstanding.  For instance, the
>> counterintuitive result:
>
>
> The issue here is that R has grown.  The as() function is newer than the
> as.numeric() function, it's part of the methods package.  It is a much more
> complicated thing, and there are cases where they differ.
>
> In this case, the problem is that is(1L, "numeric") evaluates to TRUE, and
> nobody has written a coerce method that specifically converts "integer" to
> "numeric".  So the as() function defaults to doing nothing.
> It takes a while to do nothing, approximately 360 times longer than
> as.numeric() takes to actually do the conversion:
>
>> microbenchmark(as.numeric(1L), as(1L, "numeric"))
> Unit: nanoseconds
>               expr   min    lq      mean  median       uq     max neval
>     as.numeric(1L)   133   210    516.92   273.5    409.5    9444   100
>  as(1L, "numeric") 51464 64501 119294.31 99768.5 138321.0 1313669   100
>
> R performance is not always simple and easy to predict, but I think anyone
> who had experience with R would never use as(x, "numeric").  So this just
> isn't a problem worth fixing.
>
> Now, you might object that the documentation claims they are equivalent, but
> it certainly doesn't.  The documentation aims to be accurate, not
> necessarily clear.
>
> Duncan Murdoch
>
>
>>
>>> identical(as.integer(1), as.numeric(1))
>>
>> [1] FALSE
>>
>>
>> Unfortunately the reply-to chain doesn't extend far enough -- here is the
>> original problem:
>>
>>
>>> sapply(1, identical, 1)
>>
>> [1] TRUE
>>
>>> sapply(1:2, identical, 1)
>>
>> [1] FALSE FALSE
>>
>>> sapply(1:2, function(i) identical(as.numeric(i),1) )
>>
>> [1]  TRUE FALSE
>>
>>> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
>>
>> [1] FALSE FALSE
>>
>> These are the results of R's hair-splitting!
>
>
>
>>
>> Ariel
>>
>> ________________________________
>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> Sent: Monday, April 11, 2016 6:49 PM
>> To: Bert Gunter; Paulson, Ariel
>> Cc: Rolf Turner; r-help at r-project.org
>> Subject: Re: [R] [FORGED] Re: identical() versus sapply()
>>
>> Hypothesis regarding the thought process: integer is a perfect subset of
>> numeric, so why split hairs?
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>> Indeed!
>>
>> Slightly simplified to emphasize your point:
>>
>>   class(as(1:2,"numeric"))
>> [1] "integer"
>>
>>   class(as.numeric(1:2))
>> [1] "numeric"
>>
>> whereas in ?as it says:
>>
>> "Methods are pre-defined for coercing any object to one of the basic
>> datatypes. For example, as(x, "numeric") uses the existing as.numeric
>> function. "
>>
>> I suspect this is related to my ignorance of S4 classes (i.e. as() )
>> and how they relate to S3 classes, but I certainly don't get it
>> either.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things
>> into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org> wrote:
>>   Ok, I see the difference between 1 and 1:2, I'll just leave it as one of
>> those "only in R" things.
>>
>>   But it seems then, that as.numeric() should guarantee a FALSE outcome,
>> yet it does not.
>>
>>   To build on what Rolf pointed out, I would really love for someone to
>> explain this one:
>>
>>   str(1)
>>    num 1
>>
>>   str(1:2)
>>    int [1:2] 1 2
>>
>>   str(as.numeric(1:2))
>>    num [1:2] 1 2
>>
>>   str(as(1:2,"numeric"))
>>    int [1:2] 1 2
>>
>>   Which doubly makes no sense.  1) Either the class is "numeric" or it
>> isn't; I did not call as.integer() here.  2) method of recasting should not
>> affect final class.
>>
>>   Thanks,
>>   Ariel
>>
>>
>>   -----Original Message-----
>>   From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>>   Sent: Saturday, April 09, 2016 5:27 AM
>>   To: Jeff Newmiller
>>   Cc: Paulson, Ariel; 'r-help at r-project.org'
>>   Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>>
>>   On 09/04/16 16:24, Jeff Newmiller wrote:
>>   I highly
>> recommend making friends with the str function. Try
>>
>>   str( 1 )
>>   str( 1:2 )
>>
>>   Interesting.  But to me counter-intuitive.  Since R makes no distinction
>> between scalars and vectors of length 1 (or more accurately I think, since
>> in R there is *no such thing as a scalar*, only a vector of length
>>   1) I don't see why "1" should be treated in a manner that is
>> categorically different from the way in which "1:2" is treated.
>>
>>   Can you, or someone else with deep insight into R and its rationale,
>> explain the basis for this difference in treatment?
>>
>>   for the clue you need, and then
>>
>>   sapply( 1:2, identical, 1L )
>>
>>   cheers,
>>
>>   Rolf
>>
>>   --
>>   Technical Editor ANZJS
>>   Department of Statistics
>>   University of Auckland
>>   Phone: +64-9-373-7599 ext. 88276
>>
>> ________________________________
>>
>>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>   https://stat.ethz.ch/mailman/listinfo/r-help
>>   PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>   and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From murdoch.duncan at gmail.com  Tue Apr 12 04:45:44 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Apr 2016 22:45:44 -0400
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
Message-ID: <570C6158.5010707@gmail.com>

On 11/04/2016 10:18 PM, Bert Gunter wrote:
> "The documentation aims to be accurate, not necessarily clear."
>
> !!!
>
> I hope that is not the case! Accurate documentation that is confusing
> is not very useful.

I don't think it is ever intentionally confusing, but it is often 
concise to the point of obscurity.  Words are chosen carefully, and 
explanations are not repeated.  It takes an effort to read it.  It will 
be clear to careful readers, but not to all readers.

I was thinking of the statement quoted earlier, 'as(x, "numeric") uses 
the existing as.numeric function'.  That is different than saying 'as(x, 
"numeric") is the same as as.numeric(x)'.

Duncan Murdoch

  I understand that it is challenging to write docs
> that are both clear and accurate; but I hope that is always the goal.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Apr 11, 2016 at 6:09 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 11/04/2016 8:25 PM, Paulson, Ariel wrote:
>>>
>>> Hi Jeff,
>>>
>>>
>>> We are splitting hairs because R is splitting hairs, and causing us
>>> problems.  Integer and numeric are different R classes with different
>>> properties, mathematical relationships notwithstanding.  For instance, the
>>> counterintuitive result:
>>
>>
>> The issue here is that R has grown.  The as() function is newer than the
>> as.numeric() function, it's part of the methods package.  It is a much more
>> complicated thing, and there are cases where they differ.
>>
>> In this case, the problem is that is(1L, "numeric") evaluates to TRUE, and
>> nobody has written a coerce method that specifically converts "integer" to
>> "numeric".  So the as() function defaults to doing nothing.
>> It takes a while to do nothing, approximately 360 times longer than
>> as.numeric() takes to actually do the conversion:
>>
>>> microbenchmark(as.numeric(1L), as(1L, "numeric"))
>> Unit: nanoseconds
>>                expr   min    lq      mean  median       uq     max neval
>>      as.numeric(1L)   133   210    516.92   273.5    409.5    9444   100
>>   as(1L, "numeric") 51464 64501 119294.31 99768.5 138321.0 1313669   100
>>
>> R performance is not always simple and easy to predict, but I think anyone
>> who had experience with R would never use as(x, "numeric").  So this just
>> isn't a problem worth fixing.
>>
>> Now, you might object that the documentation claims they are equivalent, but
>> it certainly doesn't.  The documentation aims to be accurate, not
>> necessarily clear.
>>
>> Duncan Murdoch
>>
>>
>>>
>>>> identical(as.integer(1), as.numeric(1))
>>>
>>> [1] FALSE
>>>
>>>
>>> Unfortunately the reply-to chain doesn't extend far enough -- here is the
>>> original problem:
>>>
>>>
>>>> sapply(1, identical, 1)
>>>
>>> [1] TRUE
>>>
>>>> sapply(1:2, identical, 1)
>>>
>>> [1] FALSE FALSE
>>>
>>>> sapply(1:2, function(i) identical(as.numeric(i),1) )
>>>
>>> [1]  TRUE FALSE
>>>
>>>> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
>>>
>>> [1] FALSE FALSE
>>>
>>> These are the results of R's hair-splitting!
>>
>>
>>
>>>
>>> Ariel
>>>
>>> ________________________________
>>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> Sent: Monday, April 11, 2016 6:49 PM
>>> To: Bert Gunter; Paulson, Ariel
>>> Cc: Rolf Turner; r-help at r-project.org
>>> Subject: Re: [R] [FORGED] Re: identical() versus sapply()
>>>
>>> Hypothesis regarding the thought process: integer is a perfect subset of
>>> numeric, so why split hairs?
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>
>>> Indeed!
>>>
>>> Slightly simplified to emphasize your point:
>>>
>>>    class(as(1:2,"numeric"))
>>> [1] "integer"
>>>
>>>    class(as.numeric(1:2))
>>> [1] "numeric"
>>>
>>> whereas in ?as it says:
>>>
>>> "Methods are pre-defined for coercing any object to one of the basic
>>> datatypes. For example, as(x, "numeric") uses the existing as.numeric
>>> function. "
>>>
>>> I suspect this is related to my ignorance of S4 classes (i.e. as() )
>>> and how they relate to S3 classes, but I certainly don't get it
>>> either.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things
>>> into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org> wrote:
>>>    Ok, I see the difference between 1 and 1:2, I'll just leave it as one of
>>> those "only in R" things.
>>>
>>>    But it seems then, that as.numeric() should guarantee a FALSE outcome,
>>> yet it does not.
>>>
>>>    To build on what Rolf pointed out, I would really love for someone to
>>> explain this one:
>>>
>>>    str(1)
>>>     num 1
>>>
>>>    str(1:2)
>>>     int [1:2] 1 2
>>>
>>>    str(as.numeric(1:2))
>>>     num [1:2] 1 2
>>>
>>>    str(as(1:2,"numeric"))
>>>     int [1:2] 1 2
>>>
>>>    Which doubly makes no sense.  1) Either the class is "numeric" or it
>>> isn't; I did not call as.integer() here.  2) method of recasting should not
>>> affect final class.
>>>
>>>    Thanks,
>>>    Ariel
>>>
>>>
>>>    -----Original Message-----
>>>    From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>>>    Sent: Saturday, April 09, 2016 5:27 AM
>>>    To: Jeff Newmiller
>>>    Cc: Paulson, Ariel; 'r-help at r-project.org'
>>>    Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>>>
>>>    On 09/04/16 16:24, Jeff Newmiller wrote:
>>>    I highly
>>> recommend making friends with the str function. Try
>>>
>>>    str( 1 )
>>>    str( 1:2 )
>>>
>>>    Interesting.  But to me counter-intuitive.  Since R makes no distinction
>>> between scalars and vectors of length 1 (or more accurately I think, since
>>> in R there is *no such thing as a scalar*, only a vector of length
>>>    1) I don't see why "1" should be treated in a manner that is
>>> categorically different from the way in which "1:2" is treated.
>>>
>>>    Can you, or someone else with deep insight into R and its rationale,
>>> explain the basis for this difference in treatment?
>>>
>>>    for the clue you need, and then
>>>
>>>    sapply( 1:2, identical, 1L )
>>>
>>>    cheers,
>>>
>>>    Rolf
>>>
>>>    --
>>>    Technical Editor ANZJS
>>>    Department of Statistics
>>>    University of Auckland
>>>    Phone: +64-9-373-7599 ext. 88276
>>>
>>> ________________________________
>>>
>>>    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>>    PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>    and provide commented, minimal, self-contained, reproducible code.
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From r.turner at auckland.ac.nz  Tue Apr 12 05:19:36 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 12 Apr 2016 15:19:36 +1200
Subject: [R] [FORGED] Re:  [FORGED] Re: identical() versus sapply()
In-Reply-To: <570C4AC2.5040408@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
Message-ID: <570C6948.40506@auckland.ac.nz>



On 12/04/16 13:09, Duncan Murdoch wrote:

<SNIP>

> The documentation aims to be accurate, not necessarily clear.

<SNIP>

Fortune nomination!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Tue Apr 12 05:34:54 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 12 Apr 2016 15:34:54 +1200
Subject: [R] [FORGED] Re:  [FORGED] Re: identical() versus sapply()
In-Reply-To: <570C6158.5010707@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com>
Message-ID: <570C6CDE.2050907@auckland.ac.nz>

On 12/04/16 14:45, Duncan Murdoch wrote:
> On 11/04/2016 10:18 PM, Bert Gunter wrote:
>> "The documentation aims to be accurate, not necessarily clear."
>>
>> !!!
>>
>> I hope that is not the case! Accurate documentation that is confusing
>> is not very useful.
>
> I don't think it is ever intentionally confusing, but it is often
> concise to the point of obscurity.  Words are chosen carefully, and
> explanations are not repeated.  It takes an effort to read it.  It will
> be clear to careful readers, but not to all readers.
>
> I was thinking of the statement quoted earlier, 'as(x, "numeric") uses
> the existing as.numeric function'.  That is different than saying 'as(x,
> "numeric") is the same as as.numeric(x)'.


IMHO this is so *obviously* confusing and misleading --- even though it 
is technically correct --- that whoever wrote it was either 
intentionally trying to be confusing or is unbelievably obtuse and/or 
out of touch with reality.

It is not (again IMHO) clear even to *very* careful readers.

To my mind this documentation fails even the fortune(350) test.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From j.para.fernandez at hotmail.com  Tue Apr 12 07:17:14 2016
From: j.para.fernandez at hotmail.com (=?iso-8859-1?B?SmVz+nMgUGFyYSBGZXJu4W5kZXo=?=)
Date: Tue, 12 Apr 2016 07:17:14 +0200
Subject: [R] Random Forest classification
Message-ID: <DUB131-W72225254081BC9AAB79364CC950@phx.gbl>

Hi, 

To evaluate the partial influence of a factor with a random Forest, wich response is OK/NOK I?m using partialPlot, being the x axis the factor axis and the Y axis is between -1 and 1. What this -1 and 1 means?

An example:

https://www.dropbox.com/s/4b92lqxi3592r0d/Captura.JPG?dl=0


Thanks for all!!! 		 	   		  
	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Tue Apr 12 12:24:23 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Tue, 12 Apr 2016 13:24:23 +0300
Subject: [R] formula argument evaluation
Message-ID: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>

I have a simple function such as:

foo <- function(x) {
    call <- lapply(match.call(), deparse)
    testit <- capture.output(tryCatch(eval(x), error = function(e) e))
    if (grepl("Error", testit)) {
        return(call$x)
    }
}

and I would like to detect a formula when x is not an object:

# this works
> foo(A + B)
[1] "A + B"

# but this doesn't
> foo(A + B => C)
Error: unexpected '=' in "foo(A + B ="

Can I prevent it from evaluating the "=" sign?
The addition sign "+" hasn't been evaluated, and I was hoping the "=" would
not get evaluated either. The "=>" sign is important for other purposes,
not related to this example.

Thank you in advance,
Adrian

--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From michael.griffiths at news.co.uk  Tue Apr 12 12:25:33 2016
From: michael.griffiths at news.co.uk (Griffiths, Michael)
Date: Tue, 12 Apr 2016 11:25:33 +0100
Subject: [R] R integration with SAP-HANA and SQLScripting
Message-ID: <CANOihi9iTDVTA0REMK4JKC1aezpr4evaxbYNoYUQaMxh=FYdTA@mail.gmail.com>

Dear R forum,

I am seeking relevant material that discusses processes and methods of
incorporating R code into SAP-HANA. I would greatly appreciate links to any
relevant literature.

Background research on my part has only found the SAP-HANA R Integration
Guide, and several short examples. If the forum knows of any other sources
of information, this would be greatly appreciated.

Regards

Mike Griffiths

-- 


--

"Please consider the environment before printing this e-mail"

Newsworks - bringing advertisers and newsbrands together

www.newsworks.org.uk

This e-mail and any attachments are confidential, may be

legally privileged and are the property of News Corp UK & Ireland

Limited on whose systems they were generated. News Corp UK

& Ireland Limited is the holding company for the News UK group,

is registered in England & Wales under number 81701, has its 

registered office at 1 London Bridge Street, London, SE1 9GF and 

is registered with VAT number GB 243 8054 69. If you have received 

this e-mail in error, please notify the sender immediately and do not

use, distribute, store or copy it in any way. Statements or opinions in

this e-mail or any attachment are those of the author and are not 
necessarily agreed or authorised by News Corp UK & Ireland Limited 

or any member of its group. News Corp UK & Ireland Limited may

monitor outgoing or incoming emails as permitted by law.  It accepts
no liability for viruses introduced by this e-mail or attachments. 

News Corp UK & Ireland Limited and its titles are committed to abiding by 
IPSO's regulations and the Editors' Code of Practice that IPSO enforces.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 12 13:08:14 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Apr 2016 07:08:14 -0400
Subject: [R] formula argument evaluation
In-Reply-To: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
References: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
Message-ID: <570CD71E.4040107@gmail.com>

On 12/04/2016 6:24 AM, Adrian Du?a wrote:
> I have a simple function such as:
>
> foo <- function(x) {
>      call <- lapply(match.call(), deparse)
>      testit <- capture.output(tryCatch(eval(x), error = function(e) e))
>      if (grepl("Error", testit)) {
>          return(call$x)
>      }
> }
>
> and I would like to detect a formula when x is not an object:
>
> # this works
>> foo(A + B)
> [1] "A + B"
>
> # but this doesn't
>> foo(A + B => C)
> Error: unexpected '=' in "foo(A + B ="
>
> Can I prevent it from evaluating the "=" sign?

It never gets to evaluating it.  It is not a legal R statement, so the 
parser signals an error.

If you want to pass arbitrary strings to a function, you need to put 
them in quotes.

Duncan Murdoch

> The addition sign "+" hasn't been evaluated, and I was hoping the "=" would
> not get evaluated either. The "=>" sign is important for other purposes,
> not related to this example.
>
> Thank you in advance,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Tue Apr 12 13:15:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 12 Apr 2016 21:15:56 +1000
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7NZGuoyAkXhokJXwjHT4eUsb1w0SLJHQNWcnTZuo7YQ6g@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
	<3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
	<CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>
	<CA+8X3fXaHp6aiZ0K+B3Wv_zw=s1gW0neD_QDt7kW5LunHE5WLg@mail.gmail.com>
	<CAMLwc7NZGuoyAkXhokJXwjHT4eUsb1w0SLJHQNWcnTZuo7YQ6g@mail.gmail.com>
Message-ID: <CA+8X3fU+r4iFOQUpA+hQaV7Ub=spxd9deWbhzDk8dxNGTBZjBg@mail.gmail.com>

Hi Milu,
There is a two-headed arrow on the image you sent, and it seems to be
where you specified. Did you want it beneath the map, as:

par(xpd=TRUE)
arrows(-22,54.75,-22,74,code=3)
par(xpd=FALSE)

Jim

On Tue, Apr 12, 2016 at 7:58 PM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear Jim,
>
> Thanks again! I do want the arrows at the bottom (beneath the map). This is
> what I am doing:
>
> # Draw the map
> eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
> Score - Europe",colourPalette=colourPalette,
> catMethod="fixedWidth", missingCountryCol = "white", mapRegion="Europe",
> addLegend=FALSE)
>
> # ISO3 codes on the map
> text(n, labels="ISO3", cex=0.30)
>
> # Obtain coordinates for the arrow
> par('usr')
>
> # -19.75966  54.75966  33.60000  71.40000
>
> # Arrows
> par(xpd=TRUE)
> arrows(-19.75966,  54.75966,  33.60000,  71.40000,code=3)
> par(xpd=FALSE)
>
> As the output shows I cannot seem to get the correct coordinates for the
> arrows. Thanks again.
>
> Sincerely,
>
> Milu


From jrkrideau at inbox.com  Tue Apr 12 13:35:32 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 12 Apr 2016 03:35:32 -0800
Subject: [R] [FORGED] Re: identical() versus sapply()
In-Reply-To: <CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
References: <cagxfjbsw-o85ianrxoqiisjn-mhsshat2djlpfre3tnuvorbmq@mail.gmail.com>
	<8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<570c4ac2.5040408@gmail.com>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<3470ae64-da70-45ee-9e14-6b2edd21a538@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org>
	<d23058dd-e4df-4857-a0ae-d73b72562bdc@dcn.davis.ca.us>
	<5708d8f8.3020701@auckland.ac.nz>
Message-ID: <2838097843B.00000DF4jrkrideau@inbox.com>




> -----Original Message-----
> From: bgunter.4567 at gmail.com
> Sent: Mon, 11 Apr 2016 19:18:39 -0700
> To: murdoch.duncan at gmail.com
> Subject: Re: [R] [FORGED] Re: identical() versus sapply()
> 
> "The documentation aims to be accurate, not necessarily clear."
> 
> !!!
> 
> I hope that is not the case! Accurate documentation that is confusing
> is not very useful. I understand that it is challenging to write docs
> that are both clear and accurate; but I hope that is always the goal.

I have lost the link but someone here had a lovely essay on R documentation which pointed out that one had to  have "faith" that everything was in the documentation.


> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Apr 11, 2016 at 6:09 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 11/04/2016 8:25 PM, Paulson, Ariel wrote:
>>> 
>>> Hi Jeff,
>>> 
>>> 
>>> We are splitting hairs because R is splitting hairs, and causing us
>>> problems.  Integer and numeric are different R classes with different
>>> properties, mathematical relationships notwithstanding.  For instance,
>>> the
>>> counterintuitive result:
>> 
>> 
>> The issue here is that R has grown.  The as() function is newer than the
>> as.numeric() function, it's part of the methods package.  It is a much
>> more
>> complicated thing, and there are cases where they differ.
>> 
>> In this case, the problem is that is(1L, "numeric") evaluates to TRUE,
>> and
>> nobody has written a coerce method that specifically converts "integer"
>> to
>> "numeric".  So the as() function defaults to doing nothing.
>> It takes a while to do nothing, approximately 360 times longer than
>> as.numeric() takes to actually do the conversion:
>> 
>>> microbenchmark(as.numeric(1L), as(1L, "numeric"))
>> Unit: nanoseconds
>>               expr   min    lq      mean  median       uq     max neval
>>     as.numeric(1L)   133   210    516.92   273.5    409.5    9444   100
>>  as(1L, "numeric") 51464 64501 119294.31 99768.5 138321.0 1313669   100
>> 
>> R performance is not always simple and easy to predict, but I think
>> anyone
>> who had experience with R would never use as(x, "numeric").  So this
>> just
>> isn't a problem worth fixing.
>> 
>> Now, you might object that the documentation claims they are equivalent,
>> but
>> it certainly doesn't.  The documentation aims to be accurate, not
>> necessarily clear.
>> 
>> Duncan Murdoch
>> 
>> 
>>> 
>>>> identical(as.integer(1), as.numeric(1))
>>> 
>>> [1] FALSE
>>> 
>>> 
>>> Unfortunately the reply-to chain doesn't extend far enough -- here is
>>> the
>>> original problem:
>>> 
>>> 
>>>> sapply(1, identical, 1)
>>> 
>>> [1] TRUE
>>> 
>>>> sapply(1:2, identical, 1)
>>> 
>>> [1] FALSE FALSE
>>> 
>>>> sapply(1:2, function(i) identical(as.numeric(i),1) )
>>> 
>>> [1]  TRUE FALSE
>>> 
>>>> sapply(1:2, function(i) identical(as(i,"numeric"),1) )
>>> 
>>> [1] FALSE FALSE
>>> 
>>> These are the results of R's hair-splitting!
>> 
>> 
>> 
>>> 
>>> Ariel
>>> 
>>> ________________________________
>>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> Sent: Monday, April 11, 2016 6:49 PM
>>> To: Bert Gunter; Paulson, Ariel
>>> Cc: Rolf Turner; r-help at r-project.org
>>> Subject: Re: [R] [FORGED] Re: identical() versus sapply()
>>> 
>>> Hypothesis regarding the thought process: integer is a perfect subset
>>> of
>>> numeric, so why split hairs?
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On April 11, 2016 12:36:56 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> 
>>> Indeed!
>>> 
>>> Slightly simplified to emphasize your point:
>>> 
>>>   class(as(1:2,"numeric"))
>>> [1] "integer"
>>> 
>>>   class(as.numeric(1:2))
>>> [1] "numeric"
>>> 
>>> whereas in ?as it says:
>>> 
>>> "Methods are pre-defined for coercing any object to one of the basic
>>> datatypes. For example, as(x, "numeric") uses the existing as.numeric
>>> function. "
>>> 
>>> I suspect this is related to my ignorance of S4 classes (i.e. as() )
>>> and how they relate to S3 classes, but I certainly don't get it
>>> either.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things
>>> into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Mon, Apr 11, 2016 at 9:30 AM, Paulson, Ariel <apa at stowers.org>
>>> wrote:
>>>   Ok, I see the difference between 1 and 1:2, I'll just leave it as one
>>> of
>>> those "only in R" things.
>>> 
>>>   But it seems then, that as.numeric() should guarantee a FALSE
>>> outcome,
>>> yet it does not.
>>> 
>>>   To build on what Rolf pointed out, I would really love for someone to
>>> explain this one:
>>> 
>>>   str(1)
>>>    num 1
>>> 
>>>   str(1:2)
>>>    int [1:2] 1 2
>>> 
>>>   str(as.numeric(1:2))
>>>    num [1:2] 1 2
>>> 
>>>   str(as(1:2,"numeric"))
>>>    int [1:2] 1 2
>>> 
>>>   Which doubly makes no sense.  1) Either the class is "numeric" or it
>>> isn't; I did not call as.integer() here.  2) method of recasting should
>>> not
>>> affect final class.
>>> 
>>>   Thanks,
>>>   Ariel
>>> 
>>> 
>>>   -----Original Message-----
>>>   From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
>>>   Sent: Saturday, April 09, 2016 5:27 AM
>>>   To: Jeff Newmiller
>>>   Cc: Paulson, Ariel; 'r-help at r-project.org'
>>>   Subject: Re: [FORGED] Re: [R] identical() versus sapply()
>>> 
>>>   On 09/04/16 16:24, Jeff Newmiller wrote:
>>>   I highly
>>> recommend making friends with the str function. Try
>>> 
>>>   str( 1 )
>>>   str( 1:2 )
>>> 
>>>   Interesting.  But to me counter-intuitive.  Since R makes no
>>> distinction
>>> between scalars and vectors of length 1 (or more accurately I think,
>>> since
>>> in R there is *no such thing as a scalar*, only a vector of length
>>>   1) I don't see why "1" should be treated in a manner that is
>>> categorically different from the way in which "1:2" is treated.
>>> 
>>>   Can you, or someone else with deep insight into R and its rationale,
>>> explain the basis for this difference in treatment?
>>> 
>>>   for the clue you need, and then
>>> 
>>>   sapply( 1:2, identical, 1L )
>>> 
>>>   cheers,
>>> 
>>>   Rolf
>>> 
>>>   --
>>>   Technical Editor ANZJS
>>>   Department of Statistics
>>>   University of Auckland
>>>   Phone: +64-9-373-7599 ext. 88276
>>> 
>>> ________________________________
>>> 
>>>   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>   https://stat.ethz.ch/mailman/listinfo/r-help
>>>   PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>   and provide commented, minimal, self-contained, reproducible code.
>>> 
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From jrkrideau at inbox.com  Tue Apr 12 13:45:16 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 12 Apr 2016 03:45:16 -0800
Subject: [R] [FORGED] Re: [FORGED] Re: identical() versus sapply()
In-Reply-To: <570C6CDE.2050907@auckland.ac.nz>
References: <cagxfjbsw-o85ianrxoqiisjn-mhsshat2djlpfre3tnuvorbmq@mail.gmail.com>
	<8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<570c4ac2.5040408@gmail.com>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<3470ae64-da70-45ee-9e14-6b2edd21a538@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570c6158.5010707@gmail.com>
	<d23058dd-e4df-4857-a0ae-d73b72562bdc@dcn.davis.ca.us>
	<cagxfjbqkq4dwfvdfkr=c_6avcvegs-tergcvel9nl0lmkxjjfq@mail.gmail.com>
	<5708d8f8.3020701@auckland.ac.nz>
Message-ID: <284DC790A9E.00000E05jrkrideau@inbox.com>


Thank you Rolf.  fortune(350) was the link I was trying to remember.

I believe! I believe in the documentation. 

It can be incredibly difficult to document something and unless one has an editor to read and 'try' to interpret the results the original writer may not realise just how opaque the explanation is.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r.turner at auckland.ac.nz
> Sent: Tue, 12 Apr 2016 15:34:54 +1200
> To: murdoch.duncan at gmail.com
> Subject: Re: [R] [FORGED] Re: [FORGED] Re: identical() versus sapply()
> 
> On 12/04/16 14:45, Duncan Murdoch wrote:
>> On 11/04/2016 10:18 PM, Bert Gunter wrote:
>>> "The documentation aims to be accurate, not necessarily clear."
>>> 
>>> !!!
>>> 
>>> I hope that is not the case! Accurate documentation that is confusing
>>> is not very useful.
>> 
>> I don't think it is ever intentionally confusing, but it is often
>> concise to the point of obscurity.  Words are chosen carefully, and
>> explanations are not repeated.  It takes an effort to read it.  It will
>> be clear to careful readers, but not to all readers.
>> 
>> I was thinking of the statement quoted earlier, 'as(x, "numeric") uses
>> the existing as.numeric function'.  That is different than saying 'as(x,
>> "numeric") is the same as as.numeric(x)'.
> 
> 
> IMHO this is so *obviously* confusing and misleading --- even though it
> is technically correct --- that whoever wrote it was either
> intentionally trying to be confusing or is unbelievably obtuse and/or
> out of touch with reality.
> 
> It is not (again IMHO) clear even to *very* careful readers.
> 
> To my mind this documentation fails even the fortune(350) test.
> 
> cheers,
> 
> Rolf
> 
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From John.Szumiloski at bms.com  Tue Apr 12 13:51:43 2016
From: John.Szumiloski at bms.com (Szumiloski, John)
Date: Tue, 12 Apr 2016 11:51:43 +0000
Subject: [R] Dispatch issue in package check?
Message-ID: <1f140c52f574404f9ba389019f5c4b64@CO2PR26MB0011.067d.mgd.msft.net>

Dear useRs,

I am developing a package using RStudio and roxygen markup files.  I have run into a problem while checking.

The relevant function is a generic S3 statistical function modeled on t.test(), with methods.  It returns an object of class "htest" etc.  Here Is the (anonymized) relevant code:

                <...>
#' @examples
#' foo(c(5,4,6,5,7,9,8,11,12,10), <other arguments>)
                <...>
#' @export
foo <- function(x, ...) UseMethod("foo ")
#'
foo.default <- function(x, <other specific arguments>)  {< code adapted from t.test.default() >}
#'
foo.formula <- function(formula, data, subset, na.action, ...) {< code adapted from t.test.formula() >)

The issue comes when checking.  In RStudio I select the Check button in the Build tab.  It executes the command


devtools::check(cleanup = FALSE)

I attach the console output to demonstrate the error, as well as to perhaps see any clues:


Updating <pkg> documentation

Loading <pkg>

Writing NAMESPACE

Writing <Rd files...>

Writing foo.Rd

Writing <Rd files...>

Setting env vars ---------------------------------------------------------------

CFLAGS  : -Wall -pedantic

CXXFLAGS: -Wall -pedantic

Building <pkg> ---------------------------------------------------------------

"C:/PROGRA~1/R/R-32~1.4/bin/i386/R" --no-site-file --no-environ --no-save  \

  --no-restore --quiet CMD build "C:\Users\szumiloj\R\<pkg>"  \

  --no-resave-data --no-manual



* checking for file 'C:\Users\szumiloj\R\<pkg>/DESCRIPTION' ... OK

* preparing '<pkg>':

* checking DESCRIPTION meta-information ... OK

* checking for LF line-endings in source and make files

* checking for empty or unneeded directories

* building '<pkg>_0.0.0.9001.tar.gz'



Setting env vars ---------------------------------------------------------------

_R_CHECK_CRAN_INCOMING_ : FALSE

_R_CHECK_FORCE_SUGGESTS_: FALSE

Checking <other arguments>) ---------------------------------------------------------------

"C:/PROGRA~1/R/R-32~1.4/bin/i386/R" --no-site-file --no-environ --no-save  \

  --no-restore --quiet CMD check  \

  "C:\Users\szumiloj\AppData\Local\Temp\RtmpWKHu33/<pkg>_0.0.0.9001.tar.gz"  \

  --as-cran --timings --no-manual



* using log directory 'C:/Users/szumiloj/R/<pkg>.Rcheck'

* using R version 3.2.4 (2016-03-10)

* using platform: i386-w64-mingw32 (32-bit)

* using session charset: ISO8859-1

* using options '--no-manual --as-cran'

* checking for file '<pkg>/DESCRIPTION' ... OK

* checking extension type ... Package

* this is package '<pkg>' version '0.0.0.9001'

* checking package namespace information ... OK

* checking package dependencies ... OK

* checking if this is a source package ... OK

* checking if there is a namespace ... OK

* checking for executable files ... OK

* checking for hidden files and directories ... OK

* checking for portable file names ... OK

* checking whether package '<pkg>' can be installed ... OK

* checking installed package size ... OK

* checking package directory ... OK

* checking DESCRIPTION meta-information ... OK

* checking top-level files ... OK

* checking for left-over files ... OK

* checking index information ... OK

* checking package subdirectories ... OK

* checking R files for non-ASCII characters ... OK

* checking R files for syntax errors ... OK

* checking whether the package can be loaded ... OK

* checking whether the package can be loaded with stated dependencies ... OK

* checking whether the package can be unloaded cleanly ... OK

* checking whether the namespace can be loaded with stated dependencies ... OK

* checking whether the namespace can be unloaded cleanly ... OK

* checking loading without being on the library search path ... OK

* checking dependencies in R code ... OK

* checking S3 generic/method consistency ... OK

* checking replacement functions ... OK

* checking foreign function calls ... OK

* checking R code for possible problems ... OK

* checking Rd files ... OK

* checking Rd metadata ... OK

* checking Rd line widths ... OK

* checking Rd cross-references ... OK

* checking for missing documentation entries ... OK

* checking for code/documentation mismatches ... OK

* checking Rd \usage sections ... OK

* checking Rd contents ... OK

* checking for unstated dependencies in examples ... OK

* checking examples ... ERROR

Running examples in '<pkg>-Ex.R' failed

The error most likely occurred in:



> base::assign(".ptime", proc.time(), pos = "CheckExEnv")

> ### Name: foo

> ### Title: <foo title>

> ### Aliases: foo foo.default foo.formula <"Foo" etc>

>

> ### ** Examples

>

> foo(c(5,4,6,5,7,9,8,11,12,10), <other arguments>)

Error in UseMethod("foo") :

  no applicable method for 'foo' applied to an object of class "c('double', 'numeric')"

Calls: foo

Execution halted

* DONE

Status: 1 ERROR



See

  'C:/Users/szumiloj/R/<pkg>.Rcheck/00check.log'

for details.



checking examples ... ERROR

Running examples in '<pkg>-Ex.R' failed

The error most likely occurred in:



> base::assign(".ptime", proc.time(), pos = "CheckExEnv")

> ### Name: foo

> ### Title: <foo title>

> ### Aliases: foo foo.default foo.formula <"Foo" etc>

>

> ### ** Examples

>

> foo(c(5,4,6,5,7,9,8,11,12,10), <other arguments>)

Error in UseMethod("foo") :

  no applicable method for 'foo' applied to an object of class "c('double', 'numeric')"

Calls: foo

Execution halted

R CMD check results

1 error  | 0 warnings | 0 notes

Warning messages:

1: `cleanup` is deprecated

2: @title [foo.R#1]: requires a value

3: @description [foo.R#1]: requires a value

4: @title [foo.R#1]: requires a value

5: @description [foo.R#1]: requires a value



R CMD check succeeded

It appears to me there is a dispatch problem, that the default method is not being called.  The issue persists even if I @export the default and formula methods.

However, if I source() the whole file foo.Rd into the global environment, then run the example foo(c(5,4,6,5,7,9,8,11,12,10), <other arguments>), it runs just fine.

Any insight as to what is happening here?  Also I do not understand the warnings about @title and @description, as I certainly have those fields in the source file.  But this is not as critical.

Thanks in advance,
John Szumiloski

######## session info


> version

               _

platform       i386-w64-mingw32

arch           i386

os             mingw32

system         i386, mingw32

status

major          3

minor          2.4

year           2016

month          03

day            10

svn rev        70301

language       R

version.string R version 3.2.4 (2016-03-10)

nickname       Very Secure Dishes

> devtools::session_info()

Session info --------------------------------------------------------------------------------

 setting  value

 version  R version 3.2.4 (2016-03-10)

 system   i386, mingw32

 ui       RStudio (0.99.893)

 language (EN)

 collate  English_United States.1252

 tz       America/New_York

 date     2016-04-12



Packages ------------------------------------------------------------------------------------

 package  * version date       source

 devtools * 1.11.0  2016-04-12 CRAN (R 3.2.4)

 digest     0.6.9   2016-01-08 CRAN (R 3.2.3)

 magrittr   1.5     2014-11-22 CRAN (R 3.2.0)

 memoise    1.0.0   2016-01-29 CRAN (R 3.2.3)

 Rcpp       0.12.4  2016-03-26 CRAN (R 3.2.4)

 roxygen2 * 5.0.1   2015-11-11 CRAN (R 3.2.2)

 stringi    1.0-1   2015-10-22 CRAN (R 3.2.2)

 stringr    1.0.0   2015-04-30 CRAN (R 3.2.0)

 withr      1.0.1   2016-02-04 CRAN (R 3.2.3)


John Szumiloski, Ph.D.
Senior Principal Scientist, Statistician
Analytical and Bioanalytical Operations<http://teams.bms.com/sites/ARD/>
NBR105-1-1411

Bristol-Myers Squibb
P.O. Box 191
1 Squibb Drive
New Brunswick, NJ
08903-0191
USA
(732) 227-7167
________________________________
This message (including any attachments) may contain con...{{dropped:11}}


From murdoch.duncan at gmail.com  Tue Apr 12 14:06:42 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Apr 2016 08:06:42 -0400
Subject: [R] [FORGED] Re:  [FORGED] Re: identical() versus sapply()
In-Reply-To: <570C6CDE.2050907@auckland.ac.nz>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
Message-ID: <570CE4D2.4020405@gmail.com>

On 11/04/2016 11:34 PM, Rolf Turner wrote:
> On 12/04/16 14:45, Duncan Murdoch wrote:
>> On 11/04/2016 10:18 PM, Bert Gunter wrote:
>>> "The documentation aims to be accurate, not necessarily clear."
>>>
>>> !!!
>>>
>>> I hope that is not the case! Accurate documentation that is confusing
>>> is not very useful.
>>
>> I don't think it is ever intentionally confusing, but it is often
>> concise to the point of obscurity.  Words are chosen carefully, and
>> explanations are not repeated.  It takes an effort to read it.  It will
>> be clear to careful readers, but not to all readers.
>>
>> I was thinking of the statement quoted earlier, 'as(x, "numeric") uses
>> the existing as.numeric function'.  That is different than saying 'as(x,
>> "numeric") is the same as as.numeric(x)'.
>
>
> IMHO this is so *obviously* confusing and misleading --- even though it
> is technically correct --- that whoever wrote it was either
> intentionally trying to be confusing or is unbelievably obtuse and/or
> out of touch with reality.
>
> It is not (again IMHO) clear even to *very* careful readers.
>
> To my mind this documentation fails even the fortune(350) test.
>

I generally agree that that particular sentence falls pretty far out on 
the obscurity end of the spectrum, but it's much easier to criticize the 
documentation than it is to write it.  I notice that none of the critics 
in this thread have offered improvements on what is there.

I haven't looked up who wrote it (it wasn't me, though I'm sure I've 
written equally obscure sentences), but I do not believe it was 
intentionally confusing, nor is the author obtuse or out of touch with 
reality.  I think that insulting authors is not a way to encourage them 
to change.  That's reality.

Duncan Murdoch


From milujisb at gmail.com  Tue Apr 12 11:58:47 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Tue, 12 Apr 2016 11:58:47 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CA+8X3fXaHp6aiZ0K+B3Wv_zw=s1gW0neD_QDt7kW5LunHE5WLg@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
	<3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
	<CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>
	<CA+8X3fXaHp6aiZ0K+B3Wv_zw=s1gW0neD_QDt7kW5LunHE5WLg@mail.gmail.com>
Message-ID: <CAMLwc7NZGuoyAkXhokJXwjHT4eUsb1w0SLJHQNWcnTZuo7YQ6g@mail.gmail.com>

Dear Jim,

Thanks again! I do want the arrows at the bottom (beneath the map). This is
what I am doing:

# Draw the map
eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score", mapTitle="EPS
Score - Europe",colourPalette=colourPalette,
catMethod="fixedWidth", missingCountryCol = "white", mapRegion="Europe",
addLegend=FALSE)

# ISO3 codes on the map
text(n, labels="ISO3", cex=0.30)

# Obtain coordinates for the arrow
par('usr')

# -19.75966  54.75966  33.60000  71.40000

# Arrows
par(xpd=TRUE)
arrows(-19.75966,  54.75966,  33.60000,  71.40000,code=3)
par(xpd=FALSE)

As the output shows I cannot seem to get the correct coordinates for the
arrows. Thanks again.

Sincerely,

Milu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: myplot.pdf
Type: application/pdf
Size: 116608 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160412/d53f8072/attachment.pdf>

From milujisb at gmail.com  Tue Apr 12 14:11:10 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Tue, 12 Apr 2016 14:11:10 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CA+8X3fU+r4iFOQUpA+hQaV7Ub=spxd9deWbhzDk8dxNGTBZjBg@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
	<3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
	<CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>
	<CA+8X3fXaHp6aiZ0K+B3Wv_zw=s1gW0neD_QDt7kW5LunHE5WLg@mail.gmail.com>
	<CAMLwc7NZGuoyAkXhokJXwjHT4eUsb1w0SLJHQNWcnTZuo7YQ6g@mail.gmail.com>
	<CA+8X3fU+r4iFOQUpA+hQaV7Ub=spxd9deWbhzDk8dxNGTBZjBg@mail.gmail.com>
Message-ID: <CAMLwc7PAptJ-Q4ci5W2pY4PMar9jJQisyXLtLfb0d+61Sq46dA@mail.gmail.com>

Hello Jim,

Thanks again. I am getting the two-headed arrow but I cannot seem to get
the coordinates right for the arrow to appear beneath the map. These
coordinates puts the arrow on the left hand side. Thanks again!

Sincerely,

Milu

On Tue, Apr 12, 2016 at 1:15 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Milu,
> There is a two-headed arrow on the image you sent, and it seems to be
> where you specified. Did you want it beneath the map, as:
>
> par(xpd=TRUE)
> arrows(-22,54.75,-22,74,code=3)
> par(xpd=FALSE)
>
> Jim
>
> On Tue, Apr 12, 2016 at 7:58 PM, Miluji Sb <milujisb at gmail.com> wrote:
> > Dear Jim,
> >
> > Thanks again! I do want the arrows at the bottom (beneath the map). This
> is
> > what I am doing:
> >
> > # Draw the map
> > eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score",
> mapTitle="EPS
> > Score - Europe",colourPalette=colourPalette,
> > catMethod="fixedWidth", missingCountryCol = "white", mapRegion="Europe",
> > addLegend=FALSE)
> >
> > # ISO3 codes on the map
> > text(n, labels="ISO3", cex=0.30)
> >
> > # Obtain coordinates for the arrow
> > par('usr')
> >
> > # -19.75966  54.75966  33.60000  71.40000
> >
> > # Arrows
> > par(xpd=TRUE)
> > arrows(-19.75966,  54.75966,  33.60000,  71.40000,code=3)
> > par(xpd=FALSE)
> >
> > As the output shows I cannot seem to get the correct coordinates for the
> > arrows. Thanks again.
> >
> > Sincerely,
> >
> > Milu
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: myplot.pdf
Type: application/pdf
Size: 113072 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160412/745a323a/attachment.pdf>

From profjcnash at gmail.com  Tue Apr 12 15:21:17 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Tue, 12 Apr 2016 09:21:17 -0400
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <570CE4D2.4020405@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com>
Message-ID: <570CF64D.7000403@gmail.com>


>>>> "The documentation aims to be accurate, not necessarily clear."
> I notice that none of the critics
> in this thread have offered improvements on what is there.


This issue is as old as documented things. With software it is
particularly nasty, especially when we want the software to function
across many platforms.

Duncan has pointed out that critics need to step up to do something.
I would put documentation failures at the top of my list of
time-wasters, and have been bitten by some particularly weak offerings
(not in R) in the last 2 weeks. So ....

Proposal: That the R community consider establishing a "test and
document" group to parallel R-core to focus on the documentation.
An experiment to test the waters is suggested below.

The needs:
- tools that let the difficulties with documentation be visualized along
with proposed changes and the discussion accessed by the wider
community, while keeping a well-defined process for committing accepted
changes.
- a process for the above. Right now a lot happens by discussion in the
lists and someone in R-core committing the result. If it is
well-organized, it is not well-understood by the wider R user community.
- tools for managing and providing access to tests

At the risk of opening another can of worms, documentation is an area
where such an effort could benefit from paid help. It's an area where
there's low reward for high effort, particularly for volunteers.
Moreover, like many volunteers, I'm happy to do some work, but I need
ways to contribute in small bites (bytes?), and it is difficult to find
suitable tasks to take on.

Is it worth an experiment to customize something like Dokuwiki (which I
believe was the platform for the apparently defunct R wiki) to allow a
segment of R documentation to be reviewed, discussed and changes
proposed? It could show how we might get to a better process for
managing R documentation.

Cheers, JN


From lists at dewey.myzen.co.uk  Tue Apr 12 15:51:08 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 12 Apr 2016 14:51:08 +0100
Subject: [R] [FORGED] Re: [FORGED] Re: identical() versus sapply()
In-Reply-To: <284DC790A9E.00000E05jrkrideau@inbox.com>
References: <cagxfjbsw-o85ianrxoqiisjn-mhsshat2djlpfre3tnuvorbmq@mail.gmail.com>
	<8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<570c4ac2.5040408@gmail.com>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<3470ae64-da70-45ee-9e14-6b2edd21a538@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570c6158.5010707@gmail.com>
	<d23058dd-e4df-4857-a0ae-d73b72562bdc@dcn.davis.ca.us>
	<cagxfjbqkq4dwfvdfkr=c_6avcvegs-tergcvel9nl0lmkxjjfq@mail.gmail.com>
	<5708d8f8.3020701@auckland.ac.nz>
	<284DC790A9E.00000E05jrkrideau@inbox.com>
Message-ID: <570CFD4C.2080204@dewey.myzen.co.uk>

Short comment inline

On 12/04/2016 12:45, John Kane wrote:
>
> Thank you Rolf.  fortune(350) was the link I was trying to remember.
>
> I believe! I believe in the documentation.
>
> It can be incredibly difficult to document something and unless one has an editor to read and 'try' to interpret the results the original writer may not realise just how opaque the explanation is.
>

I do not think anyone who has written documentation would disagree.
Would one way forward here for the OP to suggest with the benefit of all 
the comments how things might be enhanced so that he would not have been 
baffled?

> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: r.turner at auckland.ac.nz
>> Sent: Tue, 12 Apr 2016 15:34:54 +1200
>> To: murdoch.duncan at gmail.com
>> Subject: Re: [R] [FORGED] Re: [FORGED] Re: identical() versus sapply()
>>
>> On 12/04/16 14:45, Duncan Murdoch wrote:
>>> On 11/04/2016 10:18 PM, Bert Gunter wrote:
>>>> "The documentation aims to be accurate, not necessarily clear."
>>>>
>>>> !!!
>>>>
>>>> I hope that is not the case! Accurate documentation that is confusing
>>>> is not very useful.
>>>
>>> I don't think it is ever intentionally confusing, but it is often
>>> concise to the point of obscurity.  Words are chosen carefully, and
>>> explanations are not repeated.  It takes an effort to read it.  It will
>>> be clear to careful readers, but not to all readers.
>>>
>>> I was thinking of the statement quoted earlier, 'as(x, "numeric") uses
>>> the existing as.numeric function'.  That is different than saying 'as(x,
>>> "numeric") is the same as as.numeric(x)'.
>>
>>
>> IMHO this is so *obviously* confusing and misleading --- even though it
>> is technically correct --- that whoever wrote it was either
>> intentionally trying to be confusing or is unbelievably obtuse and/or
>> out of touch with reality.
>>
>> It is not (again IMHO) clear even to *very* careful readers.
>>
>> To my mind this documentation fails even the fortune(350) test.
>>
>> cheers,
>>
>> Rolf
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Can't remember your password? Do you need a strong and secure password?
> Use Password manager! It stores your passwords & protects your account.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From Keith.Jewell at campdenbri.co.uk  Tue Apr 12 16:43:22 2016
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Tue, 12 Apr 2016 15:43:22 +0100
Subject: [R] formula argument evaluation
In-Reply-To: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
References: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
Message-ID: <nej1ia$t9u$1@ger.gmane.org>

On 12/04/2016 11:24, Adrian Du?a wrote:
> I have a simple function such as:
>
> foo <- function(x) {
>      call <- lapply(match.call(), deparse)
>      testit <- capture.output(tryCatch(eval(x), error = function(e) e))
>      if (grepl("Error", testit)) {
>          return(call$x)
>      }
> }
>
> and I would like to detect a formula when x is not an object:
>
> # this works
>> foo(A + B)
> [1] "A + B"
>
> # but this doesn't
>> foo(A + B => C)
> Error: unexpected '=' in "foo(A + B ="
>
> Can I prevent it from evaluating the "=" sign?
> The addition sign "+" hasn't been evaluated, and I was hoping the "=" would
> not get evaluated either. The "=>" sign is important for other purposes,
> not related to this example.
>
> Thank you in advance,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
> 	[[alternative HTML version deleted]]
>
Did you mean
 > foo (A + B >= C)
??


From murdoch.duncan at gmail.com  Tue Apr 12 16:52:14 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Apr 2016 10:52:14 -0400
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <570CF64D.7000403@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
Message-ID: <570D0B9E.6060304@gmail.com>

On 12/04/2016 9:21 AM, ProfJCNash wrote:
> >>>> "The documentation aims to be accurate, not necessarily clear."
> > I notice that none of the critics
> > in this thread have offered improvements on what is there.
>
>
> This issue is as old as documented things. With software it is
> particularly nasty, especially when we want the software to function
> across many platforms.
>
> Duncan has pointed out that critics need to step up to do something.
> I would put documentation failures at the top of my list of
> time-wasters, and have been bitten by some particularly weak offerings
> (not in R) in the last 2 weeks. So ....
>
> Proposal: That the R community consider establishing a "test and
> document" group to parallel R-core to focus on the documentation.
> An experiment to test the waters is suggested below.
>
> The needs:
> - tools that let the difficulties with documentation be visualized along
> with proposed changes and the discussion accessed by the wider
> community, while keeping a well-defined process for committing accepted
> changes.
> - a process for the above. Right now a lot happens by discussion in the
> lists and someone in R-core committing the result. If it is
> well-organized, it is not well-understood by the wider R user community.
> - tools for managing and providing access to tests
>
> At the risk of opening another can of worms, documentation is an area
> where such an effort could benefit from paid help. It's an area where
> there's low reward for high effort, particularly for volunteers.
> Moreover, like many volunteers, I'm happy to do some work, but I need
> ways to contribute in small bites (bytes?), and it is difficult to find
> suitable tasks to take on.
>
> Is it worth an experiment to customize something like Dokuwiki (which I
> believe was the platform for the apparently defunct R wiki) to allow a
> segment of R documentation to be reviewed, discussed and changes
> proposed? It could show how we might get to a better process for
> managing R documentation.

The idea of having non-core people write and test documentation appeals 
to me.   The mechanism (Dokuwiki or whatever) makes no difference to me; 
it should be up to the participants to decide on what works.

The difficulty will be "calibration":  those people need to make changes 
that core members agree are improvements, or they won't be incorporated.

I'd suggest that you start very slowly.  First choose *one* help page 
that you think needs improvement, and explain why to one of the authors 
of that page, and what sort of improvements you propose to make.  Then 
get  the author to agree with the proposal, do it, and get the same 
author to agree to the final version and commit it.

I'll volunteer to participate in the approval and committing stage, but 
at first only for pages that I authored.  If it turns out to be an 
efficient way to improve docs, then I'd consider other pages too.

Duncan Murdoch


From bgunter.4567 at gmail.com  Tue Apr 12 17:06:57 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 12 Apr 2016 08:06:57 -0700
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <570CF64D.7000403@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
Message-ID: <CAGxFJbSMUbdZ+=4mQD67M1HAcikW2NwHB3owLs1Q=_1VgT5MEQ@mail.gmail.com>

FWIW:

1. I agree that this is an idea worth considering. Especially now that
R has become so widely used among practitioners who are neither
especially software literate nor interested in poring over R manuals
(as I did when I first learned R). They have explicit tasks to do and
just want to get to them as directly as possible.

2. A partial reply to the (fair) criticism of those who criticize docs
without offering improvements is that one may not know what
improvement to offer precisely because the docs do not make it clear.
This proposal or something similar addresses this issue. The experts
could adjudicate.

3. I agree: writing good docs is hard. Having a mechanism like this
would also help non-native English writers of software (or challenged
native writers like me!) .

4. I also think John is right, that if the right mechanism were found
so that small efforts could be accumulated, a lot of us would
participate. A wiki sounds about right, but I bow to those with
greater wisdom and experience here.

5. The danger here is that this would suck a lot of time from R core.
That's unacceptable. Presumably a wiki (self-correcting?) would help
avoid this.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 12, 2016 at 6:21 AM, ProfJCNash <profjcnash at gmail.com> wrote:
>
>>>>> "The documentation aims to be accurate, not necessarily clear."
>> I notice that none of the critics
>> in this thread have offered improvements on what is there.
>
>
> This issue is as old as documented things. With software it is
> particularly nasty, especially when we want the software to function
> across many platforms.
>
> Duncan has pointed out that critics need to step up to do something.
> I would put documentation failures at the top of my list of
> time-wasters, and have been bitten by some particularly weak offerings
> (not in R) in the last 2 weeks. So ....
>
> Proposal: That the R community consider establishing a "test and
> document" group to parallel R-core to focus on the documentation.
> An experiment to test the waters is suggested below.
>
> The needs:
> - tools that let the difficulties with documentation be visualized along
> with proposed changes and the discussion accessed by the wider
> community, while keeping a well-defined process for committing accepted
> changes.
> - a process for the above. Right now a lot happens by discussion in the
> lists and someone in R-core committing the result. If it is
> well-organized, it is not well-understood by the wider R user community.
> - tools for managing and providing access to tests
>
> At the risk of opening another can of worms, documentation is an area
> where such an effort could benefit from paid help. It's an area where
> there's low reward for high effort, particularly for volunteers.
> Moreover, like many volunteers, I'm happy to do some work, but I need
> ways to contribute in small bites (bytes?), and it is difficult to find
> suitable tasks to take on.
>
> Is it worth an experiment to customize something like Dokuwiki (which I
> believe was the platform for the apparently defunct R wiki) to allow a
> segment of R documentation to be reviewed, discussed and changes
> proposed? It could show how we might get to a better process for
> managing R documentation.
>
> Cheers, JN
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dusa.adrian at unibuc.ro  Tue Apr 12 17:09:50 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Tue, 12 Apr 2016 18:09:50 +0300
Subject: [R] formula argument evaluation
In-Reply-To: <570CD71E.4040107@gmail.com>
References: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
	<570CD71E.4040107@gmail.com>
Message-ID: <CAJ=0CtBRNHsa=8hrULR3aK8V0si4S+gmyZzhCYHs7iVVN56afw@mail.gmail.com>

On Tue, Apr 12, 2016 at 2:08 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:
> [...]
>
> It never gets to evaluating it.  It is not a legal R statement, so the
parser signals an error.
> If you want to pass arbitrary strings to a function, you need to put them
in quotes.

I see. I thought it was parsed inside the function, but if it's parsed
before then quoting is the only option.


To Keith: no, I mean it like this "A + B => C" which is translated as:
"the union of A and B is sufficient for C" in set theoretic language.

The "=>" operator means sufficiency, while "<=" means necessity. Quoting
the expression is good enough, I was just curious if the quotes could be
made redundant, somehow.

Thank you both,
Adrian

--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue Apr 12 17:20:47 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 12 Apr 2016 11:20:47 -0400
Subject: [R] formula argument evaluation
In-Reply-To: <CAJ=0CtBRNHsa=8hrULR3aK8V0si4S+gmyZzhCYHs7iVVN56afw@mail.gmail.com>
References: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
	<570CD71E.4040107@gmail.com>
	<CAJ=0CtBRNHsa=8hrULR3aK8V0si4S+gmyZzhCYHs7iVVN56afw@mail.gmail.com>
Message-ID: <CAGx1TMAruoQ5r+_f=F3x2f7D0LVd0LX+-muxbP4XcRar=g-V_w@mail.gmail.com>

Would making it regular function %=>%, using "%" instead of quotes,
work for you?

On Tue, Apr 12, 2016 at 11:09 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> On Tue, Apr 12, 2016 at 2:08 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>> [...]
>>
>> It never gets to evaluating it.  It is not a legal R statement, so the
> parser signals an error.
>> If you want to pass arbitrary strings to a function, you need to put them
> in quotes.
>
> I see. I thought it was parsed inside the function, but if it's parsed
> before then quoting is the only option.
>
>
> To Keith: no, I mean it like this "A + B => C" which is translated as:
> "the union of A and B is sufficient for C" in set theoretic language.
>
> The "=>" operator means sufficiency, while "<=" means necessity. Quoting
> the expression is good enough, I was just curious if the quotes could be
> made redundant, somehow.
>
> Thank you both,
> Adrian
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Tue Apr 12 17:25:30 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 12 Apr 2016 11:25:30 -0400
Subject: [R] Correlation between package output
In-Reply-To: <CAG0T74qaxW5QezD-mw+WHjoHatUq2thVp0yHp0g07T0V9WPQQg@mail.gmail.com>
References: <CAG0T74qaxW5QezD-mw+WHjoHatUq2thVp0yHp0g07T0V9WPQQg@mail.gmail.com>
Message-ID: <CAM_vjukOAuTWHMj0GF_yiMmCVRREdvxt4jjKXjGe-D7XkfACTg@mail.gmail.com>

Hi Fabio,

Using the first example from ?dbFD

ex1 <- dbFD(dummy$trait, dummy$abun)

If you look at that help page, or at str(ex1), you'll see that the
returned object is a list with named components. So, you can access
the different indices just as you would access any other list. If
that's confusing to you, a good basic intro to R might be just the
thing.

Here are two ways to do so:
with(ex1, plot(nbsp, FRic))
cor(ex1$nbsp, ex1$FRic, use="pair") # the toy example has one NA value

You might in the future find R-sig-ecology to be a better place to ask
this sort of question.

Sarah


On Mon, Apr 11, 2016 at 9:20 AM, Fabio Monteiro
<fabio.monteiro1992 at gmail.com> wrote:
> Hello
>
> I'm currently using the dbFD function of the FD package and i'm having some
> things that I can't do.
>
> Is there any way to check the relations between dbFD indexes?
>
> Function cor for example? I can't manage to put the informations correctly
>
> dbFD function gives a lot of output (indexes - nbsp, sing.sp, FRic, FEve,
> FDiv, FDis and RaoQ). I want to see the relationships between the dbFD
> output (nbsp, sing.sp, FRic, FEve, FDiv, FDis and RaoQ)
>
> How should I type it?
>
> Thank you
>
> F?bio
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From profjcnash at gmail.com  Tue Apr 12 17:30:59 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Tue, 12 Apr 2016 11:30:59 -0400
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <570D0B9E.6060304@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
	<570D0B9E.6060304@gmail.com>
Message-ID: <570D14B3.6000701@gmail.com>

Thanks Duncan, for the offer to experiment.

Can you suggest a couple of your pages that you think might need
improvement? We might as well start with something you'd like looked at.

Then I'll ask if there are interested people and see what can be done
about getting a framework set up to work on one of those documents.

JN


On 16-04-12 10:52 AM, Duncan Murdoch wrote:
> On 12/04/2016 9:21 AM, ProfJCNash wrote:
>> >>>> "The documentation aims to be accurate, not necessarily clear."
>> > I notice that none of the critics
>> > in this thread have offered improvements on what is there.
>>
>>
>> This issue is as old as documented things. With software it is
>> particularly nasty, especially when we want the software to function
>> across many platforms.
>>
>> Duncan has pointed out that critics need to step up to do something.
>> I would put documentation failures at the top of my list of
>> time-wasters, and have been bitten by some particularly weak offerings
>> (not in R) in the last 2 weeks. So ....
>>
>> Proposal: That the R community consider establishing a "test and
>> document" group to parallel R-core to focus on the documentation.
>> An experiment to test the waters is suggested below.
>>
>> The needs:
>> - tools that let the difficulties with documentation be visualized along
>> with proposed changes and the discussion accessed by the wider
>> community, while keeping a well-defined process for committing accepted
>> changes.
>> - a process for the above. Right now a lot happens by discussion in the
>> lists and someone in R-core committing the result. If it is
>> well-organized, it is not well-understood by the wider R user community.
>> - tools for managing and providing access to tests
>>
>> At the risk of opening another can of worms, documentation is an area
>> where such an effort could benefit from paid help. It's an area where
>> there's low reward for high effort, particularly for volunteers.
>> Moreover, like many volunteers, I'm happy to do some work, but I need
>> ways to contribute in small bites (bytes?), and it is difficult to find
>> suitable tasks to take on.
>>
>> Is it worth an experiment to customize something like Dokuwiki (which I
>> believe was the platform for the apparently defunct R wiki) to allow a
>> segment of R documentation to be reviewed, discussed and changes
>> proposed? It could show how we might get to a better process for
>> managing R documentation.
> 
> The idea of having non-core people write and test documentation appeals
> to me.   The mechanism (Dokuwiki or whatever) makes no difference to me;
> it should be up to the participants to decide on what works.
> 
> The difficulty will be "calibration":  those people need to make changes
> that core members agree are improvements, or they won't be incorporated.
> 
> I'd suggest that you start very slowly.  First choose *one* help page
> that you think needs improvement, and explain why to one of the authors
> of that page, and what sort of improvements you propose to make.  Then
> get  the author to agree with the proposal, do it, and get the same
> author to agree to the final version and commit it.
> 
> I'll volunteer to participate in the approval and committing stage, but
> at first only for pages that I authored.  If it turns out to be an
> efficient way to improve docs, then I'd consider other pages too.
> 
> Duncan Murdoch


From sarah.goslee at gmail.com  Tue Apr 12 17:31:19 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 12 Apr 2016 11:31:19 -0400
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <CAGxFJbSMUbdZ+=4mQD67M1HAcikW2NwHB3owLs1Q=_1VgT5MEQ@mail.gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
	<CAGxFJbSMUbdZ+=4mQD67M1HAcikW2NwHB3owLs1Q=_1VgT5MEQ@mail.gmail.com>
Message-ID: <CAM_vjuniDNTUHbFD=tKLR565msDoL5Uoz5d3nuaFQn7+Ukeyxg@mail.gmail.com>

I am very interested in such a distributed documentation editing
project, and have some thoughts on how to make it workable for both
volunteers and core members who would need to review.

I'm willing to lead or colead such a project, if someone stepping up
would be a useful first step, and I'm also willing to host a wiki,
although I think something like GitHub is probably the best place.
I've been contemplating for a while how I can get more involved in the
main R efforts, and have contributed to the documentation before, in
tiny ways. I think those of us who have participated in R-help for a
while have an idea of the main stumbling blocks in the documentation
(besides, of course, getting people to read it in the first place).

I don't think R-help is the right place to continue discussion; should
this be moved to R-devel, or somewhere else entirely?

Sarah

On Tue, Apr 12, 2016 at 11:06 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> FWIW:
>
> 1. I agree that this is an idea worth considering. Especially now that
> R has become so widely used among practitioners who are neither
> especially software literate nor interested in poring over R manuals
> (as I did when I first learned R). They have explicit tasks to do and
> just want to get to them as directly as possible.
>
> 2. A partial reply to the (fair) criticism of those who criticize docs
> without offering improvements is that one may not know what
> improvement to offer precisely because the docs do not make it clear.
> This proposal or something similar addresses this issue. The experts
> could adjudicate.
>
> 3. I agree: writing good docs is hard. Having a mechanism like this
> would also help non-native English writers of software (or challenged
> native writers like me!) .
>
> 4. I also think John is right, that if the right mechanism were found
> so that small efforts could be accumulated, a lot of us would
> participate. A wiki sounds about right, but I bow to those with
> greater wisdom and experience here.
>
> 5. The danger here is that this would suck a lot of time from R core.
> That's unacceptable. Presumably a wiki (self-correcting?) would help
> avoid this.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 12, 2016 at 6:21 AM, ProfJCNash <profjcnash at gmail.com> wrote:
>>
>>>>>> "The documentation aims to be accurate, not necessarily clear."
>>> I notice that none of the critics
>>> in this thread have offered improvements on what is there.
>>
>>
>> This issue is as old as documented things. With software it is
>> particularly nasty, especially when we want the software to function
>> across many platforms.
>>
>> Duncan has pointed out that critics need to step up to do something.
>> I would put documentation failures at the top of my list of
>> time-wasters, and have been bitten by some particularly weak offerings
>> (not in R) in the last 2 weeks. So ....
>>
>> Proposal: That the R community consider establishing a "test and
>> document" group to parallel R-core to focus on the documentation.
>> An experiment to test the waters is suggested below.
>>
>> The needs:
>> - tools that let the difficulties with documentation be visualized along
>> with proposed changes and the discussion accessed by the wider
>> community, while keeping a well-defined process for committing accepted
>> changes.
>> - a process for the above. Right now a lot happens by discussion in the
>> lists and someone in R-core committing the result. If it is
>> well-organized, it is not well-understood by the wider R user community.
>> - tools for managing and providing access to tests
>>
>> At the risk of opening another can of worms, documentation is an area
>> where such an effort could benefit from paid help. It's an area where
>> there's low reward for high effort, particularly for volunteers.
>> Moreover, like many volunteers, I'm happy to do some work, but I need
>> ways to contribute in small bites (bytes?), and it is difficult to find
>> suitable tasks to take on.
>>
>> Is it worth an experiment to customize something like Dokuwiki (which I
>> believe was the platform for the apparently defunct R wiki) to allow a
>> segment of R documentation to be reviewed, discussed and changes
>> proposed? It could show how we might get to a better process for
>> managing R documentation.
>>
>> Cheers, JN
>>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From dwinsemius at comcast.net  Tue Apr 12 18:44:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 Apr 2016 09:44:12 -0700
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <CAM_vjuniDNTUHbFD=tKLR565msDoL5Uoz5d3nuaFQn7+Ukeyxg@mail.gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
	<CAGxFJbSMUbdZ+=4mQD67M1HAcikW2NwHB3owLs1Q=_1VgT5MEQ@mail.gmail.com>
	<CAM_vjuniDNTUHbFD=tKLR565msDoL5Uoz5d3nuaFQn7+Ukeyxg@mail.gmail.com>
Message-ID: <533B97A8-2860-4F32-AEE3-A628F7A1D25F@comcast.net>


> On Apr 12, 2016, at 8:31 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> I am very interested in such a distributed documentation editing
> project, and have some thoughts on how to make it workable for both
> volunteers and core members who would need to review.
> 
> I'm willing to lead or colead such a project, if someone stepping up
> would be a useful first step, and I'm also willing to host a wiki,
> although I think something like GitHub is probably the best place.
> I've been contemplating for a while how I can get more involved in the
> main R efforts, and have contributed to the documentation before, in
> tiny ways. I think those of us who have participated in R-help for a
> while have an idea of the main stumbling blocks in the documentation
> (besides, of course, getting people to read it in the first place).
> 
> I don't think R-help is the right place to continue discussion; should
> this be moved to R-devel, or somewhere else entirely?

I'm in. My personal experience with R's documentation has been mostly satisfactory, once I learned to pay careful attention to the words 'list', 'name', and 'expression'.  I'm not an experienced C programmer or package author, so the requirement that I submit a "diff" file to an existing document is a hurdle that I cannot not yet clear while running, but I can probably muscle my way over. I remember taking a big step up in learning R when I built a Powerpoint deck to teach basic R, so I would probably learn quite a bit from such a process.

My nomination for an improvement 'target' is the `?reshape` page. I've never been able to understand it, despite years of trying, and I've seen many others report a similar experience. Opinion: Its Details section needs to be expanded into two distinct subsections: a 'wide'-direction subsection and a 'long'-direction subsection. Each subsection would outline the minimum number of supplied arguments for an error-free execution. There need to be more worked examples, but those could easily be mined from problems submitted as recorded in the R-help Archives and StackOverFlow.

-- 
David.

> 
> Sarah
> 
> On Tue, Apr 12, 2016 at 11:06 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> FWIW:
>> 
>> 1. I agree that this is an idea worth considering. Especially now that
>> R has become so widely used among practitioners who are neither
>> especially software literate nor interested in poring over R manuals
>> (as I did when I first learned R). They have explicit tasks to do and
>> just want to get to them as directly as possible.
>> 
>> 2. A partial reply to the (fair) criticism of those who criticize docs
>> without offering improvements is that one may not know what
>> improvement to offer precisely because the docs do not make it clear.
>> This proposal or something similar addresses this issue. The experts
>> could adjudicate.
>> 
>> 3. I agree: writing good docs is hard. Having a mechanism like this
>> would also help non-native English writers of software (or challenged
>> native writers like me!) .
>> 
>> 4. I also think John is right, that if the right mechanism were found
>> so that small efforts could be accumulated, a lot of us would
>> participate. A wiki sounds about right, but I bow to those with
>> greater wisdom and experience here.
>> 
>> 5. The danger here is that this would suck a lot of time from R core.
>> That's unacceptable. Presumably a wiki (self-correcting?) would help
>> avoid this.
>> 
>> Cheers,
>> Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Tue, Apr 12, 2016 at 6:21 AM, ProfJCNash <profjcnash at gmail.com> wrote:
>>> 
>>>>>>> "The documentation aims to be accurate, not necessarily clear."
>>>> I notice that none of the critics
>>>> in this thread have offered improvements on what is there.
>>> 
>>> 
>>> This issue is as old as documented things. With software it is
>>> particularly nasty, especially when we want the software to function
>>> across many platforms.
>>> 
>>> Duncan has pointed out that critics need to step up to do something.
>>> I would put documentation failures at the top of my list of
>>> time-wasters, and have been bitten by some particularly weak offerings
>>> (not in R) in the last 2 weeks. So ....
>>> 
>>> Proposal: That the R community consider establishing a "test and
>>> document" group to parallel R-core to focus on the documentation.
>>> An experiment to test the waters is suggested below.
>>> 
>>> The needs:
>>> - tools that let the difficulties with documentation be visualized along
>>> with proposed changes and the discussion accessed by the wider
>>> community, while keeping a well-defined process for committing accepted
>>> changes.
>>> - a process for the above. Right now a lot happens by discussion in the
>>> lists and someone in R-core committing the result. If it is
>>> well-organized, it is not well-understood by the wider R user community.
>>> - tools for managing and providing access to tests
>>> 
>>> At the risk of opening another can of worms, documentation is an area
>>> where such an effort could benefit from paid help. It's an area where
>>> there's low reward for high effort, particularly for volunteers.
>>> Moreover, like many volunteers, I'm happy to do some work, but I need
>>> ways to contribute in small bites (bytes?), and it is difficult to find
>>> suitable tasks to take on.
>>> 
>>> Is it worth an experiment to customize something like Dokuwiki (which I
>>> believe was the platform for the apparently defunct R wiki) to allow a
>>> segment of R documentation to be reviewed, discussed and changes
>>> proposed? It could show how we might get to a better process for
>>> managing R documentation.
>>> 
>>> Cheers, JN
>>> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Tue Apr 12 18:58:09 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Apr 2016 12:58:09 -0400
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <533B97A8-2860-4F32-AEE3-A628F7A1D25F@comcast.net>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
	<CAGxFJbSMUbdZ+=4mQD67M1HAcikW2NwHB3owLs1Q=_1VgT5MEQ@mail.gmail.com>
	<CAM_vjuniDNTUHbFD=tKLR565msDoL5Uoz5d3nuaFQn7+Ukeyxg@mail.gmail.com>
	<533B97A8-2860-4F32-AEE3-A628F7A1D25F@comcast.net>
Message-ID: <570D2921.9060007@stats.uwo.ca>

On 12/04/2016 12:44 PM, David Winsemius wrote:
> > On Apr 12, 2016, at 8:31 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> >
> > I am very interested in such a distributed documentation editing
> > project, and have some thoughts on how to make it workable for both
> > volunteers and core members who would need to review.
> >
> > I'm willing to lead or colead such a project, if someone stepping up
> > would be a useful first step, and I'm also willing to host a wiki,
> > although I think something like GitHub is probably the best place.
> > I've been contemplating for a while how I can get more involved in the
> > main R efforts, and have contributed to the documentation before, in
> > tiny ways. I think those of us who have participated in R-help for a
> > while have an idea of the main stumbling blocks in the documentation
> > (besides, of course, getting people to read it in the first place).
> >
> > I don't think R-help is the right place to continue discussion; should
> > this be moved to R-devel, or somewhere else entirely?
>
> I'm in. My personal experience with R's documentation has been mostly satisfactory, once I learned to pay careful attention to the words 'list', 'name', and 'expression'.  I'm not an experienced C programmer or package author, so the requirement that I submit a "diff" file to an existing document is a hurdle that I cannot not yet clear while running, but I can probably muscle my way over. I remember taking a big step up in learning R when I built a Powerpoint deck to teach basic R, so I would probably learn quite a bit from such a process.
>
> My nomination for an improvement 'target' is the `?reshape` page. I've never been able to understand it, despite years of trying, and I've seen many others report a similar experience. Opinion: Its Details section needs to be expanded into two distinct subsections: a 'wide'-direction subsection and a 'long'-direction subsection. Each subsection would outline the minimum number of supplied arguments for an error-free execution. There need to be more worked examples, but those could easily be mined from problems submitted as recorded in the R-help Archives and StackOverFlow.

I'd suggest something different -- that one sounds hard.  The revision 
history for the last 13 years is shown below.  Though my name appears, 
it's for trivial changes, and I wouldn't consider myself to be an 
author, and I do not offer to participate in the revision.

Duncan

------------------------------------------------------------------------
r68948 | ripley | 2015-08-09 10:51:17 -0400 (Sun, 09 Aug 2015) | 1 line

use https
------------------------------------------------------------------------
r68070 | hornik | 2015-03-24 03:32:16 -0400 (Tue, 24 Mar 2015) | 1 line

Spelling.
------------------------------------------------------------------------
r68059 | ripley | 2015-03-21 18:14:23 -0400 (Sat, 21 Mar 2015) | 1 line

faulty svn merge, one more partial match
------------------------------------------------------------------------
r68055 | ripley | 2015-03-21 16:08:08 -0400 (Sat, 21 Mar 2015) | 1 line

document where use of match.arg allows partial matching
------------------------------------------------------------------------
r61521 | ripley | 2013-01-02 10:09:27 -0500 (Wed, 02 Jan 2013) | 1 line

correction
------------------------------------------------------------------------
r61433 | ripley | 2012-12-25 07:19:50 -0500 (Tue, 25 Dec 2012) | 1 line

remove trailing spaces
------------------------------------------------------------------------
r59039 | ripley | 2012-04-15 06:32:41 -0400 (Sun, 15 Apr 2012) | 1 line

use preferred form of 'R Core Team'
------------------------------------------------------------------------
r57816 | ripley | 2011-12-05 03:08:17 -0500 (Mon, 05 Dec 2011) | 1 line

more tidying up
------------------------------------------------------------------------
r57814 | ripley | 2011-12-05 02:42:30 -0500 (Mon, 05 Dec 2011) | 1 line

add note about duplicate records
------------------------------------------------------------------------
r57094 | maechler | 2011-09-27 11:32:03 -0400 (Tue, 27 Sep 2011) | 1 line

white space only
------------------------------------------------------------------------
r56186 | murdoch | 2011-06-19 21:51:45 -0400 (Sun, 19 Jun 2011) | 1 line

Revert r56184 and r56185
------------------------------------------------------------------------
r56184 | murdoch | 2011-06-19 19:58:46 -0400 (Sun, 19 Jun 2011) | 1 line

Remove redundant \alias entries from man pages
------------------------------------------------------------------------
r53637 | ripley | 2010-11-19 18:13:25 -0500 (Fri, 19 Nov 2010) | 1 line

revise documentation for PR#14435
------------------------------------------------------------------------
r50263 | ripley | 2009-10-30 13:52:33 -0400 (Fri, 30 Oct 2009) | 3 lines

spell 'indices' consistently
add an example of CJK fonts for quartz devices (borrowed from Ei-Ji Nakama)

------------------------------------------------------------------------
r49566 | ripley | 2009-09-04 17:41:50 -0400 (Fri, 04 Sep 2009) | 2 lines

remove unnecessay use of \link[]{} form

------------------------------------------------------------------------
r47616 | ripley | 2009-01-15 17:59:26 -0500 (Thu, 15 Jan 2009) | 2 lines

expand tabs in help files, which were often not rendering as intended

------------------------------------------------------------------------
r47077 | ripley | 2008-12-05 10:59:56 -0500 (Fri, 05 Dec 2008) | 1 line

invalid space
------------------------------------------------------------------------
r42961 | ripley | 2007-09-24 08:43:45 -0400 (Mon, 24 Sep 2007) | 2 lines

try to use \dQuote for actual quotes, and \emph or \sQuote or \code otherwis

------------------------------------------------------------------------
r42667 | pd | 2007-08-27 10:09:08 -0400 (Mon, 27 Aug 2007) | 1 line

reshape revamped, bug in split<-.data.frame
------------------------------------------------------------------------
r42555 | maechler | 2007-08-18 16:11:40 -0400 (Sat, 18 Aug 2007) | 1 line

more \seealso entries (long overdue)
------------------------------------------------------------------------
r42333 | ripley | 2007-07-27 06:16:22 -0400 (Fri, 27 Jul 2007) | 3 lines

add copyright/licence header
remove CVS-style $Id fields

------------------------------------------------------------------------
r41600 | ripley | 2007-05-17 01:08:32 -0400 (Thu, 17 May 2007) | 2 lines

avoid unnecessary/confusing abbrevation of arguments

------------------------------------------------------------------------
r41461 | ripley | 2007-05-07 07:08:51 -0400 (Mon, 07 May 2007) | 1 line

typo
------------------------------------------------------------------------
r41446 | ripley | 2007-05-05 09:17:30 -0400 (Sat, 05 May 2007) | 2 lines

corrections to the handling of \ in Rd files

------------------------------------------------------------------------
r40814 | murdoch | 2007-03-05 12:47:13 -0500 (Mon, 05 Mar 2007) | 1 line

Typos
------------------------------------------------------------------------
r36816 | ripley | 2005-12-20 06:38:29 -0500 (Tue, 20 Dec 2005) | 2 lines

tweaks, usually over-long lines

------------------------------------------------------------------------
r30549 | tlumley | 2004-08-06 16:27:33 -0400 (Fri, 06 Aug 2004) | 2 lines

allow multiple id variables in reshape

------------------------------------------------------------------------
r30449 | ripley | 2004-08-02 10:03:44 -0400 (Mon, 02 Aug 2004) | 2 lines

more removal of unneeded data() statements

------------------------------------------------------------------------
r27501 | ripley | 2003-12-11 03:24:12 -0500 (Thu, 11 Dec 2003) | 2 lines

nls, ts -> stubs

------------------------------------------------------------------------
r27442 | ripley | 2003-12-09 02:24:25 -0500 (Tue, 09 Dec 2003) | 2 lines

split from base


From jfhenson1 at gmail.com  Tue Apr 12 19:02:10 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Tue, 12 Apr 2016 12:02:10 -0500
Subject: [R] ggplot2
Message-ID: <CABPq8JPa2b4LydcNh5NHeo8XUYFeQhSsHewjCLPQhdCYDdUNTw@mail.gmail.com>

Dear R Community,

Below is a problem with a simple ggplot2 graph. The code returns the error
message below.

Error: stat_count() must not be used with a y aesthetic.

My code is below and the data is attached as a ?text? file.



# Graph of the probabilities

library(digest)

library(DT)

datatable(probability)

str(probability)

probability$Fertilizer <- as.factor(probability$Fertilizer)

str(probability)

library(ggplot2)

plot1 <- ggplot(probability, aes(x=Fertilizer, y=prob)) +
geom_bar(aes(fill=Treatment))

plot1



Thanks.

Best regards,

James F. Henson
-------------- next part --------------
Trt	prob	LL	UL	Fertilizer	Treatment
S0	0.1111	0.0154	0.4998	0	S
S2	0.1111	0.0154	0.4998	2	S
S4	0.1111	0.0154	0.4998	4	S
S6	0.1111	0.0154	0.4998	6	S
P0	0.2222	0.056	0.579	0	P
P2	0.7778	0.4208	0.9439	2	P
P3	0.333	0.1111	0.6665	4	P
P4	0.6667	0.3334	0.8888	6	P

From murdoch.duncan at gmail.com  Tue Apr 12 19:53:54 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Apr 2016 13:53:54 -0400
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <570D14B3.6000701@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
	<570D0B9E.6060304@gmail.com> <570D14B3.6000701@gmail.com>
Message-ID: <570D3632.4000806@gmail.com>

On 12/04/2016 11:30 AM, ProfJCNash wrote:
> Thanks Duncan, for the offer to experiment.
>
> Can you suggest a couple of your pages that you think might need
> improvement? We might as well start with something you'd like looked at.

I don't think I can.  I don't intentionally write obscure documentation, 
so I think they're all clearly written.

Which leaves the problem of choosing one.  I could probably generate a 
list of help pages where I've contributed enough
to be comfortable editing them, but you'll need to choose which one to fix.

Duncan
>
> Then I'll ask if there are interested people and see what can be done
> about getting a framework set up to work on one of those documents.
>
> JN
>
>
> On 16-04-12 10:52 AM, Duncan Murdoch wrote:
> > On 12/04/2016 9:21 AM, ProfJCNash wrote:
> >> >>>> "The documentation aims to be accurate, not necessarily clear."
> >> > I notice that none of the critics
> >> > in this thread have offered improvements on what is there.
> >>
> >>
> >> This issue is as old as documented things. With software it is
> >> particularly nasty, especially when we want the software to function
> >> across many platforms.
> >>
> >> Duncan has pointed out that critics need to step up to do something.
> >> I would put documentation failures at the top of my list of
> >> time-wasters, and have been bitten by some particularly weak offerings
> >> (not in R) in the last 2 weeks. So ....
> >>
> >> Proposal: That the R community consider establishing a "test and
> >> document" group to parallel R-core to focus on the documentation.
> >> An experiment to test the waters is suggested below.
> >>
> >> The needs:
> >> - tools that let the difficulties with documentation be visualized along
> >> with proposed changes and the discussion accessed by the wider
> >> community, while keeping a well-defined process for committing accepted
> >> changes.
> >> - a process for the above. Right now a lot happens by discussion in the
> >> lists and someone in R-core committing the result. If it is
> >> well-organized, it is not well-understood by the wider R user community.
> >> - tools for managing and providing access to tests
> >>
> >> At the risk of opening another can of worms, documentation is an area
> >> where such an effort could benefit from paid help. It's an area where
> >> there's low reward for high effort, particularly for volunteers.
> >> Moreover, like many volunteers, I'm happy to do some work, but I need
> >> ways to contribute in small bites (bytes?), and it is difficult to find
> >> suitable tasks to take on.
> >>
> >> Is it worth an experiment to customize something like Dokuwiki (which I
> >> believe was the platform for the apparently defunct R wiki) to allow a
> >> segment of R documentation to be reviewed, discussed and changes
> >> proposed? It could show how we might get to a better process for
> >> managing R documentation.
> >
> > The idea of having non-core people write and test documentation appeals
> > to me.   The mechanism (Dokuwiki or whatever) makes no difference to me;
> > it should be up to the participants to decide on what works.
> >
> > The difficulty will be "calibration":  those people need to make changes
> > that core members agree are improvements, or they won't be incorporated.
> >
> > I'd suggest that you start very slowly.  First choose *one* help page
> > that you think needs improvement, and explain why to one of the authors
> > of that page, and what sort of improvements you propose to make.  Then
> > get  the author to agree with the proposal, do it, and get the same
> > author to agree to the final version and commit it.
> >
> > I'll volunteer to participate in the approval and committing stage, but
> > at first only for pages that I authored.  If it turns out to be an
> > efficient way to improve docs, then I'd consider other pages too.
> >
> > Duncan Murdoch


From wjm1 at caa.columbia.edu  Tue Apr 12 20:00:09 2016
From: wjm1 at caa.columbia.edu (William Michels)
Date: Tue, 12 Apr 2016 11:00:09 -0700
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <533B97A8-2860-4F32-AEE3-A628F7A1D25F@comcast.net>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
	<CAGxFJbSMUbdZ+=4mQD67M1HAcikW2NwHB3owLs1Q=_1VgT5MEQ@mail.gmail.com>
	<CAM_vjuniDNTUHbFD=tKLR565msDoL5Uoz5d3nuaFQn7+Ukeyxg@mail.gmail.com>
	<533B97A8-2860-4F32-AEE3-A628F7A1D25F@comcast.net>
Message-ID: <CAA99HCyq8jO-U2NUH5atVzFPoqbjkZwan_CLiPrbR4OKa=WMYA@mail.gmail.com>

On Tue, Apr 12, 2016 at 9:44 AM, David Winsemius <dwinsemius at comcast.net> wrote:
<SNIP>
>
>  There need to be more worked examples, but those could easily be mined from problems submitted as recorded in the R-help Archives and StackOverFlow.
>
<SNIP>

This sounds like a great opportunity for R-users to contribute to the
community (and I certainly would love to participate).

One question for R-Core gurus: R-GUIs have the ability to open a
script window and use a shortcut to execute code in the R-Console. Can
each "Example" on the help pages be configured to do the same? Or at
least assist in block-copying to the Console?

We'd get a lot more people working through examples that way, and
contributors might come up with their own examples to illustrate a
particular function. A Dokuwiki site might be a place where people
could post and vote on new examples to be included in pre-existing
documentation.

--Bill
William Michels, Ph.D.


From profjcnash at gmail.com  Tue Apr 12 20:21:06 2016
From: profjcnash at gmail.com (ProfJCNash)
Date: Tue, 12 Apr 2016 14:21:06 -0400
Subject: [R] Documentation: Was -- identical() versus sapply()
In-Reply-To: <570D3632.4000806@gmail.com>
References: <8b436b6b6af34ff6869fd96ac3be77d9@exchsrv3.sgc.loc>
	<3470AE64-DA70-45EE-9E14-6B2EDD21A538@dcn.davis.ca.us>
	<5708D8F8.3020701@auckland.ac.nz>
	<6320704a6d7944ca80f71d8fb134f1d9@exchsrv3.sgc.loc>
	<CAGxFJbSW-O85ianrxoQiiSjN-MHSSHat2dJLPfRe3tnuVoRbMQ@mail.gmail.com>
	<D23058DD-E4DF-4857-A0AE-D73B72562BDC@dcn.davis.ca.us>
	<1460420710420.50418@stowers.org> <570C4AC2.5040408@gmail.com>
	<CAGxFJbQKq4DWfvDFkR=c_6avCvegS-TergcveL9NL0LMKXjjfQ@mail.gmail.com>
	<570C6158.5010707@gmail.com> <570C6CDE.2050907@auckland.ac.nz>
	<570CE4D2.4020405@gmail.com> <570CF64D.7000403@gmail.com>
	<570D0B9E.6060304@gmail.com> <570D14B3.6000701@gmail.com>
	<570D3632.4000806@gmail.com>
Message-ID: <570D3C92.9020504@gmail.com>

If you generate the list of pages you're comfortable editing, the posse
of folk who have already come forward can select one that we think can
be improved and see how we get along with it.

Sarah has already noted that Github offers wiki documentation. It is
likely imperfect, but we can (and should!) get a bit of experience to
learn where the important issues lie.

Thanks, JN

On 16-04-12 01:53 PM, Duncan Murdoch wrote:
> On 12/04/2016 11:30 AM, ProfJCNash wrote:
>> Thanks Duncan, for the offer to experiment.
>>
>> Can you suggest a couple of your pages that you think might need
>> improvement? We might as well start with something you'd like looked at.
> 
> I don't think I can.  I don't intentionally write obscure documentation,
> so I think they're all clearly written.
> 
> Which leaves the problem of choosing one.  I could probably generate a
> list of help pages where I've contributed enough
> to be comfortable editing them, but you'll need to choose which one to fix.
> 
> Duncan
>>
>> Then I'll ask if there are interested people and see what can be done
>> about getting a framework set up to work on one of those documents.
>>
>> JN
>>
>>
>> On 16-04-12 10:52 AM, Duncan Murdoch wrote:
>> > On 12/04/2016 9:21 AM, ProfJCNash wrote:
>> >> >>>> "The documentation aims to be accurate, not necessarily clear."
>> >> > I notice that none of the critics
>> >> > in this thread have offered improvements on what is there.
>> >>
>> >>
>> >> This issue is as old as documented things. With software it is
>> >> particularly nasty, especially when we want the software to function
>> >> across many platforms.
>> >>
>> >> Duncan has pointed out that critics need to step up to do something.
>> >> I would put documentation failures at the top of my list of
>> >> time-wasters, and have been bitten by some particularly weak offerings
>> >> (not in R) in the last 2 weeks. So ....
>> >>
>> >> Proposal: That the R community consider establishing a "test and
>> >> document" group to parallel R-core to focus on the documentation.
>> >> An experiment to test the waters is suggested below.
>> >>
>> >> The needs:
>> >> - tools that let the difficulties with documentation be visualized
>> along
>> >> with proposed changes and the discussion accessed by the wider
>> >> community, while keeping a well-defined process for committing
>> accepted
>> >> changes.
>> >> - a process for the above. Right now a lot happens by discussion in
>> the
>> >> lists and someone in R-core committing the result. If it is
>> >> well-organized, it is not well-understood by the wider R user
>> community.
>> >> - tools for managing and providing access to tests
>> >>
>> >> At the risk of opening another can of worms, documentation is an area
>> >> where such an effort could benefit from paid help. It's an area where
>> >> there's low reward for high effort, particularly for volunteers.
>> >> Moreover, like many volunteers, I'm happy to do some work, but I need
>> >> ways to contribute in small bites (bytes?), and it is difficult to
>> find
>> >> suitable tasks to take on.
>> >>
>> >> Is it worth an experiment to customize something like Dokuwiki
>> (which I
>> >> believe was the platform for the apparently defunct R wiki) to allow a
>> >> segment of R documentation to be reviewed, discussed and changes
>> >> proposed? It could show how we might get to a better process for
>> >> managing R documentation.
>> >
>> > The idea of having non-core people write and test documentation appeals
>> > to me.   The mechanism (Dokuwiki or whatever) makes no difference to
>> me;
>> > it should be up to the participants to decide on what works.
>> >
>> > The difficulty will be "calibration":  those people need to make
>> changes
>> > that core members agree are improvements, or they won't be
>> incorporated.
>> >
>> > I'd suggest that you start very slowly.  First choose *one* help page
>> > that you think needs improvement, and explain why to one of the authors
>> > of that page, and what sort of improvements you propose to make.  Then
>> > get  the author to agree with the proposal, do it, and get the same
>> > author to agree to the final version and commit it.
>> >
>> > I'll volunteer to participate in the approval and committing stage, but
>> > at first only for pages that I authored.  If it turns out to be an
>> > efficient way to improve docs, then I'd consider other pages too.
>> >
>> > Duncan Murdoch
>


From huzefa.khalil at umich.edu  Tue Apr 12 22:34:43 2016
From: huzefa.khalil at umich.edu (Huzefa Khalil)
Date: Tue, 12 Apr 2016 16:34:43 -0400
Subject: [R] ggplot2
In-Reply-To: <CABPq8JPa2b4LydcNh5NHeo8XUYFeQhSsHewjCLPQhdCYDdUNTw@mail.gmail.com>
References: <CABPq8JPa2b4LydcNh5NHeo8XUYFeQhSsHewjCLPQhdCYDdUNTw@mail.gmail.com>
Message-ID: <CADsG8gNERuQ9X8WGASQEn7g-u=NGm4GGjU7=abbgG2LJWiNmLQ@mail.gmail.com>

Hi James,

If you want to specify the y-values, you need to use stat="identity" as below:

ggplot(probability, aes(x=Fertilizer, y=prob)) +
geom_bar(stat="identity", aes(fill=Treatment))


best,
huzefa

On Tue, Apr 12, 2016 at 1:02 PM, James Henson <jfhenson1 at gmail.com> wrote:
> Dear R Community,
>
> Below is a problem with a simple ggplot2 graph. The code returns the error
> message below.
>
> Error: stat_count() must not be used with a y aesthetic.
>
> My code is below and the data is attached as a ?text? file.
>
>
>
> # Graph of the probabilities
>
> library(digest)
>
> library(DT)
>
> datatable(probability)
>
> str(probability)
>
> probability$Fertilizer <- as.factor(probability$Fertilizer)
>
> str(probability)
>
> library(ggplot2)
>
> plot1 <- ggplot(probability, aes(x=Fertilizer, y=prob)) +
> geom_bar(aes(fill=Treatment))
>
> plot1
>
>
>
> Thanks.
>
> Best regards,
>
> James F. Henson
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfhenson1 at gmail.com  Tue Apr 12 22:54:58 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Tue, 12 Apr 2016 15:54:58 -0500
Subject: [R] ggplot2
In-Reply-To: <CADsG8gNERuQ9X8WGASQEn7g-u=NGm4GGjU7=abbgG2LJWiNmLQ@mail.gmail.com>
References: <CABPq8JPa2b4LydcNh5NHeo8XUYFeQhSsHewjCLPQhdCYDdUNTw@mail.gmail.com>
	<CADsG8gNERuQ9X8WGASQEn7g-u=NGm4GGjU7=abbgG2LJWiNmLQ@mail.gmail.com>
Message-ID: <CABPq8JM__bivKJ=QiX=Ct1udnUqoFXHTK7HWhs4FnJCPdsPDqQ@mail.gmail.com>

Thanks, the stat="identity" worked.

On Tue, Apr 12, 2016 at 3:34 PM, Huzefa Khalil <huzefa.khalil at umich.edu>
wrote:

> Hi James,
>
> If you want to specify the y-values, you need to use stat="identity" as
> below:
>
> ggplot(probability, aes(x=Fertilizer, y=prob)) +
> geom_bar(stat="identity", aes(fill=Treatment))
>
>
> best,
> huzefa
>
> On Tue, Apr 12, 2016 at 1:02 PM, James Henson <jfhenson1 at gmail.com> wrote:
> > Dear R Community,
> >
> > Below is a problem with a simple ggplot2 graph. The code returns the
> error
> > message below.
> >
> > Error: stat_count() must not be used with a y aesthetic.
> >
> > My code is below and the data is attached as a ?text? file.
> >
> >
> >
> > # Graph of the probabilities
> >
> > library(digest)
> >
> > library(DT)
> >
> > datatable(probability)
> >
> > str(probability)
> >
> > probability$Fertilizer <- as.factor(probability$Fertilizer)
> >
> > str(probability)
> >
> > library(ggplot2)
> >
> > plot1 <- ggplot(probability, aes(x=Fertilizer, y=prob)) +
> > geom_bar(aes(fill=Treatment))
> >
> > plot1
> >
> >
> >
> > Thanks.
> >
> > Best regards,
> >
> > James F. Henson
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From luisfo89 at yahoo.es  Tue Apr 12 23:37:20 2016
From: luisfo89 at yahoo.es (Luisfo Chiroque)
Date: Wed, 13 Apr 2016 00:37:20 +0300
Subject: [R] Dissimilarity matrix and number clusters determination
In-Reply-To: <CA+pG8eNVyCDyZ5-zyjG=Bqyqb2=J8Zu7XtLBeBuBhKB_KoE2Bw@mail.gmail.com>
References: <CA+pG8eNVyCDyZ5-zyjG=Bqyqb2=J8Zu7XtLBeBuBhKB_KoE2Bw@mail.gmail.com>
Message-ID: <5F1C1BC5-1C82-4239-85A1-D40199BB16A8@yahoo.es>

Dear Michael,

Yes, AFAIK you are correctly reading the results.
You can print
elbow.obj$k
to obtain the optimal number of clusters, and ?visually? you can check it plotting the variance vs #clusters
plot(css.obj$k, css.obj$ev)

HTH

Best,
Luisfo Chiroque
PhD Student
IMDEA Networks Institute
http://fourier.networks.imdea.org/people/~luis_nunez/ <http://fourier.networks.imdea.org/people/~luis_nunez/>
> El 12 abr 2016, a las 4:30, Michael Artz <michaeleartz at gmail.com> escribi?:
> 
> Hi,
>  I already have a dissimilarity matrix and I am submitting the results to
> the elbow.obj method to get an optimal number of clusters.  Am I reading
> the below output correctly that I should have 17 clusters?
> 
> code:
> top150 <- sampleset[1:150,]
> {cluster1 <- daisy(top150
>                   , metric = c("gower")
>                   , stand = TRUE
>                   , type = list(symm = 1))
> }
> 
> dist.obj <- dist(cluster1)
> hclust.obj <- hclust(dist.obj)
> css.obj <- css.hclust(dist.obj,hclust.obj)
> elbow.obj <- elbow.batch(css.obj)
> 
> [1] "A \"good\" k=17 (EV=0.80) is detected when the EV is no less than
> 0.8\nand the increment of EV is no more than 0.01 for a bigger k.\n"
> attr(,"class")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From mahmoudfarid30 at yahoo.com  Wed Apr 13 01:42:56 2016
From: mahmoudfarid30 at yahoo.com (mahmoudfarid30 at yahoo.com)
Date: Tue, 12 Apr 2016 23:42:56 +0000 (UTC)
Subject: [R] error: contextstack overflow
References: <1962958956.1615603.1460504576128.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1962958956.1615603.1460504576128.JavaMail.yahoo@mail.yahoo.com>

Dear r users
I've a loop that has 20 if else statements but it gave me the ""contextstack overflow"" error at statement 14 
Is there any way to overcome this problem cause i'm forced to do that loop 
any help or recommendations please


From jrkrideau at inbox.com  Wed Apr 13 03:30:46 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 12 Apr 2016 17:30:46 -0800
Subject: [R] error: contextstack overflow
In-Reply-To: <1962958956.1615603.1460504576128.JavaMail.yahoo@mail.yahoo.com>
References: <1962958956.1615603.1460504576128.javamail.yahoo.ref@mail.yahoo.com>
Message-ID: <2F82E7A527C.00000917jrkrideau@inbox.com>

I've never seen the error mentioned before but see Brian Ripley's post https://stat.ethz.ch/pipermail/r-help/2008-March/157341.html. It looks like you are exceeding a limit.

We probably should see some sample code and data. 

Please have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html  for some suggestions on what to include in a question.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Tue, 12 Apr 2016 23:42:56 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] error: contextstack overflow
> 
> Dear r users
> I've a loop that has 20 if else statements but it gave me the
> ""contextstack overflow"" error at statement 14
> Is there any way to overcome this problem cause i'm forced to do that
> loop
> any help or recommendations please
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From drjimlemon at gmail.com  Wed Apr 13 06:51:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 13 Apr 2016 14:51:21 +1000
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CAMLwc7PAptJ-Q4ci5W2pY4PMar9jJQisyXLtLfb0d+61Sq46dA@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
	<3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
	<CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>
	<CA+8X3fXaHp6aiZ0K+B3Wv_zw=s1gW0neD_QDt7kW5LunHE5WLg@mail.gmail.com>
	<CAMLwc7NZGuoyAkXhokJXwjHT4eUsb1w0SLJHQNWcnTZuo7YQ6g@mail.gmail.com>
	<CA+8X3fU+r4iFOQUpA+hQaV7Ub=spxd9deWbhzDk8dxNGTBZjBg@mail.gmail.com>
	<CAMLwc7PAptJ-Q4ci5W2pY4PMar9jJQisyXLtLfb0d+61Sq46dA@mail.gmail.com>
Message-ID: <CA+8X3fUDDZoQx6=etdOC9rukqgTuOba378TqJssDbSnXX7-_4Q@mail.gmail.com>

Hi Milu,
My fault here. As I don't have the data to make the map and try out my
suggestions I mixed up the x and y coordinates. Try this:

par(xpd=TRUE)
arrows(-19.75966,53,33.60000,53,code=3)
par(xpd=FALSE)

Jim

On Tue, Apr 12, 2016 at 10:11 PM, Miluji Sb <milujisb at gmail.com> wrote:
> Hello Jim,
>
> Thanks again. I am getting the two-headed arrow but I cannot seem to get the
> coordinates right for the arrow to appear beneath the map. These coordinates
> puts the arrow on the left hand side. Thanks again!
>
> Sincerely,
>
> Milu
>
> On Tue, Apr 12, 2016 at 1:15 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Milu,
>> There is a two-headed arrow on the image you sent, and it seems to be
>> where you specified. Did you want it beneath the map, as:
>>
>> par(xpd=TRUE)
>> arrows(-22,54.75,-22,74,code=3)
>> par(xpd=FALSE)
>>
>> Jim
>>
>> On Tue, Apr 12, 2016 at 7:58 PM, Miluji Sb <milujisb at gmail.com> wrote:
>> > Dear Jim,
>> >
>> > Thanks again! I do want the arrows at the bottom (beneath the map). This
>> > is
>> > what I am doing:
>> >
>> > # Draw the map
>> > eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score",
>> > mapTitle="EPS
>> > Score - Europe",colourPalette=colourPalette,
>> > catMethod="fixedWidth", missingCountryCol = "white", mapRegion="Europe",
>> > addLegend=FALSE)
>> >
>> > # ISO3 codes on the map
>> > text(n, labels="ISO3", cex=0.30)
>> >
>> > # Obtain coordinates for the arrow
>> > par('usr')
>> >
>> > # -19.75966  54.75966  33.60000  71.40000
>> >
>> > # Arrows
>> > par(xpd=TRUE)
>> > arrows(-19.75966,  54.75966,  33.60000,  71.40000,code=3)
>> > par(xpd=FALSE)
>> >
>> > As the output shows I cannot seem to get the correct coordinates for the
>> > arrows. Thanks again.
>> >
>> > Sincerely,
>> >
>> > Milu
>
>


From rini.john3 at yahoo.com  Wed Apr 13 07:57:29 2016
From: rini.john3 at yahoo.com (=?UTF-8?Q?=E2=80=AARini_John=E2=80=AC_=E2=80=AA?=)
Date: Wed, 13 Apr 2016 05:57:29 +0000 (UTC)
Subject: [R] RWeka Error
In-Reply-To: <F1826B54-53CF-42B9-81C6-00FD6D1C3FB4@dcn.davis.ca.us>
References: <F1826B54-53CF-42B9-81C6-00FD6D1C3FB4@dcn.davis.ca.us>
Message-ID: <1305756593.3128738.1460527049965.JavaMail.yahoo@mail.yahoo.com>

Hi,When I use any function of RWeka Package in Rstudio I get an error, "Error in .jnew (name): java.lang.ClassFormatError." can anyone guide me in this?Operation system used:?Linux 64 bit (CentOS)
Command used:?>data("crude")>tdm <- TermDocumentMatrix(crude, control=list(tokenize = NGramTokenizer))
Packages loaded:?tm and RWeka

Regards,Rini John?
      From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
 To: ?Rini John? ? <rini.john3 at yahoo.com>; ?Rini John? ? via R-help <r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org> 
 Sent: Tuesday, 5 April 2016, 18:30:26
 Subject: Re: [R] RWeka Error
   
Read the Posting Guide mentioned at the bottom of this email. Highlights you should be sure to address:

* HTML formatted email gets messed up on the R mailing lists, so post in plain text. Yes, you can and need to do this. 

* Make sure the problem occurs in R by trying it without RStudio. Sometimes RStudio interferes with R, and you have to ask elsewhere about such problems. 

* Give us details about your setup and the exact commands you used. The sessionInfo function is helpful here, as is a sample of what you entered into a clean R session to get that error (for completeness). Make sure you are clear in your post about what operating system you are using, and what Java runtime (version and 32/64 bitness) is installed. 
-- 
Sent from my phone. Please excuse my brevity.

On April 5, 2016 5:14:55 AM PDT, "?Rini John? ? via R-help" <r-help at r-project.org> wrote:

When I use any function of RWeka Package in Rstudio I get an error, "Error in .jnew (name): java.lang.ClassFormatError." can anyone guide me in this?

 [[alternative HTML version deleted]]


R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



  
	[[alternative HTML version deleted]]


From rini.john3 at yahoo.com  Wed Apr 13 07:58:43 2016
From: rini.john3 at yahoo.com (=?UTF-8?Q?=E2=80=AARini_John=E2=80=AC_=E2=80=AA?=)
Date: Wed, 13 Apr 2016 05:58:43 +0000 (UTC)
Subject: [R] RWeka Error
In-Reply-To: <1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
References: <1813506092.5021836.1459858495405.JavaMail.yahoo.ref@mail.yahoo.com>
	<1813506092.5021836.1459858495405.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1608659407.3198828.1460527123952.JavaMail.yahoo@mail.yahoo.com>

Hi,When I use any function of RWeka Package in Rstudio I get an error, "Error in .jnew (name): java.lang.ClassFormatError." can anyone guide me in this?Operation system used:?Linux 64 bit (CentOS)
Command used:?>data("crude")>tdm <- TermDocumentMatrix(crude, control=list(tokenize = NGramTokenizer))
Packages loaded:?tm and RWeka

Regards,Rini John?
	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Wed Apr 13 08:33:15 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Wed, 13 Apr 2016 01:33:15 -0500
Subject: [R] No color in plotting
In-Reply-To: <CA+pG8ePfmnJbROw=chC0D_vzj_OuZnkU65G1iV_kBYOx1CL6sQ@mail.gmail.com>
References: <CA+pG8eM_fzveURP+9kB13bGQGt6m+_hAS33CQfy05mQ-dy8V6w@mail.gmail.com>
	<CA+pG8ePqwri1EnbZ3yQFemQFjVS46goYV7aiCVh++8fVMs338w@mail.gmail.com>
	<CA+pG8eOif2qxdxYD45QVPJoKbgL6MmnTvj-FwOdzBskVgJXFBQ@mail.gmail.com>
	<CA+pG8eMbharkeBtx=5qCrg8MCi0y2h=a=RWiYeZx0Uhb8nBZMw@mail.gmail.com>
	<CA+pG8ePfmnJbROw=chC0D_vzj_OuZnkU65G1iV_kBYOx1CL6sQ@mail.gmail.com>
Message-ID: <CA+pG8eNPwZYYy-dY1AAJwZmW_z2v6+jUGVdjMBd1FpJE0b-ezA@mail.gmail.com>

Hi I am having a problem with plot () and ggplot ().  When I call one of
these functions, the plotting area starts to look as though it is working,
but nothijg ever is visible.  Unless it was a dendrogram.  Woth the bar
chart, the plotting area just had an x and y axis and nothing else. I tried
a bar chart with ggplot and i tried to plot a tree result from rpart ().  I
couldnt see anything plotted.  Is there some way I should be
troubleshooting this?  Im thinking its an R config I did or didnt do.  I
really have no idea though.

	[[alternative HTML version deleted]]


From huimincheng2015 at gmail.com  Wed Apr 13 06:58:50 2016
From: huimincheng2015 at gmail.com (cheng huimin)
Date: Wed, 13 Apr 2016 12:58:50 +0800
Subject: [R] could not find function in mempry inside foreach loop
Message-ID: <CALdFzwC2HDbW4LUqhYb+womhw9jpq=BwaLaxU+esHfq+tApxRw@mail.gmail.com>

I'm trying to use foreach function to do multicore computing in R.



Error in FUN(train_adjmt, iter = missedmat[i, 1], iter2 = missedmat[i,  :
  task 1 failed - "?????'predictMatrix'"

then I call function A in the console. The problem is I'm calling a
function Posdef inside B that is defined in another script file which I
source. I had to put predictMatrix in the list of export argument of foreach
: .export=c("predictMatrix"). However I get the following error:

Warning message:
In e$fun(obj, substitute(ex), parent.frame(), e$data) :
  already exporting variable(s): predictMatrix

	[[alternative HTML version deleted]]


From huimincheng2015 at gmail.com  Wed Apr 13 07:06:39 2016
From: huimincheng2015 at gmail.com (cheng huimin)
Date: Wed, 13 Apr 2016 13:06:39 +0800
Subject: [R] could not find function in mempry inside foreach loop
Message-ID: <CALdFzwA2jRJHy=9XtcJFg0TeZEOkbOEKehzjMdPLksXY6qmugw@mail.gmail.com>

I'm trying to use foreach function to do multicore computing in R.

A <-function(....) {
    foreach(i=1:10) %dopar% {
    B()
    }}

then I call function A in the console. The problem is I'm calling a
function  ipredictMatrix inside B that is defined in another script file
which I source.However I get the following error:

Error in FUN(train_adjmt, iter = missedmat[i, 1], iter2 = missedmat[i,  :
  task 1 failed - "?????'predictMatrix'"

Then  I tried to put predictMatrix in the list of export argument of foreach
: .export=c("predictMatrix"). However I get the following error:

Warning message:
In e$fun(obj, substitute(ex), parent.frame(), e$data) :
  already exporting variable(s): predictMatrix

Why  can't R find this defined function? How to solve this problem?
Futermore ,R-version I am using is "3.2.3",and my computer is running on
windows.

Thanks,
Alice

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Wed Apr 13 08:59:04 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Wed, 13 Apr 2016 09:59:04 +0300
Subject: [R] formula argument evaluation
In-Reply-To: <CAGx1TMAruoQ5r+_f=F3x2f7D0LVd0LX+-muxbP4XcRar=g-V_w@mail.gmail.com>
References: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
	<570CD71E.4040107@gmail.com>
	<CAJ=0CtBRNHsa=8hrULR3aK8V0si4S+gmyZzhCYHs7iVVN56afw@mail.gmail.com>
	<CAGx1TMAruoQ5r+_f=F3x2f7D0LVd0LX+-muxbP4XcRar=g-V_w@mail.gmail.com>
Message-ID: <CAJ=0CtCRfUqQ5Oa=bvbjRchiYGYQmVjYN0K95VOp16v_vKkwww@mail.gmail.com>

I suppose it would work, although "=>" is rather a descriptive symbol and
less a function.
But choosing between quoting:
"A + B => C"
and a regular function:
A + B %=>% C
probably quoting is the most straightforward, as the result of the foo()
function has to be a string anyways (which is parsed by other functions).

On Tue, Apr 12, 2016 at 6:20 PM, Richard M. Heiberger <rmh at temple.edu>
wrote:

> Would making it regular function %=>%, using "%" instead of quotes,
> work for you?
>
> On Tue, Apr 12, 2016 at 11:09 AM, Adrian Du?a <dusa.adrian at unibuc.ro>
> wrote:
> > On Tue, Apr 12, 2016 at 2:08 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com>
> > wrote:
> >> [...]
> >>
> >> It never gets to evaluating it.  It is not a legal R statement, so the
> > parser signals an error.
> >> If you want to pass arbitrary strings to a function, you need to put
> them
> > in quotes.
> >
> > I see. I thought it was parsed inside the function, but if it's parsed
> > before then quoting is the only option.
> >
> >
> > To Keith: no, I mean it like this "A + B => C" which is translated as:
> > "the union of A and B is sufficient for C" in set theoretic language.
> >
> > The "=>" operator means sufficiency, while "<=" means necessity. Quoting
> > the expression is good enough, I was just curious if the quotes could be
> > made redundant, somehow.
> >
> > Thank you both,
> > Adrian
> >
> > --
> > Adrian Dusa
> > University of Bucharest
> > Romanian Social Data Archive
> > Soseaua Panduri nr.90
> > 050663 Bucharest sector 5
> > Romania
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Wed Apr 13 09:49:35 2016
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 13 Apr 2016 19:49:35 +1200
Subject: [R] R 3.2.4-revised is released
In-Reply-To: <A252BB23-7C0A-4495-AE46-BD0CA1003B6B@cbs.dk>
References: <A252BB23-7C0A-4495-AE46-BD0CA1003B6B@cbs.dk>
Message-ID: <20160413074935.GC2013@slingshot.co.nz>

My CRAN mirror still says this:

  The latest release (Thursday 2016-03-10, Very Secure Dishes)
  R-3.2.4.tar.gz, read what's new in the latest version.

Should that not be updated?  Anyone who has not seen that post won't
know to look further.


On Wed, 16-Mar-2016 at 08:39PM +0000, Peter Dalgaard wrote:

|> The 3.2.4 release had two annoyances which we would rather not have
|> in an "ultra-stable" release, designed to hang around for the
|> duration of the 3.3 series. One was a relatively minor Makefile
|> issue affecting system using R's bundled lzma library. The other,
|> rather more serious, affected printing and formatting of POSIXlt
|> objects, which would unpredictably get the Daylight Savings Time
|> wrong.


|> Accordingly a revised version has been created.
|> 
|> You can get the source code from
|> 
|> http://cran.r-project.org/src/base/R-3/R-3.2.4-revised.tar.gz
|> 
|> or wait for it to be mirrored at a CRAN site nearer to you.
|> 
|> Maintainers of binary versions are requested to rebuild their binaries using the revised sources.
|> 
|> 
|> For the R Core Team,
|> 
|> Peter Dalgaard
|> 
|> New md5 sums are
|> 
|> MD5 (NEWS) = b0b43ac87a5b5858098da065966551af
|> MD5 (R-3/R-3.2.4-revised.tar.gz) = 552b0c8088bab08ca4188797b919a58f
|> 
|> The relevant NEWS file entry is
|> 
|>   BUG FIXES:
|> 
|>     ? format.POSIXlt() behaved wrongly, e.g.,
|>       format(as.POSIXlt(paste0(1940:2000,"-01-01"), tz="CET"),
|>       usetz=TRUE) ended in two "CEST" time formats.
|> 
|> -- 
|> Peter Dalgaard, Professor,
|> Center for Statistics, Copenhagen Business School
|> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
|> Phone: (+45)38153501
|> Office: A 4.23
|> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
|> 
|> _______________________________________________
|> R-announce at r-project.org mailing list
|> https://stat.ethz.ch/mailman/listinfo/r-announce
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From petr.pikal at precheza.cz  Wed Apr 13 10:16:35 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 13 Apr 2016 08:16:35 +0000
Subject: [R] No color in plotting
In-Reply-To: <CA+pG8eNPwZYYy-dY1AAJwZmW_z2v6+jUGVdjMBd1FpJE0b-ezA@mail.gmail.com>
References: <CA+pG8eM_fzveURP+9kB13bGQGt6m+_hAS33CQfy05mQ-dy8V6w@mail.gmail.com>
	<CA+pG8ePqwri1EnbZ3yQFemQFjVS46goYV7aiCVh++8fVMs338w@mail.gmail.com>
	<CA+pG8eOif2qxdxYD45QVPJoKbgL6MmnTvj-FwOdzBskVgJXFBQ@mail.gmail.com>
	<CA+pG8eMbharkeBtx=5qCrg8MCi0y2h=a=RWiYeZx0Uhb8nBZMw@mail.gmail.com>
	<CA+pG8ePfmnJbROw=chC0D_vzj_OuZnkU65G1iV_kBYOx1CL6sQ@mail.gmail.com>
	<CA+pG8eNPwZYYy-dY1AAJwZmW_z2v6+jUGVdjMBd1FpJE0b-ezA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5025F3B@SRVEXCHMBX.precheza.cz>

Hi

Without some reproducible example you hardly get any answer.

if this works
library(ggplot2)
p <- ggplot(mtcars, aes(wt, mpg))
p + geom_point()

the problem is in your data.

If it does not, the problem is elsewhere, including broken R installation.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Artz
> Sent: Wednesday, April 13, 2016 8:33 AM
> To: r-help at r-project.org
> Subject: [R] No color in plotting
>
> Hi I am having a problem with plot () and ggplot ().  When I call one of these
> functions, the plotting area starts to look as though it is working, but nothijg
> ever is visible.  Unless it was a dendrogram.  Woth the bar chart, the plotting
> area just had an x and y axis and nothing else. I tried a bar chart with ggplot
> and i tried to plot a tree result from rpart ().  I couldnt see anything plotted.
> Is there some way I should be troubleshooting this?  Im thinking its an R
> config I did or didnt do.  I really have no idea though.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pd.mes at cbs.dk  Wed Apr 13 10:25:38 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Wed, 13 Apr 2016 08:25:38 +0000
Subject: [R] R 3.2.4-revised is released
In-Reply-To: <20160413074935.GC2013@slingshot.co.nz>
References: <A252BB23-7C0A-4495-AE46-BD0CA1003B6B@cbs.dk>
	<20160413074935.GC2013@slingshot.co.nz>
Message-ID: <82DB9780-1163-48D8-B763-ACFC000DF351@cbs.dk>

CRAN turned out to have structural issues with version numbers that are not of the x.y.z variety (some script break). I'm trying to find time to build a 3.2.5 just to fix this up. Of course all standard procedures are broken as 3.3.0 is now in progress, so several things now need to be done manually, which is "tedious and error-prone" as the saying goes.

-pd

On 13 Apr 2016, at 09:49 , Patrick Connolly <p_connolly at slingshot.co.nz> wrote:

> My CRAN mirror still says this:
> 
>  The latest release (Thursday 2016-03-10, Very Secure Dishes)
>  R-3.2.4.tar.gz, read what's new in the latest version.
> 
> Should that not be updated?  Anyone who has not seen that post won't
> know to look further.
> 
> 
> On Wed, 16-Mar-2016 at 08:39PM +0000, Peter Dalgaard wrote:
> 
> |> The 3.2.4 release had two annoyances which we would rather not have
> |> in an "ultra-stable" release, designed to hang around for the
> |> duration of the 3.3 series. One was a relatively minor Makefile
> |> issue affecting system using R's bundled lzma library. The other,
> |> rather more serious, affected printing and formatting of POSIXlt
> |> objects, which would unpredictably get the Daylight Savings Time
> |> wrong.
> 
> 
> |> Accordingly a revised version has been created.
> |> 
> |> You can get the source code from
> |> 
> |> http://cran.r-project.org/src/base/R-3/R-3.2.4-revised.tar.gz
> |> 
> |> or wait for it to be mirrored at a CRAN site nearer to you.
> |> 
> |> Maintainers of binary versions are requested to rebuild their binaries using the revised sources.
> |> 
> |> 
> |> For the R Core Team,
> |> 
> |> Peter Dalgaard
> |> 
> |> New md5 sums are
> |> 
> |> MD5 (NEWS) = b0b43ac87a5b5858098da065966551af
> |> MD5 (R-3/R-3.2.4-revised.tar.gz) = 552b0c8088bab08ca4188797b919a58f
> |> 
> |> The relevant NEWS file entry is
> |> 
> |>   BUG FIXES:
> |> 
> |>     ? format.POSIXlt() behaved wrongly, e.g.,
> |>       format(as.POSIXlt(paste0(1940:2000,"-01-01"), tz="CET"),
> |>       usetz=TRUE) ended in two "CEST" time formats.
> |> 
> |> -- 
> |> Peter Dalgaard, Professor,
> |> Center for Statistics, Copenhagen Business School
> |> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> |> Phone: (+45)38153501
> |> Office: A 4.23
> |> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> |> 
> |> _______________________________________________
> |> R-announce at r-project.org mailing list
> |> https://stat.ethz.ch/mailman/listinfo/r-announce
> |> ______________________________________________
> |> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> https://stat.ethz.ch/mailman/listinfo/r-help
> |> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> |> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
>   ___    Patrick Connolly   
> {~._.~}                   Great minds discuss ideas    
> _( Y )_  	         Average minds discuss events 
> (:_~*~_:)                  Small minds discuss people  
> (_)-(_)  	                      ..... Eleanor Roosevelt
> 	  
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Wed Apr 13 17:03:55 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 13 Apr 2016 08:03:55 -0700
Subject: [R] formula argument evaluation
In-Reply-To: <CAJ=0CtCRfUqQ5Oa=bvbjRchiYGYQmVjYN0K95VOp16v_vKkwww@mail.gmail.com>
References: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
	<570CD71E.4040107@gmail.com>
	<CAJ=0CtBRNHsa=8hrULR3aK8V0si4S+gmyZzhCYHs7iVVN56afw@mail.gmail.com>
	<CAGx1TMAruoQ5r+_f=F3x2f7D0LVd0LX+-muxbP4XcRar=g-V_w@mail.gmail.com>
	<CAJ=0CtCRfUqQ5Oa=bvbjRchiYGYQmVjYN0K95VOp16v_vKkwww@mail.gmail.com>
Message-ID: <CAF8bMcYZksHEzSAZ9_HiRywC+NYw0f_qnPJz8JvP0VZNAz=rYA@mail.gmail.com>

%=>% would have precendence ('order of operations') problems also.

   A + B %=>% C

is equivalent to

  A + ( B %=>% C)

and I don't think that is what you want.

as.list(quote(A + B %=>% C)) shows the first branch in the parse tree.  The
following function, str.language, shows the entire parse tree, as in

  > str.language(quote(A + B %=>% C))
  `quote(A + B %=>% C)` call(3): A + B %=>% C
    `` name(1): +
    `` name(1): A
    `` call(3): B %=>% C
      `` name(1): %=>%
      `` name(1): B
      `` name(1): C

str.language <-
function (object, ..., level = 0, name = myDeparse(substitute(object)))
{
    abbr <- function(string, maxlen = 25) {
        if (length(string) > 1 || nchar(string) > maxlen)
            paste(substring(string[1], 1, maxlen), "...", sep = "")
        else string
    }
    myDeparse <- function(object) {
        if (!is.environment(object)) {
            deparse(object)
        }
        else {
            ename <- environmentName(object)
            if (ename == "")
                ename <- "<unnamed env>"
            paste(sep = "", "<", ename, "> ", paste(collapse = " ",
                objects(object)))
        }
    }
    cat(rep("  ", level), sep = "")
    if (is.null(name))
        name <- ""
    cat(sprintf("`%s` %s(%d): %s\n", abbr(name), class(object),
        length(object), abbr(myDeparse(object))))
    a <- attributes(object)
    if (is.recursive(object) && !is.environment(object)) {
        object <- as.list(object)
        names <- names(object)
        for (i in seq_along(object)) {
            str.language(object[[i]], ..., level = level + 1,
                name = names[i])
        }
    }
    a$names <- NULL
    if (length(a) > 0) {
        str.language(a, level = level + 1, name = paste("Attributes of",
            abbr(name)))
    }
}



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 12, 2016 at 11:59 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:

> I suppose it would work, although "=>" is rather a descriptive symbol and
> less a function.
> But choosing between quoting:
> "A + B => C"
> and a regular function:
> A + B %=>% C
> probably quoting is the most straightforward, as the result of the foo()
> function has to be a string anyways (which is parsed by other functions).
>
> On Tue, Apr 12, 2016 at 6:20 PM, Richard M. Heiberger <rmh at temple.edu>
> wrote:
>
> > Would making it regular function %=>%, using "%" instead of quotes,
> > work for you?
> >
> > On Tue, Apr 12, 2016 at 11:09 AM, Adrian Du?a <dusa.adrian at unibuc.ro>
> > wrote:
> > > On Tue, Apr 12, 2016 at 2:08 PM, Duncan Murdoch <
> > murdoch.duncan at gmail.com>
> > > wrote:
> > >> [...]
> > >>
> > >> It never gets to evaluating it.  It is not a legal R statement, so the
> > > parser signals an error.
> > >> If you want to pass arbitrary strings to a function, you need to put
> > them
> > > in quotes.
> > >
> > > I see. I thought it was parsed inside the function, but if it's parsed
> > > before then quoting is the only option.
> > >
> > >
> > > To Keith: no, I mean it like this "A + B => C" which is translated as:
> > > "the union of A and B is sufficient for C" in set theoretic language.
> > >
> > > The "=>" operator means sufficiency, while "<=" means necessity.
> Quoting
> > > the expression is good enough, I was just curious if the quotes could
> be
> > > made redundant, somehow.
> > >
> > > Thank you both,
> > > Adrian
> > >
> > > --
> > > Adrian Dusa
> > > University of Bucharest
> > > Romanian Social Data Archive
> > > Soseaua Panduri nr.90
> > > 050663 Bucharest sector 5
> > > Romania
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jose.ferraro at LOGITeng.com  Wed Apr 13 19:18:35 2016
From: jose.ferraro at LOGITeng.com (Jose Marcos Ferraro)
Date: Wed, 13 Apr 2016 17:18:35 +0000
Subject: [R] reduced set of alternatives in package mlogit
In-Reply-To: <CAOGrcjqjAXXwUK_jNp1Qv4oxSJr5PTVgRaUUsgatrukAcQk0RQ@mail.gmail.com>
References: <GRUPR80MB04443F1875EAF793C2385609E2990@GRUPR80MB0444.lamprd80.prod.outlook.com>
	<CAGxFJbRGPWZv3hhDiUV4cuzg5xHoihfb+FjaZ0cJCeMVx33ATw@mail.gmail.com>
	<GRUPR80MB0444F78421CA9EC09BA00859E29A0@GRUPR80MB0444.lamprd80.prod.outlook.com>
	<CAOGrcjqjAXXwUK_jNp1Qv4oxSJr5PTVgRaUUsgatrukAcQk0RQ@mail.gmail.com>
Message-ID: <GRUPR80MB04440BA1175DC802979749DEE2960@GRUPR80MB0444.lamprd80.prod.outlook.com>



code? example data?  We can only guess based on your vague post.

"PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code."

Moreover, this sounds like a statistical question, not a question about R programming, and so might be more appropriate for a statistical list like stats.stackexchange.com<http://stats.stackexchange.com>  .

Cheers,
Bert


Bert Gunter



Sorry if I was not clear enough, but  there is hardly any code to show.
The problem is that a parameter or function is lacking (or , mostly likely, I can't find it), so in some sense the problem itself is that  there is no code to show.

In what follows choice situations , alternatives, wide, and variables have the same meaning that they have on the mlogit documentation. All variables are alternative specific.

1)I want to estimate a multinomial Logit  using the mlogit package

2)I have a dataset, made of choice situations

3)There is a set of alternatives

4)in some choice situations, not all alternatives were available, but only a subset of them. So there are no variables for the unavailable alternatives and the chosen alternative evidently  belongs to the set of available ones.

5)I use mlogit.data to prepare the dataset from a "wide" dataframe . There is no option to have only a subset of alternatives and the resulting object will have them all , that is, there will be a line for every alternative and every choice situation, even if in reality some of them were not available. The variables of these alternatives did not exist, so must be filled with 0s or any other made up value

6) If ones estimate a model from this data it will be wrong

7) It is possible to get an "almost right" model by using a dummy variable marking which alternatives are unavailable, for as it is only used in alternatives that are never chosen, its coefficient will get negative with big absolute value, in practice giving almost 0% probability for them

8)this is a workaround because it obligates the model to estimate a number that should be -infinity and this is known in advance, so it's ugly and difficult to know what the numeric consequences are as the coefficient can never converge. In fact, I don't use it the way I described for these reasons, preferring a more complex but almost equivalent formulation. The important point is that I want a clean solution, not a workaround

9)I demand simply if mlogit package has such functionality





Hi,
I meant that in some choice situations there are some alternatives missing, but the available alternatives are known to everybody(both the one that made the choice as well as to who collected the data).
For future reference, I would like to post here that I found the answer.
Apparently it is not possible if one uses mlogit.data  with shape = ?wide?, but it is if one uses it with shape = ?long? .
So basically one can create an alternative specific variable with availability (let?s call it is_avaliable) and use mlogit.data  normally that is :
all_avaliable <- mlogit.data(df , shape = ?wide? , ?)
then one can subset it
real_avaliability <-  all_avaliable[all_avaliable$is_avaliable ,]
and resend it through mlogit.data with format long
mlogit.data(real_avaliability , shape = "long" , alt.var = "alt" ,  chid.var = "chid", ?)
please observe that alt and chid will have been created by the first call to mlogit.data

	[[alternative HTML version deleted]]


From dutangc at gmail.com  Wed Apr 13 21:25:38 2016
From: dutangc at gmail.com (Christophe Dutang)
Date: Wed, 13 Apr 2016 21:25:38 +0200
Subject: [R] on the output of constrOptim()
Message-ID: <6BEA96BE-C5BF-4109-8C78-F7104C8E5CA4@gmail.com>

Dear list,

The following example of constrOptim() where the initial point is the solution shows that the component counts is not a two-element vector as documented in the man page. 

constrOptim(c(1,1), fr, grr, ui = diag(2), ci = c(0,0))

Does anyone have the same behavior?

A possible solution is to put line 69 in constrOptim.R before the first possible break line 67.

Regards, Christophe


> sessionInfo()
R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.5 (Yosemite)

locale:
[1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/fr_FR.UTF-8/fr_FR.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] nlstools_1.0-2     fitdistrplus_1.0-7 survival_2.38-3    MASS_7.3-45       

loaded via a namespace (and not attached):
[1] tools_3.2.4   splines_3.2.4
---------------------------------------
Christophe Dutang
LMM, UdM, Le Mans, France
web: http://dutangc.free.fr <http://dutangc.free.fr/>

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Wed Apr 13 22:40:19 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Wed, 13 Apr 2016 15:40:19 -0500
Subject: [R] Decision Tree and Random Forrest
Message-ID: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>

Hi I'm trying to get the top decision rules from a decision tree.
Eventually I will like to do this with R and Random Forrest.  There has to
be a way to output the decsion rules of each leaf node in an easily
readable way. I am looking at the randomforrest and rpart packages and I
dont see anything yet.
Mike

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Apr 13 22:41:52 2016
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 13 Apr 2016 12:41:52 -0800
Subject: [R] reduced set of alternatives in package mlogit
In-Reply-To: <GRUPR80MB04440BA1175DC802979749DEE2960@GRUPR80MB0444.lamprd80.prod.outlook.com>
References: <grupr80mb04443f1875eaf793c2385609e2990@grupr80mb0444.lamprd80.prod.outlook.com>
	<caogrcjqjaxxwuk_jnp1qv4oxsjr5ptvgrauusgatrukacqk0rq@mail.gmail.com>
	<cagxfjbrgpwzv3hhdiuv4cuzg5xhoihfb+fjaz0cjcemvx33atw@mail.gmail.com>
	<grupr80mb0444f78421ca9ec09ba00859e29a0@grupr80mb0444.lamprd80.prod.outlook.com>
Message-ID: <398FD089328.000001D4jrkrideau@inbox.com>

To back up Ber's please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jose.ferraro at logiteng.com
> Sent: Wed, 13 Apr 2016 17:18:35 +0000
> To: cdesjard at umn.edu
> Subject: Re: [R] reduced set of alternatives in package mlogit
> 
> 
> 
> code? example data?  We can only guess based on your vague post.
> 
> "PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code."
> 
> Moreover, this sounds like a statistical question, not a question about R
> programming, and so might be more appropriate for a statistical list like
> stats.stackexchange.com<http://stats.stackexchange.com>  .
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> 
> 
> Sorry if I was not clear enough, but  there is hardly any code to show.
> The problem is that a parameter or function is lacking (or , mostly
> likely, I can't find it), so in some sense the problem itself is that
> there is no code to show.
> 
> In what follows choice situations , alternatives, wide, and variables
> have the same meaning that they have on the mlogit documentation. All
> variables are alternative specific.
> 
> 1)I want to estimate a multinomial Logit  using the mlogit package
> 
> 2)I have a dataset, made of choice situations
> 
> 3)There is a set of alternatives
> 
> 4)in some choice situations, not all alternatives were available, but
> only a subset of them. So there are no variables for the unavailable
> alternatives and the chosen alternative evidently  belongs to the set of
> available ones.
> 
> 5)I use mlogit.data to prepare the dataset from a "wide" dataframe .
> There is no option to have only a subset of alternatives and the
> resulting object will have them all , that is, there will be a line for
> every alternative and every choice situation, even if in reality some of
> them were not available. The variables of these alternatives did not
> exist, so must be filled with 0s or any other made up value
> 
> 6) If ones estimate a model from this data it will be wrong
> 
> 7) It is possible to get an "almost right" model by using a dummy
> variable marking which alternatives are unavailable, for as it is only
> used in alternatives that are never chosen, its coefficient will get
> negative with big absolute value, in practice giving almost 0%
> probability for them
> 
> 8)this is a workaround because it obligates the model to estimate a
> number that should be -infinity and this is known in advance, so it's
> ugly and difficult to know what the numeric consequences are as the
> coefficient can never converge. In fact, I don't use it the way I
> described for these reasons, preferring a more complex but almost
> equivalent formulation. The important point is that I want a clean
> solution, not a workaround
> 
> 9)I demand simply if mlogit package has such functionality
> 
> 
> 
> 
> 
> Hi,
> I meant that in some choice situations there are some alternatives
> missing, but the available alternatives are known to everybody(both the
> one that made the choice as well as to who collected the data).
> For future reference, I would like to post here that I found the answer.
> Apparently it is not possible if one uses mlogit.data  with shape =
> ?wide?, but it is if one uses it with shape = ?long? .
> So basically one can create an alternative specific variable with
> availability (let?s call it is_avaliable) and use mlogit.data  normally
> that is :
> all_avaliable <- mlogit.data(df , shape = ?wide? , ?)
> then one can subset it
> real_avaliability <-  all_avaliable[all_avaliable$is_avaliable ,]
> and resend it through mlogit.data with format long
> mlogit.data(real_avaliability , shape = "long" , alt.var = "alt" ,
> chid.var = "chid", ?)
> please observe that alt and chid will have been created by the first call
> to mlogit.data
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if5
Capture screenshots, upload images, edit and send them to your friends
through IMs, post on Twitter?, Facebook?, MySpace?, LinkedIn? ? FAST!


From bgunter.4567 at gmail.com  Wed Apr 13 23:08:26 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 13 Apr 2016 14:08:26 -0700
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
Message-ID: <CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>

Nope.

Random forests are not decision trees -- they are ensembles (forests)
of trees. You need to go back and read up on them so you understand
how they work. The Hastie/Tibshirani/Friedman "The Elements of
Statistical Learning" has a nice explanation, but I'm sure there are
lots of good web resources, too.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 13, 2016 at 1:40 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> Hi I'm trying to get the top decision rules from a decision tree.
> Eventually I will like to do this with R and Random Forrest.  There has to
> be a way to output the decsion rules of each leaf node in an easily
> readable way. I am looking at the randomforrest and rpart packages and I
> dont see anything yet.
> Mike
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michaeleartz at gmail.com  Wed Apr 13 23:11:46 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Wed, 13 Apr 2016 16:11:46 -0500
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
Message-ID: <CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>

Ok is there a way to do  it with decision tree?  I just need to make the
decision rules. Perhaps I can pick one of the trees used with Random
Forrest.  I am somewhat familiar already with Random Forrest with
respective to bagging and feature sampling and getting the mode from the
leaf nodes and it being an ensemble technique of many trees.  I am just
working from the perspective that I need decision rules, and I am working
backward form that, and I need to do it in R.

On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Nope.
>
> Random forests are not decision trees -- they are ensembles (forests)
> of trees. You need to go back and read up on them so you understand
> how they work. The Hastie/Tibshirani/Friedman "The Elements of
> Statistical Learning" has a nice explanation, but I'm sure there are
> lots of good web resources, too.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Apr 13, 2016 at 1:40 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> > Hi I'm trying to get the top decision rules from a decision tree.
> > Eventually I will like to do this with R and Random Forrest.  There has
> to
> > be a way to output the decsion rules of each leaf node in an easily
> > readable way. I am looking at the randomforrest and rpart packages and I
> > dont see anything yet.
> > Mike
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Wed Apr 13 23:15:19 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Wed, 13 Apr 2016 16:15:19 -0500
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
	<CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
Message-ID: <CA+pG8eMsgMvUFAedVk0MaH=JJNYvTfYxsh4-92SJndx03DZy6Q@mail.gmail.com>

Also that being said, just because random forest are not the same thing as
decision trees does not mean that you can't get decision rules from random
forest.

On Wed, Apr 13, 2016 at 4:11 PM, Michael Artz <michaeleartz at gmail.com>
wrote:

> Ok is there a way to do  it with decision tree?  I just need to make the
> decision rules. Perhaps I can pick one of the trees used with Random
> Forrest.  I am somewhat familiar already with Random Forrest with
> respective to bagging and feature sampling and getting the mode from the
> leaf nodes and it being an ensemble technique of many trees.  I am just
> working from the perspective that I need decision rules, and I am working
> backward form that, and I need to do it in R.
>
> On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Nope.
>>
>> Random forests are not decision trees -- they are ensembles (forests)
>> of trees. You need to go back and read up on them so you understand
>> how they work. The Hastie/Tibshirani/Friedman "The Elements of
>> Statistical Learning" has a nice explanation, but I'm sure there are
>> lots of good web resources, too.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Apr 13, 2016 at 1:40 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>> > Hi I'm trying to get the top decision rules from a decision tree.
>> > Eventually I will like to do this with R and Random Forrest.  There has
>> to
>> > be a way to output the decsion rules of each leaf node in an easily
>> > readable way. I am looking at the randomforrest and rpart packages and I
>> > dont see anything yet.
>> > Mike
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Apr 13 23:30:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 13 Apr 2016 14:30:43 -0700
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
	<CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
Message-ID: <CAGxFJbRdkopCgfSs7pumB37eR1TeeaNhpS0AfR3hBSwwt_=RLg@mail.gmail.com>

I think you are missing the point of random forests. But if you just
want to predict using the forest, there is a predict() method that you
can use. Other than that, I certainly don't understand what you mean.
Maybe someone else might.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> Ok is there a way to do  it with decision tree?  I just need to make the
> decision rules. Perhaps I can pick one of the trees used with Random
> Forrest.  I am somewhat familiar already with Random Forrest with respective
> to bagging and feature sampling and getting the mode from the leaf nodes and
> it being an ensemble technique of many trees.  I am just working from the
> perspective that I need decision rules, and I am working backward form that,
> and I need to do it in R.
>
> On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> Nope.
>>
>> Random forests are not decision trees -- they are ensembles (forests)
>> of trees. You need to go back and read up on them so you understand
>> how they work. The Hastie/Tibshirani/Friedman "The Elements of
>> Statistical Learning" has a nice explanation, but I'm sure there are
>> lots of good web resources, too.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Apr 13, 2016 at 1:40 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>> > Hi I'm trying to get the top decision rules from a decision tree.
>> > Eventually I will like to do this with R and Random Forrest.  There has
>> > to
>> > be a way to output the decsion rules of each leaf node in an easily
>> > readable way. I am looking at the randomforrest and rpart packages and I
>> > dont see anything yet.
>> > Mike
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From michaeleartz at gmail.com  Thu Apr 14 00:02:18 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Wed, 13 Apr 2016 17:02:18 -0500
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CAGxFJbRdkopCgfSs7pumB37eR1TeeaNhpS0AfR3hBSwwt_=RLg@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
	<CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
	<CAGxFJbRdkopCgfSs7pumB37eR1TeeaNhpS0AfR3hBSwwt_=RLg@mail.gmail.com>
Message-ID: <CA+pG8ePvj6S1sFq3=xWcxwrM12BYRBodCR71-wTc=jwiFzuEmg@mail.gmail.com>

Ah yes I will have to use the predict function.  But the predict function
will not get me there really.  If I can take the example that I have a
model predicting whether or not I will play golf (this is the dependent
value), and there are three independent variables Humidity(High, Medium,
Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind (High,
Low).  I would like rules like where any record that follows these rules
(IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
there is probability that play_golf is YES).  I was thinking that random
forrest would weight the rules somehow on the collection of trees and give
a probability.  But if that doesnt make sense, then can you just tell me
how to get the decsion rules with one tree and I will work from that.

Mike

Mike

On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I think you are missing the point of random forests. But if you just
> want to predict using the forest, there is a predict() method that you
> can use. Other than that, I certainly don't understand what you mean.
> Maybe someone else might.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> > Ok is there a way to do  it with decision tree?  I just need to make the
> > decision rules. Perhaps I can pick one of the trees used with Random
> > Forrest.  I am somewhat familiar already with Random Forrest with
> respective
> > to bagging and feature sampling and getting the mode from the leaf nodes
> and
> > it being an ensemble technique of many trees.  I am just working from the
> > perspective that I need decision rules, and I am working backward form
> that,
> > and I need to do it in R.
> >
> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>
> >> Nope.
> >>
> >> Random forests are not decision trees -- they are ensembles (forests)
> >> of trees. You need to go back and read up on them so you understand
> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
> >> Statistical Learning" has a nice explanation, but I'm sure there are
> >> lots of good web resources, too.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, Apr 13, 2016 at 1:40 PM, Michael Artz <michaeleartz at gmail.com>
> >> wrote:
> >> > Hi I'm trying to get the top decision rules from a decision tree.
> >> > Eventually I will like to do this with R and Random Forrest.  There
> has
> >> > to
> >> > be a way to output the decsion rules of each leaf node in an easily
> >> > readable way. I am looking at the randomforrest and rpart packages
> and I
> >> > dont see anything yet.
> >> > Mike
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Apr 14 00:32:37 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 13 Apr 2016 18:32:37 -0400
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8ePvj6S1sFq3=xWcxwrM12BYRBodCR71-wTc=jwiFzuEmg@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
	<CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
	<CAGxFJbRdkopCgfSs7pumB37eR1TeeaNhpS0AfR3hBSwwt_=RLg@mail.gmail.com>
	<CA+pG8ePvj6S1sFq3=xWcxwrM12BYRBodCR71-wTc=jwiFzuEmg@mail.gmail.com>
Message-ID: <CAM_vjumar+BNV2n-iZiBF4YH4+LnjHvxtFM9auXMBXxCbwdVDQ@mail.gmail.com>

It sounds like you want classification or regression trees. rpart does
exactly what you describe.

Here's an overview:
http://www.statmethods.net/advstats/cart.html

But there are a lot of other ways to do the same thing in R, for instance:
http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/

You can get the same kind of information from random forests, but it's
less straightforward. If you want a clear set of rules as in your golf
example, then you need rpart or similar.

Sarah

On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> Ah yes I will have to use the predict function.  But the predict function
> will not get me there really.  If I can take the example that I have a
> model predicting whether or not I will play golf (this is the dependent
> value), and there are three independent variables Humidity(High, Medium,
> Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind (High,
> Low).  I would like rules like where any record that follows these rules
> (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
> there is probability that play_golf is YES).  I was thinking that random
> forrest would weight the rules somehow on the collection of trees and give
> a probability.  But if that doesnt make sense, then can you just tell me
> how to get the decsion rules with one tree and I will work from that.
>
> Mike
>
> Mike
>
> On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> I think you are missing the point of random forests. But if you just
>> want to predict using the forest, there is a predict() method that you
>> can use. Other than that, I certainly don't understand what you mean.
>> Maybe someone else might.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>> > Ok is there a way to do  it with decision tree?  I just need to make the
>> > decision rules. Perhaps I can pick one of the trees used with Random
>> > Forrest.  I am somewhat familiar already with Random Forrest with
>> respective
>> > to bagging and feature sampling and getting the mode from the leaf nodes
>> and
>> > it being an ensemble technique of many trees.  I am just working from the
>> > perspective that I need decision rules, and I am working backward form
>> that,
>> > and I need to do it in R.
>> >
>> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >>
>> >> Nope.
>> >>
>> >> Random forests are not decision trees -- they are ensembles (forests)
>> >> of trees. You need to go back and read up on them so you understand
>> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
>> >> Statistical Learning" has a nice explanation, but I'm sure there are
>> >> lots of good web resources, too.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >> Bert Gunter
>> >>


From michaeleartz at gmail.com  Thu Apr 14 00:45:11 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Wed, 13 Apr 2016 17:45:11 -0500
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8eNLC5zBb5RMoEbzozho9ygzWNCPPHiNobtdif3Ce_+HjQ@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
	<CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
	<CAGxFJbRdkopCgfSs7pumB37eR1TeeaNhpS0AfR3hBSwwt_=RLg@mail.gmail.com>
	<CA+pG8ePvj6S1sFq3=xWcxwrM12BYRBodCR71-wTc=jwiFzuEmg@mail.gmail.com>
	<CAM_vjumar+BNV2n-iZiBF4YH4+LnjHvxtFM9auXMBXxCbwdVDQ@mail.gmail.com>
	<CA+pG8eN5d9PzEoAjtNQJE-CSSo56CxUgmZbuHcpYKRL73yv_8g@mail.gmail.com>
	<CA+pG8eNLC5zBb5RMoEbzozho9ygzWNCPPHiNobtdif3Ce_+HjQ@mail.gmail.com>
Message-ID: <CA+pG8eOYWW9Tw=e26fTWrmNuqgpGtoB2-hULBM49PqQL8iwZrA@mail.gmail.com>

Tjats great that you are familiar and thanks for responding.  Have you ever
done what I am referring to? I have alteady spent time going through links
and tutorials about decision trees and random forrests and have even used
them both before.

Mike
On Apr 13, 2016 5:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:

It sounds like you want classification or regression trees. rpart does
exactly what you describe.

Here's an overview:
http://www.statmethods.net/advstats/cart.html

But there are a lot of other ways to do the same thing in R, for instance:
http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/

You can get the same kind of information from random forests, but it's
less straightforward. If you want a clear set of rules as in your golf
example, then you need rpart or similar.

Sarah

On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com>
wrote:
> Ah yes I will have to use the predict function.  But the predict function
> will not get me there really.  If I can take the example that I have a
> model predicting whether or not I will play golf (this is the dependent
> value), and there are three independent variables Humidity(High, Medium,
> Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind
(High,
> Low).  I would like rules like where any record that follows these rules
> (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
> there is probability that play_golf is YES).  I was thinking that random
> forrest would weight the rules somehow on the collection of trees and give
> a probability.  But if that doesnt make sense, then can you just tell me
> how to get the decsion rules with one tree and I will work from that.
>
> Mike
>
> Mike
>
> On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:
>
>> I think you are missing the point of random forests. But if you just
>> want to predict using the forest, there is a predict() method that you
>> can use. Other than that, I certainly don't understand what you mean.
>> Maybe someone else might.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>> > Ok is there a way to do  it with decision tree?  I just need to make
the
>> > decision rules. Perhaps I can pick one of the trees used with Random
>> > Forrest.  I am somewhat familiar already with Random Forrest with
>> respective
>> > to bagging and feature sampling and getting the mode from the leaf
nodes
>> and
>> > it being an ensemble technique of many trees.  I am just working from
the
>> > perspective that I need decision rules, and I am working backward form
>> that,
>> > and I need to do it in R.
>> >
>> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >>
>> >> Nope.
>> >>
>> >> Random forests are not decision trees -- they are ensembles (forests)
>> >> of trees. You need to go back and read up on them so you understand
>> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
>> >> Statistical Learning" has a nice explanation, but I'm sure there are
>> >> lots of good web resources, too.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >> Bert Gunter
>> >>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Apr 14 03:04:42 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 13 Apr 2016 21:04:42 -0400
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8eOYWW9Tw=e26fTWrmNuqgpGtoB2-hULBM49PqQL8iwZrA@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
	<CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
	<CAGxFJbRdkopCgfSs7pumB37eR1TeeaNhpS0AfR3hBSwwt_=RLg@mail.gmail.com>
	<CA+pG8ePvj6S1sFq3=xWcxwrM12BYRBodCR71-wTc=jwiFzuEmg@mail.gmail.com>
	<CAM_vjumar+BNV2n-iZiBF4YH4+LnjHvxtFM9auXMBXxCbwdVDQ@mail.gmail.com>
	<CA+pG8eN5d9PzEoAjtNQJE-CSSo56CxUgmZbuHcpYKRL73yv_8g@mail.gmail.com>
	<CA+pG8eNLC5zBb5RMoEbzozho9ygzWNCPPHiNobtdif3Ce_+HjQ@mail.gmail.com>
	<CA+pG8eOYWW9Tw=e26fTWrmNuqgpGtoB2-hULBM49PqQL8iwZrA@mail.gmail.com>
Message-ID: <CAM_vjum+xWobM0x7XYV0g96AhD2J6+mPKBxJbCuDBJWpLLgJPw@mail.gmail.com>

On Wednesday, April 13, 2016, Michael Artz <michaeleartz at gmail.com> wrote:

> Tjats great that you are familiar and thanks for responding.  Have you
> ever done what I am referring to? I have alteady spent time going through
> links and tutorials about decision trees and random forrests and have even
> used them both before.
>
Then what specifically is your problem? Both of the tutorials I provided
show worked examples, as does even the help for rpart. If none of those, or
your extensive reading, work for your project you will have to be a lot
more specific about why not.

Sarah



> Mike
> On Apr 13, 2016 5:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com
> <javascript:_e(%7B%7D,'cvml','sarah.goslee at gmail.com');>> wrote:
>
> It sounds like you want classification or regression trees. rpart does
> exactly what you describe.
>
> Here's an overview:
> http://www.statmethods.net/advstats/cart.html
>
> But there are a lot of other ways to do the same thing in R, for instance:
> http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/
>
> You can get the same kind of information from random forests, but it's
> less straightforward. If you want a clear set of rules as in your golf
> example, then you need rpart or similar.
>
> Sarah
>
> On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com
> <javascript:_e(%7B%7D,'cvml','michaeleartz at gmail.com');>> wrote:
> > Ah yes I will have to use the predict function.  But the predict function
> > will not get me there really.  If I can take the example that I have a
> > model predicting whether or not I will play golf (this is the dependent
> > value), and there are three independent variables Humidity(High, Medium,
> > Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind
> (High,
> > Low).  I would like rules like where any record that follows these rules
> > (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
> > there is probability that play_golf is YES).  I was thinking that random
> > forrest would weight the rules somehow on the collection of trees and
> give
> > a probability.  But if that doesnt make sense, then can you just tell me
> > how to get the decsion rules with one tree and I will work from that.
> >
> > Mike
> >
> > Mike
> >
> > On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com
> <javascript:_e(%7B%7D,'cvml','bgunter.4567 at gmail.com');>> wrote:
> >
> >> I think you are missing the point of random forests. But if you just
> >> want to predict using the forest, there is a predict() method that you
> >> can use. Other than that, I certainly don't understand what you mean.
> >> Maybe someone else might.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com
> <javascript:_e(%7B%7D,'cvml','michaeleartz at gmail.com');>>
> >> wrote:
> >> > Ok is there a way to do  it with decision tree?  I just need to make
> the
> >> > decision rules. Perhaps I can pick one of the trees used with Random
> >> > Forrest.  I am somewhat familiar already with Random Forrest with
> >> respective
> >> > to bagging and feature sampling and getting the mode from the leaf
> nodes
> >> and
> >> > it being an ensemble technique of many trees.  I am just working from
> the
> >> > perspective that I need decision rules, and I am working backward form
> >> that,
> >> > and I need to do it in R.
> >> >
> >> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com
> <javascript:_e(%7B%7D,'cvml','bgunter.4567 at gmail.com');>>
> >> wrote:
> >> >>
> >> >> Nope.
> >> >>
> >> >> Random forests are not decision trees -- they are ensembles (forests)
> >> >> of trees. You need to go back and read up on them so you understand
> >> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
> >> >> Statistical Learning" has a nice explanation, but I'm sure there are
> >> >> lots of good web resources, too.
> >> >>
> >> >> Cheers,
> >> >> Bert
> >> >>
> >> >>
> >> >> Bert Gunter
> >> >>
>
>

-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From fartzy at hotmail.com  Thu Apr 14 03:12:53 2016
From: fartzy at hotmail.com (Michael Eugene)
Date: Wed, 13 Apr 2016 20:12:53 -0500
Subject: [R] Decision Tree and Random Forrest
Message-ID: <BLU406-EAS2105F5EFDF041F6D9B77D45CD970@phx.gbl>

I still need the output to match my requiremnt in my original post.  With decision rules "clusters" and probability attached to them.  The examples are sort of similar.  You just provided links to general info about trees.


Sent from my Verizon, Samsung Galaxy smartphone<div>
</div><div>
</div><!-- originalMessage --><div>-------- Original message --------</div><div>From: Sarah Goslee <sarah.goslee at gmail.com> </div><div>Date: 4/13/16  8:04 PM  (GMT-06:00) </div><div>To: Michael Artz <michaeleartz at gmail.com> </div><div>Cc: "r-help at r-project.org" <R-help at r-project.org> </div><div>Subject: Re: [R] Decision Tree and Random Forrest </div><div>
</div>
On Wednesday, April 13, 2016, Michael Artz <michaeleartz at gmail.com> wrote:

> Tjats great that you are familiar and thanks for responding.  Have you
> ever done what I am referring to? I have alteady spent time going through
> links and tutorials about decision trees and random forrests and have even
> used them both before.
>
Then what specifically is your problem? Both of the tutorials I provided
show worked examples, as does even the help for rpart. If none of those, or
your extensive reading, work for your project you will have to be a lot
more specific about why not.

Sarah



> Mike
> On Apr 13, 2016 5:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com
> <javascript:_e(%7B%7D,'cvml','sarah.goslee at gmail.com');>> wrote:
>
> It sounds like you want classification or regression trees. rpart does
> exactly what you describe.
>
> Here's an overview:
> http://www.statmethods.net/advstats/cart.html
>
> But there are a lot of other ways to do the same thing in R, for instance:
> http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/
>
> You can get the same kind of information from random forests, but it's
> less straightforward. If you want a clear set of rules as in your golf
> example, then you need rpart or similar.
>
> Sarah
>
> On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com
> <javascript:_e(%7B%7D,'cvml','michaeleartz at gmail.com');>> wrote:
> > Ah yes I will have to use the predict function.  But the predict function
> > will not get me there really.  If I can take the example that I have a
> > model predicting whether or not I will play golf (this is the dependent
> > value), and there are three independent variables Humidity(High, Medium,
> > Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind
> (High,
> > Low).  I would like rules like where any record that follows these rules
> > (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
> > there is probability that play_golf is YES).  I was thinking that random
> > forrest would weight the rules somehow on the collection of trees and
> give
> > a probability.  But if that doesnt make sense, then can you just tell me
> > how to get the decsion rules with one tree and I will work from that.
> >
> > Mike
> >
> > Mike
> >
> > On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com
> <javascript:_e(%7B%7D,'cvml','bgunter.4567 at gmail.com');>> wrote:
> >
> >> I think you are missing the point of random forests. But if you just
> >> want to predict using the forest, there is a predict() method that you
> >> can use. Other than that, I certainly don't understand what you mean.
> >> Maybe someone else might.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com
> <javascript:_e(%7B%7D,'cvml','michaeleartz at gmail.com');>>
> >> wrote:
> >> > Ok is there a way to do  it with decision tree?  I just need to make
> the
> >> > decision rules. Perhaps I can pick one of the trees used with Random
> >> > Forrest.  I am somewhat familiar already with Random Forrest with
> >> respective
> >> > to bagging and feature sampling and getting the mode from the leaf
> nodes
> >> and
> >> > it being an ensemble technique of many trees.  I am just working from
> the
> >> > perspective that I need decision rules, and I am working backward form
> >> that,
> >> > and I need to do it in R.
> >> >
> >> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com
> <javascript:_e(%7B%7D,'cvml','bgunter.4567 at gmail.com');>>
> >> wrote:
> >> >>
> >> >> Nope.
> >> >>
> >> >> Random forests are not decision trees -- they are ensembles (forests)
> >> >> of trees. You need to go back and read up on them so you understand
> >> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
> >> >> Statistical Learning" has a nice explanation, but I'm sure there are
> >> >> lots of good web resources, too.
> >> >>
> >> >> Cheers,
> >> >> Bert
> >> >>
> >> >>
> >> >> Bert Gunter
> >> >>
>
>

--
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Thu Apr 14 09:23:47 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 14 Apr 2016 09:23:47 +0200 (CEST)
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8ePvj6S1sFq3=xWcxwrM12BYRBodCR71-wTc=jwiFzuEmg@mail.gmail.com>
References: <CA+pG8eOJdvg=fCHci+Y_B8u_FkTdg7A8SN77Nv74Hrb_p9cQYQ@mail.gmail.com>
	<CAGxFJbSGhiSAwMw62zJsPwuWzG29yrRsXcO7+6jJDcdh6jCWpg@mail.gmail.com>
	<CA+pG8eNEt3MZFCVtHP0gwrhRX9kfPUC8R1W-WOt6GVXfQ=+bPg@mail.gmail.com>
	<CAGxFJbRdkopCgfSs7pumB37eR1TeeaNhpS0AfR3hBSwwt_=RLg@mail.gmail.com>
	<CA+pG8ePvj6S1sFq3=xWcxwrM12BYRBodCR71-wTc=jwiFzuEmg@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1604140913450.27275@paninaro>

On Thu, 14 Apr 2016, Michael Artz wrote:

> Ah yes I will have to use the predict function.  But the predict function
> will not get me there really.  If I can take the example that I have a
> model predicting whether or not I will play golf (this is the dependent
> value), and there are three independent variables Humidity(High, Medium,
> Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind (High,
> Low).  I would like rules like where any record that follows these rules
> (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
> there is probability that play_golf is YES).

Although I think that this toy example is not overly useful for practical 
illustrations we have included the standard dataset in the "partykit" 
package:

## data
data("WeatherPlay", package = "partykit")

> I was thinking that random forrest would weight the rules somehow on the 
> collection of trees and give a probability.  But if that doesnt make 
> sense, then can you just tell me how to get the decsion rules with one 
> tree and I will work from that.

Then you can learn one tree on this data, e.g., with rpart() or ctree():

## trees
library("rpart")
rp <- rpart(play ~ ., data = WeatherPlay,
   control = rpart.control(minsplit = 5))

library("partykit")
ct <- ctree(play ~ ., data = WeatherPlay,
   minsplit = 5, mincriterion = 0.1)

## visualize via partykit
pr <- as.party(rp)
plot(pr)
plot(ct)

And the partykit package also includes a function to generate a text 
representation of the rules although this is currently not exported:

partykit:::.list.rules.party(pr)
##                            "outlook %in% c(\"overcast\")"
##                                                         4
##  "outlook %in% c(\"sunny\", \"rainy\") & humidity < 82.5"
##                                                         5
## "outlook %in% c(\"sunny\", \"rainy\") & humidity >= 82.5"

partykit:::.list.rules.party(ct)
##                2                3
## "humidity <= 80"  "humidity > 80"

If you do not want a text representation but something else you can 
compute on, then look at the source code of partykit:::.list.rules.party() 
and try to adapt it to your needs.

> On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> I think you are missing the point of random forests. But if you just
>> want to predict using the forest, there is a predict() method that you
>> can use. Other than that, I certainly don't understand what you mean.
>> Maybe someone else might.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>> Ok is there a way to do  it with decision tree?  I just need to make the
>>> decision rules. Perhaps I can pick one of the trees used with Random
>>> Forrest.  I am somewhat familiar already with Random Forrest with
>> respective
>>> to bagging and feature sampling and getting the mode from the leaf nodes
>> and
>>> it being an ensemble technique of many trees.  I am just working from the
>>> perspective that I need decision rules, and I am working backward form
>> that,
>>> and I need to do it in R.
>>>
>>> On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>>>
>>>> Nope.
>>>>
>>>> Random forests are not decision trees -- they are ensembles (forests)
>>>> of trees. You need to go back and read up on them so you understand
>>>> how they work. The Hastie/Tibshirani/Friedman "The Elements of
>>>> Statistical Learning" has a nice explanation, but I'm sure there are
>>>> lots of good web resources, too.
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Wed, Apr 13, 2016 at 1:40 PM, Michael Artz <michaeleartz at gmail.com>
>>>> wrote:
>>>>> Hi I'm trying to get the top decision rules from a decision tree.
>>>>> Eventually I will like to do this with R and Random Forrest.  There
>> has
>>>>> to
>>>>> be a way to output the decsion rules of each leaf node in an easily
>>>>> readable way. I am looking at the randomforrest and rpart packages
>> and I
>>>>> dont see anything yet.
>>>>> Mike
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marna.wagley at gmail.com  Thu Apr 14 09:28:18 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Thu, 14 Apr 2016 00:28:18 -0700
Subject: [R] calculate sampel size?
Message-ID: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>

Hi R user,
Can we calculate sample size when only mean and SE are given?
Let say one example,  I have mean with SE is  0.54+-0.0517 (mean+-SE). Is
there any way to find the samples (sample size n) in that condition in R?

i think this question is not related to R, I hope you won't mind.
Thanks

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Apr 14 09:26:41 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 14 Apr 2016 03:26:41 -0400
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <BLU406-EAS2105F5EFDF041F6D9B77D45CD970@phx.gbl>
References: <BLU406-EAS2105F5EFDF041F6D9B77D45CD970@phx.gbl>
Message-ID: <CAM_vju=KKvpRWetkdHsW1Rxp7X1KPHmd93JEZFFwe1PcFCGf0Q@mail.gmail.com>

So. Given that the second and third panels of the first figure in the first
link I gave show a decision tree with decision rules at each split and the
number of samples at each direction, what _exactly_ is your problem?



On Wednesday, April 13, 2016, Michael Eugene <fartzy at hotmail.com> wrote:

> I still need the output to match my requiremnt in my original post.  With
> decision rules "clusters" and probability attached to them.  The examples
> are sort of similar.  You just provided links to general info about trees.
>
>
>
> Sent from my Verizon, Samsung Galaxy smartphone
>
>
> -------- Original message --------
> From: Sarah Goslee <sarah.goslee at gmail.com
> <javascript:_e(%7B%7D,'cvml','sarah.goslee at gmail.com');>>
> Date: 4/13/16 8:04 PM (GMT-06:00)
> To: Michael Artz <michaeleartz at gmail.com
> <javascript:_e(%7B%7D,'cvml','michaeleartz at gmail.com');>>
> Cc: "r-help at r-project.org
> <javascript:_e(%7B%7D,'cvml','r-help at r-project.org');>" <
> R-help at r-project.org
> <javascript:_e(%7B%7D,'cvml','R-help at r-project.org');>>
> Subject: Re: [R] Decision Tree and Random Forrest
>
>
>
> On Wednesday, April 13, 2016, Michael Artz <michaeleartz at gmail.com
> <javascript:_e(%7B%7D,'cvml','michaeleartz at gmail.com');>> wrote:
>
> Tjats great that you are familiar and thanks for responding.  Have you
> ever done what I am referring to? I have alteady spent time going through
> links and tutorials about decision trees and random forrests and have even
> used them both before.
>
> Then what specifically is your problem? Both of the tutorials I provided
> show worked examples, as does even the help for rpart. If none of those, or
> your extensive reading, work for your project you will have to be a lot
> more specific about why not.
>
> Sarah
>
>
>
> Mike
> On Apr 13, 2016 5:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
>
> It sounds like you want classification or regression trees. rpart does
> exactly what you describe.
>
> Here's an overview:
> http://www.statmethods.net/advstats/cart.html
>
> But there are a lot of other ways to do the same thing in R, for instance:
> http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/
>
> You can get the same kind of information from random forests, but it's
> less straightforward. If you want a clear set of rules as in your golf
> example, then you need rpart or similar.
>
> Sarah
>
> On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> > Ah yes I will have to use the predict function.  But the predict function
> > will not get me there really.  If I can take the example that I have a
> > model predicting whether or not I will play golf (this is the dependent
> > value), and there are three independent variables Humidity(High, Medium,
> > Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind
> (High,
> > Low).  I would like rules like where any record that follows these rules
> > (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
> > there is probability that play_golf is YES).  I was thinking that random
> > forrest would weight the rules somehow on the collection of trees and
> give
> > a probability.  But if that doesnt make sense, then can you just tell me
> > how to get the decsion rules with one tree and I will work from that.
> >
> > Mike
> >
> > Mike
> >
> > On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> I think you are missing the point of random forests. But if you just
> >> want to predict using the forest, there is a predict() method that you
> >> can use. Other than that, I certainly don't understand what you mean.
> >> Maybe someone else might.
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com>
> >> wrote:
> >> > Ok is there a way to do  it with decision tree?  I just need to make
> the
> >> > decision rules. Perhaps I can pick one of the trees used with Random
> >> > Forrest.  I am somewhat familiar already with Random Forrest with
> >> respective
> >> > to bagging and feature sampling and getting the mode from the leaf
> nodes
> >> and
> >> > it being an ensemble technique of many trees.  I am just working from
> the
> >> > perspective that I need decision rules, and I am working backward form
> >> that,
> >> > and I need to do it in R.
> >> >
> >> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >> >>
> >> >> Nope.
> >> >>
> >> >> Random forests are not decision trees -- they are ensembles (forests)
> >> >> of trees. You need to go back and read up on them so you understand
> >> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
> >> >> Statistical Learning" has a nice explanation, but I'm sure there are
> >> >> lots of good web resources, too.
> >> >>
> >> >> Cheers,
> >> >> Bert
> >> >>
> >> >>
> >> >> Bert Gunter
> >> >>
>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Apr 14 09:37:44 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 14 Apr 2016 03:37:44 -0400
Subject: [R] calculate sampel size?
In-Reply-To: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>
References: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>
Message-ID: <CAM_vju=fR72t45YG_iDWSGQYMCaaWMfTudJtxRDqvTQY_TE+3Q@mail.gmail.com>

You are right, your question is not related to R, so not appropraie here. I
pasted your question into google instead, and got all sorts of suggestions,
ncluding

https://www.isixsigma.com/tools-templates/sampling-data/how-determine-sample-size-determining-sample-size/

Sarah

On Thursday, April 14, 2016, Marna Wagley <marna.wagley at gmail.com> wrote:

> Hi R user,
> Can we calculate sample size when only mean and SE are given?
> Let say one example,  I have mean with SE is  0.54+-0.0517 (mean+-SE). Is
> there any way to find the samples (sample size n) in that condition in R?
>
> i think this question is not related to R, I hope you won't mind.
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Apr 14 09:55:23 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 14 Apr 2016 19:55:23 +1200
Subject: [R] [FORGED]  calculate sampel size?
In-Reply-To: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>
References: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>
Message-ID: <570F4CEB.7060208@auckland.ac.nz>

On 14/04/16 19:28, Marna Wagley wrote:
> Hi R user,
> Can we calculate sample size when only mean and SE are given?
> Let say one example,  I have mean with SE is  0.54+-0.0517 (mean+-SE). Is
> there any way to find the samples (sample size n) in that condition in R?
>
> i think this question is not related to R, I hope you won't mind.


You're correct, your question is not related to R.

But the answer (short, long or indifferent) to your question is No.

And furthermore, don't be silly.  SE = s/sqrt(n).  If you knew s you 
could solve for n, but you don't.  Full stop.  There's an end to it.
Any further mucking about is unproductive wishful thinking.

cheers,

Rolf Turner

P. S.  See fortune(299).

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From milujisb at gmail.com  Thu Apr 14 10:01:21 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 14 Apr 2016 10:01:21 +0200
Subject: [R] Adding Two-Headed Arrow in map legend
In-Reply-To: <CA+8X3fUDDZoQx6=etdOC9rukqgTuOba378TqJssDbSnXX7-_4Q@mail.gmail.com>
References: <CAMLwc7MNr90uc=PsZnaozOeYBbi0VW2NeJj4p90Qk0WMmvoeFA@mail.gmail.com>
	<CA+8X3fWsNu4a_-mnSJn6rdVxkXFfTN9pRsQ8ka5kYz57DM_M-Q@mail.gmail.com>
	<CAMLwc7NvqrFihPpBeKaB5jVsXPuU7XALojpbuQSezD75G_Dnrg@mail.gmail.com>
	<2965F95C-8C2C-4260-9451-B2981552764E@comcast.net>
	<CAMLwc7M7sAedUH+vAHtTM+af3JkOoajLczsD5T=oavdjaRMYvQ@mail.gmail.com>
	<CE58A550-9A1E-4E27-B0E0-C188FEEE3288@comcast.net>
	<2176A5C6-B02B-40EB-98AE-9472D5F80D12@comcast.net>
	<9E253A2A-BD07-4F76-9D75-B885E9DC1683@comcast.net>
	<CAMLwc7MsNU5yTVFFbW0iYQ-p0jbOHHxT19GRz1Rknb8VAMKGFQ@mail.gmail.com>
	<0EEF95A1-AC3A-419D-BA5D-FC7D0733AA4A@comcast.net>
	<CAMLwc7M+DaDxM1UcMpA_qS0MEo=kLFU3eXvZYeZMFursbFxRRQ@mail.gmail.com>
	<3B88203A-7EDB-46A4-9D36-6F581BC4E5AC@comcast.net>
	<CAMLwc7P1Tm+fYQC4JTT8o-At=btxZP=Hprg9wCp_hXXMkN2eFQ@mail.gmail.com>
	<CA+8X3fXaHp6aiZ0K+B3Wv_zw=s1gW0neD_QDt7kW5LunHE5WLg@mail.gmail.com>
	<CAMLwc7NZGuoyAkXhokJXwjHT4eUsb1w0SLJHQNWcnTZuo7YQ6g@mail.gmail.com>
	<CA+8X3fU+r4iFOQUpA+hQaV7Ub=spxd9deWbhzDk8dxNGTBZjBg@mail.gmail.com>
	<CAMLwc7PAptJ-Q4ci5W2pY4PMar9jJQisyXLtLfb0d+61Sq46dA@mail.gmail.com>
	<CA+8X3fUDDZoQx6=etdOC9rukqgTuOba378TqJssDbSnXX7-_4Q@mail.gmail.com>
Message-ID: <CAMLwc7PcvTHaoVbAjT3EEgLRCyaVkwF_qCF5Vooe6j8b2vOv9Q@mail.gmail.com>

Hello Jim,

You're amazing. This is what finally worked:

arrows(-1,19,35.6,19,code=3, xpd=T).

Don't know the coordinates were giving so much trouble. Maybe something to
do with maps in rworldmap. Thanks again!

Sincerely,

Milu

On Wed, Apr 13, 2016 at 6:51 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Milu,
> My fault here. As I don't have the data to make the map and try out my
> suggestions I mixed up the x and y coordinates. Try this:
>
> par(xpd=TRUE)
> arrows(-19.75966,53,33.60000,53,code=3)
> par(xpd=FALSE)
>
> Jim
>
> On Tue, Apr 12, 2016 at 10:11 PM, Miluji Sb <milujisb at gmail.com> wrote:
> > Hello Jim,
> >
> > Thanks again. I am getting the two-headed arrow but I cannot seem to get
> the
> > coordinates right for the arrow to appear beneath the map. These
> coordinates
> > puts the arrow on the left hand side. Thanks again!
> >
> > Sincerely,
> >
> > Milu
> >
> > On Tue, Apr 12, 2016 at 1:15 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Milu,
> >> There is a two-headed arrow on the image you sent, and it seems to be
> >> where you specified. Did you want it beneath the map, as:
> >>
> >> par(xpd=TRUE)
> >> arrows(-22,54.75,-22,74,code=3)
> >> par(xpd=FALSE)
> >>
> >> Jim
> >>
> >> On Tue, Apr 12, 2016 at 7:58 PM, Miluji Sb <milujisb at gmail.com> wrote:
> >> > Dear Jim,
> >> >
> >> > Thanks again! I do want the arrows at the bottom (beneath the map).
> This
> >> > is
> >> > what I am doing:
> >> >
> >> > # Draw the map
> >> > eps_europe <- mapCountryData(n, nameColumnToPlot="eps_score",
> >> > mapTitle="EPS
> >> > Score - Europe",colourPalette=colourPalette,
> >> > catMethod="fixedWidth", missingCountryCol = "white",
> mapRegion="Europe",
> >> > addLegend=FALSE)
> >> >
> >> > # ISO3 codes on the map
> >> > text(n, labels="ISO3", cex=0.30)
> >> >
> >> > # Obtain coordinates for the arrow
> >> > par('usr')
> >> >
> >> > # -19.75966  54.75966  33.60000  71.40000
> >> >
> >> > # Arrows
> >> > par(xpd=TRUE)
> >> > arrows(-19.75966,  54.75966,  33.60000,  71.40000,code=3)
> >> > par(xpd=FALSE)
> >> >
> >> > As the output shows I cannot seem to get the correct coordinates for
> the
> >> > arrows. Thanks again.
> >> >
> >> > Sincerely,
> >> >
> >> > Milu
> >
> >
>

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Thu Apr 14 14:33:57 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 14 Apr 2016 08:33:57 -0400
Subject: [R] Microsoft R Server
In-Reply-To: <570F4CEB.7060208@auckland.ac.nz>
References: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>
	<570F4CEB.7060208@auckland.ac.nz>
Message-ID: <570F55FB020000CB001509F2@smtp.medicine.umaryland.edu>

Has anyone ever heard of or used Microsoft R server? Does the product work? What are requirements for running it? How much does it cost and is it supported by the R community?
Thank you,
John
Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}


From bob at rudis.net  Thu Apr 14 14:52:51 2016
From: bob at rudis.net (boB Rudis)
Date: Thu, 14 Apr 2016 08:52:51 -0400
Subject: [R] Microsoft R Server
In-Reply-To: <570F55FB020000CB001509F2@smtp.medicine.umaryland.edu>
References: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>
	<570F4CEB.7060208@auckland.ac.nz>
	<570F55FB020000CB001509F2@smtp.medicine.umaryland.edu>
Message-ID: <CAJ4QxaMTyQmfRDJmNXL2k41TiM0yyzH=c=Y4ZDfUfBJFU8d=_Q@mail.gmail.com>

Yes. Yes. That info is on their site. That info is on their site. They
have paid support for their customers and
non-Microsoft-R-platform-dependent packages will (most likely) still
be answered by the community.

This is just a re-branding and expansion of what was Revolution R
which has been around for ages and a really great supporter and
champion of the R community & ecosystem.

On Thu, Apr 14, 2016 at 8:33 AM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> Has anyone ever heard of or used Microsoft R server? Does the product work? What are requirements for running it? How much does it cost and is it supported by the R community?
> Thank you,
> John
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:8}}


From leandromarino at leandromarino.com.br  Thu Apr 14 14:55:45 2016
From: leandromarino at leandromarino.com.br (Leandro Marino)
Date: Thu, 14 Apr 2016 09:55:45 -0300
Subject: [R] Microsoft R Server
In-Reply-To: <570F55FB020000CB001509F2@smtp.medicine.umaryland.edu>
References: <CAMwU6B0BVzYYY5sxe2GCdg8XF1=NcQjHOtni5Nq+hKZpfDMthQ@mail.gmail.com>
	<570F4CEB.7060208@auckland.ac.nz>
	<570F55FB020000CB001509F2@smtp.medicine.umaryland.edu>
Message-ID: <CAKSaaF=CMQsq0aDGZVoPRLP_j3=8NXygKwsvSd4AC1hOJjpbgg@mail.gmail.com>

John,

as I know Microsoft has owned the Revolution Analytics and is continuing
the development of the Revolurion R with a new name Microsoft R. Note that
Microsoft R has an open source stable version. I'm not quite sure which
modifications they are doing on it. I suppose that this modified version of
R is the one they are putting in their servers.

As I could search few weeks ago they inform us that all R packages works
with their version.

Best
Leandro

2016-04-14 9:33 GMT-03:00 John Sorkin <jsorkin at grecc.umaryland.edu>:

> Has anyone ever heard of or used Microsoft R server? Does the product
> work? What are requirements for running it? How much does it cost and is it
> supported by the R community?
> Thank you,
> John
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:13}}


From kipkorirfranklin78 at gmail.com  Thu Apr 14 12:39:50 2016
From: kipkorirfranklin78 at gmail.com (kipkorirfranklin78 at gmail.com)
Date: Thu, 14 Apr 2016 13:39:50 +0300
Subject: [R] New member
Message-ID: <82pkss1hklbcbm2evyjt8fga.1460630390729@email.android.com>


Hello. I am Franklin from University of Eldoret. I really want to study the R package. What should I first of all do?
	[[alternative HTML version deleted]]


From olebrudvik at gmail.com  Thu Apr 14 09:47:11 2016
From: olebrudvik at gmail.com (Ole C. Brudvik)
Date: Thu, 14 Apr 2016 09:47:11 +0200
Subject: [R] Error messages when start first time R: "You're using a
	non-UTF8 locale, therefore only ASCII characters will work."
Message-ID: <727B337D-3EE1-4FCE-B942-015109D9BEBB@gmail.com>

Hi!
I just started this course and just installed R and RStudio but I got this warning/error messages when I open R and RStudio:

During startup - Warning messages:

1: Setting LC_CTYPE failed, using "C"

2: Setting LC_COLLATE failed, using "C"

3: Setting LC_TIME failed, using "C"

4: Setting LC_MESSAGES failed, using "C"

5: Setting LC_MONETARY failed, using "C"

[R.app GUI 1.67 (7152) x86_64-apple-darwin13.4.0]

WARNING: You're using a non-UTF8 locale, therefore only ASCII characters will work.

Please read R for Mac OS X FAQ (see Help) section 9 and adjust your system preferences accordingly.

Section 9 is just Acknowledgements so I cant find the help the software refer to.

Please, can anyone help me with this? It seems important to get this fixed before I do work with RStudio.

Thanks a lot! Appreciate very much any help.

Cheers

Ole
	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Apr 14 18:35:58 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 14 Apr 2016 11:35:58 -0500
Subject: [R] New member
In-Reply-To: <82pkss1hklbcbm2evyjt8fga.1460630390729@email.android.com>
References: <82pkss1hklbcbm2evyjt8fga.1460630390729@email.android.com>
Message-ID: <CAN5YmCFa9QvjnYyw4GNU6xBw1RdFWyM7pK=Shz2z+ekhHZ=+Ng@mail.gmail.com>

This is a good place to start ...
https://cran.r-project.org/doc/manuals/R-intro.pdf

Jean

On Thu, Apr 14, 2016 at 5:39 AM, kipkorirfranklin78 at gmail.com <
kipkorirfranklin78 at gmail.com> wrote:

>
> Hello. I am Franklin from University of Eldoret. I really want to study
> the R package. What should I first of all do?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Thu Apr 14 18:39:06 2016
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 14 Apr 2016 16:39:06 +0000
Subject: [R] R 3.2.5 is released
Message-ID: <CEF88BD0-E706-4711-932B-E9C2B537D86D@cbs.dk>

The 3.2.4-revised version turned out to give trouble for some of CRAN's subsystems.

Accordingly, a rebadged version 3.2.5 is now released; it only differs in the version number and a few clean-up items. If you have a working install of 3.2.4-revised there should be no reason to upgrade it.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.2.5.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

For the R Core Team,

Peter Dalgaard

New md5 sums are

MD5 (AUTHORS) = eb97a5cd38acb1cfc6408988bffef765
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = cd7bfa946b8650cb87807e94e46984c6
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 42d76ce7f8e80977d5043bca4234f4c9
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = e840d32b7ef7a7603455d30d6d54fda7
MD5 (R-latest.tar.gz) = 7b23ee70cfb383be3bd4360e3c71d8c3
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = ba00f6cc68a823e1741cfa6011f40ccb
MD5 (VERSION-INFO.dcf) = 661c20647b9f0b9fa980297c53438609
MD5 (R-3/R-3.2.5.tar.gz) = 7b23ee70cfb383be3bd4360e3c71d8c3


The relevant NEWS file entries (relative to 3.2.4) are

CHANGES IN R 3.2.5:

  BUG FIXES:

    ? format.POSIXlt() behaved incorrectly in R 3.2.4.  E.g. the output
      of format(as.POSIXlt(paste0(1940:2000,"-01-01"), tz = "CET"),
      usetz = TRUE) ended in two "CEST" time formats.

    ? A typo in the Makefile for src/extra/xz prevented builds of
      liblzma.a. (Notice that this will become unbundled in 3.3.0.)



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From bgunter.4567 at gmail.com  Thu Apr 14 18:48:16 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 14 Apr 2016 09:48:16 -0700
Subject: [R] Error messages when start first time R: "You're using a
 non-UTF8 locale, therefore only ASCII characters will work."
In-Reply-To: <727B337D-3EE1-4FCE-B942-015109D9BEBB@gmail.com>
References: <727B337D-3EE1-4FCE-B942-015109D9BEBB@gmail.com>
Message-ID: <CAGxFJbS+9kEOG1fxuiqCmLpmwbEM_hOwusv+qQ4zKM4Mxq9yRQ@mail.gmail.com>

1. These are warnings, not error. So you could just ignore them and proceed.

2. However, you may wish to go to the tools -->General menu in RStudio
and set the default text encoding to UTF-8. I think that will get rid
of the warnings.

Happy R-ing. Please make use of R's docs and web resources (especially
tutorials) before posting on this list, as most questions you might
have should be quickly answerable from them.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 14, 2016 at 12:47 AM, Ole C. Brudvik <olebrudvik at gmail.com> wrote:
> Hi!
> I just started this course and just installed R and RStudio but I got this warning/error messages when I open R and RStudio:
>
> During startup - Warning messages:
>
> 1: Setting LC_CTYPE failed, using "C"
>
> 2: Setting LC_COLLATE failed, using "C"
>
> 3: Setting LC_TIME failed, using "C"
>
> 4: Setting LC_MESSAGES failed, using "C"
>
> 5: Setting LC_MONETARY failed, using "C"
>
> [R.app GUI 1.67 (7152) x86_64-apple-darwin13.4.0]
>
> WARNING: You're using a non-UTF8 locale, therefore only ASCII characters will work.
>
> Please read R for Mac OS X FAQ (see Help) section 9 and adjust your system preferences accordingly.
>
> Section 9 is just Acknowledgements so I cant find the help the software refer to.
>
> Please, can anyone help me with this? It seems important to get this fixed before I do work with RStudio.
>
> Thanks a lot! Appreciate very much any help.
>
> Cheers
>
> Ole
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Apr 14 18:49:20 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 14 Apr 2016 18:49:20 +0200
Subject: [R] Error messages when start first time R: "You're using a
	non-UTF8 locale, therefore only ASCII characters will work."
In-Reply-To: <727B337D-3EE1-4FCE-B942-015109D9BEBB@gmail.com>
References: <727B337D-3EE1-4FCE-B942-015109D9BEBB@gmail.com>
Message-ID: <2F16F28F-C1DF-4D36-A0AB-1B2A7E206E46@gmail.com>


On 14 Apr 2016, at 09:47 , Ole C. Brudvik <olebrudvik at gmail.com> wrote:

> Hi!
> I just started this course and just installed R and RStudio but I got this warning/error messages when I open R and RStudio:
> 

This is not a help list for any course...

However, that particular issue is just that the FAQ was edited and it ws forgotten to update the warning message. The instructions are in Sec.7 now.

-pd

> During startup - Warning messages:
> 
> 1: Setting LC_CTYPE failed, using "C"
> 
> 2: Setting LC_COLLATE failed, using "C"
> 
> 3: Setting LC_TIME failed, using "C"
> 
> 4: Setting LC_MESSAGES failed, using "C"
> 
> 5: Setting LC_MONETARY failed, using "C"
> 
> [R.app GUI 1.67 (7152) x86_64-apple-darwin13.4.0]
> 
> WARNING: You're using a non-UTF8 locale, therefore only ASCII characters will work.
> 
> Please read R for Mac OS X FAQ (see Help) section 9 and adjust your system preferences accordingly.
> 
> Section 9 is just Acknowledgements so I cant find the help the software refer to.
> 
> Please, can anyone help me with this? It seems important to get this fixed before I do work with RStudio.
> 
> Thanks a lot! Appreciate very much any help.
> 
> Cheers
> 
> Ole
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dusa.adrian at unibuc.ro  Thu Apr 14 19:00:39 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Thu, 14 Apr 2016 20:00:39 +0300
Subject: [R] formula argument evaluation
In-Reply-To: <CAF8bMcYZksHEzSAZ9_HiRywC+NYw0f_qnPJz8JvP0VZNAz=rYA@mail.gmail.com>
References: <CAJ=0CtB31AK2Ot7Z5753EB-M55LZNtMhoEA2dTAzd0P9ngB+aw@mail.gmail.com>
	<570CD71E.4040107@gmail.com>
	<CAJ=0CtBRNHsa=8hrULR3aK8V0si4S+gmyZzhCYHs7iVVN56afw@mail.gmail.com>
	<CAGx1TMAruoQ5r+_f=F3x2f7D0LVd0LX+-muxbP4XcRar=g-V_w@mail.gmail.com>
	<CAJ=0CtCRfUqQ5Oa=bvbjRchiYGYQmVjYN0K95VOp16v_vKkwww@mail.gmail.com>
	<CAF8bMcYZksHEzSAZ9_HiRywC+NYw0f_qnPJz8JvP0VZNAz=rYA@mail.gmail.com>
Message-ID: <CAJ=0CtBXBYR4vKhzjibsLzqR532MDn-wOF0aZKnUNg6=zx4xiw@mail.gmail.com>

Thanks Bill, it's very useful to know how parsing and evaluation works.
It seems that quoting is the least complicated solution which is guaranteed
to work.

Best,
Adrian
On 13 Apr 2016 6:04 p.m., "William Dunlap" <wdunlap at tibco.com> wrote:

> %=>% would have precendence ('order of operations') problems also.
>
>    A + B %=>% C
>
> is equivalent to
>
>   A + ( B %=>% C)
>
> and I don't think that is what you want.
>
> as.list(quote(A + B %=>% C)) shows the first branch in the parse tree.
> The following function, str.language, shows the entire parse tree, as in
>
>   > str.language(quote(A + B %=>% C))
>   `quote(A + B %=>% C)` call(3): A + B %=>% C
>     `` name(1): +
>     `` name(1): A
>     `` call(3): B %=>% C
>       `` name(1): %=>%
>       `` name(1): B
>       `` name(1): C
>
> str.language <-
> function (object, ..., level = 0, name = myDeparse(substitute(object)))
> {
>     abbr <- function(string, maxlen = 25) {
>         if (length(string) > 1 || nchar(string) > maxlen)
>             paste(substring(string[1], 1, maxlen), "...", sep = "")
>         else string
>     }
>     myDeparse <- function(object) {
>         if (!is.environment(object)) {
>             deparse(object)
>         }
>         else {
>             ename <- environmentName(object)
>             if (ename == "")
>                 ename <- "<unnamed env>"
>             paste(sep = "", "<", ename, "> ", paste(collapse = " ",
>                 objects(object)))
>         }
>     }
>     cat(rep("  ", level), sep = "")
>     if (is.null(name))
>         name <- ""
>     cat(sprintf("`%s` %s(%d): %s\n", abbr(name), class(object),
>         length(object), abbr(myDeparse(object))))
>     a <- attributes(object)
>     if (is.recursive(object) && !is.environment(object)) {
>         object <- as.list(object)
>         names <- names(object)
>         for (i in seq_along(object)) {
>             str.language(object[[i]], ..., level = level + 1,
>                 name = names[i])
>         }
>     }
>     a$names <- NULL
>     if (length(a) > 0) {
>         str.language(a, level = level + 1, name = paste("Attributes of",
>             abbr(name)))
>     }
> }
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Apr 12, 2016 at 11:59 PM, Adrian Du?a <dusa.adrian at unibuc.ro>
> wrote:
>
>> I suppose it would work, although "=>" is rather a descriptive symbol and
>> less a function.
>> But choosing between quoting:
>> "A + B => C"
>> and a regular function:
>> A + B %=>% C
>> probably quoting is the most straightforward, as the result of the foo()
>> function has to be a string anyways (which is parsed by other functions).
>>
>> On Tue, Apr 12, 2016 at 6:20 PM, Richard M. Heiberger <rmh at temple.edu>
>> wrote:
>>
>> > Would making it regular function %=>%, using "%" instead of quotes,
>> > work for you?
>> >
>> > On Tue, Apr 12, 2016 at 11:09 AM, Adrian Du?a <dusa.adrian at unibuc.ro>
>> > wrote:
>> > > On Tue, Apr 12, 2016 at 2:08 PM, Duncan Murdoch <
>> > murdoch.duncan at gmail.com>
>> > > wrote:
>> > >> [...]
>> > >>
>> > >> It never gets to evaluating it.  It is not a legal R statement, so
>> the
>> > > parser signals an error.
>> > >> If you want to pass arbitrary strings to a function, you need to put
>> > them
>> > > in quotes.
>> > >
>> > > I see. I thought it was parsed inside the function, but if it's parsed
>> > > before then quoting is the only option.
>> > >
>> > >
>> > > To Keith: no, I mean it like this "A + B => C" which is translated as:
>> > > "the union of A and B is sufficient for C" in set theoretic language.
>> > >
>> > > The "=>" operator means sufficiency, while "<=" means necessity.
>> Quoting
>> > > the expression is good enough, I was just curious if the quotes could
>> be
>> > > made redundant, somehow.
>> > >
>> > > Thank you both,
>> > > Adrian
>> > >
>> > > --
>> > > Adrian Dusa
>> > > University of Bucharest
>> > > Romanian Social Data Archive
>> > > Soseaua Panduri nr.90
>> > > 050663 Bucharest sector 5
>> > > Romania
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>>
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From rosita21 at gmail.com  Thu Apr 14 20:07:04 2016
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Thu, 14 Apr 2016 19:07:04 +0100
Subject: [R] Odds Ratio and OR CI
In-Reply-To: <CEF88BD0-E706-4711-932B-E9C2B537D86D@cbs.dk>
References: <CEF88BD0-E706-4711-932B-E9C2B537D86D@cbs.dk>
Message-ID: <E58B7D3B-C978-4D32-B1E8-A3C790DCB4CE@gmail.com>

Howdy everyone



I?m trying to get Odds ratio and OR confidence intervals using a probit model, but I'm not getting.

 

Do you think you can help me?

 

I?m new with R L

 

naive                   = summary(glm(pcr.data[,7]~boldBeta_individual+pcr.data$age,family=binomial(link=probit)))

naive_answer            = c(naive$coefficients[,1:3])                           #naive estimates for

                                                                                #alpha (first 4 collumns: intercept; beta_intercept, beta_slope and age) and

                                                                                #and SE(last 4 collumns: intercept; beta_intercept, beta_slope and age)

 

OR.naive = exp(1.6*coef(naive))

 

(till here works, the problem is with the confidence interval)

 

I tried to get the Standard error from the variance, but I?m not sure if this can be done as I?ve done.

 

 

Var_coef <- 1.6^2*var(coef(naive))

SE_coef <- Var_coef/sqrt(nsample)                    ########## I thi k this is correct

 

OR.naive.inf <- exp(OR.naive - (1.96 * SE_coef))

OR.naive.sup <- exp(OR.naive + (1.96 * SE_coef))

 

if I used logit link I would get the CI with confint(na?ve) command, but with probit I don't think so. Is there a way?

 

What should I do?

 

 

 


Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________



Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates


From rosita21 at gmail.com  Thu Apr 14 20:11:36 2016
From: rosita21 at gmail.com (Rosa Oliveira)
Date: Thu, 14 Apr 2016 19:11:36 +0100
Subject: [R] help with OR confidence interval using probit link
Message-ID: <953019CF-2D00-4198-A091-CEC32041C7F6@gmail.com>

Howdy everyone



I?m trying to get Odds ratio and OR confidence intervals using a probit model, but I'm not getting.

 
Do you think you can help me?

 
I?m new with R L

 
naive                   = summary(glm(pcr.data[,7]~boldBeta_individual+pcr.data$age,family=binomial(link=probit)))

naive_answer            = c(naive$coefficients[,1:3])                           #naive estimates for

                                                                                #alpha (first 4 collumns: intercept; beta_intercept, beta_slope and age) and 

                                                                                #and SE(last 4 collumns: intercept; beta_intercept, beta_slope and age)

 
OR.naive = exp(1.6*coef(naive))

 
(till here works, the problem is with the confidence interval)

 
I tried to get the Standard error from the variance, but I?m not sure if this can be done as I?ve done.

 
 
Var_coef <- 1.6^2*var(coef(naive))

SE_coef <- Var_coef/sqrt(nsample)                    ########## I thi k this is correct

 
OR.naive.inf <- exp(OR.naive - (1.96 * SE_coef))

OR.naive.sup <- exp(OR.naive + (1.96 * SE_coef))

 
if I used logit link I would get the CI with confint(na?ve) command, but with probit I don't think so. Is there a way?

 
What should I do?



Atenciosamente,
Rosa Oliveira

-- 
____________________________________________________________________________



Rosa Celeste dos Santos Oliveira, 

E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
Tlm: +351 939355143 
Linkedin: https://pt.linkedin.com/in/rosacsoliveira <https://pt.linkedin.com/in/rosacsoliveira>
____________________________________________________________________________
"Many admire, few know"
Hippocrates


From akhileshsingh.igkv at gmail.com  Thu Apr 14 22:14:53 2016
From: akhileshsingh.igkv at gmail.com (Akhilesh Singh)
Date: Fri, 15 Apr 2016 01:44:53 +0530
Subject: [R] Bug in by() function which works for some FUN argument and does
 not work for others
Message-ID: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>

Dear Sirs,

I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
Chhattisgarh, India.

While taking classes, I found the *by() *function producing following error
when I use FUN=mean or median and some other functions, however,
FUN=summary works.

Given below is the output of the example I used on a built-in dataset
"mtcars", along with error message reproduced herewith:

> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
: 0
[1] NA
------------------------------------------------------------
: 1
[1] NA
Warning messages:
1: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA
2: In mean.default(data[x, , drop = FALSE], ...) :
  argument is not numeric or logical: returning NA

However, the same by() function works for FUN=summary, given below is the
output:

> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
: 0
      mpg             cyl             disp             hp
 Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
 Median :17.30   Median :8.000   Median :275.8   Median :175.0
 Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
 Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
      drat             wt             qsec             vs               am

 Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.   :0

 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st Qu.:0

 Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median :0

 Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean   :0

 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd Qu.:0

 Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :0

      gear            carb
 Min.   :3.000   Min.   :1.000
 1st Qu.:3.000   1st Qu.:2.000
 Median :3.000   Median :3.000
 Mean   :3.211   Mean   :2.737
 3rd Qu.:3.000   3rd Qu.:4.000
 Max.   :4.000   Max.   :4.000
------------------------------------------------------------
: 1
      mpg             cyl             disp             hp             drat

 Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
:3.54
 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
Qu.:3.85
 Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
:4.08
 Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
:4.05
 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
Qu.:4.22
 Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
:4.93
       wt             qsec             vs               am         gear

 Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.   :4.000

 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st Qu.:4.000

 Median :2.320   Median :17.02   Median :1.0000   Median :1   Median :4.000

 Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean   :4.385

 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd Qu.:5.000

 Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.   :5.000

      carb
 Min.   :1.000
 1st Qu.:1.000
 Median :2.000
 Mean   :2.923
 3rd Qu.:4.000
 Max.   :8.000
>

I am using the latest version of *R-3.2.4 on Windows*, however, this error
is being generated in the previous version too,

Hope this reporting will get serious attention in debugging.

With best regards,

Dr. A.K. Singh
Head, Department of Agril. Statistics
Indira Gandhi Krishi Vishwavidyalaya, Raipur
Chhattisgarh, India, PIN-492012
Mobile: +919752620740
Email: akhileshsingh.igkv at gmail.com

	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Thu Apr 14 22:14:44 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Thu, 14 Apr 2016 20:14:44 +0000 (UTC)
Subject: [R] a replace for subset
References: <1505718437.1109430.1460664884050.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1505718437.1109430.1460664884050.JavaMail.yahoo@mail.yahoo.com>

Hi,I have a data set (mydata), which a part of this is like the following:??'data.frame': ? 36190 obs. of 16 variables:$ RE ? ? ? ? ? ? ? ? ? ?: int ?38 41 11 67 30 18 38 41 41 30 ...$ LU ? ? ? ? ? ? ? ? ? ? : int ?4200 3330 530 4500 3000 1790 4700 3400 3640 4000 ...$ COUNTRY ? ? ? ?: Factor w/ 4 levels "DE","FR","JP", "FR"?$Light ? ? ? ? ? ? ? ? ?: Factor w/2 levels ? "ON","OFF","ON", ?.$OR ? ? ? ? ? ? ? ? ? ? : Factor w/2 levels ? "S","T","S",?.$PAT ? ? ? ? ? ? ? ? ?: Factor w/3 levels ? "low", "high", "middle",?.??Now I want to plot RE vs LU with ggplot2 for all the possible cases, I know how to do subsetting for the data but I want to know is there any shorter way to do that? For example I want to have a plot for RE vs LU for (COUNTRY= FR, Light=off, OR=S, PAT=low) and one for (COUNTRY= FR, Light=on, OR=S, PAT=high) and ?., as you see doing subset is time consuming, is there any other way?Thank you for any help.Elahe
	[[alternative HTML version deleted]]


From yessile24 at gmail.com  Thu Apr 14 21:53:51 2016
From: yessile24 at gmail.com (Yessile)
Date: Thu, 14 Apr 2016 22:53:51 +0300
Subject: [R] DataControl and DCARContControl functions
Message-ID: <570ff54e.070d1c0a.e33e5.ffffdec9@mx.google.com>

Hello,
I have some trouble with DataControl and DCARContControl functions. I can use the following codes for multivariate normal distribution. 

sigma <- matrix(c(-1, 0, 0, 1), 2, 2)
?dc <- DataControl(size = 100, distribution = rmvnorm, dots = list(sigma = sigma))
?cc <- DCARContControl(epsilon = seq(0.05, 0.15, by = 0.05), distribution = rmvnorm,dots = list(mean = c(1, -1), sigma = sigma))


But, I want to use the same code for Multivariate Laplace and Multivariate Cauchy.  I have used to arrange the code for these two distributions but i didn?t succeed. 

I would be glad if you could help. 
Thank you from now?




	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Thu Apr 14 23:36:52 2016
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Fri, 15 Apr 2016 00:36:52 +0300
Subject: [R] Bug in by() function which works for some FUN argument and
 does not work for others
In-Reply-To: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
Message-ID: <CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>

I think you are not using the best function for what your intentions are.
Try:

> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
: 0
        mpg         cyl        disp          hp        drat          wt
   qsec          vs
 17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
 18.1831579   0.3684211
         am        gear        carb
  0.0000000   3.2105263   2.7368421
---------------------------------------------------------------------------
: 1
        mpg         cyl        disp          hp        drat          wt
   qsec          vs
 24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
 17.3600000   0.5384615
         am        gear        carb
  1.0000000   4.3846154   2.9230769

See the difference between colMeans() and mean() in their respective help
files.
Hth,
Adrian

On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
akhileshsingh.igkv at gmail.com> wrote:

> Dear Sirs,
>
> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
> Chhattisgarh, India.
>
> While taking classes, I found the *by() *function producing following error
> when I use FUN=mean or median and some other functions, however,
> FUN=summary works.
>
> Given below is the output of the example I used on a built-in dataset
> "mtcars", along with error message reproduced herewith:
>
> > by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
> : 0
> [1] NA
> ------------------------------------------------------------
> : 1
> [1] NA
> Warning messages:
> 1: In mean.default(data[x, , drop = FALSE], ...) :
>   argument is not numeric or logical: returning NA
> 2: In mean.default(data[x, , drop = FALSE], ...) :
>   argument is not numeric or logical: returning NA
>
> However, the same by() function works for FUN=summary, given below is the
> output:
>
> > by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
> : 0
>       mpg             cyl             disp             hp
>  Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
>  1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
>  Median :17.30   Median :8.000   Median :275.8   Median :175.0
>  Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
>  3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
>  Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
>       drat             wt             qsec             vs               am
>
>  Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.   :0
>
>  1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st Qu.:0
>
>  Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median :0
>
>  Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean   :0
>
>  3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd Qu.:0
>
>  Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :0
>
>       gear            carb
>  Min.   :3.000   Min.   :1.000
>  1st Qu.:3.000   1st Qu.:2.000
>  Median :3.000   Median :3.000
>  Mean   :3.211   Mean   :2.737
>  3rd Qu.:3.000   3rd Qu.:4.000
>  Max.   :4.000   Max.   :4.000
> ------------------------------------------------------------
> : 1
>       mpg             cyl             disp             hp             drat
>
>  Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
> :3.54
>  1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
> Qu.:3.85
>  Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
> :4.08
>  Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
> :4.05
>  3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
> Qu.:4.22
>  Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
> :4.93
>        wt             qsec             vs               am         gear
>
>  Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.   :4.000
>
>  1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st Qu.:4.000
>
>  Median :2.320   Median :17.02   Median :1.0000   Median :1   Median :4.000
>
>  Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean   :4.385
>
>  3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd Qu.:5.000
>
>  Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.   :5.000
>
>       carb
>  Min.   :1.000
>  1st Qu.:1.000
>  Median :2.000
>  Mean   :2.923
>  3rd Qu.:4.000
>  Max.   :8.000
> >
>
> I am using the latest version of *R-3.2.4 on Windows*, however, this error
> is being generated in the previous version too,
>
> Hope this reporting will get serious attention in debugging.
>
> With best regards,
>
> Dr. A.K. Singh
> Head, Department of Agril. Statistics
> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> Chhattisgarh, India, PIN-492012
> Mobile: +919752620740
> Email: akhileshsingh.igkv at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Apr 15 00:46:39 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 14 Apr 2016 15:46:39 -0700
Subject: [R] a replace for subset
In-Reply-To: <1505718437.1109430.1460664884050.JavaMail.yahoo@mail.yahoo.com>
References: <1505718437.1109430.1460664884050.JavaMail.yahoo.ref@mail.yahoo.com>
	<1505718437.1109430.1460664884050.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbRa8N+x-x_mZBV0HYQX7v5EDqR1yKUN1u1OLDNi21Fo6A@mail.gmail.com>

A mess!
Please follow the posting guide: post in *plain text*, not HTML.

Cheers.
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 14, 2016 at 1:14 PM, ch.elahe via R-help
<r-help at r-project.org> wrote:
> Hi,I have a data set (mydata), which a part of this is like the following:  'data.frame':   36190 obs. of 16 variables:$ RE                    : int  38 41 11 67 30 18 38 41 41 30 ...$ LU                     : int  4200 3330 530 4500 3000 1790 4700 3400 3640 4000 ...$ COUNTRY        : Factor w/ 4 levels "DE","FR","JP", "FR"?$Light                  : Factor w/2 levels   "ON","OFF","ON", ?.$OR                     : Factor w/2 levels   "S","T","S",?.$PAT                  : Factor w/3 levels   "low", "high", "middle",?.  Now I want to plot RE vs LU with ggplot2 for all the possible cases, I know how to do subsetting for the data but I want to know is there any shorter way to do that? For example I want to have a plot for RE vs LU for (COUNTRY= FR, Light=off, OR=S, PAT=low) and one for (COUNTRY= FR, Light=on, OR=S, PAT=high) and ?., as you see doing subset is time consuming, is there any other way?Thank you for any help.Elahe
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tom at vims.edu  Thu Apr 14 23:33:31 2016
From: tom at vims.edu (Tom Mosca)
Date: Thu, 14 Apr 2016 21:33:31 +0000
Subject: [R] Unequal column lengths
Message-ID: <CB5791F5EA3D82408B277900997482D27F7D3B49@mboxes2.campus.vims.edu>

Hello,

I?ve tried several times to learn R, but have never gotten past a particular gate.  My data are organized by column in Excel, with column headers in the first row.  The columns are of unequal lengths.  I export them as CSV, then import the CSV file into R.  I wish to summarize the data by column.  R inserts NA for missing values, then refuses to operate on columns with NA.  R is importing my data into a data frame, and I realize that is inappropriate for what I want to do.

How can I import my data so that I can work on columns of unequal length?  The first thing I would like to do is generate a table containing mean, median, mode, standard deviation, min, max and count, all per column.

Thank you, Tom

Example data
  Dat1 Dat2 Dat3
1    1    5    4
2    7    7    9
3    3    3    5
4    2   NA  5
5    9   NA NA

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Apr 15 00:45:33 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 14 Apr 2016 15:45:33 -0700
Subject: [R] Bug in by() function which works for some FUN argument and
 does not work for others
In-Reply-To: <CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
Message-ID: <CAGxFJbSfPHR-PaTkwo-ZYWfcgpg6MwQe2nJdPnzB3_PGOmY1pQ@mail.gmail.com>

You're right, but I think this fails to pinpoint the error. The
problem is that FUN's argument is  "applied to (usually data-frame)
subsets of data,"  and the OP has used FUN = mean, which takes a
vector (+ a few other classes), not a data frame, as argument. See
?mean

Morals:

1.  It is rather presumptuous to think that long used, well-tested,
core R functionality like by() have bugs; a (new?) user's first
thought should be to assume it is HIS error, not R's.


2. DO read the Help docs carefully. They are often terse, but usually
they mean what they (appear to) say.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 14, 2016 at 2:36 PM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> I think you are not using the best function for what your intentions are.
> Try:
>
>> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
> : 0
>         mpg         cyl        disp          hp        drat          wt
>    qsec          vs
>  17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
>  18.1831579   0.3684211
>          am        gear        carb
>   0.0000000   3.2105263   2.7368421
> ---------------------------------------------------------------------------
> : 1
>         mpg         cyl        disp          hp        drat          wt
>    qsec          vs
>  24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
>  17.3600000   0.5384615
>          am        gear        carb
>   1.0000000   4.3846154   2.9230769
>
> See the difference between colMeans() and mean() in their respective help
> files.
> Hth,
> Adrian
>
> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
> akhileshsingh.igkv at gmail.com> wrote:
>
>> Dear Sirs,
>>
>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
>> Chhattisgarh, India.
>>
>> While taking classes, I found the *by() *function producing following error
>> when I use FUN=mean or median and some other functions, however,
>> FUN=summary works.
>>
>> Given below is the output of the example I used on a built-in dataset
>> "mtcars", along with error message reproduced herewith:
>>
>> > by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
>> : 0
>> [1] NA
>> ------------------------------------------------------------
>> : 1
>> [1] NA
>> Warning messages:
>> 1: In mean.default(data[x, , drop = FALSE], ...) :
>>   argument is not numeric or logical: returning NA
>> 2: In mean.default(data[x, , drop = FALSE], ...) :
>>   argument is not numeric or logical: returning NA
>>
>> However, the same by() function works for FUN=summary, given below is the
>> output:
>>
>> > by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
>> : 0
>>       mpg             cyl             disp             hp
>>  Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
>>  1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
>>  Median :17.30   Median :8.000   Median :275.8   Median :175.0
>>  Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
>>  3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
>>  Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
>>       drat             wt             qsec             vs               am
>>
>>  Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.   :0
>>
>>  1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st Qu.:0
>>
>>  Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median :0
>>
>>  Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean   :0
>>
>>  3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd Qu.:0
>>
>>  Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :0
>>
>>       gear            carb
>>  Min.   :3.000   Min.   :1.000
>>  1st Qu.:3.000   1st Qu.:2.000
>>  Median :3.000   Median :3.000
>>  Mean   :3.211   Mean   :2.737
>>  3rd Qu.:3.000   3rd Qu.:4.000
>>  Max.   :4.000   Max.   :4.000
>> ------------------------------------------------------------
>> : 1
>>       mpg             cyl             disp             hp             drat
>>
>>  Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
>> :3.54
>>  1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
>> Qu.:3.85
>>  Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
>> :4.08
>>  Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
>> :4.05
>>  3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
>> Qu.:4.22
>>  Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
>> :4.93
>>        wt             qsec             vs               am         gear
>>
>>  Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.   :4.000
>>
>>  1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st Qu.:4.000
>>
>>  Median :2.320   Median :17.02   Median :1.0000   Median :1   Median :4.000
>>
>>  Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean   :4.385
>>
>>  3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd Qu.:5.000
>>
>>  Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.   :5.000
>>
>>       carb
>>  Min.   :1.000
>>  1st Qu.:1.000
>>  Median :2.000
>>  Mean   :2.923
>>  3rd Qu.:4.000
>>  Max.   :8.000
>> >
>>
>> I am using the latest version of *R-3.2.4 on Windows*, however, this error
>> is being generated in the previous version too,
>>
>> Hope this reporting will get serious attention in debugging.
>>
>> With best regards,
>>
>> Dr. A.K. Singh
>> Head, Department of Agril. Statistics
>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
>> Chhattisgarh, India, PIN-492012
>> Mobile: +919752620740
>> Email: akhileshsingh.igkv at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Apr 15 01:08:28 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 15 Apr 2016 09:08:28 +1000
Subject: [R] Bug in by() function which works for some FUN argument and
 does not work for others
In-Reply-To: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
Message-ID: <CA+8X3fUwbPFKf7M8gtL6pFT9rwwKZ1LvvVD5=ObQYukdzm-=PQ@mail.gmail.com>

Hi Dr Singh,
The object mtcars is a data frame and the mean is not defined for a
data frame. If you try it on a component of the data frame for which
mean is defined:

 by(mtcars$mpg,mtcars$am,mean)
mtcars$am: 0
[1] 17.14737
------------------------------------------------------------
mtcars$am: 1
[1] 24.39231

Jim

On Fri, Apr 15, 2016 at 6:14 AM, Akhilesh Singh
<akhileshsingh.igkv at gmail.com> wrote:
> Dear Sirs,
>
> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
> Chhattisgarh, India.
>
> While taking classes, I found the *by() *function producing following error
> when I use FUN=mean or median and some other functions, however,
> FUN=summary works.
>
> Given below is the output of the example I used on a built-in dataset
> "mtcars", along with error message reproduced herewith:
>
>> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
> : 0
> [1] NA
> ------------------------------------------------------------
> : 1
> [1] NA
> Warning messages:
> 1: In mean.default(data[x, , drop = FALSE], ...) :
>   argument is not numeric or logical: returning NA
> 2: In mean.default(data[x, , drop = FALSE], ...) :
>   argument is not numeric or logical: returning NA
>
> However, the same by() function works for FUN=summary, given below is the
> output:
>
>> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
> : 0
>       mpg             cyl             disp             hp
>  Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
>  1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
>  Median :17.30   Median :8.000   Median :275.8   Median :175.0
>  Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
>  3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
>  Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
>       drat             wt             qsec             vs               am
>
>  Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.   :0
>
>  1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st Qu.:0
>
>  Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median :0
>
>  Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean   :0
>
>  3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd Qu.:0
>
>  Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.   :0
>
>       gear            carb
>  Min.   :3.000   Min.   :1.000
>  1st Qu.:3.000   1st Qu.:2.000
>  Median :3.000   Median :3.000
>  Mean   :3.211   Mean   :2.737
>  3rd Qu.:3.000   3rd Qu.:4.000
>  Max.   :4.000   Max.   :4.000
> ------------------------------------------------------------
> : 1
>       mpg             cyl             disp             hp             drat
>
>  Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
> :3.54
>  1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
> Qu.:3.85
>  Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
> :4.08
>  Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
> :4.05
>  3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
> Qu.:4.22
>  Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
> :4.93
>        wt             qsec             vs               am         gear
>
>  Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.   :4.000
>
>  1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st Qu.:4.000
>
>  Median :2.320   Median :17.02   Median :1.0000   Median :1   Median :4.000
>
>  Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean   :4.385
>
>  3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd Qu.:5.000
>
>  Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.   :5.000
>
>       carb
>  Min.   :1.000
>  1st Qu.:1.000
>  Median :2.000
>  Mean   :2.923
>  3rd Qu.:4.000
>  Max.   :8.000
>>
>
> I am using the latest version of *R-3.2.4 on Windows*, however, this error
> is being generated in the previous version too,
>
> Hope this reporting will get serious attention in debugging.
>
> With best regards,
>
> Dr. A.K. Singh
> Head, Department of Agril. Statistics
> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> Chhattisgarh, India, PIN-492012
> Mobile: +919752620740
> Email: akhileshsingh.igkv at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Apr 15 02:31:29 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 Apr 2016 17:31:29 -0700
Subject: [R] Unequal column lengths
In-Reply-To: <CB5791F5EA3D82408B277900997482D27F7D3B49@mboxes2.campus.vims.edu>
References: <CB5791F5EA3D82408B277900997482D27F7D3B49@mboxes2.campus.vims.edu>
Message-ID: <064CC1D8-E45D-4DDD-BEFC-FEA41B72D713@comcast.net>


> On Apr 14, 2016, at 2:33 PM, Tom Mosca <tom at vims.edu> wrote:
> 
> Hello,
> 
> I?ve tried several times to learn R, but have never gotten past a particular gate.  My data are organized by column in Excel, with column headers in the first row.  The columns are of unequal lengths.  I export them as CSV, then import the CSV file into R.  I wish to summarize the data by column.  R inserts NA for missing values, then refuses to operate on columns with NA.  R is importing my data into a data frame, and I realize that is inappropriate for what I want to do.
> 
> How can I import my data so that I can work on columns of unequal length?  The first thing I would like to do is generate a table containing mean, median, mode, standard deviation, min, max and count, all per column.
> 

Most of the summary statistic functions have an na.rm options that you should set to TRUE.


> Thank you, Tom
> 
> Example data
>  Dat1 Dat2 Dat3
> 1    1    5    4
> 2    7    7    9
> 3    3    3    5
> 4    2   NA  5
> 5    9   NA NA

Looks like you have an R dataframe already, so I would try(

colMeans(data, na.rm=TRUE)


> 
> 	[[alternative HTML version deleted]]

And do learn to configure your email client to post to r-help in plain text.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Fri Apr 15 02:41:15 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 15 Apr 2016 10:41:15 +1000
Subject: [R] Unequal column lengths
In-Reply-To: <CB5791F5EA3D82408B277900997482D27F7D3B49@mboxes2.campus.vims.edu>
References: <CB5791F5EA3D82408B277900997482D27F7D3B49@mboxes2.campus.vims.edu>
Message-ID: <CA+8X3fUV+Q9JoEjgt0cPmsncn6Tuj=-mJ0i_ZZBJR4v0aPLKdw@mail.gmail.com>

Hi Tom,
What you want is a list rather than a data frame. So:

df<-read.table(text="  Dat1 Dat2 Dat3
 1    1    5    4
 2    7    7    9
 3    3    3    5
 4    2   NA  5
 5    9   NA NA",
 header=TRUE)
dflist<-as.list(df)
na.remove<-function(x) return(x[!is.na(x)])
sapply(dflist,na.remove)

Jim

On Fri, Apr 15, 2016 at 7:33 AM, Tom Mosca <tom at vims.edu> wrote:
> Hello,
>
> I?ve tried several times to learn R, but have never gotten past a particular gate.  My data are organized by column in Excel, with column headers in the first row.  The columns are of unequal lengths.  I export them as CSV, then import the CSV file into R.  I wish to summarize the data by column.  R inserts NA for missing values, then refuses to operate on columns with NA.  R is importing my data into a data frame, and I realize that is inappropriate for what I want to do.
>
> How can I import my data so that I can work on columns of unequal length?  The first thing I would like to do is generate a table containing mean, median, mode, standard deviation, min, max and count, all per column.
>
> Thank you, Tom
>
> Example data
>   Dat1 Dat2 Dat3
> 1    1    5    4
> 2    7    7    9
> 3    3    3    5
> 4    2   NA  5
> 5    9   NA NA
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amina at maths.otago.ac.nz  Fri Apr 15 03:52:47 2016
From: amina at maths.otago.ac.nz (amina)
Date: Fri, 15 Apr 2016 13:52:47 +1200
Subject: [R] nlm() giving initials as estimates of parameters
Message-ID: <d45c89dfd14a0106b7376de1b9913119@maths.otago.ac.nz>

Hi R community

I have written a loglikelihood function which I am minimizing using 
nlm().
nlm() is giving me no results...I mean, I am getting initial values as 
estimates. No iteration.
I have tried many initials value close to true values and far away from 
tru values. But every time I
am getting initial values as estimates and no iteration. Anybody can 
guide why this happens.

Thank You


From jdnewmil at dcn.davis.ca.us  Fri Apr 15 08:49:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 14 Apr 2016 23:49:02 -0700
Subject: [R] nlm() giving initials as estimates of parameters
In-Reply-To: <d45c89dfd14a0106b7376de1b9913119@maths.otago.ac.nz>
References: <d45c89dfd14a0106b7376de1b9913119@maths.otago.ac.nz>
Message-ID: <36C10AD7-60E4-4B45-B204-6BAB89761141@dcn.davis.ca.us>

Unlikely that someone will be interested in guessing. You are much more likely to get a constructive response if you provide the minimal reproducible example requested in the footer.

Of course, it is possible that you just might find the answer if you carefully read the help page for nlm, since I don't think it matches your description of your problem. 
-- 
Sent from my phone. Please excuse my brevity.

On April 14, 2016 6:52:47 PM PDT, amina <amina at maths.otago.ac.nz> wrote:
>Hi R community
>
>I have written a loglikelihood function which I am minimizing using 
>nlm().
>nlm() is giving me no results...I mean, I am getting initial values as 
>estimates. No iteration.
>I have tried many initials value close to true values and far away from
>
>tru values. But every time I
>am getting initial values as estimates and no iteration. Anybody can 
>guide why this happens.
>
>Thank You
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From akhileshsingh.igkv at gmail.com  Fri Apr 15 10:16:54 2016
From: akhileshsingh.igkv at gmail.com (Akhilesh Singh)
Date: Fri, 15 Apr 2016 13:46:54 +0530
Subject: [R] Bug in by() function which works for some FUN argument and
 does not work for others
In-Reply-To: <CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
Message-ID: <CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>

Dear All,

Thanks for your help. However, I would like to draw your attention to the
following:

Actually, I was replicating the Example 2.3, using the dataset
"brainsize.txt" given in Section 2.3.3 ("Summarize by group") at page 55,
of a famous book "R by Example" written by "Jim Albert and Maria Rizzo"
published in Springers (2012) in a Use R! Series. The output of the by()
function printed in the book is being reproduced below for information to
all:

> by(data=brain[, -1], INDICES=brain$Gender, FUN=mean, na.rm=TRUE)
brain$Gender: Female
FSIQ VIQ PIQ Weight Height MRI_Count
111.900 109.450 110.450 137.200 65.765 862654.600
------------------------------------------------------------
brain$Gender: Male
FSIQ  VIQ    PIQ       Weight    Height   MRI_Count
115.00000 115.25000 111.60000 166.44444 71.43158 954855.40000


I do not know how could the writers of the book have produced the above
results by by() function. But, when I could not reproduce these results,
then I thought that probably, this could possibly be due to some missing
values NA's in Weight and Height variables. Then I tried the above code for
the "mtcars" dataset for INDICES=mtcars$am. When I found the same results
here too, then I reported the case in "r-help at R-project.org".

With best regards,

Dr. A.K. Singh
Head, Department of Agril. Statistics
Indira Gandhi Krishi Vishwavidyalaya, Raipur
Chhattisgarh, India, PIN-492012
Mobile: +919752620740
Email: akhileshsingh.igkv at gmail.com

On Fri, Apr 15, 2016 at 3:06 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:

> I think you are not using the best function for what your intentions are.
> Try:
>
> > by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
> : 0
>         mpg         cyl        disp          hp        drat          wt
>      qsec          vs
>  17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
>  18.1831579   0.3684211
>          am        gear        carb
>   0.0000000   3.2105263   2.7368421
>
> ---------------------------------------------------------------------------
> : 1
>         mpg         cyl        disp          hp        drat          wt
>      qsec          vs
>  24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
>  17.3600000   0.5384615
>          am        gear        carb
>   1.0000000   4.3846154   2.9230769
>
> See the difference between colMeans() and mean() in their respective help
> files.
> Hth,
> Adrian
>
> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
> akhileshsingh.igkv at gmail.com> wrote:
>
>> Dear Sirs,
>>
>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
>> Chhattisgarh, India.
>>
>> While taking classes, I found the *by() *function producing following
>> error
>>
>> when I use FUN=mean or median and some other functions, however,
>> FUN=summary works.
>>
>> Given below is the output of the example I used on a built-in dataset
>> "mtcars", along with error message reproduced herewith:
>>
>> > by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
>> : 0
>> [1] NA
>> ------------------------------------------------------------
>> : 1
>> [1] NA
>> Warning messages:
>> 1: In mean.default(data[x, , drop = FALSE], ...) :
>>   argument is not numeric or logical: returning NA
>> 2: In mean.default(data[x, , drop = FALSE], ...) :
>>   argument is not numeric or logical: returning NA
>>
>> However, the same by() function works for FUN=summary, given below is the
>> output:
>>
>> > by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
>> : 0
>>       mpg             cyl             disp             hp
>>  Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
>>  1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
>>  Median :17.30   Median :8.000   Median :275.8   Median :175.0
>>  Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
>>  3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
>>  Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
>>       drat             wt             qsec             vs               am
>>
>>  Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.
>>  :0
>>
>>  1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st
>> Qu.:0
>>
>>  Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median
>> :0
>>
>>  Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean
>>  :0
>>
>>  3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd
>> Qu.:0
>>
>>  Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.
>>  :0
>>
>>       gear            carb
>>  Min.   :3.000   Min.   :1.000
>>  1st Qu.:3.000   1st Qu.:2.000
>>  Median :3.000   Median :3.000
>>  Mean   :3.211   Mean   :2.737
>>  3rd Qu.:3.000   3rd Qu.:4.000
>>  Max.   :4.000   Max.   :4.000
>> ------------------------------------------------------------
>> : 1
>>       mpg             cyl             disp             hp             drat
>>
>>  Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
>> :3.54
>>  1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
>> Qu.:3.85
>>  Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
>> :4.08
>>  Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
>> :4.05
>>  3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
>> Qu.:4.22
>>  Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
>> :4.93
>>        wt             qsec             vs               am         gear
>>
>>  Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.
>>  :4.000
>>
>>  1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st
>> Qu.:4.000
>>
>>  Median :2.320   Median :17.02   Median :1.0000   Median :1   Median
>> :4.000
>>
>>  Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean
>>  :4.385
>>
>>  3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd
>> Qu.:5.000
>>
>>  Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.
>>  :5.000
>>
>>       carb
>>  Min.   :1.000
>>  1st Qu.:1.000
>>  Median :2.000
>>  Mean   :2.923
>>  3rd Qu.:4.000
>>  Max.   :8.000
>> >
>>
>> I am using the latest version of *R-3.2.4 on Windows*, however, this error
>> is being generated in the previous version too,
>>
>> Hope this reporting will get serious attention in debugging.
>>
>> With best regards,
>>
>> Dr. A.K. Singh
>> Head, Department of Agril. Statistics
>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
>> Chhattisgarh, India, PIN-492012
>> Mobile: +919752620740
>> Email: akhileshsingh.igkv at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Adrian Dusa
> University of Bucharest
> Romanian Social Data Archive
> Soseaua Panduri nr.90
> 050663 Bucharest sector 5
> Romania
>

	[[alternative HTML version deleted]]


From s.lai at u.nus.edu  Fri Apr 15 07:49:12 2016
From: s.lai at u.nus.edu (Lai Wen Ya Samantha)
Date: Fri, 15 Apr 2016 05:49:12 +0000
Subject: [R] Heteroscedasticity in a percent-cover dataset
In-Reply-To: <1460691377486-4719735.post@n4.nabble.com>
References: <1460691377486-4719735.post@n4.nabble.com>
Message-ID: <HK2PR06MB0995B160999B2284A6FAF68FAA680@HK2PR06MB0995.apcprd06.prod.outlook.com>



Hi,

I am currently trying to do a GLMM on a dataset with percent cover of
seagrass (dep. var) and a suite of explanatory variables including algal
(AC) and epiphyte cover (EC), rainfall, temperature and sunshine hours.

M2=glmer(SG~AC+EC+TP+SS+RF+(1|Location/fSi/fTr),
family=binomial,data=data,nAGQ=1)

As the dependent variable is percent cover, I used a binomial error
structure. I also have a random effect due to nested of the data collection
strategy. However, I keep getting heteroscedasticity issues as shown in the
image below. I have tried using an arcsine transformation (with a lme), but
the scatter of residuals are still very much similar.

What else can I do to try to resolve the heteroscedasticity in my data? Any
help will be very much appreciated!


<http://r.789695.n4.nabble.com/file/n4719735/Heteroscedasticity.png>




[http://r.789695.n4.nabble.com/file/n4719735/Heteroscedasticity.png]

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Apr 15 10:54:29 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Apr 2016 01:54:29 -0700
Subject: [R] Bug in by() function which works for some FUN argument and
	does not work for others
In-Reply-To: <CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
	<CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
Message-ID: <49C85E5A-AAB2-47BB-AEC4-41ECDC069180@comcast.net>


> On Apr 15, 2016, at 1:16 AM, Akhilesh Singh <akhileshsingh.igkv at gmail.com> wrote:
> 
> Dear All,
> 
> Thanks for your help. However, I would like to draw your attention to the
> following:
> 
> Actually, I was replicating the Example 2.3, using the dataset
> "brainsize.txt" given in Section 2.3.3 ("Summarize by group") at page 55,
> of a famous book "R by Example" written by "Jim Albert and Maria Rizzo"
> published in Springers (2012) in a Use R! Series. The output of the by()
> function printed in the book is being reproduced below for information to
> all:
> 
>> by(data=brain[, -1], INDICES=brain$Gender, FUN=mean, na.rm=TRUE)
> brain$Gender: Female
> FSIQ VIQ PIQ Weight Height MRI_Count
> 111.900 109.450 110.450 137.200 65.765 862654.600
> ------------------------------------------------------------
> brain$Gender: Male
> FSIQ  VIQ    PIQ       Weight    Height   MRI_Count
> 115.00000 115.25000 111.60000 166.44444 71.43158 954855.40000
> 
> 
> I do not know how could the writers of the book have produced the above
> results by by() function.


There was in the not-so-distant past a function named `mean.data.frame` which would have "worked" in that instance. That function was removed. I thought you could  find the exact date of that action by searching the NEWS but failed. Reviewing the citations of `mean.data.frame` in the r-help archives I see that users were being warned that its use was deprecated in mid 2012.  It's very possible that the authors of a book in 2012 were using an earlier version of R that had that facility available to them before it was deprecated. With a more than current version of R 3.3.0 and a modest number of loaded packages I see this:

> methods(mean)
 [1] mean,ANY-method          mean,Matrix-method       mean,Raster-method      
 [4] mean,sparseMatrix-method mean,sparseVector-method mean.Date               
 [7] mean.default             mean.difftime            mean.POSIXct            
[10] mean.POSIXlt             mean.yearmon*            mean.yearqtr*           
[13] mean.zoo*

It is your responsibility to determine whether any particular function in your version of R satisfies the language requirements at the time of your use. Jim Albert and Maria Rizzo do not set the standards for what is an evolving piece of software.

-- 
David.


> But, when I could not reproduce these results,
> then I thought that probably, this could possibly be due to some missing
> values NA's in Weight and Height variables. Then I tried the above code for
> the "mtcars" dataset for INDICES=mtcars$am. When I found the same results
> here too, then I reported the case in "r-help at R-project.org".
> 
> With best regards,
> 
> Dr. A.K. Singh
> Head, Department of Agril. Statistics
> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> Chhattisgarh, India, PIN-492012
> Mobile: +919752620740
> Email: akhileshsingh.igkv at gmail.com
> 
> On Fri, Apr 15, 2016 at 3:06 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> 
>> I think you are not using the best function for what your intentions are.
>> Try:
>> 
>>> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
>> : 0
>>        mpg         cyl        disp          hp        drat          wt
>>     qsec          vs
>> 17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
>> 18.1831579   0.3684211
>>         am        gear        carb
>>  0.0000000   3.2105263   2.7368421
>> 
>> ---------------------------------------------------------------------------
>> : 1
>>        mpg         cyl        disp          hp        drat          wt
>>     qsec          vs
>> 24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
>> 17.3600000   0.5384615
>>         am        gear        carb
>>  1.0000000   4.3846154   2.9230769
>> 
>> See the difference between colMeans() and mean() in their respective help
>> files.
>> Hth,
>> Adrian
>> 
>> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
>> akhileshsingh.igkv at gmail.com> wrote:
>> 
>>> Dear Sirs,
>>> 
>>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
>>> Chhattisgarh, India.
>>> 
>>> While taking classes, I found the *by() *function producing following
>>> error
>>> 
>>> when I use FUN=mean or median and some other functions, however,
>>> FUN=summary works.
>>> 
>>> Given below is the output of the example I used on a built-in dataset
>>> "mtcars", along with error message reproduced herewith:
>>> 
>>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
>>> : 0
>>> [1] NA
>>> ------------------------------------------------------------
>>> : 1
>>> [1] NA
>>> Warning messages:
>>> 1: In mean.default(data[x, , drop = FALSE], ...) :
>>>  argument is not numeric or logical: returning NA
>>> 2: In mean.default(data[x, , drop = FALSE], ...) :
>>>  argument is not numeric or logical: returning NA
>>> 
>>> However, the same by() function works for FUN=summary, given below is the
>>> output:
>>> 
>>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
>>> : 0
>>>      mpg             cyl             disp             hp
>>> Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
>>> 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
>>> Median :17.30   Median :8.000   Median :275.8   Median :175.0
>>> Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
>>> 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
>>> Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
>>>      drat             wt             qsec             vs               am
>>> 
>>> Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.
>>> :0
>>> 
>>> 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st
>>> Qu.:0
>>> 
>>> Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median
>>> :0
>>> 
>>> Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean
>>> :0
>>> 
>>> 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd
>>> Qu.:0
>>> 
>>> Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.
>>> :0
>>> 
>>>      gear            carb
>>> Min.   :3.000   Min.   :1.000
>>> 1st Qu.:3.000   1st Qu.:2.000
>>> Median :3.000   Median :3.000
>>> Mean   :3.211   Mean   :2.737
>>> 3rd Qu.:3.000   3rd Qu.:4.000
>>> Max.   :4.000   Max.   :4.000
>>> ------------------------------------------------------------
>>> : 1
>>>      mpg             cyl             disp             hp             drat
>>> 
>>> Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
>>> :3.54
>>> 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
>>> Qu.:3.85
>>> Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
>>> :4.08
>>> Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
>>> :4.05
>>> 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
>>> Qu.:4.22
>>> Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
>>> :4.93
>>>       wt             qsec             vs               am         gear
>>> 
>>> Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.
>>> :4.000
>>> 
>>> 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st
>>> Qu.:4.000
>>> 
>>> Median :2.320   Median :17.02   Median :1.0000   Median :1   Median
>>> :4.000
>>> 
>>> Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean
>>> :4.385
>>> 
>>> 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd
>>> Qu.:5.000
>>> 
>>> Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.
>>> :5.000
>>> 
>>>      carb
>>> Min.   :1.000
>>> 1st Qu.:1.000
>>> Median :2.000
>>> Mean   :2.923
>>> 3rd Qu.:4.000
>>> Max.   :8.000
>>>> 
>>> 
>>> I am using the latest version of *R-3.2.4 on Windows*, however, this error
>>> is being generated in the previous version too,
>>> 
>>> Hope this reporting will get serious attention in debugging.
>>> 
>>> With best regards,
>>> 
>>> Dr. A.K. Singh
>>> Head, Department of Agril. Statistics
>>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
>>> Chhattisgarh, India, PIN-492012
>>> Mobile: +919752620740
>>> Email: akhileshsingh.igkv at gmail.com
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Fri Apr 15 13:00:18 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 15 Apr 2016 21:00:18 +1000
Subject: [R] a replace for subset
In-Reply-To: <CA+8X3fWN7QNp-0a_q1QMjV1xGTAxJqVnF5VioFcLs_=Pnocg_A@mail.gmail.com>
References: <1505718437.1109430.1460664884050.JavaMail.yahoo.ref@mail.yahoo.com>
	<1505718437.1109430.1460664884050.JavaMail.yahoo@mail.yahoo.com>
	<CA+8X3fWN7QNp-0a_q1QMjV1xGTAxJqVnF5VioFcLs_=Pnocg_A@mail.gmail.com>
Message-ID: <CA+8X3fXU1EaitSGV7zRchTw=Vhe7GFtos--2xCzkYDhTNXzG=w@mail.gmail.com>

Hi Elahe,
When you want to include a usable toy data frame, it's better to use
something like:

dput(mydata[1:100])

So if we have a data frame like this:

mydata<-data.frame(RE=sample(5:50,100,TRUE),
  LU=sample(1500:4500,100),
  COUNTRY=factor(sample(c("DE","FR","JP","AU"),100,TRUE)),
  Light=factor(sample(c("ON","OFF"),100,TRUE)),
  OR=factor(sample(c("S","T"),100,TRUE)),
  PAT=factor(sample(c("low","high","middle"),100,TRUE)))

Then you can create logical expressions for all combinations of your
levels like this:

subcomb<-expand.grid(list(levels(mydata$COUNTRY),
 levels(mydata$Light),levels(mydata$OR),levels(mydata$PAT)))

Then you can loop through this data frame creating a string that
corresponds to your logical expression:

for(subsetter in 1:dim(subcomb)[1]) {
 subexpr<-paste(names(mydata)[3:6],subcomb[subsetter,],
  sep="==",collapse="&")
 subset(mydata,do_something_to(subexpr),select=c("RE","LU"))
}

but I have not been able to work out how to transform the strings
"subexpr" into logical expressions. I feel pretty sure that someone
will show me up on this.

Jim


From betsy.mccoach at uconn.edu  Fri Apr 15 13:19:43 2016
From: betsy.mccoach at uconn.edu (Mccoach, D. Betsy)
Date: Fri, 15 Apr 2016 11:19:43 +0000
Subject: [R] 2016 Modern Modeling Methods Conference
Message-ID: <SN1PR0501MB1759C80054CCE3900C9436E3E6680@SN1PR0501MB1759.namprd05.prod.outlook.com>

The 6th annual Modern Modeling Methods Conference will be held on May 24-25, 2016 at the University of Connecticut.  This year's keynote speakers are Andrew Gelman and Bengt Muthen. May 23rd, Bengt Muthen is offering a full-day pre-conference workshop on Advances in Latent Variable Modeling in Mplus. May 26, Jeffrey R. Harring is offering a full-day post-conference workshop on Mixture Modeling for Correlated Data. Early bird registration for the conference ends next week.  For the lowest prices, register by April 22nd at 5:00pm. Please visit our website www.modeling.uconn.edu<http://www.modeling.uconn.edu> or email us at mmm at uconn.edu<mailto:mmm at uconn.edu> for more information.



	[[alternative HTML version deleted]]


From therneau at mayo.edu  Fri Apr 15 13:58:22 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 15 Apr 2016 06:58:22 -0500
Subject: [R] simple interactions
Message-ID: <519743$2rmv4f@ironport10.mayo.edu>

I'd like to get interaction terms in a model to be in another form.  Namely, suppose I had 
variables age and group, the latter a factor with levels A, B, C, with  age * group in the 
model.  What I would like are the variables "age:group=A", "age:group=B" and 
"age:group=C"  (and group itself of course).  The coefficients of the model will then be 
the age effect in group A, the age effect in group B and the age effect in C rather than 
the standard ones of an overall age effect followed by contrasts.  These is often a better 
format for tables in a publication.

Yes, I can reconstruct these from the original fit, but I have a lot of variables for 
several models and it would be easier to have an automatic form.  I suspect that there is 
an easy answer, but I don't see it.

Terry Therneau


From pdalgd at gmail.com  Fri Apr 15 11:02:55 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 15 Apr 2016 11:02:55 +0200
Subject: [R] Bug in by() function which works for some FUN argument and
	does not work for others
In-Reply-To: <CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
	<CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
Message-ID: <95A398B3-4A34-4689-B496-3528ACDE5136@gmail.com>

Books don't rewrite themselves retroactively....

NEWS for 3.0.0 has

   ? mean() for data frames and sd() for data frames and matrices are
      defunct.

and 3.0.0 was released April 3, 2013.

A book published in 2012 would likely be based on R 2.13.x or maybe even 2.12.x.

So mean(dataframe) worked in the past. It was changed because of inconsistencies, e.g. mean(as.matrix(dataframe)) is a single number, median.data.frame never existed, var(dataframe) differed from sd(dataframe)^2, etc. The deprecation/defunct process started with 2.14.0-pre in October 2011.

-pd 



On 15 Apr 2016, at 10:16 , Akhilesh Singh <akhileshsingh.igkv at gmail.com> wrote:

> Dear All,
> 
> Thanks for your help. However, I would like to draw your attention to the
> following:
> 
> Actually, I was replicating the Example 2.3, using the dataset
> "brainsize.txt" given in Section 2.3.3 ("Summarize by group") at page 55,
> of a famous book "R by Example" written by "Jim Albert and Maria Rizzo"
> published in Springers (2012) in a Use R! Series. The output of the by()
> function printed in the book is being reproduced below for information to
> all:
> 
>> by(data=brain[, -1], INDICES=brain$Gender, FUN=mean, na.rm=TRUE)
> brain$Gender: Female
> FSIQ VIQ PIQ Weight Height MRI_Count
> 111.900 109.450 110.450 137.200 65.765 862654.600
> ------------------------------------------------------------
> brain$Gender: Male
> FSIQ  VIQ    PIQ       Weight    Height   MRI_Count
> 115.00000 115.25000 111.60000 166.44444 71.43158 954855.40000
> 
> 
> I do not know how could the writers of the book have produced the above
> results by by() function. But, when I could not reproduce these results,
> then I thought that probably, this could possibly be due to some missing
> values NA's in Weight and Height variables. Then I tried the above code for
> the "mtcars" dataset for INDICES=mtcars$am. When I found the same results
> here too, then I reported the case in "r-help at R-project.org".
> 
> With best regards,
> 
> Dr. A.K. Singh
> Head, Department of Agril. Statistics
> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> Chhattisgarh, India, PIN-492012
> Mobile: +919752620740
> Email: akhileshsingh.igkv at gmail.com
> 
> On Fri, Apr 15, 2016 at 3:06 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> 
>> I think you are not using the best function for what your intentions are.
>> Try:
>> 
>>> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
>> : 0
>>        mpg         cyl        disp          hp        drat          wt
>>     qsec          vs
>> 17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
>> 18.1831579   0.3684211
>>         am        gear        carb
>>  0.0000000   3.2105263   2.7368421
>> 
>> ---------------------------------------------------------------------------
>> : 1
>>        mpg         cyl        disp          hp        drat          wt
>>     qsec          vs
>> 24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
>> 17.3600000   0.5384615
>>         am        gear        carb
>>  1.0000000   4.3846154   2.9230769
>> 
>> See the difference between colMeans() and mean() in their respective help
>> files.
>> Hth,
>> Adrian
>> 
>> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
>> akhileshsingh.igkv at gmail.com> wrote:
>> 
>>> Dear Sirs,
>>> 
>>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
>>> Chhattisgarh, India.
>>> 
>>> While taking classes, I found the *by() *function producing following
>>> error
>>> 
>>> when I use FUN=mean or median and some other functions, however,
>>> FUN=summary works.
>>> 
>>> Given below is the output of the example I used on a built-in dataset
>>> "mtcars", along with error message reproduced herewith:
>>> 
>>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
>>> : 0
>>> [1] NA
>>> ------------------------------------------------------------
>>> : 1
>>> [1] NA
>>> Warning messages:
>>> 1: In mean.default(data[x, , drop = FALSE], ...) :
>>>  argument is not numeric or logical: returning NA
>>> 2: In mean.default(data[x, , drop = FALSE], ...) :
>>>  argument is not numeric or logical: returning NA
>>> 
>>> However, the same by() function works for FUN=summary, given below is the
>>> output:
>>> 
>>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
>>> : 0
>>>      mpg             cyl             disp             hp
>>> Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
>>> 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
>>> Median :17.30   Median :8.000   Median :275.8   Median :175.0
>>> Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
>>> 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
>>> Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
>>>      drat             wt             qsec             vs               am
>>> 
>>> Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.
>>> :0
>>> 
>>> 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st
>>> Qu.:0
>>> 
>>> Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median
>>> :0
>>> 
>>> Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean
>>> :0
>>> 
>>> 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd
>>> Qu.:0
>>> 
>>> Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.
>>> :0
>>> 
>>>      gear            carb
>>> Min.   :3.000   Min.   :1.000
>>> 1st Qu.:3.000   1st Qu.:2.000
>>> Median :3.000   Median :3.000
>>> Mean   :3.211   Mean   :2.737
>>> 3rd Qu.:3.000   3rd Qu.:4.000
>>> Max.   :4.000   Max.   :4.000
>>> ------------------------------------------------------------
>>> : 1
>>>      mpg             cyl             disp             hp             drat
>>> 
>>> Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
>>> :3.54
>>> 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
>>> Qu.:3.85
>>> Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
>>> :4.08
>>> Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
>>> :4.05
>>> 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
>>> Qu.:4.22
>>> Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
>>> :4.93
>>>       wt             qsec             vs               am         gear
>>> 
>>> Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.
>>> :4.000
>>> 
>>> 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st
>>> Qu.:4.000
>>> 
>>> Median :2.320   Median :17.02   Median :1.0000   Median :1   Median
>>> :4.000
>>> 
>>> Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean
>>> :4.385
>>> 
>>> 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd
>>> Qu.:5.000
>>> 
>>> Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.
>>> :5.000
>>> 
>>>      carb
>>> Min.   :1.000
>>> 1st Qu.:1.000
>>> Median :2.000
>>> Mean   :2.923
>>> 3rd Qu.:4.000
>>> Max.   :8.000
>>>> 
>>> 
>>> I am using the latest version of *R-3.2.4 on Windows*, however, this error
>>> is being generated in the previous version too,
>>> 
>>> Hope this reporting will get serious attention in debugging.
>>> 
>>> With best regards,
>>> 
>>> Dr. A.K. Singh
>>> Head, Department of Agril. Statistics
>>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
>>> Chhattisgarh, India, PIN-492012
>>> Mobile: +919752620740
>>> Email: akhileshsingh.igkv at gmail.com
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Fri Apr 15 11:30:15 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 Apr 2016 05:30:15 -0400
Subject: [R] Bug in by() function which works for some FUN argument and
 does not work for others
In-Reply-To: <CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
	<CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
Message-ID: <5710B4A7.7090001@gmail.com>

On 15/04/2016 4:16 AM, Akhilesh Singh wrote:
> Dear All,
>
> Thanks for your help. However, I would like to draw your attention to the
> following:
>
> Actually, I was replicating the Example 2.3, using the dataset
> "brainsize.txt" given in Section 2.3.3 ("Summarize by group") at page 55,
> of a famous book "R by Example" written by "Jim Albert and Maria Rizzo"
> published in Springers (2012) in a Use R! Series. The output of the by()
> function printed in the book is being reproduced below for information to
> all:

See their errata page http://personal.bgsu.edu/~mrizzo/Rx/Rx-errata.txt. 
  They corrected "mean" to "colMeans".

Duncan Murdoch

>
>> by(data=brain[, -1], INDICES=brain$Gender, FUN=mean, na.rm=TRUE)
> brain$Gender: Female
> FSIQ VIQ PIQ Weight Height MRI_Count
> 111.900 109.450 110.450 137.200 65.765 862654.600
> ------------------------------------------------------------
> brain$Gender: Male
> FSIQ  VIQ    PIQ       Weight    Height   MRI_Count
> 115.00000 115.25000 111.60000 166.44444 71.43158 954855.40000
>
>
> I do not know how could the writers of the book have produced the above
> results by by() function. But, when I could not reproduce these results,
> then I thought that probably, this could possibly be due to some missing
> values NA's in Weight and Height variables. Then I tried the above code for
> the "mtcars" dataset for INDICES=mtcars$am. When I found the same results
> here too, then I reported the case in "r-help at R-project.org".
>
> With best regards,
>
> Dr. A.K. Singh
> Head, Department of Agril. Statistics
> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> Chhattisgarh, India, PIN-492012
> Mobile: +919752620740
> Email: akhileshsingh.igkv at gmail.com
>
> On Fri, Apr 15, 2016 at 3:06 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
>
>> I think you are not using the best function for what your intentions are.
>> Try:
>>
>>> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
>> : 0
>>          mpg         cyl        disp          hp        drat          wt
>>       qsec          vs
>>   17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
>>   18.1831579   0.3684211
>>           am        gear        carb
>>    0.0000000   3.2105263   2.7368421
>>
>> ---------------------------------------------------------------------------
>> : 1
>>          mpg         cyl        disp          hp        drat          wt
>>       qsec          vs
>>   24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
>>   17.3600000   0.5384615
>>           am        gear        carb
>>    1.0000000   4.3846154   2.9230769
>>
>> See the difference between colMeans() and mean() in their respective help
>> files.
>> Hth,
>> Adrian
>>
>> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
>> akhileshsingh.igkv at gmail.com> wrote:
>>
>>> Dear Sirs,
>>>
>>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
>>> Chhattisgarh, India.
>>>
>>> While taking classes, I found the *by() *function producing following
>>> error
>>>
>>> when I use FUN=mean or median and some other functions, however,
>>> FUN=summary works.
>>>
>>> Given below is the output of the example I used on a built-in dataset
>>> "mtcars", along with error message reproduced herewith:
>>>
>>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
>>> : 0
>>> [1] NA
>>> ------------------------------------------------------------
>>> : 1
>>> [1] NA
>>> Warning messages:
>>> 1: In mean.default(data[x, , drop = FALSE], ...) :
>>>    argument is not numeric or logical: returning NA
>>> 2: In mean.default(data[x, , drop = FALSE], ...) :
>>>    argument is not numeric or logical: returning NA
>>>
>>> However, the same by() function works for FUN=summary, given below is the
>>> output:
>>>
>>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
>>> : 0
>>>        mpg             cyl             disp             hp
>>>   Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
>>>   1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
>>>   Median :17.30   Median :8.000   Median :275.8   Median :175.0
>>>   Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
>>>   3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
>>>   Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
>>>        drat             wt             qsec             vs               am
>>>
>>>   Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.
>>>   :0
>>>
>>>   1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st
>>> Qu.:0
>>>
>>>   Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median
>>> :0
>>>
>>>   Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean
>>>   :0
>>>
>>>   3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd
>>> Qu.:0
>>>
>>>   Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.
>>>   :0
>>>
>>>        gear            carb
>>>   Min.   :3.000   Min.   :1.000
>>>   1st Qu.:3.000   1st Qu.:2.000
>>>   Median :3.000   Median :3.000
>>>   Mean   :3.211   Mean   :2.737
>>>   3rd Qu.:3.000   3rd Qu.:4.000
>>>   Max.   :4.000   Max.   :4.000
>>> ------------------------------------------------------------
>>> : 1
>>>        mpg             cyl             disp             hp             drat
>>>
>>>   Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
>>> :3.54
>>>   1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
>>> Qu.:3.85
>>>   Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
>>> :4.08
>>>   Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
>>> :4.05
>>>   3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
>>> Qu.:4.22
>>>   Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
>>> :4.93
>>>         wt             qsec             vs               am         gear
>>>
>>>   Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.
>>>   :4.000
>>>
>>>   1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st
>>> Qu.:4.000
>>>
>>>   Median :2.320   Median :17.02   Median :1.0000   Median :1   Median
>>> :4.000
>>>
>>>   Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean
>>>   :4.385
>>>
>>>   3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd
>>> Qu.:5.000
>>>
>>>   Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.
>>>   :5.000
>>>
>>>        carb
>>>   Min.   :1.000
>>>   1st Qu.:1.000
>>>   Median :2.000
>>>   Mean   :2.923
>>>   3rd Qu.:4.000
>>>   Max.   :8.000
>>>>
>>>
>>> I am using the latest version of *R-3.2.4 on Windows*, however, this error
>>> is being generated in the previous version too,
>>>
>>> Hope this reporting will get serious attention in debugging.
>>>
>>> With best regards,
>>>
>>> Dr. A.K. Singh
>>> Head, Department of Agril. Statistics
>>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
>>> Chhattisgarh, India, PIN-492012
>>> Mobile: +919752620740
>>> Email: akhileshsingh.igkv at gmail.com
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Adrian Dusa
>> University of Bucharest
>> Romanian Social Data Archive
>> Soseaua Panduri nr.90
>> 050663 Bucharest sector 5
>> Romania
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 31sharmajittu1991 at gmail.com  Fri Apr 15 12:02:20 2016
From: 31sharmajittu1991 at gmail.com (Jyoti Sharma)
Date: Fri, 15 Apr 2016 15:32:20 +0530
Subject: [R] Need Help to solve an Error in R
Message-ID: <CANM3OPhnZC14Vx8u1xFM5Fyo8zAJTCL8=mLrxS1H_BxWxJ5kgA@mail.gmail.com>

Hello Sir/ma'am,

Greetings for the Day !

I am Jyoti Sharma, from India and recently start working on R. I am new in
this field and my knowledge is not up to the mark, so if I sound dumb then
please forgive me.

I tried to read some text file in R so that I can do further analysis on
those files. All files are MicroRNA dataset and in exiqon format. When I
write function ReadExi and path of my file gives me error - Error in a
file(file, "rt") : cannot open the connection.

I put a file in the same directory too, even then also it is not working.
Can you help me on this issue?? Is there any issue with GAL file or
samplesinfo.txt file as these are to be there in same folder as described
in ExiMir package ??

I didn't get this issue. Please help on this matter.

Thanks in advance.


-- 
*Regards*

*Jyoti Sharma*
*Junior Research Fellow*
*University of Hyderabad*
*India*

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Apr 15 14:15:40 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 15 Apr 2016 14:15:40 +0200
Subject: [R] simple interactions
In-Reply-To: <519743$2rmv4f@ironport10.mayo.edu>
References: <519743$2rmv4f@ironport10.mayo.edu>
Message-ID: <CAJuCY5wVy3TFEP37HOvsPd=DCerjhYrx2G6LxYmdPyNgL1ynRg@mail.gmail.com>

Dear Terry,

Does fitting group + age:group instead of age*group solves your problem?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-15 13:58 GMT+02:00 Therneau, Terry M., Ph.D. <therneau at mayo.edu>:

> I'd like to get interaction terms in a model to be in another form.
> Namely, suppose I had variables age and group, the latter a factor with
> levels A, B, C, with  age * group in the model.  What I would like are the
> variables "age:group=A", "age:group=B" and "age:group=C"  (and group itself
> of course).  The coefficients of the model will then be the age effect in
> group A, the age effect in group B and the age effect in C rather than the
> standard ones of an overall age effect followed by contrasts.  These is
> often a better format for tables in a publication.
>
> Yes, I can reconstruct these from the original fit, but I have a lot of
> variables for several models and it would be easier to have an automatic
> form.  I suspect that there is an easy answer, but I don't see it.
>
> Terry Therneau
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Apr 15 14:31:00 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 15 Apr 2016 12:31:00 +0000
Subject: [R] Need Help to solve an Error in R
In-Reply-To: <CANM3OPhnZC14Vx8u1xFM5Fyo8zAJTCL8=mLrxS1H_BxWxJ5kgA@mail.gmail.com>
References: <CANM3OPhnZC14Vx8u1xFM5Fyo8zAJTCL8=mLrxS1H_BxWxJ5kgA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5026892@SRVEXCHMBX.precheza.cz>

Hi

If you recently start with R maybe you shall spend some time with R intro document to understand R basics.

I looked to ExiMiR package and I must say that although I am after 20 years quite familiar with R I have problems to understand what I should do and I would need to study thoroughly how those files I shall read in look like.

Maybe some people who are familiar with ExiMiR package can give you more insight but in any case you shall provide not only error message but also commands you used before those errors.

My guess is that you did not specify name of the file correctly.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jyoti
> Sharma
> Sent: Friday, April 15, 2016 12:02 PM
> To: r-help at r-project.org
> Subject: [R] Need Help to solve an Error in R
>
> Hello Sir/ma'am,
>
> Greetings for the Day !
>
> I am Jyoti Sharma, from India and recently start working on R. I am new in this
> field and my knowledge is not up to the mark, so if I sound dumb then please
> forgive me.
>
> I tried to read some text file in R so that I can do further analysis on those
> files. All files are MicroRNA dataset and in exiqon format. When I write
> function ReadExi and path of my file gives me error - Error in a file(file, "rt") :
> cannot open the connection.
>
> I put a file in the same directory too, even then also it is not working.
> Can you help me on this issue?? Is there any issue with GAL file or
> samplesinfo.txt file as these are to be there in same folder as described in
> ExiMir package ??
>
> I didn't get this issue. Please help on this matter.
>
> Thanks in advance.
>
>
> --
> *Regards*
>
> *Jyoti Sharma*
> *Junior Research Fellow*
> *University of Hyderabad*
> *India*
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Achim.Zeileis at uibk.ac.at  Fri Apr 15 14:51:31 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 15 Apr 2016 14:51:31 +0200 (CEST)
Subject: [R] simple interactions
In-Reply-To: <519743$2rmv4f@ironport10.mayo.edu>
References: <519743$2rmv4f@ironport10.mayo.edu>
Message-ID: <alpine.DEB.2.20.1604151447380.9640@paninaro>

Try using
   ~ group/age
or even
   ~ 0 + group/age

Both have all three group-specific slopes but differ with respect to the 
intercept codings. The latter has three group-specific intercepts as well. 
But the former has an intercept corresponding to the reference group A and 
then the usual treatment contrasts for group B and C (i.e., intercept 
differences).

IIRC then I found the discussion of these contrasts and nested codings in 
the MASS book very useful.

On Fri, 15 Apr 2016, Therneau, Terry M., Ph.D. wrote:

> I'd like to get interaction terms in a model to be in another form.  Namely, 
> suppose I had variables age and group, the latter a factor with levels A, B, 
> C, with  age * group in the model.  What I would like are the variables 
> "age:group=A", "age:group=B" and "age:group=C"  (and group itself of course). 
> The coefficients of the model will then be the age effect in group A, the age 
> effect in group B and the age effect in C rather than the standard ones of an 
> overall age effect followed by contrasts.  These is often a better format for 
> tables in a publication.
>
> Yes, I can reconstruct these from the original fit, but I have a lot of 
> variables for several models and it would be easier to have an automatic 
> form.  I suspect that there is an easy answer, but I don't see it.
>
> Terry Therneau
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Fri Apr 15 15:07:41 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 15 Apr 2016 13:07:41 +0000
Subject: [R] Need Help to solve an Error in R
In-Reply-To: <CANM3OPitpc2ynRG793j05DPMKOTnSczO_orETZ35VwNotPT28A@mail.gmail.com>
References: <CANM3OPhnZC14Vx8u1xFM5Fyo8zAJTCL8=mLrxS1H_BxWxJ5kgA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5026892@SRVEXCHMBX.precheza.cz>
	<CANM3OPitpc2ynRG793j05DPMKOTnSczO_orETZ35VwNotPT28A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50268DC@SRVEXCHMBX.precheza.cz>

Hi

Keep your answers to R help (others can help you too)

From the warning message it seems to me possible that function ReadExi needs to write something to the working directory. As I said I am not an expert in this package, but commands from help

R> make.gal.env(galname='galenv', gal.path='Exiqon')
R> ebatch <- ReadExi(galname='galenv', txtfile.path='Exiqon')

are rather different from yours and I am not sure if it matters.

Here I understand that
# The folder 'Exiqon' contains the file 'samplesinfo.txt' and the corresponding raw data files in ImaGene format
## Not run: ebatch <- ReadExi(txtfile.path='Exiqon')
# If the GAL environment has already created by the function make.gal.env
## Not run: ebatch <- ReadExi(galenv='galenv', txtfile.path='Exiqon')

if you already created gal environment you shall use it in ReadExi command.

If you do not understand what environment is I again strongly recommend to read R intro, especially chapter 1 and chapter 7.

Cheers
Petr


From: Jyoti Sharma [mailto:31sharmajittu1991 at gmail.com]
Sent: Friday, April 15, 2016 2:46 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] Need Help to solve an Error in R

First of all Thank you so much for your reply.

I used this code

library(ExiMiR)
make.gal.env(galname='galenv')

fileRead <- ReadExi(txtfile.path = getwd())

after this the error msg prints -

Read header information
Read C:/Users/Kirti/Documents/working/Exiqon/GSM1302311_0_Exiqon_14173049_S01.txt
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'C:/Users/Kirti/Documents/working/Exiqon/NA': Permission denied


2 txt files, one samplesinfo file and one gal file is already in  C:/Users/Kirti/Documents/working/Exiqon/ directory.

Now I fail to understand where is the problem.



On Fri, Apr 15, 2016 at 6:01 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

If you recently start with R maybe you shall spend some time with R intro document to understand R basics.

I looked to ExiMiR package and I must say that although I am after 20 years quite familiar with R I have problems to understand what I should do and I would need to study thoroughly how those files I shall read in look like.

Maybe some people who are familiar with ExiMiR package can give you more insight but in any case you shall provide not only error message but also commands you used before those errors.

My guess is that you did not specify name of the file correctly.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Jyoti
> Sharma
> Sent: Friday, April 15, 2016 12:02 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Need Help to solve an Error in R
>
> Hello Sir/ma'am,
>
> Greetings for the Day !
>
> I am Jyoti Sharma, from India and recently start working on R. I am new in this
> field and my knowledge is not up to the mark, so if I sound dumb then please
> forgive me.
>
> I tried to read some text file in R so that I can do further analysis on those
> files. All files are MicroRNA dataset and in exiqon format. When I write
> function ReadExi and path of my file gives me error - Error in a file(file, "rt") :
> cannot open the connection.
>
> I put a file in the same directory too, even then also it is not working.
> Can you help me on this issue?? Is there any issue with GAL file or
> samplesinfo.txt file as these are to be there in same folder as described in
> ExiMir package ??
>
> I didn't get this issue. Please help on this matter.
>
> Thanks in advance.
>
>
> --
> *Regards*
>
> *Jyoti Sharma*
> *Junior Research Fellow*
> *University of Hyderabad*
> *India*
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



--
Regards

Jyoti Sharma
Junior Research Fellow
University of Hyderabad
India

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Fri Apr 15 15:42:56 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 15 Apr 2016 08:42:56 -0500
Subject: [R] simple interactions
In-Reply-To: <CAJuCY5wVy3TFEP37HOvsPd=DCerjhYrx2G6LxYmdPyNgL1ynRg@mail.gmail.com>
References: <519743$2rmv4f@ironport10.mayo.edu>
	<CAJuCY5wVy3TFEP37HOvsPd=DCerjhYrx2G6LxYmdPyNgL1ynRg@mail.gmail.com>
Message-ID: <519743$2rnv2u@ironport10.mayo.edu>

I was right that there is an easy answer!

Thanks for the 3 quick answers, all three correct and useful.

Terry Therneau


On 04/15/2016 07:15 AM, Thierry Onkelinx wrote:
> Dear Terry,
>
> Does fitting group + age:group instead of age*group solves your problem?
>
> Best regards,
>
> ir. Thierry Onkelinx
>
>> 2016-04-15 13:58 GMT+02:00 Therneau, Terry M., Ph.D. <therneau at mayo.edu
> <mailto:therneau at mayo.edu>>:
>
>     I'd like to get interaction terms in a model to be in another form. Namely, suppose I
>     had variables age and group, the latter a factor with levels A, B, C, with  age *
>     group in the model.  What I would like are the variables "age:group=A", "age:group=B"
>     and "age:group=C"  (and group itself of course).  The coefficients of the model will
>     then be the age effect in group A, the age effect in group B and the age effect in C
>     rather than the standard ones of an overall age effect followed by contrasts.  These
>     is often a better format for tables in a publication.
>
>     Yes, I can reconstruct these from the original fit, but I have a lot of variables for
>     several models and it would be easier to have an automatic form.  I suspect that there
>     is an easy answer, but I don't see it.
>
>     Terry Therneau


From maechler at stat.math.ethz.ch  Fri Apr 15 16:13:50 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 15 Apr 2016 16:13:50 +0200
Subject: [R] simple interactions
In-Reply-To: <519743$2rmv4f@ironport10.mayo.edu>
References: <519743$2rmv4f@ironport10.mayo.edu>
Message-ID: <22288.63262.282754.669339@stat.math.ethz.ch>

>>>>> Therneau, Terry M , Ph D <therneau at mayo.edu>
>>>>>     on Fri, 15 Apr 2016 06:58:22 -0500 writes:

    > I'd like to get interaction terms in a model to be in
    > another form.  Namely, suppose I had variables age and
    > group, the latter a factor with levels A, B, C, with age *
    > group in the model.  What I would like are the variables
    > "age:group=A", "age:group=B" and "age:group=C" (and group
    > itself of course).  The coefficients of the model will
    > then be the age effect in group A, the age effect in group
    > B and the age effect in C rather than the standard ones of
    > an overall age effect followed by contrasts.  These is
    > often a better format for tables in a publication.

Did you try  to use  one of the good old

   dummy.coef()

or

   model.tables()

Functions?
Please use R  3.2.4 or newer, notably for dummy.coef() which was
improved (made more generally working) for R 3.2.4, notably
thanks to my colleague Werner Stahel.

Best regards,
Martin

--
Martin Maechler, ETH Zurich

  

    > Yes, I can reconstruct these from the original fit, but I
    > have a lot of variables for several models and it would be
    > easier to have an automatic form.  I suspect that there is
    > an easy answer, but I don't see it.

    > Terry Therneau

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Fri Apr 15 17:40:22 2016
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 15 Apr 2016 16:40:22 +0100
Subject: [R] aggregate combination data
In-Reply-To: <CAEW+BD+_YGs2Y72nF6bcEmQ1xcZ6xDQMc+tSYdce-eEtqg4MGA@mail.gmail.com>
References: <CAEW+BDKyZz2kDOO=i81chBZ5mWhuqFB=F475L9mvtCT42+fj+g@mail.gmail.com>
	<50A37FBF.2090502@sapo.pt>
	<CAEW+BDLk4Zj+diCqOd9+6fFv39R6EfmKBZDK5dbvtUpKGYXsDQ@mail.gmail.com>
	<50A39C82.9040705@sapo.pt>
	<CAEW+BD+komw3NNC4A-VMT1AcwVK1p4qOQG3PaknCz5fozA_U=Q@mail.gmail.com>
	<50A39ED7.9080806@sapo.pt>
	<CAEW+BD+Xvtp+eJ1n0D25Jq+kR-J-kPVP7PF-C96r2ry7y1AS9w@mail.gmail.com>
	<50A3A4E3.2020906@sapo.pt>
	<CAEW+BDLyYBTpHbK3j9foRV5RvBGMgc+P=XX4+Y0xGq6tiq5bDA@mail.gmail.com>
	<50A3CB11.3050308@sapo.pt>
	<CAEW+BD+tS2PkYbSZKEESf7XJ1iNK8opB8HUUbNQ1_mWTRqbMTA@mail.gmail.com>
	<CAEW+BDLvLc4oAP9oAjgoKvTc3dp9fBP=DrS_knMMPzMHBwRVZQ@mail.gmail.com>
	<50A3D4C7.7050908@sapo.pt>
	<CAEW+BD+64fjTH0qfrXQcHuD56LVaH9GoLkKpA9dGp-ymRoLnAA@mail.gmail.com>
	<CAEW+BDLzEwWzeZPug6SeXETjCtYuURHdqGWrj41ex59ssFVHSg@mail.gmail.com>
	<50A4D226.1010808@sapo.pt>
	<CAEW+BD+_YGs2Y72nF6bcEmQ1xcZ6xDQMc+tSYdce-eEtqg4MGA@mail.gmail.com>
Message-ID: <20160415164022.Horde.vIXFxiAH4DN6XQZjZioRwII@mail.sapo.pt>

Hello,

I'm cc'ing R-Help.

Sorry but your question was asked 3.5 years ago, I really don't  
remember it. Can you please post a question to R-Help, with a  
reproducible example that describes your problem?

Rui Barradas
?

Citando catalin roibu <catalinroibu at gmail.com>:

> Dear Rui,
> ?
> I helped me some time ago with a code..... regarding aggregated data  
> from combination values. I solved partial the problem...I have one  
> single question. From combination I have a number of data frames. I  
> want for each combination to insert a column with combination ID (C1  
> for first iteration to Cn for last one)? Is there a possibility to  
> do that?
> ?
> Thank you very much!
> ?
> best regards!
> ?
> Catalin
> ? On 15 November 2012 at 13:29, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Sorry but now I don't understand, what you are saying is that you  
>> want all the results in just one df?
>>
>> all <- do.call(rbind, result)
>>
>> But this creates just one very large df.
>>
>> Hope this helps,
>>
>> Rui Barradas Em 15-11-2012 10:42, catalin roibu escreveu:
>>> Hello again,
>>> I solve that problem.
>>> But I have another one. I want my result is this form:
>>> plot d
>>> 1 15.00
>>> 1 27.50
>>> 1 10.50
>>> 1 12.25
>>> 2 14.00
>>> 2 32.50
>>> ?
>>> 99 32.00
>>> 99 42.00
>>> 100 57.00
>>> 100 16.00
>>> 100 8.00
>>> 100 56.00
>>>
>>> in final values of d for all combination possible.
>>>
>>> Thank you very much!
>>>
>>> On 15 November 2012 12:10, catalin roibu <catalinroibu at gmail.com> wrote:
>>> ?
>>>> Hello again,
>>>> Wen I want to show all combination 100C3, I have this problem:
>>>> ? [ reached getOption("max.print") -- omitted 2498631 rows ]
>>>> How can you do?
>>>>
>>>> On 14 November 2012 19:28, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>> ?
>>>>> Simple
>>>>> Just use unlist(result).
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>> Em 14-11-2012 17:13, catalin roibu escreveu:
>>>>> ?
>>>>>> hello again,
>>>>>> It's ok now, but I have a little problem. I want to remove the
>>>>>> combination
>>>>>> number (1 to 4950). In this mode the all data are continuous. Thank you!
>>>>>> *[[4271]]*
>>>>>>
>>>>>> ? ? ? plot? ? ?d
>>>>>> 218? ?74 11.50
>>>>>> 219? ?74 12.00
>>>>>> 220? ?74 10.50
>>>>>> 221? ?74 80.75
>>>>>> 251? ?87 15.25
>>>>>> 252? ?87 93.50
>>>>>> 253? ?87 14.50
>>>>>> 254? ?87 83.75
>>>>>> 255? ?87? 9.75
>>>>>> 256? ?87 95.00
>>>>>>
>>>>>> *[[4272]]*
>>>>>>
>>>>>> ? ? ? plot? ? ?d
>>>>>> 218? ?74 11.50
>>>>>> 219? ?74 12.00
>>>>>> 220? ?74 10.50
>>>>>> 221? ?74 80.75
>>>>>> 257? ?88 13.50
>>>>>> 258? ?88 16.25
>>>>>> 259? ?88? 8.50
>>>>>> 260? ?88? 8.50
>>>>>>
>>>>>> On 14 November 2012 18:56, catalin roibu <catalinroibu at gmail.com> wrote:
>>>>>>
>>>>>> ? thank you very much!
>>>>>>> On 14 November 2012 18:47, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>>>>>
>>>>>>> ? Hello,
>>>>>>>> Ok, I think this is it.
>>>>>>>>
>>>>>>>> fun <- function(x, k){
>>>>>>>> ? ? ? n <- length(x)
>>>>>>>> ? ? ? cmb <- combn(n, k)
>>>>>>>> ? ? ? apply(cmb, 2, function(j) x[j])
>>>>>>>> }
>>>>>>>>
>>>>>>>> fun2 <- function(x, p){
>>>>>>>> ? ? ? idx <- x[["plot"]] %in% p
>>>>>>>> ? ? ? x[idx, ]
>>>>>>>> }
>>>>>>>>
>>>>>>>> uplot <- unique(dat$plot)
>>>>>>>> plots <- fun(uplot, 2)
>>>>>>>> apply(plots, 2, function(p) fun2(dat, p))
>>>>>>>>
>>>>>>>> There's a total of 4560 df's returned.
>>>>>>>>
>>>>>>>> Rui Barradas
>>>>>>>> Em 14-11-2012 14:22, catalin roibu escreveu:
>>>>>>>>
>>>>>>>> ? ?Hello again,
>>>>>>>> ?
>>>>>>>>> I want all d values for all posible combination, 100C2 (all d values
>>>>>>>>> for
>>>>>>>>> plot 1 with all d values in the plot 2.......all d values from plot 1
>>>>>>>>> with
>>>>>>>>> all d values from plot 100, ......all d values from plot 99  
>>>>>>>>> with all d
>>>>>>>>> values from plot 100). Total 4950 values
>>>>>>>>> structure(list(plot = c(1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L,
>>>>>>>>> 4L, 4L, 4L, 5L, 5L, 5L, 5L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 9L, 9L,
>>>>>>>>> 10L, 10L, 10L, 11L, 11L, 12L, 12L, 12L, 12L, 13L, 13L, 13L, 13L,
>>>>>>>>> 13L, 14L, 14L, 14L, 14L, 15L, 15L, 15L, 15L, 15L, 15L, 16L, 16L,
>>>>>>>>> 16L, 16L, 16L, 17L, 17L, 17L, 18L, 18L, 18L, 19L, 19L, 19L, 19L,
>>>>>>>>> 20L, 20L, 20L, 21L, 22L, 22L, 22L, 23L, 23L, 23L, 23L, 23L, 24L,
>>>>>>>>> 24L, 25L, 25L, 25L, 25L, 26L, 26L, 26L, 26L, 26L, 27L, 27L, 27L,
>>>>>>>>> 27L, 27L, 28L, 28L, 28L, 28L, 29L, 29L, 29L, 30L, 30L, 30L, 30L,
>>>>>>>>> 32L, 32L, 32L, 32L, 33L, 34L, 34L, 34L, 35L, 36L, 36L, 36L, 36L,
>>>>>>>>> 37L, 37L, 37L, 38L, 38L, 38L, 38L, 38L, 38L, 39L, 39L, 39L, 39L,
>>>>>>>>> 39L, 39L, 40L, 40L, 40L, 41L, 41L, 42L, 42L, 42L, 42L, 42L, 42L,
>>>>>>>>> 42L, 43L, 44L, 44L, 44L, 45L, 45L, 46L, 46L, 47L, 48L, 48L, 48L,
>>>>>>>>> 49L, 50L, 50L, 50L, 50L, 50L, 50L, 51L, 51L, 52L, 52L, 53L, 53L,
>>>>>>>>> 53L, 54L, 54L, 54L, 54L, 55L, 56L, 56L, 57L, 57L, 57L, 58L, 58L,
>>>>>>>>> 58L, 59L, 60L, 60L, 60L, 61L, 61L, 62L, 62L, 63L, 63L, 64L, 64L,
>>>>>>>>> 64L, 65L, 65L, 66L, 66L, 66L, 67L, 67L, 67L, 68L, 68L, 68L, 69L,
>>>>>>>>> 69L, 70L, 70L, 71L, 71L, 73L, 73L, 73L, 73L, 74L, 74L, 74L, 74L,
>>>>>>>>> 75L, 75L, 75L, 75L, 76L, 76L, 76L, 76L, 78L, 78L, 78L, 79L, 79L,
>>>>>>>>> 80L, 80L, 81L, 81L, 81L, 81L, 82L, 82L, 82L, 83L, 83L, 83L, 84L,
>>>>>>>>> 85L, 85L, 85L, 87L, 87L, 87L, 87L, 87L, 87L, 88L, 88L, 88L, 88L,
>>>>>>>>> 89L, 89L, 90L, 91L, 91L, 91L, 91L, 91L, 92L, 93L, 93L, 94L, 95L,
>>>>>>>>> 95L, 95L, 95L, 96L, 96L, 96L, 97L, 97L, 98L, 98L, 98L, 98L, 99L,
>>>>>>>>> 100L, 100L, 100L, 100L, 100L), d = c(15, 27.5, 10.5, 12.25, 14,
>>>>>>>>> 32.5, 80, 49.5, 15.25, 13.5, 12.25, 12, 72.5, 68.5, 12, 9.25,
>>>>>>>>> 12.75, 13.5, 28, 38, 10.25, 62.5, 73.5, 61.5, 54.5, 40, 24.25,
>>>>>>>>> 43, 13, 20.75, 23.25, 25.5, 7.25, 11.25, 60.5, 11.25, 8, 11,
>>>>>>>>> 93.25, 8.75, 10.5, 35, 19, 79, 60.5, 64.5, 53.75, 8.75, 9.75,
>>>>>>>>> 9.5, 12.5, 21, 10, 46.75, 48.5, 77.5, 23.75, 60, 11.5, 13.25,
>>>>>>>>> 13.75, 76.25, 12.5, 8, 70, 47.75, 52.25, 49.25, 11.25, 12.5,
>>>>>>>>> 15.25, 20.25, 19.25, 20.5, 13.5, 86, 23, 10.5, 20.25, 27.75,
>>>>>>>>> 11.25, 32.5, 28.25, 12.5, 14.75, 83, 19.25, 14.25, 21.5, 26.75,
>>>>>>>>> 11.25, 56, 19.75, 55.25, 10, 16.75, 12.5, 19.75, 13, 19.25, 9.75,
>>>>>>>>> 75, 12.5, 11.25, 14.5, 69.5, 13.75, 15.75, 63.75, 18.75, 9.25,
>>>>>>>>> 68, 29, 17.75, 15, 27.25, 10.25, 13.5, 68.25, 9.25, 13, 16.75,
>>>>>>>>> 36.5, 11.25, 87.25, 69.75, 66.25, 15.25, 14.75, 9, 15.75, 17.75,
>>>>>>>>> 82, 13.25, 20, 82.5, 86.5, 7.75, 14.5, 9.25, 95.5, 8.25, 12,
>>>>>>>>> 13.5, 16.5, 69, 15.5, 12, 42, 79.5, 40.75, 13.25, 10, 76.5, 10.75,
>>>>>>>>> 16.5, 12.5, 60.25, 11.25, 17, 63.25, 96, 14.25, 49.5, 56.5, 18,
>>>>>>>>> 84.25, 69.5, 12, 64.75, 48.5, 8.25, 29, 68, 7.25, 79.75, 55,
>>>>>>>>> 75.5, 60.75, 57.5, 61, 15.25, 69, 52.25, 98, 13.25, 14.25, 60.75,
>>>>>>>>> 14.25, 12.25, 56.5, 18, 76.25, 20.75, 10.5, 63.25, 12.5, 11.75,
>>>>>>>>> 84.5, 33.25, 77.75, 71.5, 11.5, 13.5, 19, 31.5, 27.25, 21, 13.25,
>>>>>>>>> 12.5, 31.75, 22, 20, 58.5, 40.5, 62, 85.5, 11.5, 12, 10.5, 80.75,
>>>>>>>>> 55.5, 87, 42.5, 70.5, 9.25, 56, 73.75, 12.75, 11, 59, 18.75,
>>>>>>>>> 10.75, 81, 14, 33.5, 13.25, 69.25, 8.75, 14.5, 63, 89.25, 73.75,
>>>>>>>>> 48.25, 58, 11.5, 17.25, 12.75, 10, 11.5, 15.25, 93.5, 14.5, 83.75,
>>>>>>>>> 9.75, 95, 13.5, 16.25, 8.5, 8.5, 70, 9.75, 72.5, 71.5, 9.5, 83,
>>>>>>>>> 43.75, 51, 55.25, 75.5, 61, 53.75, 60, 12.25, 47, 13.75, 86.5,
>>>>>>>>> 14.5, 10, 9.75, 12, 13.75, 31.75, 64.75, 13.75, 83.5, 45.5, 67,
>>>>>>>>> 84.5, 57.5, 46)), .Names = c("plot", "d"), class = "data.frame",
>>>>>>>>> row.names
>>>>>>>>> = c(NA,
>>>>>>>>> -291L))
>>>>>>>>>
>>>>>>>>> On 14 November 2012 16:04, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>>>>>>>
>>>>>>>>> ? ?Hello,
>>>>>>>>> ?
>>>>>>>>>> Try the following.
>>>>>>>>>>
>>>>>>>>>> fun <- function(x, k){
>>>>>>>>>> ? ? ? ?n <- length(x)
>>>>>>>>>> ? ? ? ?cmb <- combn(n, k)
>>>>>>>>>> ? ? ? ?apply(cmb, 2, function(j) x[j])
>>>>>>>>>> }
>>>>>>>>>>
>>>>>>>>>> uplot <- unique(dat$plot)
>>>>>>>>>> fun(uplot, 2)
>>>>>>>>>>
>>>>>>>>>> Hope this helps,
>>>>>>>>>>
>>>>>>>>>> Rui Barradas
>>>>>>>>>> Em 14-11-2012 13:42, catalin roibu escreveu:
>>>>>>>>>>
>>>>>>>>>> ? ? Hello again,
>>>>>>>>>>
>>>>>>>>>> ? I want the individual plots aggregated by k-combination.  
>>>>>>>>>> I have 100
>>>>>>>>>>> plots.
>>>>>>>>>>> ? ? ?For example I want all values of diameter (d) for combination
>>>>>>>>>>> of two
>>>>>>>>>>> plots
>>>>>>>>>>> (plot 1 and 2, plot 1 and 3 etc) taken by 100.
>>>>>>>>>>>
>>>>>>>>>>> On 14 November 2012 15:38, Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>>>>>> wrote:
>>>>>>>>>>>
>>>>>>>>>>> ? ? Hello,
>>>>>>>>>>>
>>>>>>>>>>> ? This will give you a list of 19 elements, each element k is a
>>>>>>>>>>>> matrix
>>>>>>>>>>>> of
>>>>>>>>>>>> all combinations of 19 taken k at a time.
>>>>>>>>>>>>
>>>>>>>>>>>> cmb <- lapply(seq_len(nrow(dat)), function(k) combn(nrow(dat), k))
>>>>>>>>>>>> d <- dat[["d"]]
>>>>>>>>>>>> lapply(cmb, function(cc) apply(cc, 2, function(j) d[j]))
>>>>>>>>>>>>
>>>>>>>>>>>> Hope this helps,
>>>>>>>>>>>>
>>>>>>>>>>>> Rui Barradas
>>>>>>>>>>>> Em 14-11-2012 13:32, catalin roibu escreveu:
>>>>>>>>>>>>
>>>>>>>>>>>> ? ? ?I want to aggregate all values of diameter after the
>>>>>>>>>>>> combination
>>>>>>>>>>>> between
>>>>>>>>>>>>
>>>>>>>>>>>> ? ?plots. For example all diameter (d) values for combination of n
>>>>>>>>>>>> plots
>>>>>>>>>>>> ?
>>>>>>>>>>>>> taken
>>>>>>>>>>>>> by k.
>>>>>>>>>>>>>
>>>>>>>>>>>>> On 14 November 2012 15:28, Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>
>>>>>>>>>>>>> ? ? ?Hello,
>>>>>>>>>>>>>
>>>>>>>>>>>>> ? ?You forgot to Cc the list.
>>>>>>>>>>>>> ?
>>>>>>>>>>>>>> As for your question, you want all possible  
>>>>>>>>>>>>>> combinations of rows?
>>>>>>>>>>>>>> For
>>>>>>>>>>>>>> all
>>>>>>>>>>>>>> possible values of k in 1:19?
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ? ? ?sum(sapply(1:19, function(k) choose(19, k)))
>>>>>>>>>>>>>> [1] 524287
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Or you want to split the data.frame by plot and the have all
>>>>>>>>>>>>>> possible
>>>>>>>>>>>>>> combinations?
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ? ? ?sum(sapply(1:10, function(k) choose(10, k)))
>>>>>>>>>>>>>> [1] 1023
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ? ? sum(sapply(1:9, function(k) choose(9, k)))
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ? ? ?[1] 511
>>>>>>>>>>>>>>> ? Rui Barradas
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Em 14-11-2012 11:31, catalin roibu escreveu:
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ? ? ? I don't want to sum the data from all  
>>>>>>>>>>>>>> combination. I want to
>>>>>>>>>>>>>> group
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ? ? (aggregate) the all values resulted from all combination
>>>>>>>>>>>>>> possible.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> ? plot d
>>>>>>>>>>>>>>> 1 14
>>>>>>>>>>>>>>> 1 13
>>>>>>>>>>>>>>> 1 12
>>>>>>>>>>>>>>> 1 14
>>>>>>>>>>>>>>> 1 18
>>>>>>>>>>>>>>> 1 20
>>>>>>>>>>>>>>> 1 21
>>>>>>>>>>>>>>> 1 43
>>>>>>>>>>>>>>> 1 108
>>>>>>>>>>>>>>> 1 43
>>>>>>>>>>>>>>> 2 41
>>>>>>>>>>>>>>> 2 61
>>>>>>>>>>>>>>> 2 83
>>>>>>>>>>>>>>> 2 61
>>>>>>>>>>>>>>> 2 84
>>>>>>>>>>>>>>> 2 45
>>>>>>>>>>>>>>> 2 21
>>>>>>>>>>>>>>> 2 12
>>>>>>>>>>>>>>> 2 11
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> On 14 November 2012 13:25, Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>>>>>>>>>> wrote:
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> ? ? ? Hello,
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> ? ? Please use ?dput to post your data.
>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>> ? dput(MyData)? # paste the output of this in a post.
>>>>>>>>>>>>>>>> And you must be more clear, what does "aggregate" mean? To
>>>>>>>>>>>>>>>> sum? In
>>>>>>>>>>>>>>>> the
>>>>>>>>>>>>>>>> mean time see
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> ?combn
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Hope this helps,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> Rui Barradas
>>>>>>>>>>>>>>>> Em 14-11-2012 11:11, catalin roibu escreveu:
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> ? ? ? Dear R users,
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> ? ? I want to aggregate all *d *data from? all  
>>>>>>>>>>>>>>>> combination of n
>>>>>>>>>>>>>>>> *plots*
>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>> ? taken
>>>>>>>>>>>>>>>>> by k.
>>>>>>>>>>>>>>>>> Thank very much!
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> My data is like that:
>>>>>>>>>>>>>>>>> ? ? ? ? ? ? ? ? ? plot? ? ? ? ? ? ? d? 1 14? 1 13? 1 12? 1 14
>>>>>>>>>>>>>>>>> ? 1
>>>>>>>>>>>>>>>>> 18? 1
>>>>>>>>>>>>>>>>> 20
>>>>>>>>>>>>>>>>> ? ? ?1
>>>>>>>>>>>>>>>>> 21
>>>>>>>>>>>>>>>>> ? ? ? ?1
>>>>>>>>>>>>>>>>> 43? 1 108? 1 43? 2 41? 2 61? 2 83? 2 61? 2 84? 2 45? 2 21? 2
>>>>>>>>>>>>>>>>> 12
>>>>>>>>>>>>>>>>> ? ?2
>>>>>>>>>>>>>>>>> 11
>>>>>>>>>>>>>>>>> ? ? ? ?...? 100
>>>>>>>>>>>>>>>>> ? ? ? ? ? ? ?10
>>>>>>>>>>>>>>>>> 100? ? ? ?12
>>>>>>>>>>>>>>>>>
>>>>>>>>>>>>>>>>> ?
>>>>>>>
>>>>>>> --
>>>>>>> ---
>>>>>>> Catalin-Constantin ROIBU
>>>>>>> Forestry engineer, PhD
>>>>>>> Forestry Faculty of Suceava
>>>>>>> Str. Universitatii no. 13, Suceava, 720229, Romania
>>>>>>> office phone? ? ?+4 0230 52 29 78, ext. 531[1]
>>>>>>> mobile phone? ?+4 0745 53 18 01[2]
>>>>>>> ? ? ? ? ? ? ? ? ? ? ? ? ?+4 0766 71 76 58[3]
>>>>>>> FAX:? ? ? ? ? ? ? ? +4 0230 52 16 64[4]
>>>>>>> silvic.usv.ro[5]
>>>>>>>
>>>>>>> ?
>>>>
>>>> --
>>>> ---
>>>> Catalin-Constantin ROIBU
>>>> Forestry engineer, PhD
>>>> Forestry Faculty of Suceava
>>>> Str. Universitatii no. 13, Suceava, 720229, Romania
>>>> office phone? ? ?+4 0230 52 29 78, ext. 531[1]
>>>> mobile phone? ?+4 0745 53 18 01[2]
>>>> ? ? ? ? ? ? ? ? ? ? ? ? +4 0766 71 76 58[3]
>>>> FAX:? ? ? ? ? ? ? ? +4 0230 52 16 64[4]
>>>> silvic.usv.ro[5]
>>>> ?
>>>
>>> ?
>
> ?  ?
> --  ?
> -
> -
> Catalin-Constantin ROIBU? ?
> Lecturer PhD,?Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone ? ? ?+4 0230 52 29 78, ext. 531
> mobile phone ? ?+4 0745 53 18 01
> FAX: ??? ??? ?????? +4 0230 52 16 64 silvic.usv.ro[6]
>
> ?

?

Liga??es:
---------
[1] tel:%2B4%200230%2052%2029%2078%2C%20ext.%20531
[2] tel:%2B4%200745%2053%2018%2001
[3] tel:%2B4%200766%2071%2076%2058
[4] tel:%2B4%200230%2052%2016%2064
[5] http://silvic.usv.ro
[6] http://www.usv.ro/

	[[alternative HTML version deleted]]


From cadeb at usgs.gov  Fri Apr 15 18:36:19 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Fri, 15 Apr 2016 10:36:19 -0600
Subject: [R] Heteroscedasticity in a percent-cover dataset
In-Reply-To: <HK2PR06MB0995B160999B2284A6FAF68FAA680@HK2PR06MB0995.apcprd06.prod.outlook.com>
References: <1460691377486-4719735.post@n4.nabble.com>
	<HK2PR06MB0995B160999B2284A6FAF68FAA680@HK2PR06MB0995.apcprd06.prod.outlook.com>
Message-ID: <CAM5M9BQY46nKscQMe4xqZ4WgS-jicG2qB+iC4nHgpQBzgLe7Pg@mail.gmail.com>

Quit trying to eliminate heteroscedasticity in your data - there is
information there in the pattern of changing variances.  I would suggest
instead that  you go directly after modeling the change in entire
distributional form by using quantile regression (package quantreg).  So,
for example, depending on your sample size and model complexity you might
estimate 0.05 to 0.95 quantiles by increments of 0.05 to categorize how the
distribution of percent cover changes conditional on your predictor
variables.  Heterosecdasticity will be accomodated by changing coefficients
(slopes) for some of your predictors for different values of tau denoting
the quantiles.  See Cade and Noon (2003) for a good introduction for
ecologists.  For percent or proportion data you can use a simple logit
transformation of the dependent variable (see Bottai et al. 2010) to keep
the response bounded appropriately, and incorporate predictor variables any
way you would in any other linear (or generalized linear) model.  There
even are mixed-effects versions of quantile regression now (package lqmm)
but I haven't used them enough to speak to their veracity and value.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Thu, Apr 14, 2016 at 11:49 PM, Lai Wen Ya Samantha <s.lai at u.nus.edu>
wrote:

>
>
> Hi,
>
> I am currently trying to do a GLMM on a dataset with percent cover of
> seagrass (dep. var) and a suite of explanatory variables including algal
> (AC) and epiphyte cover (EC), rainfall, temperature and sunshine hours.
>
> M2=glmer(SG~AC+EC+TP+SS+RF+(1|Location/fSi/fTr),
> family=binomial,data=data,nAGQ=1)
>
> As the dependent variable is percent cover, I used a binomial error
> structure. I also have a random effect due to nested of the data collection
> strategy. However, I keep getting heteroscedasticity issues as shown in the
> image below. I have tried using an arcsine transformation (with a lme), but
> the scatter of residuals are still very much similar.
>
> What else can I do to try to resolve the heteroscedasticity in my data? Any
> help will be very much appreciated!
>
>
> <http://r.789695.n4.nabble.com/file/n4719735/Heteroscedasticity.png>
>
>
>
>
> [http://r.789695.n4.nabble.com/file/n4719735/Heteroscedasticity.png]
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From n4fbz at tampabay.rr.com  Fri Apr 15 19:08:37 2016
From: n4fbz at tampabay.rr.com (Robert D. Bowers)
Date: Fri, 15 Apr 2016 13:08:37 -0400
Subject: [R] R stops responding/communicating in for loop (lengthy
 description of issue)
Message-ID: <57112015.8020005@tampabay.rr.com>

Yeah, this is a bit lengthy, but it's a vexing problem.

First, I'm working on learning R, mainly by using it and coming more 
from a programming aspect (I have the books and have gone through them, 
but learn best by doing).  I have multiple projects going where R is 
almost necessary.  I learned C a few years ago, but am very rusty with 
it (and other languages back in the 70s).  I also am a doctoral student 
and have taken doctoral stats using SPSS, but using the GUI only and for 
what I want to do, it won't be as useful.  My proposed dissertation 
research will probably require R for some rather esoteric statistical 
manipulations which have proved difficult with SPSS (in a pilot study I 
did).  As you probably can tell, I'm no R guru... more on the lines of a 
beginner.

My platform:
Dell Optiplex quad 3.4Ghz 16Gb ram 1Tb hard drive.
Linux Ubuntu 14.04LTS 64 bit
R (from the repositories) version 3.0.2
using RKWard for programming (and testing) version 0.6.1 (from repositories)
using socat to help establish communications - command is: socat 
UDP-DATAGRAM:0.0.0.0:19004 PIPE:"usbsoft" (setting up a pipe between a 
udb connection and R - which needs to access the pipe using FIFO() as I 
learned).  Version 1.7.2.3 from the repositories
I can run the target software (which has a UDP option) in R in the loops 
reliably using system(), but each loop takes between 3/4 and 1 1/2 
seconds.  Using the UDP option, I can run between 20 and 50 loops per 
second.  I've tried using other forms (such as socket() and pipe() but 
they didn't work.

The program runs and locks up at different points (unpredictable) - I 
have to shut down and restart RKWard to "unlock".  I CAN save and edit 
the program in RKWard even when the R console is locked up. I've also 
tried running the program directly from the R command line, without 
success (but haven't tried with the most recent iterations).  In every 
case there are no error codes and seemingly no problems with socat or 
the final software.  I've been tweaking the code here and there, with 
some improvement in the problem, but it's not completely gone.

I HAVE observed that sometimes the program runs through without 
problems, often when I don't have any other major programs running in 
the background (Firefox, Thunderbird, Google Earth, etc.).

My program/routine (and I'd like some feedback if there are easier ways 
to do this):
First I start the program with the UDP interface
Then I start socat
___________________________________________________________________
test=c(1:50)
frequency=c(5+(1*1:500))
response = c(1:500)
number=c(1:500)
dBm=0
newline=('\n')
questionmark="?"
out=fifo("usbsoft",open="w")
volt=file("/dev/ttyUSB0",open="r+w")
for(j in test){
   writeChar("set freq 6.0000",out)
   Sys.sleep(1)
   for(i in number){
     print(frequency[i])  #used to determine where the loop stops
writeChar(questionmark,nchars=nchar(questionmark,type="chars"),volt,eos="\n")
     dBm=readChar(volt,n=5,useBytes=FALSE)
     response[i]=as.integer(dBm)
     freq=paste("set freq ",frequency[i])
     writeChar(freq,out,nchars=nchar(freq,type="chars"))
     flush(out)
     Sys.sleep(.05)
     }                #sometimes this loop doesn't finish on first try, 
sometimes I'll get one successful loop, sometimes 3-4.
   testno=data.frame(response)
   testout=paste("/home/bob/TMP/test",j,".csv")
   write.csv(testno,testout)
   num=paste("test Number ",j)
   print(num)
   }   #A few times this loop has successfully completed.  Most of the 
time it doesn't.
writeLines("\"quit\"",con=out,sep="\n")  (Shuts down the UDP connected 
software and clears the service.)
experiment=data.frame(frequency)
# experiment
write.csv(experiment, file="/home/bob/TMP/scanner-frequency.csv")
close(volt)
close(out)
___________________________________________________________________________

Basically, I'm using R to get data from some equipment modules I've come 
up with and storing the result in a series of vectors (in csv form in a 
folder).  Then I'm building a spreadsheet (at the end) using all of the 
different vectors so as to determine various factors about the 
equipment.  I'd really like to be able to run the loops and build a 
single spreadsheet, but haven't figured that out yet.
_The statement flush(out) seems to help a little._  The Sys.sleep() 
statements are to allow the UDP software link to "catch up" (too fast 
and the equipment/software can't keep up and it appears that the buffer 
starts filling up) - but not connected to the problem I'm asking help for.

It shouldn't be taking up THAT much memory.  However, I've read of 
similar problems with the for() loop in R when working with big data.

I've pretty well isolated it to some issue in R... maybe I don't have 
something set right.

Thanks for any help!

Bob


	[[alternative HTML version deleted]]


From ncommons at gmail.com  Fri Apr 15 17:34:25 2016
From: ncommons at gmail.com (Nicholas Commons-Miller)
Date: Fri, 15 Apr 2016 11:34:25 -0400
Subject: [R] Difficulty with LRSM Rasch analysis with eRm package in R.
Message-ID: <57110A01.1080906@gmail.com>

Hi,

I am trying to do an LRSM Rasch analysis for 72-item data. 67 of the 
items are binary, and 5 are ternary. I have tried it with and without a 
specified matrix, and cannot get it to work.

The primary problems I am having are:
1. Without a matrix, I get an error:

Error in `rownames<-`(`*tmp*`, value = betanames) : length of 'dimnames' 
[1] not equal to array extent


This is from these commands:
rGrps = c(rep.int(1, nrow(X)))
results.LRSM <- LRSM(X, mpoints = 1, groupvec = rGrps, se = TRUE)

2. I don't know how to make a design matrix myself. I tried making one 
with 1's along the diagonal, but it doesn't seem to work. I get an error:

Error in likLR(X, W, mpoints, groupvec, model, st.err = se, sum0, 
etaStart) : Mismatch between number of rows (beta's) in W and number of 
items (categories) in X!


This is from these commands:
rGrps = c(rep.int(1, nrow(X)))
W = matrix(data=NA, nrow=ncol(X), ncol=ncol(X))
for(i in 1:(ncol(X) - 8))
{
   vec = c(rep(0, i - 1),1,rep(0, (ncol(X) - i)))
   W[i,] = vec
}
results.LRSM <- LRSM(X, W, mpoints = 1, groupvec = rGrps, se = TRUE)

Both of these errors seem to arise somewhere within the eRm code, and I 
have had great difficulty finding specifically where. I am using R 
Studio, but I do not seem to be able to figure out the debugging, 
particularly when I need it to go into eRm package files.

So basically, if I could get a few points of help, I would appreciate it:
1. How do I create a design matrix?
2. Why do the betas seem to not match the data? (The betanames to the 
rownames, or the betas to categories.)
3. How do I use R Studio debugging to step into the package files?

Thank you,
Nicholas Commons-Miller

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Apr 15 20:25:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Apr 2016 11:25:12 -0700
Subject: [R] Need Help to solve an Error in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50268DC@SRVEXCHMBX.precheza.cz>
References: <CANM3OPhnZC14Vx8u1xFM5Fyo8zAJTCL8=mLrxS1H_BxWxJ5kgA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5026892@SRVEXCHMBX.precheza.cz>
	<CANM3OPitpc2ynRG793j05DPMKOTnSczO_orETZ35VwNotPT28A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50268DC@SRVEXCHMBX.precheza.cz>
Message-ID: <35070A5B-0850-4D33-8EEC-EDAEE12B64D2@comcast.net>


> On Apr 15, 2016, at 6:07 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hi
> 
> Keep your answers to R help (others can help you too)
> 
> From the warning message it seems to me possible that function ReadExi needs to write something to the working directory. As I said I am not an expert in this package, but commands from help
> 
> R> make.gal.env(galname='galenv', gal.path='Exiqon')
> R> ebatch <- ReadExi(galname='galenv', txtfile.path='Exiqon')
> 
> are rather different from yours and I am not sure if it matters.

To Jyoti;

The first line of code in the help file fails with a message:

> make.gal.env(galname='galenv', gal.path='Exiqon')
Error in make.gal.env(galname = "galenv", gal.path = "Exiqon") : 
  Cannot find GAL file.


The package documentation mentions a file named GSE20122_RAW.tar at (http://www.ncbi.nlm.nih.gov/geo/) You can find this at an NIH website: http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE20122 . 

Status	Public on Feb 02, 2010
Title	Vitamin D and microRNA Expression

The file is linked to at the bottom of that document. It's 87.7 Mb and only expands to a directory slightly large, because the contents are all gzipped. The server is reasonably fast so download only takes a few minutes. The documentation then describes the process for extracting text files. The first file is named GSM503404_Hy3_Exiqon_14114404_S01_Cropped.txt.gz and each of the 108 items are slightly over 900 KB. 

The unlabeled appendix at the end of the vignette has 24 file names at least some of which are in the 108 items. You are given directions about how to store these names in a text file.

The package vignette appears to be a "work in progress" because references to figures and appendices are often to "??". It does describe a process for constructing a directory that can be used with package functions, but there are no code segments to copy, either in the vignette or this the help page link to "R code".

You are much more likely to find someone who knows anything further about this package at the Bioconductor help page. (It is a Bioconductor package after all.) They have a spiffy new Q&A interface that reminds me of StackOverflow. I suspect a lot of newbies find it easier to use than the text based mailing list:

https://support.bioconductor.org/

-- 
David.




> Here I understand that
> # The folder 'Exiqon' contains the file 'samplesinfo.txt' and the corresponding raw data files in ImaGene format
> ## Not run: ebatch <- ReadExi(txtfile.path='Exiqon')
> # If the GAL environment has already created by the function make.gal.env
> ## Not run: ebatch <- ReadExi(galenv='galenv', txtfile.path='Exiqon')
> 
> if you already created gal environment you shall use it in ReadExi command.
> 
> If you do not understand what environment is I again strongly recommend to read R intro, especially chapter 1 and chapter 7.
> 
> Cheers
> Petr
> 
> 
> From: Jyoti Sharma [mailto:31sharmajittu1991 at gmail.com]
> Sent: Friday, April 15, 2016 2:46 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Subject: Re: [R] Need Help to solve an Error in R
> 
> First of all Thank you so much for your reply.
> 
> I used this code
> 
> library(ExiMiR)
> make.gal.env(galname='galenv')
> 
> fileRead <- ReadExi(txtfile.path = getwd())
> 
> after this the error msg prints -
> 
> Read header information
> Read C:/Users/Kirti/Documents/working/Exiqon/GSM1302311_0_Exiqon_14173049_S01.txt
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>  cannot open file 'C:/Users/Kirti/Documents/working/Exiqon/NA': Permission denied
> 
> 
> 2 txt files, one samplesinfo file and one gal file is already in  C:/Users/Kirti/Documents/working/Exiqon/ directory.
> 
> Now I fail to understand where is the problem.
> 
> 
> 
> On Fri, Apr 15, 2016 at 6:01 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> Hi
> 
> If you recently start with R maybe you shall spend some time with R intro document to understand R basics.
> 
> I looked to ExiMiR package and I must say that although I am after 20 years quite familiar with R I have problems to understand what I should do and I would need to study thoroughly how those files I shall read in look like.
> 
> Maybe some people who are familiar with ExiMiR package can give you more insight but in any case you shall provide not only error message but also commands you used before those errors.
> 
> My guess is that you did not specify name of the file correctly.
> 
> Cheers
> Petr
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Jyoti
>> Sharma
>> Sent: Friday, April 15, 2016 12:02 PM
>> To: r-help at r-project.org<mailto:r-help at r-project.org>
>> Subject: [R] Need Help to solve an Error in R
>> 
>> Hello Sir/ma'am,
>> 
>> Greetings for the Day !
>> 
>> I am Jyoti Sharma, from India and recently start working on R. I am new in this
>> field and my knowledge is not up to the mark, so if I sound dumb then please
>> forgive me.
>> 
>> I tried to read some text file in R so that I can do further analysis on those
>> files. All files are MicroRNA dataset and in exiqon format. When I write
>> function ReadExi and path of my file gives me error - Error in a file(file, "rt") :
>> cannot open the connection.
>> 
>> I put a file in the same directory too, even then also it is not working.
>> Can you help me on this issue?? Is there any issue with GAL file or
>> samplesinfo.txt file as these are to be there in same folder as described in
>> ExiMir package ??
>> 
>> I didn't get this issue. Please help on this matter.
>> 
>> Thanks in advance.
>> 
>> 
>> --
>> *Regards*
>> 
>> *Jyoti Sharma*
>> *Junior Research Fellow*
>> *University of Hyderabad*
>> *India*
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> 
> 
> 
> --
> Regards
> 
> Jyoti Sharma
> Junior Research Fellow
> University of Hyderabad
> India
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jrkrideau at inbox.com  Fri Apr 15 21:18:10 2016
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 15 Apr 2016 11:18:10 -0800
Subject: [R] New member
In-Reply-To: <82pkss1hklbcbm2evyjt8fga.1460630390729@email.android.com>
Message-ID: <51FA0DA794B.000008E3jrkrideau@inbox.com>

There are a number of articles and even books at the R site that are worth looking at. Look Dnder documentation on the main page of the site.  

This link may also help http://www.burns-stat.com/documents/tutorials/

John Kane
Kingston ON Canada


> -----Original Message-----
> From: kipkorirfranklin78 at gmail.com
> Sent: Thu, 14 Apr 2016 13:39:50 +0300
> To: r-help at r-project.org
> Subject: [R] New member
> 
> 
> Hello. I am Franklin from University of Eldoret. I really want to study
> the R package. What should I first of all do?
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Fri Apr 15 21:33:00 2016
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 15 Apr 2016 11:33:00 -0800
Subject: [R] Odds Ratio and OR CI
In-Reply-To: <E58B7D3B-C978-4D32-B1E8-A3C790DCB4CE@gmail.com>
References: <cef88bd0-e706-4711-932b-e9c2b537d86d@cbs.dk>
Message-ID: <521B302073D.0000090Fjrkrideau@inbox.com>

Please don't post in HTML. Your post is almost unreadable

Also,lease have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html for some suggestions about what you should include in your question.

Welcome to R.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: rosita21 at gmail.com
> Sent: Thu, 14 Apr 2016 19:07:04 +0100
> To: pd.mes at cbs.dk, r-help at r-project.org
> Subject: [R] Odds Ratio and OR CI
> 
> Howdy everyone
> 
> 
> 
> I?m trying to get Odds ratio and OR confidence intervals using a probit
> model, but I'm not getting.
> 
> 
> 
> Do you think you can help me?
> 
> 
> 
> I?m new with R L
> 
> 
> 
> naive                   =
> summary(glm(pcr.data[,7]~boldBeta_individual+pcr.data$age,family=binomial(link=probit)))
> 
> naive_answer            = c(naive$coefficients[,1:3])
> #naive estimates for
> 
> 
> #alpha (first 4 collumns: intercept; beta_intercept, beta_slope and age)
> and
> 
> 
> #and SE(last 4 collumns: intercept; beta_intercept, beta_slope and age)
> 
> 
> 
> OR.naive = exp(1.6*coef(naive))
> 
> 
> 
> (till here works, the problem is with the confidence interval)
> 
> 
> 
> I tried to get the Standard error from the variance, but I?m not sure if
> this can be done as I?ve done.
> 
> 
> 
> 
> 
> Var_coef <- 1.6^2*var(coef(naive))
> 
> SE_coef <- Var_coef/sqrt(nsample)                    ########## I thi k
> this is correct
> 
> 
> 
> OR.naive.inf <- exp(OR.naive - (1.96 * SE_coef))
> 
> OR.naive.sup <- exp(OR.naive + (1.96 * SE_coef))
> 
> 
> 
> if I used logit link I would get the CI with confint(na?ve) command, but
> with probit I don't think so. Is there a way?
> 
> 
> 
> What should I do?
> 
> 
> 
> 
> 
> 
> 
> 
> Atenciosamente,
> Rosa Oliveira
> 
> --
> ____________________________________________________________________________
> 
> 
> 
> Rosa Celeste dos Santos Oliveira,
> 
> E-mail: rosita21 at gmail.com <mailto:rosita21 at gmail.com>
> Tlm: +351 939355143
> Linkedin: https://pt.linkedin.com/in/rosacsoliveira
> <https://pt.linkedin.com/in/rosacsoliveira>
> ____________________________________________________________________________
> "Many admire, few know"
> Hippocrates
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From devazresearch at gmail.com  Fri Apr 15 22:07:11 2016
From: devazresearch at gmail.com (deva d)
Date: Sat, 16 Apr 2016 01:37:11 +0530
Subject: [R] Multicollinearity & Endogeniety : PLSPM
Message-ID: <CAKuYVCWStshzft-iDtzWV_7ekWAE6wFW4_ip0b-WDvVNi9NJMg@mail.gmail.com>

Hi

I need a bit of guidance on tests and methods to look for multicollinearity
and Endogeniety while using plspm

Pl help

------------------
T&R
...
Deva

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri Apr 15 22:15:09 2016
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 15 Apr 2016 12:15:09 -0800
Subject: [R] Unequal column lengths
In-Reply-To: <CB5791F5EA3D82408B277900997482D27F7D3B49@mboxes2.campus.vims.edu>
Message-ID: <52796EAD1E5.00000965jrkrideau@inbox.com>

Many basic summary stats in R will not work (i.e. usually return an NA) if there are NAs in the data unless you explicitylauthorize it to do so.

With your data set df
with(df, mean(Dat2, na.rm = TRUE))
[1] 5

This by the way is functionally the same as 
mean(df$Dat2, na.rm = TRUE) 
It's just easier to type the first one 


In other cases R will do not object to the NA's

summary(df)
     Dat1          Dat2        Dat3     
 Min.   :1.0   Min.   :3   Min.   :4.00  
 1st Qu.:2.0   1st Qu.:4   1st Qu.:4.75  
 Median :3.0   Median :5   Median :5.00  
 Mean   :4.4   Mean   :5   Mean   :5.75  
 3rd Qu.:7.0   3rd Qu.:6   3rd Qu.:6.00  
 Max.   :9.0   Max.   :7   Max.   :9.00  
               NA's   :2   NA's   :1     


John Kane
Kingston ON Canada


> -----Original Message-----
> From: tom at vims.edu
> Sent: Thu, 14 Apr 2016 21:33:31 +0000
> To: r-help at r-project.org
> Subject: [R] Unequal column lengths
> 
> Hello,
> 
> Ive tried several times to learn R, but have never gotten past a
> particular gate.  My data are organized by column in Excel, with column
> headers in the first row.  The columns are of unequal lengths.  I export
> them as CSV, then import the CSV file into R.  I wish to summarize the
> data by column.  R inserts NA for missing values, then refuses to operate
> on columns with NA.  R is importing my data into a data frame, and I
> realize that is inappropriate for what I want to do.
> 
> How can I import my data so that I can work on columns of unequal length?
> The first thing I would like to do is generate a table containing mean,
> median, mode, standard deviation, min, max and count, all per column.
> 
> Thank you, Tom
> 
> Example data
>   Dat1 Dat2 Dat3
> 1    1    5    4
> 2    7    7    9
> 3    3    3    5
> 4    2   NA  5
> 5    9   NA NA
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From dwinsemius at comcast.net  Fri Apr 15 23:34:30 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Apr 2016 14:34:30 -0700
Subject: [R] Multicollinearity & Endogeniety : PLSPM
In-Reply-To: <CAKuYVCWStshzft-iDtzWV_7ekWAE6wFW4_ip0b-WDvVNi9NJMg@mail.gmail.com>
References: <CAKuYVCWStshzft-iDtzWV_7ekWAE6wFW4_ip0b-WDvVNi9NJMg@mail.gmail.com>
Message-ID: <E8B4B18A-F132-4EFB-8D39-2FEF4132D1E5@comcast.net>


> On Apr 15, 2016, at 1:07 PM, deva d <devazresearch at gmail.com> wrote:
> 
> Hi
> 
> I need a bit of guidance on tests and methods to look for multicollinearity
> and Endogeniety while using plspm

R help is not set up for statistical guidance. You probably need to post a more detailed question about your data and analytic goals at stats.stackexchange.com.


> 
> Pl help
> 
> ------------------
> T&R
> ...
> Deva
> 
> 	[[alternative HTML version deleted]]

It's also a plain text mailing list. Please read the Posting Guide when you if you return with a coding question.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From divakarreddy.a at gmail.com  Fri Apr 15 23:47:52 2016
From: divakarreddy.a at gmail.com (Divakar Reddy)
Date: Fri, 15 Apr 2016 14:47:52 -0700
Subject: [R] help on moving data from local to HDFS using RODBC in R
Message-ID: <CALEm3d1Zews0gASe+pgZWa70PzF7F7jmmWN__cnhb46jizSGnQ@mail.gmail.com>

Hi,

I have requirement to move the data from Linux local path( ex
 /home/user/sample.txt) to hadoop HDFS using RODBC in R

I knew that we can move the data using rhive comamnds like *rhive.put*
and *rhive.get
*but looking for similar commands using RODBC as well.

I would appreciate for your inputs.

Regards,
Divakar
Phoenix, USA

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Sat Apr 16 00:09:39 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Fri, 15 Apr 2016 17:09:39 -0500
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8ePrciqkbnR1JS+QTQFCMVNX6xJUiYnhpBbpaWWvV2OgxA@mail.gmail.com>
References: <BLU406-EAS2105F5EFDF041F6D9B77D45CD970@phx.gbl>
	<CAM_vju=KKvpRWetkdHsW1Rxp7X1KPHmd93JEZFFwe1PcFCGf0Q@mail.gmail.com>
	<CA+pG8eORyLnqmW-W4JV+_TGmFx_y1OM3Hz2+MtEWYpZf7OgTEA@mail.gmail.com>
	<CA+pG8eMV=ZXPcG+k1_3ot6WctbXdgyHRJ0=XKt6A_Tj8nedZqA@mail.gmail.com>
	<CA+pG8eML_XAiXvTeb5OgKpO2SGVjaofMWtLa6=cQp+bo3C6PoA@mail.gmail.com>
	<CA+pG8eOgwq7pc+=RXRgWwHOMSoRZeNTuzB0MW8V6C+zyPwJzGQ@mail.gmail.com>
	<CA+pG8eN63T844jeGpwK+F2c7y3ea+ktxU-zqq2Eey+HcnZFDmA@mail.gmail.com>
	<CA+pG8ePrciqkbnR1JS+QTQFCMVNX6xJUiYnhpBbpaWWvV2OgxA@mail.gmail.com>
Message-ID: <CA+pG8ePxJxubKEz=FzmXKmGnbS7WXySMGs6hF-3N1nsm4RvWqg@mail.gmail.com>

I need the output to have groups and the probability any given record in
that group then has of being in the response class. Just like my email in
the beginning i need the output that looks like if A and if B and if C then
%77 it will be D.  The examples you provided are just simply not similar.
They are different and would take interpretation to get what i need.
On Apr 14, 2016 1:26 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:

> So. Given that the second and third panels of the first figure in the
> first link I gave show a decision tree with decision rules at each split
> and the number of samples at each direction, what _exactly_ is your
> problem?
>
>
>
> On Wednesday, April 13, 2016, Michael Eugene <fartzy at hotmail.com> wrote:
>
>> I still need the output to match my requiremnt in my original post.  With
>> decision rules "clusters" and probability attached to them.  The examples
>> are sort of similar.  You just provided links to general info about trees.
>>
>>
>>
>> Sent from my Verizon, Samsung Galaxy smartphone
>>
>>
>> -------- Original message --------
>> From: Sarah Goslee <sarah.goslee at gmail.com>
>> Date: 4/13/16 8:04 PM (GMT-06:00)
>> To: Michael Artz <michaeleartz at gmail.com>
>> Cc: "r-help at r-project.org" <R-help at r-project.org>
>> Subject: Re: [R] Decision Tree and Random Forrest
>>
>>
>>
>> On Wednesday, April 13, 2016, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>
>> Tjats great that you are familiar and thanks for responding.  Have you
>> ever done what I am referring to? I have alteady spent time going through
>> links and tutorials about decision trees and random forrests and have even
>> used them both before.
>>
>> Then what specifically is your problem? Both of the tutorials I provided
>> show worked examples, as does even the help for rpart. If none of those, or
>> your extensive reading, work for your project you will have to be a lot
>> more specific about why not.
>>
>> Sarah
>>
>>
>>
>> Mike
>> On Apr 13, 2016 5:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
>>
>> It sounds like you want classification or regression trees. rpart does
>> exactly what you describe.
>>
>> Here's an overview:
>> http://www.statmethods.net/advstats/cart.html
>>
>> But there are a lot of other ways to do the same thing in R, for instance:
>> http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/
>>
>> You can get the same kind of information from random forests, but it's
>> less straightforward. If you want a clear set of rules as in your golf
>> example, then you need rpart or similar.
>>
>> Sarah
>>
>> On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>> > Ah yes I will have to use the predict function.  But the predict
>> function
>> > will not get me there really.  If I can take the example that I have a
>> > model predicting whether or not I will play golf (this is the dependent
>> > value), and there are three independent variables Humidity(High, Medium,
>> > Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind
>> (High,
>> > Low).  I would like rules like where any record that follows these rules
>> > (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
>> > there is probability that play_golf is YES).  I was thinking that random
>> > forrest would weight the rules somehow on the collection of trees and
>> give
>> > a probability.  But if that doesnt make sense, then can you just tell me
>> > how to get the decsion rules with one tree and I will work from that.
>> >
>> > Mike
>> >
>> > Mike
>> >
>> > On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >
>> >> I think you are missing the point of random forests. But if you just
>> >> want to predict using the forest, there is a predict() method that you
>> >> can use. Other than that, I certainly don't understand what you mean.
>> >> Maybe someone else might.
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <michaeleartz at gmail.com>
>> >> wrote:
>> >> > Ok is there a way to do  it with decision tree?  I just need to make
>> the
>> >> > decision rules. Perhaps I can pick one of the trees used with Random
>> >> > Forrest.  I am somewhat familiar already with Random Forrest with
>> >> respective
>> >> > to bagging and feature sampling and getting the mode from the leaf
>> nodes
>> >> and
>> >> > it being an ensemble technique of many trees.  I am just working
>> from the
>> >> > perspective that I need decision rules, and I am working backward
>> form
>> >> that,
>> >> > and I need to do it in R.
>> >> >
>> >> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <bgunter.4567 at gmail.com
>> >
>> >> wrote:
>> >> >>
>> >> >> Nope.
>> >> >>
>> >> >> Random forests are not decision trees -- they are ensembles
>> (forests)
>> >> >> of trees. You need to go back and read up on them so you understand
>> >> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
>> >> >> Statistical Learning" has a nice explanation, but I'm sure there are
>> >> >> lots of good web resources, too.
>> >> >>
>> >> >> Cheers,
>> >> >> Bert
>> >> >>
>> >> >>
>> >> >> Bert Gunter
>> >> >>
>>
>>
>>
>> --
>> Sarah Goslee
>> http://www.stringpage.com
>> http://www.sarahgoslee.com
>> http://www.functionaldiversity.org
>>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Apr 16 00:44:38 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 15 Apr 2016 15:44:38 -0700
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CA+pG8ePxJxubKEz=FzmXKmGnbS7WXySMGs6hF-3N1nsm4RvWqg@mail.gmail.com>
References: <BLU406-EAS2105F5EFDF041F6D9B77D45CD970@phx.gbl>
	<CAM_vju=KKvpRWetkdHsW1Rxp7X1KPHmd93JEZFFwe1PcFCGf0Q@mail.gmail.com>
	<CA+pG8eORyLnqmW-W4JV+_TGmFx_y1OM3Hz2+MtEWYpZf7OgTEA@mail.gmail.com>
	<CA+pG8eMV=ZXPcG+k1_3ot6WctbXdgyHRJ0=XKt6A_Tj8nedZqA@mail.gmail.com>
	<CA+pG8eML_XAiXvTeb5OgKpO2SGVjaofMWtLa6=cQp+bo3C6PoA@mail.gmail.com>
	<CA+pG8eOgwq7pc+=RXRgWwHOMSoRZeNTuzB0MW8V6C+zyPwJzGQ@mail.gmail.com>
	<CA+pG8eN63T844jeGpwK+F2c7y3ea+ktxU-zqq2Eey+HcnZFDmA@mail.gmail.com>
	<CA+pG8ePrciqkbnR1JS+QTQFCMVNX6xJUiYnhpBbpaWWvV2OgxA@mail.gmail.com>
	<CA+pG8ePxJxubKEz=FzmXKmGnbS7WXySMGs6hF-3N1nsm4RvWqg@mail.gmail.com>
Message-ID: <CAF8bMcapo_G6RTBCa-J35VzOdiPuGsnBzvfbptqDsYPCmjyZQQ@mail.gmail.com>

Since you only have 3 predictors, each categorical with a small number of
categories, you can use expand.grid to make a data.frame containing all
possible combinations and give that the predict method for your model to
get all possible predictions.

Something like the following untested code.
    newdata <- expand.grid(
        Humidity = levels(Humidity), #(High, Medium,Low)
        Pending_Chores = levels(Pending_Chores), #(Taxes, None, Laundry,
Car Maintenance)
        Wind = levels(Wind)) # (High,Low)
    newdata$ProbabilityOfPlayingGolf <- predict(fittedModel,
newdata=newdata)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Apr 15, 2016 at 3:09 PM, Michael Artz <michaeleartz at gmail.com>
wrote:

> I need the output to have groups and the probability any given record in
> that group then has of being in the response class. Just like my email in
> the beginning i need the output that looks like if A and if B and if C then
> %77 it will be D.  The examples you provided are just simply not similar.
> They are different and would take interpretation to get what i need.
> On Apr 14, 2016 1:26 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
>
> > So. Given that the second and third panels of the first figure in the
> > first link I gave show a decision tree with decision rules at each split
> > and the number of samples at each direction, what _exactly_ is your
> > problem?
> >
> >
> >
> > On Wednesday, April 13, 2016, Michael Eugene <fartzy at hotmail.com> wrote:
> >
> >> I still need the output to match my requiremnt in my original post.
> With
> >> decision rules "clusters" and probability attached to them.  The
> examples
> >> are sort of similar.  You just provided links to general info about
> trees.
> >>
> >>
> >>
> >> Sent from my Verizon, Samsung Galaxy smartphone
> >>
> >>
> >> -------- Original message --------
> >> From: Sarah Goslee <sarah.goslee at gmail.com>
> >> Date: 4/13/16 8:04 PM (GMT-06:00)
> >> To: Michael Artz <michaeleartz at gmail.com>
> >> Cc: "r-help at r-project.org" <R-help at r-project.org>
> >> Subject: Re: [R] Decision Tree and Random Forrest
> >>
> >>
> >>
> >> On Wednesday, April 13, 2016, Michael Artz <michaeleartz at gmail.com>
> >> wrote:
> >>
> >> Tjats great that you are familiar and thanks for responding.  Have you
> >> ever done what I am referring to? I have alteady spent time going
> through
> >> links and tutorials about decision trees and random forrests and have
> even
> >> used them both before.
> >>
> >> Then what specifically is your problem? Both of the tutorials I provided
> >> show worked examples, as does even the help for rpart. If none of
> those, or
> >> your extensive reading, work for your project you will have to be a lot
> >> more specific about why not.
> >>
> >> Sarah
> >>
> >>
> >>
> >> Mike
> >> On Apr 13, 2016 5:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
> >>
> >> It sounds like you want classification or regression trees. rpart does
> >> exactly what you describe.
> >>
> >> Here's an overview:
> >> http://www.statmethods.net/advstats/cart.html
> >>
> >> But there are a lot of other ways to do the same thing in R, for
> instance:
> >> http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/
> >>
> >> You can get the same kind of information from random forests, but it's
> >> less straightforward. If you want a clear set of rules as in your golf
> >> example, then you need rpart or similar.
> >>
> >> Sarah
> >>
> >> On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com>
> >> wrote:
> >> > Ah yes I will have to use the predict function.  But the predict
> >> function
> >> > will not get me there really.  If I can take the example that I have a
> >> > model predicting whether or not I will play golf (this is the
> dependent
> >> > value), and there are three independent variables Humidity(High,
> Medium,
> >> > Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind
> >> (High,
> >> > Low).  I would like rules like where any record that follows these
> rules
> >> > (IF humidity = high AND pending_chores = None AND Wind = High THEN 77%
> >> > there is probability that play_golf is YES).  I was thinking that
> random
> >> > forrest would weight the rules somehow on the collection of trees and
> >> give
> >> > a probability.  But if that doesnt make sense, then can you just tell
> me
> >> > how to get the decsion rules with one tree and I will work from that.
> >> >
> >> > Mike
> >> >
> >> > Mike
> >> >
> >> > On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >> >
> >> >> I think you are missing the point of random forests. But if you just
> >> >> want to predict using the forest, there is a predict() method that
> you
> >> >> can use. Other than that, I certainly don't understand what you mean.
> >> >> Maybe someone else might.
> >> >>
> >> >> Cheers,
> >> >> Bert
> >> >>
> >> >>
> >> >> Bert Gunter
> >> >>
> >> >> "The trouble with having an open mind is that people keep coming
> along
> >> >> and sticking things into it."
> >> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>
> >> >>
> >> >> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <
> michaeleartz at gmail.com>
> >> >> wrote:
> >> >> > Ok is there a way to do  it with decision tree?  I just need to
> make
> >> the
> >> >> > decision rules. Perhaps I can pick one of the trees used with
> Random
> >> >> > Forrest.  I am somewhat familiar already with Random Forrest with
> >> >> respective
> >> >> > to bagging and feature sampling and getting the mode from the leaf
> >> nodes
> >> >> and
> >> >> > it being an ensemble technique of many trees.  I am just working
> >> from the
> >> >> > perspective that I need decision rules, and I am working backward
> >> form
> >> >> that,
> >> >> > and I need to do it in R.
> >> >> >
> >> >> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <
> bgunter.4567 at gmail.com
> >> >
> >> >> wrote:
> >> >> >>
> >> >> >> Nope.
> >> >> >>
> >> >> >> Random forests are not decision trees -- they are ensembles
> >> (forests)
> >> >> >> of trees. You need to go back and read up on them so you
> understand
> >> >> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
> >> >> >> Statistical Learning" has a nice explanation, but I'm sure there
> are
> >> >> >> lots of good web resources, too.
> >> >> >>
> >> >> >> Cheers,
> >> >> >> Bert
> >> >> >>
> >> >> >>
> >> >> >> Bert Gunter
> >> >> >>
> >>
> >>
> >>
> >> --
> >> Sarah Goslee
> >> http://www.stringpage.com
> >> http://www.sarahgoslee.com
> >> http://www.functionaldiversity.org
> >>
> >
> >
> > --
> > Sarah Goslee
> > http://www.stringpage.com
> > http://www.sarahgoslee.com
> > http://www.functionaldiversity.org
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From paulhtremblay at gmail.com  Sat Apr 16 02:58:43 2016
From: paulhtremblay at gmail.com (Paul Tremblay)
Date: Fri, 15 Apr 2016 17:58:43 -0700
Subject: [R] faster way to use filter this
Message-ID: <CAP5QEc5Z_GhHW+66u__9nKxpP8BkoypDXM-Jz1xy7Qj5vgwXcg@mail.gmail.com>

I have the following (simplified) vectors:
index <- c("shoe"  "shirt" "fruit")
cost <- c(100, 50, 2)
data <- c("shirt", "shoe", "vegetable")

I want my outcome to be:

(50, 100, 0)

(shirt => 50, shoe => 100, vegetable => not found, so 0)

I have written the following function:


for (i in custom_list) {
+ this_cost <- cost[index == i]

+ message(this_cost)
+ }


This gives me (50, 100)

I haven't figured out how to use the ifelse. But more importantly, I think
there should be an easier, and faster way to do this with vectors?

Thanks!

Paul

	[[alternative HTML version deleted]]


From sj_style_1125 at outlook.com  Sat Apr 16 04:06:12 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Sat, 16 Apr 2016 02:06:12 +0000
Subject: [R] R [loop statement ]
Message-ID: <KL1PR01MB08871B56834D3D4BC87C329CB5690@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>

hi, i am new in this field.

I am now writing a code in robustness simulation study. I have written a brief code "for loop" for the factor (samples sizes d,std deviation ) , i wish to test them in gamma distribution with equal and unequal skewness, with the above for loop in a single code if possible. Can i ask is that any suitable loop statement for this situation.

This is my ideas ,all the two for loop runs then run for the first set of gamma distribution with equal skewness then store the result,
then,
all the two for loops run again and then run for the second set of gamma distribution with unequal skewness then store the result again.

if-else statement look like is not quite suitable in this situation as it will run one set only.
Please, i hope can get some help here. Thanks.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Apr 16 06:26:14 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 15 Apr 2016 21:26:14 -0700
Subject: [R] help on moving data from local to HDFS using RODBC in R
In-Reply-To: <CALEm3d1Zews0gASe+pgZWa70PzF7F7jmmWN__cnhb46jizSGnQ@mail.gmail.com>
References: <CALEm3d1Zews0gASe+pgZWa70PzF7F7jmmWN__cnhb46jizSGnQ@mail.gmail.com>
Message-ID: <985249AA-F3AE-4471-91B6-FD5FE6B86569@dcn.davis.ca.us>

Why?  RODBC is usable for reading data, but not particularly well adapted for inserting data. So if you have a solution, why are you still looking for one? 
-- 
Sent from my phone. Please excuse my brevity.

On April 15, 2016 2:47:52 PM PDT, Divakar Reddy <divakarreddy.a at gmail.com> wrote:
>Hi,
>
>I have requirement to move the data from Linux local path( ex
> /home/user/sample.txt) to hadoop HDFS using RODBC in R
>
>I knew that we can move the data using rhive comamnds like *rhive.put*
>and *rhive.get
>*but looking for similar commands using RODBC as well.
>
>I would appreciate for your inputs.
>
>Regards,
>Divakar
>Phoenix, USA
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Sat Apr 16 06:58:20 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Fri, 15 Apr 2016 23:58:20 -0500
Subject: [R] Decision Tree and Random Forrest
In-Reply-To: <CAF8bMcapo_G6RTBCa-J35VzOdiPuGsnBzvfbptqDsYPCmjyZQQ@mail.gmail.com>
References: <BLU406-EAS2105F5EFDF041F6D9B77D45CD970@phx.gbl>
	<CAM_vju=KKvpRWetkdHsW1Rxp7X1KPHmd93JEZFFwe1PcFCGf0Q@mail.gmail.com>
	<CA+pG8eORyLnqmW-W4JV+_TGmFx_y1OM3Hz2+MtEWYpZf7OgTEA@mail.gmail.com>
	<CA+pG8eMV=ZXPcG+k1_3ot6WctbXdgyHRJ0=XKt6A_Tj8nedZqA@mail.gmail.com>
	<CA+pG8eML_XAiXvTeb5OgKpO2SGVjaofMWtLa6=cQp+bo3C6PoA@mail.gmail.com>
	<CA+pG8eOgwq7pc+=RXRgWwHOMSoRZeNTuzB0MW8V6C+zyPwJzGQ@mail.gmail.com>
	<CA+pG8eN63T844jeGpwK+F2c7y3ea+ktxU-zqq2Eey+HcnZFDmA@mail.gmail.com>
	<CA+pG8ePrciqkbnR1JS+QTQFCMVNX6xJUiYnhpBbpaWWvV2OgxA@mail.gmail.com>
	<CA+pG8ePxJxubKEz=FzmXKmGnbS7WXySMGs6hF-3N1nsm4RvWqg@mail.gmail.com>
	<CAF8bMcapo_G6RTBCa-J35VzOdiPuGsnBzvfbptqDsYPCmjyZQQ@mail.gmail.com>
Message-ID: <CA+pG8eM=_JVa03YPYEEUH124JX1D86y-HHdvQQwk88Fo138g3g@mail.gmail.com>

Thanks bill that will give the result I would like, however the example I
used is not the actual data I'm working with.  I have 25 or so columns,
each with 1-5 factors and 4 off them are numerical.

On Fri, Apr 15, 2016 at 5:44 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Since you only have 3 predictors, each categorical with a small number of
> categories, you can use expand.grid to make a data.frame containing all
> possible combinations and give that the predict method for your model to
> get all possible predictions.
>
> Something like the following untested code.
>     newdata <- expand.grid(
>         Humidity = levels(Humidity), #(High, Medium,Low)
>         Pending_Chores = levels(Pending_Chores), #(Taxes, None, Laundry,
> Car Maintenance)
>         Wind = levels(Wind)) # (High,Low)
>     newdata$ProbabilityOfPlayingGolf <- predict(fittedModel,
> newdata=newdata)
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Apr 15, 2016 at 3:09 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
>
>> I need the output to have groups and the probability any given record in
>> that group then has of being in the response class. Just like my email in
>> the beginning i need the output that looks like if A and if B and if C
>> then
>> %77 it will be D.  The examples you provided are just simply not similar.
>> They are different and would take interpretation to get what i need.
>> On Apr 14, 2016 1:26 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:
>>
>> > So. Given that the second and third panels of the first figure in the
>> > first link I gave show a decision tree with decision rules at each split
>> > and the number of samples at each direction, what _exactly_ is your
>> > problem?
>> >
>> >
>> >
>> > On Wednesday, April 13, 2016, Michael Eugene <fartzy at hotmail.com>
>> wrote:
>> >
>> >> I still need the output to match my requiremnt in my original post.
>> With
>> >> decision rules "clusters" and probability attached to them.  The
>> examples
>> >> are sort of similar.  You just provided links to general info about
>> trees.
>> >>
>> >>
>> >>
>> >> Sent from my Verizon, Samsung Galaxy smartphone
>> >>
>> >>
>> >> -------- Original message --------
>> >> From: Sarah Goslee <sarah.goslee at gmail.com>
>> >> Date: 4/13/16 8:04 PM (GMT-06:00)
>> >> To: Michael Artz <michaeleartz at gmail.com>
>> >> Cc: "r-help at r-project.org" <R-help at r-project.org>
>> >> Subject: Re: [R] Decision Tree and Random Forrest
>> >>
>> >>
>> >>
>> >> On Wednesday, April 13, 2016, Michael Artz <michaeleartz at gmail.com>
>> >> wrote:
>> >>
>> >> Tjats great that you are familiar and thanks for responding.  Have you
>> >> ever done what I am referring to? I have alteady spent time going
>> through
>> >> links and tutorials about decision trees and random forrests and have
>> even
>> >> used them both before.
>> >>
>> >> Then what specifically is your problem? Both of the tutorials I
>> provided
>> >> show worked examples, as does even the help for rpart. If none of
>> those, or
>> >> your extensive reading, work for your project you will have to be a lot
>> >> more specific about why not.
>> >>
>> >> Sarah
>> >>
>> >>
>> >>
>> >> Mike
>> >> On Apr 13, 2016 5:32 PM, "Sarah Goslee" <sarah.goslee at gmail.com>
>> wrote:
>> >>
>> >> It sounds like you want classification or regression trees. rpart does
>> >> exactly what you describe.
>> >>
>> >> Here's an overview:
>> >> http://www.statmethods.net/advstats/cart.html
>> >>
>> >> But there are a lot of other ways to do the same thing in R, for
>> instance:
>> >> http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/
>> >>
>> >> You can get the same kind of information from random forests, but it's
>> >> less straightforward. If you want a clear set of rules as in your golf
>> >> example, then you need rpart or similar.
>> >>
>> >> Sarah
>> >>
>> >> On Wed, Apr 13, 2016 at 6:02 PM, Michael Artz <michaeleartz at gmail.com>
>> >> wrote:
>> >> > Ah yes I will have to use the predict function.  But the predict
>> >> function
>> >> > will not get me there really.  If I can take the example that I have
>> a
>> >> > model predicting whether or not I will play golf (this is the
>> dependent
>> >> > value), and there are three independent variables Humidity(High,
>> Medium,
>> >> > Low), Pending_Chores(Taxes, None, Laundry, Car Maintenance) and Wind
>> >> (High,
>> >> > Low).  I would like rules like where any record that follows these
>> rules
>> >> > (IF humidity = high AND pending_chores = None AND Wind = High THEN
>> 77%
>> >> > there is probability that play_golf is YES).  I was thinking that
>> random
>> >> > forrest would weight the rules somehow on the collection of trees and
>> >> give
>> >> > a probability.  But if that doesnt make sense, then can you just
>> tell me
>> >> > how to get the decsion rules with one tree and I will work from that.
>> >> >
>> >> > Mike
>> >> >
>> >> > Mike
>> >> >
>> >> > On Wed, Apr 13, 2016 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com
>> >
>> >> wrote:
>> >> >
>> >> >> I think you are missing the point of random forests. But if you just
>> >> >> want to predict using the forest, there is a predict() method that
>> you
>> >> >> can use. Other than that, I certainly don't understand what you
>> mean.
>> >> >> Maybe someone else might.
>> >> >>
>> >> >> Cheers,
>> >> >> Bert
>> >> >>
>> >> >>
>> >> >> Bert Gunter
>> >> >>
>> >> >> "The trouble with having an open mind is that people keep coming
>> along
>> >> >> and sticking things into it."
>> >> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >> >>
>> >> >>
>> >> >> On Wed, Apr 13, 2016 at 2:11 PM, Michael Artz <
>> michaeleartz at gmail.com>
>> >> >> wrote:
>> >> >> > Ok is there a way to do  it with decision tree?  I just need to
>> make
>> >> the
>> >> >> > decision rules. Perhaps I can pick one of the trees used with
>> Random
>> >> >> > Forrest.  I am somewhat familiar already with Random Forrest with
>> >> >> respective
>> >> >> > to bagging and feature sampling and getting the mode from the leaf
>> >> nodes
>> >> >> and
>> >> >> > it being an ensemble technique of many trees.  I am just working
>> >> from the
>> >> >> > perspective that I need decision rules, and I am working backward
>> >> form
>> >> >> that,
>> >> >> > and I need to do it in R.
>> >> >> >
>> >> >> > On Wed, Apr 13, 2016 at 4:08 PM, Bert Gunter <
>> bgunter.4567 at gmail.com
>> >> >
>> >> >> wrote:
>> >> >> >>
>> >> >> >> Nope.
>> >> >> >>
>> >> >> >> Random forests are not decision trees -- they are ensembles
>> >> (forests)
>> >> >> >> of trees. You need to go back and read up on them so you
>> understand
>> >> >> >> how they work. The Hastie/Tibshirani/Friedman "The Elements of
>> >> >> >> Statistical Learning" has a nice explanation, but I'm sure there
>> are
>> >> >> >> lots of good web resources, too.
>> >> >> >>
>> >> >> >> Cheers,
>> >> >> >> Bert
>> >> >> >>
>> >> >> >>
>> >> >> >> Bert Gunter
>> >> >> >>
>> >>
>> >>
>> >>
>> >> --
>> >> Sarah Goslee
>> >> http://www.stringpage.com
>> >> http://www.sarahgoslee.com
>> >> http://www.functionaldiversity.org
>> >>
>> >
>> >
>> > --
>> > Sarah Goslee
>> > http://www.stringpage.com
>> > http://www.sarahgoslee.com
>> > http://www.functionaldiversity.org
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Apr 16 07:08:49 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Apr 2016 22:08:49 -0700
Subject: [R] faster way to use filter this
In-Reply-To: <CAP5QEc5Z_GhHW+66u__9nKxpP8BkoypDXM-Jz1xy7Qj5vgwXcg@mail.gmail.com>
References: <CAP5QEc5Z_GhHW+66u__9nKxpP8BkoypDXM-Jz1xy7Qj5vgwXcg@mail.gmail.com>
Message-ID: <3EAD218E-07FE-4A50-A3D2-FA22A4F49F40@comcast.net>


> On Apr 15, 2016, at 5:58 PM, Paul Tremblay <paulhtremblay at gmail.com> wrote:
> 
> I have the following (simplified) vectors:
> index <- c("shoe"  "shirt" "fruit")
> cost <- c(100, 50, 2)
> data <- c("shirt", "shoe", "vegetable")
> 
> I want my outcome to be:
> 
> (50, 100, 0)
> 
> (shirt => 50, shoe => 100, vegetable => not found, so 0)

 c(cost,0)[ match(index, data, nomatch = length(index)+1) ]
#[1]  50 100   0


> 
> I have written the following function:
> 
> 
> for (i in custom_list) {
> + this_cost <- cost[index == i]
> 
> + message(this_cost)
> + }
> 
> 
> This gives me (50, 100)
> 
> I haven't figured out how to use the ifelse. But more importantly, I think
> there should be an easier, and faster way to do this with vectors?
> 
> Thanks!
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From akhileshsingh.igkv at gmail.com  Sat Apr 16 11:03:04 2016
From: akhileshsingh.igkv at gmail.com (Akhilesh Singh)
Date: Sat, 16 Apr 2016 14:33:04 +0530
Subject: [R] Bug in by() function which works for some FUN argument and
 does not work for others
In-Reply-To: <49C85E5A-AAB2-47BB-AEC4-41ECDC069180@comcast.net>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
	<CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
	<49C85E5A-AAB2-47BB-AEC4-41ECDC069180@comcast.net>
Message-ID: <CACLgfx32KJQY=yWkx_72aS6=vOpACJwY8bG_FuvgFAxMh-wAxA@mail.gmail.com>

Dear All,

I have got your core message, that it is my responsibility to determine
whether any particular function in my version of R satisfies the language
requirements at the time of your use. Jim Albert and Maria Rizzo must have
used their code, which was permitted in the R-code of their time (2012).

Therefore, I have now modified my R-code, as per R-3..2.4 version,
according to my requirement as follows, which is working for my 'brain'
data set, whose output is reproduced below for your information please:

> by(brain[,-1], INDICES=list(Gender=brain$Gender), FUN=function(x,
na.rm=FALSE) sapply(x, mean, na.rm=na.rm), na.rm=TRUE)
Gender: Female
      FSIQ        VIQ        PIQ     Weight     Height  MRI_Count
   111.900    109.450    110.450    137.200     65.765 862654.600
--------------------------------------------------------------------------------------------------
Gender: Male
        FSIQ          VIQ          PIQ       Weight       Height
 MRI_Count
   115.00000    115.25000    111.60000    166.44444     71.43158
954855.40000

With best regards,

Dr. A.K. Singh
Head, Department of Agril. Statistics
Indira Gandhi Krishi Vishwavidyalaya, Raipur
Chhattisgarh, India, PIN-492012
Mobile: +919752620740
Email: akhileshsingh.igkv at gmail.com

On Fri, Apr 15, 2016 at 2:24 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 15, 2016, at 1:16 AM, Akhilesh Singh <
> akhileshsingh.igkv at gmail.com> wrote:
> >
> > Dear All,
> >
> > Thanks for your help. However, I would like to draw your attention to the
> > following:
> >
> > Actually, I was replicating the Example 2.3, using the dataset
> > "brainsize.txt" given in Section 2.3.3 ("Summarize by group") at page 55,
> > of a famous book "R by Example" written by "Jim Albert and Maria Rizzo"
> > published in Springers (2012) in a Use R! Series. The output of the by()
> > function printed in the book is being reproduced below for information to
> > all:
> >
> >> by(data=brain[, -1], INDICES=brain$Gender, FUN=mean, na.rm=TRUE)
> > brain$Gender: Female
> > FSIQ VIQ PIQ Weight Height MRI_Count
> > 111.900 109.450 110.450 137.200 65.765 862654.600
> > ------------------------------------------------------------
> > brain$Gender: Male
> > FSIQ  VIQ    PIQ       Weight    Height   MRI_Count
> > 115.00000 115.25000 111.60000 166.44444 71.43158 954855.40000
> >
> >
> > I do not know how could the writers of the book have produced the above
> > results by by() function.
>
>
> There was in the not-so-distant past a function named `mean.data.frame`
> which would have "worked" in that instance. That function was removed. I
> thought you could  find the exact date of that action by searching the NEWS
> but failed. Reviewing the citations of `mean.data.frame` in the r-help
> archives I see that users were being warned that its use was deprecated in
> mid 2012.  It's very possible that the authors of a book in 2012 were using
> an earlier version of R that had that facility available to them before it
> was deprecated. With a more than current version of R 3.3.0 and a modest
> number of loaded packages I see this:
>
> > methods(mean)
>  [1] mean,ANY-method          mean,Matrix-method       mean,Raster-method
>  [4] mean,sparseMatrix-method mean,sparseVector-method mean.Date
>  [7] mean.default             mean.difftime            mean.POSIXct
> [10] mean.POSIXlt             mean.yearmon*            mean.yearqtr*
> [13] mean.zoo*
>
> It is your responsibility to determine whether any particular function in
> your version of R satisfies the language requirements at the time of your
> use. Jim Albert and Maria Rizzo do not set the standards for what is an
> evolving piece of software.
>
> --
> David.
>
>
> > But, when I could not reproduce these results,
> > then I thought that probably, this could possibly be due to some missing
> > values NA's in Weight and Height variables. Then I tried the above code
> for
> > the "mtcars" dataset for INDICES=mtcars$am. When I found the same results
> > here too, then I reported the case in "r-help at R-project.org".
> >
> > With best regards,
> >
> > Dr. A.K. Singh
> > Head, Department of Agril. Statistics
> > Indira Gandhi Krishi Vishwavidyalaya, Raipur
> > Chhattisgarh, India, PIN-492012
> > Mobile: +919752620740
> > Email: akhileshsingh.igkv at gmail.com
> >
> > On Fri, Apr 15, 2016 at 3:06 AM, Adrian Du?a <dusa.adrian at unibuc.ro>
> wrote:
> >
> >> I think you are not using the best function for what your intentions
> are.
> >> Try:
> >>
> >>> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
> >> : 0
> >>        mpg         cyl        disp          hp        drat          wt
> >>     qsec          vs
> >> 17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
> >> 18.1831579   0.3684211
> >>         am        gear        carb
> >>  0.0000000   3.2105263   2.7368421
> >>
> >>
> ---------------------------------------------------------------------------
> >> : 1
> >>        mpg         cyl        disp          hp        drat          wt
> >>     qsec          vs
> >> 24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
> >> 17.3600000   0.5384615
> >>         am        gear        carb
> >>  1.0000000   4.3846154   2.9230769
> >>
> >> See the difference between colMeans() and mean() in their respective
> help
> >> files.
> >> Hth,
> >> Adrian
> >>
> >> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
> >> akhileshsingh.igkv at gmail.com> wrote:
> >>
> >>> Dear Sirs,
> >>>
> >>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
> >>> Chhattisgarh, India.
> >>>
> >>> While taking classes, I found the *by() *function producing following
> >>> error
> >>>
> >>> when I use FUN=mean or median and some other functions, however,
> >>> FUN=summary works.
> >>>
> >>> Given below is the output of the example I used on a built-in dataset
> >>> "mtcars", along with error message reproduced herewith:
> >>>
> >>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
> >>> : 0
> >>> [1] NA
> >>> ------------------------------------------------------------
> >>> : 1
> >>> [1] NA
> >>> Warning messages:
> >>> 1: In mean.default(data[x, , drop = FALSE], ...) :
> >>>  argument is not numeric or logical: returning NA
> >>> 2: In mean.default(data[x, , drop = FALSE], ...) :
> >>>  argument is not numeric or logical: returning NA
> >>>
> >>> However, the same by() function works for FUN=summary, given below is
> the
> >>> output:
> >>>
> >>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
> >>> : 0
> >>>      mpg             cyl             disp             hp
> >>> Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
> >>> 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
> >>> Median :17.30   Median :8.000   Median :275.8   Median :175.0
> >>> Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
> >>> 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
> >>> Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
> >>>      drat             wt             qsec             vs
>  am
> >>>
> >>> Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.
> >>> :0
> >>>
> >>> 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st
> >>> Qu.:0
> >>>
> >>> Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median
> >>> :0
> >>>
> >>> Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean
> >>> :0
> >>>
> >>> 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd
> >>> Qu.:0
> >>>
> >>> Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.
> >>> :0
> >>>
> >>>      gear            carb
> >>> Min.   :3.000   Min.   :1.000
> >>> 1st Qu.:3.000   1st Qu.:2.000
> >>> Median :3.000   Median :3.000
> >>> Mean   :3.211   Mean   :2.737
> >>> 3rd Qu.:3.000   3rd Qu.:4.000
> >>> Max.   :4.000   Max.   :4.000
> >>> ------------------------------------------------------------
> >>> : 1
> >>>      mpg             cyl             disp             hp
>  drat
> >>>
> >>> Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
> >>> :3.54
> >>> 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
> >>> Qu.:3.85
> >>> Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
> >>> :4.08
> >>> Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
> >>> :4.05
> >>> 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
> >>> Qu.:4.22
> >>> Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
> >>> :4.93
> >>>       wt             qsec             vs               am         gear
> >>>
> >>> Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.
> >>> :4.000
> >>>
> >>> 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st
> >>> Qu.:4.000
> >>>
> >>> Median :2.320   Median :17.02   Median :1.0000   Median :1   Median
> >>> :4.000
> >>>
> >>> Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean
> >>> :4.385
> >>>
> >>> 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd
> >>> Qu.:5.000
> >>>
> >>> Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.
> >>> :5.000
> >>>
> >>>      carb
> >>> Min.   :1.000
> >>> 1st Qu.:1.000
> >>> Median :2.000
> >>> Mean   :2.923
> >>> 3rd Qu.:4.000
> >>> Max.   :8.000
> >>>>
> >>>
> >>> I am using the latest version of *R-3.2.4 on Windows*, however, this
> error
> >>> is being generated in the previous version too,
> >>>
> >>> Hope this reporting will get serious attention in debugging.
> >>>
> >>> With best regards,
> >>>
> >>> Dr. A.K. Singh
> >>> Head, Department of Agril. Statistics
> >>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> >>> Chhattisgarh, India, PIN-492012
> >>> Mobile: +919752620740
> >>> Email: akhileshsingh.igkv at gmail.com
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>
> >> --
> >> Adrian Dusa
> >> University of Bucharest
> >> Romanian Social Data Archive
> >> Soseaua Panduri nr.90
> >> 050663 Bucharest sector 5
> >> Romania
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From d.maiori at windowslive.com  Sat Apr 16 11:39:47 2016
From: d.maiori at windowslive.com (Dominik Maiori)
Date: Sat, 16 Apr 2016 11:39:47 +0200
Subject: [R] Problem: No p-value for a point-baserial correlation with R
Message-ID: <DUB127-W91F48CA1C6FFC1EC27932087690@phx.gbl>

Dear community
 
I'm pretty new to R and I'm trying to do a Point-baserial correlation for a nominal dichotomous variable with a interval scaled variable. It works fine, but the output just shows me the correlation and nothing else (p-Value would be important). 
 
I tried it with the following codes:
 
- biseral.cor()
- cor.biseral()
- I also tried a polyserial() I've found on this question page: http://stackoverflow.com/questions/35880910/point-biserial-and-p-value
Problem: It's not working (telling me y has fewer than 2 levels) and it would also be for a ordinal dichotomous variable, but I only have a nominal dichotomous variable. 
 
In the forum if found following Syntax that I've tried out: https://stat.ethz.ch/pipermail/r-help/2003-April/031852.html
It seams to work because I don't get any error messages but I'm not getting an output either.
 
I'm really thankful for every help I could get on this topic or tips where I can find out and learn how to find a correlation with a p-value in R for a nominal dichotomous and an interval scaled variable.
Thanks in advance and have a nice weekend!
 		 	   		  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Apr 16 12:44:43 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 16 Apr 2016 20:44:43 +1000
Subject: [R] R [loop statement ]
In-Reply-To: <KL1PR01MB08871B56834D3D4BC87C329CB5690@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB08871B56834D3D4BC87C329CB5690@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fU8fV_8i-o5yV==GPgRvc9uCVARRbs1GD=MCW=+cFy0Tg@mail.gmail.com>

Hi tan sj,
It is by no means easy to figure out what you want without the code,
but If I read your message correctly, you can run the loops either
way. When you have nested loops producing output, it is often a good
idea to include the parameters for each run in the output as well as
the result so that you don't get the results mixed up:

cat(N,mean,...,p.value,"\n")

Jim


On Sat, Apr 16, 2016 at 12:06 PM, tan sj <sj_style_1125 at outlook.com> wrote:
> hi, i am new in this field.
>
> I am now writing a code in robustness simulation study. I have written a brief code "for loop" for the factor (samples sizes d,std deviation ) , i wish to test them in gamma distribution with equal and unequal skewness, with the above for loop in a single code if possible. Can i ask is that any suitable loop statement for this situation.
>
> This is my ideas ,all the two for loop runs then run for the first set of gamma distribution with equal skewness then store the result,
> then,
> all the two for loops run again and then run for the second set of gamma distribution with unequal skewness then store the result again.
>
> if-else statement look like is not quite suitable in this situation as it will run one set only.
> Please, i hope can get some help here. Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sat Apr 16 14:41:33 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 16 Apr 2016 12:41:33 +0000
Subject: [R] Problem: No p-value for a point-baserial correlation with R
In-Reply-To: <DUB127-W91F48CA1C6FFC1EC27932087690@phx.gbl>
References: <DUB127-W91F48CA1C6FFC1EC27932087690@phx.gbl>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F6D624@FHSDB2D11-2.csu.mcmaster.ca>

Dear Dominik,

There's not enough information here to answer your question: You don't show the commands you used, nor the output that was produced, and you don't share your data. A good guess, however, is that there is only one level of the factor, perhaps after missing data are removed, and so it's not possible to compute a biserial correlation. 

By the way, if the dichotomous factor is really nominal, then it doesn't make sense to compute a biserial correlation, which assumes that there's a latent continuous and normally distributed variable that has been dichotomized at an unknown threshold.

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
web: socserv.mcmaster.ca/jfox


________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Dominik Maiori [d.maiori at windowslive.com]
Sent: April 16, 2016 5:39 AM
To: r-help at r-project.org
Subject: [R] Problem: No p-value for a point-baserial correlation with R

Dear community

I'm pretty new to R and I'm trying to do a Point-baserial correlation for a nominal dichotomous variable with a interval scaled variable. It works fine, but the output just shows me the correlation and nothing else (p-Value would be important).

I tried it with the following codes:

- biseral.cor()
- cor.biseral()
- I also tried a polyserial() I've found on this question page: http://stackoverflow.com/questions/35880910/point-biserial-and-p-value
Problem: It's not working (telling me y has fewer than 2 levels) and it would also be for a ordinal dichotomous variable, but I only have a nominal dichotomous variable.

In the forum if found following Syntax that I've tried out: https://stat.ethz.ch/pipermail/r-help/2003-April/031852.html
It seams to work because I don't get any error messages but I'm not getting an output either.

I'm really thankful for every help I could get on this topic or tips where I can find out and learn how to find a correlation with a p-value in R for a nominal dichotomous and an interval scaled variable.
Thanks in advance and have a nice weekend!

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Sat Apr 16 14:45:14 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sat, 16 Apr 2016 12:45:14 +0000 (UTC)
Subject: [R] a replace for subset
References: <1254096290.2451184.1460810714645.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1254096290.2451184.1460810714645.JavaMail.yahoo@mail.yahoo.com>

Hi, 
I have a data set (mydata), which a part of this is like the following: 


'data.frame':   36190 obs. of 16 variables: 
$ RE                    : int  38 41 11 67 30 18 38 41 41 30 ... 
$ LU                     : int  4200 3330 530 4500 3000 1790 4700 3400 3640 4000 ... 
$ COUNTRY        : Factor w/ 4 levels "DE","FR","JP", "FR"? 
$Light                  : Factor w/2 levels   "ON","OFF","ON", ?. 
$OR                     : Factor w/2 levels   "S","T","S",?. 
$PAT                  : Factor w/3 levels   "low", "high", "middle",?. 


Now I want to plot RE vs LU with ggplot2 for all the possible cases, I know how to do subsetting for the data but I want to know is there any shorter way to do that? For example I want to have a plot for RE vs LU for (COUNTRY= FR, Light=off, OR=S, PAT=low) and one for (COUNTRY= FR, Light=on, OR=S, PAT=high) and ?., as you see doing subset is time consuming, is there any other way? 
Thank you for any help. 
Elahe


From james.whanger at gmail.com  Sat Apr 16 15:01:46 2016
From: james.whanger at gmail.com (James C. Whanger)
Date: Sat, 16 Apr 2016 09:01:46 -0400
Subject: [R] a replace for subset
In-Reply-To: <1254096290.2451184.1460810714645.JavaMail.yahoo@mail.yahoo.com>
References: <1254096290.2451184.1460810714645.JavaMail.yahoo.ref@mail.yahoo.com>
	<1254096290.2451184.1460810714645.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGG=QuG7bnsZF-aDfdei7Pc2VACZQANR3GFkMk+Y4s3S4cvNtQ@mail.gmail.com>

Would facet_wrap or facet_grid give you what you want?

On Sat, Apr 16, 2016 at 8:45 AM, ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi,
> I have a data set (mydata), which a part of this is like the following:
>
>
> 'data.frame':   36190 obs. of 16 variables:
> $ RE                    : int  38 41 11 67 30 18 38 41 41 30 ...
> $ LU                     : int  4200 3330 530 4500 3000 1790 4700 3400
> 3640 4000 ...
> $ COUNTRY        : Factor w/ 4 levels "DE","FR","JP", "FR"?
> $Light                  : Factor w/2 levels   "ON","OFF","ON", ?.
> $OR                     : Factor w/2 levels   "S","T","S",?.
> $PAT                  : Factor w/3 levels   "low", "high", "middle",?.
>
>
> Now I want to plot RE vs LU with ggplot2 for all the possible cases, I
> know how to do subsetting for the data but I want to know is there any
> shorter way to do that? For example I want to have a plot for RE vs LU for
> (COUNTRY= FR, Light=off, OR=S, PAT=low) and one for (COUNTRY= FR, Light=on,
> OR=S, PAT=high) and ?., as you see doing subset is time consuming, is there
> any other way?
> Thank you for any help.
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
*James C. Whanger*

	[[alternative HTML version deleted]]


From haenlein at escpeurope.eu  Sat Apr 16 15:16:20 2016
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Sat, 16 Apr 2016 15:16:20 +0200
Subject: [R] Social Network Simulation
Message-ID: <CAOyz9G5uceOub7eoFxB2hzyRWmdct=V=OG6n6QtoXsVQVP8ATg@mail.gmail.com>

Dear all,

I am trying to simulate a series of networks that have characteristics
similar to real life social networks. Specifically I am interested in
networks that have (a) a reasonable degree of clustering (as measured by
the transitivity function in igraph) and (b) a reasonable degree of degree
polarization (as measured by the average degree of the top 10% nodes with
highest degree divided by the overall average degree).

Right now I am using two functions from irgaph (sample_pa and
sample_smallworld) but these are not ideal since they only allow me to vary
one of the two characteristics. Either the network has good clustering but
not enough polarization or the other way round.

I looked around and I found some network algorithms that solve the problem
(E.g., Jackson and Rogers, Meeting Strangers and Friends of Friends), but I
did not find their implemented in an R package. I also found the R package
NetSim which seems to be in this spirit, but I cannot get it to work.

Could anyone point me to an R library that I could check out? I do not care
much about the specific algorithm used as long as it allows me to vary
clustering and degree polarization in certain ranges.

Thanks,

Michael


Michael Haenlein
Professor of Marketing
ESCP Europe, Paris

	[[alternative HTML version deleted]]


From dan.abner99 at gmail.com  Sat Apr 16 15:18:39 2016
From: dan.abner99 at gmail.com (Dan Abner)
Date: Sat, 16 Apr 2016 09:18:39 -0400
Subject: [R] Equivalent in R of the Contains operator in SAS
Message-ID: <CAPRGo-=Fi-2XxPp+4m7TjwD3-Nj3V83KPQU8jTdw8uh-2C0rdw@mail.gmail.com>

Hi all,

I want to select all variables in the data.frame with a name that
includes are certain string. Something like the following:

merge3[,names(merge3) %in% c("Email","Email.x")]

But there are too many variations on the Email variable names to list them all.

Can anyone advise?

Thanks!

Dan


From pdalgd at gmail.com  Sat Apr 16 15:30:36 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 16 Apr 2016 15:30:36 +0200
Subject: [R] Equivalent in R of the Contains operator in SAS
In-Reply-To: <CAPRGo-=Fi-2XxPp+4m7TjwD3-Nj3V83KPQU8jTdw8uh-2C0rdw@mail.gmail.com>
References: <CAPRGo-=Fi-2XxPp+4m7TjwD3-Nj3V83KPQU8jTdw8uh-2C0rdw@mail.gmail.com>
Message-ID: <428B4C92-79AA-4186-933A-57C9F22846F9@gmail.com>

Check the string matching functions, e.g. grepl().

-pd

> On 16 Apr 2016, at 15:18 , Dan Abner <dan.abner99 at gmail.com> wrote:
> 
> Hi all,
> 
> I want to select all variables in the data.frame with a name that
> includes are certain string. Something like the following:
> 
> merge3[,names(merge3) %in% c("Email","Email.x")]
> 
> But there are too many variations on the Email variable names to list them all.
> 
> Can anyone advise?
> 
> Thanks!
> 
> Dan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chalabi.elahe at yahoo.de  Sat Apr 16 15:42:46 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sat, 16 Apr 2016 13:42:46 +0000 (UTC)
Subject: [R] a replace for subset
In-Reply-To: <CAGG=QuG7bnsZF-aDfdei7Pc2VACZQANR3GFkMk+Y4s3S4cvNtQ@mail.gmail.com>
References: <CAGG=QuG7bnsZF-aDfdei7Pc2VACZQANR3GFkMk+Y4s3S4cvNtQ@mail.gmail.com>
Message-ID: <1956844026.2480696.1460814166944.JavaMail.yahoo@mail.yahoo.com>

-Thank you James, well the problem of my type of data is that there can be many possible subsets and therefore plots, and I want to automatically generate them, and facet_wrap does not give me all the possible cases




On Saturday, April 16, 2016 6:01 AM, James C. Whanger <james.whanger at gmail.com> wrote:



Would facet_wrap or facet_grid give you what you want?


On Sat, Apr 16, 2016 at 8:45 AM, ch.elahe via R-help <r-help at r-project.org> wrote:

Hi,
>I have a data set (mydata), which a part of this is like the following:
>
>
>'data.frame':   36190 obs. of 16 variables:
>$ RE                    : int  38 41 11 67 30 18 38 41 41 30 ...
>$ LU                     : int  4200 3330 530 4500 3000 1790 4700 3400 3640 4000 ...
>$ COUNTRY        : Factor w/ 4 levels "DE","FR","JP", "FR"?
>$Light                  : Factor w/2 levels   "ON","OFF","ON", ?.
>$OR                     : Factor w/2 levels   "S","T","S",?.
>$PAT                  : Factor w/3 levels   "low", "high", "middle",?.
>
>
>Now I want to plot RE vs LU with ggplot2 for all the possible cases, I know how to do subsetting for the data but I want to know is there any shorter way to do that? For example I want to have a plot for RE vs LU for (COUNTRY= FR, Light=off, OR=S, PAT=low) and one for (COUNTRY= FR, Light=on, OR=S, PAT=high) and ?., as you see doing subset is time consuming, is there any other way?
>Thank you for any help.
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


-- 

James C. Whanger


From jrkrideau at inbox.com  Sat Apr 16 15:54:44 2016
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 16 Apr 2016 05:54:44 -0800
Subject: [R] Problem: No p-value for a point-baserial correlation with R
In-Reply-To: <DUB127-W91F48CA1C6FFC1EC27932087690@phx.gbl>
Message-ID: <5BB9C797A9E.000002FEjrkrideau@inbox.com>

Hi Dominik
Welcome to R-help 

Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html for some suggestions on how to ask questions here.

In particular we probably need to know what packages have the biseral.cor() & cor.biseral() functions and some sample data.

Read the part about dput() carefully. This is the best way to provide sample data to R-help.

BTW try a str(mydata) and check to see that you have the factor levels you think you do.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: d.maiori at windowslive.com
> Sent: Sat, 16 Apr 2016 11:39:47 +0200
> To: r-help at r-project.org
> Subject: [R] Problem: No p-value for a point-baserial correlation with R
> 
> Dear community
> 
> I'm pretty new to R and I'm trying to do a Point-baserial correlation for
> a nominal dichotomous variable with a interval scaled variable. It works
> fine, but the output just shows me the correlation and nothing else
> (p-Value would be important).
> 
> I tried it with the following codes:
> 
> - biseral.cor()
> - cor.biseral()
> - I also tried a polyserial() I've found on this question page:
> http://stackoverflow.com/questions/35880910/point-biserial-and-p-value
> Problem: It's not working (telling me y has fewer than 2 levels) and it
> would also be for a ordinal dichotomous variable, but I only have a
> nominal dichotomous variable.
> 
> In the forum if found following Syntax that I've tried out:
> https://stat.ethz.ch/pipermail/r-help/2003-April/031852.html
> It seams to work because I don't get any error messages but I'm not
> getting an output either.
> 
> I'm really thankful for every help I could get on this topic or tips
> where I can find out and learn how to find a correlation with a p-value
> in R for a nominal dichotomous and an interval scaled variable.
> Thanks in advance and have a nice weekend!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jdnewmil at dcn.davis.ca.us  Sat Apr 16 15:55:45 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 16 Apr 2016 06:55:45 -0700 (PDT)
Subject: [R] a replace for subset
In-Reply-To: <1254096290.2451184.1460810714645.JavaMail.yahoo@mail.yahoo.com>
References: <1254096290.2451184.1460810714645.JavaMail.yahoo.ref@mail.yahoo.com>
	<1254096290.2451184.1460810714645.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1604160638530.18760@pedal.dcn.davis.ca.us>

Use the split function to automatically create a list of pre-subsetted 
data frames, and then generate your output however you wish to. For 
example (using Jim Lemon's sample data generator):

library(ggplot2)

mydata <- data.frame( RE = sample( 5:50, 100, TRUE)
                     , LU = sample( 1500:4500, 100 )
                     , COUNTRY = factor( sample( c( "DE","FR","JP","AU")
                                               , 100
                                               , TRUE
                                               )
                                       )
                     , Light = factor( sample( c( "ON", "OFF" )
                                             , 100
                                             , TRUE
                                             )
                                     )
                     , OR = factor( sample( c( "S", "T" )
                                          , 100
                                          , TRUE
                                          )
                                  )
                     , PAT = factor( sample( c( "low", "high", "middle" )
                                           ,100
                                           ,TRUE
                                           )
                                   )
                     )
# split wants you to specify a list of columns to create unique
# groups by;
# data frames are lists of columns;
# data frame indexing lets you specify a subset of columns
mydataList0 <- split( mydata
                     , mydata[ , c( "COUNTRY", "Light" ) ]
                     )
# you should use the str() function frequently in an interactive
# fashion to help you understand the data you are working with:
str( mydataList0 )

# if you try to specify a single column as a subset of columns,
# R will by default forget the "list of" aspect... to keep it, use 
# drop=FALSE
mydataList <- split( mydata
                    , mydata[ , c( "COUNTRY" ), drop = FALSE ]
                    )

# I happen to like packing information into a single plot where possible.
# Since you did not provide a minimial reproducible example, I cannot
# tell whether this will work for you. You can use some variant of 
# mydataList0 if you don't like this approach.
for ( idx in seq_along( mydataList ) ) {
     print( ggplot( mydataList[[ idx ]], aes( x=RE, y=LU, shape=Light ) ) +
             geom_point() +
             facet_grid( PAT ~ OR ) +
             ggtitle( paste( "Country ="
                           , mydataList[[ idx ]][1,"COUNTRY"]))
     )
}

For future reference, the Posting Guide mentions several good practices 
for asking questions online that will help you understand your own problem 
better as well as making it easier for us to provide answers.

On Sat, 16 Apr 2016, ch.elahe via R-help wrote:

> Hi, 
> I have a data set (mydata), which a part of this is like the following: 
>
>
> 'data.frame':   36190 obs. of 16 variables: 
> $ RE                    : int  38 41 11 67 30 18 38 41 41 30 ... 
> $ LU                     : int  4200 3330 530 4500 3000 1790 4700 3400 3640 4000 ... 
> $ COUNTRY        : Factor w/ 4 levels "DE","FR","JP", "FR"? 
> $Light                  : Factor w/2 levels   "ON","OFF","ON", ?. 
> $OR                     : Factor w/2 levels   "S","T","S",?. 
> $PAT                  : Factor w/3 levels   "low", "high", "middle",?. 
>
>
> Now I want to plot RE vs LU with ggplot2 for all the possible cases, I know how to do subsetting for the data but I want to know is there any shorter way to do that? For example I want to have a plot for RE vs LU for (COUNTRY= FR, Light=off, OR=S, PAT=low) and one for (COUNTRY= FR, Light=on, OR=S, PAT=high) and ?., as you see doing subset is time consuming, is there any other way? 
> Thank you for any help. 
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Sat Apr 16 16:03:22 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 16 Apr 2016 07:03:22 -0700 (PDT)
Subject: [R] a replace for subset
In-Reply-To: <1956844026.2480696.1460814166944.JavaMail.yahoo@mail.yahoo.com>
References: <CAGG=QuG7bnsZF-aDfdei7Pc2VACZQANR3GFkMk+Y4s3S4cvNtQ@mail.gmail.com>
	<1956844026.2480696.1460814166944.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1604160656360.18760@pedal.dcn.davis.ca.us>

On Sat, 16 Apr 2016, ch.elahe via R-help wrote:

> -Thank you James, well the problem of my type of data is that there can 
> be many possible subsets and therefore plots, and I want to 
> automatically generate them, and facet_wrap does not give me all the 
> possible cases

Not true.

It may get cramped, but it does give you all of the cases listed in the 
levels of the factor you plot with. If you specify a vector of character 
strings then ggplot will automatically convert it to a factor using only 
those cases present in the data. You can use the "factor" function to 
specify how you want the data represented more precisely than this 
automatic conversion will represent it. Read ?factor.

Note that if you have missing cases throughout, you may encounter 
difficulties plotting some graphs due to not having any data.

>
> On Saturday, April 16, 2016 6:01 AM, James C. Whanger <james.whanger at gmail.com> wrote:
>
> Would facet_wrap or facet_grid give you what you want?
>
> On Sat, Apr 16, 2016 at 8:45 AM, ch.elahe via R-help <r-help at r-project.org> wrote:
>
> Hi,
>> I have a data set (mydata), which a part of this is like the following:
>>
>>
>> 'data.frame':   36190 obs. of 16 variables:
>> $ RE                    : int  38 41 11 67 30 18 38 41 41 30 ...
>> $ LU                     : int  4200 3330 530 4500 3000 1790 4700 3400 3640 4000 ...
>> $ COUNTRY        : Factor w/ 4 levels "DE","FR","JP", "FR"?
>> $Light                  : Factor w/2 levels   "ON","OFF","ON", ?.
>> $OR                     : Factor w/2 levels   "S","T","S",?.
>> $PAT                  : Factor w/3 levels   "low", "high", "middle",?.
>>
>>
>> Now I want to plot RE vs LU with ggplot2 for all the possible cases, I 
>> know how to do subsetting for the data but I want to know is there any 
>> shorter way to do that? For example I want to have a plot for RE vs LU 
>> for (COUNTRY= FR, Light=off, OR=S, PAT=low) and one for (COUNTRY= FR, 
>> Light=on, OR=S, PAT=high) and ?., as you see doing subset is time 
>> consuming, is there any other way?
>> Thank you for any help.
>> Elahe

[...]

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From bgunter.4567 at gmail.com  Sat Apr 16 16:47:37 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 16 Apr 2016 07:47:37 -0700
Subject: [R] faster way to use filter this
In-Reply-To: <CAP5QEc5Z_GhHW+66u__9nKxpP8BkoypDXM-Jz1xy7Qj5vgwXcg@mail.gmail.com>
References: <CAP5QEc5Z_GhHW+66u__9nKxpP8BkoypDXM-Jz1xy7Qj5vgwXcg@mail.gmail.com>
Message-ID: <CAGxFJbT2C8eTdKRRx8Qq7ymbzqR_KdLAd5=9ESproK0a82h_1A@mail.gmail.com>

You neglected the commas in your index expression!

See ?match

as in:

> out <- cost[match(data,index)]
> out
[1]  50 100  NA

(and "data" is a bad name to use as there is already a data() function in R).

Please DO go through an R tutorial or two to learn about some of these
basic, useful  R capabilities. There are many good ones on the Web.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 15, 2016 at 5:58 PM, Paul Tremblay <paulhtremblay at gmail.com> wrote:
> I have the following (simplified) vectors:
> index <- c("shoe"  "shirt" "fruit")
> cost <- c(100, 50, 2)
> data <- c("shirt", "shoe", "vegetable")
>
> I want my outcome to be:
>
> (50, 100, 0)
>
> (shirt => 50, shoe => 100, vegetable => not found, so 0)
>
> I have written the following function:
>
>
> for (i in custom_list) {
> + this_cost <- cost[index == i]
>
> + message(this_cost)
> + }
>
>
> This gives me (50, 100)
>
> I haven't figured out how to use the ifelse. But more importantly, I think
> there should be an easier, and faster way to do this with vectors?
>
> Thanks!
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From attenka at utu.fi  Sat Apr 16 14:47:43 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Sat, 16 Apr 2016 15:47:43 +0300
Subject: [R] Mean of hexadecimal numbers
Message-ID: <5712346F.4050003@utu.fi>

Hi,

How would you calculate the "mean colour" of several colours, for 
example c("#FF7C00","#00BF40","#FFFF00")?

Yours,

Atte Tenkanen


From bgunter.4567 at gmail.com  Sat Apr 16 17:20:33 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 16 Apr 2016 08:20:33 -0700
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <5712346F.4050003@utu.fi>
References: <5712346F.4050003@utu.fi>
Message-ID: <CAGxFJbS8UP8mkokz5xsRpFtw5pN2rK8OaVUQLk=WB3pSt4L0=g@mail.gmail.com>

?strtoi

You'll have to remove the "#" first, e.g. via substring()

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 16, 2016 at 5:47 AM, Atte Tenkanen <attenka at utu.fi> wrote:
> Hi,
>
> How would you calculate the "mean colour" of several colours, for example
> c("#FF7C00","#00BF40","#FFFF00")?
>
> Yours,
>
> Atte Tenkanen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Apr 16 17:27:01 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 16 Apr 2016 08:27:01 -0700
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <CAGxFJbS8UP8mkokz5xsRpFtw5pN2rK8OaVUQLk=WB3pSt4L0=g@mail.gmail.com>
References: <5712346F.4050003@utu.fi>
	<CAGxFJbS8UP8mkokz5xsRpFtw5pN2rK8OaVUQLk=WB3pSt4L0=g@mail.gmail.com>
Message-ID: <CAGxFJbRA7X=yHpdGWP1Piz1H6B8Wm0Q0JcaJkfNhJUwzTuFRig@mail.gmail.com>

... and if you need to convert back:  ?as.hexmode


-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 16, 2016 at 8:20 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ?strtoi
>
> You'll have to remove the "#" first, e.g. via substring()
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Apr 16, 2016 at 5:47 AM, Atte Tenkanen <attenka at utu.fi> wrote:
>> Hi,
>>
>> How would you calculate the "mean colour" of several colours, for example
>> c("#FF7C00","#00BF40","#FFFF00")?
>>
>> Yours,
>>
>> Atte Tenkanen
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Apr 16 17:56:18 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 16 Apr 2016 08:56:18 -0700
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <CAGxFJbRA7X=yHpdGWP1Piz1H6B8Wm0Q0JcaJkfNhJUwzTuFRig@mail.gmail.com>
References: <5712346F.4050003@utu.fi>
	<CAGxFJbS8UP8mkokz5xsRpFtw5pN2rK8OaVUQLk=WB3pSt4L0=g@mail.gmail.com>
	<CAGxFJbRA7X=yHpdGWP1Piz1H6B8Wm0Q0JcaJkfNhJUwzTuFRig@mail.gmail.com>
Message-ID: <CAF8bMcYx=mHPq8nWdn9D6uXn50MoebLVxeYpAhw3wfHJfeD8uQ@mail.gmail.com>

Since these are color strings, you can use functions in the grDevices
package (other others) to manipulate them.  E.g., you can convert them
to various color spaces and perhaps use the mean in one of those
spaces as your 'average color'.

  > myColors <- c(One="#FF7C00",Two="#00BF40",Three="#FFFF00")
  > col2rgb(myColors)
        One Two Three
  red   255   0   255
  green 124 191   255
  blue    0  64     0
  > rgb2hsv(col2rgb(myColors))
           One       Two     Three
  h 0.08104575 0.3891798 0.1666667
  s 1.00000000 1.0000000 1.0000000
  v 1.00000000 0.7490196 1.0000000



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Apr 16, 2016 at 8:27 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... and if you need to convert back:  ?as.hexmode
>
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Apr 16, 2016 at 8:20 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > ?strtoi
> >
> > You'll have to remove the "#" first, e.g. via substring()
> >
> > -- Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Sat, Apr 16, 2016 at 5:47 AM, Atte Tenkanen <attenka at utu.fi> wrote:
> >> Hi,
> >>
> >> How would you calculate the "mean colour" of several colours, for
> example
> >> c("#FF7C00","#00BF40","#FFFF00")?
> >>
> >> Yours,
> >>
> >> Atte Tenkanen
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Apr 16 18:03:56 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 16 Apr 2016 12:03:56 -0400
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <5712346F.4050003@utu.fi>
References: <5712346F.4050003@utu.fi>
Message-ID: <5712626C.2090800@gmail.com>

On 16/04/2016 8:47 AM, Atte Tenkanen wrote:
> Hi,
>
> How would you calculate the "mean colour" of several colours, for
> example c("#FF7C00","#00BF40","#FFFF00")?
>

Bert answered your subject line question.  Your text is asking something 
else:  if those are colours, you don't want to treat each of them as a 
single integer.

A simple-minded approach would split them into 3 hex numbers, and 
average those (using Bert's solution).

A more sophisticated approach would take into account that they are 
really colours.  You could probably put together something using the 
colorRamp or colorRampPalette functions to average in perception space. 
  For example,

# Average the 1st two by taking the middle colour of a 3 colour palette
x <- colorRampPalette(c("#FF7C00","#00BF40"), space = "Lab")(3)[2]

# Average in the third by taking the 2nd of a 4 colour palette, so x
# gets twice the weight
colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]

Duncan Murdoch


From bob at rudis.net  Sat Apr 16 19:53:28 2016
From: bob at rudis.net (boB Rudis)
Date: Sat, 16 Apr 2016 13:53:28 -0400
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <5712626C.2090800@gmail.com>
References: <5712346F.4050003@utu.fi> <5712626C.2090800@gmail.com>
Message-ID: <CAJ4QxaNKkdZnKffyBAxpV7R4xY9cfnnf=58MxMAVUZyipm32yg@mail.gmail.com>

grDevices has `convertColor()` and the `colorspace` has other
functions that can convert from RBG to Lab space. You should convert
the RGB colors to Lab and average them that way (or us other functions
to convert to HSL or HSV). It all depends on what you are trying to
accomplish with the "average" color determination.

-Bob

On Sat, Apr 16, 2016 at 12:03 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 16/04/2016 8:47 AM, Atte Tenkanen wrote:
>>
>> Hi,
>>
>> How would you calculate the "mean colour" of several colours, for
>> example c("#FF7C00","#00BF40","#FFFF00")?
>>
>
> Bert answered your subject line question.  Your text is asking something
> else:  if those are colours, you don't want to treat each of them as a
> single integer.
>
> A simple-minded approach would split them into 3 hex numbers, and average
> those (using Bert's solution).
>
> A more sophisticated approach would take into account that they are really
> colours.  You could probably put together something using the colorRamp or
> colorRampPalette functions to average in perception space.  For example,
>
> # Average the 1st two by taking the middle colour of a 3 colour palette
> x <- colorRampPalette(c("#FF7C00","#00BF40"), space = "Lab")(3)[2]
>
> # Average in the third by taking the 2nd of a 4 colour palette, so x
> # gets twice the weight
> colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Apr 16 20:15:51 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 16 Apr 2016 14:15:51 -0400
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <57126969.6090005@utu.fi>
References: <5712346F.4050003@utu.fi> <5712626C.2090800@gmail.com>
	<57126969.6090005@utu.fi>
Message-ID: <57128157.7020000@gmail.com>

On 16/04/2016 12:33 PM, Atte Tenkanen wrote:
> Hm...,
>
> Should these two versions produce the same solution?

I wouldn't expect them to.

Duncan Murdoch


  Unfortunately and
> shame to confess, I don't know much about the colors in R:
>
> myColors <- c("#FF7C00","#00BF40","#FFFF00")
> Colors=rgb2hsv(col2rgb(myColors))
> apply(Colors,1,mean)
>
>           h         s         v
> 0.2122974 1.0000000 0.9163399
>
> * * * * *
>
> # Average the 1st two by taking the middle colour of a 3 colour palette
> x <- colorRampPalette(c("#FF7C00","#00BF40"), space = "Lab")(3)[2]
>
> # Average in the third by taking the 2nd of a 4 colour palette, so x
> # gets twice the weight
> colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]
>
> rgb2hsv(col2rgb(colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]))
>
>          [,1]
> h 0.1597633
> s 0.8407960
> v 0.7882353
>
> Atte T.
>
>
> 16.4.2016, 19.03, Duncan Murdoch kirjoitti:
>> On 16/04/2016 8:47 AM, Atte Tenkanen wrote:
>>> Hi,
>>>
>>> How would you calculate the "mean colour" of several colours, for
>>> example c("#FF7C00","#00BF40","#FFFF00")?
>>>
>>
>> Bert answered your subject line question.  Your text is asking
>> something else:  if those are colours, you don't want to treat each of
>> them as a single integer.
>>
>> A simple-minded approach would split them into 3 hex numbers, and
>> average those (using Bert's solution).
>>
>> A more sophisticated approach would take into account that they are
>> really colours.  You could probably put together something using the
>> colorRamp or colorRampPalette functions to average in perception
>> space.  For example,
>>
>> # Average the 1st two by taking the middle colour of a 3 colour palette
>> x <- colorRampPalette(c("#FF7C00","#00BF40"), space = "Lab")(3)[2]
>>
>> # Average in the third by taking the 2nd of a 4 colour palette, so x
>> # gets twice the weight
>> colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]
>>
>> Duncan Murdoch
>


From ragia11 at hotmail.com  Sat Apr 16 20:58:05 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Sat, 16 Apr 2016 20:58:05 +0200
Subject: [R] Twitter Hashtag
Message-ID: <DUB125-W165C885243F71279BC2892B3690@phx.gbl>


Dear group,
I want to download text of weets and other data such as user id or so for a specific hashtag on twitter,  how to do this..any reference suggestions that could help me to download almost it all without limits in number of dlwonloaded tweets.
thanks in advance
RaGiA 		 	   		  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sat Apr 16 21:02:28 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 16 Apr 2016 15:02:28 -0400
Subject: [R] Twitter Hashtag
In-Reply-To: <DUB125-W165C885243F71279BC2892B3690@phx.gbl>
References: <DUB125-W165C885243F71279BC2892B3690@phx.gbl>
Message-ID: <2E3631A6-60EF-45B3-B43D-0B091C18BFAF@utoronto.ca>

See here:
http://www.r-bloggers.com/search/twitter



On Apr 16, 2016, at 2:58 PM, Ragia . <ragia11 at hotmail.com> wrote:

> 
> Dear group,
> I want to download text of weets and other data such as user id or so for a specific hashtag on twitter,  how to do this..any reference suggestions that could help me to download almost it all without limits in number of dlwonloaded tweets.
> thanks in advance
> RaGiA 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Sat Apr 16 21:09:54 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 17 Apr 2016 00:39:54 +0530
Subject: [R] How to delete Locked files in Mac
Message-ID: <CA+dpOJm4+cgGKMLZSy7Po2P=kmbJQJuj2HHWJEcahoD7tr94CA@mail.gmail.com>

Hi,

I am looking for some R code, which will delete all files in a Folder
that contains both Locked and Unlocked files. There are many,
therefore i would like to delete all files programmatically in one go.

I used following code :

## "SS" is the Folder name including entire path which contains Locked
and Unlocked files.

file.remove(file.path(ss, list.files(ss)))
[1] FALSE
Warning messages:
1: In file.remove(file.path(ss, list.files(ss))) :
  cannot remove file '..... my folder path...', reason 'Read-only file system'

Also when I tried to delete a single Locked file, I am getting following error:

Warning message:
In file.remove(ss1) :
  cannot remove file '/..... my folder path...', reason 'Operation not
permitted'

I am using Mac with OS : 10.7.5

Could you please help me with correct R code?


From boris.steipe at utoronto.ca  Sat Apr 16 21:44:22 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 16 Apr 2016 15:44:22 -0400
Subject: [R] How to delete Locked files in Mac
In-Reply-To: <CA+dpOJm4+cgGKMLZSy7Po2P=kmbJQJuj2HHWJEcahoD7tr94CA@mail.gmail.com>
References: <CA+dpOJm4+cgGKMLZSy7Po2P=kmbJQJuj2HHWJEcahoD7tr94CA@mail.gmail.com>
Message-ID: <0BAD9F2E-2A01-4AFA-B5D4-7A39B49D30ED@utoronto.ca>

The command:

   system("chflags -R nouchg /path/to/your/directory")

... should unlock your files recursively in the directory. Then proceed with 
file.remove()

B.



On Apr 16, 2016, at 3:09 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

> Hi,
> 
> I am looking for some R code, which will delete all files in a Folder
> that contains both Locked and Unlocked files. There are many,
> therefore i would like to delete all files programmatically in one go.
> 
> I used following code :
> 
> ## "SS" is the Folder name including entire path which contains Locked
> and Unlocked files.
> 
> file.remove(file.path(ss, list.files(ss)))
> [1] FALSE
> Warning messages:
> 1: In file.remove(file.path(ss, list.files(ss))) :
>  cannot remove file '..... my folder path...', reason 'Read-only file system'
> 
> Also when I tried to delete a single Locked file, I am getting following error:
> 
> Warning message:
> In file.remove(ss1) :
>  cannot remove file '/..... my folder path...', reason 'Operation not
> permitted'
> 
> I am using Mac with OS : 10.7.5
> 
> Could you please help me with correct R code?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Sun Apr 17 01:17:47 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 17 Apr 2016 04:47:47 +0530
Subject: [R] How to delete Locked files in Mac
In-Reply-To: <0BAD9F2E-2A01-4AFA-B5D4-7A39B49D30ED@utoronto.ca>
References: <CA+dpOJm4+cgGKMLZSy7Po2P=kmbJQJuj2HHWJEcahoD7tr94CA@mail.gmail.com>
	<0BAD9F2E-2A01-4AFA-B5D4-7A39B49D30ED@utoronto.ca>
Message-ID: <CA+dpOJ=NqmvuPEZZcVEhvK4h2bWejfmTehSRdDiOy9_8KKzMuQ@mail.gmail.com>

Thank you Boris. It worked.

On Sun, Apr 17, 2016 at 1:14 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> The command:
>
>    system("chflags -R nouchg /path/to/your/directory")
>
> ... should unlock your files recursively in the directory. Then proceed with
> file.remove()
>
> B.
>
>
>
> On Apr 16, 2016, at 3:09 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>
>> Hi,
>>
>> I am looking for some R code, which will delete all files in a Folder
>> that contains both Locked and Unlocked files. There are many,
>> therefore i would like to delete all files programmatically in one go.
>>
>> I used following code :
>>
>> ## "SS" is the Folder name including entire path which contains Locked
>> and Unlocked files.
>>
>> file.remove(file.path(ss, list.files(ss)))
>> [1] FALSE
>> Warning messages:
>> 1: In file.remove(file.path(ss, list.files(ss))) :
>>  cannot remove file '..... my folder path...', reason 'Read-only file system'
>>
>> Also when I tried to delete a single Locked file, I am getting following error:
>>
>> Warning message:
>> In file.remove(ss1) :
>>  cannot remove file '/..... my folder path...', reason 'Operation not
>> permitted'
>>
>> I am using Mac with OS : 10.7.5
>>
>> Could you please help me with correct R code?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sun Apr 17 04:16:16 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 16 Apr 2016 19:16:16 -0700
Subject: [R] Equivalent in R of the Contains operator in SAS
In-Reply-To: <428B4C92-79AA-4186-933A-57C9F22846F9@gmail.com>
References: <CAPRGo-=Fi-2XxPp+4m7TjwD3-Nj3V83KPQU8jTdw8uh-2C0rdw@mail.gmail.com>
	<428B4C92-79AA-4186-933A-57C9F22846F9@gmail.com>
Message-ID: <F1E5BF69-F20A-4164-82AD-43B5BA38A829@comcast.net>


> On Apr 16, 2016, at 6:30 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Check the string matching functions, e.g. grepl().

Concretely:

merge3[, grepl( "Email|Email\\.x", names(merge3) ) ]  # since "." is special in grepisch patterns.

Which admittedly is a bit redundant since any character value that included `Email.x" would already have been picked up by the "Email" alternative.

> 
> -pd
> 
>> On 16 Apr 2016, at 15:18 , Dan Abner <dan.abner99 at gmail.com> wrote:
>> 
>> Hi all,
>> 
>> I want to select all variables in the data.frame with a name that
>> includes are certain string. Something like the following:
>> 
>> merge3[,names(merge3) %in% c("Email","Email.x")]
>> 
>> But there are too many variations on the Email variable names to list them all.
>> 
>> Can anyone advise?
>> 
>> Thanks!
>> 
>> Dan
>> 

> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Apr 17 04:22:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 16 Apr 2016 19:22:44 -0700
Subject: [R] Bug in by() function which works for some FUN argument and
	does not work for others
In-Reply-To: <CACLgfx32KJQY=yWkx_72aS6=vOpACJwY8bG_FuvgFAxMh-wAxA@mail.gmail.com>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
	<CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
	<49C85E5A-AAB2-47BB-AEC4-41ECDC069180@comcast.net>
	<CACLgfx32KJQY=yWkx_72aS6=vOpACJwY8bG_FuvgFAxMh-wAxA@mail.gmail.com>
Message-ID: <D7C990D2-D60E-4A56-8946-E5B1A7A0CD89@comcast.net>


> On Apr 16, 2016, at 2:03 AM, Akhilesh Singh <akhileshsingh.igkv at gmail.com> wrote:
> 
> Dear All, 
> 
> I have got your core message, that it is my responsibility to determine whether any particular function in my version of R satisfies the language requirements at the time of your use. Jim Albert and Maria Rizzo must have used their code, which was permitted in the R-code of their time (2012). 
> 
> Therefore, I have now modified my R-code, as per R-3..2.4 version, according to my requirement as follows, which is working for my 'brain' data set, whose output is reproduced below for your information please:
> 
> > by(brain[,-1], INDICES=list(Gender=brain$Gender), FUN=function(x, na.rm=FALSE) sapply(x, mean, na.rm=na.rm), na.rm=TRUE)
> Gender: Female
>       FSIQ        VIQ        PIQ     Weight     Height  MRI_Count 
>    111.900    109.450    110.450    137.200     65.765 862654.600 
> -------------------------------------------------------------------------------------------------- 
> Gender: Male
>         FSIQ          VIQ          PIQ       Weight       Height    MRI_Count 
>    115.00000    115.25000    111.60000    166.44444     71.43158 954855.40000 

Yes. that is certainly a workable alternative, although I thought the question of "how to to it" had been effectively answered with the suggestion from Adrian Dusa to use colMeans. It, too, has an `na.rm=TRUE` option

I was only responding to your plaintive complaint that the current version of R had a "bug" because it was not behaving as promised by an introductory text with a three year-old publishing date.

-- 
David.


> 
> With best regards,
> 
> Dr. A.K. Singh
> Head, Department of Agril. Statistics
> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> Chhattisgarh, India, PIN-492012
> Mobile: +919752620740
> Email: akhileshsingh.igkv at gmail.com
> 
> On Fri, Apr 15, 2016 at 2:24 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Apr 15, 2016, at 1:16 AM, Akhilesh Singh <akhileshsingh.igkv at gmail.com> wrote:
> >
> > Dear All,
> >
> > Thanks for your help. However, I would like to draw your attention to the
> > following:
> >
> > Actually, I was replicating the Example 2.3, using the dataset
> > "brainsize.txt" given in Section 2.3.3 ("Summarize by group") at page 55,
> > of a famous book "R by Example" written by "Jim Albert and Maria Rizzo"
> > published in Springers (2012) in a Use R! Series. The output of the by()
> > function printed in the book is being reproduced below for information to
> > all:
> >
> >> by(data=brain[, -1], INDICES=brain$Gender, FUN=mean, na.rm=TRUE)
> > brain$Gender: Female
> > FSIQ VIQ PIQ Weight Height MRI_Count
> > 111.900 109.450 110.450 137.200 65.765 862654.600
> > ------------------------------------------------------------
> > brain$Gender: Male
> > FSIQ  VIQ    PIQ       Weight    Height   MRI_Count
> > 115.00000 115.25000 111.60000 166.44444 71.43158 954855.40000
> >
> >
> > I do not know how could the writers of the book have produced the above
> > results by by() function.
> 
> 
> There was in the not-so-distant past a function named `mean.data.frame` which would have "worked" in that instance. That function was removed. I thought you could  find the exact date of that action by searching the NEWS but failed. Reviewing the citations of `mean.data.frame` in the r-help archives I see that users were being warned that its use was deprecated in mid 2012.  It's very possible that the authors of a book in 2012 were using an earlier version of R that had that facility available to them before it was deprecated. With a more than current version of R 3.3.0 and a modest number of loaded packages I see this:
> 
> > methods(mean)
>  [1] mean,ANY-method          mean,Matrix-method       mean,Raster-method
>  [4] mean,sparseMatrix-method mean,sparseVector-method mean.Date
>  [7] mean.default             mean.difftime            mean.POSIXct
> [10] mean.POSIXlt             mean.yearmon*            mean.yearqtr*
> [13] mean.zoo*
> 
> It is your responsibility to determine whether any particular function in your version of R satisfies the language requirements at the time of your use. Jim Albert and Maria Rizzo do not set the standards for what is an evolving piece of software.
> 
> --
> David.
> 
> 
> > But, when I could not reproduce these results,
> > then I thought that probably, this could possibly be due to some missing
> > values NA's in Weight and Height variables. Then I tried the above code for
> > the "mtcars" dataset for INDICES=mtcars$am. When I found the same results
> > here too, then I reported the case in "r-help at R-project.org".
> >
> > With best regards,
> >
> > Dr. A.K. Singh
> > Head, Department of Agril. Statistics
> > Indira Gandhi Krishi Vishwavidyalaya, Raipur
> > Chhattisgarh, India, PIN-492012
> > Mobile: +919752620740
> > Email: akhileshsingh.igkv at gmail.com
> >
> > On Fri, Apr 15, 2016 at 3:06 AM, Adrian Du?a <dusa.adrian at unibuc.ro> wrote:
> >
> >> I think you are not using the best function for what your intentions are.
> >> Try:
> >>
> >>> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
> >> : 0
> >>        mpg         cyl        disp          hp        drat          wt
> >>     qsec          vs
> >> 17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
> >> 18.1831579   0.3684211
> >>         am        gear        carb
> >>  0.0000000   3.2105263   2.7368421
> >>
> >> ---------------------------------------------------------------------------
> >> : 1
> >>        mpg         cyl        disp          hp        drat          wt
> >>     qsec          vs
> >> 24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
> >> 17.3600000   0.5384615
> >>         am        gear        carb
> >>  1.0000000   4.3846154   2.9230769
> >>
> >> See the difference between colMeans() and mean() in their respective help
> >> files.
> >> Hth,
> >> Adrian
> >>
> >> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
> >> akhileshsingh.igkv at gmail.com> wrote:
> >>
> >>> Dear Sirs,
> >>>
> >>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
> >>> Chhattisgarh, India.
> >>>
> >>> While taking classes, I found the *by() *function producing following
> >>> error
> >>>
> >>> when I use FUN=mean or median and some other functions, however,
> >>> FUN=summary works.
> >>>
> >>> Given below is the output of the example I used on a built-in dataset
> >>> "mtcars", along with error message reproduced herewith:
> >>>
> >>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
> >>> : 0
> >>> [1] NA
> >>> ------------------------------------------------------------
> >>> : 1
> >>> [1] NA
> >>> Warning messages:
> >>> 1: In mean.default(data[x, , drop = FALSE], ...) :
> >>>  argument is not numeric or logical: returning NA
> >>> 2: In mean.default(data[x, , drop = FALSE], ...) :
> >>>  argument is not numeric or logical: returning NA
> >>>
> >>> However, the same by() function works for FUN=summary, given below is the
> >>> output:
> >>>
> >>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
> >>> : 0
> >>>      mpg             cyl             disp             hp
> >>> Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
> >>> 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
> >>> Median :17.30   Median :8.000   Median :275.8   Median :175.0
> >>> Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
> >>> 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
> >>> Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
> >>>      drat             wt             qsec             vs               am
> >>>
> >>> Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.
> >>> :0
> >>>
> >>> 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st
> >>> Qu.:0
> >>>
> >>> Median :3.150   Median :3.520   Median :17.82   Median :0.0000   Median
> >>> :0
> >>>
> >>> Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean
> >>> :0
> >>>
> >>> 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd
> >>> Qu.:0
> >>>
> >>> Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.
> >>> :0
> >>>
> >>>      gear            carb
> >>> Min.   :3.000   Min.   :1.000
> >>> 1st Qu.:3.000   1st Qu.:2.000
> >>> Median :3.000   Median :3.000
> >>> Mean   :3.211   Mean   :2.737
> >>> 3rd Qu.:3.000   3rd Qu.:4.000
> >>> Max.   :4.000   Max.   :4.000
> >>> ------------------------------------------------------------
> >>> : 1
> >>>      mpg             cyl             disp             hp             drat
> >>>
> >>> Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
> >>> :3.54
> >>> 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
> >>> Qu.:3.85
> >>> Median :22.80   Median :4.000   Median :120.3   Median :109.0   Median
> >>> :4.08
> >>> Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
> >>> :4.05
> >>> 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
> >>> Qu.:4.22
> >>> Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
> >>> :4.93
> >>>       wt             qsec             vs               am         gear
> >>>
> >>> Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.
> >>> :4.000
> >>>
> >>> 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st
> >>> Qu.:4.000
> >>>
> >>> Median :2.320   Median :17.02   Median :1.0000   Median :1   Median
> >>> :4.000
> >>>
> >>> Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean
> >>> :4.385
> >>>
> >>> 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd
> >>> Qu.:5.000
> >>>
> >>> Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.
> >>> :5.000
> >>>
> >>>      carb
> >>> Min.   :1.000
> >>> 1st Qu.:1.000
> >>> Median :2.000
> >>> Mean   :2.923
> >>> 3rd Qu.:4.000
> >>> Max.   :8.000
> >>>>
> >>>
> >>> I am using the latest version of *R-3.2.4 on Windows*, however, this error
> >>> is being generated in the previous version too,
> >>>
> >>> Hope this reporting will get serious attention in debugging.
> >>>
> >>> With best regards,
> >>>
> >>> Dr. A.K. Singh
> >>> Head, Department of Agril. Statistics
> >>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> >>> Chhattisgarh, India, PIN-492012
> >>> Mobile: +919752620740
> >>> Email: akhileshsingh.igkv at gmail.com
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>
> >> --
> >> Adrian Dusa
> >> University of Bucharest
> >> Romanian Social Data Archive
> >> Soseaua Panduri nr.90
> >> 050663 Bucharest sector 5
> >> Romania
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From jsorkin at grecc.umaryland.edu  Sun Apr 17 04:38:50 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 16 Apr 2016 22:38:50 -0400
Subject: [R] Trying to understand cut
Message-ID: <5712BEFA020000CB00150E41@smtp.medicine.umaryland.edu>

I am trying to understand cut so I can divide a list of numbers into 10 group:
  0-9.0
10-10.9
20-20.9
30-30.9,
40-40.9,
50-50.9
60-60.9
70-70.9
80-80.9
90-90.9
 
As I try to do this, I have been playing with the cut function. Surprising the following for applications of cut give me the exact same groups. This surprises me given that I have varied parameters include.lowest and right. Can someone help me understand what include.lowest and right do? I have looked at the help page, but I don't seem to understand what I am being told!
Thank you,
John

values <- c((0:99),c(0.9:99.9))
sort(values)
c1<-cut(values,10,include.lowest=FALSE,right=TRUE)
c2<-cut(values,10,include.lowest=FALSE,right=FALSE)
c3<-cut(values,10,include.lowest=TRUE,right=TRUE)
c4<-cut(values,10,include.lowest=TRUE,right=FALSE)
cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))

You can run the code below, or inspect the results I got which are reproduced below:
 
> cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
      min.Group.1 min.x    max.Group.1 max.x
1  (-0.0999,9.91]     0 (-0.0999,9.91]   9.9
2     (9.91,19.9]    10    (9.91,19.9]  19.9
3     (19.9,29.9]    20    (19.9,29.9]  29.9
4     (29.9,39.9]    30    (29.9,39.9]  39.9
5       (39.9,50]    40      (39.9,50]  49.9
6         (50,60]    50        (50,60]  59.9
7         (60,70]    60        (60,70]  69.9
8         (70,80]    70        (70,80]  79.9
9         (80,90]    80        (80,90]  89.9
10       (90,100]    90       (90,100]  99.9
> cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
      min.Group.1 min.x    max.Group.1 max.x
1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
2     [9.91,19.9)    10    [9.91,19.9)  19.9
3     [19.9,29.9)    20    [19.9,29.9)  29.9
4     [29.9,39.9)    30    [29.9,39.9)  39.9
5       [39.9,50)    40      [39.9,50)  49.9
6         [50,60)    50        [50,60)  59.9
7         [60,70)    60        [60,70)  69.9
8         [70,80)    70        [70,80)  79.9
9         [80,90)    80        [80,90)  89.9
10       [90,100)    90       [90,100)  99.9
> cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
      min.Group.1 min.x    max.Group.1 max.x
1  [-0.0999,9.91]     0 [-0.0999,9.91]   9.9
2     (9.91,19.9]    10    (9.91,19.9]  19.9
3     (19.9,29.9]    20    (19.9,29.9]  29.9
4     (29.9,39.9]    30    (29.9,39.9]  39.9
5       (39.9,50]    40      (39.9,50]  49.9
6         (50,60]    50        (50,60]  59.9
7         (60,70]    60        (60,70]  69.9
8         (70,80]    70        (70,80]  79.9
9         (80,90]    80        (80,90]  89.9
10       (90,100]    90       (90,100]  99.9
> cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
      min.Group.1 min.x    max.Group.1 max.x
1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
2     [9.91,19.9)    10    [9.91,19.9)  19.9
3     [19.9,29.9)    20    [19.9,29.9)  29.9
4     [29.9,39.9)    30    [29.9,39.9)  39.9
5       [39.9,50)    40      [39.9,50)  49.9
6         [50,60)    50        [50,60)  59.9
7         [60,70)    60        [60,70)  69.9
8         [70,80)    70        [70,80)  79.9
9         [80,90)    80        [80,90)  89.9
10       [90,100]    90       [90,100]  99.9
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jdnewmil at dcn.davis.ca.us  Sun Apr 17 05:07:24 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 16 Apr 2016 20:07:24 -0700
Subject: [R] Trying to understand cut
In-Reply-To: <5712BEFA020000CB00150E41@smtp.medicine.umaryland.edu>
References: <5712BEFA020000CB00150E41@smtp.medicine.umaryland.edu>
Message-ID: <30EA0677-9DF5-472D-8721-FEE568953F57@dcn.davis.ca.us>

Have you read FAQ 7.31 recently, John? Your whole premise is flawed. You should be thinking of ranges  [0,10), [10,20), and so on because numbers ending in 0.9 are never going to be exact. 
-- 
Sent from my phone. Please excuse my brevity.

On April 16, 2016 7:38:50 PM PDT, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>I am trying to understand cut so I can divide a list of numbers into 10
>group:
>  0-9.0
>10-10.9
>20-20.9
>30-30.9,
>40-40.9,
>50-50.9
>60-60.9
>70-70.9
>80-80.9
>90-90.9
> 
>As I try to do this, I have been playing with the cut function.
>Surprising the following for applications of cut give me the exact same
>groups. This surprises me given that I have varied parameters
>include.lowest and right. Can someone help me understand what
>include.lowest and right do? I have looked at the help page, but I
>don't seem to understand what I am being told!
>Thank you,
>John
>
>values <- c((0:99),c(0.9:99.9))
>sort(values)
>c1<-cut(values,10,include.lowest=FALSE,right=TRUE)
>c2<-cut(values,10,include.lowest=FALSE,right=FALSE)
>c3<-cut(values,10,include.lowest=TRUE,right=TRUE)
>c4<-cut(values,10,include.lowest=TRUE,right=FALSE)
>cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
>cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
>cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
>cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
>
>You can run the code below, or inspect the results I got which are
>reproduced below:
> 
>>
>cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
>      min.Group.1 min.x    max.Group.1 max.x
>1  (-0.0999,9.91]     0 (-0.0999,9.91]   9.9
>2     (9.91,19.9]    10    (9.91,19.9]  19.9
>3     (19.9,29.9]    20    (19.9,29.9]  29.9
>4     (29.9,39.9]    30    (29.9,39.9]  39.9
>5       (39.9,50]    40      (39.9,50]  49.9
>6         (50,60]    50        (50,60]  59.9
>7         (60,70]    60        (60,70]  69.9
>8         (70,80]    70        (70,80]  79.9
>9         (80,90]    80        (80,90]  89.9
>10       (90,100]    90       (90,100]  99.9
>>
>cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
>      min.Group.1 min.x    max.Group.1 max.x
>1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
>2     [9.91,19.9)    10    [9.91,19.9)  19.9
>3     [19.9,29.9)    20    [19.9,29.9)  29.9
>4     [29.9,39.9)    30    [29.9,39.9)  39.9
>5       [39.9,50)    40      [39.9,50)  49.9
>6         [50,60)    50        [50,60)  59.9
>7         [60,70)    60        [60,70)  69.9
>8         [70,80)    70        [70,80)  79.9
>9         [80,90)    80        [80,90)  89.9
>10       [90,100)    90       [90,100)  99.9
>>
>cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
>      min.Group.1 min.x    max.Group.1 max.x
>1  [-0.0999,9.91]     0 [-0.0999,9.91]   9.9
>2     (9.91,19.9]    10    (9.91,19.9]  19.9
>3     (19.9,29.9]    20    (19.9,29.9]  29.9
>4     (29.9,39.9]    30    (29.9,39.9]  39.9
>5       (39.9,50]    40      (39.9,50]  49.9
>6         (50,60]    50        (50,60]  59.9
>7         (60,70]    60        (60,70]  69.9
>8         (70,80]    70        (70,80]  79.9
>9         (80,90]    80        (80,90]  89.9
>10       (90,100]    90       (90,100]  99.9
>>
>cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
>      min.Group.1 min.x    max.Group.1 max.x
>1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
>2     [9.91,19.9)    10    [9.91,19.9)  19.9
>3     [19.9,29.9)    20    [19.9,29.9)  29.9
>4     [29.9,39.9)    30    [29.9,39.9)  39.9
>5       [39.9,50)    40      [39.9,50)  49.9
>6         [50,60)    50        [50,60)  59.9
>7         [60,70)    60        [60,70)  69.9
>8         [70,80)    70        [70,80)  79.9
>9         [80,90)    80        [80,90)  89.9
>10       [90,100]    90       [90,100]  99.9
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>
>Confidentiality Statement:
>This email message, including any attachments, is for t...{{dropped:15}}


From attenka at utu.fi  Sat Apr 16 18:01:41 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Sat, 16 Apr 2016 19:01:41 +0300
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <CAF8bMcYx=mHPq8nWdn9D6uXn50MoebLVxeYpAhw3wfHJfeD8uQ@mail.gmail.com>
References: <5712346F.4050003@utu.fi>
	<CAGxFJbS8UP8mkokz5xsRpFtw5pN2rK8OaVUQLk=WB3pSt4L0=g@mail.gmail.com>
	<CAGxFJbRA7X=yHpdGWP1Piz1H6B8Wm0Q0JcaJkfNhJUwzTuFRig@mail.gmail.com>
	<CAF8bMcYx=mHPq8nWdn9D6uXn50MoebLVxeYpAhw3wfHJfeD8uQ@mail.gmail.com>
Message-ID: <571261E5.8060508@utu.fi>

Thanks to William and Bert!

Atte

16.4.2016, 18.56, William Dunlap kirjoitti:
> Since these are color strings, you can use functions in the grDevices
> package (other others) to manipulate them.  E.g., you can convert them
> to various color spaces and perhaps use the mean in one of those
> spaces as your 'average color'.
>
>   > myColors <- c(One="#FF7C00",Two="#00BF40",Three="#FFFF00")
>   > col2rgb(myColors)
>         One Two Three
>   red   255   0   255
>   green 124 191   255
>   blue    0  64     0
>   > rgb2hsv(col2rgb(myColors))
>            One       Two     Three
>   h 0.08104575 0.3891798 0.1666667
>   s 1.00000000 1.0000000 1.0000000
>   v 1.00000000 0.7490196 1.0000000
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Sat, Apr 16, 2016 at 8:27 AM, Bert Gunter <bgunter.4567 at gmail.com 
> <mailto:bgunter.4567 at gmail.com>> wrote:
>
>     ... and if you need to convert back:  ?as.hexmode
>
>
>     -- Bert
>
>
>     Bert Gunter
>
>     "The trouble with having an open mind is that people keep coming along
>     and sticking things into it."
>     -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>     On Sat, Apr 16, 2016 at 8:20 AM, Bert Gunter
>     <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>     > ?strtoi
>     >
>     > You'll have to remove the "#" first, e.g. via substring()
>     >
>     > -- Bert
>     >
>     >
>     > Bert Gunter
>     >
>     > "The trouble with having an open mind is that people keep coming
>     along
>     > and sticking things into it."
>     > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>     >
>     >
>     > On Sat, Apr 16, 2016 at 5:47 AM, Atte Tenkanen <attenka at utu.fi
>     <mailto:attenka at utu.fi>> wrote:
>     >> Hi,
>     >>
>     >> How would you calculate the "mean colour" of several colours,
>     for example
>     >> c("#FF7C00","#00BF40","#FFFF00")?
>     >>
>     >> Yours,
>     >>
>     >> Atte Tenkanen
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From attenka at utu.fi  Sat Apr 16 18:33:45 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Sat, 16 Apr 2016 19:33:45 +0300
Subject: [R] Mean of hexadecimal numbers
In-Reply-To: <5712626C.2090800@gmail.com>
References: <5712346F.4050003@utu.fi> <5712626C.2090800@gmail.com>
Message-ID: <57126969.6090005@utu.fi>

Hm...,

Should these two versions produce the same solution? Unfortunately and 
shame to confess, I don't know much about the colors in R:

myColors <- c("#FF7C00","#00BF40","#FFFF00")
Colors=rgb2hsv(col2rgb(myColors))
apply(Colors,1,mean)

         h         s         v
0.2122974 1.0000000 0.9163399

* * * * *

# Average the 1st two by taking the middle colour of a 3 colour palette
x <- colorRampPalette(c("#FF7C00","#00BF40"), space = "Lab")(3)[2]

# Average in the third by taking the 2nd of a 4 colour palette, so x
# gets twice the weight
colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]

rgb2hsv(col2rgb(colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]))

        [,1]
h 0.1597633
s 0.8407960
v 0.7882353

Atte T.


16.4.2016, 19.03, Duncan Murdoch kirjoitti:
> On 16/04/2016 8:47 AM, Atte Tenkanen wrote:
>> Hi,
>>
>> How would you calculate the "mean colour" of several colours, for
>> example c("#FF7C00","#00BF40","#FFFF00")?
>>
>
> Bert answered your subject line question.  Your text is asking 
> something else:  if those are colours, you don't want to treat each of 
> them as a single integer.
>
> A simple-minded approach would split them into 3 hex numbers, and 
> average those (using Bert's solution).
>
> A more sophisticated approach would take into account that they are 
> really colours.  You could probably put together something using the 
> colorRamp or colorRampPalette functions to average in perception 
> space.  For example,
>
> # Average the 1st two by taking the middle colour of a 3 colour palette
> x <- colorRampPalette(c("#FF7C00","#00BF40"), space = "Lab")(3)[2]
>
> # Average in the third by taking the 2nd of a 4 colour palette, so x
> # gets twice the weight
> colorRampPalette(c(x, "#FFFF00"), space = "Lab")(4)[2]
>
> Duncan Murdoch


From jsorkin at grecc.umaryland.edu  Sun Apr 17 06:12:41 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 17 Apr 2016 00:12:41 -0400
Subject: [R] Trying to understand cut
In-Reply-To: <30EA0677-9DF5-472D-8721-FEE568953F57@dcn.davis.ca.us>
References: <5712BEFA020000CB00150E41@smtp.medicine.umaryland.edu>
	<30EA0677-9DF5-472D-8721-FEE568953F57@dcn.davis.ca.us>
Message-ID: <5712D4F9020000CB00150E53@smtp.medicine.umaryland.edu>

Jeff,
Perhaps I was sloppy with my notation:
I want groups
>=0 <10
>=10 <20
>=20<30
......
>=90 <100
 
In any event, my question remains, why did the four different versions of cut give me the same results? I hope someone can explain to me the function of 
include.lowest and right in the call to cut. As demonstrated in my example below, the parameters do not seem to alter the results of using cut.
Thank you,
John
 
 
P.S. How do I find FAQ 7.31?
Thank you,
John
 
I 



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 04/16/16 11:07 PM >>>
Have you read FAQ 7.31 recently, John? Your whole premise is flawed. You should be thinking of ranges [0,10), [10,20), and so on because numbers ending in 0.9 are never going to be exact. 
-- 
Sent from my phone. Please excuse my brevity.


On April 16, 2016 7:38:50 PM PDT, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
I am trying to understand cut so I can divide a list of numbers into 10 group:
  0-9.0
10-10.9
20-20.9
30-30.9,
40-40.9,
50-50.9
60-60.9
70-70.9
80-80.9
90-90.9
 
As I try to do this, I have been playing with the cut function. Surprising the following for applications of cut give me the exact same groups. This surprises me given that I have varied parameters include.lowest and right. Can someone help me understand what include.lowest and right do? I have looked at the help page, but I don't seem to understand what I am being told!
Thank you,
John

values <- c((0:99),c(0.9:99.9))
sort(values)
c1<-cut(values,10,include.lowest=FALSE,right=TRUE)
c2<-cut(values,10,include.lowest=FALSE,right=FALSE)
c3<-cut(values,10,include.lowest=TRUE,right=TRUE)
c4<-cut(values,10,include.lowest=TRUE,right=FALSE)
cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))

You can run the code below, or inspect the results I got which are reproduced below:
 
 cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))

      min.Group.1 min.x    max.Group.1 max.x
1  (-0.0999,9.91]     0 (-0.0999,9.91]   9.9
2     (9.91,19.9]    10    (9.91,19.9]  19.9
3     (19.9,29.9]    20    (19.9,29.9]  29.9
4     (29.9,39.9]    30    (29.9,39.9]  39.9
5       (39.9,50]    40      (39.9,50]  49.9
6         (50,60]    50        (50,60]  59.9
7         (60,70]    60        (60,70]  69.9
8         (70,80]    70        (70,80]  79.9
9         (80,90]    80        (80,90]  89.9
10       (90,100]    90       (90,100]  99.9
 cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))

      min.Group.1 min.x    max.Group.1 max.x
1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
2     [9.91,19.9)    10    [9.91,19.9)  19.9
3     [19.9,29.9)    20    [19.9,29.9)  29.9
4     [29.9,39.9)    30    [29.9,39.9)  39.9
5       [39.9,50)    40      [39.9,50)  49.9
6         [50,60)    50        [50,60)  59.9
7         [60,70)    60        [60,70)  69.9
8         [70,80)    70        [70,80)  79.9
9         [80,90)    80        [80,90)  89.9
10       [90,100)    90       [90,100)  99.9
 cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))

      min.Group.1 min.x    max.Group.1 max.x
1  [-0.0999,9.91]     0 [-0.0999,9.91]   9.9
2     (9.91,19.9]    10    (9.91,19.9]  19.9
3     (19.9,29.9]    20    (19.9,29.9]  29.9
4     (29.9,39.9]    30    (29.9,39.9]  39.9
5       (39.9,50]    40      (39.9,50]  49.9
6         (50,60]    50        (50,60]  59.9
7         (60,70]    60        (60,70]  69.9
8         (70,80]    70        (70,80]  79.9
9         (80,90]    80        (80,90]  89.9
10       (90,100]    90       (90,100]  99.9
 cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))

      min.Group.1 min.x    max.Group.1 max.x
1 [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
2     [9.91,19.9)    10    [9.91,19.9)  19.9
3     [19.9,29.9)    20    [19.9,29.9)  29.9
4     [29.9,39.9)    30    [29.9,39.9)  39.9
5       [39.9,50)    40      [39.9,50)  49.9
6         [50,60)    50        [50,60)  59.9
7         [60,70)    60        [60,70)  69.9
8         [70,80)    70        [70,80)  79.9
9         [80,90)    80        [80,90)  89.9
10       [90,100]    90       [90,100]  99.9
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, isfor the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 



R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From drjimlemon at gmail.com  Sun Apr 17 07:15:41 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 17 Apr 2016 15:15:41 +1000
Subject: [R] Trying to understand cut
In-Reply-To: <5712D4F9020000CB00150E53@smtp.medicine.umaryland.edu>
References: <5712BEFA020000CB00150E41@smtp.medicine.umaryland.edu>
	<30EA0677-9DF5-472D-8721-FEE568953F57@dcn.davis.ca.us>
	<5712D4F9020000CB00150E53@smtp.medicine.umaryland.edu>
Message-ID: <CA+8X3fWEux5T2KbyfuDyvEgcho+UP7PUsffh-Qtp6=Hi+yn-cA@mail.gmail.com>

Hi John,
Both the "right" and "include.lowest" arguments are usually useful
when there are values equal to those in "breaks". A value equal to a
break can fall on either side of the break depending upon these
arguments:

> nums<-1:100
> table(cut(nums,breaks=seq(0,100,by=10)))

 (0,10]  (10,20]  (20,30]  (30,40]  (40,50]  (50,60]  (60,70]  (70,80]
     10       10       10       10       10       10       10       10
(80,90] (90,100]
     10       10

because the breaks are left-closed all of the values equal to a break
at the higher end are shifted up and the 100 value is lost in this one

> table(cut(nums,breaks=seq(0,100,by=10),right=FALSE))

 [0,10)  [10,20)  [20,30)  [30,40)  [40,50)  [50,60)  [60,70)  [70,80)
      9       10       10       10       10       10       10       10
[80,90) [90,100)
     10       10

but if I include.lowest (which is really highest when right=FALSE),
the highest value in the last cut (100) is preserved.

> table(cut(nums,breaks=seq(0,100,by=10),right=FALSE,include.lowest=TRUE))

 [0,10)  [10,20)  [20,30)  [30,40)  [40,50)  [50,60)  [60,70)  [70,80)
      9       10       10       10       10       10       10       10
[80,90) [90,100]
     10       11

data.frame(A=nums,
 B=cut(nums,breaks=seq(0,100,by=10),right=FALSE,
 include.lowest=TRUE))

to see the correspondence.

Jim

On Sun, Apr 17, 2016 at 2:12 PM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> Jeff,
> Perhaps I was sloppy with my notation:
> I want groups
>>=0 <10
>>=10 <20
>>=20<30
> ......
>>=90 <100
>
> In any event, my question remains, why did the four different versions of cut give me the same results? I hope someone can explain to me the function of
> include.lowest and right in the call to cut. As demonstrated in my example below, the parameters do not seem to alter the results of using cut.
> Thank you,
> John
>
>
> P.S. How do I find FAQ 7.31?
> Thank you,
> John
>
> I
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 04/16/16 11:07 PM >>>
> Have you read FAQ 7.31 recently, John? Your whole premise is flawed. You should be thinking of ranges [0,10), [10,20), and so on because numbers ending in 0.9 are never going to be exact.
> --
> Sent from my phone. Please excuse my brevity.
>
>
> On April 16, 2016 7:38:50 PM PDT, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> I am trying to understand cut so I can divide a list of numbers into 10 group:
>   0-9.0
> 10-10.9
> 20-20.9
> 30-30.9,
> 40-40.9,
> 50-50.9
> 60-60.9
> 70-70.9
> 80-80.9
> 90-90.9
>
> As I try to do this, I have been playing with the cut function. Surprising the following for applications of cut give me the exact same groups. This surprises me given that I have varied parameters include.lowest and right. Can someone help me understand what include.lowest and right do? I have looked at the help page, but I don't seem to understand what I am being told!
> Thank you,
> John
>
> values <- c((0:99),c(0.9:99.9))
> sort(values)
> c1<-cut(values,10,include.lowest=FALSE,right=TRUE)
> c2<-cut(values,10,include.lowest=FALSE,right=FALSE)
> c3<-cut(values,10,include.lowest=TRUE,right=TRUE)
> c4<-cut(values,10,include.lowest=TRUE,right=FALSE)
> cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
> cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
> cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
> cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
>
> You can run the code below, or inspect the results I got which are reproduced below:
>
>  cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
>
>       min.Group.1 min.x    max.Group.1 max.x
> 1  (-0.0999,9.91]     0 (-0.0999,9.91]   9.9
> 2     (9.91,19.9]    10    (9.91,19.9]  19.9
> 3     (19.9,29.9]    20    (19.9,29.9]  29.9
> 4     (29.9,39.9]    30    (29.9,39.9]  39.9
> 5       (39.9,50]    40      (39.9,50]  49.9
> 6         (50,60]    50        (50,60]  59.9
> 7         (60,70]    60        (60,70]  69.9
> 8         (70,80]    70        (70,80]  79.9
> 9         (80,90]    80        (80,90]  89.9
> 10       (90,100]    90       (90,100]  99.9
>  cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
>
>       min.Group.1 min.x    max.Group.1 max.x
> 1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
> 2     [9.91,19.9)    10    [9.91,19.9)  19.9
> 3     [19.9,29.9)    20    [19.9,29.9)  29.9
> 4     [29.9,39.9)    30    [29.9,39.9)  39.9
> 5       [39.9,50)    40      [39.9,50)  49.9
> 6         [50,60)    50        [50,60)  59.9
> 7         [60,70)    60        [60,70)  69.9
> 8         [70,80)    70        [70,80)  79.9
> 9         [80,90)    80        [80,90)  89.9
> 10       [90,100)    90       [90,100)  99.9
>  cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
>
>       min.Group.1 min.x    max.Group.1 max.x
> 1  [-0.0999,9.91]     0 [-0.0999,9.91]   9.9
> 2     (9.91,19.9]    10    (9.91,19.9]  19.9
> 3     (19.9,29.9]    20    (19.9,29.9]  29.9
> 4     (29.9,39.9]    30    (29.9,39.9]  39.9
> 5       (39.9,50]    40      (39.9,50]  49.9
> 6         (50,60]    50        (50,60]  59.9
> 7         (60,70]    60        (60,70]  69.9
> 8         (70,80]    70        (70,80]  79.9
> 9         (80,90]    80        (80,90]  89.9
> 10       (90,100]    90       (90,100]  99.9
>  cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
>
>       min.Group.1 min.x    max.Group.1 max.x
> 1 [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
> 2     [9.91,19.9)    10    [9.91,19.9)  19.9
> 3     [19.9,29.9)    20    [19.9,29.9)  29.9
> 4     [29.9,39.9)    30    [29.9,39.9)  39.9
> 5       [39.9,50)    40      [39.9,50)  49.9
> 6         [50,60)    50        [50,60)  59.9
> 7         [60,70)    60        [60,70)  69.9
> 8         [70,80)    70        [70,80)  79.9
> 9         [80,90)    80        [80,90)  89.9
> 10       [90,100]    90       [90,100]  99.9
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, isfor t...{{dropped:26}}


From drjimlemon at gmail.com  Sun Apr 17 08:16:43 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 17 Apr 2016 16:16:43 +1000
Subject: [R] Need Help to solve an Error in R
In-Reply-To: <35070A5B-0850-4D33-8EEC-EDAEE12B64D2@comcast.net>
References: <CANM3OPhnZC14Vx8u1xFM5Fyo8zAJTCL8=mLrxS1H_BxWxJ5kgA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5026892@SRVEXCHMBX.precheza.cz>
	<CANM3OPitpc2ynRG793j05DPMKOTnSczO_orETZ35VwNotPT28A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50268DC@SRVEXCHMBX.precheza.cz>
	<35070A5B-0850-4D33-8EEC-EDAEE12B64D2@comcast.net>
Message-ID: <CA+8X3fWUiQpgVAchiRPisEkOkEVo5Yq8rOenNpBi6kq7o-s3Pw@mail.gmail.com>

Hi Jyoti,
>From what you and others have written I am going to guess that you are
using Windows, that Windows has hidden the extension on the file you
are trying to read, and the filename is actually:

galenv.gal

I may be wrong, but this problem has beset others before you.

Jim



>>> I tried to read some text file in R so that I can do further analysis on those
>>> files. All files are MicroRNA dataset and in exiqon format. When I write
>>> function ReadExi and path of my file gives me error - Error in a file(file, "rt") :
>>> cannot open the connection.
>>>
>>> I put a file in the same directory too, even then also it is not working.
>>> Can you help me on this issue?? Is there any issue with GAL file or
>>> samplesinfo.txt file as these are to be there in same folder as described in
>>> ExiMir package ??
>>>


From pdalgd at gmail.com  Sun Apr 17 09:35:50 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 17 Apr 2016 09:35:50 +0200
Subject: [R] Trying to understand cut
In-Reply-To: <5712D4F9020000CB00150E53@smtp.medicine.umaryland.edu>
References: <5712BEFA020000CB00150E41@smtp.medicine.umaryland.edu>
	<30EA0677-9DF5-472D-8721-FEE568953F57@dcn.davis.ca.us>
	<5712D4F9020000CB00150E53@smtp.medicine.umaryland.edu>
Message-ID: <512C8A17-9AF0-4001-AB85-82FEFB67F9F7@gmail.com>

This isn't really FAQ 7.31 (for once). 

The clue is in this part of cut.default():

            breaks <- seq.int(rx[1L], rx[2L], length.out = nb)
            breaks[c(1L, nb)] <- c(rx[1L] - dx/1000, rx[2L] + 
                dx/1000)

which _is_ as documented. Notice that it is based on the range(values) which in your example is 0-99.9, so the thing boils down to

> rx <- range(values)
> dx <- diff(rx)
> dx
[1] 99.9
> nb <- 11
> breaks <- seq.int(rx[1L], rx[2L], length.out = nb)
> breaks[c(1L, nb)] <- c(rx[1L] - dx/1000, rx[2L] + 
+                 dx/1000)
>  breaks
 [1] -0.0999  9.9900 19.9800 29.9700 39.9600 49.9500 59.9400 69.9300 79.9200
[10] 89.9100 99.9999

Notice that all the breakpoints have a nonzero 2nd decimal digit, which none of your data  have, so no data are on interval boundaries and left/right and include.lowest have no effect. There's a little fuzz at the ends to prevent the extremes from being excluded without having to explicitly set include.lowest=TRUE.

Short version: If you want fine control over the cutpoints, do not use cut(x,n)...

-pd

PS: To read the FAQ, go to www.r-project.org, and click "FAQs" (under Documentation, to the left).


> On 17 Apr 2016, at 06:12 , John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> Jeff,
> Perhaps I was sloppy with my notation:
> I want groups
>> =0 <10
>> =10 <20
>> =20<30
> ......
>> =90 <100
> 
> In any event, my question remains, why did the four different versions of cut give me the same results? I hope someone can explain to me the function of 
> include.lowest and right in the call to cut. As demonstrated in my example below, the parameters do not seem to alter the results of using cut.
> Thank you,
> John
> 
> 
> P.S. How do I find FAQ 7.31?
> Thank you,
> John
> 
> I 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 04/16/16 11:07 PM >>>
> Have you read FAQ 7.31 recently, John? Your whole premise is flawed. You should be thinking of ranges [0,10), [10,20), and so on because numbers ending in 0.9 are never going to be exact. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> 
> On April 16, 2016 7:38:50 PM PDT, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> I am trying to understand cut so I can divide a list of numbers into 10 group:
>  0-9.0
> 10-10.9
> 20-20.9
> 30-30.9,
> 40-40.9,
> 50-50.9
> 60-60.9
> 70-70.9
> 80-80.9
> 90-90.9
> 
> As I try to do this, I have been playing with the cut function. Surprising the following for applications of cut give me the exact same groups. This surprises me given that I have varied parameters include.lowest and right. Can someone help me understand what include.lowest and right do? I have looked at the help page, but I don't seem to understand what I am being told!
> Thank you,
> John
> 
> values <- c((0:99),c(0.9:99.9))
> sort(values)
> c1<-cut(values,10,include.lowest=FALSE,right=TRUE)
> c2<-cut(values,10,include.lowest=FALSE,right=FALSE)
> c3<-cut(values,10,include.lowest=TRUE,right=TRUE)
> c4<-cut(values,10,include.lowest=TRUE,right=FALSE)
> cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
> cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
> cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
> cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
> 
> You can run the code below, or inspect the results I got which are reproduced below:
> 
> cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1  (-0.0999,9.91]     0 (-0.0999,9.91]   9.9
> 2     (9.91,19.9]    10    (9.91,19.9]  19.9
> 3     (19.9,29.9]    20    (19.9,29.9]  29.9
> 4     (29.9,39.9]    30    (29.9,39.9]  39.9
> 5       (39.9,50]    40      (39.9,50]  49.9
> 6         (50,60]    50        (50,60]  59.9
> 7         (60,70]    60        (60,70]  69.9
> 8         (70,80]    70        (70,80]  79.9
> 9         (80,90]    80        (80,90]  89.9
> 10       (90,100]    90       (90,100]  99.9
> cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
> 2     [9.91,19.9)    10    [9.91,19.9)  19.9
> 3     [19.9,29.9)    20    [19.9,29.9)  29.9
> 4     [29.9,39.9)    30    [29.9,39.9)  39.9
> 5       [39.9,50)    40      [39.9,50)  49.9
> 6         [50,60)    50        [50,60)  59.9
> 7         [60,70)    60        [60,70)  69.9
> 8         [70,80)    70        [70,80)  79.9
> 9         [80,90)    80        [80,90)  89.9
> 10       [90,100)    90       [90,100)  99.9
> cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1  [-0.0999,9.91]     0 [-0.0999,9.91]   9.9
> 2     (9.91,19.9]    10    (9.91,19.9]  19.9
> 3     (19.9,29.9]    20    (19.9,29.9]  29.9
> 4     (29.9,39.9]    30    (29.9,39.9]  39.9
> 5       (39.9,50]    40      (39.9,50]  49.9
> 6         (50,60]    50        (50,60]  59.9
> 7         (60,70]    60        (60,70]  69.9
> 8         (70,80]    70        (70,80]  79.9
> 9         (80,90]    80        (80,90]  89.9
> 10       (90,100]    90       (90,100]  99.9
> cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1 [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
> 2     [9.91,19.9)    10    [9.91,19.9)  19.9
> 3     [19.9,29.9)    20    [19.9,29.9)  29.9
> 4     [29.9,39.9)    30    [29.9,39.9)  39.9
> 5       [39.9,50)    40      [39.9,50)  49.9
> 6         [50,60)    50        [50,60)  59.9
> 7         [60,70)    60        [60,70)  69.9
> 8         [70,80)    70        [70,80)  79.9
> 9         [80,90)    80        [80,90)  89.9
> 10       [90,100]    90       [90,100]  99.9
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, isfor the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 
> 
> 
> 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From valkremk at gmail.com  Sun Apr 17 15:43:04 2016
From: valkremk at gmail.com (Val)
Date: Sun, 17 Apr 2016 08:43:04 -0500
Subject: [R] Last
Message-ID: <CAJOiR6ZTBFjwq979Z+qMgS4ZjDgiv=Mw74_a0TVSCMdv0HOz4Q@mail.gmail.com>

Hi all,

I am trying to read data from a particular  excel sheet.

library(xlsx)
dat1=read.xlsx("las.xlsx", sheetIndex = 5)

I know that this is sheet is the last one and this number grows over time

When I run my script to read the last sheet then I have to change this
number every time manually.

Is it possible to read the last sheet of an excel file?
Thank yo in advance
Val

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Apr 17 16:26:16 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 17 Apr 2016 10:26:16 -0400
Subject: [R] Last
In-Reply-To: <CAJOiR6ZTBFjwq979Z+qMgS4ZjDgiv=Mw74_a0TVSCMdv0HOz4Q@mail.gmail.com>
References: <CAJOiR6ZTBFjwq979Z+qMgS4ZjDgiv=Mw74_a0TVSCMdv0HOz4Q@mail.gmail.com>
Message-ID: <74AD0C3F-9A00-4682-AD02-E25E9F7705ED@utoronto.ca>

Does 
  length(getSheets(loadWorkbook("las.xlsx"))
  
give you the index you need? (Untested).

B.


On Apr 17, 2016, at 9:43 AM, Val <valkremk at gmail.com> wrote:

> Hi all,
> 
> I am trying to read data from a particular  excel sheet.
> 
> library(xlsx)
> dat1=read.xlsx("las.xlsx", sheetIndex = 5)
> 
> I know that this is sheet is the last one and this number grows over time
> 
> When I run my script to read the last sheet then I have to change this
> number every time manually.
> 
> Is it possible to read the last sheet of an excel file?
> Thank yo in advance
> Val
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Apr 17 18:39:45 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 17 Apr 2016 09:39:45 -0700
Subject: [R] Trying to understand cut
In-Reply-To: <5712D4F9020000CB00150E53@smtp.medicine.umaryland.edu>
References: <5712BEFA020000CB00150E41@smtp.medicine.umaryland.edu>
	<30EA0677-9DF5-472D-8721-FEE568953F57@dcn.davis.ca.us>
	<5712D4F9020000CB00150E53@smtp.medicine.umaryland.edu>
Message-ID: <ED678003-F1D0-4EAA-BE58-417B8214DA72@comcast.net>


> On Apr 16, 2016, at 9:12 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> Jeff,
> Perhaps I was sloppy with my notation:
> I want groups
>> =0 <10
>> =10 <20
>> =20<30
> ......
>> =90 <100
> 
> In any event, my question remains, why did the four different versions of cut give me the same results? I hope someone can explain to me the function of 
> include.lowest and right in the call to cut. As demonstrated in my example below, the parameters do not seem to alter the results of using cut.

The pitfalls of using `cut` has pushed me toward a preference for findIntervals

nums<-1:100
table( findInterval( nums ,  seq(0, 100, by=10) ) )

It does mean that I often need to construct names for my groups but at least I know that I will be getting left closed intervals by default, since its `rightmost.closed`-default is FALSE. I often flank my cutting sequence with -Inf on the left and Inf on the right to know that I am seeing any outliers:

table( findInterval( nums ,  c(-Inf, seq(10, 90, by=10), Inf)  )  ) # slightly different

-- 
David.


> Thank you,
> John
> 
> 
> P.S. How do I find FAQ 7.31?

On my machine pulling down the Help-menu and choosing "R Help", the R FAQ comes up as a link that will display the full FAQ. I thought the behavior in The Windows R-GUI might be similar, but I lost the ability to use my virtually hosted version of R in my last OS upgrade.

.
> Thank you,
> John
> 
> I 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 04/16/16 11:07 PM >>>
> Have you read FAQ 7.31 recently, John? Your whole premise is flawed. You should be thinking of ranges [0,10), [10,20), and so on because numbers ending in 0.9 are never going to be exact. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> 
> On April 16, 2016 7:38:50 PM PDT, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> I am trying to understand cut so I can divide a list of numbers into 10 group:
>  0-9.0
> 10-10.9
> 20-20.9
> 30-30.9,
> 40-40.9,
> 50-50.9
> 60-60.9
> 70-70.9
> 80-80.9
> 90-90.9
> 
> As I try to do this, I have been playing with the cut function. Surprising the following for applications of cut give me the exact same groups. This surprises me given that I have varied parameters include.lowest and right. Can someone help me understand what include.lowest and right do? I have looked at the help page, but I don't seem to understand what I am being told!
> Thank you,
> John
> 
> values <- c((0:99),c(0.9:99.9))
> sort(values)
> c1<-cut(values,10,include.lowest=FALSE,right=TRUE)
> c2<-cut(values,10,include.lowest=FALSE,right=FALSE)
> c3<-cut(values,10,include.lowest=TRUE,right=TRUE)
> c4<-cut(values,10,include.lowest=TRUE,right=FALSE)
> cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
> cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
> cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
> cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
> 
> You can run the code below, or inspect the results I got which are reproduced below:
> 
> cbind(min=aggregate(values,list(c1),min),max=aggregate(values,list(c1),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1  (-0.0999,9.91]     0 (-0.0999,9.91]   9.9
> 2     (9.91,19.9]    10    (9.91,19.9]  19.9
> 3     (19.9,29.9]    20    (19.9,29.9]  29.9
> 4     (29.9,39.9]    30    (29.9,39.9]  39.9
> 5       (39.9,50]    40      (39.9,50]  49.9
> 6         (50,60]    50        (50,60]  59.9
> 7         (60,70]    60        (60,70]  69.9
> 8         (70,80]    70        (70,80]  79.9
> 9         (80,90]    80        (80,90]  89.9
> 10       (90,100]    90       (90,100]  99.9
> cbind(min=aggregate(values,list(c2),min),max=aggregate(values,list(c2),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1  [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
> 2     [9.91,19.9)    10    [9.91,19.9)  19.9
> 3     [19.9,29.9)    20    [19.9,29.9)  29.9
> 4     [29.9,39.9)    30    [29.9,39.9)  39.9
> 5       [39.9,50)    40      [39.9,50)  49.9
> 6         [50,60)    50        [50,60)  59.9
> 7         [60,70)    60        [60,70)  69.9
> 8         [70,80)    70        [70,80)  79.9
> 9         [80,90)    80        [80,90)  89.9
> 10       [90,100)    90       [90,100)  99.9
> cbind(min=aggregate(values,list(c3),min),max=aggregate(values,list(c3),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1  [-0.0999,9.91]     0 [-0.0999,9.91]   9.9
> 2     (9.91,19.9]    10    (9.91,19.9]  19.9
> 3     (19.9,29.9]    20    (19.9,29.9]  29.9
> 4     (29.9,39.9]    30    (29.9,39.9]  39.9
> 5       (39.9,50]    40      (39.9,50]  49.9
> 6         (50,60]    50        (50,60]  59.9
> 7         (60,70]    60        (60,70]  69.9
> 8         (70,80]    70        (70,80]  79.9
> 9         (80,90]    80        (80,90]  89.9
> 10       (90,100]    90       (90,100]  99.9
> cbind(min=aggregate(values,list(c4),min),max=aggregate(values,list(c4),max))
> 
>      min.Group.1 min.x    max.Group.1 max.x
> 1 [-0.0999,9.91)     0 [-0.0999,9.91)   9.9
> 2     [9.91,19.9)    10    [9.91,19.9)  19.9
> 3     [19.9,29.9)    20    [19.9,29.9)  29.9
> 4     [29.9,39.9)    30    [29.9,39.9)  39.9
> 5       [39.9,50)    40      [39.9,50)  49.9
> 6         [50,60)    50        [50,60)  59.9
> 7         [60,70)    60        [60,70)  69.9
> 8         [70,80)    70        [70,80)  79.9
> 9         [80,90)    80        [80,90)  89.9
> 10       [90,100]    90       [90,100]  99.9
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, isfor t...{{dropped:29}}


From n4fbz at tampabay.rr.com  Sun Apr 17 18:56:22 2016
From: n4fbz at tampabay.rr.com (Robert D. Bowers)
Date: Sun, 17 Apr 2016 12:56:22 -0400
Subject: [R] Solved: Communication in for() loop (Linux version)
Message-ID: <5713C036.2080900@tampabay.rr.com>

Thanks for the advice I've received.

FYI - It turns out that the problem was connected to the way R handles 
pipes and FIFOs, compared to the way the socat command does.  (I don't 
know exactly what, but trying different things solved it!)

I found that if you use FIFO() in R AND set up a FIFO connection in a 
terminal and then use SOCAT to communicate, it becomes reliable (at 
least for sending commands to a UDP connection).  I wasn't sure what 
exactly a FIFO connection was like (not that much info), but it worked.

I'll try getting data FROM the UDP connection at another time.

Next - figure out how to build a multi-dimensional array i.e. 
data(x,y,z...) with different-sized dimensions.  I've got a "system" 
kludged together that does it (putting the data into a OpenOffice 
spreadsheet), but I'd rather have R do the work.  That's this evening's 
experimentation/lesson!

Bob


From bgunter.4567 at gmail.com  Sun Apr 17 19:44:16 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 17 Apr 2016 10:44:16 -0700
Subject: [R] Solved: Communication in for() loop (Linux version)
In-Reply-To: <5713C036.2080900@tampabay.rr.com>
References: <5713C036.2080900@tampabay.rr.com>
Message-ID: <CAGxFJbRzf_+V=LP5aBaejTUbT0S9RFstDDh76BQAG2kc5E_mOw@mail.gmail.com>

I am not exactly sure what YOU mean by a "multidimensional array," but
I do know what R means: all elements must be the same mode (e.g all
numeric, all character, etc.) . See ?array for how to do this in R if
this accords with what you want to do.

BTW, searching rseek.org, google, and/or using the search capabilities
in the sos package may help facilitate your efforts if you are not
already using these resources.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 17, 2016 at 9:56 AM, Robert D. Bowers <n4fbz at tampabay.rr.com> wrote:
> Thanks for the advice I've received.
>
> FYI - It turns out that the problem was connected to the way R handles pipes
> and FIFOs, compared to the way the socat command does.  (I don't know
> exactly what, but trying different things solved it!)
>
> I found that if you use FIFO() in R AND set up a FIFO connection in a
> terminal and then use SOCAT to communicate, it becomes reliable (at least
> for sending commands to a UDP connection).  I wasn't sure what exactly a
> FIFO connection was like (not that much info), but it worked.
>
> I'll try getting data FROM the UDP connection at another time.
>
> Next - figure out how to build a multi-dimensional array i.e. data(x,y,z...)
> with different-sized dimensions.  I've got a "system" kludged together that
> does it (putting the data into a OpenOffice spreadsheet), but I'd rather
> have R do the work.  That's this evening's experimentation/lesson!
>
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sergio.fonda99 at gmail.com  Sun Apr 17 21:09:31 2016
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Sun, 17 Apr 2016 21:09:31 +0200
Subject: [R] use hjust or vjust with dendextend
Message-ID: <CAJRuHoq8bivY92mGGhaDKT1r9yyYF9o4r=dMuuE8_xMXhbJgww@mail.gmail.com>

Following "Introduction to dendextend" from Tal Galili, I applied this
code on iris data:
##
library(dendextend)
library(dendextendRcpp)
library(ggplot2)
dend2 <- iris[1:30,-5] %>% dist %>% hclust %>% as.dendrogram %>%
set("branches_k_color", k=3) %>% set("branches_lwd", rep(1,4)) %>%
set("branches_lty", rep(1,6))  %>%   set("labels_colors") %>%
set("labels_cex", c(1.0,1.0)) %>%   set("nodes_pch", 19) %>%
set("nodes_col", c("orange", "black", "plum", NA))
ggd2 <- as.ggdend(dend2)
ggplot(ggd2, horiz = TRUE, theme = NULL)

My problem is that the labels overlap the dendogram leafs and I have no
idea on how parameter hjust or vjust may be used to create space between
label and leaf.

Thanks for any help,
Sergio

	[[alternative HTML version deleted]]


From akhileshsingh.igkv at gmail.com  Sun Apr 17 17:11:26 2016
From: akhileshsingh.igkv at gmail.com (Akhilesh Singh)
Date: Sun, 17 Apr 2016 20:41:26 +0530
Subject: [R] Bug in by() function which works for some FUN argument and
 does not work for others
In-Reply-To: <D7C990D2-D60E-4A56-8946-E5B1A7A0CD89@comcast.net>
References: <CACLgfx18G4_==CaVMp61OmS6C3h13XTh4Ph_0uKBYivuUnYBQQ@mail.gmail.com>
	<CAJ=0CtBQVdn5irtSe5d9HG1ZqtFe785ezdu2V1HCQdERoPfNsw@mail.gmail.com>
	<CACLgfx1PhK13_nztXMMM8WaZ_LucUQ=KxSHaQMtKX6V1Em-7Rw@mail.gmail.com>
	<49C85E5A-AAB2-47BB-AEC4-41ECDC069180@comcast.net>
	<CACLgfx32KJQY=yWkx_72aS6=vOpACJwY8bG_FuvgFAxMh-wAxA@mail.gmail.com>
	<D7C990D2-D60E-4A56-8946-E5B1A7A0CD89@comcast.net>
Message-ID: <CACLgfx3bs+WLSmUKGK1EZLcgM8HRSyevmDDD_jOoOXQqMSWWqw@mail.gmail.com>

Dear All,

Yes, I certainly now agree with the suggestion of Adrian Dusa for using
colMeans in place of mean in the situation that I had reported to r-help.
And I am sorry that I did not personally extend my thanks to him. I really
wish to thank him for his suggestion, and I do this now.

However, I wished for future a way to apply a more complex function than
mean, say, e.g. a function for skewness or kurtosis and the likes in the
by() function. The function colMeans would be applicable for mean only.
That is why, I later came to above solution.

Yet, during all these deliberations, I wish to mention the suggestion given
by Dr. Jim Lemon, who suggested to use following code mixing by() into
sapply() wonderfully taking advantage of positional interpretations of
arguments in any R-code, that actually met my objective nicely for my
future project of using more complex functions in lieu of mean:

sapply(brain[,-1],by,brain$Gender,mean,na.rm=TRUE)
       FSIQ    VIQ    PIQ   Weight   Height MRI_Count
Female 111.9 109.45 110.45 137.2000 65.76500  862654.6
Male   115.0 115.25 111.60 166.4444 71.43158  954855.4

Secondly, I also wish to express my sorry to have mentioned "bug" for the
by() function, instead of thinking that I could be my mistake, whereas I
should have plainly sought help from r-help instead of calling it a "bug".
Had this hurt anybody's feeling, I express my regret and offer my apologies
to all of them for calling this name.

With best regards,

Dr. A.K. Singh
Head, Department of Agril. Statistics
Indira Gandhi Krishi Vishwavidyalaya, Raipur
Chhattisgarh, India, PIN-492012
Mobile: +919752620740
Email: akhileshsingh.igkv at gmail.com



On Sun, Apr 17, 2016 at 7:52 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 16, 2016, at 2:03 AM, Akhilesh Singh <
> akhileshsingh.igkv at gmail.com> wrote:
> >
> > Dear All,
> >
> > I have got your core message, that it is my responsibility to determine
> whether any particular function in my version of R satisfies the language
> requirements at the time of your use. Jim Albert and Maria Rizzo must have
> used their code, which was permitted in the R-code of their time (2012).
> >
> > Therefore, I have now modified my R-code, as per R-3..2.4 version,
> according to my requirement as follows, which is working for my 'brain'
> data set, whose output is reproduced below for your information please:
> >
> > > by(brain[,-1], INDICES=list(Gender=brain$Gender), FUN=function(x,
> na.rm=FALSE) sapply(x, mean, na.rm=na.rm), na.rm=TRUE)
> > Gender: Female
> >       FSIQ        VIQ        PIQ     Weight     Height  MRI_Count
> >    111.900    109.450    110.450    137.200     65.765 862654.600
> >
> --------------------------------------------------------------------------------------------------
> > Gender: Male
> >         FSIQ          VIQ          PIQ       Weight       Height
> MRI_Count
> >    115.00000    115.25000    111.60000    166.44444     71.43158
> 954855.40000
>
> Yes. that is certainly a workable alternative, although I thought the
> question of "how to to it" had been effectively answered with the
> suggestion from Adrian Dusa to use colMeans. It, too, has an `na.rm=TRUE`
> option
>
> I was only responding to your plaintive complaint that the current version
> of R had a "bug" because it was not behaving as promised by an introductory
> text with a three year-old publishing date.
>
> --
> David.
>
>
> >
> > With best regards,
> >
> > Dr. A.K. Singh
> > Head, Department of Agril. Statistics
> > Indira Gandhi Krishi Vishwavidyalaya, Raipur
> > Chhattisgarh, India, PIN-492012
> > Mobile: +919752620740
> > Email: akhileshsingh.igkv at gmail.com
> >
> > On Fri, Apr 15, 2016 at 2:24 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Apr 15, 2016, at 1:16 AM, Akhilesh Singh <
> akhileshsingh.igkv at gmail.com> wrote:
> > >
> > > Dear All,
> > >
> > > Thanks for your help. However, I would like to draw your attention to
> the
> > > following:
> > >
> > > Actually, I was replicating the Example 2.3, using the dataset
> > > "brainsize.txt" given in Section 2.3.3 ("Summarize by group") at page
> 55,
> > > of a famous book "R by Example" written by "Jim Albert and Maria Rizzo"
> > > published in Springers (2012) in a Use R! Series. The output of the
> by()
> > > function printed in the book is being reproduced below for information
> to
> > > all:
> > >
> > >> by(data=brain[, -1], INDICES=brain$Gender, FUN=mean, na.rm=TRUE)
> > > brain$Gender: Female
> > > FSIQ VIQ PIQ Weight Height MRI_Count
> > > 111.900 109.450 110.450 137.200 65.765 862654.600
> > > ------------------------------------------------------------
> > > brain$Gender: Male
> > > FSIQ  VIQ    PIQ       Weight    Height   MRI_Count
> > > 115.00000 115.25000 111.60000 166.44444 71.43158 954855.40000
> > >
> > >
> > > I do not know how could the writers of the book have produced the above
> > > results by by() function.
> >
> >
> > There was in the not-so-distant past a function named `mean.data.frame`
> which would have "worked" in that instance. That function was removed. I
> thought you could  find the exact date of that action by searching the NEWS
> but failed. Reviewing the citations of `mean.data.frame` in the r-help
> archives I see that users were being warned that its use was deprecated in
> mid 2012.  It's very possible that the authors of a book in 2012 were using
> an earlier version of R that had that facility available to them before it
> was deprecated. With a more than current version of R 3.3.0 and a modest
> number of loaded packages I see this:
> >
> > > methods(mean)
> >  [1] mean,ANY-method          mean,Matrix-method       mean,Raster-method
> >  [4] mean,sparseMatrix-method mean,sparseVector-method mean.Date
> >  [7] mean.default             mean.difftime            mean.POSIXct
> > [10] mean.POSIXlt             mean.yearmon*            mean.yearqtr*
> > [13] mean.zoo*
> >
> > It is your responsibility to determine whether any particular function
> in your version of R satisfies the language requirements at the time of
> your use. Jim Albert and Maria Rizzo do not set the standards for what is
> an evolving piece of software.
> >
> > --
> > David.
> >
> >
> > > But, when I could not reproduce these results,
> > > then I thought that probably, this could possibly be due to some
> missing
> > > values NA's in Weight and Height variables. Then I tried the above
> code for
> > > the "mtcars" dataset for INDICES=mtcars$am. When I found the same
> results
> > > here too, then I reported the case in "r-help at R-project.org".
> > >
> > > With best regards,
> > >
> > > Dr. A.K. Singh
> > > Head, Department of Agril. Statistics
> > > Indira Gandhi Krishi Vishwavidyalaya, Raipur
> > > Chhattisgarh, India, PIN-492012
> > > Mobile: +919752620740
> > > Email: akhileshsingh.igkv at gmail.com
> > >
> > > On Fri, Apr 15, 2016 at 3:06 AM, Adrian Du?a <dusa.adrian at unibuc.ro>
> wrote:
> > >
> > >> I think you are not using the best function for what your intentions
> are.
> > >> Try:
> > >>
> > >>> by(data=mtcars, INDICES=list(as.factor(mtcars$am)), FUN=colMeans)
> > >> : 0
> > >>        mpg         cyl        disp          hp        drat          wt
> > >>     qsec          vs
> > >> 17.1473684   6.9473684 290.3789474 160.2631579   3.2863158   3.7688947
> > >> 18.1831579   0.3684211
> > >>         am        gear        carb
> > >>  0.0000000   3.2105263   2.7368421
> > >>
> > >>
> ---------------------------------------------------------------------------
> > >> : 1
> > >>        mpg         cyl        disp          hp        drat          wt
> > >>     qsec          vs
> > >> 24.3923077   5.0769231 143.5307692 126.8461538   4.0500000   2.4110000
> > >> 17.3600000   0.5384615
> > >>         am        gear        carb
> > >>  1.0000000   4.3846154   2.9230769
> > >>
> > >> See the difference between colMeans() and mean() in their respective
> help
> > >> files.
> > >> Hth,
> > >> Adrian
> > >>
> > >> On Thu, Apr 14, 2016 at 11:14 PM, Akhilesh Singh <
> > >> akhileshsingh.igkv at gmail.com> wrote:
> > >>
> > >>> Dear Sirs,
> > >>>
> > >>> I am Professor at Indira Gandhi Krishi Vishwavidyalaya, Raipur,
> > >>> Chhattisgarh, India.
> > >>>
> > >>> While taking classes, I found the *by() *function producing following
> > >>> error
> > >>>
> > >>> when I use FUN=mean or median and some other functions, however,
> > >>> FUN=summary works.
> > >>>
> > >>> Given below is the output of the example I used on a built-in dataset
> > >>> "mtcars", along with error message reproduced herewith:
> > >>>
> > >>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=mean)
> > >>> : 0
> > >>> [1] NA
> > >>> ------------------------------------------------------------
> > >>> : 1
> > >>> [1] NA
> > >>> Warning messages:
> > >>> 1: In mean.default(data[x, , drop = FALSE], ...) :
> > >>>  argument is not numeric or logical: returning NA
> > >>> 2: In mean.default(data[x, , drop = FALSE], ...) :
> > >>>  argument is not numeric or logical: returning NA
> > >>>
> > >>> However, the same by() function works for FUN=summary, given below
> is the
> > >>> output:
> > >>>
> > >>>> by(data=mtcars, INDICES=list(mtcars$am), FUN=summary)
> > >>> : 0
> > >>>      mpg             cyl             disp             hp
> > >>> Min.   :10.40   Min.   :4.000   Min.   :120.1   Min.   : 62.0
> > >>> 1st Qu.:14.95   1st Qu.:6.000   1st Qu.:196.3   1st Qu.:116.5
> > >>> Median :17.30   Median :8.000   Median :275.8   Median :175.0
> > >>> Mean   :17.15   Mean   :6.947   Mean   :290.4   Mean   :160.3
> > >>> 3rd Qu.:19.20   3rd Qu.:8.000   3rd Qu.:360.0   3rd Qu.:192.5
> > >>> Max.   :24.40   Max.   :8.000   Max.   :472.0   Max.   :245.0
> > >>>      drat             wt             qsec             vs
>    am
> > >>>
> > >>> Min.   :2.760   Min.   :2.465   Min.   :15.41   Min.   :0.0000   Min.
> > >>> :0
> > >>>
> > >>> 1st Qu.:3.070   1st Qu.:3.438   1st Qu.:17.18   1st Qu.:0.0000   1st
> > >>> Qu.:0
> > >>>
> > >>> Median :3.150   Median :3.520   Median :17.82   Median :0.0000
>  Median
> > >>> :0
> > >>>
> > >>> Mean   :3.286   Mean   :3.769   Mean   :18.18   Mean   :0.3684   Mean
> > >>> :0
> > >>>
> > >>> 3rd Qu.:3.695   3rd Qu.:3.842   3rd Qu.:19.17   3rd Qu.:1.0000   3rd
> > >>> Qu.:0
> > >>>
> > >>> Max.   :3.920   Max.   :5.424   Max.   :22.90   Max.   :1.0000   Max.
> > >>> :0
> > >>>
> > >>>      gear            carb
> > >>> Min.   :3.000   Min.   :1.000
> > >>> 1st Qu.:3.000   1st Qu.:2.000
> > >>> Median :3.000   Median :3.000
> > >>> Mean   :3.211   Mean   :2.737
> > >>> 3rd Qu.:3.000   3rd Qu.:4.000
> > >>> Max.   :4.000   Max.   :4.000
> > >>> ------------------------------------------------------------
> > >>> : 1
> > >>>      mpg             cyl             disp             hp
>  drat
> > >>>
> > >>> Min.   :15.00   Min.   :4.000   Min.   : 71.1   Min.   : 52.0   Min.
> > >>> :3.54
> > >>> 1st Qu.:21.00   1st Qu.:4.000   1st Qu.: 79.0   1st Qu.: 66.0   1st
> > >>> Qu.:3.85
> > >>> Median :22.80   Median :4.000   Median :120.3   Median :109.0
>  Median
> > >>> :4.08
> > >>> Mean   :24.39   Mean   :5.077   Mean   :143.5   Mean   :126.8   Mean
> > >>> :4.05
> > >>> 3rd Qu.:30.40   3rd Qu.:6.000   3rd Qu.:160.0   3rd Qu.:113.0   3rd
> > >>> Qu.:4.22
> > >>> Max.   :33.90   Max.   :8.000   Max.   :351.0   Max.   :335.0   Max.
> > >>> :4.93
> > >>>       wt             qsec             vs               am
>  gear
> > >>>
> > >>> Min.   :1.513   Min.   :14.50   Min.   :0.0000   Min.   :1   Min.
> > >>> :4.000
> > >>>
> > >>> 1st Qu.:1.935   1st Qu.:16.46   1st Qu.:0.0000   1st Qu.:1   1st
> > >>> Qu.:4.000
> > >>>
> > >>> Median :2.320   Median :17.02   Median :1.0000   Median :1   Median
> > >>> :4.000
> > >>>
> > >>> Mean   :2.411   Mean   :17.36   Mean   :0.5385   Mean   :1   Mean
> > >>> :4.385
> > >>>
> > >>> 3rd Qu.:2.780   3rd Qu.:18.61   3rd Qu.:1.0000   3rd Qu.:1   3rd
> > >>> Qu.:5.000
> > >>>
> > >>> Max.   :3.570   Max.   :19.90   Max.   :1.0000   Max.   :1   Max.
> > >>> :5.000
> > >>>
> > >>>      carb
> > >>> Min.   :1.000
> > >>> 1st Qu.:1.000
> > >>> Median :2.000
> > >>> Mean   :2.923
> > >>> 3rd Qu.:4.000
> > >>> Max.   :8.000
> > >>>>
> > >>>
> > >>> I am using the latest version of *R-3.2.4 on Windows*, however, this
> error
> > >>> is being generated in the previous version too,
> > >>>
> > >>> Hope this reporting will get serious attention in debugging.
> > >>>
> > >>> With best regards,
> > >>>
> > >>> Dr. A.K. Singh
> > >>> Head, Department of Agril. Statistics
> > >>> Indira Gandhi Krishi Vishwavidyalaya, Raipur
> > >>> Chhattisgarh, India, PIN-492012
> > >>> Mobile: +919752620740
> > >>> Email: akhileshsingh.igkv at gmail.com
> > >>>
> > >>>        [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >>> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>
> > >>
> > >>
> > >> --
> > >> Adrian Dusa
> > >> University of Bucharest
> > >> Romanian Social Data Archive
> > >> Soseaua Panduri nr.90
> > >> 050663 Bucharest sector 5
> > >> Romania
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From sj_style_1125 at outlook.com  Sun Apr 17 19:59:17 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Sun, 17 Apr 2016 17:59:17 +0000
Subject: [R] R [coding : do not run for every row ]
Message-ID: <HK2PR01MB0881F987E2E35CEBB107D475B56A0@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>

i have combined all the variables in a matrix, and i wish to conduct a simulation row by row.

But i found out the code only works for the every first row after a cycle of nine samples.

But after check out the code, i don know where is my mistake...

can anyone pls help ....


#For gamma disribution with equal skewness 1.5

#to evaluate the same R function on many different sets of data
library(parallel)

nSims<-100
alpha<-0.05

#set nrow =nsims because wan storing every p-value simulated
#for gamma distribution with equal skewness
matrix2_equal  <-matrix(0,nrow=nSims,ncol=3)
matrix5_unequal<-matrix(0,nrow=nSims,ncol=3)
matrix8_mann   <-matrix(0,nrow=nSims,ncol=3)

# to ensure the reproducity of the result
#here we declare the random seed generator
set.seed(1)

## Put the samples sizes into matrix then use a loop for sample sizes
sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
nrow=2)

#shape parameter for both gamma distribution for equal skewness
#forty five cases for each skewness!!
shp<-rep(16/9,each=5)

#scale parameter for sample 1
#scale paramter for sample 2 set as constant 1
scp1<-c(1,1.5,2,2.5,3)

#get all combinations with one row of the sample_sizes matrix
##(use expand.grid)to create a data frame from combination of data

ss_sd1<- expand.grid(sample_sizes[2,],shp)
scp1<-rep(scp1,9)

std2<-rep(sd2,9)

#create a matrix combining the forty five cases of combination of sample sizes,shape and scale parameter
all_combine1 <- cbind(rep(sample_sizes[1,], 5),ss_sd1,scp1)

# name the column samples 1 and 2 and standard deviation
colnames(all_combine1) <- c("m", "n","sp(skewness1.5)","scp1")

##for the samples sizes into matrix then use a loop for sample sizes
 # this loop steps through the all_combine matrix
  for(ss in 1:nrow(all_combine1))
  {
    #generate samples from the first column and second column
     m<-all_combine1[ss,1]
     n<-all_combine1[ss,2]

       for (sim in 1:nSims)
       {
        #generate 2 random samples from gamma distribution with equal skewness
        gamma1<-rgamma(m,all_combine1[ss,3],all_combine1[ss,4])
        gamma2<-rgamma(n,all_combine1[ss,4],1)

        # minus the population mean to ensure that there is no lose of equality of mean
        gamma1<-gamma1-all_combine1[ss,3]*all_combine1[ss,4]
        gamma2<-gamma2-all_combine1[ss,3]

        #extract p-value out and store every p-value into matrix
        matrix2_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
        matrix5_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
        matrix8_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
    }
       ##store the result
      equal[ss]<- mean(matrix2_equal[,1]<=alpha)
      unequal[ss]<-mean(matrix5_unequal[,2]<=alpha)
      mann[ss]<- mean(matrix8_mann[,3]<=alpha)
  }

g_equal<-cbind(all_combine1, equal, unequal, mann)

It is my result but it show a very big mistake ....TT
     m   n sp(skewness1.5) scp1 equal unequal mann
1   10  10        1.777778  1.0  0.36    0.34 0.34
2   10  25        1.777778  1.5  0.84    0.87 0.90
3   25  25        1.777778  2.0  1.00    1.00 1.00
4   25  50        1.777778  2.5  1.00    1.00 1.00
5   25 100        1.777778  3.0  1.00    1.00 1.00
6   50  25        1.777778  1.0  0.77    0.77 0.84
7   50 100        1.777778  1.5  1.00    1.00 1.00
8  100  25        1.777778  2.0  1.00    1.00 1.00
9  100 100        1.777778  2.5  1.00    1.00 1.00
10  10  10        1.777778  3.0  1.00    1.00 1.00
11  10  25        1.777778  1.0  0.48    0.30 0.55
12  25  25        1.777778  1.5  0.99    0.99 1.00
13  25  50        1.777778  2.0  1.00    1.00 1.00
14  25 100        1.777778  2.5  1.00    1.00 1.00
15  50  25        1.777778  3.0  1.00    1.00 1.00
16  50 100        1.777778  1.0  0.97    0.97 1.00
17 100  25        1.777778  1.5  1.00    1.00 1.00
18 100 100        1.777778  2.0  1.00    1.00 1.00
19  10  10        1.777778  2.5  1.00    1.00 1.00
20  10  25        1.777778  3.0  1.00    1.00 1.00
21  25  25        1.777778  1.0  0.63    0.63 0.71
22  25  50        1.777778  1.5  0.99    0.99 0.99
23  25 100        1.777778  2.0  1.00    1.00 1.00
24  50  25        1.777778  2.5  1.00    1.00 1.00
25  50 100        1.777778  3.0  1.00    1.00 1.00
26 100  25        1.777778  1.0  0.83    0.90 0.88
27 100 100        1.777778  1.5  1.00    1.00 1.00
28  10  10        1.777778  2.0  1.00    1.00 1.00
29  10  25        1.777778  2.5  1.00    1.00 1.00
30  25  25        1.777778  3.0  1.00    1.00 1.00
31  25  50        1.777778  1.0  0.71    0.66 0.81
32  25 100        1.777778  1.5  1.00    1.00 1.00
33  50  25        1.777778  2.0  1.00    1.00 1.00
34  50 100        1.777778  2.5  1.00    1.00 1.00
35 100  25        1.777778  3.0  1.00    1.00 1.00
36 100 100        1.777778  1.0  0.99    0.99 1.00
37  10  10        1.777778  1.5  0.65    0.65 0.71
38  10  25        1.777778  2.0  1.00    1.00 1.00
39  25  25        1.777778  2.5  1.00    1.00 1.00
40  25  50        1.777778  3.0  1.00    1.00 1.00
41  25 100        1.777778  1.0  0.90    0.89 0.96
42  50  25        1.777778  1.5  0.99    0.99 1.00
43  50 100        1.777778  2.0  1.00    1.00 1.00
44 100  25        1.777778  2.5  1.00    1.00 1.00
45 100 100        1.777778  3.0  1.00    1.00 1.00
>



	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Apr 17 23:45:27 2016
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 17 Apr 2016 17:45:27 -0400
Subject: [R] Last
In-Reply-To: <CAJOiR6Ye9FCvRO_U_RaRRHjSKzT__ojQph0ukeJXCETj+HXM6Q@mail.gmail.com>
References: <CAJOiR6ZTBFjwq979Z+qMgS4ZjDgiv=Mw74_a0TVSCMdv0HOz4Q@mail.gmail.com>
	<74AD0C3F-9A00-4682-AD02-E25E9F7705ED@utoronto.ca>
	<CAJOiR6Ye9FCvRO_U_RaRRHjSKzT__ojQph0ukeJXCETj+HXM6Q@mail.gmail.com>
Message-ID: <CFF9D56F-88F0-4154-824F-70BD6D025324@utoronto.ca>

According to the docs:
  getSheets() returns a list of java object references each pointing to an worksheet.

...and the Examples section of the help page shows you how to work with that. Can't tell whether the methods cover what you need though.


B.




On Apr 17, 2016, at 5:36 PM, Val <valkremk at gmail.com> wrote:

> Thank you very much Boris.
> Worked fine.  My aim is to read the last sheet and the sheet preceding to it
> 
> What I did is
> L = length(getSheets(loadWorkbook("las.xlsx"))
> 
> K1 =read.xlsx("las.xlsx", sheetIndex = L)
> K2 =read.xlsx("las.xlsx", sheetIndex = L-1)
> 
> Is it possible to in one step instead of reading the file three times?
> 
> 
> Val
> 
> 
> 
> 
> 
> On Sun, Apr 17, 2016 at 9:26 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Does
>   length(getSheets(loadWorkbook("las.xlsx"))
> 
> give you the index you need? (Untested).
> 
> B.
> 
> 
> On Apr 17, 2016, at 9:43 AM, Val <valkremk at gmail.com> wrote:
> 
> > Hi all,
> >
> > I am trying to read data from a particular  excel sheet.
> >
> > library(xlsx)
> > dat1=read.xlsx("las.xlsx", sheetIndex = 5)
> >
> > I know that this is sheet is the last one and this number grows over time
> >
> > When I run my script to read the last sheet then I have to change this
> > number every time manually.
> >
> > Is it possible to read the last sheet of an excel file?
> > Thank yo in advance
> > Val
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From thierry.onkelinx at inbo.be  Mon Apr 18 08:54:56 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 18 Apr 2016 08:54:56 +0200
Subject: [R] R [coding : do not run for every row ]
In-Reply-To: <HK2PR01MB0881F987E2E35CEBB107D475B56A0@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>
References: <HK2PR01MB0881F987E2E35CEBB107D475B56A0@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>
Message-ID: <CAJuCY5yUh5giO0cFxtX9nhnUONOCjr2t2SyeTOOzQgZ5rXwA+g@mail.gmail.com>

Dear anonymous,

The big mistake in the output might be obvious to you but not to
others. Please make clear what the correct output should be or at
least what is wrong with the current output.

And please DO read the posting guide which asks you not to post in HTML.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2016-04-17 19:59 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
> i have combined all the variables in a matrix, and i wish to conduct a simulation row by row.
>
> But i found out the code only works for the every first row after a cycle of nine samples.
>
> But after check out the code, i don know where is my mistake...
>
> can anyone pls help ....
>
>
> #For gamma disribution with equal skewness 1.5
>
> #to evaluate the same R function on many different sets of data
> library(parallel)
>
> nSims<-100
> alpha<-0.05
>
> #set nrow =nsims because wan storing every p-value simulated
> #for gamma distribution with equal skewness
> matrix2_equal  <-matrix(0,nrow=nSims,ncol=3)
> matrix5_unequal<-matrix(0,nrow=nSims,ncol=3)
> matrix8_mann   <-matrix(0,nrow=nSims,ncol=3)
>
> # to ensure the reproducity of the result
> #here we declare the random seed generator
> set.seed(1)
>
> ## Put the samples sizes into matrix then use a loop for sample sizes
> sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
> nrow=2)
>
> #shape parameter for both gamma distribution for equal skewness
> #forty five cases for each skewness!!
> shp<-rep(16/9,each=5)
>
> #scale parameter for sample 1
> #scale paramter for sample 2 set as constant 1
> scp1<-c(1,1.5,2,2.5,3)
>
> #get all combinations with one row of the sample_sizes matrix
> ##(use expand.grid)to create a data frame from combination of data
>
> ss_sd1<- expand.grid(sample_sizes[2,],shp)
> scp1<-rep(scp1,9)
>
> std2<-rep(sd2,9)
>
> #create a matrix combining the forty five cases of combination of sample sizes,shape and scale parameter
> all_combine1 <- cbind(rep(sample_sizes[1,], 5),ss_sd1,scp1)
>
> # name the column samples 1 and 2 and standard deviation
> colnames(all_combine1) <- c("m", "n","sp(skewness1.5)","scp1")
>
> ##for the samples sizes into matrix then use a loop for sample sizes
>  # this loop steps through the all_combine matrix
>   for(ss in 1:nrow(all_combine1))
>   {
>     #generate samples from the first column and second column
>      m<-all_combine1[ss,1]
>      n<-all_combine1[ss,2]
>
>        for (sim in 1:nSims)
>        {
>         #generate 2 random samples from gamma distribution with equal skewness
>         gamma1<-rgamma(m,all_combine1[ss,3],all_combine1[ss,4])
>         gamma2<-rgamma(n,all_combine1[ss,4],1)
>
>         # minus the population mean to ensure that there is no lose of equality of mean
>         gamma1<-gamma1-all_combine1[ss,3]*all_combine1[ss,4]
>         gamma2<-gamma2-all_combine1[ss,3]
>
>         #extract p-value out and store every p-value into matrix
>         matrix2_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
>         matrix5_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
>         matrix8_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
>     }
>        ##store the result
>       equal[ss]<- mean(matrix2_equal[,1]<=alpha)
>       unequal[ss]<-mean(matrix5_unequal[,2]<=alpha)
>       mann[ss]<- mean(matrix8_mann[,3]<=alpha)
>   }
>
> g_equal<-cbind(all_combine1, equal, unequal, mann)
>
> It is my result but it show a very big mistake ....TT
>      m   n sp(skewness1.5) scp1 equal unequal mann
> 1   10  10        1.777778  1.0  0.36    0.34 0.34
> 2   10  25        1.777778  1.5  0.84    0.87 0.90
> 3   25  25        1.777778  2.0  1.00    1.00 1.00
> 4   25  50        1.777778  2.5  1.00    1.00 1.00
> 5   25 100        1.777778  3.0  1.00    1.00 1.00
> 6   50  25        1.777778  1.0  0.77    0.77 0.84
> 7   50 100        1.777778  1.5  1.00    1.00 1.00
> 8  100  25        1.777778  2.0  1.00    1.00 1.00
> 9  100 100        1.777778  2.5  1.00    1.00 1.00
> 10  10  10        1.777778  3.0  1.00    1.00 1.00
> 11  10  25        1.777778  1.0  0.48    0.30 0.55
> 12  25  25        1.777778  1.5  0.99    0.99 1.00
> 13  25  50        1.777778  2.0  1.00    1.00 1.00
> 14  25 100        1.777778  2.5  1.00    1.00 1.00
> 15  50  25        1.777778  3.0  1.00    1.00 1.00
> 16  50 100        1.777778  1.0  0.97    0.97 1.00
> 17 100  25        1.777778  1.5  1.00    1.00 1.00
> 18 100 100        1.777778  2.0  1.00    1.00 1.00
> 19  10  10        1.777778  2.5  1.00    1.00 1.00
> 20  10  25        1.777778  3.0  1.00    1.00 1.00
> 21  25  25        1.777778  1.0  0.63    0.63 0.71
> 22  25  50        1.777778  1.5  0.99    0.99 0.99
> 23  25 100        1.777778  2.0  1.00    1.00 1.00
> 24  50  25        1.777778  2.5  1.00    1.00 1.00
> 25  50 100        1.777778  3.0  1.00    1.00 1.00
> 26 100  25        1.777778  1.0  0.83    0.90 0.88
> 27 100 100        1.777778  1.5  1.00    1.00 1.00
> 28  10  10        1.777778  2.0  1.00    1.00 1.00
> 29  10  25        1.777778  2.5  1.00    1.00 1.00
> 30  25  25        1.777778  3.0  1.00    1.00 1.00
> 31  25  50        1.777778  1.0  0.71    0.66 0.81
> 32  25 100        1.777778  1.5  1.00    1.00 1.00
> 33  50  25        1.777778  2.0  1.00    1.00 1.00
> 34  50 100        1.777778  2.5  1.00    1.00 1.00
> 35 100  25        1.777778  3.0  1.00    1.00 1.00
> 36 100 100        1.777778  1.0  0.99    0.99 1.00
> 37  10  10        1.777778  1.5  0.65    0.65 0.71
> 38  10  25        1.777778  2.0  1.00    1.00 1.00
> 39  25  25        1.777778  2.5  1.00    1.00 1.00
> 40  25  50        1.777778  3.0  1.00    1.00 1.00
> 41  25 100        1.777778  1.0  0.90    0.89 0.96
> 42  50  25        1.777778  1.5  0.99    0.99 1.00
> 43  50 100        1.777778  2.0  1.00    1.00 1.00
> 44 100  25        1.777778  2.5  1.00    1.00 1.00
> 45 100 100        1.777778  3.0  1.00    1.00 1.00
>>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Mon Apr 18 09:21:43 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 18 Apr 2016 09:21:43 +0200
Subject: [R] R [coding : do not run for every row ]
In-Reply-To: <KL1PR01MB08877493D844C7BAA6E3E433B56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <HK2PR01MB0881F987E2E35CEBB107D475B56A0@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>
	<CAJuCY5yUh5giO0cFxtX9nhnUONOCjr2t2SyeTOOzQgZ5rXwA+g@mail.gmail.com>
	<KL1PR01MB08877493D844C7BAA6E3E433B56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <CAJuCY5zHFeSkBBb4icOJSVKo1-nTauYKJsvXdnk6TD=+RCfSYQ@mail.gmail.com>

You can make this much more readable with apply functions.

result <- apply(
  all_combine1,
  1,
  function(x){
    p.value <- sapply(
      seq_len(nSims),
      function(sim){
        gamma1 <- rgamma(x["m"], x["sp(skewness1.5)"], x["scp1"])
        gamma2 <- rgamma(x["n"], x["scp1"], 1)
        gamma1 <- gamma1 - x["sp(skewness1.5)"] * x["scp1"]
        gamma2 <- gamma2 - x["sp(skewness1.5)"]
        c(
          equal = t.test(gamma1, gamma2, var.equal=TRUE)$p.value,
          unequal = t.test(gamma1,gamma2,var.equal=FALSE)$p.value,
          mann = wilcox.test(gamma1,gamma2)$p.value
        )
      }
    )
    rowMeans(p.value <= alpha)
  }
)
cbind(all_combine1, t(result))
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2016-04-18 9:05 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
> Hi, i am sorry, the output should be values between 0 and 0.1 and not
> supposed to be 1.00, it is because they are type 1 error rate. And now i get
> output 1.00 for several samples,rhis is no correct. The loop do not run for
> every row. i do not know where is my mistake.  As i use the same concept on
> normal distribution setup, i get the result.
>
> Sent from my phone
>
> On Thierry Onkelinx <thierry.onkelinx at inbo.be>, Apr 18, 2016 2:55 PM wrote:
> Dear anonymous,
>
> The big mistake in the output might be obvious to you but not to
> others. Please make clear what the correct output should be or at
> least what is wrong with the current output.
>
> And please DO read the posting guide which asks you not to post in HTML.
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2016-04-17 19:59 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
>> i have combined all the variables in a matrix, and i wish to conduct a
>> simulation row by row.
>>
>> But i found out the code only works for the every first row after a cycle
>> of nine samples.
>>
>> But after check out the code, i don know where is my mistake...
>>
>> can anyone pls help ....
>>
>>
>> #For gamma disribution with equal skewness 1.5
>>
>> #to evaluate the same R function on many different sets of data
>> library(parallel)
>>
>> nSims<-100
>> alpha<-0.05
>>
>> #set nrow =nsims because wan storing every p-value simulated
>> #for gamma distribution with equal skewness
>> matrix2_equal  <-matrix(0,nrow=nSims,ncol=3)
>> matrix5_unequal<-matrix(0,nrow=nSims,ncol=3)
>> matrix8_mann   <-matrix(0,nrow=nSims,ncol=3)
>>
>> # to ensure the reproducity of the result
>> #here we declare the random seed generator
>> set.seed(1)
>>
>> ## Put the samples sizes into matrix then use a loop for sample sizes
>>
>> sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
>> nrow=2)
>>
>> #shape parameter for both gamma distribution for equal skewness
>> #forty five cases for each skewness!!
>> shp<-rep(16/9,each=5)
>>
>> #scale parameter for sample 1
>> #scale paramter for sample 2 set as constant 1
>> scp1<-c(1,1.5,2,2.5,3)
>>
>> #get all combinations with one row of the sample_sizes matrix
>> ##(use expand.grid)to create a data frame from combination of data
>>
>> ss_sd1<- expand.grid(sample_sizes[2,],shp)
>> scp1<-rep(scp1,9)
>>
>> std2<-rep(sd2,9)
>>
>> #create a matrix combining the forty five cases of combination of sample
>> sizes,shape and scale parameter
>> all_combine1 <- cbind(rep(sample_sizes[1,], 5),ss_sd1,scp1)
>>
>> # name the column samples 1 and 2 and standard deviation
>> colnames(all_combine1) <- c("m", "n","sp(skewness1.5)","scp1")
>>
>> ##for the samples sizes into matrix then use a loop for sample sizes
>>  # this loop steps through the all_combine matrix
>>   for(ss in 1:nrow(all_combine1))
>>   {
>>     #generate samples from the first column and second column
>>      m<-all_combine1[ss,1]
>>      n<-all_combine1[ss,2]
>>
>>        for (sim in 1:nSims)
>>        {
>>         #generate 2 random samples from gamma distribution with equal
>> skewness
>>         gamma1<-rgamma(m,all_combine1[ss,3],all_combine1[ss,4])
>>         gamma2<-rgamma(n,all_combine1[ss,4],1)
>>
>>         # minus the population mean to ensure that there is no lose of
>> equality of mean
>>         gamma1<-gamma1-all_combine1[ss,3]*all_combine1[ss,4]
>>         gamma2<-gamma2-all_combine1[ss,3]
>>
>>         #extract p-value out and store every p-value into matrix
>>         matrix2_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
>>
>> matrix5_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
>>         matrix8_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
>>     }
>>        ##store the result
>>       equal[ss]<- mean(matrix2_equal[,1]<=alpha)
>>       unequal[ss]<-mean(matrix5_unequal[,2]<=alpha)
>>       mann[ss]<- mean(matrix8_mann[,3]<=alpha)
>>   }
>>
>> g_equal<-cbind(all_combine1, equal, unequal, mann)
>>
>> It is my result but it show a very big mistake ....TT
>>      m   n sp(skewness1.5) scp1 equal unequal mann
>> 1   10  10        1.777778  1.0  0.36    0.34 0.34
>> 2   10  25        1.777778  1.5  0.84    0.87 0.90
>> 3   25  25        1.777778  2.0  1.00    1.00 1.00
>> 4   25  50        1.777778  2.5  1.00    1.00 1.00
>> 5   25 100        1.777778  3.0  1.00    1.00 1.00
>> 6   50  25        1.777778  1.0  0.77    0.77 0.84
>> 7   50 100        1.777778  1.5  1.00    1.00 1.00
>> 8  100  25        1.777778  2.0  1.00    1.00 1.00
>> 9  100 100        1.777778  2.5  1.00    1.00 1.00
>> 10  10  10        1.777778  3.0  1.00    1.00 1.00
>> 11  10  25        1.777778  1.0  0.48    0.30 0.55
>> 12  25  25        1.777778  1.5  0.99    0.99 1.00
>> 13  25  50        1.777778  2.0  1.00    1.00 1.00
>> 14  25 100        1.777778  2.5  1.00    1.00 1.00
>> 15  50  25        1.777778  3.0  1.00    1.00 1.00
>> 16  50 100        1.777778  1.0  0.97    0.97 1.00
>> 17 100  25        1.777778  1.5  1.00    1.00 1.00
>> 18 100 100        1.777778  2.0  1.00    1.00 1.00
>> 19  10  10        1.777778  2.5  1.00    1.00 1.00
>> 20  10  25        1.777778  3.0  1.00    1.00 1.00
>> 21  25  25        1.777778  1.0  0.63    0.63 0.71
>> 22  25  50        1.777778  1.5  0.99    0.99 0.99
>> 23  25 100        1.777778  2.0  1.00    1.00 1.00
>> 24  50  25        1.777778  2.5  1.00    1.00 1.00
>> 25  50 100        1.777778  3.0  1.00    1.00 1.00
>> 26 100  25        1.777778  1.0  0.83    0.90 0.88
>> 27 100 100        1.777778  1.5  1.00    1.00 1.00
>> 28  10  10        1.777778  2.0  1.00    1.00 1.00
>> 29  10  25        1.777778  2.5  1.00    1.00 1.00
>> 30  25  25        1.777778  3.0  1.00    1.00 1.00
>> 31  25  50        1.777778  1.0  0.71    0.66 0.81
>> 32  25 100        1.777778  1.5  1.00    1.00 1.00
>> 33  50  25        1.777778  2.0  1.00    1.00 1.00
>> 34  50 100        1.777778  2.5  1.00    1.00 1.00
>> 35 100  25        1.777778  3.0  1.00    1.00 1.00
>> 36 100 100        1.777778  1.0  0.99    0.99 1.00
>> 37  10  10        1.777778  1.5  0.65    0.65 0.71
>> 38  10  25        1.777778  2.0  1.00    1.00 1.00
>> 39  25  25        1.777778  2.5  1.00    1.00 1.00
>> 40  25  50        1.777778  3.0  1.00    1.00 1.00
>> 41  25 100        1.777778  1.0  0.90    0.89 0.96
>> 42  50  25        1.777778  1.5  0.99    0.99 1.00
>> 43  50 100        1.777778  2.0  1.00    1.00 1.00
>> 44 100  25        1.777778  2.5  1.00    1.00 1.00
>> 45 100 100        1.777778  3.0  1.00    1.00 1.00
>>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From msuzen at gmail.com  Mon Apr 18 11:18:41 2016
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 18 Apr 2016 10:18:41 +0100
Subject: [R] Social Network Simulation
In-Reply-To: <CAOyz9G5uceOub7eoFxB2hzyRWmdct=V=OG6n6QtoXsVQVP8ATg@mail.gmail.com>
References: <CAOyz9G5uceOub7eoFxB2hzyRWmdct=V=OG6n6QtoXsVQVP8ATg@mail.gmail.com>
Message-ID: <CAPtbhHw5KZAcOEtPqqVUs3uy7zizamqOsiQL_s0RbjJ4k7fv=A@mail.gmail.com>

Dear Professor Haenlein,
Have you solved this issue yet? I found this eally interesting problem
I was wondering if it is possible to wrapper "objective function"
around igraph's 'sample_pa' and
'sample_smallworld'. If you have an example data set, I can have a look at this.
Viele Gruesse aus London
Mehmet

On 16 April 2016 at 14:16, Michael Haenlein <haenlein at escpeurope.eu> wrote:
> Dear all,
>
> I am trying to simulate a series of networks that have characteristics
> similar to real life social networks. Specifically I am interested in
> networks that have (a) a reasonable degree of clustering (as measured by
> the transitivity function in igraph) and (b) a reasonable degree of degree
> polarization (as measured by the average degree of the top 10% nodes with
> highest degree divided by the overall average degree).
>
> Right now I am using two functions from irgaph (sample_pa and
> sample_smallworld) but these are not ideal since they only allow me to vary
> one of the two characteristics. Either the network has good clustering but
> not enough polarization or the other way round.
>
> I looked around and I found some network algorithms that solve the problem
> (E.g., Jackson and Rogers, Meeting Strangers and Friends of Friends), but I
> did not find their implemented in an R package. I also found the R package
> NetSim which seems to be in this spirit, but I cannot get it to work.
>
> Could anyone point me to an R library that I could check out? I do not care
> much about the specific algorithm used as long as it allows me to vary
> clustering and degree polarization in certain ranges.
>
> Thanks,
>
> Michael
>
>
> Michael Haenlein
> Professor of Marketing
> ESCP Europe, Paris
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From angelovarlotta at gmail.com  Mon Apr 18 09:48:54 2016
From: angelovarlotta at gmail.com (Angelo Varlotta)
Date: Mon, 18 Apr 2016 09:48:54 +0200
Subject: [R] 'nlme' package not compiling
Message-ID: <57149166.8000905@gmail.com>

Hi,
I'm trying to install from source code the 'nlme' package in 
RStudio. When I try, I get the following error message:

ld: warning: directory not found for option 
'-L/usr/local/lib/gcc/x86_64-apple-darwin13.0.0/4.8.2'
ld: library not found for -lgfortran
clang: error: linker command failed with exit code 1 (use -v to 
see invocation)
make: *** [nlme.so] Error 1
ERROR: compilation failed for package ?nlme?
* removing 
?/Library/Frameworks/R.framework/Versions/3.2/Resources/library/nlme?
* restoring previous 
?/Library/Frameworks/R.framework/Versions/3.2/Resources/library/nlme?
Warning in install.packages :
   installation of package ?nlme? had non-zero exit status

I'm using gfortran 4.8 from Macports and running OS X 10.11.4 
with RStudio Version 0.99.893. I've tried to use the FLIBS 
command in R:

FLIBS="-L/opt/local/lib/gcc48/gcc/x86_64-apple-darwin15/4.8.5/"

so that it knows where the Fortran libraries are at and compile 
again, but it still searchesregardless for the directory:

/usr/local/lib/gcc/x86_64-apple-darwin13.0.0/4.8.2.

which of course doesn't exist. Any suggestions?

Cheers,
Angelo



	[[alternative HTML version deleted]]


From jody.kelly at northumbria.ac.uk  Mon Apr 18 09:45:26 2016
From: jody.kelly at northumbria.ac.uk (jody.kelly)
Date: Mon, 18 Apr 2016 07:45:26 +0000
Subject: [R] Help using R Sensitivity
Message-ID: <HE1PR04MB16262197D12F26C8E848FFB7C86B0@HE1PR04MB1626.eurprd04.prod.outlook.com>

Hello,

I am currently using the sensitivity package standard regression coefficient in order to rank variable importance in a model. I am new to using R so there may be some obvious things I am unaware of, apologies in advance as I am still learning.

I am using the following which I have taken straight from the help guide.

# a 100-sample with X1 ~ U(0.5, 1.5)
# X2 ~ U(1.5, 4.5)
# X3 ~ U(4.5, 13.5)

library(boot)
n <- 100
X <- data.frame(X1 = runif(n, 0.5, 1.5),
X2 = runif(n, 1.5, 4.5),
X3 = runif(n, 4.5, 13.5))

# linear model : Y = X1 + X2 + X3

y <- with(X, X1 + X2 + X3)

# sensitivity analysis

x <- src(X, y, nboot = 100)


plot(x)
Print(x)

This gives me ranks of the variables I have defined between -1 - 1. However this is the part I am unsure of how to apply to my own model.
I hope some one can give me advice on how to do this based on my own model as follows:



Model type: building energy consumption model.
Model Input variables (X): parameters relating to the building (X1 = 1.5-3.5, X2 = 7-12, X3 = 0.5 - 3, X4 = 10-15)
Model output variables (Y): Monthly Gas and electricity energy consumption

The spread sheet is as follows:  No of simulations: 1-40, for each simulation a new combination of model inputs (X) is used, therefore each simulation output (Y) will be different.

The aim of this analysis based on the 40 simulations is to rank input variables (X1-X4) based on importance of 1-4 with one being the most influential parameter and 4 being the least. What these variables are ranked upon, is their effect on the output variable (Y) which is energy consumption. Two variables will primarily have an effect on gas energy usage, and two will have an effect primarily on electricity energy usage. The aim is to produce a graph with left Y axis showing rank importance 1-4, X axis showing months January to December and the Y axis right showing the input variables with plots at each month showing its rank.

The spread sheet titles are set up as below. There are 40 simulations with varying combinations of X1-X4. Below each X value (X1-4) will be the input parameter value. Each simulations Y value will also change due to the change in variable combinations.

              Variable combinations (X)Y
Simulation No.X1X2X3X4JanFebMarAprMayJunJulAugSepOctNovDec


Thanks for any help in advance, much appreciated.

Jody


This message is intended solely for the addressee and may contain confidential and/or legally privileged information. Any use, disclosure or reproduction without the sender?s explicit consent is unauthorised and may be unlawful. If you have received this message in error, please notify Northumbria University immediately and permanently delete it. Any views or opinions expressed in this message are solely those of the author and do not necessarily represent those of the University. The University cannot guarantee that this message or any attachment is virus free or has not been intercepted and/or amended.

From sj_style_1125 at outlook.com  Mon Apr 18 09:05:43 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Mon, 18 Apr 2016 07:05:43 +0000
Subject: [R] R [coding : do not run for every row ]
In-Reply-To: <CAJuCY5yUh5giO0cFxtX9nhnUONOCjr2t2SyeTOOzQgZ5rXwA+g@mail.gmail.com>
References: <HK2PR01MB0881F987E2E35CEBB107D475B56A0@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>,
	<CAJuCY5yUh5giO0cFxtX9nhnUONOCjr2t2SyeTOOzQgZ5rXwA+g@mail.gmail.com>
Message-ID: <KL1PR01MB08877493D844C7BAA6E3E433B56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>

Hi, i am sorry, the output should be values between 0 and 0.1 and not supposed to be 1.00, it is because they are type 1 error rate. And now i get output 1.00 for several samples,rhis is no correct. The loop do not run for every row. i do not know where is my mistake.  As i use the same concept on normal distribution setup, i get the result.

Sent from my phone

On Thierry Onkelinx <thierry.onkelinx at inbo.be>, Apr 18, 2016 2:55 PM wrote:
Dear anonymous,

The big mistake in the output might be obvious to you but not to
others. Please make clear what the correct output should be or at
least what is wrong with the current output.

And please DO read the posting guide which asks you not to post in HTML.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2016-04-17 19:59 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
> i have combined all the variables in a matrix, and i wish to conduct a simulation row by row.
>
> But i found out the code only works for the every first row after a cycle of nine samples.
>
> But after check out the code, i don know where is my mistake...
>
> can anyone pls help ....
>
>
> #For gamma disribution with equal skewness 1.5
>
> #to evaluate the same R function on many different sets of data
> library(parallel)
>
> nSims<-100
> alpha<-0.05
>
> #set nrow =nsims because wan storing every p-value simulated
> #for gamma distribution with equal skewness
> matrix2_equal  <-matrix(0,nrow=nSims,ncol=3)
> matrix5_unequal<-matrix(0,nrow=nSims,ncol=3)
> matrix8_mann   <-matrix(0,nrow=nSims,ncol=3)
>
> # to ensure the reproducity of the result
> #here we declare the random seed generator
> set.seed(1)
>
> ## Put the samples sizes into matrix then use a loop for sample sizes
> sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
> nrow=2)
>
> #shape parameter for both gamma distribution for equal skewness
> #forty five cases for each skewness!!
> shp<-rep(16/9,each=5)
>
> #scale parameter for sample 1
> #scale paramter for sample 2 set as constant 1
> scp1<-c(1,1.5,2,2.5,3)
>
> #get all combinations with one row of the sample_sizes matrix
> ##(use expand.grid)to create a data frame from combination of data
>
> ss_sd1<- expand.grid(sample_sizes[2,],shp)
> scp1<-rep(scp1,9)
>
> std2<-rep(sd2,9)
>
> #create a matrix combining the forty five cases of combination of sample sizes,shape and scale parameter
> all_combine1 <- cbind(rep(sample_sizes[1,], 5),ss_sd1,scp1)
>
> # name the column samples 1 and 2 and standard deviation
> colnames(all_combine1) <- c("m", "n","sp(skewness1.5)","scp1")
>
> ##for the samples sizes into matrix then use a loop for sample sizes
>  # this loop steps through the all_combine matrix
>   for(ss in 1:nrow(all_combine1))
>   {
>     #generate samples from the first column and second column
>      m<-all_combine1[ss,1]
>      n<-all_combine1[ss,2]
>
>        for (sim in 1:nSims)
>        {
>         #generate 2 random samples from gamma distribution with equal skewness
>         gamma1<-rgamma(m,all_combine1[ss,3],all_combine1[ss,4])
>         gamma2<-rgamma(n,all_combine1[ss,4],1)
>
>         # minus the population mean to ensure that there is no lose of equality of mean
>         gamma1<-gamma1-all_combine1[ss,3]*all_combine1[ss,4]
>         gamma2<-gamma2-all_combine1[ss,3]
>
>         #extract p-value out and store every p-value into matrix
>         matrix2_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
>         matrix5_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
>         matrix8_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
>     }
>        ##store the result
>       equal[ss]<- mean(matrix2_equal[,1]<=alpha)
>       unequal[ss]<-mean(matrix5_unequal[,2]<=alpha)
>       mann[ss]<- mean(matrix8_mann[,3]<=alpha)
>   }
>
> g_equal<-cbind(all_combine1, equal, unequal, mann)
>
> It is my result but it show a very big mistake ....TT
>      m   n sp(skewness1.5) scp1 equal unequal mann
> 1   10  10        1.777778  1.0  0.36    0.34 0.34
> 2   10  25        1.777778  1.5  0.84    0.87 0.90
> 3   25  25        1.777778  2.0  1.00    1.00 1.00
> 4   25  50        1.777778  2.5  1.00    1.00 1.00
> 5   25 100        1.777778  3.0  1.00    1.00 1.00
> 6   50  25        1.777778  1.0  0.77    0.77 0.84
> 7   50 100        1.777778  1.5  1.00    1.00 1.00
> 8  100  25        1.777778  2.0  1.00    1.00 1.00
> 9  100 100        1.777778  2.5  1.00    1.00 1.00
> 10  10  10        1.777778  3.0  1.00    1.00 1.00
> 11  10  25        1.777778  1.0  0.48    0.30 0.55
> 12  25  25        1.777778  1.5  0.99    0.99 1.00
> 13  25  50        1.777778  2.0  1.00    1.00 1.00
> 14  25 100        1.777778  2.5  1.00    1.00 1.00
> 15  50  25        1.777778  3.0  1.00    1.00 1.00
> 16  50 100        1.777778  1.0  0.97    0.97 1.00
> 17 100  25        1.777778  1.5  1.00    1.00 1.00
> 18 100 100        1.777778  2.0  1.00    1.00 1.00
> 19  10  10        1.777778  2.5  1.00    1.00 1.00
> 20  10  25        1.777778  3.0  1.00    1.00 1.00
> 21  25  25        1.777778  1.0  0.63    0.63 0.71
> 22  25  50        1.777778  1.5  0.99    0.99 0.99
> 23  25 100        1.777778  2.0  1.00    1.00 1.00
> 24  50  25        1.777778  2.5  1.00    1.00 1.00
> 25  50 100        1.777778  3.0  1.00    1.00 1.00
> 26 100  25        1.777778  1.0  0.83    0.90 0.88
> 27 100 100        1.777778  1.5  1.00    1.00 1.00
> 28  10  10        1.777778  2.0  1.00    1.00 1.00
> 29  10  25        1.777778  2.5  1.00    1.00 1.00
> 30  25  25        1.777778  3.0  1.00    1.00 1.00
> 31  25  50        1.777778  1.0  0.71    0.66 0.81
> 32  25 100        1.777778  1.5  1.00    1.00 1.00
> 33  50  25        1.777778  2.0  1.00    1.00 1.00
> 34  50 100        1.777778  2.5  1.00    1.00 1.00
> 35 100  25        1.777778  3.0  1.00    1.00 1.00
> 36 100 100        1.777778  1.0  0.99    0.99 1.00
> 37  10  10        1.777778  1.5  0.65    0.65 0.71
> 38  10  25        1.777778  2.0  1.00    1.00 1.00
> 39  25  25        1.777778  2.5  1.00    1.00 1.00
> 40  25  50        1.777778  3.0  1.00    1.00 1.00
> 41  25 100        1.777778  1.0  0.90    0.89 0.96
> 42  50  25        1.777778  1.5  0.99    0.99 1.00
> 43  50 100        1.777778  2.0  1.00    1.00 1.00
> 44 100  25        1.777778  2.5  1.00    1.00 1.00
> 45 100 100        1.777778  3.0  1.00    1.00 1.00
>>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Apr 18 12:03:04 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 18 Apr 2016 12:03:04 +0200
Subject: [R] R [coding : do not run for every row ]
In-Reply-To: <KL1PR01MB08872B7FBD23D8D7AE506ACBB56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <HK2PR01MB0881F987E2E35CEBB107D475B56A0@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>
	<CAJuCY5yUh5giO0cFxtX9nhnUONOCjr2t2SyeTOOzQgZ5rXwA+g@mail.gmail.com>
	<KL1PR01MB08877493D844C7BAA6E3E433B56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
	<CAJuCY5zHFeSkBBb4icOJSVKo1-nTauYKJsvXdnk6TD=+RCfSYQ@mail.gmail.com>
	<KL1PR01MB08872B7FBD23D8D7AE506ACBB56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <CAJuCY5x==1pCVSj6HdJWimo_H6Exb99oh7DeV6ZxjisaQt04yg@mail.gmail.com>

Always keep the mailing list in cc.

The code runs for each row in the data. However I get the feeling that
there is a mismatch between what you think that is in the data and the
actual data.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2016-04-18 10:35 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
> Thanks but it seem like the problem of looping through data is still the same....i am really wondering where is the mistake....
>
> ________________________________________
> From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Sent: Monday, April 18, 2016 7:21 AM
> To: tan sj
> Cc: r-help
> Subject: Re: [R] R [coding : do not run for every row ]
>
> You can make this much more readable with apply functions.
>
> result <- apply(
>   all_combine1,
>   1,
>   function(x){
>     p.value <- sapply(
>       seq_len(nSims),
>       function(sim){
>         gamma1 <- rgamma(x["m"], x["sp(skewness1.5)"], x["scp1"])
>         gamma2 <- rgamma(x["n"], x["scp1"], 1)
>         gamma1 <- gamma1 - x["sp(skewness1.5)"] * x["scp1"]
>         gamma2 <- gamma2 - x["sp(skewness1.5)"]
>         c(
>           equal = t.test(gamma1, gamma2, var.equal=TRUE)$p.value,
>           unequal = t.test(gamma1,gamma2,var.equal=FALSE)$p.value,
>           mann = wilcox.test(gamma1,gamma2)$p.value
>         )
>       }
>     )
>     rowMeans(p.value <= alpha)
>   }
> )
> cbind(all_combine1, t(result))
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2016-04-18 9:05 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
>> Hi, i am sorry, the output should be values between 0 and 0.1 and not
>> supposed to be 1.00, it is because they are type 1 error rate. And now i get
>> output 1.00 for several samples,rhis is no correct. The loop do not run for
>> every row. i do not know where is my mistake.  As i use the same concept on
>> normal distribution setup, i get the result.
>>
>> Sent from my phone
>>
>> On Thierry Onkelinx <thierry.onkelinx at inbo.be>, Apr 18, 2016 2:55 PM wrote:
>> Dear anonymous,
>>
>> The big mistake in the output might be obvious to you but not to
>> others. Please make clear what the correct output should be or at
>> least what is wrong with the current output.
>>
>> And please DO read the posting guide which asks you not to post in HTML.
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2016-04-17 19:59 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
>>> i have combined all the variables in a matrix, and i wish to conduct a
>>> simulation row by row.
>>>
>>> But i found out the code only works for the every first row after a cycle
>>> of nine samples.
>>>
>>> But after check out the code, i don know where is my mistake...
>>>
>>> can anyone pls help ....
>>>
>>>
>>> #For gamma disribution with equal skewness 1.5
>>>
>>> #to evaluate the same R function on many different sets of data
>>> library(parallel)
>>>
>>> nSims<-100
>>> alpha<-0.05
>>>
>>> #set nrow =nsims because wan storing every p-value simulated
>>> #for gamma distribution with equal skewness
>>> matrix2_equal  <-matrix(0,nrow=nSims,ncol=3)
>>> matrix5_unequal<-matrix(0,nrow=nSims,ncol=3)
>>> matrix8_mann   <-matrix(0,nrow=nSims,ncol=3)
>>>
>>> # to ensure the reproducity of the result
>>> #here we declare the random seed generator
>>> set.seed(1)
>>>
>>> ## Put the samples sizes into matrix then use a loop for sample sizes
>>>
>>> sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
>>> nrow=2)
>>>
>>> #shape parameter for both gamma distribution for equal skewness
>>> #forty five cases for each skewness!!
>>> shp<-rep(16/9,each=5)
>>>
>>> #scale parameter for sample 1
>>> #scale paramter for sample 2 set as constant 1
>>> scp1<-c(1,1.5,2,2.5,3)
>>>
>>> #get all combinations with one row of the sample_sizes matrix
>>> ##(use expand.grid)to create a data frame from combination of data
>>>
>>> ss_sd1<- expand.grid(sample_sizes[2,],shp)
>>> scp1<-rep(scp1,9)
>>>
>>> std2<-rep(sd2,9)
>>>
>>> #create a matrix combining the forty five cases of combination of sample
>>> sizes,shape and scale parameter
>>> all_combine1 <- cbind(rep(sample_sizes[1,], 5),ss_sd1,scp1)
>>>
>>> # name the column samples 1 and 2 and standard deviation
>>> colnames(all_combine1) <- c("m", "n","sp(skewness1.5)","scp1")
>>>
>>> ##for the samples sizes into matrix then use a loop for sample sizes
>>>  # this loop steps through the all_combine matrix
>>>   for(ss in 1:nrow(all_combine1))
>>>   {
>>>     #generate samples from the first column and second column
>>>      m<-all_combine1[ss,1]
>>>      n<-all_combine1[ss,2]
>>>
>>>        for (sim in 1:nSims)
>>>        {
>>>         #generate 2 random samples from gamma distribution with equal
>>> skewness
>>>         gamma1<-rgamma(m,all_combine1[ss,3],all_combine1[ss,4])
>>>         gamma2<-rgamma(n,all_combine1[ss,4],1)
>>>
>>>         # minus the population mean to ensure that there is no lose of
>>> equality of mean
>>>         gamma1<-gamma1-all_combine1[ss,3]*all_combine1[ss,4]
>>>         gamma2<-gamma2-all_combine1[ss,3]
>>>
>>>         #extract p-value out and store every p-value into matrix
>>>         matrix2_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
>>>
>>> matrix5_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
>>>         matrix8_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
>>>     }
>>>        ##store the result
>>>       equal[ss]<- mean(matrix2_equal[,1]<=alpha)
>>>       unequal[ss]<-mean(matrix5_unequal[,2]<=alpha)
>>>       mann[ss]<- mean(matrix8_mann[,3]<=alpha)
>>>   }
>>>
>>> g_equal<-cbind(all_combine1, equal, unequal, mann)
>>>
>>> It is my result but it show a very big mistake ....TT
>>>      m   n sp(skewness1.5) scp1 equal unequal mann
>>> 1   10  10        1.777778  1.0  0.36    0.34 0.34
>>> 2   10  25        1.777778  1.5  0.84    0.87 0.90
>>> 3   25  25        1.777778  2.0  1.00    1.00 1.00
>>> 4   25  50        1.777778  2.5  1.00    1.00 1.00
>>> 5   25 100        1.777778  3.0  1.00    1.00 1.00
>>> 6   50  25        1.777778  1.0  0.77    0.77 0.84
>>> 7   50 100        1.777778  1.5  1.00    1.00 1.00
>>> 8  100  25        1.777778  2.0  1.00    1.00 1.00
>>> 9  100 100        1.777778  2.5  1.00    1.00 1.00
>>> 10  10  10        1.777778  3.0  1.00    1.00 1.00
>>> 11  10  25        1.777778  1.0  0.48    0.30 0.55
>>> 12  25  25        1.777778  1.5  0.99    0.99 1.00
>>> 13  25  50        1.777778  2.0  1.00    1.00 1.00
>>> 14  25 100        1.777778  2.5  1.00    1.00 1.00
>>> 15  50  25        1.777778  3.0  1.00    1.00 1.00
>>> 16  50 100        1.777778  1.0  0.97    0.97 1.00
>>> 17 100  25        1.777778  1.5  1.00    1.00 1.00
>>> 18 100 100        1.777778  2.0  1.00    1.00 1.00
>>> 19  10  10        1.777778  2.5  1.00    1.00 1.00
>>> 20  10  25        1.777778  3.0  1.00    1.00 1.00
>>> 21  25  25        1.777778  1.0  0.63    0.63 0.71
>>> 22  25  50        1.777778  1.5  0.99    0.99 0.99
>>> 23  25 100        1.777778  2.0  1.00    1.00 1.00
>>> 24  50  25        1.777778  2.5  1.00    1.00 1.00
>>> 25  50 100        1.777778  3.0  1.00    1.00 1.00
>>> 26 100  25        1.777778  1.0  0.83    0.90 0.88
>>> 27 100 100        1.777778  1.5  1.00    1.00 1.00
>>> 28  10  10        1.777778  2.0  1.00    1.00 1.00
>>> 29  10  25        1.777778  2.5  1.00    1.00 1.00
>>> 30  25  25        1.777778  3.0  1.00    1.00 1.00
>>> 31  25  50        1.777778  1.0  0.71    0.66 0.81
>>> 32  25 100        1.777778  1.5  1.00    1.00 1.00
>>> 33  50  25        1.777778  2.0  1.00    1.00 1.00
>>> 34  50 100        1.777778  2.5  1.00    1.00 1.00
>>> 35 100  25        1.777778  3.0  1.00    1.00 1.00
>>> 36 100 100        1.777778  1.0  0.99    0.99 1.00
>>> 37  10  10        1.777778  1.5  0.65    0.65 0.71
>>> 38  10  25        1.777778  2.0  1.00    1.00 1.00
>>> 39  25  25        1.777778  2.5  1.00    1.00 1.00
>>> 40  25  50        1.777778  3.0  1.00    1.00 1.00
>>> 41  25 100        1.777778  1.0  0.90    0.89 0.96
>>> 42  50  25        1.777778  1.5  0.99    0.99 1.00
>>> 43  50 100        1.777778  2.0  1.00    1.00 1.00
>>> 44 100  25        1.777778  2.5  1.00    1.00 1.00
>>> 45 100 100        1.777778  3.0  1.00    1.00 1.00
>>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From phil at pricom.com.au  Sat Apr 16 09:08:03 2016
From: phil at pricom.com.au (Philip Rhoades)
Date: Sat, 16 Apr 2016 17:08:03 +1000
Subject: [R] A Neural Network question
In-Reply-To: <82e95f04d56b55fce3384978fa2f38ae@localhost>
References: <d69884edcff9597d877b201aaf90ee96@localhost>
	<CAJnm8B0eHU=VN8wEdE92fwRXYATuEiB78vaPJY1FnNcRGy9dNQ@mail.gmail.com>
	<251fe71f7ac9e44cc051565fd82b9cfa@localhost>
	<CAJnm8B0fjtkGMS+f2w3hxHxDUreae9XWAov0-Dg5t=rmS9AOSg@mail.gmail.com>
	<2f65f6fe1308e3b2f223d063ca303ce6@localhost>
	<CAJnm8B3sXHYB1DgPQMMvO5-vHOv31AV8LicP7Js_dnCud6-7Xw@mail.gmail.com>
	<655d2b8bdca82bd7554430002212fa58@localhost>
	<99bd9108da366ab3958eaff486c79c90@localhost>
	<CAJnm8B2dYCBJH9U1e2MKSrK72jWTQaMeOAGZ8mOmy7yq+11ruA@mail.gmail.com>
	<15bafad2d2235db75194066f6ea2b63b@localhost>
	<CAJnm8B1R3oTXYq74rG+n2TVkQdg6eX=R9FQ2EhCLzrNEbJgadA@mail.gmail.com>
	<82e95f04d56b55fce3384978fa2f38ae@localhost>
Message-ID: <d9a579040a27dde76939517d98cf7dd7@localhost>

People,

I thought I needed to have some familiarity with NNs for some of my 
current (non-profit, brain-related) projects so I started looking at 
various programming environments including R and I got this working:

   http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example

however I needed pictures to help understand what was going on and then 
I found this:

   
https://jamesmccaffrey.files.wordpress.com/2012/11/backpropagationcalculations.jpg

which I thought was almost intelligible so I had an idea which I thought 
would help the learning process:

- Create a very simple NN implemented as a spreadsheet where each sheet 
would correspond to an iteration

I started doing this on LibreOffice:

- I think am already starting to get a better idea of how NNs work just 
from the stuff I have done on the spreadsheet already

- I have now transferred my LibreOffice SpreadSheet (SS) to a shared 
Google Docs Calc file and can share it for editing with others

   
https://docs.google.com/spreadsheets/d/1eSCgGU5qeI3_PmQhwZn4RH0NznUekVP5BP7w4MpKSUc/pub?output=pdf

- I think I have the SS calculations correct so far except for the stuff 
in the dashed purple box in the diagram

- I am not sure how to implement the purple box . . so I thought I would 
ask for help on this mailing list

If someone can help me with the last bit of the SS, from there I think I 
can then repeat the FR and BP sheets and see how the Diffs evolve . .

Is anyone interested in helping to get this last bit of the spreadsheet 
working so I can move on to doing actual work with the R packages with 
better understanding?

Thanks,

Phil.
-- 
Philip Rhoades

PO Box 896
Cowra  NSW  2794
Australia
E-mail:  phil at pricom.com.au


From sj_style_1125 at outlook.com  Mon Apr 18 13:11:34 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Mon, 18 Apr 2016 11:11:34 +0000
Subject: [R] R [coding : do not run for every row ]
In-Reply-To: <CAJuCY5x==1pCVSj6HdJWimo_H6Exb99oh7DeV6ZxjisaQt04yg@mail.gmail.com>
References: <HK2PR01MB0881F987E2E35CEBB107D475B56A0@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>
	<CAJuCY5yUh5giO0cFxtX9nhnUONOCjr2t2SyeTOOzQgZ5rXwA+g@mail.gmail.com>
	<KL1PR01MB08877493D844C7BAA6E3E433B56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
	<CAJuCY5zHFeSkBBb4icOJSVKo1-nTauYKJsvXdnk6TD=+RCfSYQ@mail.gmail.com>
	<KL1PR01MB08872B7FBD23D8D7AE506ACBB56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>,
	<CAJuCY5x==1pCVSj6HdJWimo_H6Exb99oh7DeV6ZxjisaQt04yg@mail.gmail.com>
Message-ID: <KL1PR01MB08879576B65306DAAFCDBC7FB56B0@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>

yes, i think that must be some mistake. I just noticed that it run for the nine sample sizes with the column fill in "1" in the result.
And yet i am still trying to figure out what is happening.

________________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: Monday, April 18, 2016 10:03 AM
To: tan sj; r-help at r-project.org
Subject: Re: [R] R [coding : do not run for every row ]

Always keep the mailing list in cc.

The code runs for each row in the data. However I get the feeling that
there is a mismatch between what you think that is in the data and the
actual data.
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey


2016-04-18 10:35 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
> Thanks but it seem like the problem of looping through data is still the same....i am really wondering where is the mistake....
>
> ________________________________________
> From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Sent: Monday, April 18, 2016 7:21 AM
> To: tan sj
> Cc: r-help
> Subject: Re: [R] R [coding : do not run for every row ]
>
> You can make this much more readable with apply functions.
>
> result <- apply(
>   all_combine1,
>   1,
>   function(x){
>     p.value <- sapply(
>       seq_len(nSims),
>       function(sim){
>         gamma1 <- rgamma(x["m"], x["sp(skewness1.5)"], x["scp1"])
>         gamma2 <- rgamma(x["n"], x["scp1"], 1)
>         gamma1 <- gamma1 - x["sp(skewness1.5)"] * x["scp1"]
>         gamma2 <- gamma2 - x["sp(skewness1.5)"]
>         c(
>           equal = t.test(gamma1, gamma2, var.equal=TRUE)$p.value,
>           unequal = t.test(gamma1,gamma2,var.equal=FALSE)$p.value,
>           mann = wilcox.test(gamma1,gamma2)$p.value
>         )
>       }
>     )
>     rowMeans(p.value <= alpha)
>   }
> )
> cbind(all_combine1, t(result))
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
>
>
> 2016-04-18 9:05 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
>> Hi, i am sorry, the output should be values between 0 and 0.1 and not
>> supposed to be 1.00, it is because they are type 1 error rate. And now i get
>> output 1.00 for several samples,rhis is no correct. The loop do not run for
>> every row. i do not know where is my mistake.  As i use the same concept on
>> normal distribution setup, i get the result.
>>
>> Sent from my phone
>>
>> On Thierry Onkelinx <thierry.onkelinx at inbo.be>, Apr 18, 2016 2:55 PM wrote:
>> Dear anonymous,
>>
>> The big mistake in the output might be obvious to you but not to
>> others. Please make clear what the correct output should be or at
>> least what is wrong with the current output.
>>
>> And please DO read the posting guide which asks you not to post in HTML.
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>>
>> 2016-04-17 19:59 GMT+02:00 tan sj <sj_style_1125 at outlook.com>:
>>> i have combined all the variables in a matrix, and i wish to conduct a
>>> simulation row by row.
>>>
>>> But i found out the code only works for the every first row after a cycle
>>> of nine samples.
>>>
>>> But after check out the code, i don know where is my mistake...
>>>
>>> can anyone pls help ....
>>>
>>>
>>> #For gamma disribution with equal skewness 1.5
>>>
>>> #to evaluate the same R function on many different sets of data
>>> library(parallel)
>>>
>>> nSims<-100
>>> alpha<-0.05
>>>
>>> #set nrow =nsims because wan storing every p-value simulated
>>> #for gamma distribution with equal skewness
>>> matrix2_equal  <-matrix(0,nrow=nSims,ncol=3)
>>> matrix5_unequal<-matrix(0,nrow=nSims,ncol=3)
>>> matrix8_mann   <-matrix(0,nrow=nSims,ncol=3)
>>>
>>> # to ensure the reproducity of the result
>>> #here we declare the random seed generator
>>> set.seed(1)
>>>
>>> ## Put the samples sizes into matrix then use a loop for sample sizes
>>>
>>> sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
>>> nrow=2)
>>>
>>> #shape parameter for both gamma distribution for equal skewness
>>> #forty five cases for each skewness!!
>>> shp<-rep(16/9,each=5)
>>>
>>> #scale parameter for sample 1
>>> #scale paramter for sample 2 set as constant 1
>>> scp1<-c(1,1.5,2,2.5,3)
>>>
>>> #get all combinations with one row of the sample_sizes matrix
>>> ##(use expand.grid)to create a data frame from combination of data
>>>
>>> ss_sd1<- expand.grid(sample_sizes[2,],shp)
>>> scp1<-rep(scp1,9)
>>>
>>> std2<-rep(sd2,9)
>>>
>>> #create a matrix combining the forty five cases of combination of sample
>>> sizes,shape and scale parameter
>>> all_combine1 <- cbind(rep(sample_sizes[1,], 5),ss_sd1,scp1)
>>>
>>> # name the column samples 1 and 2 and standard deviation
>>> colnames(all_combine1) <- c("m", "n","sp(skewness1.5)","scp1")
>>>
>>> ##for the samples sizes into matrix then use a loop for sample sizes
>>>  # this loop steps through the all_combine matrix
>>>   for(ss in 1:nrow(all_combine1))
>>>   {
>>>     #generate samples from the first column and second column
>>>      m<-all_combine1[ss,1]
>>>      n<-all_combine1[ss,2]
>>>
>>>        for (sim in 1:nSims)
>>>        {
>>>         #generate 2 random samples from gamma distribution with equal
>>> skewness
>>>         gamma1<-rgamma(m,all_combine1[ss,3],all_combine1[ss,4])
>>>         gamma2<-rgamma(n,all_combine1[ss,4],1)
>>>
>>>         # minus the population mean to ensure that there is no lose of
>>> equality of mean
>>>         gamma1<-gamma1-all_combine1[ss,3]*all_combine1[ss,4]
>>>         gamma2<-gamma2-all_combine1[ss,3]
>>>
>>>         #extract p-value out and store every p-value into matrix
>>>         matrix2_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
>>>
>>> matrix5_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
>>>         matrix8_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
>>>     }
>>>        ##store the result
>>>       equal[ss]<- mean(matrix2_equal[,1]<=alpha)
>>>       unequal[ss]<-mean(matrix5_unequal[,2]<=alpha)
>>>       mann[ss]<- mean(matrix8_mann[,3]<=alpha)
>>>   }
>>>
>>> g_equal<-cbind(all_combine1, equal, unequal, mann)
>>>
>>> It is my result but it show a very big mistake ....TT
>>>      m   n sp(skewness1.5) scp1 equal unequal mann
>>> 1   10  10        1.777778  1.0  0.36    0.34 0.34
>>> 2   10  25        1.777778  1.5  0.84    0.87 0.90
>>> 3   25  25        1.777778  2.0  1.00    1.00 1.00
>>> 4   25  50        1.777778  2.5  1.00    1.00 1.00
>>> 5   25 100        1.777778  3.0  1.00    1.00 1.00
>>> 6   50  25        1.777778  1.0  0.77    0.77 0.84
>>> 7   50 100        1.777778  1.5  1.00    1.00 1.00
>>> 8  100  25        1.777778  2.0  1.00    1.00 1.00
>>> 9  100 100        1.777778  2.5  1.00    1.00 1.00
>>> 10  10  10        1.777778  3.0  1.00    1.00 1.00
>>> 11  10  25        1.777778  1.0  0.48    0.30 0.55
>>> 12  25  25        1.777778  1.5  0.99    0.99 1.00
>>> 13  25  50        1.777778  2.0  1.00    1.00 1.00
>>> 14  25 100        1.777778  2.5  1.00    1.00 1.00
>>> 15  50  25        1.777778  3.0  1.00    1.00 1.00
>>> 16  50 100        1.777778  1.0  0.97    0.97 1.00
>>> 17 100  25        1.777778  1.5  1.00    1.00 1.00
>>> 18 100 100        1.777778  2.0  1.00    1.00 1.00
>>> 19  10  10        1.777778  2.5  1.00    1.00 1.00
>>> 20  10  25        1.777778  3.0  1.00    1.00 1.00
>>> 21  25  25        1.777778  1.0  0.63    0.63 0.71
>>> 22  25  50        1.777778  1.5  0.99    0.99 0.99
>>> 23  25 100        1.777778  2.0  1.00    1.00 1.00
>>> 24  50  25        1.777778  2.5  1.00    1.00 1.00
>>> 25  50 100        1.777778  3.0  1.00    1.00 1.00
>>> 26 100  25        1.777778  1.0  0.83    0.90 0.88
>>> 27 100 100        1.777778  1.5  1.00    1.00 1.00
>>> 28  10  10        1.777778  2.0  1.00    1.00 1.00
>>> 29  10  25        1.777778  2.5  1.00    1.00 1.00
>>> 30  25  25        1.777778  3.0  1.00    1.00 1.00
>>> 31  25  50        1.777778  1.0  0.71    0.66 0.81
>>> 32  25 100        1.777778  1.5  1.00    1.00 1.00
>>> 33  50  25        1.777778  2.0  1.00    1.00 1.00
>>> 34  50 100        1.777778  2.5  1.00    1.00 1.00
>>> 35 100  25        1.777778  3.0  1.00    1.00 1.00
>>> 36 100 100        1.777778  1.0  0.99    0.99 1.00
>>> 37  10  10        1.777778  1.5  0.65    0.65 0.71
>>> 38  10  25        1.777778  2.0  1.00    1.00 1.00
>>> 39  25  25        1.777778  2.5  1.00    1.00 1.00
>>> 40  25  50        1.777778  3.0  1.00    1.00 1.00
>>> 41  25 100        1.777778  1.0  0.90    0.89 0.96
>>> 42  50  25        1.777778  1.5  0.99    0.99 1.00
>>> 43  50 100        1.777778  2.0  1.00    1.00 1.00
>>> 44 100  25        1.777778  2.5  1.00    1.00 1.00
>>> 45 100 100        1.777778  3.0  1.00    1.00 1.00
>>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From andy_liaw at merck.com  Mon Apr 18 15:38:17 2016
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 18 Apr 2016 09:38:17 -0400
Subject: [R] Random Forest classification
In-Reply-To: <DUB131-W72225254081BC9AAB79364CC950@phx.gbl>
References: <DUB131-W72225254081BC9AAB79364CC950@phx.gbl>
Message-ID: <D5FA03935F7418419332B61CA255F65F0120D40B2CB2@USCTMXP51012.merck.com>

This is explained in the "Details" section of the help page for partialPlot.

Best
Andy

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jes?s Para
> Fern?ndez
> Sent: Tuesday, April 12, 2016 1:17 AM
> To: r-help at r-project.org
> Subject: [R] Random Forest classification
> 
> Hi,
> 
> To evaluate the partial influence of a factor with a random Forest, wich
> response is OK/NOK I?m using partialPlot, being the x axis the factor axis and
> the Y axis is between -1 and 1. What this -1 and 1 means?
> 
> An example:
> 
> https://www.dropbox.com/s/4b92lqxi3592r0d/Captura.JPG?dl=0
> 
> 
> Thanks for all!!!
> 	[[alternative HTML version deleted]]

Notice:  This e-mail message, together with any attachments, contains
information of Merck & Co., Inc. (2000 Galloping Hill Road, Kenilworth,
New Jersey, USA 07033), and/or its affiliates Direct contact information
for affiliates is available at 
http://www.merck.com/contact/contacts.html) that may be confidential,
proprietary copyrighted and/or legally privileged. It is intended solely
for the use of the individual or entity named on this message. If you are
not the intended recipient, and have received this message in error,
please notify us immediately by reply e-mail and then delete it from 
your system.

From giftedlife2014 at gmail.com  Mon Apr 18 15:09:50 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Mon, 18 Apr 2016 14:09:50 +0100
Subject: [R] as.Date
Message-ID: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>

Dear All,

I have a data set containing year, month, day and counts as shown below:
data <- read.table("data.txt", col.names = c("year", "month", "day", "counts"))
Using the formula below, I converted the data to as date and plotted.

new.century <- data$year < 70

data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)

data$date <- as.Date(ISOdate(data$year, data$month, data$day))

The form of the data is:
16 1 19 9078
16 1 20 9060
16 1 21 9090
16 1 22 9080
16 1 23 9121
16 1 24 9199
16 1 25 9289
16 1 26 9285
16 1 27 9245
16 1 28 9223
16 1 29 9298
16 1 30 9327
16 1 31 9365

Now, I wish to include time (hour) in my data. The new data is of the form:
05 01 06 14    3849
05 01 06 15    3845
05 01 06 16    3836
05 01 06 17    3847
05 01 06 18    3850
05 01 06 19    3872
05 01 06 20    3849
05 01 06 21    3860
05 01 06 22    3868
05 01 06 23    3853
05 01 07 00    3839
05 01 07 01    3842
05 01 07 02    3843
05 01 07 03    3865
05 01 07 04    3879
05 01 07 05    3876
05 01 07 06    3867
05 01 07 07    3887

I now read the data as:
data <- read.table("data.txt", col.names = c("year", "month", "day",
"counts", "hour")) and also included hour in data$date <-
as.Date(ISOdate(data$year, data$month, data$day))
i.e data$date <- as.Date(ISOdate(data$year, data$month, data$day, data$hour)).

However, these did not work.

Can you please assist be on how to get this date and time in the right
format. The right format I got without hour looks like : 2005-12-29"
"2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
[8696] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
[8701] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
[8706] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"

I used this in my plot. Please I want this format to include hour.

Many thanks for your help. I am just a newbe. I am not sure if this
forum is the right one. After registration, I tried to post to Nabble
forum where I registered but could not succeed.

If there is a mistake, please help/direct me to the right forum.

Best regards
Ogbos


From pdalgd at gmail.com  Mon Apr 18 15:54:51 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 18 Apr 2016 15:54:51 +0200
Subject: [R] as.Date
In-Reply-To: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
References: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
Message-ID: <7D4CE9CA-5B3E-4C66-8AB4-C265E61951A4@gmail.com>

The most important thing is that Date objects by definition do not include time of day. You want to look at ISOdatetime() and as.POSIXct() instead. And beware daylight savings time issues.

-pd

On 18 Apr 2016, at 15:09 , Ogbos Okike <giftedlife2014 at gmail.com> wrote:

> Dear All,
> 
> I have a data set containing year, month, day and counts as shown below:
> data <- read.table("data.txt", col.names = c("year", "month", "day", "counts"))
> Using the formula below, I converted the data to as date and plotted.
> 
> new.century <- data$year < 70
> 
> data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
> 
> data$date <- as.Date(ISOdate(data$year, data$month, data$day))
> 
> The form of the data is:
> 16 1 19 9078
> 16 1 20 9060
> 16 1 21 9090
> 16 1 22 9080
> 16 1 23 9121
> 16 1 24 9199
> 16 1 25 9289
> 16 1 26 9285
> 16 1 27 9245
> 16 1 28 9223
> 16 1 29 9298
> 16 1 30 9327
> 16 1 31 9365
> 
> Now, I wish to include time (hour) in my data. The new data is of the form:
> 05 01 06 14    3849
> 05 01 06 15    3845
> 05 01 06 16    3836
> 05 01 06 17    3847
> 05 01 06 18    3850
> 05 01 06 19    3872
> 05 01 06 20    3849
> 05 01 06 21    3860
> 05 01 06 22    3868
> 05 01 06 23    3853
> 05 01 07 00    3839
> 05 01 07 01    3842
> 05 01 07 02    3843
> 05 01 07 03    3865
> 05 01 07 04    3879
> 05 01 07 05    3876
> 05 01 07 06    3867
> 05 01 07 07    3887
> 
> I now read the data as:
> data <- read.table("data.txt", col.names = c("year", "month", "day",
> "counts", "hour")) and also included hour in data$date <-
> as.Date(ISOdate(data$year, data$month, data$day))
> i.e data$date <- as.Date(ISOdate(data$year, data$month, data$day, data$hour)).
> 
> However, these did not work.
> 
> Can you please assist be on how to get this date and time in the right
> format. The right format I got without hour looks like : 2005-12-29"
> "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> [8696] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> [8701] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> [8706] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> 
> I used this in my plot. Please I want this format to include hour.
> 
> Many thanks for your help. I am just a newbe. I am not sure if this
> forum is the right one. After registration, I tried to post to Nabble
> forum where I registered but could not succeed.
> 
> If there is a mistake, please help/direct me to the right forum.
> 
> Best regards
> Ogbos
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Mon Apr 18 16:01:28 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 18 Apr 2016 14:01:28 +0000
Subject: [R] as.Date
In-Reply-To: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
References: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5026C62@SRVEXCHMBX.precheza.cz>

Hi

AFAIK as.Date does not accept hours. Although it is not explicitly written in help page, the name as.Date seems to me clear enough that it works only with dates.

If you want to use hours, minutes ... you should use strptime for converting your values to valid date_time object.

And you should also use ISOdatetime conversion function to use hours etc. in your commands.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ogbos
> Okike
> Sent: Monday, April 18, 2016 3:10 PM
> To: r-help at r-project.org
> Subject: [R] as.Date
>
> Dear All,
>
> I have a data set containing year, month, day and counts as shown below:
> data <- read.table("data.txt", col.names = c("year", "month", "day",
> "counts")) Using the formula below, I converted the data to as date and
> plotted.
>
> new.century <- data$year < 70
>
> data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
>
> data$date <- as.Date(ISOdate(data$year, data$month, data$day))
>
> The form of the data is:
> 16 1 19 9078
> 16 1 20 9060
> 16 1 21 9090
> 16 1 22 9080
> 16 1 23 9121
> 16 1 24 9199
> 16 1 25 9289
> 16 1 26 9285
> 16 1 27 9245
> 16 1 28 9223
> 16 1 29 9298
> 16 1 30 9327
> 16 1 31 9365
>
> Now, I wish to include time (hour) in my data. The new data is of the form:
> 05 01 06 14    3849
> 05 01 06 15    3845
> 05 01 06 16    3836
> 05 01 06 17    3847
> 05 01 06 18    3850
> 05 01 06 19    3872
> 05 01 06 20    3849
> 05 01 06 21    3860
> 05 01 06 22    3868
> 05 01 06 23    3853
> 05 01 07 00    3839
> 05 01 07 01    3842
> 05 01 07 02    3843
> 05 01 07 03    3865
> 05 01 07 04    3879
> 05 01 07 05    3876
> 05 01 07 06    3867
> 05 01 07 07    3887
>
> I now read the data as:
> data <- read.table("data.txt", col.names = c("year", "month", "day",
> "counts", "hour")) and also included hour in data$date <-
> as.Date(ISOdate(data$year, data$month, data$day)) i.e data$date <-
> as.Date(ISOdate(data$year, data$month, data$day, data$hour)).
>
> However, these did not work.
>
> Can you please assist be on how to get this date and time in the right format.
> The right format I got without hour looks like : 2005-12-29"
> "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> [8696] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> [8701] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> [8706] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>
> I used this in my plot. Please I want this format to include hour.
>
> Many thanks for your help. I am just a newbe. I am not sure if this forum is
> the right one. After registration, I tried to post to Nabble forum where I
> registered but could not succeed.
>
> If there is a mistake, please help/direct me to the right forum.
>
> Best regards
> Ogbos
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Mon Apr 18 16:02:39 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 18 Apr 2016 07:02:39 -0700
Subject: [R] as.Date
In-Reply-To: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
References: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
Message-ID: <14595636-66DC-4EA4-BDF8-63A17B5DAAA1@dcn.davis.ca.us>

Date data cannot represent hour data. You need to use POSIXct or perhaps the chron class from the chron package. 

To use POSIXct, use ISOdatetime instead of ISOdate. Also be careful which timezone you have set as default (in most operating systems calling Sys.setenv(TZ="Etc/GMT") or similar will get you started) when you invoke ISOdatetime, since daylight savings can complicate things. Of course if daylight savings is built into your data already then  you are better off choosing a timezone that understands that. See ?DateTimeClasses.
-- 
Sent from my phone. Please excuse my brevity.

On April 18, 2016 6:09:50 AM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear All,
>
>I have a data set containing year, month, day and counts as shown
>below:
>data <- read.table("data.txt", col.names = c("year", "month", "day",
>"counts"))
>Using the formula below, I converted the data to as date and plotted.
>
>new.century <- data$year < 70
>
>data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
>
>data$date <- as.Date(ISOdate(data$year, data$month, data$day))
>
>The form of the data is:
>16 1 19 9078
>16 1 20 9060
>16 1 21 9090
>16 1 22 9080
>16 1 23 9121
>16 1 24 9199
>16 1 25 9289
>16 1 26 9285
>16 1 27 9245
>16 1 28 9223
>16 1 29 9298
>16 1 30 9327
>16 1 31 9365
>
>Now, I wish to include time (hour) in my data. The new data is of the
>form:
>05 01 06 14    3849
>05 01 06 15    3845
>05 01 06 16    3836
>05 01 06 17    3847
>05 01 06 18    3850
>05 01 06 19    3872
>05 01 06 20    3849
>05 01 06 21    3860
>05 01 06 22    3868
>05 01 06 23    3853
>05 01 07 00    3839
>05 01 07 01    3842
>05 01 07 02    3843
>05 01 07 03    3865
>05 01 07 04    3879
>05 01 07 05    3876
>05 01 07 06    3867
>05 01 07 07    3887
>
>I now read the data as:
>data <- read.table("data.txt", col.names = c("year", "month", "day",
>"counts", "hour")) and also included hour in data$date <-
>as.Date(ISOdate(data$year, data$month, data$day))
>i.e data$date <- as.Date(ISOdate(data$year, data$month, data$day,
>data$hour)).
>
>However, these did not work.
>
>Can you please assist be on how to get this date and time in the right
>format. The right format I got without hour looks like : 2005-12-29"
>"2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>[8696] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>[8701] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>[8706] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>
>I used this in my plot. Please I want this format to include hour.
>
>Many thanks for your help. I am just a newbe. I am not sure if this
>forum is the right one. After registration, I tried to post to Nabble
>forum where I registered but could not succeed.
>
>If there is a mistake, please help/direct me to the right forum.
>
>Best regards
>Ogbos
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ulhaqz at gmail.com  Mon Apr 18 18:48:07 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Mon, 18 Apr 2016 21:48:07 +0500
Subject: [R] Sum of Numeric Values in a DF Column
Message-ID: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>

Hi,

I request help with the following:

INPUT: A data frame where column "Lower" is a character containing numeric
values (different count or occurrences of numeric values in each row,
mostly 2)

> dput(dd)
structure(list(State = c("Alabama", "Alaska", "Arizona", "Arkansas",
"California"), Lower = c("R 72?33", "R/Coalition 27(23 R, 4 D)?12 D, 1
Ind.",
"R 36?24", "R 64?35, 1 Ind.", "D 52?28"), Upper = c("R 26?8, 1 Ind.",
"R/Coalition 15(14 R, 1 D)?5 D", "R 18?12", "R 24?11", "D 26?14"
)), .Names = c("State", "Lower", "Upper"), row.names = c(NA,
5L), class = "data.frame")

PROBLEM: Need to extract all numeric values and sum them. There are few
exceptions like row2. But these can be ignored and will be fixed manually

SOLUTION SO FAR:
str_extract_all(dd[[2]],"[[:digit:]]+"), returns a list of numbers as
character. I am unable to unlist it, because it mixes them all together, ...

And if I may add, is there a "dplyr" way of doing it ...


Thanks

	[[alternative HTML version deleted]]


From rmh at temple.edu  Mon Apr 18 19:07:44 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 18 Apr 2016 13:07:44 -0400
Subject: [R] Sum of Numeric Values in a DF Column
In-Reply-To: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>
References: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>
Message-ID: <CAGx1TMDkCbc9qOwb3q35ivoYdfBPxFfK+cF1-QeyBGkrVVV8Rg@mail.gmail.com>

## Continuing with your data

AA <- stringr::str_extract_all(dd[[2]],"[[:digit:]]+")
BB <- lapply(AA, as.numeric)
## I think you are looking for one of the following two expressions
sum(unlist(BB))
sapply(BB, sum)


On Mon, Apr 18, 2016 at 12:48 PM, Burhan ul haq <ulhaqz at gmail.com> wrote:
> Hi,
>
> I request help with the following:
>
> INPUT: A data frame where column "Lower" is a character containing numeric
> values (different count or occurrences of numeric values in each row,
> mostly 2)
>
>> dput(dd)
> structure(list(State = c("Alabama", "Alaska", "Arizona", "Arkansas",
> "California"), Lower = c("R 72?33", "R/Coalition 27(23 R, 4 D)?12 D, 1
> Ind.",
> "R 36?24", "R 64?35, 1 Ind.", "D 52?28"), Upper = c("R 26?8, 1 Ind.",
> "R/Coalition 15(14 R, 1 D)?5 D", "R 18?12", "R 24?11", "D 26?14"
> )), .Names = c("State", "Lower", "Upper"), row.names = c(NA,
> 5L), class = "data.frame")
>
> PROBLEM: Need to extract all numeric values and sum them. There are few
> exceptions like row2. But these can be ignored and will be fixed manually
>
> SOLUTION SO FAR:
> str_extract_all(dd[[2]],"[[:digit:]]+"), returns a list of numbers as
> character. I am unable to unlist it, because it mixes them all together, ...
>
> And if I may add, is there a "dplyr" way of doing it ...
>
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Apr 18 19:08:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Apr 2016 10:08:11 -0700
Subject: [R] Sum of Numeric Values in a DF Column
In-Reply-To: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>
References: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>
Message-ID: <1A3E5FB1-E923-4070-8B30-ADE4DFEDA484@comcast.net>


> On Apr 18, 2016, at 9:48 AM, Burhan ul haq <ulhaqz at gmail.com> wrote:
> 
> Hi,
> 
> I request help with the following:
> 
> INPUT: A data frame where column "Lower" is a character containing numeric
> values (different count or occurrences of numeric values in each row,
> mostly 2)
> 
>> dput(dd)
> structure(list(State = c("Alabama", "Alaska", "Arizona", "Arkansas",
> "California"), Lower = c("R 72?33", "R/Coalition 27(23 R, 4 D)?12 D, 1
> Ind.",
> "R 36?24", "R 64?35, 1 Ind.", "D 52?28"), Upper = c("R 26?8, 1 Ind.",
> "R/Coalition 15(14 R, 1 D)?5 D", "R 18?12", "R 24?11", "D 26?14"
> )), .Names = c("State", "Lower", "Upper"), row.names = c(NA,
> 5L), class = "data.frame")
> 
> PROBLEM: Need to extract all numeric values and sum them. There are few
> exceptions like row2. But these can be ignored and will be fixed manually
> 
> SOLUTION SO FAR:
> str_extract_all(dd[[2]],"[[:digit:]]+"), returns a list of numbers as
> character. I am unable to unlist it, because it mixes them all together, ...
> 
> And if I may add, is there a "dplyr" way of doing it ...

I don't understand what is mean by "it mixes them all together". This runs without error and appears to deliver what was requested in your natural language description:

> sum( as.numeric( unlist(str_extract_all(dd[[2]],"[[:digit:]]+") )))
[1] 412


> 
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Mon Apr 18 19:43:35 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 18 Apr 2016 10:43:35 -0700
Subject: [R] Sum of Numeric Values in a DF Column
In-Reply-To: <CAGx1TMDkCbc9qOwb3q35ivoYdfBPxFfK+cF1-QeyBGkrVVV8Rg@mail.gmail.com>
References: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>
	<CAGx1TMDkCbc9qOwb3q35ivoYdfBPxFfK+cF1-QeyBGkrVVV8Rg@mail.gmail.com>
Message-ID: <CAGxFJbSq_cezBRy7jQZD1N-DNZOYMOKPaUE9jopkeQ=x-Uu3Pw@mail.gmail.com>

... and here is a non-dplyr rsolution:

> z <-gsub("[^[:digit:]]"," ",dd$Lower)

> sapply(strsplit(z," +"),function(x)sum(as.numeric(x),na.rm=TRUE))
[1] 105  67  60 100  80


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 18, 2016 at 10:07 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> ## Continuing with your data
>
> AA <- stringr::str_extract_all(dd[[2]],"[[:digit:]]+")
> BB <- lapply(AA, as.numeric)
> ## I think you are looking for one of the following two expressions
> sum(unlist(BB))
> sapply(BB, sum)
>
>
> On Mon, Apr 18, 2016 at 12:48 PM, Burhan ul haq <ulhaqz at gmail.com> wrote:
>> Hi,
>>
>> I request help with the following:
>>
>> INPUT: A data frame where column "Lower" is a character containing numeric
>> values (different count or occurrences of numeric values in each row,
>> mostly 2)
>>
>>> dput(dd)
>> structure(list(State = c("Alabama", "Alaska", "Arizona", "Arkansas",
>> "California"), Lower = c("R 72?33", "R/Coalition 27(23 R, 4 D)?12 D, 1
>> Ind.",
>> "R 36?24", "R 64?35, 1 Ind.", "D 52?28"), Upper = c("R 26?8, 1 Ind.",
>> "R/Coalition 15(14 R, 1 D)?5 D", "R 18?12", "R 24?11", "D 26?14"
>> )), .Names = c("State", "Lower", "Upper"), row.names = c(NA,
>> 5L), class = "data.frame")
>>
>> PROBLEM: Need to extract all numeric values and sum them. There are few
>> exceptions like row2. But these can be ignored and will be fixed manually
>>
>> SOLUTION SO FAR:
>> str_extract_all(dd[[2]],"[[:digit:]]+"), returns a list of numbers as
>> character. I am unable to unlist it, because it mixes them all together, ...
>>
>> And if I may add, is there a "dplyr" way of doing it ...
>>
>>
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Apr 18 19:44:34 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Apr 2016 10:44:34 -0700
Subject: [R] 'nlme' package not compiling
In-Reply-To: <57149166.8000905@gmail.com>
References: <57149166.8000905@gmail.com>
Message-ID: <3222EB4F-23B6-4A0D-8025-FE471732618B@comcast.net>


> On Apr 18, 2016, at 12:48 AM, Angelo Varlotta <angelovarlotta at gmail.com> wrote:
> 
> Hi,
> I'm trying to install from source code the 'nlme' package in 
> RStudio. When I try, I get the following error message:
> 
> ld: warning: directory not found for option 
> '-L/usr/local/lib/gcc/x86_64-apple-darwin13.0.0/4.8.2'
> ld: library not found for -lgfortran
> clang: error: linker command failed with exit code 1 (use -v to 
> see invocation)
> make: *** [nlme.so] Error 1
> ERROR: compilation failed for package ?nlme?
> * removing 
> ?/Library/Frameworks/R.framework/Versions/3.2/Resources/library/nlme?
> * restoring previous 
> ?/Library/Frameworks/R.framework/Versions/3.2/Resources/library/nlme?
> Warning in install.packages :
>   installation of package ?nlme? had non-zero exit status
> 
> I'm using gfortran 4.8 from Macports and running OS X 10.11.4 
> with RStudio Version 0.99.893. I've tried to use the FLIBS 
> command in R:
> 
> FLIBS="-L/opt/local/lib/gcc48/gcc/x86_64-apple-darwin15/4.8.5/"
> 
> so that it knows where the Fortran libraries are at and compile 
> again, but it still searchesregardless for the directory:
> 
> /usr/local/lib/gcc/x86_64-apple-darwin13.0.0/4.8.2.

This is the fortran against which the Mac R is compiled, provided as a disk image:

gfortran-4.2.3.dmg:
http://r.research.att.com/gfortran-4.2.3.dmg

If you had been reading the R-SIG-Mac forum (or searching the archives you should have seen repeated warnings against Macports versions.)

The proper site for Mac questions regarding package compilation.
R-SIG-Mac:
https://stat.ethz.ch/mailman/listinfo/r-sig-mac


I'm was using Version 0.99.491 but updated to the same version as you have. The install packages dialog doesn't offer compiling from source as an options so the first test was to see if the binary could be install easily on version 3.3.0 of R.... it did.

I then tried compiling from source and do get the same error as did you. I'm  not a very capable Unix programmer and am unable to tell why this is happening. Perhaps something RStudio is doing? So I tried in the R.app gui with : 

install.packages("~/Downloads/nlme_3.1-127.tar.gz", repo=NULL, type="source")

#==== result=======
* installing *source* package ?nlme? ...
** package ?nlme? successfully unpacked and MD5 sums checked
** libs
gfortran-4.8   -fPIC  -g -O2  -c chol.f -o chol.o
make: gfortran-4.8: No such file or directory
make: *** [chol.o] Error 1
ERROR: compilation failed for package ?nlme?
Warning message:
In install.packages("~/Downloads/nlme_3.1-127.tar.gz", repo = NULL,  :
  installation of package ?/Users/davidwinsemius/Downloads/nlme_3.1-127.tar.gz? had non-zero exit status
* removing ?/Library/Frameworks/R.framework/Versions/3.3/Resources/library/nlme?
* restoring previous ?/Library/Frameworks/R.framework/Versions/3.3/Resources/library/nlme?

Also tried from Terminal.app session with similar error report.

> which of course doesn't exist. Any suggestions?

A) Install from binary. That's certainly seems easiest.

Or B)
-- install gfortran 4.8 in the directory that your installation of R expects it to be found. 
Perhaps:

http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2

Or at the Unix command line:

curl -s http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2 | sudo tar fxj - -C /

(As was suggested by Simon Urbanek two years ago and  was reported successful by Jason Eyerly on R-SIG-Mac.)

But in any case this thread belongs on R-SIG-MAC so copying there, and if any response is needed then when responding you should remove r-help from future replies.

-- 

David Winsemius


> 
> Cheers,
> Angelo
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Mon Apr 18 19:57:38 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 18 Apr 2016 10:57:38 -0700
Subject: [R] Sum of Numeric Values in a DF Column
In-Reply-To: <CAGxFJbSq_cezBRy7jQZD1N-DNZOYMOKPaUE9jopkeQ=x-Uu3Pw@mail.gmail.com>
References: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>
	<CAGx1TMDkCbc9qOwb3q35ivoYdfBPxFfK+cF1-QeyBGkrVVV8Rg@mail.gmail.com>
	<CAGxFJbSq_cezBRy7jQZD1N-DNZOYMOKPaUE9jopkeQ=x-Uu3Pw@mail.gmail.com>
Message-ID: <CAGxFJbRTmHu0p1eZbZg0p6UMYxAYL875nMWCgO2jyn0xZcmMBw@mail.gmail.com>

... and a slightly more efficient non-dplyr 1-liner:

> sapply(strsplit(dd$Lower,"[^[:digit:]]"),
function(x)sum(as.numeric(x), na.rm=TRUE))

[1] 105  67  60 100  80

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 18, 2016 at 10:43 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> ... and here is a non-dplyr rsolution:
>
>> z <-gsub("[^[:digit:]]"," ",dd$Lower)
>
>> sapply(strsplit(z," +"),function(x)sum(as.numeric(x),na.rm=TRUE))
> [1] 105  67  60 100  80
>
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Apr 18, 2016 at 10:07 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> ## Continuing with your data
>>
>> AA <- stringr::str_extract_all(dd[[2]],"[[:digit:]]+")
>> BB <- lapply(AA, as.numeric)
>> ## I think you are looking for one of the following two expressions
>> sum(unlist(BB))
>> sapply(BB, sum)
>>
>>
>> On Mon, Apr 18, 2016 at 12:48 PM, Burhan ul haq <ulhaqz at gmail.com> wrote:
>>> Hi,
>>>
>>> I request help with the following:
>>>
>>> INPUT: A data frame where column "Lower" is a character containing numeric
>>> values (different count or occurrences of numeric values in each row,
>>> mostly 2)
>>>
>>>> dput(dd)
>>> structure(list(State = c("Alabama", "Alaska", "Arizona", "Arkansas",
>>> "California"), Lower = c("R 72?33", "R/Coalition 27(23 R, 4 D)?12 D, 1
>>> Ind.",
>>> "R 36?24", "R 64?35, 1 Ind.", "D 52?28"), Upper = c("R 26?8, 1 Ind.",
>>> "R/Coalition 15(14 R, 1 D)?5 D", "R 18?12", "R 24?11", "D 26?14"
>>> )), .Names = c("State", "Lower", "Upper"), row.names = c(NA,
>>> 5L), class = "data.frame")
>>>
>>> PROBLEM: Need to extract all numeric values and sum them. There are few
>>> exceptions like row2. But these can be ignored and will be fixed manually
>>>
>>> SOLUTION SO FAR:
>>> str_extract_all(dd[[2]],"[[:digit:]]+"), returns a list of numbers as
>>> character. I am unable to unlist it, because it mixes them all together, ...
>>>
>>> And if I may add, is there a "dplyr" way of doing it ...
>>>
>>>
>>> Thanks
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From o.o.wolf at qmul.ac.uk  Mon Apr 18 18:20:18 2016
From: o.o.wolf at qmul.ac.uk (olsen)
Date: Mon, 18 Apr 2016 17:20:18 +0100
Subject: [R] project test data into principal components of training dataset
Message-ID: <57150942.8080200@qmul.ac.uk>

Hi there,

I've a training dataset and a test dataset. My aim is to visually
allocate the test data within the calibrated space reassembled by the
PC's of the training data set, furthermore to keep the training data set
coordinates fixed, so they can serve as ruler for measurement for
additional test datasets coming up.

Please find a minimum working example using the wine dataset below.
Ideally I would like to use ggbiplot as it comes with the elegant
features but it only accepts objects of class prcomp, princomp, PCA, or
lda, which is not fullfilled by the predicted test data.

I'm still slightly wet behind my R ears and the only solution I can
think of is to plot the calibrated space in ggbiplot and the training
data in ggplot and then join them, in the worst case by exporting them
as svg and importing them in inkscape. Which is slightly complicated
plus the scaling is different.

Any indication how this mission can be accomplished very welcome!

Thanks and greets
Olsen

I started a threat on stackoverflow on that issue but know relevant
indications so far.
http://stackoverflow.com/questions/36603268/how-to-plot-training-and-test-validation-data-in-r-using-ggbiplot

##MWE
library(ggbiplot)
data(wine)

##pca on the wine dataset used as training data
wine.pca <- prcomp(wine, center = TRUE, scale. = TRUE)

wine$class <- wine.class

##simulate test data by generating three new wine classes
wine.new.1 <- wine[c(sample(1:nrow(wine), 25)),]
wine.new.2 <- wine[c(sample(1:nrow(wine), 43)),]
wine.new.3 <- wine[c(sample(1:nrow(wine), 36)),]

##Predict PCs for the new classes by transforming
#them using the predict.prcomp function
pred.new.1 <- predict(wine.pca, newdata = wine.new.1)
pred.new.2 <- predict(wine.pca, newdata = wine.new.2)
pred.new.3 <- predict(wine.pca, newdata = wine.new.3)

#simulate the classes for the new sorts
wine.new.1$class <- rep("new.wine.1", nrow(wine.new.1))
wine.new.2$class <- rep("new.wine.2", nrow(wine.new.2))
wine.new.3$class <- rep("new.wine.3", nrow(wine.new.3))
wine.new.bind <- rbind(wine.new.1, wine.new.2, wine.new.3)

##compose the plot by joining the PCA ggbiplot training data with the
testing data from ggplot
#plot the calibrated space resulting from the test data
g.train <- ggbiplot(wine.pca, obs.scale = 1, var.scale = 1, groups =
wine$class, ellipse = TRUE, circle = TRUE)
g.train
#plot the test data resulting from the prediction
df.pred = data.frame(PC1 = wine.new.bind[,1], PC2 = wine.new.bind[,2],
                    PC3 = wine.new.bind[,3], PC4 = wine.new.bind[,4],
                    classes = wine.new.bind$class)
g.test <- ggplot(df.pred, aes(PC1, PC2, color = classes, shape =
classes)) +  geom_point() +  stat_ellipse()
g.test





-- 
Our solar system is the cream of the crop
http://hasa-labs.org


From giftedlife2014 at gmail.com  Mon Apr 18 19:44:23 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Mon, 18 Apr 2016 18:44:23 +0100
Subject: [R] as.Date
In-Reply-To: <7D4CE9CA-5B3E-4C66-8AB4-C265E61951A4@gmail.com>
References: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
	<7D4CE9CA-5B3E-4C66-8AB4-C265E61951A4@gmail.com>
Message-ID: <CAC8ss32D3_eFkGq7pJz1fCBCXJW-Fn9=xA6xGgbVAeRHXbkjHQ@mail.gmail.com>

Dear ALL,
Thank you so much for your contributions.
I have made some progress. Below is a simple script I gleaned from
your kind responses:
Sys.setenv(TZ="Etc/GMT")
dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/92")
     times <- c("23:0:0", "22:0:0", "01:00:00", "18:0:0", "16:0:0")
     x <- paste(dates, times)
     aa<-strptime(x, "%m/%d/%y %H:%M:%S")
bb<-1:5
plot(aa, bb)

I tried plotting my result and I got what I am looking for. I think I
am almost there.

I am, however, stuck here. My data is a large file and the form
differs a little from the example I used. The quotation marks in both
date and time is my headache now. Such inverted commas are not in my
data. I can with awk transform my data to get exactly something like
dd/mm/yy. But I wont know how to make the data appear in quotation
mark in R. I will once more be glad for any more help.
Ogbos

PS: I am still afraid of this forum. Please direct me to the right
forum if this is not ok. Thanks again.


On 4/18/16, peter dalgaard <pdalgd at gmail.com> wrote:
> The most important thing is that Date objects by definition do not include
> time of day. You want to look at ISOdatetime() and as.POSIXct() instead. And
> beware daylight savings time issues.
>
> -pd
>
> On 18 Apr 2016, at 15:09 , Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
>> Dear All,
>>
>> I have a data set containing year, month, day and counts as shown below:
>> data <- read.table("data.txt", col.names = c("year", "month", "day",
>> "counts"))
>> Using the formula below, I converted the data to as date and plotted.
>>
>> new.century <- data$year < 70
>>
>> data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
>>
>> data$date <- as.Date(ISOdate(data$year, data$month, data$day))
>>
>> The form of the data is:
>> 16 1 19 9078
>> 16 1 20 9060
>> 16 1 21 9090
>> 16 1 22 9080
>> 16 1 23 9121
>> 16 1 24 9199
>> 16 1 25 9289
>> 16 1 26 9285
>> 16 1 27 9245
>> 16 1 28 9223
>> 16 1 29 9298
>> 16 1 30 9327
>> 16 1 31 9365
>>
>> Now, I wish to include time (hour) in my data. The new data is of the
>> form:
>> 05 01 06 14    3849
>> 05 01 06 15    3845
>> 05 01 06 16    3836
>> 05 01 06 17    3847
>> 05 01 06 18    3850
>> 05 01 06 19    3872
>> 05 01 06 20    3849
>> 05 01 06 21    3860
>> 05 01 06 22    3868
>> 05 01 06 23    3853
>> 05 01 07 00    3839
>> 05 01 07 01    3842
>> 05 01 07 02    3843
>> 05 01 07 03    3865
>> 05 01 07 04    3879
>> 05 01 07 05    3876
>> 05 01 07 06    3867
>> 05 01 07 07    3887
>>
>> I now read the data as:
>> data <- read.table("data.txt", col.names = c("year", "month", "day",
>> "counts", "hour")) and also included hour in data$date <-
>> as.Date(ISOdate(data$year, data$month, data$day))
>> i.e data$date <- as.Date(ISOdate(data$year, data$month, data$day,
>> data$hour)).
>>
>> However, these did not work.
>>
>> Can you please assist be on how to get this date and time in the right
>> format. The right format I got without hour looks like : 2005-12-29"
>> "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>> [8696] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>> [8701] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>> [8706] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>>
>> I used this in my plot. Please I want this format to include hour.
>>
>> Many thanks for your help. I am just a newbe. I am not sure if this
>> forum is the right one. After registration, I tried to post to Nabble
>> forum where I registered but could not succeed.
>>
>> If there is a mistake, please help/direct me to the right forum.
>>
>> Best regards
>> Ogbos
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>


From dwinsemius at comcast.net  Mon Apr 18 22:07:28 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Apr 2016 13:07:28 -0700
Subject: [R] as.Date
In-Reply-To: <CAC8ss32D3_eFkGq7pJz1fCBCXJW-Fn9=xA6xGgbVAeRHXbkjHQ@mail.gmail.com>
References: <CAC8ss31n27yUydo7gRUf9w1sTRSafXZgXsUGktw8exDYQCxnPw@mail.gmail.com>
	<7D4CE9CA-5B3E-4C66-8AB4-C265E61951A4@gmail.com>
	<CAC8ss32D3_eFkGq7pJz1fCBCXJW-Fn9=xA6xGgbVAeRHXbkjHQ@mail.gmail.com>
Message-ID: <41E769C5-0528-4BA1-865F-62F1C5BA2C49@comcast.net>


> On Apr 18, 2016, at 10:44 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear ALL,
> Thank you so much for your contributions.
> I have made some progress. Below is a simple script I gleaned from
> your kind responses:
> Sys.setenv(TZ="Etc/GMT")
> dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/92")
>     times <- c("23:0:0", "22:0:0", "01:00:00", "18:0:0", "16:0:0")
>     x <- paste(dates, times)
>     aa<-strptime(x, "%m/%d/%y %H:%M:%S")
> bb<-1:5
> plot(aa, bb)
> 
> I tried plotting my result and I got what I am looking for. I think I
> am almost there.
> 
> I am, however, stuck here. My data is a large file and the form
> differs a little from the example I used. The quotation marks in both
> date and time is my headache now. Such inverted commas are not in my
> data. I can with awk transform my data to get exactly something like
> dd/mm/yy. But I wont know how to make the data appear in quotation
> mark in R.

There are not any quotation marks in an R object that is displayed as "02/27/92". The quotation marks are just added by the print function to make it clear to the user that it is a character value. 

If you read such values in with read.table they would automatically be interpreted as character values and then converted to factor class (which you do not want). Read up on the use in the read.* functions for colClasses and stringsAsFactors to safely input character values.
-- 
David.

> I will once more be glad for any more help.
> Ogbos
> 
> PS: I am still afraid of this forum. Please direct me to the right
> forum if this is not ok. Thanks again.
> 
> 
> On 4/18/16, peter dalgaard <pdalgd at gmail.com> wrote:
>> The most important thing is that Date objects by definition do not include
>> time of day. You want to look at ISOdatetime() and as.POSIXct() instead. And
>> beware daylight savings time issues.
>> 
>> -pd
>> 
>> On 18 Apr 2016, at 15:09 , Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>> 
>>> Dear All,
>>> 
>>> I have a data set containing year, month, day and counts as shown below:
>>> data <- read.table("data.txt", col.names = c("year", "month", "day",
>>> "counts"))
>>> Using the formula below, I converted the data to as date and plotted.
>>> 
>>> new.century <- data$year < 70
>>> 
>>> data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
>>> 
>>> data$date <- as.Date(ISOdate(data$year, data$month, data$day))
>>> 
>>> The form of the data is:
>>> 16 1 19 9078
>>> 16 1 20 9060
>>> 16 1 21 9090
>>> 16 1 22 9080
>>> 16 1 23 9121
>>> 16 1 24 9199
>>> 16 1 25 9289
>>> 16 1 26 9285
>>> 16 1 27 9245
>>> 16 1 28 9223
>>> 16 1 29 9298
>>> 16 1 30 9327
>>> 16 1 31 9365
>>> 
>>> Now, I wish to include time (hour) in my data. The new data is of the
>>> form:
>>> 05 01 06 14    3849
>>> 05 01 06 15    3845
>>> 05 01 06 16    3836
>>> 05 01 06 17    3847
>>> 05 01 06 18    3850
>>> 05 01 06 19    3872
>>> 05 01 06 20    3849
>>> 05 01 06 21    3860
>>> 05 01 06 22    3868
>>> 05 01 06 23    3853
>>> 05 01 07 00    3839
>>> 05 01 07 01    3842
>>> 05 01 07 02    3843
>>> 05 01 07 03    3865
>>> 05 01 07 04    3879
>>> 05 01 07 05    3876
>>> 05 01 07 06    3867
>>> 05 01 07 07    3887
>>> 
>>> I now read the data as:
>>> data <- read.table("data.txt", col.names = c("year", "month", "day",
>>> "counts", "hour")) and also included hour in data$date <-
>>> as.Date(ISOdate(data$year, data$month, data$day))
>>> i.e data$date <- as.Date(ISOdate(data$year, data$month, data$day,
>>> data$hour)).
>>> 
>>> However, these did not work.
>>> 
>>> Can you please assist be on how to get this date and time in the right
>>> format. The right format I got without hour looks like : 2005-12-29"
>>> "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>>> [8696] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>>> [8701] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>>> [8706] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
>>> 
>>> I used this in my plot. Please I want this format to include hour.
>>> 
>>> Many thanks for your help. I am just a newbe. I am not sure if this
>>> forum is the right one. After registration, I tried to post to Nabble
>>> forum where I registered but could not succeed.
>>> 
>>> If there is a mistake, please help/direct me to the right forum.
>>> 
>>> Best regards
>>> Ogbos
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Olga.Viedma at uclm.es  Mon Apr 18 21:25:26 2016
From: Olga.Viedma at uclm.es (MARIA OLGA VIEDMA SILLERO)
Date: Mon, 18 Apr 2016 19:25:26 +0000
Subject: [R] ZINB multi-level model using MCMCglmm
Message-ID: <AMXPR01MB022CBA4F64ED4B6F0C044F1EC6B0@AMXPR01MB022.eurprd01.prod.exchangelabs.com>

Hi,



I am Olga Viedma. I am running a Zero-inflated negative binomial (ZINB) multi-level model using MCMCglmm package. I have a doubt. Can I use the "Liab" outputs as fitted data, instead of the predicted values from "predict"? The liab outputs fit very well with the observed data, whereas the predicted values are so bad.



Thanks in advance,



Olga Viedma



D . Olga Viedma Sillero

Profesora Ordenaci n del Territorio

Facultad de Ciencias del Medio Ambiente y Bioqu mica Universidad de Castilla-La Mancha Avd/ Carlos III, s/n. 45071 Toledo

Tel: 925 268800 (ext. 5780)

Email: olga.viedma at uclm.es<mailto:olga.viedma at uclm.es>

http://blog.uclm.es/grupofuego




D?. Olga Viedma Sillero
Profesora Ordenaci?n del Territorio
Facultad de Ciencias del Medio Ambiente y Bioqu?mica
Universidad de Castilla-La Mancha
Avd/ Carlos III, s/n. 45071 Toledo
Tel: 925 268800 (ext. 5780)
Email: olga.viedma at uclm.es
http://blog.uclm.es/grupofuego


	[[alternative HTML version deleted]]


From ebs15242 at gmail.com  Mon Apr 18 22:21:15 2016
From: ebs15242 at gmail.com (Ed Siefker)
Date: Mon, 18 Apr 2016 15:21:15 -0500
Subject: [R] lists and rownames
Message-ID: <CALRb-odexxj1WEt14zg=sVyT9DTbQn+pBz2FuooedLKjUDdJKw@mail.gmail.com>

I'm doing some string manipulation on a vector of file names, and noticed
something curious.  When I strsplit the vector, I get a list of
character vectors.
The list is numbered, as lists are.  When I cast that list as a data
frame with 'as.data.frame()', the resulting columns have names derived
from the original filenames.

Example code is below.  My question is, where are these names stored
in the list?  Are there methods that can access this from the list?
Is there a way to preserve them verbatim?  Thanks
-Ed

> example.names
[1] "con1-1-masked-bottom-green.tsv" "con1-1-masked-bottom-red.tsv"
[3] "con1-1-masked-top-green.tsv"    "con1-1-masked-top-red.tsv"
> example.list <- strsplit(example.names, "-")
> example.list
[[1]]
[1] "con1"      "1"         "masked"    "bottom"    "green.tsv"

[[2]]
[1] "con1"    "1"       "masked"  "bottom"  "red.tsv"

[[3]]
[1] "con1"      "1"         "masked"    "top"       "green.tsv"

[[4]]
[1] "con1"    "1"       "masked"  "top"     "red.tsv"

> example.df <- as.data.frame(example.list)
> example.df
  c..con1....1....masked....bottom....green.tsv..
1                                            con1
2                                               1
3                                          masked
4                                          bottom
5                                       green.tsv
  c..con1....1....masked....bottom....red.tsv..
1                                          con1
2                                             1
3                                        masked
4                                        bottom
5                                       red.tsv
  c..con1....1....masked....top....green.tsv..
1                                         con1
2                                            1
3                                       masked
4                                          top
5                                    green.tsv
  c..con1....1....masked....top....red.tsv..
1                                       con1
2                                          1
3                                     masked
4                                        top
5                                    red.tsv


From thierry.onkelinx at inbo.be  Mon Apr 18 22:22:20 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 18 Apr 2016 22:22:20 +0200
Subject: [R] ZINB multi-level model using MCMCglmm
In-Reply-To: <AMXPR01MB022CBA4F64ED4B6F0C044F1EC6B0@AMXPR01MB022.eurprd01.prod.exchangelabs.com>
References: <AMXPR01MB022CBA4F64ED4B6F0C044F1EC6B0@AMXPR01MB022.eurprd01.prod.exchangelabs.com>
Message-ID: <CAJuCY5zBuPweJs7utajmMBv-GS=L+cS3FzjRgNF7O_cR3EjqGg@mail.gmail.com>

Please don't crosspost. You already posted this question to
r-sig-mixedmodels which is the appropriate list for your question.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-18 21:25 GMT+02:00 MARIA OLGA VIEDMA SILLERO <Olga.Viedma at uclm.es>:

> Hi,
>
>
>
> I am Olga Viedma. I am running a Zero-inflated negative binomial (ZINB)
> multi-level model using MCMCglmm package. I have a doubt. Can I use the
> "Liab" outputs as fitted data, instead of the predicted values from
> "predict"? The liab outputs fit very well with the observed data, whereas
> the predicted values are so bad.
>
>
>
> Thanks in advance,
>
>
>
> Olga Viedma
>
>
>
> D . Olga Viedma Sillero
>
> Profesora Ordenaci n del Territorio
>
> Facultad de Ciencias del Medio Ambiente y Bioqu mica Universidad de
> Castilla-La Mancha Avd/ Carlos III, s/n. 45071 Toledo
>
> Tel: 925 268800 (ext. 5780)
>
> Email: olga.viedma at uclm.es<mailto:olga.viedma at uclm.es>
>
> http://blog.uclm.es/grupofuego
>
>
>
>
> D?. Olga Viedma Sillero
> Profesora Ordenaci?n del Territorio
> Facultad de Ciencias del Medio Ambiente y Bioqu?mica
> Universidad de Castilla-La Mancha
> Avd/ Carlos III, s/n. 45071 Toledo
> Tel: 925 268800 (ext. 5780)
> Email: olga.viedma at uclm.es
> http://blog.uclm.es/grupofuego
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Mon Apr 18 22:28:10 2016
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 18 Apr 2016 13:28:10 -0700
Subject: [R] Add a vertical arrow to a time series graph using ggplot and xts
Message-ID: <CABcx46DnQuWWY2MEy6S_LCEGnHF+59BakCsDf55SCZgLfiOr0Q@mail.gmail.com>

Hi,

   I am trying to add a vertical arrow (from top to bottom or from bottom
to up) to a time series plot using ggplot2 and xts. It seems that the
vertical line command "geom_vline" does not work for this purpose (Correct
me if I am wrong). I try the command "geom_segment" as follows, but I got
an error message at the last line "Error: Invalid input: date_trans works
with objects of class Date only".

    Sometimes the error message occurs when I run the program, sometimes it
does not occur until I call the plot "p1". How could I add a vertical line
to the plot? Thanks!

Miao


######################
library(xts)  # primary
#library(tseries)   # Unit root tests
library(ggplot2)
library(vars)
library(grid)
dt_xts<-xts(x = 1:10, order.by = seq(as.Date("2016-01-01"),
as.Date("2016-01-10"), by = "1 day"))
colnames(dt_xts)<-"gdp"
xmin<-min(index(dt_xts))
xmax<-max(index(dt_xts))
df1<-data.frame(x = index(dt_xts), coredata(dt_xts))
p<-ggplot(data = df1, mapping= aes(x=x, y=gdp))+geom_line()
rg<-ggplot_build(p)$panel$ranges[[1]]$y.range
y1<-rg[1]
y2<-rg[2]
df2<-data.frame(x = "2016-01-05", y1=y1, y2=y2 )
p1<-p+geom_segment(mapping=aes(x=x, y=y1, xend=x, yend=y2), data=df2,
arrow=arrow())

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Apr 18 22:51:53 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 18 Apr 2016 16:51:53 -0400
Subject: [R] lists and rownames
In-Reply-To: <CALRb-odexxj1WEt14zg=sVyT9DTbQn+pBz2FuooedLKjUDdJKw@mail.gmail.com>
References: <CALRb-odexxj1WEt14zg=sVyT9DTbQn+pBz2FuooedLKjUDdJKw@mail.gmail.com>
Message-ID: <CAM_vjuniEgEJ_2Bh7pC2fdDtZKrX8zdjgeqM8p4mZ52pFRrZiQ@mail.gmail.com>

They aren't being stored, they are being generated on the fly. You can
create the same names using make.names()

example.names <- c("con1-1-masked-bottom-green.tsv",
"con1-1-masked-bottom-red.tsv", "con1-1-masked-top-green.tsv",
"con1-1-masked-top-red.tsv")

example.list <- strsplit(example.names, "-")

as.data.frame(example.list)

> make.names(example.list)
[1] "c..con1....1....masked....bottom....green.tsv.."
"c..con1....1....masked....bottom....red.tsv.."
[3] "c..con1....1....masked....top....green.tsv.."
"c..con1....1....masked....top....red.tsv.."


But you'll probably get a more usable result if you set names
explicitly, for instance:

names(example.list) <- example.names
as.data.frame(example.list)

Note that the characters that are not legal in column names are
changed for you. You can disable that behavior with check.names=FALSE
if you use data.frame() rather than as.data.frame().

Sarah



On Mon, Apr 18, 2016 at 4:21 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I'm doing some string manipulation on a vector of file names, and noticed
> something curious.  When I strsplit the vector, I get a list of
> character vectors.
> The list is numbered, as lists are.  When I cast that list as a data
> frame with 'as.data.frame()', the resulting columns have names derived
> from the original filenames.
>
> Example code is below.  My question is, where are these names stored
> in the list?  Are there methods that can access this from the list?
> Is there a way to preserve them verbatim?  Thanks
> -Ed
>
>> example.names
> [1] "con1-1-masked-bottom-green.tsv" "con1-1-masked-bottom-red.tsv"
> [3] "con1-1-masked-top-green.tsv"    "con1-1-masked-top-red.tsv"
>> example.list <- strsplit(example.names, "-")
>> example.list
> [[1]]
> [1] "con1"      "1"         "masked"    "bottom"    "green.tsv"
>
> [[2]]
> [1] "con1"    "1"       "masked"  "bottom"  "red.tsv"
>
> [[3]]
> [1] "con1"      "1"         "masked"    "top"       "green.tsv"
>
> [[4]]
> [1] "con1"    "1"       "masked"  "top"     "red.tsv"
>
>> example.df <- as.data.frame(example.list)
>> example.df
>   c..con1....1....masked....bottom....green.tsv..
> 1                                            con1
> 2                                               1
> 3                                          masked
> 4                                          bottom
> 5                                       green.tsv
>   c..con1....1....masked....bottom....red.tsv..
> 1                                          con1
> 2                                             1
> 3                                        masked
> 4                                        bottom
> 5                                       red.tsv
>   c..con1....1....masked....top....green.tsv..
> 1                                         con1
> 2                                            1
> 3                                       masked
> 4                                          top
> 5                                    green.tsv
>   c..con1....1....masked....top....red.tsv..
> 1                                       con1
> 2                                          1
> 3                                     masked
> 4                                        top
> 5                                    red.tsv
>


From jholtman at gmail.com  Mon Apr 18 23:44:34 2016
From: jholtman at gmail.com (jim holtman)
Date: Mon, 18 Apr 2016 17:44:34 -0400
Subject: [R] lists and rownames
In-Reply-To: <CALRb-odexxj1WEt14zg=sVyT9DTbQn+pBz2FuooedLKjUDdJKw@mail.gmail.com>
References: <CALRb-odexxj1WEt14zg=sVyT9DTbQn+pBz2FuooedLKjUDdJKw@mail.gmail.com>
Message-ID: <CAAxdm-5jZ9zWw5y5P+aKyeza9n_bsm9W5sOh5TR_i4y6u-uCQg@mail.gmail.com>

You can always add those names to the list:  is this what you are after?

> example.names <- c("con1-1-masked-bottom-green.tsv",
"con1-1-masked-bottom-red.tsv"
+         , "con1-1-masked-top-green.tsv",    "con1-1-masked-top-red.tsv")
> example.list <- strsplit(example.names, "-")
> names(example.list) <- example.names
> example.df <- as.data.frame(example.list)
>
> example.df
  con1.1.masked.bottom.green.tsv con1.1.masked.bottom.red.tsv
con1.1.masked.top.green.tsv
1                           con1                         con1
         con1
2                              1                            1
            1
3                         masked                       masked
       masked
4                         bottom                       bottom
          top
5                      green.tsv                      red.tsv
    green.tsv
  con1.1.masked.top.red.tsv
1                      con1
2                         1
3                    masked
4                       top
5                   red.tsv
> str(example.df)
'data.frame':   5 obs. of  4 variables:
 $ con1.1.masked.bottom.green.tsv: Factor w/ 5 levels
"1","bottom","con1",..: 3 1 5 2 4
 $ con1.1.masked.bottom.red.tsv  : Factor w/ 5 levels
"1","bottom","con1",..: 3 1 4 2 5
 $ con1.1.masked.top.green.tsv   : Factor w/ 5 levels
"1","con1","green.tsv",..: 2 1 4 5 3
 $ con1.1.masked.top.red.tsv     : Factor w/ 5 levels
"1","con1","masked",..: 2 1 3 5 4



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Apr 18, 2016 at 4:21 PM, Ed Siefker <ebs15242 at gmail.com> wrote:

> I'm doing some string manipulation on a vector of file names, and noticed
> something curious.  When I strsplit the vector, I get a list of
> character vectors.
> The list is numbered, as lists are.  When I cast that list as a data
> frame with 'as.data.frame()', the resulting columns have names derived
> from the original filenames.
>
> Example code is below.  My question is, where are these names stored
> in the list?  Are there methods that can access this from the list?
> Is there a way to preserve them verbatim?  Thanks
> -Ed
>
> > example.names
> [1] "con1-1-masked-bottom-green.tsv" "con1-1-masked-bottom-red.tsv"
> [3] "con1-1-masked-top-green.tsv"    "con1-1-masked-top-red.tsv"
> > example.list <- strsplit(example.names, "-")
> > example.list
> [[1]]
> [1] "con1"      "1"         "masked"    "bottom"    "green.tsv"
>
> [[2]]
> [1] "con1"    "1"       "masked"  "bottom"  "red.tsv"
>
> [[3]]
> [1] "con1"      "1"         "masked"    "top"       "green.tsv"
>
> [[4]]
> [1] "con1"    "1"       "masked"  "top"     "red.tsv"
>
> > example.df <- as.data.frame(example.list)
> > example.df
>   c..con1....1....masked....bottom....green.tsv..
> 1                                            con1
> 2                                               1
> 3                                          masked
> 4                                          bottom
> 5                                       green.tsv
>   c..con1....1....masked....bottom....red.tsv..
> 1                                          con1
> 2                                             1
> 3                                        masked
> 4                                        bottom
> 5                                       red.tsv
>   c..con1....1....masked....top....green.tsv..
> 1                                         con1
> 2                                            1
> 3                                       masked
> 4                                          top
> 5                                    green.tsv
>   c..con1....1....masked....top....red.tsv..
> 1                                       con1
> 2                                          1
> 3                                     masked
> 4                                        top
> 5                                    red.tsv
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From daily.puja at gmail.com  Mon Apr 18 22:33:54 2016
From: daily.puja at gmail.com (Ansley Silva)
Date: Mon, 18 Apr 2016 16:33:54 -0400
Subject: [R] Indicator Species analysis; trouble with multipatt
Message-ID: <CAK2Sg-3zkzZ7TTNiM4fvrrMf=XCUBmVYLA1STpJy_Lh9QGVm0A@mail.gmail.com>

Hello,

*Error in tx  %*% comb : non-conformable arguments*

Suggestions greatly appreciated.  I am a beginner and this is my first time
posting.

I would like to get the summary for indicator species analysis, using
package indicspecies with multipatt.  I am getting errors, I believe, do to
my data organization.  After reorganizing and reorganizing, nothing has
helped.

> data<- read.csv(file="Data1.csv", header=TRUE, row.names=1, sep=",")
> ap<-data[c(1:24, 1:81)]
> groups<-c(rep(1:4,6))
> indval<- multipatt(ap, groups, control = how(nperm=999))
*Error in tx  %*% comb : non-conformable arguments*



-- 
Ansley Silva


*"The clearest way into the Universe is through a forest wilderness." John
Muir*


*Graduate Research Assistant*

From giftedlife2014 at gmail.com  Mon Apr 18 23:09:36 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Mon, 18 Apr 2016 22:09:36 +0100
Subject: [R] as.Date: fixed
Message-ID: <CAC8ss31dRWdbD6N6DA791UV05gnYZQCprx4JL6fp3uFHzTj1rQ@mail.gmail.com>

Dear All,
Many thanks for bailing me out.
Ogbos
On Apr 18, 2016 9:07 PM, "David Winsemius" <dwinsemius at comcast.net> wrote:

>
> > On Apr 18, 2016, at 10:44 AM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >
> > Dear ALL,
> > Thank you so much for your contributions.
> > I have made some progress. Below is a simple script I gleaned from
> > your kind responses:
> > Sys.setenv(TZ="Etc/GMT")
> > dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/92")
> >     times <- c("23:0:0", "22:0:0", "01:00:00", "18:0:0", "16:0:0")
> >     x <- paste(dates, times)
> >     aa<-strptime(x, "%m/%d/%y %H:%M:%S")
> > bb<-1:5
> > plot(aa, bb)
> >
> > I tried plotting my result and I got what I am looking for. I think I
> > am almost there.
> >
> > I am, however, stuck here. My data is a large file and the form
> > differs a little from the example I used. The quotation marks in both
> > date and time is my headache now. Such inverted commas are not in my
> > data. I can with awk transform my data to get exactly something like
> > dd/mm/yy. But I wont know how to make the data appear in quotation
> > mark in R.
>
> There are not any quotation marks in an R object that is displayed as
> "02/27/92". The quotation marks are just added by the print function to
> make it clear to the user that it is a character value.
>
> If you read such values in with read.table they would automatically be
> interpreted as character values and then converted to factor class (which
> you do not want). Read up on the use in the read.* functions for colClasses
> and stringsAsFactors to safely input character values.
> --
> David.
>
> > I will once more be glad for any more help.
> > Ogbos
> >
> > PS: I am still afraid of this forum. Please direct me to the right
> > forum if this is not ok. Thanks again.
> >
> >
> > On 4/18/16, peter dalgaard <pdalgd at gmail.com> wrote:
> >> The most important thing is that Date objects by definition do not
> include
> >> time of day. You want to look at ISOdatetime() and as.POSIXct()
> instead. And
> >> beware daylight savings time issues.
> >>
> >> -pd
> >>
> >> On 18 Apr 2016, at 15:09 , Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >>
> >>> Dear All,
> >>>
> >>> I have a data set containing year, month, day and counts as shown
> below:
> >>> data <- read.table("data.txt", col.names = c("year", "month", "day",
> >>> "counts"))
> >>> Using the formula below, I converted the data to as date and plotted.
> >>>
> >>> new.century <- data$year < 70
> >>>
> >>> data$year <- ifelse(new.century, data$year + 2000, data$year + 1900)
> >>>
> >>> data$date <- as.Date(ISOdate(data$year, data$month, data$day))
> >>>
> >>> The form of the data is:
> >>> 16 1 19 9078
> >>> 16 1 20 9060
> >>> 16 1 21 9090
> >>> 16 1 22 9080
> >>> 16 1 23 9121
> >>> 16 1 24 9199
> >>> 16 1 25 9289
> >>> 16 1 26 9285
> >>> 16 1 27 9245
> >>> 16 1 28 9223
> >>> 16 1 29 9298
> >>> 16 1 30 9327
> >>> 16 1 31 9365
> >>>
> >>> Now, I wish to include time (hour) in my data. The new data is of the
> >>> form:
> >>> 05 01 06 14    3849
> >>> 05 01 06 15    3845
> >>> 05 01 06 16    3836
> >>> 05 01 06 17    3847
> >>> 05 01 06 18    3850
> >>> 05 01 06 19    3872
> >>> 05 01 06 20    3849
> >>> 05 01 06 21    3860
> >>> 05 01 06 22    3868
> >>> 05 01 06 23    3853
> >>> 05 01 07 00    3839
> >>> 05 01 07 01    3842
> >>> 05 01 07 02    3843
> >>> 05 01 07 03    3865
> >>> 05 01 07 04    3879
> >>> 05 01 07 05    3876
> >>> 05 01 07 06    3867
> >>> 05 01 07 07    3887
> >>>
> >>> I now read the data as:
> >>> data <- read.table("data.txt", col.names = c("year", "month", "day",
> >>> "counts", "hour")) and also included hour in data$date <-
> >>> as.Date(ISOdate(data$year, data$month, data$day))
> >>> i.e data$date <- as.Date(ISOdate(data$year, data$month, data$day,
> >>> data$hour)).
> >>>
> >>> However, these did not work.
> >>>
> >>> Can you please assist be on how to get this date and time in the right
> >>> format. The right format I got without hour looks like : 2005-12-29"
> >>> "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> >>> [8696] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> >>> [8701] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> >>> [8706] "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29" "2005-12-29"
> >>>
> >>> I used this in my plot. Please I want this format to include hour.
> >>>
> >>> Many thanks for your help. I am just a newbe. I am not sure if this
> >>> forum is the right one. After registration, I tried to post to Nabble
> >>> forum where I registered but could not succeed.
> >>>
> >>> If there is a mistake, please help/direct me to the right forum.
> >>>
> >>> Best regards
> >>> Ogbos
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Peter Dalgaard, Professor,
> >> Center for Statistics, Copenhagen Business School
> >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >> Phone: (+45)38153501
> >> Office: A 4.23
> >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Apr 19 01:11:30 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 19 Apr 2016 09:11:30 +1000
Subject: [R] Indicator Species analysis; trouble with multipatt
In-Reply-To: <CAK2Sg-3zkzZ7TTNiM4fvrrMf=XCUBmVYLA1STpJy_Lh9QGVm0A@mail.gmail.com>
References: <CAK2Sg-3zkzZ7TTNiM4fvrrMf=XCUBmVYLA1STpJy_Lh9QGVm0A@mail.gmail.com>
Message-ID: <CA+8X3fVWXN1brU10Lbit5+mPr-2rw16Oxk0OcGp+LmoALzJ5jQ@mail.gmail.com>

Hi Ansley,
Without your data file (or a meaningful subset) we can only guess, but
you may be trying to define groups on the columns rather than the rows
of the data set. Usually rows represent cases and each case must have
a value for the grouping variable.

Jim


On Tue, Apr 19, 2016 at 6:33 AM, Ansley Silva <daily.puja at gmail.com> wrote:
> Hello,
>
> *Error in tx  %*% comb : non-conformable arguments*
>
> Suggestions greatly appreciated.  I am a beginner and this is my first time
> posting.
>
> I would like to get the summary for indicator species analysis, using
> package indicspecies with multipatt.  I am getting errors, I believe, do to
> my data organization.  After reorganizing and reorganizing, nothing has
> helped.
>
>> data<- read.csv(file="Data1.csv", header=TRUE, row.names=1, sep=",")
>> ap<-data[c(1:24, 1:81)]
>> groups<-c(rep(1:4,6))
>> indval<- multipatt(ap, groups, control = how(nperm=999))
> *Error in tx  %*% comb : non-conformable arguments*
>
>
>
> --
> Ansley Silva
>
>
> *"The clearest way into the Universe is through a forest wilderness." John
> Muir*
>
>
> *Graduate Research Assistant*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Apr 19 02:25:32 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 19 Apr 2016 10:25:32 +1000
Subject: [R] problem on simulation code (the loop unable to function
	effectively)
In-Reply-To: <58235.172.16.74.16.1461002601.squirrel@webmail.student.umt.edu.my>
References: <58235.172.16.74.16.1461002601.squirrel@webmail.student.umt.edu.my>
Message-ID: <CA+8X3fUWxPC4WozT0VQNE3X7pw=LDjHGz3xbN+6B0NrAYpGOcA@mail.gmail.com>

Hi Jeem,
First, please send questions like this to the help list, not me.

I assume that you are in a similar position to sjtan who has been
sending almost exactly the same questions.

The problem is not in the loops (which look rather familiar to me) but
in your initial assignments at the top. For instance:

scale parameter=(1,1.5,2,2.5,3)

produces an error which has nothing to do with the loops. This is a
very basic mistake, for:

scale_parameter<-c(1,1.5,2,2.5,3)

fixes it. I think if you learn a bit about basic R coding you will be
able to fix these problems yourself.

Jim


On Tue, Apr 19, 2016 at 4:03 AM,  <uk31429 at student.umt.edu.my> wrote:
> Greeting dr jim,
>
> I am student from Malaysia. I am doing R simulation study. For your
> information, I have been written a code relating to 2 gamma distribution
> with equal skewness.
> skewness=1.0
> shape parameter=16/9
> scale parameter=(1,1.5,2,2.5,3)
>
> Below are my coding, however, the code have some error and yet after
> trying this and that for a whole day, i couldn't spot the mistake. The
> output should be greater or smaller than 0.05 while no exceeding too much
> .But the for loop only able to function for scale parameter 1 .I try to
> apply another for loop for the scale parameter, but the output become
> worsen, as the simulation will even get hang. all of the output is 100.
> Please, could you give me some advice ?
>
> #For gamma disribution with equal skewness 1.5
> rm(list=ls())
> nSims<-100
> alpha<-0.05
>
> #here we declare the random seed generator
> set.seed(3)
>
> ## Put the samples sizes into matrix then use a loop for sample sizes
> sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),nrow=2)
>
> #shape parameter for both gamma distribution for equal skewness
> shp<-rep(16/9,each=45)
>
> #scale parameter for sample 1
> #scale paramter for sample 2 set as constant 1
> d1<-matrix(c(1,1.5,2,2.5,3),ncol=1)
> scp<-rep(d1,9)
>
> #create a matrix combining the forty five cases of combination of sample
> sizes,shape and scale parameter
> all<- cbind(rep(sample_sizes[1,],5),rep(sample_sizes[2,],5),scp)
>
> # name the column samples 1 and 2 and standard deviation
> colnames(all) <- c("m", "n","scp")
>
>
> #set empty vector of length to store p-value
> equal3<-rep(0,nrow(all))
> unequal4<-rep(0,nrow(all))
> mann5<-rep(0,nrow(all))
>
> #set nrow =nsims because wan storing every p-value simulated
> #for gamma distribution with equal skewness
> matrix3_equal  <-matrix(0,nrow=nSims,ncol=3)
> matrix4_unequal<-matrix(0,nrow=nSims,ncol=3)
> matrix5_mann   <-matrix(0,nrow=nSims,ncol=3)
>
>
> # this loop steps through the all_combine matrix
>  for(ss in 1:nrow(all))
>
>   {  #generate samples from the first column and second column
>      m<-all[ss,1]
>      n<-all[ss,2]
>
>       for ( sim in 1:nSims)
>      {
>         #generate 2 random samples from gamma distribution with equal
> skewness
>         gamma1<-rgamma(m,16/9,all[ss,3])
>         gamma2<-rgamma(n,16/9,1)
>     #minus population mean from each sample to maintain the equality of
> null    #hypotheses (population mean =scale parameter *shape
> parameter)
> gamma1<-gamma1-16/9*all[ss,3]
> gamma2<-gamma2-16/9
>
>      matrix3_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
>      matrix4_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
>      matrix5_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
>
>       }
> ##store the result
> equal3[ss]<- sum(matrix3_equal[,1]<alpha)
>    unequal4[ss]<-sum(matrix4_unequal[,2]<alpha)
>       mann5[ss]<- sum(matrix5_mann[,3]<alpha)
> }
> g<-cbind(all, equal3, unequal4, mann5)
>
> I will be really appreciated for any respond .Thanks.
>
> Your sincerely
> Jeem
>
>
>
>
> Computational Mathematics
> School of Informatics and Applied Mathematics
> Universiti Malaysia Terengganu
> 21030 Kuala Terengganu, Terengganu, Malaysia
> Phone : 017-7799039
> Email : uk31429 at student.umt.edu.my
>


From michaeleartz at gmail.com  Tue Apr 19 03:15:53 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Mon, 18 Apr 2016 20:15:53 -0500
Subject: [R] Interquartile Range
Message-ID: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>

Hi,
  I am trying to show an interquartile range while grouping values using
the function ddply().  So my function call now is like

groupedAll <- ddply(data
                 ,~groupColumn
                 ,summarise
                 ,col1_mean=mean(col1)
                 ,col2_mode=Mode(col2) #Function I wrote for getting the
mode shown below

 ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
                 )

#custom Mode function
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

I am not sre what is going wrong on my interquartile range function, it
works on its own outside of ddply()

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Apr 19 03:25:56 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 19 Apr 2016 11:25:56 +1000
Subject: [R] problem on simulation code (the loop unable to function
	effectively)
In-Reply-To: <61967.172.16.74.16.1461026107.squirrel@webmail.student.umt.edu.my>
References: <58235.172.16.74.16.1461002601.squirrel@webmail.student.umt.edu.my>
	<CA+8X3fUWxPC4WozT0VQNE3X7pw=LDjHGz3xbN+6B0NrAYpGOcA@mail.gmail.com>
	<61967.172.16.74.16.1461026107.squirrel@webmail.student.umt.edu.my>
Message-ID: <CA+8X3fUPdxWfj+8XFV-scVJYvV=YcMqDhUvgNykgUi8xcvwuqw@mail.gmail.com>

Hi Si Jie,
Again, please send questions to the list, not me.

Okay, I may have worked out what you are doing. The program runs and
produces what I would expect in the rightmost columns of the result
"g".

You are storing the number of each test for which the p value is less
than 0.05. It looks to me as though the objects storing the results
should be vectors as you are only storing 100 p values at a time.
Using matrices in which the only part of the values are used is a bit
confusing. Perhaps this resulted from my initial suggestion of using
matrices and storing all of the results before calculating the number
of p values less than 0.05, which you didn't do.

If I rewrite your code with vectors for storing the p values, I get
the same results. Essentially, with the scale parameter set the same
for both distributions, you get about five false positives (Type I
errors) per 100 simulations. This is expected. As the scale
parameters, and thus the means, of the groups diverge, you first get a
large number of results less than 0.05. With large differences between
the means, all results are less than 0.05, which seems correct to me.
You have probably been asked to interpret the effect of group size and
difference in means on the number of p values less than 0.05. If the
difference in means is large enough, you are almost guaranteed this.
In the cases where this is not occurring (i.e. the first difference in
scale parameters) you can see the difference in outcomes between the
three significance tests.

Jim



On Tue, Apr 19, 2016 at 10:35 AM,  <uk31429 at student.umt.edu.my> wrote:
> Hi, i am sorry but that part is not a part of the code.
> I am just listing my variable for simulation out at the beginning in order
> to provide easy understanding.
> i am doing a whole night to find out where have i done wrong.But i just
> keep repeat producing the wrong output ...
>
>
>
>
>
>
>> Hi Jeem,
>> First, please send questions like this to the help list, not me.
>>
>> I assume that you are in a similar position to sjtan who has been
>> sending almost exactly the same questions.
>>
>> The problem is not in the loops (which look rather familiar to me) but
>> in your initial assignments at the top. For instance:
>>
>> scale parameter=(1,1.5,2,2.5,3)
>>
>> produces an error which has nothing to do with the loops. This is a
>> very basic mistake, for:
>>
>> scale_parameter<-c(1,1.5,2,2.5,3)
>>
>> fixes it. I think if you learn a bit about basic R coding you will be
>> able to fix these problems yourself.
>>
>> Jim
>>
>>
>> On Tue, Apr 19, 2016 at 4:03 AM,  <uk31429 at student.umt.edu.my> wrote:
>>> Greeting dr jim,
>>>
>>> I am student from Malaysia. I am doing R simulation study. For your
>>> information, I have been written a code relating to 2 gamma distribution
>>> with equal skewness.
>>> skewness=1.0
>>> shape parameter=16/9
>>> scale parameter=(1,1.5,2,2.5,3)
>>>
>>> Below are my coding, however, the code have some error and yet after
>>> trying this and that for a whole day, i couldn't spot the mistake. The
>>> output should be greater or smaller than 0.05 while no exceeding too
>>> much
>>> .But the for loop only able to function for scale parameter 1 .I try to
>>> apply another for loop for the scale parameter, but the output become
>>> worsen, as the simulation will even get hang. all of the output is 100.
>>> Please, could you give me some advice ?
>>>
>>> #For gamma disribution with equal skewness 1.5
>>> rm(list=ls())
>>> nSims<-100
>>> alpha<-0.05
>>>
>>> #here we declare the random seed generator
>>> set.seed(3)
>>>
>>> ## Put the samples sizes into matrix then use a loop for sample sizes
>>> sample_sizes<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),nrow=2)
>>>
>>> #shape parameter for both gamma distribution for equal skewness
>>> shp<-rep(16/9,each=45)
>>>
>>> #scale parameter for sample 1
>>> #scale paramter for sample 2 set as constant 1
>>> d1<-matrix(c(1,1.5,2,2.5,3),ncol=1)
>>> scp<-rep(d1,9)
>>>
>>> #create a matrix combining the forty five cases of combination of sample
>>> sizes,shape and scale parameter
>>> all<- cbind(rep(sample_sizes[1,],5),rep(sample_sizes[2,],5),scp)
>>>
>>> # name the column samples 1 and 2 and standard deviation
>>> colnames(all) <- c("m", "n","scp")
>>>
>>>
>>> #set empty vector of length to store p-value
>>> equal3<-rep(0,nrow(all))
>>> unequal4<-rep(0,nrow(all))
>>> mann5<-rep(0,nrow(all))
>>>
>>> #set nrow =nsims because wan storing every p-value simulated
>>> #for gamma distribution with equal skewness
>>> matrix3_equal  <-matrix(0,nrow=nSims,ncol=3)
>>> matrix4_unequal<-matrix(0,nrow=nSims,ncol=3)
>>> matrix5_mann   <-matrix(0,nrow=nSims,ncol=3)
>>>
>>>
>>> # this loop steps through the all_combine matrix
>>>  for(ss in 1:nrow(all))
>>>
>>>   {  #generate samples from the first column and second column
>>>      m<-all[ss,1]
>>>      n<-all[ss,2]
>>>
>>>       for ( sim in 1:nSims)
>>>      {
>>>         #generate 2 random samples from gamma distribution with equal
>>> skewness
>>>         gamma1<-rgamma(m,16/9,all[ss,3])
>>>         gamma2<-rgamma(n,16/9,1)
>>>     #minus population mean from each sample to maintain the equality of
>>> null    #hypotheses (population mean =scale parameter *shape
>>> parameter)
>>> gamma1<-gamma1-16/9*all[ss,3]
>>> gamma2<-gamma2-16/9
>>>
>>>      matrix3_equal[sim,1]<-t.test(gamma1,gamma2,var.equal=TRUE)$p.value
>>>      matrix4_unequal[sim,2]<-t.test(gamma1,gamma2,var.equal=FALSE)$p.value
>>>      matrix5_mann[sim,3] <-wilcox.test(gamma1,gamma2)$p.value
>>>
>>>       }
>>> ##store the result
>>> equal3[ss]<- sum(matrix3_equal[,1]<alpha)
>>>    unequal4[ss]<-sum(matrix4_unequal[,2]<alpha)
>>>       mann5[ss]<- sum(matrix5_mann[,3]<alpha)
>>> }
>>> g<-cbind(all, equal3, unequal4, mann5)
>>>
>>> I will be really appreciated for any respond .Thanks.
>>>
>>> Your sincerely
>>> Jeem
>>>
>>>
>>>
>>>
>>> Computational Mathematics
>>> School of Informatics and Applied Mathematics
>>> Universiti Malaysia Terengganu
>>> 21030 Kuala Terengganu, Terengganu, Malaysia
>>> Phone : 017-7799039
>>> Email : uk31429 at student.umt.edu.my
>>>
>>
>
>
> Tan Si Jie UK31429
> Computational Mathematics
> School of Informatics and Applied Mathematics
> Universiti Malaysia Terengganu
> 21030 Kuala Terengganu, Terengganu, Malaysia
> Phone : 017-7799039
> Email : uk31429 at student.umt.edu.my
>


From drjimlemon at gmail.com  Tue Apr 19 04:02:13 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 19 Apr 2016 12:02:13 +1000
Subject: [R] Interquartile Range
In-Reply-To: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
Message-ID: <CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>

Hi Michael,
At a guess, try this:

iqr<-function(x) {
 return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
}

.col3_Range=iqr(datat$tenure)

Jim



On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com> wrote:
> Hi,
>   I am trying to show an interquartile range while grouping values using
> the function ddply().  So my function call now is like
>
> groupedAll <- ddply(data
>                  ,~groupColumn
>                  ,summarise
>                  ,col1_mean=mean(col1)
>                  ,col2_mode=Mode(col2) #Function I wrote for getting the
> mode shown below
>
>  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
> as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>                  )
>
> #custom Mode function
> Mode <- function(x) {
>   ux <- unique(x)
>   ux[which.max(tabulate(match(x, ux)))]
> }
>
> I am not sre what is going wrong on my interquartile range function, it
> works on its own outside of ddply()
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulhaqz at gmail.com  Tue Apr 19 06:37:16 2016
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Tue, 19 Apr 2016 09:37:16 +0500
Subject: [R] Sum of Numeric Values in a DF Column
In-Reply-To: <CAGxFJbRTmHu0p1eZbZg0p6UMYxAYL875nMWCgO2jyn0xZcmMBw@mail.gmail.com>
References: <CADw4CktTb_=S_DRYoBAYRqc49qdf-AHxkdqdBzG50uaiF41xOQ@mail.gmail.com>
	<CAGx1TMDkCbc9qOwb3q35ivoYdfBPxFfK+cF1-QeyBGkrVVV8Rg@mail.gmail.com>
	<CAGxFJbSq_cezBRy7jQZD1N-DNZOYMOKPaUE9jopkeQ=x-Uu3Pw@mail.gmail.com>
	<CAGxFJbRTmHu0p1eZbZg0p6UMYxAYL875nMWCgO2jyn0xZcmMBw@mail.gmail.com>
Message-ID: <CADw4Ckso0i0GYBVm3vornJhzqaKy0E430GhDXrOj9MyphxiuUg@mail.gmail.com>

Dear Gunter /  Heiberger,

Thanks for the help. This is what I was looking for:

> ... and here is a non-dplyr rsolution:
>
>> z <-gsub("[^[:digit:]]"," ",dd$Lower)
>
>> sapply(strsplit(z," +"),function(x)sum(as.numeric(x),na.rm=TRUE))
> [1] 105  67  60 100  80

And that would explain, why one could not use "unlist" as a grand sum total
was not desired, but rather sum for each of the rows.


Br /

On Mon, Apr 18, 2016 at 10:57 PM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> ... and a slightly more efficient non-dplyr 1-liner:
>
> > sapply(strsplit(dd$Lower,"[^[:digit:]]"),
> function(x)sum(as.numeric(x), na.rm=TRUE))
>
> [1] 105  67  60 100  80
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Apr 18, 2016 at 10:43 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > ... and here is a non-dplyr rsolution:
> >
> >> z <-gsub("[^[:digit:]]"," ",dd$Lower)
> >
> >> sapply(strsplit(z," +"),function(x)sum(as.numeric(x),na.rm=TRUE))
> > [1] 105  67  60 100  80
> >
> >
> > Cheers,
> > Bert
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Apr 18, 2016 at 10:07 AM, Richard M. Heiberger <rmh at temple.edu>
> wrote:
> >> ## Continuing with your data
> >>
> >> AA <- stringr::str_extract_all(dd[[2]],"[[:digit:]]+")
> >> BB <- lapply(AA, as.numeric)
> >> ## I think you are looking for one of the following two expressions
> >> sum(unlist(BB))
> >> sapply(BB, sum)
> >>
> >>
> >> On Mon, Apr 18, 2016 at 12:48 PM, Burhan ul haq <ulhaqz at gmail.com>
> wrote:
> >>> Hi,
> >>>
> >>> I request help with the following:
> >>>
> >>> INPUT: A data frame where column "Lower" is a character containing
> numeric
> >>> values (different count or occurrences of numeric values in each row,
> >>> mostly 2)
> >>>
> >>>> dput(dd)
> >>> structure(list(State = c("Alabama", "Alaska", "Arizona", "Arkansas",
> >>> "California"), Lower = c("R 72?33", "R/Coalition 27(23 R, 4 D)?12 D, 1
> >>> Ind.",
> >>> "R 36?24", "R 64?35, 1 Ind.", "D 52?28"), Upper = c("R 26?8, 1 Ind.",
> >>> "R/Coalition 15(14 R, 1 D)?5 D", "R 18?12", "R 24?11", "D 26?14"
> >>> )), .Names = c("State", "Lower", "Upper"), row.names = c(NA,
> >>> 5L), class = "data.frame")
> >>>
> >>> PROBLEM: Need to extract all numeric values and sum them. There are few
> >>> exceptions like row2. But these can be ignored and will be fixed
> manually
> >>>
> >>> SOLUTION SO FAR:
> >>> str_extract_all(dd[[2]],"[[:digit:]]+"), returns a list of numbers as
> >>> character. I am unable to unlist it, because it mixes them all
> together, ...
> >>>
> >>> And if I may add, is there a "dplyr" way of doing it ...
> >>>
> >>>
> >>> Thanks
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From haenlein at escpeurope.eu  Tue Apr 19 08:57:53 2016
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Tue, 19 Apr 2016 08:57:53 +0200
Subject: [R] (Small) programming job related to network analysis
Message-ID: <CAOyz9G4WPNVaifaYy=6+F2+W_N2WspezXguo9aJpWMjGCC7BfQ@mail.gmail.com>

Dear all,

I am looking for help in programming three functions. Those functions
should simulate (social) networks according to the process described in :

(1) A.H. Dekker - "Realistic Social Networks for Simulation using Network
Rewiring" (
http://www.mssanz.org.au/MODSIM07/papers/13_s20/RealisticSocial_s20_Dekker_.pdf
)

(2) Konstantin Klemm and V?ctor M. Egu?luz - "Growing scale-free networks
with small-world behavior" (http://ifisc.uib-csic.es/victor/Nets/sw.pdf)

(3) Petter Holme and Beom Jun Kim - "Growing Scale-Free Networks with
Tunable Clustering" (http://arxiv.org/pdf/cond-mat/0110452.pdf)

I am looking for three functions (e.g., sample_dekker, sample_klemm,
sample_holme) that generate an output similar to the functions sample_pa
and sample_smallworld in the R package igraph. The input should be the
number of nodes in the network (e.g., 1000) and any other parameters those
models require.

In case this is of relevance please get in touch with me by email to
discuss further details.

Thanks,

Michael



Michael Haenlein
Professor of Marketing
ESCP Europe

	[[alternative HTML version deleted]]


From catagui at gmail.com  Tue Apr 19 01:35:14 2016
From: catagui at gmail.com (Catalina Aguilar Hurtado)
Date: Tue, 19 Apr 2016 09:35:14 +1000
Subject: [R] heatmap2 error key
Message-ID: <CAAHBMXZGVMnGovB+xE2UNrVpEq4O6Gi3veCy9NSDBXPd_T8wRw@mail.gmail.com>

Hi I am trying to understand what happen with the heatmap.2 code that it
used to work (last used in October 2015). I am able to get a heatmap but my
colour key doesn't come up and instead I get an error in all my files the
used to work. Does anyone has any idea of what could have changed? or how
to fix this.

Thanks.

#

Error in seq.default(min.raw, max.raw, by = min(diff(breaks)/100)) :
  wrong sign in 'by' argument
In addition: Warning message:
In image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  :
  unsorted 'breaks' will be sorted before use

##

library("RColorBrewer")
library("gplots")

library ("gtools")

GO_Fil=read.table("1h-6h-up-down-v4.csv", sep=",", header=T)

data =data.matrix (GO_Fil[,3:4]) # define which columns to use for the
heatmap

rownames(data) <- GO_Fil$Description

summary (data)

pairs.breaks <- c(seq(-6, -0.01, length.out=50), seq(-0.02,
0.01,length.out=150), seq(0.02, 3.9,length.out=80))

hmcols<- colorRampPalette(c("blue","white", "red"))(length(pairs.breaks)-1)

pdf("Heat_1hv6h-updown-key.pdf",
    width = 15,
    height = 20,
    pointsize = 5)

hm<- heatmap.2(data, breaks=pairs.breaks, col=hmcols, na.color="white",
               trace="none",Colv=FALSE,
               dendrogram = "none",
               density.info="none",
               key="TRUE",
               keysize = 2,
               key.xlab = "Log2FC",
               key.title = "key",
               cexCol=3.0,
               cexRow=2,
               lwid= c(0.4,1),
               lhei = c(0.1, 4),
               margins= c(50,80),
               symm=F,symkey=F,symbreaks=T, scale="none")

dev.off()

> R.version
               _
platform       x86_64-apple-darwin13.4.0
arch           x86_64
os             darwin13.4.0
system         x86_64, darwin13.4.0
status
major          3
minor          2.2
year           2015
month          08
day            14
svn rev        69053
language       R
version.string R version 3.2.2 (2015-08-14)

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Mon Apr 18 15:41:48 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Mon, 18 Apr 2016 08:41:48 -0500
Subject: [R] A Neural Network question
In-Reply-To: <d9a579040a27dde76939517d98cf7dd7@localhost>
References: <d69884edcff9597d877b201aaf90ee96@localhost>
	<CAJnm8B0eHU=VN8wEdE92fwRXYATuEiB78vaPJY1FnNcRGy9dNQ@mail.gmail.com>
	<251fe71f7ac9e44cc051565fd82b9cfa@localhost>
	<CAJnm8B0fjtkGMS+f2w3hxHxDUreae9XWAov0-Dg5t=rmS9AOSg@mail.gmail.com>
	<2f65f6fe1308e3b2f223d063ca303ce6@localhost>
	<CAJnm8B3sXHYB1DgPQMMvO5-vHOv31AV8LicP7Js_dnCud6-7Xw@mail.gmail.com>
	<655d2b8bdca82bd7554430002212fa58@localhost>
	<99bd9108da366ab3958eaff486c79c90@localhost>
	<CAJnm8B2dYCBJH9U1e2MKSrK72jWTQaMeOAGZ8mOmy7yq+11ruA@mail.gmail.com>
	<15bafad2d2235db75194066f6ea2b63b@localhost>
	<CAJnm8B1R3oTXYq74rG+n2TVkQdg6eX=R9FQ2EhCLzrNEbJgadA@mail.gmail.com>
	<82e95f04d56b55fce3384978fa2f38ae@localhost>
	<d9a579040a27dde76939517d98cf7dd7@localhost>
Message-ID: <CAKxd1KMZsaTMmX4yEkrAiuHLEQ5U48h+W1qjOTjp9kKh=H1bmw@mail.gmail.com>

Hi Phil,

I don't think this is the correct list for this.  You question has nothing
to do with R specifically which is the purpose here.  I suggest you pursue
other help lists related to neural networks to try and find someone to
assist you.

Regards,
Charles

On Sat, Apr 16, 2016 at 2:08 AM, Philip Rhoades <phil at pricom.com.au> wrote:

> People,
>
> I thought I needed to have some familiarity with NNs for some of my
> current (non-profit, brain-related) projects so I started looking at
> various programming environments including R and I got this working:
>
>   http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example
>
> however I needed pictures to help understand what was going on and then I
> found this:
>
>
> https://jamesmccaffrey.files.wordpress.com/2012/11/backpropagationcalculations.jpg
>
> which I thought was almost intelligible so I had an idea which I thought
> would help the learning process:
>
> - Create a very simple NN implemented as a spreadsheet where each sheet
> would correspond to an iteration
>
> I started doing this on LibreOffice:
>
> - I think am already starting to get a better idea of how NNs work just
> from the stuff I have done on the spreadsheet already
>
> - I have now transferred my LibreOffice SpreadSheet (SS) to a shared
> Google Docs Calc file and can share it for editing with others
>
>
> https://docs.google.com/spreadsheets/d/1eSCgGU5qeI3_PmQhwZn4RH0NznUekVP5BP7w4MpKSUc/pub?output=pdf
>
> - I think I have the SS calculations correct so far except for the stuff
> in the dashed purple box in the diagram
>
> - I am not sure how to implement the purple box . . so I thought I would
> ask for help on this mailing list
>
> If someone can help me with the last bit of the SS, from there I think I
> can then repeat the FR and BP sheets and see how the Diffs evolve . .
>
> Is anyone interested in helping to get this last bit of the spreadsheet
> working so I can move on to doing actual work with the R packages with
> better understanding?
>
> Thanks,
>
> Phil.
> --
> Philip Rhoades
>
> PO Box 896
> Cowra  NSW  2794
> Australia
> E-mail:  phil at pricom.com.au
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Tue Apr 19 12:47:23 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 19 Apr 2016 02:47:23 -0800
Subject: [R] Indicator Species analysis; trouble with multipatt
In-Reply-To: <CAK2Sg-3zkzZ7TTNiM4fvrrMf=XCUBmVYLA1STpJy_Lh9QGVm0A@mail.gmail.com>
Message-ID: <7FCEF3B72D1.00000E55jrkrideau@inbox.com>

Hi Ansely,
As Jim points out we really need some sample data to go with the code.

Have a look at ?dput which is the best way to supply sample data here or have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html for some general suggestions on asking questions here---including discussions of using dput()

John Kane
Kingston ON Canada


> -----Original Message-----
> From: daily.puja at gmail.com
> Sent: Mon, 18 Apr 2016 16:33:54 -0400
> To: r-help at r-project.org
> Subject: [R] Indicator Species analysis; trouble with multipatt
> 
> Hello,
> 
> *Error in tx  %*% comb : non-conformable arguments*
> 
> Suggestions greatly appreciated.  I am a beginner and this is my first
> time
> posting.
> 
> I would like to get the summary for indicator species analysis, using
> package indicspecies with multipatt.  I am getting errors, I believe, do
> to
> my data organization.  After reorganizing and reorganizing, nothing has
> helped.
> 
>> data<- read.csv(file="Data1.csv", header=TRUE, row.names=1, sep=",")
>> ap<-data[c(1:24, 1:81)]
>> groups<-c(rep(1:4,6))
>> indval<- multipatt(ap, groups, control = how(nperm=999))
> *Error in tx  %*% comb : non-conformable arguments*
> 
> 
> 
> --
> Ansley Silva
> 
> 
> *"The clearest way into the Universe is through a forest wilderness."
> John
> Muir*
> 
> 
> *Graduate Research Assistant*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Tue Apr 19 13:00:47 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 19 Apr 2016 03:00:47 -0800
Subject: [R] heatmap2 error key
In-Reply-To: <CAAHBMXZGVMnGovB+xE2UNrVpEq4O6Gi3veCy9NSDBXPd_T8wRw@mail.gmail.com>
Message-ID: <7FECEBBA35D.00000E79jrkrideau@inbox.com>

Data?  Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html



John Kane
Kingston ON Canada


> -----Original Message-----
> From: catagui at gmail.com
> Sent: Tue, 19 Apr 2016 09:35:14 +1000
> To: r-help at r-project.org
> Subject: [R] heatmap2 error key
> 
> Hi I am trying to understand what happen with the heatmap.2 code that it
> used to work (last used in October 2015). I am able to get a heatmap but
> my
> colour key doesn't come up and instead I get an error in all my files the
> used to work. Does anyone has any idea of what could have changed? or how
> to fix this.
> 
> Thanks.
> 
> #
> 
> Error in seq.default(min.raw, max.raw, by = min(diff(breaks)/100)) :
>   wrong sign in 'by' argument
> In addition: Warning message:
> In image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  :
>   unsorted 'breaks' will be sorted before use
> 
> ##
> 
> library("RColorBrewer")
> library("gplots")
> 
> library ("gtools")
> 
> GO_Fil=read.table("1h-6h-up-down-v4.csv", sep=",", header=T)
> 
> data =data.matrix (GO_Fil[,3:4]) # define which columns to use for the
> heatmap
> 
> rownames(data) <- GO_Fil$Description
> 
> summary (data)
> 
> pairs.breaks <- c(seq(-6, -0.01, length.out=50), seq(-0.02,
> 0.01,length.out=150), seq(0.02, 3.9,length.out=80))
> 
> hmcols<- colorRampPalette(c("blue","white",
> "red"))(length(pairs.breaks)-1)
> 
> pdf("Heat_1hv6h-updown-key.pdf",
>     width = 15,
>     height = 20,
>     pointsize = 5)
> 
> hm<- heatmap.2(data, breaks=pairs.breaks, col=hmcols, na.color="white",
>                trace="none",Colv=FALSE,
>                dendrogram = "none",
>                density.info="none",
>                key="TRUE",
>                keysize = 2,
>                key.xlab = "Log2FC",
>                key.title = "key",
>                cexCol=3.0,
>                cexRow=2,
>                lwid= c(0.4,1),
>                lhei = c(0.1, 4),
>                margins= c(50,80),
>                symm=F,symkey=F,symbreaks=T, scale="none")
> 
> dev.off()
> 
>> R.version
>                _
> platform       x86_64-apple-darwin13.4.0
> arch           x86_64
> os             darwin13.4.0
> system         x86_64, darwin13.4.0
> status
> major          3
> minor          2.2
> year           2015
> month          08
> day            14
> svn rev        69053
> language       R
> version.string R version 3.2.2 (2015-08-14)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From drjimlemon at gmail.com  Tue Apr 19 13:07:03 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 19 Apr 2016 21:07:03 +1000
Subject: [R] heatmap2 error key
In-Reply-To: <CAAHBMXZGVMnGovB+xE2UNrVpEq4O6Gi3veCy9NSDBXPd_T8wRw@mail.gmail.com>
References: <CAAHBMXZGVMnGovB+xE2UNrVpEq4O6Gi3veCy9NSDBXPd_T8wRw@mail.gmail.com>
Message-ID: <CA+8X3fVOb4S4rj-6wyqT5Sf0tfkgmP7aTTf-J=rsBXGXesc8nA@mail.gmail.com>

Hi Catalina,
The error message is pretty clear. min(diff(breaks)/100) evaluates to
a negative number. Perhaps the sort order for the values in "breaks"
has changed.

Jim


On Tue, Apr 19, 2016 at 9:35 AM, Catalina Aguilar Hurtado
<catagui at gmail.com> wrote:
> Hi I am trying to understand what happen with the heatmap.2 code that it
> used to work (last used in October 2015). I am able to get a heatmap but my
> colour key doesn't come up and instead I get an error in all my files the
> used to work. Does anyone has any idea of what could have changed? or how
> to fix this.
>
> Thanks.
>
> #
>
> Error in seq.default(min.raw, max.raw, by = min(diff(breaks)/100)) :
>   wrong sign in 'by' argument
> In addition: Warning message:
> In image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  :
>   unsorted 'breaks' will be sorted before use
>
> ##
>
> library("RColorBrewer")
> library("gplots")
>
> library ("gtools")
>
> GO_Fil=read.table("1h-6h-up-down-v4.csv", sep=",", header=T)
>
> data =data.matrix (GO_Fil[,3:4]) # define which columns to use for the
> heatmap
>
> rownames(data) <- GO_Fil$Description
>
> summary (data)
>
> pairs.breaks <- c(seq(-6, -0.01, length.out=50), seq(-0.02,
> 0.01,length.out=150), seq(0.02, 3.9,length.out=80))
>
> hmcols<- colorRampPalette(c("blue","white", "red"))(length(pairs.breaks)-1)
>
> pdf("Heat_1hv6h-updown-key.pdf",
>     width = 15,
>     height = 20,
>     pointsize = 5)
>
> hm<- heatmap.2(data, breaks=pairs.breaks, col=hmcols, na.color="white",
>                trace="none",Colv=FALSE,
>                dendrogram = "none",
>                density.info="none",
>                key="TRUE",
>                keysize = 2,
>                key.xlab = "Log2FC",
>                key.title = "key",
>                cexCol=3.0,
>                cexRow=2,
>                lwid= c(0.4,1),
>                lhei = c(0.1, 4),
>                margins= c(50,80),
>                symm=F,symkey=F,symbreaks=T, scale="none")
>
> dev.off()
>
>> R.version
>                _
> platform       x86_64-apple-darwin13.4.0
> arch           x86_64
> os             darwin13.4.0
> system         x86_64, darwin13.4.0
> status
> major          3
> minor          2.2
> year           2015
> month          08
> day            14
> svn rev        69053
> language       R
> version.string R version 3.2.2 (2015-08-14)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From daily.puja at gmail.com  Tue Apr 19 14:16:54 2016
From: daily.puja at gmail.com (Ansley Silva)
Date: Tue, 19 Apr 2016 08:16:54 -0400
Subject: [R] Indicator Species analysis; trouble with multipatt
In-Reply-To: <7FCEF3B72D1.00000E55jrkrideau@inbox.com>
References: <CAK2Sg-3zkzZ7TTNiM4fvrrMf=XCUBmVYLA1STpJy_Lh9QGVm0A@mail.gmail.com>
	<7FCEF3B72D1.00000E55jrkrideau@inbox.com>
Message-ID: <CAK2Sg-1E3=o7MjYnDVwOZQMFoq7zU3T0VMTSqZc6SX8OMX6jkw@mail.gmail.com>

Thanks for the replies.

I have fixed the problem.  I only need to reorganized my data.  Now my
question is about asking questions correctly.  I hope I've got it.  Please
find the script attached here.

R Version 3.2.2

I am looking for indicator species with Indicspecies package.  After
running the function multipatt, I get the following error:

Error in is.factor(x) : object 'groups1' not found

**Is this reproducibility satisfactory?  I fixed the problem by
reorganizing my csv file.  I was trying to be efficient when making my
groups and that was causing the trouble.

Thanks.


On Tue, Apr 19, 2016 at 6:47 AM, John Kane <jrkrideau at inbox.com> wrote:

> Hi Ansely,
> As Jim points out we really need some sample data to go with the code.
>
> Have a look at ?dput which is the best way to supply sample data here or
> have a look at
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> and/or http://adv-r.had.co.nz/Reproducibility.html for some general
> suggestions on asking questions here---including discussions of using dput()
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: daily.puja at gmail.com
> > Sent: Mon, 18 Apr 2016 16:33:54 -0400
> > To: r-help at r-project.org
> > Subject: [R] Indicator Species analysis; trouble with multipatt
> >
> > Hello,
> >
> > *Error in tx  %*% comb : non-conformable arguments*
> >
> > Suggestions greatly appreciated.  I am a beginner and this is my first
> > time
> > posting.
> >
> > I would like to get the summary for indicator species analysis, using
> > package indicspecies with multipatt.  I am getting errors, I believe, do
> > to
> > my data organization.  After reorganizing and reorganizing, nothing has
> > helped.
> >
> >> data<- read.csv(file="Data1.csv", header=TRUE, row.names=1, sep=",")
> >> ap<-data[c(1:24, 1:81)]
> >> groups<-c(rep(1:4,6))
> >> indval<- multipatt(ap, groups, control = how(nperm=999))
> > *Error in tx  %*% comb : non-conformable arguments*
> >
> >
> >
> > --
> > Ansley Silva
> >
> >
> > *"The clearest way into the Universe is through a forest wilderness."
> > John
> > Muir*
> >
> >
> > *Graduate Research Assistant*
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth
>
>
>


-- 
Ansley Silva


*"The clearest way into the Universe is through a forest wilderness." John
Muir*


*Graduate Research Assistant*

*University of Georgia*

*D.B. Warnell School of Forestry and Natural Resources*

*180 East Green Street*

*Athens, GA 30602*
-------------- next part --------------
install.packages("indicspecies")
library(indicspecies)

mydata<-
structure(list(necsur = structure(c(6L, 1L, 1L, 4L, 4L, 2L), .Label = c("0", 
"1", "11", "2", "24", "3", "4", "42", "5", "8", "9", "PA"), class = "factor"), 
    necame = structure(c(11L, 2L, 5L, 5L, 17L, 9L), .Label = c("0", 
    "1", "10", "11", "12", "13", "15", "2", "20", "22", "3", 
    "4", "5", "6", "7", "8", "9", "PA"), class = "factor"), niccar = structure(c(1L, 
    1L, 1L, 2L, 1L, 1L), .Label = c("0", "1", "19", "2", "3", 
    "4", "5", "6", "PA"), class = "factor"), nicorb = structure(c(1L, 
    18L, 19L, 17L, 1L, 27L), .Label = c("0", "1", "10", "11", 
    "12", "13", "15", "16", "18", "19", "2", "20", "21", "23", 
    "25", "29", "3", "30", "31", "32", "33", "36", "4", "40", 
    "42", "44", "48", "5", "50", "6", "61", "7", "8", "9", "PA"
    ), class = "factor"), nicpus = structure(c(1L, 1L, 1L, 1L, 
    1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    nictor = structure(c(1L, 1L, 2L, 1L, 1L, 1L), .Label = c("0", 
    "1", "10", "11", "16", "18", "2", "22", "3", "4", "5", "6", 
    "7", "8", "9", "PA"), class = "factor"), oicina = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "15", "2", "3", 
    "PA"), class = "factor"), delgib = structure(c(37L, 5L, 7L, 
    11L, 11L, 43L), .Label = c("0", "1", "10", "104", "11", "12", 
    "126", "13", "14", "15", "16", "18", "19", "2", "20", "21", 
    "22", "23", "24", "25", "26", "27", "28", "29", "3", "30", 
    "31", "32", "33", "34", "35", "37", "39", "4", "40", "43", 
    "5", "50", "6", "61", "63", "65", "68", "7", "72", "8", "81", 
    "82", "97", "PA"), class = "factor"), cancha = structure(c(1L, 
    1L, 2L, 7L, 7L, 10L), .Label = c("0", "1", "11", "12", "16", 
    "17", "2", "27", "3", "4", "5", "6", "7", "8", "9", "PA"), class = "factor"), 
    melbis = structure(c(2L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "11", "17", "18", "2", "3", "4", "5", "6", "8", "9", 
    "PA"), class = "factor"), atelec = structure(c(1L, 1L, 1L, 
    22L, 7L, 2L), .Label = c("0", "1", "10", "11", "12", "13", 
    "14", "15", "17", "174", "18", "19", "2", "20", "21", "23", 
    "24", "27", "3", "30", "31", "32", "34", "37", "39", "41", 
    "42", "5", "51", "6", "61", "66", "7", "72", "76", "77", 
    "79", "8", "81", "83", "9", "97", "PA"), class = "factor"), 
    copmin = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "10", "11", "12", "2", "3", "33", "4", "5", "6", "7", 
    "8", "PA"), class = "factor"), ontcon = structure(c(1L, 2L, 
    8L, 1L, 1L, 12L), .Label = c("0", "1", "10", "11", "13", 
    "14", "2", "3", "33", "4", "5", "6", "7", "8", "PA"), class = "factor"), 
    ontdep = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "10", "2", "PA"), class = "factor"), onthec = structure(c(2L, 
    18L, 29L, 7L, 1L, 19L), .Label = c("0", "1", "10", "11", 
    "12", "13", "14", "141", "143", "16", "17", "18", "19", "2", 
    "20", "21", "24", "28", "29", "3", "30", "4", "48", "5", 
    "50", "54", "55", "6", "7", "70", "8", "9", "PA"), class = "factor"), 
    ontstr = structure(c(1L, 2L, 1L, 3L, 1L, 1L), .Label = c("0", 
    "1", "2", "3", "4", "5", "6", "7", "8", "PA"), class = "factor"), 
    onttau = structure(c(1L, 1L, 12L, 8L, 1L, 12L), .Label = c("0", 
    "1", "10", "104", "2", "24", "3", "4", "5", "6", "66", "8", 
    "PA"), class = "factor"), ontpen = structure(c(1L, 1L, 8L, 
    13L, 1L, 11L), .Label = c("0", "1", "11", "12", "13", "14", 
    "15", "2", "3", "34", "4", "5", "6", "7", "8", "9", "PA"), class = "factor"), 
    onttub = structure(c(1L, 1L, 7L, 5L, 1L, 10L), .Label = c("0", 
    "1", "11", "12", "2", "20", "3", "4", "5", "6", "7", "PA"
    ), class = "factor"), ontsub = structure(c(1L, 1L, 1L, 1L, 
    1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    ontorp = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), phatri = structure(c(1L, 1L, 
    1L, 1L, 1L, 2L), .Label = c("0", "1", "3", "PA"), class = "factor"), 
    phaign = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "2", "PA"), class = "factor"), phavin = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "2", "3", "5", "PA"), class = "factor"), 
    phival = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), diccar = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    diggaz = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), Phyili = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "3", "PA"), class = "factor"), 
    phyfor = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), physps = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    dippun = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), diplib = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    euehum = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), canvir = structure(c(1L, 3L, 
    3L, 1L, 1L, 2L), .Label = c("0", "1", "2", "3", "PA"), class = "factor"), 
    phycle = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "2", "PA"), class = "factor"), pseper = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    aphrus = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), hybill = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    geobla = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), geoege = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    boltho = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), braalt = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "3", "8", "PA"
    ), class = "factor"), chlery = structure(c(1L, 1L, 1L, 1L, 
    1L, 1L), .Label = c("0", "1", "3", "PA"), class = "factor"), 
    chlema = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "2", "PA"), class = "factor"), cyclae = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    cyclev = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "2", "5", "6", "PA"), class = "factor"), dicdil = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "3", "PA"), class = "factor"), 
    dicfur = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "2", "3", "PA"), class = "factor"), dicpur = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    galjan = structure(c(1L, 1L, 1L, 1L, 1L, 2L), .Label = c("0", 
    "1", "2", "3", "4", "5", "PA"), class = "factor"), carvin = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    carsyl = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), cargor = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    cyclosig = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "3", "5", "PA"), class = "factor"), helnig = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    helcla = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), scaqua = structure(c(1L, 1L, 
    1L, 1L, 1L, 2L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    scasub = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "2", "PA"), class = "factor"), oodama = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    stemex = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "3", "PA"), class = "factor"), agoalb = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    moctet = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), pasmar = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    passub = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), apesin = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    anirus = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), calopa = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    harsps = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), copgly = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    omomon = structure(c(1L, 1L, 11L, 8L, 1L, 8L), .Label = c("0", 
    "1", "11", "12", "13", "15", "19", "2", "3", "32", "4", "5", 
    "6", "7", "8", "9", "PA"), class = "factor"), omosub = structure(c(1L, 
    2L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    trofov = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "14", "15", "16", "2", "22", "3", "31", "4", "5", "6", 
    "7", "PA"), class = "factor"), trouni = structure(c(3L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "4", "6", "8", 
    "PA"), class = "factor"), trotub = structure(c(1L, 1L, 1L, 
    1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    troaeq = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), troter = structure(c(1L, 2L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "3", "6", "8", 
    "PA"), class = "factor"), eusass = structure(c(3L, 19L, 63L, 
    15L, 14L, 63L), .Label = c("0", "1", "10", "107", "11", "12", 
    "126", "13", "130", "133", "14", "143", "15", "16", "17", 
    "18", "186", "19", "2", "20", "21", "22", "24", "25", "26", 
    "27", "28", "29", "3", "30", "31", "32", "33", "34", "37", 
    "38", "39", "4", "42", "43", "44", "45", "48", "49", "5", 
    "51", "53", "54", "56", "57", "6", "64", "65", "7", "70", 
    "71", "78", "79", "8", "82", "88", "89", "9", "93", "98", 
    "99", "PA"), class = "factor"), hiscoe = structure(c(1L, 
    2L, 15L, 1L, 1L, 2L), .Label = c("0", "1", "10", "11", "13", 
    "14", "17", "19", "2", "23", "27", "3", "30", "4", "43", 
    "5", "6", "7", "8", "9", "PA"), class = "factor"), hisabb = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "3", "4", "9", 
    "PA"), class = "factor"), hisfun = structure(c(1L, 1L, 1L, 
    1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    sappen = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), saplug = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    ontnod = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), dercan = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    cremax = structure(c(23L, 1L, 1L, 1L, 1L, 18L), .Label = c("0", 
    "1", "10", "11", "12", "13", "17", "18", "2", "23", "24", 
    "25", "28", "3", "30", "31", "33", "4", "5", "54", "6", "7", 
    "8", "PA"), class = "factor"), plamac = structure(c(1L, 2L, 
    7L, 2L, 1L, 1L), .Label = c("0", "1", "13", "2", "3", "4", 
    "5", "6", "8", "PA"), class = "factor"), ontcin = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    plafem = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "6", "PA"), class = "factor"), plafos = structure(c(1L, 
    1L, 1L, 2L, 1L, 2L), .Label = c("0", "1", "11", "2", "3", 
    "4", "9", "PA"), class = "factor"), placom = structure(c(1L, 
    3L, 1L, 12L, 9L, 10L), .Label = c("0", "1", "10", "14", "2", 
    "23", "3", "30", "33", "4", "40", "45", "5", "54", "6", "7", 
    "8", "PA"), class = "factor"), placin = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    plapra = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "2", "PA"), class = "factor"), phiumb = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "2", "PA"), class = "factor"), 
    tacfim = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "2", "4", "6", "7", "8", "PA"), class = "factor"), alesps = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "PA"), class = "factor"), 
    tetcar = structure(c(1L, 1L, 1L, 1L, 1L, 2L), .Label = c("0", 
    "1", "3", "4", "PA"), class = "factor"), tetvir = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L), .Label = c("0", "1", "2", "5", "PA"), class = "factor"), 
    cicsex = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), spsA = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "2", "PA"), class = "factor"), 
    spsB = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), spsC = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    spsD = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), spsE = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    spsF = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), spsG = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    spsH = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), spsI = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    spsJ = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), spsK = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    spsL = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), spsM = structure(c(1L, 1L, 
    1L, 1L, 1L, 1L), .Label = c("0", "1", "PA"), class = "factor"), 
    spsN = structure(c(1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", 
    "1", "PA"), class = "factor"), X = c(NA, NA, NA, NA, NA, 
    NA)), .Names = c("necsur", "necame", "niccar", "nicorb", 
"nicpus", "nictor", "oicina", "delgib", "cancha", "melbis", "atelec", 
"copmin", "ontcon", "ontdep", "onthec", "ontstr", "onttau", "ontpen", 
"onttub", "ontsub", "ontorp", "phatri", "phaign", "phavin", "phival", 
"diccar", "diggaz", "Phyili", "phyfor", "physps", "dippun", "diplib", 
"euehum", "canvir", "phycle", "pseper", "aphrus", "hybill", "geobla", 
"geoege", "boltho", "braalt", "chlery", "chlema", "cyclae", "cyclev", 
"dicdil", "dicfur", "dicpur", "galjan", "carvin", "carsyl", "cargor", 
"cyclosig", "helnig", "helcla", "scaqua", "scasub", "oodama", 
"stemex", "agoalb", "moctet", "pasmar", "passub", "apesin", "anirus", 
"calopa", "harsps", "copgly", "omomon", "omosub", "trofov", "trouni", 
"trotub", "troaeq", "troter", "eusass", "hiscoe", "hisabb", "hisfun", 
"sappen", "saplug", "ontnod", "dercan", "cremax", "plamac", "ontcin", 
"plafem", "plafos", "placom", "placin", "plapra", "phiumb", "tacfim", 
"alesps", "tetcar", "tetvir", "cicsex", "spsA", "spsB", "spsC", 
"spsD", "spsE", "spsF", "spsG", "spsH", "spsI", "spsJ", "spsK", 
"spsL", "spsM", "spsN", "X"), row.names = c("AP1-1", "AP1-2", 
"AP1-3", "AP1-4", "AP2-1", "AP2-2"), class = "data.frame")

ap<-mydata[1:24, ]
groups<-c(rep(1:4,6))
indval1<- multipatt(ap, groups1, control = how(nperm=999))



From jrkrideau at inbox.com  Tue Apr 19 14:41:31 2016
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 19 Apr 2016 04:41:31 -0800
Subject: [R] Indicator Species analysis; trouble with multipatt
In-Reply-To: <CAK2Sg-1E3=o7MjYnDVwOZQMFoq7zU3T0VMTSqZc6SX8OMX6jkw@mail.gmail.com>
References: <cak2sg-3zkzz7ttnim4fvrrmf=xcubmvyla1stpjy_lh9qgvm0a@mail.gmail.com>
	<7fcef3b72d1.00000e55jrkrideau@inbox.com>
Message-ID: <80CE0F4D17C.00000F8Ajrkrideau@inbox.com>

Hi Ansley
It looks good to me but I did not run the analysis as I am too lazy to install "indicspecies".  The inclusion of the raw data is a great help.

John Kane
Kingston ON Canada

-----Original Message-----
From: daily.puja at gmail.com
Sent: Tue, 19 Apr 2016 08:16:54 -0400
To: jrkrideau at inbox.com
Subject: Re: [R] Indicator Species analysis; trouble with multipatt

Thanks for the replies.

I have fixed the problem.? I only need to reorganized my data.? Now my question is about asking questions correctly.? I hope I've got it.? Please find the script attached here.

R Version 3.2.2

I am looking for indicator species with Indicspecies package.? After running the function multipatt, I get the following error:

Error in is.factor(x) : object 'groups1' not found

**Is this?reproducibility satisfactory?? I fixed the problem by reorganizing my csv file.? I was trying to be?efficient?when making my groups?and that was causing the trouble.

Thanks.

On Tue, Apr 19, 2016 at 6:47 AM, John Kane <jrkrideau at inbox.com> wrote:

	Hi Ansely,
 As Jim points out we really need some sample data to go with the code.

 Have a look at ?dput which is the best way to supply sample data here or have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example [http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example] and/or http://adv-r.had.co.nz/Reproducibility.html [http://adv-r.had.co.nz/Reproducibility.html] for some general suggestions on asking questions here---including discussions of using dput()

 John Kane
 Kingston ON Canada

 > -----Original Message-----
 > From: daily.puja at gmail.com
 > Sent: Mon, 18 Apr 2016 16:33:54 -0400
 > To: r-help at r-project.org
 > Subject: [R] Indicator Species analysis; trouble with multipatt
 >
 > Hello,
 >
 > *Error in tx? %*% comb : non-conformable arguments*
 >
 > Suggestions greatly appreciated.? I am a beginner and this is my first
 > time
 > posting.
 >
 > I would like to get the summary for indicator species analysis, using
 > package indicspecies with multipatt.? I am getting errors, I believe, do
 > to
 > my data organization.? After reorganizing and reorganizing, nothing has
 > helped.
 >
 >> data<- read.csv(file="Data1.csv", header=TRUE, row.names=1, sep=",")
 >> ap<-data[c(1:24, 1:81)]
 >> groups<-c(rep(1:4,6))
 >> indval<- multipatt(ap, groups, control = how(nperm=999))
 > *Error in tx? %*% comb : non-conformable arguments*
 >
 >
 >
 > --
 > Ansley Silva
 >
 >
 > *"The clearest way into the Universe is through a forest wilderness."
 > John
 > Muir*
 >
 >
 > *Graduate Research Assistant*
 > ______________________________________________
 > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help [https://stat.ethz.ch/mailman/listinfo/r-help]
 > PLEASE do read the posting guide
 > http://www.R-project.org/posting-guide.html [http://www.R-project.org/posting-guide.html]
 > and provide commented, minimal, self-contained, reproducible code.

 ____________________________________________________________
 FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
 Check it out at http://www.inbox.com/earth [http://www.inbox.com/earth]

-- 

Ansley Silva

	_
_

	_"The clearest way into the Universe is through a forest wilderness." John Muir_

	_
_

	_Graduate Research Assistant_
__

	_University of Georgia_
__

	_D.B. Warnell School of Forestry and Natural Resources_
__

	_180 East Green Street_
__

	_Athens, GA 30602_

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From michaeleartz at gmail.com  Tue Apr 19 16:56:39 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 19 Apr 2016 09:56:39 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
Message-ID: <CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>

That didn't work Jim!

Thanks anyway

On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Michael,
> At a guess, try this:
>
> iqr<-function(x) {
>  return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> }
>
> .col3_Range=iqr(datat$tenure)
>
> Jim
>
>
>
> On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> > Hi,
> >   I am trying to show an interquartile range while grouping values using
> > the function ddply().  So my function call now is like
> >
> > groupedAll <- ddply(data
> >                  ,~groupColumn
> >                  ,summarise
> >                  ,col1_mean=mean(col1)
> >                  ,col2_mode=Mode(col2) #Function I wrote for getting the
> > mode shown below
> >
> >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
> > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
> >                  )
> >
> > #custom Mode function
> > Mode <- function(x) {
> >   ux <- unique(x)
> >   ux[which.max(tabulate(match(x, ux)))]
> > }
> >
> > I am not sre what is going wrong on my interquartile range function, it
> > works on its own outside of ddply()
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Apr 19 17:20:41 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Apr 2016 08:20:41 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
Message-ID: <CAGxFJbTke3YQ0Em5DyE8ggGFxBxU8QA8T=NEdjsPuOXqMZmpFw@mail.gmail.com>

Are you aware that there *already is* a function that does this?

?IQR

(also your "function" iqr" is just a character string and would have
to be parsed and evaluated to become a function. But this is a
TERRIBLE way to do things in R as it completely circumvents R's
central functional programming paradigm).

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com> wrote:
> That didn't work Jim!
>
> Thanks anyway
>
> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Michael,
>> At a guess, try this:
>>
>> iqr<-function(x) {
>>  return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> }
>>
>> .col3_Range=iqr(datat$tenure)
>>
>> Jim
>>
>>
>>
>> On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>> > Hi,
>> >   I am trying to show an interquartile range while grouping values using
>> > the function ddply().  So my function call now is like
>> >
>> > groupedAll <- ddply(data
>> >                  ,~groupColumn
>> >                  ,summarise
>> >                  ,col1_mean=mean(col1)
>> >                  ,col2_mode=Mode(col2) #Function I wrote for getting the
>> > mode shown below
>> >
>> >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>> > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>> >                  )
>> >
>> > #custom Mode function
>> > Mode <- function(x) {
>> >   ux <- unique(x)
>> >   ux[which.max(tabulate(match(x, ux)))]
>> > }
>> >
>> > I am not sre what is going wrong on my interquartile range function, it
>> > works on its own outside of ddply()
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Tue Apr 19 17:23:37 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 19 Apr 2016 17:23:37 +0200
Subject: [R] Problem with X11
Message-ID: <20160419152337.GA3547@localhost.localdomain>

Dear All,
I have never had this problem before. I run debian testing on my box
and I have recently update my R environment.
Now, see what happens when I try the most trivial of all plots

> plot(seq(22))
Error in (function (display = "", width, height, pointsize, gamma, bg,
:
  X11 module cannot be loaded
  In addition: Warning message:
  In (function (display = "", width, height, pointsize, gamma, bg,  :
    unable to load shared object '/usr/lib/R/modules//R_X11.so':
      /usr/lib/x86_64-linux-gnu/libpng12.so.0: version `PNG12_0' not
      found (required by /usr/lib/R/modules//R_X11.so)

and this is my sessionInfo()

> sessionInfo()
R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux stretch/sid

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
     [9] LC_ADDRESS=C              LC_TELEPHONE=C
     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Anybody understands what is going on here?
Regards

Lorenzo


From michaeleartz at gmail.com  Tue Apr 19 17:29:01 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 19 Apr 2016 10:29:01 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CAGxFJbTke3YQ0Em5DyE8ggGFxBxU8QA8T=NEdjsPuOXqMZmpFw@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAGxFJbTke3YQ0Em5DyE8ggGFxBxU8QA8T=NEdjsPuOXqMZmpFw@mail.gmail.com>
Message-ID: <CA+pG8eMm+PBOdcPkSiP8Uz7xrDhMSQwFNa2zNECENfnuFZWQnA@mail.gmail.com>

Hi bert,

I understand the difference between a character string and a number. I need
to return a character string, that is a requirement.  It needs to be in
that format.  Getting the range with IQR is trivial I already tried it. The
grouping function accepts only one return value,  and IQR returns two.
Thanks for the reply though sir.
On Apr 19, 2016 10:20 AM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

> Are you aware that there *already is* a function that does this?
>
> ?IQR
>
> (also your "function" iqr" is just a character string and would have
> to be parsed and evaluated to become a function. But this is a
> TERRIBLE way to do things in R as it completely circumvents R's
> central functional programming paradigm).
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> > That didn't work Jim!
> >
> > Thanks anyway
> >
> > On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Michael,
> >> At a guess, try this:
> >>
> >> iqr<-function(x) {
> >>
> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >> }
> >>
> >> .col3_Range=iqr(datat$tenure)
> >>
> >> Jim
> >>
> >>
> >>
> >> On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
> >> wrote:
> >> > Hi,
> >> >   I am trying to show an interquartile range while grouping values
> using
> >> > the function ddply().  So my function call now is like
> >> >
> >> > groupedAll <- ddply(data
> >> >                  ,~groupColumn
> >> >                  ,summarise
> >> >                  ,col1_mean=mean(col1)
> >> >                  ,col2_mode=Mode(col2) #Function I wrote for getting
> the
> >> > mode shown below
> >> >
> >> >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
> >> > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
> >> >                  )
> >> >
> >> > #custom Mode function
> >> > Mode <- function(x) {
> >> >   ux <- unique(x)
> >> >   ux[which.max(tabulate(match(x, ux)))]
> >> > }
> >> >
> >> > I am not sre what is going wrong on my interquartile range function,
> it
> >> > works on its own outside of ddply()
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Apr 19 17:34:40 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 19 Apr 2016 08:34:40 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
Message-ID: <CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>

> That didn't work Jim!

It always helps to say how the suggestion did not work.  Jim's
function had a typo in it - was that the problem?  Or did you not
change the call to ddply to use that function.  Here is something
that might "work" for you:

 library(plyr)

 data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
 myIqr <- function(x) {
     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
 }
 ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
col1_IQR=stats::IQR(col1))
 #  groupColumn col1_myIqr col1_IQR
 #1           1        1-1        0
 #2           2        2-4        1
 #3           3      12-24       12
 #4           4    112-320      208
 #5           5  2048-8192     6144

The important point is that
    paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
is not a function, it is an expression.   ddplyr wants functions.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
wrote:

> That didn't work Jim!
>
> Thanks anyway
>
> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Michael,
> > At a guess, try this:
> >
> > iqr<-function(x) {
> >
> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> > }
> >
> > .col3_Range=iqr(datat$tenure)
> >
> > Jim
> >
> >
> >
> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
> > wrote:
> > > Hi,
> > >   I am trying to show an interquartile range while grouping values
> using
> > > the function ddply().  So my function call now is like
> > >
> > > groupedAll <- ddply(data
> > >                  ,~groupColumn
> > >                  ,summarise
> > >                  ,col1_mean=mean(col1)
> > >                  ,col2_mode=Mode(col2) #Function I wrote for getting
> the
> > > mode shown below
> > >
> > >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
> > >                  )
> > >
> > > #custom Mode function
> > > Mode <- function(x) {
> > >   ux <- unique(x)
> > >   ux[which.max(tabulate(match(x, ux)))]
> > > }
> > >
> > > I am not sre what is going wrong on my interquartile range function, it
> > > works on its own outside of ddply()
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rainer.schuermann at gmx.net  Tue Apr 19 17:50:19 2016
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Tue, 19 Apr 2016 17:50:19 +0200
Subject: [R] Problem with X11
In-Reply-To: <20160419152337.GA3547@localhost.localdomain>
References: <20160419152337.GA3547@localhost.localdomain>
Message-ID: <4200522.QO68Cu3Dbe@rainer-tuxedo>

Probably wrong list, but anyway:
Same problem here, after a 
   apt-get dist-upgrade


On Tuesday, April 19, 2016 05:23:37 PM Lorenzo Isella wrote:
> Dear All,
> I have never had this problem before. I run debian testing on my box
> and I have recently update my R environment.
> Now, see what happens when I try the most trivial of all plots
> 
> > plot(seq(22))
> Error in (function (display = "", width, height, pointsize, gamma, bg,
> :
>   X11 module cannot be loaded
>   In addition: Warning message:
>   In (function (display = "", width, height, pointsize, gamma, bg,  :
>     unable to load shared object '/usr/lib/R/modules//R_X11.so':
>       /usr/lib/x86_64-linux-gnu/libpng12.so.0: version `PNG12_0' not
>       found (required by /usr/lib/R/modules//R_X11.so)
> 
> and this is my sessionInfo()
> 
> > sessionInfo()
> R version 3.2.4 Revised (2016-03-16 r70336)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux stretch/sid
> 
> locale:
>  [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>   [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>    [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
>     [7] LC_PAPER=en_GB.utf8       LC_NAME=C
>      [9] LC_ADDRESS=C              LC_TELEPHONE=C
>      [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> Anybody understands what is going on here?
> Regards
> 
> Lorenzo
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michaeleartz at gmail.com  Tue Apr 19 17:57:13 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 19 Apr 2016 10:57:13 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
Message-ID: <CA+pG8ePG8Uch_gq4eq871Qbm0s4jO8kNS=v1CD9CsCnCOdGZPA@mail.gmail.com>

HI that did not work for me either.  The value I got returned from that
function was "<rounded mean> - <rounded mean>"  :(. thanks for the reply
through

On Tue, Apr 19, 2016 at 10:34 AM, William Dunlap <wdunlap at tibco.com> wrote:

> > That didn't work Jim!
>
> It always helps to say how the suggestion did not work.  Jim's
> function had a typo in it - was that the problem?  Or did you not
> change the call to ddply to use that function.  Here is something
> that might "work" for you:
>
>  library(plyr)
>
>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>  myIqr <- function(x) {
>      paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>  }
>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
> col1_IQR=stats::IQR(col1))
>  #  groupColumn col1_myIqr col1_IQR
>  #1           1        1-1        0
>  #2           2        2-4        1
>  #3           3      12-24       12
>  #4           4    112-320      208
>  #5           5  2048-8192     6144
>
> The important point is that
>     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> is not a function, it is an expression.   ddplyr wants functions.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
> wrote:
>
>> That didn't work Jim!
>>
>> Thanks anyway
>>
>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> > Hi Michael,
>> > At a guess, try this:
>> >
>> > iqr<-function(x) {
>> >
>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> > }
>> >
>> > .col3_Range=iqr(datat$tenure)
>> >
>> > Jim
>> >
>> >
>> >
>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
>> > wrote:
>> > > Hi,
>> > >   I am trying to show an interquartile range while grouping values
>> using
>> > > the function ddply().  So my function call now is like
>> > >
>> > > groupedAll <- ddply(data
>> > >                  ,~groupColumn
>> > >                  ,summarise
>> > >                  ,col1_mean=mean(col1)
>> > >                  ,col2_mode=Mode(col2) #Function I wrote for getting
>> the
>> > > mode shown below
>> > >
>> > >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>> > >                  )
>> > >
>> > > #custom Mode function
>> > > Mode <- function(x) {
>> > >   ux <- unique(x)
>> > >   ux[which.max(tabulate(match(x, ux)))]
>> > > }
>> > >
>> > > I am not sre what is going wrong on my interquartile range function,
>> it
>> > > works on its own outside of ddply()
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Apr 19 18:01:19 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 19 Apr 2016 09:01:19 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CA+pG8ePG8Uch_gq4eq871Qbm0s4jO8kNS=v1CD9CsCnCOdGZPA@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CA+pG8ePG8Uch_gq4eq871Qbm0s4jO8kNS=v1CD9CsCnCOdGZPA@mail.gmail.com>
Message-ID: <CAF8bMcYygqGazes3xomV1TJP48QK0mwOoHaHLfjcj=ntt9sF9A@mail.gmail.com>

Can you show us a self-contained example, along with the output of
running conflicts()?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 19, 2016 at 8:57 AM, Michael Artz <michaeleartz at gmail.com>
wrote:

> HI that did not work for me either.  The value I got returned from that
> function was "<rounded mean> - <rounded mean>"  :(. thanks for the reply
> through
>
> On Tue, Apr 19, 2016 at 10:34 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>> > That didn't work Jim!
>>
>> It always helps to say how the suggestion did not work.  Jim's
>> function had a typo in it - was that the problem?  Or did you not
>> change the call to ddply to use that function.  Here is something
>> that might "work" for you:
>>
>>  library(plyr)
>>
>>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>>  myIqr <- function(x) {
>>      paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>  }
>>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>> col1_IQR=stats::IQR(col1))
>>  #  groupColumn col1_myIqr col1_IQR
>>  #1           1        1-1        0
>>  #2           2        2-4        1
>>  #3           3      12-24       12
>>  #4           4    112-320      208
>>  #5           5  2048-8192     6144
>>
>> The important point is that
>>     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> is not a function, it is an expression.   ddplyr wants functions.
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>
>>> That didn't work Jim!
>>>
>>> Thanks anyway
>>>
>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> > Hi Michael,
>>> > At a guess, try this:
>>> >
>>> > iqr<-function(x) {
>>> >
>>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>> > }
>>> >
>>> > .col3_Range=iqr(datat$tenure)
>>> >
>>> > Jim
>>> >
>>> >
>>> >
>>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com
>>> >
>>> > wrote:
>>> > > Hi,
>>> > >   I am trying to show an interquartile range while grouping values
>>> using
>>> > > the function ddply().  So my function call now is like
>>> > >
>>> > > groupedAll <- ddply(data
>>> > >                  ,~groupColumn
>>> > >                  ,summarise
>>> > >                  ,col1_mean=mean(col1)
>>> > >                  ,col2_mode=Mode(col2) #Function I wrote for getting
>>> the
>>> > > mode shown below
>>> > >
>>> > >
>>> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>>> > >                  )
>>> > >
>>> > > #custom Mode function
>>> > > Mode <- function(x) {
>>> > >   ux <- unique(x)
>>> > >   ux[which.max(tabulate(match(x, ux)))]
>>> > > }
>>> > >
>>> > > I am not sre what is going wrong on my interquartile range function,
>>> it
>>> > > works on its own outside of ddply()
>>> > >
>>> > >         [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Apr 19 19:25:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Apr 2016 10:25:27 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
Message-ID: <CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>

To be precise:

paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")

is an expression that evaluates to a character string:
"round(quantile(x,.25),0) - round(quantile(x,0.75),0)"

no matter what the argument of your function, x. Hence

return(paste(...)) will return this exact character string and never
evaluates x.


Cheers,
Bert








Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
<r-help at r-project.org> wrote:
>> That didn't work Jim!
>
> It always helps to say how the suggestion did not work.  Jim's
> function had a typo in it - was that the problem?  Or did you not
> change the call to ddply to use that function.  Here is something
> that might "work" for you:
>
>  library(plyr)
>
>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>  myIqr <- function(x) {
>      paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>  }
>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
> col1_IQR=stats::IQR(col1))
>  #  groupColumn col1_myIqr col1_IQR
>  #1           1        1-1        0
>  #2           2        2-4        1
>  #3           3      12-24       12
>  #4           4    112-320      208
>  #5           5  2048-8192     6144
>
> The important point is that
>     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> is not a function, it is an expression.   ddplyr wants functions.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
> wrote:
>
>> That didn't work Jim!
>>
>> Thanks anyway
>>
>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> > Hi Michael,
>> > At a guess, try this:
>> >
>> > iqr<-function(x) {
>> >
>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> > }
>> >
>> > .col3_Range=iqr(datat$tenure)
>> >
>> > Jim
>> >
>> >
>> >
>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
>> > wrote:
>> > > Hi,
>> > >   I am trying to show an interquartile range while grouping values
>> using
>> > > the function ddply().  So my function call now is like
>> > >
>> > > groupedAll <- ddply(data
>> > >                  ,~groupColumn
>> > >                  ,summarise
>> > >                  ,col1_mean=mean(col1)
>> > >                  ,col2_mode=Mode(col2) #Function I wrote for getting
>> the
>> > > mode shown below
>> > >
>> > >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>> > >                  )
>> > >
>> > > #custom Mode function
>> > > Mode <- function(x) {
>> > >   ux <- unique(x)
>> > >   ux[which.max(tabulate(match(x, ux)))]
>> > > }
>> > >
>> > > I am not sre what is going wrong on my interquartile range function, it
>> > > works on its own outside of ddply()
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Apr 19 19:30:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Apr 2016 10:30:18 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
Message-ID: <CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>

NO NO  -- I am wrong! The paste() expression is of course evaluated.
It's just that a character string is returned of the form "something -
something".

I apologize for the confusion.

-- Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> To be precise:
>
> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>
> is an expression that evaluates to a character string:
> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
>
> no matter what the argument of your function, x. Hence
>
> return(paste(...)) will return this exact character string and never
> evaluates x.
>
>
> Cheers,
> Bert
>
>
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
> <r-help at r-project.org> wrote:
>>> That didn't work Jim!
>>
>> It always helps to say how the suggestion did not work.  Jim's
>> function had a typo in it - was that the problem?  Or did you not
>> change the call to ddply to use that function.  Here is something
>> that might "work" for you:
>>
>>  library(plyr)
>>
>>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>>  myIqr <- function(x) {
>>      paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>  }
>>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>> col1_IQR=stats::IQR(col1))
>>  #  groupColumn col1_myIqr col1_IQR
>>  #1           1        1-1        0
>>  #2           2        2-4        1
>>  #3           3      12-24       12
>>  #4           4    112-320      208
>>  #5           5  2048-8192     6144
>>
>> The important point is that
>>     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> is not a function, it is an expression.   ddplyr wants functions.
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>
>>> That didn't work Jim!
>>>
>>> Thanks anyway
>>>
>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> > Hi Michael,
>>> > At a guess, try this:
>>> >
>>> > iqr<-function(x) {
>>> >
>>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>> > }
>>> >
>>> > .col3_Range=iqr(datat$tenure)
>>> >
>>> > Jim
>>> >
>>> >
>>> >
>>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
>>> > wrote:
>>> > > Hi,
>>> > >   I am trying to show an interquartile range while grouping values
>>> using
>>> > > the function ddply().  So my function call now is like
>>> > >
>>> > > groupedAll <- ddply(data
>>> > >                  ,~groupColumn
>>> > >                  ,summarise
>>> > >                  ,col1_mean=mean(col1)
>>> > >                  ,col2_mode=Mode(col2) #Function I wrote for getting
>>> the
>>> > > mode shown below
>>> > >
>>> > >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>>> > >                  )
>>> > >
>>> > > #custom Mode function
>>> > > Mode <- function(x) {
>>> > >   ux <- unique(x)
>>> > >   ux[which.max(tabulate(match(x, ux)))]
>>> > > }
>>> > >
>>> > > I am not sre what is going wrong on my interquartile range function, it
>>> > > works on its own outside of ddply()
>>> > >
>>> > >         [[alternative HTML version deleted]]
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Apr 19 19:31:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Apr 2016 10:31:47 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
Message-ID: <CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>

... and I'm getting another cup of coffee...

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> NO NO  -- I am wrong! The paste() expression is of course evaluated.
> It's just that a character string is returned of the form "something -
> something".
>
> I apologize for the confusion.
>
> -- Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> To be precise:
>>
>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>
>> is an expression that evaluates to a character string:
>> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
>>
>> no matter what the argument of your function, x. Hence
>>
>> return(paste(...)) will return this exact character string and never
>> evaluates x.
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
>> <r-help at r-project.org> wrote:
>>>> That didn't work Jim!
>>>
>>> It always helps to say how the suggestion did not work.  Jim's
>>> function had a typo in it - was that the problem?  Or did you not
>>> change the call to ddply to use that function.  Here is something
>>> that might "work" for you:
>>>
>>>  library(plyr)
>>>
>>>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>>>  myIqr <- function(x) {
>>>      paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>  }
>>>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>>> col1_IQR=stats::IQR(col1))
>>>  #  groupColumn col1_myIqr col1_IQR
>>>  #1           1        1-1        0
>>>  #2           2        2-4        1
>>>  #3           3      12-24       12
>>>  #4           4    112-320      208
>>>  #5           5  2048-8192     6144
>>>
>>> The important point is that
>>>     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>> is not a function, it is an expression.   ddplyr wants functions.
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
>>> wrote:
>>>
>>>> That didn't work Jim!
>>>>
>>>> Thanks anyway
>>>>
>>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>>
>>>> > Hi Michael,
>>>> > At a guess, try this:
>>>> >
>>>> > iqr<-function(x) {
>>>> >
>>>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>> > }
>>>> >
>>>> > .col3_Range=iqr(datat$tenure)
>>>> >
>>>> > Jim
>>>> >
>>>> >
>>>> >
>>>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <michaeleartz at gmail.com>
>>>> > wrote:
>>>> > > Hi,
>>>> > >   I am trying to show an interquartile range while grouping values
>>>> using
>>>> > > the function ddply().  So my function call now is like
>>>> > >
>>>> > > groupedAll <- ddply(data
>>>> > >                  ,~groupColumn
>>>> > >                  ,summarise
>>>> > >                  ,col1_mean=mean(col1)
>>>> > >                  ,col2_mode=Mode(col2) #Function I wrote for getting
>>>> the
>>>> > > mode shown below
>>>> > >
>>>> > >  ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>>>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>>>> > >                  )
>>>> > >
>>>> > > #custom Mode function
>>>> > > Mode <- function(x) {
>>>> > >   ux <- unique(x)
>>>> > >   ux[which.max(tabulate(match(x, ux)))]
>>>> > > }
>>>> > >
>>>> > > I am not sre what is going wrong on my interquartile range function, it
>>>> > > works on its own outside of ddply()
>>>> > >
>>>> > >         [[alternative HTML version deleted]]
>>>> > >
>>>> > > ______________________________________________
>>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > > PLEASE do read the posting guide
>>>> > http://www.R-project.org/posting-guide.html
>>>> > > and provide commented, minimal, self-contained, reproducible code.
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From tom at maladmin.com  Tue Apr 19 20:28:44 2016
From: tom at maladmin.com (Tom Wright)
Date: Tue, 19 Apr 2016 14:28:44 -0400
Subject: [R] Problem with X11
In-Reply-To: <20160419152337.GA3547@localhost.localdomain>
References: <20160419152337.GA3547@localhost.localdomain>
Message-ID: <CAKmUXV8PNsTLThE+mRfQP038Fv7w=0QUqHsg8t6g+1VLsZ8W1Q@mail.gmail.com>

I don't have my debian box available so can't confirm. But I would try
$apt-get install libpng

On Tue, Apr 19, 2016 at 11:23 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> I have never had this problem before. I run debian testing on my box
> and I have recently update my R environment.
> Now, see what happens when I try the most trivial of all plots
>
> plot(seq(22))
>>
> Error in (function (display = "", width, height, pointsize, gamma, bg,
> :
>  X11 module cannot be loaded
>  In addition: Warning message:
>  In (function (display = "", width, height, pointsize, gamma, bg,  :
>    unable to load shared object '/usr/lib/R/modules//R_X11.so':
>      /usr/lib/x86_64-linux-gnu/libpng12.so.0: version `PNG12_0' not
>      found (required by /usr/lib/R/modules//R_X11.so)
>
> and this is my sessionInfo()
>
> sessionInfo()
>>
> R version 3.2.4 Revised (2016-03-16 r70336)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux stretch/sid
>
> locale:
> [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
>    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
>     [9] LC_ADDRESS=C              LC_TELEPHONE=C
>     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> Anybody understands what is going on here?
> Regards
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From klerer at sxmail.de  Tue Apr 19 20:41:46 2016
From: klerer at sxmail.de (klerer at sxmail.de)
Date: Tue, 19 Apr 2016 20:41:46 +0200
Subject: [R] Problem with X11
Message-ID: <30c3f2b52dafa9baa3f0cbb30d7a6aaa@www.sxmail.de>

Dear Lorenzo, Dear R list,[a] to all recipients: sorry, this email is html-against my own believes and because of inevitable constraints so far.[b] to Lorenzo: "...and I have recently update my R environment" sounds as that would be a gift of heaven! How did you manage to update and how exactly went the process of updating the whole R environment, as you put it? I turn to you since I have not received an understandable answer to that question yet (see [d] below for sessionInfo() details).[c] to all R users: I use as OS a debian derivative (Kubuntu) long-term service version; this spring/ early summer as I was told, a new LTS would be released. Has a new/ revised R version in release in 2016 any Achille's heel that is already known? I perceive that some of the (package) update issues I experience might be due to OS compatibility (see [d] below for sessionInfo() details).[d]> sessionInfo()R version 3.0.2 (2013-09-25)Platform: x86_64-pc-linux-gnu (64-bit)locale:?[1]
LC_CTYPE=de_DE.UTF-8????????? LC_NUMERIC=C???????????????? ?[3] LC_TIME=de_DE.UTF-8?????????? LC_COLLATE=de_DE.UTF-8?????? ?[5] LC_MONETARY=de_DE.UTF-8?????? LC_MESSAGES=de_DE.UTF-8????? ?[7] LC_PAPER=de_DE.UTF-8????????? LC_NAME=de_DE.UTF-8????????? ?[9] LC_ADDRESS=de_DE.UTF-8??????? LC_TELEPHONE=de_DE.UTF-8???? [11] LC_MEASUREMENT=de_DE.UTF-8??? LC_IDENTIFICATION=de_DE.UTF-8attached base packages:[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? other attached packages:[1] rkward_0.6.1loaded via a namespace (and not attached):[1] tools_3.0.2Best regards,Markus HofstetterLorenzo Isella <lorenzo.isella at gmail.com> schrieb (19.04.2016 17:23):Dear All,
I have never had this problem before. I run debian testing on my box
and I have recently update my R environment.
Now, see what happens when I try the most trivial of all plots

> plot(seq(22))
Error in (function (display = "", width, height, pointsize, gamma, bg,
:
  X11 module cannot be loaded
  In addition: Warning message:
  In (function (display = "", width, height, pointsize, gamma, bg,  :
    unable to load shared object '/usr/lib/R/modules//R_X11.so':
      /usr/lib/x86_64-linux-gnu/libpng12.so.0: version `PNG12_0' not
      found (required by /usr/lib/R/modules//R_X11.so)

and this is my sessionInfo()

> sessionInfo()
R version 3.2.4 Revised (2016-03-16 r70336)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux stretch/sid

locale:
 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
     [9] LC_ADDRESS=C              LC_TELEPHONE=C
     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


Anybody understands what is going on here?
Regards

Lorenzo

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From michaeleartz at gmail.com  Tue Apr 19 21:18:59 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 19 Apr 2016 14:18:59 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
Message-ID: <CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>

Oh thanks for that clarification Bert!  Hope you enjoyed your coffee!  I
ended up just using the transform argument in the ddply function.  It
worked and it repeated, then I called a mode function in another call to
ddply that summarised.  Kinda hacky but oh well!

On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> ... and I'm getting another cup of coffee...
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > NO NO  -- I am wrong! The paste() expression is of course evaluated.
> > It's just that a character string is returned of the form "something -
> > something".
> >
> > I apologize for the confusion.
> >
> > -- Bert
> >
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >> To be precise:
> >>
> >> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>
> >> is an expression that evaluates to a character string:
> >> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
> >>
> >> no matter what the argument of your function, x. Hence
> >>
> >> return(paste(...)) will return this exact character string and never
> >> evaluates x.
> >>
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
> >> <r-help at r-project.org> wrote:
> >>>> That didn't work Jim!
> >>>
> >>> It always helps to say how the suggestion did not work.  Jim's
> >>> function had a typo in it - was that the problem?  Or did you not
> >>> change the call to ddply to use that function.  Here is something
> >>> that might "work" for you:
> >>>
> >>>  library(plyr)
> >>>
> >>>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
> >>>  myIqr <- function(x) {
> >>>      paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>>  }
> >>>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
> >>> col1_IQR=stats::IQR(col1))
> >>>  #  groupColumn col1_myIqr col1_IQR
> >>>  #1           1        1-1        0
> >>>  #2           2        2-4        1
> >>>  #3           3      12-24       12
> >>>  #4           4    112-320      208
> >>>  #5           5  2048-8192     6144
> >>>
> >>> The important point is that
> >>>     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>> is not a function, it is an expression.   ddplyr wants functions.
> >>>
> >>>
> >>> Bill Dunlap
> >>> TIBCO Software
> >>> wdunlap tibco.com
> >>>
> >>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com>
> >>> wrote:
> >>>
> >>>> That didn't work Jim!
> >>>>
> >>>> Thanks anyway
> >>>>
> >>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>>
> >>>> > Hi Michael,
> >>>> > At a guess, try this:
> >>>> >
> >>>> > iqr<-function(x) {
> >>>> >
> >>>>
> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>>> > }
> >>>> >
> >>>> > .col3_Range=iqr(datat$tenure)
> >>>> >
> >>>> > Jim
> >>>> >
> >>>> >
> >>>> >
> >>>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <
> michaeleartz at gmail.com>
> >>>> > wrote:
> >>>> > > Hi,
> >>>> > >   I am trying to show an interquartile range while grouping values
> >>>> using
> >>>> > > the function ddply().  So my function call now is like
> >>>> > >
> >>>> > > groupedAll <- ddply(data
> >>>> > >                  ,~groupColumn
> >>>> > >                  ,summarise
> >>>> > >                  ,col1_mean=mean(col1)
> >>>> > >                  ,col2_mode=Mode(col2) #Function I wrote for
> getting
> >>>> the
> >>>> > > mode shown below
> >>>> > >
> >>>> > >
> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
> >>>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
> >>>> > >                  )
> >>>> > >
> >>>> > > #custom Mode function
> >>>> > > Mode <- function(x) {
> >>>> > >   ux <- unique(x)
> >>>> > >   ux[which.max(tabulate(match(x, ux)))]
> >>>> > > }
> >>>> > >
> >>>> > > I am not sre what is going wrong on my interquartile range
> function, it
> >>>> > > works on its own outside of ddply()
> >>>> > >
> >>>> > >         [[alternative HTML version deleted]]
> >>>> > >
> >>>> > > ______________________________________________
> >>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> > > PLEASE do read the posting guide
> >>>> > http://www.R-project.org/posting-guide.html
> >>>> > > and provide commented, minimal, self-contained, reproducible code.
> >>>> >
> >>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Tue Apr 19 21:47:19 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 19 Apr 2016 15:47:19 -0400
Subject: [R] installation of dplyr
Message-ID: <E13FC27C-D395-4CA5-8489-1CF8D3EA8117@bigelow.org>

Hello,

I am getting a fresh CentOS 6.7 machine set up with all of the goodies for R 3.2.3, including dplyr package. I am unable to successfully install it.  Below I show the failed installation using utils::install.packages() and then again using devtools::install_github().  Each yields an error similar to the other but not quite exactly the same - the error messages sail right over my head.

I can contact the package author if that would be better, but thought it best to start here.

Thanks!
Ben

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

> sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS release 6.7 (Final)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base   
  


####
#	utils::install.packages()
####

> install.packages("dplyr", repo = "http://cran.r-project.org")
Installing package into ?/usr/lib64/R/library?
(as ?lib? is unspecified)
trying URL 'http://cran.r-project.org/src/contrib/dplyr_0.4.3.tar.gz'
Content type 'application/x-gzip' length 655997 bytes (640 KB)
==================================================
downloaded 640 KB

* installing *source* package ?dplyr? ...
** package ?dplyr? successfully unpacked and MD5 sums checked
** libs
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
In file included from ../inst/include/dplyr.h:131,
                 from arrange.cpp:1:
../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
../inst/include/dplyr/DataFrameSubsetVisitors.h:40: warning: ?column? may be used uninitialized in this function
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
dplyr.cpp:242: warning: ?number_tiles? may be used uninitialized in this function
{standard input}: Assembler messages:
{standard input}:509159: Warning: end of file not at end of a line; newline inserted
{standard input}:509591: Error: open CFI at the end of file; missing .cfi_endproc directive
g++: Internal error: Killed (program cc1plus)
Please submit a full bug report.
See <http://bugzilla.redhat.com/bugzilla> for instructions.
make: *** [dplyr.o] Error 1
ERROR: compilation failed for package ?dplyr?
* removing ?/usr/lib64/R/library/dplyr?

The downloaded source packages are in
	?/tmp/RtmpkdCODF/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("dplyr", repo = "http://cran.r-project.org") :
  installation of package ?dplyr? had non-zero exit status



####
#	devtools::install_github()
####


> library(devtools)
> install_github("hadley/dplyr", lib = '/usr/lib64/R/library')
Using GitHub PAT from envvar GITHUB_PAT
Downloading GitHub repo hadley/dplyr at master
from URL https://api.github.com/repos/hadley/dplyr/zipball/master
Installing dplyr
Using GitHub PAT from envvar GITHUB_PAT
Downloading GitHub repo hadley/testthat at master
from URL https://api.github.com/repos/hadley/testthat/zipball/master
Installing testthat
'/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
  --quiet CMD INSTALL  \
  '/tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494'  \
  --library='/usr/lib64/R/library' --install-tests 

* installing *source* package ?testthat? ...
** libs
gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c label.c -o label.o
gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c reassign.c -o reassign.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-catch.cpp -o test-catch.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-example.cpp -o test-example.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-runner.cpp -o test-runner.o
g++ -m64 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o testthat.so label.o reassign.o test-catch.o test-example.o test-runner.o -L/usr/lib64/R/lib -lR
installing to /usr/lib64/R/library/testthat/libs
** R
** inst
** tests
** preparing package for lazy loading
** help
*** installing help indices
  converting help for package ?testthat?
    finding HTML links ... done
    CheckReporter                           html  
    FailReporter                            html  
    ListReporter                            html  
    MinimalReporter                         html  
    MultiReporter                           html  
    Reporter                                html  
    RstudioReporter                         html  
    SilentReporter                          html  
    StopReporter                            html  
    SummaryReporter                         html  
    TapReporter                             html  
    TeamcityReporter                        html  
    auto_test                               html  
    auto_test_package                       html  
    compare                                 html  
    compare_state                           html  
    comparison-expectations                 html  
    context                                 html  
    describe                                html  
    dir_state                               html  
    equality-expectations                   html  
    evaluate_promise                        html  
    expect_cpp_tests_pass                   html  
    expect_equal_to_reference               html  
    expect_length                           html  
    expect_match                            html  
    expect_named                            html  
    expect_success                          html  
    expect_that                             html  
    expectation                             html  
    fail                                    html  
    find_reporter                           html  
    find_test_scripts                       html  
    inheritance-expectations                html  
    logical-expectations                    html  
    make_expectation                        html  
    not                                     html  
    oldskool                                html  
    output-expectations                     html  
    reexports                               html  
Rd warning: /tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494/man/reexports.Rd:13: missing file link ?%>%?
    reporter-accessors                      html  
    safe_digest                             html  
    skip                                    html  
    source_file                             html  
    takes_less_than                         html  
    test_dir                                html  
    test_env                                html  
    test_examples                           html  
    test_file                               html  
    test_package                            html  
    test_path                               html  
    test_that                               html  
    testthat                                html  
    testthat_results                        html  
    try_again                               html  
    use_catch                               html  
    watch                                   html  
    with_mock                               html  
** building package indices
** testing if installed package can be loaded
* DONE (testthat)
Making 'packages.html' ... done
Using GitHub PAT from envvar GITHUB_PAT
Skipping install for github remote, the SHA1 (cb38672f) has not changed since last install.
  Use `force = TRUE` to force installation
Skipping 2 packages ahead of CRAN: lazyeval, tibble
'/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
  --quiet CMD INSTALL  \
  '/tmp/RtmpkdCODF/devtools45c2fff716f/hadley-dplyr-afb9ac7'  \
  --library='/usr/lib64/R/library' --install-tests 

* installing *source* package ?dplyr? ...
** libs
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
In file included from ../inst/include/dplyr.h:141,
                 from arrange.cpp:1:
../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
dplyr.cpp:213: warning: ?number_tiles? may be used uninitialized in this function
In file included from ../inst/include/dplyr.h:141,
                 from dplyr.cpp:1:
../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
{standard input}: Assembler messages:
{standard input}:812569: Warning: end of file not at end of a line; newline inserted
g++: Internal error: Killed (program cc1plus)
Please submit a full bug report.
See <http://bugzilla.redhat.com/bugzilla> for instructions.
make: *** [dplyr.o] Error 1
ERROR: compilation failed for package ?dplyr?
* removing ?/usr/lib64/R/library/dplyr?
Error: Command failed (1)
> 


From wdunlap at tibco.com  Tue Apr 19 21:57:12 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 19 Apr 2016 12:57:12 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
	<CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
Message-ID: <CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>

If you show us, not just tell us about, a self-contained example
someone might show you a non-hacky way of getting the job done.
(I don't see an argument to plyr::ddply called 'transform'.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 19, 2016 at 12:18 PM, Michael Artz <michaeleartz at gmail.com>
wrote:

> Oh thanks for that clarification Bert!  Hope you enjoyed your coffee!  I
> ended up just using the transform argument in the ddply function.  It
> worked and it repeated, then I called a mode function in another call to
> ddply that summarised.  Kinda hacky but oh well!
>
> On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> ... and I'm getting another cup of coffee...
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> > NO NO  -- I am wrong! The paste() expression is of course evaluated.
>> > It's just that a character string is returned of the form "something -
>> > something".
>> >
>> > I apologize for the confusion.
>> >
>> > -- Bert
>> >
>> >
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >> To be precise:
>> >>
>> >> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>
>> >> is an expression that evaluates to a character string:
>> >> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
>> >>
>> >> no matter what the argument of your function, x. Hence
>> >>
>> >> return(paste(...)) will return this exact character string and never
>> >> evaluates x.
>> >>
>> >>
>> >> Cheers,
>> >> Bert
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming along
>> >> and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
>> >> <r-help at r-project.org> wrote:
>> >>>> That didn't work Jim!
>> >>>
>> >>> It always helps to say how the suggestion did not work.  Jim's
>> >>> function had a typo in it - was that the problem?  Or did you not
>> >>> change the call to ddply to use that function.  Here is something
>> >>> that might "work" for you:
>> >>>
>> >>>  library(plyr)
>> >>>
>> >>>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>> >>>  myIqr <- function(x) {
>> >>>
>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>>  }
>> >>>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>> >>> col1_IQR=stats::IQR(col1))
>> >>>  #  groupColumn col1_myIqr col1_IQR
>> >>>  #1           1        1-1        0
>> >>>  #2           2        2-4        1
>> >>>  #3           3      12-24       12
>> >>>  #4           4    112-320      208
>> >>>  #5           5  2048-8192     6144
>> >>>
>> >>> The important point is that
>> >>>     paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>> is not a function, it is an expression.   ddplyr wants functions.
>> >>>
>> >>>
>> >>> Bill Dunlap
>> >>> TIBCO Software
>> >>> wdunlap tibco.com
>> >>>
>> >>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <michaeleartz at gmail.com
>> >
>> >>> wrote:
>> >>>
>> >>>> That didn't work Jim!
>> >>>>
>> >>>> Thanks anyway
>> >>>>
>> >>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>> >>>>
>> >>>> > Hi Michael,
>> >>>> > At a guess, try this:
>> >>>> >
>> >>>> > iqr<-function(x) {
>> >>>> >
>> >>>>
>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>>> > }
>> >>>> >
>> >>>> > .col3_Range=iqr(datat$tenure)
>> >>>> >
>> >>>> > Jim
>> >>>> >
>> >>>> >
>> >>>> >
>> >>>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <
>> michaeleartz at gmail.com>
>> >>>> > wrote:
>> >>>> > > Hi,
>> >>>> > >   I am trying to show an interquartile range while grouping
>> values
>> >>>> using
>> >>>> > > the function ddply().  So my function call now is like
>> >>>> > >
>> >>>> > > groupedAll <- ddply(data
>> >>>> > >                  ,~groupColumn
>> >>>> > >                  ,summarise
>> >>>> > >                  ,col1_mean=mean(col1)
>> >>>> > >                  ,col2_mode=Mode(col2) #Function I wrote for
>> getting
>> >>>> the
>> >>>> > > mode shown below
>> >>>> > >
>> >>>> > >
>> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>> >>>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>> >>>> > >                  )
>> >>>> > >
>> >>>> > > #custom Mode function
>> >>>> > > Mode <- function(x) {
>> >>>> > >   ux <- unique(x)
>> >>>> > >   ux[which.max(tabulate(match(x, ux)))]
>> >>>> > > }
>> >>>> > >
>> >>>> > > I am not sre what is going wrong on my interquartile range
>> function, it
>> >>>> > > works on its own outside of ddply()
>> >>>> > >
>> >>>> > >         [[alternative HTML version deleted]]
>> >>>> > >
>> >>>> > > ______________________________________________
>> >>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> >>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> > > PLEASE do read the posting guide
>> >>>> > http://www.R-project.org/posting-guide.html
>> >>>> > > and provide commented, minimal, self-contained, reproducible
>> code.
>> >>>> >
>> >>>>
>> >>>>         [[alternative HTML version deleted]]
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Tue Apr 19 22:10:20 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 19 Apr 2016 15:10:20 -0500
Subject: [R] installation of dplyr
In-Reply-To: <E13FC27C-D395-4CA5-8489-1CF8D3EA8117@bigelow.org>
References: <E13FC27C-D395-4CA5-8489-1CF8D3EA8117@bigelow.org>
Message-ID: <CABdHhvFc8hp42rJ-LNu411Ju5fSvDb=6tj-RBecjFmYACMsmaA@mail.gmail.com>

You normally see these errors when compiling on a vm that has very
little memory.
Hadley

On Tue, Apr 19, 2016 at 2:47 PM, Ben Tupper <btupper at bigelow.org> wrote:
> Hello,
>
> I am getting a fresh CentOS 6.7 machine set up with all of the goodies for R 3.2.3, including dplyr package. I am unable to successfully install it.  Below I show the failed installation using utils::install.packages() and then again using devtools::install_github().  Each yields an error similar to the other but not quite exactly the same - the error messages sail right over my head.
>
> I can contact the package author if that would be better, but thought it best to start here.
>
> Thanks!
> Ben
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>> sessionInfo()
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> Running under: CentOS release 6.7 (Final)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> ####
> #       utils::install.packages()
> ####
>
>> install.packages("dplyr", repo = "http://cran.r-project.org")
> Installing package into ?/usr/lib64/R/library?
> (as ?lib? is unspecified)
> trying URL 'http://cran.r-project.org/src/contrib/dplyr_0.4.3.tar.gz'
> Content type 'application/x-gzip' length 655997 bytes (640 KB)
> ==================================================
> downloaded 640 KB
>
> * installing *source* package ?dplyr? ...
> ** package ?dplyr? successfully unpacked and MD5 sums checked
> ** libs
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
> In file included from ../inst/include/dplyr.h:131,
>                  from arrange.cpp:1:
> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
> ../inst/include/dplyr/DataFrameSubsetVisitors.h:40: warning: ?column? may be used uninitialized in this function
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
> dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
> dplyr.cpp:242: warning: ?number_tiles? may be used uninitialized in this function
> {standard input}: Assembler messages:
> {standard input}:509159: Warning: end of file not at end of a line; newline inserted
> {standard input}:509591: Error: open CFI at the end of file; missing .cfi_endproc directive
> g++: Internal error: Killed (program cc1plus)
> Please submit a full bug report.
> See <http://bugzilla.redhat.com/bugzilla> for instructions.
> make: *** [dplyr.o] Error 1
> ERROR: compilation failed for package ?dplyr?
> * removing ?/usr/lib64/R/library/dplyr?
>
> The downloaded source packages are in
>         ?/tmp/RtmpkdCODF/downloaded_packages?
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("dplyr", repo = "http://cran.r-project.org") :
>   installation of package ?dplyr? had non-zero exit status
>
>
>
> ####
> #       devtools::install_github()
> ####
>
>
>> library(devtools)
>> install_github("hadley/dplyr", lib = '/usr/lib64/R/library')
> Using GitHub PAT from envvar GITHUB_PAT
> Downloading GitHub repo hadley/dplyr at master
> from URL https://api.github.com/repos/hadley/dplyr/zipball/master
> Installing dplyr
> Using GitHub PAT from envvar GITHUB_PAT
> Downloading GitHub repo hadley/testthat at master
> from URL https://api.github.com/repos/hadley/testthat/zipball/master
> Installing testthat
> '/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
>   --quiet CMD INSTALL  \
>   '/tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494'  \
>   --library='/usr/lib64/R/library' --install-tests
>
> * installing *source* package ?testthat? ...
> ** libs
> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c label.c -o label.o
> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c reassign.c -o reassign.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-catch.cpp -o test-catch.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-example.cpp -o test-example.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-runner.cpp -o test-runner.o
> g++ -m64 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o testthat.so label.o reassign.o test-catch.o test-example.o test-runner.o -L/usr/lib64/R/lib -lR
> installing to /usr/lib64/R/library/testthat/libs
> ** R
> ** inst
> ** tests
> ** preparing package for lazy loading
> ** help
> *** installing help indices
>   converting help for package ?testthat?
>     finding HTML links ... done
>     CheckReporter                           html
>     FailReporter                            html
>     ListReporter                            html
>     MinimalReporter                         html
>     MultiReporter                           html
>     Reporter                                html
>     RstudioReporter                         html
>     SilentReporter                          html
>     StopReporter                            html
>     SummaryReporter                         html
>     TapReporter                             html
>     TeamcityReporter                        html
>     auto_test                               html
>     auto_test_package                       html
>     compare                                 html
>     compare_state                           html
>     comparison-expectations                 html
>     context                                 html
>     describe                                html
>     dir_state                               html
>     equality-expectations                   html
>     evaluate_promise                        html
>     expect_cpp_tests_pass                   html
>     expect_equal_to_reference               html
>     expect_length                           html
>     expect_match                            html
>     expect_named                            html
>     expect_success                          html
>     expect_that                             html
>     expectation                             html
>     fail                                    html
>     find_reporter                           html
>     find_test_scripts                       html
>     inheritance-expectations                html
>     logical-expectations                    html
>     make_expectation                        html
>     not                                     html
>     oldskool                                html
>     output-expectations                     html
>     reexports                               html
> Rd warning: /tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494/man/reexports.Rd:13: missing file link ?%>%?
>     reporter-accessors                      html
>     safe_digest                             html
>     skip                                    html
>     source_file                             html
>     takes_less_than                         html
>     test_dir                                html
>     test_env                                html
>     test_examples                           html
>     test_file                               html
>     test_package                            html
>     test_path                               html
>     test_that                               html
>     testthat                                html
>     testthat_results                        html
>     try_again                               html
>     use_catch                               html
>     watch                                   html
>     with_mock                               html
> ** building package indices
> ** testing if installed package can be loaded
> * DONE (testthat)
> Making 'packages.html' ... done
> Using GitHub PAT from envvar GITHUB_PAT
> Skipping install for github remote, the SHA1 (cb38672f) has not changed since last install.
>   Use `force = TRUE` to force installation
> Skipping 2 packages ahead of CRAN: lazyeval, tibble
> '/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
>   --quiet CMD INSTALL  \
>   '/tmp/RtmpkdCODF/devtools45c2fff716f/hadley-dplyr-afb9ac7'  \
>   --library='/usr/lib64/R/library' --install-tests
>
> * installing *source* package ?dplyr? ...
> ** libs
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
> In file included from ../inst/include/dplyr.h:141,
>                  from arrange.cpp:1:
> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
> ../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
> dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
> dplyr.cpp:213: warning: ?number_tiles? may be used uninitialized in this function
> In file included from ../inst/include/dplyr.h:141,
>                  from dplyr.cpp:1:
> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
> ../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
> {standard input}: Assembler messages:
> {standard input}:812569: Warning: end of file not at end of a line; newline inserted
> g++: Internal error: Killed (program cc1plus)
> Please submit a full bug report.
> See <http://bugzilla.redhat.com/bugzilla> for instructions.
> make: *** [dplyr.o] Error 1
> ERROR: compilation failed for package ?dplyr?
> * removing ?/usr/lib64/R/library/dplyr?
> Error: Command failed (1)
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From btupper at bigelow.org  Tue Apr 19 22:22:40 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 19 Apr 2016 16:22:40 -0400
Subject: [R] installation of dplyr
In-Reply-To: <CABdHhvFc8hp42rJ-LNu411Ju5fSvDb=6tj-RBecjFmYACMsmaA@mail.gmail.com>
References: <E13FC27C-D395-4CA5-8489-1CF8D3EA8117@bigelow.org>
	<CABdHhvFc8hp42rJ-LNu411Ju5fSvDb=6tj-RBecjFmYACMsmaA@mail.gmail.com>
Message-ID: <7C57AE9B-CFBE-4B5C-B9A3-7500AEA20A2C@bigelow.org>

Hi,

OK - that can be fixed by our IT whizzes.  

Thanks,
Ben

P.S.  Thanks for dplyr!

> On Apr 19, 2016, at 4:10 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> 
> You normally see these errors when compiling on a vm that has very
> little memory.
> Hadley
> 
> On Tue, Apr 19, 2016 at 2:47 PM, Ben Tupper <btupper at bigelow.org> wrote:
>> Hello,
>> 
>> I am getting a fresh CentOS 6.7 machine set up with all of the goodies for R 3.2.3, including dplyr package. I am unable to successfully install it.  Below I show the failed installation using utils::install.packages() and then again using devtools::install_github().  Each yields an error similar to the other but not quite exactly the same - the error messages sail right over my head.
>> 
>> I can contact the package author if that would be better, but thought it best to start here.
>> 
>> Thanks!
>> Ben
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>>> sessionInfo()
>> R version 3.2.3 (2015-12-10)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>> Running under: CentOS release 6.7 (Final)
>> 
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> 
>> 
>> ####
>> #       utils::install.packages()
>> ####
>> 
>>> install.packages("dplyr", repo = "http://cran.r-project.org")
>> Installing package into ?/usr/lib64/R/library?
>> (as ?lib? is unspecified)
>> trying URL 'http://cran.r-project.org/src/contrib/dplyr_0.4.3.tar.gz'
>> Content type 'application/x-gzip' length 655997 bytes (640 KB)
>> ==================================================
>> downloaded 640 KB
>> 
>> * installing *source* package ?dplyr? ...
>> ** package ?dplyr? successfully unpacked and MD5 sums checked
>> ** libs
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
>> In file included from ../inst/include/dplyr.h:131,
>>                 from arrange.cpp:1:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h:40: warning: ?column? may be used uninitialized in this function
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
>> dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
>> dplyr.cpp:242: warning: ?number_tiles? may be used uninitialized in this function
>> {standard input}: Assembler messages:
>> {standard input}:509159: Warning: end of file not at end of a line; newline inserted
>> {standard input}:509591: Error: open CFI at the end of file; missing .cfi_endproc directive
>> g++: Internal error: Killed (program cc1plus)
>> Please submit a full bug report.
>> See <http://bugzilla.redhat.com/bugzilla> for instructions.
>> make: *** [dplyr.o] Error 1
>> ERROR: compilation failed for package ?dplyr?
>> * removing ?/usr/lib64/R/library/dplyr?
>> 
>> The downloaded source packages are in
>>        ?/tmp/RtmpkdCODF/downloaded_packages?
>> Updating HTML index of packages in '.Library'
>> Making 'packages.html' ... done
>> Warning message:
>> In install.packages("dplyr", repo = "http://cran.r-project.org") :
>>  installation of package ?dplyr? had non-zero exit status
>> 
>> 
>> 
>> ####
>> #       devtools::install_github()
>> ####
>> 
>> 
>>> library(devtools)
>>> install_github("hadley/dplyr", lib = '/usr/lib64/R/library')
>> Using GitHub PAT from envvar GITHUB_PAT
>> Downloading GitHub repo hadley/dplyr at master
>> from URL https://api.github.com/repos/hadley/dplyr/zipball/master
>> Installing dplyr
>> Using GitHub PAT from envvar GITHUB_PAT
>> Downloading GitHub repo hadley/testthat at master
>> from URL https://api.github.com/repos/hadley/testthat/zipball/master
>> Installing testthat
>> '/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
>>  --quiet CMD INSTALL  \
>>  '/tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494'  \
>>  --library='/usr/lib64/R/library' --install-tests
>> 
>> * installing *source* package ?testthat? ...
>> ** libs
>> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c label.c -o label.o
>> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c reassign.c -o reassign.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-catch.cpp -o test-catch.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-example.cpp -o test-example.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-runner.cpp -o test-runner.o
>> g++ -m64 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o testthat.so label.o reassign.o test-catch.o test-example.o test-runner.o -L/usr/lib64/R/lib -lR
>> installing to /usr/lib64/R/library/testthat/libs
>> ** R
>> ** inst
>> ** tests
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>>  converting help for package ?testthat?
>>    finding HTML links ... done
>>    CheckReporter                           html
>>    FailReporter                            html
>>    ListReporter                            html
>>    MinimalReporter                         html
>>    MultiReporter                           html
>>    Reporter                                html
>>    RstudioReporter                         html
>>    SilentReporter                          html
>>    StopReporter                            html
>>    SummaryReporter                         html
>>    TapReporter                             html
>>    TeamcityReporter                        html
>>    auto_test                               html
>>    auto_test_package                       html
>>    compare                                 html
>>    compare_state                           html
>>    comparison-expectations                 html
>>    context                                 html
>>    describe                                html
>>    dir_state                               html
>>    equality-expectations                   html
>>    evaluate_promise                        html
>>    expect_cpp_tests_pass                   html
>>    expect_equal_to_reference               html
>>    expect_length                           html
>>    expect_match                            html
>>    expect_named                            html
>>    expect_success                          html
>>    expect_that                             html
>>    expectation                             html
>>    fail                                    html
>>    find_reporter                           html
>>    find_test_scripts                       html
>>    inheritance-expectations                html
>>    logical-expectations                    html
>>    make_expectation                        html
>>    not                                     html
>>    oldskool                                html
>>    output-expectations                     html
>>    reexports                               html
>> Rd warning: /tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494/man/reexports.Rd:13: missing file link ?%>%?
>>    reporter-accessors                      html
>>    safe_digest                             html
>>    skip                                    html
>>    source_file                             html
>>    takes_less_than                         html
>>    test_dir                                html
>>    test_env                                html
>>    test_examples                           html
>>    test_file                               html
>>    test_package                            html
>>    test_path                               html
>>    test_that                               html
>>    testthat                                html
>>    testthat_results                        html
>>    try_again                               html
>>    use_catch                               html
>>    watch                                   html
>>    with_mock                               html
>> ** building package indices
>> ** testing if installed package can be loaded
>> * DONE (testthat)
>> Making 'packages.html' ... done
>> Using GitHub PAT from envvar GITHUB_PAT
>> Skipping install for github remote, the SHA1 (cb38672f) has not changed since last install.
>>  Use `force = TRUE` to force installation
>> Skipping 2 packages ahead of CRAN: lazyeval, tibble
>> '/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
>>  --quiet CMD INSTALL  \
>>  '/tmp/RtmpkdCODF/devtools45c2fff716f/hadley-dplyr-afb9ac7'  \
>>  --library='/usr/lib64/R/library' --install-tests
>> 
>> * installing *source* package ?dplyr? ...
>> ** libs
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
>> In file included from ../inst/include/dplyr.h:141,
>>                 from arrange.cpp:1:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
>> dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
>> dplyr.cpp:213: warning: ?number_tiles? may be used uninitialized in this function
>> In file included from ../inst/include/dplyr.h:141,
>>                 from dplyr.cpp:1:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
>> {standard input}: Assembler messages:
>> {standard input}:812569: Warning: end of file not at end of a line; newline inserted
>> g++: Internal error: Killed (program cc1plus)
>> Please submit a full bug report.
>> See <http://bugzilla.redhat.com/bugzilla> for instructions.
>> make: *** [dplyr.o] Error 1
>> ERROR: compilation failed for package ?dplyr?
>> * removing ?/usr/lib64/R/library/dplyr?
>> Error: Command failed (1)
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> http://hadley.nz

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From henrik.bengtsson at gmail.com  Tue Apr 19 23:04:11 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 19 Apr 2016 14:04:11 -0700
Subject: [R] Matrix: How create a _row-oriented_ sparse Matrix (=dgRMatrix)?
Message-ID: <CAFDcVCRmwh6H63oZCJORdKF6fY304XDZWgLNg6L8fcdkj+qXpA@mail.gmail.com>

Using the Matrix package, how can I create a row-oriented sparse
Matrix from scratch populated with some data?  By default a
column-oriented one is created and I'm aware of the note that the
package is optimized for column-oriented ones, but I'm only interested
in using it for holding my sparse row-oriented data and doing basic
subsetting by rows (even using drop=FALSE).

Here is what I get when I set up a column-oriented sparse Matrix:

> Cc <- Matrix(0, nrow=5, ncol=5, sparse=TRUE)
> Cc[1:3,1] <- 1
> Cc
5 x 5 sparse Matrix of class "dgCMatrix"

[1,] 1 . . . .
[2,] 1 . . . .
[3,] 1 . . . .
[4,] . . . . .
[5,] . . . . .
> str(Cc)
Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
  ..@ i       : int [1:3] 0 1 2
  ..@ p       : int [1:6] 0 3 3 3 3 3
  ..@ Dim     : int [1:2] 5 5
  ..@ Dimnames:List of 2
  .. ..$ : NULL
  .. ..$ : NULL
  ..@ x       : num [1:3] 1 1 1
  ..@ factors : list()

When I try to do the analogue for a row-oriented matrix, I get a
"dgTMatrix", whereas I would expect a "dgRMatrix":

> Cr <- Matrix(0, nrow=5, ncol=5, sparse=TRUE)
> Cr <- as(Cr, "dsRMatrix")
> Cr[1,1:3] <- 1
> Cr
5 x 5 sparse Matrix of class "dgTMatrix"

[1,] 1 1 1 . .
[2,] . . . . .
[3,] . . . . .
[4,] . . . . .
[5,] . . . . .
> str(Cr)
Formal class 'dgTMatrix' [package "Matrix"] with 6 slots
  ..@ i       : int [1:3] 0 0 0
  ..@ j       : int [1:3] 0 1 2
  ..@ Dim     : int [1:2] 5 5
  ..@ Dimnames:List of 2
  .. ..$ : NULL
  .. ..$ : NULL
  ..@ x       : num [1:3] 1 1 1
  ..@ factors : list()


Trying with explicit coercion does not work:

> as(Cc, "dgRMatrix")
Error in as(Cc, "dgRMatrix") :
  no method or default for coercing "dgCMatrix" to "dgRMatrix"

> as(Cr, "dgRMatrix")
Error in as(Cr, "dgRMatrix") :
  no method or default for coercing "dgTMatrix" to "dgRMatrix"


Am I doing some wrong here?  Or is this what means that the package is
optimized for the column-oriented representation and I shouldn't
really work with row-oriented ones?  I'm really only interested in
access to efficient Cr[row,,drop=FALSE] subsetting (and a small memory
footprint).

Thanks,

Henrik


From dpv at gmx.ch  Tue Apr 19 21:39:33 2016
From: dpv at gmx.ch (Gaston)
Date: Tue, 19 Apr 2016 21:39:33 +0200
Subject: [R] Merge sort
Message-ID: <57168975.3030708@gmx.ch>

Hello everyone,

I am learning R since recently, and as a small exercise I wanted to 
write a recursive mergesort. I was extremely surprised to discover that 
my sorting, although operational, is deeply inefficient in time. Here is 
my code :

> merge <- function(x,y){
>   if (is.na(x[1])) return(y)
>   else if (is.na(y[1])) return(x)
>   else if (x[1]<y[1]) return(c(x[1],merge(x[-1],y)))
>   else return(c(y[1],merge(x,y[-1])))
> }
>
> division <- function(x){
>   if (is.na(x[3])) return(cbind(x[1],x[2]))
>   else 
> return(cbind(c(x[1],division(x[-c(1,2)])[,1]),c(x[2],division(x[-c(1,2)])[,2])))
> }
>
> mergesort <- function(x){
>   if (is.na(x[2])) return(x)
>   else{
>     print(x)
>     t=division(x)
>     return(merge(mergesort(t[,1]),mergesort(t[,2])))
>   }
> }

I tried my best to write it "the R-way", but apparently I failed. I 
suppose some of the functions I used are quite heavy. I would be 
grateful if you could give a hint on how to change that!

I hope I made myself clear and wish you a nice day,

Cheers,

Gaston

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Apr 19 23:51:40 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Apr 2016 17:51:40 -0400
Subject: [R] Merge sort
In-Reply-To: <57168975.3030708@gmx.ch>
References: <57168975.3030708@gmx.ch>
Message-ID: <5716A86C.4050000@gmail.com>

On 19/04/2016 3:39 PM, Gaston wrote:
> Hello everyone,
>
> I am learning R since recently, and as a small exercise I wanted to
> write a recursive mergesort. I was extremely surprised to discover that
> my sorting, although operational, is deeply inefficient in time. Here is
> my code :
>
>> merge <- function(x,y){
>>    if (is.na(x[1])) return(y)
>>    else if (is.na(y[1])) return(x)
>>    else if (x[1]<y[1]) return(c(x[1],merge(x[-1],y)))
>>    else return(c(y[1],merge(x,y[-1])))
>> }
>>
>> division <- function(x){
>>    if (is.na(x[3])) return(cbind(x[1],x[2]))
>>    else
>> return(cbind(c(x[1],division(x[-c(1,2)])[,1]),c(x[2],division(x[-c(1,2)])[,2])))
>> }
>>
>> mergesort <- function(x){
>>    if (is.na(x[2])) return(x)
>>    else{
>>      print(x)
>>      t=division(x)
>>      return(merge(mergesort(t[,1]),mergesort(t[,2])))
>>    }
>> }
>
> I tried my best to write it "the R-way", but apparently I failed. I
> suppose some of the functions I used are quite heavy. I would be
> grateful if you could give a hint on how to change that!
>
> I hope I made myself clear and wish you a nice day,

Your use of is.na() looks strange.  I don't understand why you are 
testing element 2 in mergesort(), and element 1 in merge(), and element 
3 in division.  Are you using it to test the length?  It's better to use 
the length() function for that.

The division() function returns a matrix.  It would make more R-sense to 
return a list containing the two parts, because they might not be the 
same length.

Generally speaking, function calls are expensive in R, so the recursive 
merge you're using looks like it would be the bottleneck.  You'd almost 
certainly be better off to allocate something of length(x) + length(y), 
and do the assignments in a loop.

Here's a merge sort I wrote as an illustration in a class.  It's 
designed for clarity rather than speed, but I'd guess it would be faster 
than yours:

mergesort <- function(x) {

   n <- length(x)
   if (n < 2) return(x)

   # split x into two pieces of approximately equal size, x1 and x2

   x1 <- x[1:(n %/% 2)]
   x2 <- x[(n %/% 2 + 1):n]

   # sort each of the pieces
   x1 <- mergesort(x1)
   x2 <- mergesort(x2)

   # merge them back together
   result <- c()
   i <- 0
   while (length(x1) > 0 && length(x2) > 0) {
     # compare the first values
     if (x1[1] < x2[1]) {
       result[i + 1] <- x1[1]
       x1 <- x1[-1]
     } else {
       result[i + 1] <- x2[1]
       x2 <- x2[-1]
     }
     i <- i + 1
   }

   # put the smaller one into the result
   # delete it from whichever vector it came from
   # repeat until one of x1 or x2 is empty
   # copy both vectors (one is empty!) onto the end of the results
   result <- c(result, x1, x2)
   result
}

If I were going for speed, I wouldn't modify the x1 and x2 vectors, and 
I'd pre-allocate result to the appropriate length, rather than growing 
it in the while loop.  But that was a different class!

Duncan Murdoch


From michaeleartz at gmail.com  Wed Apr 20 01:25:22 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 19 Apr 2016 18:25:22 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
	<CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
	<CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>
Message-ID: <CA+pG8eP1d8=xV7VOr7Dj+3rumbTCZVFYxw0vU6=dr2OfGUUd4Q@mail.gmail.com>

Hi,
  Here is what I am doing

notGroupedAll <- ddply(data
                 ,~groupColumn
                 ,summarise
                 ,col1_mean=mean(col1)
                 ,col2_mode=Mode(col2) #Function I wrote for getting the
mode shown below
                 ,col3_Range=myIqr(col3)
                 )

groupedAll <- ddply(data
                 ,~groupColumn
                 ,summarise
                 ,col1_mean=mean(col1)
                 ,col2_mode=Mode(col2) #Function I wrote for getting the
mode shown below
                 ,col3_Range=Mode(col3)
                 )

#custom Mode function
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]

#the range function
myIqr <- function(x) {
  paste(round(quantile(x,0.375),0),round(quantile(x,0.625),0),sep="-")
}


}


Here is what I am doing!! :)



On Tue, Apr 19, 2016 at 2:57 PM, William Dunlap <wdunlap at tibco.com> wrote:

> If you show us, not just tell us about, a self-contained example
> someone might show you a non-hacky way of getting the job done.
> (I don't see an argument to plyr::ddply called 'transform'.)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Apr 19, 2016 at 12:18 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
>
>> Oh thanks for that clarification Bert!  Hope you enjoyed your coffee!  I
>> ended up just using the transform argument in the ddply function.  It
>> worked and it repeated, then I called a mode function in another call to
>> ddply that summarised.  Kinda hacky but oh well!
>>
>> On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> ... and I'm getting another cup of coffee...
>>>
>>> -- Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> > NO NO  -- I am wrong! The paste() expression is of course evaluated.
>>> > It's just that a character string is returned of the form "something -
>>> > something".
>>> >
>>> > I apologize for the confusion.
>>> >
>>> > -- Bert
>>> >
>>> >
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming along
>>> > and sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> >> To be precise:
>>> >>
>>> >> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>> >>
>>> >> is an expression that evaluates to a character string:
>>> >> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
>>> >>
>>> >> no matter what the argument of your function, x. Hence
>>> >>
>>> >> return(paste(...)) will return this exact character string and never
>>> >> evaluates x.
>>> >>
>>> >>
>>> >> Cheers,
>>> >> Bert
>>> >>
>>> >>
>>> >>
>>> >>
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> Bert Gunter
>>> >>
>>> >> "The trouble with having an open mind is that people keep coming along
>>> >> and sticking things into it."
>>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >>
>>> >>
>>> >> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
>>> >> <r-help at r-project.org> wrote:
>>> >>>> That didn't work Jim!
>>> >>>
>>> >>> It always helps to say how the suggestion did not work.  Jim's
>>> >>> function had a typo in it - was that the problem?  Or did you not
>>> >>> change the call to ddply to use that function.  Here is something
>>> >>> that might "work" for you:
>>> >>>
>>> >>>  library(plyr)
>>> >>>
>>> >>>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>>> >>>  myIqr <- function(x) {
>>> >>>
>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>> >>>  }
>>> >>>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>>> >>> col1_IQR=stats::IQR(col1))
>>> >>>  #  groupColumn col1_myIqr col1_IQR
>>> >>>  #1           1        1-1        0
>>> >>>  #2           2        2-4        1
>>> >>>  #3           3      12-24       12
>>> >>>  #4           4    112-320      208
>>> >>>  #5           5  2048-8192     6144
>>> >>>
>>> >>> The important point is that
>>> >>>
>>>  paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>> >>> is not a function, it is an expression.   ddplyr wants functions.
>>> >>>
>>> >>>
>>> >>> Bill Dunlap
>>> >>> TIBCO Software
>>> >>> wdunlap tibco.com
>>> >>>
>>> >>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz <
>>> michaeleartz at gmail.com>
>>> >>> wrote:
>>> >>>
>>> >>>> That didn't work Jim!
>>> >>>>
>>> >>>> Thanks anyway
>>> >>>>
>>> >>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>> >>>>
>>> >>>> > Hi Michael,
>>> >>>> > At a guess, try this:
>>> >>>> >
>>> >>>> > iqr<-function(x) {
>>> >>>> >
>>> >>>>
>>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>> >>>> > }
>>> >>>> >
>>> >>>> > .col3_Range=iqr(datat$tenure)
>>> >>>> >
>>> >>>> > Jim
>>> >>>> >
>>> >>>> >
>>> >>>> >
>>> >>>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz <
>>> michaeleartz at gmail.com>
>>> >>>> > wrote:
>>> >>>> > > Hi,
>>> >>>> > >   I am trying to show an interquartile range while grouping
>>> values
>>> >>>> using
>>> >>>> > > the function ddply().  So my function call now is like
>>> >>>> > >
>>> >>>> > > groupedAll <- ddply(data
>>> >>>> > >                  ,~groupColumn
>>> >>>> > >                  ,summarise
>>> >>>> > >                  ,col1_mean=mean(col1)
>>> >>>> > >                  ,col2_mode=Mode(col2) #Function I wrote for
>>> getting
>>> >>>> the
>>> >>>> > > mode shown below
>>> >>>> > >
>>> >>>> > >
>>> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>>> >>>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>>> >>>> > >                  )
>>> >>>> > >
>>> >>>> > > #custom Mode function
>>> >>>> > > Mode <- function(x) {
>>> >>>> > >   ux <- unique(x)
>>> >>>> > >   ux[which.max(tabulate(match(x, ux)))]
>>> >>>> > > }
>>> >>>> > >
>>> >>>> > > I am not sre what is going wrong on my interquartile range
>>> function, it
>>> >>>> > > works on its own outside of ddply()
>>> >>>> > >
>>> >>>> > >         [[alternative HTML version deleted]]
>>> >>>> > >
>>> >>>> > > ______________________________________________
>>> >>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>> >>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>> > > PLEASE do read the posting guide
>>> >>>> > http://www.R-project.org/posting-guide.html
>>> >>>> > > and provide commented, minimal, self-contained, reproducible
>>> code.
>>> >>>> >
>>> >>>>
>>> >>>>         [[alternative HTML version deleted]]
>>> >>>>
>>> >>>> ______________________________________________
>>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>>> PLEASE do read the posting guide
>>> >>>> http://www.R-project.org/posting-guide.html
>>> >>>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>>
>>> >>>
>>> >>>         [[alternative HTML version deleted]]
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From pele.s at yahoo.com  Wed Apr 20 00:59:41 2016
From: pele.s at yahoo.com (pele.s at yahoo.com)
Date: Tue, 19 Apr 2016 22:59:41 +0000 (UTC)
Subject: [R] Creating two new variables conditional on retaining values from
 previous rows
References: <651388086.3057310.1461106781620.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <651388086.3057310.1461106781620.JavaMail.yahoo@mail.yahoo.com>

Hello,

Iam looking for an R solution that can efficiently produce the output shown below. I can produce this easily in SAS with retain statement and a few lines of if-then-else logic, etc.. but I am not find anything similar on the Rforum archives. Below is the logic I am trying to apply to produce the output table below. Thanks in any help!

if the ID is the first ID encountered then group=1 and groupdate=date or else if not first ID and date - previous date > 10 or date - previous group date >10 then group=previous group # + 1 and groupdate = date or else if not first ID and date - previous date <= 10 or date - previous group date<=10 then group=previous group # and groupdate = previous date.

Input:

ID  DATE        ITEM
1   1/1/2014    P1
1   1/15/2014   P2
1   1/20/2014   P3
1   1/22/2014   P4
1   3/10/2015   P5
2   1/13/2015   P1
2   1/20/2015   P2
2   1/28/2015   P3
2   2/28/2015   P4
2   3/20/2015   P5
Desired Output

ID  DATE        ITEM    GROUP   GROUPDATE
1   1/1/2014    P1  1   1/1/2014
1   1/15/2014   P2  2   1/15/2014
1   1/20/2014   P3  2   1/15/2014
1   1/22/2014   P4  2   1/15/2014
1   3/10/2015   P5  3   3/10/2015
2   1/13/2015   P1  1   1/13/2015
2   1/20/2015   P2  1   1/13/2015
2   1/28/2015   P3  2   1/28/2015
2   2/28/2015   P4  3   2/28/2015
2   3/20/2015   P5  4   3/20/2015

Thanks for any help!


From bgunter.4567 at gmail.com  Wed Apr 20 02:07:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Apr 2016 17:07:47 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CA+pG8eP1d8=xV7VOr7Dj+3rumbTCZVFYxw0vU6=dr2OfGUUd4Q@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
	<CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
	<CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>
	<CA+pG8eP1d8=xV7VOr7Dj+3rumbTCZVFYxw0vU6=dr2OfGUUd4Q@mail.gmail.com>
Message-ID: <CAGxFJbQmraMdH-9cw6=fSiF3fdJUddOwgY-9=pB=0iTvKc-VYA@mail.gmail.com>

Well, instead of your functions try:

Mode <- function(x) {
     tabx <- table(x)
     tabx[which.max(tabx)]
}

and use R's IQR function instead of yours.

... so I still don't get why you want to return a character string
instead of a value for the IQR;
and the mode of a sample defined as above is generally a bad estimator
of the mode of the distribution. To say more than that would take me
too far afield. Post on stats.stackexchange.com if you want to know
why (if it's even relevant).

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 19, 2016 at 4:25 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> Hi,
>   Here is what I am doing
>
> notGroupedAll <- ddply(data
>                  ,~groupColumn
>                  ,summarise
>                  ,col1_mean=mean(col1)
>                  ,col2_mode=Mode(col2) #Function I wrote for getting the
> mode shown below
>                  ,col3_Range=myIqr(col3)
>                  )
>
> groupedAll <- ddply(data
>                  ,~groupColumn
>                  ,summarise
>                  ,col1_mean=mean(col1)
>                  ,col2_mode=Mode(col2) #Function I wrote for getting the
> mode shown below
>                  ,col3_Range=Mode(col3)
>                  )
>
> #custom Mode function
> Mode <- function(x) {
>   ux <- unique(x)
>   ux[which.max(tabulate(match(x, ux)))]
>
> #the range function
> myIqr <- function(x) {
>   paste(round(quantile(x,0.375),0),round(quantile(x,0.625),0),sep="-")
> }
>
>
> }
>
>
> Here is what I am doing!! :)
>
>
>
> On Tue, Apr 19, 2016 at 2:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> If you show us, not just tell us about, a self-contained example
>> someone might show you a non-hacky way of getting the job done.
>> (I don't see an argument to plyr::ddply called 'transform'.)
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Tue, Apr 19, 2016 at 12:18 PM, Michael Artz <michaeleartz at gmail.com>
>> wrote:
>>>
>>> Oh thanks for that clarification Bert!  Hope you enjoyed your coffee!  I
>>> ended up just using the transform argument in the ddply function.  It worked
>>> and it repeated, then I called a mode function in another call to ddply that
>>> summarised.  Kinda hacky but oh well!
>>>
>>> On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>>
>>>> ... and I'm getting another cup of coffee...
>>>>
>>>> -- Bert
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>> > NO NO  -- I am wrong! The paste() expression is of course evaluated.
>>>> > It's just that a character string is returned of the form "something -
>>>> > something".
>>>> >
>>>> > I apologize for the confusion.
>>>> >
>>>> > -- Bert
>>>> >
>>>> >
>>>> >
>>>> >
>>>> > Bert Gunter
>>>> >
>>>> > "The trouble with having an open mind is that people keep coming along
>>>> > and sticking things into it."
>>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> >
>>>> >
>>>> > On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> > wrote:
>>>> >> To be precise:
>>>> >>
>>>> >> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>> >>
>>>> >> is an expression that evaluates to a character string:
>>>> >> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
>>>> >>
>>>> >> no matter what the argument of your function, x. Hence
>>>> >>
>>>> >> return(paste(...)) will return this exact character string and never
>>>> >> evaluates x.
>>>> >>
>>>> >>
>>>> >> Cheers,
>>>> >> Bert
>>>> >>
>>>> >>
>>>> >>
>>>> >>
>>>> >>
>>>> >>
>>>> >>
>>>> >>
>>>> >> Bert Gunter
>>>> >>
>>>> >> "The trouble with having an open mind is that people keep coming
>>>> >> along
>>>> >> and sticking things into it."
>>>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> >>
>>>> >>
>>>> >> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
>>>> >> <r-help at r-project.org> wrote:
>>>> >>>> That didn't work Jim!
>>>> >>>
>>>> >>> It always helps to say how the suggestion did not work.  Jim's
>>>> >>> function had a typo in it - was that the problem?  Or did you not
>>>> >>> change the call to ddply to use that function.  Here is something
>>>> >>> that might "work" for you:
>>>> >>>
>>>> >>>  library(plyr)
>>>> >>>
>>>> >>>  data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>>>> >>>  myIqr <- function(x) {
>>>> >>>
>>>> >>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>> >>>  }
>>>> >>>  ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>>>> >>> col1_IQR=stats::IQR(col1))
>>>> >>>  #  groupColumn col1_myIqr col1_IQR
>>>> >>>  #1           1        1-1        0
>>>> >>>  #2           2        2-4        1
>>>> >>>  #3           3      12-24       12
>>>> >>>  #4           4    112-320      208
>>>> >>>  #5           5  2048-8192     6144
>>>> >>>
>>>> >>> The important point is that
>>>> >>>
>>>> >>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>> >>> is not a function, it is an expression.   ddplyr wants functions.
>>>> >>>
>>>> >>>
>>>> >>> Bill Dunlap
>>>> >>> TIBCO Software
>>>> >>> wdunlap tibco.com
>>>> >>>
>>>> >>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz
>>>> >>> <michaeleartz at gmail.com>
>>>> >>> wrote:
>>>> >>>
>>>> >>>> That didn't work Jim!
>>>> >>>>
>>>> >>>> Thanks anyway
>>>> >>>>
>>>> >>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com>
>>>> >>>> wrote:
>>>> >>>>
>>>> >>>> > Hi Michael,
>>>> >>>> > At a guess, try this:
>>>> >>>> >
>>>> >>>> > iqr<-function(x) {
>>>> >>>> >
>>>> >>>>
>>>> >>>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>> >>>> > }
>>>> >>>> >
>>>> >>>> > .col3_Range=iqr(datat$tenure)
>>>> >>>> >
>>>> >>>> > Jim
>>>> >>>> >
>>>> >>>> >
>>>> >>>> >
>>>> >>>> > On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz
>>>> >>>> > <michaeleartz at gmail.com>
>>>> >>>> > wrote:
>>>> >>>> > > Hi,
>>>> >>>> > >   I am trying to show an interquartile range while grouping
>>>> >>>> > > values
>>>> >>>> using
>>>> >>>> > > the function ddply().  So my function call now is like
>>>> >>>> > >
>>>> >>>> > > groupedAll <- ddply(data
>>>> >>>> > >                  ,~groupColumn
>>>> >>>> > >                  ,summarise
>>>> >>>> > >                  ,col1_mean=mean(col1)
>>>> >>>> > >                  ,col2_mode=Mode(col2) #Function I wrote for
>>>> >>>> > > getting
>>>> >>>> the
>>>> >>>> > > mode shown below
>>>> >>>> > >
>>>> >>>> > >
>>>> >>>> > > ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>>>> >>>> > > as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>>>> >>>> > >                  )
>>>> >>>> > >
>>>> >>>> > > #custom Mode function
>>>> >>>> > > Mode <- function(x) {
>>>> >>>> > >   ux <- unique(x)
>>>> >>>> > >   ux[which.max(tabulate(match(x, ux)))]
>>>> >>>> > > }
>>>> >>>> > >
>>>> >>>> > > I am not sre what is going wrong on my interquartile range
>>>> >>>> > > function, it
>>>> >>>> > > works on its own outside of ddply()
>>>> >>>> > >
>>>> >>>> > >         [[alternative HTML version deleted]]
>>>> >>>> > >
>>>> >>>> > > ______________________________________________
>>>> >>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> >>>> > > see
>>>> >>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>> > > PLEASE do read the posting guide
>>>> >>>> > http://www.R-project.org/posting-guide.html
>>>> >>>> > > and provide commented, minimal, self-contained, reproducible
>>>> >>>> > > code.
>>>> >>>> >
>>>> >>>>
>>>> >>>>         [[alternative HTML version deleted]]
>>>> >>>>
>>>> >>>> ______________________________________________
>>>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>> PLEASE do read the posting guide
>>>> >>>> http://www.R-project.org/posting-guide.html
>>>> >>>> and provide commented, minimal, self-contained, reproducible code.
>>>> >>>>
>>>> >>>
>>>> >>>         [[alternative HTML version deleted]]
>>>> >>>
>>>> >>> ______________________________________________
>>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>> PLEASE do read the posting guide
>>>> >>> http://www.R-project.org/posting-guide.html
>>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>


From bgunter.4567 at gmail.com  Wed Apr 20 02:16:09 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Apr 2016 17:16:09 -0700
Subject: [R] Creating two new variables conditional on retaining values
 from previous rows
In-Reply-To: <651388086.3057310.1461106781620.JavaMail.yahoo@mail.yahoo.com>
References: <651388086.3057310.1461106781620.JavaMail.yahoo.ref@mail.yahoo.com>
	<651388086.3057310.1461106781620.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbSQOW3UDGT_q+MQ=iGOcNh4GEUJjZEbx5sxPqKKcbaLTA@mail.gmail.com>

I do not have the tenacity to decipher your logic, but I would suggest
that you go through an R tutorial or two instead of limiting yourself
to R-Help (not R forum?) archives. You probably are going about it
wrongly in R (I suspect you need indexing). In fact, I would guess
that you probably don't want to go about things this way at all in R,
but of course that would require my knowing the underlying problem you
are trying to solve, which I do not.  My point is that you need to
change your programming paradigm and learn R instead of trying to
overlay SAS paradigms. And yup, it requires time and effort to do
this.

Note that there are various "R for SAS programmers" tutorials out
there, which might be helpful, either for your specific query or more
generally.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 19, 2016 at 3:59 PM, pele.s--- via R-help
<r-help at r-project.org> wrote:
> Hello,
>
> Iam looking for an R solution that can efficiently produce the output shown below. I can produce this easily in SAS with retain statement and a few lines of if-then-else logic, etc.. but I am not find anything similar on the Rforum archives. Below is the logic I am trying to apply to produce the output table below. Thanks in any help!
>
> if the ID is the first ID encountered then group=1 and groupdate=date or else if not first ID and date - previous date > 10 or date - previous group date >10 then group=previous group # + 1 and groupdate = date or else if not first ID and date - previous date <= 10 or date - previous group date<=10 then group=previous group # and groupdate = previous date.
>
> Input:
>
> ID  DATE        ITEM
> 1   1/1/2014    P1
> 1   1/15/2014   P2
> 1   1/20/2014   P3
> 1   1/22/2014   P4
> 1   3/10/2015   P5
> 2   1/13/2015   P1
> 2   1/20/2015   P2
> 2   1/28/2015   P3
> 2   2/28/2015   P4
> 2   3/20/2015   P5
> Desired Output
>
> ID  DATE        ITEM    GROUP   GROUPDATE
> 1   1/1/2014    P1  1   1/1/2014
> 1   1/15/2014   P2  2   1/15/2014
> 1   1/20/2014   P3  2   1/15/2014
> 1   1/22/2014   P4  2   1/15/2014
> 1   3/10/2015   P5  3   3/10/2015
> 2   1/13/2015   P1  1   1/13/2015
> 2   1/20/2015   P2  1   1/13/2015
> 2   1/28/2015   P3  2   1/28/2015
> 2   2/28/2015   P4  3   2/28/2015
> 2   3/20/2015   P5  4   3/20/2015
>
> Thanks for any help!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Wed Apr 20 02:24:17 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 19 Apr 2016 19:24:17 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CAGxFJbQmraMdH-9cw6=fSiF3fdJUddOwgY-9=pB=0iTvKc-VYA@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
	<CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
	<CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>
	<CA+pG8eP1d8=xV7VOr7Dj+3rumbTCZVFYxw0vU6=dr2OfGUUd4Q@mail.gmail.com>
	<CAGxFJbQmraMdH-9cw6=fSiF3fdJUddOwgY-9=pB=0iTvKc-VYA@mail.gmail.com>
Message-ID: <CEC3E5FE-E298-4CF4-A454-D7416B8AF937@me.com>

Hi,

Jumping into this thread mainly on the point of the mode of the distribution, while also supporting Bert's comments below on theory.

If the vector 'x' that is being passed to this function is an integer vector, then a tabulation of the integers can yield a 'mode', presuming of course that there is only one unique mode. You may have to decide how you want to handle a multi-modal discrete distribution.

If the vector 'x' is continuous (e.g. contains floating point values), then a tabulation is going to be problematic for a variety of reasons.

In that case, prior discussions on this point, have yielded the following estimation of the mode of a continuous distribution by using:

Mode <- function(x) {
  D <- density(x)
  D$x[which.max(D$y)]
}

where the second line of the function gets you the value of 'x' at the maximum of the density estimate. Of course, there is still the possibility of a multi-modal distribution and the nuances of which kernel is used, etc., etc.

Food for thought.

Regards,

Marc Schwartz


> On Apr 19, 2016, at 7:07 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Well, instead of your functions try:
> 
> Mode <- function(x) {
>     tabx <- table(x)
>     tabx[which.max(tabx)]
> }
> 
> and use R's IQR function instead of yours.
> 
> ... so I still don't get why you want to return a character string
> instead of a value for the IQR;
> and the mode of a sample defined as above is generally a bad estimator
> of the mode of the distribution. To say more than that would take me
> too far afield. Post on stats.stackexchange.com if you want to know
> why (if it's even relevant).
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Apr 19, 2016 at 4:25 PM, Michael Artz <michaeleartz at gmail.com> wrote:
>> Hi,
>>  Here is what I am doing
>> 
>> notGroupedAll <- ddply(data
>>                 ,~groupColumn
>>                 ,summarise
>>                 ,col1_mean=mean(col1)
>>                 ,col2_mode=Mode(col2) #Function I wrote for getting the
>> mode shown below
>>                 ,col3_Range=myIqr(col3)
>>                 )
>> 
>> groupedAll <- ddply(data
>>                 ,~groupColumn
>>                 ,summarise
>>                 ,col1_mean=mean(col1)
>>                 ,col2_mode=Mode(col2) #Function I wrote for getting the
>> mode shown below
>>                 ,col3_Range=Mode(col3)
>>                 )
>> 
>> #custom Mode function
>> Mode <- function(x) {
>>  ux <- unique(x)
>>  ux[which.max(tabulate(match(x, ux)))]
>> 
>> #the range function
>> myIqr <- function(x) {
>>  paste(round(quantile(x,0.375),0),round(quantile(x,0.625),0),sep="-")
>> }
>> 
>> 
>> }
>> 
>> 
>> Here is what I am doing!! :)
>> 
>> 
>> 
>> On Tue, Apr 19, 2016 at 2:57 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> 
>>> If you show us, not just tell us about, a self-contained example
>>> someone might show you a non-hacky way of getting the job done.
>>> (I don't see an argument to plyr::ddply called 'transform'.)
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> On Tue, Apr 19, 2016 at 12:18 PM, Michael Artz <michaeleartz at gmail.com>
>>> wrote:
>>>> 
>>>> Oh thanks for that clarification Bert!  Hope you enjoyed your coffee!  I
>>>> ended up just using the transform argument in the ddply function.  It worked
>>>> and it repeated, then I called a mode function in another call to ddply that
>>>> summarised.  Kinda hacky but oh well!
>>>> 
>>>> On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>>> wrote:
>>>>> 
>>>>> ... and I'm getting another cup of coffee...
>>>>> 
>>>>> -- Bert
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>>> NO NO  -- I am wrong! The paste() expression is of course evaluated.
>>>>>> It's just that a character string is returned of the form "something -
>>>>>> something".
>>>>>> 
>>>>>> I apologize for the confusion.
>>>>>> 
>>>>>> -- Bert
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Bert Gunter
>>>>>> 
>>>>>> "The trouble with having an open mind is that people keep coming along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>> 
>>>>>> 
>>>>>> On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>>> To be precise:
>>>>>>> 
>>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>>>>> 
>>>>>>> is an expression that evaluates to a character string:
>>>>>>> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
>>>>>>> 
>>>>>>> no matter what the argument of your function, x. Hence
>>>>>>> 
>>>>>>> return(paste(...)) will return this exact character string and never
>>>>>>> evaluates x.
>>>>>>> 
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> Bert
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> Bert Gunter
>>>>>>> 
>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>> along
>>>>>>> and sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>> 
>>>>>>> 
>>>>>>> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
>>>>>>> <r-help at r-project.org> wrote:
>>>>>>>>> That didn't work Jim!
>>>>>>>> 
>>>>>>>> It always helps to say how the suggestion did not work.  Jim's
>>>>>>>> function had a typo in it - was that the problem?  Or did you not
>>>>>>>> change the call to ddply to use that function.  Here is something
>>>>>>>> that might "work" for you:
>>>>>>>> 
>>>>>>>> library(plyr)
>>>>>>>> 
>>>>>>>> data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>>>>>>>> myIqr <- function(x) {
>>>>>>>> 
>>>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>>>>>> }
>>>>>>>> ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>>>>>>>> col1_IQR=stats::IQR(col1))
>>>>>>>> #  groupColumn col1_myIqr col1_IQR
>>>>>>>> #1           1        1-1        0
>>>>>>>> #2           2        2-4        1
>>>>>>>> #3           3      12-24       12
>>>>>>>> #4           4    112-320      208
>>>>>>>> #5           5  2048-8192     6144
>>>>>>>> 
>>>>>>>> The important point is that
>>>>>>>> 
>>>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>>>>>> is not a function, it is an expression.   ddplyr wants functions.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Bill Dunlap
>>>>>>>> TIBCO Software
>>>>>>>> wdunlap tibco.com
>>>>>>>> 
>>>>>>>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz
>>>>>>>> <michaeleartz at gmail.com>
>>>>>>>> wrote:
>>>>>>>> 
>>>>>>>>> That didn't work Jim!
>>>>>>>>> 
>>>>>>>>> Thanks anyway
>>>>>>>>> 
>>>>>>>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com>
>>>>>>>>> wrote:
>>>>>>>>> 
>>>>>>>>>> Hi Michael,
>>>>>>>>>> At a guess, try this:
>>>>>>>>>> 
>>>>>>>>>> iqr<-function(x) {
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>>>>>>>>>> }
>>>>>>>>>> 
>>>>>>>>>> .col3_Range=iqr(datat$tenure)
>>>>>>>>>> 
>>>>>>>>>> Jim
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz
>>>>>>>>>> <michaeleartz at gmail.com>
>>>>>>>>>> wrote:
>>>>>>>>>>> Hi,
>>>>>>>>>>>  I am trying to show an interquartile range while grouping
>>>>>>>>>>> values
>>>>>>>>> using
>>>>>>>>>>> the function ddply().  So my function call now is like
>>>>>>>>>>> 
>>>>>>>>>>> groupedAll <- ddply(data
>>>>>>>>>>>                 ,~groupColumn
>>>>>>>>>>>                 ,summarise
>>>>>>>>>>>                 ,col1_mean=mean(col1)
>>>>>>>>>>>                 ,col2_mode=Mode(col2) #Function I wrote for
>>>>>>>>>>> getting
>>>>>>>>> the
>>>>>>>>>>> mode shown below
>>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>>>>>>>>>>> as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>>>>>>>>>>>                 )
>>>>>>>>>>> 
>>>>>>>>>>> #custom Mode function
>>>>>>>>>>> Mode <- function(x) {
>>>>>>>>>>>  ux <- unique(x)
>>>>>>>>>>>  ux[which.max(tabulate(match(x, ux)))]
>>>>>>>>>>> }
>>>>>>>>>>> 
>>>>>>>>>>> I am not sre what is going wrong on my interquartile range
>>>>>>>>>>> function, it
>>>>>>>>>>> works on its own outside of ddply()
>>>>>>>>>>> 
>>>>>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>>>>> 
>>>>>>>>>>> ______________________________________________
>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>>>>>>>>> see
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>>>>>>>>> code.
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>>> 
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>> 
>>>>>>>> 
>>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michaeleartz at gmail.com  Wed Apr 20 02:29:34 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 19 Apr 2016 19:29:34 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CEC3E5FE-E298-4CF4-A454-D7416B8AF937@me.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
	<CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
	<CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>
	<CA+pG8eP1d8=xV7VOr7Dj+3rumbTCZVFYxw0vU6=dr2OfGUUd4Q@mail.gmail.com>
	<CAGxFJbQmraMdH-9cw6=fSiF3fdJUddOwgY-9=pB=0iTvKc-VYA@mail.gmail.com>
	<CEC3E5FE-E298-4CF4-A454-D7416B8AF937@me.com>
Message-ID: <CA+pG8eNxOHYYu8dx6xNXyFyRXDj01DPg3rBDy9MwD2yPkUJRzg@mail.gmail.com>

Again, IQR returns two both a .25 and a .75 value and it failed, which is
why I didn't use it before. Also, the first function just returns tha same
value repeating.  Since they are the same, before the second call, using
the mode function is just a way to grab one value. I could have used
average, min, max, they all would have returned the same thing.

Mike

On Tue, Apr 19, 2016 at 7:24 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> Jumping into this thread mainly on the point of the mode of the
> distribution, while also supporting Bert's comments below on theory.
>
> If the vector 'x' that is being passed to this function is an integer
> vector, then a tabulation of the integers can yield a 'mode', presuming of
> course that there is only one unique mode. You may have to decide how you
> want to handle a multi-modal discrete distribution.
>
> If the vector 'x' is continuous (e.g. contains floating point values),
> then a tabulation is going to be problematic for a variety of reasons.
>
> In that case, prior discussions on this point, have yielded the following
> estimation of the mode of a continuous distribution by using:
>
> Mode <- function(x) {
>   D <- density(x)
>   D$x[which.max(D$y)]
> }
>
> where the second line of the function gets you the value of 'x' at the
> maximum of the density estimate. Of course, there is still the possibility
> of a multi-modal distribution and the nuances of which kernel is used,
> etc., etc.
>
> Food for thought.
>
> Regards,
>
> Marc Schwartz
>
>
> > On Apr 19, 2016, at 7:07 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Well, instead of your functions try:
> >
> > Mode <- function(x) {
> >     tabx <- table(x)
> >     tabx[which.max(tabx)]
> > }
> >
> > and use R's IQR function instead of yours.
> >
> > ... so I still don't get why you want to return a character string
> > instead of a value for the IQR;
> > and the mode of a sample defined as above is generally a bad estimator
> > of the mode of the distribution. To say more than that would take me
> > too far afield. Post on stats.stackexchange.com if you want to know
> > why (if it's even relevant).
> >
> > Cheers,
> > Bert
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Apr 19, 2016 at 4:25 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> >> Hi,
> >>  Here is what I am doing
> >>
> >> notGroupedAll <- ddply(data
> >>                 ,~groupColumn
> >>                 ,summarise
> >>                 ,col1_mean=mean(col1)
> >>                 ,col2_mode=Mode(col2) #Function I wrote for getting the
> >> mode shown below
> >>                 ,col3_Range=myIqr(col3)
> >>                 )
> >>
> >> groupedAll <- ddply(data
> >>                 ,~groupColumn
> >>                 ,summarise
> >>                 ,col1_mean=mean(col1)
> >>                 ,col2_mode=Mode(col2) #Function I wrote for getting the
> >> mode shown below
> >>                 ,col3_Range=Mode(col3)
> >>                 )
> >>
> >> #custom Mode function
> >> Mode <- function(x) {
> >>  ux <- unique(x)
> >>  ux[which.max(tabulate(match(x, ux)))]
> >>
> >> #the range function
> >> myIqr <- function(x) {
> >>  paste(round(quantile(x,0.375),0),round(quantile(x,0.625),0),sep="-")
> >> }
> >>
> >>
> >> }
> >>
> >>
> >> Here is what I am doing!! :)
> >>
> >>
> >>
> >> On Tue, Apr 19, 2016 at 2:57 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
> >>>
> >>> If you show us, not just tell us about, a self-contained example
> >>> someone might show you a non-hacky way of getting the job done.
> >>> (I don't see an argument to plyr::ddply called 'transform'.)
> >>>
> >>> Bill Dunlap
> >>> TIBCO Software
> >>> wdunlap tibco.com
> >>>
> >>> On Tue, Apr 19, 2016 at 12:18 PM, Michael Artz <michaeleartz at gmail.com
> >
> >>> wrote:
> >>>>
> >>>> Oh thanks for that clarification Bert!  Hope you enjoyed your
> coffee!  I
> >>>> ended up just using the transform argument in the ddply function.  It
> worked
> >>>> and it repeated, then I called a mode function in another call to
> ddply that
> >>>> summarised.  Kinda hacky but oh well!
> >>>>
> >>>> On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter <bgunter.4567 at gmail.com
> >
> >>>> wrote:
> >>>>>
> >>>>> ... and I'm getting another cup of coffee...
> >>>>>
> >>>>> -- Bert
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming
> along
> >>>>> and sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>>
> >>>>> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter <
> bgunter.4567 at gmail.com>
> >>>>> wrote:
> >>>>>> NO NO  -- I am wrong! The paste() expression is of course evaluated.
> >>>>>> It's just that a character string is returned of the form
> "something -
> >>>>>> something".
> >>>>>>
> >>>>>> I apologize for the confusion.
> >>>>>>
> >>>>>> -- Bert
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> Bert Gunter
> >>>>>>
> >>>>>> "The trouble with having an open mind is that people keep coming
> along
> >>>>>> and sticking things into it."
> >>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>>
> >>>>>>
> >>>>>> On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter <
> bgunter.4567 at gmail.com>
> >>>>>> wrote:
> >>>>>>> To be precise:
> >>>>>>>
> >>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>>>>>>
> >>>>>>> is an expression that evaluates to a character string:
> >>>>>>> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
> >>>>>>>
> >>>>>>> no matter what the argument of your function, x. Hence
> >>>>>>>
> >>>>>>> return(paste(...)) will return this exact character string and
> never
> >>>>>>> evaluates x.
> >>>>>>>
> >>>>>>>
> >>>>>>> Cheers,
> >>>>>>> Bert
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> Bert Gunter
> >>>>>>>
> >>>>>>> "The trouble with having an open mind is that people keep coming
> >>>>>>> along
> >>>>>>> and sticking things into it."
> >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>>>
> >>>>>>>
> >>>>>>> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
> >>>>>>> <r-help at r-project.org> wrote:
> >>>>>>>>> That didn't work Jim!
> >>>>>>>>
> >>>>>>>> It always helps to say how the suggestion did not work.  Jim's
> >>>>>>>> function had a typo in it - was that the problem?  Or did you not
> >>>>>>>> change the call to ddply to use that function.  Here is something
> >>>>>>>> that might "work" for you:
> >>>>>>>>
> >>>>>>>> library(plyr)
> >>>>>>>>
> >>>>>>>> data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
> >>>>>>>> myIqr <- function(x) {
> >>>>>>>>
> >>>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>>>>>>> }
> >>>>>>>> ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
> >>>>>>>> col1_IQR=stats::IQR(col1))
> >>>>>>>> #  groupColumn col1_myIqr col1_IQR
> >>>>>>>> #1           1        1-1        0
> >>>>>>>> #2           2        2-4        1
> >>>>>>>> #3           3      12-24       12
> >>>>>>>> #4           4    112-320      208
> >>>>>>>> #5           5  2048-8192     6144
> >>>>>>>>
> >>>>>>>> The important point is that
> >>>>>>>>
> >>>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>>>>>>> is not a function, it is an expression.   ddplyr wants functions.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Bill Dunlap
> >>>>>>>> TIBCO Software
> >>>>>>>> wdunlap tibco.com
> >>>>>>>>
> >>>>>>>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz
> >>>>>>>> <michaeleartz at gmail.com>
> >>>>>>>> wrote:
> >>>>>>>>
> >>>>>>>>> That didn't work Jim!
> >>>>>>>>>
> >>>>>>>>> Thanks anyway
> >>>>>>>>>
> >>>>>>>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon <drjimlemon at gmail.com
> >
> >>>>>>>>> wrote:
> >>>>>>>>>
> >>>>>>>>>> Hi Michael,
> >>>>>>>>>> At a guess, try this:
> >>>>>>>>>>
> >>>>>>>>>> iqr<-function(x) {
> >>>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >>>>>>>>>> }
> >>>>>>>>>>
> >>>>>>>>>> .col3_Range=iqr(datat$tenure)
> >>>>>>>>>>
> >>>>>>>>>> Jim
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz
> >>>>>>>>>> <michaeleartz at gmail.com>
> >>>>>>>>>> wrote:
> >>>>>>>>>>> Hi,
> >>>>>>>>>>>  I am trying to show an interquartile range while grouping
> >>>>>>>>>>> values
> >>>>>>>>> using
> >>>>>>>>>>> the function ddply().  So my function call now is like
> >>>>>>>>>>>
> >>>>>>>>>>> groupedAll <- ddply(data
> >>>>>>>>>>>                 ,~groupColumn
> >>>>>>>>>>>                 ,summarise
> >>>>>>>>>>>                 ,col1_mean=mean(col1)
> >>>>>>>>>>>                 ,col2_mode=Mode(col2) #Function I wrote for
> >>>>>>>>>>> getting
> >>>>>>>>> the
> >>>>>>>>>>> mode shown below
> >>>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>>
> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
> >>>>>>>>>>> as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
> >>>>>>>>>>>                 )
> >>>>>>>>>>>
> >>>>>>>>>>> #custom Mode function
> >>>>>>>>>>> Mode <- function(x) {
> >>>>>>>>>>>  ux <- unique(x)
> >>>>>>>>>>>  ux[which.max(tabulate(match(x, ux)))]
> >>>>>>>>>>> }
> >>>>>>>>>>>
> >>>>>>>>>>> I am not sre what is going wrong on my interquartile range
> >>>>>>>>>>> function, it
> >>>>>>>>>>> works on its own outside of ddply()
> >>>>>>>>>>>
> >>>>>>>>>>>        [[alternative HTML version deleted]]
> >>>>>>>>>>>
> >>>>>>>>>>> ______________________________________________
> >>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>>>>>>>>>> see
> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>>>>>>>>>> code.
> >>>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>        [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >>>>>>>>>
> >>>>>>>>
> >>>>>>>>        [[alternative HTML version deleted]]
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Wed Apr 20 03:02:00 2016
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 19 Apr 2016 21:02:00 -0400
Subject: [R] XLConnect Package
Message-ID: <10AE6D56-5238-4EF6-ADA1-8F0F91239C08@gmail.com>

Folks,
I am using the XLConnect package. I can download all the named ranges except a couple that are defined by the Excel function ?Offset?.

For example I have this named range:
   =OFFSET(APA!$A$1,0,0,APA!$K$11,3)

I am pretty sure that this won?t work but I thought I would give it a shot here. 

Thanks for your time,
Best,
KW


From bgunter.4567 at gmail.com  Wed Apr 20 05:53:26 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Apr 2016 20:53:26 -0700
Subject: [R] Interquartile Range
In-Reply-To: <CA+pG8eNxOHYYu8dx6xNXyFyRXDj01DPg3rBDy9MwD2yPkUJRzg@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
	<CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
	<CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>
	<CA+pG8eP1d8=xV7VOr7Dj+3rumbTCZVFYxw0vU6=dr2OfGUUd4Q@mail.gmail.com>
	<CAGxFJbQmraMdH-9cw6=fSiF3fdJUddOwgY-9=pB=0iTvKc-VYA@mail.gmail.com>
	<CEC3E5FE-E298-4CF4-A454-D7416B8AF937@me.com>
	<CA+pG8eNxOHYYu8dx6xNXyFyRXDj01DPg3rBDy9MwD2yPkUJRzg@mail.gmail.com>
Message-ID: <CAGxFJbQYw8Bbe9xrOQFVaVbtw52F3=mYaw9GT-KAqYbW0kT8Vw@mail.gmail.com>

???

IQR returns a single number.

> IQR(rnorm(10))
[1] 1.090168

To your 2nd response:
"I could have used average, min, max, they all would have returned the
same thing., "

I can only respond: huh?? Are all your values identical?

You really need to provide a small reproducible example as requested
by the posting guide -- I certainly don't get it, and I'm done
guessing. Maybe others will see what I am missing and say something
useful. I clearly can't.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 19, 2016 at 5:29 PM, Michael Artz <michaeleartz at gmail.com> wrote:
> Again, IQR returns two both a .25 and a .75 value and it failed, which is
> why I didn't use it before. Also, the first function just returns tha same
> value repeating.  Since they are the same, before the second call, using the
> mode function is just a way to grab one value. I could have used average,
> min, max, they all would have returned the same thing.
>
> Mike
>
> On Tue, Apr 19, 2016 at 7:24 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>
>> Hi,
>>
>> Jumping into this thread mainly on the point of the mode of the
>> distribution, while also supporting Bert's comments below on theory.
>>
>> If the vector 'x' that is being passed to this function is an integer
>> vector, then a tabulation of the integers can yield a 'mode', presuming of
>> course that there is only one unique mode. You may have to decide how you
>> want to handle a multi-modal discrete distribution.
>>
>> If the vector 'x' is continuous (e.g. contains floating point values),
>> then a tabulation is going to be problematic for a variety of reasons.
>>
>> In that case, prior discussions on this point, have yielded the following
>> estimation of the mode of a continuous distribution by using:
>>
>> Mode <- function(x) {
>>   D <- density(x)
>>   D$x[which.max(D$y)]
>> }
>>
>> where the second line of the function gets you the value of 'x' at the
>> maximum of the density estimate. Of course, there is still the possibility
>> of a multi-modal distribution and the nuances of which kernel is used, etc.,
>> etc.
>>
>> Food for thought.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>> > On Apr 19, 2016, at 7:07 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >
>> > Well, instead of your functions try:
>> >
>> > Mode <- function(x) {
>> >     tabx <- table(x)
>> >     tabx[which.max(tabx)]
>> > }
>> >
>> > and use R's IQR function instead of yours.
>> >
>> > ... so I still don't get why you want to return a character string
>> > instead of a value for the IQR;
>> > and the mode of a sample defined as above is generally a bad estimator
>> > of the mode of the distribution. To say more than that would take me
>> > too far afield. Post on stats.stackexchange.com if you want to know
>> > why (if it's even relevant).
>> >
>> > Cheers,
>> > Bert
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> > and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Tue, Apr 19, 2016 at 4:25 PM, Michael Artz <michaeleartz at gmail.com>
>> > wrote:
>> >> Hi,
>> >>  Here is what I am doing
>> >>
>> >> notGroupedAll <- ddply(data
>> >>                 ,~groupColumn
>> >>                 ,summarise
>> >>                 ,col1_mean=mean(col1)
>> >>                 ,col2_mode=Mode(col2) #Function I wrote for getting the
>> >> mode shown below
>> >>                 ,col3_Range=myIqr(col3)
>> >>                 )
>> >>
>> >> groupedAll <- ddply(data
>> >>                 ,~groupColumn
>> >>                 ,summarise
>> >>                 ,col1_mean=mean(col1)
>> >>                 ,col2_mode=Mode(col2) #Function I wrote for getting the
>> >> mode shown below
>> >>                 ,col3_Range=Mode(col3)
>> >>                 )
>> >>
>> >> #custom Mode function
>> >> Mode <- function(x) {
>> >>  ux <- unique(x)
>> >>  ux[which.max(tabulate(match(x, ux)))]
>> >>
>> >> #the range function
>> >> myIqr <- function(x) {
>> >>  paste(round(quantile(x,0.375),0),round(quantile(x,0.625),0),sep="-")
>> >> }
>> >>
>> >>
>> >> }
>> >>
>> >>
>> >> Here is what I am doing!! :)
>> >>
>> >>
>> >>
>> >> On Tue, Apr 19, 2016 at 2:57 PM, William Dunlap <wdunlap at tibco.com>
>> >> wrote:
>> >>>
>> >>> If you show us, not just tell us about, a self-contained example
>> >>> someone might show you a non-hacky way of getting the job done.
>> >>> (I don't see an argument to plyr::ddply called 'transform'.)
>> >>>
>> >>> Bill Dunlap
>> >>> TIBCO Software
>> >>> wdunlap tibco.com
>> >>>
>> >>> On Tue, Apr 19, 2016 at 12:18 PM, Michael Artz
>> >>> <michaeleartz at gmail.com>
>> >>> wrote:
>> >>>>
>> >>>> Oh thanks for that clarification Bert!  Hope you enjoyed your coffee!
>> >>>> I
>> >>>> ended up just using the transform argument in the ddply function.  It
>> >>>> worked
>> >>>> and it repeated, then I called a mode function in another call to
>> >>>> ddply that
>> >>>> summarised.  Kinda hacky but oh well!
>> >>>>
>> >>>> On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter
>> >>>> <bgunter.4567 at gmail.com>
>> >>>> wrote:
>> >>>>>
>> >>>>> ... and I'm getting another cup of coffee...
>> >>>>>
>> >>>>> -- Bert
>> >>>>> Bert Gunter
>> >>>>>
>> >>>>> "The trouble with having an open mind is that people keep coming
>> >>>>> along
>> >>>>> and sticking things into it."
>> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>>>
>> >>>>>
>> >>>>> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter
>> >>>>> <bgunter.4567 at gmail.com>
>> >>>>> wrote:
>> >>>>>> NO NO  -- I am wrong! The paste() expression is of course
>> >>>>>> evaluated.
>> >>>>>> It's just that a character string is returned of the form
>> >>>>>> "something -
>> >>>>>> something".
>> >>>>>>
>> >>>>>> I apologize for the confusion.
>> >>>>>>
>> >>>>>> -- Bert
>> >>>>>>
>> >>>>>>
>> >>>>>>
>> >>>>>>
>> >>>>>> Bert Gunter
>> >>>>>>
>> >>>>>> "The trouble with having an open mind is that people keep coming
>> >>>>>> along
>> >>>>>> and sticking things into it."
>> >>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>>>>
>> >>>>>>
>> >>>>>> On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter
>> >>>>>> <bgunter.4567 at gmail.com>
>> >>>>>> wrote:
>> >>>>>>> To be precise:
>> >>>>>>>
>> >>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>>>>>>
>> >>>>>>> is an expression that evaluates to a character string:
>> >>>>>>> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
>> >>>>>>>
>> >>>>>>> no matter what the argument of your function, x. Hence
>> >>>>>>>
>> >>>>>>> return(paste(...)) will return this exact character string and
>> >>>>>>> never
>> >>>>>>> evaluates x.
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> Cheers,
>> >>>>>>> Bert
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> Bert Gunter
>> >>>>>>>
>> >>>>>>> "The trouble with having an open mind is that people keep coming
>> >>>>>>> along
>> >>>>>>> and sticking things into it."
>> >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
>> >>>>>>> <r-help at r-project.org> wrote:
>> >>>>>>>>> That didn't work Jim!
>> >>>>>>>>
>> >>>>>>>> It always helps to say how the suggestion did not work.  Jim's
>> >>>>>>>> function had a typo in it - was that the problem?  Or did you not
>> >>>>>>>> change the call to ddply to use that function.  Here is something
>> >>>>>>>> that might "work" for you:
>> >>>>>>>>
>> >>>>>>>> library(plyr)
>> >>>>>>>>
>> >>>>>>>> data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
>> >>>>>>>> myIqr <- function(x) {
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>>>>>>> }
>> >>>>>>>> ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
>> >>>>>>>> col1_IQR=stats::IQR(col1))
>> >>>>>>>> #  groupColumn col1_myIqr col1_IQR
>> >>>>>>>> #1           1        1-1        0
>> >>>>>>>> #2           2        2-4        1
>> >>>>>>>> #3           3      12-24       12
>> >>>>>>>> #4           4    112-320      208
>> >>>>>>>> #5           5  2048-8192     6144
>> >>>>>>>>
>> >>>>>>>> The important point is that
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>>>>>>> is not a function, it is an expression.   ddplyr wants functions.
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> Bill Dunlap
>> >>>>>>>> TIBCO Software
>> >>>>>>>> wdunlap tibco.com
>> >>>>>>>>
>> >>>>>>>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz
>> >>>>>>>> <michaeleartz at gmail.com>
>> >>>>>>>> wrote:
>> >>>>>>>>
>> >>>>>>>>> That didn't work Jim!
>> >>>>>>>>>
>> >>>>>>>>> Thanks anyway
>> >>>>>>>>>
>> >>>>>>>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon
>> >>>>>>>>> <drjimlemon at gmail.com>
>> >>>>>>>>> wrote:
>> >>>>>>>>>
>> >>>>>>>>>> Hi Michael,
>> >>>>>>>>>> At a guess, try this:
>> >>>>>>>>>>
>> >>>>>>>>>> iqr<-function(x) {
>> >>>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
>> >>>>>>>>>> }
>> >>>>>>>>>>
>> >>>>>>>>>> .col3_Range=iqr(datat$tenure)
>> >>>>>>>>>>
>> >>>>>>>>>> Jim
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>> On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz
>> >>>>>>>>>> <michaeleartz at gmail.com>
>> >>>>>>>>>> wrote:
>> >>>>>>>>>>> Hi,
>> >>>>>>>>>>>  I am trying to show an interquartile range while grouping
>> >>>>>>>>>>> values
>> >>>>>>>>> using
>> >>>>>>>>>>> the function ddply().  So my function call now is like
>> >>>>>>>>>>>
>> >>>>>>>>>>> groupedAll <- ddply(data
>> >>>>>>>>>>>                 ,~groupColumn
>> >>>>>>>>>>>                 ,summarise
>> >>>>>>>>>>>                 ,col1_mean=mean(col1)
>> >>>>>>>>>>>                 ,col2_mode=Mode(col2) #Function I wrote for
>> >>>>>>>>>>> getting
>> >>>>>>>>> the
>> >>>>>>>>>>> mode shown below
>> >>>>>>>>>>>
>> >>>>>>>>>>>
>> >>>>>>>>>>>
>> >>>>>>>>>>> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
>> >>>>>>>>>>> as.character(round(quantile(data$tenure,c(.75)))), sep = "-")
>> >>>>>>>>>>>                 )
>> >>>>>>>>>>>
>> >>>>>>>>>>> #custom Mode function
>> >>>>>>>>>>> Mode <- function(x) {
>> >>>>>>>>>>>  ux <- unique(x)
>> >>>>>>>>>>>  ux[which.max(tabulate(match(x, ux)))]
>> >>>>>>>>>>> }
>> >>>>>>>>>>>
>> >>>>>>>>>>> I am not sre what is going wrong on my interquartile range
>> >>>>>>>>>>> function, it
>> >>>>>>>>>>> works on its own outside of ddply()
>> >>>>>>>>>>>
>> >>>>>>>>>>>        [[alternative HTML version deleted]]
>> >>>>>>>>>>>
>> >>>>>>>>>>> ______________________________________________
>> >>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >>>>>>>>>>> see
>> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>>>>>>> PLEASE do read the posting guide
>> >>>>>>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> >>>>>>>>>>> code.
>> >>>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>>        [[alternative HTML version deleted]]
>> >>>>>>>>>
>> >>>>>>>>> ______________________________________________
>> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >>>>>>>>> see
>> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>>>>> PLEASE do read the posting guide
>> >>>>>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> >>>>>>>>> code.
>> >>>>>>>>>
>> >>>>>>>>
>> >>>>>>>>        [[alternative HTML version deleted]]
>> >>>>>>>>
>> >>>>>>>> ______________________________________________
>> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>>>> PLEASE do read the posting guide
>> >>>>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>>>> and provide commented, minimal, self-contained, reproducible
>> >>>>>>>> code.
>> >>>>
>> >>>>
>> >>>
>> >>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>


From drjimlemon at gmail.com  Wed Apr 20 06:34:57 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 20 Apr 2016 14:34:57 +1000
Subject: [R] Creating two new variables conditional on retaining values
 from previous rows
In-Reply-To: <651388086.3057310.1461106781620.JavaMail.yahoo@mail.yahoo.com>
References: <651388086.3057310.1461106781620.JavaMail.yahoo.ref@mail.yahoo.com>
	<651388086.3057310.1461106781620.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fV3V6yCK-aoqFzgMrBb1u1LwH4XviivLB9noMGChyitkQ@mail.gmail.com>

Hi pele,
There are probably more elegant ways to do this using some function,
but this might help:

psdat<-read.table(text="ID DATE ITEM
 1   1/1/2014    P1
 1   1/15/2014   P2
 1   1/20/2014   P3
 1   1/22/2014   P4
 1   3/10/2015   P5
 2   1/13/2015   P1
 2   1/20/2015   P2
 2   1/28/2015   P3
 2   2/28/2015   P4
 2   3/20/2015   P5",
 header=TRUE)
psdat$DATE<-as.Date(as.character(psdat$DATE),"%m/%d/%Y")
psdat$GROUP<-1
psdat$GROUPDATE<-psdat$DATE[1]
for(case in 2:dim(psdat)[1]) {
 # start a new ID
 if(lastID != psdat$ID[case-1]) {
  lastID<-psdat$ID[case]
  psdat$GROUP[case]<-1
  psdat$GROUPDATE[case]<-psdat$DATE[case]
 } else {
  if((psdat$DATE[case] - psdat$DATE[case-1]) > 10 ||
   (psdat$DATE[case] - psdat$GROUPDATE[case-1]) > 10) {
   psdat$GROUP[case]<-psdat$GROUP[case-1]+1
   psdat$GROUPDATE[case]<-psdat$DATE[case]
  } else {
   psdat$GROUP[case]<-psdat$GROUP[case-1]
   psdat$GROUPDATE[case]<-psdat$GROUPDATE[case-1]
  }
 }
}
psdat

Jim

On Wed, Apr 20, 2016 at 8:59 AM, pele.s--- via R-help
<r-help at r-project.org> wrote:
> Hello,
>
> Iam looking for an R solution that can efficiently produce the output shown below. I can produce this easily in SAS with retain statement and a few lines of if-then-else logic, etc.. but I am not find anything similar on the Rforum archives. Below is the logic I am trying to apply to produce the output table below. Thanks in any help!
>
> if the ID is the first ID encountered then group=1 and groupdate=date or else if not first ID and date - previous date > 10 or date - previous group date >10 then group=previous group # + 1 and groupdate = date or else if not first ID and date - previous date <= 10 or date - previous group date<=10 then group=previous group # and groupdate = previous date.
>
> Input:
>
> ID  DATE        ITEM
> 1   1/1/2014    P1
> 1   1/15/2014   P2
> 1   1/20/2014   P3
> 1   1/22/2014   P4
> 1   3/10/2015   P5
> 2   1/13/2015   P1
> 2   1/20/2015   P2
> 2   1/28/2015   P3
> 2   2/28/2015   P4
> 2   3/20/2015   P5
> Desired Output
>
> ID  DATE        ITEM    GROUP   GROUPDATE
> 1   1/1/2014    P1  1   1/1/2014
> 1   1/15/2014   P2  2   1/15/2014
> 1   1/20/2014   P3  2   1/15/2014
> 1   1/22/2014   P4  2   1/15/2014
> 1   3/10/2015   P5  3   3/10/2015
> 2   1/13/2015   P1  1   1/13/2015
> 2   1/20/2015   P2  1   1/13/2015
> 2   1/28/2015   P3  2   1/28/2015
> 2   2/28/2015   P4  3   2/28/2015
> 2   3/20/2015   P5  4   3/20/2015
>
> Thanks for any help!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michaeleartz at gmail.com  Wed Apr 20 06:39:53 2016
From: michaeleartz at gmail.com (Michael Artz)
Date: Tue, 19 Apr 2016 23:39:53 -0500
Subject: [R] Interquartile Range
In-Reply-To: <CAGxFJbQYw8Bbe9xrOQFVaVbtw52F3=mYaw9GT-KAqYbW0kT8Vw@mail.gmail.com>
References: <CA+pG8eMpFLnw2P3woRYLxbMS_G2H=A0fXy0ncL4jzOJmym5DpA@mail.gmail.com>
	<CA+8X3fUJkpnJcivmzkAW-8wGp9akouySeCz3jdH68zfBb2oSQA@mail.gmail.com>
	<CA+pG8ePO2NrE34tjCp_oC+v4cDUYkHWGcqHq234JVvSsaFa0Sw@mail.gmail.com>
	<CAF8bMcZ5x5HO3Tp+kpx_GObjsN1OJfRXe2RDR+g-4zvSQKxG9w@mail.gmail.com>
	<CAGxFJbTm2Hz1Nu4H73kG_cf67vEc2Ye5Px6HDZeTA0FbpXqs2w@mail.gmail.com>
	<CAGxFJbRFiBURSZ2L5dEyxYZcBvud3tDNcpYXO-86k0-58m1bYw@mail.gmail.com>
	<CAGxFJbTvTeABRFXHJaznDnq6Pw6jFZ1D_sMzw6=hc+i7LXqUdQ@mail.gmail.com>
	<CA+pG8ePHEpbzbvhtq76qZfD9XNumP+1fTS=vOHiDGbsmJe2Hsg@mail.gmail.com>
	<CAF8bMca=uXEr1pJPJX-x4V9u+aqHhVPFOOK4UP-YaDNcgLASKw@mail.gmail.com>
	<CA+pG8eP1d8=xV7VOr7Dj+3rumbTCZVFYxw0vU6=dr2OfGUUd4Q@mail.gmail.com>
	<CAGxFJbQmraMdH-9cw6=fSiF3fdJUddOwgY-9=pB=0iTvKc-VYA@mail.gmail.com>
	<CEC3E5FE-E298-4CF4-A454-D7416B8AF937@me.com>
	<CA+pG8eNxOHYYu8dx6xNXyFyRXDj01DPg3rBDy9MwD2yPkUJRzg@mail.gmail.com>
	<CAGxFJbQYw8Bbe9xrOQFVaVbtw52F3=mYaw9GT-KAqYbW0kT8Vw@mail.gmail.com>
Message-ID: <CA+pG8ePD1WvO7UxoBVB9FHKJ9wdLna7zFUq4OeYFUPhjDKpgCA@mail.gmail.com>

I already found a solution, you suggested I try to find a non hacky
solution, which was not really my priority. I should have declined
politely, which I will do now. Or, ifyou just want me to post reproducible
code because you are bored or because you like solving problems then let me
know and I will accommodate. You have been helpful and I wouldnt mind in
that case.  Also, IQR was not a help from the beginning. If it supplies one
value, then its not even a candidate to be helpful for my problem. I
already talked about the format i was looking for.  I dont think I violated
any posting guideline, I asked for help, and people pointed me in a
direction and it helped me. Thanks again, I appreciate it.
On Apr 19, 2016 10:53 PM, "Bert Gunter" <bgunter.4567 at gmail.com> wrote:

> ???
>
> IQR returns a single number.
>
> > IQR(rnorm(10))
> [1] 1.090168
>
> To your 2nd response:
> "I could have used average, min, max, they all would have returned the
> same thing., "
>
> I can only respond: huh?? Are all your values identical?
>
> You really need to provide a small reproducible example as requested
> by the posting guide -- I certainly don't get it, and I'm done
> guessing. Maybe others will see what I am missing and say something
> useful. I clearly can't.
>
> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 19, 2016 at 5:29 PM, Michael Artz <michaeleartz at gmail.com>
> wrote:
> > Again, IQR returns two both a .25 and a .75 value and it failed, which is
> > why I didn't use it before. Also, the first function just returns tha
> same
> > value repeating.  Since they are the same, before the second call, using
> the
> > mode function is just a way to grab one value. I could have used average,
> > min, max, they all would have returned the same thing.
> >
> > Mike
> >
> > On Tue, Apr 19, 2016 at 7:24 PM, Marc Schwartz <marc_schwartz at me.com>
> wrote:
> >>
> >> Hi,
> >>
> >> Jumping into this thread mainly on the point of the mode of the
> >> distribution, while also supporting Bert's comments below on theory.
> >>
> >> If the vector 'x' that is being passed to this function is an integer
> >> vector, then a tabulation of the integers can yield a 'mode', presuming
> of
> >> course that there is only one unique mode. You may have to decide how
> you
> >> want to handle a multi-modal discrete distribution.
> >>
> >> If the vector 'x' is continuous (e.g. contains floating point values),
> >> then a tabulation is going to be problematic for a variety of reasons.
> >>
> >> In that case, prior discussions on this point, have yielded the
> following
> >> estimation of the mode of a continuous distribution by using:
> >>
> >> Mode <- function(x) {
> >>   D <- density(x)
> >>   D$x[which.max(D$y)]
> >> }
> >>
> >> where the second line of the function gets you the value of 'x' at the
> >> maximum of the density estimate. Of course, there is still the
> possibility
> >> of a multi-modal distribution and the nuances of which kernel is used,
> etc.,
> >> etc.
> >>
> >> Food for thought.
> >>
> >> Regards,
> >>
> >> Marc Schwartz
> >>
> >>
> >> > On Apr 19, 2016, at 7:07 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >> >
> >> > Well, instead of your functions try:
> >> >
> >> > Mode <- function(x) {
> >> >     tabx <- table(x)
> >> >     tabx[which.max(tabx)]
> >> > }
> >> >
> >> > and use R's IQR function instead of yours.
> >> >
> >> > ... so I still don't get why you want to return a character string
> >> > instead of a value for the IQR;
> >> > and the mode of a sample defined as above is generally a bad estimator
> >> > of the mode of the distribution. To say more than that would take me
> >> > too far afield. Post on stats.stackexchange.com if you want to know
> >> > why (if it's even relevant).
> >> >
> >> > Cheers,
> >> > Bert
> >> > Bert Gunter
> >> >
> >> > "The trouble with having an open mind is that people keep coming along
> >> > and sticking things into it."
> >> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> > On Tue, Apr 19, 2016 at 4:25 PM, Michael Artz <michaeleartz at gmail.com
> >
> >> > wrote:
> >> >> Hi,
> >> >>  Here is what I am doing
> >> >>
> >> >> notGroupedAll <- ddply(data
> >> >>                 ,~groupColumn
> >> >>                 ,summarise
> >> >>                 ,col1_mean=mean(col1)
> >> >>                 ,col2_mode=Mode(col2) #Function I wrote for getting
> the
> >> >> mode shown below
> >> >>                 ,col3_Range=myIqr(col3)
> >> >>                 )
> >> >>
> >> >> groupedAll <- ddply(data
> >> >>                 ,~groupColumn
> >> >>                 ,summarise
> >> >>                 ,col1_mean=mean(col1)
> >> >>                 ,col2_mode=Mode(col2) #Function I wrote for getting
> the
> >> >> mode shown below
> >> >>                 ,col3_Range=Mode(col3)
> >> >>                 )
> >> >>
> >> >> #custom Mode function
> >> >> Mode <- function(x) {
> >> >>  ux <- unique(x)
> >> >>  ux[which.max(tabulate(match(x, ux)))]
> >> >>
> >> >> #the range function
> >> >> myIqr <- function(x) {
> >> >>  paste(round(quantile(x,0.375),0),round(quantile(x,0.625),0),sep="-")
> >> >> }
> >> >>
> >> >>
> >> >> }
> >> >>
> >> >>
> >> >> Here is what I am doing!! :)
> >> >>
> >> >>
> >> >>
> >> >> On Tue, Apr 19, 2016 at 2:57 PM, William Dunlap <wdunlap at tibco.com>
> >> >> wrote:
> >> >>>
> >> >>> If you show us, not just tell us about, a self-contained example
> >> >>> someone might show you a non-hacky way of getting the job done.
> >> >>> (I don't see an argument to plyr::ddply called 'transform'.)
> >> >>>
> >> >>> Bill Dunlap
> >> >>> TIBCO Software
> >> >>> wdunlap tibco.com
> >> >>>
> >> >>> On Tue, Apr 19, 2016 at 12:18 PM, Michael Artz
> >> >>> <michaeleartz at gmail.com>
> >> >>> wrote:
> >> >>>>
> >> >>>> Oh thanks for that clarification Bert!  Hope you enjoyed your
> coffee!
> >> >>>> I
> >> >>>> ended up just using the transform argument in the ddply function.
> It
> >> >>>> worked
> >> >>>> and it repeated, then I called a mode function in another call to
> >> >>>> ddply that
> >> >>>> summarised.  Kinda hacky but oh well!
> >> >>>>
> >> >>>> On Tue, Apr 19, 2016 at 12:31 PM, Bert Gunter
> >> >>>> <bgunter.4567 at gmail.com>
> >> >>>> wrote:
> >> >>>>>
> >> >>>>> ... and I'm getting another cup of coffee...
> >> >>>>>
> >> >>>>> -- Bert
> >> >>>>> Bert Gunter
> >> >>>>>
> >> >>>>> "The trouble with having an open mind is that people keep coming
> >> >>>>> along
> >> >>>>> and sticking things into it."
> >> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>>>>
> >> >>>>>
> >> >>>>> On Tue, Apr 19, 2016 at 10:30 AM, Bert Gunter
> >> >>>>> <bgunter.4567 at gmail.com>
> >> >>>>> wrote:
> >> >>>>>> NO NO  -- I am wrong! The paste() expression is of course
> >> >>>>>> evaluated.
> >> >>>>>> It's just that a character string is returned of the form
> >> >>>>>> "something -
> >> >>>>>> something".
> >> >>>>>>
> >> >>>>>> I apologize for the confusion.
> >> >>>>>>
> >> >>>>>> -- Bert
> >> >>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> Bert Gunter
> >> >>>>>>
> >> >>>>>> "The trouble with having an open mind is that people keep coming
> >> >>>>>> along
> >> >>>>>> and sticking things into it."
> >> >>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> )
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> On Tue, Apr 19, 2016 at 10:25 AM, Bert Gunter
> >> >>>>>> <bgunter.4567 at gmail.com>
> >> >>>>>> wrote:
> >> >>>>>>> To be precise:
> >> >>>>>>>
> >> >>>>>>>
> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >> >>>>>>>
> >> >>>>>>> is an expression that evaluates to a character string:
> >> >>>>>>> "round(quantile(x,.25),0) - round(quantile(x,0.75),0)"
> >> >>>>>>>
> >> >>>>>>> no matter what the argument of your function, x. Hence
> >> >>>>>>>
> >> >>>>>>> return(paste(...)) will return this exact character string and
> >> >>>>>>> never
> >> >>>>>>> evaluates x.
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>> Cheers,
> >> >>>>>>> Bert
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>> Bert Gunter
> >> >>>>>>>
> >> >>>>>>> "The trouble with having an open mind is that people keep coming
> >> >>>>>>> along
> >> >>>>>>> and sticking things into it."
> >> >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
> strip )
> >> >>>>>>>
> >> >>>>>>>
> >> >>>>>>> On Tue, Apr 19, 2016 at 8:34 AM, William Dunlap via R-help
> >> >>>>>>> <r-help at r-project.org> wrote:
> >> >>>>>>>>> That didn't work Jim!
> >> >>>>>>>>
> >> >>>>>>>> It always helps to say how the suggestion did not work.  Jim's
> >> >>>>>>>> function had a typo in it - was that the problem?  Or did you
> not
> >> >>>>>>>> change the call to ddply to use that function.  Here is
> something
> >> >>>>>>>> that might "work" for you:
> >> >>>>>>>>
> >> >>>>>>>> library(plyr)
> >> >>>>>>>>
> >> >>>>>>>> data <- data.frame(groupColumn=rep(1:5,1:5), col1=2^(0:14))
> >> >>>>>>>> myIqr <- function(x) {
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>
> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >> >>>>>>>> }
> >> >>>>>>>> ddply(data, ~groupColumn, summarise, col1_myIqr=myIqr(col1),
> >> >>>>>>>> col1_IQR=stats::IQR(col1))
> >> >>>>>>>> #  groupColumn col1_myIqr col1_IQR
> >> >>>>>>>> #1           1        1-1        0
> >> >>>>>>>> #2           2        2-4        1
> >> >>>>>>>> #3           3      12-24       12
> >> >>>>>>>> #4           4    112-320      208
> >> >>>>>>>> #5           5  2048-8192     6144
> >> >>>>>>>>
> >> >>>>>>>> The important point is that
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>
> paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >> >>>>>>>> is not a function, it is an expression.   ddplyr wants
> functions.
> >> >>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>> Bill Dunlap
> >> >>>>>>>> TIBCO Software
> >> >>>>>>>> wdunlap tibco.com
> >> >>>>>>>>
> >> >>>>>>>> On Tue, Apr 19, 2016 at 7:56 AM, Michael Artz
> >> >>>>>>>> <michaeleartz at gmail.com>
> >> >>>>>>>> wrote:
> >> >>>>>>>>
> >> >>>>>>>>> That didn't work Jim!
> >> >>>>>>>>>
> >> >>>>>>>>> Thanks anyway
> >> >>>>>>>>>
> >> >>>>>>>>> On Mon, Apr 18, 2016 at 9:02 PM, Jim Lemon
> >> >>>>>>>>> <drjimlemon at gmail.com>
> >> >>>>>>>>> wrote:
> >> >>>>>>>>>
> >> >>>>>>>>>> Hi Michael,
> >> >>>>>>>>>> At a guess, try this:
> >> >>>>>>>>>>
> >> >>>>>>>>>> iqr<-function(x) {
> >> >>>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>
> return(paste(round(quantile(x,0.25),0),round(quantile(x,0.75),0),sep="-")
> >> >>>>>>>>>> }
> >> >>>>>>>>>>
> >> >>>>>>>>>> .col3_Range=iqr(datat$tenure)
> >> >>>>>>>>>>
> >> >>>>>>>>>> Jim
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>>
> >> >>>>>>>>>> On Tue, Apr 19, 2016 at 11:15 AM, Michael Artz
> >> >>>>>>>>>> <michaeleartz at gmail.com>
> >> >>>>>>>>>> wrote:
> >> >>>>>>>>>>> Hi,
> >> >>>>>>>>>>>  I am trying to show an interquartile range while grouping
> >> >>>>>>>>>>> values
> >> >>>>>>>>> using
> >> >>>>>>>>>>> the function ddply().  So my function call now is like
> >> >>>>>>>>>>>
> >> >>>>>>>>>>> groupedAll <- ddply(data
> >> >>>>>>>>>>>                 ,~groupColumn
> >> >>>>>>>>>>>                 ,summarise
> >> >>>>>>>>>>>                 ,col1_mean=mean(col1)
> >> >>>>>>>>>>>                 ,col2_mode=Mode(col2) #Function I wrote for
> >> >>>>>>>>>>> getting
> >> >>>>>>>>> the
> >> >>>>>>>>>>> mode shown below
> >> >>>>>>>>>>>
> >> >>>>>>>>>>>
> >> >>>>>>>>>>>
> >> >>>>>>>>>>>
> ,col3_Range=paste(as.character(round(quantile(datat$tenure,c(.25)))),
> >> >>>>>>>>>>> as.character(round(quantile(data$tenure,c(.75)))), sep =
> "-")
> >> >>>>>>>>>>>                 )
> >> >>>>>>>>>>>
> >> >>>>>>>>>>> #custom Mode function
> >> >>>>>>>>>>> Mode <- function(x) {
> >> >>>>>>>>>>>  ux <- unique(x)
> >> >>>>>>>>>>>  ux[which.max(tabulate(match(x, ux)))]
> >> >>>>>>>>>>> }
> >> >>>>>>>>>>>
> >> >>>>>>>>>>> I am not sre what is going wrong on my interquartile range
> >> >>>>>>>>>>> function, it
> >> >>>>>>>>>>> works on its own outside of ddply()
> >> >>>>>>>>>>>
> >> >>>>>>>>>>>        [[alternative HTML version deleted]]
> >> >>>>>>>>>>>
> >> >>>>>>>>>>> ______________________________________________
> >> >>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more,
> >> >>>>>>>>>>> see
> >> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>>>>>>>> PLEASE do read the posting guide
> >> >>>>>>>>>> http://www.R-project.org/posting-guide.html
> >> >>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >> >>>>>>>>>>> code.
> >> >>>>>>>>>>
> >> >>>>>>>>>
> >> >>>>>>>>>        [[alternative HTML version deleted]]
> >> >>>>>>>>>
> >> >>>>>>>>> ______________________________________________
> >> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >>>>>>>>> see
> >> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>>>>>> PLEASE do read the posting guide
> >> >>>>>>>>> http://www.R-project.org/posting-guide.html
> >> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >> >>>>>>>>> code.
> >> >>>>>>>>>
> >> >>>>>>>>
> >> >>>>>>>>        [[alternative HTML version deleted]]
> >> >>>>>>>>
> >> >>>>>>>> ______________________________________________
> >> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>>>>> PLEASE do read the posting guide
> >> >>>>>>>> http://www.R-project.org/posting-guide.html
> >> >>>>>>>> and provide commented, minimal, self-contained, reproducible
> >> >>>>>>>> code.
> >> >>>>
> >> >>>>
> >> >>>
> >> >>
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>

	[[alternative HTML version deleted]]


From evan.kransdorf at gmail.com  Wed Apr 20 06:55:11 2016
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Tue, 19 Apr 2016 21:55:11 -0700
Subject: [R] UpSetR
Message-ID: <CAKZWb7dA2cKFXDoR5s+DMAd8G1WPQV3UsFTyttLpynoEbOgvWA@mail.gmail.com>

Hello,

Does anyone use UpSetR for set visualization?

I am wanting to re-order the sets in the diagram.

Thanks, Evan

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Apr 20 07:48:41 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 20 Apr 2016 05:48:41 +0000
Subject: [R] simulation in R
Message-ID: <BY2PR13MB0454E407FACEFDF06A2D8408FA6D0@BY2PR13MB0454.namprd13.prod.outlook.com>

Hi R user,
Would you mind to help me to find the range with stochastic events? For example,

daT<-structure(list(sn = 1:14, growthrate = c(0.5, 0.6, 0.7, 0.99,
0.1, 0.3, 0.4, 0.5, 0.5, 0.2, 0.1, 0.4, 0.3, 0.43)), .Names = c("sn",
"growthrate"), class = "data.frame", row.names = c(NA, -14L))

I want to find the ranges of growth rate of the above data using Mote corle simulation (9999 times) under three conditions:
1. very drought ( in that condition growth will not be more than 0.5). [what would be the range (max, min ) of the growth rate for this scenario)
2. no constraints of  food (growth will be 1 or 100%) (what would be the range (max,min) of growth rate in this scenario?).
3. Control (as it is) (Range??, max.min)

I tried to find whether some one had same problem but I could not find it, is it too complicated to write the code in R for this example? your help will be highly appreciated.

Sincerely,


KG



	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Apr 20 08:06:06 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 20 Apr 2016 06:06:06 +0000
Subject: [R] simulation in R
In-Reply-To: <BY2PR13MB0454E407FACEFDF06A2D8408FA6D0@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454E407FACEFDF06A2D8408FA6D0@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <BY2PR13MB0454F9CBDF0B0A8B5E3A3163FA6D0@BY2PR13MB0454.namprd13.prod.outlook.com>

I realized that there was a typo error. I mean "Monte Carlo Simulation"

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Kristi Glover <kristi.glover at hotmail.com>
Sent: April 19, 2016 11:48 PM
To: R-help
Subject: [R] simulation in R

Hi R user,
Would you mind to help me to find the range with stochastic events? For example,

daT<-structure(list(sn = 1:14, growthrate = c(0.5, 0.6, 0.7, 0.99,
0.1, 0.3, 0.4, 0.5, 0.5, 0.2, 0.1, 0.4, 0.3, 0.43)), .Names = c("sn",
"growthrate"), class = "data.frame", row.names = c(NA, -14L))

I want to find the ranges of growth rate of the above data using Mote corle simulation (9999 times) under three conditions:
1. very drought ( in that condition growth will not be more than 0.5). [what would be the range (max, min ) of the growth rate for this scenario)
2. no constraints of  food (growth will be 1 or 100%) (what would be the range (max,min) of growth rate in this scenario?).
3. Control (as it is) (Range??, max.min)

I tried to find whether some one had same problem but I could not find it, is it too complicated to write the code in R for this example? your help will be highly appreciated.

Sincerely,


KG



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From lorenzo.isella at gmail.com  Wed Apr 20 08:56:38 2016
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Wed, 20 Apr 2016 08:56:38 +0200
Subject: [R] Problem with X11
In-Reply-To: <CAKmUXV8PNsTLThE+mRfQP038Fv7w=0QUqHsg8t6g+1VLsZ8W1Q@mail.gmail.com>
References: <20160419152337.GA3547@localhost.localdomain>
	<CAKmUXV8PNsTLThE+mRfQP038Fv7w=0QUqHsg8t6g+1VLsZ8W1Q@mail.gmail.com>
Message-ID: <20160420065638.GA3250@localhost.localdomain>

Hello!
Today on debian testing R 3.2.5 was delivered among the updates.
The X11 problem is no longer there.
Cheers

Lorenzo

On Tue, Apr 19, 2016 at 02:28:44PM -0400, Tom Wright wrote:
>I don't have my debian box available so can't confirm. But I would try
>$apt-get install libpng
>
>On Tue, Apr 19, 2016 at 11:23 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
>wrote:
>
>> Dear All,
>> I have never had this problem before. I run debian testing on my box
>> and I have recently update my R environment.
>> Now, see what happens when I try the most trivial of all plots
>>
>> plot(seq(22))
>>>
>> Error in (function (display = "", width, height, pointsize, gamma, bg,
>> :
>>  X11 module cannot be loaded
>>  In addition: Warning message:
>>  In (function (display = "", width, height, pointsize, gamma, bg,  :
>>    unable to load shared object '/usr/lib/R/modules//R_X11.so':
>>      /usr/lib/x86_64-linux-gnu/libpng12.so.0: version `PNG12_0' not
>>      found (required by /usr/lib/R/modules//R_X11.so)
>>
>> and this is my sessionInfo()
>>
>> sessionInfo()
>>>
>> R version 3.2.4 Revised (2016-03-16 r70336)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Debian GNU/Linux stretch/sid
>>
>> locale:
>> [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>>  [3] LC_TIME=en_GB.utf8        LC_COLLATE=en_GB.utf8
>>   [5] LC_MONETARY=en_GB.utf8    LC_MESSAGES=en_GB.utf8
>>    [7] LC_PAPER=en_GB.utf8       LC_NAME=C
>>     [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>     [11] LC_MEASUREMENT=en_GB.utf8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>> Anybody understands what is going on here?
>> Regards
>>
>> Lorenzo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From maechler at stat.math.ethz.ch  Wed Apr 20 10:25:11 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 20 Apr 2016 10:25:11 +0200
Subject: [R] Matrix: How create a _row-oriented_ sparse Matrix
	(=dgRMatrix)?
In-Reply-To: <CAFDcVCRmwh6H63oZCJORdKF6fY304XDZWgLNg6L8fcdkj+qXpA@mail.gmail.com>
References: <CAFDcVCRmwh6H63oZCJORdKF6fY304XDZWgLNg6L8fcdkj+qXpA@mail.gmail.com>
Message-ID: <22295.15591.767816.546202@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Tue, 19 Apr 2016 14:04:11 -0700 writes:

    > Using the Matrix package, how can I create a row-oriented sparse
    > Matrix from scratch populated with some data?  By default a
    > column-oriented one is created and I'm aware of the note that the
    > package is optimized for column-oriented ones, but I'm only interested
    > in using it for holding my sparse row-oriented data and doing basic
    > subsetting by rows (even using drop=FALSE).

    > Here is what I get when I set up a column-oriented sparse Matrix:

    >> Cc <- Matrix(0, nrow=5, ncol=5, sparse=TRUE)
    >> Cc[1:3,1] <- 1

A general ("teaching") remark :
The above use of Matrix() is seen in many places, and is fine
for small matrices and the case where you only use the `[<-`
method very few times (as above).
Also using  Matrix()  is nice when being introduced to using the
Matrix package.

However, for efficience in non-small cases, do use

   sparseMatrix()

directly to construct sparse matrices.


    >> Cc
    > 5 x 5 sparse Matrix of class "dgCMatrix"

    > [1,] 1 . . . .
    > [2,] 1 . . . .
    > [3,] 1 . . . .
    > [4,] . . . . .
    > [5,] . . . . .
    >> str(Cc)
    > Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
    > ..@ i       : int [1:3] 0 1 2
    > ..@ p       : int [1:6] 0 3 3 3 3 3
    > ..@ Dim     : int [1:2] 5 5
    > ..@ Dimnames:List of 2
    > .. ..$ : NULL
    > .. ..$ : NULL
    > ..@ x       : num [1:3] 1 1 1
    > ..@ factors : list()

    > When I try to do the analogue for a row-oriented matrix, I get a
    > "dgTMatrix", whereas I would expect a "dgRMatrix":

    >> Cr <- Matrix(0, nrow=5, ncol=5, sparse=TRUE)
    >> Cr <- as(Cr, "dsRMatrix")
    >> Cr[1,1:3] <- 1
    >> Cr
    > 5 x 5 sparse Matrix of class "dgTMatrix"

    > [1,] 1 1 1 . .
    > [2,] . . . . .
    > [3,] . . . . .
    > [4,] . . . . .
    > [5,] . . . . .

The reason for the above behavior has been

a) efficiency.  All the subassignment ( `[<-` ) methods for
   "RsparseMatrix" objects (of which "dsRMatrix" is a special case)
   are implemented via  TsparseMatrix.
b) because of the general attitude that Csparse (and Tsparse to
   some extent) are well supported in Matrix,
   and e.g. further operations on Rsparse matrices would *again*
   go via T* or C* sparse ones, I had decided to keep things Tsparse.

[...]

    > Trying with explicit coercion does not work:

    >> as(Cc, "dgRMatrix")
    > Error in as(Cc, "dgRMatrix") :
    > no method or default for coercing "dgCMatrix" to "dgRMatrix"

    >> as(Cr, "dgRMatrix")
    > Error in as(Cr, "dgRMatrix") :
    > no method or default for coercing "dgTMatrix" to "dgRMatrix"

The general philosophy in 'Matrix' with all the class
hierarchies and the many specific classes has been to allow and
foster coercing to abstract super classes,
i.e, to  "dMatrix"  or "generalMatrix", "triangularMatrix", or
then "denseMatrix", "sparseMatrix", "CsparseMatrix" or
"RsparseMatrix", etc

So in the above  as(*, "RsparseMatrix")   should work always.


As a summary, in other words,  for what you want,

   as(sparseMatrix(.....), "RsparseMatrix")

should give you what you want reliably and efficiently.


    > Am I doing some wrong here?  Or is this what means that the package is
    > optimized for the column-oriented representation and I shouldn't
    > really work with row-oriented ones?  I'm really only interested in
    > access to efficient Cr[row,,drop=FALSE] subsetting (and a small memory
    > footprint).

{ though you could equivalently use   Cc[,row, drop=FALSE]
  with a CsparseMatrix Cc := t(Cr),
  couldn't you ?
}


Martin Maechler  (maintainer of 'Matrix')
ETH Zurich


From dpv at gmx.ch  Wed Apr 20 13:38:53 2016
From: dpv at gmx.ch (Gaston)
Date: Wed, 20 Apr 2016 13:38:53 +0200
Subject: [R] Merge sort
In-Reply-To: <5716A86C.4050000@gmail.com>
References: <57168975.3030708@gmx.ch> <5716A86C.4050000@gmail.com>
Message-ID: <57176A4D.4090509@gmx.ch>

I indeed used is.na() to check length, as I was not sure weather 
lenght() was a simple query or would go through the whole vector to 
count the elements.

So to sum up, function calls are expensive, therefore recursion should 
be avoided, and growing the size of a vector (which is probably 
reassigning and copying?) is also expensive.

Thank you for your help!



On 04/19/2016 11:51 PM, Duncan Murdoch wrote:
> On 19/04/2016 3:39 PM, Gaston wrote:
>> Hello everyone,
>>
>> I am learning R since recently, and as a small exercise I wanted to
>> write a recursive mergesort. I was extremely surprised to discover that
>> my sorting, although operational, is deeply inefficient in time. Here is
>> my code :
>>
>>> merge <- function(x,y){
>>>    if (is.na(x[1])) return(y)
>>>    else if (is.na(y[1])) return(x)
>>>    else if (x[1]<y[1]) return(c(x[1],merge(x[-1],y)))
>>>    else return(c(y[1],merge(x,y[-1])))
>>> }
>>>
>>> division <- function(x){
>>>    if (is.na(x[3])) return(cbind(x[1],x[2]))
>>>    else
>>> return(cbind(c(x[1],division(x[-c(1,2)])[,1]),c(x[2],division(x[-c(1,2)])[,2]))) 
>>>
>>> }
>>>
>>> mergesort <- function(x){
>>>    if (is.na(x[2])) return(x)
>>>    else{
>>>      print(x)
>>>      t=division(x)
>>>      return(merge(mergesort(t[,1]),mergesort(t[,2])))
>>>    }
>>> }
>>
>> I tried my best to write it "the R-way", but apparently I failed. I
>> suppose some of the functions I used are quite heavy. I would be
>> grateful if you could give a hint on how to change that!
>>
>> I hope I made myself clear and wish you a nice day,
>
> Your use of is.na() looks strange.  I don't understand why you are 
> testing element 2 in mergesort(), and element 1 in merge(), and 
> element 3 in division.  Are you using it to test the length?  It's 
> better to use the length() function for that.
>
> The division() function returns a matrix.  It would make more R-sense 
> to return a list containing the two parts, because they might not be 
> the same length.
>
> Generally speaking, function calls are expensive in R, so the 
> recursive merge you're using looks like it would be the bottleneck.  
> You'd almost certainly be better off to allocate something of 
> length(x) + length(y), and do the assignments in a loop.
>
> Here's a merge sort I wrote as an illustration in a class.  It's 
> designed for clarity rather than speed, but I'd guess it would be 
> faster than yours:
>
> mergesort <- function(x) {
>
>   n <- length(x)
>   if (n < 2) return(x)
>
>   # split x into two pieces of approximately equal size, x1 and x2
>
>   x1 <- x[1:(n %/% 2)]
>   x2 <- x[(n %/% 2 + 1):n]
>
>   # sort each of the pieces
>   x1 <- mergesort(x1)
>   x2 <- mergesort(x2)
>
>   # merge them back together
>   result <- c()
>   i <- 0
>   while (length(x1) > 0 && length(x2) > 0) {
>     # compare the first values
>     if (x1[1] < x2[1]) {
>       result[i + 1] <- x1[1]
>       x1 <- x1[-1]
>     } else {
>       result[i + 1] <- x2[1]
>       x2 <- x2[-1]
>     }
>     i <- i + 1
>   }
>
>   # put the smaller one into the result
>   # delete it from whichever vector it came from
>   # repeat until one of x1 or x2 is empty
>   # copy both vectors (one is empty!) onto the end of the results
>   result <- c(result, x1, x2)
>   result
> }
>
> If I were going for speed, I wouldn't modify the x1 and x2 vectors, 
> and I'd pre-allocate result to the appropriate length, rather than 
> growing it in the while loop.  But that was a different class!
>
> Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Apr 20 14:02:53 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 Apr 2016 08:02:53 -0400
Subject: [R] Merge sort
In-Reply-To: <57176A4D.4090509@gmx.ch>
References: <57168975.3030708@gmx.ch> <5716A86C.4050000@gmail.com>
	<57176A4D.4090509@gmx.ch>
Message-ID: <57176FED.5070400@gmail.com>

On 20/04/2016 7:38 AM, Gaston wrote:
> I indeed used is.na() to check length, as I was not sure weather
> lenght() was a simple query or would go through the whole vector to
> count the elements.

length() is a simple query, and is very fast.  The other problem in your 
approach (which may not be a problem with your current data) is that NA 
is commonly used as an element of a vector to represent a missing value.

>
> So to sum up, function calls are expensive, therefore recursion should
> be avoided, and growing the size of a vector (which is probably
> reassigning and copying?) is also expensive.

"Avoided" may be too strong:  speed isn't always a concern, sometimes 
clarity is more important.  Growing vectors is definitely expensive.

Duncan Murdoch

>
> Thank you for your help!
>
>
>
> On 04/19/2016 11:51 PM, Duncan Murdoch wrote:
>> On 19/04/2016 3:39 PM, Gaston wrote:
>>> Hello everyone,
>>>
>>> I am learning R since recently, and as a small exercise I wanted to
>>> write a recursive mergesort. I was extremely surprised to discover that
>>> my sorting, although operational, is deeply inefficient in time. Here is
>>> my code :
>>>
>>>> merge <- function(x,y){
>>>>     if (is.na(x[1])) return(y)
>>>>     else if (is.na(y[1])) return(x)
>>>>     else if (x[1]<y[1]) return(c(x[1],merge(x[-1],y)))
>>>>     else return(c(y[1],merge(x,y[-1])))
>>>> }
>>>>
>>>> division <- function(x){
>>>>     if (is.na(x[3])) return(cbind(x[1],x[2]))
>>>>     else
>>>> return(cbind(c(x[1],division(x[-c(1,2)])[,1]),c(x[2],division(x[-c(1,2)])[,2])))
>>>>
>>>> }
>>>>
>>>> mergesort <- function(x){
>>>>     if (is.na(x[2])) return(x)
>>>>     else{
>>>>       print(x)
>>>>       t=division(x)
>>>>       return(merge(mergesort(t[,1]),mergesort(t[,2])))
>>>>     }
>>>> }
>>>
>>> I tried my best to write it "the R-way", but apparently I failed. I
>>> suppose some of the functions I used are quite heavy. I would be
>>> grateful if you could give a hint on how to change that!
>>>
>>> I hope I made myself clear and wish you a nice day,
>>
>> Your use of is.na() looks strange.  I don't understand why you are
>> testing element 2 in mergesort(), and element 1 in merge(), and
>> element 3 in division.  Are you using it to test the length?  It's
>> better to use the length() function for that.
>>
>> The division() function returns a matrix.  It would make more R-sense
>> to return a list containing the two parts, because they might not be
>> the same length.
>>
>> Generally speaking, function calls are expensive in R, so the
>> recursive merge you're using looks like it would be the bottleneck.
>> You'd almost certainly be better off to allocate something of
>> length(x) + length(y), and do the assignments in a loop.
>>
>> Here's a merge sort I wrote as an illustration in a class.  It's
>> designed for clarity rather than speed, but I'd guess it would be
>> faster than yours:
>>
>> mergesort <- function(x) {
>>
>>    n <- length(x)
>>    if (n < 2) return(x)
>>
>>    # split x into two pieces of approximately equal size, x1 and x2
>>
>>    x1 <- x[1:(n %/% 2)]
>>    x2 <- x[(n %/% 2 + 1):n]
>>
>>    # sort each of the pieces
>>    x1 <- mergesort(x1)
>>    x2 <- mergesort(x2)
>>
>>    # merge them back together
>>    result <- c()
>>    i <- 0
>>    while (length(x1) > 0 && length(x2) > 0) {
>>      # compare the first values
>>      if (x1[1] < x2[1]) {
>>        result[i + 1] <- x1[1]
>>        x1 <- x1[-1]
>>      } else {
>>        result[i + 1] <- x2[1]
>>        x2 <- x2[-1]
>>      }
>>      i <- i + 1
>>    }
>>
>>    # put the smaller one into the result
>>    # delete it from whichever vector it came from
>>    # repeat until one of x1 or x2 is empty
>>    # copy both vectors (one is empty!) onto the end of the results
>>    result <- c(result, x1, x2)
>>    result
>> }
>>
>> If I were going for speed, I wouldn't modify the x1 and x2 vectors,
>> and I'd pre-allocate result to the appropriate length, rather than
>> growing it in the while loop.  But that was a different class!
>>
>> Duncan Murdoch
>


From srivibish at gmail.com  Wed Apr 20 07:03:30 2016
From: srivibish at gmail.com (sri vathsan)
Date: Wed, 20 Apr 2016 10:33:30 +0530
Subject: [R] Data reshaping with conditions
Message-ID: <CAGO7QoM0VUEobcEcVsR5uWuzXRfChJWya=tkUigURg-38VzeOA@mail.gmail.com>

Dear All,

I am trying to reshape the data with some conditions. A small part of the
data looks like below. Like this there will be more data with repeating ID.

Count id name type
117 335 sally A
19 335 sally A
167 335 sally B
18 340 susan A
56 340 susan A
22 340 susan B
53 340 susan B
135 351 lee A
114 351 lee A
84 351 lee A
80 351 lee A
19 351 lee A
8 351 lee A
21 351 lee A
88 351 lee B
111 351 lee B
46 351 lee B
108 351 lee B

>From the above data I am expecting an output like below.

id name type count_of_B Max of count B     x               y
335 sally B 167 167 117,19      NA
340 susan B 22,53 53 18              56
351 lee B 88,111,46,108  111 84,80,19,8,2   135,114

Where, the column x and column y are:

x = Count_A_less_than_max of (Count type B)
y = Count_A_higher_than_max of (Count type B)?.

*1)* I tried with dplyr with the following code for the initial step to get
the values for each column.
*2)*  I thought to transpose the columns which has the unique ID alone.

I tried with the following code and I am struck with the intial step
itself. The code is executed but higher and lower value of A is not coming.

Expected_output= data %>%
  group_by(id, Type) %>%
  mutate(Count_of_B = paste(unlist(count[Type=="B"]), collapse = ","))%>%
  mutate(Max_of_count_B = ifelse(Type == "B", max(count[Type ==
"B"]),max(count[Type == "A"]))) %>%
  mutate(count_type_A_lesser = ifelse
(Type=="B",(paste(unlist(count[Type=="A"]) < Max_of_count_B[Type=="B"],
collapse = ",")), "NA"))%>%
  mutate(count_type_A_higher =
ifelse(Type=="B",(paste(unlist(count[Type=="A"]) >
Max_of_count_B[Type=="B"], collapse = ",")), "NA"))

I hope I make my point clear. Please bare with the code, as I am new to
this.

Regards,
?sri

	[[alternative HTML version deleted]]


From awawaed at yahoo.com  Wed Apr 20 13:22:34 2016
From: awawaed at yahoo.com (A A)
Date: Wed, 20 Apr 2016 11:22:34 +0000 (UTC)
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <1123237897.3149726.1461151017390.JavaMail.yahoo@mail.yahoo.com>
References: <1123237897.3149726.1461151017390.JavaMail.yahoo.ref@mail.yahoo.com>
	<1123237897.3149726.1461151017390.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1039874725.3161671.1461151354933.JavaMail.yahoo@mail.yahoo.com>




 I have a situation in R where I would like to find any x (if one exists) that solves the linear system of equations Ax = b, where A is square, sparse, and singular, and b is a vector. Here is some code that mimics my issue with a relatively simple A and b, along with three other methods of solving this system that I found online, two of which give me an error and one of which succeeds on the simplified problem, but fails on my data set(attached). Is there a solver in R that I can use in order to get x without any errors given the structure of A? Thanks for your time.
#CODE STARTS HEREA = as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b = matrix(c(-30,40,-10),nrow=3,ncol=1)
#solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A (or out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
#one x that happens to solve Ax = bx = matrix(c(-10,10,0),nrow=3,ncol=1)A %*% x
#Error in lsfit(A, b) : only 3 cases, but 4 variableslsfit(A,b)#solves the system, but fails belowsolve(qr(A, LAPACK=TRUE),b)#Error in qr.solve(A, b) : singular matrix 'a' in solveqr.solve(A,b)
#matrices used in my actual problem (see attached files)A = readMM("A.txt")b = readMM("b.txt")
#Error in as(x, "matrix")[i, , drop = drop] : subscript out of boundssolve(qr(A, LAPACK=TRUE),b)

   
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: A.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160420/d5cf4593/attachment-0002.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: b.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160420/d5cf4593/attachment-0003.txt>

From milujisb at gmail.com  Wed Apr 20 16:37:07 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Wed, 20 Apr 2016 16:37:07 +0200
Subject: [R] Use multiple cores on Linux
Message-ID: <CAMLwc7OMGigJ_PYP=J3aegsVKdK8CwS3bRW0zG6_usAvWQmOpg@mail.gmail.com>

I am trying to run the following code in R on a Linux cluster. I would like
to use the full processing power (specifying cores/nodes/memory). The code
essentially runs predictions based on a GAM regression and saves the
results as a CSV file for multiple sets of data (here I only show two).

Is it possible to run this code using HPC packages such as
Rmpi/snow/doParallel? Thank you!

#####################
library(data.table)
library(mgcv)
library(reshape2)
library(dplyr)
library(tidyr)
library(lubridate)
library(DataCombine)
#
gam_max_count_wk <- gam(count_pop ~ factor(citycode) + factor(year) +
factor(week) + s(lnincome) + s(tmax) +
s(hmax),data=cont,na.action="na.omit", method="ML")

#
# Historic
temp_hist <- read.csv("/work/sd00815/giss_historic/giss_temp_hist.csv")
humid_hist <- read.csv("/work/sd00815/giss_historic/giss_hum_hist.csv")
#
temp_hist <- as.data.table(temp_hist)
humid_hist <- as.data.table(humid_hist)
#
# Merge
mykey<- c("FIPS", "year","month", "week")
setkeyv(temp_hist, mykey)
setkeyv(humid_hist, mykey)
#
hist<- merge(temp_hist, humid_hist, by=mykey)
#
hist$X.x <- NULL
hist$X.y <- NULL
#
# Max
hist_max <- hist
hist_max$FIPS <- hist_max$year <- hist_max$month <- hist_max$tmin <-
hist_max$tmean <- hist_max$hmin <- hist_max$hmean <- NULL
#
# Adding Factors
hist_max$citycode <- rep(101,nrow(hist_max))
hist_max$year <- rep(2010,nrow(hist_max))
hist_max$lnincome <- rep(10.262,nrow(hist_max))
#
# Predictions
pred_hist_max <- predict.gam(gam_max_count_wk,hist_max)
#
pred_hist_max <- as.data.table(pred_hist_max)
pred_hist_max <- cbind(hist, pred_hist_max)
pred_hist_max$tmax <- pred_hist_max$tmean <- pred_hist_max$tmin <-
pred_hist_max$hmean <- pred_hist_max$hmax <- pred_hist_max$hmin <- NULL
#
# Aggregate by FIPS
max_hist <- pred_hist_max %>%
  group_by(FIPS) %>%
  summarise(pred_hist = mean(pred_hist_max))
#
### Future
## 4.5
# 4.5_2021_2050
temp_sim <-
read.csv("/work/sd00815/giss_future/giss_4.5_2021_2050_temp.csv")
humid_sim <-
read.csv("/work/sd00815/giss_future/giss_4.5_2021_2050_temp.csv")
#
# Max
temp_sim <- as.data.table(temp_sim)
setnames(temp_sim, "max", "tmax")
setnames(temp_sim, "min", "tmin")
setnames(temp_sim, "avg", "tmean")
#
humid_sim <- as.data.table(humid_sim)
setnames(humid_sim, "max", "hmax")
setnames(humid_sim, "min", "hmin")
setnames(humid_sim, "avg", "hmean")
#
temp_sim$X <- NULL
humid_sim$X <- NULL
#
# Merge
mykey<- c("FIPS", "year","month", "week")
setkeyv(temp_sim, mykey)
setkeyv(humid_sim, mykey)
#
sim <- merge(temp_sim, humid_sim, by=mykey)
#
sim_max <- sim
#
sim_max$FIPS <- sim_max$year <- sim_max$month <- sim_max$tmin <-
sim_max$tmean <- sim_max$hmin <- sim_max$hmean <- NULL
#
# Adding Factors
sim_max$citycode <- rep(101,nrow(sim_max))
sim_max$year <- rep(2010,nrow(sim_max))
sim_max$week <- rep(1,nrow(sim_max))
sim_max$lnincome <- rep(10.262,nrow(sim_max))
#
# Predictions
pred_sim_max <- predict.gam(gam_max_count_wk,sim_max)
#
pred_sim_max <- as.data.table(pred_sim_max)
pred_sim_max <- cbind(sim, pred_sim_max)
pred_sim_max$tmax <- pred_sim_max$tmean <- pred_sim_max$tmin <-
pred_sim_max$hmean <- pred_sim_max$hmax <- pred_sim_max$hmin <- NULL
#
# Aggregate by FIPS
max_sim <- pred_sim_max %>%
  group_by(FIPS) %>%
  summarise(pred_sim = mean(pred_sim_max))
#
# Merge with Historical Data
max_hist$FIPS <- as.factor(max_hist$FIPS)
max_sim$FIPS <- as.factor(max_sim$FIPS)
#
mykey1<- c("FIPS")
setkeyv(max_hist, mykey1)
setkeyv(max_sim, mykey1)
max_change <- merge(max_hist, max_sim, by=mykey1)
max_change$change <-
((max_change$pred_sim-max_change$pred_hist)/max_change$pred_hist)*100
#
write.csv(max_change, file =
"/work/sd00815/projections_data/year_wk_fe/giss/max/giss_4.5_2021_2050.csv")



# 4.5_2081_2100
temp_sim <-
read.csv("/work/sd00815/giss_future/giss_4.5_2081_2100_temp.csv")
humid_sim <-
read.csv("/work/sd00815/giss_future/giss_4.5_2081_2100_temp.csv")
#
# Max
temp_sim <- as.data.table(temp_sim)
setnames(temp_sim, "max", "tmax")
setnames(temp_sim, "min", "tmin")
setnames(temp_sim, "avg", "tmean")
#
humid_sim <- as.data.table(humid_sim)
setnames(humid_sim, "max", "hmax")
setnames(humid_sim, "min", "hmin")
setnames(humid_sim, "avg", "hmean")
#
temp_sim$X <- NULL
humid_sim$X <- NULL
#
# Merge
mykey<- c("FIPS", "year","month", "week")
setkeyv(temp_sim, mykey)
setkeyv(humid_sim, mykey)
#
sim <- merge(temp_sim, humid_sim, by=mykey)
#
sim_max <- sim
#
sim_max$FIPS <- sim_max$year <- sim_max$month <- sim_max$tmin <-
sim_max$tmean <- sim_max$hmin <- sim_max$hmean <- NULL
#
# Adding Factors
sim_max$citycode <- rep(101,nrow(sim_max))
sim_max$year <- rep(2010,nrow(sim_max))
sim_max$week <- rep(1,nrow(sim_max))
sim_max$lnincome <- rep(10.262,nrow(sim_max))
#
# Predictions
pred_sim_max <- predict.gam(gam_max_count_wk,sim_max)
#
pred_sim_max <- as.data.table(pred_sim_max)
pred_sim_max <- cbind(sim, pred_sim_max)
pred_sim_max$tmax <- pred_sim_max$tmean <- pred_sim_max$tmin <-
pred_sim_max$hmean <- pred_sim_max$hmax <- pred_sim_max$hmin <- NULL
#
# Aggregate by FIPS
max_sim <- pred_sim_max %>%
  group_by(FIPS) %>%
  summarise(pred_sim = mean(pred_sim_max))
#
# Merge with Historical Data
max_hist$FIPS <- as.factor(max_hist$FIPS)
max_sim$FIPS <- as.factor(max_sim$FIPS)
#
mykey1<- c("FIPS")
setkeyv(max_hist, mykey1)
setkeyv(max_sim, mykey1)
max_change <- merge(max_hist, max_sim, by=mykey1)
max_change$change <-
((max_change$pred_sim-max_change$pred_hist)/max_change$pred_hist)*100
#
write.csv(max_change, file =
"/work/sd00815/projections_data/year_wk_fe/giss/max/giss_4.5_2081_2100.csv")

####################


Sincerely,

Milu

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Wed Apr 20 16:45:01 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Wed, 20 Apr 2016 14:45:01 +0000
Subject: [R] Add a vertical arrow to a time series graph using ggplot
 and xts
Message-ID: <248E6FA047A8C746BA491485764190F53D3AE1DD@ESESSMB207.ericsson.se>

Please see updates to df2 assignment as shown below.

library(xts)  # primary
#library(tseries)   # Unit root tests
library(ggplot2)
library(vars)
library(grid)
dt_xts<-xts(x = 1:10, order.by = seq(as.Date("2016-01-01"),
                                     as.Date("2016-01-10"), by = "1 day"))
colnames(dt_xts)<-"gdp"
xmin<-min(index(dt_xts))
xmax<-max(index(dt_xts))
df1<-data.frame(x = index(dt_xts), coredata(dt_xts))
p<-ggplot(data = df1, mapping= aes(x=x, y=gdp))+geom_line()
rg<-ggplot_build(p)$panel$ranges[[1]]$y.range
y1<-rg[1]
y2<-rg[2]


# x = as.Date(..) in place of x = "2016-01-05"
df2<-data.frame(x = as.Date("2016-01-05"), y1=y1, y2=y2 )

p1<-p+geom_segment(mapping=aes(x=x, y=y1, xend=x, yend=y2), data=df2,
                   arrow=arrow())
--

Best,

GG




	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Apr 20 16:59:08 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 20 Apr 2016 07:59:08 -0700
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <1039874725.3161671.1461151354933.JavaMail.yahoo@mail.yahoo.com>
References: <1123237897.3149726.1461151017390.JavaMail.yahoo.ref@mail.yahoo.com>
	<1123237897.3149726.1461151017390.JavaMail.yahoo@mail.yahoo.com>
	<1039874725.3161671.1461151354933.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcYiS8KKfW93PEs9UCW52GA5D54YsErx-iTmW3NBW8CMew@mail.gmail.com>

This is not a solution but your lsfit attempt
   #Error in lsfit(A, b) : only 3 cases, but 4 variables
   lsfit(A,b)
gave that error because lsfit adds a column of 1 to
its first argument unless you use intercept=FALSE.
Then it will give you an answer (but I think it converts
your sparse matrix into a dense one before doing
any linear algebra).



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Apr 20, 2016 at 4:22 AM, A A via R-help <r-help at r-project.org>
wrote:

>
>
>
>  I have a situation in R where I would like to find any x (if one exists)
> that solves the linear system of equations Ax = b, where A is square,
> sparse, and singular, and b is a vector. Here is some code that mimics my
> issue with a relatively simple A and b, along with three other methods of
> solving this system that I found online, two of which give me an error and
> one of which succeeds on the simplified problem, but fails on my data
> set(attached). Is there a solver in R that I can use in order to get x
> without any errors given the structure of A? Thanks for your time.
> #CODE STARTS HEREA =
> as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b
> = matrix(c(-30,40,-10),nrow=3,ncol=1)
> #solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A (or
> out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
> #one x that happens to solve Ax = bx = matrix(c(-10,10,0),nrow=3,ncol=1)A
> %*% x
> #Error in lsfit(A, b) : only 3 cases, but 4 variableslsfit(A,b)#solves the
> system, but fails belowsolve(qr(A, LAPACK=TRUE),b)#Error in qr.solve(A, b)
> : singular matrix 'a' in solveqr.solve(A,b)
> #matrices used in my actual problem (see attached files)A =
> readMM("A.txt")b = readMM("b.txt")
> #Error in as(x, "matrix")[i, , drop = drop] : subscript out of
> boundssolve(qr(A, LAPACK=TRUE),b)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Apr 20 17:01:08 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 20 Apr 2016 08:01:08 -0700
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <1039874725.3161671.1461151354933.JavaMail.yahoo@mail.yahoo.com>
References: <1123237897.3149726.1461151017390.JavaMail.yahoo.ref@mail.yahoo.com>
	<1123237897.3149726.1461151017390.JavaMail.yahoo@mail.yahoo.com>
	<1039874725.3161671.1461151354933.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <B6FC6B8E-FA99-4794-A56D-909C3F64F9FA@dcn.davis.ca.us>

This is kind of like asking for a solution to x+1=x+1. Go back to linear algebra and look up Singular Value Decomposition, and decide if you really want to proceed.  See also ?svd and package irlba.
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2016 4:22:34 AM PDT, A A via R-help <r-help at r-project.org> wrote:
>
>
>
>I have a situation in R where I would like to find any x (if one
>exists) that solves the linear system of equations Ax = b, where A is
>square, sparse, and singular, and b is a vector. Here is some code that
>mimics my issue with a relatively simple A and b, along with three
>other methods of solving this system that I found online, two of which
>give me an error and one of which succeeds on the simplified problem,
>but fails on my data set(attached). Is there a solver in R that I can
>use in order to get x without any errors given the structure of A?
>Thanks for your time.
>#CODE STARTS HEREA =
>as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b
>= matrix(c(-30,40,-10),nrow=3,ncol=1)
>#solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A (or
>out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
>#one x that happens to solve Ax = bx =
>matrix(c(-10,10,0),nrow=3,ncol=1)A %*% x
>#Error in lsfit(A, b) : only 3 cases, but 4 variableslsfit(A,b)#solves
>the system, but fails belowsolve(qr(A, LAPACK=TRUE),b)#Error in
>qr.solve(A, b) : singular matrix 'a' in solveqr.solve(A,b)
>#matrices used in my actual problem (see attached files)A =
>readMM("A.txt")b = readMM("b.txt")
>#Error in as(x, "matrix")[i, , drop = drop] : subscript out of
>boundssolve(qr(A, LAPACK=TRUE),b)
>
>   
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jody.kelly at northumbria.ac.uk  Wed Apr 20 17:19:48 2016
From: jody.kelly at northumbria.ac.uk (jody.kelly)
Date: Wed, 20 Apr 2016 15:19:48 +0000
Subject: [R] Reading Multiple Output Variables
Message-ID: <HE1PR04MB16261461FA18EA6F17273EC0C86D0@HE1PR04MB1626.eurprd04.prod.outlook.com>


Hi all,


I am trying to read multiple out variables for a sensitivity analysis.


Currently using one output value as follows:


Y<-(E1)


However I need to run analysis against 12 values of Y. So E1-E12.


My matrix will be: Inputs are Column=4, Rows = 40 i.e. 40 rows of  4  input variables in different combinations. These will be analysed against 40 rows of output variables for 12 columns.


e.g.


      V1 V2 V3 V4    E1 E2 E3 E4 ... E12

1

2

...

40


Can someone provide guidance on How I can plot against all 12 months?


Thanks


Jody


This message is intended solely for the addressee and may contain confidential and/or legally privileged information. Any use, disclosure or reproduction without the sender's explicit consent is unauthorised and may be unlawful. If you have received this message in error, please notify Northumbria University immediately and permanently delete it. Any views or opinions expressed in this message are solely those of the author and do not necessarily represent those of the University. The University cannot guarantee that this message or any attachment is virus free or has not been intercepted and/or amended.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Apr 20 17:21:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 20 Apr 2016 08:21:19 -0700
Subject: [R] Use multiple cores on Linux
In-Reply-To: <CAMLwc7OMGigJ_PYP=J3aegsVKdK8CwS3bRW0zG6_usAvWQmOpg@mail.gmail.com>
References: <CAMLwc7OMGigJ_PYP=J3aegsVKdK8CwS3bRW0zG6_usAvWQmOpg@mail.gmail.com>
Message-ID: <41E24AD6-927F-4FBB-AC40-B5CC9CA6C339@dcn.davis.ca.us>

The answer to your question is yes. You might consider using the parallel package., and I would suggest starting  with a simpler test case to learn how it works and incrementally adding complexity of packages and data handling. 
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2016 7:37:07 AM PDT, Miluji Sb <milujisb at gmail.com> wrote:
>I am trying to run the following code in R on a Linux cluster. I would
>like
>to use the full processing power (specifying cores/nodes/memory). The
>code
>essentially runs predictions based on a GAM regression and saves the
>results as a CSV file for multiple sets of data (here I only show two).
>
>Is it possible to run this code using HPC packages such as
>Rmpi/snow/doParallel? Thank you!
>
>#####################
>library(data.table)
>library(mgcv)
>library(reshape2)
>library(dplyr)
>library(tidyr)
>library(lubridate)
>library(DataCombine)
>#
>gam_max_count_wk <- gam(count_pop ~ factor(citycode) + factor(year) +
>factor(week) + s(lnincome) + s(tmax) +
>s(hmax),data=cont,na.action="na.omit", method="ML")
>
>#
># Historic
>temp_hist <- read.csv("/work/sd00815/giss_historic/giss_temp_hist.csv")
>humid_hist <- read.csv("/work/sd00815/giss_historic/giss_hum_hist.csv")
>#
>temp_hist <- as.data.table(temp_hist)
>humid_hist <- as.data.table(humid_hist)
>#
># Merge
>mykey<- c("FIPS", "year","month", "week")
>setkeyv(temp_hist, mykey)
>setkeyv(humid_hist, mykey)
>#
>hist<- merge(temp_hist, humid_hist, by=mykey)
>#
>hist$X.x <- NULL
>hist$X.y <- NULL
>#
># Max
>hist_max <- hist
>hist_max$FIPS <- hist_max$year <- hist_max$month <- hist_max$tmin <-
>hist_max$tmean <- hist_max$hmin <- hist_max$hmean <- NULL
>#
># Adding Factors
>hist_max$citycode <- rep(101,nrow(hist_max))
>hist_max$year <- rep(2010,nrow(hist_max))
>hist_max$lnincome <- rep(10.262,nrow(hist_max))
>#
># Predictions
>pred_hist_max <- predict.gam(gam_max_count_wk,hist_max)
>#
>pred_hist_max <- as.data.table(pred_hist_max)
>pred_hist_max <- cbind(hist, pred_hist_max)
>pred_hist_max$tmax <- pred_hist_max$tmean <- pred_hist_max$tmin <-
>pred_hist_max$hmean <- pred_hist_max$hmax <- pred_hist_max$hmin <- NULL
>#
># Aggregate by FIPS
>max_hist <- pred_hist_max %>%
>  group_by(FIPS) %>%
>  summarise(pred_hist = mean(pred_hist_max))
>#
>### Future
>## 4.5
># 4.5_2021_2050
>temp_sim <-
>read.csv("/work/sd00815/giss_future/giss_4.5_2021_2050_temp.csv")
>humid_sim <-
>read.csv("/work/sd00815/giss_future/giss_4.5_2021_2050_temp.csv")
>#
># Max
>temp_sim <- as.data.table(temp_sim)
>setnames(temp_sim, "max", "tmax")
>setnames(temp_sim, "min", "tmin")
>setnames(temp_sim, "avg", "tmean")
>#
>humid_sim <- as.data.table(humid_sim)
>setnames(humid_sim, "max", "hmax")
>setnames(humid_sim, "min", "hmin")
>setnames(humid_sim, "avg", "hmean")
>#
>temp_sim$X <- NULL
>humid_sim$X <- NULL
>#
># Merge
>mykey<- c("FIPS", "year","month", "week")
>setkeyv(temp_sim, mykey)
>setkeyv(humid_sim, mykey)
>#
>sim <- merge(temp_sim, humid_sim, by=mykey)
>#
>sim_max <- sim
>#
>sim_max$FIPS <- sim_max$year <- sim_max$month <- sim_max$tmin <-
>sim_max$tmean <- sim_max$hmin <- sim_max$hmean <- NULL
>#
># Adding Factors
>sim_max$citycode <- rep(101,nrow(sim_max))
>sim_max$year <- rep(2010,nrow(sim_max))
>sim_max$week <- rep(1,nrow(sim_max))
>sim_max$lnincome <- rep(10.262,nrow(sim_max))
>#
># Predictions
>pred_sim_max <- predict.gam(gam_max_count_wk,sim_max)
>#
>pred_sim_max <- as.data.table(pred_sim_max)
>pred_sim_max <- cbind(sim, pred_sim_max)
>pred_sim_max$tmax <- pred_sim_max$tmean <- pred_sim_max$tmin <-
>pred_sim_max$hmean <- pred_sim_max$hmax <- pred_sim_max$hmin <- NULL
>#
># Aggregate by FIPS
>max_sim <- pred_sim_max %>%
>  group_by(FIPS) %>%
>  summarise(pred_sim = mean(pred_sim_max))
>#
># Merge with Historical Data
>max_hist$FIPS <- as.factor(max_hist$FIPS)
>max_sim$FIPS <- as.factor(max_sim$FIPS)
>#
>mykey1<- c("FIPS")
>setkeyv(max_hist, mykey1)
>setkeyv(max_sim, mykey1)
>max_change <- merge(max_hist, max_sim, by=mykey1)
>max_change$change <-
>((max_change$pred_sim-max_change$pred_hist)/max_change$pred_hist)*100
>#
>write.csv(max_change, file =
>"/work/sd00815/projections_data/year_wk_fe/giss/max/giss_4.5_2021_2050.csv")
>
>
>
># 4.5_2081_2100
>temp_sim <-
>read.csv("/work/sd00815/giss_future/giss_4.5_2081_2100_temp.csv")
>humid_sim <-
>read.csv("/work/sd00815/giss_future/giss_4.5_2081_2100_temp.csv")
>#
># Max
>temp_sim <- as.data.table(temp_sim)
>setnames(temp_sim, "max", "tmax")
>setnames(temp_sim, "min", "tmin")
>setnames(temp_sim, "avg", "tmean")
>#
>humid_sim <- as.data.table(humid_sim)
>setnames(humid_sim, "max", "hmax")
>setnames(humid_sim, "min", "hmin")
>setnames(humid_sim, "avg", "hmean")
>#
>temp_sim$X <- NULL
>humid_sim$X <- NULL
>#
># Merge
>mykey<- c("FIPS", "year","month", "week")
>setkeyv(temp_sim, mykey)
>setkeyv(humid_sim, mykey)
>#
>sim <- merge(temp_sim, humid_sim, by=mykey)
>#
>sim_max <- sim
>#
>sim_max$FIPS <- sim_max$year <- sim_max$month <- sim_max$tmin <-
>sim_max$tmean <- sim_max$hmin <- sim_max$hmean <- NULL
>#
># Adding Factors
>sim_max$citycode <- rep(101,nrow(sim_max))
>sim_max$year <- rep(2010,nrow(sim_max))
>sim_max$week <- rep(1,nrow(sim_max))
>sim_max$lnincome <- rep(10.262,nrow(sim_max))
>#
># Predictions
>pred_sim_max <- predict.gam(gam_max_count_wk,sim_max)
>#
>pred_sim_max <- as.data.table(pred_sim_max)
>pred_sim_max <- cbind(sim, pred_sim_max)
>pred_sim_max$tmax <- pred_sim_max$tmean <- pred_sim_max$tmin <-
>pred_sim_max$hmean <- pred_sim_max$hmax <- pred_sim_max$hmin <- NULL
>#
># Aggregate by FIPS
>max_sim <- pred_sim_max %>%
>  group_by(FIPS) %>%
>  summarise(pred_sim = mean(pred_sim_max))
>#
># Merge with Historical Data
>max_hist$FIPS <- as.factor(max_hist$FIPS)
>max_sim$FIPS <- as.factor(max_sim$FIPS)
>#
>mykey1<- c("FIPS")
>setkeyv(max_hist, mykey1)
>setkeyv(max_sim, mykey1)
>max_change <- merge(max_hist, max_sim, by=mykey1)
>max_change$change <-
>((max_change$pred_sim-max_change$pred_hist)/max_change$pred_hist)*100
>#
>write.csv(max_change, file =
>"/work/sd00815/projections_data/year_wk_fe/giss/max/giss_4.5_2081_2100.csv")
>
>####################
>
>
>Sincerely,
>
>Milu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Apr 20 17:44:25 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 20 Apr 2016 08:44:25 -0700
Subject: [R] Reading Multiple Output Variables
In-Reply-To: <HE1PR04MB16261461FA18EA6F17273EC0C86D0@HE1PR04MB1626.eurprd04.prod.outlook.com>
References: <HE1PR04MB16261461FA18EA6F17273EC0C86D0@HE1PR04MB1626.eurprd04.prod.outlook.com>
Message-ID: <EFCBC02B-398A-43E3-BA42-F9F107159A27@dcn.davis.ca.us>

The word "analysis" is too vague. 

If you are referring to lm regression, you can specify Y as a matrix instead of a vector. 

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Also, please disable HTML in your email when sending to this list, since it will usually come through to us in damaged form. 
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2016 8:19:48 AM PDT, "jody.kelly" <jody.kelly at northumbria.ac.uk> wrote:
>
>Hi all,
>
>
>I am trying to read multiple out variables for a sensitivity analysis.
>
>
>Currently using one output value as follows:
>
>
>Y<-(E1)
>
>
>However I need to run analysis against 12 values of Y. So E1-E12.
>
>
>My matrix will be: Inputs are Column=4, Rows = 40 i.e. 40 rows of  4 
>input variables in different combinations. These will be analysed
>against 40 rows of output variables for 12 columns.
>
>
>e.g.
>
>
>      V1 V2 V3 V4    E1 E2 E3 E4 ... E12
>
>1
>
>2
>
>...
>
>40
>
>
>Can someone provide guidance on How I can plot against all 12 months?
>
>
>Thanks
>
>
>Jody
>
>
>This message is intended solely for the addressee and may contain
>confidential and/or legally privileged information. Any use, disclosure
>or reproduction without the sender's explicit consent is unauthorised
>and may be unlawful. If you have received this message in error, please
>notify Northumbria University immediately and permanently delete it.
>Any views or opinions expressed in this message are solely those of the
>author and do not necessarily represent those of the University. The
>University cannot guarantee that this message or any attachment is
>virus free or has not been intercepted and/or amended.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Wed Apr 20 18:10:17 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 20 Apr 2016 12:10:17 -0400
Subject: [R] installation of dplyr
In-Reply-To: <CABdHhvFc8hp42rJ-LNu411Ju5fSvDb=6tj-RBecjFmYACMsmaA@mail.gmail.com>
References: <E13FC27C-D395-4CA5-8489-1CF8D3EA8117@bigelow.org>
	<CABdHhvFc8hp42rJ-LNu411Ju5fSvDb=6tj-RBecjFmYACMsmaA@mail.gmail.com>
Message-ID: <8A3D9AF6-D86A-4806-A261-80C39F4E2A6C@bigelow.org>

Increasing memory resolved the issue for me.

Thanks again,
Ben

> On Apr 19, 2016, at 4:10 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> 
> You normally see these errors when compiling on a vm that has very
> little memory.
> Hadley
> 
> On Tue, Apr 19, 2016 at 2:47 PM, Ben Tupper <btupper at bigelow.org> wrote:
>> Hello,
>> 
>> I am getting a fresh CentOS 6.7 machine set up with all of the goodies for R 3.2.3, including dplyr package. I am unable to successfully install it.  Below I show the failed installation using utils::install.packages() and then again using devtools::install_github().  Each yields an error similar to the other but not quite exactly the same - the error messages sail right over my head.
>> 
>> I can contact the package author if that would be better, but thought it best to start here.
>> 
>> Thanks!
>> Ben
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>>> sessionInfo()
>> R version 3.2.3 (2015-12-10)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>> Running under: CentOS release 6.7 (Final)
>> 
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> 
>> 
>> ####
>> #       utils::install.packages()
>> ####
>> 
>>> install.packages("dplyr", repo = "http://cran.r-project.org")
>> Installing package into ?/usr/lib64/R/library?
>> (as ?lib? is unspecified)
>> trying URL 'http://cran.r-project.org/src/contrib/dplyr_0.4.3.tar.gz'
>> Content type 'application/x-gzip' length 655997 bytes (640 KB)
>> ==================================================
>> downloaded 640 KB
>> 
>> * installing *source* package ?dplyr? ...
>> ** package ?dplyr? successfully unpacked and MD5 sums checked
>> ** libs
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
>> In file included from ../inst/include/dplyr.h:131,
>>                 from arrange.cpp:1:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h:40: warning: ?column? may be used uninitialized in this function
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
>> dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
>> dplyr.cpp:242: warning: ?number_tiles? may be used uninitialized in this function
>> {standard input}: Assembler messages:
>> {standard input}:509159: Warning: end of file not at end of a line; newline inserted
>> {standard input}:509591: Error: open CFI at the end of file; missing .cfi_endproc directive
>> g++: Internal error: Killed (program cc1plus)
>> Please submit a full bug report.
>> See <http://bugzilla.redhat.com/bugzilla> for instructions.
>> make: *** [dplyr.o] Error 1
>> ERROR: compilation failed for package ?dplyr?
>> * removing ?/usr/lib64/R/library/dplyr?
>> 
>> The downloaded source packages are in
>>        ?/tmp/RtmpkdCODF/downloaded_packages?
>> Updating HTML index of packages in '.Library'
>> Making 'packages.html' ... done
>> Warning message:
>> In install.packages("dplyr", repo = "http://cran.r-project.org") :
>>  installation of package ?dplyr? had non-zero exit status
>> 
>> 
>> 
>> ####
>> #       devtools::install_github()
>> ####
>> 
>> 
>>> library(devtools)
>>> install_github("hadley/dplyr", lib = '/usr/lib64/R/library')
>> Using GitHub PAT from envvar GITHUB_PAT
>> Downloading GitHub repo hadley/dplyr at master
>> from URL https://api.github.com/repos/hadley/dplyr/zipball/master
>> Installing dplyr
>> Using GitHub PAT from envvar GITHUB_PAT
>> Downloading GitHub repo hadley/testthat at master
>> from URL https://api.github.com/repos/hadley/testthat/zipball/master
>> Installing testthat
>> '/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
>>  --quiet CMD INSTALL  \
>>  '/tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494'  \
>>  --library='/usr/lib64/R/library' --install-tests
>> 
>> * installing *source* package ?testthat? ...
>> ** libs
>> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c label.c -o label.o
>> gcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c reassign.c -o reassign.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-catch.cpp -o test-catch.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-example.cpp -o test-example.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_TESTTHAT -I/usr/local/include    -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c test-runner.cpp -o test-runner.o
>> g++ -m64 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o testthat.so label.o reassign.o test-catch.o test-example.o test-runner.o -L/usr/lib64/R/lib -lR
>> installing to /usr/lib64/R/library/testthat/libs
>> ** R
>> ** inst
>> ** tests
>> ** preparing package for lazy loading
>> ** help
>> *** installing help indices
>>  converting help for package ?testthat?
>>    finding HTML links ... done
>>    CheckReporter                           html
>>    FailReporter                            html
>>    ListReporter                            html
>>    MinimalReporter                         html
>>    MultiReporter                           html
>>    Reporter                                html
>>    RstudioReporter                         html
>>    SilentReporter                          html
>>    StopReporter                            html
>>    SummaryReporter                         html
>>    TapReporter                             html
>>    TeamcityReporter                        html
>>    auto_test                               html
>>    auto_test_package                       html
>>    compare                                 html
>>    compare_state                           html
>>    comparison-expectations                 html
>>    context                                 html
>>    describe                                html
>>    dir_state                               html
>>    equality-expectations                   html
>>    evaluate_promise                        html
>>    expect_cpp_tests_pass                   html
>>    expect_equal_to_reference               html
>>    expect_length                           html
>>    expect_match                            html
>>    expect_named                            html
>>    expect_success                          html
>>    expect_that                             html
>>    expectation                             html
>>    fail                                    html
>>    find_reporter                           html
>>    find_test_scripts                       html
>>    inheritance-expectations                html
>>    logical-expectations                    html
>>    make_expectation                        html
>>    not                                     html
>>    oldskool                                html
>>    output-expectations                     html
>>    reexports                               html
>> Rd warning: /tmp/RtmpkdCODF/devtools45c22638b2f2/hadley-testthat-52d5494/man/reexports.Rd:13: missing file link ?%>%?
>>    reporter-accessors                      html
>>    safe_digest                             html
>>    skip                                    html
>>    source_file                             html
>>    takes_less_than                         html
>>    test_dir                                html
>>    test_env                                html
>>    test_examples                           html
>>    test_file                               html
>>    test_package                            html
>>    test_path                               html
>>    test_that                               html
>>    testthat                                html
>>    testthat_results                        html
>>    try_again                               html
>>    use_catch                               html
>>    watch                                   html
>>    with_mock                               html
>> ** building package indices
>> ** testing if installed package can be loaded
>> * DONE (testthat)
>> Making 'packages.html' ... done
>> Using GitHub PAT from envvar GITHUB_PAT
>> Skipping install for github remote, the SHA1 (cb38672f) has not changed since last install.
>>  Use `force = TRUE` to force installation
>> Skipping 2 packages ahead of CRAN: lazyeval, tibble
>> '/usr/lib64/R/bin/R' --no-site-file --no-environ --no-save --no-restore  \
>>  --quiet CMD INSTALL  \
>>  '/tmp/RtmpkdCODF/devtools45c2fff716f/hadley-dplyr-afb9ac7'  \
>>  --library='/usr/lib64/R/library' --install-tests
>> 
>> * installing *source* package ?dplyr? ...
>> ** libs
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c RcppExports.cpp -o RcppExports.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c address.cpp -o address.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c api.cpp -o api.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c arrange.cpp -o arrange.o
>> In file included from ../inst/include/dplyr.h:141,
>>                 from arrange.cpp:1:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c between.cpp -o between.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c bind.cpp -o bind.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c combine_variables.cpp -o combine_variables.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c distinct.cpp -o distinct.o
>> g++ -m64 -I/usr/include/R -DNDEBUG -I../inst/include -DCOMPILING_DPLYR -I/usr/local/include -I"/usr/lib64/R/library/Rcpp/include" -I"/usr/lib64/R/library/BH/include"  -DBOOST_NO_INT64_T -DBOOST_NO_INTEGRAL_INT64_T -DBOOST_NO_LONG_LONG -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic  -c dplyr.cpp -o dplyr.o
>> dplyr.cpp: In function ?dplyr::Result* ntile_prototype(SEXPREC*, const dplyr::LazySubsets&, int)?:
>> dplyr.cpp:213: warning: ?number_tiles? may be used uninitialized in this function
>> In file included from ../inst/include/dplyr.h:141,
>>                 from dplyr.cpp:1:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h: In constructor ?dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(const Rcpp::DataFrame&, const Rcpp::CharacterVector&)?:
>> ../inst/include/dplyr/DataFrameSubsetVisitors.h:41: warning: ?column? may be used uninitialized in this function
>> {standard input}: Assembler messages:
>> {standard input}:812569: Warning: end of file not at end of a line; newline inserted
>> g++: Internal error: Killed (program cc1plus)
>> Please submit a full bug report.
>> See <http://bugzilla.redhat.com/bugzilla> for instructions.
>> make: *** [dplyr.o] Error 1
>> ERROR: compilation failed for package ?dplyr?
>> * removing ?/usr/lib64/R/library/dplyr?
>> Error: Command failed (1)
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> http://hadley.nz

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From bhh at xs4all.nl  Wed Apr 20 20:01:32 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 20 Apr 2016 20:01:32 +0200
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <1039874725.3161671.1461151354933.JavaMail.yahoo@mail.yahoo.com>
References: <1123237897.3149726.1461151017390.JavaMail.yahoo.ref@mail.yahoo.com>
	<1123237897.3149726.1461151017390.JavaMail.yahoo@mail.yahoo.com>
	<1039874725.3161671.1461151354933.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <268093FF-4916-46BA-BDEA-7833C21839FA@xs4all.nl>


> On 20 Apr 2016, at 13:22, A A via R-help <r-help at r-project.org> wrote:
> 
> 
> 
> 
> I have a situation in R where I would like to find any x (if one exists) that solves the linear system of equations Ax = b, where A is square, sparse, and singular, and b is a vector. Here is some code that mimics my issue with a relatively simple A and b, along with three other methods of solving this system that I found online, two of which give me an error and one of which succeeds on the simplified problem, but fails on my data set(attached). Is there a solver in R that I can use in order to get x without any errors given the structure of A? Thanks for your time.
> #CODE STARTS HEREA = as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b = matrix(c(-30,40,-10),nrow=3,ncol=1)
> #solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A (or out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
> #one x that happens to solve Ax = bx = matrix(c(-10,10,0),nrow=3,ncol=1)A %*% x
> #Error in lsfit(A, b) : only 3 cases, but 4 variableslsfit(A,b)#solves the system, but fails belowsolve(qr(A, LAPACK=TRUE),b)#Error in qr.solve(A, b) : singular matrix 'a' in solveqr.solve(A,b)
> #matrices used in my actual problem (see attached files)A = readMM("A.txt")b = readMM("b.txt")
> #Error in as(x, "matrix")[i, , drop = drop] : subscript out of boundssolve(qr(A, LAPACK=TRUE),b)

Your code is a mess. 

A singular square system of linear equations has an infinity of solutions if a solution exists at all.
How that works you can find here: https://en.wikipedia.org/wiki/System_of_linear_equations
in the section "Matrix solutions".

For your simple example you can do it like this:

library(MASS)
Ag <- ginv(A)	# pseudoinverse

xb <- Ag %*% b # minimum norm solution

Aw <- diag(nrow=nrow(Ag)) - Ag %*% A  # see the Wikipedia page
w <- runif(3)
z <- xb + Aw %*% w
A %*% z - b

N <- Null(t(A))	 # null space of A;  see the help for Null in package MASS
A %*% N
A %*% (xb + 2 * N) - b

For sparse systems you will have to approach this differently; I have no experience with that.

Berend


From awawaed at yahoo.com  Wed Apr 20 20:50:26 2016
From: awawaed at yahoo.com (A A)
Date: Wed, 20 Apr 2016 18:50:26 +0000 (UTC)
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <CAF8bMcYiS8KKfW93PEs9UCW52GA5D54YsErx-iTmW3NBW8CMew@mail.gmail.com>
References: <CAF8bMcYiS8KKfW93PEs9UCW52GA5D54YsErx-iTmW3NBW8CMew@mail.gmail.com>
Message-ID: <752755066.3511934.1461178226644.JavaMail.yahoo@mail.yahoo.com>

Thanks for the advice. I fixed the function and ran it on my systems just to see if it would work; for the first set of A and b, I got a valid solution, but for the second set, I got the error "Error in complete.cases(x, y, wt) : not all arguments have the same length".? 

    On Wednesday, April 20, 2016 10:59 AM, William Dunlap <wdunlap at tibco.com> wrote:
 

 This is not a solution but your lsfit attempt? ?#Error in lsfit(A, b) : only 3 cases, but 4 variables? ?lsfit(A,b)gave that error because lsfit adds a column of 1 toits first argument unless you use intercept=FALSE.Then it will give you an answer (but I think it convertsyour sparse matrix into a dense one before doingany linear algebra).


Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Wed, Apr 20, 2016 at 4:22 AM, A A via R-help <r-help at r-project.org> wrote:




?I have a situation in R where I would like to find any x (if one exists) that solves the linear system of equations Ax = b, where A is square, sparse, and singular, and b is a vector. Here is some code that mimics my issue with a relatively simple A and b, along with three other methods of solving this system that I found online, two of which give me an error and one of which succeeds on the simplified problem, but fails on my data set(attached). Is there a solver in R that I can use in order to get x without any errors given the structure of A? Thanks for your time.
#CODE STARTS HEREA = as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b = matrix(c(-30,40,-10),nrow=3,ncol=1)
#solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A (or out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
#one x that happens to solve Ax = bx = matrix(c(-10,10,0),nrow=3,ncol=1)A %*% x
#Error in lsfit(A, b) : only 3 cases, but 4 variableslsfit(A,b)#solves the system, but fails belowsolve(qr(A, LAPACK=TRUE),b)#Error in qr.solve(A, b) : singular matrix 'a' in solveqr.solve(A,b)
#matrices used in my actual problem (see attached files)A = readMM("A.txt")b = readMM("b.txt")
#Error in as(x, "matrix")[i, , drop = drop] : subscript out of boundssolve(qr(A, LAPACK=TRUE),b)

? ?
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




  
	[[alternative HTML version deleted]]


From awawaed at yahoo.com  Wed Apr 20 20:50:34 2016
From: awawaed at yahoo.com (A A)
Date: Wed, 20 Apr 2016 18:50:34 +0000 (UTC)
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <B6FC6B8E-FA99-4794-A56D-909C3F64F9FA@dcn.davis.ca.us>
References: <B6FC6B8E-FA99-4794-A56D-909C3F64F9FA@dcn.davis.ca.us>
Message-ID: <283599216.3487878.1461178234100.JavaMail.yahoo@mail.yahoo.com>

Thanks for the response. Yes, in that situation a solution of x = 1 would be just as good as x = 1000 or any other value of x for me (but in my problem the matrix has nonzero rank, so I can't just randomly choose a vector and have it be a solution). If it helps, what I'm interested in is the R equivalent of?
x = A\b
in MATLAB, for these particular kinds of A matrices. I looked into irlba, and it seems to be able to calculate some of the singular values/vectors for the large dataset without taking too much time. I'll look more into seeing how I can solve the system with it. 

    On Wednesday, April 20, 2016 11:01 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
 

 This is kind of like asking for a solution to x+1=x+1. Go back to linear algebra and look up Singular Value Decomposition, and decide if you really want to proceed. See also ?svd and package irlba.
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2016 4:22:34 AM PDT, A A via R-help <r-help at r-project.org> wrote:



 I have a situation in R where I would like to find any x (if one exists) that solves the linear system of equations Ax = b, where A is square, sparse, and singular, and b is a vector. Here is some code that mimics my issue with a relatively simple A and b, along with three other methods of solving this system that I found online, two of which give me an error and one of which succeeds on the simplified problem, but fails on my data set(attached). Is there a solver in R that I can use in order to get x without any errors given the structure of A? Thanks for your time.
#CODE STARTS HEREA = as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b = matrix(c(-30,40,-10),nrow=3,ncol=1)
#solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A (or out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
#one x that happens to solve Ax = bx = matrix(c(-10,10,0),nrow=3,ncol=1)A %*% x
#Error in
lsfit(A, b) : only 3 cases, but 4 variableslsfit(A,b)#solves the system, but fails belowsolve(qr(A, LAPACK=TRUE),b)#Error in qr.solve(A, b) : singular matrix 'a' in solveqr.solve(A,b)
#matrices used in my actual problem (see attached files)A = readMM("A.txt")b = readMM("b.txt")
#Error in as(x, "matrix")[i, , drop = drop] : subscript out of boundssolve(qr(A, LAPACK=TRUE),b)


R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From awawaed at yahoo.com  Wed Apr 20 20:51:40 2016
From: awawaed at yahoo.com (A A)
Date: Wed, 20 Apr 2016 18:51:40 +0000 (UTC)
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <268093FF-4916-46BA-BDEA-7833C21839FA@xs4all.nl>
References: <268093FF-4916-46BA-BDEA-7833C21839FA@xs4all.nl>
Message-ID: <1694264233.3432028.1461178300914.JavaMail.yahoo@mail.yahoo.com>

Thanks for the help. Sorry, I am not sure why it looks like that in the mailing list - it looks much more neat on my end (see attached file). 

    On Wednesday, April 20, 2016 2:01 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
 

 
> On 20 Apr 2016, at 13:22, A A via R-help <r-help at r-project.org> wrote:
> 
> 
> 
> 
> I have a situation in R where I would like to find any x (if one exists) that solves the linear system of equations Ax = b, where A is square, sparse, and singular, and b is a vector. Here is some code that mimics my issue with a relatively simple A and b, along with three other methods of solving this system that I found online, two of which give me an error and one of which succeeds on the simplified problem, but fails on my data set(attached). Is there a solver in R that I can use in order to get x without any errors given the structure of A? Thanks for your time.
> #CODE STARTS HEREA = as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b = matrix(c(-30,40,-10),nrow=3,ncol=1)
> #solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A (or out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
> #one x that happens to solve Ax = bx = matrix(c(-10,10,0),nrow=3,ncol=1)A %*% x
> #Error in lsfit(A, b) : only 3 cases, but 4 variableslsfit(A,b)#solves the system, but fails belowsolve(qr(A, LAPACK=TRUE),b)#Error in qr.solve(A, b) : singular matrix 'a' in solveqr.solve(A,b)
> #matrices used in my actual problem (see attached files)A = readMM("A.txt")b = readMM("b.txt")
> #Error in as(x, "matrix")[i, , drop = drop] : subscript out of boundssolve(qr(A, LAPACK=TRUE),b)

Your code is a mess. 

A singular square system of linear equations has an infinity of solutions if a solution exists at all.
How that works you can find here: https://en.wikipedia.org/wiki/System_of_linear_equations
in the section "Matrix solutions".

For your simple example you can do it like this:

library(MASS)
Ag <- ginv(A)??? # pseudoinverse

xb <- Ag %*% b # minimum norm solution

Aw <- diag(nrow=nrow(Ag)) - Ag %*% A? # see the Wikipedia page
w <- runif(3)
z <- xb + Aw %*% w
A %*% z - b

N <- Null(t(A))??? # null space of A;? see the help for Null in package MASS
A %*% N
A %*% (xb + 2 * N) - b

For sparse systems you will have to approach this differently; I have no experience with that.

Berend


  

From sidoti.23 at buckeyemail.osu.edu  Wed Apr 20 15:40:13 2016
From: sidoti.23 at buckeyemail.osu.edu (Sidoti, Salvatore A.)
Date: Wed, 20 Apr 2016 13:40:13 +0000
Subject: [R] Splitting Numerical Vector Into Chunks
Message-ID: <CY1PR0101MB10046C9003C13DD9FCAD4B3FAB6D0@CY1PR0101MB1004.prod.exchangelabs.com>

Greetings!

I have several large data sets of animal movements. Their pauses (zero magnitude vectors) are of particular interest in addition to the speed distributions that precede the periods of rest. Here is an example of the kind of data I am interested in analyzing:

x <- abs(c(rnorm(2),replicate(3,0),rnorm(4),replicate(5,0),rnorm(6),replicate(7,0)))
length(x)

This example has 27 elements with strings of zeroes (pauses) situated among the speed values.
Is there a way to split the vector into zero and nonzero chunks and store them in a form where they can be analyzed? I have tried various forms of split() to no avail.

Thank you!
Salvatore A. Sidoti


From 24790 at novasbe.pt  Wed Apr 20 18:07:58 2016
From: 24790 at novasbe.pt (Alexander Nikles)
Date: Wed, 20 Apr 2016 17:07:58 +0100
Subject: [R] Parsing and counting expressions in .txt-files
Message-ID: <CAEFR6QD+XS+vYeV5EQrDwvzUrPdJtK7X5e-49OCJA75Kr_mdUA@mail.gmail.com>

Dear Community,



I hope that I have the right category selected because I am relatively new
to the "R" world. I come with a relatively challenging problem in the
luggage.  I would like to realize, that "R" reads text files (there are
several hundred pieces in my folder) sequentially, and screens for specific
terms. If the term is found, the program should write a 1, if not a 0.
Another task is to scrape a ten-digit number from the file after a
particular keyword, so that I can map the results. The Programm should
create an .txt file ideally.



A brief example:



Keywords: "surpassed" "achieved", "very motivated"

Text1:

"Personnel number: 0123456789



The employee has exceeded the set targets and was also otherwise always
motivated (...) "



So I want that my program for this case, ideally reflects the following (in
lines and columns=



Personell number;surpassed;achieved; very motivated (do not write)
0123456789;1;0;1


For the following files, he shall all continue analogously in line 2, 3, 4
and so on.



Could you give a brief assessment, how to realize such a thing? How do I
start best and whether you are possibly "stumbled" in advance about
something similar in R? I am grateful for any suggestions/proposals.



Thank you in advance,



Alex

	[[alternative HTML version deleted]]


From paulhtremblay at gmail.com  Wed Apr 20 18:36:51 2016
From: paulhtremblay at gmail.com (Paul Tremblay)
Date: Wed, 20 Apr 2016 09:36:51 -0700
Subject: [R] installation problem on Ubuntu
Message-ID: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>

I needed to update R so I could install ggplot. I am running Ubuntu 12.04.
I cannot upgrade Ubuntu because I am using a work computer.

I tried upgrading the normal way:

sudo apt-get update
 sudo apt-get install r-base r-base-dev

But this only installed an earlier version. Finally I tried installing from
source (./configure, Make install). This worked. However, when I try to
install packages, I get this error:

Error in download.file(url, destfile = f, quiet = TRUE) :
  internet routines cannot be loaded
In addition: Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
  unable to load shared object '/usr/local/lib/R/modules//internet.so':
  /usr/local/lib/R/modules//internet.so: undefined symbol: curl_multi_wait


>> ls /usr/local/lib/R/modules/
>> R_X11.so  R_de.so  internet.so  lapack.so

Thanks!

P

	[[alternative HTML version deleted]]


From o.o.wolf at qmul.ac.uk  Wed Apr 20 19:33:54 2016
From: o.o.wolf at qmul.ac.uk (olsen)
Date: Wed, 20 Apr 2016 18:33:54 +0100
Subject: [R] project test data into principal components of training
 dataset
In-Reply-To: <57150942.8080200@qmul.ac.uk>
References: <57150942.8080200@qmul.ac.uk>
Message-ID: <5717BD82.4050809@qmul.ac.uk>

For the records, a slightly hacky answer, by modifying the ggbiplot
function, is provided now here:
http://stackoverflow.com/questions/36603268/how-to-plot-training-and-test-validation-data-in-r-using-ggbiplot

On 18/04/16 17:20, olsen wrote:
> Hi there,
> 
> I've a training dataset and a test dataset. My aim is to visually
> allocate the test data within the calibrated space reassembled by the
> PC's of the training data set, furthermore to keep the training data set
> coordinates fixed, so they can serve as ruler for measurement for
> additional test datasets coming up.
> 
> Please find a minimum working example using the wine dataset below.
> Ideally I would like to use ggbiplot as it comes with the elegant
> features but it only accepts objects of class prcomp, princomp, PCA, or
> lda, which is not fullfilled by the predicted test data.
> 
> I'm still slightly wet behind my R ears and the only solution I can
> think of is to plot the calibrated space in ggbiplot and the training
> data in ggplot and then join them, in the worst case by exporting them
> as svg and importing them in inkscape. Which is slightly complicated
> plus the scaling is different.
> 
> Any indication how this mission can be accomplished very welcome!
> 
> Thanks and greets
> Olsen
> 
> I started a threat on stackoverflow on that issue but know relevant
> indications so far.
> http://stackoverflow.com/questions/36603268/how-to-plot-training-and-test-validation-data-in-r-using-ggbiplot
> 
> ##MWE
> library(ggbiplot)
> data(wine)
> 
> ##pca on the wine dataset used as training data
> wine.pca <- prcomp(wine, center = TRUE, scale. = TRUE)
> 
> wine$class <- wine.class
> 
> ##simulate test data by generating three new wine classes
> wine.new.1 <- wine[c(sample(1:nrow(wine), 25)),]
> wine.new.2 <- wine[c(sample(1:nrow(wine), 43)),]
> wine.new.3 <- wine[c(sample(1:nrow(wine), 36)),]
> 
> ##Predict PCs for the new classes by transforming
> #them using the predict.prcomp function
> pred.new.1 <- predict(wine.pca, newdata = wine.new.1)
> pred.new.2 <- predict(wine.pca, newdata = wine.new.2)
> pred.new.3 <- predict(wine.pca, newdata = wine.new.3)
> 
> #simulate the classes for the new sorts
> wine.new.1$class <- rep("new.wine.1", nrow(wine.new.1))
> wine.new.2$class <- rep("new.wine.2", nrow(wine.new.2))
> wine.new.3$class <- rep("new.wine.3", nrow(wine.new.3))
> wine.new.bind <- rbind(wine.new.1, wine.new.2, wine.new.3)
> 
> ##compose the plot by joining the PCA ggbiplot training data with the
> testing data from ggplot
> #plot the calibrated space resulting from the test data
> g.train <- ggbiplot(wine.pca, obs.scale = 1, var.scale = 1, groups =
> wine$class, ellipse = TRUE, circle = TRUE)
> g.train
> #plot the test data resulting from the prediction
> df.pred = data.frame(PC1 = wine.new.bind[,1], PC2 = wine.new.bind[,2],
>                     PC3 = wine.new.bind[,3], PC4 = wine.new.bind[,4],
>                     classes = wine.new.bind$class)
> g.test <- ggplot(df.pred, aes(PC1, PC2, color = classes, shape =
> classes)) +  geom_point() +  stat_ellipse()
> g.test
> 
> 
> 
> 
> 

-- 
Our solar system is the cream of the crop
http://hasa-labs.org


From G.Maubach at weinwolf.de  Wed Apr 20 08:23:03 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 20 Apr 2016 08:23:03 +0200
Subject: [R] Merging Data Sets with Full Outer Join
Message-ID: <OFCEAA073F.71D9D863-ONC1257F9B.0022E7D3-C1257F9B.0023124A@lotus.hawesko.de>

Hi All,

I would like to match some datasets. Both deliver variables AND cases 
which might or might not be present in all datasets:

This sequence

Kunden <- Kunden_2011 
Kunden <- merge(Kunden, Kunden_2012,
                by.x = "Debitor", by.y = "Debitor")

Kunden <- merge(Kunden, Kunden_2013,
                by.x = "Debitor", by.y = "Debitor")

Kunden <- merge(Kunden, Kunden_2014,
                by.x = "Debitor", by.y = "Debitor")

Kunden <- merge(Kunden, Kunden_2015,
                by.x = "Debitor", by.y = "Debitor")

delivers too few cases. So I guess it does an equi-join.

How can I join the datasets and keep the variables as well as the cases?

I am looking forward to your reply.

Kind regards

Georg


From dwinsemius at comcast.net  Wed Apr 20 21:44:39 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Apr 2016 12:44:39 -0700
Subject: [R] Merging Data Sets with Full Outer Join
In-Reply-To: <OFCEAA073F.71D9D863-ONC1257F9B.0022E7D3-C1257F9B.0023124A@lotus.hawesko.de>
References: <OFCEAA073F.71D9D863-ONC1257F9B.0022E7D3-C1257F9B.0023124A@lotus.hawesko.de>
Message-ID: <429AC0B1-87C6-4087-ADD7-54E1D8A6DE48@comcast.net>


> On Apr 19, 2016, at 11:23 PM, G.Maubach at weinwolf.de wrote:
> 
> Hi All,
> 
> I would like to match some datasets. Both deliver variables AND cases 
> which might or might not be present in all datasets:
> 
> This sequence
> 
> Kunden <- Kunden_2011 
> Kunden <- merge(Kunden, Kunden_2012,
>                by.x = "Debitor", by.y = "Debitor")
> 
> Kunden <- merge(Kunden, Kunden_2013,
>                by.x = "Debitor", by.y = "Debitor")
> 
> Kunden <- merge(Kunden, Kunden_2014,
>                by.x = "Debitor", by.y = "Debitor")
> 
> Kunden <- merge(Kunden, Kunden_2015,
>                by.x = "Debitor", by.y = "Debitor")
> 
> delivers too few cases. So I guess it does an equi-join.

You should not be guessing. Read the help page. It calls the default setting a natural join.

> 
> How can I join the datasets and keep the variables as well as the cases?
> 

If you want a full outer join use all=TRUE. This, too, should have been in the ?merge help page.


> I am looking forward to your reply.
> 
> Kind regards
> 
> Georg
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From istazahn at gmail.com  Wed Apr 20 21:46:37 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 20 Apr 2016 15:46:37 -0400
Subject: [R] Merging Data Sets with Full Outer Join
In-Reply-To: <OFCEAA073F.71D9D863-ONC1257F9B.0022E7D3-C1257F9B.0023124A@lotus.hawesko.de>
References: <OFCEAA073F.71D9D863-ONC1257F9B.0022E7D3-C1257F9B.0023124A@lotus.hawesko.de>
Message-ID: <CA+vqiLH3-VZ8j3eZpmDmafPWVOBxTUQsSzB3V3qHcctNZ8JsJw@mail.gmail.com>

Kunden <- Kunden_2011
Kunden <- merge(Kunden, Kunden_2012,
                by = "Debitor", all = TRUE)

etc.

See ?merge for details.

Best,
Ista

On Wed, Apr 20, 2016 at 2:23 AM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I would like to match some datasets. Both deliver variables AND cases
> which might or might not be present in all datasets:
>
> This sequence
>
> Kunden <- Kunden_2011
> Kunden <- merge(Kunden, Kunden_2012,
>                 by.x = "Debitor", by.y = "Debitor")
>
> Kunden <- merge(Kunden, Kunden_2013,
>                 by.x = "Debitor", by.y = "Debitor")
>
> Kunden <- merge(Kunden, Kunden_2014,
>                 by.x = "Debitor", by.y = "Debitor")
>
> Kunden <- merge(Kunden, Kunden_2015,
>                 by.x = "Debitor", by.y = "Debitor")
>
> delivers too few cases. So I guess it does an equi-join.
>
> How can I join the datasets and keep the variables as well as the cases?
>
> I am looking forward to your reply.
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Apr 20 21:49:23 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 20 Apr 2016 15:49:23 -0400
Subject: [R] Splitting Numerical Vector Into Chunks
In-Reply-To: <CY1PR0101MB10046C9003C13DD9FCAD4B3FAB6D0@CY1PR0101MB1004.prod.exchangelabs.com>
References: <CY1PR0101MB10046C9003C13DD9FCAD4B3FAB6D0@CY1PR0101MB1004.prod.exchangelabs.com>
Message-ID: <CA+vqiLGU5CqF1QkAOP0h7sobG9ST_4TBZtO1socYAXfHG_OHMA@mail.gmail.com>

Perhaps

x <- split(x, x == 0)

Best,
Ista

On Wed, Apr 20, 2016 at 9:40 AM, Sidoti, Salvatore A.
<sidoti.23 at buckeyemail.osu.edu> wrote:
> Greetings!
>
> I have several large data sets of animal movements. Their pauses (zero magnitude vectors) are of particular interest in addition to the speed distributions that precede the periods of rest. Here is an example of the kind of data I am interested in analyzing:
>
> x <- abs(c(rnorm(2),replicate(3,0),rnorm(4),replicate(5,0),rnorm(6),replicate(7,0)))
> length(x)
>
> This example has 27 elements with strings of zeroes (pauses) situated among the speed values.
> Is there a way to split the vector into zero and nonzero chunks and store them in a form where they can be analyzed? I have tried various forms of split() to no avail.
>
> Thank you!
> Salvatore A. Sidoti
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Apr 20 21:55:48 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 20 Apr 2016 12:55:48 -0700
Subject: [R] Splitting Numerical Vector Into Chunks
In-Reply-To: <CA+vqiLGU5CqF1QkAOP0h7sobG9ST_4TBZtO1socYAXfHG_OHMA@mail.gmail.com>
References: <CY1PR0101MB10046C9003C13DD9FCAD4B3FAB6D0@CY1PR0101MB1004.prod.exchangelabs.com>
	<CA+vqiLGU5CqF1QkAOP0h7sobG9ST_4TBZtO1socYAXfHG_OHMA@mail.gmail.com>
Message-ID: <CAF8bMcbF0t75+nyrvOVQtautB7-mg9zMOWy5YXww3gyZQcWpsA@mail.gmail.com>

> i <- seq_len(length(x)-1)
> split(x, cumsum(c(TRUE, (x[i]==0) != (x[i+1]==0))))
$`1`
[1] 0.144872972504 0.850797178400

$`2`
[1] 0 0 0

$`3`
[1] 0.199304859380 2.063609410700 0.939393760782 0.838781367540

$`4`
[1] 0 0 0 0 0

$`5`
[1] 0.374688091264 0.488423999452 0.783034615362 0.626990428900
0.138188255307 2.324635712186

$`6`
[1] 0 0 0 0 0 0 0


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Apr 20, 2016 at 12:49 PM, Ista Zahn <istazahn at gmail.com> wrote:

> Perhaps
>
> x <- split(x, x == 0)
>
> Best,
> Ista
>
> On Wed, Apr 20, 2016 at 9:40 AM, Sidoti, Salvatore A.
> <sidoti.23 at buckeyemail.osu.edu> wrote:
> > Greetings!
> >
> > I have several large data sets of animal movements. Their pauses (zero
> magnitude vectors) are of particular interest in addition to the speed
> distributions that precede the periods of rest. Here is an example of the
> kind of data I am interested in analyzing:
> >
> > x <-
> abs(c(rnorm(2),replicate(3,0),rnorm(4),replicate(5,0),rnorm(6),replicate(7,0)))
> > length(x)
> >
> > This example has 27 elements with strings of zeroes (pauses) situated
> among the speed values.
> > Is there a way to split the vector into zero and nonzero chunks and
> store them in a form where they can be analyzed? I have tried various forms
> of split() to no avail.
> >
> > Thank you!
> > Salvatore A. Sidoti
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Apr 20 22:00:47 2016
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 20 Apr 2016 13:00:47 -0700
Subject: [R] Matrix: How create a _row-oriented_ sparse Matrix
	(=dgRMatrix)?
In-Reply-To: <22295.15591.767816.546202@stat.math.ethz.ch>
References: <CAFDcVCRmwh6H63oZCJORdKF6fY304XDZWgLNg6L8fcdkj+qXpA@mail.gmail.com>
	<22295.15591.767816.546202@stat.math.ethz.ch>
Message-ID: <CAFDcVCReSEsLFFxwWJ9VLxvKjZjm1q_j3BZWccYiYGmgO8QhPQ@mail.gmail.com>

On Wed, Apr 20, 2016 at 1:25 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>>     on Tue, 19 Apr 2016 14:04:11 -0700 writes:
>
>     > Using the Matrix package, how can I create a row-oriented sparse
>     > Matrix from scratch populated with some data?  By default a
>     > column-oriented one is created and I'm aware of the note that the
>     > package is optimized for column-oriented ones, but I'm only interested
>     > in using it for holding my sparse row-oriented data and doing basic
>     > subsetting by rows (even using drop=FALSE).
>
>     > Here is what I get when I set up a column-oriented sparse Matrix:
>
>     >> Cc <- Matrix(0, nrow=5, ncol=5, sparse=TRUE)
>     >> Cc[1:3,1] <- 1
>
> A general ("teaching") remark :
> The above use of Matrix() is seen in many places, and is fine
> for small matrices and the case where you only use the `[<-`
> method very few times (as above).
> Also using  Matrix()  is nice when being introduced to using the
> Matrix package.
>
> However, for efficience in non-small cases, do use
>
>    sparseMatrix()
>
> directly to construct sparse matrices.
>
>
>     >> Cc
>     > 5 x 5 sparse Matrix of class "dgCMatrix"
>
>     > [1,] 1 . . . .
>     > [2,] 1 . . . .
>     > [3,] 1 . . . .
>     > [4,] . . . . .
>     > [5,] . . . . .
>     >> str(Cc)
>     > Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
>     > ..@ i       : int [1:3] 0 1 2
>     > ..@ p       : int [1:6] 0 3 3 3 3 3
>     > ..@ Dim     : int [1:2] 5 5
>     > ..@ Dimnames:List of 2
>     > .. ..$ : NULL
>     > .. ..$ : NULL
>     > ..@ x       : num [1:3] 1 1 1
>     > ..@ factors : list()
>
>     > When I try to do the analogue for a row-oriented matrix, I get a
>     > "dgTMatrix", whereas I would expect a "dgRMatrix":
>
>     >> Cr <- Matrix(0, nrow=5, ncol=5, sparse=TRUE)
>     >> Cr <- as(Cr, "dsRMatrix")
>     >> Cr[1,1:3] <- 1
>     >> Cr
>     > 5 x 5 sparse Matrix of class "dgTMatrix"
>
>     > [1,] 1 1 1 . .
>     > [2,] . . . . .
>     > [3,] . . . . .
>     > [4,] . . . . .
>     > [5,] . . . . .
>
> The reason for the above behavior has been
>
> a) efficiency.  All the subassignment ( `[<-` ) methods for
>    "RsparseMatrix" objects (of which "dsRMatrix" is a special case)
>    are implemented via  TsparseMatrix.
> b) because of the general attitude that Csparse (and Tsparse to
>    some extent) are well supported in Matrix,
>    and e.g. further operations on Rsparse matrices would *again*
>    go via T* or C* sparse ones, I had decided to keep things Tsparse.

Thanks, understanding these design decisions is helpful.
Particularly, since I consider myself a rookie when it comes to the
Matrix package.

>
> [...]
>
>     > Trying with explicit coercion does not work:
>
>     >> as(Cc, "dgRMatrix")
>     > Error in as(Cc, "dgRMatrix") :
>     > no method or default for coercing "dgCMatrix" to "dgRMatrix"
>
>     >> as(Cr, "dgRMatrix")
>     > Error in as(Cr, "dgRMatrix") :
>     > no method or default for coercing "dgTMatrix" to "dgRMatrix"
>
> The general philosophy in 'Matrix' with all the class
> hierarchies and the many specific classes has been to allow and
> foster coercing to abstract super classes,
> i.e, to  "dMatrix"  or "generalMatrix", "triangularMatrix", or
> then "denseMatrix", "sparseMatrix", "CsparseMatrix" or
> "RsparseMatrix", etc
>
> So in the above  as(*, "RsparseMatrix")   should work always.

Thanks for pointing this out (and confirming as I since discovered the
virtual RsparseMatrix class in the help).

>
>
> As a summary, in other words,  for what you want,
>
>    as(sparseMatrix(.....), "RsparseMatrix")
>
> should give you what you want reliably and efficiently.

Perfect.

>
>
>     > Am I doing some wrong here?  Or is this what means that the package is
>     > optimized for the column-oriented representation and I shouldn't
>     > really work with row-oriented ones?  I'm really only interested in
>     > access to efficient Cr[row,,drop=FALSE] subsetting (and a small memory
>     > footprint).
>
> { though you could equivalently use   Cc[,row, drop=FALSE]
>   with a CsparseMatrix Cc := t(Cr),
>   couldn't you ?
> }

Yes, I actually went ahead did that, but since the code I'm writing
supports both plain matrix:es and sparse Matrix:es, and the underlying
model operates row-by-row, I figured the code would be more consistent
if I could use row-orientation everywhere.  Not a big deal.

Thanks Martin

Henrik

>
>
> Martin Maechler  (maintainer of 'Matrix')
> ETH Zurich
>


From jdnewmil at dcn.davis.ca.us  Wed Apr 20 22:25:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 20 Apr 2016 13:25:19 -0700
Subject: [R] Solving sparse, singular systems of equations
In-Reply-To: <1694264233.3432028.1461178300914.JavaMail.yahoo@mail.yahoo.com>
References: <268093FF-4916-46BA-BDEA-7833C21839FA@xs4all.nl>
	<1694264233.3432028.1461178300914.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <FDDC9A22-9641-4A8F-8E5F-8CD39D056C00@dcn.davis.ca.us>

The usual culprit in messy code is posting in HTML format. That usually leads to stripping of the formatting by the mailing list and a notice that that occurred, but I don't see that warning here. I still think posting plain text format would fix the problem. 
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2016 11:51:40 AM PDT, A A via R-help <r-help at r-project.org> wrote:
>Thanks for the help. Sorry, I am not sure why it looks like that in the
>mailing list - it looks much more neat on my end (see attached file). 
>
>On Wednesday, April 20, 2016 2:01 PM, Berend Hasselman <bhh at xs4all.nl>
>wrote:
> 
>
> 
>> On 20 Apr 2016, at 13:22, A A via R-help <r-help at r-project.org>
>wrote:
>> 
>> 
>> 
>> 
>> I have a situation in R where I would like to find any x (if one
>exists) that solves the linear system of equations Ax = b, where A is
>square, sparse, and singular, and b is a vector. Here is some code that
>mimics my issue with a relatively simple A and b, along with three
>other methods of solving this system that I found online, two of which
>give me an error and one of which succeeds on the simplified problem,
>but fails on my data set(attached). Is there a solver in R that I can
>use in order to get x without any errors given the structure of A?
>Thanks for your time.
>> #CODE STARTS HEREA =
>as(matrix(c(1.5,-1.5,0,-1.5,2.5,-1,0,-1,1),nrow=3,ncol=3),"sparseMatrix")b
>= matrix(c(-30,40,-10),nrow=3,ncol=1)
>> #solve for x, Error in LU.dgC(a) : cs_lu(A) failed: near-singular A
>(or out of memory)solve(A,b,sparse=TRUE,tol=.Machine$double.eps)
>> #one x that happens to solve Ax = bx =
>matrix(c(-10,10,0),nrow=3,ncol=1)A %*% x
>> #Error in lsfit(A, b) : only 3 cases, but 4
>variableslsfit(A,b)#solves the system, but fails belowsolve(qr(A,
>LAPACK=TRUE),b)#Error in qr.solve(A, b) : singular matrix 'a' in
>solveqr.solve(A,b)
>> #matrices used in my actual problem (see attached files)A =
>readMM("A.txt")b = readMM("b.txt")
>> #Error in as(x, "matrix")[i, , drop = drop] : subscript out of
>boundssolve(qr(A, LAPACK=TRUE),b)
>
>Your code is a mess. 
>
>A singular square system of linear equations has an infinity of
>solutions if a solution exists at all.
>How that works you can find here:
>https://en.wikipedia.org/wiki/System_of_linear_equations
>in the section "Matrix solutions".
>
>For your simple example you can do it like this:
>
>library(MASS)
>Ag <- ginv(A)??? # pseudoinverse
>
>xb <- Ag %*% b # minimum norm solution
>
>Aw <- diag(nrow=nrow(Ag)) - Ag %*% A? # see the Wikipedia page
>w <- runif(3)
>z <- xb + Aw %*% w
>A %*% z - b
>
>N <- Null(t(A))??? # null space of A;? see the help for Null in package
>MASS
>A %*% N
>A %*% (xb + 2 * N) - b
>
>For sparse systems you will have to approach this differently; I have
>no experience with that.
>
>Berend
>
>
>  
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Apr 20 23:00:42 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 20 Apr 2016 14:00:42 -0700
Subject: [R] Parsing and counting expressions in .txt-files
In-Reply-To: <CAEFR6QD+XS+vYeV5EQrDwvzUrPdJtK7X5e-49OCJA75Kr_mdUA@mail.gmail.com>
References: <CAEFR6QD+XS+vYeV5EQrDwvzUrPdJtK7X5e-49OCJA75Kr_mdUA@mail.gmail.com>
Message-ID: <CAGxFJbSU=4N7kmUoVOuYNw3ihQ6WcdBdeZw11N-rQh7UhH4Y5Q@mail.gmail.com>

I suggest you go through some R tutorials to learn about R's
capabilities.  Some recommendations can be found here:
https://www.rstudio.com/online-learning/#R

To answer your specific query:

?scan  ## Because you do not specify file format.

?grep  ?regexp ## to use regular expressions to find text.

R may not be the best tool for this task, however. Or certain R
packages may be better than the basic R tools. Try searching on the
rseek.org site to see what might be available if you do not receive
suggestions here.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 20, 2016 at 9:07 AM, Alexander Nikles <24790 at novasbe.pt> wrote:
> Dear Community,
>
>
>
> I hope that I have the right category selected because I am relatively new
> to the "R" world. I come with a relatively challenging problem in the
> luggage.  I would like to realize, that "R" reads text files (there are
> several hundred pieces in my folder) sequentially, and screens for specific
> terms. If the term is found, the program should write a 1, if not a 0.
> Another task is to scrape a ten-digit number from the file after a
> particular keyword, so that I can map the results. The Programm should
> create an .txt file ideally.
>
>
>
> A brief example:
>
>
>
> Keywords: "surpassed" "achieved", "very motivated"
>
> Text1:
>
> "Personnel number: 0123456789
>
>
>
> The employee has exceeded the set targets and was also otherwise always
> motivated (...) "
>
>
>
> So I want that my program for this case, ideally reflects the following (in
> lines and columns=
>
>
>
> Personell number;surpassed;achieved; very motivated (do not write)
> 0123456789;1;0;1
>
>
> For the following files, he shall all continue analogously in line 2, 3, 4
> and so on.
>
>
>
> Could you give a brief assessment, how to realize such a thing? How do I
> start best and whether you are possibly "stumbled" in advance about
> something similar in R? I am grateful for any suggestions/proposals.
>
>
>
> Thank you in advance,
>
>
>
> Alex
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Apr 20 23:35:29 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 20 Apr 2016 14:35:29 -0700
Subject: [R] Parsing and counting expressions in .txt-files
In-Reply-To: <CAEFR6QD+XS+vYeV5EQrDwvzUrPdJtK7X5e-49OCJA75Kr_mdUA@mail.gmail.com>
References: <CAEFR6QD+XS+vYeV5EQrDwvzUrPdJtK7X5e-49OCJA75Kr_mdUA@mail.gmail.com>
Message-ID: <CAGxFJbRW822Zo5BEmhKWkNOeF=-K73Jz9Lxu-=9wK0s4Fhb-7A@mail.gmail.com>

also check out this CRAN task view:

https://cran.r-project.org/web/views/NaturalLanguageProcessing.html

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 20, 2016 at 9:07 AM, Alexander Nikles <24790 at novasbe.pt> wrote:
> Dear Community,
>
>
>
> I hope that I have the right category selected because I am relatively new
> to the "R" world. I come with a relatively challenging problem in the
> luggage.  I would like to realize, that "R" reads text files (there are
> several hundred pieces in my folder) sequentially, and screens for specific
> terms. If the term is found, the program should write a 1, if not a 0.
> Another task is to scrape a ten-digit number from the file after a
> particular keyword, so that I can map the results. The Programm should
> create an .txt file ideally.
>
>
>
> A brief example:
>
>
>
> Keywords: "surpassed" "achieved", "very motivated"
>
> Text1:
>
> "Personnel number: 0123456789
>
>
>
> The employee has exceeded the set targets and was also otherwise always
> motivated (...) "
>
>
>
> So I want that my program for this case, ideally reflects the following (in
> lines and columns=
>
>
>
> Personell number;surpassed;achieved; very motivated (do not write)
> 0123456789;1;0;1
>
>
> For the following files, he shall all continue analogously in line 2, 3, 4
> and so on.
>
>
>
> Could you give a brief assessment, how to realize such a thing? How do I
> start best and whether you are possibly "stumbled" in advance about
> something similar in R? I am grateful for any suggestions/proposals.
>
>
>
> Thank you in advance,
>
>
>
> Alex
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Thu Apr 21 00:01:43 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Wed, 20 Apr 2016 22:01:43 +0000 (UTC)
Subject: [R] overlay two facet_grid
References: <1264450772.6793560.1461189703268.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1264450772.6793560.1461189703268.JavaMail.yahoo@mail.yahoo.com>

Hi all,
Does anyone know how to overlay two facet_grids? I have two facet grids as following:


ggplot(data=df,aes(x=TE,y=TR,color="orange"))+geom_point()+facet_grid(FS+TRJ~OR+INV,labeller=label_both)+xlim(0,200)+ylim(0,10000)
ggplot(data=df,aes(x=TE,y=TR))+geom_point(aes(color=TST))+facet_grid(FS+TRJ~OR+INV,labeller=label_both)+xlim(0,200)+ylim(0,10000)

Thanks for any help!
Elahe


From jdnewmil at dcn.davis.ca.us  Thu Apr 21 00:48:51 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 20 Apr 2016 15:48:51 -0700
Subject: [R] overlay two facet_grid
In-Reply-To: <1264450772.6793560.1461189703268.JavaMail.yahoo@mail.yahoo.com>
References: <1264450772.6793560.1461189703268.JavaMail.yahoo.ref@mail.yahoo.com>
	<1264450772.6793560.1461189703268.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <A7443591-053B-4522-8F3E-B63D3E3A8D2E@dcn.davis.ca.us>

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

Overlaying aesthetics is possible. Overlaying graphs is not. Without sample data, concrete examples will be unlikely to  appear, so read the above link and pay attention to the dput function. 
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2016 3:01:43 PM PDT, "ch.elahe via R-help" <r-help at r-project.org> wrote:
>Hi all,
>Does anyone know how to overlay two facet_grids? I have two facet grids
>as following:
>
>
>ggplot(data=df,aes(x=TE,y=TR,color="orange"))+geom_point()+facet_grid(FS+TRJ~OR+INV,labeller=label_both)+xlim(0,200)+ylim(0,10000)
>ggplot(data=df,aes(x=TE,y=TR))+geom_point(aes(color=TST))+facet_grid(FS+TRJ~OR+INV,labeller=label_both)+xlim(0,200)+ylim(0,10000)
>
>Thanks for any help!
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Apr 21 00:57:32 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 20 Apr 2016 15:57:32 -0700
Subject: [R] installation problem on Ubuntu
In-Reply-To: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>
References: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>
Message-ID: <490462CC-2F37-44D4-A467-E87D7CD2BE7D@dcn.davis.ca.us>

Have you read the CRAN  instructions for installing on Ubuntu?  Have you read the Posting Guide that mentions the R-sig-debian mailing list and that if you need help compiling R this is not the right list?
-- 
Sent from my phone. Please excuse my brevity.

On April 20, 2016 9:36:51 AM PDT, Paul Tremblay <paulhtremblay at gmail.com> wrote:
>I needed to update R so I could install ggplot. I am running Ubuntu
>12.04.
>I cannot upgrade Ubuntu because I am using a work computer.
>
>I tried upgrading the normal way:
>
>sudo apt-get update
> sudo apt-get install r-base r-base-dev
>
>But this only installed an earlier version. Finally I tried installing
>from
>source (./configure, Make install). This worked. However, when I try to
>install packages, I get this error:
>
>Error in download.file(url, destfile = f, quiet = TRUE) :
>  internet routines cannot be loaded
>In addition: Warning message:
>In download.file(url, destfile = f, quiet = TRUE) :
>  unable to load shared object '/usr/local/lib/R/modules//internet.so':
>/usr/local/lib/R/modules//internet.so: undefined symbol:
>curl_multi_wait
>
>
>>> ls /usr/local/lib/R/modules/
>>> R_X11.so  R_de.so  internet.so  lapack.so
>
>Thanks!
>
>P
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Apr 21 01:22:41 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 21 Apr 2016 09:22:41 +1000
Subject: [R] Data reshaping with conditions
In-Reply-To: <CAGO7QoM0VUEobcEcVsR5uWuzXRfChJWya=tkUigURg-38VzeOA@mail.gmail.com>
References: <CAGO7QoM0VUEobcEcVsR5uWuzXRfChJWya=tkUigURg-38VzeOA@mail.gmail.com>
Message-ID: <CA+8X3fXRa2ivH1=p=_98+_anr+uQsO-zKb3pdkrN0moQyMBc2Q@mail.gmail.com>

Hi sri,
As your problem involves a few logical steps, I found it easier to
approach it in a stepwise way. Perhaps there are more elegant ways to
accomplish this.

svdat<-read.table(text="Count id name type
117 335 sally A
19 335 sally A
167 335 sally B
18 340 susan A
56 340 susan A
22 340 susan B
53 340 susan B
135 351 lee A
114 351 lee A
84 351 lee A
80 351 lee A
19 351 lee A
8 351 lee A
21 351 lee A
88 351 lee B
111 351 lee B
46 351 lee B
108 351 lee B",header=TRUE)
# you can also do this with other reshape functions
library(prettyR)
svdatstr<-stretch_df(svdat,"id",c("Count","type"))
count_ind<-grep("Count",names(svdatstr))
type_ind<-grep("type",names(svdatstr))
svdatstr$maxA<-NA
svdatstr$maxB<-NA
svdatstr$x<-NA
svdatstr$y<-NA
for(row in 1:nrow(svdatstr)) {
 svdatstr[row,"maxA"]<-
  max(svdatstr[row,count_ind[as.logical(match(svdatstr[1,type_ind],"A",0))]])
 svdatstr[row,"maxB"]<-
  max(svdatstr[row,count_ind[as.logical(match(svdatstr[1,type_ind],"B",0))]])
 svdatstr[row,"x"]<-svdatstr[row,"maxA"] < svdatstr[row,"maxB"]
 svdatstr[row,"y"]<-!svdatstr[row,"x"]
}
svdatstr

You can then just extract the columns that you need.

Jim


On Wed, Apr 20, 2016 at 3:03 PM, sri vathsan <srivibish at gmail.com> wrote:
> Dear All,
>
> I am trying to reshape the data with some conditions. A small part of the
> data looks like below. Like this there will be more data with repeating ID.
>
> Count id name type
> 117 335 sally A
> 19 335 sally A
> 167 335 sally B
> 18 340 susan A
> 56 340 susan A
> 22 340 susan B
> 53 340 susan B
> 135 351 lee A
> 114 351 lee A
> 84 351 lee A
> 80 351 lee A
> 19 351 lee A
> 8 351 lee A
> 21 351 lee A
> 88 351 lee B
> 111 351 lee B
> 46 351 lee B
> 108 351 lee B
>
> >From the above data I am expecting an output like below.
>
> id name type count_of_B Max of count B     x               y
> 335 sally B 167 167 117,19      NA
> 340 susan B 22,53 53 18              56
> 351 lee B 88,111,46,108  111 84,80,19,8,2   135,114
>
> Where, the column x and column y are:
>
> x = Count_A_less_than_max of (Count type B)
> y = Count_A_higher_than_max of (Count type B).
>
> *1)* I tried with dplyr with the following code for the initial step to get
> the values for each column.
> *2)*  I thought to transpose the columns which has the unique ID alone.
>
> I tried with the following code and I am struck with the intial step
> itself. The code is executed but higher and lower value of A is not coming.
>
> Expected_output= data %>%
>   group_by(id, Type) %>%
>   mutate(Count_of_B = paste(unlist(count[Type=="B"]), collapse = ","))%>%
>   mutate(Max_of_count_B = ifelse(Type == "B", max(count[Type ==
> "B"]),max(count[Type == "A"]))) %>%
>   mutate(count_type_A_lesser = ifelse
> (Type=="B",(paste(unlist(count[Type=="A"]) < Max_of_count_B[Type=="B"],
> collapse = ",")), "NA"))%>%
>   mutate(count_type_A_higher =
> ifelse(Type=="B",(paste(unlist(count[Type=="A"]) >
> Max_of_count_B[Type=="B"], collapse = ",")), "NA"))
>
> I hope I make my point clear. Please bare with the code, as I am new to
> this.
>
> Regards,
> sri
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Thu Apr 21 06:10:08 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 21 Apr 2016 04:10:08 +0000
Subject: [R] overlay two facet_grid
In-Reply-To: <A7443591-053B-4522-8F3E-B63D3E3A8D2E@dcn.davis.ca.us>
References: <1264450772.6793560.1461189703268.JavaMail.yahoo.ref@mail.yahoo.com>
	<1264450772.6793560.1461189703268.JavaMail.yahoo@mail.yahoo.com>
	<A7443591-053B-4522-8F3E-B63D3E3A8D2E@dcn.davis.ca.us>
Message-ID: <CAKVAULMzoMvxdGNaybUmVRa9KdQRR+Q2k2omWRHcrPnDptxbcQ@mail.gmail.com>

It sounds like you want to use grid.arrange() from gridExtra:
https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.html

Hope this helps,
Ulrik

On Thu, 21 Apr 2016 at 00:52 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> Overlaying aesthetics is possible. Overlaying graphs is not. Without
> sample data, concrete examples will be unlikely to  appear, so read the
> above link and pay attention to the dput function.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 20, 2016 3:01:43 PM PDT, "ch.elahe via R-help" <
> r-help at r-project.org> wrote:
> >Hi all,
> >Does anyone know how to overlay two facet_grids? I have two facet grids
> >as following:
> >
> >
>
> >ggplot(data=df,aes(x=TE,y=TR,color="orange"))+geom_point()+facet_grid(FS+TRJ~OR+INV,labeller=label_both)+xlim(0,200)+ylim(0,10000)
>
> >ggplot(data=df,aes(x=TE,y=TR))+geom_point(aes(color=TST))+facet_grid(FS+TRJ~OR+INV,labeller=label_both)+xlim(0,200)+ylim(0,10000)
> >
> >Thanks for any help!
> >Elahe
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Apr 21 06:53:03 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 21 Apr 2016 14:53:03 +1000
Subject: [R] Data reshaping with conditions
In-Reply-To: <CAGO7QoMs6VmskNJkNu-xuh8C-ze73miYUE7eyMT1=RXzJf_8Vg@mail.gmail.com>
References: <CAGO7QoM0VUEobcEcVsR5uWuzXRfChJWya=tkUigURg-38VzeOA@mail.gmail.com>
	<CA+8X3fXRa2ivH1=p=_98+_anr+uQsO-zKb3pdkrN0moQyMBc2Q@mail.gmail.com>
	<CAGO7QoMs6VmskNJkNu-xuh8C-ze73miYUE7eyMT1=RXzJf_8Vg@mail.gmail.com>
Message-ID: <CA+8X3fVTOwBQ5ssLH6D5kop522a_XiE9AHRLSpey5s4+pc9-bQ@mail.gmail.com>

Hi sri,
I think that I see what you mean. Your statements:

x = Count_A_less_than_max of (Count type B)
y = Count_A_higher_than_max of (Count type B).

I took to mean that you wanted a logical value for x and y. Looking
more closely at your initial message, I see that you wanted _all_
values of A with respect to maxB in x and y. The error with maximum
values was due to a typo. Perhaps this will do what you want:

svdat<-read.table(text="Count id name type
117 335 sally A
19 335 sally A
167 335 sally B
18 340 susan A
56 340 susan A
22 340 susan B
53 340 susan B
135 351 lee A
114 351 lee A
84 351 lee A
80 351 lee A
19 351 lee A
8 351 lee A
21 351 lee A
88 351 lee B
111 351 lee B
46 351 lee B
108 351 lee B",header=TRUE)
# you can also do this with other reshape functions
library(prettyR)
svdatstr<-stretch_df(svdat,"id",c("Count","type"))
count_ind<-grep("Count",names(svdatstr))
type_ind<-grep("type",names(svdatstr))
svdatstr$maxA<-NA
svdatstr$maxB<-NA
svdatstr$x<-NA
svdatstr$y<-NA
for(row in 1:nrow(svdatstr)) {
 indicesA<-count_ind[as.logical(match(svdatstr[row,type_ind],"A",0))]
 svdatstr[row,"maxA"]<-max(svdatstr[row,indicesA])
 indicesB<-count_ind[as.logical(match(svdatstr[row,type_ind],"B",0))]
 svdatstr[row,"maxB"]<-max(svdatstr[row,indicesB])
 AltB<-svdatstr[row,indicesA][svdatstr[row,indicesA]<svdatstr[row,"maxB"]]
 svdatstr[row,"x"]<-paste(AltB,collapse=",")
 AgeB<-svdatstr[row,indicesA][svdatstr[row,indicesA]>=svdatstr[row,"maxB"]]
 svdatstr[row,"y"]<-paste(AgeB,collapse=",")
}
svdatstr[,c("id","name","maxB","x","y")]

Jim


On Thu, Apr 21, 2016 at 2:23 PM, sri vathsan <srivibish at gmail.com> wrote:
> Hi Jim,
>
> Thanks for your time. But somehow this code did not help me to achieve my
> expected output.
> Problems: 1) x, y are coming as logical rather than values as I mentioned in
> my post
>                2) The values that I get for Max A and Max B not correct
>                3) It looks like a pretty big data, but I just need to
> concatenate the values with a comma, the final output will be a character
> variable.
>
> Regards,
> Sri
>
> On Thu, Apr 21, 2016 at 4:52 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi sri,
>> As your problem involves a few logical steps, I found it easier to
>> approach it in a stepwise way. Perhaps there are more elegant ways to
>> accomplish this.
>>
>> svdat<-read.table(text="Count id name type
>> 117 335 sally A
>> 19 335 sally A
>> 167 335 sally B
>> 18 340 susan A
>> 56 340 susan A
>> 22 340 susan B
>> 53 340 susan B
>> 135 351 lee A
>> 114 351 lee A
>> 84 351 lee A
>> 80 351 lee A
>> 19 351 lee A
>> 8 351 lee A
>> 21 351 lee A
>> 88 351 lee B
>> 111 351 lee B
>> 46 351 lee B
>> 108 351 lee B",header=TRUE)
>> # you can also do this with other reshape functions
>> library(prettyR)
>> svdatstr<-stretch_df(svdat,"id",c("Count","type"))
>> count_ind<-grep("Count",names(svdatstr))
>> type_ind<-grep("type",names(svdatstr))
>> svdatstr$maxA<-NA
>> svdatstr$maxB<-NA
>> svdatstr$x<-NA
>> svdatstr$y<-NA
>> for(row in 1:nrow(svdatstr)) {
>>  svdatstr[row,"maxA"]<-
>>
>> max(svdatstr[row,count_ind[as.logical(match(svdatstr[1,type_ind],"A",0))]])
>>  svdatstr[row,"maxB"]<-
>>
>> max(svdatstr[row,count_ind[as.logical(match(svdatstr[1,type_ind],"B",0))]])
>>  svdatstr[row,"x"]<-svdatstr[row,"maxA"] < svdatstr[row,"maxB"]
>>  svdatstr[row,"y"]<-!svdatstr[row,"x"]
>> }
>> svdatstr
>>
>> You can then just extract the columns that you need.
>>
>> Jim
>>
>>
>> On Wed, Apr 20, 2016 at 3:03 PM, sri vathsan <srivibish at gmail.com> wrote:
>> > Dear All,
>> >
>> > I am trying to reshape the data with some conditions. A small part of
>> > the
>> > data looks like below. Like this there will be more data with repeating
>> > ID.
>> >
>> > Count id name type
>> > 117 335 sally A
>> > 19 335 sally A
>> > 167 335 sally B
>> > 18 340 susan A
>> > 56 340 susan A
>> > 22 340 susan B
>> > 53 340 susan B
>> > 135 351 lee A
>> > 114 351 lee A
>> > 84 351 lee A
>> > 80 351 lee A
>> > 19 351 lee A
>> > 8 351 lee A
>> > 21 351 lee A
>> > 88 351 lee B
>> > 111 351 lee B
>> > 46 351 lee B
>> > 108 351 lee B
>> >
>> > >From the above data I am expecting an output like below.
>> >
>> > id name type count_of_B Max of count B     x               y
>> > 335 sally B 167 167 117,19      NA
>> > 340 susan B 22,53 53 18              56
>> > 351 lee B 88,111,46,108  111 84,80,19,8,2   135,114
>> >
>> > Where, the column x and column y are:
>> >
>> > x = Count_A_less_than_max of (Count type B)
>> > y = Count_A_higher_than_max of (Count type B).
>> >
>> > *1)* I tried with dplyr with the following code for the initial step to
>> > get
>> > the values for each column.
>> > *2)*  I thought to transpose the columns which has the unique ID alone.
>> >
>> > I tried with the following code and I am struck with the intial step
>> > itself. The code is executed but higher and lower value of A is not
>> > coming.
>> >
>> > Expected_output= data %>%
>> >   group_by(id, Type) %>%
>> >   mutate(Count_of_B = paste(unlist(count[Type=="B"]), collapse =
>> > ","))%>%
>> >   mutate(Max_of_count_B = ifelse(Type == "B", max(count[Type ==
>> > "B"]),max(count[Type == "A"]))) %>%
>> >   mutate(count_type_A_lesser = ifelse
>> > (Type=="B",(paste(unlist(count[Type=="A"]) < Max_of_count_B[Type=="B"],
>> > collapse = ",")), "NA"))%>%
>> >   mutate(count_type_A_higher =
>> > ifelse(Type=="B",(paste(unlist(count[Type=="A"]) >
>> > Max_of_count_B[Type=="B"], collapse = ",")), "NA"))
>> >
>> > I hope I make my point clear. Please bare with the code, as I am new to
>> > this.
>> >
>> > Regards,
>> > sri
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
>
> Regards,
> Srivathsan.K
> Phone : 9600165206


From srivibish at gmail.com  Thu Apr 21 06:23:25 2016
From: srivibish at gmail.com (sri vathsan)
Date: Thu, 21 Apr 2016 09:53:25 +0530
Subject: [R] Data reshaping with conditions
In-Reply-To: <CA+8X3fXRa2ivH1=p=_98+_anr+uQsO-zKb3pdkrN0moQyMBc2Q@mail.gmail.com>
References: <CAGO7QoM0VUEobcEcVsR5uWuzXRfChJWya=tkUigURg-38VzeOA@mail.gmail.com>
	<CA+8X3fXRa2ivH1=p=_98+_anr+uQsO-zKb3pdkrN0moQyMBc2Q@mail.gmail.com>
Message-ID: <CAGO7QoMs6VmskNJkNu-xuh8C-ze73miYUE7eyMT1=RXzJf_8Vg@mail.gmail.com>

Hi Jim,

Thanks for your time. But somehow this code did not help me to achieve my
expected output.
Problems: 1) x, y are coming as logical rather than values as I mentioned
in my post
               2) The values that I get for Max A and Max B not correct
               3) It looks like a pretty big data, but I just need to
concatenate the values with a comma, the final output will be a character
variable.

Regards,
Sri

On Thu, Apr 21, 2016 at 4:52 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi sri,
> As your problem involves a few logical steps, I found it easier to
> approach it in a stepwise way. Perhaps there are more elegant ways to
> accomplish this.
>
> svdat<-read.table(text="Count id name type
> 117 335 sally A
> 19 335 sally A
> 167 335 sally B
> 18 340 susan A
> 56 340 susan A
> 22 340 susan B
> 53 340 susan B
> 135 351 lee A
> 114 351 lee A
> 84 351 lee A
> 80 351 lee A
> 19 351 lee A
> 8 351 lee A
> 21 351 lee A
> 88 351 lee B
> 111 351 lee B
> 46 351 lee B
> 108 351 lee B",header=TRUE)
> # you can also do this with other reshape functions
> library(prettyR)
> svdatstr<-stretch_df(svdat,"id",c("Count","type"))
> count_ind<-grep("Count",names(svdatstr))
> type_ind<-grep("type",names(svdatstr))
> svdatstr$maxA<-NA
> svdatstr$maxB<-NA
> svdatstr$x<-NA
> svdatstr$y<-NA
> for(row in 1:nrow(svdatstr)) {
>  svdatstr[row,"maxA"]<-
>
> max(svdatstr[row,count_ind[as.logical(match(svdatstr[1,type_ind],"A",0))]])
>  svdatstr[row,"maxB"]<-
>
> max(svdatstr[row,count_ind[as.logical(match(svdatstr[1,type_ind],"B",0))]])
>  svdatstr[row,"x"]<-svdatstr[row,"maxA"] < svdatstr[row,"maxB"]
>  svdatstr[row,"y"]<-!svdatstr[row,"x"]
> }
> svdatstr
>
> You can then just extract the columns that you need.
>
> Jim
>
>
> On Wed, Apr 20, 2016 at 3:03 PM, sri vathsan <srivibish at gmail.com> wrote:
> > Dear All,
> >
> > I am trying to reshape the data with some conditions. A small part of the
> > data looks like below. Like this there will be more data with repeating
> ID.
> >
> > Count id name type
> > 117 335 sally A
> > 19 335 sally A
> > 167 335 sally B
> > 18 340 susan A
> > 56 340 susan A
> > 22 340 susan B
> > 53 340 susan B
> > 135 351 lee A
> > 114 351 lee A
> > 84 351 lee A
> > 80 351 lee A
> > 19 351 lee A
> > 8 351 lee A
> > 21 351 lee A
> > 88 351 lee B
> > 111 351 lee B
> > 46 351 lee B
> > 108 351 lee B
> >
> > >From the above data I am expecting an output like below.
> >
> > id name type count_of_B Max of count B     x               y
> > 335 sally B 167 167 117,19      NA
> > 340 susan B 22,53 53 18              56
> > 351 lee B 88,111,46,108  111 84,80,19,8,2   135,114
> >
> > Where, the column x and column y are:
> >
> > x = Count_A_less_than_max of (Count type B)
> > y = Count_A_higher_than_max of (Count type B).
> >
> > *1)* I tried with dplyr with the following code for the initial step to
> get
> > the values for each column.
> > *2)*  I thought to transpose the columns which has the unique ID alone.
> >
> > I tried with the following code and I am struck with the intial step
> > itself. The code is executed but higher and lower value of A is not
> coming.
> >
> > Expected_output= data %>%
> >   group_by(id, Type) %>%
> >   mutate(Count_of_B = paste(unlist(count[Type=="B"]), collapse = ","))%>%
> >   mutate(Max_of_count_B = ifelse(Type == "B", max(count[Type ==
> > "B"]),max(count[Type == "A"]))) %>%
> >   mutate(count_type_A_lesser = ifelse
> > (Type=="B",(paste(unlist(count[Type=="A"]) < Max_of_count_B[Type=="B"],
> > collapse = ",")), "NA"))%>%
> >   mutate(count_type_A_higher =
> > ifelse(Type=="B",(paste(unlist(count[Type=="A"]) >
> > Max_of_count_B[Type=="B"], collapse = ",")), "NA"))
> >
> > I hope I make my point clear. Please bare with the code, as I am new to
> > this.
> >
> > Regards,
> > sri
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 

Regards,
Srivathsan.K
Phone : 9600165206

	[[alternative HTML version deleted]]


From giftedlife2014 at gmail.com  Thu Apr 21 06:58:14 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Thu, 21 Apr 2016 05:58:14 +0100
Subject: [R] Mailing List
Message-ID: <CAC8ss33gKV9CjF6HC4mDHJfGFZjN490h-RU500=3gscGXocbhA@mail.gmail.com>

Dear All,
I am using R to do my work and thank you very much for developing,
maintaining and making such excellent software available to anyone
that is interested enough to ask for it.

 I have registered at Nabble. I was wondering the right forum for me
to send my help request. I have tried sending to R-help at r-project.org.
However, I do receive a kind of warning email stating that my email
awaits approval from the moderator since I am a non-member posting to
membership email.

Can any one please direct me to the right forum for me. My problem
range from plotting graph using R, statistics in R, etc. You could
have seen some of my request this few days.

Thank you for your time.
Ogbos


From pdalgd at gmail.com  Thu Apr 21 09:38:29 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 Apr 2016 09:38:29 +0200
Subject: [R] Mailing List
In-Reply-To: <CAC8ss33gKV9CjF6HC4mDHJfGFZjN490h-RU500=3gscGXocbhA@mail.gmail.com>
References: <CAC8ss33gKV9CjF6HC4mDHJfGFZjN490h-RU500=3gscGXocbhA@mail.gmail.com>
Message-ID: <C56D398B-73D7-4407-B98D-677B7EBDCFB0@gmail.com>


> On 21 Apr 2016, at 06:58 , Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear All,
> I am using R to do my work and thank you very much for developing,
> maintaining and making such excellent software available to anyone
> that is interested enough to ask for it.
> 
> I have registered at Nabble. I was wondering the right forum for me
> to send my help request. I have tried sending to R-help at r-project.org.
> However, I do receive a kind of warning email stating that my email
> awaits approval from the moderator since I am a non-member posting to
> membership email.
> 

If you send to r-help at r-project.org and just wait for a moderator to approve your post, it will get here eventually. r-help-request is a dead end.

However, the canonical way is to subscribe to the mailing list. You do this using the link in the footer  (same one as for unsubscribing). Notice that you can select to get the list in digest format (1 mail per day) or - as I think most do - set up a filter rule in your mail reader to send messages to a separate mailbox.

It is somewhat unfortunate that we have had to make unmoderated posting members-only, but the amount of spam from non-member accounts is overwhelming and the spam filters would inevitably let some false negatives through. (Even member messages get held for approval from time to time due to false positives in the filters.)

The Nabble interface was made unidirectional some months ago. This happened because too many people didn't understand the differences between a forum and a mailing list. 

-pd



> Can any one please direct me to the right forum for me. My problem
> range from plotting graph using R, statistics in R, etc. You could
> have seen some of my request this few days.
> 
> Thank you for your time.
> Ogbos
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Mon Apr 18 14:28:11 2016
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 18 Apr 2016 07:28:11 -0500
Subject: [R] [R-pkgs] Survival 2.39
Message-ID: <519743$2s38ma@ironport10.mayo.edu>

A new version of the survival package has been released.  The biggest change is stronger 
support for multi-state models, which is an outgrowth of their increasing use in my own 
practice. Interested users are directed to the "time dependent covariates" vignette for 
discussion of the tmerge and survSplit functions, which are useful tools to build the 
requisite data sets, and to the "multi-state" vignette for model fits and plots.

Terry Therneau

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From istazahn at gmail.com  Thu Apr 21 21:37:41 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 21 Apr 2016 15:37:41 -0400
Subject: [R] installation problem on Ubuntu
In-Reply-To: <CAP5QEc5cQG40Xv2aPSJRrGdtDqSvyj6S_vDe-i7+Z8mFs8RE_w@mail.gmail.com>
References: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>
	<CA+vqiLH9FiFywMDEdjWKGsmSbc2a6h-RxnRPjnLSJUvnwGutPQ@mail.gmail.com>
	<CAP5QEc5cQG40Xv2aPSJRrGdtDqSvyj6S_vDe-i7+Z8mFs8RE_w@mail.gmail.com>
Message-ID: <CA+vqiLG7i+K9ygeN2fOBPO=Q3thGk9Tz_mBT2oWbya2ktVqBqg@mail.gmail.com>

Hi Paul,

Please keep the list copied so that others might chime in with suggestions.

I'm afraid "no success" is too vague to be useful. What did you do,
and what errors did you encounter?

Best,
Ista

On Thu, Apr 21, 2016 at 1:48 PM, Paul Tremblay <paulhtremblay at gmail.com> wrote:
> Yes, I tried those instructions as well with no success.
>
> On Wed, Apr 20, 2016 at 12:45 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>> Hi Paul,
>>
>> Did you read the installation instructions for Ubuntu at
>> https://cloud.r-project.org/bin/linux/ubuntu/ ?
>>
>> Best,
>> Ista
>>
>>
>> On Wed, Apr 20, 2016 at 12:36 PM, Paul Tremblay <paulhtremblay at gmail.com>
>> wrote:
>> > I needed to update R so I could install ggplot. I am running Ubuntu
>> > 12.04.
>> > I cannot upgrade Ubuntu because I am using a work computer.
>> >
>> > I tried upgrading the normal way:
>> >
>> > sudo apt-get update
>> >  sudo apt-get install r-base r-base-dev
>> >
>> > But this only installed an earlier version. Finally I tried installing
>> > from
>> > source (./configure, Make install). This worked. However, when I try to
>> > install packages, I get this error:
>> >
>> > Error in download.file(url, destfile = f, quiet = TRUE) :
>> >   internet routines cannot be loaded
>> > In addition: Warning message:
>> > In download.file(url, destfile = f, quiet = TRUE) :
>> >   unable to load shared object '/usr/local/lib/R/modules//internet.so':
>> >   /usr/local/lib/R/modules//internet.so: undefined symbol:
>> > curl_multi_wait
>> >
>> >
>> >>> ls /usr/local/lib/R/modules/
>> >>> R_X11.so  R_de.so  internet.so  lapack.so
>> >
>> > Thanks!
>> >
>> > P
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From paulhtremblay at gmail.com  Thu Apr 21 22:23:04 2016
From: paulhtremblay at gmail.com (Paul Tremblay)
Date: Thu, 21 Apr 2016 13:23:04 -0700
Subject: [R] installation problem on Ubuntu
In-Reply-To: <1461183848.3220.6.camel@maladmin.com>
References: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>
	<1461183848.3220.6.camel@maladmin.com>
Message-ID: <CAP5QEc6D=iabCuszhAF+oMFnn_eOUNPxEfWVJMNGtGfjQNJc9g@mail.gmail.com>

I was able to install the curl library with no problems. However, when I
tried to install ggplot (install.packages("ggplot2")), I got the same
message as earlier, that R can't load internet.so.

Thanks for your help!

On Wed, Apr 20, 2016 at 1:24 PM, Tom Wright <tom at maladmin.com> wrote:

> apt-get install curl libcurl4-openssl-dev
>
> On Wed, 2016-04-20 at 09:36 -0700, Paul Tremblay wrote:
> > I needed to update R so I could install ggplot. I am running Ubuntu
> 12.04.
> > I cannot upgrade Ubuntu because I am using a work computer.
> >
> > I tried upgrading the normal way:
> >
> > sudo apt-get update
> >  sudo apt-get install r-base r-base-dev
> >
> > But this only installed an earlier version. Finally I tried installing
> from
> > source (./configure, Make install). This worked. However, when I try to
> > install packages, I get this error:
> >
> > Error in download.file(url, destfile = f, quiet = TRUE) :
> >   internet routines cannot be loaded
> > In addition: Warning message:
> > In download.file(url, destfile = f, quiet = TRUE) :
> >   unable to load shared object '/usr/local/lib/R/modules//internet.so':
> >   /usr/local/lib/R/modules//internet.so: undefined symbol:
> curl_multi_wait
> >
> >
> > >> ls /usr/local/lib/R/modules/
> > >> R_X11.so  R_de.so  internet.so  lapack.so
> >
> > Thanks!
> >
> > P
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Apr 22 00:28:43 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 22 Apr 2016 08:28:43 +1000
Subject: [R] Data reshaping with conditions
In-Reply-To: <CAGO7QoP2mEo_ompVby0R=AFLi7TnAbB6DJbF2T9=RQE5z=CnUg@mail.gmail.com>
References: <CAGO7QoM0VUEobcEcVsR5uWuzXRfChJWya=tkUigURg-38VzeOA@mail.gmail.com>
	<CA+8X3fXRa2ivH1=p=_98+_anr+uQsO-zKb3pdkrN0moQyMBc2Q@mail.gmail.com>
	<CAGO7QoMs6VmskNJkNu-xuh8C-ze73miYUE7eyMT1=RXzJf_8Vg@mail.gmail.com>
	<CA+8X3fVTOwBQ5ssLH6D5kop522a_XiE9AHRLSpey5s4+pc9-bQ@mail.gmail.com>
	<CAGO7QoNf49oYPaSZOsFq5iMvCDUdMdEfBoxGFAxZETcPOUqzfw@mail.gmail.com>
	<CA+8X3fW0aLoeqK-yVEmooK6mm9avxNtZLZwmC6EfJjOPpup_3Q@mail.gmail.com>
	<CAGO7QoMUEMZuWdsMEuTfkR6VScMh5Ui8Cp308TyJ=6JEJH2EiA@mail.gmail.com>
	<CA+8X3fX=Wu3H61qLm9hgvjDGeV6gcrFkvP0gddp2su==EhSttg@mail.gmail.com>
	<CAGO7QoNM7dfE9-H7x0KAeR+Gb2AWn+jpaOD-7ALoDREpszuFTQ@mail.gmail.com>
	<CAGO7QoP2mEo_ompVby0R=AFLi7TnAbB6DJbF2T9=RQE5z=CnUg@mail.gmail.com>
Message-ID: <CA+8X3fV-pAj_p3vVN+zHG8S+jQLt-MQNoXgn93-ZUAb126NZ3g@mail.gmail.com>

In R, square brackets [] are called "extraction operators" as they are
interpreted so as to "extract" the parts of an object specified by the
information within them. Your message contained only part of the line
below:

AltB<-svdatstr[row,indicesA][svdatstr[row,indicesA]<svdatstr[row,"maxB"]]

Extraction operators may be specified sequentially or nested. Both are
used in this line. However, to understand how it works, first look at
the line that defines the value of "indicesA":

 indicesA<-count_ind[as.logical(match(svdatstr[row,type_ind],"A",0))]

This defines a vector of logical (TRUE/FALSE) values for the valid
"Count" values in the current row by finding the matches in the "type"
values for the character string "A". The reason I have used the
"match" function instead of "=="" is to get rid of the NA values that
would have been generated by specifying "0" (zero) in the
"incomparables" argument. I then used the "as.logical" function to
transform the "1" AND "0" to TRUE and FALSE..This logical vector can
then be placed within square brackets to "extract" the valid "Count"
values that have a "type" of "A" in the current row of svdatstr.

Having done this, the expression within the latter pair of extraction
operators can be translated as "Return a logical vector in which the
TRUE values correspond to the "Count" values with a type of "A" that
are less than the maximum value for type "B" count values". The
expression within the first pair of extraction operators can be
translated, "Extract all of the values of "Count" with a type of "A"
in the current row". So, the second extraction then operates on those
values, producing a vector of all of the "Count" values that are less
than the value of "maxB". The line following this in the code uses the
same logic to extract those values that are greater than or equal to
"maxB".

Jim

On Thu, Apr 21, 2016 at 11:25 PM, sri vathsan <srivibish at gmail.com> wrote:
> Dear Jim,
>
> I hope, I am not pestering you. When I was studying your code to grasp and
> learn and found one thing which I can not understand the following line. I
> would be grateful If you could tell what it exactly denote and this helps me
> to grow better in R.
>
> I understand the first part of the code will check the rows of indicesA, but
> I finding difficulty to grasp the second part starting with the square
> bracket.
>
> "AltB<-svdatstr[row,indicesA][svdatstr[row,indicesA]"
>


From daily.puja at gmail.com  Fri Apr 22 01:49:38 2016
From: daily.puja at gmail.com (Ansley Silva)
Date: Thu, 21 Apr 2016 19:49:38 -0400
Subject: [R] Vegemite Function is Cowardly refusing
Message-ID: <CAK2Sg-3_x+ndjR860Wc=E5t6Df+2_yrrn+chyKbooq=1EOgR5w@mail.gmail.com>

R version 3.2.2.
library(vegan)

I was to look at community tables from my dendrograms and am trying out the
vegemite command.  This is the error I get:

Error in vegemite(apst, apst.clusters) :
  Cowardly refusing to use longer than 1 char symbols:
Use scale

I thought the problem was that I was using the log transformed data, but I
tried it on the raw (which is single digit numbers), and still no luck.
Any suggestions would be appreciated.




-- 
Ansley Silva


*"The clearest way into the Universe is through a forest wilderness." John
Muir*


*Graduate Research Assistant*

*University of Georgia*

*D.B. Warnell School of Forestry and Natural Resources*

*180 East Green Street*

*Athens, GA 30602*
-------------- next part --------------
data<-structure(list(necsur = c(1L, 4L, 0L, 8L, 0L, 1L), necame = c(4L, 
5L, 9L, 9L, 4L, 7L), niccar = c(1L, 1L, 1L, 2L, 1L, 4L), nicorb = c(2L, 
20L, 23L, 26L, 3L, 12L), nicpus = c(0L, 0L, 1L, 0L, 0L, 0L), 
    nictor = c(0L, 2L, 1L, 3L, 2L, 1L), oicina = c(0L, 0L, 0L, 
    0L, 0L, 0L), delgib = c(10L, 31L, 47L, 48L, 15L, 55L), cancha = c(5L, 
    6L, 4L, 4L, 1L, 6L), melbis = c(3L, 0L, 1L, 3L, 0L, 1L), 
    atelec = c(4L, 6L, 28L, 22L, 8L, 52L), copmin = c(0L, 0L, 
    1L, 1L, 0L, 1L), ontcon = c(3L, 3L, 11L, 7L, 1L, 2L), ontdep = c(2L, 
    0L, 0L, 0L, 0L, 0L), onthec = c(17L, 15L, 9L, 6L, 6L, 2L), 
    ontstr = c(0L, 0L, 0L, 1L, 1L, 0L), onttau = c(20L, 13L, 
    6L, 2L, 0L, 2L), ontpen = c(2L, 3L, 5L, 3L, 2L, 4L), onttub = c(2L, 
    3L, 4L, 1L, 1L, 0L), ontsub = c(0L, 0L, 0L, 0L, 0L, 0L), 
    phaign = c(0L, 0L, 0L, 0L, 0L, 0L), phavin = c(1L, 0L, 0L, 
    0L, 0L, 1L), Phyili = c(0L, 0L, 0L, 0L, 0L, 1L), canvir = c(0L, 
    1L, 0L, 0L, 0L, 0L), hybill = c(1L, 0L, 0L, 0L, 0L, 0L), 
    chlema = c(0L, 0L, 0L, 0L, 0L, 0L), cyclev = c(0L, 0L, 0L, 
    0L, 1L, 1L), dicdil = c(0L, 0L, 0L, 0L, 0L, 0L), galjan = c(0L, 
    0L, 1L, 1L, 0L, 0L), cyclosig = c(0L, 0L, 0L, 0L, 1L, 0L), 
    omomon = c(1L, 2L, 4L, 10L, 1L, 6L), trofov = c(1L, 2L, 3L, 
    1L, 0L, 1L), trouni = c(1L, 0L, 0L, 1L, 0L, 0L), troter = c(0L, 
    1L, 1L, 0L, 0L, 0L), eusass = c(9L, 8L, 23L, 14L, 11L, 28L
    ), hiscoe = c(2L, 1L, 10L, 4L, 2L, 4L), hisabb = c(0L, 0L, 
    0L, 0L, 2L, 0L), sappen = c(0L, 0L, 0L, 0L, 0L, 0L), dercan = c(0L, 
    0L, 0L, 0L, 0L, 0L), cremax = c(4L, 7L, 1L, 2L, 2L, 5L), 
    plamac = c(1L, 0L, 3L, 2L, 2L, 2L), plafem = c(0L, 0L, 0L, 
    0L, 0L, 0L), plafos = c(1L, 1L, 3L, 2L, 1L, 2L), placom = c(6L, 
    3L, 3L, 10L, 13L, 7L), tacfim = c(0L, 0L, 1L, 0L, 0L, 0L), 
    cicsex = c(0L, 0L, 0L, 0L, 0L, 0L), spsK = c(0L, 0L, 0L, 
    0L, 0L, 0L)), .Names = c("necsur", "necame", "niccar", "nicorb", 
"nicpus", "nictor", "oicina", "delgib", "cancha", "melbis", "atelec", 
"copmin", "ontcon", "ontdep", "onthec", "ontstr", "onttau", "ontpen", 
"onttub", "ontsub", "phaign", "phavin", "Phyili", "canvir", "hybill", 
"chlema", "cyclev", "dicdil", "galjan", "cyclosig", "omomon", 
"trofov", "trouni", "troter", "eusass", "hiscoe", "hisabb", "sappen", 
"dercan", "cremax", "plamac", "plafem", "plafos", "placom", "tacfim", 
"cicsex", "spsK"), row.names = c("AP-0", "AP-100", "AP-200", 
"AP-300", "ST-0", "ST-100"), class = "data.frame")

apst.log <- decostand(apst, "log")
apst.bray <- vegdist(apst.log)
apst.clusters <- hclust(apst.bray, method = "average")
vegemite(apst, apst.clusters)


From dwinsemius at comcast.net  Fri Apr 22 04:45:41 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 21 Apr 2016 19:45:41 -0700
Subject: [R] installation problem on Ubuntu
In-Reply-To: <CAP5QEc6D=iabCuszhAF+oMFnn_eOUNPxEfWVJMNGtGfjQNJc9g@mail.gmail.com>
References: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>
	<1461183848.3220.6.camel@maladmin.com>
	<CAP5QEc6D=iabCuszhAF+oMFnn_eOUNPxEfWVJMNGtGfjQNJc9g@mail.gmail.com>
Message-ID: <6CE71142-C250-40AF-B8B0-839475A5EC8B@comcast.net>


> On Apr 21, 2016, at 1:23 PM, Paul Tremblay <paulhtremblay at gmail.com> wrote:
> 
> I was able to install the curl library with no problems. However, when I
> tried to install ggplot (install.packages("ggplot2")), I got the same
> message as earlier, that R can't load internet.so.

Is the libcurl directory in your search path?

David.
> 
> Thanks for your help!
> 
> On Wed, Apr 20, 2016 at 1:24 PM, Tom Wright <tom at maladmin.com> wrote:
> 
>> apt-get install curl libcurl4-openssl-dev
>> 
>> On Wed, 2016-04-20 at 09:36 -0700, Paul Tremblay wrote:
>>> I needed to update R so I could install ggplot. I am running Ubuntu
>> 12.04.
>>> I cannot upgrade Ubuntu because I am using a work computer.
>>> 
>>> I tried upgrading the normal way:
>>> 
>>> sudo apt-get update
>>> sudo apt-get install r-base r-base-dev
>>> 
>>> But this only installed an earlier version. Finally I tried installing
>> from
>>> source (./configure, Make install). This worked. However, when I try to
>>> install packages, I get this error:
>>> 
>>> Error in download.file(url, destfile = f, quiet = TRUE) :
>>>  internet routines cannot be loaded
>>> In addition: Warning message:
>>> In download.file(url, destfile = f, quiet = TRUE) :
>>>  unable to load shared object '/usr/local/lib/R/modules//internet.so':
>>>  /usr/local/lib/R/modules//internet.so: undefined symbol:
>> curl_multi_wait
>>> 
>>> 
>>>>> ls /usr/local/lib/R/modules/
>>>>> R_X11.so  R_de.so  internet.so  lapack.so
>>> 
>>> Thanks!
>>> 
>>> P
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mail at p-roocks.de  Thu Apr 21 09:23:23 2016
From: mail at p-roocks.de (Patrick Roocks)
Date: Thu, 21 Apr 2016 09:23:23 +0200
Subject: [R] [R-pkgs] rPref 1.0 - Computing Pareto Optima and
	Database	Preferences
Message-ID: <57187FEB.7070008@p-roocks.de>

Dear R users,

the first 1.0 version of the rPref package is now on CRAN.

rPref allows to select the Pareto-optimal tuples from a data set, also 
called Skylines in the database community. For example, optimal tuples 
from mtcars according to "high(mpg) * high(hp)" (where "*" is the Pareto 
operator) are those cars, for which no other dominating car exists. 
There, a car dominates another car if its horsepower or miles-per-gallon 
value is strictly better while the other value is better or equal.

See http://p-roocks.de/rpref/index.php?section=examples for more examples.

The changes of this version include:
- A new function get_btg_dot to generate Better-Than-Graphs induced by 
the preference using Graphviz.
- Fixed compatibility issues with new versions of dplyr and testthat.

Comments and contributions are very welcome via github:
https://github.com/patrickroocks/rpref

Best regards,

Patrick

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From giftedlife2014 at gmail.com  Thu Apr 21 10:44:03 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Thu, 21 Apr 2016 09:44:03 +0100
Subject: [R] clock24.plot/radial plot
Message-ID: <CAC8ss30n+aWgTyc8-b0ebrcLPgrw5M4swec3rAin0ko4xyKXYQ@mail.gmail.com>

Dear All,
I am trying to generate a circular/radial plot. The script below has a
result I am looking for:
testlen<-rnorm(24)*2+5
 testpos<-0:23+rnorm(24)/4
 clock24.plot(testlen,testpos,main="Test Clock24 (lines)",show.grid=FALSE,
  line.col="green",lwd=3)
 if(dev.interactive()) par(ask=TRUE)
 # now do a 'daylight' plot
 oldpar<-clock24.plot(testlen[7:19],testpos[7:19],
  main="Test Clock24 daytime (symbols)",
  point.col="blue",rp.type="s",lwd=3)
 # reset everything
 par(oldpar)

I tried to play with the script to work with my data. I read my data:
swe<-scan("onedaydata",list(dates="",time="",count=""))
dates<-swe$dates
times<-swe$time
count<-swe$count.
I tried to replace testlen<-rnorm(24)*2+5 with testlen<-count and
oldpar<-clock24.plot(testlen[7:19],testpos[7:19], with
oldpar<-clock24.plot(testlen[0:23],testpos[0:23], but nothing worked.
The format of my data is 2005/01/01 00:00   4009
2005/01/01 01:00   3969
2005/01/01 02:00   3946
2005/01/01 03:00   3975
2005/01/01 04:00   3960
2005/01/01 05:00   3974
2005/01/01 06:00   3971
2005/01/01 07:00   3970
2005/01/01 08:00   3962
2005/01/01 09:00   3992
2005/01/01 10:00   3955
2005/01/01 11:00   3963
2005/01/01 12:00   3965
2005/01/01 13:00   3947
2005/01/01 14:00   3959
2005/01/01 15:00   3978
2005/01/01 16:00   3967
2005/01/01 17:00   3978
2005/01/01 18:00   3988
2005/01/01 19:00   4043
2005/01/01 20:00   4026
2005/01/01 21:00   3996
2005/01/01 22:00   3967
2005/01/01 23:00   3969
2005/01/02 00:00   3976
2005/01/02 01:00   3969
2005/01/02 02:00   3955
2005/01/02 03:00   3984
2005/01/02 04:00   3971
2005/01/02 05:00   3960
2005/01/02 06:00   3951
2005/01/02 07:00   3948
2005/01/02 08:00   3954
2005/01/02 09:00   3948
2005/01/02 10:00   3960
2005/01/02 11:00   3964
2005/01/02 12:00   3962
2005/01/02 13:00   3959
2005/01/02 14:00   3950
2005/01/02 15:00   3972
2005/01/02 16:00   3984
2005/01/02 17:00   3983
2005/01/02 18:00   3982
2005/01/02 19:00   3987
2005/01/02 20:00   3989
2005/01/02 21:00   3975
2005/01/02 22:00   3956
2005/01/02 23:00   3975
2005/01/03 00:00   3946
2005/01/03 01:00   3944
2005/01/03 02:00   3915
2005/01/03 03:00   3901
2005/01/03 04:00   3893
2005/01/03 05:00   3854
2005/01/03 06:00   3824
2005/01/03 07:00   3790
2005/01/03 08:00   3770
2005/01/03 09:00   3794
2005/01/03 10:00   3778
2005/01/03 11:00   3803
2005/01/03 12:00   3801
2005/01/03 13:00   3800
2005/01/03 14:00   3783
2005/01/03 15:00   3789
2005/01/03 16:00   3804
2005/01/03 17:00   3781
2005/01/03 18:00   3785
2005/01/03 19:00   3772
2005/01/03 20:00   3777
2005/01/03 21:00   3766
2005/01/03 22:00   3775
2005/01/03 23:00   3779
2005/01/04 00:00   3798
2005/01/04 01:00   3806

A sample of the plot I want is attached. My data is quite large.
Thanks for your time.
Best wishes
Ogbos
-------------- next part --------------
A non-text attachment was scrubbed...
Name: radialplot.png
Type: image/png
Size: 69198 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160421/07696a8c/attachment.png>

From parsifalblake at gmail.com  Thu Apr 21 16:41:32 2016
From: parsifalblake at gmail.com (Judson Blake)
Date: Thu, 21 Apr 2016 10:41:32 -0400
Subject: [R] plot 8 functions on one graph?
Message-ID: <CAOrp6CegN6XaLONi8JbRdYnMfvnC_f4bE-6nKDe750uQUVrMSA@mail.gmail.com>

 I'm trying to use
ggplot to make a single graph
that plots 8 distributions,
one above the other.

I created a data.frame
with 9 rows.   The first
is the coordinate along the x-axis.
The next is the y-values for
the first distribution.
After that is the y-values
for the next distribution... and so on.

How do I call ggplot to use such a data.frame
to make a single graph of 8 distributions?

Should my data.frame be formed differently?

.................. judson blake

	[[alternative HTML version deleted]]


From izaakrogan at gmail.com  Thu Apr 21 17:49:49 2016
From: izaakrogan at gmail.com (Izaak Rogan)
Date: Thu, 21 Apr 2016 16:49:49 +0100
Subject: [R] Error using RPostgreSQL
Message-ID: <CAD5LvW=VF=8LM1-q8qAyPP8qPNNVsA8Ye35gecVkK2uje5teaw@mail.gmail.com>

Hi,

I'm having trouble connecting to my postgreSQL db on Heroku(Amazon)
using RPostgreSQL.

I've looked through GitHub for people doing the same thing. There are
quite a few examples and all look similar to the below:

drv <- dbDriver("PostgreSQL")

con <- dbConnect(
          drv,
          dbname = "dadqn30er7ghpl",
          host = "ec2-27-837-167-90.eu-west-1.compute.amazonaws.com",
          port = 5432,
          user = "tascofyvasswmblc",
          password = XXXXXX'
);

I'm getting the error:

Error in postgresqlNewConnection(drv, ...) :
  RS-DBI driver: (could not connect
tascofyvasswmblc at ec2-27-837-167-90.eu-west-1.compute.amazonaws.com on
dbname "dascn90er7ghpl"
)

Any pointers would be hugely appreciated!

Thanks,
Izaak


From habib.drj at gmail.com  Thu Apr 21 22:17:42 2016
From: habib.drj at gmail.com (MD. HABIBUR RAHMAN)
Date: Fri, 22 Apr 2016 02:17:42 +0600
Subject: [R] EIGEN VECTOR PROBLEM
Message-ID: <CABw44Yx9Uh=meQiUWHe3BjdYZDeYi2kY07_uC8JeyQwDNM_eTQ@mail.gmail.com>

Dear Sir,
I am an R user.
I am in problem to find eigen vectors in R.
For the following matrix eigen vectors are not right. I can not understand
why??
For the 1st eigen value and 2nd eigen value are same, but the eigen vectors
are not same.

*HOW CAN I RESOLVE THE PROBLEM??*











*>c=matrix(c(1,0,0,1,2,0,-3,5,2),nrow=3,byrow=T)> eigen(c)$values[1] 2 2
1$vectors     [,1]          [,2]       [,3][1,]    0  0.000000e+00
0.1230915[2,]    0  8.881784e-17 -0.1230915[3,]    1 -1.000000e+00
0.9847319*
>

-- 






Thanking You

Md. Habibur Rahman

	[[alternative HTML version deleted]]


From nonlosing at gmail.com  Fri Apr 22 03:34:30 2016
From: nonlosing at gmail.com (Hairong Gu)
Date: Thu, 21 Apr 2016 21:34:30 -0400
Subject: [R] R2BayesX help
Message-ID: <CALmToYrASGe=qToTD2EwYvRUx_dURS+qxeUtWxa_HxtUSHzUkw@mail.gmail.com>

Hi,

I wonder if anyone can help me with this issue. I am using R2BayesX. It
seems that the model can maximally contain 20 interactions. When the number
of interaction terms exceed 20, the code stops working. Here is a piece of
toy code.

rm(list=ls())
library(BayesX)
library(R2BayesX)

#data generating model
f2<-function(x1,x2,x3,x4)
{
  y<-2*sin(pi*x1)*1.5+exp(2*x2)/3+2 * sin(4 * pi * (x3 - 0.2) *(x4 - 0.7))
}

#the dataset
nsample<-40  #sample size
x1.tot<-runif(nsample,0,1)
x2.tot<-runif(nsample,0,1)
x3.tot<-runif(nsample,0,1)
x4.tot<-runif(nsample,0,1)
x5.tot<-runif(nsample,0,1)
x6.tot<-runif(nsample,0,1)
x7.tot<-runif(nsample,0,1)

pnoise<-0.2
eta<-f2(x1.tot,x2.tot,x3.tot,x4.tot)
y.tot<-eta+pnoise*rnorm(nsample,0,1)
d<-data.frame(y.tot,x1.tot,x2.tot,x3.tot,x4.tot,x5.tot,x6.tot,x7.tot)

nk2<-5

# the full model that contains the interactions of all pairs of x1~x7, 21
terms in total
fr2<-y.tot ~ sx(x1.tot, x2.tot, knots = nk2, bs = "te") + sx(x1.tot,
x3.tot, knots = nk2, bs = "te") +
  sx(x1.tot, x4.tot, knots = nk2, bs = "te") + sx(x1.tot, x5.tot, knots =
nk2, bs = "te") +
  sx(x1.tot, x6.tot, knots = nk2, bs = "te") + sx(x1.tot, x7.tot, knots =
nk2, bs = "te") +
  sx(x2.tot, x3.tot, knots = nk2, bs = "te") + sx(x2.tot, x4.tot, knots =
nk2, bs = "te") +
  sx(x2.tot, x5.tot, knots = nk2, bs = "te") + sx(x2.tot, x6.tot, knots =
nk2, bs = "te") +
  sx(x2.tot, x7.tot, knots = nk2, bs = "te") + sx(x3.tot, x4.tot, knots =
nk2, bs = "te") +
  sx(x3.tot, x5.tot, knots = nk2, bs = "te") + sx(x3.tot, x6.tot, knots =
nk2, bs = "te") +
  sx(x3.tot, x7.tot, knots = nk2, bs = "te") + sx(x4.tot, x5.tot, knots =
nk2, bs = "te") +
  sx(x4.tot, x6.tot, knots = nk2, bs = "te") + sx(x4.tot, x7.tot, knots =
nk2, bs = "te") +
  sx(x5.tot, x6.tot, knots = nk2, bs = "te") + sx(x5.tot, x7.tot, knots =
nk2, bs = "te") +
  sx(x6.tot, x7.tot, knots = nk2, bs = "te")

m2<-bayesx(fr2,data = d)

The code halted in a couple of seconds after the last function, with a
warning:

Warning message:
running command
'"C:/Users/Hairong/Documents/R/win-library/3.2/BayesXsrc/libs/x64/BayesX.exe"
C:/Users/Hairong/AppData/Local/Temp/RtmpkFfoCH/bayesx5/bayesx.estim.input.prg'
had status 5

The model was not estimated. However, if I delete ANY one of the
interaction terms to make the total interaction terms 20, the model can be
estimated.


I would appreciate your suggestion and explanation on this problem. Thank
you a lot.

Hairong

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Apr 22 08:42:12 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 22 Apr 2016 06:42:12 +0000
Subject: [R] clock24.plot/radial plot
In-Reply-To: <CAC8ss30n+aWgTyc8-b0ebrcLPgrw5M4swec3rAin0ko4xyKXYQ@mail.gmail.com>
References: <CAC8ss30n+aWgTyc8-b0ebrcLPgrw5M4swec3rAin0ko4xyKXYQ@mail.gmail.com>
Message-ID: <CAKVAULMOmRcHOdYsECVYtGD7eUS6Wi81dLe9Z-emimuzK1FSiQ@mail.gmail.com>

I use ggplot2 for all my plotting needs where you can make plots circular
with the coord_polar. Maybe this will help you along:
http://rstudio-pubs-static.s3.amazonaws.com/3369_998f8b2d788e4a0384ae565c4280aa47.html

On Fri, 22 Apr 2016 at 08:31 Ogbos Okike <giftedlife2014 at gmail.com> wrote:

> Dear All,
> I am trying to generate a circular/radial plot. The script below has a
> result I am looking for:
> testlen<-rnorm(24)*2+5
>  testpos<-0:23+rnorm(24)/4
>  clock24.plot(testlen,testpos,main="Test Clock24 (lines)",show.grid=FALSE,
>   line.col="green",lwd=3)
>  if(dev.interactive()) par(ask=TRUE)
>  # now do a 'daylight' plot
>  oldpar<-clock24.plot(testlen[7:19],testpos[7:19],
>   main="Test Clock24 daytime (symbols)",
>   point.col="blue",rp.type="s",lwd=3)
>  # reset everything
>  par(oldpar)
>
> I tried to play with the script to work with my data. I read my data:
> swe<-scan("onedaydata",list(dates="",time="",count=""))
> dates<-swe$dates
> times<-swe$time
> count<-swe$count.
> I tried to replace testlen<-rnorm(24)*2+5 with testlen<-count and
> oldpar<-clock24.plot(testlen[7:19],testpos[7:19], with
> oldpar<-clock24.plot(testlen[0:23],testpos[0:23], but nothing worked.
> The format of my data is 2005/01/01 00:00   4009
> 2005/01/01 01:00   3969
> 2005/01/01 02:00   3946
> 2005/01/01 03:00   3975
> 2005/01/01 04:00   3960
> 2005/01/01 05:00   3974
> 2005/01/01 06:00   3971
> 2005/01/01 07:00   3970
> 2005/01/01 08:00   3962
> 2005/01/01 09:00   3992
> 2005/01/01 10:00   3955
> 2005/01/01 11:00   3963
> 2005/01/01 12:00   3965
> 2005/01/01 13:00   3947
> 2005/01/01 14:00   3959
> 2005/01/01 15:00   3978
> 2005/01/01 16:00   3967
> 2005/01/01 17:00   3978
> 2005/01/01 18:00   3988
> 2005/01/01 19:00   4043
> 2005/01/01 20:00   4026
> 2005/01/01 21:00   3996
> 2005/01/01 22:00   3967
> 2005/01/01 23:00   3969
> 2005/01/02 00:00   3976
> 2005/01/02 01:00   3969
> 2005/01/02 02:00   3955
> 2005/01/02 03:00   3984
> 2005/01/02 04:00   3971
> 2005/01/02 05:00   3960
> 2005/01/02 06:00   3951
> 2005/01/02 07:00   3948
> 2005/01/02 08:00   3954
> 2005/01/02 09:00   3948
> 2005/01/02 10:00   3960
> 2005/01/02 11:00   3964
> 2005/01/02 12:00   3962
> 2005/01/02 13:00   3959
> 2005/01/02 14:00   3950
> 2005/01/02 15:00   3972
> 2005/01/02 16:00   3984
> 2005/01/02 17:00   3983
> 2005/01/02 18:00   3982
> 2005/01/02 19:00   3987
> 2005/01/02 20:00   3989
> 2005/01/02 21:00   3975
> 2005/01/02 22:00   3956
> 2005/01/02 23:00   3975
> 2005/01/03 00:00   3946
> 2005/01/03 01:00   3944
> 2005/01/03 02:00   3915
> 2005/01/03 03:00   3901
> 2005/01/03 04:00   3893
> 2005/01/03 05:00   3854
> 2005/01/03 06:00   3824
> 2005/01/03 07:00   3790
> 2005/01/03 08:00   3770
> 2005/01/03 09:00   3794
> 2005/01/03 10:00   3778
> 2005/01/03 11:00   3803
> 2005/01/03 12:00   3801
> 2005/01/03 13:00   3800
> 2005/01/03 14:00   3783
> 2005/01/03 15:00   3789
> 2005/01/03 16:00   3804
> 2005/01/03 17:00   3781
> 2005/01/03 18:00   3785
> 2005/01/03 19:00   3772
> 2005/01/03 20:00   3777
> 2005/01/03 21:00   3766
> 2005/01/03 22:00   3775
> 2005/01/03 23:00   3779
> 2005/01/04 00:00   3798
> 2005/01/04 01:00   3806
>
> A sample of the plot I want is attached. My data is quite large.
> Thanks for your time.
> Best wishes
> Ogbos
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Fri Apr 22 08:59:47 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 22 Apr 2016 08:59:47 +0200
Subject: [R] EIGEN VECTOR PROBLEM
In-Reply-To: <CABw44Yx9Uh=meQiUWHe3BjdYZDeYi2kY07_uC8JeyQwDNM_eTQ@mail.gmail.com>
References: <CABw44Yx9Uh=meQiUWHe3BjdYZDeYi2kY07_uC8JeyQwDNM_eTQ@mail.gmail.com>
Message-ID: <570BAB1A-21BD-4F53-825A-1EBBC1047E9E@xs4all.nl>


> On 21 Apr 2016, at 22:17, MD. HABIBUR RAHMAN <habib.drj at gmail.com> wrote:
> 
> Dear Sir,
> I am an R user.
> I am in problem to find eigen vectors in R.
> For the following matrix eigen vectors are not right. I can not understand
> why??
> For the 1st eigen value and 2nd eigen value are same, but the eigen vectors
> are not same.
> 
> *HOW CAN I RESOLVE THE PROBLEM??*
> 

Please do not post in html as the Posting guide directs.
Your code is a mess because of the html.

You can't resolve the problem: it is non existent.

See: https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Triangular_matrix_example


> 
> *>c=matrix(c(1,0,0,1,2,0,-3,5,2),nrow=3,byrow=T)> eigen(c)$values[1] 2 2
> 1$vectors     [,1]          [,2]       [,3][1,]    0  0.000000e+00
> 0.1230915[2,]    0  8.881784e-17 -0.1230915[3,]    1 -1.000000e+00

Do not use c as a variable name. It is a builtin function.
Do not use T for TRUE; it will lead to tears at some point.

Berend Hasselman


From petr.pikal at precheza.cz  Fri Apr 22 09:09:51 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 22 Apr 2016 07:09:51 +0000
Subject: [R] plot 8 functions on one graph?
In-Reply-To: <CAOrp6CegN6XaLONi8JbRdYnMfvnC_f4bE-6nKDe750uQUVrMSA@mail.gmail.com>
References: <CAOrp6CegN6XaLONi8JbRdYnMfvnC_f4bE-6nKDe750uQUVrMSA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50279EB@SRVEXCHMBX.precheza.cz>

Hi

Normally data in data frames are considered column wise and ggplot expects this

ggplot(yourdataframe, aes(x=some column, y=other column, colour=grouping factor, ...)

So if you want to use ggplot, you shall transpose your data frame and reshape it to long format.

See
?ggplot
?t
?reshape
?melt

Cheers
Petr
BTW, although there was no problem with your HTML formated mail it is preferable to use plain text mail in this list.


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Judson
> Blake
> Sent: Thursday, April 21, 2016 4:42 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] plot 8 functions on one graph?
>
>  I'm trying to use
> ggplot to make a single graph
> that plots 8 distributions,
> one above the other.
>
> I created a data.frame
> with 9 rows.   The first
> is the coordinate along the x-axis.
> The next is the y-values for
> the first distribution.
> After that is the y-values
> for the next distribution... and so on.
>
> How do I call ggplot to use such a data.frame to make a single graph of 8
> distributions?
>
> Should my data.frame be formed differently?
>
> .................. judson blake
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Fri Apr 22 12:30:46 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 22 Apr 2016 20:30:46 +1000
Subject: [R] clock24.plot
In-Reply-To: <CAC8ss33Xe2D6HhfBBF40dEFECgaB9NKK1AogzW1ywGm8s7s8KA@mail.gmail.com>
References: <CAC8ss32pnwcBojn5ePPMiSfcRGkooy-M9Lai69Oio+rHJSzxYA@mail.gmail.com>
	<CA+8X3fWm61rwEYYCU-DmmAFCFXEPPHr=vPrxB452xcfZN7bX=Q@mail.gmail.com>
	<CAC8ss33Hz6f_WUz9wpw6KVhsVmEmKdUAHcjxm0=WddUmzoLpbg@mail.gmail.com>
	<CAC8ss3113HPvpoGG95=pSGz-0-1Kv02wevCGo2k=3R+1-J9NBA@mail.gmail.com>
	<CAC8ss33Xe2D6HhfBBF40dEFECgaB9NKK1AogzW1ywGm8s7s8KA@mail.gmail.com>
Message-ID: <CA+8X3fXgkAZuOZq4xnxu0xyvt0fwSXF_dwn5q-LiZU07C2mjMQ@mail.gmail.com>

Hi Ogbos,
Here is your sample data plotted in roughly the same way as the image.
You can get the hours to start at the bottom, but it will require more
code.

swe$hour<-as.numeric(sapply(strsplit(swe$time,":"),"[",1))
swe$FD<-sample(1:2,nrow(swe),TRUE)
library(plotrix)
clock24.plot(swe$count,swe$hour,rp.type="s",radial.lim=c(3000,4010),
show.grid.labels=0,point.col=swe$FD,mar=c(2,2,6,2))
legend(0,1600,c("FD1","FD2"),pch=1,col=1:2,xjust=0.5,yjust=0.5,
 xpd=TRUE)

Jim

On Fri, Apr 22, 2016 at 3:01 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Dear Jim,
> I am forwarding the same mail from my phone to be sure you have it.
> Additionally, will my data require a daylight plot?
> Many thanks for your time.
> Ogbos
>
> ---------- Forwarded message ----------
> From: "Ogbos Okike" <giftedlife2014 at gmail.com>
> Date: Apr 22, 2016 5:42 AM
> Subject: Fwd: clock24.plot
> To: "Ogbos Okike" <giftedlife2014 at gmail.com>
> Cc:
>
>
> ---------- Forwarded message ----------
> From: Ogbos Okike <giftedlife2014 at gmail.com>
> Date: Fri, Apr 22, 2016 at 5:28 AM
> Subject: Re: clock24.plot
> To: Jim Lemon <drjimlemon at gmail.com>
>
>
> Dear Jim,
> Thank you for your time. I am working on comic ray data this time. I think
> that displaying the format of my data will make things much easier for me.
> Here is a part of my data:
> 2005/01/01 00:00   4009
> 2005/01/01 01:00   3969
> 2005/01/01 02:00   3946
> 2005/01/01 03:00   3975
> 2005/01/01 04:00   3960
> 2005/01/01 05:00   3974
> 2005/01/01 06:00   3971
> 2005/01/01 07:00   3970
> 2005/01/01 08:00   3962
> 2005/01/01 09:00   3992
> 2005/01/01 10:00   3955
> 2005/01/01 11:00   3963
> 2005/01/01 12:00   3965
> 2005/01/01 13:00   3947
> 2005/01/01 14:00   3959
> 2005/01/01 15:00   3978
> 2005/01/01 16:00   3967
> 2005/01/01 17:00   3978
> 2005/01/01 18:00   3988
> 2005/01/01 19:00   4043
> 2005/01/01 20:00   4026
> 2005/01/01 21:00   3996
> 2005/01/01 22:00   3967
> 2005/01/01 23:00   3969
> 2005/01/02 00:00   3976
> 2005/01/02 01:00   3969
> 2005/01/02 02:00   3955
> 2005/01/02 03:00   3984
> 2005/01/02 04:00   3971
> 2005/01/02 05:00   3960
> 2005/01/02 06:00   3951
> 2005/01/02 07:00   3948
> 2005/01/02 08:00   3954
> 2005/01/02 09:00   3948
> 2005/01/02 10:00   3960
> 2005/01/02 11:00   3964
> 2005/01/02 12:00   3962
> This run for 56 years.
> The type of plot I wish to generated is attached. If I have an idea of how
> to use my data and generate the kind of graph attached, I can then start
> playing with many stations as the different colours represent.
>
> Thank you so much for assisting.
> Ogbos
>
> On Fri, Apr 22, 2016 at 4:53 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Ogbos,
>> Here is an example that might get you started:
>>
>> lightning<-data.frame(year=rep(1901:2000,each=100),time=runif(10000,0,24))
>> lightning$hour<-floor(lightning$time)
>> clock24.plot(as.vector(table(lightning$hour)),0:23,rp.type="p",
>>  show.grid.labels=0,main="24 hour distribution of lightning strikes",
>>  radial.lim=c(360,460),mar=c(3,2,3,2))
>> segments(c(0,0,100),c(-130,-130,-130),c(100,0,100),c(-130,-128,-128))
>> mtext(c(360,460),side=1,at=c(0,100),line=1)
>>
>> As you say you have date/time values, you will have to extract the
>> time values from the date/times. If all you want is something like the
>> hours as in the above example, you can just do this:
>>
>> mydata$hours<-format(strptime(mydatetimes,<date time format>),"%H")
>> hour_freq<-as.vector(table(mydata$hours))
>>
>> I am assuming that you want some sort of frequency distribution during
>> the day. If I have misunderstood, please let me know.
>>
>> Jim
>>
>> On Fri, Apr 22, 2016 at 12:56 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>> > Dear Jim,
>> > I am trying to understand one of your codes on clock24.plot. I have not
>> > been
>> > quite successful. My data run for 24hours for many years. Most of the
>> > examples you put online were generated by rnorm function.
>> > Since I have two columns with date time and the actual data, can you
>> > give me
>> > an idea on how to go.
>> > Thanks for time.
>> > Ogbos
>
>
>


From oscar.b.janin at gmail.com  Fri Apr 22 09:52:58 2016
From: oscar.b.janin at gmail.com (Oscar Janin)
Date: Fri, 22 Apr 2016 09:52:58 +0200
Subject: [R] R - Understanding output of the Knoxtest (Package
	(surveillance))
Message-ID: <CABv_6jPcatayHj=q4BkEV8hSZmY66offhGFp4+GK-SewB8m28A@mail.gmail.com>

The function knox of the "Surveillance" package performs Knox test for
space-time interaction. The output is supposed to give the numbers of
events that occur in a specific distance in space and time define by the
function arguments. This function also perform a Monte Carlo permutation
test, which give the estimated value (based on a random distribution) which
are supposed to be compared to the observed value. This comparison gives a
ratio which means the chance that event occur in a specific distance in
time and space.

Here is the example of the function and it's output:

        library(surveillance)
>     data("imdepi")
>     imdepiB <- subset(imdepi, type == "B")
>
>     ## Obtain the p-value via a Monte Carlo permutation test,
>     ## where the permutations can be computed in parallel
>     ## (using forking on Unix-alikes and a cluster on Windows, see
> ?plapply)
>     knoxtest <- knox(
>       dt = dist(imdepiB$events$time), eps.t = 30,
>       ds = dist(coordinates(imdepiB$events)), eps.s = 50,
>       simulate.p.value = TRUE, B = 19,
>       .parallel = 2, .seed = 1, .verbose = FALSE
>     )
>     knoxtest
>


Output:


    Knox test with Poisson approximation
>
>     data:  dt = dist(imdepiB$events$time) and ds =
> dist(coordinates(imdepiB$events))
>     number of close pairs = 204, lambda = 181.57, p-value = 0.04649
>     alternative hypothesis: true number is greater than 181.5686
>
>     contingency table:
>            ds
>     dt      <= 50  > 50
>       <= 30   204  1295
>        > 30  6613 48168
>

The "imdepi" dataset include 636 events, so, the output isn't a count of
the event occuring in a specific distance in space and time. Also, even if
I change the value of "B", which correspond to the number of permutation
for the Monte Carlo approach, the results stays the same.




*What the numbers of output contingency table mean?How the Monte Carlo
iteration influence the results?*


Here are the links to the Knox Test function Description [1] and it's Code
[2].

  [1]: http://finzi.psych.upenn.edu/R/library/surveillance/html/knox.html
  [2]:
https://r-forge.r-project.org/scm/viewvc.php/pkg/R/knox.R?view=markup&root=surveillance&pathrev=1292

In advance, thank you for your help

	[[alternative HTML version deleted]]


From louise.mair at slu.se  Fri Apr 22 10:32:28 2016
From: louise.mair at slu.se (Louise Mair)
Date: Fri, 22 Apr 2016 08:32:28 +0000
Subject: [R] Unexpected values obtained when reading in data using ncdf and
	ncdf4
Message-ID: <ce01ddcca00c4f72aea9ac96e3b275ec@EXCH2-1.slu.se>

Dear R Users,

I am encountering a problem when reading nc files into R using the ncdf and ncdf4 libraries. The nc files are too large to attach an example (but if someone is interested in helping out I could send a file privately via an online drive), but the code is basic:

for(i in 1:length(thesenames[,1])){
   data <- nc_open(paste(INDIR, thesenames[i,c("wholename")], sep=""), write=F)
   d.vars <- names(data$var)
   d.size <- (data$var[[length(d.vars)]])$size

   # Obtaining longitude and latitude values
   d.lon <- as.vector(ncvar_get(data, varid="lon", start=c(1,1), count=c(d.size[1],d.size[2])))
   d.lat <- as.vector(ncvar_get(data, varid="lat", start=c(1,1), count=c(d.size[1],d.size[2])))

   # Obtaining climate data values
   df.clim <- data.frame(rn=seq(1:length(d.lon)))
   for(y in 1:d.size[3]){
     df.clim[,1+y] <- as.vector(ncvar_get(data, varid=d.vars[length(d.vars)], start=c(1,1,y), count=c(d.size[1],d.size[2],1)))
      names(df.clim)[1+y] <- paste("y",y,sep="")  }
   tosummarise[,,i] <- as.matrix(df.clim[,-1])
}

The data are temperature or precipitation, across space and time.

For most of the >250 files I have, there are no problems, but for around 8 of these files, I get strange values. The data should be within a relatively narrow range, yet I get values such as -8.246508e+07  or  7.659506e+11. The particularly strange part is that these kind of values occur at regularly spaced intervals across the data, usually within a single time step.

I have the same problem (including the exact same strange values) when using ArcMap, yet the data provider assures me that the data look normal when using CDO (climate data operators) to view them, and that there are no missing values.

I realise this is very difficult to diagnose without the nc files themselves, so my questions are (1) Has anyone encountered something like this before?, (2) Is there something I am failing to specify in the code when reading in?, and (3) Is anyone interested in digging into this and willing to play around with the nc files if I make them available privately?

Thanks very much in advance!
Louise





	[[alternative HTML version deleted]]


From timwerwie at gmail.com  Fri Apr 22 12:41:36 2016
From: timwerwie at gmail.com (Tim Werwie)
Date: Fri, 22 Apr 2016 10:41:36 +0000
Subject: [R] Problem installing/loading packages from Africa
Message-ID: <CAH+j5oYNRDBA3vP4pEFFS1tEdZKD-XBssfs7QDsCp4ZH2mr8AA@mail.gmail.com>

I'm very new to R and I live in Mali, west Africa. I'm on *OS X 10.7.5*. I
downloaded and installed *R 3.2.1*. I downloaded and installed *RStudio
00.99.893*.

I ran through the free Microsoft data camp intro to R course, then started
another free course through 'edX', for Data and Statistics for Life
Sciences, using R. The first prompt in the course is to
install.packages("swirl"). Copied below are the various error messages I
get when trying to install or load any package.

My best guess is that the problems I'm having are due to being in west
Africa, with unreliable connections, weak connections and no CRAN Mirror
closer than Italy or Spain (as far as I know). I checked into common
package errors on the RStudio page, but I'm not confident enough in my
computing to get into internet proxies and some of the other suggested
troubleshooting.

Any insight would be very helpful. See error messages below. Thanks -- Tim

- When attempting to install, the print-out I get in the Console in RStudio
is any length of: > install.packages("swirl")
  % Total    % Received % Xferd  Average Speed   Time    Time     Time
Current
                                 Dload  Upload   Total   Spent    Left
Speed
  0     0    0     0    0     0      0      0 --:--:--  0:00:10
--:--:--     0  0     0    0     0    0     0      0      0 --:--:--
0:00:10 --:--:--     0  0     0    0     0    0     0      0      0
--:--:--  0:00:11 --:--:--     0 22  207k   22 48384    0     0   3833
0  0:00:55  0:00:12  0:00:43 19740 30  207k   30 64823    0     0
4808      0  0:00:44  0:00:13  0:00:31 19578 38  207k   38 81207    0
0   5638      0  0:00:37  0:00:14  0:00:23 19193 46  207k   46 97591
0     0   6299      0  0:00:33  0:00:15  0:00:18 20076 53  207k   53
111k    0     0   6966      0  0:00:30  0:00:16  0:00:14 22717 69  207k
69  143k    0     0   8423      0  0:00:25  0:00:17  0:00:08 20487 76
207k   76  159k    0     0   8821      0  0:00:24  0:00:18  0:00:06 19621
92  207k   92  191k    0     0  10085      0  0:00:21  0:00:19  0:00:02
22841100  207k  100  207k    0     0  10363      0  0:00:20  0:00:20
--:--:-- 230100  207k  100  207k    0     0  10363      0  0:00:20  0:00:20
--:--:-- 23922
The downloaded binary packages are in

/var/folders/yb/7z339kn56mdbwx92ydmsqswc0000gn/T//RtmpBzQ16u/downloaded_packages

For other packages, ggplot2, forexample, a similar printout can run for
hundreds and hundred of lines. So RStudio tells me that the packages are
available to load, BUT:

- when *loading* any package an error comes up saying package 'name of
package' was built under R version 3.2.5 but info on swirl says it should
work on any version of R above 3.0.2. I get similar errors for other
packages (treemap, ggplot2, etc).

- Or sometimes I"ll get this: Error : .onAttach failed in attachNamespace()
for 'swirl', details: call: stri_c(..., sep = sep, collapse = collapse,
ignore_null = TRUE)
error: object 'C_stri_join' not found
In addition: Warning message:
package ?swirl? was built under R version 3.2.5
Error: package or namespace load failed for ?swirl?

Any suggestions?

	[[alternative HTML version deleted]]


From carolienlavigne at hotmail.com  Fri Apr 22 11:15:00 2016
From: carolienlavigne at hotmail.com (carolien lavigne)
Date: Fri, 22 Apr 2016 11:15:00 +0200
Subject: [R] npudens(np) Error missing value where TRUE/FALSE needed
Message-ID: <DUB124-W113046DE588B7438214923A06F0@phx.gbl>

Hi,

 

I am looking for some help concerning the npudens function
in the np package.

I am trying to find a kernel density function of a
multivariate dataset and the density evaluated at each of the 176 points. 

I have 2 continuous and 3 ordered discrete variables. My
sample size is 176.

So edata is a 176x(2+3) data frame, while tdat is a 1x(2+3)
vector. 

bw_cx[i,] is a 1x (2+3) vector representing the bandwidths h for each variable, which were calculated using the npcdensbw function. (no this is not a mistake, I deliberately use the conditional one)

For this I use the below function in R.

 kerz <-
npudens(bws=(bw_cx[i,]),cykertype="epanechnikov",cxkertype="epanechnikov",oxkertype="liracine",tdat=tdata,edat=dat)

In version 2.15.2, this worked fine, as I was able to
retrieve the necessary density estimates with kerz$dens.

This version was installed on a very old (read very slow and
about to crash) computer.

I recently installed version 3.2.4 on my new computer, and
now I get the following error message when I try to execute the npudens
function:

 

Error in if (any(a <= 0)) warning(paste("variable
", which(a <= 0), " appears to be constant",  : 

  missing value where
TRUE/FALSE needed

 

I suppose some if-statement doesn?t evaluate to a TRUE or
FALSE somewhere in the npudens function.

But as I am not an expert in writing functions, this error
message doesn?t really help.Changing it to the following also doesn't help: kerz <- npudens(bws=(bw_cx[i,]),ckertype="epanechnikov",,okertype="liracine",tdat=tdata,edat=dat)

 

Am I doing something wrong here? 

Were some changes made to this function and
do I need to alter some arguments to these changes?

Or might this be a bug?

 

Thanks!

 

Carolien 		 	   		  
	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Fri Apr 22 15:42:29 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Fri, 22 Apr 2016 13:42:29 +0000 (UTC)
Subject: [R] subset by multiple letters condition
References: <1111928406.550790.1461332549416.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1111928406.550790.1461332549416.JavaMail.yahoo@mail.yahoo.com>


Hi all, 

I have a data frame df and I want to do subset based on several conditions of letters of the names in Command.1)if the names contain PD 2)if the names contain t1 3)if the names contain t2 4)if the names contain t1 and PD 5)if the names contain t2 and PD 6)otherwise the names would be unknown. I don't know how to use grep for all these conditions. 
 
   'data.frame': 36919 obs. of 162 variables
   $TE                :int 38,41,11,52,48,75,.....
   $Command           :factor W/2229 levels "_localize_PD","_localize_tre_t2","_localize_t1_seq",...
 
 
Thanks for any help


From sabasehrish at yahoo.com  Fri Apr 22 15:51:23 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Fri, 22 Apr 2016 13:51:23 +0000 (UTC)
Subject: [R] Finding Highest value in groups
References: <1507049824.272645.1461333083629.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1507049824.272645.1461333083629.JavaMail.yahoo@mail.yahoo.com>

Hi


I have two columns in data frame. First column is based on "ID" assigned to each group of my data (similar ID depicts one group). From second column, I want to identify highest value among each group and want to assign the same ID to that highest value.

Right now the data looks like:

ID    Value
1        0.69
1        0.31
2        0.01
2        0.99
3        1.00
4        NA
4        0
4        1
5        0.5
5        0.5

I want to use R program to get results as below:

ID       Value
1        0.69
2        0.99
3        1.00
4        1
5        0.5

Kindly guide me in this regard.

Thanks
Saba


From jdnewmil at dcn.davis.ca.us  Fri Apr 22 15:55:42 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 22 Apr 2016 06:55:42 -0700
Subject: [R] Error using RPostgreSQL
In-Reply-To: <CAD5LvW=VF=8LM1-q8qAyPP8qPNNVsA8Ye35gecVkK2uje5teaw@mail.gmail.com>
References: <CAD5LvW=VF=8LM1-q8qAyPP8qPNNVsA8Ye35gecVkK2uje5teaw@mail.gmail.com>
Message-ID: <A8B5227F-C97C-42F9-88B5-2B1566387E0E@dcn.davis.ca.us>

I don't use PostGreSQL, but I strongly suspect that you would have this problem using other drivers as well, so pick any method described in the PostGreSQL documentation to verify that you can reach the server and your dbname from the machine where you are running R. Note that where you are connecting from may be just as important as where the server is,  and configuration of any of the database, the virtual OS or the AWS environment may prevent connections for security reasons. 

If you have confirmed all this is working outside of R, then you should probably ask on R-sig-db for R-specific help. 
-- 
Sent from my phone. Please excuse my brevity.

On April 21, 2016 8:49:49 AM PDT, Izaak Rogan <izaakrogan at gmail.com> wrote:
>Hi,
>
>I'm having trouble connecting to my postgreSQL db on Heroku(Amazon)
>using RPostgreSQL.
>
>I've looked through GitHub for people doing the same thing. There are
>quite a few examples and all look similar to the below:
>
>drv <- dbDriver("PostgreSQL")
>
>con <- dbConnect(
>          drv,
>          dbname = "dadqn30er7ghpl",
>          host = "ec2-27-837-167-90.eu-west-1.compute.amazonaws.com",
>          port = 5432,
>          user = "tascofyvasswmblc",
>          password = XXXXXX'
>);
>
>I'm getting the error:
>
>Error in postgresqlNewConnection(drv, ...) :
>  RS-DBI driver: (could not connect
>tascofyvasswmblc at ec2-27-837-167-90.eu-west-1.compute.amazonaws.com on
>dbname "dascn90er7ghpl"
>)
>
>Any pointers would be hugely appreciated!
>
>Thanks,
>Izaak
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From tom at maladmin.com  Fri Apr 22 16:13:16 2016
From: tom at maladmin.com (Tom Wright)
Date: Fri, 22 Apr 2016 10:13:16 -0400
Subject: [R] Finding Highest value in groups
In-Reply-To: <1507049824.272645.1461333083629.JavaMail.yahoo@mail.yahoo.com>
References: <1507049824.272645.1461333083629.JavaMail.yahoo.ref@mail.yahoo.com>
	<1507049824.272645.1461333083629.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1461334396.2445.8.camel@maladmin.com>

Assuming your dataframe is in a variable x:

> require(dplyr)
> x %>% group_by(ID) %>% summarise(maxVal = max(Value,na.rm=TRUE))



On Fri, 2016-04-22 at 13:51 +0000, Saba Sehrish via R-help wrote:
> Hi
> 
> 
> I have two columns in data frame. First column is based on "ID" assigned to each group of my data (similar ID depicts one group). From second column, I want to identify highest value among each group and want to assign the same ID to that highest value.
> 
> Right now the data looks like:
> 
> ID    Value
> 1        0.69
> 1        0.31
> 2        0.01
> 2        0.99
> 3        1.00
> 4        NA
> 4        0
> 4        1
> 5        0.5
> 5        0.5
> 
> I want to use R program to get results as below:
> 
> ID       Value
> 1        0.69
> 2        0.99
> 3        1.00
> 4        1
> 5        0.5
> 
> Kindly guide me in this regard.
> 
> Thanks
> Saba
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giorgio.garziano at ericsson.com  Fri Apr 22 16:28:04 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 22 Apr 2016 14:28:04 +0000
Subject: [R] subset by multiple letters condition
Message-ID: <248E6FA047A8C746BA491485764190F53D3AEEA7@ESESSMB207.ericsson.se>

You may investigate a solution based on regular expressions.

Some tutorials to help:

http://www.regular-expressions.info/rlanguage.html

http://www.endmemo.com/program/R/grep.php

http://biostat.mc.vanderbilt.edu/wiki/pub/Main/SvetlanaEdenRFiles/regExprTalk.pdf

https://rstudio-pubs-static.s3.amazonaws.com/74603_76cd14d5983f47408fdf0b323550b846.html

http://stat545.com/block022_regular-expression.html

https://www.youtube.com/watch?v=q8SzNKib5-4


--

Best,

GG





	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Apr 22 16:28:30 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 22 Apr 2016 15:28:30 +0100
Subject: [R] Problem installing/loading packages from Africa
In-Reply-To: <CAH+j5oYNRDBA3vP4pEFFS1tEdZKD-XBssfs7QDsCp4ZH2mr8AA@mail.gmail.com>
References: <CAH+j5oYNRDBA3vP4pEFFS1tEdZKD-XBssfs7QDsCp4ZH2mr8AA@mail.gmail.com>
Message-ID: <571A350E.9010409@dewey.myzen.co.uk>

Dear Tim

1 - if this is a specific RStudio problem best to use their forums
2 - please try not to post in HTML as it mangles your messages
3 - I think you will find that you are getting a _warning_ not an 
_error_ about the package being built under 3.2.5 when you are running 3.2.1
4 - my guess is that this is unrelated to your being in Mali

On 22/04/2016 11:41, Tim Werwie wrote:
> I'm very new to R and I live in Mali, west Africa. I'm on *OS X 10.7.5*. I
> downloaded and installed *R 3.2.1*. I downloaded and installed *RStudio
> 00.99.893*.
>
> I ran through the free Microsoft data camp intro to R course, then started
> another free course through 'edX', for Data and Statistics for Life
> Sciences, using R. The first prompt in the course is to
> install.packages("swirl"). Copied below are the various error messages I
> get when trying to install or load any package.
>
> My best guess is that the problems I'm having are due to being in west
> Africa, with unreliable connections, weak connections and no CRAN Mirror
> closer than Italy or Spain (as far as I know). I checked into common
> package errors on the RStudio page, but I'm not confident enough in my
> computing to get into internet proxies and some of the other suggested
> troubleshooting.
>
> Any insight would be very helpful. See error messages below. Thanks -- Tim
>
> - When attempting to install, the print-out I get in the Console in RStudio
> is any length of: > install.packages("swirl")
>    % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                   Dload  Upload   Total   Spent    Left
> Speed
>    0     0    0     0    0     0      0      0 --:--:--  0:00:10
> --:--:--     0  0     0    0     0    0     0      0      0 --:--:--
> 0:00:10 --:--:--     0  0     0    0     0    0     0      0      0
> --:--:--  0:00:11 --:--:--     0 22  207k   22 48384    0     0   3833
> 0  0:00:55  0:00:12  0:00:43 19740 30  207k   30 64823    0     0
> 4808      0  0:00:44  0:00:13  0:00:31 19578 38  207k   38 81207    0
> 0   5638      0  0:00:37  0:00:14  0:00:23 19193 46  207k   46 97591
> 0     0   6299      0  0:00:33  0:00:15  0:00:18 20076 53  207k   53
> 111k    0     0   6966      0  0:00:30  0:00:16  0:00:14 22717 69  207k
> 69  143k    0     0   8423      0  0:00:25  0:00:17  0:00:08 20487 76
> 207k   76  159k    0     0   8821      0  0:00:24  0:00:18  0:00:06 19621
> 92  207k   92  191k    0     0  10085      0  0:00:21  0:00:19  0:00:02
> 22841100  207k  100  207k    0     0  10363      0  0:00:20  0:00:20
> --:--:-- 230100  207k  100  207k    0     0  10363      0  0:00:20  0:00:20
> --:--:-- 23922
> The downloaded binary packages are in
>
> /var/folders/yb/7z339kn56mdbwx92ydmsqswc0000gn/T//RtmpBzQ16u/downloaded_packages
>
> For other packages, ggplot2, forexample, a similar printout can run for
> hundreds and hundred of lines. So RStudio tells me that the packages are
> available to load, BUT:
>
> - when *loading* any package an error comes up saying package 'name of
> package' was built under R version 3.2.5 but info on swirl says it should
> work on any version of R above 3.0.2. I get similar errors for other
> packages (treemap, ggplot2, etc).
>
> - Or sometimes I"ll get this: Error : .onAttach failed in attachNamespace()
> for 'swirl', details: call: stri_c(..., sep = sep, collapse = collapse,
> ignore_null = TRUE)
> error: object 'C_stri_join' not found
> In addition: Warning message:
> package ?swirl? was built under R version 3.2.5
> Error: package or namespace load failed for ?swirl?
>
> Any suggestions?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tom at maladmin.com  Fri Apr 22 16:28:23 2016
From: tom at maladmin.com (Tom Wright)
Date: Fri, 22 Apr 2016 10:28:23 -0400
Subject: [R] Error using RPostgreSQL
In-Reply-To: <CAD5LvW=VF=8LM1-q8qAyPP8qPNNVsA8Ye35gecVkK2uje5teaw@mail.gmail.com>
References: <CAD5LvW=VF=8LM1-q8qAyPP8qPNNVsA8Ye35gecVkK2uje5teaw@mail.gmail.com>
Message-ID: <1461335303.2445.11.camel@maladmin.com>

On heroku the database uri is stored in an environment variable.

> db_uri = Sys.getenv(''DATABASE_URL')

I'm not sure if you can use that directly or if you will need to parse
it for username, password etc.

On Thu, 2016-04-21 at 16:49 +0100, Izaak Rogan wrote:
> Hi,
> 
> I'm having trouble connecting to my postgreSQL db on Heroku(Amazon)
> using RPostgreSQL.
> 
> I've looked through GitHub for people doing the same thing. There are
> quite a few examples and all look similar to the below:
> 
> drv <- dbDriver("PostgreSQL")
> 
> con <- dbConnect(
>           drv,
>           dbname = "dadqn30er7ghpl",
>           host = "ec2-27-837-167-90.eu-west-1.compute.amazonaws.com",
>           port = 5432,
>           user = "tascofyvasswmblc",
>           password = XXXXXX'
> );
> 
> I'm getting the error:
> 
> Error in postgresqlNewConnection(drv, ...) :
>   RS-DBI driver: (could not connect
> tascofyvasswmblc at ec2-27-837-167-90.eu-west-1.compute.amazonaws.com on
> dbname "dascn90er7ghpl"
> )
> 
> Any pointers would be hugely appreciated!
> 
> Thanks,
> Izaak
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Fri Apr 22 16:38:19 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 22 Apr 2016 09:38:19 -0500
Subject: [R] subset by multiple letters condition
In-Reply-To: <1111928406.550790.1461332549416.JavaMail.yahoo@mail.yahoo.com>
References: <1111928406.550790.1461332549416.JavaMail.yahoo.ref@mail.yahoo.com>
	<1111928406.550790.1461332549416.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAN5YmCFcJX9yChY-yfr8J-1zvW+YBwpF-iAgDM_CM9uWdrE6pg@mail.gmail.com>

You can use the grepl() function to give you logicals for each criterion,
then combine them as needed.  For example:

# example version of Command
Command <- paste0("_localize_", c("PD","t2","t1_seq", "abc", "xyz",
"PD_t1"))

hasPD <- grepl("PD", Command, fixed=TRUE)
hast1 <- grepl("t1", Command, fixed=TRUE)
hast2 <- grepl("t2", Command, fixed=TRUE)

> Command[hast1]
[1] "_localize_t1_seq" "_localize_PD_t1"

> Command[hasPD]
[1] "_localize_PD"    "_localize_PD_t1"

> Command[hast1 & hasPD]
[1] "_localize_PD_t1"

Jean

On Fri, Apr 22, 2016 at 8:42 AM, ch.elahe via R-help <r-help at r-project.org>
wrote:

>
> Hi all,
>
> I have a data frame df and I want to do subset based on several conditions
> of letters of the names in Command.1)if the names contain PD 2)if the names
> contain t1 3)if the names contain t2 4)if the names contain t1 and PD 5)if
> the names contain t2 and PD 6)otherwise the names would be unknown. I don't
> know how to use grep for all these conditions.
>
>    'data.frame': 36919 obs. of 162 variables
>    $TE                :int 38,41,11,52,48,75,.....
>    $Command           :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_localize_t1_seq",...
>
>
> Thanks for any help
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dpierce at ucsd.edu  Fri Apr 22 17:08:52 2016
From: dpierce at ucsd.edu (David W. Pierce)
Date: Fri, 22 Apr 2016 08:08:52 -0700
Subject: [R] Unexpected values obtained when reading in data using ncdf
 and ncdf4
In-Reply-To: <ce01ddcca00c4f72aea9ac96e3b275ec@EXCH2-1.slu.se>
References: <ce01ddcca00c4f72aea9ac96e3b275ec@EXCH2-1.slu.se>
Message-ID: <CAL+Zad8z1cgEEQz8cPCn=M3_PALy+Q+gk=yo_Rp=O+_bv-rOOA@mail.gmail.com>

On Fri, Apr 22, 2016 at 1:32 AM, Louise Mair <louise.mair at slu.se> wrote:

> Dear R Users,
>
> I am encountering a problem when reading nc files into R using the ncdf
> and ncdf4 libraries. The nc files are too large to attach an example (but
> if someone is interested in helping out I could send a file privately via
> an online drive), but the code is basic:
>
?[...]?


?Hi Louise,

I'm the author of the ncdf and ncdf4 libraries. What are the details --
what operating system are you running on, what version of R and the netcdf
library are you using?

If you make the files available to me I can take a look.

Regards,

--Dave Pierce
?





> for(i in 1:length(thesenames[,1])){
>    data <- nc_open(paste(INDIR, thesenames[i,c("wholename")], sep=""),
> write=F)
>    d.vars <- names(data$var)
>    d.size <- (data$var[[length(d.vars)]])$size
>
>    # Obtaining longitude and latitude values
>    d.lon <- as.vector(ncvar_get(data, varid="lon", start=c(1,1),
> count=c(d.size[1],d.size[2])))
>    d.lat <- as.vector(ncvar_get(data, varid="lat", start=c(1,1),
> count=c(d.size[1],d.size[2])))
>
>    # Obtaining climate data values
>    df.clim <- data.frame(rn=seq(1:length(d.lon)))
>    for(y in 1:d.size[3]){
>      df.clim[,1+y] <- as.vector(ncvar_get(data,
> varid=d.vars[length(d.vars)], start=c(1,1,y),
> count=c(d.size[1],d.size[2],1)))
>       names(df.clim)[1+y] <- paste("y",y,sep="")  }
>    tosummarise[,,i] <- as.matrix(df.clim[,-1])
> }
>
> The data are temperature or precipitation, across space and time.
>
> For most of the >250 files I have, there are no problems, but for around 8
> of these files, I get strange values. The data should be within a
> relatively narrow range, yet I get values such as -8.246508e+07  or
> 7.659506e+11. The particularly strange part is that these kind of values
> occur at regularly spaced intervals across the data, usually within a
> single time step.
>
> I have the same problem (including the exact same strange values) when
> using ArcMap, yet the data provider assures me that the data look normal
> when using CDO (climate data operators) to view them, and that there are no
> missing values.
>
> I realise this is very difficult to diagnose without the nc files
> themselves, so my questions are (1) Has anyone encountered something like
> this before?, (2) Is there something I am failing to specify in the code
> when reading in?, and (3) Is anyone interested in digging into this and
> willing to play around with the nc files if I make them available privately?
>
> Thanks very much in advance!
> Louise
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
David W. Pierce
Division of Climate, Atmospheric Science, and Physical Oceanography
Scripps Institution of Oceanography, La Jolla, California, USA
(858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Fri Apr 22 17:30:47 2016
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 22 Apr 2016 08:30:47 -0700
Subject: [R] Unexpected values obtained when reading in data using ncdf
	and ncdf4
In-Reply-To: <CAL+Zad8z1cgEEQz8cPCn=M3_PALy+Q+gk=yo_Rp=O+_bv-rOOA@mail.gmail.com>
References: <ce01ddcca00c4f72aea9ac96e3b275ec@EXCH2-1.slu.se>
	<CAL+Zad8z1cgEEQz8cPCn=M3_PALy+Q+gk=yo_Rp=O+_bv-rOOA@mail.gmail.com>
Message-ID: <8AFD184A-C2EE-4A29-8CE3-DFE8F27DA70C@noaa.gov>

Hi Louise:

If Dave can?t figure it out, I can give a look also.  A couple of things I would suggest:

1.  Don?t use the name ?data? in the nc_open command, that is a reserved command in R and you never know what problems that can cause.

2. You are doing calculations to get set the start and count values in the ncvar_get commands, print those values out before you make the calls to make certain they are valid.

HTH,

-Roy

> On Apr 22, 2016, at 8:08 AM, David W. Pierce <dpierce at ucsd.edu> wrote:
> 
> On Fri, Apr 22, 2016 at 1:32 AM, Louise Mair <louise.mair at slu.se> wrote:
> 
>> Dear R Users,
>> 
>> I am encountering a problem when reading nc files into R using the ncdf
>> and ncdf4 libraries. The nc files are too large to attach an example (but
>> if someone is interested in helping out I could send a file privately via
>> an online drive), but the code is basic:
>> 
> ?[...]?
> 
> 
> ?Hi Louise,
> 
> I'm the author of the ncdf and ncdf4 libraries. What are the details --
> what operating system are you running on, what version of R and the netcdf
> library are you using?
> 
> If you make the files available to me I can take a look.
> 
> Regards,
> 
> --Dave Pierce
> ?
> 
> 
> 
> 
> 
>> for(i in 1:length(thesenames[,1])){
>>   data <- nc_open(paste(INDIR, thesenames[i,c("wholename")], sep=""),
>> write=F)
>>   d.vars <- names(data$var)
>>   d.size <- (data$var[[length(d.vars)]])$size
>> 
>>   # Obtaining longitude and latitude values
>>   d.lon <- as.vector(ncvar_get(data, varid="lon", start=c(1,1),
>> count=c(d.size[1],d.size[2])))
>>   d.lat <- as.vector(ncvar_get(data, varid="lat", start=c(1,1),
>> count=c(d.size[1],d.size[2])))
>> 
>>   # Obtaining climate data values
>>   df.clim <- data.frame(rn=seq(1:length(d.lon)))
>>   for(y in 1:d.size[3]){
>>     df.clim[,1+y] <- as.vector(ncvar_get(data,
>> varid=d.vars[length(d.vars)], start=c(1,1,y),
>> count=c(d.size[1],d.size[2],1)))
>>      names(df.clim)[1+y] <- paste("y",y,sep="")  }
>>   tosummarise[,,i] <- as.matrix(df.clim[,-1])
>> }
>> 
>> The data are temperature or precipitation, across space and time.
>> 
>> For most of the >250 files I have, there are no problems, but for around 8
>> of these files, I get strange values. The data should be within a
>> relatively narrow range, yet I get values such as -8.246508e+07  or
>> 7.659506e+11. The particularly strange part is that these kind of values
>> occur at regularly spaced intervals across the data, usually within a
>> single time step.
>> 
>> I have the same problem (including the exact same strange values) when
>> using ArcMap, yet the data provider assures me that the data look normal
>> when using CDO (climate data operators) to view them, and that there are no
>> missing values.
>> 
>> I realise this is very difficult to diagnose without the nc files
>> themselves, so my questions are (1) Has anyone encountered something like
>> this before?, (2) Is there something I am failing to specify in the code
>> when reading in?, and (3) Is anyone interested in digging into this and
>> willing to play around with the nc files if I make them available privately?
>> 
>> Thanks very much in advance!
>> Louise
>> 
>> 
>> 
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> David W. Pierce
> Division of Climate, Atmospheric Science, and Physical Oceanography
> Scripps Institution of Oceanography, La Jolla, California, USA
> (858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From giorgio.garziano at ericsson.com  Fri Apr 22 17:42:24 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 22 Apr 2016 15:42:24 +0000
Subject: [R] Finding Highest value in groups
Message-ID: <248E6FA047A8C746BA491485764190F53D3AEF14@ESESSMB207.ericsson.se>

idvalues <- data.frame (ID = c(1, 1, 2, 2, 3, 4, 4, 4, 5, 5),
                        Value = c(0.69, 0.31, 0.01, 0.99, 1.00, NA, 0,1, 0.5, 0.5))

aggregate(Value~ID, data=idvalues, max)

ID Value
1  1  0.69
2  2  0.99
3  3  1.00
4  4  1.00
5  5  0.50

--

Best,

GG




	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Apr 22 19:47:30 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 22 Apr 2016 17:47:30 +0000
Subject: [R] Finding Highest value in groups
In-Reply-To: <1461334396.2445.8.camel@maladmin.com>
References: <1507049824.272645.1461333083629.JavaMail.yahoo.ref@mail.yahoo.com>
	<1507049824.272645.1461333083629.JavaMail.yahoo@mail.yahoo.com>
	<1461334396.2445.8.camel@maladmin.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72E33C@mb02.ads.tamu.edu>

Base R functions can handle this easily. It is preferable to use dput() as a compact way of providing data on the list:

> dta <- read.table(text="ID    Value
+ 1        0.69
+ 1        0.31
+ 2        0.01
+ 2        0.99
+ 3        1.00
+ 4        NA
+ 4        0
+ 4        1
+ 5        0.5
+ 5        0.5
+ ", header=TRUE)
> dput(dta)
structure(list(ID = c(1L, 1L, 2L, 2L, 3L, 4L, 4L, 4L, 5L, 5L), 
    Value = c(0.69, 0.31, 0.01, 0.99, 1, NA, 0, 1, 0.5, 0.5)), .Names = c("ID", 
"Value"), class = "data.frame", row.names = c(NA, -10L))

Then you just need the aggregate() function:

> aggregate(Value~ID, dta, max, na.rm=TRUE)
  ID Value
1  1  0.69
2  2  0.99
3  3  1.00
4  4  1.00
5  5  0.50

See ?aggregate for the help page.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tom Wright
Sent: Friday, April 22, 2016 9:13 AM
To: Saba Sehrish
Cc: R-help Mailing List
Subject: Re: [R] Finding Highest value in groups

Assuming your dataframe is in a variable x:

> require(dplyr)
> x %>% group_by(ID) %>% summarise(maxVal = max(Value,na.rm=TRUE))



On Fri, 2016-04-22 at 13:51 +0000, Saba Sehrish via R-help wrote:
> Hi
> 
> 
> I have two columns in data frame. First column is based on "ID" assigned to each group of my data (similar ID depicts one group). From second column, I want to identify highest value among each group and want to assign the same ID to that highest value.
> 
> Right now the data looks like:
> 
> ID    Value
> 1        0.69
> 1        0.31
> 2        0.01
> 2        0.99
> 3        1.00
> 4        NA
> 4        0
> 4        1
> 5        0.5
> 5        0.5
> 
> I want to use R program to get results as below:
> 
> ID       Value
> 1        0.69
> 2        0.99
> 3        1.00
> 4        1
> 5        0.5
> 
> Kindly guide me in this regard.
> 
> Thanks
> Saba
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From giorgio.garziano at ericsson.com  Fri Apr 22 20:47:41 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 22 Apr 2016 18:47:41 +0000
Subject: [R] Finding Highest value in groups
Message-ID: <248E6FA047A8C746BA491485764190F53D3AF033@ESESSMB207.ericsson.se>

Since the aggregate S3 method for class formula already has got na.action = na.omit,

## S3 method for class 'formula'
aggregate(formula, data, FUN, ...,
          subset, na.action = na.omit)


I think that to deal with NA's, it is enough:

   aggregate(Value~ID, dta, max)

Moreover, passing na.rm = FALSE/TRUE is "don't care":

aggregate(Value~ID, dta, max, na.rm=FALSE) result is:

  ID Value
1  1  0.69
2  2  0.99
3  3  1.00
4  4  1.00
5  5  0.50

which is the same of na.rm=TRUE.

On the contrary, in the following cases:

aggregate(Value~ID, dta, max, na.action = na.pass)

  ID Value
1  1  0.69
2  2  0.99
3  3  1.00
4  4    NA
5  5  0.50

aggregate(Value~ID, dta, max, na.action = na.fail)

  Error in na.fail.default(list(Value = c(0.69, 0.31, 0.01, 0.99, 1, NA


the result is different.

--

Best,

GG





	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Apr 22 20:50:57 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 22 Apr 2016 18:50:57 +0000
Subject: [R] simulation in R
In-Reply-To: <BY2PR13MB0454F9CBDF0B0A8B5E3A3163FA6D0@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454E407FACEFDF06A2D8408FA6D0@BY2PR13MB0454.namprd13.prod.outlook.com>
	<BY2PR13MB0454F9CBDF0B0A8B5E3A3163FA6D0@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72E3A7@mb02.ads.tamu.edu>

I don't think we have enough information to help you with this. 

Do you intent the simulated values for growthrate to be selected from the values in daT$growthrate? Or do these values define a distribution of values (perhaps ranging between 0 and 1) and the simulation should use that empirical distribution? In that case any value of growthrate in the range of 0 and 1 inclusive is possible.

What is the sample size of the 9999 Monte Carlo simulations? This will have a major effect on the ranges since as the sample size increases the range will be closer and closer to the range of the growthrate (0 to 1 for condition 3 and 0 to .5 for condition 1).

In your example of no constraints on food (condition 2), if the growthrate is always 1, the range will always be 1 and 1.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kristi Glover
Sent: Wednesday, April 20, 2016 1:06 AM
To: R-help
Subject: [R] simulation in R

I realized that there was a typo error. I mean "Monte Carlo Simulation"

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Kristi Glover <kristi.glover at hotmail.com>
Sent: April 19, 2016 11:48 PM
To: R-help
Subject: [R] simulation in R

Hi R user,
Would you mind to help me to find the range with stochastic events? For example,

daT<-structure(list(sn = 1:14, growthrate = c(0.5, 0.6, 0.7, 0.99,
0.1, 0.3, 0.4, 0.5, 0.5, 0.2, 0.1, 0.4, 0.3, 0.43)), .Names = c("sn",
"growthrate"), class = "data.frame", row.names = c(NA, -14L))

I want to find the ranges of growth rate of the above data using Mote corle simulation (9999 times) under three conditions:
1. very drought ( in that condition growth will not be more than 0.5). [what would be the range (max, min ) of the growth rate for this scenario)
2. no constraints of  food (growth will be 1 or 100%) (what would be the range (max,min) of growth rate in this scenario?).
3. Control (as it is) (Range??, max.min)

I tried to find whether some one had same problem but I could not find it, is it too complicated to write the code in R for this example? your help will be highly appreciated.

Sincerely,


KG



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mylisttech at gmail.com  Fri Apr 22 20:51:16 2016
From: mylisttech at gmail.com (mylisttech at gmail.com)
Date: Sat, 23 Apr 2016 00:21:16 +0530
Subject: [R] Number of package in Ubuntu
Message-ID: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>

Dear Experts ,

I am using R with Spark on Windows and now there is a need to move to Ubuntu. I wanted to know if most of the packages that are available on windows , would they be available on Ubuntu/Linux? If not can I compile the source code of those package ? Has any one of you used the packages on Ubuntu ?  

Thanks in Advance.


From giftedlife2014 at gmail.com  Fri Apr 22 21:04:56 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Fri, 22 Apr 2016 20:04:56 +0100
Subject: [R] clock24.plot/radial plot
In-Reply-To: <CAKVAULMOmRcHOdYsECVYtGD7eUS6Wi81dLe9Z-emimuzK1FSiQ@mail.gmail.com>
References: <CAC8ss30n+aWgTyc8-b0ebrcLPgrw5M4swec3rAin0ko4xyKXYQ@mail.gmail.com>
	<CAKVAULMOmRcHOdYsECVYtGD7eUS6Wi81dLe9Z-emimuzK1FSiQ@mail.gmail.com>
Message-ID: <CAC8ss33P8NPTXB2pGMuuL8mJtqP8Q9kOkjhsiKcn1aq5mOFPww@mail.gmail.com>

Kind Experts,
Many thanks for your guide. I have tried to figure out something that
can help me plot my own data using the examples you referred me to. I
copied part of the code as:

set.seed(44)
N=500
events <- as.POSIXct("2011-01-01", tz="GMT") +
              days(floor(365*runif(N))) +
              hours(floor(24*rnorm(N))) +  # using rnorm here
              minutes(floor(60*runif(N))) +
              seconds(floor(60*runif(N)))
hour_of_event <- hour(events)
# make a dataframe
eventdata <- data.frame(datetime = events, eventhour = hour_of_event)
# determine if event is in business hours
eventdata$Workday <- eventdata$eventhour %in% seq(9, 17)
library(circular)
eventdata$eventhour <- circular(hour_of_event%%24, # convert to 24 hrs
      units="hours", template="clock24")
rose.diag(eventdata$eventhour, bin = 24, col = "lightblue", main =
"Events by Hour (sqrt scale)",
    prop = 3)
I tried to run the above but got an error message: "Error in
eval(expr, envir, enclos) : could not find function "days"
I was thinking that if I could run this code, I can see what is doing
and then start trying to see if I can adapt it to solve my problem.

Thank you so much for further assistance.
Ogbos


On 4/22/16, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> I use ggplot2 for all my plotting needs where you can make plots circular
> with the coord_polar. Maybe this will help you along:
> http://rstudio-pubs-static.s3.amazonaws.com/3369_998f8b2d788e4a0384ae565c4280aa47.html
>
> On Fri, 22 Apr 2016 at 08:31 Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
>> Dear All,
>> I am trying to generate a circular/radial plot. The script below has a
>> result I am looking for:
>> testlen<-rnorm(24)*2+5
>>  testpos<-0:23+rnorm(24)/4
>>  clock24.plot(testlen,testpos,main="Test Clock24
>> (lines)",show.grid=FALSE,
>>   line.col="green",lwd=3)
>>  if(dev.interactive()) par(ask=TRUE)
>>  # now do a 'daylight' plot
>>  oldpar<-clock24.plot(testlen[7:19],testpos[7:19],
>>   main="Test Clock24 daytime (symbols)",
>>   point.col="blue",rp.type="s",lwd=3)
>>  # reset everything
>>  par(oldpar)
>>
>> I tried to play with the script to work with my data. I read my data:
>> swe<-scan("onedaydata",list(dates="",time="",count=""))
>> dates<-swe$dates
>> times<-swe$time
>> count<-swe$count.
>> I tried to replace testlen<-rnorm(24)*2+5 with testlen<-count and
>> oldpar<-clock24.plot(testlen[7:19],testpos[7:19], with
>> oldpar<-clock24.plot(testlen[0:23],testpos[0:23], but nothing worked.
>> The format of my data is 2005/01/01 00:00   4009
>> 2005/01/01 01:00   3969
>> 2005/01/01 02:00   3946
>> 2005/01/01 03:00   3975
>> 2005/01/01 04:00   3960
>> 2005/01/01 05:00   3974
>> 2005/01/01 06:00   3971
>> 2005/01/01 07:00   3970
>> 2005/01/01 08:00   3962
>> 2005/01/01 09:00   3992
>> 2005/01/01 10:00   3955
>> 2005/01/01 11:00   3963
>> 2005/01/01 12:00   3965
>> 2005/01/01 13:00   3947
>> 2005/01/01 14:00   3959
>> 2005/01/01 15:00   3978
>> 2005/01/01 16:00   3967
>> 2005/01/01 17:00   3978
>> 2005/01/01 18:00   3988
>> 2005/01/01 19:00   4043
>> 2005/01/01 20:00   4026
>> 2005/01/01 21:00   3996
>> 2005/01/01 22:00   3967
>> 2005/01/01 23:00   3969
>> 2005/01/02 00:00   3976
>> 2005/01/02 01:00   3969
>> 2005/01/02 02:00   3955
>> 2005/01/02 03:00   3984
>> 2005/01/02 04:00   3971
>> 2005/01/02 05:00   3960
>> 2005/01/02 06:00   3951
>> 2005/01/02 07:00   3948
>> 2005/01/02 08:00   3954
>> 2005/01/02 09:00   3948
>> 2005/01/02 10:00   3960
>> 2005/01/02 11:00   3964
>> 2005/01/02 12:00   3962
>> 2005/01/02 13:00   3959
>> 2005/01/02 14:00   3950
>> 2005/01/02 15:00   3972
>> 2005/01/02 16:00   3984
>> 2005/01/02 17:00   3983
>> 2005/01/02 18:00   3982
>> 2005/01/02 19:00   3987
>> 2005/01/02 20:00   3989
>> 2005/01/02 21:00   3975
>> 2005/01/02 22:00   3956
>> 2005/01/02 23:00   3975
>> 2005/01/03 00:00   3946
>> 2005/01/03 01:00   3944
>> 2005/01/03 02:00   3915
>> 2005/01/03 03:00   3901
>> 2005/01/03 04:00   3893
>> 2005/01/03 05:00   3854
>> 2005/01/03 06:00   3824
>> 2005/01/03 07:00   3790
>> 2005/01/03 08:00   3770
>> 2005/01/03 09:00   3794
>> 2005/01/03 10:00   3778
>> 2005/01/03 11:00   3803
>> 2005/01/03 12:00   3801
>> 2005/01/03 13:00   3800
>> 2005/01/03 14:00   3783
>> 2005/01/03 15:00   3789
>> 2005/01/03 16:00   3804
>> 2005/01/03 17:00   3781
>> 2005/01/03 18:00   3785
>> 2005/01/03 19:00   3772
>> 2005/01/03 20:00   3777
>> 2005/01/03 21:00   3766
>> 2005/01/03 22:00   3775
>> 2005/01/03 23:00   3779
>> 2005/01/04 00:00   3798
>> 2005/01/04 01:00   3806
>>
>> A sample of the plot I want is attached. My data is quite large.
>> Thanks for your time.
>> Best wishes
>> Ogbos
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Fri Apr 22 21:24:53 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 22 Apr 2016 19:24:53 +0000
Subject: [R] clock24.plot/radial plot
In-Reply-To: <CAC8ss33P8NPTXB2pGMuuL8mJtqP8Q9kOkjhsiKcn1aq5mOFPww@mail.gmail.com>
References: <CAC8ss30n+aWgTyc8-b0ebrcLPgrw5M4swec3rAin0ko4xyKXYQ@mail.gmail.com>
	<CAKVAULMOmRcHOdYsECVYtGD7eUS6Wi81dLe9Z-emimuzK1FSiQ@mail.gmail.com>
	<CAC8ss33P8NPTXB2pGMuuL8mJtqP8Q9kOkjhsiKcn1aq5mOFPww@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72E4B8@mb02.ads.tamu.edu>

Looks like you forgot to load the lubridate package

library(lubridate)

You are calling functions days(), hours(), minutes(), seconds(), and hour() which all come from that package. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ogbos Okike
Sent: Friday, April 22, 2016 2:05 PM
To: Ulrik Stervbo
Cc: r-help at r-project.org
Subject: Re: [R] clock24.plot/radial plot

Kind Experts,
Many thanks for your guide. I have tried to figure out something that
can help me plot my own data using the examples you referred me to. I
copied part of the code as:

set.seed(44)
N=500
events <- as.POSIXct("2011-01-01", tz="GMT") +
              days(floor(365*runif(N))) +
              hours(floor(24*rnorm(N))) +  # using rnorm here
              minutes(floor(60*runif(N))) +
              seconds(floor(60*runif(N)))
hour_of_event <- hour(events)
# make a dataframe
eventdata <- data.frame(datetime = events, eventhour = hour_of_event)
# determine if event is in business hours
eventdata$Workday <- eventdata$eventhour %in% seq(9, 17)
library(circular)
eventdata$eventhour <- circular(hour_of_event%%24, # convert to 24 hrs
      units="hours", template="clock24")
rose.diag(eventdata$eventhour, bin = 24, col = "lightblue", main =
"Events by Hour (sqrt scale)",
    prop = 3)
I tried to run the above but got an error message: "Error in
eval(expr, envir, enclos) : could not find function "days"
I was thinking that if I could run this code, I can see what is doing
and then start trying to see if I can adapt it to solve my problem.

Thank you so much for further assistance.
Ogbos


On 4/22/16, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> I use ggplot2 for all my plotting needs where you can make plots circular
> with the coord_polar. Maybe this will help you along:
> http://rstudio-pubs-static.s3.amazonaws.com/3369_998f8b2d788e4a0384ae565c4280aa47.html
>
> On Fri, 22 Apr 2016 at 08:31 Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>
>> Dear All,
>> I am trying to generate a circular/radial plot. The script below has a
>> result I am looking for:
>> testlen<-rnorm(24)*2+5
>>  testpos<-0:23+rnorm(24)/4
>>  clock24.plot(testlen,testpos,main="Test Clock24
>> (lines)",show.grid=FALSE,
>>   line.col="green",lwd=3)
>>  if(dev.interactive()) par(ask=TRUE)
>>  # now do a 'daylight' plot
>>  oldpar<-clock24.plot(testlen[7:19],testpos[7:19],
>>   main="Test Clock24 daytime (symbols)",
>>   point.col="blue",rp.type="s",lwd=3)
>>  # reset everything
>>  par(oldpar)
>>
>> I tried to play with the script to work with my data. I read my data:
>> swe<-scan("onedaydata",list(dates="",time="",count=""))
>> dates<-swe$dates
>> times<-swe$time
>> count<-swe$count.
>> I tried to replace testlen<-rnorm(24)*2+5 with testlen<-count and
>> oldpar<-clock24.plot(testlen[7:19],testpos[7:19], with
>> oldpar<-clock24.plot(testlen[0:23],testpos[0:23], but nothing worked.
>> The format of my data is 2005/01/01 00:00   4009
>> 2005/01/01 01:00   3969
>> 2005/01/01 02:00   3946
>> 2005/01/01 03:00   3975
>> 2005/01/01 04:00   3960
>> 2005/01/01 05:00   3974
>> 2005/01/01 06:00   3971
>> 2005/01/01 07:00   3970
>> 2005/01/01 08:00   3962
>> 2005/01/01 09:00   3992
>> 2005/01/01 10:00   3955
>> 2005/01/01 11:00   3963
>> 2005/01/01 12:00   3965
>> 2005/01/01 13:00   3947
>> 2005/01/01 14:00   3959
>> 2005/01/01 15:00   3978
>> 2005/01/01 16:00   3967
>> 2005/01/01 17:00   3978
>> 2005/01/01 18:00   3988
>> 2005/01/01 19:00   4043
>> 2005/01/01 20:00   4026
>> 2005/01/01 21:00   3996
>> 2005/01/01 22:00   3967
>> 2005/01/01 23:00   3969
>> 2005/01/02 00:00   3976
>> 2005/01/02 01:00   3969
>> 2005/01/02 02:00   3955
>> 2005/01/02 03:00   3984
>> 2005/01/02 04:00   3971
>> 2005/01/02 05:00   3960
>> 2005/01/02 06:00   3951
>> 2005/01/02 07:00   3948
>> 2005/01/02 08:00   3954
>> 2005/01/02 09:00   3948
>> 2005/01/02 10:00   3960
>> 2005/01/02 11:00   3964
>> 2005/01/02 12:00   3962
>> 2005/01/02 13:00   3959
>> 2005/01/02 14:00   3950
>> 2005/01/02 15:00   3972
>> 2005/01/02 16:00   3984
>> 2005/01/02 17:00   3983
>> 2005/01/02 18:00   3982
>> 2005/01/02 19:00   3987
>> 2005/01/02 20:00   3989
>> 2005/01/02 21:00   3975
>> 2005/01/02 22:00   3956
>> 2005/01/02 23:00   3975
>> 2005/01/03 00:00   3946
>> 2005/01/03 01:00   3944
>> 2005/01/03 02:00   3915
>> 2005/01/03 03:00   3901
>> 2005/01/03 04:00   3893
>> 2005/01/03 05:00   3854
>> 2005/01/03 06:00   3824
>> 2005/01/03 07:00   3790
>> 2005/01/03 08:00   3770
>> 2005/01/03 09:00   3794
>> 2005/01/03 10:00   3778
>> 2005/01/03 11:00   3803
>> 2005/01/03 12:00   3801
>> 2005/01/03 13:00   3800
>> 2005/01/03 14:00   3783
>> 2005/01/03 15:00   3789
>> 2005/01/03 16:00   3804
>> 2005/01/03 17:00   3781
>> 2005/01/03 18:00   3785
>> 2005/01/03 19:00   3772
>> 2005/01/03 20:00   3777
>> 2005/01/03 21:00   3766
>> 2005/01/03 22:00   3775
>> 2005/01/03 23:00   3779
>> 2005/01/04 00:00   3798
>> 2005/01/04 01:00   3806
>>
>> A sample of the plot I want is attached. My data is quite large.
>> Thanks for your time.
>> Best wishes
>> Ogbos
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From giftedlife2014 at gmail.com  Fri Apr 22 21:34:52 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Fri, 22 Apr 2016 20:34:52 +0100
Subject: [R] clock24.plot/radial plot
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72E4B8@mb02.ads.tamu.edu>
References: <CAC8ss30n+aWgTyc8-b0ebrcLPgrw5M4swec3rAin0ko4xyKXYQ@mail.gmail.com>
	<CAKVAULMOmRcHOdYsECVYtGD7eUS6Wi81dLe9Z-emimuzK1FSiQ@mail.gmail.com>
	<CAC8ss33P8NPTXB2pGMuuL8mJtqP8Q9kOkjhsiKcn1aq5mOFPww@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D72E4B8@mb02.ads.tamu.edu>
Message-ID: <CAC8ss325iteBY7DokOV542D08ba31LUM0EL7xxw3AkCDg2KwFA@mail.gmail.com>

Dear All,
One hand. Many thanks!! The code run as soon as I loaded lubridate.

Please can you guide me on how to relate this code to my actual data.
My actual data is looking like:
2005/01/01 00:00   4009
2005/01/01 01:00   3969
2005/01/01 02:00   3946
2005/01/01 03:00   3975
2005/01/01 04:00   3960
2005/01/01 05:00   3974
2005/01/01 06:00   3971
2005/01/01 07:00   3970
2005/01/01 08:00   3962
2005/01/01 09:00   3992
2005/01/01 10:00   3955
2005/01/01 11:00   3963
2005/01/01 12:00   3965
2005/01/01 13:00   3947
2005/01/01 14:00   3959
2005/01/01 15:00   3978
2005/01/01 16:00   3967
and it runs for many years.

Many thanks for time.
Ogbos

On 4/22/16, David L Carlson <dcarlson at tamu.edu> wrote:
> Looks like you forgot to load the lubridate package
>
> library(lubridate)
>
> You are calling functions days(), hours(), minutes(), seconds(), and hour()
> which all come from that package.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ogbos Okike
> Sent: Friday, April 22, 2016 2:05 PM
> To: Ulrik Stervbo
> Cc: r-help at r-project.org
> Subject: Re: [R] clock24.plot/radial plot
>
> Kind Experts,
> Many thanks for your guide. I have tried to figure out something that
> can help me plot my own data using the examples you referred me to. I
> copied part of the code as:
>
> set.seed(44)
> N=500
> events <- as.POSIXct("2011-01-01", tz="GMT") +
>               days(floor(365*runif(N))) +
>               hours(floor(24*rnorm(N))) +  # using rnorm here
>               minutes(floor(60*runif(N))) +
>               seconds(floor(60*runif(N)))
> hour_of_event <- hour(events)
> # make a dataframe
> eventdata <- data.frame(datetime = events, eventhour = hour_of_event)
> # determine if event is in business hours
> eventdata$Workday <- eventdata$eventhour %in% seq(9, 17)
> library(circular)
> eventdata$eventhour <- circular(hour_of_event%%24, # convert to 24 hrs
>       units="hours", template="clock24")
> rose.diag(eventdata$eventhour, bin = 24, col = "lightblue", main =
> "Events by Hour (sqrt scale)",
>     prop = 3)
> I tried to run the above but got an error message: "Error in
> eval(expr, envir, enclos) : could not find function "days"
> I was thinking that if I could run this code, I can see what is doing
> and then start trying to see if I can adapt it to solve my problem.
>
> Thank you so much for further assistance.
> Ogbos
>
>
> On 4/22/16, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>> I use ggplot2 for all my plotting needs where you can make plots circular
>> with the coord_polar. Maybe this will help you along:
>> http://rstudio-pubs-static.s3.amazonaws.com/3369_998f8b2d788e4a0384ae565c4280aa47.html
>>
>> On Fri, 22 Apr 2016 at 08:31 Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>>> Dear All,
>>> I am trying to generate a circular/radial plot. The script below has a
>>> result I am looking for:
>>> testlen<-rnorm(24)*2+5
>>>  testpos<-0:23+rnorm(24)/4
>>>  clock24.plot(testlen,testpos,main="Test Clock24
>>> (lines)",show.grid=FALSE,
>>>   line.col="green",lwd=3)
>>>  if(dev.interactive()) par(ask=TRUE)
>>>  # now do a 'daylight' plot
>>>  oldpar<-clock24.plot(testlen[7:19],testpos[7:19],
>>>   main="Test Clock24 daytime (symbols)",
>>>   point.col="blue",rp.type="s",lwd=3)
>>>  # reset everything
>>>  par(oldpar)
>>>
>>> I tried to play with the script to work with my data. I read my data:
>>> swe<-scan("onedaydata",list(dates="",time="",count=""))
>>> dates<-swe$dates
>>> times<-swe$time
>>> count<-swe$count.
>>> I tried to replace testlen<-rnorm(24)*2+5 with testlen<-count and
>>> oldpar<-clock24.plot(testlen[7:19],testpos[7:19], with
>>> oldpar<-clock24.plot(testlen[0:23],testpos[0:23], but nothing worked.
>>> The format of my data is 2005/01/01 00:00   4009
>>> 2005/01/01 01:00   3969
>>> 2005/01/01 02:00   3946
>>> 2005/01/01 03:00   3975
>>> 2005/01/01 04:00   3960
>>> 2005/01/01 05:00   3974
>>> 2005/01/01 06:00   3971
>>> 2005/01/01 07:00   3970
>>> 2005/01/01 08:00   3962
>>> 2005/01/01 09:00   3992
>>> 2005/01/01 10:00   3955
>>> 2005/01/01 11:00   3963
>>> 2005/01/01 12:00   3965
>>> 2005/01/01 13:00   3947
>>> 2005/01/01 14:00   3959
>>> 2005/01/01 15:00   3978
>>> 2005/01/01 16:00   3967
>>> 2005/01/01 17:00   3978
>>> 2005/01/01 18:00   3988
>>> 2005/01/01 19:00   4043
>>> 2005/01/01 20:00   4026
>>> 2005/01/01 21:00   3996
>>> 2005/01/01 22:00   3967
>>> 2005/01/01 23:00   3969
>>> 2005/01/02 00:00   3976
>>> 2005/01/02 01:00   3969
>>> 2005/01/02 02:00   3955
>>> 2005/01/02 03:00   3984
>>> 2005/01/02 04:00   3971
>>> 2005/01/02 05:00   3960
>>> 2005/01/02 06:00   3951
>>> 2005/01/02 07:00   3948
>>> 2005/01/02 08:00   3954
>>> 2005/01/02 09:00   3948
>>> 2005/01/02 10:00   3960
>>> 2005/01/02 11:00   3964
>>> 2005/01/02 12:00   3962
>>> 2005/01/02 13:00   3959
>>> 2005/01/02 14:00   3950
>>> 2005/01/02 15:00   3972
>>> 2005/01/02 16:00   3984
>>> 2005/01/02 17:00   3983
>>> 2005/01/02 18:00   3982
>>> 2005/01/02 19:00   3987
>>> 2005/01/02 20:00   3989
>>> 2005/01/02 21:00   3975
>>> 2005/01/02 22:00   3956
>>> 2005/01/02 23:00   3975
>>> 2005/01/03 00:00   3946
>>> 2005/01/03 01:00   3944
>>> 2005/01/03 02:00   3915
>>> 2005/01/03 03:00   3901
>>> 2005/01/03 04:00   3893
>>> 2005/01/03 05:00   3854
>>> 2005/01/03 06:00   3824
>>> 2005/01/03 07:00   3790
>>> 2005/01/03 08:00   3770
>>> 2005/01/03 09:00   3794
>>> 2005/01/03 10:00   3778
>>> 2005/01/03 11:00   3803
>>> 2005/01/03 12:00   3801
>>> 2005/01/03 13:00   3800
>>> 2005/01/03 14:00   3783
>>> 2005/01/03 15:00   3789
>>> 2005/01/03 16:00   3804
>>> 2005/01/03 17:00   3781
>>> 2005/01/03 18:00   3785
>>> 2005/01/03 19:00   3772
>>> 2005/01/03 20:00   3777
>>> 2005/01/03 21:00   3766
>>> 2005/01/03 22:00   3775
>>> 2005/01/03 23:00   3779
>>> 2005/01/04 00:00   3798
>>> 2005/01/04 01:00   3806
>>>
>>> A sample of the plot I want is attached. My data is quite large.
>>> Thanks for your time.
>>> Best wishes
>>> Ogbos
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Fri Apr 22 21:39:29 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 22 Apr 2016 12:39:29 -0700
Subject: [R] Number of package in Ubuntu
In-Reply-To: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
References: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
Message-ID: <60EA0191-E4A2-4367-86F2-69315229433A@dcn.davis.ca.us>

There are thousands of R packages. The majority work fine on multiple platforms.  Whether your packages are in that group is something only you can determine. 

I will say that Linux is typically better than Windows when it comes to big data tech, so even if some specific packages don't work there are likely equivalent packages that do. 
-- 
Sent from my phone. Please excuse my brevity.

On April 22, 2016 11:51:16 AM PDT, mylisttech at gmail.com wrote:
>Dear Experts ,
>
>I am using R with Spark on Windows and now there is a need to move to
>Ubuntu. I wanted to know if most of the packages that are available on
>windows , would they be available on Ubuntu/Linux? If not can I compile
>the source code of those package ? Has any one of you used the packages
>on Ubuntu ?  
>
>Thanks in Advance.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From paulhtremblay at gmail.com  Fri Apr 22 21:47:42 2016
From: paulhtremblay at gmail.com (Paul Tremblay)
Date: Fri, 22 Apr 2016 12:47:42 -0700
Subject: [R] installation problem on Ubuntu
In-Reply-To: <6CE71142-C250-40AF-B8B0-839475A5EC8B@comcast.net>
References: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>
	<1461183848.3220.6.camel@maladmin.com>
	<CAP5QEc6D=iabCuszhAF+oMFnn_eOUNPxEfWVJMNGtGfjQNJc9g@mail.gmail.com>
	<6CE71142-C250-40AF-B8B0-839475A5EC8B@comcast.net>
Message-ID: <CAP5QEc7PXn4tSDJYxCWDrW9FL_28pcF5GNoQ=_mosxAjGuce5Q@mail.gmail.com>

LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/:$LD_LIBRARY_PATH
source ~/.bash_profile

I still get the same error.

On Thu, Apr 21, 2016 at 7:45 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Apr 21, 2016, at 1:23 PM, Paul Tremblay <paulhtremblay at gmail.com>
> wrote:
> >
> > I was able to install the curl library with no problems. However, when I
> > tried to install ggplot (install.packages("ggplot2")), I got the same
> > message as earlier, that R can't load internet.so.
>
> Is the libcurl directory in your search path?
>
> David.
> >
> > Thanks for your help!
> >
> > On Wed, Apr 20, 2016 at 1:24 PM, Tom Wright <tom at maladmin.com> wrote:
> >
> >> apt-get install curl libcurl4-openssl-dev
> >>
> >> On Wed, 2016-04-20 at 09:36 -0700, Paul Tremblay wrote:
> >>> I needed to update R so I could install ggplot. I am running Ubuntu
> >> 12.04.
> >>> I cannot upgrade Ubuntu because I am using a work computer.
> >>>
> >>> I tried upgrading the normal way:
> >>>
> >>> sudo apt-get update
> >>> sudo apt-get install r-base r-base-dev
> >>>
> >>> But this only installed an earlier version. Finally I tried installing
> >> from
> >>> source (./configure, Make install). This worked. However, when I try to
> >>> install packages, I get this error:
> >>>
> >>> Error in download.file(url, destfile = f, quiet = TRUE) :
> >>>  internet routines cannot be loaded
> >>> In addition: Warning message:
> >>> In download.file(url, destfile = f, quiet = TRUE) :
> >>>  unable to load shared object '/usr/local/lib/R/modules//internet.so':
> >>>  /usr/local/lib/R/modules//internet.so: undefined symbol:
> >> curl_multi_wait
> >>>
> >>>
> >>>>> ls /usr/local/lib/R/modules/
> >>>>> R_X11.so  R_de.so  internet.so  lapack.so
> >>>
> >>> Thanks!
> >>>
> >>> P
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From Ross.Boylan at ucsf.edu  Fri Apr 22 22:38:57 2016
From: Ross.Boylan at ucsf.edu (Boylan, Ross)
Date: Fri, 22 Apr 2016 20:38:57 +0000
Subject: [R] S4 non-virtual class with no slots?
Message-ID: <F1F13E14A610474196571953929C02090C0FA308@ex08.net.ucsf.edu>

It seems that if an S4 class has no slots it can't be instantiated because it is assumed to be virtual.  Is there a way around this other than adding a do-nothing slot?  A singleton would be OK, though is not essential.

Problem:
EmptyFitResult <- setClass("EmptyFitResult", representation=representation())
# also tried it without the second argument.  same result.
 > e <- EmptyFitResult()
 Error in new("EmptyFitResult", ...) :
   trying to generate an object from a virtual class ("EmptyFitResult")

This in R 3.1.1.

Context:
I fit simulated data; in some simulations none survive to the second stage of fitting.  So I just need a way to record that this happened, in a way that integrates with my other non-null results.

Thanks.
Ross Boylan


From dwinsemius at comcast.net  Fri Apr 22 23:08:54 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Apr 2016 14:08:54 -0700
Subject: [R] installation problem on Ubuntu
In-Reply-To: <CAP5QEc7PXn4tSDJYxCWDrW9FL_28pcF5GNoQ=_mosxAjGuce5Q@mail.gmail.com>
References: <CAP5QEc7AtqomLW8BQXyfZqFR82UkrStxxvmyP878q5O4zHOmUQ@mail.gmail.com>
	<1461183848.3220.6.camel@maladmin.com>
	<CAP5QEc6D=iabCuszhAF+oMFnn_eOUNPxEfWVJMNGtGfjQNJc9g@mail.gmail.com>
	<6CE71142-C250-40AF-B8B0-839475A5EC8B@comcast.net>
	<CAP5QEc7PXn4tSDJYxCWDrW9FL_28pcF5GNoQ=_mosxAjGuce5Q@mail.gmail.com>
Message-ID: <A6EE1EE6-184D-4C3B-89A1-43B1C6C2C5A6@comcast.net>


> On Apr 22, 2016, at 12:47 PM, Paul Tremblay <paulhtremblay at gmail.com> wrote:
> 
> LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/:$LD_LIBRARY_PATH
> source ~/.bash_profile

On my machine Sys.getenv("LD_LIBRARY_PATH") returns "" in R and echo $LD_LIBRARY_PATH likewise returns only a carriage return from a bash console, but I'm on a UNIX box and Linux may be different. You might try posting on R-SIG-Debian since Ubuntu is a fork of Debian. 

Best;
David.
> 
> I still get the same error. 
> 
> On Thu, Apr 21, 2016 at 7:45 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Apr 21, 2016, at 1:23 PM, Paul Tremblay <paulhtremblay at gmail.com> wrote:
> >
> > I was able to install the curl library with no problems. However, when I
> > tried to install ggplot (install.packages("ggplot2")), I got the same
> > message as earlier, that R can't load internet.so.
> 
> Is the libcurl directory in your search path?
> 
> David.
> >
> > Thanks for your help!
> >
> > On Wed, Apr 20, 2016 at 1:24 PM, Tom Wright <tom at maladmin.com> wrote:
> >
> >> apt-get install curl libcurl4-openssl-dev
> >>
> >> On Wed, 2016-04-20 at 09:36 -0700, Paul Tremblay wrote:
> >>> I needed to update R so I could install ggplot. I am running Ubuntu
> >> 12.04.
> >>> I cannot upgrade Ubuntu because I am using a work computer.
> >>>
> >>> I tried upgrading the normal way:
> >>>
> >>> sudo apt-get update
> >>> sudo apt-get install r-base r-base-dev
> >>>
> >>> But this only installed an earlier version. Finally I tried installing
> >> from
> >>> source (./configure, Make install). This worked. However, when I try to
> >>> install packages, I get this error:
> >>>
> >>> Error in download.file(url, destfile = f, quiet = TRUE) :
> >>>  internet routines cannot be loaded
> >>> In addition: Warning message:
> >>> In download.file(url, destfile = f, quiet = TRUE) :
> >>>  unable to load shared object '/usr/local/lib/R/modules//internet.so':
> >>>  /usr/local/lib/R/modules//internet.so: undefined symbol:
> >> curl_multi_wait
> >>>
> >>>
> >>>>> ls /usr/local/lib/R/modules/
> >>>>> R_X11.so  R_de.so  internet.so  lapack.so
> >>>
> >>> Thanks!
> >>>
> >>> P
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Fri Apr 22 23:15:44 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 22 Apr 2016 14:15:44 -0700
Subject: [R] S4 non-virtual class with no slots?
In-Reply-To: <F1F13E14A610474196571953929C02090C0FA308@ex08.net.ucsf.edu>
References: <F1F13E14A610474196571953929C02090C0FA308@ex08.net.ucsf.edu>
Message-ID: <4AA80D33-AB7D-48A5-8996-8F6EB40484B8@dcn.davis.ca.us>

Isn't this why NULL is different than NA?

Alternatively,  what about using a data frame with no rows? 
-- 
Sent from my phone. Please excuse my brevity.

On April 22, 2016 1:38:57 PM PDT, "Boylan, Ross" <Ross.Boylan at ucsf.edu> wrote:
>It seems that if an S4 class has no slots it can't be instantiated
>because it is assumed to be virtual.  Is there a way around this other
>than adding a do-nothing slot?  A singleton would be OK, though is not
>essential.
>
>Problem:
>EmptyFitResult <- setClass("EmptyFitResult",
>representation=representation())
># also tried it without the second argument.  same result.
> > e <- EmptyFitResult()
> Error in new("EmptyFitResult", ...) :
>   trying to generate an object from a virtual class ("EmptyFitResult")
>
>This in R 3.1.1.
>
>Context:
>I fit simulated data; in some simulations none survive to the second
>stage of fitting.  So I just need a way to record that this happened,
>in a way that integrates with my other non-null results.
>
>Thanks.
>Ross Boylan
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From martin.morgan at roswellpark.org  Fri Apr 22 23:36:08 2016
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Fri, 22 Apr 2016 17:36:08 -0400
Subject: [R] S4 non-virtual class with no slots?
In-Reply-To: <F1F13E14A610474196571953929C02090C0FA308@ex08.net.ucsf.edu>
References: <F1F13E14A610474196571953929C02090C0FA308@ex08.net.ucsf.edu>
Message-ID: <571A9948.2000806@roswellpark.org>



On 04/22/2016 04:38 PM, Boylan, Ross wrote:
> It seems that if an S4 class has no slots it can't be instantiated because it is assumed to be virtual.  Is there a way around this other than adding a do-nothing slot?  A singleton would be OK, though is not essential.
>
> Problem:
> EmptyFitResult <- setClass("EmptyFitResult", representation=representation())
> # also tried it without the second argument.  same result.
>   > e <- EmptyFitResult()
>   Error in new("EmptyFitResult", ...) :
>     trying to generate an object from a virtual class ("EmptyFitResult")
>
> This in R 3.1.1.
>
> Context:
> I fit simulated data; in some simulations none survive to the second stage of fitting.  So I just need a way to record that this happened, in a way that integrates with my other non-null results.
>

A not too artificial solution is to create a base class, with derived 
classes corresponding to stateless or stateful conditions

Base = setClass("Base"); A = setClass("A", contains="Base"); A()

Martin Morgan

> Thanks.
> Ross Boylan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From drjimlemon at gmail.com  Sat Apr 23 01:42:07 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 23 Apr 2016 09:42:07 +1000
Subject: [R] npudens(np) Error missing value where TRUE/FALSE needed
In-Reply-To: <DUB124-W113046DE588B7438214923A06F0@phx.gbl>
References: <DUB124-W113046DE588B7438214923A06F0@phx.gbl>
Message-ID: <CA+8X3fXpUbov82fX=n7m7_97jZeG9Rg33y4mVf4wkU7EY0Cg2A@mail.gmail.com>

Hi Carolien,
There was a recent request involving a change in the functionality of
R that may be relevant to your problem. The usual trigger for the
"missing value where TRUE/FALSE needed" error is a conditional
expression that doesn't evaluate because of an NA value. As some
coercion or summary functions that worked in older versions of R but
have been deprecated in more recent ones, your code may be generating
NA values at some point where it did not before.

Jim


On Fri, Apr 22, 2016 at 7:15 PM, carolien lavigne
<carolienlavigne at hotmail.com> wrote:
> Hi,
>
>
>
> I am looking for some help concerning the npudens function
> in the np package.
>
> I am trying to find a kernel density function of a
> multivariate dataset and the density evaluated at each of the 176 points.
>
> I have 2 continuous and 3 ordered discrete variables. My
> sample size is 176.
>
> So edata is a 176x(2+3) data frame, while tdat is a 1x(2+3)
> vector.
>
> bw_cx[i,] is a 1x (2+3) vector representing the bandwidths h for each variable, which were calculated using the npcdensbw function. (no this is not a mistake, I deliberately use the conditional one)
>
> For this I use the below function in R.
>
>  kerz <-
> npudens(bws=(bw_cx[i,]),cykertype="epanechnikov",cxkertype="epanechnikov",oxkertype="liracine",tdat=tdata,edat=dat)
>
> In version 2.15.2, this worked fine, as I was able to
> retrieve the necessary density estimates with kerz$dens.
>
> This version was installed on a very old (read very slow and
> about to crash) computer.
>
> I recently installed version 3.2.4 on my new computer, and
> now I get the following error message when I try to execute the npudens
> function:
>
>
>
> Error in if (any(a <= 0)) warning(paste("variable
> ", which(a <= 0), " appears to be constant",  :
>
>   missing value where
> TRUE/FALSE needed
>
>
>
> I suppose some if-statement doesn?t evaluate to a TRUE or
> FALSE somewhere in the npudens function.
>
> But as I am not an expert in writing functions, this error
> message doesn?t really help.Changing it to the following also doesn't help: kerz <- npudens(bws=(bw_cx[i,]),ckertype="epanechnikov",,okertype="liracine",tdat=tdata,edat=dat)
>
>
>
> Am I doing something wrong here?
>
> Were some changes made to this function and
> do I need to alter some arguments to these changes?
>
> Or might this be a bug?
>
>
>
> Thanks!
>
>
>
> Carolien
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ross.Boylan at ucsf.edu  Sat Apr 23 02:33:15 2016
From: Ross.Boylan at ucsf.edu (Boylan, Ross)
Date: Sat, 23 Apr 2016 00:33:15 +0000
Subject: [R] S4 non-virtual class with no slots? [SOLVED]
Message-ID: <F1F13E14A610474196571953929C02090C0FA9EC@ex08.net.ucsf.edu>

Thanks, Martin, that (inherit from a virtual class) worked great.  I already had a base class created with setUnion, and so this was an easy switch.

I had assumed that since inheriting from a class without slots would produce a class without slots the result would still be virtual.  Fortunately that's not the case.

Ross
________________________________________
From: Martin Morgan [martin.morgan at roswellpark.org]
Sent: Friday, April 22, 2016 2:36 PM
To: Boylan, Ross; r-help at r-project.org
Subject: Re: [R] S4 non-virtual class with no slots?

On 04/22/2016 04:38 PM, Boylan, Ross wrote:
> It seems that if an S4 class has no slots it can't be instantiated because it is assumed to be virtual.  Is there a way around this other than adding a do-nothing slot?  A singleton would be OK, though is not essential.
>
> Problem:
> EmptyFitResult <- setClass("EmptyFitResult", representation=representation())
> # also tried it without the second argument.  same result.
>   > e <- EmptyFitResult()
>   Error in new("EmptyFitResult", ...) :
>     trying to generate an object from a virtual class ("EmptyFitResult")
>
> This in R 3.1.1.
>
> Context:
> I fit simulated data; in some simulations none survive to the second stage of fitting.  So I just need a way to record that this happened, in a way that integrates with my other non-null results.
>

A not too artificial solution is to create a base class, with derived
classes corresponding to stateless or stateful conditions

Base = setClass("Base"); A = setClass("A", contains="Base"); A()

Martin Morgan

> Thanks.
> Ross Boylan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From kehonglu at hotmail.com  Fri Apr 22 17:47:22 2016
From: kehonglu at hotmail.com (Lukehong)
Date: Fri, 22 Apr 2016 11:47:22 -0400
Subject: [R] non-numeric argument to binary operator problem in stock
	analysis
Message-ID: <SNT148-W90DC5B2613D20713516D9CD66F0@phx.gbl>

I use these codes to get the returns of my simulated portfolio
but, I can not get returns as the non-numeric argument to binary operator problem in stoc
thank you guys first.
library(quantmod)library(quadprog)library(stockPortfolio)library(fPortfolio)library(tseries)source("efficientFrontierFunction.r")
myenv <- new.env()##Calculate the mean and sd of the monthly returns of each stocksPotf <- c('IBM', 'KO', 'C', 'TSLA', 'F')getSymbols(Potf, from="2011-01-01", env=myenv)ts<-do.call(merge,eapply(myenv, Ad))
#we allocate equal weights to every stocksstocks <- c('IBM'=.20, 'KO'=.20, 'C'=.20, 'TSLA'=.20, 'F'=.20)#get Monthly Expected Return and Standard Deviationreturns <-getReturns(names(stocks),freq = "month",start = "2011-01-01")
 		 	   		  
	[[alternative HTML version deleted]]


From patzelt at g.harvard.edu  Fri Apr 22 20:08:26 2016
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Fri, 22 Apr 2016 14:08:26 -0400
Subject: [R] Unique Ordering
Message-ID: <CAB9UfhR0qn_Hb8qJkxCF_iNyxbKYM--3o-strOzoae5f1HDz+Q@mail.gmail.com>

Hi R-Help,

data at bottom

I've been struggling with a problem where I need to order based on 1) the
Frequency "Freq" and 2) keeping each group of 3 of the same type together
"Var2" but I want across all groups it to go "high to low" based on the
earn factor.

Thank you!

structure(list(Var1 = structure(c(1L, 3L, 2L, 1L, 2L, 3L, 1L,
3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 1L, 2L,
3L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L,
1L, 3L, 2L, 1L, 3L, 2L, 1L, 2L, 3L, 1L, 3L, 2L, 1L, 3L, 2L, 1L,
2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 2L,
3L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L,
1L, 3L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 1L,
3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L,
2L, 3L, 1L, 2L, 1L, 2L, 3L, 1L, 2L, 3L, 3L, 2L, 1L, 3L, 1L, 2L,
3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 3L,
1L, 2L, 1L, 3L, 2L, 1L, 2L, 3L, 1L, 3L, 2L, 3L, 1L, 2L, 3L, 1L,
2L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L,
3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L,
2L, 3L, 1L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 1L, 2L, 3L,
1L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 2L, 1L, 2L, 3L, 1L, 3L, 2L, 1L,
2L, 3L, 1L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L,
2L, 1L, 2L, 3L), .Label = c("bank", "missed", "steal"), class = "factor"),
    Var2 = structure(c(89L, 89L, 89L, 88L, 88L, 88L, 87L, 87L,
    87L, 86L, 86L, 86L, 85L, 85L, 85L, 84L, 84L, 84L, 83L, 83L,
    83L, 82L, 82L, 82L, 81L, 81L, 81L, 80L, 80L, 80L, 79L, 79L,
    79L, 78L, 78L, 78L, 77L, 77L, 77L, 76L, 76L, 76L, 75L, 75L,
    75L, 74L, 74L, 74L, 73L, 73L, 73L, 72L, 72L, 72L, 71L, 71L,
    71L, 70L, 70L, 70L, 69L, 69L, 69L, 68L, 68L, 68L, 67L, 67L,
    67L, 66L, 66L, 66L, 65L, 65L, 65L, 64L, 64L, 64L, 63L, 63L,
    63L, 62L, 62L, 62L, 61L, 61L, 61L, 60L, 60L, 60L, 59L, 59L,
    59L, 58L, 58L, 58L, 57L, 57L, 57L, 56L, 56L, 56L, 55L, 55L,
    55L, 54L, 54L, 54L, 53L, 53L, 53L, 52L, 52L, 52L, 51L, 51L,
    51L, 50L, 50L, 50L, 49L, 49L, 49L, 48L, 48L, 48L, 47L, 47L,
    47L, 46L, 46L, 46L, 45L, 45L, 45L, 44L, 44L, 44L, 43L, 43L,
    43L, 42L, 42L, 42L, 41L, 41L, 41L, 40L, 40L, 40L, 39L, 39L,
    39L, 38L, 38L, 38L, 37L, 37L, 37L, 36L, 36L, 36L, 35L, 35L,
    35L, 34L, 34L, 34L, 33L, 33L, 33L, 32L, 32L, 32L, 31L, 31L,
    31L, 30L, 30L, 30L, 29L, 29L, 29L, 28L, 28L, 28L, 27L, 27L,
    27L, 26L, 26L, 26L, 25L, 25L, 25L, 24L, 24L, 24L, 23L, 23L,
    23L, 22L, 22L, 22L, 21L, 21L, 21L, 20L, 20L, 20L, 19L, 19L,
    19L, 18L, 18L, 18L, 17L, 17L, 17L, 16L, 16L, 16L, 15L, 15L,
    15L, 14L, 14L, 14L, 13L, 13L, 13L, 12L, 12L, 12L, 11L, 11L,
    11L, 10L, 10L, 10L, 9L, 9L, 9L, 8L, 8L, 8L, 7L, 7L, 7L, 6L,
    6L, 6L, 5L, 5L, 5L, 4L, 4L, 4L, 3L, 3L, 3L, 2L, 2L, 2L, 1L,
    1L, 1L), .Label = c("PROCS001", "PROCS002", "PROCS003", "PROCS004",
    "PROCS006", "PROCS007", "PROCS008", "PROCS009", "PROCS010",
    "PROCS011", "PROCS012", "PROCS013", "PROCS014", "PROCS016",
    "PROCS017", "PROCS019", "PROCS020", "PROC009", "PROC010",
    "PROC012", "PROC013", "PROC014", "PROC015", "PROC016", "PROC017",
    "PROC018", "PROC019", "PROC020", "PROC021", "PROC024", "PROC025",
    "PROC026", "PROC028", "PROC030", "PROC032", "PROA001", "PROA002",
    "PROA003", "PROA006", "PROA007", "PROA008", "PROA009", "PROA010",
    "PROA011", "PROA012", "PROA013", "PROA014", "PROA015", "PROA016",
    "PROA018", "PROA019", "PROA020", "PROA021", "PROA022", "PRO013",
    "PRO016", "PRO017", "PRO018", "PRO019", "PRO020", "PRO021",
    "PRO022", "PRO024", "PRO027", "PRO028", "PRO029", "PRO030",
    "PRO032", "PRO033", "PRO034", "PRO035", "PRO037", "PRO038",
    "PRO039", "PRO040", "PRO041", "PRO042", "PRO044", "PRO045",
    "PRO047", "PRO048", "PRO049", "PRO050", "PRO051", "PRO052",
    "PRO053", "PRO056", "PRO057", "PRO058"), class = "factor"),
    Freq = c(71L, 9L, 0L, 80L, 0L, 0L, 63L, 17L, 0L, 80L, 0L,
    0L, 53L, 27L, 0L, 74L, 6L, 0L, 40L, 40L, 0L, 80L, 0L, 0L,
    66L, 14L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 60L, 20L, 0L, 68L,
    12L, 0L, 61L, 18L, 1L, 56L, 24L, 0L, 80L, 0L, 0L, 40L, 40L,
    0L, 46L, 34L, 0L, 80L, 0L, 0L, 57L, 23L, 0L, 77L, 2L, 1L,
    78L, 2L, 0L, 56L, 24L, 0L, 80L, 0L, 0L, 79L, 1L, 0L, 73L,
    7L, 0L, 73L, 7L, 0L, 80L, 0L, 0L, 79L, 1L, 0L, 52L, 28L,
    0L, 53L, 27L, 0L, 53L, 26L, 1L, 55L, 25L, 0L, 70L, 9L, 1L,
    66L, 14L, 0L, 50L, 30L, 0L, 46L, 34L, 0L, 80L, 0L, 0L, 71L,
    9L, 0L, 62L, 18L, 0L, 73L, 7L, 0L, 80L, 0L, 0L, 80L, 0L,
    0L, 79L, 1L, 0L, 77L, 3L, 0L, 59L, 21L, 0L, 41L, 39L, 0L,
    74L, 6L, 0L, 80L, 0L, 0L, 59L, 21L, 0L, 74L, 6L, 0L, 78L,
    2L, 0L, 80L, 0L, 0L, 74L, 6L, 0L, 80L, 0L, 0L, 80L, 0L, 0L,
    80L, 0L, 0L, 79L, 1L, 0L, 66L, 14L, 0L, 80L, 0L, 0L, 80L,
    0L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 72L, 8L, 0L,
    80L, 0L, 0L, 69L, 11L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 79L,
    1L, 0L, 80L, 0L, 0L, 64L, 16L, 0L, 75L, 0L, 0L, 67L, 8L,
    0L, 68L, 7L, 0L, 73L, 2L, 0L, 75L, 0L, 0L, 75L, 0L, 0L, 75L,
    0L, 0L, 44L, 30L, 1L, 75L, 0L, 0L, 42L, 33L, 0L, 75L, 0L,
    0L, 42L, 33L, 0L, 45L, 30L, 0L, 67L, 8L, 0L, 51L, 24L, 0L,
    58L, 17L, 0L, 75L, 0L, 0L)), .Names = c("Var1", "Var2", "Freq"
), row.names = c(265L, 267L, 266L, 262L, 263L, 264L, 259L, 261L,
260L, 258L, 256L, 257L, 255L, 253L, 254L, 250L, 252L, 251L, 247L,
249L, 248L, 244L, 245L, 246L, 243L, 241L, 242L, 240L, 238L, 239L,
235L, 236L, 237L, 234L, 232L, 233L, 231L, 229L, 230L, 226L, 228L,
227L, 223L, 225L, 224L, 220L, 221L, 222L, 217L, 219L, 218L, 214L,
216L, 215L, 211L, 212L, 213L, 210L, 208L, 209L, 207L, 205L, 206L,
202L, 204L, 203L, 201L, 199L, 200L, 196L, 197L, 198L, 195L, 193L,
194L, 190L, 192L, 191L, 189L, 187L, 188L, 184L, 185L, 186L, 183L,
181L, 182L, 178L, 180L, 179L, 175L, 177L, 176L, 172L, 174L, 173L,
171L, 169L, 170L, 166L, 168L, 167L, 163L, 165L, 164L, 162L, 160L,
161L, 159L, 157L, 158L, 156L, 154L, 155L, 153L, 151L, 152L, 148L,
150L, 149L, 147L, 145L, 146L, 142L, 143L, 144L, 139L, 140L, 141L,
138L, 137L, 136L, 135L, 133L, 134L, 132L, 130L, 131L, 127L, 129L,
128L, 126L, 124L, 125L, 121L, 122L, 123L, 120L, 118L, 119L, 117L,
115L, 116L, 112L, 114L, 113L, 109L, 110L, 111L, 106L, 108L, 107L,
105L, 103L, 104L, 102L, 100L, 101L, 99L, 97L, 98L, 94L, 96L,
95L, 93L, 91L, 92L, 90L, 88L, 89L, 85L, 86L, 87L, 84L, 82L, 83L,
81L, 79L, 80L, 76L, 77L, 78L, 75L, 73L, 74L, 72L, 70L, 71L, 69L,
67L, 68L, 66L, 64L, 65L, 61L, 62L, 63L, 60L, 58L, 59L, 55L, 56L,
57L, 54L, 52L, 53L, 51L, 49L, 50L, 46L, 48L, 47L, 43L, 45L, 44L,
40L, 42L, 41L, 37L, 38L, 39L, 34L, 35L, 36L, 31L, 32L, 33L, 28L,
30L, 29L, 25L, 26L, 27L, 22L, 24L, 23L, 19L, 20L, 21L, 16L, 18L,
17L, 15L, 13L, 14L, 12L, 10L, 11L, 7L, 9L, 8L, 6L, 4L, 5L, 1L,
2L, 3L), class = "data.frame")



-- 
Edward H Patzelt | Clinical Science PhD Student
Psychology | Harvard University
Systems Neuroscience of Psychopathology Laboratory

	[[alternative HTML version deleted]]


From G.Maubach at gmx.de  Fri Apr 22 17:52:01 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Fri, 22 Apr 2016 17:52:01 +0200
Subject: [R] Creating variables on the fly
Message-ID: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>

Hi all,

I would like to use a loop for tasks that occurs repeatedly:

# Groups 
# Umsatz <= 0: 1 (NICHT kaufend) 
# Umsatz > 0: 2  (kaufend) 
for (year in c("2011", "2012", "2013", "2014", "2015")) { 
  paste0("Kunden$Kunde_real_", year) <- (paste0("Kunden$Umsatz_", year) <= 0) * 1 + 
                                        (paste0("Kunden$Umsatz_", year) >  0) * 2 
  paste0("Kunden$Kunde_real_", year) <- factor(paste0("Kunden$Umsatz_", year), 
                                               levels = c(1, 2), 
                                               labels = c("NICHT kaufend", "kaufend")) 
  } 

This actually does not work due to the fact that the expression "paste0("Kunden$Kunde_real_", year)" ist not interpreted as a variable name by the R script language interpreter.

Is there a way to assembly variable names on the fly in R?

Regards

Georg


From hd625b at gmail.com  Sat Apr 23 01:12:43 2016
From: hd625b at gmail.com (Michael Long)
Date: Fri, 22 Apr 2016 16:12:43 -0700
Subject: [R] Number of package in Ubuntu
In-Reply-To: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
References: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
Message-ID: <571AAFEB.1000805@gmail.com>

I have been using Ubuntu and R Studio for about 5 years and have not had 
any problems finding and installing packages. I believe there are 
packages that only work in Windows but I don't what they are.

Michael Long

On 04/22/2016 11:51 AM, mylisttech at gmail.com wrote:
> Dear Experts ,
>
> I am using R with Spark on Windows and now there is a need to move to Ubuntu. I wanted to know if most of the packages that are available on windows , would they be available on Ubuntu/Linux? If not can I compile the source code of those package ? Has any one of you used the packages on Ubuntu ?
>
> Thanks in Advance.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael Long


From hd625b at gmail.com  Sat Apr 23 01:21:44 2016
From: hd625b at gmail.com (Michael Long)
Date: Fri, 22 Apr 2016 16:21:44 -0700
Subject: [R] Problem installing/loading packages from Africa
In-Reply-To: <CAH+j5oYNRDBA3vP4pEFFS1tEdZKD-XBssfs7QDsCp4ZH2mr8AA@mail.gmail.com>
References: <CAH+j5oYNRDBA3vP4pEFFS1tEdZKD-XBssfs7QDsCp4ZH2mr8AA@mail.gmail.com>
Message-ID: <571AB208.50508@gmail.com>

Try upgrading R to version 3.2.5 and then try to reinstall swirl.

Michael Long

On 04/22/2016 03:41 AM, Tim Werwie wrote:
> I'm very new to R and I live in Mali, west Africa. I'm on *OS X 10.7.5*. I
> downloaded and installed *R 3.2.1*. I downloaded and installed *RStudio
> 00.99.893*.
>
> I ran through the free Microsoft data camp intro to R course, then started
> another free course through 'edX', for Data and Statistics for Life
> Sciences, using R. The first prompt in the course is to
> install.packages("swirl"). Copied below are the various error messages I
> get when trying to install or load any package.
>
> My best guess is that the problems I'm having are due to being in west
> Africa, with unreliable connections, weak connections and no CRAN Mirror
> closer than Italy or Spain (as far as I know). I checked into common
> package errors on the RStudio page, but I'm not confident enough in my
> computing to get into internet proxies and some of the other suggested
> troubleshooting.
>
> Any insight would be very helpful. See error messages below. Thanks -- Tim
>
> - When attempting to install, the print-out I get in the Console in RStudio
> is any length of: > install.packages("swirl")
>    % Total    % Received % Xferd  Average Speed   Time    Time     Time
> Current
>                                   Dload  Upload   Total   Spent    Left
> Speed
>    0     0    0     0    0     0      0      0 --:--:--  0:00:10
> --:--:--     0  0     0    0     0    0     0      0      0 --:--:--
> 0:00:10 --:--:--     0  0     0    0     0    0     0      0      0
> --:--:--  0:00:11 --:--:--     0 22  207k   22 48384    0     0   3833
> 0  0:00:55  0:00:12  0:00:43 19740 30  207k   30 64823    0     0
> 4808      0  0:00:44  0:00:13  0:00:31 19578 38  207k   38 81207    0
> 0   5638      0  0:00:37  0:00:14  0:00:23 19193 46  207k   46 97591
> 0     0   6299      0  0:00:33  0:00:15  0:00:18 20076 53  207k   53
> 111k    0     0   6966      0  0:00:30  0:00:16  0:00:14 22717 69  207k
> 69  143k    0     0   8423      0  0:00:25  0:00:17  0:00:08 20487 76
> 207k   76  159k    0     0   8821      0  0:00:24  0:00:18  0:00:06 19621
> 92  207k   92  191k    0     0  10085      0  0:00:21  0:00:19  0:00:02
> 22841100  207k  100  207k    0     0  10363      0  0:00:20  0:00:20
> --:--:-- 230100  207k  100  207k    0     0  10363      0  0:00:20  0:00:20
> --:--:-- 23922
> The downloaded binary packages are in
>
> /var/folders/yb/7z339kn56mdbwx92ydmsqswc0000gn/T//RtmpBzQ16u/downloaded_packages
>
> For other packages, ggplot2, forexample, a similar printout can run for
> hundreds and hundred of lines. So RStudio tells me that the packages are
> available to load, BUT:
>
> - when *loading* any package an error comes up saying package 'name of
> package' was built under R version 3.2.5 but info on swirl says it should
> work on any version of R above 3.0.2. I get similar errors for other
> packages (treemap, ggplot2, etc).
>
> - Or sometimes I"ll get this: Error : .onAttach failed in attachNamespace()
> for 'swirl', details: call: stri_c(..., sep = sep, collapse = collapse,
> ignore_null = TRUE)
> error: object 'C_stri_join' not found
> In addition: Warning message:
> package ?swirl? was built under R version 3.2.5
> Error: package or namespace load failed for ?swirl?
>
> Any suggestions?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael Long


From sarah.goslee at gmail.com  Sat Apr 23 08:10:37 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 23 Apr 2016 02:10:37 -0400
Subject: [R] Creating variables on the fly
In-Reply-To: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>
References: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>
Message-ID: <CAM_vjumUgGLpR_LVE+DEK+XgyXPqQ-08zcE_FSS4A+i7S_JmtA@mail.gmail.com>

The direct answer to your question is to look at ?get and ? assign.

The R-ish answer to your question is to store the data as elements of a
list rather than separate files and use lapply() instead.

Sarah

On Friday, April 22, 2016, <G.Maubach at gmx.de> wrote:

> Hi all,
>
> I would like to use a loop for tasks that occurs repeatedly:
>
> # Groups
> # Umsatz <= 0: 1 (NICHT kaufend)
> # Umsatz > 0: 2  (kaufend)
> for (year in c("2011", "2012", "2013", "2014", "2015")) {
>   paste0("Kunden$Kunde_real_", year) <- (paste0("Kunden$Umsatz_", year) <=
> 0) * 1 +
>                                         (paste0("Kunden$Umsatz_", year) >
> 0) * 2
>   paste0("Kunden$Kunde_real_", year) <- factor(paste0("Kunden$Umsatz_",
> year),
>                                                levels = c(1, 2),
>                                                labels = c("NICHT kaufend",
> "kaufend"))
>   }
>
> This actually does not work due to the fact that the expression
> "paste0("Kunden$Kunde_real_", year)" ist not interpreted as a variable name
> by the R script language interpreter.
>
> Is there a way to assembly variable names on the fly in R?
>
> Regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Sat Apr 23 08:19:11 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 23 Apr 2016 06:19:11 +0000
Subject: [R] Creating variables on the fly
In-Reply-To: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>
References: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>
Message-ID: <CAKVAULMHx62Jw7hgM1-pdRGY54UdxBK_X1tsKKxse=cSmhSjtg@mail.gmail.com>

Hi Georg,

The " around Kunden$* looks unintentional to me.

Second: haveyou considered using a long table? Then you would fill a known
set of columns.

Third if you must have columns based on year I believe df[[a.column.name]]
will work.

Best


Ulrik

<G.Maubach at gmx.de> schrieb am Sa., 23. Apr. 2016 07:33:

> Hi all,
>
> I would like to use a loop for tasks that occurs repeatedly:
>
> # Groups
> # Umsatz <= 0: 1 (NICHT kaufend)
> # Umsatz > 0: 2  (kaufend)
> for (year in c("2011", "2012", "2013", "2014", "2015")) {
>   paste0("Kunden$Kunde_real_", year) <- (paste0("Kunden$Umsatz_", year) <=
> 0) * 1 +
>                                         (paste0("Kunden$Umsatz_", year) >
> 0) * 2
>   paste0("Kunden$Kunde_real_", year) <- factor(paste0("Kunden$Umsatz_",
> year),
>                                                levels = c(1, 2),
>                                                labels = c("NICHT kaufend",
> "kaufend"))
>   }
>
> This actually does not work due to the fact that the expression
> "paste0("Kunden$Kunde_real_", year)" ist not interpreted as a variable name
> by the R script language interpreter.
>
> Is there a way to assembly variable names on the fly in R?
>
> Regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Apr 23 08:21:26 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 23 Apr 2016 16:21:26 +1000
Subject: [R] Unique Ordering
In-Reply-To: <CAB9UfhR0qn_Hb8qJkxCF_iNyxbKYM--3o-strOzoae5f1HDz+Q@mail.gmail.com>
References: <CAB9UfhR0qn_Hb8qJkxCF_iNyxbKYM--3o-strOzoae5f1HDz+Q@mail.gmail.com>
Message-ID: <CA+8X3fVbyVTGJTg5UXnL0oute9DyDkJLeE=Vy8rkumQyX3LqtA@mail.gmail.com>

Hi Edward,
I'm not really sure that this is what you want as I can't figure out
what the "earn" factor is, but:

epdat[order(epdat$Var2,epdat$Freq,decreasing=TRUE),]

Jim


On Sat, Apr 23, 2016 at 4:08 AM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:
> Hi R-Help,
>
> data at bottom
>
> I've been struggling with a problem where I need to order based on 1) the
> Frequency "Freq" and 2) keeping each group of 3 of the same type together
> "Var2" but I want across all groups it to go "high to low" based on the
> earn factor.
>
> Thank you!
>
> structure(list(Var1 = structure(c(1L, 3L, 2L, 1L, 2L, 3L, 1L,
> 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 1L, 2L,
> 3L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L,
> 1L, 3L, 2L, 1L, 3L, 2L, 1L, 2L, 3L, 1L, 3L, 2L, 1L, 3L, 2L, 1L,
> 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 2L,
> 3L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L,
> 1L, 3L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 1L,
> 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L,
> 2L, 3L, 1L, 2L, 1L, 2L, 3L, 1L, 2L, 3L, 3L, 2L, 1L, 3L, 1L, 2L,
> 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 3L,
> 1L, 2L, 1L, 3L, 2L, 1L, 2L, 3L, 1L, 3L, 2L, 3L, 1L, 2L, 3L, 1L,
> 2L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L,
> 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
> 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 1L, 2L, 3L, 3L, 1L,
> 2L, 3L, 1L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 1L, 3L, 2L, 1L, 2L, 3L,
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 2L, 1L, 2L, 3L, 1L, 3L, 2L, 1L,
> 2L, 3L, 1L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 3L, 2L, 3L, 1L,
> 2L, 1L, 2L, 3L), .Label = c("bank", "missed", "steal"), class = "factor"),
>     Var2 = structure(c(89L, 89L, 89L, 88L, 88L, 88L, 87L, 87L,
>     87L, 86L, 86L, 86L, 85L, 85L, 85L, 84L, 84L, 84L, 83L, 83L,
>     83L, 82L, 82L, 82L, 81L, 81L, 81L, 80L, 80L, 80L, 79L, 79L,
>     79L, 78L, 78L, 78L, 77L, 77L, 77L, 76L, 76L, 76L, 75L, 75L,
>     75L, 74L, 74L, 74L, 73L, 73L, 73L, 72L, 72L, 72L, 71L, 71L,
>     71L, 70L, 70L, 70L, 69L, 69L, 69L, 68L, 68L, 68L, 67L, 67L,
>     67L, 66L, 66L, 66L, 65L, 65L, 65L, 64L, 64L, 64L, 63L, 63L,
>     63L, 62L, 62L, 62L, 61L, 61L, 61L, 60L, 60L, 60L, 59L, 59L,
>     59L, 58L, 58L, 58L, 57L, 57L, 57L, 56L, 56L, 56L, 55L, 55L,
>     55L, 54L, 54L, 54L, 53L, 53L, 53L, 52L, 52L, 52L, 51L, 51L,
>     51L, 50L, 50L, 50L, 49L, 49L, 49L, 48L, 48L, 48L, 47L, 47L,
>     47L, 46L, 46L, 46L, 45L, 45L, 45L, 44L, 44L, 44L, 43L, 43L,
>     43L, 42L, 42L, 42L, 41L, 41L, 41L, 40L, 40L, 40L, 39L, 39L,
>     39L, 38L, 38L, 38L, 37L, 37L, 37L, 36L, 36L, 36L, 35L, 35L,
>     35L, 34L, 34L, 34L, 33L, 33L, 33L, 32L, 32L, 32L, 31L, 31L,
>     31L, 30L, 30L, 30L, 29L, 29L, 29L, 28L, 28L, 28L, 27L, 27L,
>     27L, 26L, 26L, 26L, 25L, 25L, 25L, 24L, 24L, 24L, 23L, 23L,
>     23L, 22L, 22L, 22L, 21L, 21L, 21L, 20L, 20L, 20L, 19L, 19L,
>     19L, 18L, 18L, 18L, 17L, 17L, 17L, 16L, 16L, 16L, 15L, 15L,
>     15L, 14L, 14L, 14L, 13L, 13L, 13L, 12L, 12L, 12L, 11L, 11L,
>     11L, 10L, 10L, 10L, 9L, 9L, 9L, 8L, 8L, 8L, 7L, 7L, 7L, 6L,
>     6L, 6L, 5L, 5L, 5L, 4L, 4L, 4L, 3L, 3L, 3L, 2L, 2L, 2L, 1L,
>     1L, 1L), .Label = c("PROCS001", "PROCS002", "PROCS003", "PROCS004",
>     "PROCS006", "PROCS007", "PROCS008", "PROCS009", "PROCS010",
>     "PROCS011", "PROCS012", "PROCS013", "PROCS014", "PROCS016",
>     "PROCS017", "PROCS019", "PROCS020", "PROC009", "PROC010",
>     "PROC012", "PROC013", "PROC014", "PROC015", "PROC016", "PROC017",
>     "PROC018", "PROC019", "PROC020", "PROC021", "PROC024", "PROC025",
>     "PROC026", "PROC028", "PROC030", "PROC032", "PROA001", "PROA002",
>     "PROA003", "PROA006", "PROA007", "PROA008", "PROA009", "PROA010",
>     "PROA011", "PROA012", "PROA013", "PROA014", "PROA015", "PROA016",
>     "PROA018", "PROA019", "PROA020", "PROA021", "PROA022", "PRO013",
>     "PRO016", "PRO017", "PRO018", "PRO019", "PRO020", "PRO021",
>     "PRO022", "PRO024", "PRO027", "PRO028", "PRO029", "PRO030",
>     "PRO032", "PRO033", "PRO034", "PRO035", "PRO037", "PRO038",
>     "PRO039", "PRO040", "PRO041", "PRO042", "PRO044", "PRO045",
>     "PRO047", "PRO048", "PRO049", "PRO050", "PRO051", "PRO052",
>     "PRO053", "PRO056", "PRO057", "PRO058"), class = "factor"),
>     Freq = c(71L, 9L, 0L, 80L, 0L, 0L, 63L, 17L, 0L, 80L, 0L,
>     0L, 53L, 27L, 0L, 74L, 6L, 0L, 40L, 40L, 0L, 80L, 0L, 0L,
>     66L, 14L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 60L, 20L, 0L, 68L,
>     12L, 0L, 61L, 18L, 1L, 56L, 24L, 0L, 80L, 0L, 0L, 40L, 40L,
>     0L, 46L, 34L, 0L, 80L, 0L, 0L, 57L, 23L, 0L, 77L, 2L, 1L,
>     78L, 2L, 0L, 56L, 24L, 0L, 80L, 0L, 0L, 79L, 1L, 0L, 73L,
>     7L, 0L, 73L, 7L, 0L, 80L, 0L, 0L, 79L, 1L, 0L, 52L, 28L,
>     0L, 53L, 27L, 0L, 53L, 26L, 1L, 55L, 25L, 0L, 70L, 9L, 1L,
>     66L, 14L, 0L, 50L, 30L, 0L, 46L, 34L, 0L, 80L, 0L, 0L, 71L,
>     9L, 0L, 62L, 18L, 0L, 73L, 7L, 0L, 80L, 0L, 0L, 80L, 0L,
>     0L, 79L, 1L, 0L, 77L, 3L, 0L, 59L, 21L, 0L, 41L, 39L, 0L,
>     74L, 6L, 0L, 80L, 0L, 0L, 59L, 21L, 0L, 74L, 6L, 0L, 78L,
>     2L, 0L, 80L, 0L, 0L, 74L, 6L, 0L, 80L, 0L, 0L, 80L, 0L, 0L,
>     80L, 0L, 0L, 79L, 1L, 0L, 66L, 14L, 0L, 80L, 0L, 0L, 80L,
>     0L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 72L, 8L, 0L,
>     80L, 0L, 0L, 69L, 11L, 0L, 80L, 0L, 0L, 80L, 0L, 0L, 79L,
>     1L, 0L, 80L, 0L, 0L, 64L, 16L, 0L, 75L, 0L, 0L, 67L, 8L,
>     0L, 68L, 7L, 0L, 73L, 2L, 0L, 75L, 0L, 0L, 75L, 0L, 0L, 75L,
>     0L, 0L, 44L, 30L, 1L, 75L, 0L, 0L, 42L, 33L, 0L, 75L, 0L,
>     0L, 42L, 33L, 0L, 45L, 30L, 0L, 67L, 8L, 0L, 51L, 24L, 0L,
>     58L, 17L, 0L, 75L, 0L, 0L)), .Names = c("Var1", "Var2", "Freq"
> ), row.names = c(265L, 267L, 266L, 262L, 263L, 264L, 259L, 261L,
> 260L, 258L, 256L, 257L, 255L, 253L, 254L, 250L, 252L, 251L, 247L,
> 249L, 248L, 244L, 245L, 246L, 243L, 241L, 242L, 240L, 238L, 239L,
> 235L, 236L, 237L, 234L, 232L, 233L, 231L, 229L, 230L, 226L, 228L,
> 227L, 223L, 225L, 224L, 220L, 221L, 222L, 217L, 219L, 218L, 214L,
> 216L, 215L, 211L, 212L, 213L, 210L, 208L, 209L, 207L, 205L, 206L,
> 202L, 204L, 203L, 201L, 199L, 200L, 196L, 197L, 198L, 195L, 193L,
> 194L, 190L, 192L, 191L, 189L, 187L, 188L, 184L, 185L, 186L, 183L,
> 181L, 182L, 178L, 180L, 179L, 175L, 177L, 176L, 172L, 174L, 173L,
> 171L, 169L, 170L, 166L, 168L, 167L, 163L, 165L, 164L, 162L, 160L,
> 161L, 159L, 157L, 158L, 156L, 154L, 155L, 153L, 151L, 152L, 148L,
> 150L, 149L, 147L, 145L, 146L, 142L, 143L, 144L, 139L, 140L, 141L,
> 138L, 137L, 136L, 135L, 133L, 134L, 132L, 130L, 131L, 127L, 129L,
> 128L, 126L, 124L, 125L, 121L, 122L, 123L, 120L, 118L, 119L, 117L,
> 115L, 116L, 112L, 114L, 113L, 109L, 110L, 111L, 106L, 108L, 107L,
> 105L, 103L, 104L, 102L, 100L, 101L, 99L, 97L, 98L, 94L, 96L,
> 95L, 93L, 91L, 92L, 90L, 88L, 89L, 85L, 86L, 87L, 84L, 82L, 83L,
> 81L, 79L, 80L, 76L, 77L, 78L, 75L, 73L, 74L, 72L, 70L, 71L, 69L,
> 67L, 68L, 66L, 64L, 65L, 61L, 62L, 63L, 60L, 58L, 59L, 55L, 56L,
> 57L, 54L, 52L, 53L, 51L, 49L, 50L, 46L, 48L, 47L, 43L, 45L, 44L,
> 40L, 42L, 41L, 37L, 38L, 39L, 34L, 35L, 36L, 31L, 32L, 33L, 28L,
> 30L, 29L, 25L, 26L, 27L, 22L, 24L, 23L, 19L, 20L, 21L, 16L, 18L,
> 17L, 15L, 13L, 14L, 12L, 10L, 11L, 7L, 9L, 8L, 6L, 4L, 5L, 1L,
> 2L, 3L), class = "data.frame")
>
>
>
> --
> Edward H Patzelt | Clinical Science PhD Student
> Psychology | Harvard University
> Systems Neuroscience of Psychopathology Laboratory
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Apr 23 15:56:18 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 23 Apr 2016 06:56:18 -0700
Subject: [R] Number of package in Ubuntu
In-Reply-To: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
References: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
Message-ID: <21756501-903B-433C-93DA-6CFAF7A70C2A@comcast.net>


> On Apr 22, 2016, at 11:51 AM, mylisttech at gmail.com wrote:
> 
> Dear Experts ,
> 
> I am using R with Spark on Windows and now there is a need to move to Ubuntu. I wanted to know if most of the packages that are available on windows , would they be available on Ubuntu/Linux? If not can I compile the source code of those package ? Has any one of you used the packages on Ubuntu ?  

You can get the status of efforts to compile packages on the various machine avaialbe to CRAN at the CRAN package checks page:

https://cran.r-project.org/web/checks/check_summary.html

-- 

David Winsemius
Alameda, CA, USA


From acm538 at york.ac.uk  Sat Apr 23 13:37:59 2016
From: acm538 at york.ac.uk (Adrian Mcmenamin)
Date: Sat, 23 Apr 2016 12:37:59 +0100
Subject: [R] Plotting a large time series
Message-ID: <CAATR6d8osHGCts8c=UVQxFGfQd-yeYxsCOd7RE+Tgs0RzM1MAQ@mail.gmail.com>

I have a time series with many millions of points.

Each point is of the form (time, value) but where the value is 0 there is
no record - ie the data set is sparse.

If I plot this using plot(myData) I get a correct plot going from time 0 to
time 7x10e7.

Given that there are many millions of points (it's not *that* sparse), this
looks very busy.

But if I attempt to plot this as a line - plot(myData, type="l") - the plot
is wrong (it looks like solid semi-sinusoidal curves) and although the
x-axis is drawn from 0 to 7x10e7, the plotting stops at about 3x10e7.

The same thing is seen if I use plot(myData[[1]], myData[[2]], type="l").

If I use plot(myData[[2]], myData[[1]], type="l") I do get a line (albeit
that the orientation seems odd), but again, while the y-axis is drawn
between 0 and 7x10e7, the plotting again seems to stop at 3x10e7 or
thereabouts.

What have I got wrong? How can I get a line (preferably with the standard
orientation)?

Adrian

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Apr 23 16:43:33 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 23 Apr 2016 07:43:33 -0700
Subject: [R] CRAN package check results tabulated ... wasRe: Number of
	package in Ubuntu
In-Reply-To: <21756501-903B-433C-93DA-6CFAF7A70C2A@comcast.net>
References: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
	<21756501-903B-433C-93DA-6CFAF7A70C2A@comcast.net>
Message-ID: <9F92D1AE-ECAC-45A8-B42F-326BACE0DBAD@comcast.net>


> On Apr 23, 2016, at 6:56 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Apr 22, 2016, at 11:51 AM, mylisttech at gmail.com wrote:
>> 
>> Dear Experts ,
>> 
>> I am using R with Spark on Windows and now there is a need to move to Ubuntu. I wanted to know if most of the packages that are available on windows , would they be available on Ubuntu/Linux? If not can I compile the source code of those package ? Has any one of you used the packages on Ubuntu ?  
> 
> You can get the status of efforts to compile packages on the various machine avaialbe to CRAN at the CRAN package checks page:
> 
> https://cran.r-project.org/web/checks/check_summary.html
> 

After scraping that page with rvest::read_html I then used `table` to summarize. I posted the full output at the end of this but here are the relevant rows for Debian (for the Ubuntu option) and the Windows platforms tested:

> res_tbl
$`r-develLinuxx86_64(Debian GCC)`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  261    59  4150    28  3994    35    25 

$`r-develWindowsix86+x86_64`

        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN 
   295    124      1   3962     25   4064     36     45 

$`r-patchedLinuxx86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  259    54  4153    28  3998    35    25 

$`r-releaseLinuxx86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  268    54  2578    18  5569    45    20 

$`r-releaseWindowsix86+x86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  324    70  2187    16  5885    46    24 

$`r-oldrelWindowsix86+x86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN WARN* 
  532   159  1605    13  6028    45   168     2 

I think the various "NOTE" and "WARN" categories in most cases should be interpreted as "probably OK". It's those initial <blank>'s and ERROR categories that would most likely be the ones affecting users. 

-- 

David Winsemius
Alameda, CA, USA

--------- full tables--------
Tabulate on just the first letter of hte result:

> t(res_tbl2)
                                 blank   E    N    O   W
r-develLinuxx86_64(Debian GCC)     261  59 4178 4029  25
r-develLinuxx86_64(Fedora Clang)   265  66 4191 4001  29
r-develLinuxx86_64(Fedora GCC)     265  60 4204 3991  32
r-develOS Xx86_64(Clang)           294  70 4075 4081  32
r-develWindowsix86+x86_64          295 125 3987 4100  45
r-patchedLinuxx86_64               259  54 4181 4033  25
r-patchedSolarissparc              364 131 4082 3909  66
r-patchedSolarisx86                343 106 4091 3965  47
r-releaseLinuxx86_64               268  54 2596 5614  20
r-releaseOS Xx86_64(Mavericks)     255 174 2337 5718  68
r-releaseWindowsix86+x86_64        324  70 2203 5931  24
r-oldrelWindowsix86+x86_64         532 159 1618 6073 170

Tablulate on full message:
> res_tbl
$`r-develLinuxx86_64(Debian GCC)`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  261    59  4150    28  3994    35    25 

$`r-develLinuxx86_64(Fedora Clang)`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  265    66  4179    12  3982    19    29 

$`r-develLinuxx86_64(Fedora GCC)`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  265    60  4191    13  3972    19    32 

$`r-develOS Xx86_64(Clang)`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  294    70  4066     9  4068    13    32 

$`r-develWindowsix86+x86_64`

        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN 
   295    124      1   3962     25   4064     36     45 

$`r-patchedLinuxx86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  259    54  4153    28  3998    35    25 

$`r-patchedSolarissparc`

        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN  WARN* 
   364    129      2   4006     76   3839     70     65      1 

$`r-patchedSolarisx86`

        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN 
   343    105      1   4062     29   3945     20     47 

$`r-releaseLinuxx86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  268    54  2578    18  5569    45    20 

$`r-releaseOS Xx86_64(Mavericks)`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  255   174  2335     2  5716     2    68 

$`r-releaseWindowsix86+x86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN 
  324    70  2187    16  5885    46    24 

$`r-oldrelWindowsix86+x86_64`

      ERROR  NOTE NOTE*    OK   OK*  WARN WARN* 
  532   159  1605    13  6028    45   168     2 


From chalabi.elahe at yahoo.de  Sat Apr 23 18:09:21 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sat, 23 Apr 2016 16:09:21 +0000 (UTC)
Subject: [R] subset by multiple letters condition
In-Reply-To: <CAN5YmCFcJX9yChY-yfr8J-1zvW+YBwpF-iAgDM_CM9uWdrE6pg@mail.gmail.com>
References: <CAN5YmCFcJX9yChY-yfr8J-1zvW+YBwpF-iAgDM_CM9uWdrE6pg@mail.gmail.com>
Message-ID: <1357259211.1312517.1461427761806.JavaMail.yahoo@mail.yahoo.com>

Thanks Jean, Does anyone know how to set these [hast1] and [hast2] as the colors of a plot?  


On Friday, April 22, 2016 7:39 AM, "Adams, Jean" <jvadams at usgs.gov> wrote:



You can use the grepl() function to give you logicals for each criterion, then combine them as needed.  For example:

# example version of Command
Command <- paste0("_localize_", c("PD","t2","t1_seq", "abc", "xyz", "PD_t1"))

hasPD <- grepl("PD", Command, fixed=TRUE)
hast1 <- grepl("t1", Command, fixed=TRUE)
hast2 <- grepl("t2", Command, fixed=TRUE)

> Command[hast1]
[1] "_localize_t1_seq" "_localize_PD_t1" 

> Command[hasPD]
[1] "_localize_PD"    "_localize_PD_t1"

> Command[hast1 & hasPD]
[1] "_localize_PD_t1"

Jean


On Fri, Apr 22, 2016 at 8:42 AM, ch.elahe via R-help <r-help at r-project.org> wrote:


>Hi all,
>
>I have a data frame df and I want to do subset based on several conditions of letters of the names in Command.1)if the names contain PD 2)if the names contain t1 3)if the names contain t2 4)if the names contain t1 and PD 5)if the names contain t2 and PD 6)otherwise the names would be unknown. I don't know how to use grep for all these conditions.
>
>   'data.frame': 36919 obs. of 162 variables
>   $TE                :int 38,41,11,52,48,75,.....
>   $Command           :factor W/2229 levels "_localize_PD","_localize_tre_t2","_localize_t1_seq",...
>
>
>Thanks for any help
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From jvadams at usgs.gov  Sat Apr 23 20:07:27 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Sat, 23 Apr 2016 13:07:27 -0500
Subject: [R] subset by multiple letters condition
In-Reply-To: <1357259211.1312517.1461427761806.JavaMail.yahoo@mail.yahoo.com>
References: <CAN5YmCFcJX9yChY-yfr8J-1zvW+YBwpF-iAgDM_CM9uWdrE6pg@mail.gmail.com>
	<1357259211.1312517.1461427761806.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAN5YmCHRODBhZ3trNoJjbdoMPPf5Q66yVY-bZSdpnqQFRvWhaw@mail.gmail.com>

This is quite a different question.  I suggest you start a new post with a
new subject line for this.  And I suggest you include code for an example
plot that you want to use.

Otherwise, you might look here for some ideas on how to control colors in a
scatter plot using base r, http://stackoverflow.com/a/8475315

Jean

On Sat, Apr 23, 2016 at 11:09 AM, <chalabi.elahe at yahoo.de> wrote:

> Thanks Jean, Does anyone know how to set these [hast1] and [hast2] as the
> colors of a plot?
>
>
> On Friday, April 22, 2016 7:39 AM, "Adams, Jean" <jvadams at usgs.gov> wrote:
>
>
>
> You can use the grepl() function to give you logicals for each criterion,
> then combine them as needed.  For example:
>
> # example version of Command
> Command <- paste0("_localize_", c("PD","t2","t1_seq", "abc", "xyz",
> "PD_t1"))
>
> hasPD <- grepl("PD", Command, fixed=TRUE)
> hast1 <- grepl("t1", Command, fixed=TRUE)
> hast2 <- grepl("t2", Command, fixed=TRUE)
>
> > Command[hast1]
> [1] "_localize_t1_seq" "_localize_PD_t1"
>
> > Command[hasPD]
> [1] "_localize_PD"    "_localize_PD_t1"
>
> > Command[hast1 & hasPD]
> [1] "_localize_PD_t1"
>
> Jean
>
>
> On Fri, Apr 22, 2016 at 8:42 AM, ch.elahe via R-help <r-help at r-project.org>
> wrote:
>
>
> >Hi all,
> >
> >I have a data frame df and I want to do subset based on several
> conditions of letters of the names in Command.1)if the names contain PD
> 2)if the names contain t1 3)if the names contain t2 4)if the names contain
> t1 and PD 5)if the names contain t2 and PD 6)otherwise the names would be
> unknown. I don't know how to use grep for all these conditions.
> >
> >   'data.frame': 36919 obs. of 162 variables
> >   $TE                :int 38,41,11,52,48,75,.....
> >   $Command           :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_localize_t1_seq",...
> >
> >
> >Thanks for any help
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Sat Apr 23 21:43:14 2016
From: miaojpm at gmail.com (jpm miao)
Date: Sat, 23 Apr 2016 12:43:14 -0700
Subject: [R] Java memory error when reading a small xlsx file
Message-ID: <CABcx46DQvJPq7iQ5uj005yw0vb-n1Argn-mUFb1NTpWxv8TsRg@mail.gmail.com>

Hi,

   I tried to read a (small) xlsx file by "readWorksheetFromFile" function
of "XLConnect" package and "read.xlsx" function in "xlsx" package, but I
got this error message:

Error: OutOfMemoryError (Java): Java heap space

   I tried to follow the solution on the web
http://stackoverflow.com/questions/21937640/handling-java-lang-outofmemoryerror-when-writing-to-excel-from-r

   and I did add a line to my program
#######
options(java.parameters = "-Xmx8000m")
########
#or
########
options(java.parameters = "-Xmx1000m")
#######
   but it did not work.

   I wonder if I need to detach the packages before adding that line
########
detach("package:XLConnect", unload=TRUE)
detach("package:xlsx", unload=TRUE)
detach("package:xlsxjars", unload=TRUE)
detach("package:XLConnectJars", unload=TRUE)
detach("package:rJava", unload=TRUE)
options(java.parameters = "-Xmx8000m")
library(XLConnect)
library(xlsx)
#######
    but it did not work.

I am on a Mac, with very new OS and very new R version.

R version 3.2.4 (2016-03-10)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.3 (El Capitan)

    Could someone guide me how to solve the problem? Thanks!

Miao

	[[alternative HTML version deleted]]


From piburnjo at ornl.gov  Fri Apr 22 16:37:28 2016
From: piburnjo at ornl.gov (Piburn, Jesse O.)
Date: Fri, 22 Apr 2016 14:37:28 +0000
Subject: [R] [R-pkgs] New Package on CRAN: wbstats
Message-ID: <f5d2fa1b8f0047dbaccc47145c0ab1e9@EXCHCS34.ornl.gov>

Hello,

I wanted to announce the release of a new package on CRAN wbstats.

>From the description "Tools for searching and downloading data and statistics from the World Bank Data API (http://data.worldbank.org/developers/api-overview) and the World Bank Data Catalog API (http://data.worldbank.org/developers/data-catalog-api)"

Here is a (hopefully) useful vignette if you would like to learn more
https://cran.r-project.org/web/packages/wbstats/vignettes/Using_the_wbstats_package.html

Comments and suggestions are always welcome. Thank you

Repos
CRAN: https://cran.r-project.org/web/packages/wbstats/
Github: https://github.com/GIST-ORNL/wbstats


Best,
Jesse




Jesse Piburn
Research Scientist in Geographic Data Sciences
Geographic Information Science and Technology Group
Computational Sciences and Engineering Division
Oak Ridge National Laboratory
Office E304, Building 5600
Office Phone: 865 576 9318
Email: piburnjo at ornl.gov


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From twiniverse2000 at gmail.com  Sat Apr 23 17:59:06 2016
From: twiniverse2000 at gmail.com (thomas mann)
Date: Sat, 23 Apr 2016 08:59:06 -0700
Subject: [R] Data Frame Column Name Attribute
Message-ID: <CACcG51Nee=gwNWvGhn4N0awJK-kY2-fD_qbJnJaPpecbDXSGtw@mail.gmail.com>

I am attempting to add a calculated column to a data frame.  Basically,
adding a column called "newcol2" which are the stock closing prices from 1
day to the next.

The one little hang up is the name of the column.  There seems to be an
additional data column name included in the attributes (dimnames?).  So
when i run HEAD(DATAFRAMENAME) i get the column name = "Open".   but you
can see below... it is called "newcol2 with some attribute called open.

I did a lot of google searches but really could not find what i was looking
for.  Any help is greatly appreciated.  Thank you!

tdata[["newcol2"]] <- rbind(0,apply(tdata["Open"],2,diff))

> str(tdata)
'data.frame': 7505 obs. of  8 variables:
 $ Date   : int  19860709 19860710 19860711 19860714 19860715 19860716
19860717 19860718 19860721 19860722 ...
 $ Open   : num  9.14 9.45 9.3 9.08 8.71 ...
 $ High   : num  9.45 9.51 9.35 9.08 8.71 ...
 $ Low    : num  9.03 9.14 9.03 8.65 7.96 ...
 $ Close  : num  9.4 9.35 9.03 8.76 8.5 ...
 $ Volume : int  332719 180049 234212 218772 605427 339507 306866 418593
94880 119332 ...
 $ OpenInt: num [1:7505, 1] 0 0.317 -0.155 -0.223 -0.367 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr "Open"
* $ newcol2:* num [1:7505, 1] 0 0.317 -0.155 -0.223 -0.367 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
*  .. ..$ : chr "Open"*

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Apr 23 22:15:33 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 23 Apr 2016 13:15:33 -0700
Subject: [R] Data Frame Column Name Attribute
In-Reply-To: <CACcG51Nee=gwNWvGhn4N0awJK-kY2-fD_qbJnJaPpecbDXSGtw@mail.gmail.com>
References: <CACcG51Nee=gwNWvGhn4N0awJK-kY2-fD_qbJnJaPpecbDXSGtw@mail.gmail.com>
Message-ID: <CBBE2913-EEB2-43C7-A5CD-D6DCF10D25EF@comcast.net>


> On Apr 23, 2016, at 8:59 AM, thomas mann <twiniverse2000 at gmail.com> wrote:
> 
> I am attempting to add a calculated column to a data frame.  Basically,
> adding a column called "newcol2" which are the stock closing prices from 1
> day to the next.
> 
> The one little hang up is the name of the column.  There seems to be an
> additional data column name included in the attributes (dimnames?).  So
> when i run HEAD(DATAFRAMENAME) i get the column name = "Open".   but you
> can see below... it is called "newcol2 with some attribute called open.

The attribute comes from the name of the argument to `apply`

> 
> I did a lot of google searches but really could not find what i was looking
> for.  Any help is greatly appreciated.  Thank you!
> 
> tdata[["newcol2"]] <- rbind(0,apply(tdata["Open"],2,diff))

The `rbind` function is returning a matrix and `[[<-. data.frame` is adding it to the tdata object. Matrices have dimname attributes. It appears to me that you have also earlier attempted (successfully) to add a column named "OpenInt" higher up in your code that you have not shown us.

If you want to get rid of this column use `[<-.data.frame` with a NULL argument

tdata['OpenInt'] <- NULL


If you start again with neither of these columns, I would suggest this instead:

tdata[["newcol2"]] <- c( 0, apply(tdata["Open"],2,diff ) )

The valued returned should be an undimensioned object and will not get bound to the dataframe as a matrix.

-- 
David.
> 
>> str(tdata)
> 'data.frame': 7505 obs. of  8 variables:
> $ Date   : int  19860709 19860710 19860711 19860714 19860715 19860716
> 19860717 19860718 19860721 19860722 ...
> $ Open   : num  9.14 9.45 9.3 9.08 8.71 ...
> $ High   : num  9.45 9.51 9.35 9.08 8.71 ...
> $ Low    : num  9.03 9.14 9.03 8.65 7.96 ...
> $ Close  : num  9.4 9.35 9.03 8.76 8.5 ...
> $ Volume : int  332719 180049 234212 218772 605427 339507 306866 418593
> 94880 119332 ...
> $ OpenInt: num [1:7505, 1] 0 0.317 -0.155 -0.223 -0.367 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
>  .. ..$ : chr "Open"
> * $ newcol2:* num [1:7505, 1] 0 0.317 -0.155 -0.223 -0.367 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
> *  .. ..$ : chr "Open"*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From chalabi.elahe at yahoo.de  Sat Apr 23 22:16:50 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sat, 23 Apr 2016 20:16:50 +0000 (UTC)
Subject: [R] assign color to subsets
References: <665092859.1453464.1461442610610.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <665092859.1453464.1461442610610.JavaMail.yahoo@mail.yahoo.com>

Hi 
I have the following df and I created two subsets but I don't know how to use these subsets as the colors of my plot.

    
   data.frame': 36919 obs. of 162 variables 
   $TE           :int 38,41,11,52,48,75,..... 
   $TR           :int 100,210,548,546,..... 
   $Command       :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize"...

and the subsets are names in Command which has t1 or t2 letters:

  
   
  hast1=grepl("t1", df$Command, fixed=TRUE) 
  hast2=grepl("t2", df$Command, fixed=TRUE) 
  

the colors I want in my plot are : hast1 and hast2 
Thanks for any help.
Elahe


From wdunlap at tibco.com  Sat Apr 23 22:17:29 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 23 Apr 2016 13:17:29 -0700
Subject: [R] Data Frame Column Name Attribute
In-Reply-To: <CACcG51Nee=gwNWvGhn4N0awJK-kY2-fD_qbJnJaPpecbDXSGtw@mail.gmail.com>
References: <CACcG51Nee=gwNWvGhn4N0awJK-kY2-fD_qbJnJaPpecbDXSGtw@mail.gmail.com>
Message-ID: <CAF8bMcbHhZ562AbiM3kOyF0YcnvAnkH_yJ=eFMGYcrcQNpuArQ@mail.gmail.com>

You could use transform() instead of [[<- to add columns to your data.frame
so the new columns get transformed they way they do when given to the
data.frame function itself.  E.g.,

> dd <- data.frame(X=1:5, Y=11:15)
> str(transform(dd, Z=matrix(X+Y,ncol=1,dimnames=list(NULL, "NewZ"))))
'data.frame':   5 obs. of  3 variables:
 $ X   : int  1 2 3 4 5
 $ Y   : int  11 12 13 14 15
 $ NewZ: int  12 14 16 18 20
> str(transform(dd, Z=matrix(c(X,Y),ncol=2,dimnames=list(NULL,
c("NewZ1","NewZ2")))))
'data.frame':   5 obs. of  4 variables:
 $ X      : int  1 2 3 4 5
 $ Y      : int  11 12 13 14 15
 $ Z.NewZ1: int  1 2 3 4 5
 $ Z.NewZ2: int  11 12 13 14 15



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Apr 23, 2016 at 8:59 AM, thomas mann <twiniverse2000 at gmail.com>
wrote:

> I am attempting to add a calculated column to a data frame.  Basically,
> adding a column called "newcol2" which are the stock closing prices from 1
> day to the next.
>
> The one little hang up is the name of the column.  There seems to be an
> additional data column name included in the attributes (dimnames?).  So
> when i run HEAD(DATAFRAMENAME) i get the column name = "Open".   but you
> can see below... it is called "newcol2 with some attribute called open.
>
> I did a lot of google searches but really could not find what i was looking
> for.  Any help is greatly appreciated.  Thank you!
>
> tdata[["newcol2"]] <- rbind(0,apply(tdata["Open"],2,diff))
>
> > str(tdata)
> 'data.frame': 7505 obs. of  8 variables:
>  $ Date   : int  19860709 19860710 19860711 19860714 19860715 19860716
> 19860717 19860718 19860721 19860722 ...
>  $ Open   : num  9.14 9.45 9.3 9.08 8.71 ...
>  $ High   : num  9.45 9.51 9.35 9.08 8.71 ...
>  $ Low    : num  9.03 9.14 9.03 8.65 7.96 ...
>  $ Close  : num  9.4 9.35 9.03 8.76 8.5 ...
>  $ Volume : int  332719 180049 234212 218772 605427 339507 306866 418593
> 94880 119332 ...
>  $ OpenInt: num [1:7505, 1] 0 0.317 -0.155 -0.223 -0.367 ...
>   ..- attr(*, "dimnames")=List of 2
>   .. ..$ : NULL
>   .. ..$ : chr "Open"
> * $ newcol2:* num [1:7505, 1] 0 0.317 -0.155 -0.223 -0.367 ...
>   ..- attr(*, "dimnames")=List of 2
>   .. ..$ : NULL
> *  .. ..$ : chr "Open"*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sabasehrish at yahoo.com  Sun Apr 24 05:56:32 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Sun, 24 Apr 2016 03:56:32 +0000 (UTC)
Subject: [R] Finding Highest value in groups
In-Reply-To: <248E6FA047A8C746BA491485764190F53D3AF033@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F53D3AF033@ESESSMB207.ericsson.se>
Message-ID: <727725526.846380.1461470192913.JavaMail.yahoo@mail.yahoo.com>

Thanks a lot. Its really helpful

Regards
Saba



On Saturday, 23 April 2016, 6:50, Giorgio Garziano <giorgio.garziano at ericsson.com> wrote:
Since the aggregate S3 method for class formula already has got na.action = na.omit,

## S3 method for class 'formula'
aggregate(formula, data, FUN, ...,
          subset, na.action = na.omit)


I think that to deal with NA's, it is enough:

   aggregate(Value~ID, dta, max)

Moreover, passing na.rm = FALSE/TRUE is "don't care":

aggregate(Value~ID, dta, max, na.rm=FALSE) result is:

  ID Value
1  1  0.69
2  2  0.99
3  3  1.00
4  4  1.00
5  5  0.50

which is the same of na.rm=TRUE.

On the contrary, in the following cases:

aggregate(Value~ID, dta, max, na.action = na.pass)

  ID Value
1  1  0.69
2  2  0.99
3  3  1.00
4  4    NA
5  5  0.50

aggregate(Value~ID, dta, max, na.action = na.fail)

  Error in na.fail.default(list(Value = c(0.69, 0.31, 0.01, 0.99, 1, NA


the result is different.

--

Best,

GG





    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sabasehrish at yahoo.com  Sun Apr 24 06:36:40 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Sun, 24 Apr 2016 04:36:40 +0000 (UTC)
Subject: [R] multiplication by groups
References: <171732449.875986.1461472600104.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <171732449.875986.1461472600104.JavaMail.yahoo@mail.yahoo.com>

Hi 


I have two data frames as shown below (second one is obtained by aggregating rows of similar IDs in df1.). They both have similar number of columns but rows of df2 are lesser than rows of df1. 


df1:
ID    A            B 
1      1            2 
1      0            3 
2     5            NA 
2      1            3 
3      1            4 
4      NA           NA 
4      0            1 
4      3            0 
5      2            5 
5      7            NA 


df2:
ID    A        B
1      1        5 
2      6        3 
3      1        4
4      3        1 

5     9        5

Now, to obtain weight of each value of df1, I want to divide each row of df1 by the row of df2 having similar ID. What I want is as below:

ID        A                B 
1         1      0.4 
1      0      0.6 
2      0.83    NA         
2      0.17     1
3         1        4
4         NA               NA 
4         0        1 
4      1        0
5      0.22     1
5      0.78    NA

 
Kindly guide me in this regard. 

Thanks 
Saba


From sabasehrish at yahoo.com  Sun Apr 24 06:46:03 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Sun, 24 Apr 2016 04:46:03 +0000 (UTC)
Subject: [R] Dividing rows in groups
References: <1072145304.889619.1461473163979.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1072145304.889619.1461473163979.JavaMail.yahoo@mail.yahoo.com>

Hi 


I have two data frames as shown below (second one is obtained by aggregating rows of similar IDs in df1.). They both have similar number of columns but rows of df2 are lesser than rows of df1. 


df1: 
ID       A             B 
1         1             2 
1         0             3 
2        5             NA 
2         1             3 
3         1             4 
4         NA           NA 
4         0             1 
4         3             0 
5         2             5 
5         7           NA


df2: 
ID       A          B 
1         1          5 
2         6          3 
3         1          4 
4         3          1 
5        9          5 

Now, to obtain weight of each value of df1, I want to divide each row of df1 by the row of df2 having similar ID. What I want is as below: 

ID    A    B 
1    1    0.4 
1    0    0.6 
2    0.83  NA 
2    0.17  1 
3    1     4 
4    NA    NA 
4    0     1 
4    1     0 
5    0.22  1 
5    0.78  NA 


Kindly guide me in this regard. 

Thanks 
Saba


From dwinsemius at comcast.net  Sun Apr 24 07:42:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 23 Apr 2016 22:42:15 -0700
Subject: [R] Dividing rows in groups
In-Reply-To: <1072145304.889619.1461473163979.JavaMail.yahoo@mail.yahoo.com>
References: <1072145304.889619.1461473163979.JavaMail.yahoo.ref@mail.yahoo.com>
	<1072145304.889619.1461473163979.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <7133D39E-1502-4B28-B938-492428CD9AD7@comcast.net>


> On Apr 23, 2016, at 9:46 PM, Saba Sehrish via R-help <r-help at r-project.org> wrote:
> 
> Hi 
> 
> 
> I have two data frames as shown below (second one is obtained by aggregating rows of similar IDs in df1.). They both have similar number of columns but rows of df2 are lesser than rows of df1. 
> 
> 
> df1: 
> ID       A             B 
> 1         1             2 
> 1         0             3 
> 2        5             NA 
> 2         1             3 
> 3         1             4 
> 4         NA           NA 
> 4         0             1 
> 4         3             0 
> 5         2             5 
> 5         7           NA
> 
> 
> df2: 
> ID       A          B 
> 1         1          5 
> 2         6          3 
> 3         1          4 
> 4         3          1 
> 5        9          5 
> 
> Now, to obtain weight of each value of df1, I want to divide each row of df1 by the row of df2 having similar ID. What I want is as below: 
> 
> ID    A    B 
> 1    1    0.4 
> 1    0    0.6 
> 2    0.83  NA 
> 2    0.17  1 
> 3    1     4 
> 4    NA    NA 
> 4    0     1 
> 4    1     0 
> 5    0.22  1 
> 5    0.78  NA 
> 
> 
> Kindly guide me in this regard. 

Do a merge on "ID"  and then calculate.


-- 

David Winsemius
Alameda, CA, USA


From lars52r at gmail.com  Sun Apr 24 13:16:27 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Sun, 24 Apr 2016 07:16:27 -0400
Subject: [R] Interactive ggvis plot - question
Message-ID: <CAO7OmOhn0L4XRcyBVzEjS+Nn0eABkBz7KX6Kv7FKGtmybMp-rQ@mail.gmail.com>

Hello,

I'm trying to plot a histogram (or alternatively the density) of a
variable, with a slider that displays a vertical line with the
corresponding quantile of the distribution of the variable. That is, I what
to interactivity pick for example, the median, and have the vertical line
move to the corresponding value.

Is this possible to implement in ggvis? I read this comment from Hadley
that says vertical lines are not implemented in ggvis (at least as of last
year).

https://groups.google.com/forum/#!topic/ggvis/VpUYCvhbfX8

Any guidance would be greatly appreciated.

Best,
Lars.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Apr 24 13:28:02 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 24 Apr 2016 07:28:02 -0400
Subject: [R] Java memory error when reading a small xlsx file
In-Reply-To: <CABcx46DQvJPq7iQ5uj005yw0vb-n1Argn-mUFb1NTpWxv8TsRg@mail.gmail.com>
References: <CABcx46DQvJPq7iQ5uj005yw0vb-n1Argn-mUFb1NTpWxv8TsRg@mail.gmail.com>
Message-ID: <CAAxdm-4LG5BuBXiH7CdZfzk5-3FeRTp+AxNAd45W5LtSj=-v-g@mail.gmail.com>

Try using the openxlsx package; it does not require Java.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Apr 23, 2016 at 3:43 PM, jpm miao <miaojpm at gmail.com> wrote:

> Hi,
>
>    I tried to read a (small) xlsx file by "readWorksheetFromFile" function
> of "XLConnect" package and "read.xlsx" function in "xlsx" package, but I
> got this error message:
>
> Error: OutOfMemoryError (Java): Java heap space
>
>    I tried to follow the solution on the web
>
> http://stackoverflow.com/questions/21937640/handling-java-lang-outofmemoryerror-when-writing-to-excel-from-r
>
>    and I did add a line to my program
> #######
> options(java.parameters = "-Xmx8000m")
> ########
> #or
> ########
> options(java.parameters = "-Xmx1000m")
> #######
>    but it did not work.
>
>    I wonder if I need to detach the packages before adding that line
> ########
> detach("package:XLConnect", unload=TRUE)
> detach("package:xlsx", unload=TRUE)
> detach("package:xlsxjars", unload=TRUE)
> detach("package:XLConnectJars", unload=TRUE)
> detach("package:rJava", unload=TRUE)
> options(java.parameters = "-Xmx8000m")
> library(XLConnect)
> library(xlsx)
> #######
>     but it did not work.
>
> I am on a Mac, with very new OS and very new R version.
>
> R version 3.2.4 (2016-03-10)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.11.3 (El Capitan)
>
>     Could someone guide me how to solve the problem? Thanks!
>
> Miao
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bob at rudis.net  Sun Apr 24 13:51:46 2016
From: bob at rudis.net (boB Rudis)
Date: Sun, 24 Apr 2016 07:51:46 -0400
Subject: [R] CRAN package check results tabulated ... wasRe: Number of
 package in Ubuntu
In-Reply-To: <9F92D1AE-ECAC-45A8-B42F-326BACE0DBAD@comcast.net>
References: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
	<21756501-903B-433C-93DA-6CFAF7A70C2A@comcast.net>
	<9F92D1AE-ECAC-45A8-B42F-326BACE0DBAD@comcast.net>
Message-ID: <CAJ4QxaO2xuOVC4QjnktitPixChpLUrEQE1wwowgUA1kE-EzmMA@mail.gmail.com>

Or grab https://cran.r-project.org/web/checks/check_results.rds and
read it w/o the need for scraping.

On Sat, Apr 23, 2016 at 10:43 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
>> On Apr 23, 2016, at 6:56 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Apr 22, 2016, at 11:51 AM, mylisttech at gmail.com wrote:
>>>
>>> Dear Experts ,
>>>
>>> I am using R with Spark on Windows and now there is a need to move to Ubuntu. I wanted to know if most of the packages that are available on windows , would they be available on Ubuntu/Linux? If not can I compile the source code of those package ? Has any one of you used the packages on Ubuntu ?
>>
>> You can get the status of efforts to compile packages on the various machine avaialbe to CRAN at the CRAN package checks page:
>>
>> https://cran.r-project.org/web/checks/check_summary.html
>>
>
> After scraping that page with rvest::read_html I then used `table` to summarize. I posted the full output at the end of this but here are the relevant rows for Debian (for the Ubuntu option) and the Windows platforms tested:
>
>> res_tbl
> $`r-develLinuxx86_64(Debian GCC)`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   261    59  4150    28  3994    35    25
>
> $`r-develWindowsix86+x86_64`
>
>         ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN
>    295    124      1   3962     25   4064     36     45
>
> $`r-patchedLinuxx86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   259    54  4153    28  3998    35    25
>
> $`r-releaseLinuxx86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   268    54  2578    18  5569    45    20
>
> $`r-releaseWindowsix86+x86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   324    70  2187    16  5885    46    24
>
> $`r-oldrelWindowsix86+x86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN WARN*
>   532   159  1605    13  6028    45   168     2
>
> I think the various "NOTE" and "WARN" categories in most cases should be interpreted as "probably OK". It's those initial <blank>'s and ERROR categories that would most likely be the ones affecting users.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> --------- full tables--------
> Tabulate on just the first letter of hte result:
>
>> t(res_tbl2)
>                                  blank   E    N    O   W
> r-develLinuxx86_64(Debian GCC)     261  59 4178 4029  25
> r-develLinuxx86_64(Fedora Clang)   265  66 4191 4001  29
> r-develLinuxx86_64(Fedora GCC)     265  60 4204 3991  32
> r-develOS Xx86_64(Clang)           294  70 4075 4081  32
> r-develWindowsix86+x86_64          295 125 3987 4100  45
> r-patchedLinuxx86_64               259  54 4181 4033  25
> r-patchedSolarissparc              364 131 4082 3909  66
> r-patchedSolarisx86                343 106 4091 3965  47
> r-releaseLinuxx86_64               268  54 2596 5614  20
> r-releaseOS Xx86_64(Mavericks)     255 174 2337 5718  68
> r-releaseWindowsix86+x86_64        324  70 2203 5931  24
> r-oldrelWindowsix86+x86_64         532 159 1618 6073 170
>
> Tablulate on full message:
>> res_tbl
> $`r-develLinuxx86_64(Debian GCC)`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   261    59  4150    28  3994    35    25
>
> $`r-develLinuxx86_64(Fedora Clang)`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   265    66  4179    12  3982    19    29
>
> $`r-develLinuxx86_64(Fedora GCC)`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   265    60  4191    13  3972    19    32
>
> $`r-develOS Xx86_64(Clang)`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   294    70  4066     9  4068    13    32
>
> $`r-develWindowsix86+x86_64`
>
>         ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN
>    295    124      1   3962     25   4064     36     45
>
> $`r-patchedLinuxx86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   259    54  4153    28  3998    35    25
>
> $`r-patchedSolarissparc`
>
>         ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN  WARN*
>    364    129      2   4006     76   3839     70     65      1
>
> $`r-patchedSolarisx86`
>
>         ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN
>    343    105      1   4062     29   3945     20     47
>
> $`r-releaseLinuxx86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   268    54  2578    18  5569    45    20
>
> $`r-releaseOS Xx86_64(Mavericks)`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   255   174  2335     2  5716     2    68
>
> $`r-releaseWindowsix86+x86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN
>   324    70  2187    16  5885    46    24
>
> $`r-oldrelWindowsix86+x86_64`
>
>       ERROR  NOTE NOTE*    OK   OK*  WARN WARN*
>   532   159  1605    13  6028    45   168     2
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sabasehrish at yahoo.com  Sun Apr 24 14:02:29 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Sun, 24 Apr 2016 12:02:29 +0000 (UTC)
Subject: [R] Inserting a blank row to every other row
References: <217909546.876702.1461499349660.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <217909546.876702.1461499349660.JavaMail.yahoo@mail.yahoo.com>

Hi

I need to insert a blank row after every row in R data frame. I have achieved it through:


df[rep(1:nrow(df),1,each=2),]

But it inserts a row with name of previous row, while i want a complete blank row without any name/title.

Please guide me

Regards
Saba


From ulrik.stervbo at gmail.com  Sun Apr 24 17:21:54 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sun, 24 Apr 2016 15:21:54 +0000
Subject: [R] Inserting a blank row to every other row
In-Reply-To: <217909546.876702.1461499349660.JavaMail.yahoo@mail.yahoo.com>
References: <217909546.876702.1461499349660.JavaMail.yahoo.ref@mail.yahoo.com>
	<217909546.876702.1461499349660.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAKVAULOVP_PEbRdb=6NjVKqNTkUd5iT_6KE+bhpZHtn_wMP86g@mail.gmail.com>

Hi Saba,

I don't know how to do what you want and I also cannot see why.

If you describe what you hope to achieve there might be a different
solution.

Best wishes
Ulrik

Saba Sehrish via R-help <r-help at r-project.org> schrieb am So., 24. Apr.
2016 14:04:

> Hi
>
> I need to insert a blank row after every row in R data frame. I have
> achieved it through:
>
>
> df[rep(1:nrow(df),1,each=2),]
>
> But it inserts a row with name of previous row, while i want a complete
> blank row without any name/title.
>
> Please guide me
>
> Regards
> Saba
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Apr 24 17:38:09 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 24 Apr 2016 11:38:09 -0400
Subject: [R] Dividing rows in groups
In-Reply-To: <1072145304.889619.1461473163979.JavaMail.yahoo@mail.yahoo.com>
References: <1072145304.889619.1461473163979.JavaMail.yahoo.ref@mail.yahoo.com>
	<1072145304.889619.1461473163979.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-5nUUK9MBxxgxa+wNcf1M4z214aQYAd0psL6NAxwX2Rrg@mail.gmail.com>

You can use 'dplyr':

> library(dplyr)
> df1 <- read.table(text = "ID       A             B
+ 1         1             2
+ 1         0             3
+ 2        5             NA
+ 2         1             3
+ 3         1             4
+ 4         NA           NA
+ 4         0             1
+ 4         3             0
+ 5         2             5
+ 5         7           NA", header = TRUE)
> df2 <- df1 %>%
+         group_by(ID) %>%
+         mutate(new_A = A / sum(A, na.rm = TRUE)
+             , new_B = B / sum(B, na.rm = TRUE)
+             )
>
> df2
Source: local data frame [10 x 5]
Groups: ID [5]

      ID     A     B     new_A new_B
   (int) (int) (int)     (dbl) (dbl)
1      1     1     2 1.0000000   0.4
2      1     0     3 0.0000000   0.6
3      2     5    NA 0.8333333    NA
4      2     1     3 0.1666667   1.0
5      3     1     4 1.0000000   1.0
6      4    NA    NA        NA    NA
7      4     0     1 0.0000000   1.0
8      4     3     0 1.0000000   0.0
9      5     2     5 0.2222222   1.0
10     5     7    NA 0.7777778    NA



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Apr 24, 2016 at 12:46 AM, Saba Sehrish via R-help <
r-help at r-project.org> wrote:

> Hi
>
>
> I have two data frames as shown below (second one is obtained by
> aggregating rows of similar IDs in df1.). They both have similar number of
> columns but rows of df2 are lesser than rows of df1.
>
>
> df1:
> ID       A             B
> 1         1             2
> 1         0             3
> 2        5             NA
> 2         1             3
> 3         1             4
> 4         NA           NA
> 4         0             1
> 4         3             0
> 5         2             5
> 5         7           NA
>
>
> df2:
> ID       A          B
> 1         1          5
> 2         6          3
> 3         1          4
> 4         3          1
> 5        9          5
>
> Now, to obtain weight of each value of df1, I want to divide each row of
> df1 by the row of df2 having similar ID. What I want is as below:
>
> ID    A    B
> 1    1    0.4
> 1    0    0.6
> 2    0.83  NA
> 2    0.17  1
> 3    1     4
> 4    NA    NA
> 4    0     1
> 4    1     0
> 5    0.22  1
> 5    0.78  NA
>
>
> Kindly guide me in this regard.
>
> Thanks
> Saba
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Apr 24 17:53:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 24 Apr 2016 08:53:19 -0700
Subject: [R] Inserting a blank row to every other row
In-Reply-To: <CAKVAULOVP_PEbRdb=6NjVKqNTkUd5iT_6KE+bhpZHtn_wMP86g@mail.gmail.com>
References: <217909546.876702.1461499349660.JavaMail.yahoo.ref@mail.yahoo.com>
	<217909546.876702.1461499349660.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOVP_PEbRdb=6NjVKqNTkUd5iT_6KE+bhpZHtn_wMP86g@mail.gmail.com>
Message-ID: <CAGxFJbRJAEGvciFFVJ5bxX_eNL3usoUk6tOUz2gHbcSLtOOyBA@mail.gmail.com>

Well, something like this would work (there may be slicker solutions):

> z <- data.frame(a=1:3,b = letters[1:3])
> i <- seq_len(nrow(z)) *2
> z <-rbind(z,z)
> z[i, ] <- matrix(NA, nr=nrow(z),nc=ncol(z))
> z
   a    b
1  1    a
2 NA <NA>
3  3    c
4 NA <NA>
5  2    b
6 NA <NA>

But I agree with you that there is probably a way to handle the
underlying issues that does not require this kind of artifice.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 24, 2016 at 8:21 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Hi Saba,
>
> I don't know how to do what you want and I also cannot see why.
>
> If you describe what you hope to achieve there might be a different
> solution.
>
> Best wishes
> Ulrik
>
> Saba Sehrish via R-help <r-help at r-project.org> schrieb am So., 24. Apr.
> 2016 14:04:
>
>> Hi
>>
>> I need to insert a blank row after every row in R data frame. I have
>> achieved it through:
>>
>>
>> df[rep(1:nrow(df),1,each=2),]
>>
>> But it inserts a row with name of previous row, while i want a complete
>> blank row without any name/title.
>>
>> Please guide me
>>
>> Regards
>> Saba
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun Apr 24 18:10:02 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 24 Apr 2016 12:10:02 -0400
Subject: [R] assign color to subsets
In-Reply-To: <665092859.1453464.1461442610610.JavaMail.yahoo@mail.yahoo.com>
References: <665092859.1453464.1461442610610.JavaMail.yahoo.ref@mail.yahoo.com>
	<665092859.1453464.1461442610610.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-43BKsaqNe-n-U2cBJQ66Hq9OkM=G3oG-3wUy98=T6z+g@mail.gmail.com>

You never did provide a reproducible example or say how you wanted to
plot.  Here is a way to get a subset of t1 or t2, and you can then use it
as input to ggplot:

library(dplyr)
your_subset <- df %>%
          mutate(key = grep(".*(t1|t2).*", "\\1", Command, value = TRUE))
%>%
          filter(!(Command %in% c('t1', 't2')))

This will give you a subset with just t1/t2 and you can use 'key' as the
colour option for ggplot.



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Apr 23, 2016 at 4:16 PM, ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi
> I have the following df and I created two subsets but I don't know how to
> use these subsets as the colors of my plot.
>
>
>    data.frame': 36919 obs. of 162 variables
>    $TE           :int 38,41,11,52,48,75,.....
>    $TR           :int 100,210,548,546,.....
>    $Command       :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize"...
>
> and the subsets are names in Command which has t1 or t2 letters:
>
>
>
>   hast1=grepl("t1", df$Command, fixed=TRUE)
>   hast2=grepl("t2", df$Command, fixed=TRUE)
>
>
> the colors I want in my plot are : hast1 and hast2
> Thanks for any help.
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Apr 24 18:13:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 24 Apr 2016 09:13:03 -0700
Subject: [R] Inserting a blank row to every other row
In-Reply-To: <CAGxFJbRJAEGvciFFVJ5bxX_eNL3usoUk6tOUz2gHbcSLtOOyBA@mail.gmail.com>
References: <217909546.876702.1461499349660.JavaMail.yahoo.ref@mail.yahoo.com>
	<217909546.876702.1461499349660.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOVP_PEbRdb=6NjVKqNTkUd5iT_6KE+bhpZHtn_wMP86g@mail.gmail.com>
	<CAGxFJbRJAEGvciFFVJ5bxX_eNL3usoUk6tOUz2gHbcSLtOOyBA@mail.gmail.com>
Message-ID: <CAGxFJbTo8agB=V6B9KHkcHapgR4cU9H5z0hO6NeKD0K=D7b6HQ@mail.gmail.com>

Oh, sorry, I just realized that I messed up the indicing. Here is the
correct way:

> z <- data.frame(a=1:3,b = letters[1:3])
>  i <- seq_len(nrow(z))
>  z<-z[rep(i,e=2),]
>  z[2*i, ] <- matrix(NA, nr=nrow(z),nc=ncol(z))
>  z

Still doubt that this is a good idea, though.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 24, 2016 at 8:53 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Well, something like this would work (there may be slicker solutions):
>
>> z <- data.frame(a=1:3,b = letters[1:3])
>> i <- seq_len(nrow(z)) *2
>> z <-rbind(z,z)
>> z[i, ] <- matrix(NA, nr=nrow(z),nc=ncol(z))
>> z
>    a    b
> 1  1    a
> 2 NA <NA>
> 3  3    c
> 4 NA <NA>
> 5  2    b
> 6 NA <NA>
>
> But I agree with you that there is probably a way to handle the
> underlying issues that does not require this kind of artifice.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Apr 24, 2016 at 8:21 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>> Hi Saba,
>>
>> I don't know how to do what you want and I also cannot see why.
>>
>> If you describe what you hope to achieve there might be a different
>> solution.
>>
>> Best wishes
>> Ulrik
>>
>> Saba Sehrish via R-help <r-help at r-project.org> schrieb am So., 24. Apr.
>> 2016 14:04:
>>
>>> Hi
>>>
>>> I need to insert a blank row after every row in R data frame. I have
>>> achieved it through:
>>>
>>>
>>> df[rep(1:nrow(df),1,each=2),]
>>>
>>> But it inserts a row with name of previous row, while i want a complete
>>> blank row without any name/title.
>>>
>>> Please guide me
>>>
>>> Regards
>>> Saba
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun Apr 24 18:26:24 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 24 Apr 2016 12:26:24 -0400
Subject: [R] Dividing rows in groups
In-Reply-To: <647822941.982370.1461513739348.JavaMail.yahoo@mail.yahoo.com>
References: <CAAxdm-5nUUK9MBxxgxa+wNcf1M4z214aQYAd0psL6NAxwX2Rrg@mail.gmail.com>
	<647822941.982370.1461513739348.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-5jqFVFf6cOT5nBxgkXiQAe3u=RhfhNrcHfsWWqMDhqfg@mail.gmail.com>

This will handle all the columns; it assumes the ones you want to start
with are in column 2 through the end:


> library(dplyr)
> df1 <- read.table(text = "ID       A             B
+ 1         1             2
+ 1         0             3
+ 2        5             NA
+ 2         1             3
+ 3         1             4
+ 4         NA           NA
+ 4         0             1
+ 4         3             0
+ 5         2             5
+ 5         7           NA", header = TRUE)
> df2 <- df1 %>%
+         group_by(ID) %>%
+         do({  # now process and indeterinant number of columns
+             result <- .  # get original input
+             for (i in 2:ncol(result)){
+                 result[[i]] <- result[[i]] / sum(result[[i]], na.rm =
TRUE)
+             }
+             result  # return value
+         })
>
> df2
Source: local data frame [10 x 3]
Groups: ID [5]

      ID         A     B
   (int)     (dbl) (dbl)
1      1 1.0000000   0.4
2      1 0.0000000   0.6
3      2 0.8333333    NA
4      2 0.1666667   1.0
5      3 1.0000000   1.0
6      4        NA    NA
7      4 0.0000000   1.0
8      4 1.0000000   0.0
9      5 0.2222222   1.0
10     5 0.7777778    NA



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Apr 24, 2016 at 12:02 PM, Saba Sehrish <sabasehrish at yahoo.com>
wrote:

> Hi Jim
>
> Thanks a lot. Its really helpful but actually I have around 10,000 columns
> & 8000 rows. I simply want to get the weight of each observation in a group
> (group is identified by ID). Therefore, I am looking for an easy way to
> divide each observation in a row with the sum of all values in its group.
>
> How can I apply this on such a huge data set?
>
> Regards
> Saba
>
>
>
> Sent from Yahoo Mail on Android
> <https://overview.mail.yahoo.com/mobile/?.src=Android>
>
> On Mon, 25 Apr, 2016 at 3:38 AM, jim holtman
> <jholtman at gmail.com> wrote:
> You can use 'dplyr':
>
> > library(dplyr)
> > df1 <- read.table(text = "ID       A             B
> + 1         1             2
> + 1         0             3
> + 2        5             NA
> + 2         1             3
> + 3         1             4
> + 4         NA           NA
> + 4         0             1
> + 4         3             0
> + 5         2             5
> + 5         7           NA", header = TRUE)
> > df2 <- df1 %>%
> +         group_by(ID) %>%
> +         mutate(new_A = A / sum(A, na.rm = TRUE)
> +             , new_B = B / sum(B, na.rm = TRUE)
> +             )
> >
> > df2
> Source: local data frame [10 x 5]
> Groups: ID [5]
>
>       ID     A     B     new_A new_B
>    (int) (int) (int)     (dbl) (dbl)
> 1      1     1     2 1.0000000   0.4
> 2      1     0     3 0.0000000   0.6
> 3      2     5    NA 0.8333333    NA
> 4      2     1     3 0.1666667   1.0
> 5      3     1     4 1.0000000   1.0
> 6      4    NA    NA        NA    NA
> 7      4     0     1 0.0000000   1.0
> 8      4     3     0 1.0000000   0.0
> 9      5     2     5 0.2222222   1.0
> 10     5     7    NA 0.7777778    NA
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sun, Apr 24, 2016 at 12:46 AM, Saba Sehrish via R-help <
> r-help at r-project.org> wrote:
>
>> Hi
>>
>>
>> I have two data frames as shown below (second one is obtained by
>> aggregating rows of similar IDs in df1.). They both have similar number of
>> columns but rows of df2 are lesser than rows of df1.
>>
>>
>> df1:
>> ID       A             B
>> 1         1             2
>> 1         0             3
>> 2        5             NA
>> 2         1             3
>> 3         1             4
>> 4         NA           NA
>> 4         0             1
>> 4         3             0
>> 5         2             5
>> 5         7           NA
>>
>>
>> df2:
>> ID       A          B
>> 1         1          5
>> 2         6          3
>> 3         1          4
>> 4         3          1
>> 5        9          5
>>
>> Now, to obtain weight of each value of df1, I want to divide each row of
>> df1 by the row of df2 having similar ID. What I want is as below:
>>
>> ID    A    B
>> 1    1    0.4
>> 1    0    0.6
>> 2    0.83  NA
>> 2    0.17  1
>> 3    1     4
>> 4    NA    NA
>> 4    0     1
>> 4    1     0
>> 5    0.22  1
>> 5    0.78  NA
>>
>>
>> Kindly guide me in this regard.
>>
>> Thanks
>> Saba
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Sun Apr 24 19:42:53 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 24 Apr 2016 17:42:53 +0000
Subject: [R] Inserting a blank row to every other row
Message-ID: <248E6FA047A8C746BA491485764190F53D3AF32E@ESESSMB207.ericsson.se>

Starting from this data frame:

my.df <- data.frame(num = 1:5, let = letters[1:5])

> my.df
  num let
1   1   a
2   2   b
3   3   c
4   4   d
5   5   e
>

and inserting a blank row (NAs row) for each one of my.df rows.

na.df <- data.frame(num = NA, let = NA)

my.df <- do.call(rbind, apply(my.df, 1, function(x) {rbind(x, na.df)}))

> my.df
    num  let
1     1    a
2  <NA> <NA>
3     2    b
4  <NA> <NA>
5     3    c
6  <NA> <NA>
7     4    d
8  <NA> <NA>
9     5    e
10 <NA> <NA>

--

Best,

GG


	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Sun Apr 24 20:30:07 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 24 Apr 2016 18:30:07 +0000
Subject: [R] multiplication by groups
Message-ID: <248E6FA047A8C746BA491485764190F53D3AF342@ESESSMB207.ericsson.se>

df1 <- data.frame(ID = c(1,1,2,2,3,3,4,4,5,5),
                   A = c(1,0,5,1,1,NA,0,3,2,7),
                   B = c(2,3,NA,3,4,NA,1,0,5,NA))

df2 <- data.frame(ID = c(1,2,3,4,5),
                   A = c(1,6,1,3,9),
                   B = c(5,3,4,1,5))

m <- match(df1$ID, df2$ID)

sel <- c("A", "B")

for (i in 1:nrow(df1)) {
  df1[i,sel] <- round(df1[i,sel]/df2[m[i],sel], 2)
}

> df1
   ID    A   B
1   1 1.00 0.4
2   1 0.00 0.6
3   2 0.83  NA
4   2 0.17 1.0
5   3 1.00 1.0
6   3   NA  NA
7   4 0.00 1.0
8   4 1.00 0.0
9   5 0.22 1.0
10  5 0.78  NA
>

--

Best,

GG




	[[alternative HTML version deleted]]


From chalabi.elahe at yahoo.de  Sun Apr 24 20:37:22 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sun, 24 Apr 2016 18:37:22 +0000 (UTC)
Subject: [R] assign color to subsets
In-Reply-To: <1833660678.1930630.1461522990055.JavaMail.yahoo@mail.yahoo.com>
References: <CAAxdm-43BKsaqNe-n-U2cBJQ66Hq9OkM=G3oG-3wUy98=T6z+g@mail.gmail.com>
	<1833660678.1930630.1461522990055.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <40579327.2006127.1461523042765.JavaMail.yahoo@mail.yahoo.com>




my problem is that in Command I have 2229 levels and I want to do subsets based on the names I have in Command. for example if the name has t1 or t2 in it or if it has both of them.and then I need to plot in a way that colors are names with t1,names with t2 and names with both. But now even the grepl I use for the subsets does not work correct! :(((

hast1=grepl("t1", df$Command, fixed=TRUE) 
hast2=grepl("t2", df$Command, fixed=TRUE) 



On Sunday, April 24, 2016 9:16 AM, jim holtman <jholtman at gmail.com> wrote:



You never did provide a reproducible example or say how you wanted to plot.  Here is a way to get a subset of t1 or t2, and you can then use it as input to ggplot:

library(dplyr)
your_subset <- df %>%
          mutate(key = grep(".*(t1|t2).*", "\\1", Command, value = TRUE)) %>%
          filter(!(Command %in% c('t1', 't2')))

This will give you a subset with just t1/t2 and you can use 'key' as the colour option for ggplot.




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Apr 23, 2016 at 4:16 PM, ch.elahe via R-help <r-help at r-project.org> wrote:

Hi
>I have the following df and I created two subsets but I don't know how to use these subsets as the colors of my plot.
>
>
>   data.frame': 36919 obs. of 162 variables
>   $TE           :int 38,41,11,52,48,75,.....
>   $TR           :int 100,210,548,546,.....
>   $Command       :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize"...
>
>and the subsets are names in Command which has t1 or t2 letters:
>
>
>
>  hast1=grepl("t1", df$Command, fixed=TRUE)
>  hast2=grepl("t2", df$Command, fixed=TRUE)
>
>
>the colors I want in my plot are : hast1 and hast2
>Thanks for any help.
>Elahe
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Sun Apr 24 21:18:03 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 24 Apr 2016 15:18:03 -0400
Subject: [R] assign color to subsets
In-Reply-To: <1833660678.1930630.1461522990055.JavaMail.yahoo@mail.yahoo.com>
References: <CAAxdm-43BKsaqNe-n-U2cBJQ66Hq9OkM=G3oG-3wUy98=T6z+g@mail.gmail.com>
	<1833660678.1930630.1461522990055.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-6WwaCQzcSGNCM_TTcBWEGbs0zUS47TK5fUCiZAw0KyKA@mail.gmail.com>

'grepl' returns a logical vector; you have to use this to get your subset.
You can use:

df_tq <- subset(df, grepl("t1", Command))
df_t2 <- subset(df, grepl("t2", Command))

# if you want to also get a subset that has both, use

df_both <- subset(df, grepl("t1", Command) & grepl("t2", Command))




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Apr 24, 2016 at 2:36 PM, <chalabi.elahe at yahoo.de> wrote:

> Thanks Jim,
>
> my problem is that in Command I have 2229 levels and I want to do subsets
> based on the names I have in Command. for example if the name has t1 or t2
> in it or if it has both of them.and then I need to plot in a way that
> colors are names with t1,names with t2 and names with both. But now even
> the grepl I use for the subsets does not work correct! :(((
>
> hast1=grepl("t1", df$Command, fixed=TRUE)
> hast2=grepl("t2", df$Command, fixed=TRUE)
>
>
> On Sunday, April 24, 2016 9:16 AM, jim holtman <jholtman at gmail.com> wrote:
>
>
>
> You never did provide a reproducible example or say how you wanted to
> plot.  Here is a way to get a subset of t1 or t2, and you can then use it
> as input to ggplot:
>
> library(dplyr)
> your_subset <- df %>%
>           mutate(key = grep(".*(t1|t2).*", "\\1", Command, value = TRUE))
> %>%
>           filter(!(Command %in% c('t1', 't2')))
>
> This will give you a subset with just t1/t2 and you can use 'key' as the
> colour option for ggplot.
>
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sat, Apr 23, 2016 at 4:16 PM, ch.elahe via R-help <r-help at r-project.org>
> wrote:
>
> Hi
> >I have the following df and I created two subsets but I don't know how to
> use these subsets as the colors of my plot.
> >
> >
> >   data.frame': 36919 obs. of 162 variables
> >   $TE           :int 38,41,11,52,48,75,.....
> >   $TR           :int 100,210,548,546,.....
> >   $Command       :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize"...
> >
> >and the subsets are names in Command which has t1 or t2 letters:
> >
> >
> >
> >  hast1=grepl("t1", df$Command, fixed=TRUE)
> >  hast2=grepl("t2", df$Command, fixed=TRUE)
> >
> >
> >the colors I want in my plot are : hast1 and hast2
> >Thanks for any help.
> >Elahe
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From jason.hernandez74 at yahoo.com  Sun Apr 24 22:30:13 2016
From: jason.hernandez74 at yahoo.com (Jason Hernandez)
Date: Sun, 24 Apr 2016 20:30:13 +0000 (UTC)
Subject: [R] Using read.csv() to import data
References: <1871485070.1055922.1461529813882.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1871485070.1055922.1461529813882.JavaMail.yahoo@mail.yahoo.com>

I am just beginning to learn R, using _R for Dummies_ by Andrie de Vries and Joris Meys. I am using Windows 7, and RGui (64-bit) version 3.0.2. I have reached the chapter on "Getting Data Into and Out of R." But the code they use for importing data doesn't seem to be working for me.

Their example is:> elements <- read.csv(file.path("f:", "elements.csv"))
Since I don't have any such file, I am trying to use a file I have. I went to Excel, brought up my file titled JPH_data, and saved it as .csv (comma delineated) on my main hard drive C:

Then I entered:>? mammals <- read.csv(file.path("C:", "JPH_data.csv"))
I got the following:Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
? cannot open file 'C:/JPH_data.csv': No such file or directory
Aside from the obvious (how can it say "no such file or directory" when I just saved one such?), the "cannot open the connection" is also unexpected. What am I doing wrong here?
Jason Hernandezno current affiliation

	[[alternative HTML version deleted]]


From raj.devesh99 at gmail.com  Sun Apr 24 19:39:06 2016
From: raj.devesh99 at gmail.com (Devesh Raj Singh)
Date: Sun, 24 Apr 2016 23:09:06 +0530
Subject: [R] How to take a multidimensional data set to higher dimensions
	using R?
Message-ID: <CAOsm4oOxeCpkC8Zs1mN_Rbo_LnwS6mj2Gis4Gh4BubuiPqY2jg@mail.gmail.com>

Hi,

I have a multidimensional data-set( multiple 'x' variables with a target
variable). I want to take it to a higher dimensional space so that I can
apply classification technique with ease . Is there a package in R which
would allow me to take these data points from lower dimensional space to
higher dimensions? so that is that higher dimension I can apply
classification techniques to be effective. My datapoints are highly
inseperable in lower dimension so i want to take the data points to higher
dimension where they can be separable( something similar to kernel trick)

-- 
Warm regards,
Devesh.

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Sun Apr 24 22:58:30 2016
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Sun, 24 Apr 2016 21:58:30 +0100 (BST)
Subject: [R] Fwd: Re:  Using read.csv() to import data
In-Reply-To: <754486261.204849.1461530660831.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
References: <1871485070.1055922.1461529813882.JavaMail.yahoo.ref@mail.yahoo.com>
	<1871485070.1055922.1461529813882.JavaMail.yahoo@mail.yahoo.com>
	<754486261.204849.1461530660831.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
Message-ID: <38167274.205477.1461531510284.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>

You probably have not reset the directory  -- go to the session tab on the R
window, click and go to ?set working directory? as C

Nick

-------- Original Message ----------
From: WRAY NICHOLAS <nicholas.wray at ntlworld.com>
To: Jason Hernandez <jason.hernandez74 at yahoo.com>
Date: 24 April 2016 at 21:44
Subject: Re: [R] Using read.csv() to import data


You probably have not reset the directory  -- go to the session tab on the R
window, click and go to "set working directory" as C

Nick



On 24 April 2016 at 21:30 Jason Hernandez via R-help <r-help at r-project.org>
wrote:


I am just beginning to learn R, using _R for Dummies_ by Andrie de Vries and
Joris Meys. I am using Windows 7, and RGui (64-bit) version 3.0.2. I have
reached the chapter on "Getting Data Into and Out of R." But the code they use
for importing data doesn't seem to be working for me.

Their example is:> elements <- read.csv(file.path("f:", "elements.csv"))
Since I don't have any such file, I am trying to use a file I have. I went to
Excel, brought up my file titled JPH_data, and saved it as .csv (comma
delineated) on my main hard drive C:

Then I entered:>  mammals <- read.csv(file.path("C:", "JPH_data.csv"))
I got the following:Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
  cannot open file 'C:/JPH_data.csv': No such file or directory
Aside from the obvious (how can it say "no such file or directory" when I just
saved one such?), the "cannot open the connection" is also unexpected. What am I
doing wrong here?
Jason Hernandezno current affiliation

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.





	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Apr 24 23:05:00 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 24 Apr 2016 17:05:00 -0400
Subject: [R] Using read.csv() to import data
In-Reply-To: <1871485070.1055922.1461529813882.JavaMail.yahoo@mail.yahoo.com>
References: <1871485070.1055922.1461529813882.JavaMail.yahoo.ref@mail.yahoo.com>
	<1871485070.1055922.1461529813882.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <571D34FC.9050204@gmail.com>

On 24/04/2016 4:30 PM, Jason Hernandez via R-help wrote:
> I am just beginning to learn R, using _R for Dummies_ by Andrie de Vries and Joris Meys. I am using Windows 7, and RGui (64-bit) version 3.0.2. I have reached the chapter on "Getting Data Into and Out of R." But the code they use for importing data doesn't seem to be working for me.
>
> Their example is:> elements <- read.csv(file.path("f:", "elements.csv"))
> Since I don't have any such file, I am trying to use a file I have. I went to Excel, brought up my file titled JPH_data, and saved it as .csv (comma delineated) on my main hard drive C:
>
> Then I entered:>  mammals <- read.csv(file.path("C:", "JPH_data.csv"))
> I got the following:Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>    cannot open file 'C:/JPH_data.csv': No such file or directory
> Aside from the obvious (how can it say "no such file or directory" when I just saved one such?), the "cannot open the connection" is also unexpected. What am I doing wrong here?
> Jason Hernandezno current affiliation

By far the easiest ways to enter Windows file paths are using the 
file.choose() and choose.files() functions.  Do something like

filename <- file.choose() # navigate to the file
mammals <- read.csv(filename)

and you should be fine.  The file.choose() function works on all 
platforms; choose.files() works only on Windows (and has more options, 
including allowing multiple files to be chosen).

Duncan Murdoch


From bgunter.4567 at gmail.com  Sun Apr 24 23:14:54 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 24 Apr 2016 14:14:54 -0700
Subject: [R] How to take a multidimensional data set to higher
 dimensions using R?
In-Reply-To: <CAOsm4oOxeCpkC8Zs1mN_Rbo_LnwS6mj2Gis4Gh4BubuiPqY2jg@mail.gmail.com>
References: <CAOsm4oOxeCpkC8Zs1mN_Rbo_LnwS6mj2Gis4Gh4BubuiPqY2jg@mail.gmail.com>
Message-ID: <CAGxFJbQ+OL1r5HwdN4ZhRsaM=pLbA0zk+9HDF+AXVCzNgsHfgQ@mail.gmail.com>

Many:

https://cran.r-project.org/web/views/MachineLearning.html

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 24, 2016 at 10:39 AM, Devesh Raj Singh
<raj.devesh99 at gmail.com> wrote:
> Hi,
>
> I have a multidimensional data-set( multiple 'x' variables with a target
> variable). I want to take it to a higher dimensional space so that I can
> apply classification technique with ease . Is there a package in R which
> would allow me to take these data points from lower dimensional space to
> higher dimensions? so that is that higher dimension I can apply
> classification techniques to be effective. My datapoints are highly
> inseperable in lower dimension so i want to take the data points to higher
> dimension where they can be separable( something similar to kernel trick)
>
> --
> Warm regards,
> Devesh.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chalabi.elahe at yahoo.de  Sun Apr 24 23:15:27 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sun, 24 Apr 2016 21:15:27 +0000 (UTC)
Subject: [R] assign color to subsets
In-Reply-To: <CAAxdm-6WwaCQzcSGNCM_TTcBWEGbs0zUS47TK5fUCiZAw0KyKA@mail.gmail.com>
References: <CAAxdm-6WwaCQzcSGNCM_TTcBWEGbs0zUS47TK5fUCiZAw0KyKA@mail.gmail.com>
Message-ID: <1947200271.2080829.1461532530551.JavaMail.yahoo@mail.yahoo.com>

now after this:

  
   df_both <- subset(df, grepl("t1", Command) & grepl("t2", Command))

I use factor to apply the subset to df but then the Command level becomes 0


   df_both$Command=factor(df_both$Command)

   str(df_both)
   
   $ Protocol     : Factor w/ 0 levels: 
Do you know what is the reason?
Thanks for replying



On Sunday, April 24, 2016 12:18 PM, jim holtman <jholtman at gmail.com> wrote:



'grepl' returns a logical vector; you have to use this to get your subset.  You can use:

df_tq <- subset(df, grepl("t1", Command))
df_t2 <- subset(df, grepl("t2", Command))

# if you want to also get a subset that has both, use

df_both <- subset(df, grepl("t1", Command) & grepl("t2", Command))





Jim Holtman
Data Munger Guru
 
What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Apr 24, 2016 at 2:36 PM, <chalabi.elahe at yahoo.de> wrote:

Thanks Jim,
>
>my problem is that in Command I have 2229 levels and I want to do subsets based on the names I have in Command. for example if the name has t1 or t2 in it or if it has both of them.and then I need to plot in a way that colors are names with t1,names with t2 and names with both. But now even the grepl I use for the subsets does not work correct! :(((
>
>hast1=grepl("t1", df$Command, fixed=TRUE)
>hast2=grepl("t2", df$Command, fixed=TRUE)
>
>
>On Sunday, April 24, 2016 9:16 AM, jim holtman <jholtman at gmail.com> wrote:
>
>
>
>You never did provide a reproducible example or say how you wanted to plot.  Here is a way to get a subset of t1 or t2, and you can then use it as input to ggplot:
>
>library(dplyr)
>your_subset <- df %>%
>          mutate(key = grep(".*(t1|t2).*", "\\1", Command, value = TRUE)) %>%
>          filter(!(Command %in% c('t1', 't2')))
>
>This will give you a subset with just t1/t2 and you can use 'key' as the colour option for ggplot.
>
>
>
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>On Sat, Apr 23, 2016 at 4:16 PM, ch.elahe via R-help <r-help at r-project.org> wrote:
>
>Hi
>>I have the following df and I created two subsets but I don't know how to use these subsets as the colors of my plot.
>>
>>
>>   data.frame': 36919 obs. of 162 variables
>>   $TE           :int 38,41,11,52,48,75,.....
>>   $TR           :int 100,210,548,546,.....
>>   $Command       :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize"...
>>
>>and the subsets are names in Command which has t1 or t2 letters:
>>
>>
>>
>>  hast1=grepl("t1", df$Command, fixed=TRUE)
>>  hast2=grepl("t2", df$Command, fixed=TRUE)
>>
>>
>>the colors I want in my plot are : hast1 and hast2
>>Thanks for any help.
>>Elahe
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>


From jdnewmil at dcn.davis.ca.us  Sun Apr 24 23:33:34 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 24 Apr 2016 14:33:34 -0700
Subject: [R] How to take a multidimensional data set to higher
	dimensions	using R?
In-Reply-To: <CAOsm4oOxeCpkC8Zs1mN_Rbo_LnwS6mj2Gis4Gh4BubuiPqY2jg@mail.gmail.com>
References: <CAOsm4oOxeCpkC8Zs1mN_Rbo_LnwS6mj2Gis4Gh4BubuiPqY2jg@mail.gmail.com>
Message-ID: <8E9977D5-64D7-4650-8FE6-70C0F05EAFAA@dcn.davis.ca.us>

Isn't the normal way to do this to collect additional independent variables as part of your test protocol? 
-- 
Sent from my phone. Please excuse my brevity.

On April 24, 2016 10:39:06 AM PDT, Devesh Raj Singh <raj.devesh99 at gmail.com> wrote:
>Hi,
>
>I have a multidimensional data-set( multiple 'x' variables with a
>target
>variable). I want to take it to a higher dimensional space so that I
>can
>apply classification technique with ease . Is there a package in R
>which
>would allow me to take these data points from lower dimensional space
>to
>higher dimensions? so that is that higher dimension I can apply
>classification techniques to be effective. My datapoints are highly
>inseperable in lower dimension so i want to take the data points to
>higher
>dimension where they can be separable( something similar to kernel
>trick)
>
>-- 
>Warm regards,
>Devesh.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Apr 25 02:50:23 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 24 Apr 2016 20:50:23 -0400
Subject: [R] assign color to subsets
In-Reply-To: <1947200271.2080829.1461532530551.JavaMail.yahoo@mail.yahoo.com>
References: <CAAxdm-6WwaCQzcSGNCM_TTcBWEGbs0zUS47TK5fUCiZAw0KyKA@mail.gmail.com>
	<1947200271.2080829.1461532530551.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-4te+xqYSk7HHt8qyUBk=ORNU1b1MEHTtVN=xzukcKN7A@mail.gmail.com>

Check the size of df_both.  It would be that there are no Command fields
that contain both a 't1' and 't2'.

You can so do:

sum(grepl("t1", df$Command) & grepl("t2", df$Command))

to see how many Command fields contain both.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Apr 24, 2016 at 5:15 PM, <chalabi.elahe at yahoo.de> wrote:

> now after this:
>
>
>    df_both <- subset(df, grepl("t1", Command) & grepl("t2", Command))
>
> I use factor to apply the subset to df but then the Command level becomes 0
>
>
>    df_both$Command=factor(df_both$Command)
>
>    str(df_both)
>
>    $ Protocol     : Factor w/ 0 levels:
> Do you know what is the reason?
> Thanks for replying
>
>
>
> On Sunday, April 24, 2016 12:18 PM, jim holtman <jholtman at gmail.com>
> wrote:
>
>
>
> 'grepl' returns a logical vector; you have to use this to get your
> subset.  You can use:
>
> df_tq <- subset(df, grepl("t1", Command))
> df_t2 <- subset(df, grepl("t2", Command))
>
> # if you want to also get a subset that has both, use
>
> df_both <- subset(df, grepl("t1", Command) & grepl("t2", Command))
>
>
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sun, Apr 24, 2016 at 2:36 PM, <chalabi.elahe at yahoo.de> wrote:
>
> Thanks Jim,
> >
> >my problem is that in Command I have 2229 levels and I want to do subsets
> based on the names I have in Command. for example if the name has t1 or t2
> in it or if it has both of them.and then I need to plot in a way that
> colors are names with t1,names with t2 and names with both. But now even
> the grepl I use for the subsets does not work correct! :(((
> >
> >hast1=grepl("t1", df$Command, fixed=TRUE)
> >hast2=grepl("t2", df$Command, fixed=TRUE)
> >
> >
> >On Sunday, April 24, 2016 9:16 AM, jim holtman <jholtman at gmail.com>
> wrote:
> >
> >
> >
> >You never did provide a reproducible example or say how you wanted to
> plot.  Here is a way to get a subset of t1 or t2, and you can then use it
> as input to ggplot:
> >
> >library(dplyr)
> >your_subset <- df %>%
> >          mutate(key = grep(".*(t1|t2).*", "\\1", Command, value = TRUE))
> %>%
> >          filter(!(Command %in% c('t1', 't2')))
> >
> >This will give you a subset with just t1/t2 and you can use 'key' as the
> colour option for ggplot.
> >
> >
> >
> >
> >Jim Holtman
> >Data Munger Guru
> >
> >What is the problem that you are trying to solve?
> >Tell me what you want to do, not how you want to do it.
> >
> >On Sat, Apr 23, 2016 at 4:16 PM, ch.elahe via R-help <
> r-help at r-project.org> wrote:
> >
> >Hi
> >>I have the following df and I created two subsets but I don't know how
> to use these subsets as the colors of my plot.
> >>
> >>
> >>   data.frame': 36919 obs. of 162 variables
> >>   $TE           :int 38,41,11,52,48,75,.....
> >>   $TR           :int 100,210,548,546,.....
> >>   $Command       :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize"...
> >>
> >>and the subsets are names in Command which has t1 or t2 letters:
> >>
> >>
> >>
> >>  hast1=grepl("t1", df$Command, fixed=TRUE)
> >>  hast2=grepl("t2", df$Command, fixed=TRUE)
> >>
> >>
> >>the colors I want in my plot are : hast1 and hast2
> >>Thanks for any help.
> >>Elahe
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>

	[[alternative HTML version deleted]]


From sj_style_1125 at outlook.com  Mon Apr 25 03:02:24 2016
From: sj_style_1125 at outlook.com (tan sj)
Date: Mon, 25 Apr 2016 01:02:24 +0000
Subject: [R] R: use switch or function in connecting different cases.
Message-ID: <KL1PR01MB08873169AF0F66A207ADF022B5620@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>

HI, I am trying to use switch () function to connect the three distribution (normal ,gamma with equal skewness and gamma with unequal skewness.

But i am losing my ideas since i have

sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100)

standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50)

distribution of gamma distribution with unequal skewness and equal skewness

several type of setup.

I have finished written 11 codes separately for all of the cases. But i have been told that it can all been done within one code.

can anyone give me a brief idea on it.

I just managed to write till here and it perhaps isnt correct ..

#set up matrix for storing data from simulation

matrix_t  <-matrix(0,nrow=nSims,ncol=3)
matrix_u<-matrix(0,nrow=nSims,ncol=3)
matrix_mann   <-matrix(0,nrow=nSims,ncol=3)

sample_sizes<-

matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
         nrow=2)
    p1<-p2<-p3<-vector()


    nSims<-10
    alpha<-0.05
    set.seed(1)

        simulation<-function(m,n,sds)
        {
    for (ss in 1:dim(sample_sizes[2])){
      m<-[ss,1]
      n<[ss,2]
    for (sim in 1:nSims)
{
m<-c(10,25,50,100)
n<-c(10,25,50,100)
sds<-c(1,1.5,2,2.5,3)

simulation(m=m,n=n,,sds=sds)

p1 <- t.test(x1,y1,var.equal=TRUE)$p.value
p2<-t.test(x1,y1,var.equal=FALSE)$p.value
p3<-wilcox(x1,y1)$p.value

return (c(p1,p2,p3))

}
}

Thanks in advance. I apologises if this is silly question.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Apr 25 05:15:37 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 25 Apr 2016 13:15:37 +1000
Subject: [R] Plotting a large time series
In-Reply-To: <CAATR6d8osHGCts8c=UVQxFGfQd-yeYxsCOd7RE+Tgs0RzM1MAQ@mail.gmail.com>
References: <CAATR6d8osHGCts8c=UVQxFGfQd-yeYxsCOd7RE+Tgs0RzM1MAQ@mail.gmail.com>
Message-ID: <CA+8X3fUoAgdURnbxUid1o1T5uQ1tdv0_O8SyBrewXNndqouJpQ@mail.gmail.com>

Hi Adrian,
This is probably taking a long time. I first tried with 7x10^6 times
and values and it took several minutes. The following code does what I
expected:

amdat<-data.frame(time=1:700000,value=rnorm(700000,-4))
amdat$value[amdat$value<0]<-0
sum(amdat$value)
[1] 5.07101
plot(amdat$time,amdat$value)
plot(amdat$time,amdat$value,type="l")

Perhaps convert the time series to two ordinary vectors?

Jim


On Sat, Apr 23, 2016 at 9:37 PM, Adrian Mcmenamin <acm538 at york.ac.uk> wrote:
> I have a time series with many millions of points.
>
> Each point is of the form (time, value) but where the value is 0 there is
> no record - ie the data set is sparse.
>
> If I plot this using plot(myData) I get a correct plot going from time 0 to
> time 7x10e7.
>
> Given that there are many millions of points (it's not *that* sparse), this
> looks very busy.
>
> But if I attempt to plot this as a line - plot(myData, type="l") - the plot
> is wrong (it looks like solid semi-sinusoidal curves) and although the
> x-axis is drawn from 0 to 7x10e7, the plotting stops at about 3x10e7.
>
> The same thing is seen if I use plot(myData[[1]], myData[[2]], type="l").
>
> If I use plot(myData[[2]], myData[[1]], type="l") I do get a line (albeit
> that the orientation seems odd), but again, while the y-axis is drawn
> between 0 and 7x10e7, the plotting again seems to stop at 3x10e7 or
> thereabouts.
>
> What have I got wrong? How can I get a line (preferably with the standard
> orientation)?
>
> Adrian
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sunnysingha.analytics at gmail.com  Mon Apr 25 08:35:23 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 25 Apr 2016 12:05:23 +0530
Subject: [R] Please assist -- Unable to remove '-' character from char
	vector--
Message-ID: <CANOG_FW9YgRAgfrL7igc2OPYbiUrjkvvc2u9X5ZgvDrS95FwjA@mail.gmail.com>

Hi,
I have a char vector with year values. Some cells have single year
value '2001-' and some have range like 1996-2007.
I need to remove hyphen character '-' from all the values within the
character vector named as 'end'. After removing the hyphen I need to
get the last
number from the cells where there are year range values i.e if the
cell has range 1996-2007, the code should return me 2007.

How could I get this done?

 Below are the values within this char vector:

> end
 [1] "2001-"            "1992-"            "2013-"            "2013-"
          "2013-"            "2013-"
 [7] "2003-"            "2010-"            "2009-"            "1986-"
          "2012-"            "2003-"
[13] "2005-"            "2013-"            "2003-"            "2013-"
          "1993?2007, 2010-" "2012-"
[19] "1984?1992, 1996-" "2015-"            "2009-"            "2000-"
          "2005-"            "1997-"
[25] "2012-"            "1997-"            "2002-"            "2006-"
          "1992-"            "2007-"
[31] "1997-"            "1982-"            "2015-"            "2015-"
          "2010-"            "1996?2007, 2011-"
[37] "2004-"            "1999-"            "2007-"            "1996-"
          "2013-"            "2012-"
[43] "2012-"            "2010-"            "2011-"            "1994-"
          "2014-"

I tried below command--> gsub('[-|,]', '', end)
This did remove all the hyphen character but not from cells having
range year values.Below is the result after executing above command:
As you see hypphen character is removed from single values but not
from ranges. Please guide.

> gsub('[-|,]', '', end)
 [1] "2001"           "1992"           "2013"           "2013"
  "2013"           "2013"           "2003"
 [8] "2010"           "2009"           "1986"           "2012"
  "2003"           "2005"           "2013"
[15] "2003"           "2013"           "1993?2007 2010" "2012"
  "1984?1992 1996" "2015"           "2009"
[22] "2000"           "2005"           "1997"           "2012"
  "1997"           "2002"           "2006"
[29] "1992"           "2007"           "1997"           "1982"
  "2015"           "2015"           "2010"
[36] "1996?2007 2011" "2004"           "1999"           "2007"
  "1996"           "2013"           "2012"
[43] "2012"           "2010"           "2011"           "1994"
  "2014"

Regards,
Sunny Singha


From petr.pikal at precheza.cz  Mon Apr 25 08:45:04 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 25 Apr 2016 06:45:04 +0000
Subject: [R] Splitting Numerical Vector Into Chunks
In-Reply-To: <CY1PR0101MB1004EE71435922B6540E5896AB600@CY1PR0101MB1004.prod.exchangelabs.com>
References: <CY1PR0101MB10046C9003C13DD9FCAD4B3FAB6D0@CY1PR0101MB1004.prod.exchangelabs.com>
	<CA+vqiLGU5CqF1QkAOP0h7sobG9ST_4TBZtO1socYAXfHG_OHMA@mail.gmail.com>
	<CAF8bMcbF0t75+nyrvOVQtautB7-mg9zMOWy5YXww3gyZQcWpsA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50274A7@SRVEXCHMBX.precheza.cz>
	<CY1PR0101MB1004EE71435922B6540E5896AB600@CY1PR0101MB1004.prod.exchangelabs.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5027D10@SRVEXCHMBX.precheza.cz>

Hi

Is this

http://stackoverflow.com/questions/2150138/how-to-parse-milliseconds-in-r

what do you want?

Cheers
Petr


> -----Original Message-----
> From: Sidoti, Salvatore A. [mailto:sidoti.23 at buckeyemail.osu.edu]
> Sent: Sunday, April 24, 2016 1:48 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>; William Dunlap
> <wdunlap at tibco.com>; Ista Zahn <istazahn at gmail.com>
> Subject: RE: [R] Splitting Numerical Vector Into Chunks
>
> There are terrific suggestions and I so appreciate everyone's help!
>
> Just one additional question: I also have some time data that accompanies
> this analysis. It is in the format h:m:s:00 where the last item is hundreths of a
> second. I tried various things with the date and time functions in R, but I have
> not found a way to convert the vetor into a workable time class.
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Thursday, April 21, 2016 4:13 AM
> To: William Dunlap <wdunlap at tibco.com>; Ista Zahn <istazahn at gmail.com>
> Cc: Sidoti, Salvatore A. <sidoti.23 at buckeyemail.osu.edu>
> Subject: RE: [R] Splitting Numerical Vector Into Chunks
>
> Hi
>
> Another aproach is to use diff to find steps.
>
> split(x, cumsum(abs(c(1,diff(x==0)))))
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > William Dunlap via R-help
> > Sent: Wednesday, April 20, 2016 9:56 PM
> > To: Ista Zahn <istazahn at gmail.com>
> > Cc: r-help at r-project.org; Sidoti, Salvatore A.
> > <sidoti.23 at buckeyemail.osu.edu>
> > Subject: Re: [R] Splitting Numerical Vector Into Chunks
> >
> > > i <- seq_len(length(x)-1)
> > > split(x, cumsum(c(TRUE, (x[i]==0) != (x[i+1]==0))))
> > $`1`
> > [1] 0.144872972504 0.850797178400
> >
> > $`2`
> > [1] 0 0 0
> >
> > $`3`
> > [1] 0.199304859380 2.063609410700 0.939393760782 0.838781367540
> >
> > $`4`
> > [1] 0 0 0 0 0
> >
> > $`5`
> > [1] 0.374688091264 0.488423999452 0.783034615362 0.626990428900
> > 0.138188255307 2.324635712186
> >
> > $`6`
> > [1] 0 0 0 0 0 0 0
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Wed, Apr 20, 2016 at 12:49 PM, Ista Zahn <istazahn at gmail.com> wrote:
> >
> > > Perhaps
> > >
> > > x <- split(x, x == 0)
> > >
> > > Best,
> > > Ista
> > >
> > > On Wed, Apr 20, 2016 at 9:40 AM, Sidoti, Salvatore A.
> > > <sidoti.23 at buckeyemail.osu.edu> wrote:
> > > > Greetings!
> > > >
> > > > I have several large data sets of animal movements. Their pauses
> > > > (zero
> > > magnitude vectors) are of particular interest in addition to the
> > > speed distributions that precede the periods of rest. Here is an
> > > example of the kind of data I am interested in analyzing:
> > > >
> > > > x <-
> > > abs(c(rnorm(2),replicate(3,0),rnorm(4),replicate(5,0),rnorm(6),repli
> > > ca
> > > te(7,0)))
> > > > length(x)
> > > >
> > > > This example has 27 elements with strings of zeroes (pauses)
> > > > situated
> > > among the speed values.
> > > > Is there a way to split the vector into zero and nonzero chunks
> > > > and
> > > store them in a form where they can be analyzed? I have tried
> > > various forms of split() to no avail.
> > > >
> > > > Thank you!
> > > > Salvatore A. Sidoti
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen?
> jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze
> sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a
> to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m
> dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost
> ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo
> p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender.
> Delete the contents of this e-mail with all attachments and its copies from
> your system.
> If you are not the intended recipient of this e-mail, you are not authorized to
> use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused
> by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately
> accept such offer; The sender of this e-mail (offer) excludes any acceptance
> of the offer on the part of the recipient containing any amendment or
> variation.
> - the sender insists on that the respective contract is concluded only upon an
> express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into
> any contracts on behalf of the company except for cases in which he/she is
> expressly authorized to do so in writing, and such authorization or power of
> attorney is submitted to the recipient or the person represented by the
> recipient, or the existence of such authorization is known to the recipient of
> the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Mon Apr 25 09:09:45 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 25 Apr 2016 17:09:45 +1000
Subject: [R] Please assist -- Unable to remove '-' character from char
	vector--
In-Reply-To: <CANOG_FW9YgRAgfrL7igc2OPYbiUrjkvvc2u9X5ZgvDrS95FwjA@mail.gmail.com>
References: <CANOG_FW9YgRAgfrL7igc2OPYbiUrjkvvc2u9X5ZgvDrS95FwjA@mail.gmail.com>
Message-ID: <CA+8X3fVGfp8VfxVJrr9hTTMZWb7kSSztOH9BnWEDQb4d6+VvQg@mail.gmail.com>

Hi Sunny,
Try this:

# notice that I have replaced the fancy hyphens with real hyphens
end<-c("2001-","1992-","2013-","2013-","2013-","2013-",
 "1993-2007","2010-","2012-","1984-1992","1996-","2015-")
splitends<-sapply(end,strsplit,"-")
last_bit(x) return(x[length(x)])
sapply(splitends,last_bit)

Jim

On Mon, Apr 25, 2016 at 4:35 PM, Sunny Singha
<sunnysingha.analytics at gmail.com> wrote:
> Hi,
> I have a char vector with year values. Some cells have single year
> value '2001-' and some have range like 1996-2007.
> I need to remove hyphen character '-' from all the values within the
> character vector named as 'end'. After removing the hyphen I need to
> get the last
> number from the cells where there are year range values i.e if the
> cell has range 1996-2007, the code should return me 2007.
>
> How could I get this done?
>
>  Below are the values within this char vector:
>
>> end
>  [1] "2001-"            "1992-"            "2013-"            "2013-"
>           "2013-"            "2013-"
>  [7] "2003-"            "2010-"            "2009-"            "1986-"
>           "2012-"            "2003-"
> [13] "2005-"            "2013-"            "2003-"            "2013-"
>           "1993?2007, 2010-" "2012-"
> [19] "1984?1992, 1996-" "2015-"            "2009-"            "2000-"
>           "2005-"            "1997-"
> [25] "2012-"            "1997-"            "2002-"            "2006-"
>           "1992-"            "2007-"
> [31] "1997-"            "1982-"            "2015-"            "2015-"
>           "2010-"            "1996?2007, 2011-"
> [37] "2004-"            "1999-"            "2007-"            "1996-"
>           "2013-"            "2012-"
> [43] "2012-"            "2010-"            "2011-"            "1994-"
>           "2014-"
>
> I tried below command--> gsub('[-|,]', '', end)
> This did remove all the hyphen character but not from cells having
> range year values.Below is the result after executing above command:
> As you see hypphen character is removed from single values but not
> from ranges. Please guide.
>
>> gsub('[-|,]', '', end)
>  [1] "2001"           "1992"           "2013"           "2013"
>   "2013"           "2013"           "2003"
>  [8] "2010"           "2009"           "1986"           "2012"
>   "2003"           "2005"           "2013"
> [15] "2003"           "2013"           "1993?2007 2010" "2012"
>   "1984?1992 1996" "2015"           "2009"
> [22] "2000"           "2005"           "1997"           "2012"
>   "1997"           "2002"           "2006"
> [29] "1992"           "2007"           "1997"           "1982"
>   "2015"           "2015"           "2010"
> [36] "1996?2007 2011" "2004"           "1999"           "2007"
>   "1996"           "2013"           "2012"
> [43] "2012"           "2010"           "2011"           "1994"
>   "2014"
>
> Regards,
> Sunny Singha
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Apr 25 09:59:35 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 25 Apr 2016 07:59:35 +0000
Subject: [R] Please assist -- Unable to remove '-' character from
	char	vector--
In-Reply-To: <CA+8X3fVGfp8VfxVJrr9hTTMZWb7kSSztOH9BnWEDQb4d6+VvQg@mail.gmail.com>
References: <CANOG_FW9YgRAgfrL7igc2OPYbiUrjkvvc2u9X5ZgvDrS95FwjA@mail.gmail.com>
	<CA+8X3fVGfp8VfxVJrr9hTTMZWb7kSSztOH9BnWEDQb4d6+VvQg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5027DDB@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Monday, April 25, 2016 9:10 AM
> To: Sunny Singha <sunnysingha.analytics at gmail.com>
> Cc: r-help <r-help at r-project.org>; Sandeep Singha
> <sandeep.singha at acrotrend.com>
> Subject: Re: [R] Please assist -- Unable to remove '-' character from char
> vector--
>
> Hi Sunny,
> Try this:
>
> # notice that I have replaced the fancy hyphens with real hyphens
> end<-c("2001-","1992-","2013-","2013-","2013-","2013-",
>  "1993-2007","2010-","2012-","1984-1992","1996-","2015-")
> splitends<-sapply(end,strsplit,"-")

> last_bit(x) return(x[length(x)])

You probably meant
last_bit <- function(x) return(x[length(x)])

> sapply(splitends,last_bit)

And good finalisation is

as.numeric(sapply(splitends,last_bit))

Cheers
Petr

>
> Jim
>
> On Mon, Apr 25, 2016 at 4:35 PM, Sunny Singha
> <sunnysingha.analytics at gmail.com> wrote:
> > Hi,
> > I have a char vector with year values. Some cells have single year
> > value '2001-' and some have range like 1996-2007.
> > I need to remove hyphen character '-' from all the values within the
> > character vector named as 'end'. After removing the hyphen I need to
> > get the last
> > number from the cells where there are year range values i.e if the
> > cell has range 1996-2007, the code should return me 2007.
> >
> > How could I get this done?
> >
> >  Below are the values within this char vector:
> >
> >> end
> >  [1] "2001-"            "1992-"            "2013-"            "2013-"
> >           "2013-"            "2013-"
> >  [7] "2003-"            "2010-"            "2009-"            "1986-"
> >           "2012-"            "2003-"
> > [13] "2005-"            "2013-"            "2003-"            "2013-"
> >           "1993?2007, 2010-" "2012-"
> > [19] "1984?1992, 1996-" "2015-"            "2009-"            "2000-"
> >           "2005-"            "1997-"
> > [25] "2012-"            "1997-"            "2002-"            "2006-"
> >           "1992-"            "2007-"
> > [31] "1997-"            "1982-"            "2015-"            "2015-"
> >           "2010-"            "1996?2007, 2011-"
> > [37] "2004-"            "1999-"            "2007-"            "1996-"
> >           "2013-"            "2012-"
> > [43] "2012-"            "2010-"            "2011-"            "1994-"
> >           "2014-"
> >
> > I tried below command--> gsub('[-|,]', '', end)
> > This did remove all the hyphen character but not from cells having
> > range year values.Below is the result after executing above command:
> > As you see hypphen character is removed from single values but not
> > from ranges. Please guide.
> >
> >> gsub('[-|,]', '', end)
> >  [1] "2001"           "1992"           "2013"           "2013"
> >   "2013"           "2013"           "2003"
> >  [8] "2010"           "2009"           "1986"           "2012"
> >   "2003"           "2005"           "2013"
> > [15] "2003"           "2013"           "1993?2007 2010" "2012"
> >   "1984?1992 1996" "2015"           "2009"
> > [22] "2000"           "2005"           "1997"           "2012"
> >   "1997"           "2002"           "2006"
> > [29] "1992"           "2007"           "1997"           "1982"
> >   "2015"           "2015"           "2010"
> > [36] "1996?2007 2011" "2004"           "1999"           "2007"
> >   "1996"           "2013"           "2012"
> > [43] "2012"           "2010"           "2011"           "1994"
> >   "2014"
> >
> > Regards,
> > Sunny Singha
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sunnysingha.analytics at gmail.com  Mon Apr 25 11:32:24 2016
From: sunnysingha.analytics at gmail.com (Sunny Singha)
Date: Mon, 25 Apr 2016 15:02:24 +0530
Subject: [R] Please assist -- Unable to remove '-' character from char
	vector--
In-Reply-To: <CA+8X3fVGfp8VfxVJrr9hTTMZWb7kSSztOH9BnWEDQb4d6+VvQg@mail.gmail.com>
References: <CANOG_FW9YgRAgfrL7igc2OPYbiUrjkvvc2u9X5ZgvDrS95FwjA@mail.gmail.com>
	<CA+8X3fVGfp8VfxVJrr9hTTMZWb7kSSztOH9BnWEDQb4d6+VvQg@mail.gmail.com>
Message-ID: <CANOG_FXYua_qSEp17PyedX4pNAofmNznQK8VTecjHt=or=iGxA@mail.gmail.com>

Thank you Jim,
The code did assist me to get the what I needed.
Also, I learnt that there are different types of dashes
(en-dash/em-dash/hyphen) as explained on this site :
http://www.punctuationmatters.com/hyphen-dash-n-dash-and-m-dash/

I achieved it by executing below command after going through this page
on stackoverflow:
http://stackoverflow.com/questions/9223795/how-to-correctly-deal-with-escaped-unicode-characters-in-r-e-g-the-em-dash

splitends<-sapply(end,strsplit,"-|\u2013|,")

where '\u2013' is, i guess, the unicode for en-dash/em-dash character
in the ranges values.
I had scrapped the HTML table from this web page :
https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger
and range values does have en-dash characters.

For now the issue is resolved but how does one capture values similar
to  '\u2013' for other possible special cases to be specified in the
regex ?

Regards,
Sunny Singha.


On Mon, Apr 25, 2016 at 12:39 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Sunny,
> Try this:
>
> # notice that I have replaced the fancy hyphens with real hyphens
> end<-c("2001-","1992-","2013-","2013-","2013-","2013-",
>  "1993-2007","2010-","2012-","1984-1992","1996-","2015-")
> splitends<-sapply(end,strsplit,"-")
> last_bit(x) return(x[length(x)])
> sapply(splitends,last_bit)
>
> Jim
>
> On Mon, Apr 25, 2016 at 4:35 PM, Sunny Singha
> <sunnysingha.analytics at gmail.com> wrote:
>> Hi,
>> I have a char vector with year values. Some cells have single year
>> value '2001-' and some have range like 1996-2007.
>> I need to remove hyphen character '-' from all the values within the
>> character vector named as 'end'. After removing the hyphen I need to
>> get the last
>> number from the cells where there are year range values i.e if the
>> cell has range 1996-2007, the code should return me 2007.
>>
>> How could I get this done?
>>
>>  Below are the values within this char vector:
>>
>>> end
>>  [1] "2001-"            "1992-"            "2013-"            "2013-"
>>           "2013-"            "2013-"
>>  [7] "2003-"            "2010-"            "2009-"            "1986-"
>>           "2012-"            "2003-"
>> [13] "2005-"            "2013-"            "2003-"            "2013-"
>>           "1993?2007, 2010-" "2012-"
>> [19] "1984?1992, 1996-" "2015-"            "2009-"            "2000-"
>>           "2005-"            "1997-"
>> [25] "2012-"            "1997-"            "2002-"            "2006-"
>>           "1992-"            "2007-"
>> [31] "1997-"            "1982-"            "2015-"            "2015-"
>>           "2010-"            "1996?2007, 2011-"
>> [37] "2004-"            "1999-"            "2007-"            "1996-"
>>           "2013-"            "2012-"
>> [43] "2012-"            "2010-"            "2011-"            "1994-"
>>           "2014-"
>>
>> I tried below command--> gsub('[-|,]', '', end)
>> This did remove all the hyphen character but not from cells having
>> range year values.Below is the result after executing above command:
>> As you see hypphen character is removed from single values but not
>> from ranges. Please guide.
>>
>>> gsub('[-|,]', '', end)
>>  [1] "2001"           "1992"           "2013"           "2013"
>>   "2013"           "2013"           "2003"
>>  [8] "2010"           "2009"           "1986"           "2012"
>>   "2003"           "2005"           "2013"
>> [15] "2003"           "2013"           "1993?2007 2010" "2012"
>>   "1984?1992 1996" "2015"           "2009"
>> [22] "2000"           "2005"           "1997"           "2012"
>>   "1997"           "2002"           "2006"
>> [29] "1992"           "2007"           "1997"           "1982"
>>   "2015"           "2015"           "2010"
>> [36] "1996?2007 2011" "2004"           "1999"           "2007"
>>   "1996"           "2013"           "2012"
>> [43] "2012"           "2010"           "2011"           "1994"
>>   "2014"
>>
>> Regards,
>> Sunny Singha
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From kcoburn at ucmerced.edu  Sun Apr 24 23:45:10 2016
From: kcoburn at ucmerced.edu (Katie Coburn)
Date: Sun, 24 Apr 2016 14:45:10 -0700
Subject: [R] [R-pkgs] New package: weightr (v. 1.0.0)
Message-ID: <CAB7cXUKeiDkxd1TJdjBRGMgRzMkaLhJOoErcX4Ou80yHK=Dysw@mail.gmail.com>

Greetings, R users!

I'm excited and pleased to announce that the weightr package was
released to CRAN today:

https://cran.r-project.org/web/packages/weightr/

Our package provides a function for meta-analysts to implement the
Vevea and Hedges (1995) weight-function model for publication bias in
R and, by specifying an additional argument, to implement the modified
Vevea and Woods (2005) version as well. We were inspired by Wolfgang
Viechtbauer's fantastic metafor package, and have formatted our output
similarly.

The package also includes a function to launch the Shiny app that
implements both of these models locally. For anyone interested who
wants to preview the Shiny app without installing the package, it's
available online here:

https://vevealab.shinyapps.io/WeightFunctionModel/

Thanks for your time, and I hope the package is useful to you! If you
encounter any problems or have feedback, please feel free to contact
me at kcoburn at ucmerced.edu.

Katie Coburn - Graduate Student, Quantitative Psychology,
University of California, Merced

Dr. Jack Vevea - Associate Professor, Quantitative Psychology,
University of California, Merced

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dcarlson at tamu.edu  Mon Apr 25 16:42:07 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 25 Apr 2016 14:42:07 +0000
Subject: [R] Inserting a blank row to every other row
In-Reply-To: <CAGxFJbTo8agB=V6B9KHkcHapgR4cU9H5z0hO6NeKD0K=D7b6HQ@mail.gmail.com>
References: <217909546.876702.1461499349660.JavaMail.yahoo.ref@mail.yahoo.com>
	<217909546.876702.1461499349660.JavaMail.yahoo@mail.yahoo.com>
	<CAKVAULOVP_PEbRdb=6NjVKqNTkUd5iT_6KE+bhpZHtn_wMP86g@mail.gmail.com>
	<CAGxFJbRJAEGvciFFVJ5bxX_eNL3usoUk6tOUz2gHbcSLtOOyBA@mail.gmail.com>
	<CAGxFJbTo8agB=V6B9KHkcHapgR4cU9H5z0hO6NeKD0K=D7b6HQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72E9DC@mb02.ads.tamu.edu>

This is basically Bert's solution, but simplifying one line.

> z <- data.frame(a=1:3,b = letters[1:3])
> i <- seq_len(nrow(z))
> z <- dat[rep(i, each=2), ]
> is.na(z[i*2, ]) <- TRUE
> z
     a    b
1    1    a
1.1 NA <NA>
2    2    b
2.1 NA <NA>
3    3    c
3.1 NA <NA>

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Sunday, April 24, 2016 11:13 AM
To: Ulrik Stervbo
Cc: R-help Mailing List
Subject: Re: [R] Inserting a blank row to every other row

Oh, sorry, I just realized that I messed up the indicing. Here is the
correct way:

> z <- data.frame(a=1:3,b = letters[1:3])
>  i <- seq_len(nrow(z))
>  z<-z[rep(i,e=2),]
>  z[2*i, ] <- matrix(NA, nr=nrow(z),nc=ncol(z))
>  z

Still doubt that this is a good idea, though.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 24, 2016 at 8:53 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Well, something like this would work (there may be slicker solutions):
>
>> z <- data.frame(a=1:3,b = letters[1:3])
>> i <- seq_len(nrow(z)) *2
>> z <-rbind(z,z)
>> z[i, ] <- matrix(NA, nr=nrow(z),nc=ncol(z))
>> z
>    a    b
> 1  1    a
> 2 NA <NA>
> 3  3    c
> 4 NA <NA>
> 5  2    b
> 6 NA <NA>
>
> But I agree with you that there is probably a way to handle the
> underlying issues that does not require this kind of artifice.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Apr 24, 2016 at 8:21 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>> Hi Saba,
>>
>> I don't know how to do what you want and I also cannot see why.
>>
>> If you describe what you hope to achieve there might be a different
>> solution.
>>
>> Best wishes
>> Ulrik
>>
>> Saba Sehrish via R-help <r-help at r-project.org> schrieb am So., 24. Apr.
>> 2016 14:04:
>>
>>> Hi
>>>
>>> I need to insert a blank row after every row in R data frame. I have
>>> achieved it through:
>>>
>>>
>>> df[rep(1:nrow(df),1,each=2),]
>>>
>>> But it inserts a row with name of previous row, while i want a complete
>>> blank row without any name/title.
>>>
>>> Please guide me
>>>
>>> Regards
>>> Saba
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Apr 25 17:02:19 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 25 Apr 2016 15:02:19 +0000
Subject: [R] Using read.csv() to import data
In-Reply-To: <571D34FC.9050204@gmail.com>
References: <1871485070.1055922.1461529813882.JavaMail.yahoo.ref@mail.yahoo.com>
	<1871485070.1055922.1461529813882.JavaMail.yahoo@mail.yahoo.com>
	<571D34FC.9050204@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72EA46@mb02.ads.tamu.edu>

You can also use getwd() to see what folder/directory R is currently using and setwd("folder") to change it. Also list.files() lists all of the files in that current directory. 

The code you included assumes that the file is located in the root directory which is probably wrong. Try 

mammals <- read.csv("JPH_data.csv")

If you are just starting out learning R, you can create a directory to use with the book by  using the dir.create() function:

dir.create("LearnR")
setwd("LearnR")

This will create a new folder in your default folder (probably called "My Documents"). Whenever you start R run setwd("LearnR") first so that anything you save goes in that folder. If you create .csv files, put them in that folder and R will find them easily. Also all of your R files will be in one place making them easier to find.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Sunday, April 24, 2016 4:05 PM
To: Jason Hernandez; r-help at r-project.org
Subject: Re: [R] Using read.csv() to import data

On 24/04/2016 4:30 PM, Jason Hernandez via R-help wrote:
> I am just beginning to learn R, using _R for Dummies_ by Andrie de Vries and Joris Meys. I am using Windows 7, and RGui (64-bit) version 3.0.2. I have reached the chapter on "Getting Data Into and Out of R." But the code they use for importing data doesn't seem to be working for me.
>
> Their example is:> elements <- read.csv(file.path("f:", "elements.csv"))
> Since I don't have any such file, I am trying to use a file I have. I went to Excel, brought up my file titled JPH_data, and saved it as .csv (comma delineated) on my main hard drive C:
>
> Then I entered:>  mammals <- read.csv(file.path("C:", "JPH_data.csv"))
> I got the following:Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>    cannot open file 'C:/JPH_data.csv': No such file or directory
> Aside from the obvious (how can it say "no such file or directory" when I just saved one such?), the "cannot open the connection" is also unexpected. What am I doing wrong here?
> Jason Hernandezno current affiliation

By far the easiest ways to enter Windows file paths are using the 
file.choose() and choose.files() functions.  Do something like

filename <- file.choose() # navigate to the file
mammals <- read.csv(filename)

and you should be fine.  The file.choose() function works on all 
platforms; choose.files() works only on Windows (and has more options, 
including allowing multiple files to be chosen).

Duncan Murdoch

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sj_style_1125 at outlook.com  Mon Apr 25 18:17:22 2016
From: sj_style_1125 at outlook.com (s ji)
Date: Mon, 25 Apr 2016 16:17:22 +0000
Subject: [R] use switch or function in connecting different cases.
In-Reply-To: <KL1PR01MB08873169AF0F66A207ADF022B5620@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB08873169AF0F66A207ADF022B5620@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
Message-ID: <HK2PR01MB0881E612E34A17534558E83EB5620@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>

This is my current work.Now i am trying to use a function to do the normal distribution simulation.

rm(list=ls())

t <- u<- mann<- rep(0, 45)

        Nsimulation<-function(S1,S2,Sds,nSims)
        { 
         set.seed(1)
           for (sim in 1:nSims)
            {
             matrix_t <-matrix(0,nrow=nSims,ncol=3)
             matrix_u<-matrix(0,nrow=nSims,ncol=3)
             matrix_mann <-matrix(0,nrow=nSims,ncol=3)

            #generate random samples from 2 normal distribution
             x<-rnorm(S1,5,Sds)
             y<-rnorm(S2,5,4)
     
            #extract p-value out and store every p-value into matrix
            matrix_t[sim,1]<-t.test(x,y,var.equal=TRUE)$p.value 
            matrix_u[sim,2]<-t.test(x,y,var.equal=FALSE)$p.value
            matrix_mann[sim,3] <-wilcox.test(x,y)$p.value 
             
            print ("sim")
             print(matrix_t)
             print(matrix_u)
            print(matrix_mann) 
            cbind(matrix_t,matrix_u,matrix_mann)
          
            t[sim]<-sum(matrix_t[,1]<0.05)
            u[sim]<-sum(matrix_u[,2]<0.05)
            mann[sim]<-sum(matrix_mann[,3]<0.05)
            print(t)
            print(u)
             }
            return(list(t=t,u=u,mann=mann))
            } 
    
s<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
         nrow=2)
s1<-rep(c(10,10,25,25,25,50,50,100,100),5)
s2<-rep(c(10,25,25,50,100,25,100,25,100),5)
sds<-rep(c(1,1.5,2,2.5,3),9)
all<-cbind(s1,s2,sds)

R<-Nsimulation(S1=s1,S2=s2,Sds=sds,nSims=5)

But the result didnt update itself..Any comment please?

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of tan sj <sj_style_1125 at outlook.com>
Sent: Monday, April 25, 2016 1:02 AM
To: r-help at r-project.org
Subject: [R] R: use switch or function in connecting different cases.

HI, I am trying to use switch () function to connect the three distribution (normal ,gamma with equal skewness and gamma with unequal skewness.

But i am losing my ideas since i have

sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100)

standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50)

distribution of gamma distribution with unequal skewness and equal skewness

several type of setup.

I have finished written 11 codes separately for all of the cases. But i have been told that it can all been done within one code.

can anyone give me a brief idea on it.

I just managed to write till here and it perhaps isnt correct ..

#set up matrix for storing data from simulation

matrix_t  <-matrix(0,nrow=nSims,ncol=3)
matrix_u<-matrix(0,nrow=nSims,ncol=3)
matrix_mann   <-matrix(0,nrow=nSims,ncol=3)

sample_sizes<-

matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
         nrow=2)
    p1<-p2<-p3<-vector()


    nSims<-10
    alpha<-0.05
    set.seed(1)

        simulation<-function(m,n,sds)
        {
    for (ss in 1:dim(sample_sizes[2])){
      m<-[ss,1]
      n<[ss,2]
    for (sim in 1:nSims)
{
m<-c(10,25,50,100)
n<-c(10,25,50,100)
sds<-c(1,1.5,2,2.5,3)

simulation(m=m,n=n,,sds=sds)

p1 <- t.test(x1,y1,var.equal=TRUE)$p.value
p2<-t.test(x1,y1,var.equal=FALSE)$p.value
p3<-wilcox(x1,y1)$p.value

return (c(p1,p2,p3))

}
}

Thanks in advance. I apologises if this is silly question.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dcarlson at tamu.edu  Mon Apr 25 18:46:58 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 25 Apr 2016 16:46:58 +0000
Subject: [R] use switch or function in connecting different cases.
In-Reply-To: <HK2PR01MB0881E612E34A17534558E83EB5620@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB08873169AF0F66A207ADF022B5620@KL1PR01MB0887.apcprd01.prod.exchangelabs.com>
	<HK2PR01MB0881E612E34A17534558E83EB5620@HK2PR01MB0881.apcprd01.prod.exchangelabs.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72EB83@mb02.ads.tamu.edu>

What do you mean by "it didnt update itself?"

You will get the same results on each run since you set the random seed to 1 when you call the function. As a result, each time you will get the same results.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of s ji
Sent: Monday, April 25, 2016 11:17 AM
To: r-help at r-project.org
Subject: Re: [R] use switch or function in connecting different cases.

This is my current work.Now i am trying to use a function to do the normal distribution simulation.

rm(list=ls())

t <- u<- mann<- rep(0, 45)

        Nsimulation<-function(S1,S2,Sds,nSims)
        { 
         set.seed(1)
           for (sim in 1:nSims)
            {
             matrix_t <-matrix(0,nrow=nSims,ncol=3)
             matrix_u<-matrix(0,nrow=nSims,ncol=3)
             matrix_mann <-matrix(0,nrow=nSims,ncol=3)

            #generate random samples from 2 normal distribution
             x<-rnorm(S1,5,Sds)
             y<-rnorm(S2,5,4)
     
            #extract p-value out and store every p-value into matrix
            matrix_t[sim,1]<-t.test(x,y,var.equal=TRUE)$p.value 
            matrix_u[sim,2]<-t.test(x,y,var.equal=FALSE)$p.value
            matrix_mann[sim,3] <-wilcox.test(x,y)$p.value 
             
            print ("sim")
             print(matrix_t)
             print(matrix_u)
            print(matrix_mann) 
            cbind(matrix_t,matrix_u,matrix_mann)
          
            t[sim]<-sum(matrix_t[,1]<0.05)
            u[sim]<-sum(matrix_u[,2]<0.05)
            mann[sim]<-sum(matrix_mann[,3]<0.05)
            print(t)
            print(u)
             }
            return(list(t=t,u=u,mann=mann))
            } 
    
s<-matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
         nrow=2)
s1<-rep(c(10,10,25,25,25,50,50,100,100),5)
s2<-rep(c(10,25,25,50,100,25,100,25,100),5)
sds<-rep(c(1,1.5,2,2.5,3),9)
all<-cbind(s1,s2,sds)

R<-Nsimulation(S1=s1,S2=s2,Sds=sds,nSims=5)

But the result didnt update itself..Any comment please?

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of tan sj <sj_style_1125 at outlook.com>
Sent: Monday, April 25, 2016 1:02 AM
To: r-help at r-project.org
Subject: [R] R: use switch or function in connecting different cases.

HI, I am trying to use switch () function to connect the three distribution (normal ,gamma with equal skewness and gamma with unequal skewness.

But i am losing my ideas since i have

sample sizes-(10,10),(10,25),(25,25),(25,50),(25,100),50,25),(50,100), (100,25),(100,100)

standard deviation ratio- (1.00, 1.50, 2.00, 2.50, 3.00 and 3.50)

distribution of gamma distribution with unequal skewness and equal skewness

several type of setup.

I have finished written 11 codes separately for all of the cases. But i have been told that it can all been done within one code.

can anyone give me a brief idea on it.

I just managed to write till here and it perhaps isnt correct ..

#set up matrix for storing data from simulation

matrix_t  <-matrix(0,nrow=nSims,ncol=3)
matrix_u<-matrix(0,nrow=nSims,ncol=3)
matrix_mann   <-matrix(0,nrow=nSims,ncol=3)

sample_sizes<-

matrix(c(10,10,10,25,25,25,25,50,25,100,50,25,50,100,100,25,100,100),
         nrow=2)
    p1<-p2<-p3<-vector()


    nSims<-10
    alpha<-0.05
    set.seed(1)

        simulation<-function(m,n,sds)
        {
    for (ss in 1:dim(sample_sizes[2])){
      m<-[ss,1]
      n<[ss,2]
    for (sim in 1:nSims)
{
m<-c(10,25,50,100)
n<-c(10,25,50,100)
sds<-c(1,1.5,2,2.5,3)

simulation(m=m,n=n,,sds=sds)

p1 <- t.test(x1,y1,var.equal=TRUE)$p.value
p2<-t.test(x1,y1,var.equal=FALSE)$p.value
p3<-wilcox(x1,y1)$p.value

return (c(p1,p2,p3))

}
}

Thanks in advance. I apologises if this is silly question.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From stephanie.eyssautier at univ-reims.fr  Mon Apr 25 16:53:13 2016
From: stephanie.eyssautier at univ-reims.fr (=?UTF-8?Q?EYSSAUTIER_St=c3=a9phanie?=)
Date: Mon, 25 Apr 2016 16:53:13 +0200
Subject: [R] ylim in barplot()
Message-ID: <571E2F59.10003@univ-reims.fr>

Dear useRs,

I'm having troubles with using ylim in barplot(): even though I reduce 
the y-scale using ylim, the bars still extend down to 0into the x-labels.
The sample data is below, and here is the code.

#This works fine but I would like to plot only from 50 to 70:
barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow", 
"purple"), legend=TRUE, las=2, axis.lty=1)

#This is the ylim version with the bar problem:
barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow", 
"purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1)

#I have tried using xpd=FALSE and this works fine withinRguior Rstudio 
but not when I plot within devEMF::emf()
barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow", 
"purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1, xpd=FALSE)

I need the emf file to edit the plot.

Why isn't it working with ylim alone? And why doesn't xpd work with emf()?

Thanks in advance for your help,
St?phanie


mydata <- structure(c(68.1799689328282, 68.2164021637813, 
68.3243626415103, 61.7899567386469, 59.5182501049449, 63.9916220705152, 
64.1442535260522, 64.2585746423512, 62.5653571705887, 61.631969055001, 
61.3991475513249, 63.2401411727188, 65.0488808306348, 63.43022364909, 
64.8425577471775, 65.4986231824992, 64.7798619682232, 64.4174790601806, 
65.5696701695485, 65.0253962620178, 63.2476885701954, 63.2473647791827, 
62.5000542212819, 63.1742307643225, 62.1560658393146, 62.5810636272476, 
64.0935149828315, 65.5432025084893, 66.7535104579705, 59.6500997601308, 
59.4641686257122, 59.8891527196501, 60.0117050975523, 64.3309521324969, 
62.0079305659785, 57.0665210362419, 57.5202118193362, 61.3280531011031, 
62.6326634763289, 60.2094259175778, 65.5923786551105, 65.6946445059829, 
65.2498254841218, 65.3468620859567, 67.024437492438, 65.8533801964148, 
65.0047369761726, 65.0310208374089, 64.3121920326177, 64.8038153143374, 
63.7306643056964, 64.2579190762784, 67.5745906026732, 67.0351170775703, 
66.4053872920113, 59.9302305698358, 60.368722602391, 60.3572311841096, 
60.0960412312049, 63.7886894551889, 62.24708719601, 59.3334729073243, 
59.9537485303794, 63.1828096654404, 63.5352778562394, 60.621828397375, 
65.8889763819732, 66.2059756115814, 66.4567010911873, 65.8796623180062, 
67.5552743734229, 66.504738660398, 66.2085036370622, 66.4230781907321, 
65.5130180297911, 65.9051623923225, 64.8408013974267, 65.5175045910169, 
68.0760225106606, 66.8615536135711, 65.0390748892256, 59.2940092440695, 
60.7061368898884, 59.7345965097738, 59.6019925755588, 63.6011933836225, 
62.1134684942427, 60.4227073441121, 60.7834352002706, 63.4539745079728, 
63.6329498376672, 58.8034486099638, 65.2910772858539, 65.5952764758513, 
65.8371262481454, 66.1191053038481, 67.5230043279325, 66.8569714429862, 
66.1045642986574, 66.8499631633452, 66.0121950308609, 66.2593339018511, 
65.4397264829666, 65.8389305084859), .Dim = c(26L, 4L), .Dimnames = 
list(c("T40", "T41", "T42", "306iv01", "306iv02", "306iv19", "306iv13", 
"306iv04", "306iv05", "402iv01", "402iv02", "402iv03", "306iv16", 
"306iv10", "TG1", "TG2", "TG3", "TG4", "TG5", "TG6", "TG7", "TG8", 
"TG9", "TG10", "TG11", "TG12"), c("L.mean", "L.mean_T1", "L.mean_T2", 
"L.mean_T3")))


-- 
St?phanie Eyssautier
Ing?nieure d'?tudes
Universit? de REIMS CHAMPAGNE-ARDENNE
Laboratoire GEGENA2
Centre de Recherches en Environnement et Agronomie
2, Esplanade Roland Garros
51100 REIMS

T?l: 03 26 77 36 36
Fax: 03 26 77 36 94


From chlsrocks at yahoo.com  Mon Apr 25 18:05:38 2016
From: chlsrocks at yahoo.com (charles rockson)
Date: Mon, 25 Apr 2016 16:05:38 +0000 (UTC)
Subject: [R]  Using read.csv() to import data
In-Reply-To: <1871485070.1055922.1461529813882.JavaMail.yahoo@mail.yahoo.com>
References: <1871485070.1055922.1461529813882.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1092217925.1790752.1461600338947.JavaMail.yahoo@mail.yahoo.com>

First save your file as csv and then type the following in the console....assignname
assignname=read.csv(file.choose())

This would open up your dcouments file and then you can select the file you saved as csv.
Cheers

      From: Jason Hernandez via R-help <r-help at r-project.org>
 To: "r-help at r-project.org" <r-help at r-project.org> 
 Sent: Sunday, April 24, 2016 1:30 PM
 Subject: [R] Using read.csv() to import data
   
I am just beginning to learn R, using _R for Dummies_ by Andrie de Vries and Joris Meys. I am using Windows 7, and RGui (64-bit) version 3.0.2. I have reached the chapter on "Getting Data Into and Out of R." But the code they use for importing data doesn't seem to be working for me.

Their example is:> elements <- read.csv(file.path("f:", "elements.csv"))
Since I don't have any such file, I am trying to use a file I have. I went to Excel, brought up my file titled JPH_data, and saved it as .csv (comma delineated) on my main hard drive C:

Then I entered:>? mammals <- read.csv(file.path("C:", "JPH_data.csv"))
I got the following:Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
? cannot open file 'C:/JPH_data.csv': No such file or directory
Aside from the obvious (how can it say "no such file or directory" when I just saved one such?), the "cannot open the connection" is also unexpected. What am I doing wrong here?
Jason Hernandezno current affiliation

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Mon Apr 25 19:35:14 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 25 Apr 2016 17:35:14 +0000
Subject: [R] Creating variables on the fly
In-Reply-To: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>
References: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>
Message-ID: <D3439ECF.16FB8B%macqueen1@llnl.gov>

I'm going to assume that Kunden is a data frame, and it has columns
(variables) with names like
  Umstatz_2011
and that you want to create new columns with names like
  Kunde_real_2011

If that is so, then try this (not tested):

for (year in 2011:2015) {
  nmK <- paste0("Kunde_real_", year)
  nmU <- paste0("Umsatz_", year)
  cat('Creating',nmK,'from',nmU,'\n')
  Kunden[[ nmK ]] <- ifelse( Kunden[[ nmU ]] <= 0, 1, 2)
  Kunden[[ nmK ]] <- factor( Kunden[[ nmK ]],
       levels=c(1,2),
       labels= c("NICHT kaufend", "kaufend")
       )

}

This little example should illustrate the method:


> foo <- data.frame(a=1:4)
> foo
  a
1 1
2 2
3 3
4 4
> foo[['b']] <- foo[['a']]*3
> foo
  a  b
1 1  3
2 2  6
3 3  9
4 4 12



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/22/16, 8:52 AM, "R-help on behalf of G.Maubach at gmx.de"
<r-help-bounces at r-project.org on behalf of G.Maubach at gmx.de> wrote:

>Hi all,
>
>I would like to use a loop for tasks that occurs repeatedly:
>
># Groups 
># Umsatz <= 0: 1 (NICHT kaufend)
># Umsatz > 0: 2  (kaufend)
>for (year in c("2011", "2012", "2013", "2014", "2015")) {
>  paste0("Kunden$Kunde_real_", year) <- (paste0("Kunden$Umsatz_", year)
><= 0) * 1 + 
>                                        (paste0("Kunden$Umsatz_", year) >
> 0) * 2 
>  paste0("Kunden$Kunde_real_", year) <- factor(paste0("Kunden$Umsatz_",
>year), 
>                                               levels = c(1, 2),
>                                               labels = c("NICHT
>kaufend", "kaufend"))
>  } 
>
>This actually does not work due to the fact that the expression
>"paste0("Kunden$Kunde_real_", year)" ist not interpreted as a variable
>name by the R script language interpreter.
>
>Is there a way to assembly variable names on the fly in R?
>
>Regards
>
>Georg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Apr 25 21:16:12 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 25 Apr 2016 19:16:12 +0000
Subject: [R] ylim in barplot()
In-Reply-To: <571E2F59.10003@univ-reims.fr>
References: <571E2F59.10003@univ-reims.fr>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72EBD0@mb02.ads.tamu.edu>

If you are using a Windows system, you can Export the plot from RStudio and save it as a metafile without using package devEMF and it will crop the bars with xpd=FALSE. When I used devEMF on a Windows machine, the bars were not cropped with barplot() as you indicated, but when I switched to plotrix::barp() they were cropped. The arguments are a bit different, but I did not need xpd=FALSE:

emf("TestPlot.emf")
barp(t(mydata), col=c("orange", "green", "yellow", "purple"), 
ylim=c(50,70), legend.lab=colnames(mydata), legend.pos="topright")
dev.off()

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of EYSSAUTIER St?phanie
Sent: Monday, April 25, 2016 9:53 AM
To: r-help at r-project.org
Subject: [R] ylim in barplot()

Dear useRs,

I'm having troubles with using ylim in barplot(): even though I reduce 
the y-scale using ylim, the bars still extend down to 0into the x-labels.
The sample data is below, and here is the code.

#This works fine but I would like to plot only from 50 to 70:
barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow", 
"purple"), legend=TRUE, las=2, axis.lty=1)

#This is the ylim version with the bar problem:
barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow", 
"purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1)

#I have tried using xpd=FALSE and this works fine withinRguior Rstudio 
but not when I plot within devEMF::emf()
barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow", 
"purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1, xpd=FALSE)

I need the emf file to edit the plot.

Why isn't it working with ylim alone? And why doesn't xpd work with emf()?

Thanks in advance for your help,
St?phanie


mydata <- structure(c(68.1799689328282, 68.2164021637813, 
68.3243626415103, 61.7899567386469, 59.5182501049449, 63.9916220705152, 
64.1442535260522, 64.2585746423512, 62.5653571705887, 61.631969055001, 
61.3991475513249, 63.2401411727188, 65.0488808306348, 63.43022364909, 
64.8425577471775, 65.4986231824992, 64.7798619682232, 64.4174790601806, 
65.5696701695485, 65.0253962620178, 63.2476885701954, 63.2473647791827, 
62.5000542212819, 63.1742307643225, 62.1560658393146, 62.5810636272476, 
64.0935149828315, 65.5432025084893, 66.7535104579705, 59.6500997601308, 
59.4641686257122, 59.8891527196501, 60.0117050975523, 64.3309521324969, 
62.0079305659785, 57.0665210362419, 57.5202118193362, 61.3280531011031, 
62.6326634763289, 60.2094259175778, 65.5923786551105, 65.6946445059829, 
65.2498254841218, 65.3468620859567, 67.024437492438, 65.8533801964148, 
65.0047369761726, 65.0310208374089, 64.3121920326177, 64.8038153143374, 
63.7306643056964, 64.2579190762784, 67.5745906026732, 67.0351170775703, 
66.4053872920113, 59.9302305698358, 60.368722602391, 60.3572311841096, 
60.0960412312049, 63.7886894551889, 62.24708719601, 59.3334729073243, 
59.9537485303794, 63.1828096654404, 63.5352778562394, 60.621828397375, 
65.8889763819732, 66.2059756115814, 66.4567010911873, 65.8796623180062, 
67.5552743734229, 66.504738660398, 66.2085036370622, 66.4230781907321, 
65.5130180297911, 65.9051623923225, 64.8408013974267, 65.5175045910169, 
68.0760225106606, 66.8615536135711, 65.0390748892256, 59.2940092440695, 
60.7061368898884, 59.7345965097738, 59.6019925755588, 63.6011933836225, 
62.1134684942427, 60.4227073441121, 60.7834352002706, 63.4539745079728, 
63.6329498376672, 58.8034486099638, 65.2910772858539, 65.5952764758513, 
65.8371262481454, 66.1191053038481, 67.5230043279325, 66.8569714429862, 
66.1045642986574, 66.8499631633452, 66.0121950308609, 66.2593339018511, 
65.4397264829666, 65.8389305084859), .Dim = c(26L, 4L), .Dimnames = 
list(c("T40", "T41", "T42", "306iv01", "306iv02", "306iv19", "306iv13", 
"306iv04", "306iv05", "402iv01", "402iv02", "402iv03", "306iv16", 
"306iv10", "TG1", "TG2", "TG3", "TG4", "TG5", "TG6", "TG7", "TG8", 
"TG9", "TG10", "TG11", "TG12"), c("L.mean", "L.mean_T1", "L.mean_T2", 
"L.mean_T3")))


-- 
St?phanie Eyssautier
Ing?nieure d'?tudes
Universit? de REIMS CHAMPAGNE-ARDENNE
Laboratoire GEGENA2
Centre de Recherches en Environnement et Agronomie
2, Esplanade Roland Garros
51100 REIMS

T?l: 03 26 77 36 36
Fax: 03 26 77 36 94

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dwinsemius at comcast.net  Mon Apr 25 21:21:01 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 25 Apr 2016 12:21:01 -0700
Subject: [R] Please assist -- Unable to remove '-' character from char
	vector--
In-Reply-To: <CANOG_FXYua_qSEp17PyedX4pNAofmNznQK8VTecjHt=or=iGxA@mail.gmail.com>
References: <CANOG_FW9YgRAgfrL7igc2OPYbiUrjkvvc2u9X5ZgvDrS95FwjA@mail.gmail.com>
	<CA+8X3fVGfp8VfxVJrr9hTTMZWb7kSSztOH9BnWEDQb4d6+VvQg@mail.gmail.com>
	<CANOG_FXYua_qSEp17PyedX4pNAofmNznQK8VTecjHt=or=iGxA@mail.gmail.com>
Message-ID: <0F29499F-F993-40FB-9875-677D21CEDE24@comcast.net>


> On Apr 25, 2016, at 2:32 AM, Sunny Singha <sunnysingha.analytics at gmail.com> wrote:
> 
> Thank you Jim,
> The code did assist me to get the what I needed.
> Also, I learnt that there are different types of dashes
> (en-dash/em-dash/hyphen) as explained on this site :
> http://www.punctuationmatters.com/hyphen-dash-n-dash-and-m-dash/
> 
> I achieved it by executing below command after going through this page
> on stackoverflow:
> http://stackoverflow.com/questions/9223795/how-to-correctly-deal-with-escaped-unicode-characters-in-r-e-g-the-em-dash
> 
> splitends<-sapply(end,strsplit,"-|\u2013|,")
> 
> where '\u2013' is, i guess, the unicode for en-dash/em-dash character
> in the ranges values.
> I had scrapped the HTML table from this web page :
> https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger
> and range values does have en-dash characters.
> 
> For now the issue is resolved but how does one capture values similar
> to  '\u2013' for other possible special cases to be specified in the
> regex ?

It's possible to target sequences of Unicode characters using a regex character class which does have a sequence operator. (R's sequence operator fails in my efforts.)

x <- "\"em\u2013dash\" \"em?dash\" \" em \u2016 dash\""
gsub('[\u2013:\u2016]', "", x)   # removes both
#[1] "\"emdash\" \"emdash\" \" em  dash\""

-- 
David.
> 
> Regards,
> Sunny Singha.
> 
> 
> On Mon, Apr 25, 2016 at 12:39 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> Hi Sunny,
>> Try this:
>> 
>> # notice that I have replaced the fancy hyphens with real hyphens
>> end<-c("2001-","1992-","2013-","2013-","2013-","2013-",
>> "1993-2007","2010-","2012-","1984-1992","1996-","2015-")
>> splitends<-sapply(end,strsplit,"-")
>> last_bit(x) return(x[length(x)])
>> sapply(splitends,last_bit)
>> 
>> Jim
>> 
>> On Mon, Apr 25, 2016 at 4:35 PM, Sunny Singha
>> <sunnysingha.analytics at gmail.com> wrote:
>>> Hi,
>>> I have a char vector with year values. Some cells have single year
>>> value '2001-' and some have range like 1996-2007.
>>> I need to remove hyphen character '-' from all the values within the
>>> character vector named as 'end'. After removing the hyphen I need to
>>> get the last
>>> number from the cells where there are year range values i.e if the
>>> cell has range 1996-2007, the code should return me 2007.
>>> 
>>> How could I get this done?
>>> 
>>> Below are the values within this char vector:
>>> 
>>>> end
>>> [1] "2001-"            "1992-"            "2013-"            "2013-"
>>>          "2013-"            "2013-"
>>> [7] "2003-"            "2010-"            "2009-"            "1986-"
>>>          "2012-"            "2003-"
>>> [13] "2005-"            "2013-"            "2003-"            "2013-"
>>>          "1993?2007, 2010-" "2012-"
>>> [19] "1984?1992, 1996-" "2015-"            "2009-"            "2000-"
>>>          "2005-"            "1997-"
>>> [25] "2012-"            "1997-"            "2002-"            "2006-"
>>>          "1992-"            "2007-"
>>> [31] "1997-"            "1982-"            "2015-"            "2015-"
>>>          "2010-"            "1996?2007, 2011-"
>>> [37] "2004-"            "1999-"            "2007-"            "1996-"
>>>          "2013-"            "2012-"
>>> [43] "2012-"            "2010-"            "2011-"            "1994-"
>>>          "2014-"
>>> 
>>> I tried below command--> gsub('[-|,]', '', end)
>>> This did remove all the hyphen character but not from cells having
>>> range year values.Below is the result after executing above command:
>>> As you see hypphen character is removed from single values but not
>>> from ranges. Please guide.
>>> 
>>>> gsub('[-|,]', '', end)
>>> [1] "2001"           "1992"           "2013"           "2013"
>>>  "2013"           "2013"           "2003"
>>> [8] "2010"           "2009"           "1986"           "2012"
>>>  "2003"           "2005"           "2013"
>>> [15] "2003"           "2013"           "1993?2007 2010" "2012"
>>>  "1984?1992 1996" "2015"           "2009"
>>> [22] "2000"           "2005"           "1997"           "2012"
>>>  "1997"           "2002"           "2006"
>>> [29] "1992"           "2007"           "1997"           "1982"
>>>  "2015"           "2015"           "2010"
>>> [36] "1996?2007 2011" "2004"           "1999"           "2007"
>>>  "1996"           "2013"           "2012"
>>> [43] "2012"           "2010"           "2011"           "1994"
>>>  "2014"
>>> 
>>> Regards,
>>> Sunny Singha
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Li.NJ.Li at huawei.com  Mon Apr 25 20:09:50 2016
From: Li.NJ.Li at huawei.com (LiLi (Z))
Date: Mon, 25 Apr 2016 18:09:50 +0000
Subject: [R] how to create initial configuraton for isoMDS
Message-ID: <B60F8F444AAC9C49A9EF0D12D05E094235C1AFC6@dfweml501-mbb>

Hi,

I'm trying to use isoMDS to project a directed graph to 2-dim vectors, but I got an error.

#here is the code to create the graph using igraph package and run isoMDS on it.
library(igraph)
library(MASS)
g<-make_graph(c(1,2, 2,3, 2,4, 3,4, 4,5, 5,6, 3,6, 1,6, 2,5),directed=TRUE)
dist<-distances(g, mode="out")
loc<-isoMDS(dist)

# below is content of the dist matrix
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    1    2    2    2    1
[2,]  Inf    0    1    1    1    2
[3,]  Inf  Inf    0    1    2    1
[4,]  Inf  Inf  Inf    0    1    2
[5,]  Inf  Inf  Inf  Inf    0    1
[6,]  Inf  Inf  Inf  Inf  Inf    0

# and here is the error message:
Error in isoMDS(dist) :
  an initial configuration must be supplied with NA/Infs in 'd'

It appears that isoMDS doesn't like the "Inf" values in the dist matrix, although help(isoMDS) suggests it accepts them if proper initial configuration is provided:
Arguments
d

distance structure of the form returned by dist, or a full, symmetric matrix. Data are assumed to be dissimilarities or relative distances, but must be positive except for self-distance. Both missing and infinite values are allowed.

y

An initial configuration. If none is supplied, cmdscale is used to provide the classical solution, unless there are missing or infinite dissimilarities.

k

The desired dimension for the solution, passed to cmdscale.


My questions is: how do I provide the y argument for this example to work?
Any help and suggestion is appreciated.
Li


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Apr 25 23:04:13 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 25 Apr 2016 14:04:13 -0700
Subject: [R] CRAN package check results tabulated ... wasRe: Number of
	package in Ubuntu
In-Reply-To: <CAJ4QxaO2xuOVC4QjnktitPixChpLUrEQE1wwowgUA1kE-EzmMA@mail.gmail.com>
References: <DF3A6EA1-AE59-423B-B813-887DDD4C3CFE@gmail.com>
	<21756501-903B-433C-93DA-6CFAF7A70C2A@comcast.net>
	<9F92D1AE-ECAC-45A8-B42F-326BACE0DBAD@comcast.net>
	<CAJ4QxaO2xuOVC4QjnktitPixChpLUrEQE1wwowgUA1kE-EzmMA@mail.gmail.com>
Message-ID: <AF199899-7ED3-4FC9-A1C5-94E86EA3444F@comcast.net>


> On Apr 24, 2016, at 4:51 AM, boB Rudis <bob at rudis.net> wrote:
> 
> Or grab https://cran.r-project.org/web/checks/check_results.rds and
> read it w/o the need for scraping.
> 

I had not realized there was a repository like that. However, I'm not sure what it means. It's not the same as the package listing on the webpage I referenced, since loading it into R gives a dataframe with more than ten times as many rows. Is there a description of that file somewhere? Does its much larger size indicate that it holds the entire archives file as well as the current CRAN offerings?

> str(dfrm)
'data.frame':	99497 obs. of  10 variables:
 $ Flavor    : Factor w/ 12 levels "r-devel-linux-x86_64-debian-gcc",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Package   : chr  "A3" "a4Base" "a4Core" "a4Preproc" ...
 $ Version   : chr  "1.0.0" NA NA NA ...
 $ Priority  : chr  NA NA NA NA ...
 $ Maintainer: chr  "Scott Fortmann-Roe <scottfr at berkeley.edu>" NA NA NA ...
 $ Status    : chr  "OK" NA NA NA ...
 $ Flags     : chr  "" NA NA NA ...
 $ T_install : num  0.664 8.491 3.184 4.511 5.063 ...
 $ T_check   : num  14.1 NA NA NA 47.5 ...
 $ T_total   : num  14.79 8.49 3.18 4.51 52.6 ...

On the other hand my efforts appear to have unnecessarily duplicated the material that is already obviously displayed in the summary table at the top of that page if one only adds the Note column totals to those of the OK column. <Heel of palm to side of head.>

-- 
David.



> On Sat, Apr 23, 2016 at 10:43 AM, David Winsemius
> <dwinsemius at comcast.net> wrote:
>> 
>>> On Apr 23, 2016, at 6:56 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> 
>>>> On Apr 22, 2016, at 11:51 AM, mylisttech at gmail.com wrote:
>>>> 
>>>> Dear Experts ,
>>>> 
>>>> I am using R with Spark on Windows and now there is a need to move to Ubuntu. I wanted to know if most of the packages that are available on windows , would they be available on Ubuntu/Linux? If not can I compile the source code of those package ? Has any one of you used the packages on Ubuntu ?
>>> 
>>> You can get the status of efforts to compile packages on the various machine avaialbe to CRAN at the CRAN package checks page:
>>> 
>>> https://cran.r-project.org/web/checks/check_summary.html
>>> 
>> 
>> After scraping that page with rvest::read_html I then used `table` to summarize. I posted the full output at the end of this but here are the relevant rows for Debian (for the Ubuntu option) and the Windows platforms tested:
>> 
>>> res_tbl
>> $`r-develLinuxx86_64(Debian GCC)`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  261    59  4150    28  3994    35    25
>> 
>> $`r-develWindowsix86+x86_64`
>> 
>>        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN
>>   295    124      1   3962     25   4064     36     45
>> 
>> $`r-patchedLinuxx86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  259    54  4153    28  3998    35    25
>> 
>> $`r-releaseLinuxx86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  268    54  2578    18  5569    45    20
>> 
>> $`r-releaseWindowsix86+x86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  324    70  2187    16  5885    46    24
>> 
>> $`r-oldrelWindowsix86+x86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN WARN*
>>  532   159  1605    13  6028    45   168     2
>> 
>> I think the various "NOTE" and "WARN" categories in most cases should be interpreted as "probably OK". It's those initial <blank>'s and ERROR categories that would most likely be the ones affecting users.
>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> --------- full tables--------
>> Tabulate on just the first letter of hte result:
>> 
>>> t(res_tbl2)
>>                                 blank   E    N    O   W
>> r-develLinuxx86_64(Debian GCC)     261  59 4178 4029  25
>> r-develLinuxx86_64(Fedora Clang)   265  66 4191 4001  29
>> r-develLinuxx86_64(Fedora GCC)     265  60 4204 3991  32
>> r-develOS Xx86_64(Clang)           294  70 4075 4081  32
>> r-develWindowsix86+x86_64          295 125 3987 4100  45
>> r-patchedLinuxx86_64               259  54 4181 4033  25
>> r-patchedSolarissparc              364 131 4082 3909  66
>> r-patchedSolarisx86                343 106 4091 3965  47
>> r-releaseLinuxx86_64               268  54 2596 5614  20
>> r-releaseOS Xx86_64(Mavericks)     255 174 2337 5718  68
>> r-releaseWindowsix86+x86_64        324  70 2203 5931  24
>> r-oldrelWindowsix86+x86_64         532 159 1618 6073 170
>> 
>> Tablulate on full message:
>>> res_tbl
>> $`r-develLinuxx86_64(Debian GCC)`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  261    59  4150    28  3994    35    25
>> 
>> $`r-develLinuxx86_64(Fedora Clang)`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  265    66  4179    12  3982    19    29
>> 
>> $`r-develLinuxx86_64(Fedora GCC)`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  265    60  4191    13  3972    19    32
>> 
>> $`r-develOS Xx86_64(Clang)`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  294    70  4066     9  4068    13    32
>> 
>> $`r-develWindowsix86+x86_64`
>> 
>>        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN
>>   295    124      1   3962     25   4064     36     45
>> 
>> $`r-patchedLinuxx86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  259    54  4153    28  3998    35    25
>> 
>> $`r-patchedSolarissparc`
>> 
>>        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN  WARN*
>>   364    129      2   4006     76   3839     70     65      1
>> 
>> $`r-patchedSolarisx86`
>> 
>>        ERROR ERROR*   NOTE  NOTE*     OK    OK*   WARN
>>   343    105      1   4062     29   3945     20     47
>> 
>> $`r-releaseLinuxx86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  268    54  2578    18  5569    45    20
>> 
>> $`r-releaseOS Xx86_64(Mavericks)`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  255   174  2335     2  5716     2    68
>> 
>> $`r-releaseWindowsix86+x86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN
>>  324    70  2187    16  5885    46    24
>> 
>> $`r-oldrelWindowsix86+x86_64`
>> 
>>      ERROR  NOTE NOTE*    OK   OK*  WARN WARN*
>>  532   159  1605    13  6028    45   168     2
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From andrluis at ualberta.ca  Tue Apr 26 00:34:39 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Mon, 25 Apr 2016 16:34:39 -0600
Subject: [R] Num to INT
Message-ID: <CAHxKz8ZrQf=FgHZE+PgsANSEOMpfSE4SRp4bLgEOqaw9V7w=sA@mail.gmail.com>

Hi there:

I transformed four columns of values in my dataset into an integer using
excel, but when I imported the dataset into R, it is still reading one of
the columns as NUM.
Then, I used as.integer function to convert the remaining column into INT,
but unfortunately, it is replacing the values by NAs.

I was wondering if you could help me to solve this problem.

Thanks,

-- 
Andre

	[[alternative HTML version deleted]]


From chlsrocks at yahoo.com  Tue Apr 26 04:53:46 2016
From: chlsrocks at yahoo.com (charles rockson)
Date: Tue, 26 Apr 2016 02:53:46 +0000 (UTC)
Subject: [R] Using read.csv() to import data
In-Reply-To: <571D34FC.9050204@gmail.com>
References: <571D34FC.9050204@gmail.com>
Message-ID: <899227864.2211210.1461639226468.JavaMail.yahoo@mail.yahoo.com>

Duncan,
What about converting your anova results in R ?back into csv or excel?
Thanks
Charles ?

      From: Duncan Murdoch <murdoch.duncan at gmail.com>
 To: Jason Hernandez <jason.hernandez74 at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org> 
 Sent: Sunday, April 24, 2016 2:05 PM
 Subject: Re: [R] Using read.csv() to import data
   
On 24/04/2016 4:30 PM, Jason Hernandez via R-help wrote:
> I am just beginning to learn R, using _R for Dummies_ by Andrie de Vries and Joris Meys. I am using Windows 7, and RGui (64-bit) version 3.0.2. I have reached the chapter on "Getting Data Into and Out of R." But the code they use for importing data doesn't seem to be working for me.
>
> Their example is:> elements <- read.csv(file.path("f:", "elements.csv"))
> Since I don't have any such file, I am trying to use a file I have. I went to Excel, brought up my file titled JPH_data, and saved it as .csv (comma delineated) on my main hard drive C:
>
> Then I entered:>? mammals <- read.csv(file.path("C:", "JPH_data.csv"))
> I got the following:Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>? ? cannot open file 'C:/JPH_data.csv': No such file or directory
> Aside from the obvious (how can it say "no such file or directory" when I just saved one such?), the "cannot open the connection" is also unexpected. What am I doing wrong here?
> Jason Hernandezno current affiliation

By far the easiest ways to enter Windows file paths are using the 
file.choose() and choose.files() functions.? Do something like

filename <- file.choose() # navigate to the file
mammals <- read.csv(filename)

and you should be fine.? The file.choose() function works on all 
platforms; choose.files() works only on Windows (and has more options, 
including allowing multiple files to be chosen).

Duncan Murdoch

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Apr 26 04:55:26 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 25 Apr 2016 19:55:26 -0700
Subject: [R] Num to INT
In-Reply-To: <CAHxKz8ZrQf=FgHZE+PgsANSEOMpfSE4SRp4bLgEOqaw9V7w=sA@mail.gmail.com>
References: <CAHxKz8ZrQf=FgHZE+PgsANSEOMpfSE4SRp4bLgEOqaw9V7w=sA@mail.gmail.com>
Message-ID: <0E500204-4CAD-4640-A4A8-C1D6DDF5DCC5@dcn.davis.ca.us>

Using Excel to prepare data can have many pitfalls that are Excel-specific and therefore off-topic here. 

Please provide a sample of your data (in CSV?) in the body of your next email along with the R code you used to import it,  and be sure to send in plain text format because HTML email frequently corrupts R code. 

Note that R data frame columns can be stored with distinct modes (e.g. numeric or integer) but the entire column MUST have the same mode. If you are still thinking like an Excel user this might take some getting used to.

You should also be aware that integers can be stored in floating point numbers just fine, though extremely large integers may not be representable in exact form either way. That is, your troubles may not actually be troubles at all, or there is a small chance that you may be asking the impossible.  That is why you have to show  us what you did and what you wanted to obtain to get effective help. 

The output of the sessionInfo function may also help clarify things here. Reading the Posting Guide mentioned below would probably also help you avoid other communication pitfalls. 
-- 
Sent from my phone. Please excuse my brevity.

On April 25, 2016 3:34:39 PM PDT, "Andr? Luis Neves" <andrluis at ualberta.ca> wrote:
>Hi there:
>
>I transformed four columns of values in my dataset into an integer
>using
>excel, but when I imported the dataset into R, it is still reading one
>of
>the columns as NUM.
>Then, I used as.integer function to convert the remaining column into
>INT,
>but unfortunately, it is replacing the values by NAs.
>
>I was wondering if you could help me to solve this problem.
>
>Thanks,
>
>-- 
>Andre
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Apr 26 06:00:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 25 Apr 2016 21:00:18 -0700
Subject: [R] Using read.csv() to import data
In-Reply-To: <899227864.2211210.1461639226468.JavaMail.yahoo@mail.yahoo.com>
References: <571D34FC.9050204@gmail.com>
	<899227864.2211210.1461639226468.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbSLYp4DMiQCcz1ceerc5HESGn1sjHTtnCQ-=aF9dWNJ4A@mail.gmail.com>

Keep on reading.

R functions (including analyses and even plots in some cases) pproduce
objects with various structures that are then summarized and displayed
by other functions (which also produce objects), sometimes
automagically. To "export" results to files or other software you need
to know how to capture, manipulate, and extract from these objects.
Keep on studying to learn how. There are also many good online
tutorials. See here for some recommendations:
https://www.rstudio.com/online-learning/#R


Of course, many of us would question why you would want to export
results back to Excel, as R has far greater capabilities  (you can
even produce "dynamic" Word reports with R results using R and
appropriate packages).  But then again, we don't know your situation
... But if you can, in the long run you might be better off ditching
Excel and gaining facility in R. It *does* require some time and
effort, though.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 25, 2016 at 7:53 PM, charles rockson via R-help
<r-help at r-project.org> wrote:
> Duncan,
> What about converting your anova results in R  back into csv or excel?
> Thanks
> Charles
>
>       From: Duncan Murdoch <murdoch.duncan at gmail.com>
>  To: Jason Hernandez <jason.hernandez74 at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
>  Sent: Sunday, April 24, 2016 2:05 PM
>  Subject: Re: [R] Using read.csv() to import data
>
> On 24/04/2016 4:30 PM, Jason Hernandez via R-help wrote:
>> I am just beginning to learn R, using _R for Dummies_ by Andrie de Vries and Joris Meys. I am using Windows 7, and RGui (64-bit) version 3.0.2. I have reached the chapter on "Getting Data Into and Out of R." But the code they use for importing data doesn't seem to be working for me.
>>
>> Their example is:> elements <- read.csv(file.path("f:", "elements.csv"))
>> Since I don't have any such file, I am trying to use a file I have. I went to Excel, brought up my file titled JPH_data, and saved it as .csv (comma delineated) on my main hard drive C:
>>
>> Then I entered:>  mammals <- read.csv(file.path("C:", "JPH_data.csv"))
>> I got the following:Error in file(file, "rt") : cannot open the connection
>> In addition: Warning message:
>> In file(file, "rt") :
>>    cannot open file 'C:/JPH_data.csv': No such file or directory
>> Aside from the obvious (how can it say "no such file or directory" when I just saved one such?), the "cannot open the connection" is also unexpected. What am I doing wrong here?
>> Jason Hernandezno current affiliation
>
> By far the easiest ways to enter Windows file paths are using the
> file.choose() and choose.files() functions.  Do something like
>
> filename <- file.choose() # navigate to the file
> mammals <- read.csv(filename)
>
> and you should be fine.  The file.choose() function works on all
> platforms; choose.files() works only on Windows (and has more options,
> including allowing multiple files to be chosen).
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-reims.fr  Tue Apr 26 08:41:42 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 26 Apr 2016 08:41:42 +0200
Subject: [R] ylim in barplot()
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72EBD0@mb02.ads.tamu.edu>
References: <571E2F59.10003@univ-reims.fr>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D72EBD0@mb02.ads.tamu.edu>
Message-ID: <571F0DA6.2060905@univ-reims.fr>

Thank you David,

That's a nice workaround using plotrix::barp(), but that doesn't explain 
why ylim doesn't work as intended (or at least, as I expect it to work), 
or why xpd has no influence when using devEMF::emf()...

The problem with saving directly in RStudio is that it requires to 
manually save the plot, and this becomes troublesome when there are a 
lot of plot commands in a single script.

Bests,
Ivan (on behalf of St?phanie)

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 25/04/2016 21:16, David L Carlson a ?crit :
> If you are using a Windows system, you can Export the plot from RStudio and save it as a metafile without using package devEMF and it will crop the bars with xpd=FALSE. When I used devEMF on a Windows machine, the bars were not cropped with barplot() as you indicated, but when I switched to plotrix::barp() they were cropped. The arguments are a bit different, but I did not need xpd=FALSE:
>
> emf("TestPlot.emf")
> barp(t(mydata), col=c("orange", "green", "yellow", "purple"),
> ylim=c(50,70), legend.lab=colnames(mydata), legend.pos="topright")
> dev.off()
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of EYSSAUTIER St?phanie
> Sent: Monday, April 25, 2016 9:53 AM
> To: r-help at r-project.org
> Subject: [R] ylim in barplot()
>
> Dear useRs,
>
> I'm having troubles with using ylim in barplot(): even though I reduce
> the y-scale using ylim, the bars still extend down to 0into the x-labels.
> The sample data is below, and here is the code.
>
> #This works fine but I would like to plot only from 50 to 70:
> barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow",
> "purple"), legend=TRUE, las=2, axis.lty=1)
>
> #This is the ylim version with the bar problem:
> barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow",
> "purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1)
>
> #I have tried using xpd=FALSE and this works fine withinRguior Rstudio
> but not when I plot within devEMF::emf()
> barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow",
> "purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1, xpd=FALSE)
>
> I need the emf file to edit the plot.
>
> Why isn't it working with ylim alone? And why doesn't xpd work with emf()?
>
> Thanks in advance for your help,
> St?phanie
>
>
> mydata <- structure(c(68.1799689328282, 68.2164021637813,
> 68.3243626415103, 61.7899567386469, 59.5182501049449, 63.9916220705152,
> 64.1442535260522, 64.2585746423512, 62.5653571705887, 61.631969055001,
> 61.3991475513249, 63.2401411727188, 65.0488808306348, 63.43022364909,
> 64.8425577471775, 65.4986231824992, 64.7798619682232, 64.4174790601806,
> 65.5696701695485, 65.0253962620178, 63.2476885701954, 63.2473647791827,
> 62.5000542212819, 63.1742307643225, 62.1560658393146, 62.5810636272476,
> 64.0935149828315, 65.5432025084893, 66.7535104579705, 59.6500997601308,
> 59.4641686257122, 59.8891527196501, 60.0117050975523, 64.3309521324969,
> 62.0079305659785, 57.0665210362419, 57.5202118193362, 61.3280531011031,
> 62.6326634763289, 60.2094259175778, 65.5923786551105, 65.6946445059829,
> 65.2498254841218, 65.3468620859567, 67.024437492438, 65.8533801964148,
> 65.0047369761726, 65.0310208374089, 64.3121920326177, 64.8038153143374,
> 63.7306643056964, 64.2579190762784, 67.5745906026732, 67.0351170775703,
> 66.4053872920113, 59.9302305698358, 60.368722602391, 60.3572311841096,
> 60.0960412312049, 63.7886894551889, 62.24708719601, 59.3334729073243,
> 59.9537485303794, 63.1828096654404, 63.5352778562394, 60.621828397375,
> 65.8889763819732, 66.2059756115814, 66.4567010911873, 65.8796623180062,
> 67.5552743734229, 66.504738660398, 66.2085036370622, 66.4230781907321,
> 65.5130180297911, 65.9051623923225, 64.8408013974267, 65.5175045910169,
> 68.0760225106606, 66.8615536135711, 65.0390748892256, 59.2940092440695,
> 60.7061368898884, 59.7345965097738, 59.6019925755588, 63.6011933836225,
> 62.1134684942427, 60.4227073441121, 60.7834352002706, 63.4539745079728,
> 63.6329498376672, 58.8034486099638, 65.2910772858539, 65.5952764758513,
> 65.8371262481454, 66.1191053038481, 67.5230043279325, 66.8569714429862,
> 66.1045642986574, 66.8499631633452, 66.0121950308609, 66.2593339018511,
> 65.4397264829666, 65.8389305084859), .Dim = c(26L, 4L), .Dimnames =
> list(c("T40", "T41", "T42", "306iv01", "306iv02", "306iv19", "306iv13",
> "306iv04", "306iv05", "402iv01", "402iv02", "402iv03", "306iv16",
> "306iv10", "TG1", "TG2", "TG3", "TG4", "TG5", "TG6", "TG7", "TG8",
> "TG9", "TG10", "TG11", "TG12"), c("L.mean", "L.mean_T1", "L.mean_T2",
> "L.mean_T3")))
>
>


From G.Maubach at weinwolf.de  Tue Apr 26 08:44:44 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 26 Apr 2016 08:44:44 +0200
Subject: [R] Antwort: Fw: Re:  Creating variables on the fly (SOLVED)
In-Reply-To: <trinity-c113f29b-55d5-4bed-bd55-e03d3ac2ec98-1461613170058@3capp-gmx-bs01>
References: <trinity-889635c8-d9ad-46fd-afd8-aad8ca2617ec-1461340321842@3capp-gmx-bs54>,
	<D3439ECF.16FB8B%macqueen1@llnl.gov>
	<trinity-c113f29b-55d5-4bed-bd55-e03d3ac2ec98-1461613170058@3capp-gmx-bs01>
Message-ID: <OF11F58074.BAA6E2AE-ONC1257FA1.00244C1F-C1257FA1.00250E41@lotus.hawesko.de>

Hi Don,
Hi to all readers,

many thanks for all your answers and all your help.

I adapted Don's code to my data and Don's code does the trick:

str(Kunden01)

for (year in 2011:2015) {
  Reeller_Kunde <- paste0("Reeller_Kunde_", year)
  Umsatz <- paste0("Umsatz_", year)
  cat('Creating', Reeller_Kunde,'from', Umsatz,'\n')
  Kunden01[[ Reeller_Kunde ]] <- ifelse( Kunden01[[ Umsatz ]] >= 0, 1, 2)
  Kunden01[[ Reeller_Kunde ]] <- factor( Kunden01[[ Reeller_Kunde ]],
                                         levels=c(1,2),
                                         labels= c("NICHT kaufend", 
"kaufend")
  )
}

str(Kunden01)

This way a new variable is created by building it from a string 
concatenation.

I also like the cat() function to document the process within the loop 
while running the program.

Many thanks for your help.

Kind regards

Georg




Von:    G.Maubach at gmx.de
An:     g.maubach at weinwolf.de, 
Datum:  25.04.2016 21:37
Betreff:        Fw: Re: [R] Creating variables on the fly





> Gesendet: Montag, 25. April 2016 um 19:35 Uhr
> Von: "MacQueen, Don" <macqueen1 at llnl.gov>
> An: "G.Maubach at gmx.de" <G.Maubach at gmx.de>, "r-help at r-project.org" 
<r-help at r-project.org>
> Betreff: Re: [R] Creating variables on the fly
>
> I'm going to assume that Kunden is a data frame, and it has columns
> (variables) with names like
>   Umstatz_2011
> and that you want to create new columns with names like
>   Kunde_real_2011
> 
> If that is so, then try this (not tested):
> 
> for (year in 2011:2015) {
>   nmK <- paste0("Kunde_real_", year)
>   nmU <- paste0("Umsatz_", year)
>   cat('Creating',nmK,'from',nmU,'\n')
>   Kunden[[ nmK ]] <- ifelse( Kunden[[ nmU ]] <= 0, 1, 2)
>   Kunden[[ nmK ]] <- factor( Kunden[[ nmK ]],
>        levels=c(1,2),
>        labels= c("NICHT kaufend", "kaufend")
>        )
> 
> }
> 
> This little example should illustrate the method:
> 
> 
> > foo <- data.frame(a=1:4)
> > foo
>   a
> 1 1
> 2 2
> 3 3
> 4 4
> > foo[['b']] <- foo[['a']]*3
> > foo
>   a  b
> 1 1  3
> 2 2  6
> 3 3  9
> 4 4 12
> 
> 
> 
> -- 
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 4/22/16, 8:52 AM, "R-help on behalf of G.Maubach at gmx.de"
> <r-help-bounces at r-project.org on behalf of G.Maubach at gmx.de> wrote:
> 
> >Hi all,
> >
> >I would like to use a loop for tasks that occurs repeatedly:
> >
> ># Groups 
> ># Umsatz <= 0: 1 (NICHT kaufend)
> ># Umsatz > 0: 2  (kaufend)
> >for (year in c("2011", "2012", "2013", "2014", "2015")) {
> >  paste0("Kunden$Kunde_real_", year) <- (paste0("Kunden$Umsatz_", year)
> ><= 0) * 1 + 
> >                                        (paste0("Kunden$Umsatz_", year) 
>
> > 0) * 2 
> >  paste0("Kunden$Kunde_real_", year) <- factor(paste0("Kunden$Umsatz_",
> >year), 
> >                                               levels = c(1, 2),
> >                                               labels = c("NICHT
> >kaufend", "kaufend"))
> >  } 
> >
> >This actually does not work due to the fact that the expression
> >"paste0("Kunden$Kunde_real_", year)" ist not interpreted as a variable
> >name by the R script language interpreter.
> >
> >Is there a way to assembly variable names on the fly in R?
> >
> >Regards
> >
> >Georg
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
>


From G.Maubach at weinwolf.de  Tue Apr 26 10:09:57 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 26 Apr 2016 10:09:57 +0200
Subject: [R] Missing Values in Logical Expressions
Message-ID: <OF8D82BBD9.4138E6C4-ONC1257FA1.002BF1AF-C1257FA1.002CDBA6@lotus.hawesko.de>

Hi All,

I need to evaluate missing values in my data. I am able to filter these 
values and do simple statistics on it. But I do need new variables based 
on variables with missing values in my dataset:

Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011 == 1, 
1, 0)
Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels = 
c("Check", "OK"))

The new variable is not correctly created. It contains no values:

table(Check_Kunde_2011)
< table of extent 0 >

I searched the web but could not find a solution.

How can I work with variables and missing values in logical expressions?

Where could I find something about this?

Kind regards

Georg


From jari.oksanen at oulu.fi  Tue Apr 26 10:24:08 2016
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 26 Apr 2016 08:24:08 +0000
Subject: [R] Vegemite Function is Cowardly refusing
References: <CAK2Sg-3_x+ndjR860Wc=E5t6Df+2_yrrn+chyKbooq=1EOgR5w@mail.gmail.com>
Message-ID: <loom.20160426T101607-976@post.gmane.org>

Ansley Silva <daily.puja <at> gmail.com> writes:

> 
> R version 3.2.2.
> library(vegan)
> 
> I was to look at community tables from my dendrograms and am trying out the
> vegemite command.  This is the error I get:
> 
> Error in vegemite(apst, apst.clusters) :
>   Cowardly refusing to use longer than 1 char symbols:
> Use scale
> 
> I thought the problem was that I was using the log transformed data, but I
> tried it on the raw (which is single digit numbers), and still no luck.
> Any suggestions would be appreciated.
> 
I imagined that the error message is clear: vegemite only uses one-character
symbols (because the result is so compact). The example data you had with
this message had numbers up to 55 -- and that is a two-digit number. The
message also suggest that you use 'scale' which is an argument of 
vegemite() to transform numbers to one-charactar symbols. You can also
transform your data to to one-digit width yourself, and vegemite() will be 
happy.

cheers, Jari Oksanen


From drjimlemon at gmail.com  Tue Apr 26 10:49:53 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 26 Apr 2016 18:49:53 +1000
Subject: [R] Missing Values in Logical Expressions
In-Reply-To: <OF8D82BBD9.4138E6C4-ONC1257FA1.002BF1AF-C1257FA1.002CDBA6@lotus.hawesko.de>
References: <OF8D82BBD9.4138E6C4-ONC1257FA1.002BF1AF-C1257FA1.002CDBA6@lotus.hawesko.de>
Message-ID: <CA+8X3fWNepT-2bC4Ox+_Hi6QUG5v7HiwPT=G86PH9rSt+VqDGw@mail.gmail.com>

Hi Georg,
You could just use this:

Umsatz_2011<-c(1,2,3,4,5,NA,7,8,NA,10)
Kunde_2011<-rep(0:1,5)
Check_Kunde_2011<-
 c("OK","Check")[as.numeric(is.na(Umsatz_2011) & Kunde_2011 == 1)+1]

Check_Kunde_2011 will be a vector of strings.

Jim


On Tue, Apr 26, 2016 at 6:09 PM,  <G.Maubach at weinwolf.de> wrote:
> Hi All,
>
> I need to evaluate missing values in my data. I am able to filter these
> values and do simple statistics on it. But I do need new variables based
> on variables with missing values in my dataset:
>
> Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011 == 1,
> 1, 0)
> Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels =
> c("Check", "OK"))
>
> The new variable is not correctly created. It contains no values:
>
> table(Check_Kunde_2011)
> < table of extent 0 >
>
> I searched the web but could not find a solution.
>
> How can I work with variables and missing values in logical expressions?
>
> Where could I find something about this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Apr 26 11:13:18 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 26 Apr 2016 09:13:18 +0000
Subject: [R] Missing Values in Logical Expressions
In-Reply-To: <OF8D82BBD9.4138E6C4-ONC1257FA1.002BF1AF-C1257FA1.002CDBA6@lotus.hawesko.de>
References: <OF8D82BBD9.4138E6C4-ONC1257FA1.002BF1AF-C1257FA1.002CDBA6@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50281BC@SRVEXCHMBX.precheza.cz>

Hm

Based on Jim's data your construction gives me correct result.

> Umsatz_2011<-c(1,2,3,4,5,NA,7,8,NA,10)
> Kunde_2011<-rep(0:1,5)
> Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011 == 1, 1, 0)
> Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels = c("Check", "OK"))
> table(Check_Kunde_2011)
Check_Kunde_2011
Check    OK
    1     9

So I presume that the problem lies in your data.
You should provide some sample of your data either by posting result of

str(yourdata)
or
dput(head(yourdata))

if you want some advice why with correct code you did not get appropriate result.

Instead ifelse you can also use

Check_Kunde_2011 <- (is.na(Umsatz_2011)&(Kunde_2011==1))*1

to get desired 0/1 vector.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Tuesday, April 26, 2016 10:10 AM
> To: r-help at r-project.org
> Subject: [R] Missing Values in Logical Expressions
>
> Hi All,
>
> I need to evaluate missing values in my data. I am able to filter these values
> and do simple statistics on it. But I do need new variables based on variables
> with missing values in my dataset:
>
> Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011 ==
> 1, 1, 0)
> Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels =
> c("Check", "OK"))
>
> The new variable is not correctly created. It contains no values:
>
> table(Check_Kunde_2011)
> < table of extent 0 >
>
> I searched the web but could not find a solution.
>
> How can I work with variables and missing values in logical expressions?
>
> Where could I find something about this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From zaid_golwala at persistent.com  Tue Apr 26 13:08:35 2016
From: zaid_golwala at persistent.com (Zaid Golwala)
Date: Tue, 26 Apr 2016 11:08:35 +0000
Subject: [R] Issue while building xtable on R on Ubuntu 15.04
Message-ID: <EC52F5F46B02B64EAECF93259BDB59F4212A2982@HJ-MBX2.persistent.co.in>

Please help in the below mentioned issue.

Regards
Zaid Golwala

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Zaid Golwala
Sent: Wednesday, April 06, 2016 1:35 PM
To: r-help at R-project.org
Subject: [R] Issue while building xtable on R on Ubuntu 15.04

Hi,

I am trying to build xtable on R  on Ubuntu 15.04 but I get following error :


+ R CMD check --no-vignettes --timings xtable_1.8-2.tar.gz

* using log directory '/home/jenkins/workspace/Rlang_xtable_Ubuntu15.04/xtable.Rcheck'

* using R version 3.2.3 (2015-12-10)

* using platform: powerpc64le-unknown-linux-gnu (64-bit)

* using session charset: UTF-8

* using option '--no-vignettes

'* checking for file 'xtable/DESCRIPTION' ... OK

* this is package 'xtable' version '1.8-2'

* checking package namespace information ... OK

* checking package dependencies ...Error in .build_vignette_index(vigns) :   In 'inst' vignettes 'xtableGallery.Rnw' and 'xtableGallery.snw' have the same vignette name

Can someone please help me regarding the same.

Regards
Zaid Golwala

DISCLAIMER\ ==========\ This e-mail ...{{dropped:18}}


From nuria.blasco at um.es  Tue Apr 26 12:03:01 2016
From: nuria.blasco at um.es (NURIA BLASCO LAVILLA)
Date: Tue, 26 Apr 2016 12:03:01 +0200
Subject: [R] Haplotype network appearance
Message-ID: <20160426120301.Horde.3MZSdpoecIhBJ6jsIv26Mw8@webmail.um.es>

Hi,

I'm doing haplotype networks with the package pegas and the script from
Jimmy O'Donell's blog. The networks which I obtain are a little ugly and
I'd like to change some aspects of their appearance, but I'm just starting
with R and I don't know how to do it. I have the following problems:

-Some nodes overlap. I increase the scale.ratio but then I get a tiny
legend. So I need to increase the legend or the links in the graphic. I
haven't found any way to increase only the links and, as to the legend, I
haven't seen a way to adjust its size without creating it apart from the
graphic. Is there another way to solve this problem?

-Some nodes are very small and labels hide them. As their size is already
small, I'd like to know if there is a way of changing its position and put
them outside the nodes.

-Finally, I get a lot of gray and discontinous lines which I don't
understand and I don't know how to remove them.

Thanks in advance,

Nuria.

	[[alternative HTML version deleted]]


From David.Mcnulty at uhb.nhs.uk  Tue Apr 26 14:25:19 2016
From: David.Mcnulty at uhb.nhs.uk (David Mcnulty)
Date: Tue, 26 Apr 2016 12:25:19 +0000
Subject: [R] Penalised spline regression
Message-ID: <2475A5E7ACB80F4C81BFF348ADCC9B0F4E635EDD@EXMBX03.xuhb.nhs.uk>

Good Afternoon Everyone,

I am looking for advice fitting a linear mixed model where the random components do not seem to fit within the model formulae for lmer. The columns of Z are not stratified and have the notional random formula (z1 | 1) + ... + (zk | 1). 

Context
I am fitting a penalised thin plate spline with knots k1 to kn. The basis functions Zk are |x-ki|^3 and the penalty matrix has elements |ki-kj|^3. Rather than fit basis functions Zk I have transformed the basis to Z = Zk %*% penalty^(-1/2).

Full details are in section 2: Bayesian analysis for penalised spline regression using winBUGS. https://www.jstatsoft.org/article/view/v014i14/v14i14.pdf

I am specifically looking for an alternative to the function spm() in package semipar.

Thank you for any help or advice.

Dave.

David Mcnulty
Medical Statistician
 
 
Tel: +44 (0) 121 371 2448  
Internal: 12448     
Email: David.Mcnulty at uhb.nhs.uk 
Web: http://www.uhb.nhs.uk  


Health Informatics - University Hospitals Birmingham NHS Foundation Trust
Yardley Court, 11-13 Frederick Road, Edgbaston
Birmingham, B15 1JD


The Health Informatics Department is a team of specialist NHS information analysts who work together to provide analysis solutions. The Team filters, analyses and presents comprehensive information that empowers NHS professionals to make informed decisions. 


From Aljosa.Aleksandrovic at man.com  Tue Apr 26 14:39:46 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Tue, 26 Apr 2016 12:39:46 +0000
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <571F6068.5040009@utoronto.ca>
References: <mailman.1833.1461672613.3828.r-help@r-project.org> 
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca> 
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
Message-ID: <9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>

Hi all,

I hope you are doing well?

I?m currently using the lm() function from the package stats to fit linear multifactor regressions.

Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.

Is there an elegant and not too complicated way to do such a constraint regression estimation in R?

I would very much appreciate if you could help me with my issue?

Thanks a lot in advance and kind regards, 
Aljosa Aleksandrovic



Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 7603

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca] 
Sent: Dienstag, 26. April 2016 14:35
To: Aleksandrovic, Aljosa (Pfaeffikon)
Subject: Re: Linear Regressions with constraint coefficients

You need to send it to r-help at r-project.org however.

Kevin

On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
> Ok, will do! Thx a lot!
>
> Please find below my request:
>
> Hi all,
>
> I hope you are doing well?
>
> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>
> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>
> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>
> I would very much appreciate if you could help me with my issue?
>
> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Dienstag, 26. April 2016 14:28
> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
> Subject: Re: Linear Regressions with constraint coefficients
>
> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>
> Kevin
>
> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>> Do you know where I get help for my issue?
>>
>> Thanks in advance and kind regards,
>> Aljosa
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> r-help-owner at r-project.org
>> Sent: Dienstag, 26. April 2016 14:10
>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>> Subject: Linear Regressions with constraint coefficients
>>
>> The message's content type was not explicitly allowed
>>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP


From bgunter.4567 at gmail.com  Tue Apr 26 16:51:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 26 Apr 2016 07:51:18 -0700
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
Message-ID: <CAGxFJbSORtDOys9QhBarCGdXQkOFgqkzoUzunMSSUVuFyOYZ-A@mail.gmail.com>

If the slope coefficients sum to a constant, the regressors are
dependent and so a unique solution is impossible (an infinity of
solutions would result). So I think you have something going on that
you don't understand and should consult a local statistician to help
you formulate your problem appropriately.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 26, 2016 at 5:39 AM, Aleksandrovic, Aljosa (Pfaeffikon)
<Aljosa.Aleksandrovic at man.com> wrote:
> Hi all,
>
> I hope you are doing well?
>
> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>
> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>
> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>
> I would very much appreciate if you could help me with my issue?
>
> Thanks a lot in advance and kind regards,
> Aljosa Aleksandrovic
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Dienstag, 26. April 2016 14:35
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Subject: Re: Linear Regressions with constraint coefficients
>
> You need to send it to r-help at r-project.org however.
>
> Kevin
>
> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>> Ok, will do! Thx a lot!
>>
>> Please find below my request:
>>
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:28
>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>
>> Kevin
>>
>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Do you know where I get help for my issue?
>>>
>>> Thanks in advance and kind regards,
>>> Aljosa
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> r-help-owner at r-project.org
>>> Sent: Dienstag, 26. April 2016 14:10
>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>> Subject: Linear Regressions with constraint coefficients
>>>
>>> The message's content type was not explicitly allowed
>>>
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Aljosa.Aleksandrovic at man.com  Tue Apr 26 17:29:23 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Tue, 26 Apr 2016 15:29:23 +0000
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <CAGxFJbSORtDOys9QhBarCGdXQkOFgqkzoUzunMSSUVuFyOYZ-A@mail.gmail.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAGxFJbSORtDOys9QhBarCGdXQkOFgqkzoUzunMSSUVuFyOYZ-A@mail.gmail.com>
Message-ID: <3963ea68a4964fbe8618a5dedbe488dd@PLONINEXMS136.maninvestments.ad.man.com>

Ok, and if I would just like to force my slope coefficients to be inside an interval, let's say, between 0 and 1? Is there a way in R to formulate such a constraint regression?

Thanks in advance and kind regards,
Aljosa



Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 7603

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Dienstag, 26. April 2016 16:51
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

If the slope coefficients sum to a constant, the regressors are dependent and so a unique solution is impossible (an infinity of solutions would result). So I think you have something going on that you don't understand and should consult a local statistician to help you formulate your problem appropriately.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 26, 2016 at 5:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Hi all,
>
> I hope you are doing well?
>
> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>
> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>
> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>
> I would very much appreciate if you could help me with my issue?
>
> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Dienstag, 26. April 2016 14:35
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Subject: Re: Linear Regressions with constraint coefficients
>
> You need to send it to r-help at r-project.org however.
>
> Kevin
>
> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>> Ok, will do! Thx a lot!
>>
>> Please find below my request:
>>
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:28
>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>
>> Kevin
>>
>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Do you know where I get help for my issue?
>>>
>>> Thanks in advance and kind regards,
>>> Aljosa
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> r-help-owner at r-project.org
>>> Sent: Dienstag, 26. April 2016 14:10
>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>> Subject: Linear Regressions with constraint coefficients
>>>
>>> The message's content type was not explicitly allowed
>>>
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter.4567 at gmail.com  Tue Apr 26 17:49:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 26 Apr 2016 08:49:27 -0700
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <3963ea68a4964fbe8618a5dedbe488dd@PLONINEXMS136.maninvestments.ad.man.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAGxFJbSORtDOys9QhBarCGdXQkOFgqkzoUzunMSSUVuFyOYZ-A@mail.gmail.com>
	<3963ea68a4964fbe8618a5dedbe488dd@PLONINEXMS136.maninvestments.ad.man.com>
Message-ID: <CAGxFJbQm3k0JuOOsG-Q8-FsD-Mch-A6cOWarFPmZ0-bo+aEuXg@mail.gmail.com>

Have you tried web searching on " R constrained linear regression" or
similar. There seemed to be resources related to your issues when I
looked. You might also search on rseek.org  . There are apparently
several packages that do regression with constraints, but I don't know
if they fit your situation.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 26, 2016 at 8:29 AM, Aleksandrovic, Aljosa (Pfaeffikon)
<Aljosa.Aleksandrovic at man.com> wrote:
> Ok, and if I would just like to force my slope coefficients to be inside an interval, let's say, between 0 and 1? Is there a way in R to formulate such a constraint regression?
>
> Thanks in advance and kind regards,
> Aljosa
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Dienstag, 26. April 2016 16:51
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Cc: r-help at r-project.org
> Subject: Re: [R] Linear Regressions with constraint coefficients
>
> If the slope coefficients sum to a constant, the regressors are dependent and so a unique solution is impossible (an infinity of solutions would result). So I think you have something going on that you don't understand and should consult a local statistician to help you formulate your problem appropriately.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 26, 2016 at 5:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:35
>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> You need to send it to r-help at r-project.org however.
>>
>> Kevin
>>
>> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Ok, will do! Thx a lot!
>>>
>>> Please find below my request:
>>>
>>> Hi all,
>>>
>>> I hope you are doing well?
>>>
>>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>>
>>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>>
>>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>>
>>> I would very much appreciate if you could help me with my issue?
>>>
>>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>>
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>>
>>> -----Original Message-----
>>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>>> Sent: Dienstag, 26. April 2016 14:28
>>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>>> Subject: Re: Linear Regressions with constraint coefficients
>>>
>>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>>
>>> Kevin
>>>
>>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>>> Do you know where I get help for my issue?
>>>>
>>>> Thanks in advance and kind regards,
>>>> Aljosa
>>>>
>>>>
>>>> Aljosa Aleksandrovic, FRM, CAIA
>>>> Quantitative Analyst - Convertibles
>>>> aljosa.aleksandrovic at man.com
>>>> Tel +41 55 417 7603
>>>>
>>>> Man Investments (CH) AG
>>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>> r-help-owner at r-project.org
>>>> Sent: Dienstag, 26. April 2016 14:10
>>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>>> Subject: Linear Regressions with constraint coefficients
>>>>
>>>> The message's content type was not explicitly allowed
>>>>
>>
>>
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC)
>> Li Ka Shing Knowledge Institute of St. Michael's Hospital
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>
>> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
>> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Aljosa.Aleksandrovic at man.com  Tue Apr 26 17:52:28 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Tue, 26 Apr 2016 15:52:28 +0000
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <CAGxFJbQm3k0JuOOsG-Q8-FsD-Mch-A6cOWarFPmZ0-bo+aEuXg@mail.gmail.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAGxFJbSORtDOys9QhBarCGdXQkOFgqkzoUzunMSSUVuFyOYZ-A@mail.gmail.com>
	<3963ea68a4964fbe8618a5dedbe488dd@PLONINEXMS136.maninvestments.ad.man.com>
	<CAGxFJbQm3k0JuOOsG-Q8-FsD-Mch-A6cOWarFPmZ0-bo+aEuXg@mail.gmail.com>
Message-ID: <c0c99b63e60d413ba1aac6a2e1d8089f@PLONINEXMS136.maninvestments.ad.man.com>

Ok, will try!

Thanks a kind regards,
Aljosa


Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Dienstag, 26. April 2016 17:49
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

Have you tried web searching on " R constrained linear regression" or similar. There seemed to be resources related to your issues when I looked. You might also search on rseek.org  . There are apparently several packages that do regression with constraints, but I don't know if they fit your situation.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 26, 2016 at 8:29 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Ok, and if I would just like to force my slope coefficients to be inside an interval, let's say, between 0 and 1? Is there a way in R to formulate such a constraint regression?
>
> Thanks in advance and kind regards,
> Aljosa
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Dienstag, 26. April 2016 16:51
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Cc: r-help at r-project.org
> Subject: Re: [R] Linear Regressions with constraint coefficients
>
> If the slope coefficients sum to a constant, the regressors are dependent and so a unique solution is impossible (an infinity of solutions would result). So I think you have something going on that you don't understand and should consult a local statistician to help you formulate your problem appropriately.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 26, 2016 at 5:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:35
>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> You need to send it to r-help at r-project.org however.
>>
>> Kevin
>>
>> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Ok, will do! Thx a lot!
>>>
>>> Please find below my request:
>>>
>>> Hi all,
>>>
>>> I hope you are doing well?
>>>
>>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>>
>>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>>
>>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>>
>>> I would very much appreciate if you could help me with my issue?
>>>
>>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>>
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>>
>>> -----Original Message-----
>>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>>> Sent: Dienstag, 26. April 2016 14:28
>>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>>> Subject: Re: Linear Regressions with constraint coefficients
>>>
>>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>>
>>> Kevin
>>>
>>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>>> Do you know where I get help for my issue?
>>>>
>>>> Thanks in advance and kind regards, Aljosa
>>>>
>>>>
>>>> Aljosa Aleksandrovic, FRM, CAIA
>>>> Quantitative Analyst - Convertibles
>>>> aljosa.aleksandrovic at man.com
>>>> Tel +41 55 417 7603
>>>>
>>>> Man Investments (CH) AG
>>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>> r-help-owner at r-project.org
>>>> Sent: Dienstag, 26. April 2016 14:10
>>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>>> Subject: Linear Regressions with constraint coefficients
>>>>
>>>> The message's content type was not explicitly allowed
>>>>
>>
>>
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC)
>> Li Ka Shing Knowledge Institute of St. Michael's Hospital
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>
>> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
>> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From ggrothendieck at gmail.com  Tue Apr 26 17:59:14 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 26 Apr 2016 11:59:14 -0400
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
Message-ID: <CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>

This is a quadratic programming problem that you can solve using
either a quadratic programming solver with constraints or a general
nonlinear solver with constraints.  See
https://cran.r-project.org/web/views/Optimization.html
for more info on what is available.

Here is an example using a nonlinear least squares solver and
non-negative bound constraints. The constraint that the coefficients
sum to 1 is implied by dividing them by their sum and then dividing
the coefficients found by their sum at the end:

# test data
set.seed(123)
n <- 1000
X1 <- rnorm(n)
X2 <- rnorm(n)
X3 <- rnorm(n)
Y <- .2 * X1 + .3 * X2 + .5 * X3 + rnorm(n)

# fit
library(nlmrt)
fm <- nlxb(Y ~ (b1 * X1 + b2 * X2 + b3 * X3)/(b1 + b2 + b3),
     data = list(Y = Y, X1 = X1, X2 = X2, X3 = X3),
     lower = numeric(3),
     start = list(b1 = 1, b2 = 2, b3 = 3))

giving the following non-negative coefficients which sum to 1 that are
reasonably close to the true values of 0.2, 0.3 and 0.5:

> fm$coefficients / sum(fm$coefficients)
     b1      b2      b3
0.18463 0.27887 0.53650


On Tue, Apr 26, 2016 at 8:39 AM, Aleksandrovic, Aljosa (Pfaeffikon)
<Aljosa.Aleksandrovic at man.com> wrote:
> Hi all,
>
> I hope you are doing well?
>
> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>
> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>
> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>
> I would very much appreciate if you could help me with my issue?
>
> Thanks a lot in advance and kind regards,
> Aljosa Aleksandrovic
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Dienstag, 26. April 2016 14:35
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Subject: Re: Linear Regressions with constraint coefficients
>
> You need to send it to r-help at r-project.org however.
>
> Kevin
>
> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>> Ok, will do! Thx a lot!
>>
>> Please find below my request:
>>
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:28
>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>
>> Kevin
>>
>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Do you know where I get help for my issue?
>>>
>>> Thanks in advance and kind regards,
>>> Aljosa
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> r-help-owner at r-project.org
>>> Sent: Dienstag, 26. April 2016 14:10
>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>> Subject: Linear Regressions with constraint coefficients
>>>
>>> The message's content type was not explicitly allowed
>>>
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ivan.calandra at univ-reims.fr  Tue Apr 26 18:05:16 2016
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 26 Apr 2016 18:05:16 +0200
Subject: [R] ylim in barplot()
In-Reply-To: <571F0DA6.2060905@univ-reims.fr>
References: <571E2F59.10003@univ-reims.fr>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D72EBD0@mb02.ads.tamu.edu>
	<571F0DA6.2060905@univ-reims.fr>
Message-ID: <fcc7795f-b716-2f66-322b-9d5e753aab07@univ-reims.fr>

Dear useRs,

It seems that my last e-mail went quite unnoticed...
Has anyone an idea about ylim doesn't work in barplot (see details below)?

Thank you in advance,
Ivan (on behalf of St?phanie)

--
Ivan Calandra, PhD
Scientific Mediator
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 26/04/2016 ? 08:41, Ivan Calandra a ?crit :
> Thank you David,
>
> That's a nice workaround using plotrix::barp(), but that doesn't 
> explain why ylim doesn't work as intended (or at least, as I expect it 
> to work), or why xpd has no influence when using devEMF::emf()...
>
> The problem with saving directly in RStudio is that it requires to 
> manually save the plot, and this becomes troublesome when there are a 
> lot of plot commands in a single script.
>
> Bests,
> Ivan (on behalf of St?phanie)
>
> -- 
> Ivan Calandra, PhD
> Scientific Mediator
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> -- 
> https://www.researchgate.net/profile/Ivan_Calandra
> https://publons.com/author/705639/
>
> Le 25/04/2016 21:16, David L Carlson a ?crit :
>> If you are using a Windows system, you can Export the plot from 
>> RStudio and save it as a metafile without using package devEMF and it 
>> will crop the bars with xpd=FALSE. When I used devEMF on a Windows 
>> machine, the bars were not cropped with barplot() as you indicated, 
>> but when I switched to plotrix::barp() they were cropped. The 
>> arguments are a bit different, but I did not need xpd=FALSE:
>>
>> emf("TestPlot.emf")
>> barp(t(mydata), col=c("orange", "green", "yellow", "purple"),
>> ylim=c(50,70), legend.lab=colnames(mydata), legend.pos="topright")
>> dev.off()
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
>> EYSSAUTIER St?phanie
>> Sent: Monday, April 25, 2016 9:53 AM
>> To: r-help at r-project.org
>> Subject: [R] ylim in barplot()
>>
>> Dear useRs,
>>
>> I'm having troubles with using ylim in barplot(): even though I reduce
>> the y-scale using ylim, the bars still extend down to 0into the 
>> x-labels.
>> The sample data is below, and here is the code.
>>
>> #This works fine but I would like to plot only from 50 to 70:
>> barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow",
>> "purple"), legend=TRUE, las=2, axis.lty=1)
>>
>> #This is the ylim version with the bar problem:
>> barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow",
>> "purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1)
>>
>> #I have tried using xpd=FALSE and this works fine withinRguior Rstudio
>> but not when I plot within devEMF::emf()
>> barplot(t(mydata), beside=TRUE, col=c("orange", "green", "yellow",
>> "purple"), ylim=c(50,70), legend=TRUE, las=2, axis.lty=1, xpd=FALSE)
>>
>> I need the emf file to edit the plot.
>>
>> Why isn't it working with ylim alone? And why doesn't xpd work with 
>> emf()?
>>
>> Thanks in advance for your help,
>> St?phanie
>>
>>
>> mydata <- structure(c(68.1799689328282, 68.2164021637813,
>> 68.3243626415103, 61.7899567386469, 59.5182501049449, 63.9916220705152,
>> 64.1442535260522, 64.2585746423512, 62.5653571705887, 61.631969055001,
>> 61.3991475513249, 63.2401411727188, 65.0488808306348, 63.43022364909,
>> 64.8425577471775, 65.4986231824992, 64.7798619682232, 64.4174790601806,
>> 65.5696701695485, 65.0253962620178, 63.2476885701954, 63.2473647791827,
>> 62.5000542212819, 63.1742307643225, 62.1560658393146, 62.5810636272476,
>> 64.0935149828315, 65.5432025084893, 66.7535104579705, 59.6500997601308,
>> 59.4641686257122, 59.8891527196501, 60.0117050975523, 64.3309521324969,
>> 62.0079305659785, 57.0665210362419, 57.5202118193362, 61.3280531011031,
>> 62.6326634763289, 60.2094259175778, 65.5923786551105, 65.6946445059829,
>> 65.2498254841218, 65.3468620859567, 67.024437492438, 65.8533801964148,
>> 65.0047369761726, 65.0310208374089, 64.3121920326177, 64.8038153143374,
>> 63.7306643056964, 64.2579190762784, 67.5745906026732, 67.0351170775703,
>> 66.4053872920113, 59.9302305698358, 60.368722602391, 60.3572311841096,
>> 60.0960412312049, 63.7886894551889, 62.24708719601, 59.3334729073243,
>> 59.9537485303794, 63.1828096654404, 63.5352778562394, 60.621828397375,
>> 65.8889763819732, 66.2059756115814, 66.4567010911873, 65.8796623180062,
>> 67.5552743734229, 66.504738660398, 66.2085036370622, 66.4230781907321,
>> 65.5130180297911, 65.9051623923225, 64.8408013974267, 65.5175045910169,
>> 68.0760225106606, 66.8615536135711, 65.0390748892256, 59.2940092440695,
>> 60.7061368898884, 59.7345965097738, 59.6019925755588, 63.6011933836225,
>> 62.1134684942427, 60.4227073441121, 60.7834352002706, 63.4539745079728,
>> 63.6329498376672, 58.8034486099638, 65.2910772858539, 65.5952764758513,
>> 65.8371262481454, 66.1191053038481, 67.5230043279325, 66.8569714429862,
>> 66.1045642986574, 66.8499631633452, 66.0121950308609, 66.2593339018511,
>> 65.4397264829666, 65.8389305084859), .Dim = c(26L, 4L), .Dimnames =
>> list(c("T40", "T41", "T42", "306iv01", "306iv02", "306iv19", "306iv13",
>> "306iv04", "306iv05", "402iv01", "402iv02", "402iv03", "306iv16",
>> "306iv10", "TG1", "TG2", "TG3", "TG4", "TG5", "TG6", "TG7", "TG8",
>> "TG9", "TG10", "TG11", "TG12"), c("L.mean", "L.mean_T1", "L.mean_T2",
>> "L.mean_T3")))
>>
>>
>


From Aljosa.Aleksandrovic at man.com  Tue Apr 26 18:16:42 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Tue, 26 Apr 2016 16:16:42 +0000
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>
Message-ID: <4cf18e411c5b419e814d85d4cbffc524@PLONINEXMS136.maninvestments.ad.man.com>

Hi Gabor,

Thanks a lot for your input!

Kind regards,
Aljosa



Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Dienstag, 26. April 2016 17:59
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

This is a quadratic programming problem that you can solve using either a quadratic programming solver with constraints or a general nonlinear solver with constraints.  See https://cran.r-project.org/web/views/Optimization.html
for more info on what is available.

Here is an example using a nonlinear least squares solver and non-negative bound constraints. The constraint that the coefficients sum to 1 is implied by dividing them by their sum and then dividing the coefficients found by their sum at the end:

# test data
set.seed(123)
n <- 1000
X1 <- rnorm(n)
X2 <- rnorm(n)
X3 <- rnorm(n)
Y <- .2 * X1 + .3 * X2 + .5 * X3 + rnorm(n)

# fit
library(nlmrt)
fm <- nlxb(Y ~ (b1 * X1 + b2 * X2 + b3 * X3)/(b1 + b2 + b3),
     data = list(Y = Y, X1 = X1, X2 = X2, X3 = X3),
     lower = numeric(3),
     start = list(b1 = 1, b2 = 2, b3 = 3))

giving the following non-negative coefficients which sum to 1 that are reasonably close to the true values of 0.2, 0.3 and 0.5:

> fm$coefficients / sum(fm$coefficients)
     b1      b2      b3
0.18463 0.27887 0.53650


On Tue, Apr 26, 2016 at 8:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Hi all,
>
> I hope you are doing well?
>
> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>
> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>
> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>
> I would very much appreciate if you could help me with my issue?
>
> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Dienstag, 26. April 2016 14:35
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Subject: Re: Linear Regressions with constraint coefficients
>
> You need to send it to r-help at r-project.org however.
>
> Kevin
>
> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>> Ok, will do! Thx a lot!
>>
>> Please find below my request:
>>
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:28
>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>
>> Kevin
>>
>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Do you know where I get help for my issue?
>>>
>>> Thanks in advance and kind regards,
>>> Aljosa
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> r-help-owner at r-project.org
>>> Sent: Dienstag, 26. April 2016 14:10
>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>> Subject: Linear Regressions with constraint coefficients
>>>
>>> The message's content type was not explicitly allowed
>>>
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

From dwinsemius at comcast.net  Tue Apr 26 18:20:49 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 Apr 2016 09:20:49 -0700
Subject: [R] Issue while building xtable on R on Ubuntu 15.04
In-Reply-To: <EC52F5F46B02B64EAECF93259BDB59F4212A2982@HJ-MBX2.persistent.co.in>
References: <EC52F5F46B02B64EAECF93259BDB59F4212A2982@HJ-MBX2.persistent.co.in>
Message-ID: <26508525-D7C6-4759-B51D-42495B1F2369@comcast.net>


> On Apr 26, 2016, at 4:08 AM, Zaid Golwala <zaid_golwala at persistent.com> wrote:
> 
> Please help in the below mentioned issue.
> 
> Regards
> Zaid Golwala
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Zaid Golwala
> Sent: Wednesday, April 06, 2016 1:35 PM
> To: r-help at R-project.org
> Subject: [R] Issue while building xtable on R on Ubuntu 15.04
> 
> Hi,
> 
> I am trying to build xtable on R  on Ubuntu 15.04 but I get following error :
> 
> 
> + R CMD check --no-vignettes --timings xtable_1.8-2.tar.gz
> 
> * using log directory '/home/jenkins/workspace/Rlang_xtable_Ubuntu15.04/xtable.Rcheck'
> 
> * using R version 3.2.3 (2015-12-10)
> 
> * using platform: powerpc64le-unknown-linux-gnu (64-bit)
> 
> * using session charset: UTF-8
> 
> * using option '--no-vignettes
> 
> '* checking for file 'xtable/DESCRIPTION' ... OK
> 
> * this is package 'xtable' version '1.8-2'
> 
> * checking package namespace information ... OK
> 
> * checking package dependencies ...Error in .build_vignette_index(vigns) :   In 'inst' vignettes 'xtableGallery.Rnw' and 'xtableGallery.snw' have the same vignette name

Why not change one of the names?

-- 
David.
> 
> Can someone please help me regarding the same.
> 
> Regards
> Zaid Golwala
> 
> DISCLAIMER\ ==========\ This e-mail ...{{dropped:18}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From andrluis at ualberta.ca  Tue Apr 26 19:11:38 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 26 Apr 2016 11:11:38 -0600
Subject: [R] From NUM to INT
Message-ID: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>

Dear all:

I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
(using excel) and then imported the data (.txt) into R. Interestingly, the
other three variables were loaded as INT, but the 'Baci' one continued as
Num.

I imported the data using the following command line:

X <- read.delim(file.choose(),
                 header = TRUE,
                 dec = ".")

Here is the structure of X:

> str(X)
'data.frame': 115 obs. of  5 variables:
 $ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18 26 27
29 31 32 36 ...
 $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
 $ Meti     : int  352645997 334146268 767208656 171567266 462747405
414905627 237010514 387480048 214671355 328813226 ...
 $ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156 13746
...
 $ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015 203685
4261780 43110492 69802572 ...


I need Baci as an integer, and tried to convert it using as.integer
function, but was not successful.


Could anyone please help me to solve this problem.

Thanks,


?
-- 
Andre
-------------- next part --------------
ID	Baci	Meti	Fungii	Protozoai
126BLK	2.90E+12	352645997	43645	3220523
13ZBLK	5.55E+11	334146268	19009	1851891
157BLK	9.46E+11	767208656	15998	3252462
162ZRED	8.13E+11	171567266	2189	1665675
17ZBLKY	4.06E+11	462747405	8972	34123768
184ZBLK	5.75E+11	414905627	8240	23175015
1ZBLKW	3.45E+10	237010514	3133	203685
2094ZBLK	3.49E+11	387480048	17922	4261780
20LZBLK	1.63E+11	214671355	6156	43110492
29ZBLK	3.37E+11	328813226	13746	69802572
2ZBLKG	3.13E+11	564519908	4003	93195958
60ZRED	3.76E+11	145383281	12473	33141411
77BLK	2.92E+11	227643897	13328	306363850
8ZBLK	2.45E+11	565298547	2900	29939862
91ZRED	5.62E+11	472996887	8584	73402283
112BLKW	7.02E+10	475554339	192654	37844605
1226BLK	1.84E+10	239034620	65524	3994847
12ZBLK	6.45E+10	296646742	286966	45244390
134BLK	9.65E+09	201168840	47474	2756770
160ZRED	5.96E+10	193983600	155040	79660710
166ZRED	8.14E+10	315417009	26056	85856558
17ZBLK G	1.88E+11	626249880	74214	17763633
226ZBLK	3.88E+10	181768548	291862	128256576
3ZBLK	2.38E+10	175939117	46015	8351259
58BLK	5.37E+10	304530782	50342	7718372
60ZBLK	4.23E+10	375725507	146473	58960339
72ZRED	9.58E+10	373650117	73205	171268872
7ZBLK	4.78E+10	146490232	17068	171268872
95BLK	4.18E+10	210377292	71368	31213851
9PZRED	7.12E+10	278312630	178204	392574732
107ZRED	1.18E+11	497812799	7074	5212968
129BLK	1.01E+10	172557004	565	373103
150ZRED	1.48E+11	343107486	7869	65118676
168BLK	9.45E+10	298332033	5281	17428719
174ZBLK	6.29E+10	269735103	24635	42532632
185ZRED	7.81E+10	647775276	1973	48855746
2ZBLKY	4.93E+09	35698451	3183	28935576
4089ZBLK	1.94E+10	326852779	1329	520051
438XZRED	7.20E+09	113153909	630	127811
4ZBLK	5.30E+10	248877230	1469	827989
706ZBLK	3.12E+10	151072339	2407	4885127
86BLK	9.39E+10	526984044	417	1034021
86ZRED	5.71E+10	385701592	7834	92440481
89BLK	3.80E+10	297806285	6314	62159379
112XZBLKG	9.56E+11	603355806	5205	199868382
1191ZBLK	4.59E+11	403738704	35115	93137246
122ZRED	2.93E+11	266699375	930	68471595
14ZBLK	8.03E+11	607043335	5570	75196835
15ZBLK	3.99E+11	185346266	1716	26429018
163BLK	7.18E+11	598193580	20475	419543828
175ZRED	2.08E+11	660223375	4421	35481033
1ZBLKY	6.84E+11	472986697	43059	137129730
20SXZBLK	3.16E+11	26119538	20297	8031502
22ZBLK	7.70E+11	823508297	154975	264859084
63ZBLK	2.10E+11	1601226529	13317	44878482
6ZBLK	1.31E+11	110772471	1395	40830068
82ZBLK	1.10E+12	839550736	5368	68087375
92ZBLK	4.32E+11	829679134	14981	98201518
94BLK	1.54E+11	197873442	1680	6800437
126BLK	2.22E+11	209765315	13000	92754991
13ZBLK	6.75E+11	366018180	18291	60965929
157BLK	2.88E+11	227660122	8904	20595699
162ZRED	1.85E+11	372912115	3124	516219
17ZBLKY	1.02E+11	170028711	4288	1391174
184ZBLK	4.28E+11	385951078	18173	142041693
1ZBLKW	1.26E+11	258658827	3974	1096335
2094ZBLK	2.80E+11	299019239	22940	4827333
20LZBLK	3.00E+11	258928407	1865	5996901
29ZBLK	2.75E+11	363091053	6551	7162010
2ZBLKG	4.53E+11	464020273	12748	20250369
60ZRED	2.45E+11	352738870	15630	22315303
77BLK	1.44E+11	342240282	4192	52542312
8ZBLK	6.66E+10	493488493	3308	8744844
91ZRED	3.52E+10	232562927	861	3506357
112BLKW	2.23E+10	261910886	35522	20277307
1226 BLK	2.39E+10	107972216	48447	25703984
12ZBLK	9.52E+09	392721062	21520	24103013
134BLK	1.73E+10	320819409	62156	107809914
160ZRED	1.06E+11	423290206	201494	62173555
166ZRED	2.92E+10	173837762	9813	4325219
17ZBLKG	2.87E+10	108073600	151168	19695454
226ZBLK	3.58E+10	470892623	203516	447240999
3ZBLK	1.98E+10	149631240	5962	758907
58BLK	6.71E+09	98009797	10103	18282903
60ZBLK	4.12E+10	382747754	96469	4348146
7ZBLK	7.97E+09	88160280	79680	0
95BLK	2.98E+10	202534656	33088	51649275
9PZRED	8.24E+10	388722787	274104	50360078
107ZRED	1.59E+11	109157702	170772	3550234
129BLK	7.59E+09	56423562	1081	1655868
150ZRED	5.69E+10	961853511	33383	13049429
168BLK	6.45E+10	858912603	5990	2934900
174ZBLK	2.04E+10	275907178	601	14077017
185ZRED	1.01E+11	659755530	12468	145136849
2ZBLKY	1.74E+11	458456526	1757	1314242
4089ZBLK	1.88E+11	166340053	2227	861368
438XZRED	3.83E+11	146896139	17545	25426282
4ZBLK	3.96E+11	340192787	7375	16393765
706ZBLK	3.35E+11	656715841	45618	16360596
86ZRED	3.58E+11	594300567	3410	6976935
89BLK	3.51E+11	452257311	22147	12239312
112XZBLKG	2.68E+11	32640092	49973	30637702
1191ZBLK	2.64E+11	744630951	6067	40742989
122ZRED	8.69E+11	1949076953	11653	75332032
14ZBLK	9.29E+11	683016842	50505	70023751
15ZBLK	9.35E+11	310951369	11492	73268344
163BLK	5.01E+11	285192250	12751	43365735
175ZRED	1.19E+12	597936244	14100	44029110
20SXZBLK	5.57E+11	903885504	22956	119497274
22ZBLK	2.60E+11	667969933	23005	6043141
63ZBLK	2.98E+11	685111047	3578	23920500
6ZBLK	4.77E+11	543466563	11550	39048343
82ZBLK	2.55E+11	697276518	3153	72481942
92ZBLK	1.95E+11	272494229	48511	60524953
94BLK	1.02E+12	2146559014	104139	258779386

From bgunter.4567 at gmail.com  Tue Apr 26 19:42:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 26 Apr 2016 10:42:28 -0700
Subject: [R] From NUM to INT
In-Reply-To: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
References: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
Message-ID: <CAGxFJbQY6N9COCNU3qKfUa-Uj_EgPTUF5DiA-qZLOOR6O7p9pw@mail.gmail.com>

No.

>From ?as.integer:

"Note that current implementations of R use 32-bit integers for
integer vectors, so the range of representable integers is restricted
to about +/-2*10^9: doubles can hold much larger integers exactly. "

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 26, 2016 at 10:11 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Dear all:
>
> I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
> (using excel) and then imported the data (.txt) into R. Interestingly, the
> other three variables were loaded as INT, but the 'Baci' one continued as
> Num.
>
> I imported the data using the following command line:
>
> X <- read.delim(file.choose(),
>                  header = TRUE,
>                  dec = ".")
>
> Here is the structure of X:
>
>> str(X)
> 'data.frame': 115 obs. of  5 variables:
>  $ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18 26 27
> 29 31 32 36 ...
>  $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
>  $ Meti     : int  352645997 334146268 767208656 171567266 462747405
> 414905627 237010514 387480048 214671355 328813226 ...
>  $ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156 13746
> ...
>  $ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015 203685
> 4261780 43110492 69802572 ...
>
>
> I need Baci as an integer, and tried to convert it using as.integer
> function, but was not successful.
>
>
> Could anyone please help me to solve this problem.
>
> Thanks,
>
>
>
> --
> Andre
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Apr 26 19:56:57 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 26 Apr 2016 10:56:57 -0700
Subject: [R] From NUM to INT
In-Reply-To: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
References: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
Message-ID: <78D2C712-8B64-43BD-8487-1EF37E067685@dcn.davis.ca.us>

That is the "impossible" case, since R integers are 32 bit signed (~2?10^9) even in 64 bit R. You can Google for "R arbitrary precision" and look for packages like Ryacas, bit64 or gmp. However, having such large integers stored as integers would not be necessary for most statistical analyses so you should confirm that your analysis cannot be performed using floating point numbers before resorting to that.
-- 
Sent from my phone. Please excuse my brevity.

On April 26, 2016 10:11:38 AM PDT, "Andr? Luis Neves" <andrluis at ualberta.ca> wrote:
>Dear all:
>
>I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
>(using excel) and then imported the data (.txt) into R. Interestingly,
>the
>other three variables were loaded as INT, but the 'Baci' one continued
>as
>Num.
>
>I imported the data using the following command line:
>
>X <- read.delim(file.choose(),
>                 header = TRUE,
>                 dec = ".")
>
>Here is the structure of X:
>
>> str(X)
>'data.frame': 115 obs. of  5 variables:
>$ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18 26
>27
>29 31 32 36 ...
> $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
> $ Meti     : int  352645997 334146268 767208656 171567266 462747405
>414905627 237010514 387480048 214671355 328813226 ...
>$ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156
>13746
>...
>$ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015
>203685
>4261780 43110492 69802572 ...
>
>
>I need Baci as an integer, and tried to convert it using as.integer
>function, but was not successful.
>
>
>Could anyone please help me to solve this problem.
>
>Thanks,
>
>
>?
>-- 
>Andre
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Apr 26 19:59:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 26 Apr 2016 10:59:11 -0700
Subject: [R] From NUM to INT
In-Reply-To: <CAHxKz8aA2VH0R0DSpZ_uCVe=8g1v8vM2bPo1PLi70H+uZJdPKw@mail.gmail.com>
References: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
	<CAGxFJbQY6N9COCNU3qKfUa-Uj_EgPTUF5DiA-qZLOOR6O7p9pw@mail.gmail.com>
	<CAHxKz8aA2VH0R0DSpZ_uCVe=8g1v8vM2bPo1PLi70H+uZJdPKw@mail.gmail.com>
Message-ID: <CAGxFJbSCPhwRtvon4tM868gwPcGj5an2+Tuf9gFUo+uU6FB18g@mail.gmail.com>

Please respond to the list. It will be obvious why in a second.

That's not my threshhold! -- it's R's. Your numeric integers cannot be
exactly represented as integers in R. Period. Maybe there are special
packages for extended arithmetic that can do this. but someone else
would have to help you there.  See here for a discussion that might be
helpful:

http://www.r-bloggers.com/r-in-a-64-bit-world/


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 26, 2016 at 10:46 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> So, How could I implement this, Bert?
>
> I really need that the variable be converted unto an integer, and it seems
> that my numbers are much higher than that threshold you stated.
>
> Thanks,
>
> Andre
>
> On Tue, Apr 26, 2016 at 11:42 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>
>> No.
>>
>> From ?as.integer:
>>
>> "Note that current implementations of R use 32-bit integers for
>> integer vectors, so the range of representable integers is restricted
>> to about +/-2*10^9: doubles can hold much larger integers exactly. "
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Apr 26, 2016 at 10:11 AM, Andr? Luis Neves <andrluis at ualberta.ca>
>> wrote:
>> > Dear all:
>> >
>> > I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
>> > (using excel) and then imported the data (.txt) into R. Interestingly,
>> > the
>> > other three variables were loaded as INT, but the 'Baci' one continued
>> > as
>> > Num.
>> >
>> > I imported the data using the following command line:
>> >
>> > X <- read.delim(file.choose(),
>> >                  header = TRUE,
>> >                  dec = ".")
>> >
>> > Here is the structure of X:
>> >
>> >> str(X)
>> > 'data.frame': 115 obs. of  5 variables:
>> >  $ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18 26
>> > 27
>> > 29 31 32 36 ...
>> >  $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
>> >  $ Meti     : int  352645997 334146268 767208656 171567266 462747405
>> > 414905627 237010514 387480048 214671355 328813226 ...
>> >  $ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156
>> > 13746
>> > ...
>> >  $ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015
>> > 203685
>> > 4261780 43110492 69802572 ...
>> >
>> >
>> > I need Baci as an integer, and tried to convert it using as.integer
>> > function, but was not successful.
>> >
>> >
>> > Could anyone please help me to solve this problem.
>> >
>> > Thanks,
>> >
>> >
>> >
>> > --
>> > Andre
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Andre


From joeceradini at gmail.com  Tue Apr 26 20:04:26 2016
From: joeceradini at gmail.com (Joe Ceradini)
Date: Tue, 26 Apr 2016 12:04:26 -0600
Subject: [R] survival::clogit, how to extract residuals for GOF assessment
Message-ID: <CAKq2vL7Wd-bW6bxvhjwQOJdoY=pfGF0JqOkmJi_hmzNLx9FyZg@mail.gmail.com>

Hi Folks,

Hopefully this question has enough R and not too much stats to be
appropriate for this list. Based on,* Hosmer et al. 2013. Logistic
regression for matched case-control studies. Applied Logistic
Regression *(eqtn.
7.8)*, *I am assessing GOF of conditional (or matched) logistic regression
models with the *standardized Pearson residuals*. The authors define
?large? as delta chi-squared values > 4.

For a 1:1 study, I can fit a conditional logistic model via an
unconditional routine by making the response variable all 1?s, taking the
difference of the covariate values for each pair, and removing the
intercept. I can then extract the standardized residuals from the model
(see code at bottom for example). However, if I want to fit a 1:many model,
I need to use survival::clogit, which is where my question comes in:

How can I apply this same "test" to a clogit model? Which residuals should
I be extracting? Or, is this not an option for a clogit model?

## The default residuals of coxph in R are the martingale residuals.

## resid(fit1,type=c("martingale", "deviance", "score", "schoenfeld",

##                   "dfbeta", "dfbetas", "scaledsch","partial"))



R code below shows equivalence between clogit and binomial GLM fit on the
differences (note: these would not be equivalent if used a "cluster"
argument in clogit), and GOF "test" for binomial GLM fit on the
differences. I would like to assess GOF of the fit.clogit model but do not
know how.


require(survival)

require(plyr)


# Dataframe

dat.full <- structure(list(resp = c(1L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L,

0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L,

0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L,

0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L,

1L, 0L), x1 = c(3.92, 2.04, 2.27, 9.25, 6.13, 10.44, 5.09, 1.27,

5.9, 2.88, 3.79, 1.46, 3.35, 3.82, 4.28, 6.52, 3.54, 3.46, 0.46,

1.68, 3.22, 1.64, -0.12, 2.78, 2.58, 2, 2.83, 3.58, 1.45, 1.64,

2.89, 3.12, 5.6, 8.29, 3.42, 4.8, 3.04, 4.33, 5.31, 1.78, 8.18,

4.56, 4.85, 7.99, 7.52, 6.85, 7.64, 3.33, 5.17, 4.62, 1.24, 2.54,

3.08, 8.2, 1.81, 2.78, 2.16, 2.76, 3.45, 3.43), ID = c(10L, 10L,

11L, 11L, 13L, 13L, 17L, 17L, 18L, 18L, 23L, 23L, 25L, 25L, 29L,

29L, 31L, 31L, 33L, 33L, 35L, 35L, 38L, 38L, 39L, 39L, 4L, 4L,

41L, 41L, 43L, 43L, 45L, 45L, 46L, 46L, 49L, 49L, 50L, 50L, 54L,

54L, 55L, 55L, 56L, 56L, 57L, 57L, 59L, 59L, 6L, 6L, 60L, 60L,

7L, 7L, 8L, 8L, 9L, 9L)), .Names = c("resp", "x1", "ID"), row.names = c(1L,

2L, 3L, 4L, 7L, 8L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 21L,

22L, 23L, 24L, 25L, 26L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L,

37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 45L, 46L, 49L, 50L, 55L,

56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L,

71L, 72L, 73L, 74L, 75L, 76L), class = "data.frame")


# fit clogit

fit.clogit <- clogit(resp ~ x1 + strata(ID), method = "efron", data =
dat.full)

summary(fit.clogit)


# Make dataframe so can fit on differences with unconditional routine.

# x1 where resp = 1 minus x1 where resp = 0, grouped by ID

dat.diff <- ddply(dat.full, .(ID), summarise,

      x1.diff = x1[resp == 1] - x1[resp == 0])

dat.diff$resp <- 1 # response variable is all 1's


# Fit on differences and 1's, remove intercept

fit.diff <- glm(resp ~ -1 + x1.diff, family = binomial, data = dat.diff)

summary(fit.diff)

summary(fit.clogit)$coefficients


# GOF: delta chi-squared

plot(fit.diff$fitted.values, rstandard(fit.diff)^2)

round(sort(rstandard(fit.diff)^2), 4)

Thanks!
Joe

	[[alternative HTML version deleted]]


From chlsrocks at yahoo.com  Tue Apr 26 20:05:25 2016
From: chlsrocks at yahoo.com (charles rockson)
Date: Tue, 26 Apr 2016 18:05:25 +0000 (UTC)
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <3963ea68a4964fbe8618a5dedbe488dd@PLONINEXMS136.maninvestments.ad.man.com>
References: <3963ea68a4964fbe8618a5dedbe488dd@PLONINEXMS136.maninvestments.ad.man.com>
Message-ID: <925427881.2694973.1461693925216.JavaMail.yahoo@mail.yahoo.com>

Any help with exporting anova output in R to csv or xlsx?

      From: "Aleksandrovic, Aljosa (Pfaeffikon)" <Aljosa.Aleksandrovic at man.com>
 To: Bert Gunter <bgunter.4567 at gmail.com> 
Cc: "r-help at r-project.org" <r-help at r-project.org>
 Sent: Tuesday, April 26, 2016 8:29 AM
 Subject: Re: [R] Linear Regressions with constraint coefficients
   
Ok, and if I would just like to force my slope coefficients to be inside an interval, let's say, between 0 and 1? Is there a way in R to formulate such a constraint regression?

Thanks in advance and kind regards,
Aljosa



Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 7603

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Dienstag, 26. April 2016 16:51
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

If the slope coefficients sum to a constant, the regressors are dependent and so a unique solution is impossible (an infinity of solutions would result). So I think you have something going on that you don't understand and should consult a local statistician to help you formulate your problem appropriately.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 26, 2016 at 5:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Hi all,
>
> I hope you are doing well?
>
> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>
> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>
> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>
> I would very much appreciate if you could help me with my issue?
>
> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Dienstag, 26. April 2016 14:35
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Subject: Re: Linear Regressions with constraint coefficients
>
> You need to send it to r-help at r-project.org however.
>
> Kevin
>
> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>> Ok, will do! Thx a lot!
>>
>> Please find below my request:
>>
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:28
>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>
>> Kevin
>>
>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Do you know where I get help for my issue?
>>>
>>> Thanks in advance and kind regards,
>>> Aljosa
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> r-help-owner at r-project.org
>>> Sent: Dienstag, 26. April 2016 14:10
>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>> Subject: Linear Regressions with constraint coefficients
>>>
>>> The message's content type was not explicitly allowed
>>>
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,? Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
>
> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan? Lane, London, EC4R 3AD.
> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From fbjournals at gmail.com  Tue Apr 26 21:20:40 2016
From: fbjournals at gmail.com (Frank B. )
Date: Tue, 26 Apr 2016 22:20:40 +0300
Subject: [R] vectors of equations in ode / desolve
Message-ID: <571FBF88.3030603@gmail.com>

Hello,

I have a syntactic problem with ode. How do I specify vectors of
equations in ordinary differential equation systems. (i.e. in my case I
want to simulate an a priory undefined number of species that have
different  parameters but the same behaviour)

I demonstrate this using the Lotka Volterra example. The code below does
not work and I have not a good idea how to specify this right. 


## =======================================================================
## Example1: Predator-Prey Lotka-Volterra model (with logistic prey)
## =======================================================================

LVmod <- function(Time, State, Pars) {
  with(as.list(c(State, Pars)), {
# Now there are different species of Prey so Prey is a one dimensional
vector,
#Ingestion is also a one-dimensional vector.  The number of species is
not defined a priory
    Ingestion    <- rIng  * Prey * Predator
    GrowthPrey   <- rGrow * Prey * (1 - Prey/K)
    MortPredator <- rMort * Predator

    dPrey        <- GrowthPrey - Ingestion
# the    growth of predator would depend on the ingestion of all prays
regardless of species
    sumIngestion<-sum(Ingestion)
dPredator    <- sumIngestion * assEff - MortPredator
 # returning an array of preys does produce an error
    return(list(c(dPrey, dPredator)))
  })
}


# Example is made for  three different species of prey
pars  <- c(rIng   = 0.2,    # /day, rate of ingestion
# I do not know how to pass on these parameters as a vector this
productes and error
           rGrow  = c(1.0, 1.3, 1.7)    # /day, growth rate of prey
           rMort  = 0.2 ,   # /day, mortality rate of predator
           assEff = 0.5,    # -, assimilation efficiency
           K      = 10)     # mmol/m3, carrying capacity

yini  <- c(Prey = c(1, 2,3), Predator = 2)
times <- seq(0, 200, by = 1)
out   <- ode(yini, times, LVmod, pars)
summary(out)


Thanks

Frank


From jholtman at gmail.com  Tue Apr 26 22:36:59 2016
From: jholtman at gmail.com (jim holtman)
Date: Tue, 26 Apr 2016 16:36:59 -0400
Subject: [R] From NUM to INT
In-Reply-To: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
References: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
Message-ID: <CAAxdm-7nbOHrNsL+z8MutinnOpr9usP_DeTe2Pq_XLGsQCGArw@mail.gmail.com>

Can you explain why you need them as 'integer',  A floating point
representation can hold a value upto ~4.5e15 as an "integer" keeping the
precision that you might need.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Apr 26, 2016 at 1:11 PM, Andr? Luis Neves <andrluis at ualberta.ca>
wrote:

> Dear all:
>
> I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
> (using excel) and then imported the data (.txt) into R. Interestingly, the
> other three variables were loaded as INT, but the 'Baci' one continued as
> Num.
>
> I imported the data using the following command line:
>
> X <- read.delim(file.choose(),
>                  header = TRUE,
>                  dec = ".")
>
> Here is the structure of X:
>
> > str(X)
> 'data.frame': 115 obs. of  5 variables:
>  $ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18 26 27
> 29 31 32 36 ...
>  $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
>  $ Meti     : int  352645997 334146268 767208656 171567266 462747405
> 414905627 237010514 387480048 214671355 328813226 ...
>  $ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156 13746
> ...
>  $ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015 203685
> 4261780 43110492 69802572 ...
>
>
> I need Baci as an integer, and tried to convert it using as.integer
> function, but was not successful.
>
>
> Could anyone please help me to solve this problem.
>
> Thanks,
>
>
> ?
> --
> Andre
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From faradj.g at gmail.com  Tue Apr 26 22:51:21 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Tue, 26 Apr 2016 22:51:21 +0200
Subject: [R] Predicting probabilities in ordinal probit analysis in R
Message-ID: <98DA08BF-BAB4-4DB8-B1A9-58D03E34F5F6@gmail.com>

Dear all, 

I have two questions that are almost completely related to how to do things in R.

I am running an ordinal probit regression analysis in R. The dependent variable has three levels (0=no action; 1=warning; 2=sanction).

I use the lrm command in the rms package:

print( res1<- lrm(Y ~ x1+x2+x3+x4+x5+x6, y=TRUE, x=TRUE, data=mydata))
I simply couldn't make any sense of the information generated my ?predict.lrm. What I want to do is to calculate the marginal effects of all explanatory variables for each level of the dependent variable. In Stata, this is very simple: mfx compute, predict (outcome(#0)); mfx compute, predict (outcome(#2)) and mfx compute, predict (outcome(#3)).

So my first question is: how do I generate marginal effects for each outcome in R? 

The second question is related to interaction effects, which I need to include in the same model:

print( res1<- lrm(Y ~ x1+x2+x3+x4+x5+x6+x5*x6, y=TRUE, x=TRUE, data=mydata))
If I knew the answer to the first question, I would have ran marginal effects with the interaction term included. Then, I would have plotted the predicted values of the interaction term.

So the second question is: how do I plot the effects (predicted values) of variables in the interaction term?

Many thanks!

Small sample from my dataset (only one country)

dput(mydatasample)

structure(list(year = 1989:2014, country = structure(c(1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "Canada", class = "factor"), 
    id = structure(1:26, .Label = c("CAN 1989", "CAN 1990", "CAN 1991", 
    "CAN 1992", "CAN 1993", "CAN 1994", "CAN 1995", "CAN 1996", 
    "CAN 1997", "CAN 1998", "CAN 1999", "CAN 2000", "CAN 2001", 
    "CAN 2002", "CAN 2003", "CAN 2004", "CAN 2005", "CAN 2006", 
    "CAN 2007", "CAN 2008", "CAN 2009", "CAN 2010", "CAN 2011", 
    "CAN 2012", "CAN 2013", "CAN 2014"), class = "factor"), stage1 = c(1L, 
    1L, 0L, 0L, 0L, 0L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 0L, 0L, 0L, 
    0L, 2L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L), x1 = c(1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L), x2 = c(1L, 2L, 1L, 2L, 2L, 
    2L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 
    2L, 1L, 2L, 2L, 2L, 2L), x3 = c(9L, 9L, 9L, 9L, 9L, 9L, 9L, 
    9L, 9L, 9L, 9L, 8L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L), x4 = c(31L, 31L, 31L, 31L, 
    31L, 30L, 30L, 30L, 31L, 30L, 29L, 30L, 28L, 28L, 28L, 27L, 
    29L, 29L, 29L, 28L, 25L, 24L, 23L, NA, NA, NA), x5 = structure(1:26, .Label = c("17,12528685", 
    "17,14022279", "17,15382785", "17,16610202", "17,17704534", 
    "17,18665779", "17,19493938", "17,20571103", "17,21628118", 
    "17,22493732", "17,23321101", "17,242041", "17,25213621", 
    "17,26110753", "17,27106985", "17,2810902", "17,29094924", 
    "17,29891768", "17,30861622", "17,31943819", "17,33088659", 
    "17,34202619", "17,35190237", "17,36381421", "17,37537139", 
    "17,38618117"), class = "factor"), x5.1 = c(0L, 0L, 0L, 0L, 
    1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 
    0L, 0L, 0L, 0L, 1L, 1L, 0L)), .Names = c("year", "country", 
"id", "stage1", "x1", "x2", "x3", "x4", "x5", "x5.1"), class = "data.frame", row.names = c(NA, 
-26L))




	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Tue Apr 26 23:21:00 2016
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 26 Apr 2016 14:21:00 -0700
Subject: [R] table ,
	exclude - count the frequency in a data frame but exclude one value
Message-ID: <CABcx46BjgGysuj68=Q88SPOC+vaXV6KSpKCXt1z_1xJtGtxf2g@mail.gmail.com>

Hi,

   I have a data frame with two variables x, y, both of which take values
in the set {1,2,3}. I'd like to count the frequency by the command "table",
but exclude the value "1" in variable x, but keep "1" in variable y. Is it
possible?  When I use "exclude", value 1 in both x and y are excluded.
Thanks,


> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
> table(df[,c("y","x")])
   x
y   1 2 3
  1 0 0 1
  2 0 1 0
  3 1 0 0
> table(df[,c("y","x")], exclude = 1)
   x
y   2 3
  2 1 0
  3 0 0
> table(df[,c("y","x")], exclude = c(NULL, 1))
   x
y   2 3
  2 1 0
  3 0 0
> table(df[,c("y","x")], exclude = c(1, NULL))
   x
y   2 3
  2 1 0
  3 0 0
> table(df[,c("y","x")], exclude = c(1, 0))
   x
y   2 3
  2 1 0
  3 0 0
> table(df[,c("y","x")], exclude = list(1 , NULL))
Error in as.vector(exclude, typeof(x)) :
  (list) object cannot be coerced to type 'integer'

	[[alternative HTML version deleted]]


From andrluis at ualberta.ca  Tue Apr 26 23:25:28 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 26 Apr 2016 15:25:28 -0600
Subject: [R] From NUM to INT
In-Reply-To: <CAAxdm-7nbOHrNsL+z8MutinnOpr9usP_DeTe2Pq_XLGsQCGArw@mail.gmail.com>
References: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
	<CAAxdm-7nbOHrNsL+z8MutinnOpr9usP_DeTe2Pq_XLGsQCGArw@mail.gmail.com>
Message-ID: <CAHxKz8Zq3hXxO87e6TkQvQqO_kO9cYvMRgF59nRsYTD7SueBDA@mail.gmail.com>

Ok. I`m trying to run a Poisson glmm with an observation-level random
intercept. But I`m getting the following error for the 'Baci' variable:

'Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate'. I  guess this message is because the baci variable is not a
an integer, and cannot be transformed into an integer as R has a threshold
of
2x10^9 even in 64 bit R.

It runs fine for the fungii variable.

If you guys want to run the data (attached), the full command is below.

Thanks.

---------------------------------------------

##Import data:

qPCR <- read.delim(file.choose(),
                 header = TRUE,
                 dec = ".")

##Load package

library(lme4)

##Other steps:

qPCR$obs <- 1:nrow(qPCR)
qPCR$fID<-as.factor(qPCR$ID)
qPCR$fDiet<-as.factor(qPCR$Diet)

##Run the model:

M1 <- glmer (Baci ~ fDiet + Crossover + (1|fID:Crossover) + (1|obs),
             family = poisson, data=qPCR)



Andre



On Tue, Apr 26, 2016 at 2:36 PM, jim holtman <jholtman at gmail.com> wrote:

> Can you explain why you need them as 'integer',  A floating point
> representation can hold a value upto ~4.5e15 as an "integer" keeping the
> precision that you might need.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Tue, Apr 26, 2016 at 1:11 PM, Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
>
>> Dear all:
>>
>> I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
>> (using excel) and then imported the data (.txt) into R. Interestingly, the
>> other three variables were loaded as INT, but the 'Baci' one continued as
>> Num.
>>
>> I imported the data using the following command line:
>>
>> X <- read.delim(file.choose(),
>>                  header = TRUE,
>>                  dec = ".")
>>
>> Here is the structure of X:
>>
>> > str(X)
>> 'data.frame': 115 obs. of  5 variables:
>>  $ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18 26 27
>> 29 31 32 36 ...
>>  $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
>>  $ Meti     : int  352645997 334146268 767208656 171567266 462747405
>> 414905627 237010514 387480048 214671355 328813226 ...
>>  $ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156 13746
>> ...
>>  $ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015
>> 203685
>> 4261780 43110492 69802572 ...
>>
>>
>> I need Baci as an integer, and tried to convert it using as.integer
>> function, but was not successful.
>>
>>
>> Could anyone please help me to solve this problem.
>>
>> Thanks,
>>
>>
>> ?
>> --
>> Andre
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Andre
-------------- next part --------------
ID	Crossover	Period	Diet	Pen	Time	Baci	Fungii	fNDF	Starch
126BLK	1	1	Forage	1	End1	2.90E+12	43645	3.87056104	1.443771827
13ZBLK	1	1	Forage	1	End1	5.55E+11	19009	3.970286296	1.480970702
157BLK	1	1	Forage	1	End1	9.46E+11	15998	4.114130366	1.534626493
162ZRED	1	1	Forage	1	End1	8.13E+11	2189	3.600760128	1.343132423
17ZBLKY	1	1	Forage	1	End1	4.06E+11	8972	3.79087129	1.414046468
184ZBLK	1	1	Forage	1	End1	5.75E+11	8240	3.815881751	1.42337571
1ZBLKW	1	1	Forage	1	End1	34490836164	3133	3.295433507	1.229241447
2094ZBLK	1	1	Forage	1	End1	3.49E+11	17922	3.737865394	1.394274549
20LZBLK	1	1	Forage	1	End1	1.63E+11	6156	4.007824601	1.494972999
29ZBLK	1	1	Forage	1	End1	3.37E+11	13746	3.59031272	1.339235398
2ZBLKG	1	1	Forage	1	End1	3.13E+11	4003	3.964994752	1.478996884
60ZRED	1	1	Forage	1	End1	3.76E+11	12473	3.477652579	1.297211636
77BLK	1	1	Forage	1	End1	2.92E+11	13328	4.546906317	1.696057799
8ZBLK	1	1	Forage	1	End1	2.45E+11	2900	4.447927304	1.659137284
91ZRED	1	1	Forage	1	End1	5.62E+11	8584	4.118042491	1.536085769
112BLKW	2	1	Forage	2	End1	70249927920	192654	4.024558544	1.501214987
1226BLK	2	1	Forage	2	End1	18390770816	65524	3.933087193	1.467094931
12ZBLK	2	1	Forage	2	End1	64465242768	286966	3.678844325	1.372258889
134BLK	2	1	Forage	2	End1	9652868358	47474	3.902242465	1.455589429
160ZRED	2	1	Forage	2	End1	59600548800	155040	3.853736644	1.437496099
166ZRED	2	1	Forage	2	End1	81366127920	26056	4.037719564	1.506124226
17ZBLK G	2	1	Forage	2	End1	1.88E+11	74214	3.498366487	1.304938205
226ZBLK	2	1	Forage	2	End1	38794514336	291862	3.406420254	1.270641011
3ZBLK	2	1	Forage	2	End1	23837817696	46015	3.865246883	1.441789574
58BLK	2	1	Forage	2	End1	53734722624	50342	4.190382875	1.563069714
60ZBLK	2	1	Forage	2	End1	42301298024	146473	3.628258067	1.353389528
72ZRED	2	1	Forage	2	End1	95837208152	73205	4.123718464	1.538202984
7ZBLK	2	1	Forage	2	End1	47824296528	17068	4.028244534	1.502589911
95BLK	2	1	Forage	2	End1	41780037212	71368	4.099205498	1.529059315
9PZRED	2	1	Forage	2	End1	71202504840	178204	3.380912297	1.261126197
107ZRED	3	1	Grain	3	End1	1.18E+11	7074	2.146324344	3.007347766
129BLK	3	1	Grain	3	End1	10054798609	565	2.372894545	3.324809285
150ZRED	3	1	Grain	3	End1	1.48E+11	7869	2.152246315	3.015645405
168BLK	3	1	Grain	3	End1	94464253180	5281	2.500082872	3.503020716
174ZBLK	3	1	Grain	3	End1	62911040256	24635	2.273695448	3.185815296
185ZRED	3	1	Grain	3	End1	78074111590	1973	1.894214123	2.654100545
2ZBLKY	3	1	Grain	3	End1	4929843844	3183	2.483620769	3.479954645
4089ZBLK	3	1	Grain	3	End1	19370087262	1329	2.213050085	3.100841327
438XZRED	3	1	Grain	3	End1	7196105124	630	2.217241768	3.106714553
4ZBLK	3	1	Grain	3	End1	52954599928	1469	2.217302693	3.10679992
706ZBLK	3	1	Grain	3	End1	31205271204	2407	2.15080847	3.013630752
86BLK	3	1	Grain	3	End1	93866942272	417	2.753545642	3.858163077
86ZRED	3	1	Grain	3	End1	57127597772	7834	2.295665227	3.216598513
89BLK	3	1	Grain	3	End1	37992593088	6314	2.476126918	3.469454547
112XZBLKG	4	1	Grain	4	End1	9.56E+11	5205	1.890716993	2.649200499
1191ZBLK	4	1	Grain	4	End1	4.59E+11	35115	2.043372229	2.863095191
122ZRED	4	1	Grain	4	End1	2.93E+11	930	2.1174456	2.966883971
14ZBLK	4	1	Grain	4	End1	8.03E+11	5570	2.268248698	3.178183517
15ZBLK	4	1	Grain	4	End1	3.99E+11	1716	2.22233515	3.113851206
163BLK	4	1	Grain	4	End1	7.18E+11	20475	2.524745564	3.537577138
175ZRED	4	1	Grain	4	End1	2.08E+11	4421	2.113107696	2.960805865
1ZBLKY	4	1	Grain	4	End1	6.84E+11	43059	2.593311258	3.633648772
20SXZBLK	4	1	Grain	4	End1	3.16E+11	20297	1.878154129	2.631597894
22ZBLK	4	1	Grain	4	End1	7.70E+11	154975	2.263447759	3.171456625
63ZBLK	4	1	Grain	4	End1	2.10E+11	13317	2.444859889	3.425644379
6ZBLK	4	1	Grain	4	End1	1.31E+11	1395	2.630183444	3.685312672
82ZBLK	4	1	Grain	4	End1	1.10E+12	5368	2.102445712	2.945866701
92ZBLK	4	1	Grain	4	End1	4.32E+11	14981	2.137551055	2.995054968
94BLK	4	1	Grain	4	End1	1.54E+11	1680	2.533433557	3.549750423
126BLK	1	2	Forage	1	End2	2.22E+11	13000	4.760093885	1.775579657
13ZBLK	1	2	Forage	1	End2	6.75E+11	18291	4.585536093	1.71046723
157BLK	1	2	Forage	1	End2	2.88E+11	8904	5.286298418	1.971861094
162ZRED	1	2	Forage	1	End2	1.85E+11	3124	4.501846838	1.679250002
17ZBLKY	1	2	Forage	1	End2	1.02E+11	4288	4.722218572	1.761451651
184ZBLK	1	2	Forage	1	End2	4.28E+11	18173	4.787683496	1.785870957
1ZBLKW	1	2	Forage	1	End2	1.26E+11	3974	4.120447496	1.536982868
2094ZBLK	1	2	Forage	1	End2	2.80E+11	22940	5.320906238	1.98477028
20LZBLK	1	2	Forage	1	End2	3.00E+11	1865	4.910904822	1.831834185
29ZBLK	1	2	Forage	1	End2	2.75E+11	6551	4.64713525	1.733444553
2ZBLKG	1	2	Forage	1	End2	4.53E+11	12748	5.216415474	1.945793806
60ZRED	1	2	Forage	1	End2	2.45E+11	15630	4.320339869	1.611545438
77BLK	1	2	Forage	1	End2	1.44E+11	4192	4.946939294	1.845275532
8ZBLK	1	2	Forage	1	End2	66556874137	3308	5.369136284	2.002760742
91ZRED	1	2	Forage	1	End2	35178277612	861	5.194279355	1.937536734
112BLKW	2	2	Grain	2	End2	22345514304	35522	2.189470508	3.067802525
1226 BLK	2	2	Grain	2	End2	23881492608	48447	2.61032416	3.657486601
12ZBLK	2	2	Grain	2	End2	9521876928	21520	2.66964942	3.740610891
134BLK	2	2	Grain	2	End2	17265347752	62156	3.266154115	4.576410507
160ZRED	2	2	Grain	2	End2	1.06E+11	201494	2.801511562	3.925371093
166ZRED	2	2	Grain	2	End2	29245020768	9813	2.633190427	3.689525942
17ZBLKG	2	2	Grain	2	End2	28686200320	151168	2.684194907	3.760991472
226ZBLK	2	2	Grain	2	End2	35823496868	203516	2.656602944	3.722330667
3ZBLK	2	2	Grain	2	End2	19774776776	5962	3.01716587	4.22753768
58BLK	2	2	Grain	2	End2	6712885842	10103	2.776815993	3.890768604
60ZBLK	2	2	Grain	2	End2	41185544916	96469	2.757875102	3.86422935
7ZBLK	2	2	Grain	2	End2	7965902400	79680	2.876690768	4.030709327
95BLK	2	2	Grain	2	End2	29843174520	33088	3.319343593	4.650937575
9PZRED	2	2	Grain	2	End2	82361326080	274104	2.695285046	3.776530553
107ZRED	3	2	Forage	3	End2	1.59E+11	170772	4.574352981	1.706295778
129BLK	3	2	Forage	3	End2	7594466101	1081	5.509799583	2.055230063
150ZRED	3	2	Forage	3	End2	56872492896	33383	4.602932045	1.716956157
168BLK	3	2	Forage	3	End2	64542557920	5990	5.156588126	1.923477393
174ZBLK	3	2	Forage	3	End2	20398760236	601	4.777512847	1.782077167
185ZRED	3	2	Forage	3	End2	1.01E+11	12468	4.531116217	1.690167878
2ZBLKY	3	2	Forage	3	End2	1.74E+11	1757	5.336898548	1.990735629
4089ZBLK	3	2	Forage	3	End2	1.88E+11	2227	4.617405661	1.722355012
438XZRED	3	2	Forage	3	End2	3.83E+11	17545	4.698264622	1.752516503
4ZBLK	3	2	Forage	3	End2	3.96E+11	7375	4.899836763	1.827705648
706ZBLK	3	2	Forage	3	End2	3.35E+11	45618	4.437969639	1.655422939
86ZRED	3	2	Forage	3	End2	3.58E+11	3410	4.810601973	1.79441986
89BLK	3	2	Forage	3	End2	3.51E+11	22147	4.768193587	1.778600956
112XZBLKG	4	2	Grain	4	End2	2.68E+11	49973	2.531626089	3.547217868
1191ZBLK	4	2	Grain	4	End2	2.64E+11	6067	2.63885618	3.697464579
122ZRED	4	2	Grain	4	End2	8.69E+11	11653	2.389283575	3.347772968
14ZBLK	4	2	Grain	4	End2	9.29E+11	50505	2.780220526	3.895538906
15ZBLK	4	2	Grain	4	End2	9.35E+11	11492	2.662929278	3.731194885
163BLK	4	2	Grain	4	End2	5.01E+11	12751	2.616739418	3.666475416
175ZRED	4	2	Grain	4	End2	1.19E+12	14100	2.539769021	3.558627433
20SXZBLK	4	2	Grain	4	End2	5.57E+11	22956	2.310979313	3.238056024
22ZBLK	4	2	Grain	4	End2	2.60E+11	23005	2.772700065	3.885001523
63ZBLK	4	2	Grain	4	End2	2.98E+11	3578	2.921279989	4.093186042
6ZBLK	4	2	Grain	4	End2	4.77E+11	11550	2.511694326	3.519290242
82ZBLK	4	2	Grain	4	End2	2.55E+11	3153	2.781770351	3.897710461
92ZBLK	4	2	Grain	4	End2	1.95E+11	48511	2.666117852	3.735662593
94BLK	4	2	Grain	4	End2	1.02E+12	104139	2.966186797	4.156107749

From wdunlap at tibco.com  Tue Apr 26 23:43:42 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 26 Apr 2016 14:43:42 -0700
Subject: [R] table ,
 exclude - count the frequency in a data frame but exclude one value
In-Reply-To: <CABcx46BjgGysuj68=Q88SPOC+vaXV6KSpKCXt1z_1xJtGtxf2g@mail.gmail.com>
References: <CABcx46BjgGysuj68=Q88SPOC+vaXV6KSpKCXt1z_1xJtGtxf2g@mail.gmail.com>
Message-ID: <CAF8bMcamHuP0Gxbq2XnuHhZLgvb5Spyiyt4dMMP=pN5DrNU4jA@mail.gmail.com>

table converts its non-factor arguments to factors using the exclude
argument that you supply.  If you want the arguments to be handled
differently, then convert them to factors
yourself, in the way you want.  E.g.,

> with(df, table(x=factor(x, exclude=1), y))
   y
x   1 2 3
  2 0 1 0
  3 1 0 0
> with(df, table(x=factor(x, exclude=1), y=factor(y, levels=3:1)))
   y
x   3 2 1
  2 0 1 0
  3 0 0 1



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Apr 26, 2016 at 2:21 PM, jpm miao <miaojpm at gmail.com> wrote:

> Hi,
>
>    I have a data frame with two variables x, y, both of which take values
> in the set {1,2,3}. I'd like to count the frequency by the command "table",
> but exclude the value "1" in variable x, but keep "1" in variable y. Is it
> possible?  When I use "exclude", value 1 in both x and y are excluded.
> Thanks,
>
>
> > df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
> > table(df[,c("y","x")])
>    x
> y   1 2 3
>   1 0 0 1
>   2 0 1 0
>   3 1 0 0
> > table(df[,c("y","x")], exclude = 1)
>    x
> y   2 3
>   2 1 0
>   3 0 0
> > table(df[,c("y","x")], exclude = c(NULL, 1))
>    x
> y   2 3
>   2 1 0
>   3 0 0
> > table(df[,c("y","x")], exclude = c(1, NULL))
>    x
> y   2 3
>   2 1 0
>   3 0 0
> > table(df[,c("y","x")], exclude = c(1, 0))
>    x
> y   2 3
>   2 1 0
>   3 0 0
> > table(df[,c("y","x")], exclude = list(1 , NULL))
> Error in as.vector(exclude, typeof(x)) :
>   (list) object cannot be coerced to type 'integer'
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Apr 27 00:11:48 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 26 Apr 2016 15:11:48 -0700
Subject: [R] From NUM to INT
In-Reply-To: <CAHxKz8Zq3hXxO87e6TkQvQqO_kO9cYvMRgF59nRsYTD7SueBDA@mail.gmail.com>
References: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
	<CAAxdm-7nbOHrNsL+z8MutinnOpr9usP_DeTe2Pq_XLGsQCGArw@mail.gmail.com>
	<CAHxKz8Zq3hXxO87e6TkQvQqO_kO9cYvMRgF59nRsYTD7SueBDA@mail.gmail.com>
Message-ID: <CAGxFJbR_f=VtN_MGXm4NsgeCMbTOzj5opzg67w7ZWavfidtDUQ@mail.gmail.com>

Inline.

-- Bert


On Tue, Apr 26, 2016 at 2:25 PM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Ok. I`m trying to run a Poisson glmm with an observation-level random
> intercept. But I`m getting the following error for the 'Baci' variable:
>
> 'Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate'. I  guess this message is because the baci variable is not a
> an integer,

Why would you "guess" that? Given your magnitudes, I suspect it's a
scaling issue. Try centering and scaling your Baci variable before
fitting.

Cheers,
Bert





and cannot be transformed into an integer as R has a threshold
> of
> 2x10^9 even in 64 bit R.
>
> It runs fine for the fungii variable.
>
> If you guys want to run the data (attached), the full command is below.
>
> Thanks.
>
> ---------------------------------------------
>
> ##Import data:
>
> qPCR <- read.delim(file.choose(),
>                  header = TRUE,
>                  dec = ".")
>
> ##Load package
>
> library(lme4)
>
> ##Other steps:
>
> qPCR$obs <- 1:nrow(qPCR)
> qPCR$fID<-as.factor(qPCR$ID)
> qPCR$fDiet<-as.factor(qPCR$Diet)
>
> ##Run the model:
>
> M1 <- glmer (Baci ~ fDiet + Crossover + (1|fID:Crossover) + (1|obs),
>              family = poisson, data=qPCR)
>
>
>
> Andre
>
>
>
> On Tue, Apr 26, 2016 at 2:36 PM, jim holtman <jholtman at gmail.com> wrote:
>
>> Can you explain why you need them as 'integer',  A floating point
>> representation can hold a value upto ~4.5e15 as an "integer" keeping the
>> precision that you might need.
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Tue, Apr 26, 2016 at 1:11 PM, Andr? Luis Neves <andrluis at ualberta.ca>
>> wrote:
>>
>>> Dear all:
>>>
>>> I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
>>> (using excel) and then imported the data (.txt) into R. Interestingly, the
>>> other three variables were loaded as INT, but the 'Baci' one continued as
>>> Num.
>>>
>>> I imported the data using the following command line:
>>>
>>> X <- read.delim(file.choose(),
>>>                  header = TRUE,
>>>                  dec = ".")
>>>
>>> Here is the structure of X:
>>>
>>> > str(X)
>>> 'data.frame': 115 obs. of  5 variables:
>>>  $ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18 26 27
>>> 29 31 32 36 ...
>>>  $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
>>>  $ Meti     : int  352645997 334146268 767208656 171567266 462747405
>>> 414905627 237010514 387480048 214671355 328813226 ...
>>>  $ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156 13746
>>> ...
>>>  $ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015
>>> 203685
>>> 4261780 43110492 69802572 ...
>>>
>>>
>>> I need Baci as an integer, and tried to convert it using as.integer
>>> function, but was not successful.
>>>
>>>
>>> Could anyone please help me to solve this problem.
>>>
>>> Thanks,
>>>
>>>
>>>
>>> --
>>> Andre
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
> Andre
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From andrluis at ualberta.ca  Wed Apr 27 00:20:12 2016
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Tue, 26 Apr 2016 16:20:12 -0600
Subject: [R] From NUM to INT
In-Reply-To: <CAGxFJbR_f=VtN_MGXm4NsgeCMbTOzj5opzg67w7ZWavfidtDUQ@mail.gmail.com>
References: <CAHxKz8Y-8hkKMWxb-zy9jSKnZYh7VMWjfmn4ydh=th7zw9a4tQ@mail.gmail.com>
	<CAAxdm-7nbOHrNsL+z8MutinnOpr9usP_DeTe2Pq_XLGsQCGArw@mail.gmail.com>
	<CAHxKz8Zq3hXxO87e6TkQvQqO_kO9cYvMRgF59nRsYTD7SueBDA@mail.gmail.com>
	<CAGxFJbR_f=VtN_MGXm4NsgeCMbTOzj5opzg67w7ZWavfidtDUQ@mail.gmail.com>
Message-ID: <CAHxKz8ZfrC=18uvaBUgMfSdic+aVpKX+VOJNMBkfyR1ZVBdLgQ@mail.gmail.com>

Hi Bert:

I thought in centering Baci variable, but I wouldn`t like to draw a
conclusion based on the scaled response variable.

On the other hand, if I had to center the explanatory variable, that would
be great, but I cannot, as it is a factor.

Thanks a lot for your time. I really appreciated your help.

Best regards,

Andre



On Tue, Apr 26, 2016 at 4:11 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Inline.
>
> -- Bert
>
>
> On Tue, Apr 26, 2016 at 2:25 PM, Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
> > Ok. I`m trying to run a Poisson glmm with an observation-level random
> > intercept. But I`m getting the following error for the 'Baci' variable:
> >
> > 'Error: (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> > pwrssUpdate'. I  guess this message is because the baci variable is not a
> > an integer,
>
> Why would you "guess" that? Given your magnitudes, I suspect it's a
> scaling issue. Try centering and scaling your Baci variable before
> fitting.
>
> Cheers,
> Bert
>
>
>
>
>
> and cannot be transformed into an integer as R has a threshold
> > of
> > 2x10^9 even in 64 bit R.
> >
> > It runs fine for the fungii variable.
> >
> > If you guys want to run the data (attached), the full command is below.
> >
> > Thanks.
> >
> > ---------------------------------------------
> >
> > ##Import data:
> >
> > qPCR <- read.delim(file.choose(),
> >                  header = TRUE,
> >                  dec = ".")
> >
> > ##Load package
> >
> > library(lme4)
> >
> > ##Other steps:
> >
> > qPCR$obs <- 1:nrow(qPCR)
> > qPCR$fID<-as.factor(qPCR$ID)
> > qPCR$fDiet<-as.factor(qPCR$Diet)
> >
> > ##Run the model:
> >
> > M1 <- glmer (Baci ~ fDiet + Crossover + (1|fID:Crossover) + (1|obs),
> >              family = poisson, data=qPCR)
> >
> >
> >
> > Andre
> >
> >
> >
> > On Tue, Apr 26, 2016 at 2:36 PM, jim holtman <jholtman at gmail.com> wrote:
> >
> >> Can you explain why you need them as 'integer',  A floating point
> >> representation can hold a value upto ~4.5e15 as an "integer" keeping the
> >> precision that you might need.
> >>
> >>
> >> Jim Holtman
> >> Data Munger Guru
> >>
> >> What is the problem that you are trying to solve?
> >> Tell me what you want to do, not how you want to do it.
> >>
> >> On Tue, Apr 26, 2016 at 1:11 PM, Andr? Luis Neves <andrluis at ualberta.ca
> >
> >> wrote:
> >>
> >>> Dear all:
> >>>
> >>> I converted the columns (Baci, Meti, Fungii, Protozoai) into integers
> >>> (using excel) and then imported the data (.txt) into R. Interestingly,
> the
> >>> other three variables were loaded as INT, but the 'Baci' one continued
> as
> >>> Num.
> >>>
> >>> I imported the data using the following command line:
> >>>
> >>> X <- read.delim(file.choose(),
> >>>                  header = TRUE,
> >>>                  dec = ".")
> >>>
> >>> Here is the structure of X:
> >>>
> >>> > str(X)
> >>> 'data.frame': 115 obs. of  5 variables:
> >>>  $ ID       : Factor w/ 61 levels "107ZRED","112BLKW",..: 8 12 15 18
> 26 27
> >>> 29 31 32 36 ...
> >>>  $ Baci     : num  2.90e+12 5.55e+11 9.46e+11 8.13e+11 4.06e+11 ...
> >>>  $ Meti     : int  352645997 334146268 767208656 171567266 462747405
> >>> 414905627 237010514 387480048 214671355 328813226 ...
> >>>  $ Fungii   : int  43645 19009 15998 2189 8972 8240 3133 17922 6156
> 13746
> >>> ...
> >>>  $ Protozoai: int  3220523 1851891 3252462 1665675 34123768 23175015
> >>> 203685
> >>> 4261780 43110492 69802572 ...
> >>>
> >>>
> >>> I need Baci as an integer, and tried to convert it using as.integer
> >>> function, but was not successful.
> >>>
> >>>
> >>> Could anyone please help me to solve this problem.
> >>>
> >>> Thanks,
> >>>
> >>>
> >>>
> >>> --
> >>> Andre
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >
> > --
> > Andre
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Andre

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Wed Apr 27 00:35:04 2016
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 26 Apr 2016 15:35:04 -0700
Subject: [R] How to print the frequency table (produced by the command
	"table" to Excel
Message-ID: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>

Hi,

   How could we print the frequency table (produced by "table") to an Excel
file?
   Is there an easy way to do so? Thanks,

Miao

> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])

> table(df[,c("y","z")])
   z
y   a b c
  1 0 0 1
  2 0 1 0
  3 1 0 0
> test<-table(df[,c("y","z")])
> as.data.frame(test)
  y z Freq
1 1 a    0
2 2 a    0
3 3 a    1
4 1 b    0
5 2 b    1
6 3 b    0
7 1 c    1
8 2 c    0
9 3 c    0
> as.matrix(test)
   z
y   a b c
  1 0 0 1
  2 0 1 0
  3 1 0 0
> testm<-as.matrix(test)
> testm
   z
y   a b c
  1 0 0 1
  2 0 1 0
  3 1 0 0
> typeof(testm)
[1] "integer"

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Apr 27 01:14:58 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 27 Apr 2016 09:14:58 +1000
Subject: [R] How to print the frequency table (produced by the command
 "table" to Excel
In-Reply-To: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>
References: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>
Message-ID: <CA+8X3fVbX1ptDr_xaaQyCrbskqQNqBS0mN8fm8Utm-y2rnbfwA@mail.gmail.com>

Hi jpm miao,
You can get CSV files that can be imported into Excel like this:

library(prettyR)
sink("excel_table1.csv")
delim.table(table(df[,c("y","z")]))
sink()
sink("excel_table2.csv")
delim.table(as.data.frame(table(df[,c("y","z")])),label="")
sink()
sink("excel_table3.csv")
delim.table(as.matrix(table(df[,c("y","z")])),label="")
sink()

Jim

On Wed, Apr 27, 2016 at 8:35 AM, jpm miao <miaojpm at gmail.com> wrote:
> Hi,
>
>    How could we print the frequency table (produced by "table") to an Excel
> file?
>    Is there an easy way to do so? Thanks,
>
> Miao
>
>> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
>
>> table(df[,c("y","z")])
>    z
> y   a b c
>   1 0 0 1
>   2 0 1 0
>   3 1 0 0
>> test<-table(df[,c("y","z")])
>> as.data.frame(test)
>   y z Freq
> 1 1 a    0
> 2 2 a    0
> 3 3 a    1
> 4 1 b    0
> 5 2 b    1
> 6 3 b    0
> 7 1 c    1
> 8 2 c    0
> 9 3 c    0
>> as.matrix(test)
>    z
> y   a b c
>   1 0 0 1
>   2 0 1 0
>   3 1 0 0
>> testm<-as.matrix(test)
>> testm
>    z
> y   a b c
>   1 0 0 1
>   2 0 1 0
>   3 1 0 0
>> typeof(testm)
> [1] "integer"
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jan.kacaba at gmail.com  Wed Apr 27 06:56:13 2016
From: jan.kacaba at gmail.com (Jan Kacaba)
Date: Wed, 27 Apr 2016 06:56:13 +0200
Subject: [R] (windows) opening document with particular exe file
Message-ID: <CAHby=D1oja-joFFYARMTWKvUHDboDWiGUg420X6hR+n45GAB2w@mail.gmail.com>

Hello dear R, I dont have specific task on mind just learning R.

1) Is it possible to open a document for example path1\myfile.pdf with
program path2\pdfviewer.exe ?
How would I do it in win? Does it differ in linux?

2)  Is it possible to run a program and supply to it some streams? The
streams are for example txt file or web address.

One specific task which comes to mid: I would like to draw in inkscape
programmatically with script. Is it somehow possible?

Thank you very much for any help in advance.

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Wed Apr 27 10:44:17 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Wed, 27 Apr 2016 10:44:17 +0200
Subject: [R] Antwort: RE:  Missing Values in Logical Expressions
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50281BC@SRVEXCHMBX.precheza.cz>
References: <OF8D82BBD9.4138E6C4-ONC1257FA1.002BF1AF-C1257FA1.002CDBA6@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50281BC@SRVEXCHMBX.precheza.cz>
Message-ID: <OF381E25FA.21CB9C5F-ONC1257FA2.0028C780-C1257FA2.00300056@lotus.hawesko.de>

Hi Petr,
Hi Jim,

many thanks for your help. Today I constructed a sample dataset and tested 
your suggestions. Everything worked OK.

Then I took the code and testet on the original data. And - it worked OK 
this morning also.

I went back to my script of Thuesday and ran it again. OK. Then I used my 
script of Monday and ran it.. OK.

I have no idea what was wrong yesterday. To see that there is a problem 
and not being able to replicate it a day later even if it did not work all 
day before is very strange.

If the problem arises again, I will raise my hand.

Many thanks again for your help.

Kind regards

Georg




Von:    PIKAL Petr <petr.pikal at precheza.cz>
An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>, 
"r-help at r-project.org" <r-help at r-project.org>, 
Datum:  26.04.2016 11:11
Betreff:        RE: [R] Missing Values in Logical Expressions



Hm

Based on Jim's data your construction gives me correct result.

> Umsatz_2011<-c(1,2,3,4,5,NA,7,8,NA,10)
> Kunde_2011<-rep(0:1,5)
> Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011 == 1, 
1, 0)
> Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels = 
c("Check", "OK"))
> table(Check_Kunde_2011)
Check_Kunde_2011
Check    OK
    1     9

So I presume that the problem lies in your data.
You should provide some sample of your data either by posting result of

str(yourdata)
or
dput(head(yourdata))

if you want some advice why with correct code you did not get appropriate 
result.

Instead ifelse you can also use

Check_Kunde_2011 <- (is.na(Umsatz_2011)&(Kunde_2011==1))*1

to get desired 0/1 vector.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Tuesday, April 26, 2016 10:10 AM
> To: r-help at r-project.org
> Subject: [R] Missing Values in Logical Expressions
>
> Hi All,
>
> I need to evaluate missing values in my data. I am able to filter these 
values
> and do simple statistics on it. But I do need new variables based on 
variables
> with missing values in my dataset:
>
> Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011 ==
> 1, 1, 0)
> Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels =
> c("Check", "OK"))
>
> The new variable is not correctly created. It contains no values:
>
> table(Check_Kunde_2011)
> < table of extent 0 >
>
> I searched the web but could not find a solution.
>
> How can I work with variables and missing values in logical expressions?
>
> Where could I find something about this?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou 
ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? 
neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho 
kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email 
jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi 
?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? 
smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; 
Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany 
p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve 
v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za 
spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? 
zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly 
adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, 
p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? 
zn?m?.

This e-mail and any documents attached to it may be confidential and are 
intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its 
sender. Delete the contents of this e-mail with all attachments and its 
copies from your system.
If you are not the intended recipient of this e-mail, you are not 
authorized to use, disseminate, copy or disclose this e-mail in any 
manner.
The sender of this e-mail shall not be liable for any possible damage 
caused by modifications of the e-mail or by delay with transfer of the 
email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a 
contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to 
immediately accept such offer; The sender of this e-mail (offer) excludes 
any acceptance of the offer on the part of the recipient containing any 
amendment or variation.
- the sender insists on that the respective contract is concluded only 
upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter 
into any contracts on behalf of the company except for cases in which 
he/she is expressly authorized to do so in writing, and such authorization 
or power of attorney is submitted to the recipient or the person 
represented by the recipient, or the existence of such authorization is 
known to the recipient of the person represented by the recipient.


From anindya55 at gmail.com  Wed Apr 27 11:45:24 2016
From: anindya55 at gmail.com (Anindya Sankar Dey)
Date: Wed, 27 Apr 2016 15:15:24 +0530
Subject: [R] Approximate taylor series
Message-ID: <CAKC+_z_zG_wbr7ASO1swHswSsS-4RpKJy8B+8AQWHMq-iY-q5Q@mail.gmail.com>

Hi All,

Say I have the values of function f(x1,x2,x3,x4) for each values of
x1,x2,x3,x4 but not complete. But the functional form is not known.

Techniques like regression, etc. are not able to give me satisfactory
results and msy be more complex than we thought.

I wanted to use Taylor's approximation to continuous function, to
approximate a functional form using the given data. But failed to see a
package in R thaat does that.

Can anyone suggest a way to do it?

-- 
Anindya Sankar Dey

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Apr 27 12:02:47 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 27 Apr 2016 10:02:47 +0000
Subject: [R] Antwort: RE:  Missing Values in Logical Expressions
In-Reply-To: <OF381E25FA.21CB9C5F-ONC1257FA2.0028C780-C1257FA2.00300056@lotus.hawesko.de>
References: <OF8D82BBD9.4138E6C4-ONC1257FA1.002BF1AF-C1257FA1.002CDBA6@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50281BC@SRVEXCHMBX.precheza.cz>
	<OF381E25FA.21CB9C5F-ONC1257FA2.0028C780-C1257FA2.00300056@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50284D9@SRVEXCHMBX.precheza.cz>

Hi Georg

Something was wrong with your data. Even with

> res
 [1] <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA> <NA>
Levels: Check OK
>
> table(res)
res
Check    OK
    0     0

table gives me different result from yours.
I can repeat your result with

> res<-as.numeric(res)
> table(res)
< table of extent 0 >
> res
 [1] NA NA NA NA NA NA NA NA NA NA

so your second line did not result in factor. Why it did so is difficult to tell.

Cheers
Petr

> -----Original Message-----
> From: G.Maubach at weinwolf.de [mailto:G.Maubach at weinwolf.de]
> Sent: Wednesday, April 27, 2016 10:44 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: Antwort: RE: [R] Missing Values in Logical Expressions
>
> Hi Petr,
> Hi Jim,
>
> many thanks for your help. Today I constructed a sample dataset and tested
> your suggestions. Everything worked OK.
>
> Then I took the code and testet on the original data. And - it worked OK this
> morning also.
>
> I went back to my script of Thuesday and ran it again. OK. Then I used my
> script of Monday and ran it.. OK.
>
> I have no idea what was wrong yesterday. To see that there is a problem and
> not being able to replicate it a day later even if it did not work all day before is
> very strange.
>
> If the problem arises again, I will raise my hand.
>
> Many thanks again for your help.
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    PIKAL Petr <petr.pikal at precheza.cz>
> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
> "r-help at r-project.org" <r-help at r-project.org>,
> Datum:  26.04.2016 11:11
> Betreff:        RE: [R] Missing Values in Logical Expressions
>
>
>
> Hm
>
> Based on Jim's data your construction gives me correct result.
>
> > Umsatz_2011<-c(1,2,3,4,5,NA,7,8,NA,10)
> > Kunde_2011<-rep(0:1,5)
> > Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011
> == 1,
> 1, 0)
> > Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels =
> c("Check", "OK"))
> > table(Check_Kunde_2011)
> Check_Kunde_2011
> Check    OK
>     1     9
>
> So I presume that the problem lies in your data.
> You should provide some sample of your data either by posting result of
>
> str(yourdata)
> or
> dput(head(yourdata))
>
> if you want some advice why with correct code you did not get appropriate
> result.
>
> Instead ifelse you can also use
>
> Check_Kunde_2011 <- (is.na(Umsatz_2011)&(Kunde_2011==1))*1
>
> to get desired 0/1 vector.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > G.Maubach at weinwolf.de
> > Sent: Tuesday, April 26, 2016 10:10 AM
> > To: r-help at r-project.org
> > Subject: [R] Missing Values in Logical Expressions
> >
> > Hi All,
> >
> > I need to evaluate missing values in my data. I am able to filter these
> values
> > and do simple statistics on it. But I do need new variables based on
> variables
> > with missing values in my dataset:
> >
> > Check_Kunde_2011 <- ifelse(is.na(Umsatz_2011) == TRUE & Kunde_2011
> ==
> > 1, 1, 0)
> > Check_Kunde_2011 <- factor(Check_Kunde_2011, levels = c(1,0), labels =
> > c("Check", "OK"))
> >
> > The new variable is not correctly created. It contains no values:
> >
> > table(Check_Kunde_2011)
> > < table of extent 0 >
> >
> > I searched the web but could not find a solution.
> >
> > How can I work with variables and missing values in logical expressions?
> >
> > Where could I find something about this?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From ggrothendieck at gmail.com  Wed Apr 27 13:37:03 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 27 Apr 2016 07:37:03 -0400
Subject: [R] Approximate taylor series
In-Reply-To: <CAKC+_z_zG_wbr7ASO1swHswSsS-4RpKJy8B+8AQWHMq-iY-q5Q@mail.gmail.com>
References: <CAKC+_z_zG_wbr7ASO1swHswSsS-4RpKJy8B+8AQWHMq-iY-q5Q@mail.gmail.com>
Message-ID: <CAP01uRniF8h18op4UbKAL9TM=EuLJB6mJ72H7vXgVrEjVdn5kw@mail.gmail.com>

Regress on a multivariate polynomial:

    lm(y ~ polym(x1, x2, x3, x4, degree = 3))

See ?polym


From jean-externe.maurice at edf.fr  Wed Apr 27 14:48:13 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 27 Apr 2016 12:48:13 +0000
Subject: [R] AKIMA or translating to FORTRAN a R function calling a FORTRAN
 routine
Message-ID: <65253a11679d4976822b5befc81e8ab0@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,
I am hired to translate into FORTRAN R functions. It works great and my customer is happy. I am going to translate a function that call aspline in the library AKIMA.
This function call 2 FORTRAN routines that must be include (I guess) in the package AKIMA. And I have some questions.

Is the fortran code really included  in the R package AKIMA ?
In other word, do I have a mean to call these 2 routines from a FORTRAN routine compiled in a DLL ?
And if I can, am I allowed to do it (are they free) ?

Jean in France
PS English is not my natural langage and I am 'new' to R !
-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From jean-externe.maurice at edf.fr  Wed Apr 27 14:54:30 2016
From: jean-externe.maurice at edf.fr (MAURICE Jean - externe)
Date: Wed, 27 Apr 2016 12:54:30 +0000
Subject: [R] difference between require and library
Message-ID: <ed78bc2f2ec94a07b606c1f3885a0e3d@NOEINTPEXMU007.NEOPROD.EDF.FR>

Hi,

Is there any other difference between 'require' and 'library' than the error or warning when the library is not found ?

Jean in France

-------------- next part --------------



Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont ?tablis ? l'intention exclusive des destinataires et les informations qui y figurent sont strictement confidentielles. Toute utilisation de ce Message non conforme ? sa destination, toute diffusion ou toute publication totale ou partielle, est interdite sauf autorisation expresse.

Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace sur quelque support que ce soit. Nous vous remercions ?galement d'en avertir imm?diatement l'exp?diteur par retour du message.

Il est impossible de garantir que les communications par messagerie ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute erreur ou virus.
____________________________________________________

This message and any attachments (the 'Message') are intended solely for the addressees. The information contained in this Message is confidential. Any use of information contained in this Message not in accord with its purpose, any dissemination or disclosure, either whole or partial, is prohibited except formal approval.

If you are not the addressee, you may not copy, forward, disclose or use any part of it. If you have received this message in error, please delete it and all copies from your system and notify the sender immediately by return message.

E-mail communication cannot be guaranteed to be timely secure, error or virus-free.

From thierry.onkelinx at inbo.be  Wed Apr 27 15:00:49 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 27 Apr 2016 15:00:49 +0200
Subject: [R] difference between require and library
In-Reply-To: <ed78bc2f2ec94a07b606c1f3885a0e3d@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <ed78bc2f2ec94a07b606c1f3885a0e3d@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <CAJuCY5wJ_tg+ZgFG5J-2fom_-XG7Gi2ceJi5vV+XuSp90m8ZSQ@mail.gmail.com>

Dear Jean,

Have a look at
http://stackoverflow.com/questions/5595512/what-is-the-difference-between-require-and-library

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-04-27 14:54 GMT+02:00 MAURICE Jean - externe <
jean-externe.maurice at edf.fr>:

> Hi,
>
> Is there any other difference between 'require' and 'library' than the
> error or warning when the library is not found ?
>
> Jean in France
>
>
>
>
>
> Ce message et toutes les pi?ces jointes (ci-apr?s le 'Message') sont
> ?tablis ? l'intention exclusive des destinataires et les informations qui y
> figurent sont strictement confidentielles. Toute utilisation de ce Message
> non conforme ? sa destination, toute diffusion ou toute publication totale
> ou partielle, est interdite sauf autorisation expresse.
>
> Si vous n'?tes pas le destinataire de ce Message, il vous est interdit de
> le copier, de le faire suivre, de le divulguer ou d'en utiliser tout ou
> partie. Si vous avez re?u ce Message par erreur, merci de le supprimer de
> votre syst?me, ainsi que toutes ses copies, et de n'en garder aucune trace
> sur quelque support que ce soit. Nous vous remercions ?galement d'en
> avertir imm?diatement l'exp?diteur par retour du message.
>
> Il est impossible de garantir que les communications par messagerie
> ?lectronique arrivent en temps utile, sont s?curis?es ou d?nu?es de toute
> erreur ou virus.
> ____________________________________________________
>
> This message and any attachments (the 'Message') are intended solely for
> the addressees. The information contained in this Message is confidential.
> Any use of information contained in this Message not in accord with its
> purpose, any dissemination or disclosure, either whole or partial, is
> prohibited except formal approval.
>
> If you are not the addressee, you may not copy, forward, disclose or use
> any part of it. If you have received this message in error, please delete
> it and all copies from your system and notify the sender immediately by
> return message.
>
> E-mail communication cannot be guaranteed to be timely secure, error or
> virus-free.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Apr 27 15:07:30 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 27 Apr 2016 13:07:30 +0000
Subject: [R] AKIMA or translating to FORTRAN a R function calling a
 FORTRAN routine
In-Reply-To: <65253a11679d4976822b5befc81e8ab0@NOEINTPEXMU007.NEOPROD.EDF.FR>
References: <65253a11679d4976822b5befc81e8ab0@NOEINTPEXMU007.NEOPROD.EDF.FR>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C502860F@SRVEXCHMBX.precheza.cz>

Hi

License statement of Akima packages states:

This package is distributed under the ACM license at
http://www.acm.org/publications/policies/softwarecrnotice.

In detail:

1. Fortran code (src/*.f):

Copyrighted and Licensed by ACM,
see http://www.acm.org/publications/policies/softwarecrnotice


2. R interface (src/init.c src/akima.h R/*.R man/*.Rd data/*):

The R interface code has been developed as work based on the
ACM licensed code, hence it is also ACM licensed, copyright
is by A. Gebhardt <albrecht.gebhardt at uni-klu.ac.at>.

In order to fulfill the ACM copyright and license noted above,
it is stated here that this work contains modified ACM material,
and to fulfill this, the modified work including the R interface
is available free to secondary users, and no charge is associated
with such copies.

So I understand that if you want to use code from AKIMA at some commercial product you should contact ACM. But if you want to be 100% sure you shall contact lawyer.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of MAURICE
> Jean - externe
> Sent: Wednesday, April 27, 2016 2:48 PM
> To: r-help at r-project.org
> Subject: [R] AKIMA or translating to FORTRAN a R function calling a FORTRAN
> routine
>
> Hi,
> I am hired to translate into FORTRAN R functions. It works great and my
> customer is happy. I am going to translate a function that call aspline in the
> library AKIMA.
> This function call 2 FORTRAN routines that must be include (I guess) in the
> package AKIMA. And I have some questions.
>
> Is the fortran code really included  in the R package AKIMA ?
> In other word, do I have a mean to call these 2 routines from a FORTRAN
> routine compiled in a DLL ?
> And if I can, am I allowed to do it (are they free) ?
>
> Jean in France
> PS English is not my natural langage and I am 'new' to R !

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From samarvir1996 at gmail.com  Wed Apr 27 18:26:47 2016
From: samarvir1996 at gmail.com (samarvir singh)
Date: Wed, 27 Apr 2016 21:56:47 +0530
Subject: [R] using foreach function with gtrendsR
Message-ID: <CAOpgo6jvF0WHsav4MyP2+osYuXOvQoB2Zbda2M2OturZd2YTdA@mail.gmail.com>

I have this code which is working

library("checkpoint")
library("gtrendsR")
library("doParallel")

cl<-makeCluster(4)
registerDoParallel(cl)
gconnect(usr = "email at gmail.com", psw = "password", verbose = FALSE)

names <- c("apple","shit", "android", "rocks")
formula <- function(x){
x0 <- gtrends(x, res = "7d")
x1 <- x0[3]
x2 <- as.data.frame(x1)
x3 <- x2[1,2]return(x3)}
for( x in names)
{

   x5 <- rbind(x5,formula(x))
}

Now, I want to process this code with parallel processing, so I am using
foreach function

How can I do the same for foreach loop?

	[[alternative HTML version deleted]]


From sadderly at gmail.com  Wed Apr 27 10:08:08 2016
From: sadderly at gmail.com (Shawn Adderly)
Date: Wed, 27 Apr 2016 04:08:08 -0400
Subject: [R] Determine if a set of x and y-latitude points are inside of a
 polygon using R
Message-ID: <CANLU3TM=bGZrbgMRehEr8sdCBMKdrh2G_nOMMpOg5gveK19+Xg@mail.gmail.com>

Objective: Determine if a set of x and y-latitude points are inside of
a polygon using R.

Lets say I have 9 polygons. Where I have labeled the polygons to be
checked from 1-9. The problem I?m running into is running the
point.in.polygon to check if those points are in one of several
polygons, as my code overwrites the result.

To accomplish this I am using the R-built in function called
point.in.polygon. Point.in.polygon takes the x, and y lat/lon points,
and the polygon boundaries.

Here is the code I've written thus far:

 require("SDMTools")
 require("sp")

 #b is the polygon that I'm referring
 for (b in 1:9)
 {
    D <- subset(Bounds, Polygon == b)
    for (i in 1:length(Bounds$latitude))
    {
    M = point.in.polygon(Bounds$latitude[i], Bounds$longitude[i], D$PY,D$PX)
       if (M>1) {
        Bounds$T[i] = M
        }
        else
        {
        Bounds$T[i] = M
        }
        }
    }


Minimal Dataset:

 Latitude Longitude Polygon Latitude Polygon Longitude Polygon
 38.65485 -121.4965 38.43768 -121.4018 1
 38.562 -121.4768 38.56559 -121.4018 1
 38.7011 -121.3018 38.57065 -121.5141 1
 38.62568 -121.3198 38.56559 -121.5141 1
 38.60253 -121.2899 38.563459 -121.5141 2
 38.28272 -121.2969 38.56359 -121.5141 2
 38.64286 -121.2204 38.54065 -121.515 2
 38.67442 -121.5105 38.57065 -121.515


From G.Maubach at gmx.de  Wed Apr 27 14:14:17 2016
From: G.Maubach at gmx.de (G.Maubach at gmx.de)
Date: Wed, 27 Apr 2016 14:14:17 +0200
Subject: [R] R Script Template
References: <OF3944F455.D33DC9BF-ONC1257FA1.004D1C96-C1257FA2.0034EEE3@lotus.hawesko.de>
Message-ID: <trinity-09f4c915-dc8f-4d8e-8a18-9473ce86e4df-1461759257809@3capp-gmx-bs62>

Hi All,
 
I am addressing this post to all who are new to R.

When learing R in the last weeks I took some notes for myself to have code snippets ready for the data analysis process. I put these snippets 
together as a script template for future use. Almost all of the given command prototypes are tested. The template script contains snippets for best practices and leaves out the commands that should not be used. Relying on the given snippets shall lead to high quality code.

The code is based on examples from the ressources given in the template. I highly recommend to read the books or take the online courses to see how everything works and fits together.

Despite putting everything together with care, the script is provided as-is with no warrenty or liability whatsoever.

Please address any remarks or suggestions for improvement to the R-Help mailing list.

Kind regards

Georg


From deanforce14 at gmail.com  Wed Apr 27 16:12:48 2016
From: deanforce14 at gmail.com (Dean Force)
Date: Wed, 27 Apr 2016 10:12:48 -0400
Subject: [R] Random effects in package mgcv
Message-ID: <CAEd09GQ0ZQejp4CjkWk6ZTueEi9CLMBKaEi9qj6Ar8tzURBe3g@mail.gmail.com>

Hello R users,


I have a quick question I was hoping to get your input on. I am new to R
and the smooth statistical regression world, and am trying to wrap my mind
around the issues concerning using splines for mixed effect modeling.

My question is the following: in the ?gamm? function, generalized additive
mixed models can be estimated by including random components. These can be
explicitly defined in the syntax, where you can also define whether the
random component is an intercept, slope, or both. My understanding is that
in the gam/bam function the same is achieved by including the bs="re?
option for random intercepts and linear random slopes. Am I correct? If so,
is there a way to specify whether it is the intercept or slope we are
interested in, and does that have any effect on the output of the model?

I hope these questions make sense, and I look forward to learning more
about this.  Thanks for taking the time to read through this email.

	[[alternative HTML version deleted]]


From fabiana.gordon at imperial.ac.uk  Wed Apr 27 16:25:14 2016
From: fabiana.gordon at imperial.ac.uk (Gordon, Fabiana)
Date: Wed, 27 Apr 2016 14:25:14 +0000
Subject: [R] Create a new variable and concatenation inside  a "for" loop
Message-ID: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>

Hello,

Suppose the you need a loop to create a new variable , i.e., you are not reading data from outside the loop. This is a simple example in Matlab code,

for i=1:5
r1=randn
r2=randn
r=[r1 r2]
c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates all columns. In R this would be [i,]
end

The output of interest is c which I'm creating inside the "for" loop -also the index used in the loop is used to create c. In R I had to create c as an  empty vector (numeric() ) outside the loop, otherwise I get an error message saying that c doesn't exit.

The other issue is the concatenation. In each iteration I'm creating the rows of c by placing the new row  (r) below the previous one so that c becomes a 5 x 2 matrix.
In R, it seems that I have no choice but use the function "rbind". I managed to write this code in R . However, I'm not sure that if instead of creating a new variable  using  the index in the "for" loop , I wanted to use the index to read data, e.g.  suppose I have a 2 X 10 matrix X and suppose I want to calculate the sin () for each 2 x 2 sub-matrix of and stored in a matrix A. Then the code would be something like this,

for i=1:5
A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all rows
end

Many Thanks,

Fabiana


Dr Fabiana Gordon

Senior Statistical Consultant
Statistical Advisory Service, School Of Public Health,
Imperial College London
1st Floor, Stadium House, 68 Wood Lane,
London W12 7RH.

Tel: 020 7594 1749
Email: fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
Web:  www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/<http://www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/>



	[[alternative HTML version deleted]]


From attenka at utu.fi  Wed Apr 27 17:46:44 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Wed, 27 Apr 2016 18:46:44 +0300
Subject: [R] Same sum, different sets of integers
Message-ID: <5720DEE4.50909@utu.fi>

Hi,

Do you have ideas, how to find all those different combinations of 
integers (>0) that produce as a sum, a certain integer.

i.e.: if that sum is

3, the possibilities are c(1,1,1), c(1,2), c(2,1)
4, the possibilities are 
c(1,1,1,1),c(1,1,2),c(1,2,1),c(2,1,1),c(2,2),c(1,3),c(3,1)

etc.

Best regards,

Atte Tenkanen


From marlinkcox at gmail.com  Wed Apr 27 20:54:20 2016
From: marlinkcox at gmail.com (Marlin Keith Cox)
Date: Wed, 27 Apr 2016 10:54:20 -0800
Subject: [R] error.crosses
Message-ID: <CAHskWAVDZgkMPeZ7kuUVBXxjpOMrgr6FCOJGi+X_dTbS1azo+Q@mail.gmail.com>

Hello all, I have used describeBy to generate the following summary
statistics.  I simply need x and y error bars on a plot that has CQN
(xaxis) and Price (yaxis).  There should be four total points on the graph
(one for each supplier).

Using "error.crosses(desc$CQN, desc$Price)" does not work.



group: a
          vars  n  mean    sd median trimmed   mad   min   max range skew
CQN          1 65 48.22 11.12  49.61   47.86 13.79 31.30 72.71 41.41  0.1
Price        2 65  6.65  0.06   6.69    6.66  0.01  6.48  6.70  0.22 -1.2
Supplier*    3 65   NaN    NA     NA     NaN    NA   Inf  -Inf  -Inf   NA
          kurtosis   se
CQN          -1.01 1.38
Price         0.70 0.01
Supplier*       NA   NA
------------------------------------------------------------
group: b
          vars n  mean sd median trimmed mad   min   max range skew
kurtosis se
CQN          1 1 91.93 NA  91.93   91.93   0 91.93 91.93     0   NA
NA NA
Price        2 1  6.95 NA   6.95    6.95   0  6.95  6.95     0   NA
NA NA
Supplier*    3 1   NaN NA     NA     NaN  NA   Inf  -Inf  -Inf   NA
NA NA
------------------------------------------------------------
group: c
          vars n  mean   sd median trimmed  mad   min   max range skew
kurtosis
CQN          1 6 63.11 2.58  62.04   63.11 1.53 60.66 67.19  6.53 0.55
 -1.68
Price        2 6  8.92 0.00   8.92    8.92 0.00  8.92  8.92  0.00  NaN
 NaN
Supplier*    3 6   NaN   NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
  NA
            se
CQN       1.05
Price     0.00
Supplier*   NA
------------------------------------------------------------
group: d
          vars n  mean  sd median trimmed  mad   min   max range skew
kurtosis
CQN          1 6 47.20 5.7  46.31   47.20 7.17 39.52 54.45 14.93 0.08
 -1.79
Price        2 6  7.17 0.0   7.17    7.17 0.00  7.17  7.17  0.00  NaN
 NaN
Supplier*    3 6   NaN  NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
NA
            se
CQN       2.33
Price     0.00
Supplier*   NA

M. Keith Cox, Ph.D.
Principal
MKConsulting
17415 Christine Ave.
Juneau, AK 99801
U.S. 907.957.4606

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Apr 27 21:39:26 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 27 Apr 2016 19:39:26 +0000
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72F50A@mb02.ads.tamu.edu>

Instead of talking about how you want to do something and showing us your Matlab code, tell us what you want to do, include reproducible data, and show us your R code so far. Your initial assumption, that you need a loop for these examples is incorrect if I have understood you correctly. Many functions in R are vectorized so that loops can often be avoided. 

To create a 5 x 2 matrix of random normal numbers with mean=0 and sd=1:
> set.seed(42)
> crand <- cbind(r1=rnorm(5), r2=rnorm(5)) # Don't use c as a variable since c() is a function
> crand
             r1          r2
[1,]  1.3709584 -0.10612452
[2,] -0.5646982  1.51152200
[3,]  0.3631284 -0.09465904
[4,]  0.6328626  2.01842371
[5,]  0.4042683 -0.06271410

To compute sin() on pairs of rows and columns from a 2 x 10 matrix (this time we'll use uniform random numbers):

> X <- matrix(runif(20), 2, 10)
> X
          [,1]      [,2]       [,3]      [,4]      [,5]      [,6]      [,7]        [,8]
[1,] 0.9040314 0.9888917 0.08243756 0.3902035 0.4469696 0.7375956 0.3881083 0.003948339
[2,] 0.1387102 0.9466682 0.51421178 0.9057381 0.8360043 0.8110551 0.6851697 0.832916080
            [,9]     [,10]
[1,] 0.007334147 0.9066014
[2,] 0.207658973 0.6117786
> sin(X[, 1] - X[, 2])
[1] -0.08475853 -0.72287775
> t(sin(X[, 1:9] - X[, 2:10]))
              [,1]        [,2]
 [1,] -0.084758528 -0.72287775
 [2,]  0.787322543  0.41910237
 [3,] -0.302930277 -0.38159970
 [4,] -0.056735679  0.06967737
 [5,] -0.286552020  0.02494653
 [6,]  0.342416179  0.12555319
 [7,]  0.374780442 -0.14720941
 [8,] -0.003385802  0.58530576
 [9,] -0.782871221 -0.39320949

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gordon, Fabiana
Sent: Wednesday, April 27, 2016 9:25 AM
To: 'r-help at R-project.org'
Subject: [R] Create a new variable and concatenation inside a "for" loop

Hello,

Suppose the you need a loop to create a new variable , i.e., you are not reading data from outside the loop. This is a simple example in Matlab code,

for i=1:5
r1=randn
r2=randn
r=[r1 r2]
c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates all columns. In R this would be [i,]
end

The output of interest is c which I'm creating inside the "for" loop -also the index used in the loop is used to create c. In R I had to create c as an  empty vector (numeric() ) outside the loop, otherwise I get an error message saying that c doesn't exit.

The other issue is the concatenation. In each iteration I'm creating the rows of c by placing the new row  (r) below the previous one so that c becomes a 5 x 2 matrix.
In R, it seems that I have no choice but use the function "rbind". I managed to write this code in R . However, I'm not sure that if instead of creating a new variable  using  the index in the "for" loop , I wanted to use the index to read data, e.g.  suppose I have a 2 X 10 matrix X and suppose I want to calculate the sin () for each 2 x 2 sub-matrix of and stored in a matrix A. Then the code would be something like this,

for i=1:5
A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all rows
end

Many Thanks,

Fabiana


Dr Fabiana Gordon

Senior Statistical Consultant
Statistical Advisory Service, School Of Public Health,
Imperial College London
1st Floor, Stadium House, 68 Wood Lane,
London W12 7RH.

Tel: 020 7594 1749
Email: fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
Web:  www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/<http://www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/>



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Apr 27 21:57:43 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 27 Apr 2016 20:57:43 +0100
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
Message-ID: <094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>

"c" an extremely commonly-used function. Functions are first-class objects that occupy the same namespaces that variables do, so they can obscure each other. In short, don't use variables called "c" (R is case sensitive, so "C" has no such problem).

Wherever possible, avoid incremental concatenation like the plague. If you feel you must use it, at least concatenate in lists and then use functions like unlist, do.call, or pre-allocate vectors or matrix-like objects with unuseful values like NA and then overwrite each element in the vector or matrix-type object in a loop like your first one. 
-- 
Sent from my phone. Please excuse my brevity.

On April 27, 2016 3:25:14 PM GMT+01:00, "Gordon, Fabiana" <fabiana.gordon at imperial.ac.uk> wrote:
>Hello,
>
>Suppose the you need a loop to create a new variable , i.e., you are
>not reading data from outside the loop. This is a simple example in
>Matlab code,
>
>for i=1:5
>r1=randn
>r2=randn
>r=[r1 r2]
>c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates
>all columns. In R this would be [i,]
>end
>
>The output of interest is c which I'm creating inside the "for" loop
>-also the index used in the loop is used to create c. In R I had to
>create c as an  empty vector (numeric() ) outside the loop, otherwise I
>get an error message saying that c doesn't exit.
>
>The other issue is the concatenation. In each iteration I'm creating
>the rows of c by placing the new row  (r) below the previous one so
>that c becomes a 5 x 2 matrix.
>In R, it seems that I have no choice but use the function "rbind". I
>managed to write this code in R . However, I'm not sure that if instead
>of creating a new variable  using  the index in the "for" loop , I
>wanted to use the index to read data, e.g.  suppose I have a 2 X 10
>matrix X and suppose I want to calculate the sin () for each 2 x 2
>sub-matrix of and stored in a matrix A. Then the code would be
>something like this,
>
>for i=1:5
>A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all
>rows
>end
>
>Many Thanks,
>
>Fabiana
>
>
>Dr Fabiana Gordon
>
>Senior Statistical Consultant
>Statistical Advisory Service, School Of Public Health,
>Imperial College London
>1st Floor, Stadium House, 68 Wood Lane,
>London W12 7RH.
>
>Tel: 020 7594 1749
>Email:
>fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
>Web: 
>www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/<http://www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Apr 27 21:58:05 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 27 Apr 2016 14:58:05 -0500
Subject: [R] how to create initial configuraton for isoMDS
In-Reply-To: <B60F8F444AAC9C49A9EF0D12D05E094235C1AFC6@dfweml501-mbb>
References: <B60F8F444AAC9C49A9EF0D12D05E094235C1AFC6@dfweml501-mbb>
Message-ID: <572119CD.8030708@gmail.com>

Hi,

Your matrix needs to either be symmetric or an object of class dist. 
Here's one way to reformat it:

Note that calling it dist is a poor idea, since dist() is a base function.

Also note that if the distance from 1-2 is 1 while distance from 2-1 is 
Inf, as in your original matrix, then you probably need to reconsider 
what you're doing.

dconfig <- as.dist(t(dist))
loc <- isoMDS(dconfig)

Sarah

LiLi (Z) wrote:
> Hi,
>
> I'm trying to use isoMDS to project a directed graph to 2-dim vectors, but I got an error.
>
> #here is the code to create the graph using igraph package and run isoMDS on it.
> library(igraph)
> library(MASS)
> g<-make_graph(c(1,2, 2,3, 2,4, 3,4, 4,5, 5,6, 3,6, 1,6, 2,5),directed=TRUE)
> dist<-distances(g, mode="out")
> loc<-isoMDS(dist)
>
> # below is content of the dist matrix
>       [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]    0    1    2    2    2    1
> [2,]  Inf    0    1    1    1    2
> [3,]  Inf  Inf    0    1    2    1
> [4,]  Inf  Inf  Inf    0    1    2
> [5,]  Inf  Inf  Inf  Inf    0    1
> [6,]  Inf  Inf  Inf  Inf  Inf    0
>
> # and here is the error message:
> Error in isoMDS(dist) :
>    an initial configuration must be supplied with NA/Infs in 'd'
>
> It appears that isoMDS doesn't like the "Inf" values in the dist matrix, although help(isoMDS) suggests it accepts them if proper initial configuration is provided:
> Arguments
> d
>
> distance structure of the form returned by dist, or a full, symmetric matrix. Data are assumed to be dissimilarities or relative distances, but must be positive except for self-distance. Both missing and infinite values are allowed.
>
> y
>
> An initial configuration. If none is supplied, cmdscale is used to provide the classical solution, unless there are missing or infinite dissimilarities.
>
> k
>
> The desired dimension for the solution, passed to cmdscale.
>
>
> My questions is: how do I provide the y argument for this example to work?
> Any help and suggestion is appreciated.
> Li
>
>


From bgunter.4567 at gmail.com  Wed Apr 27 22:18:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 27 Apr 2016 13:18:19 -0700
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
	<094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
Message-ID: <CAGxFJbTELNKOfz2-ximsCtxiy-pEA88u8WHDYXOU8=p8Z5vqJA@mail.gmail.com>

...

"(R is case sensitive, so "C" has no such problem)."

Well, not quite. Try ?C

To add to the previous comments, Dr. Gordon appears to need to do
her/his homework and spend some time with an R tutorial or two before
posting further here. There are many good ones on the web. Some
recommendations can be found here:
https://www.rstudio.com/online-learning/#R

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 27, 2016 at 12:57 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> "c" an extremely commonly-used function. Functions are first-class objects that occupy the same namespaces that variables do, so they can obscure each other. In short, don't use variables called "c" (R is case sensitive, so "C" has no such problem).
>
> Wherever possible, avoid incremental concatenation like the plague. If you feel you must use it, at least concatenate in lists and then use functions like unlist, do.call, or pre-allocate vectors or matrix-like objects with unuseful values like NA and then overwrite each element in the vector or matrix-type object in a loop like your first one.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 27, 2016 3:25:14 PM GMT+01:00, "Gordon, Fabiana" <fabiana.gordon at imperial.ac.uk> wrote:
>>Hello,
>>
>>Suppose the you need a loop to create a new variable , i.e., you are
>>not reading data from outside the loop. This is a simple example in
>>Matlab code,
>>
>>for i=1:5
>>r1=randn
>>r2=randn
>>r=[r1 r2]
>>c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates
>>all columns. In R this would be [i,]
>>end
>>
>>The output of interest is c which I'm creating inside the "for" loop
>>-also the index used in the loop is used to create c. In R I had to
>>create c as an  empty vector (numeric() ) outside the loop, otherwise I
>>get an error message saying that c doesn't exit.
>>
>>The other issue is the concatenation. In each iteration I'm creating
>>the rows of c by placing the new row  (r) below the previous one so
>>that c becomes a 5 x 2 matrix.
>>In R, it seems that I have no choice but use the function "rbind". I
>>managed to write this code in R . However, I'm not sure that if instead
>>of creating a new variable  using  the index in the "for" loop , I
>>wanted to use the index to read data, e.g.  suppose I have a 2 X 10
>>matrix X and suppose I want to calculate the sin () for each 2 x 2
>>sub-matrix of and stored in a matrix A. Then the code would be
>>something like this,
>>
>>for i=1:5
>>A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all
>>rows
>>end
>>
>>Many Thanks,
>>
>>Fabiana
>>
>>
>>Dr Fabiana Gordon
>>
>>Senior Statistical Consultant
>>Statistical Advisory Service, School Of Public Health,
>>Imperial College London
>>1st Floor, Stadium House, 68 Wood Lane,
>>London W12 7RH.
>>
>>Tel: 020 7594 1749
>>Email:
>>fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
>>Web:
>>www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/<http://www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-advice-service/>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Apr 27 22:22:21 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 27 Apr 2016 21:22:21 +0100
Subject: [R] R Script Template
In-Reply-To: <trinity-09f4c915-dc8f-4d8e-8a18-9473ce86e4df-1461759257809@3capp-gmx-bs62>
References: <OF3944F455.D33DC9BF-ONC1257FA1.004D1C96-C1257FA2.0034EEE3@lotus.hawesko.de>
	<trinity-09f4c915-dc8f-4d8e-8a18-9473ce86e4df-1461759257809@3capp-gmx-bs62>
Message-ID: <B8BC68C5-15B2-4314-87B0-9EA85E7CC765@dcn.davis.ca.us>

The subject of your email is missing. Perhaps you need to read the Posting Guide (again?) about attachments. Embedding your example directly in the body of the email is generally more accessible in archives than attaching it. 
-- 
Sent from my phone. Please excuse my brevity.

On April 27, 2016 1:14:17 PM GMT+01:00, G.Maubach at gmx.de wrote:
>Hi All,
> 
>I am addressing this post to all who are new to R.
>
>When learing R in the last weeks I took some notes for myself to have
>code snippets ready for the data analysis process. I put these snippets
>
>together as a script template for future use. Almost all of the given
>command prototypes are tested. The template script contains snippets
>for best practices and leaves out the commands that should not be used.
>Relying on the given snippets shall lead to high quality code.
>
>The code is based on examples from the ressources given in the
>template. I highly recommend to read the books or take the online
>courses to see how everything works and fits together.
>
>Despite putting everything together with care, the script is provided
>as-is with no warrenty or liability whatsoever.
>
>Please address any remarks or suggestions for improvement to the R-Help
>mailing list.
>
>Kind regards
>
>Georg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Apr 28 02:21:27 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 28 Apr 2016 10:21:27 +1000
Subject: [R] Same sum, different sets of integers
In-Reply-To: <5720DEE4.50909@utu.fi>
References: <5720DEE4.50909@utu.fi>
Message-ID: <CA+8X3fVnN8i6WqcS7d6RW+MSEA0PgAyTt30dLiQfwVO07L7vsQ@mail.gmail.com>

Hi Atte,
I'm not sure that this actually works, and it's very much a quick hack:

sums_x<-function(x,addends=1,depth=1) {
 if(depth==1) {
  addends<-rep(addends,x)
  addlist<-list(addends)
 } else {
  addlist<-list()
 }
 lenadd<-length(addends)
 while(lenadd > 2) {
  addends<-c(addends[depth]+1,addends[-c(depth,depth+1)])
  lenadd<-lenadd-1
  if(sum(addends) == x) addlist[[length(addlist)+1]]<-addends
  cat(depth,"-",addends,"\n")
  if(lenadd > 2 && depth+1 < lenadd)
   addlist<-c(addlist,(sums_x(x,addends=addends,depth=depth+1)))
 }
 return(addlist)
}

This doesn't return all the permutations of the addends, but it's all
the time I have to waste this morning.

Jim

On Thu, Apr 28, 2016 at 1:46 AM, Atte Tenkanen <attenka at utu.fi> wrote:
> Hi,
>
> Do you have ideas, how to find all those different combinations of integers
> (>0) that produce as a sum, a certain integer.
>
> i.e.: if that sum is
>
> 3, the possibilities are c(1,1,1), c(1,2), c(2,1)
> 4, the possibilities are
> c(1,1,1,1),c(1,1,2),c(1,2,1),c(2,1,1),c(2,2),c(1,3),c(3,1)
>
> etc.
>
> Best regards,
>
> Atte Tenkanen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Thu Apr 28 03:10:35 2016
From: jholtman at gmail.com (jim holtman)
Date: Wed, 27 Apr 2016 21:10:35 -0400
Subject: [R] Same sum, different sets of integers
In-Reply-To: <5720DEE4.50909@utu.fi>
References: <5720DEE4.50909@utu.fi>
Message-ID: <CAAxdm-6rX_XeSuH0Mi=5EwD_TO+OeHgV5U=QzKPe-hNeyvOrFw@mail.gmail.com>

This is not the most efficient, but gets the idea across.  This is the
largest sum I can compute on my laptop with 16GB of memory.  If I try to
set N to 9, I run out of memory due to the size of the expand.grid.

> N <- 8  # value to add up to
> # create expand.grid for all combinations and convert to matrix
> x <- as.matrix(expand.grid(rep(list(0:(N - 1)), N)))
>
> # generate rowSums and determine which rows add to N
> z <- rowSums(x)
>
> # now extract those rows, sort and convert to strings to remove dups
> add2N <- x[z == N, ]
> strings <- apply(
+             t(apply(add2N, 1, sort))  # sort
+             , 1
+             , toString
+             )
>
> # remove dups
> strings <- strings[!duplicated(strings)]
>
> # remove leading zeros
> strings <- gsub("0, ", "", strings)
>
> # print out
> cat(strings, sep = '\n')
1, 7
2, 6
3, 5
4, 4
1, 1, 6
1, 2, 5
1, 3, 4
2, 2, 4
2, 3, 3
1, 1, 1, 5
1, 1, 2, 4
1, 1, 3, 3
1, 2, 2, 3
2, 2, 2, 2
1, 1, 1, 1, 4
1, 1, 1, 2, 3
1, 1, 2, 2, 2
1, 1, 1, 1, 1, 3
1, 1, 1, 1, 2, 2
1, 1, 1, 1, 1, 1, 2
1, 1, 1, 1, 1, 1, 1, 1



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Apr 27, 2016 at 11:46 AM, Atte Tenkanen <attenka at utu.fi> wrote:

> Hi,
>
> Do you have ideas, how to find all those different combinations of
> integers (>0) that produce as a sum, a certain integer.
>
> i.e.: if that sum is
>
> 3, the possibilities are c(1,1,1), c(1,2), c(2,1)
> 4, the possibilities are
> c(1,1,1,1),c(1,1,2),c(1,2,1),c(2,1,1),c(2,2),c(1,3),c(3,1)
>
> etc.
>
> Best regards,
>
> Atte Tenkanen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Thu Apr 28 04:00:27 2016
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 27 Apr 2016 19:00:27 -0700
Subject: [R] Same sum, different sets of integers
In-Reply-To: <CAAxdm-6rX_XeSuH0Mi=5EwD_TO+OeHgV5U=QzKPe-hNeyvOrFw@mail.gmail.com>
References: <5720DEE4.50909@utu.fi>
	<CAAxdm-6rX_XeSuH0Mi=5EwD_TO+OeHgV5U=QzKPe-hNeyvOrFw@mail.gmail.com>
Message-ID: <CA+hbrhX14cT_G0g2Bn45qP5w+8Ris9SKSYh6KPBtuiCM8zkjSQ@mail.gmail.com>

I came up with this, using recursion. Short and should work for n
greater than 9 :)

Peter

sumsToN = function(n)
{
  if (n==1) return(1);
  out = lapply(1:(n-1), function(i) {
    s1 = sumsToN(n-i);
    lapply(s1, c, i)
  })
  c(n, unlist(out, recursive = FALSE));
}

> sumsToN(4)
[[1]]
[1] 4

[[2]]
[1] 3 1

[[3]]
[1] 2 1 1

[[4]]
[1] 1 1 1 1

[[5]]
[1] 1 2 1

[[6]]
[1] 2 2

[[7]]
[1] 1 1 2

[[8]]
[1] 1 3

> sumsToN(5)
[[1]]
[1] 5

[[2]]
[1] 4 1

[[3]]
[1] 3 1 1

[[4]]
[1] 2 1 1 1

[[5]]
[1] 1 1 1 1 1

[[6]]
[1] 1 2 1 1

[[7]]
[1] 2 2 1

[[8]]
[1] 1 1 2 1

[[9]]
[1] 1 3 1

[[10]]
[1] 3 2

[[11]]
[1] 2 1 2

[[12]]
[1] 1 1 1 2

[[13]]
[1] 1 2 2

[[14]]
[1] 2 3

[[15]]
[1] 1 1 3

[[16]]
[1] 1 4


On Wed, Apr 27, 2016 at 6:10 PM, jim holtman <jholtman at gmail.com> wrote:
> This is not the most efficient, but gets the idea across.  This is the
> largest sum I can compute on my laptop with 16GB of memory.  If I try to
> set N to 9, I run out of memory due to the size of the expand.grid.
>
>> N <- 8  # value to add up to
>> # create expand.grid for all combinations and convert to matrix
>> x <- as.matrix(expand.grid(rep(list(0:(N - 1)), N)))
>>
>> # generate rowSums and determine which rows add to N
>> z <- rowSums(x)
>>
>> # now extract those rows, sort and convert to strings to remove dups
>> add2N <- x[z == N, ]
>> strings <- apply(
> +             t(apply(add2N, 1, sort))  # sort
> +             , 1
> +             , toString
> +             )
>>
>> # remove dups
>> strings <- strings[!duplicated(strings)]
>>
>> # remove leading zeros
>> strings <- gsub("0, ", "", strings)
>>
>> # print out
>> cat(strings, sep = '\n')
> 1, 7
> 2, 6
> 3, 5
> 4, 4
> 1, 1, 6
> 1, 2, 5
> 1, 3, 4
> 2, 2, 4
> 2, 3, 3
> 1, 1, 1, 5
> 1, 1, 2, 4
> 1, 1, 3, 3
> 1, 2, 2, 3
> 2, 2, 2, 2
> 1, 1, 1, 1, 4
> 1, 1, 1, 2, 3
> 1, 1, 2, 2, 2
> 1, 1, 1, 1, 1, 3
> 1, 1, 1, 1, 2, 2
> 1, 1, 1, 1, 1, 1, 2
> 1, 1, 1, 1, 1, 1, 1, 1
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Wed, Apr 27, 2016 at 11:46 AM, Atte Tenkanen <attenka at utu.fi> wrote:
>
>> Hi,
>>
>> Do you have ideas, how to find all those different combinations of
>> integers (>0) that produce as a sum, a certain integer.
>>
>> i.e.: if that sum is
>>
>> 3, the possibilities are c(1,1,1), c(1,2), c(2,1)
>> 4, the possibilities are
>> c(1,1,1,1),c(1,1,2),c(1,2,1),c(2,1,1),c(2,2),c(1,3),c(3,1)
>>
>> etc.
>>
>> Best regards,
>>
>> Atte Tenkanen
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From samarvir1996 at gmail.com  Wed Apr 27 13:59:05 2016
From: samarvir1996 at gmail.com (samarvir singh)
Date: Wed, 27 Apr 2016 17:29:05 +0530
Subject: [R] Using Foreach for downloading data
Message-ID: <CAOpgo6gopRxGVhxoL0QovnB+mXL4oUmk3B2W8TiOHrD6nm14Xw@mail.gmail.com>

Hi!

I have this code which is working


formula <- function(x){

return(x)
}

For( x in names)

        {

            x5 <- rbind(x5,formula(x))

        }


Now, I want to convert this code to parallel processing, so i am using
foreach function

foreach(x=names, .packages="checkpoint" ,.combine='rbind') %dopar%
        {
            x5 <- rbind(x5,formula(x))

        }

Now, I know that have to load packages to workers which I did!
but I also need to login to secure sever, for downloading some data, which
I did , in the case of for loop!

how can I do the same for foreach loop?

	[[alternative HTML version deleted]]


From mkcox at uas.alaska.edu  Wed Apr 27 20:49:13 2016
From: mkcox at uas.alaska.edu (Marlin Keith Cox)
Date: Wed, 27 Apr 2016 10:49:13 -0800
Subject: [R] error.crosses
Message-ID: <CAHskWAWy9g=AgOg_yShOEL0VVVLYrCxho6mUKPM_pQPYb3USsQ@mail.gmail.com>

Hello all, I have used describeBy to generate the following summary
statistics.  I simply need x and y error bars on a plot that has CQN
(xaxis) and Price (yaxis).  There should be four total points on the graph
(one for each supplier).

Using "error.crosses(desc$CQN, desc$Price)" does not work.



group: a
          vars  n  mean    sd median trimmed   mad   min   max range skew
CQN          1 65 48.22 11.12  49.61   47.86 13.79 31.30 72.71 41.41  0.1
Price        2 65  6.65  0.06   6.69    6.66  0.01  6.48  6.70  0.22 -1.2
Supplier*    3 65   NaN    NA     NA     NaN    NA   Inf  -Inf  -Inf   NA
          kurtosis   se
CQN          -1.01 1.38
Price         0.70 0.01
Supplier*       NA   NA
------------------------------------------------------------
group: b
          vars n  mean sd median trimmed mad   min   max range skew
kurtosis se
CQN          1 1 91.93 NA  91.93   91.93   0 91.93 91.93     0   NA
NA NA
Price        2 1  6.95 NA   6.95    6.95   0  6.95  6.95     0   NA
NA NA
Supplier*    3 1   NaN NA     NA     NaN  NA   Inf  -Inf  -Inf   NA
NA NA
------------------------------------------------------------
group: c
          vars n  mean   sd median trimmed  mad   min   max range skew
kurtosis
CQN          1 6 63.11 2.58  62.04   63.11 1.53 60.66 67.19  6.53 0.55
 -1.68
Price        2 6  8.92 0.00   8.92    8.92 0.00  8.92  8.92  0.00  NaN
 NaN
Supplier*    3 6   NaN   NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
  NA
            se
CQN       1.05
Price     0.00
Supplier*   NA
------------------------------------------------------------
group: d
          vars n  mean  sd median trimmed  mad   min   max range skew
kurtosis
CQN          1 6 47.20 5.7  46.31   47.20 7.17 39.52 54.45 14.93 0.08
 -1.79
Price        2 6  7.17 0.0   7.17    7.17 0.00  7.17  7.17  0.00  NaN
 NaN
Supplier*    3 6   NaN  NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
NA
            se
CQN       2.33
Price     0.00
Supplier*   NA




M. Keith Cox, PhD
Assistant Professor of Biology
Natural Sciences
Coordinator
Alaska Native Science and Engineering Program (ANSEP)
11120 Glacier Hwy
Juneau, Alaska 99801
Office: Anderson Building
Phone: 907 957-4606
web: www.ansep.net

	[[alternative HTML version deleted]]


From sarifkin at ucsd.edu  Wed Apr 27 21:29:13 2016
From: sarifkin at ucsd.edu (Scott Rifkin)
Date: Wed, 27 Apr 2016 12:29:13 -0700
Subject: [R] odd behavior of numeric()
Message-ID: <57211309.4080601@ucsd.edu>

Why does:

 > numeric(0.2*25)

return

[1] 0 0 0 0 0

but

 > numeric((1-0.8)*25)

returns

[1] 0 0 0 0

[running version 3.2.0]


[Apologies if this has been asked before - it's a hard question to find 
specific search terms for]

Thanks,
Scott


From Simon.Heather at epa.gov  Wed Apr 27 22:17:22 2016
From: Simon.Heather at epa.gov (Simon, Heather)
Date: Wed, 27 Apr 2016 20:17:22 +0000
Subject: [R] polygon angle option perpendicular to axis
Message-ID: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>

I am trying to use the angle option in polygon to create polygons filled with horizontal and vertical lines.  The polygons I am crating are irregular and it the angle function appears to set the angle of the shading perpendicular to the polygon sides rather than perpendicular to the axes.  Is there any way to set the angle relative to the axes rather than relative to the polygon sides?



	[[alternative HTML version deleted]]


From rmh at temple.edu  Thu Apr 28 06:06:47 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 28 Apr 2016 00:06:47 -0400
Subject: [R] odd behavior of numeric()
In-Reply-To: <57211309.4080601@ucsd.edu>
References: <57211309.4080601@ucsd.edu>
Message-ID: <CAGx1TMBCEB9DSm=g0W4WX_vivc3Hhi6EieegM+3xZGym=Tz-KQ@mail.gmail.com>

> numeric(0.2*25)
[1] 0 0 0 0 0
> numeric((1-0.8)*25)
[1] 0 0 0 0
> print(c(0.2*25, (1-0.8)*25), digits=17)
[1] 5.0000000000000000 4.9999999999999991
> 0.2*25 - (1-0.8)*25
[1] 8.881784e-16
> as.integer(c(0.2*25, (1-0.8)*25), digits=17)
[1] 5 4
> ## See FAQ 7.31 for other examples of floating point behavior
>

On Wed, Apr 27, 2016 at 3:29 PM, Scott Rifkin <sarifkin at ucsd.edu> wrote:
> Why does:
>
>> numeric(0.2*25)
>
> return
>
> [1] 0 0 0 0 0
>
> but
>
>> numeric((1-0.8)*25)
>
> returns
>
> [1] 0 0 0 0
>
> [running version 3.2.0]
>
>
> [Apologies if this has been asked before - it's a hard question to find
> specific search terms for]
>
> Thanks,
> Scott
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Peter.Alspach at plantandfood.co.nz  Thu Apr 28 06:10:31 2016
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 28 Apr 2016 16:10:31 +1200
Subject: [R] polygon angle option perpendicular to axis
In-Reply-To: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
References: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B75452C3A5D8F7E@AKLEXM01.PFR.CO.NZ>

Tena koe Simon

plot(1:10, 1:10, type='n')
polygon(c(2,3,6,8), c(2,5,5,3), density=20, angle=90)
polygon(c(2,3,6,8), 5+c(2,5,5,3), density=20, angle=0)

I don't understand your problem.  Perhaps if you "provide[d] commented, minimal, self-contained, reproducible code" it would help.

HTH ....

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Simon, Heather
Sent: Thursday, 28 April 2016 8:17 a.m.
To: r-help at r-project.org
Subject: [R] polygon angle option perpendicular to axis

I am trying to use the angle option in polygon to create polygons filled with horizontal and vertical lines.  The polygons I am crating are irregular and it the angle function appears to set the angle of the shading perpendicular to the polygon sides rather than perpendicular to the axes.  Is there any way to set the angle relative to the axes rather than relative to the polygon sides?



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From jdnewmil at dcn.davis.ca.us  Thu Apr 28 06:11:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 28 Apr 2016 05:11:50 +0100
Subject: [R] odd behavior of numeric()
In-Reply-To: <57211309.4080601@ucsd.edu>
References: <57211309.4080601@ucsd.edu>
Message-ID: <8FFFDD3B-1DD9-46DE-9C8B-DB16917F6046@dcn.davis.ca.us>

FAQ 7.31

0.2 is slightly larger than 1/5, and 1-0.8 is slightly smaller.  The argument to numeric has to be an integer, so fractions are discarded. This behavior is not unique to R.
-- 
Sent from my phone. Please excuse my brevity.

On April 27, 2016 8:29:13 PM GMT+01:00, Scott Rifkin <sarifkin at ucsd.edu> wrote:
>Why does:
>
> > numeric(0.2*25)
>
>return
>
>[1] 0 0 0 0 0
>
>but
>
> > numeric((1-0.8)*25)
>
>returns
>
>[1] 0 0 0 0
>
>[running version 3.2.0]
>
>
>[Apologies if this has been asked before - it's a hard question to find
>
>specific search terms for]
>
>Thanks,
>Scott
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Apr 28 06:19:30 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 27 Apr 2016 21:19:30 -0700
Subject: [R] error.crosses
In-Reply-To: <CAHskWAWy9g=AgOg_yShOEL0VVVLYrCxho6mUKPM_pQPYb3USsQ@mail.gmail.com>
References: <CAHskWAWy9g=AgOg_yShOEL0VVVLYrCxho6mUKPM_pQPYb3USsQ@mail.gmail.com>
Message-ID: <CAGxFJbQnD5UpOUmbvGmKDCQPi_HuEEmyjFe=dyvsxfV5uUiNhg@mail.gmail.com>

You posted this earlier, did you not, and no one answered, perhaps
because no one understood and/or perhaps because you failed to follow
the posting guide (no minimal reproducible example nor code; and HTML
to a plain text list).  Please be more patient and stop spamming the
list. And perhaps try following the posting guide.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 27, 2016 at 11:49 AM, Marlin Keith Cox <mkcox at uas.alaska.edu> wrote:
> Hello all, I have used describeBy to generate the following summary
> statistics.  I simply need x and y error bars on a plot that has CQN
> (xaxis) and Price (yaxis).  There should be four total points on the graph
> (one for each supplier).
>
> Using "error.crosses(desc$CQN, desc$Price)" does not work.
>
>
>
> group: a
>           vars  n  mean    sd median trimmed   mad   min   max range skew
> CQN          1 65 48.22 11.12  49.61   47.86 13.79 31.30 72.71 41.41  0.1
> Price        2 65  6.65  0.06   6.69    6.66  0.01  6.48  6.70  0.22 -1.2
> Supplier*    3 65   NaN    NA     NA     NaN    NA   Inf  -Inf  -Inf   NA
>           kurtosis   se
> CQN          -1.01 1.38
> Price         0.70 0.01
> Supplier*       NA   NA
> ------------------------------------------------------------
> group: b
>           vars n  mean sd median trimmed mad   min   max range skew
> kurtosis se
> CQN          1 1 91.93 NA  91.93   91.93   0 91.93 91.93     0   NA
> NA NA
> Price        2 1  6.95 NA   6.95    6.95   0  6.95  6.95     0   NA
> NA NA
> Supplier*    3 1   NaN NA     NA     NaN  NA   Inf  -Inf  -Inf   NA
> NA NA
> ------------------------------------------------------------
> group: c
>           vars n  mean   sd median trimmed  mad   min   max range skew
> kurtosis
> CQN          1 6 63.11 2.58  62.04   63.11 1.53 60.66 67.19  6.53 0.55
>  -1.68
> Price        2 6  8.92 0.00   8.92    8.92 0.00  8.92  8.92  0.00  NaN
>  NaN
> Supplier*    3 6   NaN   NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
>   NA
>             se
> CQN       1.05
> Price     0.00
> Supplier*   NA
> ------------------------------------------------------------
> group: d
>           vars n  mean  sd median trimmed  mad   min   max range skew
> kurtosis
> CQN          1 6 47.20 5.7  46.31   47.20 7.17 39.52 54.45 14.93 0.08
>  -1.79
> Price        2 6  7.17 0.0   7.17    7.17 0.00  7.17  7.17  0.00  NaN
>  NaN
> Supplier*    3 6   NaN  NA     NA     NaN   NA   Inf  -Inf  -Inf   NA
> NA
>             se
> CQN       2.33
> Price     0.00
> Supplier*   NA
>
>
>
>
> M. Keith Cox, PhD
> Assistant Professor of Biology
> Natural Sciences
> Coordinator
> Alaska Native Science and Engineering Program (ANSEP)
> 11120 Glacier Hwy
> Juneau, Alaska 99801
> Office: Anderson Building
> Phone: 907 957-4606
> web: www.ansep.net
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Thu Apr 28 09:07:40 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 28 Apr 2016 09:07:40 +0200
Subject: [R] Interdependencies of variable types, logical expressions and NA
Message-ID: <OF94C8E8AC.AD90A353-ONC1257FA2.004E7391-C1257FA3.002727F7@lotus.hawesko.de>

Hi All,

my script tries to do the following on factors:

> ## Check for case 3: Umsatz = 0 & Kunde = 1
> for (year in 2011:2015) {
+   Umsatz <- paste0("Umsatz_", year)
+   Kunde <- paste0("Kunde01_", year)
+   Check <- paste0("Check_U_0__Kd_1_", year)
+ 
+   cat('Creating', Check, 'from', Umsatz, "and", Kunde, '\n')
+ 
+   Kunden01[[ Check ]] <- ifelse(Kunden01[[ Umsatz ]] == 0 &
+                                 Kunden01[[ Kunde ]] == 1,
+                                 1, 0
+                                 )
+   Kunden01[[ Check ]] <- factor(Kunden01[[ Check ]],
+                                 levels=c(1, 0),
+                                 labels= c("Check 0", "OK")
+                                 )
+ 
+ }
Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011 
Creating Check_U_0__Kd_1_2012 from Umsatz_2012 and Kunde01_2012 
Creating Check_U_0__Kd_1_2013 from Umsatz_2013 and Kunde01_2013 
Creating Check_U_0__Kd_1_2014 from Umsatz_2014 and Kunde01_2014 
Creating Check_U_0__Kd_1_2015 from Umsatz_2015 and Kunde01_2015 
> 
> table(Kunden01$Check_U_0__Kd_1_2011, useNA = "ifany")

Check 0      OK    <NA> 
      1      16      13 
> table(Kunden01$Check_U_0__Kd_1_2012, useNA = "ifany")

Check 0      OK    <NA> 
      1      17      12 
> table(Kunden01$Check_U_0__Kd_1_2013, useNA = "ifany")

Check 0      OK    <NA> 
      2      17      13 
> table(Kunden01$Check_U_0__Kd_1_2014, useNA = "ifany")

Check 0      OK    <NA> 
      1      15      14 
> table(Kunden01$Check_U_0__Kd_1_2015, useNA = "ifany")

Check 0      OK    <NA> 
      2      15      13 
> 
> Kunden01$Check_U_0__Kd_1_all <- ifelse(Kunden01$Check_U_0__Kd_1_2011 == 
1 |
+                                        Kunden01$Check_U_0__Kd_1_2012 == 
1 |
+                                        Kunden01$Check_U_0__Kd_1_2013 == 
1 |
+                                        Kunden01$Check_U_0__Kd_1_2014 == 
1 |
+                                        Kunden01$Check_U_0__Kd_1_2015 == 
1,
+                                        1, 0)
> 
> table(Kunden01$Check_U_0__Kd_1_all, useNA = "ifany")

    0  <NA> 
    7    23 

(Ann.: I made the values up. But the relations equal real world data.)

I had expected to get back a factor or at least a numeric variable 
containing 0, 1 and NA, instead 1 is not included.

I searched the web for information on the treatment of logical expressions 
when the data contains NA. I found:

1. 
https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html
Examples
# Some logical operations do not return NA
c(TRUE, FALSE) & NA
c(TRUE, FALSE) | NA

2.
https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
NA is a valid logical object. Where a component of x or y is NA, the 
result will be NA if the outcome is ambiguous. In other words NA & TRUE 
evaluates to NA, but NA & FALSE evaluates to FALSE. See the examples 
below. 

## construct truth tables :
x <- c(NA, FALSE, TRUE)
names(x) <- as.character(x)
outer(x, x, "&") ## AND table
outer(x, x, "|") ## OR  table
Ann. Not very useful. How should it be read?

3.
http://www.ats.ucla.edu/stat/r/faq/missing.htm
Good explanation for NA in general and in analysis, but no information 
about NA in logical expressions.

Then I made some tests with different data types and variables with NA:

-- cut --

# 2016-04-27-001_truth_table_for_logicals_and_NA.R

# Test 1
var2 <- c(TRUE, FALSE)
var3 <- c(NA, NA)
var1 <- c(1, 1)
ds <- data.frame(var1, var2, var3)
ds

ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)

print(ds)
# Output
# var1  var2 var3 value_and_logical logical_and_na value_and_na
# 1    1  TRUE   NA              TRUE           TRUE         TRUE
# 2    1 FALSE   NA              TRUE             NA         TRUE

# Test 2
ds$var1 <- factor(ds$var1, levels = c(0, 1), labels = c("NOT ok", "OK"))
ds$var2 <- factor(ds$var2, levels = c(0, 1), labels = c("NOT ok", "OK"))
ds$var3 <- factor(ds$var3, levels = c(0, 1), labels = c("NOT ok", "OK"))

ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)

# Output (abbrev.)
# Warning message:
#  In Ops.factor(ds$var1, ds$var3) : ?|? ist nicht sinnvoll f?r Faktoren

print(ds)
# Output
# var1 var2 var3 value_and_logical logical_and_na value_and_na
# 1   OK <NA> <NA>                NA             NA           NA
# 2   OK <NA> <NA>                NA             NA           NA

-- cut --

I had expected to get the same result in Test 2 as in Test 1.

Where can I find information and documentation about NA handling in 
logical expressions on different variable types?

Kind regards

Georg


From petr.pikal at precheza.cz  Thu Apr 28 09:41:32 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 28 Apr 2016 07:41:32 +0000
Subject: [R] Interdependencies of variable types,
 logical expressions and NA
In-Reply-To: <OF94C8E8AC.AD90A353-ONC1257FA2.004E7391-C1257FA3.002727F7@lotus.hawesko.de>
References: <OF94C8E8AC.AD90A353-ONC1257FA2.004E7391-C1257FA3.002727F7@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287BD@SRVEXCHMBX.precheza.cz>

Hi

Your script is not reproducible.

Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011
Error in ifelse(Kunden01[[Umsatz]] == 0 & Kunden01[[Kunde]] == 1, 1, 0) :
  object 'Kunden01' not found
>

This is interesting
x <- c(NA, FALSE, TRUE)
names(x) <- as.character(x)
outer(x, x, "&") ## AND table
       <NA> FALSE  TRUE
<NA>     NA FALSE    NA
FALSE FALSE FALSE FALSE
TRUE     NA FALSE  TRUE
>

I am not sure, but the logic for AND is to return TRUE only when both expressions are TRUE.

so
T&T = T
F&F = F
T&NA = NA (you cannot decide hence NA)
F&NA = F (you can decide that regardless of NA the result must be F)

outer(x, x, "|") ## OR  table
      <NA> FALSE TRUE
<NA>    NA    NA TRUE
FALSE   NA FALSE TRUE
TRUE  TRUE  TRUE TRUE

OTOH the logic for OR table is that if one of the expressions is TRUE the result must be TRUE
T | T = T
F | F = F
T&NA = T (you can decide that regardless value in NA the result must be T)
F&NA = NA (you cannot decide hence NA)

And I believe that all your results can be explained by this logic.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> G.Maubach at weinwolf.de
> Sent: Thursday, April 28, 2016 9:08 AM
> To: r-help at r-project.org
> Subject: [R] Interdependencies of variable types, logical expressions and NA
>
> Hi All,
>
> my script tries to do the following on factors:
>
> > ## Check for case 3: Umsatz = 0 & Kunde = 1
> > for (year in 2011:2015) {
> +   Umsatz <- paste0("Umsatz_", year)
> +   Kunde <- paste0("Kunde01_", year)
> +   Check <- paste0("Check_U_0__Kd_1_", year)
> +
> +   cat('Creating', Check, 'from', Umsatz, "and", Kunde, '\n')
> +
> +   Kunden01[[ Check ]] <- ifelse(Kunden01[[ Umsatz ]] == 0 &
> +                                 Kunden01[[ Kunde ]] == 1,
> +                                 1, 0
> +                                 )
> +   Kunden01[[ Check ]] <- factor(Kunden01[[ Check ]],
> +                                 levels=c(1, 0),
> +                                 labels= c("Check 0", "OK")
> +                                 )
> +
> + }
> Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011
> Creating Check_U_0__Kd_1_2012 from Umsatz_2012 and Kunde01_2012
> Creating Check_U_0__Kd_1_2013 from Umsatz_2013 and Kunde01_2013
> Creating Check_U_0__Kd_1_2014 from Umsatz_2014 and Kunde01_2014
> Creating Check_U_0__Kd_1_2015 from Umsatz_2015 and Kunde01_2015
> >
> > table(Kunden01$Check_U_0__Kd_1_2011, useNA = "ifany")
>
> Check 0      OK    <NA>
>       1      16      13
> > table(Kunden01$Check_U_0__Kd_1_2012, useNA = "ifany")
>
> Check 0      OK    <NA>
>       1      17      12
> > table(Kunden01$Check_U_0__Kd_1_2013, useNA = "ifany")
>
> Check 0      OK    <NA>
>       2      17      13
> > table(Kunden01$Check_U_0__Kd_1_2014, useNA = "ifany")
>
> Check 0      OK    <NA>
>       1      15      14
> > table(Kunden01$Check_U_0__Kd_1_2015, useNA = "ifany")
>
> Check 0      OK    <NA>
>       2      15      13
> >
> > Kunden01$Check_U_0__Kd_1_all <-
> ifelse(Kunden01$Check_U_0__Kd_1_2011 ==
> 1 |
> +                                        Kunden01$Check_U_0__Kd_1_2012 ==
> 1 |
> +                                        Kunden01$Check_U_0__Kd_1_2013 ==
> 1 |
> +                                        Kunden01$Check_U_0__Kd_1_2014 ==
> 1 |
> +                                        Kunden01$Check_U_0__Kd_1_2015 ==
> 1,
> +                                        1, 0)
> >
> > table(Kunden01$Check_U_0__Kd_1_all, useNA = "ifany")
>
>     0  <NA>
>     7    23
>
> (Ann.: I made the values up. But the relations equal real world data.)
>
> I had expected to get back a factor or at least a numeric variable
> containing 0, 1 and NA, instead 1 is not included.
>
> I searched the web for information on the treatment of logical expressions
> when the data contains NA. I found:
>
> 1.
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html
> Examples
> # Some logical operations do not return NA
> c(TRUE, FALSE) & NA
> c(TRUE, FALSE) | NA
>
> 2.
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
> NA is a valid logical object. Where a component of x or y is NA, the
> result will be NA if the outcome is ambiguous. In other words NA & TRUE
> evaluates to NA, but NA & FALSE evaluates to FALSE. See the examples
> below.
>
> ## construct truth tables :
> x <- c(NA, FALSE, TRUE)
> names(x) <- as.character(x)
> outer(x, x, "&") ## AND table
> outer(x, x, "|") ## OR  table
> Ann. Not very useful. How should it be read?
>
> 3.
> http://www.ats.ucla.edu/stat/r/faq/missing.htm
> Good explanation for NA in general and in analysis, but no information
> about NA in logical expressions.
>
> Then I made some tests with different data types and variables with NA:
>
> -- cut --
>
> # 2016-04-27-001_truth_table_for_logicals_and_NA.R
>
> # Test 1
> var2 <- c(TRUE, FALSE)
> var3 <- c(NA, NA)
> var1 <- c(1, 1)
> ds <- data.frame(var1, var2, var3)
> ds
>
> ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
>
> print(ds)
> # Output
> # var1  var2 var3 value_and_logical logical_and_na value_and_na
> # 1    1  TRUE   NA              TRUE           TRUE         TRUE
> # 2    1 FALSE   NA              TRUE             NA         TRUE
>
> # Test 2
> ds$var1 <- factor(ds$var1, levels = c(0, 1), labels = c("NOT ok", "OK"))
> ds$var2 <- factor(ds$var2, levels = c(0, 1), labels = c("NOT ok", "OK"))
> ds$var3 <- factor(ds$var3, levels = c(0, 1), labels = c("NOT ok", "OK"))
>
> ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
>
> # Output (abbrev.)
> # Warning message:
> #  In Ops.factor(ds$var1, ds$var3) : ?|? ist nicht sinnvoll f?r Faktoren
>
> print(ds)
> # Output
> # var1 var2 var3 value_and_logical logical_and_na value_and_na
> # 1   OK <NA> <NA>                NA             NA           NA
> # 2   OK <NA> <NA>                NA             NA           NA
>
> -- cut --
>
> I had expected to get the same result in Test 2 as in Test 1.
>
> Where can I find information and documentation about NA handling in
> logical expressions on different variable types?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From petr.pikal at precheza.cz  Thu Apr 28 10:02:59 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 28 Apr 2016 08:02:59 +0000
Subject: [R] Interdependencies of variable types,
 logical expressions and NA
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287BD@SRVEXCHMBX.precheza.cz>
References: <OF94C8E8AC.AD90A353-ONC1257FA2.004E7391-C1257FA3.002727F7@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287BD@SRVEXCHMBX.precheza.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287F1@SRVEXCHMBX.precheza.cz>

Sorry
these

T&NA = T (you can decide that regardless value in NA the result must be T)
F&NA = NA (you cannot decide hence NA)

should be

T | NA = T (you can decide that regardless value in NA the result must be T)
F | NA = NA (you cannot decide hence NA)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
> Sent: Thursday, April 28, 2016 9:42 AM
> To: G.Maubach at weinwolf.de; r-help at r-project.org
> Subject: Re: [R] Interdependencies of variable types, logical expressions and
> NA
>
> Hi
>
> Your script is not reproducible.
>
> Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011
> Error in ifelse(Kunden01[[Umsatz]] == 0 & Kunden01[[Kunde]] == 1, 1, 0) :
>   object 'Kunden01' not found
> >
>
> This is interesting
> x <- c(NA, FALSE, TRUE)
> names(x) <- as.character(x)
> outer(x, x, "&") ## AND table
>        <NA> FALSE  TRUE
> <NA>     NA FALSE    NA
> FALSE FALSE FALSE FALSE
> TRUE     NA FALSE  TRUE
> >
>
> I am not sure, but the logic for AND is to return TRUE only when both
> expressions are TRUE.
>
> so
> T&T = T
> F&F = F
> T&NA = NA (you cannot decide hence NA)
> F&NA = F (you can decide that regardless of NA the result must be F)
>
> outer(x, x, "|") ## OR  table
>       <NA> FALSE TRUE
> <NA>    NA    NA TRUE
> FALSE   NA FALSE TRUE
> TRUE  TRUE  TRUE TRUE
>
> OTOH the logic for OR table is that if one of the expressions is TRUE the result
> must be TRUE
> T | T = T
> F | F = F
> T&NA = T (you can decide that regardless value in NA the result must be T)
> F&NA = NA (you cannot decide hence NA)
>
> And I believe that all your results can be explained by this logic.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > G.Maubach at weinwolf.de
> > Sent: Thursday, April 28, 2016 9:08 AM
> > To: r-help at r-project.org
> > Subject: [R] Interdependencies of variable types, logical expressions and
> NA
> >
> > Hi All,
> >
> > my script tries to do the following on factors:
> >
> > > ## Check for case 3: Umsatz = 0 & Kunde = 1
> > > for (year in 2011:2015) {
> > +   Umsatz <- paste0("Umsatz_", year)
> > +   Kunde <- paste0("Kunde01_", year)
> > +   Check <- paste0("Check_U_0__Kd_1_", year)
> > +
> > +   cat('Creating', Check, 'from', Umsatz, "and", Kunde, '\n')
> > +
> > +   Kunden01[[ Check ]] <- ifelse(Kunden01[[ Umsatz ]] == 0 &
> > +                                 Kunden01[[ Kunde ]] == 1,
> > +                                 1, 0
> > +                                 )
> > +   Kunden01[[ Check ]] <- factor(Kunden01[[ Check ]],
> > +                                 levels=c(1, 0),
> > +                                 labels= c("Check 0", "OK")
> > +                                 )
> > +
> > + }
> > Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011
> > Creating Check_U_0__Kd_1_2012 from Umsatz_2012 and Kunde01_2012
> > Creating Check_U_0__Kd_1_2013 from Umsatz_2013 and Kunde01_2013
> > Creating Check_U_0__Kd_1_2014 from Umsatz_2014 and Kunde01_2014
> > Creating Check_U_0__Kd_1_2015 from Umsatz_2015 and Kunde01_2015
> > >
> > > table(Kunden01$Check_U_0__Kd_1_2011, useNA = "ifany")
> >
> > Check 0      OK    <NA>
> >       1      16      13
> > > table(Kunden01$Check_U_0__Kd_1_2012, useNA = "ifany")
> >
> > Check 0      OK    <NA>
> >       1      17      12
> > > table(Kunden01$Check_U_0__Kd_1_2013, useNA = "ifany")
> >
> > Check 0      OK    <NA>
> >       2      17      13
> > > table(Kunden01$Check_U_0__Kd_1_2014, useNA = "ifany")
> >
> > Check 0      OK    <NA>
> >       1      15      14
> > > table(Kunden01$Check_U_0__Kd_1_2015, useNA = "ifany")
> >
> > Check 0      OK    <NA>
> >       2      15      13
> > >
> > > Kunden01$Check_U_0__Kd_1_all <-
> > ifelse(Kunden01$Check_U_0__Kd_1_2011 ==
> > 1 |
> > +                                        Kunden01$Check_U_0__Kd_1_2012 ==
> > 1 |
> > +                                        Kunden01$Check_U_0__Kd_1_2013 ==
> > 1 |
> > +                                        Kunden01$Check_U_0__Kd_1_2014 ==
> > 1 |
> > +                                        Kunden01$Check_U_0__Kd_1_2015 ==
> > 1,
> > +                                        1, 0)
> > >
> > > table(Kunden01$Check_U_0__Kd_1_all, useNA = "ifany")
> >
> >     0  <NA>
> >     7    23
> >
> > (Ann.: I made the values up. But the relations equal real world data.)
> >
> > I had expected to get back a factor or at least a numeric variable
> > containing 0, 1 and NA, instead 1 is not included.
> >
> > I searched the web for information on the treatment of logical expressions
> > when the data contains NA. I found:
> >
> > 1.
> > https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html
> > Examples
> > # Some logical operations do not return NA
> > c(TRUE, FALSE) & NA
> > c(TRUE, FALSE) | NA
> >
> > 2.
> > https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
> > NA is a valid logical object. Where a component of x or y is NA, the
> > result will be NA if the outcome is ambiguous. In other words NA & TRUE
> > evaluates to NA, but NA & FALSE evaluates to FALSE. See the examples
> > below.
> >
> > ## construct truth tables :
> > x <- c(NA, FALSE, TRUE)
> > names(x) <- as.character(x)
> > outer(x, x, "&") ## AND table
> > outer(x, x, "|") ## OR  table
> > Ann. Not very useful. How should it be read?
> >
> > 3.
> > http://www.ats.ucla.edu/stat/r/faq/missing.htm
> > Good explanation for NA in general and in analysis, but no information
> > about NA in logical expressions.
> >
> > Then I made some tests with different data types and variables with NA:
> >
> > -- cut --
> >
> > # 2016-04-27-001_truth_table_for_logicals_and_NA.R
> >
> > # Test 1
> > var2 <- c(TRUE, FALSE)
> > var3 <- c(NA, NA)
> > var1 <- c(1, 1)
> > ds <- data.frame(var1, var2, var3)
> > ds
> >
> > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> >
> > print(ds)
> > # Output
> > # var1  var2 var3 value_and_logical logical_and_na value_and_na
> > # 1    1  TRUE   NA              TRUE           TRUE         TRUE
> > # 2    1 FALSE   NA              TRUE             NA         TRUE
> >
> > # Test 2
> > ds$var1 <- factor(ds$var1, levels = c(0, 1), labels = c("NOT ok", "OK"))
> > ds$var2 <- factor(ds$var2, levels = c(0, 1), labels = c("NOT ok", "OK"))
> > ds$var3 <- factor(ds$var3, levels = c(0, 1), labels = c("NOT ok", "OK"))
> >
> > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> >
> > # Output (abbrev.)
> > # Warning message:
> > #  In Ops.factor(ds$var1, ds$var3) : ?|? ist nicht sinnvoll f?r Faktoren
> >
> > print(ds)
> > # Output
> > # var1 var2 var3 value_and_logical logical_and_na value_and_na
> > # 1   OK <NA> <NA>                NA             NA           NA
> > # 2   OK <NA> <NA>                NA             NA           NA
> >
> > -- cut --
> >
> > I had expected to get the same result in Test 2 as in Test 1.
> >
> > Where can I find information and documentation about NA handling in
> > logical expressions on different variable types?
> >
> > Kind regards
> >
> > Georg
> >
> > ______________________________________________

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From petr.pikal at precheza.cz  Thu Apr 28 14:31:37 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 28 Apr 2016 12:31:37 +0000
Subject: [R] Antwort: RE:  Interdependencies of variable types,
 logical expressions and NA
In-Reply-To: <OF75F5EC4A.D24EF0F5-ONC1257FA3.003628DC-C1257FA3.0036F178@lotus.hawesko.de>
References: <OF94C8E8AC.AD90A353-ONC1257FA2.004E7391-C1257FA3.002727F7@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287BD@SRVEXCHMBX.precheza.cz>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287F1@SRVEXCHMBX.precheza.cz>
	<OF75F5EC4A.D24EF0F5-ONC1257FA3.003628DC-C1257FA3.0036F178@lotus.hawesko.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50288D7@SRVEXCHMBX.precheza.cz>

Hi

your initial ds

> str(ds)
'data.frame':   2 obs. of  3 variables:
 $ var1: num  1 1
 $ var2: logi  TRUE FALSE
 $ var3: logi  NA NA

first result
> str(ds)
'data.frame':   2 obs. of  6 variables:
 $ var1             : num  1 1
 $ var2             : logi  TRUE FALSE
 $ var3             : logi  NA NA
 $ value_and_logical: logi  TRUE TRUE
 $ logical_and_na   : logi  TRUE NA
 $ value_and_na     : logi  TRUE TRUE

1 is considered as TRUE therefore OR gives TRUE TRUE in first case, TRUE NA in second and TRUE TRUE in third

Changing to factor changes var 2 to NA (I am not sure why)

> str(ds)
'data.frame':   2 obs. of  3 variables:
 $ var1: Factor w/ 2 levels "NOT ok","OK": 2 2
 $ var2: Factor w/ 2 levels "NOT ok","OK": NA NA
 $ var3: Factor w/ 2 levels "NOT ok","OK": NA NA

And this results to warning

> ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
Warning message:
In Ops.factor(ds$var1, ds$var2) : '|' not meaningful for factors
> ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
Warning message:
In Ops.factor(ds$var2, ds$var3) : '|' not meaningful for factors
> ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
Warning message:
In Ops.factor(ds$var1, ds$var3) : '|' not meaningful for factors
> str(ds)
'data.frame':   2 obs. of  6 variables:
 $ var1             : Factor w/ 2 levels "NOT ok","OK": 2 2
 $ var2             : Factor w/ 2 levels "NOT ok","OK": NA NA
 $ var3             : Factor w/ 2 levels "NOT ok","OK": NA NA
 $ value_and_logical: logi  NA NA
 $ logical_and_na   : logi  NA NA
 $ value_and_na     : logi  NA NA
>

so | operation is not valid for factor variables and results to NA values.

Cheers
Petr



> -----Original Message-----
> From: G.Maubach at weinwolf.de [mailto:G.Maubach at weinwolf.de]
> Sent: Thursday, April 28, 2016 12:00 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Subject: Antwort: RE: [R] Interdependencies of variable types, logical
> expressions and NA
>
> Hi Petr,
>
> many thanks for your reply.
>
> Yes it's interesting. I did not understand what the truth table wanted to
> say due to 4 columns instead of 3. But know I got it.
>
> The other thing is that logical expessions with NA work differently on
> different types of variables as my example code shows:
>
> -- cut --
> # Truth table for logicals and NA
>
> var2 <- c(TRUE, FALSE)
> var3 <- c(NA, NA)
> var1 <- c(1, 1)
> ds <- data.frame(var1, var2, var3)
> ds
>
> ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
>
> print(ds)
>
> ds$var1 <- factor(ds$var1, levels = c(0, 1), labels = c("NOT ok", "OK"))
> ds$var2 <- factor(ds$var2, levels = c(0, 1), labels = c("NOT ok", "OK"))
> ds$var3 <- factor(ds$var3, levels = c(0, 1), labels = c("NOT ok", "OK"))
>
> ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
>
> print(ds)
> -- cut --
>
> Additionally the warning message that this script issues was not displayed
> in my production code, but only in this test code.
>
> Also: Is "<NA>" the same as "NA"?
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    PIKAL Petr <petr.pikal at precheza.cz>
> An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
> "r-help at r-project.org" <r-help at r-project.org>,
> Datum:  28.04.2016 10:02
> Betreff:        RE: [R] Interdependencies of variable types, logical
> expressions and NA
>
>
>
> Sorry
> these
>
> T&NA = T (you can decide that regardless value in NA the result must be T)
> F&NA = NA (you cannot decide hence NA)
>
> should be
>
> T | NA = T (you can decide that regardless value in NA the result must be
> T)
> F | NA = NA (you cannot decide hence NA)
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL
> Petr
> > Sent: Thursday, April 28, 2016 9:42 AM
> > To: G.Maubach at weinwolf.de; r-help at r-project.org
> > Subject: Re: [R] Interdependencies of variable types, logical
> expressions and
> > NA
> >
> > Hi
> >
> > Your script is not reproducible.
> >
> > Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011
> > Error in ifelse(Kunden01[[Umsatz]] == 0 & Kunden01[[Kunde]] == 1, 1, 0)
> :
> >   object 'Kunden01' not found
> > >
> >
> > This is interesting
> > x <- c(NA, FALSE, TRUE)
> > names(x) <- as.character(x)
> > outer(x, x, "&") ## AND table
> >        <NA> FALSE  TRUE
> > <NA>     NA FALSE    NA
> > FALSE FALSE FALSE FALSE
> > TRUE     NA FALSE  TRUE
> > >
> >
> > I am not sure, but the logic for AND is to return TRUE only when both
> > expressions are TRUE.
> >
> > so
> > T&T = T
> > F&F = F
> > T&NA = NA (you cannot decide hence NA)
> > F&NA = F (you can decide that regardless of NA the result must be F)
> >
> > outer(x, x, "|") ## OR  table
> >       <NA> FALSE TRUE
> > <NA>    NA    NA TRUE
> > FALSE   NA FALSE TRUE
> > TRUE  TRUE  TRUE TRUE
> >
> > OTOH the logic for OR table is that if one of the expressions is TRUE
> the result
> > must be TRUE
> > T | T = T
> > F | F = F
> > T&NA = T (you can decide that regardless value in NA the result must be
> T)
> > F&NA = NA (you cannot decide hence NA)
> >
> > And I believe that all your results can be explained by this logic.
> >
> > Cheers
> > Petr
> >
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > > G.Maubach at weinwolf.de
> > > Sent: Thursday, April 28, 2016 9:08 AM
> > > To: r-help at r-project.org
> > > Subject: [R] Interdependencies of variable types, logical expressions
> and
> > NA
> > >
> > > Hi All,
> > >
> > > my script tries to do the following on factors:
> > >
> > > > ## Check for case 3: Umsatz = 0 & Kunde = 1
> > > > for (year in 2011:2015) {
> > > +   Umsatz <- paste0("Umsatz_", year)
> > > +   Kunde <- paste0("Kunde01_", year)
> > > +   Check <- paste0("Check_U_0__Kd_1_", year)
> > > +
> > > +   cat('Creating', Check, 'from', Umsatz, "and", Kunde, '\n')
> > > +
> > > +   Kunden01[[ Check ]] <- ifelse(Kunden01[[ Umsatz ]] == 0 &
> > > +                                 Kunden01[[ Kunde ]] == 1,
> > > +                                 1, 0
> > > +                                 )
> > > +   Kunden01[[ Check ]] <- factor(Kunden01[[ Check ]],
> > > +                                 levels=c(1, 0),
> > > +                                 labels= c("Check 0", "OK")
> > > +                                 )
> > > +
> > > + }
> > > Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011
> > > Creating Check_U_0__Kd_1_2012 from Umsatz_2012 and Kunde01_2012
> > > Creating Check_U_0__Kd_1_2013 from Umsatz_2013 and Kunde01_2013
> > > Creating Check_U_0__Kd_1_2014 from Umsatz_2014 and Kunde01_2014
> > > Creating Check_U_0__Kd_1_2015 from Umsatz_2015 and Kunde01_2015
> > > >
> > > > table(Kunden01$Check_U_0__Kd_1_2011, useNA = "ifany")
> > >
> > > Check 0      OK    <NA>
> > >       1      16      13
> > > > table(Kunden01$Check_U_0__Kd_1_2012, useNA = "ifany")
> > >
> > > Check 0      OK    <NA>
> > >       1      17      12
> > > > table(Kunden01$Check_U_0__Kd_1_2013, useNA = "ifany")
> > >
> > > Check 0      OK    <NA>
> > >       2      17      13
> > > > table(Kunden01$Check_U_0__Kd_1_2014, useNA = "ifany")
> > >
> > > Check 0      OK    <NA>
> > >       1      15      14
> > > > table(Kunden01$Check_U_0__Kd_1_2015, useNA = "ifany")
> > >
> > > Check 0      OK    <NA>
> > >       2      15      13
> > > >
> > > > Kunden01$Check_U_0__Kd_1_all <-
> > > ifelse(Kunden01$Check_U_0__Kd_1_2011 ==
> > > 1 |
> > > +                                        Kunden01$Check_U_0__Kd_1_2012
> ==
> > > 1 |
> > > +                                        Kunden01$Check_U_0__Kd_1_2013
> ==
> > > 1 |
> > > +                                        Kunden01$Check_U_0__Kd_1_2014
> ==
> > > 1 |
> > > +                                        Kunden01$Check_U_0__Kd_1_2015
> ==
> > > 1,
> > > +                                        1, 0)
> > > >
> > > > table(Kunden01$Check_U_0__Kd_1_all, useNA = "ifany")
> > >
> > >     0  <NA>
> > >     7    23
> > >
> > > (Ann.: I made the values up. But the relations equal real world data.)
> > >
> > > I had expected to get back a factor or at least a numeric variable
> > > containing 0, 1 and NA, instead 1 is not included.
> > >
> > > I searched the web for information on the treatment of logical
> expressions
> > > when the data contains NA. I found:
> > >
> > > 1.
> > > https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html
> > > Examples
> > > # Some logical operations do not return NA
> > > c(TRUE, FALSE) & NA
> > > c(TRUE, FALSE) | NA
> > >
> > > 2.
> > > https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
> > > NA is a valid logical object. Where a component of x or y is NA, the
> > > result will be NA if the outcome is ambiguous. In other words NA &
> TRUE
> > > evaluates to NA, but NA & FALSE evaluates to FALSE. See the examples
> > > below.
> > >
> > > ## construct truth tables :
> > > x <- c(NA, FALSE, TRUE)
> > > names(x) <- as.character(x)
> > > outer(x, x, "&") ## AND table
> > > outer(x, x, "|") ## OR  table
> > > Ann. Not very useful. How should it be read?
> > >
> > > 3.
> > > http://www.ats.ucla.edu/stat/r/faq/missing.htm
> > > Good explanation for NA in general and in analysis, but no information
> > > about NA in logical expressions.
> > >
> > > Then I made some tests with different data types and variables with
> NA:
> > >
> > > -- cut --
> > >
> > > # 2016-04-27-001_truth_table_for_logicals_and_NA.R
> > >
> > > # Test 1
> > > var2 <- c(TRUE, FALSE)
> > > var3 <- c(NA, NA)
> > > var1 <- c(1, 1)
> > > ds <- data.frame(var1, var2, var3)
> > > ds
> > >
> > > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> > >
> > > print(ds)
> > > # Output
> > > # var1  var2 var3 value_and_logical logical_and_na value_and_na
> > > # 1    1  TRUE   NA              TRUE           TRUE         TRUE
> > > # 2    1 FALSE   NA              TRUE             NA         TRUE
> > >
> > > # Test 2
> > > ds$var1 <- factor(ds$var1, levels = c(0, 1), labels = c("NOT ok",
> "OK"))
> > > ds$var2 <- factor(ds$var2, levels = c(0, 1), labels = c("NOT ok",
> "OK"))
> > > ds$var3 <- factor(ds$var3, levels = c(0, 1), labels = c("NOT ok",
> "OK"))
> > >
> > > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> > >
> > > # Output (abbrev.)
> > > # Warning message:
> > > #  In Ops.factor(ds$var1, ds$var3) : ?|? ist nicht sinnvoll f?r
> Faktoren
> > >
> > > print(ds)
> > > # Output
> > > # var1 var2 var3 value_and_logical logical_and_na value_and_na
> > > # 1   OK <NA> <NA>                NA             NA           NA
> > > # 2   OK <NA> <NA>                NA             NA           NA
> > >
> > > -- cut --
> > >
> > > I had expected to get the same result in Test 2 as in Test 1.
> > >
> > > Where can I find information and documentation about NA handling in
> > > logical expressions on different variable types?
> > >
> > > Kind regards
> > >
> > > Georg
> > >
> > > ______________________________________________
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From Aljosa.Aleksandrovic at man.com  Thu Apr 28 14:42:44 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Thu, 28 Apr 2016 12:42:44 +0000
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>
Message-ID: <680bb398817a4f7ca6498f6bbf07ff8e@PLONINEXMS136.maninvestments.ad.man.com>

Hi Gabor,

Thanks a lot for your help!

I tried to implement your nonlinear least squares solver on my data set. I was just wondering about the argument start. If I would like to force all my coefficients to be inside an interval, let?s say, between 0 and 1, what kind of starting values are normally recommended for the start argument (e.g. Using a 4 factor model with b1, b2, b3 and b4, I tried start = list(b1 = 0.5, b2 = 0.5, b3 = 0.5, b4 = 0.5))? I also tried other starting values ... Hence, the outputs are very sensitive to that start argument?     

Thanks a lot for your answer in advance!

Kind regards,
Aljosa



Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Dienstag, 26. April 2016 17:59
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

This is a quadratic programming problem that you can solve using either a quadratic programming solver with constraints or a general nonlinear solver with constraints.  See https://cran.r-project.org/web/views/Optimization.html
for more info on what is available.

Here is an example using a nonlinear least squares solver and non-negative bound constraints. The constraint that the coefficients sum to 1 is implied by dividing them by their sum and then dividing the coefficients found by their sum at the end:

# test data
set.seed(123)
n <- 1000
X1 <- rnorm(n)
X2 <- rnorm(n)
X3 <- rnorm(n)
Y <- .2 * X1 + .3 * X2 + .5 * X3 + rnorm(n)

# fit
library(nlmrt)
fm <- nlxb(Y ~ (b1 * X1 + b2 * X2 + b3 * X3)/(b1 + b2 + b3),
     data = list(Y = Y, X1 = X1, X2 = X2, X3 = X3),
     lower = numeric(3),
     start = list(b1 = 1, b2 = 2, b3 = 3))

giving the following non-negative coefficients which sum to 1 that are reasonably close to the true values of 0.2, 0.3 and 0.5:

> fm$coefficients / sum(fm$coefficients)
     b1      b2      b3
0.18463 0.27887 0.53650


On Tue, Apr 26, 2016 at 8:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Hi all,
>
> I hope you are doing well?
>
> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>
> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>
> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>
> I would very much appreciate if you could help me with my issue?
>
> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 7603
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
>
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Dienstag, 26. April 2016 14:35
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Subject: Re: Linear Regressions with constraint coefficients
>
> You need to send it to r-help at r-project.org however.
>
> Kevin
>
> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>> Ok, will do! Thx a lot!
>>
>> Please find below my request:
>>
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:28
>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>
>> Kevin
>>
>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Do you know where I get help for my issue?
>>>
>>> Thanks in advance and kind regards,
>>> Aljosa
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> r-help-owner at r-project.org
>>> Sent: Dienstag, 26. April 2016 14:10
>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>> Subject: Linear Regressions with constraint coefficients
>>>
>>> The message's content type was not explicitly allowed
>>>
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

From ggrothendieck at gmail.com  Thu Apr 28 14:48:28 2016
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Apr 2016 08:48:28 -0400
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <680bb398817a4f7ca6498f6bbf07ff8e@PLONINEXMS136.maninvestments.ad.man.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>
	<680bb398817a4f7ca6498f6bbf07ff8e@PLONINEXMS136.maninvestments.ad.man.com>
Message-ID: <CAP01uR=ezuVBAA53AubZnGDp=gge6q3ak4dcVihJSifk0nyNDw@mail.gmail.com>

The nls2 package can be used to get starting values.

On Thu, Apr 28, 2016 at 8:42 AM, Aleksandrovic, Aljosa (Pfaeffikon)
<Aljosa.Aleksandrovic at man.com> wrote:
> Hi Gabor,
>
> Thanks a lot for your help!
>
> I tried to implement your nonlinear least squares solver on my data set. I was just wondering about the argument start. If I would like to force all my coefficients to be inside an interval, let?s say, between 0 and 1, what kind of starting values are normally recommended for the start argument (e.g. Using a 4 factor model with b1, b2, b3 and b4, I tried start = list(b1 = 0.5, b2 = 0.5, b3 = 0.5, b4 = 0.5))? I also tried other starting values ... Hence, the outputs are very sensitive to that start argument?
>
> Thanks a lot for your answer in advance!
>
> Kind regards,
> Aljosa
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 76 03
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Dienstag, 26. April 2016 17:59
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Cc: r-help at r-project.org
> Subject: Re: [R] Linear Regressions with constraint coefficients
>
> This is a quadratic programming problem that you can solve using either a quadratic programming solver with constraints or a general nonlinear solver with constraints.  See https://cran.r-project.org/web/views/Optimization.html
> for more info on what is available.
>
> Here is an example using a nonlinear least squares solver and non-negative bound constraints. The constraint that the coefficients sum to 1 is implied by dividing them by their sum and then dividing the coefficients found by their sum at the end:
>
> # test data
> set.seed(123)
> n <- 1000
> X1 <- rnorm(n)
> X2 <- rnorm(n)
> X3 <- rnorm(n)
> Y <- .2 * X1 + .3 * X2 + .5 * X3 + rnorm(n)
>
> # fit
> library(nlmrt)
> fm <- nlxb(Y ~ (b1 * X1 + b2 * X2 + b3 * X3)/(b1 + b2 + b3),
>      data = list(Y = Y, X1 = X1, X2 = X2, X3 = X3),
>      lower = numeric(3),
>      start = list(b1 = 1, b2 = 2, b3 = 3))
>
> giving the following non-negative coefficients which sum to 1 that are reasonably close to the true values of 0.2, 0.3 and 0.5:
>
>> fm$coefficients / sum(fm$coefficients)
>      b1      b2      b3
> 0.18463 0.27887 0.53650
>
>
> On Tue, Apr 26, 2016 at 8:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:35
>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> You need to send it to r-help at r-project.org however.
>>
>> Kevin
>>
>> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Ok, will do! Thx a lot!
>>>
>>> Please find below my request:
>>>
>>> Hi all,
>>>
>>> I hope you are doing well?
>>>
>>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>>
>>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>>
>>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>>
>>> I would very much appreciate if you could help me with my issue?
>>>
>>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>>
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>>
>>> -----Original Message-----
>>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>>> Sent: Dienstag, 26. April 2016 14:28
>>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>>> Subject: Re: Linear Regressions with constraint coefficients
>>>
>>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>>
>>> Kevin
>>>
>>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>>> Do you know where I get help for my issue?
>>>>
>>>> Thanks in advance and kind regards,
>>>> Aljosa
>>>>
>>>>
>>>> Aljosa Aleksandrovic, FRM, CAIA
>>>> Quantitative Analyst - Convertibles
>>>> aljosa.aleksandrovic at man.com
>>>> Tel +41 55 417 7603
>>>>
>>>> Man Investments (CH) AG
>>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>> r-help-owner at r-project.org
>>>> Sent: Dienstag, 26. April 2016 14:10
>>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>>> Subject: Linear Regressions with constraint coefficients
>>>>
>>>> The message's content type was not explicitly allowed
>>>>
>>
>>
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC)
>> Li Ka Shing Knowledge Institute of St. Michael's Hospital
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>
>> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
>> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From Aljosa.Aleksandrovic at man.com  Thu Apr 28 15:06:16 2016
From: Aljosa.Aleksandrovic at man.com (Aleksandrovic, Aljosa (Pfaeffikon))
Date: Thu, 28 Apr 2016 13:06:16 +0000
Subject: [R] Linear Regressions with constraint coefficients
In-Reply-To: <CAP01uR=ezuVBAA53AubZnGDp=gge6q3ak4dcVihJSifk0nyNDw@mail.gmail.com>
References: <mailman.1833.1461672613.3828.r-help@r-project.org>
	<77d45635d56242339f16eda23cd67305@PLONINEXMS136.maninvestments.ad.man.com>
	<571F5EB6.2080700@utoronto.ca>
	<8d4d0fd727564154969a2ea55a3ba951@PLONINEXMS136.maninvestments.ad.man.com>
	<571F6068.5040009@utoronto.ca>
	<9ea9faf345cf49c4a30f9af73d3734a4@PLONINEXMS136.maninvestments.ad.man.com>
	<CAP01uR=zT6Cq+4GGvYCNzPvioZUhXYFj_0dEC+uvxrS=kkng4w@mail.gmail.com>
	<680bb398817a4f7ca6498f6bbf07ff8e@PLONINEXMS136.maninvestments.ad.man.com>
	<CAP01uR=ezuVBAA53AubZnGDp=gge6q3ak4dcVihJSifk0nyNDw@mail.gmail.com>
Message-ID: <080a62ee4649488da8da859e39b93d91@PLONINEXMS136.maninvestments.ad.man.com>

Thx a lot Gabor!

Aljosa Aleksandrovic, FRM, CAIA
Quantitative Analyst - Convertibles
aljosa.aleksandrovic at man.com
Tel +41 55 417 76 03

Man Investments (CH) AG
Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland


-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Donnerstag, 28. April 2016 14:48
To: Aleksandrovic, Aljosa (Pfaeffikon)
Cc: r-help at r-project.org
Subject: Re: [R] Linear Regressions with constraint coefficients

The nls2 package can be used to get starting values.

On Thu, Apr 28, 2016 at 8:42 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
> Hi Gabor,
>
> Thanks a lot for your help!
>
> I tried to implement your nonlinear least squares solver on my data set. I was just wondering about the argument start. If I would like to force all my coefficients to be inside an interval, let?s say, between 0 and 1, what kind of starting values are normally recommended for the start argument (e.g. Using a 4 factor model with b1, b2, b3 and b4, I tried start = list(b1 = 0.5, b2 = 0.5, b3 = 0.5, b4 = 0.5))? I also tried other starting values ... Hence, the outputs are very sensitive to that start argument?
>
> Thanks a lot for your answer in advance!
>
> Kind regards,
> Aljosa
>
>
>
> Aljosa Aleksandrovic, FRM, CAIA
> Quantitative Analyst - Convertibles
> aljosa.aleksandrovic at man.com
> Tel +41 55 417 76 03
>
> Man Investments (CH) AG
> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Dienstag, 26. April 2016 17:59
> To: Aleksandrovic, Aljosa (Pfaeffikon)
> Cc: r-help at r-project.org
> Subject: Re: [R] Linear Regressions with constraint coefficients
>
> This is a quadratic programming problem that you can solve using 
> either a quadratic programming solver with constraints or a general 
> nonlinear solver with constraints.  See 
> https://cran.r-project.org/web/views/Optimization.html
> for more info on what is available.
>
> Here is an example using a nonlinear least squares solver and non-negative bound constraints. The constraint that the coefficients sum to 1 is implied by dividing them by their sum and then dividing the coefficients found by their sum at the end:
>
> # test data
> set.seed(123)
> n <- 1000
> X1 <- rnorm(n)
> X2 <- rnorm(n)
> X3 <- rnorm(n)
> Y <- .2 * X1 + .3 * X2 + .5 * X3 + rnorm(n)
>
> # fit
> library(nlmrt)
> fm <- nlxb(Y ~ (b1 * X1 + b2 * X2 + b3 * X3)/(b1 + b2 + b3),
>      data = list(Y = Y, X1 = X1, X2 = X2, X3 = X3),
>      lower = numeric(3),
>      start = list(b1 = 1, b2 = 2, b3 = 3))
>
> giving the following non-negative coefficients which sum to 1 that are reasonably close to the true values of 0.2, 0.3 and 0.5:
>
>> fm$coefficients / sum(fm$coefficients)
>      b1      b2      b3
> 0.18463 0.27887 0.53650
>
>
> On Tue, Apr 26, 2016 at 8:39 AM, Aleksandrovic, Aljosa (Pfaeffikon) <Aljosa.Aleksandrovic at man.com> wrote:
>> Hi all,
>>
>> I hope you are doing well?
>>
>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>
>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>
>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>
>> I would very much appreciate if you could help me with my issue?
>>
>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>
>>
>>
>> Aljosa Aleksandrovic, FRM, CAIA
>> Quantitative Analyst - Convertibles
>> aljosa.aleksandrovic at man.com
>> Tel +41 55 417 7603
>>
>> Man Investments (CH) AG
>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>
>>
>> -----Original Message-----
>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>> Sent: Dienstag, 26. April 2016 14:35
>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>> Subject: Re: Linear Regressions with constraint coefficients
>>
>> You need to send it to r-help at r-project.org however.
>>
>> Kevin
>>
>> On 04/26/2016 08:32 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>> Ok, will do! Thx a lot!
>>>
>>> Please find below my request:
>>>
>>> Hi all,
>>>
>>> I hope you are doing well?
>>>
>>> I?m currently using the lm() function from the package stats to fit linear multifactor regressions.
>>>
>>> Unfortunately, I didn?t yet find a way to fit linear multifactor regressions with constraint coefficients? I would like the slope coefficients to be all inside an interval, let?s say, between 0 and 1. Further, if possible, the slope coefficients should add up to 1.
>>>
>>> Is there an elegant and not too complicated way to do such a constraint regression estimation in R?
>>>
>>> I would very much appreciate if you could help me with my issue?
>>>
>>> Thanks a lot in advance and kind regards, Aljosa Aleksandrovic
>>>
>>>
>>>
>>> Aljosa Aleksandrovic, FRM, CAIA
>>> Quantitative Analyst - Convertibles
>>> aljosa.aleksandrovic at man.com
>>> Tel +41 55 417 7603
>>>
>>> Man Investments (CH) AG
>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>
>>>
>>> -----Original Message-----
>>> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
>>> Sent: Dienstag, 26. April 2016 14:28
>>> To: Aleksandrovic, Aljosa (Pfaeffikon); r-help-owner at r-project.org
>>> Subject: Re: Linear Regressions with constraint coefficients
>>>
>>> I believe I approved a message with such a subject. Perhaps there was another layer that subsequently rejected it after that. I didn't notice any unusual content. Try again, making sure you send the message in plain text only.
>>>
>>> Kevin
>>>
>>> On 04/26/2016 08:16 AM, Aleksandrovic, Aljosa (Pfaeffikon) wrote:
>>>> Do you know where I get help for my issue?
>>>>
>>>> Thanks in advance and kind regards, Aljosa
>>>>
>>>>
>>>> Aljosa Aleksandrovic, FRM, CAIA
>>>> Quantitative Analyst - Convertibles
>>>> aljosa.aleksandrovic at man.com
>>>> Tel +41 55 417 7603
>>>>
>>>> Man Investments (CH) AG
>>>> Huobstrasse 3 | 8808 Pf?ffikon SZ | Switzerland
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>> r-help-owner at r-project.org
>>>> Sent: Dienstag, 26. April 2016 14:10
>>>> To: Aleksandrovic, Aljosa (Pfaeffikon)
>>>> Subject: Linear Regressions with constraint coefficients
>>>>
>>>> The message's content type was not explicitly allowed
>>>>
>>
>>
>> --
>> Kevin E. Thorpe
>> Head of Biostatistics,  Applied Health Research Centre (AHRC)
>> Li Ka Shing Knowledge Institute of St. Michael's Hospital
>> Assistant Professor, Dalla Lana School of Public Health
>> University of Toronto
>> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>>
>> This email has been sent by a member of the Man group (?Man?). Man?s parent company, Man Group plc, is registered in England and Wales (company number 08172396) at Riverbank House, 2 Swan  Lane, London, EC4R 3AD.
>> The contents of this email are for the named addressee(s) only. It contains information which may be confidential and privileged. If you are not the intended recipient, please notify the sender immediately, destroy this email and any attachments and do not otherwise disclose or use them. Email transmission is not a secure method of communication and Man cannot accept responsibility for the completeness or accuracy of this email or any attachments. Whilst Man makes every effort to keep its network free from viruses, it does not accept responsibility for any computer virus which might be transferred by way of this email or any attachments. This email does not constitute a request, offer, recommendation or solicitation of any kind to buy, subscribe, sell or redeem any investment instruments or to perform other such transactions of any kind. Man reserves the right to monitor, record and retain all electronic and telephone communications through its network in accordance with applicable laws and regulations. --UwQe9f5k7pI3vplngP
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

From petr.pikal at precheza.cz  Thu Apr 28 15:29:46 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 28 Apr 2016 13:29:46 +0000
Subject: [R] Antwort: RE:  Interdependencies of variable types,
 logical expressions and NA
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50288D7@SRVEXCHMBX.precheza.cz>
References: <OF94C8E8AC.AD90A353-ONC1257FA2.004E7391-C1257FA3.002727F7@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287BD@SRVEXCHMBX.precheza.cz>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50287F1@SRVEXCHMBX.precheza.cz>
	<OF75F5EC4A.D24EF0F5-ONC1257FA3.003628DC-C1257FA3.0036F178@lotus.hawesko.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C50288D7@SRVEXCHMBX.precheza.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5028909@SRVEXCHMBX.precheza.cz>

Hi

?factor
help page says rather cryptically

The encoding of the vector happens as follows. First all the values in exclude are removed from levels. If x[i] equals levels[j], then the i-th element of the result is j. If no match is found for x[i] in levels (which will happen for excluded values) then the i-th element of the result is set to NA.

So if you specify levels when calling factor, each value not mentioned in levels is changed to NA

Factors are useful but sometimes their behaviour is rather tricky.

> x<-c(1,1)
> x.f<-factor(x, levels=c(0:1))
> c(x.f,2)
[1] 2 2 2
> x.f
[1] 1 1
Levels: 0 1
> as.numeric(x.f)
[1] 2 2
> x<-c(0,1,2)
> x.f<-factor(x, levels=c(0:1))
> x.f
[1] 0    1    <NA>
Levels: 0 1
> c(x.f,2)
[1]  1  2 NA  2
>
Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
> Sent: Thursday, April 28, 2016 2:32 PM
> To: G.Maubach at weinwolf.de
> Cc: r-help at r-project.org
> Subject: Re: [R] Antwort: RE: Interdependencies of variable types, logical
> expressions and NA
>
> Hi
>
> your initial ds
>
> > str(ds)
> 'data.frame':   2 obs. of  3 variables:
>  $ var1: num  1 1
>  $ var2: logi  TRUE FALSE
>  $ var3: logi  NA NA
>
> first result
> > str(ds)
> 'data.frame':   2 obs. of  6 variables:
>  $ var1             : num  1 1
>  $ var2             : logi  TRUE FALSE
>  $ var3             : logi  NA NA
>  $ value_and_logical: logi  TRUE TRUE
>  $ logical_and_na   : logi  TRUE NA
>  $ value_and_na     : logi  TRUE TRUE
>
> 1 is considered as TRUE therefore OR gives TRUE TRUE in first case, TRUE NA
> in second and TRUE TRUE in third
>
> Changing to factor changes var 2 to NA (I am not sure why)
>
> > str(ds)
> 'data.frame':   2 obs. of  3 variables:
>  $ var1: Factor w/ 2 levels "NOT ok","OK": 2 2
>  $ var2: Factor w/ 2 levels "NOT ok","OK": NA NA
>  $ var3: Factor w/ 2 levels "NOT ok","OK": NA NA
>
> And this results to warning
>
> > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> Warning message:
> In Ops.factor(ds$var1, ds$var2) : '|' not meaningful for factors
> > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> Warning message:
> In Ops.factor(ds$var2, ds$var3) : '|' not meaningful for factors
> > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> Warning message:
> In Ops.factor(ds$var1, ds$var3) : '|' not meaningful for factors
> > str(ds)
> 'data.frame':   2 obs. of  6 variables:
>  $ var1             : Factor w/ 2 levels "NOT ok","OK": 2 2
>  $ var2             : Factor w/ 2 levels "NOT ok","OK": NA NA
>  $ var3             : Factor w/ 2 levels "NOT ok","OK": NA NA
>  $ value_and_logical: logi  NA NA
>  $ logical_and_na   : logi  NA NA
>  $ value_and_na     : logi  NA NA
> >
>
> so | operation is not valid for factor variables and results to NA values.
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: G.Maubach at weinwolf.de [mailto:G.Maubach at weinwolf.de]
> > Sent: Thursday, April 28, 2016 12:00 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Subject: Antwort: RE: [R] Interdependencies of variable types, logical
> > expressions and NA
> >
> > Hi Petr,
> >
> > many thanks for your reply.
> >
> > Yes it's interesting. I did not understand what the truth table wanted to
> > say due to 4 columns instead of 3. But know I got it.
> >
> > The other thing is that logical expessions with NA work differently on
> > different types of variables as my example code shows:
> >
> > -- cut --
> > # Truth table for logicals and NA
> >
> > var2 <- c(TRUE, FALSE)
> > var3 <- c(NA, NA)
> > var1 <- c(1, 1)
> > ds <- data.frame(var1, var2, var3)
> > ds
> >
> > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> >
> > print(ds)
> >
> > ds$var1 <- factor(ds$var1, levels = c(0, 1), labels = c("NOT ok", "OK"))
> > ds$var2 <- factor(ds$var2, levels = c(0, 1), labels = c("NOT ok", "OK"))
> > ds$var3 <- factor(ds$var3, levels = c(0, 1), labels = c("NOT ok", "OK"))
> >
> > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> >
> > print(ds)
> > -- cut --
> >
> > Additionally the warning message that this script issues was not displayed
> > in my production code, but only in this test code.
> >
> > Also: Is "<NA>" the same as "NA"?
> >
> > Kind regards
> >
> > Georg
> >
> >
> >
> >
> > Von:    PIKAL Petr <petr.pikal at precheza.cz>
> > An:     "G.Maubach at weinwolf.de" <G.Maubach at weinwolf.de>,
> > "r-help at r-project.org" <r-help at r-project.org>,
> > Datum:  28.04.2016 10:02
> > Betreff:        RE: [R] Interdependencies of variable types, logical
> > expressions and NA
> >
> >
> >
> > Sorry
> > these
> >
> > T&NA = T (you can decide that regardless value in NA the result must be T)
> > F&NA = NA (you cannot decide hence NA)
> >
> > should be
> >
> > T | NA = T (you can decide that regardless value in NA the result must be
> > T)
> > F | NA = NA (you cannot decide hence NA)
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL
> > Petr
> > > Sent: Thursday, April 28, 2016 9:42 AM
> > > To: G.Maubach at weinwolf.de; r-help at r-project.org
> > > Subject: Re: [R] Interdependencies of variable types, logical
> > expressions and
> > > NA
> > >
> > > Hi
> > >
> > > Your script is not reproducible.
> > >
> > > Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and Kunde01_2011
> > > Error in ifelse(Kunden01[[Umsatz]] == 0 & Kunden01[[Kunde]] == 1, 1, 0)
> > :
> > >   object 'Kunden01' not found
> > > >
> > >
> > > This is interesting
> > > x <- c(NA, FALSE, TRUE)
> > > names(x) <- as.character(x)
> > > outer(x, x, "&") ## AND table
> > >        <NA> FALSE  TRUE
> > > <NA>     NA FALSE    NA
> > > FALSE FALSE FALSE FALSE
> > > TRUE     NA FALSE  TRUE
> > > >
> > >
> > > I am not sure, but the logic for AND is to return TRUE only when both
> > > expressions are TRUE.
> > >
> > > so
> > > T&T = T
> > > F&F = F
> > > T&NA = NA (you cannot decide hence NA)
> > > F&NA = F (you can decide that regardless of NA the result must be F)
> > >
> > > outer(x, x, "|") ## OR  table
> > >       <NA> FALSE TRUE
> > > <NA>    NA    NA TRUE
> > > FALSE   NA FALSE TRUE
> > > TRUE  TRUE  TRUE TRUE
> > >
> > > OTOH the logic for OR table is that if one of the expressions is TRUE
> > the result
> > > must be TRUE
> > > T | T = T
> > > F | F = F
> > > T&NA = T (you can decide that regardless value in NA the result must be
> > T)
> > > F&NA = NA (you cannot decide hence NA)
> > >
> > > And I believe that all your results can be explained by this logic.
> > >
> > > Cheers
> > > Petr
> > >
> > >
> > > > -----Original Message-----
> > > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > > > G.Maubach at weinwolf.de
> > > > Sent: Thursday, April 28, 2016 9:08 AM
> > > > To: r-help at r-project.org
> > > > Subject: [R] Interdependencies of variable types, logical expressions
> > and
> > > NA
> > > >
> > > > Hi All,
> > > >
> > > > my script tries to do the following on factors:
> > > >
> > > > > ## Check for case 3: Umsatz = 0 & Kunde = 1
> > > > > for (year in 2011:2015) {
> > > > +   Umsatz <- paste0("Umsatz_", year)
> > > > +   Kunde <- paste0("Kunde01_", year)
> > > > +   Check <- paste0("Check_U_0__Kd_1_", year)
> > > > +
> > > > +   cat('Creating', Check, 'from', Umsatz, "and", Kunde, '\n')
> > > > +
> > > > +   Kunden01[[ Check ]] <- ifelse(Kunden01[[ Umsatz ]] == 0 &
> > > > +                                 Kunden01[[ Kunde ]] == 1,
> > > > +                                 1, 0
> > > > +                                 )
> > > > +   Kunden01[[ Check ]] <- factor(Kunden01[[ Check ]],
> > > > +                                 levels=c(1, 0),
> > > > +                                 labels= c("Check 0", "OK")
> > > > +                                 )
> > > > +
> > > > + }
> > > > Creating Check_U_0__Kd_1_2011 from Umsatz_2011 and
> Kunde01_2011
> > > > Creating Check_U_0__Kd_1_2012 from Umsatz_2012 and
> Kunde01_2012
> > > > Creating Check_U_0__Kd_1_2013 from Umsatz_2013 and
> Kunde01_2013
> > > > Creating Check_U_0__Kd_1_2014 from Umsatz_2014 and
> Kunde01_2014
> > > > Creating Check_U_0__Kd_1_2015 from Umsatz_2015 and
> Kunde01_2015
> > > > >
> > > > > table(Kunden01$Check_U_0__Kd_1_2011, useNA = "ifany")
> > > >
> > > > Check 0      OK    <NA>
> > > >       1      16      13
> > > > > table(Kunden01$Check_U_0__Kd_1_2012, useNA = "ifany")
> > > >
> > > > Check 0      OK    <NA>
> > > >       1      17      12
> > > > > table(Kunden01$Check_U_0__Kd_1_2013, useNA = "ifany")
> > > >
> > > > Check 0      OK    <NA>
> > > >       2      17      13
> > > > > table(Kunden01$Check_U_0__Kd_1_2014, useNA = "ifany")
> > > >
> > > > Check 0      OK    <NA>
> > > >       1      15      14
> > > > > table(Kunden01$Check_U_0__Kd_1_2015, useNA = "ifany")
> > > >
> > > > Check 0      OK    <NA>
> > > >       2      15      13
> > > > >
> > > > > Kunden01$Check_U_0__Kd_1_all <-
> > > > ifelse(Kunden01$Check_U_0__Kd_1_2011 ==
> > > > 1 |
> > > > +                                        Kunden01$Check_U_0__Kd_1_2012
> > ==
> > > > 1 |
> > > > +                                        Kunden01$Check_U_0__Kd_1_2013
> > ==
> > > > 1 |
> > > > +                                        Kunden01$Check_U_0__Kd_1_2014
> > ==
> > > > 1 |
> > > > +                                        Kunden01$Check_U_0__Kd_1_2015
> > ==
> > > > 1,
> > > > +                                        1, 0)
> > > > >
> > > > > table(Kunden01$Check_U_0__Kd_1_all, useNA = "ifany")
> > > >
> > > >     0  <NA>
> > > >     7    23
> > > >
> > > > (Ann.: I made the values up. But the relations equal real world data.)
> > > >
> > > > I had expected to get back a factor or at least a numeric variable
> > > > containing 0, 1 and NA, instead 1 is not included.
> > > >
> > > > I searched the web for information on the treatment of logical
> > expressions
> > > > when the data contains NA. I found:
> > > >
> > > > 1.
> > > > https://stat.ethz.ch/R-manual/R-devel/library/base/html/NA.html
> > > > Examples
> > > > # Some logical operations do not return NA
> > > > c(TRUE, FALSE) & NA
> > > > c(TRUE, FALSE) | NA
> > > >
> > > > 2.
> > > > https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
> > > > NA is a valid logical object. Where a component of x or y is NA, the
> > > > result will be NA if the outcome is ambiguous. In other words NA &
> > TRUE
> > > > evaluates to NA, but NA & FALSE evaluates to FALSE. See the examples
> > > > below.
> > > >
> > > > ## construct truth tables :
> > > > x <- c(NA, FALSE, TRUE)
> > > > names(x) <- as.character(x)
> > > > outer(x, x, "&") ## AND table
> > > > outer(x, x, "|") ## OR  table
> > > > Ann. Not very useful. How should it be read?
> > > >
> > > > 3.
> > > > http://www.ats.ucla.edu/stat/r/faq/missing.htm
> > > > Good explanation for NA in general and in analysis, but no information
> > > > about NA in logical expressions.
> > > >
> > > > Then I made some tests with different data types and variables with
> > NA:
> > > >
> > > > -- cut --
> > > >
> > > > # 2016-04-27-001_truth_table_for_logicals_and_NA.R
> > > >
> > > > # Test 1
> > > > var2 <- c(TRUE, FALSE)
> > > > var3 <- c(NA, NA)
> > > > var1 <- c(1, 1)
> > > > ds <- data.frame(var1, var2, var3)
> > > > ds
> > > >
> > > > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > > > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > > > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> > > >
> > > > print(ds)
> > > > # Output
> > > > # var1  var2 var3 value_and_logical logical_and_na value_and_na
> > > > # 1    1  TRUE   NA              TRUE           TRUE         TRUE
> > > > # 2    1 FALSE   NA              TRUE             NA         TRUE
> > > >
> > > > # Test 2
> > > > ds$var1 <- factor(ds$var1, levels = c(0, 1), labels = c("NOT ok",
> > "OK"))
> > > > ds$var2 <- factor(ds$var2, levels = c(0, 1), labels = c("NOT ok",
> > "OK"))
> > > > ds$var3 <- factor(ds$var3, levels = c(0, 1), labels = c("NOT ok",
> > "OK"))
> > > >
> > > > ds$value_and_logical <- ifelse(ds$var1 | ds$var2, TRUE, FALSE)
> > > > ds$logical_and_na <- ifelse(ds$var2 | ds$var3, TRUE, FALSE)
> > > > ds$value_and_na <- ifelse(ds$var1 | ds$var3, TRUE, FALSE)
> > > >
> > > > # Output (abbrev.)
> > > > # Warning message:
> > > > #  In Ops.factor(ds$var1, ds$var3) : ?|? ist nicht sinnvoll f?r
> > Faktoren
> > > >
> > > > print(ds)
> > > > # Output
> > > > # var1 var2 var3 value_and_logical logical_and_na value_and_na
> > > > # 1   OK <NA> <NA>                NA             NA           NA
> > > > # 2   OK <NA> <NA>                NA             NA           NA
> > > >
> > > > -- cut --
> > > >
> > > > I had expected to get the same result in Test 2 as in Test 1.
> > > >
> > > > Where can I find information and documentation about NA handling in
> > > > logical expressions on different variable types?
> > > >
> > > > Kind regards
> > > >
> > > > Georg
> > > >
> > > > ______________________________________________

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From dcarlson at tamu.edu  Thu Apr 28 15:38:03 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 28 Apr 2016 13:38:03 +0000
Subject: [R] Determine if a set of x and y-latitude points are inside of
 a polygon using R
In-Reply-To: <CANLU3TM=bGZrbgMRehEr8sdCBMKdrh2G_nOMMpOg5gveK19+Xg@mail.gmail.com>
References: <CANLU3TM=bGZrbgMRehEr8sdCBMKdrh2G_nOMMpOg5gveK19+Xg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72F6F7@mb02.ads.tamu.edu>

Give us reproducible data using dput(). There are easier ways to accomplish what you want in R. The overwriting problem stems from the fact that you have a double loop so each iteration of the outer loop overwrites the data produced in the inner loop. 

Also your if/else specification should be producing the following error message:

Error: unexpected 'else' in "else"

Since else needs to be on the same line as the closing curly brace for if:

if (M>1) {
        Bounds$T[i] = M
        } else
        {
        Bounds$T[i] = M
        }

And why use if/else at all since you execute Bounds$T[i] = M either way?

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Shawn Adderly
Sent: Wednesday, April 27, 2016 3:08 AM
To: r-help at r-project.org
Subject: [R] Determine if a set of x and y-latitude points are inside of a polygon using R

Objective: Determine if a set of x and y-latitude points are inside of
a polygon using R.

Lets say I have 9 polygons. Where I have labeled the polygons to be
checked from 1-9. The problem I?m running into is running the
point.in.polygon to check if those points are in one of several
polygons, as my code overwrites the result.

To accomplish this I am using the R-built in function called
point.in.polygon. Point.in.polygon takes the x, and y lat/lon points,
and the polygon boundaries.

Here is the code I've written thus far:

 require("SDMTools")
 require("sp")

 #b is the polygon that I'm referring
 for (b in 1:9)
 {
    D <- subset(Bounds, Polygon == b)
    for (i in 1:length(Bounds$latitude))
    {
    M = point.in.polygon(Bounds$latitude[i], Bounds$longitude[i], D$PY,D$PX)
       if (M>1) {
        Bounds$T[i] = M
        }
        else
        {
        Bounds$T[i] = M
        }
        }
    }


Minimal Dataset:

 Latitude Longitude Polygon Latitude Polygon Longitude Polygon
 38.65485 -121.4965 38.43768 -121.4018 1
 38.562 -121.4768 38.56559 -121.4018 1
 38.7011 -121.3018 38.57065 -121.5141 1
 38.62568 -121.3198 38.56559 -121.5141 1
 38.60253 -121.2899 38.563459 -121.5141 2
 38.28272 -121.2969 38.56359 -121.5141 2
 38.64286 -121.2204 38.54065 -121.515 2
 38.67442 -121.5105 38.57065 -121.515

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From faradj.g at gmail.com  Thu Apr 28 15:38:51 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Thu, 28 Apr 2016 15:38:51 +0200
Subject: [R] Robust clustered errors for probit ordinal regression analysis
Message-ID: <494E7D4B-E05A-48F9-BA69-5E062681022A@gmail.com>

Dear all, 

I?ll need your help with obtaining robust clustered errors. I use polr command in MASS package m<?porl(y~x1+x2,data=mydata, method=probit). In the rms package, this is as simple as: clusterSE<?robcov(m, mydata$id). Is it possible to do something similar for polr object as well? Thank you very much

Best, 
Faradj 
	[[alternative HTML version deleted]]


From 538280 at gmail.com  Thu Apr 28 16:50:10 2016
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 28 Apr 2016 08:50:10 -0600
Subject: [R] polygon angle option perpendicular to axis
In-Reply-To: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
References: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
Message-ID: <CAFEqCdyQNHyJhd3UQcTGxLKAj=tsMMzghcVLxio3_iLFbqEb6g@mail.gmail.com>

Filling polygons with lines is a throwback to the time when the height
of quality graphics was the mechanical pen plotter (a device that used
a pen in a mechanical arm to draw the plot on a piece of paper).
Computing and printing technology has advanced quite a bit from that
day, so you may want to reconsider why you want polygons filled with
lines instead of just a solid color (and I consider white, grey, and
black as colors for this purpose).

On Wed, Apr 27, 2016 at 2:17 PM, Simon, Heather <Simon.Heather at epa.gov> wrote:
> I am trying to use the angle option in polygon to create polygons filled with horizontal and vertical lines.  The polygons I am crating are irregular and it the angle function appears to set the angle of the shading perpendicular to the polygon sides rather than perpendicular to the axes.  Is there any way to set the angle relative to the axes rather than relative to the polygon sides?
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From m.p.kosinski at gmail.com  Thu Apr 28 08:59:00 2016
From: m.p.kosinski at gmail.com (=?UTF-8?Q?Marcin_Kosi=C5=84ski?=)
Date: Thu, 28 Apr 2016 08:59:00 +0200
Subject: [R] [R-pkgs] New R package on CRAN: RZabbix - easy and direct
 communication with 'Zabbix API'
Message-ID: <CAL8y_QwxacN8vbTCHchCoQXHp4wfw75+FKrmC-f4xDd-Ud-3wg@mail.gmail.com>

Hi all,

2 days ago a new R packages appeared on CRAN
https://cran.r-project.org/web/packages/RZabbix/index.html

RZabbix is an R interface to the 'Zabbix API' data <
https://www.zabbix.com/documentation/3.0/manual/api/reference>. Enables
easy and direct communication with 'Zabbix API' from 'R'.

You can now integrate your Zabbix applications monitoring with reports
created in R. Feel free to check examples in ZabbixAPI function and please
post your comments, ideas on future improvements or user requests here :
https://github.com/MarcinKosinski/RZabbix/issues
I also encourage you to provide a sweet pull request with your ideas.

Best,
RZabbix author,
Marcin Kosi?ski

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From francesco.grossetti at polimi.it  Wed Apr 27 09:58:43 2016
From: francesco.grossetti at polimi.it (Francesco Grossetti)
Date: Wed, 27 Apr 2016 09:58:43 +0200
Subject: [R] [R-pkgs] New package: msmtools (v1.0)
Message-ID: <A0A6E86D-15B7-49C0-9383-13744859EA95@polimi.it>

Greetings, R users!

It is with pleasure that I am announcing the release of msmtools package on CRAN:

https://cran.r-project.org/web/packages/msmtools/index.html

msmtools provides a fast and general method for restructuring classical longitudinal data into augmented ones. The reason for this is to facilitate the modeling of longitudinal data under a multi-state framework using the 'msm? package by Chris Jackson.
The tools is fitted for longitudinal datasets in which events are localized in time (i.e. a starting and an ending time are present). The method is efficient and fast and thus is suitable when dealing with highly dimensional datasets.

The package also includes two graphical goodness-of-fit tools which can roughly assess the behaviour of the Markov model.
I hope you?ll find the package useful for your work! 

For any issues you may encounter, please leave a related comment to my repository at: 

https://github.com/contefranz/msmtools/issues

or contact me at francesco.grossetti at polimi.it

Thanks! 
Francesco

-- 
Francesco Grossetti
Ph.D. Student
MOX - Modeling and Scientific Computing
Dipartimento di Matematica ?F. Brioschi"
Politecnico di Milano
Via Bonardi 9
I-20133 Milano - Italy
ph.: +39 02 2399 4564
email: francesco.grossetti at polimi.it

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From gokeii at 163.com  Thu Apr 28 06:37:37 2016
From: gokeii at 163.com (WU Qingwei)
Date: Thu, 28 Apr 2016 12:37:37 +0800 (CST)
Subject: [R] how to donate software to R community
Message-ID: <4e9e1885.6acc.1545b286eed.Coremail.gokeii@163.com>

hi all,


We have developed a software called HCBA (Highly Consumable Business Analytics) using R as modelling engine.
We now want to donate the whole software (R serves only as modelling engine in this project. There are other core functions.) to the R community and open-source it. But we don't know what the approach is in order to contribute HCBA.
We have looked through the official R website. And there seems to be no information about this subject. By R package way, we can only contribute the R part of HCBA.
So, our question is: what should we do to contribute HCBA to R community?
Any suggestions and opinions would be much appreciated. Thank you.




Best Regards,
WU Qingwei
School of Software Engineering, Tongji University
	[[alternative HTML version deleted]]


From attenka at utu.fi  Thu Apr 28 07:10:28 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Thu, 28 Apr 2016 08:10:28 +0300
Subject: [R] Same sum, different sets of integers
In-Reply-To: <CA+hbrhX14cT_G0g2Bn45qP5w+8Ris9SKSYh6KPBtuiCM8zkjSQ@mail.gmail.com>
References: <5720DEE4.50909@utu.fi>
	<CAAxdm-6rX_XeSuH0Mi=5EwD_TO+OeHgV5U=QzKPe-hNeyvOrFw@mail.gmail.com>
	<CA+hbrhX14cT_G0g2Bn45qP5w+8Ris9SKSYh6KPBtuiCM8zkjSQ@mail.gmail.com>
Message-ID: <57219B44.9010809@utu.fi>

Thanks for the suggestions, all of you!
I first began to think about using somehow permutations of the 
gtools-package. I will continue utilizing Peter's solution.

My purpose is to divide basic musical rhythm units (whole note, half 
note, quarter note etc durations) to meaningful entities in algorithmic 
composition. I use R for that. Usually, there are - in the composition 
algorithm - random number generators, which "composes" different 
versions of music. Those RNG's (sample in R) can be - for their part - 
conducted by using different constraints and probabilities. Here I draw 
rhythms.

For example, if my quarter note (1/4) is 1024 ticks in MIDI format, I 
may like to split it into quintuples, ie. five units, using ties 
differently:

1024*c(1/5, 4/5), 1024*c(2/5, 3/5),... This way I can produce and output 
rich and still usable rhythms to music notation software, keep the 
rhythmic entities playable and readable over barlines.

Yours,

Atte

28.4.2016, 5.00, Peter Langfelder kirjoitti:
> I came up with this, using recursion. Short and should work for n
> greater than 9 :)
>
> Peter
>
> sumsToN = function(n)
> {
>    if (n==1) return(1);
>    out = lapply(1:(n-1), function(i) {
>      s1 = sumsToN(n-i);
>      lapply(s1, c, i)
>    })
>    c(n, unlist(out, recursive = FALSE));
> }
>
>> sumsToN(4)
> [[1]]
> [1] 4
>
> [[2]]
> [1] 3 1
>
> [[3]]
> [1] 2 1 1
>
> [[4]]
> [1] 1 1 1 1
>
> [[5]]
> [1] 1 2 1
>
> [[6]]
> [1] 2 2
>
> [[7]]
> [1] 1 1 2
>
> [[8]]
> [1] 1 3
>
>> sumsToN(5)
> [[1]]
> [1] 5
>
> [[2]]
> [1] 4 1
>
> [[3]]
> [1] 3 1 1
>
> [[4]]
> [1] 2 1 1 1
>
> [[5]]
> [1] 1 1 1 1 1
>
> [[6]]
> [1] 1 2 1 1
>
> [[7]]
> [1] 2 2 1
>
> [[8]]
> [1] 1 1 2 1
>
> [[9]]
> [1] 1 3 1
>
> [[10]]
> [1] 3 2
>
> [[11]]
> [1] 2 1 2
>
> [[12]]
> [1] 1 1 1 2
>
> [[13]]
> [1] 1 2 2
>
> [[14]]
> [1] 2 3
>
> [[15]]
> [1] 1 1 3
>
> [[16]]
> [1] 1 4
>
>
> On Wed, Apr 27, 2016 at 6:10 PM, jim holtman <jholtman at gmail.com> wrote:
>> This is not the most efficient, but gets the idea across.  This is the
>> largest sum I can compute on my laptop with 16GB of memory.  If I try to
>> set N to 9, I run out of memory due to the size of the expand.grid.
>>
>>> N <- 8  # value to add up to
>>> # create expand.grid for all combinations and convert to matrix
>>> x <- as.matrix(expand.grid(rep(list(0:(N - 1)), N)))
>>>
>>> # generate rowSums and determine which rows add to N
>>> z <- rowSums(x)
>>>
>>> # now extract those rows, sort and convert to strings to remove dups
>>> add2N <- x[z == N, ]
>>> strings <- apply(
>> +             t(apply(add2N, 1, sort))  # sort
>> +             , 1
>> +             , toString
>> +             )
>>> # remove dups
>>> strings <- strings[!duplicated(strings)]
>>>
>>> # remove leading zeros
>>> strings <- gsub("0, ", "", strings)
>>>
>>> # print out
>>> cat(strings, sep = '\n')
>> 1, 7
>> 2, 6
>> 3, 5
>> 4, 4
>> 1, 1, 6
>> 1, 2, 5
>> 1, 3, 4
>> 2, 2, 4
>> 2, 3, 3
>> 1, 1, 1, 5
>> 1, 1, 2, 4
>> 1, 1, 3, 3
>> 1, 2, 2, 3
>> 2, 2, 2, 2
>> 1, 1, 1, 1, 4
>> 1, 1, 1, 2, 3
>> 1, 1, 2, 2, 2
>> 1, 1, 1, 1, 1, 3
>> 1, 1, 1, 1, 2, 2
>> 1, 1, 1, 1, 1, 1, 2
>> 1, 1, 1, 1, 1, 1, 1, 1
>>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Wed, Apr 27, 2016 at 11:46 AM, Atte Tenkanen <attenka at utu.fi> wrote:
>>
>>> Hi,
>>>
>>> Do you have ideas, how to find all those different combinations of
>>> integers (>0) that produce as a sum, a certain integer.
>>>
>>> i.e.: if that sum is
>>>
>>> 3, the possibilities are c(1,1,1), c(1,2), c(2,1)
>>> 4, the possibilities are
>>> c(1,1,1,1),c(1,1,2),c(1,2,1),c(2,1,1),c(2,2),c(1,3),c(3,1)
>>>
>>> etc.
>>>
>>> Best regards,
>>>
>>> Atte Tenkanen
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From simon.wood at bath.edu  Thu Apr 28 08:56:00 2016
From: simon.wood at bath.edu (Simon Wood)
Date: Thu, 28 Apr 2016 07:56:00 +0100
Subject: [R] Random effects in package mgcv
In-Reply-To: <CAEd09GQ0ZQejp4CjkWk6ZTueEi9CLMBKaEi9qj6Ar8tzURBe3g@mail.gmail.com>
References: <CAEd09GQ0ZQejp4CjkWk6ZTueEi9CLMBKaEi9qj6Ar8tzURBe3g@mail.gmail.com>
Message-ID: <5721B400.10008@bath.edu>

If you want to include random intercepts in a model fit by bam/gam, then 
include
   s(g,bs="re")
in the model formula, where g is a factor variable with one level for 
each group requiring a random intercept.
Now suppose that for each level of group g you want a random slope 
w.r.t. x. You should include a term
   s(g,x,bs="re")
in the gam formula (the order of g and x is not important). For random 
slopes and random intercepts include
   s(g,bs="re") + s(g,x,bs="re")

gam/bam only supports quite simple i.i.d random effects, so correlated 
intercepts and slopes can not be estimated this way. Also the methods 
are not efficient for thousands of random effects (actually 
bam(,discrete=TRUE) in recent versions will manage thousands, but not 
10s of thousands).

best,
Simon

On 27/04/16 15:12, Dean Force wrote:
> Hello R users,
>
>
> I have a quick question I was hoping to get your input on. I am new to R
> and the smooth statistical regression world, and am trying to wrap my mind
> around the issues concerning using splines for mixed effect modeling.
>
> My question is the following: in the ?gamm? function, generalized additive
> mixed models can be estimated by including random components. These can be
> explicitly defined in the syntax, where you can also define whether the
> random component is an intercept, slope, or both. My understanding is that
> in the gam/bam function the same is achieved by including the bs="re?
> option for random intercepts and linear random slopes. Am I correct? If so,
> is there a way to specify whether it is the intercept or slope we are
> interested in, and does that have any effect on the output of the model?
>
> I hope these questions make sense, and I look forward to learning more
> about this.  Thanks for taking the time to read through this email.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From bruce.swihart at gmail.com  Wed Apr 27 14:35:25 2016
From: bruce.swihart at gmail.com (Bruce Swihart)
Date: Wed, 27 Apr 2016 08:35:25 -0400
Subject: [R] [R-pkgs] New package: bridgedist (v 0.1.0)
Message-ID: <CAAHpScqMeqrGi4kLKemMNyKOZ7DO-EqQe=qiB7foESXA7gh4vA@mail.gmail.com>

R Users,

The d/p/q/r functions for the bridge distribution are now available in
bridgedist.

When a random intercept follows the bridge distribution, as detailed in
Wang and Louis (2003) <doi:10.1093/biomet/90.4.765
<http://dx.doi.org/10.1093/biomet/90.4.765>>, a marginalized
random-intercept logistic regression will still be a logistic regression
with marginal coefficients that are scalar multiples of the conditional
regression's coefficients.

Another way to state the result is that the sum of a standard logistic
random variable and a bridge random variable will follow a logistic
distribution with scale > 1.

Examples of use:

dbridge(0)#> [1] 0.1591549
pbridge(0)#> [1] 0.5
qbridge(0.5)#> [1] 0
mean(rbridge(1e5)) ## approximately 0#> [1] -0.003490218
var(rbridge(1e5, scale = 1/sqrt(1+3/pi^2)))  # approximately 1#> [1] 0.9983954


Vignette:

https://cran.r-project.org/web/packages/bridgedist/vignettes/the_bridgedist_basics.html


References:

Wang, Z. and Louis, T.A. (2003) Matching conditional and marginal shapes in
binary random intercept models using a bridge distribution function.
Biometrika, 90(4), 765-775. <DOI:10.1093/biomet/90.4.765>

See also:

Swihart, B.J., Caffo, B.S., and Crainiceanu, C.M. (2013). A Unifying
Framework for Marginalized Random-Intercept Models of Correlated Binary
Outcomes. International Statistical Review, 82 (2), 275-295 1-22. <DOI:
10.1111/insr.12035>

Griswold, M.E., Swihart, B.J., Caffo, B.S and Zeger, S.L. (2013). Practical
marginalized multilevel models. Stat, 2(1), 129-142. <DOI: 10.1002/sta4.22>

Heagerty, P.J. (1999). Marginally specified logistic-normal models for
longitudinal binary data. Biometrics, 55(3), 688-698. <DOI:
10.1111/j.0006-341X.1999.00688.x>

Heagerty, P.J. and Zeger, S.L. (2000). Marginalized multilevel models and
likelihood inference (with comments and a rejoinder by the authors). Stat.
Sci., 15(1), 1-26. <DOI: 10.1214/ss/1009212671>

All the best,
Bruce

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From Simon.Heather at epa.gov  Thu Apr 28 14:45:07 2016
From: Simon.Heather at epa.gov (Simon, Heather)
Date: Thu, 28 Apr 2016 12:45:07 +0000
Subject: [R] polygon angle option perpendicular to axis
In-Reply-To: <E41B375B7520DE4A8C60781AC60B75452C3A5D8F7E@AKLEXM01.PFR.CO.NZ>
References: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
	<E41B375B7520DE4A8C60781AC60B75452C3A5D8F7E@AKLEXM01.PFR.CO.NZ>
Message-ID: <SN1PR09MB0895FA77E1239E68B3AD8C22E1650@SN1PR09MB0895.namprd09.prod.outlook.com>


Thanks for the question.  Here is a sample of the code for my plot:

	Top = c(34, 39, 42, 45, 46, 41, 41, 40, 43, 38, 33, 33)
	 Bottom = c(24, 29, 32, 36, 32, 34, 32,41, 40, 39, 29, 24)

	plot(1,1, col = "white", xlim = c(1.3,11.7), ylim = c(0,80), axis = FALSE, xaxt = "n") 
	axis(1, at = c(1:12))

	polygon(c(c(1:12),c(12:1)), c(top, bottom), col = adjustcolor("#33a02c",alpha.f = 0.7) ,border = "#33a02c", lty = 4, density = 80, angle = 180)


I would like the hatched lines to all go in the same direction (parallel to the x-axis) so that I can layer another polygon on top with perpendicular hatches and you will be able to differentiate between the two.

-----Original Message-----
From: Peter Alspach [mailto:Peter.Alspach at plantandfood.co.nz] 
Sent: Thursday, April 28, 2016 12:11 AM
To: Simon, Heather <Simon.Heather at epa.gov>; r-help at r-project.org
Subject: RE: polygon angle option perpendicular to axis

Tena koe Simon

plot(1:10, 1:10, type='n')
polygon(c(2,3,6,8), c(2,5,5,3), density=20, angle=90) polygon(c(2,3,6,8), 5+c(2,5,5,3), density=20, angle=0)

I don't understand your problem.  Perhaps if you "provide[d] commented, minimal, self-contained, reproducible code" it would help.

HTH ....

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Simon, Heather
Sent: Thursday, 28 April 2016 8:17 a.m.
To: r-help at r-project.org
Subject: [R] polygon angle option perpendicular to axis

I am trying to use the angle option in polygon to create polygons filled with horizontal and vertical lines.  The polygons I am crating are irregular and it the angle function appears to set the angle of the shading perpendicular to the polygon sides rather than perpendicular to the axes.  Is there any way to set the angle relative to the axes rather than relative to the polygon sides?



	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:9}}


From G.Maubach at weinwolf.de  Thu Apr 28 09:17:50 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 28 Apr 2016 09:17:50 +0200
Subject: [R] Antwort: Re:  R Script Template
In-Reply-To: <B8BC68C5-15B2-4314-87B0-9EA85E7CC765@dcn.davis.ca.us>
References: <OF3944F455.D33DC9BF-ONC1257FA1.004D1C96-C1257FA2.0034EEE3@lotus.hawesko.de>
	<trinity-09f4c915-dc8f-4d8e-8a18-9473ce86e4df-1461759257809@3capp-gmx-bs62>
	<B8BC68C5-15B2-4314-87B0-9EA85E7CC765@dcn.davis.ca.us>
Message-ID: <OF48B38629.278E4454-ONC1257FA3.0027E28B-C1257FA3.00281658@lotus.hawesko.de>

Hi All,

please find enclosed the missing attachment.

Kind regards

Georg

-- cut --

#-[ Header ] 
------------------------------------------------------------------
# Program       : Framework for R scripts
# Author        : Georg Maubach
# Date          : 2016-03-03
# Update        : 2016-04-27
# Description   : Foundation for the analysis process
# Source System : R 3.2.5 (64 Bit)
# Target System : R 3.2.5 (64 Bit)
# Release       : 1
# License       : CC-BY-NC-SA
# File Name     : 2016-04-27_Template_Scipt.R
#-------------------------------------------------------------------------------

#- [ Purpose of the document ] 
------------------------------------------------
# This document provides a framework for a script able to handle real 
world 
# data throughout the complete analysis process. In each step examples or 
# prototypes of needed or helpful commands are given. Chapters and 
sections in 
# this document can be regarded as a toolbox. The needed tools shall be 
adapted 
# to the processed data. Commands are ordered an a consistent way to 
support the
# user to produce high quality output.
#-------------------------------------------------------------------------------

# - [ At hand ] 
----------------------------------------------------------------
# help("function")    # Extract or Replace Parts of an Object
# example("function") # Examples on "Extract"
# demo(package = .packages(all.available = TRUE)) # Show demos of packages
#-------------------------------------------------------------------------------

# - [ Editing Marks ] 
----------------------------------------------------------
# %ROTA% : Result of the analysis in text form if needed to explain 
further
#          steps
# %ToDo% : ToDo's
#-------------------------------------------------------------------------------

# - [ Warrenty Disclaimer ] 
----------------------------------------------------
# The software is provided "as-is". The author disclaims to the fullest 
extent
# authorized by law any and all warranties, whether express or implied,
# including, without limitation, any implied warranties of merchantability 
or
# fitness for a particular purpose. Without limitation of the foregoing, 
the
# author expressly does not warrant that:
#
# (a) the software will meet your requirements or expectations;
# (b) the software or the software content will be free of bugs, errors,
#     viruses or other defects;
# (c) any results, output, or data provided through or generated by the 
software
#     will be accurate, up-to-date, complete or reliable;
# (d) the software will be compatible with third party software;
# (e) any errors in the software will be corrected.
#-------------------------------------------------------------------------------

# - [ Limitation of Liability ] 
------------------------------------------------
# In no event will the author be liable for any direct, indirect, 
consequential,
# incidental, special, exemplary, or punitive damages or liabilities 
whatsoever
# arising from or relating to the software, the software content or this
# agreement, whether based on contract, tort (including negligence), 
strict
# liability or other theory, even if the author has been advised of the
# possibility of such damages.
#
# The use of the software goes to the whole risk of the user.
#-------------------------------------------------------------------------------

#--------1---------2---------3---------4---------5---------6---------7---------8

#-------#
# Setup #
#-------#
# Environment
# Please make sure that RTools is installed
Sys.getenv("R_ZIPCMD", "zip")
# needed for openxlsx::write.xlsx()
Sys.setenv(R_ZIPCMD= "C:/R-Project/Rtools/bin/zip")

.libPaths()  # Install directory for libraries
# .libPaths("new path if needed")

# Workplace
sessionInfo()        # Environment
list.files(R.home()) # Show R home directory
getwd()              # Get working directory
list.dirs()          # List directories in working directory
list.files()         # List files in working directory
library()            # List all installed packages
search()             # List all loaded packages
ls()                 # List objects in environment

#-----------#
# Configure #
#-----------#
path <- file.path("path", "to","directory")
setwd(path)          # Set working directory
options(width = 65)  # Set output width

#---------#
# Install #
#---------#
available.packages()

# Desired packages
my_packages <- c(
  "ctv"            # Package to install packages based on themes
  "data.table",    # Fast manipulation of large datasets
  "dplyr",         # Data manipulation for data frames
  "geoR", 
  "haven",         # import data from stastical packages
  "Hmisc", 
  "httr",          # package to deal with HTTP requests
  "installr",      # Dependency of openxlsx::write.xlsx()
  "lubridate", 
  "mapdata",       # data for high-quality maps
  "maps",          # draw maps
  "maptools",      # import ESRI data
  "memisc",        # package data import and management for SPSS
  "openxlsx",      # Read and write Excel files
  "reshape2",      # Restructure data
  "stringr", 
  "tidyr",         # Data cleaning
  "plotrix", 
  "plyr",          # Data manipulation
# "rattle",        # Be careful! rattel needs a different RGTK2 lib!
  "RColorBrewer",  # Install ColorBrewer color palettes
  "Rcpp",
  "rgdal",         # Connect to GDAL, Mercator transformation
  "RMySQL",        # Replace by package for your database
  "sp",            # Draw maps, depends on grid and lattice
  "sqldf",         # Execute SQL queries on R datasets
  "zoo"            # Time series analysis
)

# Install
## EITHER: Install from CRAN
## install.packages(pkgs = my_packages, dependencies = TRUE)

## OR: Build local CRAN repository
### EITHER: Install miniCRAN from CRAN
### install.packages(pkgs = "miniCRAN", dependencies = TRUE)
### OR: Install miniCRAN from localhost
install.packages(pkgs = 
"C:/Software/R-Project/CRAN/bin/windows/contrib/3.2/xml2_0.1.2.zip",
                 dependencies = TRUE,
                 repos = NULL)
install.packages(pkgs = 
"C:/Software/R-Project/CRAN/bin/windows/contrib/3.2/miniCRAN_0.2.5.zip",
                 dependencies = TRUE,
                 repos = NULL)

library(miniCRAN)

### Determine the dependencies for desired packages
pkg_list <- pkgDep(pkg = my_packages, suggest = TRUE)

### Define a path to local repository
repo <- file.path("H:","2016","Software","R-Project", "CRAN")

# Create repository
# Internet connection required
# If no internet connection available download at machine with internet
# connection and transfer the downloaded repository manually to the target
# machine.
makeRepos(pkgs = pkg_list, path = repo, type = "win.binary")

repo_path = paste0("file:", repo)

install.packages(pkgs = pkg_list,
                 dependencies = TRUE,
                 repos = repo_path)

# Install packages bases on themes
# see (*6) p. 26
install.packages("ctv")
library(ctv)
install.views("SocialSciences")

# update.packages(ask = FALSE)     # Update (if necessary)

# vignette(all = TRUE)             # Show vignettes of all installed 
packages

#--------#
# Import #
#--------#
# rm(list = ls()) # Clear workplace (if necessary)
                  # Comment out if handed out to someone else
                  # for not deleting somebody else's workplace

# Load data
path <- file.path("path", "to", "filename")
load(path)
 
# Import data
# see (*10)
path <- file.path("path", "to", "filename")

## From Spreadsheets, e. g. Microsoft Excel
library(readxl)

### Read only one Excel sheet
path <- file.path("path", "to", "filename")

sheet1 <- read_excel(path, sheet = 1)
sheet2 <- read_excel(path, sheet = 2)

sheets <- excel_sheets(path)
first_sheet <- read_excel(path, sheet = "first_sheet")
first_sheet <- read_excel(path, sheet = "second_sheet")

sheets <- excel_sheets(path)
first_sheet <- read_excel(path, 
                          sheet = sheets[1],
                          col_names = TRUE | FALSE | c("name1", "name2", 
...),
                          skip = n)

columns <- c("Column_Name_1", paste0("Column_Name_", 2:n))
first_sheet <- read_excel(path,
                          sheet = sheets[2],
                          col_names = columns,
                          col_types = c(NULL | "numeric" | "text" | "date" 
| "blank"))

### Read all Excel sheets within a workbook
### using lapply creating a list of data.frames
path <- file.path("path", "to", "filename")
my_workbook <- lapply(excel_sheets(path), 
                      read_excel, 
                      path = path)
detach("package:readxl")

library(XLConnect)

### Create a workbook object
path <- file.path("path", "to", "filename")

book <- loadWorkbook(filename = path)
sheets <- getSheets(book)
data <- readWorksheet(book,
                      sheet = 1 | "sheet name",
                      header = TRUE | FALSE,
                      startCol = n,
                      startRow = n,
                      endRow = n)

df <- data.frame("a data.frame")
createSheet(book, "sheet name")
writeWorksheet(book, df, "sheet_name")
saveWorkbook(book, file = path)

detach("package:XLConnect")

## From other statistical packages
### With haven
### From SAS

#### From SPSS
library(haven)

path <- file.path("path", "to", "filename")

dataset <- read_sav(path = path)

#### Convert the labelled class from SPSS to factor in R
dataset$variable <- haven::as_factor(dataset$variable)

detach("package:haven")

#### From STATA

### With foreign
library(foreign)

#### From SAS

#### From SPSS
dataset <- read.spss(file = path,
                     to.data.frame = TRUE,
                     # convert labelled variables to factors
                     use.value.labels = TRUE) 

#### From STATA
dataset <- foreign::read.dta(file = path,
                             convert.factors = FALSE
                             convert.underscore = FALSE)

detach("package:foreign")

## From Databases
library("DBI") # library(RMySQL) not required

con <- dbConnect(drv = RMySQL::MySQL(),
                 dbname = "database name",
                 host = "hostname",
                 port = port number,
                 user = "username",
                 password = "password")

tableList <- dbListTables(conn = con)

### Read entire database table
table <- dbReadTable(con, 
                     name = "table name")

### Read a selection respectively a subset of data from a database table
selection <- dbGetQuery(con,
                        statement = "SELECT col_name
                                     FROM table_name
                                     WHERE col_name > some_condition")
### Example 1
products <- dbReadTable(conn = con,
                        name = "Products")

products_selection <- subset(products,
                             subset = contract == 1)

### Example 2
### Produces the same result as Example 1
### but is more efficient because the subsetting is done in the database
### and only the needed entries are read into R.
products_selection <- dbGetQuery(conn = con,
                                 statement = "SELECT *
                                              FROM products_selection
                                              WHERE contract = 1")

### Example 3
### Read a database table one chunk at a time
res <- dbSendQuery(conn = con,
                   statement = "SELECT *
                                FROM products
                                WHERE contract = 1")

#### The data is stored in temporary file
while(!dbHasCompleted(res)) {
  chunk <- dbFetch(res, n = 1) # n can have any suitable value
  print(chunk)                 # work with chunk of data in any suitable 
way
}

dbClearResult(res) # deletes the file temporarily created by dbSendQuery

### Always disconnect from the database
dbDisconnect(conn = con)

detach("packages:DBI")

## From the web
## Check if the import function can access web sites
## right away using e. g. the file argument

## Downloading a file to you local machine
url <- "http://machine.server.com/path/to/filename"
destination <- file.path("path", "to", "filename")
download.file(url = url,
              destfile = destination)

### Import the locaclly stored file with the known import functions

## With httr
library(httr)

url <- "http://machine.server.com/path/to/filename"
response <- GET(url)
content <- content(x = response, as = data.frame)
detach("package:httr")

## With jsonlite
library("jsonlite")

fromJSON("string")

### JSON object: unordered collection of name:value pairs
### name = string
### value = string | number | boolean | null | JSON object | JSON array

### JSAN array: ordered sequence of objects

detach("packages:jsonlite")

# Build datasets from data
## Rename variables
names(dataset) <- new_colnames
names(dataset)[names(kino == "variable name")] <- "new variable name"

## Sort variables
dataset2 <- dataset[sort(names(dataset))]

## Sort cases
## see (*1) p. 333ff
## Sorting can only be done for numeric variables.
### Save the original order
#### Row numbers are stored as characters.
#### Thus type conversion is necessary.
dataset$orig_order <- as.numeric(row.names(dataset))
### Missing values are placed at the end by default
#### na.last = FALSE places missing values at the beginning
#### na.last = NA removes missing values from sorted data
#### Order is ascending by default.
#### Reverse order is only available for numeric variables
#### and done using a minus sign ("-") before each variable.
dataset2 <- order(-as.numeric(dataset$gender), # descending gender
                  dataset$age)                 # ascending age

# Save data
path <- file.path("path", "to", "filename")
save.image(path)

# Match datasets
## Merge only two datasets at a time
## see (*1) p. 288
dataset3 <- merge(dataset1, dataset2,
                  # use by if the variable names match
                  by.x = id_variable_first_dataset, 
                  by.y = id_variable_second_dataset,
                  # use all = TRUE if both datasets deliver cases
                  all.x = TRUE, all.y = TRUE)

## Merge two or more datasets at a time
## %ToDo%

# Check
xlsx_check <- "Projectname_Checks.xlsx"
wb <- createWorkbook()
addWorksheet(wb,
             sheetName = "Import")
writeData(wb,
          sheet = "Import",
          x = dataset)
saveWorkbook(wb, 
             file = xlsxCheck,
             overwrite = TRUE)

# Create Recovery Point
path <- file.path("Path", "to", "file", "Projectname_Import.RData")
save(dataset, file = path)

#----------#
# Cleaning #
#----------#
# Recover data from previous section
path <- file.path("Path", "to", "file", "Projectname_Import.RData")
load(file = path)

## 1. Inspect raw data
### Get to know the structure of datasets
### see (*6) p. 59
class()
dim()
names()
str()
dplyr::glimpse()
summary()
memisc::codebook(dataset)

### Get to know the data within datasets
### see (*6) p. 59
### see (*8)
head(dataset, n = 10)
tail(dataset, n = 10)
#print()
summary()
Hmisc::describe(dataset)
hist()
plot()

## see (*9)
## 2. Tidy the data according to the principals of tidy data
library(tidyr)
### a) Ensure observations/values are in rows
tidyr::gather()

### b) Ensure variables are in columns
tidyr::spread()

### c) each observation type is stored in its own dataset
tidyr::separate()

### d) Each table is one type of observational unit

detach("package:tidyr")

## 3. Type conversions
### Numericals
library(dplr)
dataset2 <- dplyr::mutate_each(dataset1, funs(as.numeric); var1:varX)
detach("package:dplr")

### Strings
library(stringr)
stringr::str_replace()
stringr::unite()
detach("package:stringr")

### Dates
library(lubridate)
lubridate::ymd(dataset$dateString)
detach("package:lubridate")

## 4. Missing value analysis and handling
### Missing value analysis
### see (*3)
any(is.na())          # Showing if observations contain NA
sum(is.na(variable))  # Show number of observations system missing values
sum(variable == -999, na.rm = TRUE)  # Count the occurrence of -999 (omit 
NA)
sum(variable %in% c(-998,-999))      # Count multiple user missing values

summary()                # Check summary result for NA
plot(variable)           # Spot missings graphically
table(factor(variable))  # Spot missings in contingency table

sum(!complete.cases(dataset))        # Count complete cases
which(!complete.cases(dataset))      # Show incomplete cases

cases_with_na <- which(is.na(dataset$variable)) # find indices of cases 
with NA
dataset[cases_with_na, ] # Look at the full rows for records having 
missings

#### Missing value handling
##### Replace missing value in new variable
dataset1$new_variable <- dataset1$variable_with_na
dataset$new_variable[cases_with_na] <- new_value

##### Replace missing value in new dataset
dataset2 <- dataset1
dataset2$variable_with_na[cases_with_na] <- new_value

##### Recode missing values
##### see (*3)
variable[variable == -999] = NA           # Recode all -999 as NA
variable[is.na(x)] = -999                 # Recode all NA in x as -999
variable[variable %in% c(-998,-999)] = NA # Recode any -998 or -999 as NA
variable[variable %in% -990:-999] = 0     # Recode any value between -990 
and
# -999 as 0

#### Keep only cases without any missings
dataset2 <- dataset1[complete.cases(dataset1), ]
dataset2 <- na.omit(dataset1)

# Attention:
# Watch for symbols for missing values from
# a) external sources:
#    #N/A (Excel)
#    .    (SPSS/SAS)
#    empty string
# b) internal sources
#    Inf (infinite value, e. g. 1/0)
#    NaN (not a number, e. g. 0/0)

## 5. Identify and correct errors
### Outliers
summary(dataset)
hist(dataset)
boxplot(dataset)

cases_with_data_error <- which(dataset$variable == error_value)
dataset[cases_with_data_error, ]
dataset$variable[cases_with_data_error] <- correct_value

## 6. Visualize the results of data cleaning
summary(dataset)
head(dataset, n = 20)
hist(dataset)
plot(dataset$variable1, dataset$variable2)
boxplot(dataset$variable)

# Check
xlsx_check <- "Projectname_Checks.xlsx"
wb <- createWorkbook()
addWorksheet(wb,
             sheetName = "Cleaning")
writeData(wb,
          sheet = "Cleaning",
          x = dataset)
saveWorkbook(wb, 
             file = xlsxCheck,
             overwrite = FALSE)

# Create Recovery Point
path <- file.path("Path", "to", "file", "Projectname_Cleaning.RData")
save(dataset, file = path)

#---------#
# Prepare #
#---------#
# Recover data from previous section
path <- file.path("Path", "to", "file", "Projectname_Cleaning.RData")
load(file = path)

# Delete variables
reduced_dataset <- dataset$variable <- NULL # delete a variable
reduced_dataset <- dataset[, -c(index_of_variables)] # delete variables

# Create new variables
dataset2 <- data.frame(dataset1, new_variable)
dataset2 <- cbind(dataset, new_variable)

# Recode 1: Manually
## see (*2) p. 87ff
dataset$recoded <- (dataset$variable <=17) * 1 +
                   (dataset$variable >18 & dataset$variable <= 30) * 2 + 
                   (dataset$variable >30 & dataset$variable <= 65) * 3 +
                   (dataset$variable <65) * 4
## see (*1) p. 378ff
dataset$recoded <- factor(dataset$recoded,
                          levels = c(1, 2, 3, 4),
                          labels = c("Pupils", "Young Professionals",
                                     "Professionals", "Retired"))
# Handling of character vectors
# see (*4)
# x = variable
tolower(x)                   # converts x to all lower case 
toupper(x)                   # converts x to all upper case 
nchar(x)                     # a vector of the lengths of each value
paste(a,b,sep="_")           # concatenates character values
substr(x,start,stop)         # extract characters from positions start to 
stop
strsplit(x,split)            # split each value of x into a list of 
strings 
                             # using split as the delimiter 
grep(pattern,x)              # return a vector of the elements that 
included
                             # pattern 
grepl(pattern,x)             # returns a logical vector indicating whether 

                             # each element of x contained pattern 
regexpr(pattern,x)           # returns the integer positions of the first
                             # occurrence of pattern in each element of x 
gregexpr(pattern,x)          # returns a list of the integer positions of 
all
                             # of the occurrences of pattern in each value 
of x 
gsub(pattern,replacement,x)  # replaces each occurrence of pattern with 
occurrence 

# see (*5)
match()                      # compares two vectors, can be also numeric
pmatch()                     # compares parts of two vectors, can be also 
numeric

# Creating variables on the fly
# see (*7)
str(Kunden01)

for (year in 2011:2015) {
  Reeller_Kunde <- paste0("Reeller_Kunde_", year)
  Umsatz <- paste0("Umsatz_", year)
  cat('Creating', Reeller_Kunde,'from', Umsatz,'\n')
  Kunden01[[ Reeller_Kunde ]] <- ifelse( Kunden01[[ Umsatz ]] <= 0, 1, 2)
  Kunden01[[ Reeller_Kunde ]] <- factor( Kunden01[[ Reeller_Kunde ]],
                                         levels=c(1,2),
                                         labels= c("NICHT kaufend", 
"kaufend")
  )
}

str(Kunden01)

# Sort dataset
dataset2 <- dataset[order(dataset$var_1_to_be_sorted_by, 
dataset$var_2_to_be_sorted_by), ]

# Save data
## As R data file
path <- file.path("path", "to", "filename")
save.image(path)

## As Excel file
library(XLConnect)

### Create a workbook object
path <- file.path("path", "to", "filename")

book <- loadWorkbook(filename = path)

df <- data.frame("a data.frame")
createSheet(book, "sheet name")
writeWorksheet(book, df, "sheet_name")
saveWorkbook(book, file = path)

detach("packages:XLConnect")

# Check
xlsx_check <- "Projectname_Checks.xlsx"
wb <- createWorkbook()
addWorksheet(wb,
             sheetName = "Preparation")
writeData(wb,
          sheet = "Cleaning",
          x = dataset)
saveWorkbook(wb, 
             file = xlsxCheck,
             overwrite = FALSE)

# Create Recovery Point
path <- file.path("Path", "to", "file", "Projectname_Preparation.RData")
save(dataset, file = path)

#---------#
# Analyse #
#---------#
# Recover data from previous section
path <- file.path("Path", "to", "file", "Projectname_Preparation.RData")
load(file = path)

library(dplyr)

# Combination of group_by() and mutate() creates new variables
# within each group.
# see (*8)
# If mutate() uses the rank() function within-group rankings
# are calculated.
# Example:
# Filter ArrDelay, group by carrier, create a mean by carrier,
# rank this new mean and then sort the carriers based on the
# ranking.
# Combination of arrange() and rank() ranks the values within-groups
# from the largest to the smallest.
dataset %>%
  filter(!is.nat(var1) & var1 > 0) %>%
  group_by(var2) %>%
  summarise(avg = mean(var1)) %>%
  mutate(rank = rank(avg)) %>%
  arrange(rank)

detach("package:dplr")

# References
# (*1)  Muenchen: R for SAS and SPSS Users, 2. Ed., New York, 2011
# (*2)  Hain: Statistik mit R, 1. Ed., Hannover, 2011
# (*3)  Allerhand: R Programming, Essential Functions, Missing Values
#       (http://forums.psy.ed.ac.uk/R/P01582/essential-10/)
# (*4)  Philippi: Data Manipulation in R
#       (
http://science.nature.nps.gov/im/datamgmt/statistics/r/fundamentals/manipulation.cfm
)
# (*5)  Spector: Introduction to R
#       (https://www.stat.berkeley.edu/~spector/Rcourse.pdf)
# (*6)  Manderscheid: Sozialwissenschaftliche Datenanalyse mit R, 1. 
Aufl.,
#       Wiesbaden, 2012
# (*7)  MacQueen: Creating Variables on the Fly
#       (
http://r.789695.n4.nabble.com/Creating-variables-on-the-fly-td4720034.html
)
# (*8)  Grolemund: Data Manipulation in R with dplyr in: Datacamp.com
#       (
https://www.datacamp.com/courses/dplyr-data-manipulation-r-tutorial)
# (*9)  Carchedi: Cleaning Data in R, in: Datacamp.com
#       (https://www.datacamp.com/courses/cleaning-data-in-r)
# (*10) Schouwenaars: Importing Data into R, in: Datacamp.com
#       (https://www.datacamp.com/courses/importing-data-into-r) 

# EOF



Von:    Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
An:     G.Maubach at gmx.de, r-help at r-project.org, 
Datum:  27.04.2016 22:23
Betreff:        Re: [R] R Script Template
Gesendet von:   "R-help" <r-help-bounces at r-project.org>



The subject of your email is missing. Perhaps you need to read the Posting 
Guide (again?) about attachments. Embedding your example directly in the 
body of the email is generally more accessible in archives than attaching 
it. 
-- 
Sent from my phone. Please excuse my brevity.

On April 27, 2016 1:14:17 PM GMT+01:00, G.Maubach at gmx.de wrote:
>Hi All,
> 
>I am addressing this post to all who are new to R.
>
>When learing R in the last weeks I took some notes for myself to have
>code snippets ready for the data analysis process. I put these snippets
>
>together as a script template for future use. Almost all of the given
>command prototypes are tested. The template script contains snippets
>for best practices and leaves out the commands that should not be used.
>Relying on the given snippets shall lead to high quality code.
>
>The code is based on examples from the ressources given in the
>template. I highly recommend to read the books or take the online
>courses to see how everything works and fits together.
>
>Despite putting everything together with care, the script is provided
>as-is with no warrenty or liability whatsoever.
>
>Please address any remarks or suggestions for improvement to the R-Help
>mailing list.
>
>Kind regards
>
>Georg
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

                 [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From fabiana.gordon at imperial.ac.uk  Thu Apr 28 13:51:43 2016
From: fabiana.gordon at imperial.ac.uk (Gordon, Fabiana)
Date: Thu, 28 Apr 2016 11:51:43 +0000
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <CAGxFJbTELNKOfz2-ximsCtxiy-pEA88u8WHDYXOU8=p8Z5vqJA@mail.gmail.com>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
	<094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
	<CAGxFJbTELNKOfz2-ximsCtxiy-pEA88u8WHDYXOU8=p8Z5vqJA@mail.gmail.com>
Message-ID: <VI1PR06MB11658535EEBB722EB4DF63B3B2650@VI1PR06MB1165.eurprd06.prod.outlook.com>


Maybe I wasn't  clear  about my query. 

I'm very familiar with pre-allocation and vectorization and I had already wrote an R code for this problem in this way. My question wasn't about the most efficient way to solve the problem. It was about whether in R it was possible to use the same  index used in the loop to create a new variable and store the results in as in the example showed below. The use of ?c? was because I was using Matlab, otherwise I know that a new variable shouldn?t have the same name as the name of a function.

Regards,
Fabiana


-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: 27 April 2016 21:18
To: Jeff Newmiller
Cc: Gordon, Fabiana; r-help at R-project.org
Subject: Re: [R] Create a new variable and concatenation inside a "for" loop

...

"(R is case sensitive, so "C" has no such problem)."

Well, not quite. Try ?C

To add to the previous comments, Dr. Gordon appears to need to do her/his homework and spend some time with an R tutorial or two before posting further here. There are many good ones on the web. Some recommendations can be found here:
https://www.rstudio.com/online-learning/#R

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 27, 2016 at 12:57 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> "c" an extremely commonly-used function. Functions are first-class objects that occupy the same namespaces that variables do, so they can obscure each other. In short, don't use variables called "c" (R is case sensitive, so "C" has no such problem).
>
> Wherever possible, avoid incremental concatenation like the plague. If you feel you must use it, at least concatenate in lists and then use functions like unlist, do.call, or pre-allocate vectors or matrix-like objects with unuseful values like NA and then overwrite each element in the vector or matrix-type object in a loop like your first one.
> --
> Sent from my phone. Please excuse my brevity.
>
> On April 27, 2016 3:25:14 PM GMT+01:00, "Gordon, Fabiana" <fabiana.gordon at imperial.ac.uk> wrote:
>>Hello,
>>
>>Suppose the you need a loop to create a new variable , i.e., you are 
>>not reading data from outside the loop. This is a simple example in 
>>Matlab code,
>>
>>for i=1:5
>>r1=randn
>>r2=randn
>>r=[r1 r2]
>>c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates
>>all columns. In R this would be [i,]
>>end
>>
>>The output of interest is c which I'm creating inside the "for" loop 
>>-also the index used in the loop is used to create c. In R I had to 
>>create c as an  empty vector (numeric() ) outside the loop, otherwise 
>>I get an error message saying that c doesn't exit.
>>
>>The other issue is the concatenation. In each iteration I'm creating 
>>the rows of c by placing the new row  (r) below the previous one so 
>>that c becomes a 5 x 2 matrix.
>>In R, it seems that I have no choice but use the function "rbind". I 
>>managed to write this code in R . However, I'm not sure that if 
>>instead of creating a new variable  using  the index in the "for" loop 
>>, I wanted to use the index to read data, e.g.  suppose I have a 2 X 
>>10 matrix X and suppose I want to calculate the sin () for each 2 x 2 
>>sub-matrix of and stored in a matrix A. Then the code would be 
>>something like this,
>>
>>for i=1:5
>>A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all
>>rows
>>end
>>
>>Many Thanks,
>>
>>Fabiana
>>
>>
>>Dr Fabiana Gordon
>>
>>Senior Statistical Consultant
>>Statistical Advisory Service, School Of Public Health, Imperial 
>>College London 1st Floor, Stadium House, 68 Wood Lane, London W12 7RH.
>>
>>Tel: 020 7594 1749
>>Email:
>>fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
>>Web:
>>www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-adv
>>ice-service/<http://www.imperial.ac.uk/research-and-innovation/support
>>-for-staff/stats-advice-service/>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From marc_schwartz at me.com  Thu Apr 28 17:42:30 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 28 Apr 2016 10:42:30 -0500
Subject: [R] how to donate software to R community
In-Reply-To: <4e9e1885.6acc.1545b286eed.Coremail.gokeii@163.com>
References: <4e9e1885.6acc.1545b286eed.Coremail.gokeii@163.com>
Message-ID: <9F599CEE-4524-4B1D-BDCD-8FFD46083B17@me.com>


> On Apr 27, 2016, at 11:37 PM, WU Qingwei <gokeii at 163.com> wrote:
> 
> hi all,
> 
> 
> We have developed a software called HCBA (Highly Consumable Business Analytics) using R as modelling engine.
> We now want to donate the whole software (R serves only as modelling engine in this project. There are other core functions.) to the R community and open-source it. But we don't know what the approach is in order to contribute HCBA.
> We have looked through the official R website. And there seems to be no information about this subject. By R package way, we can only contribute the R part of HCBA.
> So, our question is: what should we do to contribute HCBA to R community?
> Any suggestions and opinions would be much appreciated. Thank you.
> 
> 
> 
> 
> Best Regards,
> WU Qingwei
> School of Software Engineering, Tongji University


Hi,

Thanks for your query and your willingness to contribute.

There are a variety of ways to make your open source software available to the community at large, with arguably the primary way for third parties to do that via CRAN:

  https://cran.r-project.org

There are various policies in place to meet the CRAN requirements:

  https://cran.r-project.org/web/packages/policies.html

and presumably, you are already aware of the Writing R Extensions manual, which also has related information:

  https://cran.r-project.org/doc/manuals/r-release/R-exts.html

Lastly, there is also a dedicated e-mail list, R-Package-Devel, which you may find helpful in the course of meeting CRAN requirements, should you elect to pursue that path:

  https://stat.ethz.ch/mailman/listinfo/r-package-devel

Note that given the various dependencies you allude to above, relative to R versus other parts of your offering, there may be subtle and not so subtle issues that you face with a submission to CRAN. The R-Package-Devel list would be a good forum to engage in more detailed discussions on that point specifically.

Alternative ways to offer the package, if you elect to not pursue the CRAN path formally, would be via your own servers, R-Forge, github or similar vehicles. 

Regards,

Marc Schwartz


From wdunlap at tibco.com  Thu Apr 28 18:06:50 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 28 Apr 2016 09:06:50 -0700
Subject: [R] polygon angle option perpendicular to axis
In-Reply-To: <SN1PR09MB0895FA77E1239E68B3AD8C22E1650@SN1PR09MB0895.namprd09.prod.outlook.com>
References: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
	<E41B375B7520DE4A8C60781AC60B75452C3A5D8F7E@AKLEXM01.PFR.CO.NZ>
	<SN1PR09MB0895FA77E1239E68B3AD8C22E1650@SN1PR09MB0895.namprd09.prod.outlook.com>
Message-ID: <CAF8bMcaGcVJba+J4edw4p3kga8yGm+dOUJeroCMYWBEXc10_Mw@mail.gmail.com>

I think you are seeing the Moire (interference) pattern arising from
the interaction of lty=4 (dotted/dashed lines) and closely spaced
parallel lines.  Use lty=1 (solid lines) to see this.

[BTW, your script did not work because you changed the capitalization
of top and bottom halfway through it.]

As for hatching being old-fashioned, when I read stats stuff on my
black and white Kindle I wish that people used color less and hatching
more.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Apr 28, 2016 at 5:45 AM, Simon, Heather <Simon.Heather at epa.gov>
wrote:

>
> Thanks for the question.  Here is a sample of the code for my plot:
>
>         Top = c(34, 39, 42, 45, 46, 41, 41, 40, 43, 38, 33, 33)
>          Bottom = c(24, 29, 32, 36, 32, 34, 32,41, 40, 39, 29, 24)
>
>         plot(1,1, col = "white", xlim = c(1.3,11.7), ylim = c(0,80), axis
> = FALSE, xaxt = "n")
>         axis(1, at = c(1:12))
>
>         polygon(c(c(1:12),c(12:1)), c(top, bottom), col =
> adjustcolor("#33a02c",alpha.f = 0.7) ,border = "#33a02c", lty = 4, density
> = 80, angle = 180)
>
>
> I would like the hatched lines to all go in the same direction (parallel
> to the x-axis) so that I can layer another polygon on top with
> perpendicular hatches and you will be able to differentiate between the two.
>
> -----Original Message-----
> From: Peter Alspach [mailto:Peter.Alspach at plantandfood.co.nz]
> Sent: Thursday, April 28, 2016 12:11 AM
> To: Simon, Heather <Simon.Heather at epa.gov>; r-help at r-project.org
> Subject: RE: polygon angle option perpendicular to axis
>
> Tena koe Simon
>
> plot(1:10, 1:10, type='n')
> polygon(c(2,3,6,8), c(2,5,5,3), density=20, angle=90) polygon(c(2,3,6,8),
> 5+c(2,5,5,3), density=20, angle=0)
>
> I don't understand your problem.  Perhaps if you "provide[d] commented,
> minimal, self-contained, reproducible code" it would help.
>
> HTH ....
>
> Peter Alspach
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Simon,
> Heather
> Sent: Thursday, 28 April 2016 8:17 a.m.
> To: r-help at r-project.org
> Subject: [R] polygon angle option perpendicular to axis
>
> I am trying to use the angle option in polygon to create polygons filled
> with horizontal and vertical lines.  The polygons I am crating are
> irregular and it the angle function appears to set the angle of the shading
> perpendicular to the polygon sides rather than perpendicular to the axes.
> Is there any way to set the angle relative to the axes rather than relative
> to the polygon sides?
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> The contents of this e-mail are confidential and may be ...{{dropped:9}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Apr 28 18:17:14 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 28 Apr 2016 16:17:14 +0000
Subject: [R] polygon angle option perpendicular to axis
In-Reply-To: <CAFEqCdyQNHyJhd3UQcTGxLKAj=tsMMzghcVLxio3_iLFbqEb6g@mail.gmail.com>
References: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
	<CAFEqCdyQNHyJhd3UQcTGxLKAj=tsMMzghcVLxio3_iLFbqEb6g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72F793@mb02.ads.tamu.edu>

The angle is not based on the polygon edges, but it can seem that way if you do not use the asp=1 argument in your plot. Try this example,

> plot(1:10, 1:10, type='n')
> x <- c(1, 3, 5, 3)
> y <- c(3, 5, 3, 1)
> polygon(x, y, angle=0, density=10)
> polygon(x, y + 4.5, angle=45, density=10)
> polygon(x + 4.5, y + 4.5, angle=90, density=10)
> polygon(x + 4.5, y, angle=135, density=10)

Notice that the 45 and 135 degree lines (upper left and lower right) do not seem to be parallel to the edges of the boxes which should be 45 and 135. Run the code again adding asp=1 to the plot() function and now the lines are parallel.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Greg Snow
Sent: Thursday, April 28, 2016 9:50 AM
To: Simon, Heather
Cc: r-help at r-project.org
Subject: Re: [R] polygon angle option perpendicular to axis

Filling polygons with lines is a throwback to the time when the height
of quality graphics was the mechanical pen plotter (a device that used
a pen in a mechanical arm to draw the plot on a piece of paper).
Computing and printing technology has advanced quite a bit from that
day, so you may want to reconsider why you want polygons filled with
lines instead of just a solid color (and I consider white, grey, and
black as colors for this purpose).

On Wed, Apr 27, 2016 at 2:17 PM, Simon, Heather <Simon.Heather at epa.gov> wrote:
> I am trying to use the angle option in polygon to create polygons filled with horizontal and vertical lines.  The polygons I am crating are irregular and it the angle function appears to set the angle of the shading perpendicular to the polygon sides rather than perpendicular to the axes.  Is there any way to set the angle relative to the axes rather than relative to the polygon sides?
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Simon.Heather at epa.gov  Thu Apr 28 18:32:43 2016
From: Simon.Heather at epa.gov (Simon, Heather)
Date: Thu, 28 Apr 2016 16:32:43 +0000
Subject: [R] polygon angle option perpendicular to axis
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D72F793@mb02.ads.tamu.edu>
References: <SN1PR09MB08957F515D710624E21DEBF6E1640@SN1PR09MB0895.namprd09.prod.outlook.com>
	<CAFEqCdyQNHyJhd3UQcTGxLKAj=tsMMzghcVLxio3_iLFbqEb6g@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D72F793@mb02.ads.tamu.edu>
Message-ID: <SN1PR09MB0895B2C81CF2F94D6048D704E1650@SN1PR09MB0895.namprd09.prod.outlook.com>

Thanks, adding asp = 1 did the trick!

-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu] 
Sent: Thursday, April 28, 2016 12:17 PM
To: Greg Snow <538280 at gmail.com>; Simon, Heather <Simon.Heather at epa.gov>
Cc: r-help at r-project.org
Subject: RE: [R] polygon angle option perpendicular to axis

The angle is not based on the polygon edges, but it can seem that way if you do not use the asp=1 argument in your plot. Try this example,

> plot(1:10, 1:10, type='n')
> x <- c(1, 3, 5, 3)
> y <- c(3, 5, 3, 1)
> polygon(x, y, angle=0, density=10)
> polygon(x, y + 4.5, angle=45, density=10) polygon(x + 4.5, y + 4.5, 
> angle=90, density=10) polygon(x + 4.5, y, angle=135, density=10)

Notice that the 45 and 135 degree lines (upper left and lower right) do not seem to be parallel to the edges of the boxes which should be 45 and 135. Run the code again adding asp=1 to the plot() function and now the lines are parallel.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Greg Snow
Sent: Thursday, April 28, 2016 9:50 AM
To: Simon, Heather
Cc: r-help at r-project.org
Subject: Re: [R] polygon angle option perpendicular to axis

Filling polygons with lines is a throwback to the time when the height of quality graphics was the mechanical pen plotter (a device that used a pen in a mechanical arm to draw the plot on a piece of paper).
Computing and printing technology has advanced quite a bit from that day, so you may want to reconsider why you want polygons filled with lines instead of just a solid color (and I consider white, grey, and black as colors for this purpose).

On Wed, Apr 27, 2016 at 2:17 PM, Simon, Heather <Simon.Heather at epa.gov> wrote:
> I am trying to use the angle option in polygon to create polygons filled with horizontal and vertical lines.  The polygons I am crating are irregular and it the angle function appears to set the angle of the shading perpendicular to the polygon sides rather than perpendicular to the axes.  Is there any way to set the angle relative to the axes rather than relative to the polygon sides?
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marine.regis at hotmail.fr  Thu Apr 28 19:57:16 2016
From: marine.regis at hotmail.fr (Marine Regis)
Date: Thu, 28 Apr 2016 17:57:16 +0000
Subject: [R] Snowfall - Error in checkForRemoteErrors(val) with
	sfClusterApplyLB()
Message-ID: <AMSPR07MB470FE436001F2E7C6A559CCE2650@AMSPR07MB470.eurprd07.prod.outlook.com>

Hello,



I'm trying to run a code that uses the snowfall package. Here is the structure of my code.



sfInit(parallel=T, cpus = 5, slaveOutfile="ErrorMessage.txt")

sfExportAll()

sfLibrary(rgdal)

sfLibrary(raster)

sfLibrary(sp)

sfLibrary(rgeos)

sfLibrary(snowfall)



system.time( sfClusterApplyLB(1:10, function(k) {

  sfCat(paste("Iteration ", k), sep="\n")

if (......) {

} else {

if (class(ob1)=="SpatialCollections") {

        ob2 <- ob1 at lineobj

      } else if (class(ob1)=="SpatialLines") {

        ob2 <- ob1

      }

ob3 <- data.frame(length_m=sapply(1:length(ob2), function(l) gLength(ob2 [l, ])))

.....

}

.....

}

sfStop()



The problem is that the code returns the error message:

Error in checkForRemoteErrors(val) :

  one node produced an error: object 'ob2' not found



>From the debugging function "sfCat", I also get these warning messages:



Warning messages:

1: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: --file

2: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: MASTER

3: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: PORT

4: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: OUT

5: In searchCommandline(parallel, cpus = cpus, type = type, socketHosts = socketHosts,  :

  Unknown option on commandline: SNOWLIB

 socketHosts,  :

  Unknown option on commandline: SNOWLIB

tion on commandline: SNOWLIB


The code works when I use a simple loop for(k in 1:10) {} instead of sfClusterApplyLB(1:10, function(k) {}.



Why do I obtain this error message ? I am completely novice in using snowfall package. So any advices are appreciated.



Thanks a lot for your time.


Marine


	[[alternative HTML version deleted]]


From highstat at highstat.com  Thu Apr 28 20:10:32 2016
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 28 Apr 2016 19:10:32 +0100
Subject: [R] New book: Beginner's Guide to Zero-Inflated Models with R
Message-ID: <57225218.7080804@highstat.com>

We are pleased to announce the following book:

Title: Beginner's Guide to Zero-Inflated Models with R
Authors: Zuur, Ieno


Book website: http://www.highstat.com/BGZIM.htm
Paperback or EBook can be order (exclusively) from:
http://www.highstat.com/bookorder.htm
TOC: http://www.highstat.com/BGS/ZIM/pdfs/TOCOnly.pdf

Keywords: 430 pages. Zero inflated count data. Zero inflated continuous 
data. Zero inflated proportional data. Frequentist and Bayesian 
approaches. Random effects. Introduction to Bayesian statistics and 
MCMC. JAGS. Bayesian model selection. Multivariate GLMM.
R code and data sets available.


-----------------------------------------------------
Outline
The minimum prerequisite for Beginner's Guide to Zero-Inflated Models 
with R is knowledge of multiple linear regression, and in Chapter 2 we 
start with brief explanations of the Poisson, negative binomial, 
Bernoulli, binomial and gamma distributions. The motivation for doing 
this is that zero-inflated models consist of two distributions ?glued? 
together, one of which is the Bernoulli distribution. We begin Chapter 3 
with a brief revision of the Poisson generalised linear model (GLM) and 
the Bernoulli GLM, followed by a gentle introduction to zero-inflated 
Poisson (ZIP) models. Chapters 4 and 5 contain detailed case studies 
using count data of orange-crowned warblers and sharks. Just like all 
other chapters, these case studies are based on real datasets used in 
scientific papers.

In Chapter 6 we use zero-altered Poisson (ZAP) models to deal with the 
excessive number of zeros in count data. In Chapter 7 we analyse 
continuous data with a large number of zeros. Biomass of Chinese tallow 
trees is analysed with zero-altered gamma (ZAG) models.

In Chapter 8, which begins the second part of the book, we explain how 
to deal with dependency. Mixed models are introduced, using beaver and 
monkey datasets. In Chapter 9 we encounter a rather complicated dataset 
in terms of dependency. Reproductive indices are sampled from plants. 
But the seeds come from the same source and are planted in the same bed 
in the same garden. We apply models that take care of the excessive 
number of zeros in count data, crossed random effects and nested random 
effects.

Up to this point we have done everything in a frequentist setting, but 
at this stage of the book you will see that we are reaching the limit of 
what we can achieve with the frequentist software. For this reason we 
switch to Bayesian techniques in the third part of the book. Chapter 10 
contains an excellent beginner?s guide to Bayesian statistics and Markov 
Chain Monte Carlo (MCMC) techniques. The chapter also contains exercises 
and a video solution file for one of the exercises. This means that you 
can see our screen and listen to our voices (just in case you have 
trouble falling asleep at night). A large number of students reviewed 
this chapter and we incorporated their suggestions for improvement, so 
Chapter 10 should be very easy to understand.

In Chapter 11 we show how to implement the Poisson, negative binomial 
and ZIP models in MCMC. We do the same for mixed models in Chapter 12. 
In Chapter 13 we discuss a method, called the ?zero trick?, that allows 
you to fit nearly every distribution in JAGS.

A major stumbling block in Bayesian analysis is model selection. Chapter 
14 provides an easy-to-understand overview of various Bayesian model 
selection tools. Chapter 15 contains an example of Bayesian model 
selection using butterfly data.

In Chapter 16 we discuss methods for the analysis of proportional data 
(seagrass coverage time series) with a large number of zeros. We use a 
zero-altered beta model with nested random effects. Finally, in Chapters 
17 and 18 we discuss various topics, including multivariate GLMMs and 
generalised Poisson models (these can be used for underdispersion). We 
also discuss zero-inflated binomial models.
-----------------------------------------------------



-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From macqueen1 at llnl.gov  Thu Apr 28 20:54:14 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 28 Apr 2016 18:54:14 +0000
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <VI1PR06MB11658535EEBB722EB4DF63B3B2650@VI1PR06MB1165.eurprd06.prod.outlook.com>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
	<094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
	<CAGxFJbTELNKOfz2-ximsCtxiy-pEA88u8WHDYXOU8=p8Z5vqJA@mail.gmail.com>
	<VI1PR06MB11658535EEBB722EB4DF63B3B2650@VI1PR06MB1165.eurprd06.prod.outlook.com>
Message-ID: <D347A2A3.170B22%macqueen1@llnl.gov>

What's not possible, as far as I know, is to create a variable using an
expression that refers to elements within the variable.

For example, suppose that a some point during my R session, there is no
variable named tmpx:

> exists('tmpx')
[1] FALSE

If I try to reference tmpx, in this case by using an extraction operator

> tmpx[3] <- 2
Error in tmpx[3] <- 2 : object 'tmpx' not found

it fails. That is, you can't assign to the third element of tmpx when tmpx
doesn't exist, and trying to do so does not automatically create tmpx. As
best as I can tell, this is what you are asking about.

Note that this behavior of the R language has nothing to do with looping
or using a loop index to create a variable, but rather the idea that one
can't reference a non-existant variable.

In this case, I think that the R way of doing things is just different
than the matlab way.


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 4/28/16, 4:51 AM, "R-help on behalf of Gordon, Fabiana"
<r-help-bounces at r-project.org on behalf of fabiana.gordon at imperial.ac.uk>
wrote:

>
>Maybe I wasn't  clear  about my query.
>
>I'm very familiar with pre-allocation and vectorization and I had already
>wrote an R code for this problem in this way. My question wasn't about
>the most efficient way to solve the problem. It was about whether in R it
>was possible to use the same  index used in the loop to create a new
>variable and store the results in as in the example showed below. The use
>of ?c? was because I was using Matlab, otherwise I know that a new
>variable shouldn?t have the same name as the name of a function.
>
>Regards,
>Fabiana
>
>
>-----Original Message-----
>From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>Sent: 27 April 2016 21:18
>To: Jeff Newmiller
>Cc: Gordon, Fabiana; r-help at R-project.org
>Subject: Re: [R] Create a new variable and concatenation inside a "for"
>loop
>
>...
>
>"(R is case sensitive, so "C" has no such problem)."
>
>Well, not quite. Try ?C
>
>To add to the previous comments, Dr. Gordon appears to need to do her/his
>homework and spend some time with an R tutorial or two before posting
>further here. There are many good ones on the web. Some recommendations
>can be found here:
>https://www.rstudio.com/online-learning/#R
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Wed, Apr 27, 2016 at 12:57 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> "c" an extremely commonly-used function. Functions are first-class
>>objects that occupy the same namespaces that variables do, so they can
>>obscure each other. In short, don't use variables called "c" (R is case
>>sensitive, so "C" has no such problem).
>>
>> Wherever possible, avoid incremental concatenation like the plague. If
>>you feel you must use it, at least concatenate in lists and then use
>>functions like unlist, do.call, or pre-allocate vectors or matrix-like
>>objects with unuseful values like NA and then overwrite each element in
>>the vector or matrix-type object in a loop like your first one.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On April 27, 2016 3:25:14 PM GMT+01:00, "Gordon, Fabiana"
>><fabiana.gordon at imperial.ac.uk> wrote:
>>>Hello,
>>>
>>>Suppose the you need a loop to create a new variable , i.e., you are
>>>not reading data from outside the loop. This is a simple example in
>>>Matlab code,
>>>
>>>for i=1:5
>>>r1=randn
>>>r2=randn
>>>r=[r1 r2]
>>>c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates
>>>all columns. In R this would be [i,]
>>>end
>>>
>>>The output of interest is c which I'm creating inside the "for" loop
>>>-also the index used in the loop is used to create c. In R I had to
>>>create c as an  empty vector (numeric() ) outside the loop, otherwise
>>>I get an error message saying that c doesn't exit.
>>>
>>>The other issue is the concatenation. In each iteration I'm creating
>>>the rows of c by placing the new row  (r) below the previous one so
>>>that c becomes a 5 x 2 matrix.
>>>In R, it seems that I have no choice but use the function "rbind". I
>>>managed to write this code in R . However, I'm not sure that if
>>>instead of creating a new variable  using  the index in the "for" loop
>>>, I wanted to use the index to read data, e.g.  suppose I have a 2 X
>>>10 matrix X and suppose I want to calculate the sin () for each 2 x 2
>>>sub-matrix of and stored in a matrix A. Then the code would be
>>>something like this,
>>>
>>>for i=1:5
>>>A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all
>>>rows
>>>end
>>>
>>>Many Thanks,
>>>
>>>Fabiana
>>>
>>>
>>>Dr Fabiana Gordon
>>>
>>>Senior Statistical Consultant
>>>Statistical Advisory Service, School Of Public Health, Imperial
>>>College London 1st Floor, Stadium House, 68 Wood Lane, London W12 7RH.
>>>
>>>Tel: 020 7594 1749
>>>Email:
>>>fabiana.gordon at imperial.ac.uk<mailto:fabiana.gordon at imperial.ac.uk>
>>>Web:
>>>www.imperial.ac.uk/research-and-innovation/support-for-staff/stats-adv
>>>ice-service/<http://www.imperial.ac.uk/research-and-innovation/support
>>>-for-staff/stats-advice-service/>
>>>
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Apr 28 22:27:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 Apr 2016 13:27:12 -0700
Subject: [R] Create a new variable and concatenation inside a "for" loop
In-Reply-To: <VI1PR06MB11658535EEBB722EB4DF63B3B2650@VI1PR06MB1165.eurprd06.prod.outlook.com>
References: <VI1PR06MB116560D3E0A1EDB3E872DA20B2640@VI1PR06MB1165.eurprd06.prod.outlook.com>
	<094A4DD5-947E-4A20-B543-045F1036B915@dcn.davis.ca.us>
	<CAGxFJbTELNKOfz2-ximsCtxiy-pEA88u8WHDYXOU8=p8Z5vqJA@mail.gmail.com>
	<VI1PR06MB11658535EEBB722EB4DF63B3B2650@VI1PR06MB1165.eurprd06.prod.outlook.com>
Message-ID: <62B1E65E-53B5-4B26-994A-2B62FCFFFF36@comcast.net>


> On Apr 28, 2016, at 4:51 AM, Gordon, Fabiana <fabiana.gordon at imperial.ac.uk> wrote:
> 
> 
> Maybe I wasn't  clear  about my query. 
> 
> I'm very familiar with pre-allocation and vectorization and I had already wrote an R code for this problem in this way. My question wasn't about the most efficient way to solve the problem. It was about whether in R it was possible to use the same  index used in the loop to create a new variable and store the results in as in the example showed below. The use of ?c? was because I was using Matlab, otherwise I know that a new variable shouldn?t have the same name as the name of a function.
> 
> Regards,
> Fabiana
> 
>> 

>> 
>> On April 27, 2016 3:25:14 PM GMT+01:00, "Gordon, Fabiana" <fabiana.gordon at imperial.ac.uk> wrote:
>>> Hello,
>>> 
>>> Suppose the you need a loop to create a new variable , i.e., you are 
>>> not reading data from outside the loop. This is a simple example in 
>>> Matlab code,
>>> 
>>> for i=1:5
>>> r1=randn
>>> r2=randn
>>> r=[r1 r2]
>>> c(i,:)=r;   % creation of each row of c , % the ":" symbol indicates
>>> all columns. In R this would be [i,]
>>> end
>>> 

It is possible. 

If the object `c` exists then you can address and assign in the manner you request and in this case we would assume that `c` has 2 columns


for i=1:5 {
  r1=rnorm(1)
  r2=rnorm(1)
  r= c(r1, r2)  # c() being used as the concatenation function
  c[ i, ] =r 
           }

>>> The output of interest is c which I'm creating inside the "for" loop 
>>> -also the index used in the loop is used to create c. In R I had to 
>>> create c as an  empty vector (numeric() ) outside the loop, otherwise 
>>> I get an error message saying that c doesn't exit.
>>> 
>>> The other issue is the concatenation. In each iteration I'm creating 
>>> the rows of c by placing the new row  (r) below the previous one so 
>>> that c becomes a 5 x 2 matrix.
>>> In R, it seems that I have no choice but use the function "rbind".

If you are "adding" rows then you do need to use rbind. If you predimension which would always be faster in the long run, then you use "["
>>> I 
>>> managed to write this code in R . However, I'm not sure that if 
>>> instead of creating a new variable  using  the index in the "for" loop 
>>> , I wanted to use the index to read data, e.g.  suppose I have a 2 X 
>>> 10 matrix X and suppose I want to calculate the sin () for each 2 x 2 
>>> sub-matrix of and stored in a matrix A. Then the code would be 
>>> something like this,

There's an array class in R that would allow addressing 2 x 2 slices.

>>> 
>>> for i=1:5
>>> A(:, 2*i-1:2*i)= sin(X(:, 2*i-1:2*i))   % the ":" symbol indicates all
>>> rows
>>> end
>>> 

Since `sin` is vectorized (in the R meaning of the term) and A is either a matrix or an array, you could just do this:

A <- sin(X)


>>> Many Thanks,
>>> 
>>> Fabiana
>>> 
>>> 
>>> Dr Fabiana Gordon
>>> 
>>> Senior Statistical Consultant
>>> Statistical Advisory Service, School Of Public Health, Imperial 
>>> College London 1st Floor, Stadium House, 68 Wood Lane, London W12 7RH.
>>> 

> 

David Winsemius
Alameda, CA, USA


From biswaj41_ssf at jnu.ac.in  Thu Apr 28 18:32:16 2016
From: biswaj41_ssf at jnu.ac.in (BISWAJIT KAR)
Date: Thu, 28 Apr 2016 22:02:16 +0530
Subject: [R] Package to work with weight based data
Message-ID: <CAOL95K5S02qTZeL8Z6sg_JTtQKdgN0U1HbekHCY4cu50iZz+uw@mail.gmail.com>

Respected all,
                    I am working on a socio-economic survey (named as
National Sample Survey in India provided by National Sample Survey
Organization, Govt. of India) data of individual as well as households.
This is a sample survey where stratified random sapling method has been
used to draw samples. The data set uses 'weights' to estimate figures for
region, state or country level. In the data set, there is a variable called
weights and I use the *'weight cases'* function to activate weights
under *'Data'
 option *in menu bar in SPSS before generating any table or doing any
statistical procedure. So, my question is, is there any package/s in R
where I can use weights and work on this kind of sample survey.

Second thing, is there any package/s to generate multi layer contingency
table in R or how can I do this in R. For example, one similar kind of
table is attached here which one is created by SPSS from the above stated
data-set. Please have a look.
-- 

Thanks,

*Biswajit Kar*
(Research Scholar)
Ph. D. Student, Geography
Centre for the Study of Regional Development
School of Social Sciences
Jawaharala Nehru University
New Delhi-110067

From dwinsemius at comcast.net  Thu Apr 28 23:15:31 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 Apr 2016 14:15:31 -0700
Subject: [R] Package to work with weight based data
In-Reply-To: <CAOL95K5S02qTZeL8Z6sg_JTtQKdgN0U1HbekHCY4cu50iZz+uw@mail.gmail.com>
References: <CAOL95K5S02qTZeL8Z6sg_JTtQKdgN0U1HbekHCY4cu50iZz+uw@mail.gmail.com>
Message-ID: <F03619BB-766E-429F-B40C-C01E2C8741A4@comcast.net>


> On Apr 28, 2016, at 9:32 AM, BISWAJIT KAR <biswaj41_ssf at jnu.ac.in> wrote:
> 
> Respected all,
>                    I am working on a socio-economic survey (named as
> National Sample Survey in India provided by National Sample Survey
> Organization, Govt. of India) data of individual as well as households.
> This is a sample survey where stratified random sapling method has been
> used to draw samples. The data set uses 'weights' to estimate figures for
> region, state or country level. In the data set, there is a variable called
> weights and I use the *'weight cases'* function to activate weights
> under *'Data'
> option *in menu bar in SPSS before generating any table or doing any
> statistical procedure. So, my question is, is there any package/s in R
> where I can use weights and work on this kind of sample survey.

The 'survey' package would seem to be the obvious place to start.

Also review: 
https://cran.r-project.org/web/views/SocialSciences.html
https://cran.r-project.org/web/views/OfficialStatistics.html

> 
> Second thing, is there any package/s to generate multi layer contingency
> table in R or how can I do this in R. For example, one similar kind of
> table is attached here which one is created by SPSS from the above stated
> data-set. Please have a look.

Nothing was attached. Probably not sent in one of the acceptable formats. See the Posting Guide and List Information pages. The table-class objects can have multiple dimensions. The survey package should be able to produce tabular  estimates from multiple variables in the design specification.


> -- 
> 
> Thanks,
> 
> *Biswajit Kar*
> (Research Scholar)
> Ph. D. Student, Geography
> Centre for the Study of Regional Development
> School of Social Sciences
> Jawaharala Nehru University
> New Delhi-110067
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From akh22 at pitt.edu  Fri Apr 29 05:35:33 2016
From: akh22 at pitt.edu (Hoji, Akihiko)
Date: Fri, 29 Apr 2016 03:35:33 +0000
Subject: [R] lm() with spearman corr option ?
Message-ID: <CBBB202A-6F76-41AB-A2AB-816100803F8D@pitt.edu>

Hi,

A following function was  kindly provided by GGally?s maintainer, Barret Schloerke.

function(data, mapping, ...) {
    p <- ggplot(data = data, mapping = mapping) +
        geom_point(color = I("blue")) +
        geom_smooth(method = "lm", color = I("black"), ...) +
        theme_blank() +
        theme(panel.border=element_rect(fill=NA, linetype = "solid", color="black"))

    lmModel <- eval(substitute(lm(y ~ x, data = data), mapping))
    fs <- summary(lmModel)$fstatistic
    pValue <- pf(fs[1], fs[2], fs[3], lower.tail = FALSE)

    if (pValue < 0.05) {
        p <- p + theme(
            panel.border = element_rect(
                color = "red",
                size = 3,
                linetype = "solid",
                fill = "transparent"
            )
        )
    }

    p
}

Basically, this function draws red squares  over pairwise corr plots with p<0.05.  Now, since I need to use the spearman rank corr, I tried to modify the lm function by adding ?method=spearman?  but this did not work at al.  Could anybody suggest the way to add the spearman rank corr function in this particular function ?

Thanks.




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160429/ac0f5a6a/attachment.bin>

From bgunter.4567 at gmail.com  Fri Apr 29 05:55:20 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 28 Apr 2016 20:55:20 -0700
Subject: [R] lm() with spearman corr option ?
In-Reply-To: <CBBB202A-6F76-41AB-A2AB-816100803F8D@pitt.edu>
References: <CBBB202A-6F76-41AB-A2AB-816100803F8D@pitt.edu>
Message-ID: <CAGxFJbSr3wKhtbq4F1A1bAXraKMnZjJc_ozLaC0mmsTppSa7=A@mail.gmail.com>

Please read ?lm! -- where it says:

method:
the method to be used; for fitting, currently only method = "qr" is
supported; method = "model.frame" returns the model frame (the same as
with model = TRUE, see below).


More to the point, your request for a "spearman" method for lm() makes
little or no sense. There *are*  rank-based methods for multiple
regression, but that sort of discussion is off topic here. I suggest
you talk with a local statistician as you appear to be out of your
depth statistically; or you might try posting on a statistical site
like stats.stackexchange.com

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 28, 2016 at 8:35 PM, Hoji, Akihiko <akh22 at pitt.edu> wrote:
> Hi,
>
> A following function was  kindly provided by GGally?s maintainer, Barret Schloerke.
>
> function(data, mapping, ...) {
>     p <- ggplot(data = data, mapping = mapping) +
>         geom_point(color = I("blue")) +
>         geom_smooth(method = "lm", color = I("black"), ...) +
>         theme_blank() +
>         theme(panel.border=element_rect(fill=NA, linetype = "solid", color="black"))
>
>     lmModel <- eval(substitute(lm(y ~ x, data = data), mapping))
>     fs <- summary(lmModel)$fstatistic
>     pValue <- pf(fs[1], fs[2], fs[3], lower.tail = FALSE)
>
>     if (pValue < 0.05) {
>         p <- p + theme(
>             panel.border = element_rect(
>                 color = "red",
>                 size = 3,
>                 linetype = "solid",
>                 fill = "transparent"
>             )
>         )
>     }
>
>     p
> }
>
> Basically, this function draws red squares  over pairwise corr plots with p<0.05.  Now, since I need to use the spearman rank corr, I tried to modify the lm function by adding ?method=spearman?  but this did not work at al.  Could anybody suggest the way to add the spearman rank corr function in this particular function ?
>
> Thanks.
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Fri Apr 29 11:48:25 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 29 Apr 2016 11:48:25 +0200
Subject: [R] [Rd] paths for install and libraries?
In-Reply-To: <CAJeYpE_N+QBd9KzNaQ+vuQq7zf-_okb+SW8RjNws0finN2WWVA@mail.gmail.com>
References: <CAJeYpE_N+QBd9KzNaQ+vuQq7zf-_okb+SW8RjNws0finN2WWVA@mail.gmail.com>
Message-ID: <22307.11753.252718.135758@stat.math.ethz.ch>

>>>>> Dalthorp, Daniel <ddalthorp at usgs.gov>
>>>>>     on Thu, 28 Apr 2016 16:41:28 -0700 writes:

    > I've written a fairly elaborate package (called "eoa")
    > that relies on functions from several other packages. I've
    > built the package into a zip file on Windows using
    > Hadley's devtools::build(binary = T) and have sent the zip
    > to a couple dozen people for testing. My package installs
    > fine, but some people are having trouble loading it. After
    > library(eoa), they get something like:

    > Error: could not load package tcltk2

    > In DESCRIPTION file, I use

    > Depends: tcltk, tcltk2, tkrplot 
    > Imports: actuar, graphics, gsl, MASS, Matrix, tensorA

    > If, after getting the "could not load" message, the user
    > installs the required packages by hand, everything works
    > fine.

    > My understanding was that both the "Depends: " and the
    > "Imports: " lines in DESCRIPTION file direct R to
    > automatically install required packages that haven't been
    > previously installed.


All package installation happens via  install.packages(),
at least eventually.

If you look at the help page for that, it has always said that it
does not (as it cannot easily, in general!!) look at
dependencies when you do not install from a repository.

This question would clearly have belonged to R-help, not R-devel.
I'm CC ing to the help list and am asking all follow-ups to go
*only* to R-help, please.

Martin

    > It doesn't appear to be working that way for me. There
    > must be a simple solution that I am obviously missing....

    > Any help would be greatly appreciated!



    > -Dan

    > -- 
    > Dan Dalthorp, PhD USGS Forest and Rangeland Ecosystem
    > Science Center Forest Sciences Lab, Rm 189 3200 SW
    > Jefferson Way Corvallis, OR 97331 ph: 541-750-0953
    > ddalthorp at usgs.gov


From Douglas.Federman at utoledo.edu  Fri Apr 29 15:31:43 2016
From: Douglas.Federman at utoledo.edu (Federman, Douglas)
Date: Fri, 29 Apr 2016 13:31:43 +0000
Subject: [R] Package to work with weight based data
In-Reply-To: <CAOL95K5S02qTZeL8Z6sg_JTtQKdgN0U1HbekHCY4cu50iZz+uw@mail.gmail.com>
References: <CAOL95K5S02qTZeL8Z6sg_JTtQKdgN0U1HbekHCY4cu50iZz+uw@mail.gmail.com>
Message-ID: <F1065E5D886F4D429259CDEAE3F83CB61B013D8D@msgdb20.utad.utoledo.edu>

You might look at Anthony D'Amico's work at 

    Asdfree.com  

There is a lot to learn from here and many of those examples work with weighted survey results

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BISWAJIT KAR
Sent: Thursday, April 28, 2016 12:32 PM
To: R-help at r-project.org
Subject: [R] Package to work with weight based data

Respected all,
                    I am working on a socio-economic survey (named as
National Sample Survey in India provided by National Sample Survey
Organization, Govt. of India) data of individual as well as households.
This is a sample survey where stratified random sapling method has been
used to draw samples. The data set uses 'weights' to estimate figures for
region, state or country level. In the data set, there is a variable called
weights and I use the *'weight cases'* function to activate weights
under *'Data'
 option *in menu bar in SPSS before generating any table or doing any
statistical procedure. So, my question is, is there any package/s in R
where I can use weights and work on this kind of sample survey.

Second thing, is there any package/s to generate multi layer contingency
table in R or how can I do this in R. For example, one similar kind of
table is attached here which one is created by SPSS from the above stated
data-set. Please have a look.
-- 

Thanks,

*Biswajit Kar*
(Research Scholar)
Ph. D. Student, Geography
Centre for the Study of Regional Development
School of Social Sciences
Jawaharala Nehru University
New Delhi-110067
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From cadeb at usgs.gov  Fri Apr 29 16:38:38 2016
From: cadeb at usgs.gov (Cade, Brian)
Date: Fri, 29 Apr 2016 08:38:38 -0600
Subject: [R] lm() with spearman corr option ?
In-Reply-To: <CBBB202A-6F76-41AB-A2AB-816100803F8D@pitt.edu>
References: <CBBB202A-6F76-41AB-A2AB-816100803F8D@pitt.edu>
Message-ID: <CAM5M9BQqQ2aZAZ6h162h0h061-E2WVLU+CO=2ZTTCdzOQwGLfA@mail.gmail.com>

I think you would just need to replace the lm() function call with
cor(x,y,method="spearman".  It would probably be more informative to
actually plot by the magnitude of the correlation coefficient (all |r| >=
0.20 or something similar) rather than just by those with P <=0.05.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Thu, Apr 28, 2016 at 9:35 PM, Hoji, Akihiko <akh22 at pitt.edu> wrote:

> Hi,
>
> A following function was  kindly provided by GGally?s maintainer, Barret
> Schloerke.
>
> function(data, mapping, ...) {
>     p <- ggplot(data = data, mapping = mapping) +
>         geom_point(color = I("blue")) +
>         geom_smooth(method = "lm", color = I("black"), ...) +
>         theme_blank() +
>         theme(panel.border=element_rect(fill=NA, linetype = "solid",
> color="black"))
>
>     lmModel <- eval(substitute(lm(y ~ x, data = data), mapping))
>     fs <- summary(lmModel)$fstatistic
>     pValue <- pf(fs[1], fs[2], fs[3], lower.tail = FALSE)
>
>     if (pValue < 0.05) {
>         p <- p + theme(
>             panel.border = element_rect(
>                 color = "red",
>                 size = 3,
>                 linetype = "solid",
>                 fill = "transparent"
>             )
>         )
>     }
>
>     p
> }
>
> Basically, this function draws red squares  over pairwise corr plots with
> p<0.05.  Now, since I need to use the spearman rank corr, I tried to modify
> the lm function by adding ?method=spearman?  but this did not work at al.
> Could anybody suggest the way to add the spearman rank corr function in
> this particular function ?
>
> Thanks.
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From suttoncarl at ymail.com  Fri Apr 29 18:19:02 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 29 Apr 2016 16:19:02 +0000 (UTC)
Subject: [R] selecting columns from a data frame or data table by type, ie,
 numeric, integer
References: <141731525.5176023.1461946742806.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <141731525.5176023.1461946742806.JavaMail.yahoo@mail.yahoo.com>

Good morning RGuru's
I have a data frame of 575 columns.? I want to extract only those columns that are numeric(double) or integer to do some machine learning with.? I have searched the web for a couple of days (off and on) and have not found anything that shows how to do this.?? Lots of ways to extract rows, but not columns.? I have attempted to use "(x == y)" indices extraction method but that threw error that == was for atomic vectors and lists, and I was doing this on a data frame.

My test code is below

#? a technique to get column classes
library(data.table)
a <- 1:10
b <- c("a","b","c","d","e","f","g","h","i","j")
c <- seq(1.1, .2, length = 10)
dt1 <- data.table(a,b,c)
str(dt1)
col.classes <- sapply(dt1, class)
head(col.classes)
dt2 <- subset(dt1, typeof = "double" | "numeric")
str(dt2)
dt2?? #? not subset 
dt2 <- dt1[, list(typeof = "double")]
str(dt2)
class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
class_data
sum(class_data)
typeof(class_data)
names(class_data)
str(class_data)
?Any help is appreciated
Carl Sutton CPA

	[[alternative HTML version deleted]]


From ddalthorp at usgs.gov  Fri Apr 29 19:42:07 2016
From: ddalthorp at usgs.gov (Dalthorp, Daniel)
Date: Fri, 29 Apr 2016 10:42:07 -0700
Subject: [R] tcltk: click and return table cell index
Message-ID: <CAJeYpE_G=eTLTmOxtOTFhUNQ3LJusrGbwecpu1yXGBg3T47S4g@mail.gmail.com>

I'm struggling mightily with what should be a simple task...when a user
clicks on a cell in a tcltk table widget, I need to know which cell was
clicked.

One idea that gives a cryptic error:
tkbind(table1, "<Button-1>", function(x, y){
  tcl(table1, "index", x, y)
}

# x, y give pixel coordinates; "index" should give cell coordinates, but
format must be correct

I get an error message:

wrong # args: should be ".25.1 index <index> ?row|col?".

To which I respond, "Yes, I know I have the format wrong, but how can I
make sense of THAT?"

Does anyone know a simple fix?

Much appreciated!

-Dan

-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 189
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Apr 29 19:50:52 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 29 Apr 2016 10:50:52 -0700
Subject: [R] selecting columns from a data frame or data table by type,
 ie, numeric, integer
In-Reply-To: <141731525.5176023.1461946742806.JavaMail.yahoo@mail.yahoo.com>
References: <141731525.5176023.1461946742806.JavaMail.yahoo.ref@mail.yahoo.com>
	<141731525.5176023.1461946742806.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcZMbPgRfdH0uXY+bHcb8BsrYU+9XMFqpr9czKdzjJmLUg@mail.gmail.com>

> dt1[ vapply(dt1, FUN=is.numeric, FUN.VALUE=NA) ]
    a   c
1   1 1.1
2   2 1.0
...
10 10 0.2



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Apr 29, 2016 at 9:19 AM, Carl Sutton via R-help <
r-help at r-project.org> wrote:

> Good morning RGuru's
> I have a data frame of 575 columns.  I want to extract only those columns
> that are numeric(double) or integer to do some machine learning with.  I
> have searched the web for a couple of days (off and on) and have not found
> anything that shows how to do this.   Lots of ways to extract rows, but not
> columns.  I have attempted to use "(x == y)" indices extraction method but
> that threw error that == was for atomic vectors and lists, and I was doing
> this on a data frame.
>
> My test code is below
>
> #  a technique to get column classes
> library(data.table)
> a <- 1:10
> b <- c("a","b","c","d","e","f","g","h","i","j")
> c <- seq(1.1, .2, length = 10)
> dt1 <- data.table(a,b,c)
> str(dt1)
> col.classes <- sapply(dt1, class)
> head(col.classes)
> dt2 <- subset(dt1, typeof = "double" | "numeric")
> str(dt2)
> dt2   #  not subset
> dt2 <- dt1[, list(typeof = "double")]
> str(dt2)
> class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
> class_data
> sum(class_data)
> typeof(class_data)
> names(class_data)
> str(class_data)
>  Any help is appreciated
> Carl Sutton CPA
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Muhammad2.Bilal at live.uwe.ac.uk  Fri Apr 29 20:25:33 2016
From: Muhammad2.Bilal at live.uwe.ac.uk (Muhammad Bilal)
Date: Fri, 29 Apr 2016 18:25:33 +0000
Subject: [R] How to access the latitude & longitude for UK post codes in R
Message-ID: <DB5PR07MB1109E36DDF2B5ABDD56562ABDB660@DB5PR07MB1109.eurprd07.prod.outlook.com>

Hi All,


I have a data frame with three columns i.e., pc, lat, lon.


The pc column is populated with list of postcodes, and I want to execute R command that can get me the lat and lon for the every item in the pc column and populate the respective lat and lon columns.


Is there any package that could be used?


Any help will be really appreciated.


Many Thanks and


Kind Regards

--
Muhammad Bilal
Research Fellow and Doctoral Researcher,
Bristol Enterprise, Research, and Innovation Centre (BERIC),
University of the West of England (UWE),
Frenchay Campus,
Bristol,
BS16 1QY

muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>


	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Fri Apr 29 20:39:19 2016
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 29 Apr 2016 18:39:19 +0000
Subject: [R] selecting columns from a data frame or data table by type,
 ie, numeric, integer
Message-ID: <248E6FA047A8C746BA491485764190F53D3B0AE8@ESESSMB207.ericsson.se>

Hi,

I was able to replicate the solution as suggested by William in case of
data.frame class, not in case of data.table class.
In case of data.table, I had to do some minor changes as shown below.


library(data.table)
a <- 1:10
b <- c("a","b","c","d","e","f","g","h","i","j")
c <- seq(1.1, .2, length = 10)

# in case of data frame
dt1 <- data.frame(a,b,c)
dt1[vapply(dt1, FUN=is.numeric, FUN.VALUE=NA)]

    a   c
1   1 1.1
2   2 1.0
3   3 0.9
4   4 0.8
5   5 0.7
6   6 0.6
7   7 0.5
8   8 0.4
9   9 0.3
10 10 0.2

# in case of data table
dt1 <- data.table(a,b,c)
dt1[, vapply(dt1, FUN=is.numeric, FUN.VALUE=NA), with=FALSE]

    a   c
1   1 1.1
2   2 1.0
3   3 0.9
4   4 0.8
5   5 0.7
6   6 0.6
7   7 0.5
8   8 0.4
9   9 0.3
10 10 0.2


--

Best,

GG




	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Fri Apr 29 20:44:15 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 29 Apr 2016 13:44:15 -0500
Subject: [R] How to access the latitude & longitude for UK post codes in
	R
In-Reply-To: <DB5PR07MB1109E36DDF2B5ABDD56562ABDB660@DB5PR07MB1109.eurprd07.prod.outlook.com>
References: <DB5PR07MB1109E36DDF2B5ABDD56562ABDB660@DB5PR07MB1109.eurprd07.prod.outlook.com>
Message-ID: <CAAJSdjinCW0AL=P26L0MOnExiBJ_crt+mjW9FHGUiabsWOEOwQ@mail.gmail.com>

On Fri, Apr 29, 2016 at 1:25 PM, Muhammad Bilal <
Muhammad2.Bilal at live.uwe.ac.uk> wrote:

> Hi All,
>
>
> I have a data frame with three columns i.e., pc, lat, lon.
>
>
> The pc column is populated with list of postcodes, and I want to execute R
> command that can get me the lat and lon for the every item in the pc column
> and populate the respective lat and lon columns.
>
>
> Is there any package that could be used?
>
>
> Any help will be really appreciated.
>
>
> Many Thanks and
>
>
> Kind Regards
>
> --
> Muhammad Bilal
> Research Fellow and Doctoral Researcher,
> Bristol Enterprise, Research, and Innovation Centre (BERIC),
> University of the West of England (UWE),
> Frenchay Campus,
> Bristol,
> BS16 1QY
>
> muhammad2.bilal at live.uwe.ac.uk<mailto:olugbenga2.akinade at live.uwe.ac.uk>
>
>
?I didn't find a package, but I did find this page:
https://www.freemaptools.com/map-tools.htm
If you scroll down to the UK section, you'll find:


   - Download UK Postcodes with Latitude and Longitude
   <https://www.freemaptools.com/download-uk-postcode-lat-lng.htm> -
   Download a list of UK out code postcodes with their latitude and longitude
   coordinates
   ?.?

On that page, you will find a link which will download a ZIP file which
contains a CSV file which says (I didn't download it) it contains the post
code, lat, long for the UK postcodes.
?You might be able to use that as a source for your own lookup code.? I
found this via Google.


-- 
The unfacts, did we have them, are too imprecisely few to warrant our
certitude.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From fabien.tarrade at gmail.com  Fri Apr 29 21:03:02 2016
From: fabien.tarrade at gmail.com (Fabien Tarrade)
Date: Fri, 29 Apr 2016 21:03:02 +0200
Subject: [R] what is the faster way to search for a pattern in a few
 million entries data frame ?
In-Reply-To: <570AE278.7090407@roswellpark.org>
References: <570A956B.7080305@gmail.com> <570A9E18.5020402@gmail.com>
	<570AA914.90303@gmail.com> <570AE278.7090407@roswellpark.org>
Message-ID: <aae1befb-4a44-9e6a-9906-1592a672a17b@gmail.com>

Hi Martin and everybody,

sorry for the long delay. Thanks for all the suggestions. With my code 
and my training data I found similar numbers to the one below.

Thanks

Cheers

Fabien

> I did this to generate and search 40 million unique strings
>
> > grams <- as.character(1:4e7)        ## a long time passes...
> > system.time(grep("^900001", grams)) ## similar times to grepl
>    user  system elapsed
>  10.384   0.168  10.543
>
> Is that the basic task you're trying to accomplish? grep(l) goes 
> quickly to C, so I don't think data.table or other will be markedly 
> faster if you're looking for an arbitrary regular expression (use 
> fixed=TRUE if looking for an exact match).
>
> If you're looking for strings that start with a pattern, then in 
> R-3.3.0 there is
>
> > system.time(res0 <- startsWith(grams, "900001"))
>    user  system elapsed
>   0.658   0.012   0.669
>
> which returns the same result as grepl
>
> > identical(res0, res1 <- grepl("^900001", grams))
> [1] TRUE
>
> One can also parallelize the already vectorized grepl function with 
> parallel::pvec, with some opportunity for gain (compared to grepl) on 
> non-Windows
>
> > system.time(res2 <- pvec(seq_along(grams), function(i) 
> grepl("^900001", grams[i]), mc.cores=8))
>    user  system elapsed
>  24.996   1.709   3.974
> > identical(res0, res2)
> [[1]] TRUE
>
> I think anything else would require pre-processing of some kind, and 
> then some more detail about what your data looks like is required.

-- 
Dr Fabien Tarrade

Quantitative Analyst/Developer - Data Scientist

Senior data analyst specialised in the modelling, processing and 
statistical treatment of data.
PhD in Physics, 10 years of experience as researcher at the forefront of 
international scientific research.
Fascinated by finance and data modelling.

Geneva, Switzerland

Email : contact at fabien-tarrade.eu <mailto:contact at fabien-tarrade.eu>
Phone : www.fabien-tarrade.eu <http://www.fabien-tarrade.eu>
Phone : +33 (0)6 14 78 70 90

LinkedIn <http://ch.linkedin.com/in/fabientarrade/> Twitter 
<https://twitter.com/fabtar> Google 
<https://plus.google.com/+FabienTarradeProfile/posts> Facebook 
<https://www.facebook.com/fabien.tarrade.eu> Google 
<skype:fabtarhiggs?call> Xing <https://www.xing.com/profile/Fabien_Tarrade>


From giftedlife2014 at gmail.com  Fri Apr 29 21:40:20 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Fri, 29 Apr 2016 20:40:20 +0100
Subject: [R] clock24.plot/radial plot: Fixed
Message-ID: <CAC8ss325n6Fc7gYEGgf-PgK1C8Q-61a84Lq13OCnwG=aHeONTQ@mail.gmail.com>

Dear All,
This problem is over. Clock24.plot did the job. Thanks to all those who
assisted me.
Ogbos
On Apr 22, 2016 8:34 PM, "Ogbos Okike" <giftedlife2014 at gmail.com> wrote:

> Dear All,
> One hand. Many thanks!! The code run as soon as I loaded lubridate.
>
> Please can you guide me on how to relate this code to my actual data.
> My actual data is looking like:
> 2005/01/01 00:00   4009
> 2005/01/01 01:00   3969
> 2005/01/01 02:00   3946
> 2005/01/01 03:00   3975
> 2005/01/01 04:00   3960
> 2005/01/01 05:00   3974
> 2005/01/01 06:00   3971
> 2005/01/01 07:00   3970
> 2005/01/01 08:00   3962
> 2005/01/01 09:00   3992
> 2005/01/01 10:00   3955
> 2005/01/01 11:00   3963
> 2005/01/01 12:00   3965
> 2005/01/01 13:00   3947
> 2005/01/01 14:00   3959
> 2005/01/01 15:00   3978
> 2005/01/01 16:00   3967
> and it runs for many years.
>
> Many thanks for time.
> Ogbos
>
> On 4/22/16, David L Carlson <dcarlson at tamu.edu> wrote:
> > Looks like you forgot to load the lubridate package
> >
> > library(lubridate)
> >
> > You are calling functions days(), hours(), minutes(), seconds(), and
> hour()
> > which all come from that package.
> >
> > -------------------------------------
> > David L Carlson
> > Department of Anthropology
> > Texas A&M University
> > College Station, TX 77840-4352
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ogbos
> Okike
> > Sent: Friday, April 22, 2016 2:05 PM
> > To: Ulrik Stervbo
> > Cc: r-help at r-project.org
> > Subject: Re: [R] clock24.plot/radial plot
> >
> > Kind Experts,
> > Many thanks for your guide. I have tried to figure out something that
> > can help me plot my own data using the examples you referred me to. I
> > copied part of the code as:
> >
> > set.seed(44)
> > N=500
> > events <- as.POSIXct("2011-01-01", tz="GMT") +
> >               days(floor(365*runif(N))) +
> >               hours(floor(24*rnorm(N))) +  # using rnorm here
> >               minutes(floor(60*runif(N))) +
> >               seconds(floor(60*runif(N)))
> > hour_of_event <- hour(events)
> > # make a dataframe
> > eventdata <- data.frame(datetime = events, eventhour = hour_of_event)
> > # determine if event is in business hours
> > eventdata$Workday <- eventdata$eventhour %in% seq(9, 17)
> > library(circular)
> > eventdata$eventhour <- circular(hour_of_event%%24, # convert to 24 hrs
> >       units="hours", template="clock24")
> > rose.diag(eventdata$eventhour, bin = 24, col = "lightblue", main =
> > "Events by Hour (sqrt scale)",
> >     prop = 3)
> > I tried to run the above but got an error message: "Error in
> > eval(expr, envir, enclos) : could not find function "days"
> > I was thinking that if I could run this code, I can see what is doing
> > and then start trying to see if I can adapt it to solve my problem.
> >
> > Thank you so much for further assistance.
> > Ogbos
> >
> >
> > On 4/22/16, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> >> I use ggplot2 for all my plotting needs where you can make plots
> circular
> >> with the coord_polar. Maybe this will help you along:
> >>
> http://rstudio-pubs-static.s3.amazonaws.com/3369_998f8b2d788e4a0384ae565c4280aa47.html
> >>
> >> On Fri, 22 Apr 2016 at 08:31 Ogbos Okike <giftedlife2014 at gmail.com>
> >> wrote:
> >>
> >>> Dear All,
> >>> I am trying to generate a circular/radial plot. The script below has a
> >>> result I am looking for:
> >>> testlen<-rnorm(24)*2+5
> >>>  testpos<-0:23+rnorm(24)/4
> >>>  clock24.plot(testlen,testpos,main="Test Clock24
> >>> (lines)",show.grid=FALSE,
> >>>   line.col="green",lwd=3)
> >>>  if(dev.interactive()) par(ask=TRUE)
> >>>  # now do a 'daylight' plot
> >>>  oldpar<-clock24.plot(testlen[7:19],testpos[7:19],
> >>>   main="Test Clock24 daytime (symbols)",
> >>>   point.col="blue",rp.type="s",lwd=3)
> >>>  # reset everything
> >>>  par(oldpar)
> >>>
> >>> I tried to play with the script to work with my data. I read my data:
> >>> swe<-scan("onedaydata",list(dates="",time="",count=""))
> >>> dates<-swe$dates
> >>> times<-swe$time
> >>> count<-swe$count.
> >>> I tried to replace testlen<-rnorm(24)*2+5 with testlen<-count and
> >>> oldpar<-clock24.plot(testlen[7:19],testpos[7:19], with
> >>> oldpar<-clock24.plot(testlen[0:23],testpos[0:23], but nothing worked.
> >>> The format of my data is 2005/01/01 00:00   4009
> >>> 2005/01/01 01:00   3969
> >>> 2005/01/01 02:00   3946
> >>> 2005/01/01 03:00   3975
> >>> 2005/01/01 04:00   3960
> >>> 2005/01/01 05:00   3974
> >>> 2005/01/01 06:00   3971
> >>> 2005/01/01 07:00   3970
> >>> 2005/01/01 08:00   3962
> >>> 2005/01/01 09:00   3992
> >>> 2005/01/01 10:00   3955
> >>> 2005/01/01 11:00   3963
> >>> 2005/01/01 12:00   3965
> >>> 2005/01/01 13:00   3947
> >>> 2005/01/01 14:00   3959
> >>> 2005/01/01 15:00   3978
> >>> 2005/01/01 16:00   3967
> >>> 2005/01/01 17:00   3978
> >>> 2005/01/01 18:00   3988
> >>> 2005/01/01 19:00   4043
> >>> 2005/01/01 20:00   4026
> >>> 2005/01/01 21:00   3996
> >>> 2005/01/01 22:00   3967
> >>> 2005/01/01 23:00   3969
> >>> 2005/01/02 00:00   3976
> >>> 2005/01/02 01:00   3969
> >>> 2005/01/02 02:00   3955
> >>> 2005/01/02 03:00   3984
> >>> 2005/01/02 04:00   3971
> >>> 2005/01/02 05:00   3960
> >>> 2005/01/02 06:00   3951
> >>> 2005/01/02 07:00   3948
> >>> 2005/01/02 08:00   3954
> >>> 2005/01/02 09:00   3948
> >>> 2005/01/02 10:00   3960
> >>> 2005/01/02 11:00   3964
> >>> 2005/01/02 12:00   3962
> >>> 2005/01/02 13:00   3959
> >>> 2005/01/02 14:00   3950
> >>> 2005/01/02 15:00   3972
> >>> 2005/01/02 16:00   3984
> >>> 2005/01/02 17:00   3983
> >>> 2005/01/02 18:00   3982
> >>> 2005/01/02 19:00   3987
> >>> 2005/01/02 20:00   3989
> >>> 2005/01/02 21:00   3975
> >>> 2005/01/02 22:00   3956
> >>> 2005/01/02 23:00   3975
> >>> 2005/01/03 00:00   3946
> >>> 2005/01/03 01:00   3944
> >>> 2005/01/03 02:00   3915
> >>> 2005/01/03 03:00   3901
> >>> 2005/01/03 04:00   3893
> >>> 2005/01/03 05:00   3854
> >>> 2005/01/03 06:00   3824
> >>> 2005/01/03 07:00   3790
> >>> 2005/01/03 08:00   3770
> >>> 2005/01/03 09:00   3794
> >>> 2005/01/03 10:00   3778
> >>> 2005/01/03 11:00   3803
> >>> 2005/01/03 12:00   3801
> >>> 2005/01/03 13:00   3800
> >>> 2005/01/03 14:00   3783
> >>> 2005/01/03 15:00   3789
> >>> 2005/01/03 16:00   3804
> >>> 2005/01/03 17:00   3781
> >>> 2005/01/03 18:00   3785
> >>> 2005/01/03 19:00   3772
> >>> 2005/01/03 20:00   3777
> >>> 2005/01/03 21:00   3766
> >>> 2005/01/03 22:00   3775
> >>> 2005/01/03 23:00   3779
> >>> 2005/01/04 00:00   3798
> >>> 2005/01/04 01:00   3806
> >>>
> >>> A sample of the plot I want is attached. My data is quite large.
> >>> Thanks for your time.
> >>> Best wishes
> >>> Ogbos
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From suttoncarl at ymail.com  Fri Apr 29 22:07:21 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 29 Apr 2016 20:07:21 +0000 (UTC)
Subject: [R] selecting columns from a data frame or data table by type,
 ie, numeric, integer
In-Reply-To: <CAF8bMcZMbPgRfdH0uXY+bHcb8BsrYU+9XMFqpr9czKdzjJmLUg@mail.gmail.com>
References: <CAF8bMcZMbPgRfdH0uXY+bHcb8BsrYU+9XMFqpr9czKdzjJmLUg@mail.gmail.com>
Message-ID: <1609303718.5308381.1461960441557.JavaMail.yahoo@mail.yahoo.com>

Thank you Bill Dunlap.? So simple I never tried that approach. Tried dozens of others though, read manuals till I was getting headaches, and of course the answer was simple when one is competent.?? Learning, its a struggle, but slowly getting there.
Thanks again
?Carl Sutton CPA
 

    On Friday, April 29, 2016 10:50 AM, William Dunlap <wdunlap at tibco.com> wrote:
 
 

 > dt1[ vapply(dt1, FUN=is.numeric, FUN.VALUE=NA) ]? ? a ? c1 ? 1 1.12 ? 2 1.0...10 10 0.2


Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Fri, Apr 29, 2016 at 9:19 AM, Carl Sutton via R-help <r-help at r-project.org> wrote:

Good morning RGuru's
I have a data frame of 575 columns.? I want to extract only those columns that are numeric(double) or integer to do some machine learning with.? I have searched the web for a couple of days (off and on) and have not found anything that shows how to do this.?? Lots of ways to extract rows, but not columns.? I have attempted to use "(x == y)" indices extraction method but that threw error that == was for atomic vectors and lists, and I was doing this on a data frame.

My test code is below

#? a technique to get column classes
library(data.table)
a <- 1:10
b <- c("a","b","c","d","e","f","g","h","i","j")
c <- seq(1.1, .2, length = 10)
dt1 <- data.table(a,b,c)
str(dt1)
col.classes <- sapply(dt1, class)
head(col.classes)
dt2 <- subset(dt1, typeof = "double" | "numeric")
str(dt2)
dt2?? #? not subset
dt2 <- dt1[, list(typeof = "double")]
str(dt2)
class_data <- dt1[,sapply(dt1,is.integer) | sapply(dt1, is.numeric)]
class_data
sum(class_data)
typeof(class_data)
names(class_data)
str(class_data)
?Any help is appreciated
Carl Sutton CPA

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




  
	[[alternative HTML version deleted]]


From goran.brostrom at umu.se  Fri Apr 29 23:26:21 2016
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 29 Apr 2016 23:26:21 +0200
Subject: [R] Improper configuration
Message-ID: <5723D17D.9090801@umu.se>

Trying https://cran.r-project.org got me

"The owner of cran.r-project.org has configured their website improperly"

If I try http (instead of https) I'm redirected to

www.project.org ("Project America")

Any ideas?

G?ran Brostr?m


From bgunter.4567 at gmail.com  Fri Apr 29 23:59:21 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 29 Apr 2016 14:59:21 -0700
Subject: [R] Improper configuration
In-Reply-To: <5723D17D.9090801@umu.se>
References: <5723D17D.9090801@umu.se>
Message-ID: <CAGxFJbTPOR_NY2_pgThFLLo7eETgC6YL7ObGCZZTckJuad8YJw@mail.gmail.com>

Something on your end. I clicked on your link and it took me to CRAN
with no problems.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 29, 2016 at 2:26 PM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
> Trying https://cran.r-project.org got me
>
> "The owner of cran.r-project.org has configured their website improperly"
>
> If I try http (instead of https) I'm redirected to
>
> www.project.org ("Project America")
>
> Any ideas?
>
> G?ran Brostr?m
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From goran.brostrom at umu.se  Sat Apr 30 00:40:50 2016
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Sat, 30 Apr 2016 00:40:50 +0200
Subject: [R] Improper configuration
In-Reply-To: <CAGxFJbTPOR_NY2_pgThFLLo7eETgC6YL7ObGCZZTckJuad8YJw@mail.gmail.com>
References: <5723D17D.9090801@umu.se>
	<CAGxFJbTPOR_NY2_pgThFLLo7eETgC6YL7ObGCZZTckJuad8YJw@mail.gmail.com>
Message-ID: <5723E2F2.9070306@umu.se>



On 2016-04-29 23:59, Bert Gunter wrote:
> Something on your end. I clicked on your link and it took me to CRAN
> with no problems.

Right, the 'problem' is gone now. I am on a fresh install of ubuntu 
16.04LTS with Firefox. Maybe some core-team-guy just fixed the 
certificate?;) Or the new install needs some warming-up.

Thanks Bert,

G?ran

>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Apr 29, 2016 at 2:26 PM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
>> Trying https://cran.r-project.org got me
>>
>> "The owner of cran.r-project.org has configured their website improperly"
>>
>> If I try http (instead of https) I'm redirected to
>>
>> www.project.org ("Project America")
>>
>> Any ideas?
>>
>> G?ran Brostr?m
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From lordpreetam at gmail.com  Sat Apr 30 09:25:05 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sat, 30 Apr 2016 12:55:05 +0530
Subject: [R] Declaring All Variables as Factors in GLM()
Message-ID: <CAHVFrXEwiu+f49J7Y2Lk4bGmsRU9pKqY7_jfQx85WMbNoVdSAg@mail.gmail.com>

Hi guys,

I am running glm(y~., data = history,family=binomial)-essentially, logistic
regression for credit scoring (y = 0 or 1). The dataset 'history' has 14
variables, a few examples:
history <- read.csv("history.csv". header = TRUE)
1> 'income = 100,200,300 (these are numbers in my dataset; however
interpretation is that these are just tags or labels,for every observation,
its income gets assigned one of these tags)
2> 'job' = 'private','government','unemployed','student'

I want to declare all the regressors and y variables *as factors*
programmatically. Would be great if anyone can help me with this (idea is
to loop over variable names and use as.factor - but not sure how to do
this). Thanks

Regards,
Preetam
-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From giftedlife2014 at gmail.com  Sat Apr 30 10:28:00 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Sat, 30 Apr 2016 09:28:00 +0100
Subject: [R] Could not find function "pointsToRaster"
Message-ID: <CAC8ss30OF5jHDmvMrXLw0NJt68Ect9FsxYWK+56aH=q0bL7JFw@mail.gmail.com>

Dear All,
I have a script that draws longitude and latitude of lightning
occurrence. This script was running fine before. But when I changed my
system and do a fresh install on another laptop, this error persist.
 source("script")
Error in eval(expr, envir, enclos) :
  could not find function "pointsToRaster"

I have tried to see if  there is any other package I need to install
to take of the problem, I could not see. Already, when I installed
raster, it installed its dependencies such as sp.
Can any body please bail me out.

Thanks
Ogbos


From lars52r at gmail.com  Sat Apr 30 12:22:30 2016
From: lars52r at gmail.com (Lars Bishop)
Date: Sat, 30 Apr 2016 06:22:30 -0400
Subject: [R] Issue installing packages - Linux
Message-ID: <CAO7OmOhi1Pag3funkd9UOv7QxkWjOPmYjcEQX_QBeSTdOAvK4Q@mail.gmail.com>

Hello,

I can?t seem to be able to install packages on a redhat-linux-gnu. For
instance, this is what happens when I try to install ?bitops?. Any hint on
what might be the issue would be much appreciated.

> sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Red Hat Enterprise Linux

> Sys.setenv(https_proxy="https://labproxy.com:8080")
> install.packages("bitops", lib="mypath ")

Here I choose: 22: (HTTP mirrors) and then a mirror 16:Canada(ON)

* installing *source* package ?bitops? ...
** package ?bitops? successfully unpacked and MD5 sums checked
Error in readRDS(pfile) : error reading from connection
ERROR: lazy loading failed for package ?bitops?

I?ve also tried from the shell (after downloading the package source)

$  R CMD INSTALL bitops_1.0-6.tar.gz
ERROR: cannot extract package from bitops_1.0-6.tar.gz

Thank you,
Lars.

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Sat Apr 30 13:35:45 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Sat, 30 Apr 2016 07:35:45 -0400
Subject: [R] Could not find function "pointsToRaster"
In-Reply-To: <CAC8ss30OF5jHDmvMrXLw0NJt68Ect9FsxYWK+56aH=q0bL7JFw@mail.gmail.com>
References: <CAC8ss30OF5jHDmvMrXLw0NJt68Ect9FsxYWK+56aH=q0bL7JFw@mail.gmail.com>
Message-ID: <9D970500-C4F5-47B1-AA9C-3447D50A8E02@bigelow.org>

Hi,

A terrific resource for this type of issue (and pretty much anything related to R) is http://rseek.org/  I'm sure I use it at least daily.  Check out ...

http://rseek.org/?q=pointsToRaster

The first hit is about pointsToRaster() - it has been replaced by raster::rasterize()

Cheers,
Ben

> On Apr 30, 2016, at 4:28 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear All,
> I have a script that draws longitude and latitude of lightning
> occurrence. This script was running fine before. But when I changed my
> system and do a fresh install on another laptop, this error persist.
> source("script")
> Error in eval(expr, envir, enclos) :
>  could not find function "pointsToRaster"
> 
> I have tried to see if  there is any other package I need to install
> to take of the problem, I could not see. Already, when I installed
> raster, it installed its dependencies such as sp.
> Can any body please bail me out.
> 
> Thanks
> Ogbos
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From leonardof at leonardof.med.br  Sat Apr 30 04:40:11 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Fri, 29 Apr 2016 23:40:11 -0300
Subject: [R] Unexpected scores from weighted PCA with svyprcomp()
Message-ID: <1461984011.3962650.593973745.101FB110@webmail.messagingengine.com>

Hello!

I'd like to create an assets-based economic indicator using data from a
national household survey. The economic indicator is to be the first
principal component from a principal components analysis, which (given
the source of the data) I believe should take in consideration the
sampling weights of the observations. After running the PCA with
svyprcomp(), from the survey package, I wanted to list the loading (with
regard to the first principal component) and the scale of the variables,
so that I can tell people how to "reconstitute" the economic indicator
from the variables without any knowledge of PCA. This reconstituted
indicator wouldn't be centered, but that's OK because the important
thing for the application is the relative position of the observations.
The unexpected (at least for me) behavior was that the principal
component returned by svyprcomp() was very different from from the
reconstituted indicator as well as from the indicator returned by
predict(). "Different" here means weak correlation and different
distributions.

I hope the following code illustrates what I mean:

=====

svycor <- function(formula, design) {
  # https://stat.ethz.ch/pipermail/r-help/2003-July/036645.html
  stopifnot(require(survey))
  covariance.matrix <- svyvar(formula, design)
  variables <- diag(covariance.matrix)
  correlation.matrix <- covariance.matrix / sqrt(variables %*%
  t(variables))
  return(correlation.matrix)
}

library(survey)
data(api)
dclus2 <- svydesign(ids = ~ dnum + snum, fpc = ~ fpc1 + fpc2, data =
apiclus2)
pc <- svyprcomp( ~ api99 + api00, design = dclus2, scale = TRUE, scores
= TRUE)
dclus2$variables$pc1 <- pc$x[, "PC1"]
dclus2$variables$pc2 <- predict(pc, apiclus2)[, "PC1"]
mycoef <- pc$rotation[, "PC1"] / pc$scale
dclus2$variables$pc3 <- with(apiclus2, api99 * mycoef["api99"] + api00 *
mycoef["api00"])
svycor(~ pc1 + pc2 + pc3, dclus2)[, ]
#           pc1       pc2       pc3
# pc1 1.0000000 0.2078789 0.2078789
# pc2 0.2078789 1.0000000 1.0000000
# pc3 0.2078789 1.0000000 1.0000000
plot(svysmooth(~ pc1, dclus2), xlim = c(-2.5, 5), ylim = 0:1)
lines(svysmooth(~ pc2, dclus2), col = 2)
lines(svysmooth(~ pc3, dclus2), col = 3)
legend("topright", legend = c('pc$x[, "PC1"]', 'predict(pc, apiclus2)[,
"PC1"]', 'Reconstituted indicator'), col = 1:3, lty = 1)

sessionInfo()
# R version 3.2.4 Revised (2016-03-16 r70336)
# Platform: x86_64-pc-linux-gnu (64-bit)
# Running under: Arch Linux
# 
#  locale:
#  [1] LC_CTYPE=pt_BR.UTF-8       LC_NUMERIC=C              
#  [3] LC_TIME=pt_BR.UTF-8        LC_COLLATE=pt_BR.UTF-8    
#  [5] LC_MONETARY=pt_BR.UTF-8    LC_MESSAGES=pt_BR.UTF-8   
#  [7] LC_PAPER=pt_BR.UTF-8       LC_NAME=C                 
#  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
# [11] LC_MEASUREMENT=pt_BR.UTF-8 LC_IDENTIFICATION=C       
# 
# attached base packages:
# [1] grid      stats     graphics  utils     datasets  grDevices
# [7] methods   base     
# 
# other attached packages:
# [1] KernSmooth_2.23-15 survey_3.30-3     
# 
# loaded via a namespace (and not attached):
# [1] tools_3.2.4

=====

This lack of correlation doesn't happen if the survey design object has
uniform sampling weights or if the the data is analyzed with prcomp().

Why does the returned principal component is so different from the
predicted and the reconstituted ones? Are predict() and my
"reconstitution" missing something? Are the three methods equally valid
but with different interpretations? Is there a bug in svyprcomp() ??

Thanks in advance,

Leonardo Ferreira Fontenelle
http://lattes.cnpq.br/9234772336296638


From leonardof at leonardof.med.br  Sat Apr 30 13:20:53 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Sat, 30 Apr 2016 08:20:53 -0300
Subject: [R] Could not find function "pointsToRaster"
In-Reply-To: <CAC8ss30OF5jHDmvMrXLw0NJt68Ect9FsxYWK+56aH=q0bL7JFw@mail.gmail.com>
References: <CAC8ss30OF5jHDmvMrXLw0NJt68Ect9FsxYWK+56aH=q0bL7JFw@mail.gmail.com>
Message-ID: <1462015253.4096059.594162289.189382F7@webmail.messagingengine.com>

Dear Ogbos Okike,

I can't know how your script depends on pointsToRaster(), but googling
around I found that the function seems to have been marked as obsolete:

http://www.inside-r.org/packages/cran/raster/docs/linesToRaste

Hope that helps,

Leonardo Ferreira Fontenelle
http://lattes.cnpq.br/9234772336296638

Em S?b 30 abr. 2016, ?s 05:28, Ogbos Okike escreveu:
> Dear All,
> I have a script that draws longitude and latitude of lightning
> occurrence. This script was running fine before. But when I changed my
> system and do a fresh install on another laptop, this error persist.
>  source("script")
> Error in eval(expr, envir, enclos) :
>   could not find function "pointsToRaster"
> 
> I have tried to see if  there is any other package I need to install
> to take of the problem, I could not see. Already, when I installed
> raster, it installed its dependencies such as sp.
> Can any body please bail me out.
> 
> Thanks
> Ogbos
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From leonardof at leonardof.med.br  Sat Apr 30 13:47:57 2016
From: leonardof at leonardof.med.br (Leonardo Ferreira Fontenelle)
Date: Sat, 30 Apr 2016 08:47:57 -0300
Subject: [R] Declaring All Variables as Factors in GLM()
In-Reply-To: <CAHVFrXEwiu+f49J7Y2Lk4bGmsRU9pKqY7_jfQx85WMbNoVdSAg@mail.gmail.com>
References: <CAHVFrXEwiu+f49J7Y2Lk4bGmsRU9pKqY7_jfQx85WMbNoVdSAg@mail.gmail.com>
Message-ID: <1462016877.4103057.594172361.3BC37260@webmail.messagingengine.com>

This should do the trick:

history2 <- as.data.frame(lapply(history, as.factor))

Mind you that read.csv() by default reads string vectors as factors, so
that declaring the variables as factors should only be necessary for the
numeric ones, like income. Using as.factor() in factor variables may
drop unused levels, but in your case I believe it won't be a problem.

HTH,

Leonardo Ferreira Fontenelle
http://lattes.cnpq.br/9234772336296638

Em S?b 30 abr. 2016, ?s 04:25, Preetam Pal escreveu:
> Hi guys,
> 
> I am running glm(y~., data = history,family=binomial)-essentially,
> logistic
> regression for credit scoring (y = 0 or 1). The dataset 'history' has 14
> variables, a few examples:
> history <- read.csv("history.csv". header = TRUE)
> 1> 'income = 100,200,300 (these are numbers in my dataset; however
> interpretation is that these are just tags or labels,for every
> observation,
> its income gets assigned one of these tags)
> 2> 'job' = 'private','government','unemployed','student'
> 
> I want to declare all the regressors and y variables *as factors*
> programmatically. Would be great if anyone can help me with this (idea is
> to loop over variable names and use as.factor - but not sure how to do
> this). Thanks
> 
> Regards,
> Preetam
> -- 
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No.
> N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j.sollari.lopes at gmail.com  Sat Apr 30 14:16:24 2016
From: j.sollari.lopes at gmail.com (Joao Sollari Lopes)
Date: Sat, 30 Apr 2016 13:16:24 +0100
Subject: [R] Package to work with weight based data
In-Reply-To: <mailman.3.1462010401.15131.r-help@r-project.org>
References: <mailman.3.1462010401.15131.r-help@r-project.org>
Message-ID: <5724A218.6090600@gmail.com>

Hi Biswajit Kar,

Take a look at this CRAN Task:
https://cran.r-project.org/web/views/OfficialStatistics.html

Also, I've been re-writing functions of package "ineq" so that they 
accept weights. I can provide those if you find them useful.
Finally, there are a bunch of packages in CRAN that provide plottings 
using weights (e.g. "weights", "Hmisc", "ENmisc", ...)

Joao

On 30-04-2016 11:00, r-help-request at r-project.org wrote:
> Date: Fri, 29 Apr 2016 13:31:43 +0000
> From: "Federman, Douglas"<Douglas.Federman at utoledo.edu>
> To: "'BISWAJIT KAR'"<biswaj41_ssf at jnu.ac.in>,"R-help at r-project.org"
> 	<R-help at r-project.org>
> Subject: Re: [R] Package to work with weight based data
> Message-ID:
> 	<F1065E5D886F4D429259CDEAE3F83CB61B013D8D at msgdb20.utad.utoledo.edu>
> Content-Type: text/plain; charset="us-ascii"
>
> You might look at Anthony D'Amico's work at
>
>      Asdfree.com
>
> There is a lot to learn from here and many of those examples work with weighted survey results
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of BISWAJIT KAR
> Sent: Thursday, April 28, 2016 12:32 PM
> To:R-help at r-project.org
> Subject: [R] Package to work with weight based data
>
> Respected all,
>                      I am working on a socio-economic survey (named as
> National Sample Survey in India provided by National Sample Survey
> Organization, Govt. of India) data of individual as well as households.
> This is a sample survey where stratified random sapling method has been
> used to draw samples. The data set uses 'weights' to estimate figures for
> region, state or country level. In the data set, there is a variable called
> weights and I use the *'weight cases'* function to activate weights
> under *'Data'
>   option *in menu bar in SPSS before generating any table or doing any
> statistical procedure. So, my question is, is there any package/s in R
> where I can use weights and work on this kind of sample survey.
>
> Second thing, is there any package/s to generate multi layer contingency
> table in R or how can I do this in R. For example, one similar kind of
> table is attached here which one is created by SPSS from the above stated
> data-set. Please have a look.
> -- Thanks, *Biswajit Kar* (Research Scholar) Ph. D. Student, Geography 
> Centre for the Study of Regional Development School of Social Sciences 
> Jawaharala Nehru University New Delhi-110067 
> ______________________________________________ R-help at r-project.org 
> mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the 
> posting guide http://www.R-project.org/posting-guide.html and provide 
> commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sat Apr 30 15:43:16 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 30 Apr 2016 13:43:16 +0000
Subject: [R] tcltk: click and return table cell index
In-Reply-To: <CAJeYpE_G=eTLTmOxtOTFhUNQ3LJusrGbwecpu1yXGBg3T47S4g@mail.gmail.com>
References: <CAJeYpE_G=eTLTmOxtOTFhUNQ3LJusrGbwecpu1yXGBg3T47S4g@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F8B8A0@FHSDB2D11-2.csu.mcmaster.ca>

Dear Daniel,

Try 

tkbind(table1, "<Button-1>", function(){
     res <- try(tclvalue(tkindex(table1, "active")), silent=TRUE)
   if (inherits(res, "try-error")) print (NULL)
   else print(res)
})

I put in the calls to print() so that you could see how it works.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dalthorp,
> Daniel
> Sent: April 29, 2016 1:42 PM
> To: r-help at R-project.org (r-help at r-project.org) <r-help at r-project.org>
> Subject: [R] tcltk: click and return table cell index
> 
> I'm struggling mightily with what should be a simple task...when a user clicks
> on a cell in a tcltk table widget, I need to know which cell was clicked.
> 
> One idea that gives a cryptic error:
> tkbind(table1, "<Button-1>", function(x, y){
>   tcl(table1, "index", x, y)
> }
> 
> # x, y give pixel coordinates; "index" should give cell coordinates, but format
> must be correct
> 
> I get an error message:
> 
> wrong # args: should be ".25.1 index <index> ?row|col?".
> 
> To which I respond, "Yes, I know I have the format wrong, but how can I make
> sense of THAT?"
> 
> Does anyone know a simple fix?
> 
> Much appreciated!
> 
> -Dan
> 
> --
> Dan Dalthorp, PhD
> USGS Forest and Rangeland Ecosystem Science Center Forest Sciences Lab, Rm
> 189
> 3200 SW Jefferson Way
> Corvallis, OR 97331
> ph: 541-750-0953
> ddalthorp at usgs.gov
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From giftedlife2014 at gmail.com  Sat Apr 30 15:55:07 2016
From: giftedlife2014 at gmail.com (Ogbos Okike)
Date: Sat, 30 Apr 2016 14:55:07 +0100
Subject: [R] Could not find function "pointsToRaster"
In-Reply-To: <9D970500-C4F5-47B1-AA9C-3447D50A8E02@bigelow.org>
References: <CAC8ss30OF5jHDmvMrXLw0NJt68Ect9FsxYWK+56aH=q0bL7JFw@mail.gmail.com>
	<9D970500-C4F5-47B1-AA9C-3447D50A8E02@bigelow.org>
Message-ID: <CAC8ss33c8=K_-t-uM3pt62csn_BDpv6d2ZAhdJ35ifD7uYCY7A@mail.gmail.com>

Dear All,
Thanks for your inputs. I did replace pointsToRaster () with
raster::rasterize(). Below is part of my script.

But I got another error:
Error in (function (classes, fdef, mtable)  :
  unable to find an inherited method for function ?rasterize? for
signature ?"RasterLayer", "matrix"?

Thank you for more inputs.
Ogbos

 k<-read.table("Lat05w3.txt")
 colnames(k)<-c("y","x")
 xy<-cbind(k$x,k$y)
 library(raster)
 r<-raster()
#library(sp)
pr<-raster::rasterize(r,xy)

#pr<-pointsToRaster(r,xy)

library(maps)
w = map("world")
 wc = cbind(w$x, w$y)
 wc=wc[!is.na(wc[,1]),]
 write.table(wc, file = "my.fileb", sep=" ",row=FALSE,col=FALSE)
 my<-read.table("my.out",col.names=c("a","b"))
 rena = function(X,Z){
Y=rep(NA,length(X))
Y[!is.na(X)]=Z
Y
}




On 4/30/16, Ben Tupper <btupper at bigelow.org> wrote:
> Hi,
>
> A terrific resource for this type of issue (and pretty much anything related
> to R) is http://rseek.org/  I'm sure I use it at least daily.  Check out
> ...
>
> http://rseek.org/?q=pointsToRaster
>
> The first hit is about pointsToRaster() - it has been replaced by
> raster::rasterize()
>
> Cheers,
> Ben
>
>> On Apr 30, 2016, at 4:28 AM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>>
>> Dear All,
>> I have a script that draws longitude and latitude of lightning
>> occurrence. This script was running fine before. But when I changed my
>> system and do a fresh install on another laptop, this error persist.
>> source("script")
>> Error in eval(expr, envir, enclos) :
>>  could not find function "pointsToRaster"
>>
>> I have tried to see if  there is any other package I need to install
>> to take of the problem, I could not see. Already, when I installed
>> raster, it installed its dependencies such as sp.
>> Can any body please bail me out.
>>
>> Thanks
>> Ogbos
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
>


From beingseema03 at gmail.com  Sat Apr 30 15:25:31 2016
From: beingseema03 at gmail.com (seema aswani)
Date: Sat, 30 Apr 2016 18:55:31 +0530
Subject: [R] Graphlet degree distribution agreement in
Message-ID: <CAKPMHirtPLmaZCj-4fmLoPn2=PR2NSBFyF-u5o0=VVBp3YpxsA@mail.gmail.com>

Hi all,

I have created my network using igraph package. It provides graphlet
function to calculate number of graphltes. I want to find graphlet degree
distribution agreement of a graph. How can i achieve that..??
The package ergm.graphlets is there in r but there isn't any examples
available for usage of this package.

My R script is:

library(igraph)
g2 <- graph.formula(A:B - A:C, X:Z - X:Y - X:B, C:Z , C:X )
g2
plot(g2)

Please provide help.

	[[alternative HTML version deleted]]


From suttoncarl at ymail.com  Sat Apr 30 18:00:10 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Sat, 30 Apr 2016 16:00:10 +0000 (UTC)
Subject: [R] selection columns by type,  ie, numeric
References: <474633932.5625338.1462032010535.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <474633932.5625338.1462032010535.JavaMail.yahoo@mail.yahoo.com>

My? thanks to Bill Dunlap and??Giorgio Garziano for? their help.?? It is greatly appreciated.? I works so well, wow.
Carl Sutton CPA

	[[alternative HTML version deleted]]


From maitra.mbox.ignored at inbox.com  Sat Apr 30 19:35:34 2016
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 30 Apr 2016 12:35:34 -0500
Subject: [R] selection columns by type,  ie, numeric
In-Reply-To: <474633932.5625338.1462032010535.JavaMail.yahoo@mail.yahoo.com>
References: <474633932.5625338.1462032010535.JavaMail.yahoo.ref@mail.yahoo.com>
	<474633932.5625338.1462032010535.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160430123534.e6d2b86a279d39c45cb6f8a7@inbox.com>

It would have been more useful to the list and to posterity if you had summarized whatever it was that worked or solved your problem. This note is not very meaningful otherwise.

On Sat, 30 Apr 2016 16:00:10 +0000 (UTC) Carl Sutton via R-help <r-help at r-project.org> wrote:

> My? thanks to Bill Dunlap and??Giorgio Garziano for? their help.?? It is greatly appreciated.? I works so well, wow.
> Carl Sutton CPA
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From tr206 at kent.ac.uk  Sat Apr 30 19:48:35 2016
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sat, 30 Apr 2016 17:48:35 +0000
Subject: [R] 3D surface plot
Message-ID: <57782dcbd9f0427b878f48a7d93fec85@ex13-live-mbn1.ad.kent.ac.uk>

Dear R users,

I am trying to generate a 3D surface plot given the inflator formula in the attached file.

Now, I want to create a 3D plot showing how Delta changes with the values of Abs(B) and sigma. The other variables in the formula are constant. Delta is calculated daily therefore the subscript t which denotes the day. I have used different functions and different packages but I get either wrong results or an error in R.

Does anyone have an idea which function I should use?

Furthermore, I think I have to create a matrix using the formula above but I do not know how to do that in this connection. Can any body help me with the code for this purpose?

Thanks a lot in advance.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: buvar_countercyclical_capital_buffer_17_1419139702[1].pdf
Type: application/pdf
Size: 87302 bytes
Desc: buvar_countercyclical_capital_buffer_17_1419139702[1].pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20160430/33079f29/attachment.pdf>

From bgunter.4567 at gmail.com  Sat Apr 30 20:05:50 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 30 Apr 2016 11:05:50 -0700
Subject: [R] 3D surface plot
In-Reply-To: <57782dcbd9f0427b878f48a7d93fec85@ex13-live-mbn1.ad.kent.ac.uk>
References: <57782dcbd9f0427b878f48a7d93fec85@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <CAGxFJbSu_zn=xa-m0t=vc4RKPa1RFEMR8Du=KUQWKKPOZM0FFQ@mail.gmail.com>

There are several packages and functions that can do this (e.g. search
on "3d surface plots" at rseek.org or internet search engine).

You are much more likely to get a helpful answer if you provide a
minimal data set (e.g. via dput() ) and code from any function(s) and
package(s) that you tried. A pdf with a formula in it is not very
r-helper friendly.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 30, 2016 at 10:48 AM, T.Riedle <tr206 at kent.ac.uk> wrote:
> Dear R users,
>
> I am trying to generate a 3D surface plot given the inflator formula in the attached file.
>
> Now, I want to create a 3D plot showing how Delta changes with the values of Abs(B) and sigma. The other variables in the formula are constant. Delta is calculated daily therefore the subscript t which denotes the day. I have used different functions and different packages but I get either wrong results or an error in R.
>
> Does anyone have an idea which function I should use?
>
> Furthermore, I think I have to create a matrix using the formula above but I do not know how to do that in this connection. Can any body help me with the code for this purpose?
>
> Thanks a lot in advance.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From miaojpm at gmail.com  Sat Apr 30 20:47:15 2016
From: miaojpm at gmail.com (jpm miao)
Date: Sat, 30 Apr 2016 11:47:15 -0700
Subject: [R] How to print the frequency table (produced by the command
 "table" to Excel
In-Reply-To: <CA+8X3fVbX1ptDr_xaaQyCrbskqQNqBS0mN8fm8Utm-y2rnbfwA@mail.gmail.com>
References: <CABcx46D_isFkbjCB_uN-epssdoOsnyx34uu7ey-aQHkkWOkk2Q@mail.gmail.com>
	<CA+8X3fVbX1ptDr_xaaQyCrbskqQNqBS0mN8fm8Utm-y2rnbfwA@mail.gmail.com>
Message-ID: <CABcx46AsBxGTurGu9hJ9+XUFg+o0hyQYt6k=qiP4TWJWQc=imQ@mail.gmail.com>

Jim,

   Thanks for creating such a fantastic package "prettyR".
   I want to print the pretty frequency table (with row total and column
total) to an excel (or csv ) file. Is it possible?
>alphatab

A B Total
A 8 10 18
B 7 5 12
C 9 11 20
Total 24 26 50

   Two issues I encountered (See the attached csv file).
1. When I tried to print the above table to csv file, all elements on the
same row are printed in one cell.
2. If I write "delim.table(alpha tab)", the table is distorted (see
attached). Of course, I can adjust it manually but sometimes the number of
files is big.

    Thanks!

Miao

> alpha1<-sample(LETTERS[1:3],50,TRUE)
> alpha2<-sample(LETTERS[1:2],50,TRUE)
>
> alphas<-data.frame(alpha1,alpha2)
> alphatab<-xtab(alpha1~alpha2,alphas)
Crosstabulation of alpha1 by alpha2
alpha2
alpha1      A      B
A      8     10     18
   44.44  55.56      -
   33.33  38.46  36.00

B      7      5     12
   58.33  41.67      -
   29.17  19.23  24.00

C      9     11     20
      45     55      -
   37.50  42.31  40.00

      24     26     50
      48     52    100
> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
alphatab

A B Total
A 8 10 18
B 7 5 12
C 9 11 20
Total 24 26 50

> sink("temp_table3.csv")
> delim.xtab(alphatab,pct=NA,interdigitate=TRUE)
> sink()
> sink("temp_table3.csv", append=TRUE)
> delim.table(alphatab)
> sink()
> sink("temp_table3.csv", append=TRUE)
> delim.table(alphatab)
> sink()
> ?delim.xtab


2016-04-26 16:14 GMT-07:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi jpm miao,
> You can get CSV files that can be imported into Excel like this:
>
> library(prettyR)
> sink("excel_table1.csv")
> delim.table(table(df[,c("y","z")]))
> sink()
> sink("excel_table2.csv")
> delim.table(as.data.frame(table(df[,c("y","z")])),label="")
> sink()
> sink("excel_table3.csv")
> delim.table(as.matrix(table(df[,c("y","z")])),label="")
> sink()
>
> Jim
>
> On Wed, Apr 27, 2016 at 8:35 AM, jpm miao <miaojpm at gmail.com> wrote:
> > Hi,
> >
> >    How could we print the frequency table (produced by "table") to an
> Excel
> > file?
> >    Is there an easy way to do so? Thanks,
> >
> > Miao
> >
> >> df <- data.frame(x = 1:3, y = 3:1, z = letters[1:3])
> >
> >> table(df[,c("y","z")])
> >    z
> > y   a b c
> >   1 0 0 1
> >   2 0 1 0
> >   3 1 0 0
> >> test<-table(df[,c("y","z")])
> >> as.data.frame(test)
> >   y z Freq
> > 1 1 a    0
> > 2 2 a    0
> > 3 3 a    1
> > 4 1 b    0
> > 5 2 b    1
> > 6 3 b    0
> > 7 1 c    1
> > 8 2 c    0
> > 9 3 c    0
> >> as.matrix(test)
> >    z
> > y   a b c
> >   1 0 0 1
> >   2 0 1 0
> >   3 1 0 0
> >> testm<-as.matrix(test)
> >> testm
> >    z
> > y   a b c
> >   1 0 0 1
> >   2 0 1 0
> >   3 1 0 0
> >> typeof(testm)
> > [1] "integer"
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

From chalabi.elahe at yahoo.de  Sat Apr 30 23:38:47 2016
From: chalabi.elahe at yahoo.de (chalabi.elahe at yahoo.de)
Date: Sat, 30 Apr 2016 21:38:47 +0000 (UTC)
Subject: [R] how to use AND in grepl
References: <1930216316.8287881.1462052327296.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1930216316.8287881.1462052327296.JavaMail.yahoo@mail.yahoo.com>

Hi all,

I have one factor variable in my df and I want to extract the names from it which contain both "t2" and "pd":

  'data.frame': 36919 obs. of 162 variables 
   $TE                :int 38,41,11,52,48,75,..... 
   $TR                :int 100,210,548,546,..... 
   $Command          :factor W/2229 levels "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...

I have tried this but I did not get result: 
   
  t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))


does anyone know how to apply AND in grepl?

Thanks
Elahe


From wdunlap at tibco.com  Sat Apr 30 23:55:00 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 30 Apr 2016 14:55:00 -0700
Subject: [R] how to use AND in grepl
In-Reply-To: <1930216316.8287881.1462052327296.JavaMail.yahoo@mail.yahoo.com>
References: <1930216316.8287881.1462052327296.JavaMail.yahoo.ref@mail.yahoo.com>
	<1930216316.8287881.1462052327296.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAF8bMcYwOtm+BR5M4MzZMHNXnp-SeY2a3bW2cFPE2Lqwn0Xb8w@mail.gmail.com>

Your code looks fine to me.  What did t2pd look like?

I tried reproducing the problem in R-3.2.4(Revised) and everything worked
(although the output of str() looked a bit different - perhaps you have an
old version of R)

> df <- data.frame(TE=1:10, TR=101:110,
Command=c("pd_local_abdomen_t2","knee_pd_t1_localize","PD_localize_tre_t2","t2_localize_PD")[rep(1:4,len=10)])
> str(df)
'data.frame':   10 obs. of  3 variables:
 $ TE     : int  1 2 3 4 5 6 7 8 9 10
 $ TR     : int  101 102 103 104 105 106 107 108 109 110
 $ Command: Factor w/ 4 levels "knee_pd_t1_localize",..: 2 1 3 4 2 1 3 4 2 1
> subset(df,grepl("t2",Command) & grepl("pd",Command))
  TE  TR             Command
1  1 101 pd_local_abdomen_t2
5  5 105 pd_local_abdomen_t2
9  9 109 pd_local_abdomen_t2
> subset(df,grepl("t2",Command,ignore.case=TRUE) &
grepl("pd",Command,ignore.case=TRUE))
  TE  TR             Command
1  1 101 pd_local_abdomen_t2
3  3 103  PD_localize_tre_t2
4  4 104      t2_localize_PD
5  5 105 pd_local_abdomen_t2
7  7 107  PD_localize_tre_t2
8  8 108      t2_localize_PD
9  9 109 pd_local_abdomen_t2


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Apr 30, 2016 at 2:38 PM, ch.elahe via R-help <r-help at r-project.org>
wrote:

> Hi all,
>
> I have one factor variable in my df and I want to extract the names from
> it which contain both "t2" and "pd":
>
>   'data.frame': 36919 obs. of 162 variables
>    $TE                :int 38,41,11,52,48,75,.....
>    $TR                :int 100,210,548,546,.....
>    $Command          :factor W/2229 levels
> "_localize_PD","_localize_tre_t2","_abdomen_t1_seq","knee_pd_t1_localize","pd_local_abdomen_t2"...
>
> I have tried this but I did not get result:
>
>   t2pd=subset(df,grepl("t2",Command) & grepl("pd",Command))
>
>
> does anyone know how to apply AND in grepl?
>
> Thanks
> Elahe
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mike at hsm.org.uk  Sat Apr 30 21:58:40 2016
From: mike at hsm.org.uk (Mike Smith)
Date: Sat, 30 Apr 2016 20:58:40 +0100
Subject: [R] Removing NAs from dataframe  (for use in Vioplot)
Message-ID: <142423783.20160430205840@hsm.org.uk>

Hi

First post and a relative R newbie....

I am using the vioplot library to produce some violin plots. I have an input CSV with columns off irregular length that contain NAs. I want to strip the NAs out and produce a multiple violin plot automatically labelled using the headers. At the moment I do this

Code:?
ds1 = read.csv("http://www.lecturematerials.co.uk/data/spelling.csv")
library(vioplot)
y6<-na.omit(ds1$y6)
y5<-na.omit(ds1$y5)
y4<-na.omit(ds1$y4)
y3<-na.omit(ds1$y3)
y2<-na.omit(ds1$y2)
y1<-na.omit(ds1$y1)
vioplot(y6, y5, y4,y3,y2,y1,horizontal=TRUE, names=c("Y6", "Y5","Y4","Y3","Y2","Y1"), col = "lightblue")


Two queries:

1. Is there a more elegant way of automatically stripping the NAs, passing the columns to the function along with the header names??

2. Can I easily add the sample size to each violin plotted??

thanks

mike
						


---
Mike Smith


From wenbostar at gmail.com  Sat Apr 30 19:41:47 2016
From: wenbostar at gmail.com (wenbo)
Date: Sun, 1 May 2016 01:41:47 +0800
Subject: [R] Install R (version 3.2.5) in CentOS platform
Message-ID: <CA+swpQcDfqODkt8oSwoS7Ng5-SU3GUz9JC5F8wmXYfV=Bi=3fA@mail.gmail.com>

Hi,
I want to install the latest R in CentOS. Below is the command line:

./configure --prefix=/home/fino/R/3.2.5/
--with-tcl-config=/home/fino/software/tcl8.6.1/lib/tclConfig.sh
--with-tk-config=
/home/fino
/software/tk8.6.1/lib/tkConfig.sh --with-readline=yes
--with-cairo=yes --without-x

Below is the output message when ran the above command:
...
checking whether pkg-config knows about cairo and pango... no
checking whether pkg-config knows about cairo... yes
checking whether cairo is >= 1.2 and works... no
...

  C++ compiler:              g++  -g -O2
  C++ 11 compiler:           g++  -std=c++0x -g -O2
  Fortran 90/95 compiler:    gfortran -g -O2
  Obj-C compiler:            gcc -g -O2 -fobjc-exceptions

  Interfaces supported:      tcltk
  External libraries:        readline, zlib, bzlib, lzma, PCRE
  Additional capabilities:   PNG, JPEG, TIFF, NLS
  Options enabled:           shared BLAS, R profiling

  Capabilities skipped:      cairo, ICU
  Options not enabled:       memory profiling

  Recommended packages:      yes

After I installed the R and entered R:
> capabilities()
       jpeg         png        tiff       tcltk         X11        aqua
      FALSE       FALSE       FALSE        TRUE       FALSE       FALSE
   http/ftp     sockets      libxml        fifo      cledit       iconv
       TRUE        TRUE        TRUE        TRUE        TRUE        TRUE
        NLS     profmem       cairo         ICU long.double     libcurl
       TRUE       FALSE       FALSE       FALSE        TRUE       FALSE

The png doesn't work. Does anyone know how to solve this problem?

Best regards!
Bo

	[[alternative HTML version deleted]]


