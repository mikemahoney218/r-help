From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 04:18:06 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 21:18:06 -0500
Subject: [R] How to extract information from .Rdata format
Message-ID: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>

Hello,

I have this file:
> a=load("paired_example.Rdata")
> a
[1] "rawdata"   "treatment" "patient"

I can extract "rawdata" with:
 dat<-local(get(load("paired_example.Rdata")))

Can you please advise how would I extract in data frame "treatment"
and "patient"?

Thanks
Ana


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 04:35:05 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 31 Jul 2020 19:35:05 -0700
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
Message-ID: <CAGxFJbRnqAZ6nrOi-KbWA_V6W8+pdc7fH3fd7tSuhC-pQ2qNMQ@mail.gmail.com>

What does
str(a)

give?


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jul 31, 2020 at 7:18 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have this file:
> > a=load("paired_example.Rdata")
> > a
> [1] "rawdata"   "treatment" "patient"
>
> I can extract "rawdata" with:
>  dat<-local(get(load("paired_example.Rdata")))
>
> Can you please advise how would I extract in data frame "treatment"
> and "patient"?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sat Aug  1 04:37:38 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 31 Jul 2020 22:37:38 -0400
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
Message-ID: <CAM_vjumi5Ds2Kkzz=24wTkNwei6Kf-r9_Ev8wRZwS92S3s2SOg@mail.gmail.com>

Hi Ana,

You are making this far too complicated.

load("paired_example.Rdata")

ls()

str(rawdata)
str(treatment)
str(patient)

load() puts all of them into your current environment. If you assign
the result of load() to something, in your example a, that object
contains the names of the objects, but the objects themselves are in
your workspace.

You should probably try a basic R tutorial; it will help you with this
kind of thing.

Sarah

On Fri, Jul 31, 2020 at 10:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have this file:
> > a=load("paired_example.Rdata")
> > a
> [1] "rawdata"   "treatment" "patient"
>
> I can extract "rawdata" with:
>  dat<-local(get(load("paired_example.Rdata")))
>
> Can you please advise how would I extract in data frame "treatment"
> and "patient"?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 04:53:47 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 21:53:47 -0500
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
Message-ID: <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>

Hi Bert,

it gives me this:

> a=load("paired_example.Rdata")
> str(a)
 chr [1:3] "rawdata" "treatment" "patient"

I don't know how to extract "treatment" for example in a data frame.

I tried this but of no help.
> b=a[[2]]
> b
[1] "treatment"

> str(treatment)
 chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...

but this is not the format I need.

On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have this file:
> > a=load("paired_example.Rdata")
> > a
> [1] "rawdata"   "treatment" "patient"
>
> I can extract "rawdata" with:
>  dat<-local(get(load("paired_example.Rdata")))
>
> Can you please advise how would I extract in data frame "treatment"
> and "patient"?
>
> Thanks
> Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 04:59:41 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 21:59:41 -0500
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
Message-ID: <CAF9-5jPLcdh-H7-1edD9GbeP37Xc0rJBtakA=bo0NwST7hSYEw@mail.gmail.com>

It seems that "treatment" and "patient" are just vectors.

> treatment
 [1] "treat"   "treat"   "treat"   "treat"   "treat"   "control" "control"
 [8] "control" "control" "control"
> patient
 [1] "a" "b" "c" "d" "e" "a" "b" "c" "d" "e"

On Fri, Jul 31, 2020 at 9:53 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Bert,
>
> it gives me this:
>
> > a=load("paired_example.Rdata")
> > str(a)
>  chr [1:3] "rawdata" "treatment" "patient"
>
> I don't know how to extract "treatment" for example in a data frame.
>
> I tried this but of no help.
> > b=a[[2]]
> > b
> [1] "treatment"
>
> > str(treatment)
>  chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>
> but this is not the format I need.
>
> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have this file:
> > > a=load("paired_example.Rdata")
> > > a
> > [1] "rawdata"   "treatment" "patient"
> >
> > I can extract "rawdata" with:
> >  dat<-local(get(load("paired_example.Rdata")))
> >
> > Can you please advise how would I extract in data frame "treatment"
> > and "patient"?
> >
> > Thanks
> > Ana


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 06:05:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 31 Jul 2020 21:05:47 -0700
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
Message-ID: <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>

Sarah has explained all.

I agree with her about the need for tutorials also. This list cannot
substitute for such homework on your own.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jul 31, 2020 at 7:55 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi Bert,
>
> it gives me this:
>
> > a=load("paired_example.Rdata")
> > str(a)
>  chr [1:3] "rawdata" "treatment" "patient"
>
> I don't know how to extract "treatment" for example in a data frame.
>
> I tried this but of no help.
> > b=a[[2]]
> > b
> [1] "treatment"
>
> > str(treatment)
>  chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>
> but this is not the format I need.
>
> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >
> > Hello,
> >
> > I have this file:
> > > a=load("paired_example.Rdata")
> > > a
> > [1] "rawdata"   "treatment" "patient"
> >
> > I can extract "rawdata" with:
> >  dat<-local(get(load("paired_example.Rdata")))
> >
> > Can you please advise how would I extract in data frame "treatment"
> > and "patient"?
> >
> > Thanks
> > Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 06:30:33 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 23:30:33 -0500
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
 <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>
Message-ID: <CAF9-5jM01B-SAPAEifUoVLqLCYNUHH+v3stxoKZa5q1J=E=n8w@mail.gmail.com>

do you think that this is useful output from Basics of R?
> load("paired_example.Rdata")
> str(rawdata)
 num [1:4482, 1:10] 46 4 3 48 1 4 0 60 0 12 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:4482] "gene1" "gene2" "gene3" "gene4" ...
  ..$ : chr [1:10] "a.cancer" "b.cancer" "c.cancer" "d.cancer" ..

I think this one is better:
> dat<-local(get(load("paired_example.Rdata")))
> head(dat)
      a.cancer b.cancer c.cancer d.cancer e.cancer a.normal b.normal c.normal
gene1       46        4       33        5        8       61        5       42
gene2        4        0        2        1        5       24        1       30
gene3        3        4        4        2        1        3        0        0
gene4       48        2       10        0        6        9        4        3
gene5        1        5        2        3        6        1        0        3
gene6        4        0        0        1        1        4        0        7

On Fri, Jul 31, 2020 at 11:05 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Sarah has explained all.
>
> I agree with her about the need for tutorials also. This list cannot substitute for such homework on your own.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jul 31, 2020 at 7:55 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hi Bert,
>>
>> it gives me this:
>>
>> > a=load("paired_example.Rdata")
>> > str(a)
>>  chr [1:3] "rawdata" "treatment" "patient"
>>
>> I don't know how to extract "treatment" for example in a data frame.
>>
>> I tried this but of no help.
>> > b=a[[2]]
>> > b
>> [1] "treatment"
>>
>> > str(treatment)
>>  chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>>
>> but this is not the format I need.
>>
>> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >
>> > Hello,
>> >
>> > I have this file:
>> > > a=load("paired_example.Rdata")
>> > > a
>> > [1] "rawdata"   "treatment" "patient"
>> >
>> > I can extract "rawdata" with:
>> >  dat<-local(get(load("paired_example.Rdata")))
>> >
>> > Can you please advise how would I extract in data frame "treatment"
>> > and "patient"?
>> >
>> > Thanks
>> > Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  1 07:56:42 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Aug 2020 06:56:42 +0100
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jM01B-SAPAEifUoVLqLCYNUHH+v3stxoKZa5q1J=E=n8w@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
 <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>
 <CAF9-5jM01B-SAPAEifUoVLqLCYNUHH+v3stxoKZa5q1J=E=n8w@mail.gmail.com>
Message-ID: <1e68876b-6a1c-390a-16ca-8bdbf0b4ef37@sapo.pt>

Hello,

Inline.

?s 05:30 de 01/08/2020, Ana Marija escreveu:
> do you think that this is useful output from Basics of R?

Actually, the answer will be yes, I do. Explanation follows.

>> load("paired_example.Rdata")
>> str(rawdata)
>   num [1:4482, 1:10] 46 4 3 48 1 4 0 60 0 12 ...
>   - attr(*, "dimnames")=List of 2
>    ..$ : chr [1:4482] "gene1" "gene2" "gene3" "gene4" ...
>    ..$ : chr [1:10] "a.cancer" "b.cancer" "c.cancer" "d.cancer" ..

This says that rawdata is a numeric matrix with 4482 rows and 10 columns.
And that an useful attribute, dimnames, is set.

>
> I think this one is better:
>> dat<-local(get(load("paired_example.Rdata")))
>> head(dat)
>        a.cancer b.cancer c.cancer d.cancer e.cancer a.normal b.normal c.normal
> gene1       46        4       33        5        8       61        5       42
> gene2        4        0        2        1        5       24        1       30
> gene3        3        4        4        2        1        3        0        0
> gene4       48        2       10        0        6        9        4        3
> gene5        1        5        2        3        6        1        0        3
> gene6        4        0        0        1        1        4        0        7

This gives a better *visual* representation of the data, rawdata is an 
object of class "matrix" and it now *looks* like a table. We are used to 
seeing matrices printed like this so it's very easy to understand what 
rawdata is about.
Note that this one only has 8 columns, did you process the data before 
calling head()?

Anyway, why not run both str(rawdata) and head(rawdata)? Not only I 
don't see a conflict, they are even complementary to one another.

As for the original question, Sarah did answer to it, when you load() a 
.Rdata or .RData file the objects are created in a certain environment 
and their names are returned, you don't need get(), it's redundant.

Hope this helps,

Rui Barradas
>
> On Fri, Jul 31, 2020 at 11:05 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Sarah has explained all.
>>
>> I agree with her about the need for tutorials also. This list cannot substitute for such homework on your own.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Jul 31, 2020 at 7:55 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>> Hi Bert,
>>>
>>> it gives me this:
>>>
>>>> a=load("paired_example.Rdata")
>>>> str(a)
>>>   chr [1:3] "rawdata" "treatment" "patient"
>>>
>>> I don't know how to extract "treatment" for example in a data frame.
>>>
>>> I tried this but of no help.
>>>> b=a[[2]]
>>>> b
>>> [1] "treatment"
>>>
>>>> str(treatment)
>>>   chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>>>
>>> but this is not the format I need.
>>>
>>> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>>> Hello,
>>>>
>>>> I have this file:
>>>>> a=load("paired_example.Rdata")
>>>>> a
>>>> [1] "rawdata"   "treatment" "patient"
>>>>
>>>> I can extract "rawdata" with:
>>>>   dat<-local(get(load("paired_example.Rdata")))
>>>>
>>>> Can you please advise how would I extract in data frame "treatment"
>>>> and "patient"?
>>>>
>>>> Thanks
>>>> Ana
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Sat Aug  1 13:01:08 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Sat, 1 Aug 2020 16:01:08 +0500
Subject: [R] RNA Seq Analysis in R
Message-ID: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>

I choose microarray data GSE75693 of 30 patients with stable kidney
transplantation and 15 with BKVN to identify differentially expressed genes
(DEGs). I performed this in GEO2R and find R script there and Runs R script
Successfully on R studio as well. The R script is :

 # Differential expression analysis with limma

library(Biobase)
library(GEOquery)
library(limma)
# load series and platform data from GEO

gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE)if
(length(gset) > 1) idx <- grep("GPL570", attr(gset, "names")) else idx
<- 1
gset <- gset[[idx]]
# make proper column names to match toptable
fvarLabels(gset) <- make.names(fvarLabels(gset))
# group names for all samples
gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
        "1111111111XXXXXXXXXXXXXXXXXXX")
sml <- c()for (i in 1:nchar(gsms)) { sml[i] <- substr(gsms,i,i) }
# eliminate samples marked as "X"
sel <- which(sml != "X")
sml <- sml[sel]
gset <- gset[ ,sel]
# log2 transform
exprs(gset) <- log2(exprs(gset))
# set up the data and proceed with analysis
sml <- paste("G", sml, sep="")    # set group names
fl <- as.factor(sml)
gset$description <- fl
design <- model.matrix(~ description + 0, gset)
colnames(design) <- levels(fl)
fit <- lmFit(gset, design)
cont.matrix <- makeContrasts(G1-G0, levels=design)
fit2 <- contrasts.fit(fit, cont.matrix)
fit2 <- eBayes(fit2, 0.01)
tT <- topTable(fit2, adjust="fdr", sort.by="B", number=1250)

tT <- subset(tT,
select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))
DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2)

After running this no genes are found plz help me

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  1 19:13:56 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 01 Aug 2020 10:13:56 -0700
Subject: [R] RNA Seq Analysis in R
In-Reply-To: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
References: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
Message-ID: <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>

https://www.bioconductor.org/help/

On August 1, 2020 4:01:08 AM PDT, Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>I choose microarray data GSE75693 of 30 patients with stable kidney
>transplantation and 15 with BKVN to identify differentially expressed
>genes
>(DEGs). I performed this in GEO2R and find R script there and Runs R
>script
>Successfully on R studio as well. The R script is :
>
> # Differential expression analysis with limma
>
>library(Biobase)
>library(GEOquery)
>library(limma)
># load series and platform data from GEO
>
>gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE)if
>(length(gset) > 1) idx <- grep("GPL570", attr(gset, "names")) else idx
><- 1
>gset <- gset[[idx]]
># make proper column names to match toptable
>fvarLabels(gset) <- make.names(fvarLabels(gset))
># group names for all samples
>gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
>        "1111111111XXXXXXXXXXXXXXXXXXX")
>sml <- c()for (i in 1:nchar(gsms)) { sml[i] <- substr(gsms,i,i) }
># eliminate samples marked as "X"
>sel <- which(sml != "X")
>sml <- sml[sel]
>gset <- gset[ ,sel]
># log2 transform
>exprs(gset) <- log2(exprs(gset))
># set up the data and proceed with analysis
>sml <- paste("G", sml, sep="")    # set group names
>fl <- as.factor(sml)
>gset$description <- fl
>design <- model.matrix(~ description + 0, gset)
>colnames(design) <- levels(fl)
>fit <- lmFit(gset, design)
>cont.matrix <- makeContrasts(G1-G0, levels=design)
>fit2 <- contrasts.fit(fit, cont.matrix)
>fit2 <- eBayes(fit2, 0.01)
>tT <- topTable(fit2, adjust="fdr", sort.by="B", number=1250)
>
>tT <- subset(tT,
>select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))
>DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2)
>
>After running this no genes are found plz help me
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Aug  1 19:39:58 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 1 Aug 2020 12:39:58 -0500
Subject: [R] Dependent Variable in Logistic Regression
Message-ID: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>

Dear friends,

Hope you are doing great. I want to fit a logistic regression in R, where
the dependent variable is the covid status (I used 1 for covid positives,
and 0 for covid negatives), but when I ran the glm, R complains that I
should make the dependent variable a factor.

What would be more advisable, to keep the dependent variable with 1s and
0s, or code it as yes/no and then make it a factor?

Any guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Sat Aug  1 19:50:39 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Sat, 1 Aug 2020 22:50:39 +0500
Subject: [R] DEG Analysis in R through Bioconductor
Message-ID: <CAG0CrLj03yQCXpnQ8dk4-tdnp4_T2y4J8CYDdg680qgpBZ3RCg@mail.gmail.com>

Basically I want to redo the methodology of the paper:
https://www.nature.com/articles/s41598-018-23492-2
I choose microarray data GSE75693 of 30 patients with stable kidney
transplantation and 15 with BKVN to identify differentially expressed genes
(DEGs). I performed this in GEO2R and find R script there and Runs R script
Successfully on R studio as well. The R script is :
Differential expression analysis with limma

library(Biobase) library(GEOquery) library(limma)
load series and platform data from GEO

gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE) if (length(gset)
> 1) idx <- grep("GPL570", attr(gset, "names")) else idx <- 1 gset <-
gset[[idx]]
make proper column names to match toptable

fvarLabels(gset) <- make.names(fvarLabels(gset))
group names for all samples

gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
"1111111111XXXXXXXXXXXXXXXXXXX") sml <- c() for (i in 1:nchar(gsms)) {
sml[i] <- substr(gsms,i,i) }
eliminate samples marked as "X"

sel <- which(sml != "X") sml <- sml[sel] gset <- gset[ ,sel]
log2 transform

exprs(gset) <- log2(exprs(gset))
set up the data and proceed with analysis

sml <- paste("G", sml, sep="") # set group names fl <- as.factor(sml)
gset$description <- fl design <- model.matrix(~ description + 0, gset)
colnames(design) <- levels(fl) fit <- lmFit(gset, design) cont.matrix <-
makeContrasts(G1-G0, levels=design) fit2 <- contrasts.fit(fit, cont.matrix)
fit2 <- eBayes(fit2, 0.01) tT <- topTable(fit2, adjust="fdr", sort.by="B",
number=1250) tT <- subset(tT,
select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))

DEGs = subset(tT, P.Value < 0.01 & logFC >2)

*Problem :*

But the problem is that I can't find any DEGs based on the threshold P <
0.01 and fold change >2.0 plz help me

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 19:59:36 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 10:59:36 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>

x <- factor(0:1)
x <- factor("yes","no")

will produce identical results up to labeling.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friends,
>
> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
>
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?
>
> Any guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Aug  1 20:03:06 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 1 Aug 2020 11:03:06 -0700 (PDT)
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2008011101340.5024@salmo.appl-ecosys.com>

On Sat, 1 Aug 2020, Paul Bernal wrote:

> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
>
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?

Paul,

1 or 0 are equivalent to yes or no, success or failure. All are nomminal
variables so all should be factors, regardless of the coding.

Rich


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Aug  1 20:04:17 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 1 Aug 2020 13:04:17 -0500
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
Message-ID: <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>

Hi Bert,

Thank you for the kind reply.

But what if I don't turn the variable into a factor. Let's say that in
excel I just coded the variable as 1s and 0s and just imported the dataset
into R and fitted the logistic regression without turning any categorical
variable or dummy variable into a factor?

Does R requires every dummy variable to be treated as a factor?

Best regards,

Paul

El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
bgunter.4567 at gmail.com> escribi?:

> x <- factor(0:1)
> x <- factor("yes","no")
>
> will produce identical results up to labeling.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear friends,
>>
>> Hope you are doing great. I want to fit a logistic regression in R, where
>> the dependent variable is the covid status (I used 1 for covid positives,
>> and 0 for covid negatives), but when I ran the glm, R complains that I
>> should make the dependent variable a factor.
>>
>> What would be more advisable, to keep the dependent variable with 1s and
>> 0s, or code it as yes/no and then make it a factor?
>>
>> Any guidance will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:22:20 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:22:20 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
Message-ID: <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>

... yes, but so does lm() for a categorical **INdependent** variable with
more than 2 numerically labeled levels. n levels  = (n-1) df for a
categorical covariate, but 1 for a continuous one (unless more complex
models are explicitly specified of course). As I said, the OP seems
confused about whether he is referring to the response or covariates. Or
maybe he just made the same typo I did.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
malone at malonequantitative.com> wrote:

> No, R does not. glm() does in order to do logistic regression.
>
> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
>> Hi Bert,
>>
>> Thank you for the kind reply.
>>
>> But what if I don't turn the variable into a factor. Let's say that in
>> excel I just coded the variable as 1s and 0s and just imported the dataset
>> into R and fitted the logistic regression without turning any categorical
>> variable or dummy variable into a factor?
>>
>> Does R requires every dummy variable to be treated as a factor?
>>
>> Best regards,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>> bgunter.4567 at gmail.com> escribi?:
>>
>> > x <- factor(0:1)
>> > x <- factor("yes","no")
>> >
>> > will produce identical results up to labeling.
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> and
>> > sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>> > wrote:
>> >
>> >> Dear friends,
>> >>
>> >> Hope you are doing great. I want to fit a logistic regression in R,
>> where
>> >> the dependent variable is the covid status (I used 1 for covid
>> positives,
>> >> and 0 for covid negatives), but when I ran the glm, R complains that I
>> >> should make the dependent variable a factor.
>> >>
>> >> What would be more advisable, to keep the dependent variable with 1s
>> and
>> >> 0s, or code it as yes/no and then make it a factor?
>> >>
>> >> Any guidance will be greatly appreciated,
>> >>
>> >> Best regards,
>> >>
>> >> Paul
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Patrick S. Malone, Ph.D., Malone Quantitative
> NEW Service Models: http://malonequantitative.com
>
> He/Him/His
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Aug  1 20:25:57 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 1 Aug 2020 13:25:57 -0500
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
Message-ID: <CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>

Dear friend,

I am aware that I have a binomial dependent variable, which is covid status
(1 if covid positive, and 0 otherwise).

My question was if R requires to turn a binomial response variable into a
factor or not, that's all.

Cheers,

Paul

El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter <bgunter.4567 at gmail.com>
escribi?:

> ... yes, but so does lm() for a categorical **INdependent** variable with
> more than 2 numerically labeled levels. n levels  = (n-1) df for a
> categorical covariate, but 1 for a continuous one (unless more complex
> models are explicitly specified of course). As I said, the OP seems
> confused about whether he is referring to the response or covariates. Or
> maybe he just made the same typo I did.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
> malone at malonequantitative.com> wrote:
>
>> No, R does not. glm() does in order to do logistic regression.
>>
>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>
>>> Hi Bert,
>>>
>>> Thank you for the kind reply.
>>>
>>> But what if I don't turn the variable into a factor. Let's say that in
>>> excel I just coded the variable as 1s and 0s and just imported the
>>> dataset
>>> into R and fitted the logistic regression without turning any categorical
>>> variable or dummy variable into a factor?
>>>
>>> Does R requires every dummy variable to be treated as a factor?
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>> bgunter.4567 at gmail.com> escribi?:
>>>
>>> > x <- factor(0:1)
>>> > x <- factor("yes","no")
>>> >
>>> > will produce identical results up to labeling.
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming along
>>> and
>>> > sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> > wrote:
>>> >
>>> >> Dear friends,
>>> >>
>>> >> Hope you are doing great. I want to fit a logistic regression in R,
>>> where
>>> >> the dependent variable is the covid status (I used 1 for covid
>>> positives,
>>> >> and 0 for covid negatives), but when I ran the glm, R complains that I
>>> >> should make the dependent variable a factor.
>>> >>
>>> >> What would be more advisable, to keep the dependent variable with 1s
>>> and
>>> >> 0s, or code it as yes/no and then make it a factor?
>>> >>
>>> >> Any guidance will be greatly appreciated,
>>> >>
>>> >> Best regards,
>>> >>
>>> >> Paul
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Patrick S. Malone, Ph.D., Malone Quantitative
>> NEW Service Models: http://malonequantitative.com
>>
>> He/Him/His
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:13:59 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:13:59 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
Message-ID: <CAGxFJbRR3_Bukb4p26j1TmMHnMeJUw235BykntnLsPRFaJbYug@mail.gmail.com>

Sorry, typo.My first sentences should read:

"You appear to be confusing a binomial **response** with categorical
"independent variables." glm() of course fits continuous or categorical
independent variables."

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:11 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You appear to be confusing a binomial **response** with categorical
> "dependent variables." glm() of course fits continuous or categorical
> dependent variables. If a continuous dependent variable has only 2 values,
> the results for glm() will be the same whether or not it is considered to
> be continuous or categorical, though you may not recognize it as such.
>
> This discussion has already wandered off topic to statistical issues. I
> will not comment further on or off list. I suggest you consult a good
> reference on linear/generalized linear models or talk with a local
> statistician.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:04 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Hi Bert,
>>
>> Thank you for the kind reply.
>>
>> But what if I don't turn the variable into a factor. Let's say that in
>> excel I just coded the variable as 1s and 0s and just imported the dataset
>> into R and fitted the logistic regression without turning any categorical
>> variable or dummy variable into a factor?
>>
>> Does R requires every dummy variable to be treated as a factor?
>>
>> Best regards,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>> bgunter.4567 at gmail.com> escribi?:
>>
>>> x <- factor(0:1)
>>> x <- factor("yes","no")
>>>
>>> will produce identical results up to labeling.
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>
>>>> Dear friends,
>>>>
>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>> where
>>>> the dependent variable is the covid status (I used 1 for covid
>>>> positives,
>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>>> should make the dependent variable a factor.
>>>>
>>>> What would be more advisable, to keep the dependent variable with 1s and
>>>> 0s, or code it as yes/no and then make it a factor?
>>>>
>>>> Any guidance will be greatly appreciated,
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:15:08 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:15:08 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
Message-ID: <CAGxFJbR_Nt_ZfB6sYL0md2GkS58f6=5EDM6vG0sYRTu+87Ld_g@mail.gmail.com>

... and further:
" If a continuous independent variable has only 2 values,..."

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:11 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You appear to be confusing a binomial **response** with categorical
> "dependent variables." glm() of course fits continuous or categorical
> dependent variables. If a continuous dependent variable has only 2 values,
> the results for glm() will be the same whether or not it is considered to
> be continuous or categorical, though you may not recognize it as such.
>
> This discussion has already wandered off topic to statistical issues. I
> will not comment further on or off list. I suggest you consult a good
> reference on linear/generalized linear models or talk with a local
> statistician.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:04 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Hi Bert,
>>
>> Thank you for the kind reply.
>>
>> But what if I don't turn the variable into a factor. Let's say that in
>> excel I just coded the variable as 1s and 0s and just imported the dataset
>> into R and fitted the logistic regression without turning any categorical
>> variable or dummy variable into a factor?
>>
>> Does R requires every dummy variable to be treated as a factor?
>>
>> Best regards,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>> bgunter.4567 at gmail.com> escribi?:
>>
>>> x <- factor(0:1)
>>> x <- factor("yes","no")
>>>
>>> will produce identical results up to labeling.
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>
>>>> Dear friends,
>>>>
>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>> where
>>>> the dependent variable is the covid status (I used 1 for covid
>>>> positives,
>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>>> should make the dependent variable a factor.
>>>>
>>>> What would be more advisable, to keep the dependent variable with 1s and
>>>> 0s, or code it as yes/no and then make it a factor?
>>>>
>>>> Any guidance will be greatly appreciated,
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Aug  1 20:15:29 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sat, 1 Aug 2020 14:15:29 -0400
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
Message-ID: <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>

No, R does not. glm() does in order to do logistic regression.

On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Hi Bert,
>
> Thank you for the kind reply.
>
> But what if I don't turn the variable into a factor. Let's say that in
> excel I just coded the variable as 1s and 0s and just imported the dataset
> into R and fitted the logistic regression without turning any categorical
> variable or dummy variable into a factor?
>
> Does R requires every dummy variable to be treated as a factor?
>
> Best regards,
>
> Paul
>
> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
> bgunter.4567 at gmail.com> escribi?:
>
> > x <- factor(0:1)
> > x <- factor("yes","no")
> >
> > will produce identical results up to labeling.
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
> > wrote:
> >
> >> Dear friends,
> >>
> >> Hope you are doing great. I want to fit a logistic regression in R,
> where
> >> the dependent variable is the covid status (I used 1 for covid
> positives,
> >> and 0 for covid negatives), but when I ran the glm, R complains that I
> >> should make the dependent variable a factor.
> >>
> >> What would be more advisable, to keep the dependent variable with 1s and
> >> 0s, or code it as yes/no and then make it a factor?
> >>
> >> Any guidance will be greatly appreciated,
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:11:15 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:11:15 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
Message-ID: <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>

You appear to be confusing a binomial **response** with categorical
"dependent variables." glm() of course fits continuous or categorical
dependent variables. If a continuous dependent variable has only 2 values,
the results for glm() will be the same whether or not it is considered to
be continuous or categorical, though you may not recognize it as such.

This discussion has already wandered off topic to statistical issues. I
will not comment further on or off list. I suggest you consult a good
reference on linear/generalized linear models or talk with a local
statistician.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:04 AM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Hi Bert,
>
> Thank you for the kind reply.
>
> But what if I don't turn the variable into a factor. Let's say that in
> excel I just coded the variable as 1s and 0s and just imported the dataset
> into R and fitted the logistic regression without turning any categorical
> variable or dummy variable into a factor?
>
> Does R requires every dummy variable to be treated as a factor?
>
> Best regards,
>
> Paul
>
> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
> bgunter.4567 at gmail.com> escribi?:
>
>> x <- factor(0:1)
>> x <- factor("yes","no")
>>
>> will produce identical results up to labeling.
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>
>>> Dear friends,
>>>
>>> Hope you are doing great. I want to fit a logistic regression in R, where
>>> the dependent variable is the covid status (I used 1 for covid positives,
>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>> should make the dependent variable a factor.
>>>
>>> What would be more advisable, to keep the dependent variable with 1s and
>>> 0s, or code it as yes/no and then make it a factor?
>>>
>>> Any guidance will be greatly appreciated,
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug  1 21:01:29 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 1 Aug 2020 15:01:29 -0400
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
 <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
Message-ID: <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>

Dear Paul,

I think that this thread has gotten unnecessarily complicated. The 
answer, as is easily demonstrated, is that a binary response for a 
binomial GLM in glm() may be a factor, a numeric variable, or a logical 
variable, with identical results; for example:

--------------- snip -------------

 > set.seed(123)

 > head(x <- rnorm(100))
[1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  1.71506499

 > head(y <- rbinom(100, 1, 1/(1 + exp(-x))))
[1] 0 1 1 1 1 0

 > head(yf <- as.factor(y))
[1] 0 1 1 1 1 0
Levels: 0 1

 > head(yl <- y == 1)
[1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE

 > glm(y ~ x, family=binomial)

Call:  glm(formula = y ~ x, family = binomial)

Coefficients:
(Intercept)            x
      0.3995       1.1670

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    134.6
Residual Deviance: 114.9 	AIC: 118.9

 > glm(yf ~ x, family=binomial)

Call:  glm(formula = yf ~ x, family = binomial)

Coefficients:
(Intercept)            x
      0.3995       1.1670

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    134.6
Residual Deviance: 114.9 	AIC: 118.9

 > glm(yl ~ x, family=binomial)

Call:  glm(formula = yl ~ x, family = binomial)

Coefficients:
(Intercept)            x
      0.3995       1.1670

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    134.6
Residual Deviance: 114.9 	AIC: 118.9

--------------- snip -------------

The original poster claimed to have encountered an error with a 0/1 
numeric response, but didn't show any data or even a command. I suspect 
that the response was a character variable, but of course can't really 
know that.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-08-01 2:25 p.m., Paul Bernal wrote:
> Dear friend,
> 
> I am aware that I have a binomial dependent variable, which is covid status
> (1 if covid positive, and 0 otherwise).
> 
> My question was if R requires to turn a binomial response variable into a
> factor or not, that's all.
> 
> Cheers,
> 
> Paul
> 
> El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter <bgunter.4567 at gmail.com>
> escribi?:
> 
>> ... yes, but so does lm() for a categorical **INdependent** variable with
>> more than 2 numerically labeled levels. n levels  = (n-1) df for a
>> categorical covariate, but 1 for a continuous one (unless more complex
>> models are explicitly specified of course). As I said, the OP seems
>> confused about whether he is referring to the response or covariates. Or
>> maybe he just made the same typo I did.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
>> malone at malonequantitative.com> wrote:
>>
>>> No, R does not. glm() does in order to do logistic regression.
>>>
>>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>
>>>> Hi Bert,
>>>>
>>>> Thank you for the kind reply.
>>>>
>>>> But what if I don't turn the variable into a factor. Let's say that in
>>>> excel I just coded the variable as 1s and 0s and just imported the
>>>> dataset
>>>> into R and fitted the logistic regression without turning any categorical
>>>> variable or dummy variable into a factor?
>>>>
>>>> Does R requires every dummy variable to be treated as a factor?
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>>
>>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>>> bgunter.4567 at gmail.com> escribi?:
>>>>
>>>>> x <- factor(0:1)
>>>>> x <- factor("yes","no")
>>>>>
>>>>> will produce identical results up to labeling.
>>>>>
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>> and
>>>>> sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Dear friends,
>>>>>>
>>>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>> where
>>>>>> the dependent variable is the covid status (I used 1 for covid
>>>> positives,
>>>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>>>>> should make the dependent variable a factor.
>>>>>>
>>>>>> What would be more advisable, to keep the dependent variable with 1s
>>>> and
>>>>>> 0s, or code it as yes/no and then make it a factor?
>>>>>>
>>>>>> Any guidance will be greatly appreciated,
>>>>>>
>>>>>> Best regards,
>>>>>>
>>>>>> Paul
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> Patrick S. Malone, Ph.D., Malone Quantitative
>>> NEW Service Models: http://malonequantitative.com
>>>
>>> He/Him/His
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  1 21:09:47 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Aug 2020 20:09:47 +0100
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <0f71fcba-2503-6373-5c41-03abefc16e85@sapo.pt>

Hello,

 From the documentation, help('glm'):


      Details

A typical predictor has the form|response ~ terms|where|response|is the 
(numeric) response vector and|terms|is a series of terms which specifies 
a linear predictor for|response|. 
For|binomial|and|quasibinomial|families the response can also be 
specified as a|factor 
<http://127.0.0.1:11611/library/stats/help/factor>|(when the first level 
denotes failure and all others success) or as a two-column matrix with 
the columns giving the numbers of successes and failures. A terms 
specification of the form|first + second|indicates all the terms 
in|first|together with all the terms in|second|with any duplicates removed.


There is no need for the response to be a factor, it is optional, the 
wording is very clear,

"For|binomial|and|quasibinomial|families the response *can* also be 
specified as a|factor <http://127.0.0.1:11611/library/stats/help/factor>"|

And with binary, numeric responses I cannot reproduce the warning 
message, the models fit silently.


Hope this helps,

Rui Barradas




?s 18:39 de 01/08/2020, Paul Bernal escreveu:
> Dear friends,
>
> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
>
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?
>
> Any guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Aug  1 20:38:16 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sat, 1 Aug 2020 14:38:16 -0400
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
Message-ID: <CAJc=yOGL3O83tQs3r1nfp6hkjGJn7RjsS9jQ3wQyNYWrS0DKaA@mail.gmail.com>

I didn't mean to imply that was the only time that it was required, only
that it's not universal in R.

On Sat, Aug 1, 2020 at 2:22 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... yes, but so does lm() for a categorical **INdependent** variable with
> more than 2 numerically labeled levels. n levels  = (n-1) df for a
> categorical covariate, but 1 for a continuous one (unless more complex
> models are explicitly specified of course). As I said, the OP seems
> confused about whether he is referring to the response or covariates. Or
> maybe he just made the same typo I did.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
> malone at malonequantitative.com> wrote:
>
>> No, R does not. glm() does in order to do logistic regression.
>>
>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>
>>> Hi Bert,
>>>
>>> Thank you for the kind reply.
>>>
>>> But what if I don't turn the variable into a factor. Let's say that in
>>> excel I just coded the variable as 1s and 0s and just imported the
>>> dataset
>>> into R and fitted the logistic regression without turning any categorical
>>> variable or dummy variable into a factor?
>>>
>>> Does R requires every dummy variable to be treated as a factor?
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>> bgunter.4567 at gmail.com> escribi?:
>>>
>>> > x <- factor(0:1)
>>> > x <- factor("yes","no")
>>> >
>>> > will produce identical results up to labeling.
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming along
>>> and
>>> > sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> > wrote:
>>> >
>>> >> Dear friends,
>>> >>
>>> >> Hope you are doing great. I want to fit a logistic regression in R,
>>> where
>>> >> the dependent variable is the covid status (I used 1 for covid
>>> positives,
>>> >> and 0 for covid negatives), but when I ran the glm, R complains that I
>>> >> should make the dependent variable a factor.
>>> >>
>>> >> What would be more advisable, to keep the dependent variable with 1s
>>> and
>>> >> 0s, or code it as yes/no and then make it a factor?
>>> >>
>>> >> Any guidance will be greatly appreciated,
>>> >>
>>> >> Best regards,
>>> >>
>>> >> Paul
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Patrick S. Malone, Ph.D., Malone Quantitative
>> NEW Service Models: http://malonequantitative.com
>>
>> He/Him/His
>>
>

-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  1 21:48:12 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Aug 2020 20:48:12 +0100
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
 <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
 <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
Message-ID: <feffe1d6-fc95-29ed-24bc-7e8c5419b959@sapo.pt>

Hello,

Inline.

?s 20:01 de 01/08/2020, John Fox escreveu:
> Dear Paul,
>
> I think that this thread has gotten unnecessarily complicated. The 
> answer, as is easily demonstrated, is that a binary response for a 
> binomial GLM in glm() may be a factor, a numeric variable, or a 
> logical variable, with identical results; for example:
>
> --------------- snip -------------
>
> > set.seed(123)
>
> > head(x <- rnorm(100))
> [1] -0.56047565 -0.23017749? 1.55870831? 0.07050839? 0.12928774 
> 1.71506499
>
> > head(y <- rbinom(100, 1, 1/(1 + exp(-x))))
> [1] 0 1 1 1 1 0
>
> > head(yf <- as.factor(y))
> [1] 0 1 1 1 1 0
> Levels: 0 1
>
> > head(yl <- y == 1)
> [1] FALSE? TRUE? TRUE? TRUE? TRUE FALSE
>
> > glm(y ~ x, family=binomial)
>
> Call:? glm(formula = y ~ x, family = binomial)
>
> Coefficients:
> (Intercept)??????????? x
> ???? 0.3995?????? 1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);? 98 Residual
> Null Deviance:??????? 134.6
> Residual Deviance: 114.9???? AIC: 118.9
>
> > glm(yf ~ x, family=binomial)
>
> Call:? glm(formula = yf ~ x, family = binomial)
>
> Coefficients:
> (Intercept)??????????? x
> ???? 0.3995?????? 1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);? 98 Residual
> Null Deviance:??????? 134.6
> Residual Deviance: 114.9???? AIC: 118.9
>
> > glm(yl ~ x, family=binomial)
>
> Call:? glm(formula = yl ~ x, family = binomial)
>
> Coefficients:
> (Intercept)??????????? x
> ???? 0.3995?????? 1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);? 98 Residual
> Null Deviance:??????? 134.6
> Residual Deviance: 114.9???? AIC: 118.9
>
> --------------- snip -------------
>
> The original poster claimed to have encountered an error with a 0/1 
> numeric response, but didn't show any data or even a command. I 
> suspect that the response was a character variable, but of course 
> can't really know that.

So continuing with your example:

 > head(yc <- as.character(y))
[1] "0" "1" "1" "1" "1" "0"
 > glm(yc ~ x, family=binomial)
Error in weights * y : non-numeric argument to binary operator


But the OP says that

[...] R complains that I should make the dependent variable a factor.

That is not what the error message says, it "asks" for a numeric 
argument to the '*' operator.
We haven't seen the exact R message yet, so, like others have said, the 
OP should post it along with code.

Hope this helps,

Rui Barradas

>
> Best,
> ?John
>
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
> On 2020-08-01 2:25 p.m., Paul Bernal wrote:
>> Dear friend,
>>
>> I am aware that I have a binomial dependent variable, which is covid 
>> status
>> (1 if covid positive, and 0 otherwise).
>>
>> My question was if R requires to turn a binomial response variable 
>> into a
>> factor or not, that's all.
>>
>> Cheers,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter 
>> <bgunter.4567 at gmail.com>
>> escribi?:
>>
>>> ... yes, but so does lm() for a categorical **INdependent** variable 
>>> with
>>> more than 2 numerically labeled levels. n levels? = (n-1) df for a
>>> categorical covariate, but 1 for a continuous one (unless more complex
>>> models are explicitly specified of course). As I said, the OP seems
>>> confused about whether he is referring to the response or 
>>> covariates. Or
>>> maybe he just made the same typo I did.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming 
>>> along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
>>> malone at malonequantitative.com> wrote:
>>>
>>>> No, R does not. glm() does in order to do logistic regression.
>>>>
>>>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Bert,
>>>>>
>>>>> Thank you for the kind reply.
>>>>>
>>>>> But what if I don't turn the variable into a factor. Let's say 
>>>>> that in
>>>>> excel I just coded the variable as 1s and 0s and just imported the
>>>>> dataset
>>>>> into R and fitted the logistic regression without turning any 
>>>>> categorical
>>>>> variable or dummy variable into a factor?
>>>>>
>>>>> Does R requires every dummy variable to be treated as a factor?
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Paul
>>>>>
>>>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>>>> bgunter.4567 at gmail.com> escribi?:
>>>>>
>>>>>> x <- factor(0:1)
>>>>>> x <- factor("yes","no")
>>>>>>
>>>>>> will produce identical results up to labeling.
>>>>>>
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming 
>>>>>> along
>>>>> and
>>>>>> sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Dear friends,
>>>>>>>
>>>>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>>> where
>>>>>>> the dependent variable is the covid status (I used 1 for covid
>>>>> positives,
>>>>>>> and 0 for covid negatives), but when I ran the glm, R complains 
>>>>>>> that I
>>>>>>> should make the dependent variable a factor.
>>>>>>>
>>>>>>> What would be more advisable, to keep the dependent variable 
>>>>>>> with 1s
>>>>> and
>>>>>>> 0s, or code it as yes/no and then make it a factor?
>>>>>>>
>>>>>>> Any guidance will be greatly appreciated,
>>>>>>>
>>>>>>> Best regards,
>>>>>>>
>>>>>>> Paul
>>>>>>>
>>>>>>> ???????? [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>
>>>>> ???????? [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>> -- 
>>>> Patrick S. Malone, Ph.D., Malone Quantitative
>>>> NEW Service Models: http://malonequantitative.com
>>>>
>>>> He/Him/His
>>>>
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Sat Aug  1 21:52:19 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Sat, 1 Aug 2020 15:52:19 -0400
Subject: [R] RNA Seq Analysis in R
In-Reply-To: <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>
References: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
 <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>
Message-ID: <a43bbcd2-1063-69f9-09d4-234aec529cff@molbio.mgh.harvard.edu>

As with the previous post, I agree that Bioconductor will be a better 
place to ask this question.

As a quick thought you also might try to adjust the p-value in the last 
line:

DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2). You could play 
around with the P.Value, 0.01 is pretty low, you could try 0.05 and 
maybe abs(logFC) > 1.

But, first you should try to print out tT with something like 
write.table(tT, file = TopTable.txt, sep = "\t").

This will write out tT to a tab-delimited text file (in the directory 
that you are working in) that you can import into Excel and then inspect 
the logFC and p-values for the top 1250 genes.

Matthew

On 8/1/20 1:13 PM, Jeff Newmiller wrote:
>          External Email - Use Caution
>
> https://www.bioconductor.org/help/
>
> On August 1, 2020 4:01:08 AM PDT, Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>> I choose microarray data GSE75693 of 30 patients with stable kidney
>> transplantation and 15 with BKVN to identify differentially expressed
>> genes
>> (DEGs). I performed this in GEO2R and find R script there and Runs R
>> script
>> Successfully on R studio as well. The R script is :
>>
>> # Differential expression analysis with limma
>>
>> library(Biobase)
>> library(GEOquery)
>> library(limma)
>> # load series and platform data from GEO
>>
>> gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE)if
>> (length(gset) > 1) idx <- grep("GPL570", attr(gset, "names")) else idx
>> <- 1
>> gset <- gset[[idx]]
>> # make proper column names to match toptable
>> fvarLabels(gset) <- make.names(fvarLabels(gset))
>> # group names for all samples
>> gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
>>         "1111111111XXXXXXXXXXXXXXXXXXX")
>> sml <- c()for (i in 1:nchar(gsms)) { sml[i] <- substr(gsms,i,i) }
>> # eliminate samples marked as "X"
>> sel <- which(sml != "X")
>> sml <- sml[sel]
>> gset <- gset[ ,sel]
>> # log2 transform
>> exprs(gset) <- log2(exprs(gset))
>> # set up the data and proceed with analysis
>> sml <- paste("G", sml, sep="")    # set group names
>> fl <- as.factor(sml)
>> gset$description <- fl
>> design <- model.matrix(~ description + 0, gset)
>> colnames(design) <- levels(fl)
>> fit <- lmFit(gset, design)
>> cont.matrix <- makeContrasts(G1-G0, levels=design)
>> fit2 <- contrasts.fit(fit, cont.matrix)
>> fit2 <- eBayes(fit2, 0.01)
>> tT <- topTable(fit2, adjust="fdr", sort.by="B", number=1250)
>>
>> tT <- subset(tT,
>> select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))
>> DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2)
>>
>> After running this no genes are found plz help me
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Sat Aug  1 22:09:47 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Sat, 1 Aug 2020 13:09:47 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
 <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
 <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
Message-ID: <CAF8bMcYBu3c3stF3H=s_N-Anu2DFQ2BNDSzjSVRFjveBqEDENg@mail.gmail.com>

I like using a logical response in cases like this, but put its
construction in the formula so it is unambiguous when I look at the
results later.
> d <- data.frame(Covid=c("Pos","Pos","Neg","Pos","Neg","Neg"), Age=41:46)
> glm(family=binomial, data=d, Covid=="Pos"~Age)

Call:  glm(formula = Covid == "Pos" ~ Age, family = binomial, data = d)

Coefficients:
(Intercept)          Age
     52.810       -1.214

Degrees of Freedom: 5 Total (i.e. Null);  4 Residual
Null Deviance:      8.318
Residual Deviance: 4.956        AIC: 8.956


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Aug 1, 2020 at 12:21 PM John Fox <jfox at mcmaster.ca> wrote:
>
> Dear Paul,
>
> I think that this thread has gotten unnecessarily complicated. The
> answer, as is easily demonstrated, is that a binary response for a
> binomial GLM in glm() may be a factor, a numeric variable, or a logical
> variable, with identical results; for example:
>
> --------------- snip -------------
>
>  > set.seed(123)
>
>  > head(x <- rnorm(100))
> [1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  1.71506499
>
>  > head(y <- rbinom(100, 1, 1/(1 + exp(-x))))
> [1] 0 1 1 1 1 0
>
>  > head(yf <- as.factor(y))
> [1] 0 1 1 1 1 0
> Levels: 0 1
>
>  > head(yl <- y == 1)
> [1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE
>
>  > glm(y ~ x, family=binomial)
>
> Call:  glm(formula = y ~ x, family = binomial)
>
> Coefficients:
> (Intercept)            x
>       0.3995       1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
> Null Deviance:      134.6
> Residual Deviance: 114.9        AIC: 118.9
>
>  > glm(yf ~ x, family=binomial)
>
> Call:  glm(formula = yf ~ x, family = binomial)
>
> Coefficients:
> (Intercept)            x
>       0.3995       1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
> Null Deviance:      134.6
> Residual Deviance: 114.9        AIC: 118.9
>
>  > glm(yl ~ x, family=binomial)
>
> Call:  glm(formula = yl ~ x, family = binomial)
>
> Coefficients:
> (Intercept)            x
>       0.3995       1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
> Null Deviance:      134.6
> Residual Deviance: 114.9        AIC: 118.9
>
> --------------- snip -------------
>
> The original poster claimed to have encountered an error with a 0/1
> numeric response, but didn't show any data or even a command. I suspect
> that the response was a character variable, but of course can't really
> know that.
>
> Best,
>   John
>
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
> On 2020-08-01 2:25 p.m., Paul Bernal wrote:
> > Dear friend,
> >
> > I am aware that I have a binomial dependent variable, which is covid status
> > (1 if covid positive, and 0 otherwise).
> >
> > My question was if R requires to turn a binomial response variable into a
> > factor or not, that's all.
> >
> > Cheers,
> >
> > Paul
> >
> > El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter <bgunter.4567 at gmail.com>
> > escribi?:
> >
> >> ... yes, but so does lm() for a categorical **INdependent** variable with
> >> more than 2 numerically labeled levels. n levels  = (n-1) df for a
> >> categorical covariate, but 1 for a continuous one (unless more complex
> >> models are explicitly specified of course). As I said, the OP seems
> >> confused about whether he is referring to the response or covariates. Or
> >> maybe he just made the same typo I did.
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
> >> malone at malonequantitative.com> wrote:
> >>
> >>> No, R does not. glm() does in order to do logistic regression.
> >>>
> >>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
> >>> wrote:
> >>>
> >>>> Hi Bert,
> >>>>
> >>>> Thank you for the kind reply.
> >>>>
> >>>> But what if I don't turn the variable into a factor. Let's say that in
> >>>> excel I just coded the variable as 1s and 0s and just imported the
> >>>> dataset
> >>>> into R and fitted the logistic regression without turning any categorical
> >>>> variable or dummy variable into a factor?
> >>>>
> >>>> Does R requires every dummy variable to be treated as a factor?
> >>>>
> >>>> Best regards,
> >>>>
> >>>> Paul
> >>>>
> >>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
> >>>> bgunter.4567 at gmail.com> escribi?:
> >>>>
> >>>>> x <- factor(0:1)
> >>>>> x <- factor("yes","no")
> >>>>>
> >>>>> will produce identical results up to labeling.
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming along
> >>>> and
> >>>>> sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>>
> >>>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> Dear friends,
> >>>>>>
> >>>>>> Hope you are doing great. I want to fit a logistic regression in R,
> >>>> where
> >>>>>> the dependent variable is the covid status (I used 1 for covid
> >>>> positives,
> >>>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
> >>>>>> should make the dependent variable a factor.
> >>>>>>
> >>>>>> What would be more advisable, to keep the dependent variable with 1s
> >>>> and
> >>>>>> 0s, or code it as yes/no and then make it a factor?
> >>>>>>
> >>>>>> Any guidance will be greatly appreciated,
> >>>>>>
> >>>>>> Best regards,
> >>>>>>
> >>>>>> Paul
> >>>>>>
> >>>>>>          [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>>
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>> --
> >>> Patrick S. Malone, Ph.D., Malone Quantitative
> >>> NEW Service Models: http://malonequantitative.com
> >>>
> >>> He/Him/His
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Sun Aug  2 01:34:18 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sun, 2 Aug 2020 01:34:18 +0200
Subject: [R] RNA Seq Analysis in R
In-Reply-To: <a43bbcd2-1063-69f9-09d4-234aec529cff@molbio.mgh.harvard.edu>
References: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
 <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>
 <a43bbcd2-1063-69f9-09d4-234aec529cff@molbio.mgh.harvard.edu>
Message-ID: <20200801233418.GA303455@posteo.no>

On 2020-08-01 15:52 -0400, Matthew McCormack wrote:
| On 8/1/20 1:13 PM, Jeff Newmiller wrote:
| | On August 1, 2020 4:01:08 AM PDT, Anas Jamshed wrote:
| | | I performed this in GEO2R and find 
| | | R script there and Runs R script 

Anas, how did you come up with this 
script at all by reading the article?

How can you be sure that 
limma::lmFit/limma::eBayes procedure was 
the one Jia et al. used in their 
article?

The three author emails are listed on 
page 1 of the article.

| | | After running this no genes are 
| | | found plz help me
| |
| | https://www.bioconductor.org/help/
| 
| As with the previous post, I agree 
| that Bioconductor will be a better 
| place to ask this question.
| 
| As a quick thought you also might try 
| to adjust the p-value in the last 
| line:
 
This is the "distribution" of 
possible log2 Fold Change in tT:

	> tab <- table(signif(tT$logFC, 1))
	> tab[as.character(sort(
	+   as.numeric(names(tab)),
	+   decreasing=F))]
	 -0.5  -0.4  -0.3  -0.2  -0.1 -0.09   0.1
	    1    25   158   376   185     7    49
	  0.2   0.3   0.4   0.5   0.6   0.7
	  250   140    42    11     4     2

... knowing full well ?regulated? is 
supposed to be abs(logFC)>1, we can 
instead select above .5 there to get 
the few up-regulated ones ...

	> rownames(tT) <- NULL
	> subset(x=tT,
	+   subset=
	+     adj.P.Val < .01 &
	+     abs(logFC) > .5,
	+   select=adj.P.Val:Gene.symbol)
	       adj.P.Val      P.Value        t
	4   7.457501e-05 5.894525e-09 7.075753
	5   7.457501e-05 7.877860e-09 6.993182
	9   1.170092e-04 1.926078e-08 6.738920
	29  2.565179e-04 1.432599e-07 6.168230
	42  3.202947e-04 2.511181e-07 6.008168
	60  4.039665e-04 4.433103e-07 5.845695
	343 1.043185e-03 6.555444e-06 5.066127
	475 1.391091e-03 1.208538e-05 4.885755
	            B     logFC       Gene.symbol
	4   10.264385 0.6225559             REG1A
	5    9.996103 0.6630585              TNMD
	9    9.168329 0.5138611            NKAIN4
	29   7.306904 0.5538644              C1QB
	42   6.785641 0.5530439             ISG20
	60   6.257651 0.5082288              GZMH
	343  3.755608 0.5543619 MIR155///MIR155HG
	475  3.188253 0.7264114            CXCL13

... none of which are in the network of 
important proteins in figure 5 on page 6.

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200802/99d754d3/attachment.sig>

From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  2 02:46:40 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 2 Aug 2020 12:46:40 +1200
Subject: [R] [FORGED]  Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>


On 2/08/20 5:39 am, Paul Bernal wrote:

> Dear friends,
> 
> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
> 
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?
> 
> Any guidance will be greatly appreciated,


There have been many responses to this post, the majority of them being 
confusing and off the point.

BOTTOM LINE:  R/glm() does *NOT* complain that one "should make the 
dependent variable a factor".   This is bovine faecal output.

As Rui Barradas has pointed out (alternatively: RTFM!) when you fit a 
Bernoulli model using glm(), your response/dependent variable is allowed 
to be

     * a numeric variable with values 0 or 1
     * a logical variable
     * a factor with two levels

The OP presumably fed glm() a *character* vector with values "0" and 
"1".  Doing *this* will cause glm() to whinge.

I reiterate:  RTFM!!!  (And perhaps learn to distinguish between 
character vectors and factors.)

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @purd|e@@ @end|ng |rom gm@||@com  Sun Aug  2 05:13:51 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 2 Aug 2020 15:13:51 +1200
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
Message-ID: <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>

That's a bit harsh.
Isn't the best advice here, to post a reproducible example...
Which I believe has been mentioned.

Also, I'd strongly encourage people to use package+function name, for
this sort of thing.

    stats::glm

As there are many R functions for GLMs...


On Sun, Aug 2, 2020 at 12:47 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> On 2/08/20 5:39 am, Paul Bernal wrote:
>
> > Dear friends,
> >
> > Hope you are doing great. I want to fit a logistic regression in R, where
> > the dependent variable is the covid status (I used 1 for covid positives,
> > and 0 for covid negatives), but when I ran the glm, R complains that I
> > should make the dependent variable a factor.
> >
> > What would be more advisable, to keep the dependent variable with 1s and
> > 0s, or code it as yes/no and then make it a factor?
> >
> > Any guidance will be greatly appreciated,
>
>
> There have been many responses to this post, the majority of them being
> confusing and off the point.
>
> BOTTOM LINE:  R/glm() does *NOT* complain that one "should make the
> dependent variable a factor".   This is bovine faecal output.
>
> As Rui Barradas has pointed out (alternatively: RTFM!) when you fit a
> Bernoulli model using glm(), your response/dependent variable is allowed
> to be
>
>      * a numeric variable with values 0 or 1
>      * a logical variable
>      * a factor with two levels
>
> The OP presumably fed glm() a *character* vector with values "0" and
> "1".  Doing *this* will cause glm() to whinge.
>
> I reiterate:  RTFM!!!  (And perhaps learn to distinguish between
> character vectors and factors.)
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From herd_dog @end|ng |rom cox@net  Sun Aug  2 18:24:24 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Sun, 2 Aug 2020 09:24:24 -0700
Subject: [R] Parsing a Date
Message-ID: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>

Below is some Weather Service data.  I would like to parse the forecast date field into four different columns:

    Year
    Month
    Day
    Hour

I would like to drop the final four zeros.  Any suggestions?

forecast.date                 levels      lon           lat         HGT      RH          TMP       UGRD    VGRD
1 2020-08-01 12:00:00 1000 mb -113.130 33.6335 75.5519 49.6484 305.495 1.40155 2.23264
2 2020-08-01 12:00:00 1000 mb -113.111 33.5142 75.9582 51.0234 305.245 1.65155 2.23264
3 2020-08-01 12:00:00 1000 mb -113.092 33.3948 76.3957 52.7734 305.057 1.90155 2.23264
4 2020-08-01 12:00:00 1000 mb -112.987 33.6495 75.9269 49.1484 305.745 1.90155 2.04514
5 2020-08-01 12:00:00 1000 mb -112.968 33.5301 76.3019 50.2734 305.495 2.08905 1.98264

Philip Heinrich



	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sun Aug  2 18:33:17 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 2 Aug 2020 19:33:17 +0300
Subject: [R] Parsing a Date
In-Reply-To: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
Message-ID: <CAGgJW76f=AScpyt0sp41wgWR-RvvuGcGVoCRAAoUK5nG_j-dBw@mail.gmail.com>

If the forecast.date column is of type character you can use lubridate to
do this:

> library(lubridate)
> a <- "2020-08-01 12:00:00"
> year(a)
# [1] 2020
> month(a)
# [1] 8

etc


On Sun, Aug 2, 2020 at 7:24 PM Philip <herd_dog at cox.net> wrote:

> Below is some Weather Service data.  I would like to parse the forecast
> date field into four different columns:
>
>     Year
>     Month
>     Day
>     Hour
>
> I would like to drop the final four zeros.  Any suggestions?
>
> forecast.date                 levels      lon           lat         HGT
>   RH          TMP       UGRD    VGRD
> 1 2020-08-01 12:00:00 1000 mb -113.130 33.6335 75.5519 49.6484 305.495
> 1.40155 2.23264
> 2 2020-08-01 12:00:00 1000 mb -113.111 33.5142 75.9582 51.0234 305.245
> 1.65155 2.23264
> 3 2020-08-01 12:00:00 1000 mb -113.092 33.3948 76.3957 52.7734 305.057
> 1.90155 2.23264
> 4 2020-08-01 12:00:00 1000 mb -112.987 33.6495 75.9269 49.1484 305.745
> 1.90155 2.04514
> 5 2020-08-01 12:00:00 1000 mb -112.968 33.5301 76.3019 50.2734 305.495
> 2.08905 1.98264
>
> Philip Heinrich
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug  2 18:56:21 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 02 Aug 2020 09:56:21 -0700
Subject: [R] Parsing a Date
In-Reply-To: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
Message-ID: <887C5EFE-C578-45A9-BAEF-91DDC29B6F67@dcn.davis.ca.us>

Learn to post plain text and use dput to include data:

dta <- structure(list(forecast.date = c("2020-08-01 12:00:00", "2020-08-01 12:00:00", "2020-08-01 12:00:00", "2020-08-01 12:00:00", "2020-08-01 12:00:00" ), levels = c("1000 mb", "1000 mb", "1000 mb", "1000 mb", "1000 mb" ), lon = c(-113.13, -113.111, -113.092, -112.987, -112.968), lat = c(33.6335, 33.5142, 33.3948, 33.6495, 33.5301), HGT = c(75.5519, 75.9582, 76.3957, 75.9269, 76.3019), RH = c(49.6484, 51.0234, 52.7734, 49.1484, 50.2734), TMP = c(305.495, 305.245, 305.057, 305.745, 305.495), UGRD = c(1.40155, 1.65155, 1.90155, 1.90155, 2.08905), VGRD = c(2.23264, 2.23264, 2.23264, 2.04514, 1.98264 )), .Names = c("forecast.date", "levels", "lon", "lat", "HGT", "RH", "TMP", "UGRD", "VGRD"), class = "data.frame", row.names = c(NA, -5L))

dta$Year <- as.integer( substr( dta$forecast.date, 1, 4 ) )
dta$Month <- as.integer( substr( dta$forecast.date, 6, 7 ) )
dta$Day <- as.integer( substr( dta$forecast.date, 9, 10 ) )
dta$Hour <- as.integer( substr( dta$forecast.date, 12, 13 ) )
dta


On August 2, 2020 9:24:24 AM PDT, Philip <herd_dog at cox.net> wrote:
>Below is some Weather Service data.  I would like to parse the forecast
>date field into four different columns:
>
>    Year
>    Month
>    Day
>    Hour
>
>I would like to drop the final four zeros.  Any suggestions?
>
>forecast.date                 levels      lon           lat         HGT
>     RH          TMP       UGRD    VGRD
>1 2020-08-01 12:00:00 1000 mb -113.130 33.6335 75.5519 49.6484 305.495
>1.40155 2.23264
>2 2020-08-01 12:00:00 1000 mb -113.111 33.5142 75.9582 51.0234 305.245
>1.65155 2.23264
>3 2020-08-01 12:00:00 1000 mb -113.092 33.3948 76.3957 52.7734 305.057
>1.90155 2.23264
>4 2020-08-01 12:00:00 1000 mb -112.987 33.6495 75.9269 49.1484 305.745
>1.90155 2.04514
>5 2020-08-01 12:00:00 1000 mb -112.968 33.5301 76.3019 50.2734 305.495
>2.08905 1.98264
>
>Philip Heinrich
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Sun Aug  2 19:26:48 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sun, 2 Aug 2020 19:26:48 +0200
Subject: [R] Parsing a Date
In-Reply-To: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
Message-ID: <20200802172648.GE1827@posteo.no>

On 2020-08-02 09:24 -0700, Philip wrote:
| Below is some Weather Service data.  I 
| would like to parse the forecast date 
| field into four different columns: 
| Year, Month, Day, Hour

Dear Philip,

I'm largely re-iterating Eric and Jeff's 
excellent solutions:

	> dat <- structure(list(forecast.date =
	+ c("2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00"
	+ ), TMP = c("305.495", "305.245",
	+ "305.057", "305.745", "305.495"
	+ )), row.names = c(NA, 5L),
	+ class = "data.frame")
	> t(apply(simplify2array(
	+   strsplit(dat$forecast.date, "-| |:")),
	+   2, as.numeric))
	     [,1] [,2] [,3] [,4] [,5] [,6]
	[1,] 2020    8    1   12    0    0
	[2,] 2020    8    1   12    0    0
	[3,] 2020    8    1   12    0    0
	[4,] 2020    8    1   12    0    0
	[5,] 2020    8    1   12    0    0
	> simplify2array(parallel::mclapply(c(
	+   lubridate::year,
	+   lubridate::month,
	+   lubridate::day,
	+   lubridate::hour), function(FUN, x) {
	+     FUN(x)
	+   }, x=dat$forecast.date))
	     [,1] [,2] [,3] [,4]
	[1,] 2020    8    1   12
	[2,] 2020    8    1   12
	[3,] 2020    8    1   12
	[4,] 2020    8    1   12
	[5,] 2020    8    1   12

V

r

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200802/465df8ed/attachment.sig>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  2 23:54:21 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 2 Aug 2020 22:54:21 +0100
Subject: [R] Parsing a Date
In-Reply-To: <20200802172648.GE1827@posteo.no>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
 <20200802172648.GE1827@posteo.no>
Message-ID: <a5e29edb-b03a-dbd0-1b5f-37f9e8bde4cd@sapo.pt>

Hello,

And another solution, taking advantage of Rasmus' one:



simplify2array(parallel::mclapply(c(
 ? "%Y",
 ? "%m",
 ? "%d",
 ? "%H"), function(fmt, x) {
 ??? as.integer(format(as.POSIXct(x), format = fmt))
}, x = dta$forecast.date))
#???? [,1] [,2] [,3] [,4]
#[1,] 2020??? 8??? 1?? 12
#[2,] 2020??? 8??? 1?? 12
#[3,] 2020??? 8??? 1?? 12
#[4,] 2020??? 8??? 1?? 12
#[5,] 2020??? 8??? 1?? 12


The data set dta is Jeff's, it's in dput format.

Hope this helps,

Rui Barradas

?s 18:26 de 02/08/2020, Rasmus Liland escreveu:
> On 2020-08-02 09:24 -0700, Philip wrote:
> | Below is some Weather Service data.  I
> | would like to parse the forecast date
> | field into four different columns:
> | Year, Month, Day, Hour
>
> Dear Philip,
>
> I'm largely re-iterating Eric and Jeff's
> excellent solutions:
>
> 	> dat <- structure(list(forecast.date =
> 	+ c("2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00"
> 	+ ), TMP = c("305.495", "305.245",
> 	+ "305.057", "305.745", "305.495"
> 	+ )), row.names = c(NA, 5L),
> 	+ class = "data.frame")
> 	> t(apply(simplify2array(
> 	+   strsplit(dat$forecast.date, "-| |:")),
> 	+   2, as.numeric))
> 	     [,1] [,2] [,3] [,4] [,5] [,6]
> 	[1,] 2020    8    1   12    0    0
> 	[2,] 2020    8    1   12    0    0
> 	[3,] 2020    8    1   12    0    0
> 	[4,] 2020    8    1   12    0    0
> 	[5,] 2020    8    1   12    0    0
> 	> simplify2array(parallel::mclapply(c(
> 	+   lubridate::year,
> 	+   lubridate::month,
> 	+   lubridate::day,
> 	+   lubridate::hour), function(FUN, x) {
> 	+     FUN(x)
> 	+   }, x=dat$forecast.date))
> 	     [,1] [,2] [,3] [,4]
> 	[1,] 2020    8    1   12
> 	[2,] 2020    8    1   12
> 	[3,] 2020    8    1   12
> 	[4,] 2020    8    1   12
> 	[5,] 2020    8    1   12
>
> V
>
> r
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Aug  3 09:25:25 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 3 Aug 2020 09:25:25 +0200
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
 <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
Message-ID: <24359.48101.586559.824590@stat.math.ethz.ch>

>>>>> Abby Spurdle 
>>>>>     on Sun, 2 Aug 2020 15:13:51 +1200 writes:

    > That's a bit harsh.  Isn't the best advice here, to post a
    > reproducible example...  Which I believe has been
    > mentioned.

    > Also, I'd strongly encourage people to use
    > package+function name, for this sort of thing.

    >     stats::glm

    > As there are many R functions for GLMs...

Sorry, Abby, I do disagree here ((strongly enough as to warrant
this reply) :

We're talking about doing "basic" statistics with R,  and these
function in the stats package have been part of R even before
got a version number.

So, no,  glm()  {and the stats package} are the default and I still
think everybody should know and assume that.

Martin

    > On Sun, Aug 2, 2020 at 12:47 PM Rolf Turner
    > <r.turner at auckland.ac.nz> wrote:
    >> 
    >> 
    >> On 2/08/20 5:39 am, Paul Bernal wrote:
    >> 
    >> > Dear friends,
    >> >
    >> > Hope you are doing great. I want to fit a logistic
    >> regression in R, where > the dependent variable is the
    >> covid status (I used 1 for covid positives, > and 0 for
    >> covid negatives), but when I ran the glm, R complains
    >> that I > should make the dependent variable a factor.
    >> >
    >> > What would be more advisable, to keep the dependent
    >> variable with 1s and > 0s, or code it as yes/no and then
    >> make it a factor?
    >> >
    >> > Any guidance will be greatly appreciated,
    >> 
    >> 
    >> There have been many responses to this post, the majority
    >> of them being confusing and off the point.
    >> 
    >> BOTTOM LINE: R/glm() does *NOT* complain that one "should
    >> make the dependent variable a factor".  This is bovine
    >> faecal output.
    >> 
    >> As Rui Barradas has pointed out (alternatively: RTFM!)
    >> when you fit a Bernoulli model using glm(), your
    >> response/dependent variable is allowed to be
    >> 
    >> * a numeric variable with values 0 or 1 * a logical
    >> variable * a factor with two levels
    >> 
    >> The OP presumably fed glm() a *character* vector with
    >> values "0" and "1".  Doing *this* will cause glm() to
    >> whinge.
    >> 
    >> I reiterate: RTFM!!!  (And perhaps learn to distinguish
    >> between character vectors and factors.)
    >> 
    >> cheers,
    >> 
    >> Rolf Turner
    >> 
    >> --
    >> Honorary Research Fellow Department of Statistics
    >> University of Auckland Phone: +64-9-373-7599 ext. 88276
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  3 10:24:13 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 09:24:13 +0100
Subject: [R] Parsing a Date
In-Reply-To: <a5e29edb-b03a-dbd0-1b5f-37f9e8bde4cd@sapo.pt>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
 <20200802172648.GE1827@posteo.no>
 <a5e29edb-b03a-dbd0-1b5f-37f9e8bde4cd@sapo.pt>
Message-ID: <552cbeae-4d11-c13d-8aa6-0bacd2ffc901@sapo.pt>

Hello,

I'm reposting, I sent the previous in HTML format.
My apologies, I'm not at my computers.

And another solution, taking advantage of Rasmus' one:


simplify2array(parallel::mclapply(c(
 ?"%Y",
 ?"%m",
 ?"%d",
 ?"%H"), function(fmt, x) {
 ?as.integer(format(as.POSIXct(x), format = fmt))
}, x = dta$forecast.date))
#???? [,1] [,2] [,3] [,4]
#[1,] 2020??? 8??? 1?? 12
#[2,] 2020??? 8??? 1?? 12
#[3,] 2020??? 8??? 1?? 12
#[4,] 2020??? 8??? 1?? 12
#[5,] 2020??? 8??? 1?? 12



The data set dta is Jeff's, it's in dput format.

Hope this helps,

Rui Barradas



?s 22:54 de 02/08/2020, Rui Barradas escreveu:
> Hello,
>
> And another solution, taking advantage of Rasmus' one:
>
>
>
> simplify2array(parallel::mclapply(c(
>   ? "%Y",
>   ? "%m",
>   ? "%d",
>   ? "%H"), function(fmt, x) {
>   ??? as.integer(format(as.POSIXct(x), format = fmt))
> }, x = dta$forecast.date))
> #???? [,1] [,2] [,3] [,4]
> #[1,] 2020??? 8??? 1?? 12
> #[2,] 2020??? 8??? 1?? 12
> #[3,] 2020??? 8??? 1?? 12
> #[4,] 2020??? 8??? 1?? 12
> #[5,] 2020??? 8??? 1?? 12
>
>
> The data set dta is Jeff's, it's in dput format.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 18:26 de 02/08/2020, Rasmus Liland escreveu:
>> On 2020-08-02 09:24 -0700, Philip wrote:
>> | Below is some Weather Service data.  I
>> | would like to parse the forecast date
>> | field into four different columns:
>> | Year, Month, Day, Hour
>>
>> Dear Philip,
>>
>> I'm largely re-iterating Eric and Jeff's
>> excellent solutions:
>>
>> 	> dat <- structure(list(forecast.date =
>> 	+ c("2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00"
>> 	+ ), TMP = c("305.495", "305.245",
>> 	+ "305.057", "305.745", "305.495"
>> 	+ )), row.names = c(NA, 5L),
>> 	+ class = "data.frame")
>> 	> t(apply(simplify2array(
>> 	+   strsplit(dat$forecast.date, "-| |:")),
>> 	+   2, as.numeric))
>> 	     [,1] [,2] [,3] [,4] [,5] [,6]
>> 	[1,] 2020    8    1   12    0    0
>> 	[2,] 2020    8    1   12    0    0
>> 	[3,] 2020    8    1   12    0    0
>> 	[4,] 2020    8    1   12    0    0
>> 	[5,] 2020    8    1   12    0    0
>> 	> simplify2array(parallel::mclapply(c(
>> 	+   lubridate::year,
>> 	+   lubridate::month,
>> 	+   lubridate::day,
>> 	+   lubridate::hour), function(FUN, x) {
>> 	+     FUN(x)
>> 	+   }, x=dat$forecast.date))
>> 	     [,1] [,2] [,3] [,4]
>> 	[1,] 2020    8    1   12
>> 	[2,] 2020    8    1   12
>> 	[3,] 2020    8    1   12
>> 	[4,] 2020    8    1   12
>> 	[5,] 2020    8    1   12
>>
>> V
>>
>> r
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From ht @end|ng |rom he@therturner@net  Mon Aug  3 10:24:34 2020
From: ht @end|ng |rom he@therturner@net (Heather Turner)
Date: Mon, 03 Aug 2020 09:24:34 +0100
Subject: [R] useR! 2020 survey
Message-ID: <5af3e0c2-19ff-4840-8542-482d56487664@www.fastmail.com>

Dear All,

We hope you have been able to watch/attend some of the breakout sessions, keynotes, R core panel, contributed tutorials, or online tutorials that were part of the useR! 2020 program.

We'd appreciate it you took 5 minutes to let us know a bit more about yourself and what you thought of useR! this year, by answering the useR! 2020 survey: bit.ly/useR2020survey.

Many thanks,

Heather



	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  3 12:51:32 2020
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 3 Aug 2020 11:51:32 +0100
Subject: [R] Arrange data
Message-ID: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>

Hi,

I have a dataset having monthly observations (from January to December)
over a period of time like (2000 to 2018). Now, I am trying to take an
average the value from January to July of each year.

The data looks like
Year    Month  Value
2000    1         25
2000    2         28
2000    3         22
....    ......      .....
2000    12       26
2001     1       27
.......         ........
2018    11       30
20118   12      29

Can someone help me in this regard?

Many thanks in advance.

*Regards,*
*Md*

	[[alternative HTML version deleted]]


From @@h|mk@poor @end|ng |rom gm@||@com  Mon Aug  3 12:52:48 2020
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Mon, 3 Aug 2020 16:22:48 +0530
Subject: [R] tidyquant package
Message-ID: <CAC8=1eoz=sXUazhRkkGmhke3WXta6+MsXJ3C6a0PtCv+OF852A@mail.gmail.com>

Dear all,

I am trying to follow along/ recreate this page ( but I do not get the
same results) :-

https://bookdown.org/sstoeckl/Tidy_Portfoliomanagement_in_R/s-2Data.html

Here is a reprex / what I have done till now / my queries ( 3 in
number ) are as comments :-

> library(tidyquant)
Loading required package: lubridate

Attaching package: ?lubridate?

The following object is masked from ?package:base?:

    date

Loading required package: PerformanceAnalytics
Loading required package: xts
Loading required package: zoo

Attaching package: ?zoo?

The following objects are masked from ?package:base?:

    as.Date, as.Date.numeric


Attaching package: ?PerformanceAnalytics?

The following object is masked from ?package:graphics?:

    legend

Loading required package: quantmod
Loading required package: TTR
Registered S3 method overwritten by 'quantmod':
  method            from
  as.zoo.data.frame zoo
Version 0.4-0 included new data defaults. See ?getSymbols.
?? Need to Learn tidyquant? ????????????????????????????????????????????????????
Business Science offers a 1-hour course - Learning Lab #9: Performance
Analysis & Portfolio Optimization with tidyquant!
</> Learn more at:
https://university.business-science.io/p/learning-labs-pro </>
> library(tidyverse)
?? Attaching packages ??????????????????????????????????????? tidyverse 1.3.0 ??
? ggplot2 3.2.1     ? purrr   0.3.3
? tibble  3.0.3     ? dplyr   1.0.1
? tidyr   1.1.1     ? stringr 1.4.0
? readr   1.3.1     ? forcats 0.4.0
?? Conflicts ?????????????????????????????????????????? tidyverse_conflicts() ??
? lubridate::as.difftime() masks base::as.difftime()
? lubridate::date()        masks base::date()
? dplyr::filter()          masks stats::filter()
? dplyr::first()           masks xts::first()
? lubridate::intersect()   masks base::intersect()
? dplyr::lag()             masks stats::lag()
? dplyr::last()            masks xts::last()
? lubridate::setdiff()     masks base::setdiff()
? lubridate::union()       masks base::union()
> tq_exchange_options()
[1] "AMEX"   "NASDAQ" "NYSE"
> tq_index_options()
[1] "DOW"       "DOWGLOBAL" "SP400"     "SP500"     "SP600"

# Query 1 : The above should also show RUSSELL3000. Why is it not showing?

> tq_get_options()
 [1] "stock.prices"       "stock.prices.japan" "dividends"
 [4] "splits"             "economic.data"      "quandl"
 [7] "quandl.datatable"   "tiingo"             "tiingo.iex"
[10] "tiingo.crypto"      "alphavantager"      "alphavantage"
[13] "rblpapi"
> glimpse(sp500)
Error in glimpse(sp500) : object 'sp500' not found

# Query 2 : This is working fine in the page mentioned on top. What
mistake have I made?

> tq_exchange("NYSE")
Getting data...

[1] NA
Warning messages:
1: In download.file(url, destfile = tmp, quiet = TRUE) :
  URL 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download':
status was 'Failure when receiving data from the peer'
2: In value[[3L]](cond) : Error at nyse during call to tq_exchange.
>
# Query 3 : Is this a networking issue? Should I try after some time ?


Here is my session info:-

> sessionInfo()
R version 3.6.2 (2019-12-12)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS/LAPACK: /opt/intel/compilers_and_libraries_2018.2.199/linux/mkl/lib/intel64_lin/libmkl_rt.so

locale:
 [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
 [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
 [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] forcats_0.4.0              stringr_1.4.0
 [3] dplyr_1.0.1                purrr_0.3.3
 [5] readr_1.3.1                tidyr_1.1.1
 [7] tibble_3.0.3               ggplot2_3.2.1
 [9] tidyverse_1.3.0            tidyquant_1.0.1
[11] quantmod_0.4-15            TTR_0.23-6
[13] PerformanceAnalytics_2.0.4 xts_0.12-0
[15] zoo_1.8-7                  lubridate_1.7.4

loaded via a namespace (and not attached):
 [1] tidyselect_1.1.0 haven_2.2.0      lattice_0.20-38  colorspace_1.4-1
 [5] vctrs_0.3.2      generics_0.0.2   rlang_0.4.7      pillar_1.4.6
 [9] withr_2.1.2      glue_1.4.1       DBI_1.1.0        dbplyr_1.4.2
[13] modelr_0.1.5     readxl_1.3.1     lifecycle_0.2.0  Quandl_2.10.0
[17] cellranger_1.1.0 munsell_0.5.0    gtable_0.3.0     rvest_0.3.5
[21] curl_4.3         fansi_0.4.1      broom_0.5.3      Rcpp_1.0.3
[25] backports_1.1.5  scales_1.1.0     jsonlite_1.6     fs_1.3.1
[29] hms_0.5.2        stringi_1.4.6    grid_3.6.2       quadprog_1.5-8
[33] cli_2.0.1        tools_3.6.2      magrittr_1.5     lazyeval_0.2.2
[37] crayon_1.3.4     pkgconfig_2.0.3  ellipsis_0.3.0   xml2_1.2.2
[41] reprex_0.3.0     assertthat_0.2.1 httr_1.4.1       rstudioapi_0.10
[45] R6_2.4.1         nlme_3.1-143     compiler_3.6.2
>

Many thanks,
Ashim


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  3 13:11:59 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 3 Aug 2020 21:11:59 +1000
Subject: [R] Arrange data
In-Reply-To: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
Message-ID: <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>

Hi Md,
One way is to form a subset of your data, then calculate the means by year:

# assume your data is named mddat
mddat2<-mddat[mddat$month < 7,]
jan2jun<-by(mddat2$value,mddat2$year,mean)

Jim

On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Hi,
>
> I have a dataset having monthly observations (from January to December)
> over a period of time like (2000 to 2018). Now, I am trying to take an
> average the value from January to July of each year.
>
> The data looks like
> Year    Month  Value
> 2000    1         25
> 2000    2         28
> 2000    3         22
> ....    ......      .....
> 2000    12       26
> 2001     1       27
> .......         ........
> 2018    11       30
> 20118   12      29
>
> Can someone help me in this regard?
>
> Many thanks in advance.
>
> *Regards,*
> *Md*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Mon Aug  3 13:33:37 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 3 Aug 2020 13:33:37 +0200
Subject: [R] Arrange data
In-Reply-To: <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
Message-ID: <20200803113337.GC106339@posteo.no>

On 2020-08-03 21:11 +1000, Jim Lemon wrote:
> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
> >
> > Hi,
> >
> > I have a dataset having monthly 
> > observations (from January to 
> > December) over a period of time like 
> > (2000 to 2018). Now, I am trying to 
> > take an average the value from 
> > January to July of each year.
> >
> > The data looks like
> > Year    Month  Value
> > 2000    1         25
> > 2000    2         28
> > 2000    3         22
> > ....    ......      .....
> > 2000    12       26
> > 2001     1       27
> > .......         ........
> > 2018    11       30
> > 20118   12      29
> >
> > Can someone help me in this regard? 
> >
> > Many thanks in advance.
> 
> Hi Md,
> One way is to form a subset of your 
> data, then calculate the means by 
> year:
> 
> # assume your data is named mddat
> mddat2<-mddat[mddat$month < 7,]
> jan2jun<-by(mddat2$value,mddat2$year,mean)
> 
> Jim

Hi Md,

you can also define the period in a new 
column, and use aggregate like this:

	Md <- structure(list(
	Year = c(2000L, 2000L, 2000L, 
	2000L, 2001L, 2018L, 2018L), 
	Month = c(1L, 2L, 3L, 12L, 1L,
	11L, 12L), 
	Value = c(25L, 28L, 22L, 26L,
	27L, 30L, 29L)), 
	class = "data.frame", 
	row.names = c(NA, -7L))
	
	Md[Md$Month %in%
	        1:6,"Period"] <- "first six months of the year"
	Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
	
	aggregate(
	  formula=Value~Year+Period,
	  data=Md,
	  FUN=mean)

Rasmus


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Aug  3 16:22:21 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 3 Aug 2020 14:22:21 +0000 (UTC)
Subject: [R] Double MAD with R
References: <401386585.16460890.1596464541734.ref@mail.yahoo.com>
Message-ID: <401386585.16460890.1596464541734@mail.yahoo.com>

Dear R-Experts,

Is there an all-ready function to calculate the Double MAD (Median absolute deviation) as there is an easy function to calculate the MAD "mad function". Or I have to write my own function for Double MAD ?

To calculate the double MAD, the idea is the following : for the obtained median value, we should calculate two median absolution deviations. One deviation should be calculated for the numbers below the median and one for the numbers above the median:

Here is the very easy reproducible example :

x<-c(2.5,4.4,3.2,2.1,1.3,2.6,5,6.6,5,5,6.1,7.2,9.4,6.9)
mad(x)


From j|en@gu90 @end|ng |rom gm@||@com  Sun Aug  2 02:35:38 2020
From: j|en@gu90 @end|ng |rom gm@||@com (Jiena McLellan)
Date: Sat, 1 Aug 2020 20:35:38 -0400
Subject: [R] [R-pkgs] faq v0.1.0 on CRAN
Message-ID: <CAB+AFnLTfpSGcd2f73-9SgjX8_ROwZp4OT30wtH1KaAvLW7iAw@mail.gmail.com>

R Users,

I?m writing to introduce a new package, faq. This package offers a fast
tool to create an interactive and toggle styling Frequently Asked Questions
page by using R data.
Hopefully you find this useful. Please feel free to reach out with feedback
or questions.

CRAN: https://cran.r-project.org/web/packages/faq/index.html
Github: https://github.com/jienagu/faq

Best Regards,
Jiena Gu McLellan

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  3 16:54:20 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 15:54:20 +0100
Subject: [R] Double MAD with R
In-Reply-To: <401386585.16460890.1596464541734@mail.yahoo.com>
References: <401386585.16460890.1596464541734.ref@mail.yahoo.com>
 <401386585.16460890.1596464541734@mail.yahoo.com>
Message-ID: <c41de121-e6ca-493c-ec98-c066c32914b4@sapo.pt>

Hello,

No, there isn't a built-in that I know of.
Here is one:


double.mad <- function(x, include.right = FALSE, na.rm = FALSE){
 ? if(na.rm) x <- x[!is.na(x)]
 ? m <- median(x)
 ? odd <- (length(x) %% 2L) == 1L
 ? out <- if(odd){
 ??? if(include.right) {
 ????? c(lo = mad(x[x < m]), hi = mad(x[x >= m]))
 ??? } else {
 ????? c(lo = mad(x[x <= m]), hi = mad(x[x > m]))
 ??? }
 ? } else {
 ??? c(lo = mad(x[x < m]), hi = mad(x[x > m]))
 ? }
 ? out
}

double.mad(x)
#???? lo????? hi
#0.81543 0.44478

double.mad(c(x, 1))
#???? lo????? hi
#2.29803 0.44478

double.mad(c(x, 1), include.right = TRUE)
#???? lo????? hi
#1.03782 1.63086


Hope this helps,

Rui Barradas

?s 15:22 de 03/08/2020, varin sacha via R-help escreveu:
> Dear R-Experts,
>
> Is there an all-ready function to calculate the Double MAD (Median absolute deviation) as there is an easy function to calculate the MAD "mad function". Or I have to write my own function for Double MAD ?
>
> To calculate the double MAD, the idea is the following : for the obtained median value, we should calculate two median absolution deviations. One deviation should be calculated for the numbers below the median and one for the numbers above the median:
>
> Here is the very easy reproducible example :
>
> x<-c(2.5,4.4,3.2,2.1,1.3,2.6,5,6.6,5,5,6.1,7.2,9.4,6.9)
> mad(x)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From @purd|e@@ @end|ng |rom gm@||@com  Mon Aug  3 21:39:08 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 4 Aug 2020 07:39:08 +1200
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <24359.48101.586559.824590@stat.math.ethz.ch>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
 <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
 <24359.48101.586559.824590@stat.math.ethz.ch>
Message-ID: <CAB8pepxfDbEED8ZQW=WdWisNdrcRzOt-HZcgAhdrdA24CFokJw@mail.gmail.com>

> Sorry, Abby, I do disagree here ((strongly enough as to warrant
> this reply) :

Which part are you disagreeing with?
That unambiquous names/references should be used, or that there are
many R functions for GLMs.
The wording of your post, suggests (kind of), that there is only one R
function for GLMs.

> We're talking about doing "basic" statistics with R,  and these
> function in the stats package have been part of R even before
> got a version number.

Remember, not everyone is using the same R packages, as you.
And some people have done university courses, or done online courses,
etc, in R, without ever using one function from the stats package.

I'm reluctant to assume that all R users will have a common understanding.
And what may seem obvious to you or me, may seem quite foreign to some
users, or vice versa.

> So, no,  glm()  {and the stats package} are the default and I still
> think everybody should know and assume that.

But perhaps most importantly, the OP said "the glm".
He never said "glm()", but rather the subsequent posters did.

Rolf suggested his post was bullshit, after removing the lexical peroxide.
How does anyone know that it wasn't a genuine post, but in reference
to something other than stats::glm?

Shouldn't people be innocent until proven guilty.
Otherwise (something I have been guilty of in the past), the mailing
list turns into statistical propaganda...

Even if the OP was referring to stats::glm, I'm still inclined to feel
the post was legitimate, just a bit short on technical details...


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug  3 23:11:20 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 3 Aug 2020 14:11:20 -0700
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <CAB8pepxfDbEED8ZQW=WdWisNdrcRzOt-HZcgAhdrdA24CFokJw@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
 <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
 <24359.48101.586559.824590@stat.math.ethz.ch>
 <CAB8pepxfDbEED8ZQW=WdWisNdrcRzOt-HZcgAhdrdA24CFokJw@mail.gmail.com>
Message-ID: <CAGxFJbQtpZ9tyXmAAueiGQ0t9ObgnPeBw_v_8S0CT4OKu6svxA@mail.gmail.com>

All: Kindly take this offline please.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 3, 2020 at 12:39 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> > Sorry, Abby, I do disagree here ((strongly enough as to warrant
> > this reply) :
>
> Which part are you disagreeing with?
> That unambiquous names/references should be used, or that there are
> many R functions for GLMs.
> The wording of your post, suggests (kind of), that there is only one R
> function for GLMs.
>
> > We're talking about doing "basic" statistics with R,  and these
> > function in the stats package have been part of R even before
> > got a version number.
>
> Remember, not everyone is using the same R packages, as you.
> And some people have done university courses, or done online courses,
> etc, in R, without ever using one function from the stats package.
>
> I'm reluctant to assume that all R users will have a common understanding.
> And what may seem obvious to you or me, may seem quite foreign to some
> users, or vice versa.
>
> > So, no,  glm()  {and the stats package} are the default and I still
> > think everybody should know and assume that.
>
> But perhaps most importantly, the OP said "the glm".
> He never said "glm()", but rather the subsequent posters did.
>
> Rolf suggested his post was bullshit, after removing the lexical peroxide.
> How does anyone know that it wasn't a genuine post, but in reference
> to something other than stats::glm?
>
> Shouldn't people be innocent until proven guilty.
> Otherwise (something I have been guilty of in the past), the mailing
> list turns into statistical propaganda...
>
> Even if the OP was referring to stats::glm, I'm still inclined to feel
> the post was legitimate, just a bit short on technical details...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  3 23:44:49 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 22:44:49 +0100
Subject: [R] hist from a list
In-Reply-To: <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>
References: <CAB-TgNv88YE29BkrXg9teFoMGXVOGfrYtDWy+Ltb8znRK9_OFQ@mail.gmail.com>
 <42a74b91-08ed-f5f2-b621-193e447dd824@dewey.myzen.co.uk>
 <70ef6db0-8a9d-d140-8347-b4e8b758f640@sapo.pt>
 <CAPPM_gQTOQwXdiMQtD_smhZDJ7uAjwyfT65TR_J-0Vhh+xhYqg@mail.gmail.com>
 <20200731162847.GB106339@posteo.no>
 <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>
Message-ID: <ea46a48f-e9aa-8d89-aed5-0f7454b3da3b@sapo.pt>

Hello,

Thanks for the data in dput format.
If you run

str(bwchist)

you will see that what you have is a data.frame, yes, but, with columns 
of class "list", not vectors.
So the first step is to make them vectors, to unlist the lists. I will 
do it applying function unlist() to each of the columns. Since lapply 
returns a list, I remake a data.frame. The original is kept unchanged, 
the new object is bwch.

bwch <- lapply(bwchist, unlist, recursive = FALSE)
bwch <- do.call(cbind.data.frame, bwch)
str(bwch)


Now that everything is as it should, here are two ways of plotting bar 
graphs.

#--- base R
x11(width = 11.5, height = 6)
old_par <- par(mar =? par("mar") + c(1, 0, 0, 0))
bp <- barplot(bwch$reval, yaxt = "n", ylim = c(-1, 0.4))
axis(1, at = bp, labels = bwch$Accion, las = 2)
axis(2, at = pretty(bwch$reval))
par(old_par)


#--- package ggplot2
library(ggplot2)

x11(width = 11.5, height = 6)
ggplot(bwch, aes(factor(Accion, levels = Accion), reval)) +
 ? geom_col() +
 ? theme(axis.text.x = element_text(angle = 60, hjust = 1))


Hope this helps,

Rui Barradas

?s 19:48 de 03/08/2020, Pedro p?ramo escreveu:
> Hi Rasmus, Josh and Rui,
>
> First of all many thanks?in advance about your help.
>
> The first thig?is sometimes?you say " you are posting in HTML and that 
> makes the
> post unreadable as this is a plain text list" how can I put the code 
> in the correct way, not html (attaching in txt?)
>
> The second?about the code:
>
> I have used this:
>
> bwc <- cbind(bwfinal2,bwfinal)
> colnames(bwc)=c("Accion","reval")
> df <- matrix(unlist(bwc), nrow=nrow(bwc), byrow=F)
> colnames(bwchist)=c("Accion","reval")
> bwchist <-as.data.frame(bwc[order(df[,2]), ])
>
> bwchist is the ordered cum stock returns in the year but because is a 
> list it is not possible to plot and histogram with x (names of stocks) 
> and the x axist?the value of cum stocks (reval)
>
> when I put dput(bwchist) the console says:
>
> dput(bwchist)
> structure(list(Accion = list("REE", "Enagas", "Grifols", "Ferrovial",
> ? ? "Acerinox", "Naturgy", "Inditex", "Bankia", "ENCE", "Aena",
> ? ? "Bankinter", "Mapfre", "CaixaBank", "CIE", "Colonial", "Almirall",
> ? ? "Indra", "ArcelorMittal", "ACS", "Telefonica", "Amadeus",
> ? ? "BBVA", "Merlin", "Santander", "Repsol", "Melia", "Sabadell",
> ? ? "IAG", "Acciona", "Endesa", "MasMovil", "Iberdrola", "SGamesa",
> ? ? "Viscofan", "Cellnex"), reval = list(-0.0200827282700085,
> ? ? -0.0590294115600855, -0.214126598790964, -0.220773677809979,
> ? ? -0.229653300324357, -0.257944379583984, -0.283942789063822,
> ? ? -0.285159347392533, -0.303814713896458, -0.30734460425763,
> ? ? -0.309408155539818, -0.319912221435868, -0.322790949659181,
> ? ? -0.344047579452905, -0.347919538415482, -0.356898907103825,
> ? ? -0.374263261296661, -0.40147247119078, -0.405150043834815,
> ? ? -0.406022775042175, -0.413786100987797, -0.440679109311707,
> ? ? -0.442603156492871, -0.491634140733524, -0.499254932434042,
> ? ? -0.6, -0.709737357505148, -0.724461258850966, 0.0220528711420083,
> ? ? 0.0462767672643172, 0.115044247787611, 0.238734548714937,
> ? ? 0.274578114644054, 0.343422896082666, 0.387826126094928)), class = 
> "data.frame", row.names = c(NA,
> -35L))
>
> I try to make an hist or barplot but because it is a list no way to 
> obtain the plot.
>
> Many thanks again for your help.
>
> I have printed two manuals to improve my level, but if you can help 
> me, I would be very very gratefull.
>
>
>
> El vie., 31 jul. 2020 a las 18:28, Rasmus Liland (<jral at posteo.no 
> <mailto:jral at posteo.no>>) escribi?:
>
>     On 2020-07-31 10:07 -0500, Joshua Ulrich wrote:
>     | On Fri, Jul 31, 2020 at 9:55 AM Rui Barradas wrote:
>     | | ?s 15:44 de 31/07/2020, Michael Dewey escreveu:
>     | | | Dear Pedro
>     | | |
>     | | | Some comments in-line
>     | | |
>     | | | On 30/07/2020 21:16, Pedro p?ramo wrote:
>     | | | | Hi all,
>     | | | |
>     | | | | I attach my code, the think is I
>     | | | | want to make a bar plot the last
>     | | | | variable called "bwchist" so the
>     | | | | X axis are "Accion" and the y
>     | | | | axis are "reval" values.
>     | | | |
>     | | | | I have prove class(bwchist) and
>     | | | | says dataframe but its still a
>     | | | | list because it says me I have
>     | | | | prove to unlist, but it doesnt
>     | | | | work
>     | | | |
>     | | | | hist(bwchist)
>     | | | | Error in hist.default(bwchist) : 'x' must be numeric
>     | | |
>     | | | So bwchist is not a numeric
>     | | | variable as hist needs. Aboce you
>     | | | said it is a data frame but data
>     | | | frames are not numeric.
>     | | |
>     | | | For future reference your example
>     | | | is way too long for anyone to go
>     | | | through and try to help you. Try
>     | | | next time to reduce it to the
>     | | | absolute minimum by removing
>     | | | sections while you still get the
>     | | | error.? It is also easier to get
>     | | | help if you can remove unnecessary
>     | | | packages.
>     | | |
>     | | | It is also unreadable because you
>     | | | are posting in HTML and that makes
>     | | | the post unreadable as this is a
>     | | | plain text list.
>     | |
>     | | Hello,
>     | |
>     | | I second Michael's opinion. When the
>     | | post's code is very long, there is a
>     | | tendency to have less answers.
>     | |
>     | | Please post the output of
>     | |
>     | |? ? ?dput(head(bwchist, 30))
>     | |
>     | | It's much shorter code and it
>     | | recreates the data so we will be
>     | | able to see what's wrong and try to
>     | | find a solution.
>     |
>     | Hi Pedro,
>     |
>     | Another 'best practice' and polite
>     | thing to do is link to other places
>     | you may have cross-posted.? That will
>     | give people the opportunity to see if
>     | your questions has been answered in
>     | another forum.
>     |
>     | I saw your post on R-SIG-Finance
>     | (https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/014979.html),
>     | and started to work on a solution.
>     |
>     | I don't know how to do this in
>     | tidyquant, but here's how you can do
>     | it with quantmod:
>     |
>     | # all tickers
>     | tk <- c("ANA.MC <http://ANA.MC>", "ACS.MC <http://ACS.MC>",
>     "AENA.MC <http://AENA.MC>", "AMS.MC <http://AMS.MC>", "MTS.MC
>     <http://MTS.MC>", "BBVA.MC <http://BBVA.MC>", "SAB.MC
>     <http://SAB.MC>",
>     |? ?"SAN.MC <http://SAN.MC>", "BKT.MC <http://BKT.MC>", "CABK.MC
>     <http://CABK.MC>", "CLNX.MC <http://CLNX.MC>", "ENG.MC
>     <http://ENG.MC>", "ENC.MC <http://ENC.MC>", "ELE.MC <http://ELE.MC>",
>     |? ?"FER.MC <http://FER.MC>", "GRF.MC <http://GRF.MC>", "IBE.MC
>     <http://IBE.MC>", "ITX.MC <http://ITX.MC>", "COL.MC
>     <http://COL.MC>", "IAG.MC <http://IAG.MC>", "MAP.MC <http://MAP.MC>",
>     |? ?"MEL.MC <http://MEL.MC>", "MRL.MC <http://MRL.MC>", "NTGY.MC
>     <http://NTGY.MC>", "REE.MC <http://REE.MC>", "REP.MC
>     <http://REP.MC>", "SGRE.MC <http://SGRE.MC>", "TEF.MC
>     <http://TEF.MC>",
>     |? ?"VIS.MC <http://VIS.MC>", "ACX.MC <http://ACX.MC>", "BKIA.MC
>     <http://BKIA.MC>", "CIE.MC <http://CIE.MC>", "MAS.MC
>     <http://MAS.MC>", "ALM.MC <http://ALM.MC>", "IDR.MC <http://IDR.MC>")
>     |
>     | # download them into an environment ('e')
>     | require(quantmod)
>     | getSymbols(tk, from = "2019-12-31", env = (e <- new.env()))
>     |
>     | # extract adjusted close column
>     | adj <- lapply(e, Ad)
>     | # calculate daily returns from adjusted data,
>     | # merge into a xts matrix, and fill NA with 0
>     | ret <- do.call(merge, c(lapply(adj, dailyReturn), fill = 0))
>     | # cumulative returns
>     | cumret <- cumprod(1 + ret) - 1
>     | # set names
>     | colnames(cumret) <- names(adj)
>     | last(cumret)
>     | # calculate histogram for period-to-date returns
>     | hist(drop(last(cumret)))
>     |
>     | I'm not sure that's the histogram
>     | you're looking for, but I hope it
>     | gives you a start toward a solution.
>     |
>     | Best,
>     | Josh
>
>     Wow Josh!? That's very elegant.
>
>     Myself now, I just plowed through the
>     original code to make it simpler, but am
>     at a loss as to how this histogram looks
>     ...
>
>     ? ? ? ? x <- c("ANA.MC <http://ANA.MC>", "ACS.MC <http://ACS.MC>",
>     "AENA.MC <http://AENA.MC>", "AMS.MC <http://AMS.MC>", "MTS.MC
>     <http://MTS.MC>", "BBVA.MC <http://BBVA.MC>",
>     ? ? ? ? ? "SAB.MC <http://SAB.MC>", "SAN.MC <http://SAN.MC>",
>     "BKT.MC <http://BKT.MC>", "CABK.MC <http://CABK.MC>", "CLNX.MC
>     <http://CLNX.MC>", "ENG.MC <http://ENG.MC>",
>     ? ? ? ? ? "ENC.MC <http://ENC.MC>", "ELE.MC <http://ELE.MC>",
>     "FER.MC <http://FER.MC>", "GRF.MC <http://GRF.MC>", "IBE.MC
>     <http://IBE.MC>", "ITX.MC <http://ITX.MC>",
>     ? ? ? ? ? "COL.MC <http://COL.MC>", "IAG.MC <http://IAG.MC>",
>     "MAP.MC <http://MAP.MC>", "MEL.MC <http://MEL.MC>", "MRL.MC
>     <http://MRL.MC>", "NTGY.MC <http://NTGY.MC>",
>     ? ? ? ? ? "REE.MC <http://REE.MC>", "REP.MC <http://REP.MC>",
>     "SGRE.MC <http://SGRE.MC>", "TEF.MC <http://TEF.MC>", "VIS.MC
>     <http://VIS.MC>", "ACX.MC <http://ACX.MC>",
>     ? ? ? ? ? "BKIA.MC <http://BKIA.MC>", "CIE.MC <http://CIE.MC>",
>     "MAS.MC <http://MAS.MC>", "ALM.MC <http://ALM.MC>", "IDR.MC
>     <http://IDR.MC>")
>     ? ? ? ? stock.prices <-
>     ? ? ? ? ? lapply(x, function(stock) {
>     ? ? ? ? ? ? tidyquant::tq_get(x=stock,from = '2019-12-31',get =
>     "stock.prices")
>     ? ? ? ? ? })
>     ? ? ? ? names(stock.prices) <- x
>
>     ? ? ? ? library(tidyquant)
>
>     ? ? ? ? returns <- lapply(stock.prices, function(data) {
>     ? ? ? ? ? tab <-
>     ? ? ? ? ? ? tq_transmute(
>     ? ? ? ? ? ? ? data = data,
>     ? ? ? ? ? ? ? select = adjusted,? ? ? ? ? ?# this specifies which
>     column to select
>     ? ? ? ? ? ? ? mutate_fun = periodReturn,? ?# This specifies what
>     to do with that column
>     ? ? ? ? ? ? ? period = "daily",? ? ? ? ? ? # This argument
>     calculates Daily returns
>     ? ? ? ? ? ? ? col_rename = "idr_returns")? # renames the column
>     ? ? ? ? ? tab[,"cr"] <- cumprod(1 + tab[,"idr_returns"])
>     ? ? ? ? ? tab[,"cumulative_returns"] <- tab[,"cr"] - 1
>
>     ? ? ? ? ? dplyr::pull(
>     ? ? ? ? ? ? tab[nrow(tab[,"cumulative_returns"]),
>     ? ? ? ? ? ? ? ? ? ? ? ? ? "cumulative_returns"]
>     ? ? ? ? ? )
>     ? ? ? ? })
>
>     ? ? ? ? bestworst <- simplify2array(returns)
>
>     ? ? ? ? namebw <-
>     ? ? ? ? ? c("Acciona", "ACS", "Aena", "Amadeus",
>     ? ? ? ? ? ? "ArcelorMittal", "BBVA", "Sabadell",
>     ? ? ? ? ? ? "Santander", "Bankinter",
>     ? ? ? ? ? ? "CaixaBank", "Cellnex", "Enagas",
>     ? ? ? ? ? ? "ENCE", "Endesa", "Ferrovial",
>     ? ? ? ? ? ? "Grifols", "Iberdrola", "Inditex",
>     ? ? ? ? ? ? "Colonial", "IAG", "Mapfre",
>     ? ? ? ? ? ? "Melia", "Merlin", "Naturgy", "REE",
>     ? ? ? ? ? ? "Repsol", "SGamesa", "Telefonica",
>     ? ? ? ? ? ? "Viscofan", "Acerinox", "Bankia",
>     ? ? ? ? ? ? "CIE", "MasMovil", "Almirall",
>     ? ? ? ? ? ? "Indra")
>
>     ? ? ? ? bwc <- data.frame(
>     ? ? ? ? ? symbol=names(bestworst),
>     ? ? ? ? ? Accion=namebw,
>     ? ? ? ? ? reval=bestworst)
>
>     | | | | bwc<-cbind(bwfinal2,bwfinal)
>     | | | | colnames(bwc)=c("Accion","reval")
>     | | | | bwc <- as.data.frame(bwc)
>
>     ... aaaand you know something's
>     happening between here (where bwchist is
>     created), but you don't know what it is,
>     do you, Mr p?ramo?
>
>     | | | | colnames(bwchist)=c("Accion","reval")
>     | | | | bwchist <-as.data.frame(bwc[order(bwc$reval), ])
>
>     Best,
>     Rasmus
>



-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug  4 00:28:27 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 23:28:27 +0100
Subject: [R] Arrange data
In-Reply-To: <20200803113337.GC106339@posteo.no>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
Message-ID: <de75298f-9ba6-2ed3-5e2b-4095424f9834@sapo.pt>

Hello,

And here is another way, with aggregate.

Make up test data.

set.seed(2020)
df1 <- expand.grid(Year = 2000:2018, Month = 1:12)
df1 <- df1[order(df1$Year),]
df1$Value <- sample(20:30, nrow(df1), TRUE)
head(df1)


#Use subset to keep only the relevant months
aggregate(Value ~ Year, data = subset(df1, Month <= 7), FUN = mean)


Hope this helps,

Rui Barradas

?s 12:33 de 03/08/2020, Rasmus Liland escreveu:
> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>>> Hi,
>>>
>>> I have a dataset having monthly
>>> observations (from January to
>>> December) over a period of time like
>>> (2000 to 2018). Now, I am trying to
>>> take an average the value from
>>> January to July of each year.
>>>
>>> The data looks like
>>> Year    Month  Value
>>> 2000    1         25
>>> 2000    2         28
>>> 2000    3         22
>>> ....    ......      .....
>>> 2000    12       26
>>> 2001     1       27
>>> .......         ........
>>> 2018    11       30
>>> 20118   12      29
>>>
>>> Can someone help me in this regard?
>>>
>>> Many thanks in advance.
>> Hi Md,
>> One way is to form a subset of your
>> data, then calculate the means by
>> year:
>>
>> # assume your data is named mddat
>> mddat2<-mddat[mddat$month < 7,]
>> jan2jun<-by(mddat2$value,mddat2$year,mean)
>>
>> Jim
> Hi Md,
>
> you can also define the period in a new
> column, and use aggregate like this:
>
> 	Md <- structure(list(
> 	Year = c(2000L, 2000L, 2000L,
> 	2000L, 2001L, 2018L, 2018L),
> 	Month = c(1L, 2L, 3L, 12L, 1L,
> 	11L, 12L),
> 	Value = c(25L, 28L, 22L, 26L,
> 	27L, 30L, 29L)),
> 	class = "data.frame",
> 	row.names = c(NA, -7L))
> 	
> 	Md[Md$Month %in%
> 	        1:6,"Period"] <- "first six months of the year"
> 	Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
> 	
> 	aggregate(
> 	  formula=Value~Year+Period,
> 	  data=Md,
> 	  FUN=mean)
>
> Rasmus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug  4 09:41:09 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 4 Aug 2020 17:41:09 +1000
Subject: [R] Arrange data
In-Reply-To: <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
Message-ID: <CA+8X3fWF4TBbhqiUErDKKKw-j8nbK8+oEh0kV7+Ow8RiaU6kug@mail.gmail.com>

Your problem is in the subset operation. You have asked for a value of
month greater or equal to 7 and less than or equal to 6. You probably
got an error message that told you that the data were of length zero
or something similar. If you check the result of that statement:

> mddat$month >= 7 & mddat$month <= 6
logical(0)

In other words, the two logical statements when ANDed cannot produce a
result. A number cannot be greater than or equal to 7 AND less than or
equal to 6. What you want is:

mddat2<-mddat[mddat$Year == 1975 & mddat$Month >= 7 |
 mddat$Year == 1976 & mddat$Month <= 6,]
mean(mddat2$Value)
[1] 88.91667

Apart from that, your email client is inserting EOL characters that
cause an error when pasted into R.

Error: unexpected input in "?"

Probably due to MS Outlook, this has been happening quite a bit lately.

Jim

On Mon, Aug 3, 2020 at 11:30 PM Md. Moyazzem Hossain
<hossainmm at juniv.edu> wrote:
>
> Dear Jim,
>
> Thank you very much. It is working now.
>
> However, I am also trying to find the average of the value from July 1975 to June 1976 and recorded as the value for the year 1975 but got an error message. I am attaching the data file here. Please check the attachment.
>
> mddat=read.csv("F:/mddat.csv", header=TRUE)
> mddat2<-mddat[mddat$Month >=7 & mddat$Month <= 6,]
> jan2jun<-by(mddat2$Value,mddat2$Year,mean)
> jan2jun
>
> Please help me again and many thanks in advance.
>
> Md
>
>
> On Mon, Aug 3, 2020 at 12:33 PM Rasmus Liland <jral at posteo.no> wrote:
>>
>> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>> > On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>> > >
>> > > Hi,
>> > >
>> > > I have a dataset having monthly
>> > > observations (from January to
>> > > December) over a period of time like
>> > > (2000 to 2018). Now, I am trying to
>> > > take an average the value from
>> > > January to July of each year.
>> > >
>> > > The data looks like
>> > > Year    Month  Value
>> > > 2000    1         25
>> > > 2000    2         28
>> > > 2000    3         22
>> > > ....    ......      .....
>> > > 2000    12       26
>> > > 2001     1       27
>> > > .......         ........
>> > > 2018    11       30
>> > > 20118   12      29
>> > >
>> > > Can someone help me in this regard?
>> > >
>> > > Many thanks in advance.
>> >
>> > Hi Md,
>> > One way is to form a subset of your
>> > data, then calculate the means by
>> > year:
>> >
>> > # assume your data is named mddat
>> > mddat2<-mddat[mddat$month < 7,]
>> > jan2jun<-by(mddat2$value,mddat2$year,mean)
>> >
>> > Jim
>>
>> Hi Md,
>>
>> you can also define the period in a new
>> column, and use aggregate like this:
>>
>>         Md <- structure(list(
>>         Year = c(2000L, 2000L, 2000L,
>>         2000L, 2001L, 2018L, 2018L),
>>         Month = c(1L, 2L, 3L, 12L, 1L,
>>         11L, 12L),
>>         Value = c(25L, 28L, 22L, 26L,
>>         27L, 30L, 29L)),
>>         class = "data.frame",
>>         row.names = c(NA, -7L))
>>
>>         Md[Md$Month %in%
>>                 1:6,"Period"] <- "first six months of the year"
>>         Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
>>
>>         aggregate(
>>           formula=Value~Year+Period,
>>           data=Md,
>>           FUN=mean)
>>
>> Rasmus
>
>
>


From @ndrew@h@||ord @end|ng |rom gm@||@com  Tue Aug  4 11:48:41 2020
From: @ndrew@h@||ord @end|ng |rom gm@||@com (Andrew Halford)
Date: Tue, 4 Aug 2020 20:48:41 +1100
Subject: [R] defining group colours in a call to rda
Message-ID: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>

Hi,

I've been trying to use the output on group membership of the final leaves
in a MRT analysis to define my own colours, however I am not getting the
result I'm after.

Here is the code
fish.pca <-rda(fish_all.hel,scale=TRUE)
fish.site <- scores(fish.pca,display="sites",scaling=3)
fish.spp <-
scores(fish.pca,display="species",scaling=3)[fish.MRT.indval$pval<=0.05,]
plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
points(fish.site,pch=21,bg=MI_fish_all.mrt$where,cex=1.2)
plotcolor <-
c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
 fish.pca <-rda(fish_all.hel,scale=TRUE)
plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
points(fish.site,pch=21,bg=plotcolor,cex=1.2)
MI_fish_all.mrt$where

If I run the points command and insert the group membership direct from the
MRT analysis e.g.  bg=MI_fish_all.mrt$where , then the subsequent points
plot up correctly with a different colour for each group.However if I try
to impose my own colour combo with plotcolor.....It prints colours for 2
groups and leaves the rest uncoloured.

The call to  MI_fish_all.mrt$where gives...
 [1] 3 3 8 6 6 9 5 5 9 3 8 6 9 6 5 9 5 3 8 6 9 6 5 9 5 3 3 8 6 6 9 5 5 9 6
9 5 9.

These are the split groupings for all 39 sites in the analysis and there
are 5 numbers corresponding to 5 final leaves in the tree.

I cant see why my colour scheme isnt being recognised.

All help accepted.

Andy


-- 
Andrew Halford Ph.D
Senior Coastal Fisheries Scientist
Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
New Caledonia | Noum?a, Nouvelle-Cal?donie

	[[alternative HTML version deleted]]


From percent||101 @end|ng |rom gm@||@com  Mon Aug  3 20:48:30 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Mon, 3 Aug 2020 20:48:30 +0200
Subject: [R] hist from a list
In-Reply-To: <20200731162847.GB106339@posteo.no>
References: <CAB-TgNv88YE29BkrXg9teFoMGXVOGfrYtDWy+Ltb8znRK9_OFQ@mail.gmail.com>
 <42a74b91-08ed-f5f2-b621-193e447dd824@dewey.myzen.co.uk>
 <70ef6db0-8a9d-d140-8347-b4e8b758f640@sapo.pt>
 <CAPPM_gQTOQwXdiMQtD_smhZDJ7uAjwyfT65TR_J-0Vhh+xhYqg@mail.gmail.com>
 <20200731162847.GB106339@posteo.no>
Message-ID: <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>

Hi Rasmus, Josh and Rui,

First of all many thanks in advance about your help.

The first thig is sometimes you say " you are posting in HTML and that
makes the
post unreadable as this is a plain text list" how can I put the code in the
correct way, not html (attaching in txt?)

The second about the code:

I have used this:

bwc <- cbind(bwfinal2,bwfinal)
colnames(bwc)=c("Accion","reval")
df <- matrix(unlist(bwc), nrow=nrow(bwc), byrow=F)
colnames(bwchist)=c("Accion","reval")
bwchist <-as.data.frame(bwc[order(df[,2]), ])

bwchist is the ordered cum stock returns in the year but because is a list
it is not possible to plot and histogram with x (names of stocks) and the x
axist the value of cum stocks (reval)

when I put dput(bwchist) the console says:

dput(bwchist)
structure(list(Accion = list("REE", "Enagas", "Grifols", "Ferrovial",
    "Acerinox", "Naturgy", "Inditex", "Bankia", "ENCE", "Aena",
    "Bankinter", "Mapfre", "CaixaBank", "CIE", "Colonial", "Almirall",
    "Indra", "ArcelorMittal", "ACS", "Telefonica", "Amadeus",
    "BBVA", "Merlin", "Santander", "Repsol", "Melia", "Sabadell",
    "IAG", "Acciona", "Endesa", "MasMovil", "Iberdrola", "SGamesa",
    "Viscofan", "Cellnex"), reval = list(-0.0200827282700085,
    -0.0590294115600855, -0.214126598790964, -0.220773677809979,
    -0.229653300324357, -0.257944379583984, -0.283942789063822,
    -0.285159347392533, -0.303814713896458, -0.30734460425763,
    -0.309408155539818, -0.319912221435868, -0.322790949659181,
    -0.344047579452905, -0.347919538415482, -0.356898907103825,
    -0.374263261296661, -0.40147247119078, -0.405150043834815,
    -0.406022775042175, -0.413786100987797, -0.440679109311707,
    -0.442603156492871, -0.491634140733524, -0.499254932434042,
    -0.6, -0.709737357505148, -0.724461258850966, 0.0220528711420083,
    0.0462767672643172, 0.115044247787611, 0.238734548714937,
    0.274578114644054, 0.343422896082666, 0.387826126094928)), class =
"data.frame", row.names = c(NA,
-35L))

I try to make an hist or barplot but because it is a list no way to obtain
the plot.

Many thanks again for your help.

I have printed two manuals to improve my level, but if you can help me, I
would be very very gratefull.



El vie., 31 jul. 2020 a las 18:28, Rasmus Liland (<jral at posteo.no>)
escribi?:

> On 2020-07-31 10:07 -0500, Joshua Ulrich wrote:
> | On Fri, Jul 31, 2020 at 9:55 AM Rui Barradas wrote:
> | | ?s 15:44 de 31/07/2020, Michael Dewey escreveu:
> | | | Dear Pedro
> | | |
> | | | Some comments in-line
> | | |
> | | | On 30/07/2020 21:16, Pedro p?ramo wrote:
> | | | | Hi all,
> | | | |
> | | | | I attach my code, the think is I
> | | | | want to make a bar plot the last
> | | | | variable called "bwchist" so the
> | | | | X axis are "Accion" and the y
> | | | | axis are "reval" values.
> | | | |
> | | | | I have prove class(bwchist) and
> | | | | says dataframe but its still a
> | | | | list because it says me I have
> | | | | prove to unlist, but it doesnt
> | | | | work
> | | | |
> | | | | hist(bwchist)
> | | | | Error in hist.default(bwchist) : 'x' must be numeric
> | | |
> | | | So bwchist is not a numeric
> | | | variable as hist needs. Aboce you
> | | | said it is a data frame but data
> | | | frames are not numeric.
> | | |
> | | | For future reference your example
> | | | is way too long for anyone to go
> | | | through and try to help you. Try
> | | | next time to reduce it to the
> | | | absolute minimum by removing
> | | | sections while you still get the
> | | | error.  It is also easier to get
> | | | help if you can remove unnecessary
> | | | packages.
> | | |
> | | | It is also unreadable because you
> | | | are posting in HTML and that makes
> | | | the post unreadable as this is a
> | | | plain text list.
> | |
> | | Hello,
> | |
> | | I second Michael's opinion. When the
> | | post's code is very long, there is a
> | | tendency to have less answers.
> | |
> | | Please post the output of
> | |
> | |     dput(head(bwchist, 30))
> | |
> | | It's much shorter code and it
> | | recreates the data so we will be
> | | able to see what's wrong and try to
> | | find a solution.
> |
> | Hi Pedro,
> |
> | Another 'best practice' and polite
> | thing to do is link to other places
> | you may have cross-posted.  That will
> | give people the opportunity to see if
> | your questions has been answered in
> | another forum.
> |
> | I saw your post on R-SIG-Finance
> | (https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/014979.html),
> | and started to work on a solution.
> |
> | I don't know how to do this in
> | tidyquant, but here's how you can do
> | it with quantmod:
> |
> | # all tickers
> | tk <- c("ANA.MC", "ACS.MC", "AENA.MC", "AMS.MC", "MTS.MC", "BBVA.MC", "
> SAB.MC",
> |   "SAN.MC", "BKT.MC", "CABK.MC", "CLNX.MC", "ENG.MC", "ENC.MC", "ELE.MC
> ",
> |   "FER.MC", "GRF.MC", "IBE.MC", "ITX.MC", "COL.MC", "IAG.MC", "MAP.MC",
> |   "MEL.MC", "MRL.MC", "NTGY.MC", "REE.MC", "REP.MC", "SGRE.MC", "TEF.MC
> ",
> |   "VIS.MC", "ACX.MC", "BKIA.MC", "CIE.MC", "MAS.MC", "ALM.MC", "IDR.MC")
> |
> | # download them into an environment ('e')
> | require(quantmod)
> | getSymbols(tk, from = "2019-12-31", env = (e <- new.env()))
> |
> | # extract adjusted close column
> | adj <- lapply(e, Ad)
> | # calculate daily returns from adjusted data,
> | # merge into a xts matrix, and fill NA with 0
> | ret <- do.call(merge, c(lapply(adj, dailyReturn), fill = 0))
> | # cumulative returns
> | cumret <- cumprod(1 + ret) - 1
> | # set names
> | colnames(cumret) <- names(adj)
> | last(cumret)
> | # calculate histogram for period-to-date returns
> | hist(drop(last(cumret)))
> |
> | I'm not sure that's the histogram
> | you're looking for, but I hope it
> | gives you a start toward a solution.
> |
> | Best,
> | Josh
>
> Wow Josh!  That's very elegant.
>
> Myself now, I just plowed through the
> original code to make it simpler, but am
> at a loss as to how this histogram looks
> ...
>
>         x <- c("ANA.MC", "ACS.MC", "AENA.MC", "AMS.MC", "MTS.MC", "BBVA.MC
> ",
>           "SAB.MC", "SAN.MC", "BKT.MC", "CABK.MC", "CLNX.MC", "ENG.MC",
>           "ENC.MC", "ELE.MC", "FER.MC", "GRF.MC", "IBE.MC", "ITX.MC",
>           "COL.MC", "IAG.MC", "MAP.MC", "MEL.MC", "MRL.MC", "NTGY.MC",
>           "REE.MC", "REP.MC", "SGRE.MC", "TEF.MC", "VIS.MC", "ACX.MC",
>           "BKIA.MC", "CIE.MC", "MAS.MC", "ALM.MC", "IDR.MC")
>         stock.prices <-
>           lapply(x, function(stock) {
>             tidyquant::tq_get(x=stock,from = '2019-12-31',get =
> "stock.prices")
>           })
>         names(stock.prices) <- x
>
>         library(tidyquant)
>
>         returns <- lapply(stock.prices, function(data) {
>           tab <-
>             tq_transmute(
>               data = data,
>               select = adjusted,           # this specifies which column
> to select
>               mutate_fun = periodReturn,   # This specifies what to do
> with that column
>               period = "daily",            # This argument calculates
> Daily returns
>               col_rename = "idr_returns")  # renames the column
>           tab[,"cr"] <- cumprod(1 + tab[,"idr_returns"])
>           tab[,"cumulative_returns"] <- tab[,"cr"] - 1
>
>           dplyr::pull(
>             tab[nrow(tab[,"cumulative_returns"]),
>                           "cumulative_returns"]
>           )
>         })
>
>         bestworst <- simplify2array(returns)
>
>         namebw <-
>           c("Acciona", "ACS", "Aena", "Amadeus",
>             "ArcelorMittal", "BBVA", "Sabadell",
>             "Santander", "Bankinter",
>             "CaixaBank", "Cellnex", "Enagas",
>             "ENCE", "Endesa", "Ferrovial",
>             "Grifols", "Iberdrola", "Inditex",
>             "Colonial", "IAG", "Mapfre",
>             "Melia", "Merlin", "Naturgy", "REE",
>             "Repsol", "SGamesa", "Telefonica",
>             "Viscofan", "Acerinox", "Bankia",
>             "CIE", "MasMovil", "Almirall",
>             "Indra")
>
>         bwc <- data.frame(
>           symbol=names(bestworst),
>           Accion=namebw,
>           reval=bestworst)
>
> | | | | bwc<-cbind(bwfinal2,bwfinal)
> | | | | colnames(bwc)=c("Accion","reval")
> | | | | bwc <- as.data.frame(bwc)
>
> ... aaaand you know something's
> happening between here (where bwchist is
> created), but you don't know what it is,
> do you, Mr p?ramo?
>
> | | | | colnames(bwchist)=c("Accion","reval")
> | | | | bwchist <-as.data.frame(bwc[order(bwc$reval), ])
>
> Best,
> Rasmus
>

	[[alternative HTML version deleted]]


From pr@k@@h@n@n| @end|ng |rom gm@||@com  Tue Aug  4 13:54:23 2020
From: pr@k@@h@n@n| @end|ng |rom gm@||@com (K Purna Prakash)
Date: Tue, 4 Aug 2020 17:24:23 +0530
Subject: [R] Mathematical working procedure of duplicated() function in r
Message-ID: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>

Dear Sir(s),
I request you to provide the detailed* internal mathematical working
mechanism of the following function *for better understanding.
*x[duplicated(x) | duplicated(x, fromLast=TRUE), ]*
I am having some confusion in understanding how duplicates are being
identified when thousands of records are there.
I will look for a positive response.
Thank you,
K.Purna Prakash.

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Aug  4 15:51:26 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 4 Aug 2020 13:51:26 +0000 (UTC)
Subject: [R] Double MAD with R
In-Reply-To: <c41de121-e6ca-493c-ec98-c066c32914b4@sapo.pt>
References: <401386585.16460890.1596464541734.ref@mail.yahoo.com>
 <401386585.16460890.1596464541734@mail.yahoo.com>
 <c41de121-e6ca-493c-ec98-c066c32914b4@sapo.pt>
Message-ID: <1132519911.436880.1596549086818@mail.yahoo.com>

Dear Rui,

Many thanks for your response. 

Best,

SV







Le lundi 3 ao?t 2020 ? 16:54:35 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

No, there isn't a built-in that I know of.
Here is one:


double.mad <- function(x, include.right = FALSE, na.rm = FALSE){
? if(na.rm) x <- x[!is.na(x)]
? m <- median(x)
? odd <- (length(x) %% 2L) == 1L
? out <- if(odd){
??? if(include.right) {
????? c(lo = mad(x[x < m]), hi = mad(x[x >= m]))
??? } else {
????? c(lo = mad(x[x <= m]), hi = mad(x[x > m]))
??? }
? } else {
??? c(lo = mad(x[x < m]), hi = mad(x[x > m]))
? }
? out
}

double.mad(x)
#???? lo????? hi
#0.81543 0.44478

double.mad(c(x, 1))
#???? lo????? hi
#2.29803 0.44478

double.mad(c(x, 1), include.right = TRUE)
#???? lo????? hi
#1.03782 1.63086


Hope this helps,

Rui Barradas

?s 15:22 de 03/08/2020, varin sacha via R-help escreveu:
> Dear R-Experts,
>
> Is there an all-ready function to calculate the Double MAD (Median absolute deviation) as there is an easy function to calculate the MAD "mad function". Or I have to write my own function for Double MAD ?
>
> To calculate the double MAD, the idea is the following : for the obtained median value, we should calculate two median absolution deviations. One deviation should be calculated for the numbers below the median and one for the numbers above the median:
>
> Here is the very easy reproducible example :
>
> x<-c(2.5,4.4,3.2,2.1,1.3,2.6,5,6.6,5,5,6.1,7.2,9.4,6.9)
> mad(x)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Aug  4 16:08:06 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 4 Aug 2020 14:08:06 +0000 (UTC)
Subject: [R] confidence intervals for the difference between group means
References: <287735883.448015.1596550086626.ref@mail.yahoo.com>
Message-ID: <287735883.448015.1596550086626@mail.yahoo.com>

Dear R-experts,

Using the bootES package I can easily calculate the bootstrap confidence intervals of the means like in the toy example here below. Now, I am looking for the confidence intervals for the difference between group means. In my case, the point estimate of the mean difference is 64.4. I am looking at the 95% confidence intervals around this point estimate (64.4).

Many thanks for your response.

############
library(bootES)
a<-c(523,435,478,567,654) 
b<-c(423,523,421,467,501)
bootES(a)
bootES(b)
############


From M@tth|@@@Koh| @end|ng |rom @t@m@t@@de  Tue Aug  4 16:22:03 2020
From: M@tth|@@@Koh| @end|ng |rom @t@m@t@@de (Prof. Dr. Matthias Kohl)
Date: Tue, 4 Aug 2020 16:22:03 +0200
Subject: [R] confidence intervals for the difference between group means
In-Reply-To: <287735883.448015.1596550086626@mail.yahoo.com>
References: <287735883.448015.1596550086626.ref@mail.yahoo.com>
 <287735883.448015.1596550086626@mail.yahoo.com>
Message-ID: <49a5936b-47e3-1b19-0398-893c4a8b8c5e@stamats.de>

you could try:

library(MKinfer)
meanDiffCI(a, b, boot = TRUE)

Best
Matthias

Am 04.08.20 um 16:08 schrieb varin sacha via R-help:
> Dear R-experts,
> 
> Using the bootES package I can easily calculate the bootstrap confidence intervals of the means like in the toy example here below. Now, I am looking for the confidence intervals for the difference between group means. In my case, the point estimate of the mean difference is 64.4. I am looking at the 95% confidence intervals around this point estimate (64.4).
> 
> Many thanks for your response.
> 
> ############
> library(bootES)
> a<-c(523,435,478,567,654)
> b<-c(423,523,421,467,501)
> bootES(a)
> bootES(b)
> ############
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Prof. Dr. Matthias Kohl
www.stamats.de


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug  4 18:35:00 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 4 Aug 2020 17:35:00 +0100
Subject: [R] 
 Mathematical working procedure of duplicated() function in r
In-Reply-To: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
References: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
Message-ID: <f49bf364-4d6e-1750-b9e5-2e2b4ebeb776@sapo.pt>

Hello,

R is open source, you can see exactly what is the internal working of 
any function. You can have access to the code by typing the function's 
name without parenthesis at an R command line.

 > duplicated
function (x, incomparables = FALSE, ...)
UseMethod("duplicated")
<bytecode: 0x55e5ef683040>
<environment: namespace:base>

Now, this tells users that duplicated is a generic function, and that 
there are methods written to handle the different S3 classes of objects x.
When this happens, there is always a default method, duplicated.default

 > duplicated.default
function (x, incomparables = FALSE, fromLast = FALSE, nmax = NA,
     ...)
.Internal(duplicated(x, incomparables, fromLast, if (is.factor(x)) 
min(length(x),
     nlevels(x) + 1L) else nmax))
<bytecode: 0x55e5ef6826a0>
<environment: namespace:base>


The default method calls .Internal(duplicated, etc). So you'll have to 
download the R sources, if you haven't done it yet, and search for a 
file where that function might be. The file is

src/main/duplicate.c


Good reading.
Also, like the posting guide asks R-Help users to do, please post in 
plain text, not in HTML.

Hope this helps,

Rui Barradas

?s 12:54 de 04/08/20, K Purna Prakash escreveu:
> Dear Sir(s),
> I request you to provide the detailed* internal mathematical working
> mechanism of the following function *for better understanding.
> *x[duplicated(x) | duplicated(x, fromLast=TRUE), ]*
> I am having some confusion in understanding how duplicates are being
> identified when thousands of records are there.
> I will look for a positive response.
> Thank you,
> K.Purna Prakash.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 538280 @end|ng |rom gm@||@com  Tue Aug  4 21:22:13 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 4 Aug 2020 13:22:13 -0600
Subject: [R] 
 Mathematical working procedure of duplicated() function in r
In-Reply-To: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
References: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
Message-ID: <CAFEqCdyVzsV4muDSrMH77_M+8HGBW35oJjoTAWD9FrWfuorzzA@mail.gmail.com>

Rui pointed out that you can examine the source yourself.  FAQ 7.40
has a link to an article with detail on finding and examining the
source code.

A general algorithm for checking for duplicates follows (I have not
examined to R source code to see if they use something more clever).

Create an empty object (I will call it seen).  This could be a simple
vector, but for efficiency it is better to use an object type that has
fast lookup, e.g. binary tree, associative array/hash/dictionary, etc.

Create an empty vector of logicals the same length as x (I will call it result).

loop from 1 to the length of x (or from the length to 1 if
fromLast=TRUE), on each iteration
 check to see if the value of x[i] is in seen
   If it is: set result[i] to TRUE
   If it is not: add the current value to seen and set result[i] to false

After the loop finishes, throw away seen and reclaim the memory, then
return result.

Since it looks like you are using this on a matrix or data frame,
there is probably a preprocessing step that combines all the values on
each row into a single character string.

On Tue, Aug 4, 2020 at 6:45 AM K Purna Prakash <prakash.nani at gmail.com> wrote:
>
> Dear Sir(s),
> I request you to provide the detailed* internal mathematical working
> mechanism of the following function *for better understanding.
> *x[duplicated(x) | duplicated(x, fromLast=TRUE), ]*
> I am having some confusion in understanding how duplicates are being
> identified when thousands of records are there.
> I will look for a positive response.
> Thank you,
> K.Purna Prakash.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From @purd|e@@ @end|ng |rom gm@||@com  Tue Aug  4 23:39:56 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 5 Aug 2020 09:39:56 +1200
Subject: [R] defining group colours in a call to rda
In-Reply-To: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>
References: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>
Message-ID: <CAB8pepwCnn9qFa0NA5=yB2TFy5XhFHHi35-p2kdkkqCCrEsGSA@mail.gmail.com>

Hi,

Your example is not reproducible.
However, I suspect that the following is the problem:

c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]

Here's my version:

where = c (3, 3, 8, 6, 6, 9, 5, 5, 9, 3, 8, 6, 9, 6, 5, 9, 5, 3, 8, 6,
9, 6, 5, 9, 5, 3, 3, 8, 6, 6, 9, 5, 5, 9, 6, 9, 5, 9)
unique (where)

c("red", "green", "blue", "aquamarine", "magenta")[where]

There's five colors.
But only two of the indices are within one to five.
So, the resulting color vector contains missing values.

In the base graphics system, if you set colors to NA, it usually means no color.

I'm not sure exactly what you want to do, but I'm assuming you can fix
it from here.

On Tue, Aug 4, 2020 at 9:49 PM Andrew Halford <andrew.halford at gmail.com> wrote:
>
> Hi,
>
> I've been trying to use the output on group membership of the final leaves
> in a MRT analysis to define my own colours, however I am not getting the
> result I'm after.
>
> Here is the code
> fish.pca <-rda(fish_all.hel,scale=TRUE)
> fish.site <- scores(fish.pca,display="sites",scaling=3)
> fish.spp <-
> scores(fish.pca,display="species",scaling=3)[fish.MRT.indval$pval<=0.05,]
> plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
> points(fish.site,pch=21,bg=MI_fish_all.mrt$where,cex=1.2)
> plotcolor <-
> c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
>  fish.pca <-rda(fish_all.hel,scale=TRUE)
> plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
> points(fish.site,pch=21,bg=plotcolor,cex=1.2)
> MI_fish_all.mrt$where
>
> If I run the points command and insert the group membership direct from the
> MRT analysis e.g.  bg=MI_fish_all.mrt$where , then the subsequent points
> plot up correctly with a different colour for each group.However if I try
> to impose my own colour combo with plotcolor.....It prints colours for 2
> groups and leaves the rest uncoloured.
>
> The call to  MI_fish_all.mrt$where gives...
>  [1] 3 3 8 6 6 9 5 5 9 3 8 6 9 6 5 9 5 3 8 6 9 6 5 9 5 3 3 8 6 6 9 5 5 9 6
> 9 5 9.
>
> These are the split groupings for all 39 sites in the analysis and there
> are 5 numbers corresponding to 5 final leaves in the tree.
>
> I cant see why my colour scheme isnt being recognised.
>
> All help accepted.
>
> Andy
>
>
> --
> Andrew Halford Ph.D
> Senior Coastal Fisheries Scientist
> Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
> New Caledonia | Noum?a, Nouvelle-Cal?donie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug  4 23:45:00 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 4 Aug 2020 22:45:00 +0100
Subject: [R] Arrange data
In-Reply-To: <CAO29qn7_qpuOvDodrWUCm+3Js7mXrRhAYa0-kmunEyWZbMMUbA@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <de75298f-9ba6-2ed3-5e2b-4095424f9834@sapo.pt>
 <CAO29qn7_qpuOvDodrWUCm+3Js7mXrRhAYa0-kmunEyWZbMMUbA@mail.gmail.com>
Message-ID: <63668df7-0823-0a33-3e31-71a794e85b28@sapo.pt>

Hello,

Please keep cc-ing the list R-help is threaded and questions and answers 
might be of help to others in the future.

As for the question, see if the following code does what you want.
First, create a logical index i of the months between 7 and 3 and use 
that index to subset the original data.frame. Then, a cumsum trick gives 
a vector M defining the data grouping. Group and compute the Value means 
with aggregate. Finally, since each group spans a year border, create a 
more meaningful Years column and put everything together.

df1 <- read.csv("mddat.csv")

i <- with(df1, (Month >= 7 & Month <= 12) | (Month >= 1 & Month <= 3))
df2 <- df1[i, ]
M <- cumsum(c(FALSE, diff(as.integer(row.names(df2))) > 1))

agg <- aggregate(Value ~ M, df2, mean)
Years <- sapply(split(df2$Year, M), function(x){paste(x[1], 
x[length(x)], sep = "-")})
final <- cbind.data.frame(Years, Value = agg[["Value"]])

head(final)
#      Years    Value
#0 1975-1975 87.00000
#1 1975-1976 89.44444
#2 1976-1977 85.77778
#3 1977-1978 81.55556
#4 1978-1979 71.55556
#5 1979-1980 75.77778


Hope this helps,

Rui Barradas



?s 20:44 de 04/08/20, Md. Moyazzem Hossain escreveu:
> Dear Rui,
> 
> Thanks a lot for your help.
> 
> It is working. Now I am also trying to find the average of values for 
> *July 1975 to March 1976* and record as the value of the year 1975. 
> Moreover, I want to continue it up to the year 2017. You may check the 
> attached file for data (mddat.csv).
> 
> I use the following function but got error
> aggregate(Value ~ Year, data = subset(df1, Month >= 7 & Month <= 3), FUN 
> = mean)
> 
> Please help me again. Thanks in advance.
> 
> Best Regards,
> Md
> 
> On Mon, Aug 3, 2020 at 11:28 PM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     And here is another way, with aggregate.
> 
>     Make up test data.
> 
>     set.seed(2020)
>     df1 <- expand.grid(Year = 2000:2018, Month = 1:12)
>     df1 <- df1[order(df1$Year),]
>     df1$Value <- sample(20:30, nrow(df1), TRUE)
>     head(df1)
> 
> 
>     #Use subset to keep only the relevant months
>     aggregate(Value ~ Year, data = subset(df1, Month <= 7), FUN = mean)
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 12:33 de 03/08/2020, Rasmus Liland escreveu:
>      > On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>      >> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain
>     <hossainmm at juniv.edu <mailto:hossainmm at juniv.edu>> wrote:
>      >>> Hi,
>      >>>
>      >>> I have a dataset having monthly
>      >>> observations (from January to
>      >>> December) over a period of time like
>      >>> (2000 to 2018). Now, I am trying to
>      >>> take an average the value from
>      >>> January to July of each year.
>      >>>
>      >>> The data looks like
>      >>> Year? ? Month? Value
>      >>> 2000? ? 1? ? ? ? ?25
>      >>> 2000? ? 2? ? ? ? ?28
>      >>> 2000? ? 3? ? ? ? ?22
>      >>> ....? ? ......? ? ? .....
>      >>> 2000? ? 12? ? ? ?26
>      >>> 2001? ? ?1? ? ? ?27
>      >>> .......? ? ? ? ?........
>      >>> 2018? ? 11? ? ? ?30
>      >>> 20118? ?12? ? ? 29
>      >>>
>      >>> Can someone help me in this regard?
>      >>>
>      >>> Many thanks in advance.
>      >> Hi Md,
>      >> One way is to form a subset of your
>      >> data, then calculate the means by
>      >> year:
>      >>
>      >> # assume your data is named mddat
>      >> mddat2<-mddat[mddat$month < 7,]
>      >> jan2jun<-by(mddat2$value,mddat2$year,mean)
>      >>
>      >> Jim
>      > Hi Md,
>      >
>      > you can also define the period in a new
>      > column, and use aggregate like this:
>      >
>      >? ? ? ?Md <- structure(list(
>      >? ? ? ?Year = c(2000L, 2000L, 2000L,
>      >? ? ? ?2000L, 2001L, 2018L, 2018L),
>      >? ? ? ?Month = c(1L, 2L, 3L, 12L, 1L,
>      >? ? ? ?11L, 12L),
>      >? ? ? ?Value = c(25L, 28L, 22L, 26L,
>      >? ? ? ?27L, 30L, 29L)),
>      >? ? ? ?class = "data.frame",
>      >? ? ? ?row.names = c(NA, -7L))
>      >
>      >? ? ? ?Md[Md$Month %in%
>      >? ? ? ? ? ? ? ?1:6,"Period"] <- "first six months of the year"
>      >? ? ? ?Md[Md$Month %in% 7:12,"Period"] <- "last six months of the
>     year"
>      >
>      >? ? ? ?aggregate(
>      >? ? ? ? ?formula=Value~Year+Period,
>      >? ? ? ? ?data=Md,
>      >? ? ? ? ?FUN=mean)
>      >
>      > Rasmus
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
> 
> 
>     -- 
>     Este e-mail foi verificado em termos de v?rus pelo software
>     antiv?rus Avast.
>     https://www.avast.com/antivirus
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From d@071185 @end|ng |rom gm@||@com  Tue Aug  4 21:03:13 2020
From: d@071185 @end|ng |rom gm@||@com (Debasmita Sur)
Date: Wed, 5 Aug 2020 00:33:13 +0530
Subject: [R] finding nearest zip codes
Message-ID: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>

Dear R-experts,
I have two lists of US zip codes and want to pick the nearest zip code from
second list against my first list.e.g.30043 (from second list) is closest
to the zip code 30094 (from first list).So,it should come against 30094.The
code should compare the distance from each zip and pick the nearest one.
I have written the following code. It is giving proper results for many,
but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
giving proper minimum distance. Please note it will be effective for 5
digit zip codes. Any help will be highly appreciated.

df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")

results<-merge(x=df1,y=zipcode,all.x=TRUE)
results1<-merge(x=df2,y=zipcode,all.x=TRUE)
distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))

rnum=apply(distance, 1, which.min)
mindist=apply(distance, 1, min)

final<-cbind(results,results1$zip[unlist(rnum)],mindist)


Thanks & Regards,
*Debasmita *

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Aug  5 03:38:45 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 4 Aug 2020 21:38:45 -0400
Subject: [R] [External]  finding nearest zip codes
In-Reply-To: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
Message-ID: <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>

verify that you actually have five-digit zip codes stored as
characters. New Jersey and Massachusetts have zero as
the first digit.  When these codes are saved as numbers, they become
four-digit codes and will probably cause errors.
For example Cambridge, Mass is '02138', and would be reported as 2138
when interpreted as a number..

On Tue, Aug 4, 2020 at 9:29 PM Debasmita Sur <ds071185 at gmail.com> wrote:
>
> Dear R-experts,
> I have two lists of US zip codes and want to pick the nearest zip code from
> second list against my first list.e.g.30043 (from second list) is closest
> to the zip code 30094 (from first list).So,it should come against 30094.The
> code should compare the distance from each zip and pick the nearest one.
> I have written the following code. It is giving proper results for many,
> but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
> giving proper minimum distance. Please note it will be effective for 5
> digit zip codes. Any help will be highly appreciated.
>
> df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
> df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
>
> results<-merge(x=df1,y=zipcode,all.x=TRUE)
> results1<-merge(x=df2,y=zipcode,all.x=TRUE)
> distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
>
> rnum=apply(distance, 1, which.min)
> mindist=apply(distance, 1, min)
>
> final<-cbind(results,results1$zip[unlist(rnum)],mindist)
>
>
> Thanks & Regards,
> *Debasmita *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug  5 03:54:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Aug 2020 18:54:09 -0700
Subject: [R] finding nearest zip codes
In-Reply-To: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
Message-ID: <CAGxFJbT_zHmCWyAwmPzXjrKJrRbMX0zk3iBBBqYmAV1oqinfJA@mail.gmail.com>

In addition to Rich's advice...
as always, have you searched?!
e.g. on "zip code distances" or similar at rseek.org.

This appears to have been asked before and there are tools available.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 4, 2020 at 6:29 PM Debasmita Sur <ds071185 at gmail.com> wrote:

> Dear R-experts,
> I have two lists of US zip codes and want to pick the nearest zip code from
> second list against my first list.e.g.30043 (from second list) is closest
> to the zip code 30094 (from first list).So,it should come against 30094.The
> code should compare the distance from each zip and pick the nearest one.
> I have written the following code. It is giving proper results for many,
> but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
> giving proper minimum distance. Please note it will be effective for 5
> digit zip codes. Any help will be highly appreciated.
>
> df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
> df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
>
> results<-merge(x=df1,y=zipcode,all.x=TRUE)
> results1<-merge(x=df2,y=zipcode,all.x=TRUE)
>
> distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
>
> rnum=apply(distance, 1, which.min)
> mindist=apply(distance, 1, min)
>
> final<-cbind(results,results1$zip[unlist(rnum)],mindist)
>
>
> Thanks & Regards,
> *Debasmita *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @ndrew@h@||ord @end|ng |rom gm@||@com  Wed Aug  5 06:32:33 2020
From: @ndrew@h@||ord @end|ng |rom gm@||@com (Andrew Halford)
Date: Wed, 5 Aug 2020 15:32:33 +1100
Subject: [R] Fwd:  defining group colours in a call to rda
In-Reply-To: <CAB8pepwQEGkCcQHci12R66KYiYvczZvXAW+hQ+S6aaw6_4DaZg@mail.gmail.com>
References: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>
 <CAB8pepwCnn9qFa0NA5=yB2TFy5XhFHHi35-p2kdkkqCCrEsGSA@mail.gmail.com>
 <CAJrFtqJyN8CnCrVi9uRSQMbs=TiU7YJOYvkn_qE5uCweOqQAuw@mail.gmail.com>
 <CAB8pepwQEGkCcQHci12R66KYiYvczZvXAW+hQ+S6aaw6_4DaZg@mail.gmail.com>
Message-ID: <CAJrFtqLna9yZT+4hgr-fVswGsJLkSdmtNjPMdi1zkwXBJAqdbw@mail.gmail.com>

---------- Forwarded message ---------
From: Abby Spurdle <spurdle.a at gmail.com>
Date: Wed, Aug 5, 2020 at 3:07 PM
Subject: Re: [R] defining group colours in a call to rda
To: Andrew Halford <andrew.halford at gmail.com>


Hi Andrew,

Perhaps you want this:

    cols <- rep_len (c ("red", "green", "blue", "aquamarine", "magenta"), 9)
    cols

Or this:

    cols = rep ("", 9)
    cols [unique (MI_fish_all.mrt$where)] = c ("red", "green", "blue",
"aquamarine", "magenta")
    cols

Then you can substitute either into your original example:

    plotcolor <- cols [MI_fish_all.mrt$where]


On Wed, Aug 5, 2020 at 1:02 PM Andrew Halford <andrew.halford at gmail.com>
wrote:
>
> Hi Abby,
>
> Apologies for not providing more info but you have worked out what I was
on about anyways.
>
> I thought it would scroll through and allocate the colours to each unique
number sequentially. I will add more colours to my vector but I would like
to know if it is possible to do what I originally hoped for.
>
> cheers
>
> Andy
>
> On Wed, Aug 5, 2020 at 8:40 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>> Hi,
>>
>> Your example is not reproducible.
>> However, I suspect that the following is the problem:
>>
>> c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
>>
>> Here's my version:
>>
>> where = c (3, 3, 8, 6, 6, 9, 5, 5, 9, 3, 8, 6, 9, 6, 5, 9, 5, 3, 8, 6,
>> 9, 6, 5, 9, 5, 3, 3, 8, 6, 6, 9, 5, 5, 9, 6, 9, 5, 9)
>> unique (where)
>>
>> c("red", "green", "blue", "aquamarine", "magenta")[where]
>>
>> There's five colors.
>> But only two of the indices are within one to five.
>> So, the resulting color vector contains missing values.
>>
>> In the base graphics system, if you set colors to NA, it usually means
no color.
>>
>> I'm not sure exactly what you want to do, but I'm assuming you can fix
>> it from here.
>>
>> On Tue, Aug 4, 2020 at 9:49 PM Andrew Halford <andrew.halford at gmail.com>
wrote:
>> >
>> > Hi,
>> >
>> > I've been trying to use the output on group membership of the final
leaves
>> > in a MRT analysis to define my own colours, however I am not getting
the
>> > result I'm after.
>> >
>> > Here is the code
>> > fish.pca <-rda(fish_all.hel,scale=TRUE)
>> > fish.site <- scores(fish.pca,display="sites",scaling=3)
>> > fish.spp <-
>> >
scores(fish.pca,display="species",scaling=3)[fish.MRT.indval$pval<=0.05,]
>> > plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
>> > points(fish.site,pch=21,bg=MI_fish_all.mrt$where,cex=1.2)
>> > plotcolor <-
>> > c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
>> >  fish.pca <-rda(fish_all.hel,scale=TRUE)
>> > plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
>> > points(fish.site,pch=21,bg=plotcolor,cex=1.2)
>> > MI_fish_all.mrt$where
>> >
>> > If I run the points command and insert the group membership direct
from the
>> > MRT analysis e.g.  bg=MI_fish_all.mrt$where , then the subsequent
points
>> > plot up correctly with a different colour for each group.However if I
try
>> > to impose my own colour combo with plotcolor.....It prints colours for
2
>> > groups and leaves the rest uncoloured.
>> >
>> > The call to  MI_fish_all.mrt$where gives...
>> >  [1] 3 3 8 6 6 9 5 5 9 3 8 6 9 6 5 9 5 3 8 6 9 6 5 9 5 3 3 8 6 6 9 5 5
9 6
>> > 9 5 9.
>> >
>> > These are the split groupings for all 39 sites in the analysis and
there
>> > are 5 numbers corresponding to 5 final leaves in the tree.
>> >
>> > I cant see why my colour scheme isnt being recognised.
>> >
>> > All help accepted.
>> >
>> > Andy
>> >
>> >
>> > --
>> > Andrew Halford Ph.D
>> > Senior Coastal Fisheries Scientist
>> > Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848
Noumea,
>> > New Caledonia | Noum?a, Nouvelle-Cal?donie
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Andrew Halford Ph.D
> Senior Coastal Fisheries Scientist
> Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
> New Caledonia | Noum?a, Nouvelle-Cal?donie


-- 
Andrew Halford Ph.D
Senior Coastal Fisheries Scientist
Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
New Caledonia | Noum?a, Nouvelle-Cal?donie

	[[alternative HTML version deleted]]


From d@071185 @end|ng |rom gm@||@com  Wed Aug  5 08:01:01 2020
From: d@071185 @end|ng |rom gm@||@com (Debasmita Sur)
Date: Wed, 5 Aug 2020 11:31:01 +0530
Subject: [R] [External]  finding nearest zip codes
In-Reply-To: <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
 <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>
Message-ID: <CACtCA_N1WJo-1A_AhAVDCj4PBiLHovbVtNafzSURu8a_Bf3GAg@mail.gmail.com>

Hi Richard,

I have not considered the 4 digit zip codes, I have taken only 5 digits. I
have attached two folders, in the 'air' folder I have some specific zip
codes and in output I got proper results, whereas in the 'par' folder I got
'NA's in the minimum distance column. Actually, the problem was to find the
nearest store for a specific brand.

Thanks,
*Debasmita*

On Wed, Aug 5, 2020 at 7:08 AM Richard M. Heiberger <rmh at temple.edu> wrote:

> verify that you actually have five-digit zip codes stored as
> characters. New Jersey and Massachusetts have zero as
> the first digit.  When these codes are saved as numbers, they become
> four-digit codes and will probably cause errors.
> For example Cambridge, Mass is '02138', and would be reported as 2138
> when interpreted as a number..
>
> On Tue, Aug 4, 2020 at 9:29 PM Debasmita Sur <ds071185 at gmail.com> wrote:
> >
> > Dear R-experts,
> > I have two lists of US zip codes and want to pick the nearest zip code
> from
> > second list against my first list.e.g.30043 (from second list) is closest
> > to the zip code 30094 (from first list).So,it should come against
> 30094.The
> > code should compare the distance from each zip and pick the nearest one.
> > I have written the following code. It is giving proper results for many,
> > but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
> > giving proper minimum distance. Please note it will be effective for 5
> > digit zip codes. Any help will be highly appreciated.
> >
> > df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
> > df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
> >
> > results<-merge(x=df1,y=zipcode,all.x=TRUE)
> > results1<-merge(x=df2,y=zipcode,all.x=TRUE)
> >
> distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
> >
> > rnum=apply(distance, 1, which.min)
> > mindist=apply(distance, 1, min)
> >
> > final<-cbind(results,results1$zip[unlist(rnum)],mindist)
> >
> >
> > Thanks & Regards,
> > *Debasmita *
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug  5 08:12:39 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 04 Aug 2020 23:12:39 -0700
Subject: [R] [External]  finding nearest zip codes
In-Reply-To: <CACtCA_N1WJo-1A_AhAVDCj4PBiLHovbVtNafzSURu8a_Bf3GAg@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
 <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>
 <CACtCA_N1WJo-1A_AhAVDCj4PBiLHovbVtNafzSURu8a_Bf3GAg@mail.gmail.com>
Message-ID: <1862AB56-5524-414D-BC73-734290EF1299@dcn.davis.ca.us>

If you fail to force the zip code data to be read in as character data then you will have problems. Your code does not use the colClasses argument or the stringsAsFactors=FALSE argument (needed if you are using a version of R earlier than 4.x). Richard was suggesting that you use the str function to examine your data frames to verify correct data types were present.

Please read the Posting Guide... using HTML formatted email and attaching disallowed file types as you have done are good ways to prevent useful answers from being offered.

On August 4, 2020 11:01:01 PM PDT, Debasmita Sur <ds071185 at gmail.com> wrote:
>Hi Richard,
>
>I have not considered the 4 digit zip codes, I have taken only 5
>digits. I
>have attached two folders, in the 'air' folder I have some specific zip
>codes and in output I got proper results, whereas in the 'par' folder I
>got
>'NA's in the minimum distance column. Actually, the problem was to find
>the
>nearest store for a specific brand.
>
>Thanks,
>*Debasmita*
>
>On Wed, Aug 5, 2020 at 7:08 AM Richard M. Heiberger <rmh at temple.edu>
>wrote:
>
>> verify that you actually have five-digit zip codes stored as
>> characters. New Jersey and Massachusetts have zero as
>> the first digit.  When these codes are saved as numbers, they become
>> four-digit codes and will probably cause errors.
>> For example Cambridge, Mass is '02138', and would be reported as 2138
>> when interpreted as a number..
>>
>> On Tue, Aug 4, 2020 at 9:29 PM Debasmita Sur <ds071185 at gmail.com>
>wrote:
>> >
>> > Dear R-experts,
>> > I have two lists of US zip codes and want to pick the nearest zip
>code
>> from
>> > second list against my first list.e.g.30043 (from second list) is
>closest
>> > to the zip code 30094 (from first list).So,it should come against
>> 30094.The
>> > code should compare the distance from each zip and pick the nearest
>one.
>> > I have written the following code. It is giving proper results for
>many,
>> > but in mindist, it is showing 'NAs'. But for some of the zip codes,
>it is
>> > giving proper minimum distance. Please note it will be effective
>for 5
>> > digit zip codes. Any help will be highly appreciated.
>> >
>> > df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
>> > df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
>> >
>> > results<-merge(x=df1,y=zipcode,all.x=TRUE)
>> > results1<-merge(x=df2,y=zipcode,all.x=TRUE)
>> >
>>
>distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
>> >
>> > rnum=apply(distance, 1, which.min)
>> > mindist=apply(distance, 1, min)
>> >
>> > final<-cbind(results,results1$zip[unlist(rnum)],mindist)
>> >
>> >
>> > Thanks & Regards,
>> > *Debasmita *
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@r||61 @end|ng |rom w|ndow@||ve@com  Wed Aug  5 02:10:42 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-9?Q?ahmet_varl=FD?=)
Date: Wed, 5 Aug 2020 00:10:42 +0000
Subject: [R] find number of consecutive days in NC files
Message-ID: <VI1PR0302MB31999746078946CC2D26E474BB4B0@VI1PR0302MB3199.eurprd03.prod.outlook.com>

There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated. However, I couldn't reach exactly what I wanted.

nctoarray <- function(ncfname, varid = NA) { nc <- nc_open(ncfname) a <- aperm(ncvar_get(nc), c(2,1,3)) nc_close(nc) a }

function(x, threshold = 0.28, below = TRUE) { if (below) {

y <- ifelse(x < threshold,1,0)
   } else y <- ifelse(x > threshold,1,0)
 y2 <- rle(y)
 sel <- which(y2$values == 1)
 max(y2$lengths[sel])    }


m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))

m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug  5 09:33:19 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 05 Aug 2020 00:33:19 -0700
Subject: [R] find number of consecutive days in NC files
In-Reply-To: <VI1PR0302MB31999746078946CC2D26E474BB4B0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB31999746078946CC2D26E474BB4B0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <DD54021B-B4F9-46FB-8202-729B561AD9D8@dcn.davis.ca.us>

rle( x > thresh )

On August 4, 2020 5:10:42 PM PDT, "ahmet varl?" <varli61 at windowslive.com> wrote:
>There are 365 days of soil moisture NC files and I am trying to find
>out how many days the values are below and above this certain threshold
>are repeated. However, I couldn't reach exactly what I wanted.
>
>nctoarray <- function(ncfname, varid = NA) { nc <- nc_open(ncfname) a
><- aperm(ncvar_get(nc), c(2,1,3)) nc_close(nc) a }
>
>function(x, threshold = 0.28, below = TRUE) { if (below) {
>
>y <- ifelse(x < threshold,1,0)
>   } else y <- ifelse(x > threshold,1,0)
> y2 <- rle(y)
> sel <- which(y2$values == 1)
> max(y2$lengths[sel])    }
>
>
>m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
>
>m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug  5 14:06:13 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 5 Aug 2020 22:06:13 +1000
Subject: [R] Arrange data
In-Reply-To: <CAO29qn4qjv=i0SGr0QLZSzmpOuW1imhUqeiK4-ivwMj_fk75UQ@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
 <CA+8X3fWF4TBbhqiUErDKKKw-j8nbK8+oEh0kV7+Ow8RiaU6kug@mail.gmail.com>
 <CAO29qn4qjv=i0SGr0QLZSzmpOuW1imhUqeiK4-ivwMj_fk75UQ@mail.gmail.com>
Message-ID: <CA+8X3fUvBuPjJR+xkp+mL2KLfg3DqqOhAcEnqdiDVSpZ6LWzhg@mail.gmail.com>

Hi Md,
I think the errors are that you forgot to initialize "m", calculated
the mean outside the loops and forgot the final brace:

m<-rep(0,44)
for(i in 1975:2017) {
  for(j in 1:44) {
   mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
      mddat$Year == (i+1) & mddat$Month <= 6,]
   m[j]=mean(mddat2$Value)
 }
}

Jim

On Wed, Aug 5, 2020 at 6:04 AM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Dear Jim,
>
> Thank you very much. You are right. It is good now. However, I want to continue it up to the year 2017.
>
> I use the following code but got the error
>
> for(i in 1975:2017){
>   for(j in 1:44){
> mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
>                 mddat$Year == (i+1) & mddat$Month <= 6,]
> }
> m[j]=mean(mddat2$Value)
>
> }
> m
>
> Please help me in this regard. Many thanks in advance.
>
> Regards,
> Md
>
> On Tue, Aug 4, 2020 at 8:41 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Your problem is in the subset operation. You have asked for a value of
>> month greater or equal to 7 and less than or equal to 6. You probably
>> got an error message that told you that the data were of length zero
>> or something similar. If you check the result of that statement:
>>
>> > mddat$month >= 7 & mddat$month <= 6
>> logical(0)
>>
>> In other words, the two logical statements when ANDed cannot produce a
>> result. A number cannot be greater than or equal to 7 AND less than or
>> equal to 6. What you want is:
>>
>> mddat2<-mddat[mddat$Year == 1975 & mddat$Month >= 7 |
>>  mddat$Year == 1976 & mddat$Month <= 6,]
>> mean(mddat2$Value)
>> [1] 88.91667
>>
>> Apart from that, your email client is inserting EOL characters that
>> cause an error when pasted into R.
>>
>> Error: unexpected input in "?"
>>
>> Probably due to MS Outlook, this has been happening quite a bit lately.
>>
>> Jim
>>
>> On Mon, Aug 3, 2020 at 11:30 PM Md. Moyazzem Hossain
>> <hossainmm at juniv.edu> wrote:
>> >
>> > Dear Jim,
>> >
>> > Thank you very much. It is working now.
>> >
>> > However, I am also trying to find the average of the value from July 1975 to June 1976 and recorded as the value for the year 1975 but got an error message. I am attaching the data file here. Please check the attachment.
>> >
>> > mddat=read.csv("F:/mddat.csv", header=TRUE)
>> > mddat2<-mddat[mddat$Month >=7 & mddat$Month <= 6,]
>> > jan2jun<-by(mddat2$Value,mddat2$Year,mean)
>> > jan2jun
>> >
>> > Please help me again and many thanks in advance.
>> >
>> > Md
>> >
>> >
>> > On Mon, Aug 3, 2020 at 12:33 PM Rasmus Liland <jral at posteo.no> wrote:
>> >>
>> >> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>> >> > On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>> >> > >
>> >> > > Hi,
>> >> > >
>> >> > > I have a dataset having monthly
>> >> > > observations (from January to
>> >> > > December) over a period of time like
>> >> > > (2000 to 2018). Now, I am trying to
>> >> > > take an average the value from
>> >> > > January to July of each year.
>> >> > >
>> >> > > The data looks like
>> >> > > Year    Month  Value
>> >> > > 2000    1         25
>> >> > > 2000    2         28
>> >> > > 2000    3         22
>> >> > > ....    ......      .....
>> >> > > 2000    12       26
>> >> > > 2001     1       27
>> >> > > .......         ........
>> >> > > 2018    11       30
>> >> > > 20118   12      29
>> >> > >
>> >> > > Can someone help me in this regard?
>> >> > >
>> >> > > Many thanks in advance.
>> >> >
>> >> > Hi Md,
>> >> > One way is to form a subset of your
>> >> > data, then calculate the means by
>> >> > year:
>> >> >
>> >> > # assume your data is named mddat
>> >> > mddat2<-mddat[mddat$month < 7,]
>> >> > jan2jun<-by(mddat2$value,mddat2$year,mean)
>> >> >
>> >> > Jim
>> >>
>> >> Hi Md,
>> >>
>> >> you can also define the period in a new
>> >> column, and use aggregate like this:
>> >>
>> >>         Md <- structure(list(
>> >>         Year = c(2000L, 2000L, 2000L,
>> >>         2000L, 2001L, 2018L, 2018L),
>> >>         Month = c(1L, 2L, 3L, 12L, 1L,
>> >>         11L, 12L),
>> >>         Value = c(25L, 28L, 22L, 26L,
>> >>         27L, 30L, 29L)),
>> >>         class = "data.frame",
>> >>         row.names = c(NA, -7L))
>> >>
>> >>         Md[Md$Month %in%
>> >>                 1:6,"Period"] <- "first six months of the year"
>> >>         Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
>> >>
>> >>         aggregate(
>> >>           formula=Value~Year+Period,
>> >>           data=Md,
>> >>           FUN=mean)
>> >>
>> >> Rasmus
>> >
>> >
>> >
>
>
>


From percent||101 @end|ng |rom gm@||@com  Wed Aug  5 21:42:59 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Wed, 5 Aug 2020 21:42:59 +0200
Subject: [R] Print and plot a cross Data
Message-ID: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>

Hi all,

I have a csv (extracted from a web) I attach the data:

I use this code to read the data;

library("readr")

tusDatos <- read_csv('~/datayield.csv')

In this CSV, I want to use three columns:

 tusDatos$DATA_TYPE_FM,  (will be X axis)
tusDatos$TIME_PERIOD (will be the pivot to search the values)
tusDatos$OBS_VALUE (Y Values)

In Data_Type_FM I want to plot a graph where only some rows (included in
thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
specific DATE.

So for each day (time period) I will plot a plot imagine 04/08/2020 (a
value on TIME_PERIOD) for the values

c(  PY_1Y, PY_2Y,
PY_3Y, PY_4Y,
PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM

In excel for me is "easy" but in R I dont know how to proceed can you give
me some clue to make this king of operations?

If I wanted to do a 3D PloT would be possible? only also for this limited
values c(  PY_1Y, PY_2Y,
PY_3Y, PY_4Y,
PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM

tusDatos$DATA_TYPE_FM,  (will be X axis)
tusDatos$TIME_PERIOD (Z axis)
tusDatos$OBS_VALUE (Y Values)

Hope I explained properly and hope you can help and guide.



 datayield.csv
<https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug  6 02:24:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 6 Aug 2020 10:24:07 +1000
Subject: [R] Print and plot a cross Data
In-Reply-To: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
Message-ID: <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>

Hi Pedro,
I'm not exactly sure of what you want, but try this:

# I downloaded the CSV file as datayield.csv
tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
library(scatterplot3d)
data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
row_subset<-tus.datos$DATA_TYPE %in% data_types
scatterplot3d(tus.datos$DATA_TYPE_FM[row_subset],
 tus.datos$OBS_VALUE[row_subset],
 tus.datos$TIME_PERIOD[row_subset],
 color=order(as.numeric(tus.datos$DATA_TYPE[row_subset])))
legend(9,8,data_types,pch=1,col=1:7,xpd=TRUE)

I used a few tricks to get this to work without being too long a
script. The color for PY_7Y is yellow, and this can be changed with a
bit of extra code.

Jim

On Thu, Aug 6, 2020 at 8:40 AM Pedro p?ramo <percentil101 at gmail.com> wrote:
>
> Hi all,
>
> I have a csv (extracted from a web) I attach the data:
>
> I use this code to read the data;
>
> library("readr")
>
> tusDatos <- read_csv('~/datayield.csv')
>
> In this CSV, I want to use three columns:
>
>  tusDatos$DATA_TYPE_FM,  (will be X axis)
> tusDatos$TIME_PERIOD (will be the pivot to search the values)
> tusDatos$OBS_VALUE (Y Values)
>
> In Data_Type_FM I want to plot a graph where only some rows (included in
> thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
> specific DATE.
>
> So for each day (time period) I will plot a plot imagine 04/08/2020 (a
> value on TIME_PERIOD) for the values
>
> c(  PY_1Y, PY_2Y,
> PY_3Y, PY_4Y,
> PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>
> In excel for me is "easy" but in R I dont know how to proceed can you give
> me some clue to make this king of operations?
>
> If I wanted to do a 3D PloT would be possible? only also for this limited
> values c(  PY_1Y, PY_2Y,
> PY_3Y, PY_4Y,
> PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>
> tusDatos$DATA_TYPE_FM,  (will be X axis)
> tusDatos$TIME_PERIOD (Z axis)
> tusDatos$OBS_VALUE (Y Values)
>
> Hope I explained properly and hope you can help and guide.
>
>
>
>  datayield.csv
> <https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From percent||101 @end|ng |rom gm@||@com  Thu Aug  6 15:54:01 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Thu, 6 Aug 2020 15:54:01 +0200
Subject: [R] Print and plot a cross Data
In-Reply-To: <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
 <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
Message-ID: <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>

Hi Jim,

Many thanks for your help, I will try a 2D plot and then pass to 3D.

I am trying something like this:

tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)

data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")

row_subset<-tus.datos$DATA_TYPE %in% data_types

x<-tus.datos$DATA_TYPE_FM[row_subset]
y<-tus.datos$OBS_VALUE[row_subset]

PERIOD<-tus.datos$TIME_PERIOD=="01/06/2020"

for (PERIOD="TRUE") {


plot(x, y)

}


And the error is

 for (PERIOD="TRUE") {
Error: inesperado '=' in "for (PERIOD="
>
>
> plot(x, y)
Error: no se puede ubicar un vector de tama?o  1.3 Gb
>
> }
Error: inesperado '}' in "}"
>



El jue., 6 ago. 2020 a las 2:24, Jim Lemon (<drjimlemon at gmail.com>)
escribi?:

> Hi Pedro,
> I'm not exactly sure of what you want, but try this:
>
> # I downloaded the CSV file as datayield.csv
> tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
> library(scatterplot3d)
> data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
> row_subset<-tus.datos$DATA_TYPE %in% data_types
> scatterplot3d(tus.datos$DATA_TYPE_FM[row_subset],
>  tus.datos$OBS_VALUE[row_subset],
>  tus.datos$TIME_PERIOD[row_subset],
>  color=order(as.numeric(tus.datos$DATA_TYPE[row_subset])))
> legend(9,8,data_types,pch=1,col=1:7,xpd=TRUE)
>
> I used a few tricks to get this to work without being too long a
> script. The color for PY_7Y is yellow, and this can be changed with a
> bit of extra code.
>
> Jim
>
> On Thu, Aug 6, 2020 at 8:40 AM Pedro p?ramo <percentil101 at gmail.com>
> wrote:
> >
> > Hi all,
> >
> > I have a csv (extracted from a web) I attach the data:
> >
> > I use this code to read the data;
> >
> > library("readr")
> >
> > tusDatos <- read_csv('~/datayield.csv')
> >
> > In this CSV, I want to use three columns:
> >
> >  tusDatos$DATA_TYPE_FM,  (will be X axis)
> > tusDatos$TIME_PERIOD (will be the pivot to search the values)
> > tusDatos$OBS_VALUE (Y Values)
> >
> > In Data_Type_FM I want to plot a graph where only some rows (included in
> > thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
> > specific DATE.
> >
> > So for each day (time period) I will plot a plot imagine 04/08/2020 (a
> > value on TIME_PERIOD) for the values
> >
> > c(  PY_1Y, PY_2Y,
> > PY_3Y, PY_4Y,
> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
> >
> > In excel for me is "easy" but in R I dont know how to proceed can you
> give
> > me some clue to make this king of operations?
> >
> > If I wanted to do a 3D PloT would be possible? only also for this limited
> > values c(  PY_1Y, PY_2Y,
> > PY_3Y, PY_4Y,
> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
> >
> > tusDatos$DATA_TYPE_FM,  (will be X axis)
> > tusDatos$TIME_PERIOD (Z axis)
> > tusDatos$OBS_VALUE (Y Values)
> >
> > Hope I explained properly and hope you can help and guide.
> >
> >
> >
> >  datayield.csv
> > <
> https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@r||61 @end|ng |rom w|ndow@||ve@com  Thu Aug  6 17:58:09 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-3?Q?ahmet_varl=B9?=)
Date: Thu, 6 Aug 2020 15:58:09 +0000
Subject: [R] find number of consecutive days in NC files by R
Message-ID: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>

Hi all,


There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily

nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)

a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }



function(x, threshold = 0.28, below = TRUE) {

    if (below) {

        y <- ifelse(x < threshold,1,0)

    } else y <- ifelse(x > threshold,1,0)



    y2 <- rle(y)

    sel <- which(y2$values == 1)

    max(y2$lengths[sel])

}



m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))



m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))




	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Aug  6 19:49:50 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 06 Aug 2020 10:49:50 -0700
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <9DC09EF7-2E8A-42C5-AE2C-6F9DB9FC9D4D@dcn.davis.ca.us>

You need to make a small fake dataset that illustrates what you have and what you want out of it. Telling us you are not getting what you want is simply not useful.

On August 6, 2020 8:58:09 AM PDT, "ahmet varl?" <varli61 at windowslive.com> wrote:
>Hi all,
>
>
>There are 365 days of soil moisture NC files and I am trying to find
>out how many days the values are below and above this certain threshold
>are repeated by R. However, I couldn't reach exactly what I wanted. For
>example, Daily soil moisture is below 0.3 without interrupting how many
>days in 365 days. NC file contains annual soil moisture values daily
>
>nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
>
>a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
>
>
>
>function(x, threshold = 0.28, below = TRUE) {
>
>    if (below) {
>
>        y <- ifelse(x < threshold,1,0)
>
>    } else y <- ifelse(x > threshold,1,0)
>
>
>
>    y2 <- rle(y)
>
>    sel <- which(y2$values == 1)
>
>    max(y2$lengths[sel])
>
>}
>
>
>
>m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
>
>
>
>m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug  7 03:16:50 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 7 Aug 2020 11:16:50 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>

Hi Ahmet,
I think what you are looking for can be done using run length encoding (rle).

# make up some data
soil_moisture<-sin(seq(0,4*pi,length.out=730))+1.1
dates<-as.Date(as.Date("2018-01-01"):as.Date("2019-12-31"),
 origin=as.Date("1970-01-01"))
# get a logical vector for your condition
under.28<-soil_moisture < 0.28
# show the soil moisture against time
plot(dates,soil_moisture,pch=".",col=under.28+3,cex=2)
abline(h=0.28)
# use rle to get  the runs of low soil moisture
sm.rle<-rle(soil_moisture < 0.28)
cat("Consecutive days below 0.28",
 paste(1:sum(sm.rle$values),sm.rle$lengths[sm.rle$values==TRUE],sep="-"),
 "\n")

Jim

On Fri, Aug 7, 2020 at 3:33 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
> Hi all,
>
>
> There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily
>
> nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
>
> a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
>
>
>
> function(x, threshold = 0.28, below = TRUE) {
>
>     if (below) {
>
>         y <- ifelse(x < threshold,1,0)
>
>     } else y <- ifelse(x > threshold,1,0)
>
>
>
>     y2 <- rle(y)
>
>     sel <- which(y2$values == 1)
>
>     max(y2$lengths[sel])
>
> }
>
>
>
> m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
>
>
>
> m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug  7 07:17:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 7 Aug 2020 15:17:07 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>

Hi Ahmet,
Here is a way to get the result you ask for for one geographic grid
cell. You may want more detail or something, but this is a
"reproducible example".

# retrieved from
ftp://ftp2.psi.noaa.gov/Datasets/ncep.renalysis.dailyavgs/surface_gauss/soilw.1-10cm.gauss.1949.nc
library(ncdf4)
soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
soil_moist<-ncvar_get(soilm)
# find a suitable grid cell
for(i in 1:192) {
 for(j in 1:94) {
  minmoist<-min(soil_moist[i,j,],na.rm=TRUE)
  if(minmoist < 0.3) cat(i,j,minmoist,"\n")
 }
}
# data is 3D numeric array use cell 159,66
soil_moisture<-soil_moist[159,66,]
dates<-as.Date(as.Date("1949-01-01"):as.Date("1949-12-31"),
 origin=as.Date("1970-01-01"))
# get a logical vector for your condition
under.28<-soil_moisture < 0.28
plot(dates,soil_moisture,
 main="Soil moisture for grid cell 159,66 1949",
 col=under.28+3)
abline(h=0.28)
sm.rle<-rle(soil_moisture < 0.28)
day_of_year<-1
cat("Consecutive days below 0.28\n")
for(run in 1:length(sm.rle$lengths)) {
 if(sm.rle$values[run]) {
  cat("Day",day_of_year,"-",day_of_year+sm.rle$lengths[run],
   "-",sm.rle$lengths[run],"days\n")
  day_of_year<-day_of_year+sm.rle$lengths[run]
 }
}

Jim

On Fri, Aug 7, 2020 at 11:54 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
>  Many thanks for your answer
>
> > nc
>
> File soilw_1949.nc (NC_FORMAT_NETCDF4_CLASSIC):
>
>
>
>      1 variables (excluding dimension variables):
>
>         float soilw[lon,lat,time]
>
>             long_name: mean Daily Volumetric Soil Moisture between 0-10 cm Below Ground Level
>
>             units: fraction
>
>             precision: 4
>
>             least_significant_digit: 3
>
>             GRIB_id: 144
>
>             GRIB_name: SOILW
>
>             var_desc: Volumetric Soil Moisture
>
>             dataset: NCEP Reanalysis Daily Averages
>
>             level_desc: Between 0-10 cm BGL
>
>             statistic: Mean
>
>             parent_stat: Individual Obs
>
>             missing_value: -9.96920996838687e+36
>
>             actual_range: 0.100000143051147
>
>              actual_range: 0.434000015258789
>
>             valid_range: 0
>
>              valid_range: 1
>
>
>
>      3 dimensions:
>
>         lon  Size:192
>
>             units: degrees_east
>
>             long_name: Longitude
>
>             actual_range: 0
>
>              actual_range: 358.125
>
>             standard_name: longitude
>
>             axis: X
>
>         lat  Size:94
>
>             units: degrees_north
>
>             actual_range: 88.5419998168945
>
>              actual_range: -88.5419998168945
>
>             long_name: Latitude
>
>             standard_name: latitude
>
>             axis: Y
>
>         time  Size:365   *** is unlimited ***
>
>             long_name: Time
>
>             delta_t: 0000-00-01 00:00:00
>
>             avg_period: 0000-00-01 00:00:00
>
>             standard_name: time
>
>             axis: T
>
>             units: hours since 1800-01-01 00:00:0.0
>
>             actual_range: 1306104
>
>              actual_range: 1314840
>
>
>
>     7 global attributes:
>
>         Conventions: COARDS
>
>         title: mean daily NMC reanalysis (1949)
>
>         description: Data is from NMC initialized reanalysis
>
> (4x/day).  It consists of T62 variables interpolated to
>
> pressure surfaces from model (sigma) surfaces.
>
>         platform: Model
>
>         history: created 99/05/29 by Hoop (netCDF2.3)
>
> Converted to chunked, deflated non-packed NetCDF4 2014/09
>
>         dataset_title: NCEP-NCAR Reanalysis 1
>
>         References: http://www.psl.noaa.gov/data/gridded/data.ncep.reanalysis.html
>
>
>
> I swiched nc to array to calculate threshold it is a 3d matrix and there is no date in files
>
>
>
>
>
> > dim(a)
>
>
>
> [1]  94 192 365
>
>
>
> >a
>
> , , 1
>
>
>
>       [,169]    [,170]    [,171]    [,172]    [,173]    [,174]    [,175]    [,176]    [,177]    [,178]    [,179]    [,180]    [,181]    [,182]
>
>  [1,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [2,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [3,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [4,] 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3577001 0.3577001 0.3577001 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [5,] 0.3580000 0.3575001 0.3572001 0.3572001 0.3572001 0.3570001 0.3570001 0.3575001 0.3577001 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000
>
>
>
>
>
>
>
> [ reached getOption("max.print") -- omitted 89 row(s) and 364 matrix slice(s) ]
>
>
>
>
>
> Windows 10 i?in Posta ile g?nderildi
>
>
>
> Kimden: Jim Lemon
> G?nderilme: 7 A?ustos 2020 Cuma 02:17
> Kime: ahmet varl?; r-help mailing list
> Konu: Re: [R] find number of consecutive days in NC files by R
>
>
>
> Hi Ahmet,
> I think what you are looking for can be done using run length encoding (rle).
>
> # make up some data
> soil_moisture<-sin(seq(0,4*pi,length.out=730))+1.1
> dates<-as.Date(as.Date("2018-01-01"):as.Date("2019-12-31"),
>  origin=as.Date("1970-01-01"))
> # get a logical vector for your condition
> under.28<-soil_moisture < 0.28
> # show the soil moisture against time
> plot(dates,soil_moisture,pch=".",col=under.28+3,cex=2)
> abline(h=0.28)
> # use rle to get  the runs of low soil moisture
> sm.rle<-rle(soil_moisture < 0.28)
> cat("Consecutive days below 0.28",
>  paste(1:sum(sm.rle$values),sm.rle$lengths[sm.rle$values==TRUE],sep="-"),
>  "\n")
>
> Jim
>
> On Fri, Aug 7, 2020 at 3:33 AM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> > Hi all,
> >
> >
> > There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily
> >
> > nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
> >
> > a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
> >
> >
> >
> > function(x, threshold = 0.28, below = TRUE) {
> >
> >     if (below) {
> >
> >         y <- ifelse(x < threshold,1,0)
> >
> >     } else y <- ifelse(x > threshold,1,0)
> >
> >
> >
> >     y2 <- rle(y)
> >
> >     sel <- which(y2$values == 1)
> >
> >     max(y2$lengths[sel])
> >
> > }
> >
> >
> >
> > m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
> >
> >
> >
> > m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug  7 07:46:06 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 7 Aug 2020 15:46:06 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
Message-ID: <CA+8X3fUDzdJ3diRFthS=LzCH6R5wpwaowuBgisYTOETt=vTaQQ@mail.gmail.com>

Hi Ahmet,
My apologies, the final for loop should read:

for(run in 1:length(sm.rle$lengths)) {
 if(sm.rle$values[run]) {
  cat("Day",day_of_year,"-",day_of_year+sm.rle$lengths[run],
   "-",sm.rle$lengths[run],"days\n")
 }
 day_of_year<-day_of_year+sm.rle$lengths[run]
}

Jim

On Fri, Aug 7, 2020 at 3:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ahmet,
> Here is a way to get the result you ask for for one geographic grid
> cell. You may want more detail or something, but this is a
> "reproducible example".
>
> # retrieved from
> ftp://ftp2.psi.noaa.gov/Datasets/ncep.renalysis.dailyavgs/surface_gauss/soilw.1-10cm.gauss.1949.nc
> library(ncdf4)
> soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
> soil_moist<-ncvar_get(soilm)
> # find a suitable grid cell
> for(i in 1:192) {
>  for(j in 1:94) {
>   minmoist<-min(soil_moist[i,j,],na.rm=TRUE)
>   if(minmoist < 0.3) cat(i,j,minmoist,"\n")
>  }
> }
> # data is 3D numeric array use cell 159,66
> soil_moisture<-soil_moist[159,66,]
> dates<-as.Date(as.Date("1949-01-01"):as.Date("1949-12-31"),
>  origin=as.Date("1970-01-01"))
> # get a logical vector for your condition
> under.28<-soil_moisture < 0.28
> plot(dates,soil_moisture,
>  main="Soil moisture for grid cell 159,66 1949",
>  col=under.28+3)
> abline(h=0.28)
> sm.rle<-rle(soil_moisture < 0.28)
> day_of_year<-1
> cat("Consecutive days below 0.28\n")
> for(run in 1:length(sm.rle$lengths)) {
>  if(sm.rle$values[run]) {
>   cat("Day",day_of_year,"-",day_of_year+sm.rle$lengths[run],
>    "-",sm.rle$lengths[run],"days\n")
>   day_of_year<-day_of_year+sm.rle$lengths[run]
>  }
> }
>
> Jim
>
> On Fri, Aug 7, 2020 at 11:54 AM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> >  Many thanks for your answer
> >
> > > nc
> >
> > File soilw_1949.nc (NC_FORMAT_NETCDF4_CLASSIC):
> >
> >
> >
> >      1 variables (excluding dimension variables):
> >
> >         float soilw[lon,lat,time]
> >
> >             long_name: mean Daily Volumetric Soil Moisture between 0-10 cm Below Ground Level
> >
> >             units: fraction
> >
> >             precision: 4
> >
> >             least_significant_digit: 3
> >
> >             GRIB_id: 144
> >
> >             GRIB_name: SOILW
> >
> >             var_desc: Volumetric Soil Moisture
> >
> >             dataset: NCEP Reanalysis Daily Averages
> >
> >             level_desc: Between 0-10 cm BGL
> >
> >             statistic: Mean
> >
> >             parent_stat: Individual Obs
> >
> >             missing_value: -9.96920996838687e+36
> >
> >             actual_range: 0.100000143051147
> >
> >              actual_range: 0.434000015258789
> >
> >             valid_range: 0
> >
> >              valid_range: 1
> >
> >
> >
> >      3 dimensions:
> >
> >         lon  Size:192
> >
> >             units: degrees_east
> >
> >             long_name: Longitude
> >
> >             actual_range: 0
> >
> >              actual_range: 358.125
> >
> >             standard_name: longitude
> >
> >             axis: X
> >
> >         lat  Size:94
> >
> >             units: degrees_north
> >
> >             actual_range: 88.5419998168945
> >
> >              actual_range: -88.5419998168945
> >
> >             long_name: Latitude
> >
> >             standard_name: latitude
> >
> >             axis: Y
> >
> >         time  Size:365   *** is unlimited ***
> >
> >             long_name: Time
> >
> >             delta_t: 0000-00-01 00:00:00
> >
> >             avg_period: 0000-00-01 00:00:00
> >
> >             standard_name: time
> >
> >             axis: T
> >
> >             units: hours since 1800-01-01 00:00:0.0
> >
> >             actual_range: 1306104
> >
> >              actual_range: 1314840
> >
> >
> >
> >     7 global attributes:
> >
> >         Conventions: COARDS
> >
> >         title: mean daily NMC reanalysis (1949)
> >
> >         description: Data is from NMC initialized reanalysis
> >
> > (4x/day).  It consists of T62 variables interpolated to
> >
> > pressure surfaces from model (sigma) surfaces.
> >
> >         platform: Model
> >
> >         history: created 99/05/29 by Hoop (netCDF2.3)
> >
> > Converted to chunked, deflated non-packed NetCDF4 2014/09
> >
> >         dataset_title: NCEP-NCAR Reanalysis 1
> >
> >         References: http://www.psl.noaa.gov/data/gridded/data.ncep.reanalysis.html
> >
> >
> >
> > I swiched nc to array to calculate threshold it is a 3d matrix and there is no date in files
> >
> >
> >
> >
> >
> > > dim(a)
> >
> >
> >
> > [1]  94 192 365
> >
> >
> >
> > >a
> >
> > , , 1
> >
> >
> >
> >       [,169]    [,170]    [,171]    [,172]    [,173]    [,174]    [,175]    [,176]    [,177]    [,178]    [,179]    [,180]    [,181]    [,182]
> >
> >  [1,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [2,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [3,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [4,] 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3577001 0.3577001 0.3577001 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [5,] 0.3580000 0.3575001 0.3572001 0.3572001 0.3572001 0.3570001 0.3570001 0.3575001 0.3577001 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000
> >
> >
> >
> >
> >
> >
> >
> > [ reached getOption("max.print") -- omitted 89 row(s) and 364 matrix slice(s) ]
> >
> >
> >
> >
> >
> > Windows 10 i?in Posta ile g?nderildi
> >
> >
> >
> > Kimden: Jim Lemon
> > G?nderilme: 7 A?ustos 2020 Cuma 02:17
> > Kime: ahmet varl?; r-help mailing list
> > Konu: Re: [R] find number of consecutive days in NC files by R
> >
> >
> >
> > Hi Ahmet,
> > I think what you are looking for can be done using run length encoding (rle).
> >
> > # make up some data
> > soil_moisture<-sin(seq(0,4*pi,length.out=730))+1.1
> > dates<-as.Date(as.Date("2018-01-01"):as.Date("2019-12-31"),
> >  origin=as.Date("1970-01-01"))
> > # get a logical vector for your condition
> > under.28<-soil_moisture < 0.28
> > # show the soil moisture against time
> > plot(dates,soil_moisture,pch=".",col=under.28+3,cex=2)
> > abline(h=0.28)
> > # use rle to get  the runs of low soil moisture
> > sm.rle<-rle(soil_moisture < 0.28)
> > cat("Consecutive days below 0.28",
> >  paste(1:sum(sm.rle$values),sm.rle$lengths[sm.rle$values==TRUE],sep="-"),
> >  "\n")
> >
> > Jim
> >
> > On Fri, Aug 7, 2020 at 3:33 AM ahmet varl? <varli61 at windowslive.com> wrote:
> > >
> > > Hi all,
> > >
> > >
> > > There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily
> > >
> > > nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
> > >
> > > a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
> > >
> > >
> > >
> > > function(x, threshold = 0.28, below = TRUE) {
> > >
> > >     if (below) {
> > >
> > >         y <- ifelse(x < threshold,1,0)
> > >
> > >     } else y <- ifelse(x > threshold,1,0)
> > >
> > >
> > >
> > >     y2 <- rle(y)
> > >
> > >     sel <- which(y2$values == 1)
> > >
> > >     max(y2$lengths[sel])
> > >
> > > }
> > >
> > >
> > >
> > > m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
> > >
> > >
> > >
> > > m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
> > >
> > >
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >


From |knecht @end|ng |rom |redhutch@org  Thu Aug  6 23:32:30 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Thu, 6 Aug 2020 21:32:30 +0000
Subject: [R] How Can I Build a Standalone Binary
Message-ID: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>

Hello all,

===== The short version =====

I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.

The inspiration for this comes from here:
https://www.youtube.com/watch?v=ARrbbviGvjc
and here
https://github.com/dirkschumacher/r-shiny-electron

I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.

===== Questions =====

-   How is the R binary at this link created?
    -   Link: https://cloud.r-project.org/bin/macosx/R-4.0.2.pkg
-   How do I include `libgfortran.5.dylib`
    -   This distributable, when configured shows a file called `libgfortran.5.dylib`
    -   As of this writing, my solution fails because this is missing when I run the self-hosted R
-   Is there any guidance on how to build a self-hosted R executable for each operating system?
    -   OSX
    -   Linux
    -   Windows

===== The long version =====

----- The Goal -----

Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.

----- The Impetus -----

It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.

We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.

It should be as simple as downloading an application and running it.

----- The Current Progress -----

I have a repo here that is an electron application

https://github.com/FredHutch/FAUST_Nextflow_Desktop/tree/research/create_r_4_0_2_build-dev

I can bundle these resources without issues

-   Java
-   Nextflow
-   Our Shiny App

----- Process -----
The only missing piece is `R`

I have a set of environment variables here:
https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/build_environment_variables.env

I `source` the env variables and then I run this script here:
`https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/download_r_osx.sh`

I then use the downloaded `R` to install dependencies with these scripts:

-   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_dependencies.r
-   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_cran_dependencies.r
-   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_biocmanager_dependencies.r

And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.

Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.

===== The Plea For Guidance =====

I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.

Any guidance or suggestions are greatly appreciated!

Warm Regards,

Logan Knecht

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug  7 13:50:00 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 7 Aug 2020 07:50:00 -0400
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
Message-ID: <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>

Wouldn't it be easier to set up a Shiny host system, and just give your 
collaborators a URL to the Shiny app running there?

Duncan Murdoch


On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
> Hello all,
> 
> ===== The short version =====
> 
> I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
> 
> The inspiration for this comes from here:
> https://www.youtube.com/watch?v=ARrbbviGvjc
> and here
> https://github.com/dirkschumacher/r-shiny-electron
> 
> I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
> 
> ===== Questions =====
> 
> -   How is the R binary at this link created?
>      -   Link: https://cloud.r-project.org/bin/macosx/R-4.0.2.pkg
> -   How do I include `libgfortran.5.dylib`
>      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
>      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
> -   Is there any guidance on how to build a self-hosted R executable for each operating system?
>      -   OSX
>      -   Linux
>      -   Windows
> 
> ===== The long version =====
> 
> ----- The Goal -----
> 
> Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
> 
> ----- The Impetus -----
> 
> It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
> 
> We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
> 
> It should be as simple as downloading an application and running it.
> 
> ----- The Current Progress -----
> 
> I have a repo here that is an electron application
> 
> https://github.com/FredHutch/FAUST_Nextflow_Desktop/tree/research/create_r_4_0_2_build-dev
> 
> I can bundle these resources without issues
> 
> -   Java
> -   Nextflow
> -   Our Shiny App
> 
> ----- Process -----
> The only missing piece is `R`
> 
> I have a set of environment variables here:
> https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/build_environment_variables.env
> 
> I `source` the env variables and then I run this script here:
> `https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/download_r_osx.sh`
> 
> I then use the downloaded `R` to install dependencies with these scripts:
> 
> -   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_dependencies.r
> -   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_cran_dependencies.r
> -   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_biocmanager_dependencies.r
> 
> And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
> 
> Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
> 
> ===== The Plea For Guidance =====
> 
> I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
> 
> Any guidance or suggestions are greatly appreciated!
> 
> Warm Regards,
> 
> Logan Knecht
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Aug  7 14:05:16 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 7 Aug 2020 12:05:16 +0000
Subject: [R] find end of monotonic part of vector
Message-ID: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>

Hallo all

I have such data
> dput(kalo.v)
structure(list(cas = structure(c(1595847000, 1595847060, 1595847120, 
1595847180, 1595847240, 1595847300, 1595847360, 1595847420, 1595847480, 
1595847540, 1595847600, 1595847660, 1595847720, 1595847780, 1595847840, 
1595847900, 1595847960, 1595848020, 1595848080, 1595848140, 1595848200, 
1595848260, 1595848320, 1595848380, 1595848440, 1595848500, 1595848560, 
1595848620, 1595848680, 1595848740, 1595848800, 1595848860, 1595848920, 
1595848980, 1595849040, 1595849100, 1595849160, 1595849220, 1595849280, 
1595849340, 1595849400, 1595849460, 1595849520, 1595849580, 1595849640
), class = c("POSIXct", "POSIXt"), tzone = "UTC"), vodiv = c(999.9000244, 
999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 991.6404419, 925.2166748, 864.3446045, 812.1702271, 
758.9353027, 722.5073242, 684.5323486, 652.5300293, 82.18816376, 
141.1757813, 402.7521667, 999.9000244, 959.1779175, 967.0949707, 
517.1983643, 50, 50, 524.569458, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 999.9000244, 999.9000244, 999.9000244, 977.0491943, 
889.9714355, 999.9000244, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 999.9000244)), row.names = 71211:71255, class = "data.frame")

and I would like to automatically find endpoint of gradually decreasing part
(here point 20, vodiv = 652.****).

Usually I use diff but this is just a chunk of bigger data and diff seems to
be difficult to use. I appreciate any hint.

Best regards.
Petr

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug  7 16:05:08 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 7 Aug 2020 15:05:08 +0100
Subject: [R] find end of monotonic part of vector
In-Reply-To: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
References: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
Message-ID: <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>

Hello,

Maybe I'm not understanding but looking at this graph


i <- diff(kalo.v$vodiv) > 0
plot(kalo.v)
lines(kalo.v)
points(kalo.v$cas[i], kalo.v$vodiv[i], pch = 16, col = "red")


it seems you want the point before the first local minimum?


min(which(i)) - 1L
#[1] 20


Hope this helps,

Rui Barradas


?s 13:05 de 07/08/20, PIKAL Petr escreveu:
> Hallo all
> 
> I have such data
>> dput(kalo.v)
> structure(list(cas = structure(c(1595847000, 1595847060, 1595847120,
> 1595847180, 1595847240, 1595847300, 1595847360, 1595847420, 1595847480,
> 1595847540, 1595847600, 1595847660, 1595847720, 1595847780, 1595847840,
> 1595847900, 1595847960, 1595848020, 1595848080, 1595848140, 1595848200,
> 1595848260, 1595848320, 1595848380, 1595848440, 1595848500, 1595848560,
> 1595848620, 1595848680, 1595848740, 1595848800, 1595848860, 1595848920,
> 1595848980, 1595849040, 1595849100, 1595849160, 1595849220, 1595849280,
> 1595849340, 1595849400, 1595849460, 1595849520, 1595849580, 1595849640
> ), class = c("POSIXct", "POSIXt"), tzone = "UTC"), vodiv = c(999.9000244,
> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 991.6404419, 925.2166748, 864.3446045, 812.1702271,
> 758.9353027, 722.5073242, 684.5323486, 652.5300293, 82.18816376,
> 141.1757813, 402.7521667, 999.9000244, 959.1779175, 967.0949707,
> 517.1983643, 50, 50, 524.569458, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 977.0491943,
> 889.9714355, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 999.9000244)), row.names = 71211:71255, class = "data.frame")
> 
> and I would like to automatically find endpoint of gradually decreasing part
> (here point 20, vodiv = 652.****).
> 
> Usually I use diff but this is just a chunk of bigger data and diff seems to
> be difficult to use. I appreciate any hint.
> 
> Best regards.
> Petr
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug  7 17:44:38 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 7 Aug 2020 16:44:38 +0100
Subject: [R] find end of monotonic part of vector
In-Reply-To: <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>
References: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
 <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>
Message-ID: <5416c4bd-6365-46e0-abeb-9c8f852163f7@sapo.pt>

Hello,

I should have continued, inline.

?s 15:05 de 07/08/20, Rui Barradas escreveu:
> Hello,
> 
> Maybe I'm not understanding but looking at this graph
> 
> 
> i <- diff(kalo.v$vodiv) > 0
> plot(kalo.v)
> lines(kalo.v)
> points(kalo.v$cas[i], kalo.v$vodiv[i], pch = 16, col = "red")
> 
> 
> it seems you want the point before the first local minimum?
> 
> 
> min(which(i)) - 1L
> #[1] 20
> 

(k <- min(which(i)) - 1L)
#[1] 20

kalo.v[k, ]
#                      cas  vodiv
#71230 2020-07-27 11:09:00 652.53


Rui Barradas

> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 13:05 de 07/08/20, PIKAL Petr escreveu:
>> Hallo all
>>
>> I have such data
>>> dput(kalo.v)
>> structure(list(cas = structure(c(1595847000, 1595847060, 1595847120,
>> 1595847180, 1595847240, 1595847300, 1595847360, 1595847420, 1595847480,
>> 1595847540, 1595847600, 1595847660, 1595847720, 1595847780, 1595847840,
>> 1595847900, 1595847960, 1595848020, 1595848080, 1595848140, 1595848200,
>> 1595848260, 1595848320, 1595848380, 1595848440, 1595848500, 1595848560,
>> 1595848620, 1595848680, 1595848740, 1595848800, 1595848860, 1595848920,
>> 1595848980, 1595849040, 1595849100, 1595849160, 1595849220, 1595849280,
>> 1595849340, 1595849400, 1595849460, 1595849520, 1595849580, 1595849640
>> ), class = c("POSIXct", "POSIXt"), tzone = "UTC"), vodiv = c(999.9000244,
>> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 991.6404419, 925.2166748, 864.3446045, 812.1702271,
>> 758.9353027, 722.5073242, 684.5323486, 652.5300293, 82.18816376,
>> 141.1757813, 402.7521667, 999.9000244, 959.1779175, 967.0949707,
>> 517.1983643, 50, 50, 524.569458, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 977.0491943,
>> 889.9714355, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 999.9000244)), row.names = 71211:71255, class = 
>> "data.frame")
>>
>> and I would like to automatically find endpoint of gradually 
>> decreasing part
>> (here point 20, vodiv = 652.****).
>>
>> Usually I use diff but this is just a chunk of bigger data and diff 
>> seems to
>> be difficult to use. I appreciate any hint.
>>
>> Best regards.
>> Petr
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug  7 23:23:48 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 7 Aug 2020 17:23:48 -0400
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
Message-ID: <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>

I don't think it's feasible to do what you want.  At a very basic level, 
R assumes it has files distributed across a file system (mostly below 
the R.home() directory).  Faking that in a single standalone executable 
may be possible but wouldn't be easy.

If running a server isn't possible, then I'd suggest you work on 
automating a regular R installation, and put the things you want to run 
into scripts that make use of it.  Two steps instead of one.

Duncan Murdoch



On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
> Unfortunately, that is not a solution due to the constraints of file sizes associated with the run time operations as well as specific execution workflows.
> 
> I need to make this a packaged distributable and the only blocker for it at the moment is not being able to successfully bundle R as a standalone binary.
> 
> Warm Regards,
> 
> Logan Knecht
> 
> ?2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:
> 
>      Wouldn't it be easier to set up a Shiny host system, and just give your
>      collaborators a URL to the Shiny app running there?
> 
>      Duncan Murdoch
> 
> 
>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
>      > Hello all,
>      >
>      > ===== The short version =====
>      >
>      > I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
>      >
>      > The inspiration for this comes from here:
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
>      > and here
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
>      >
>      > I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
>      >
>      > ===== Questions =====
>      >
>      > -   How is the R binary at this link created?
>      >      -   Link: https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
>      > -   How do I include `libgfortran.5.dylib`
>      >      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
>      >      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
>      > -   Is there any guidance on how to build a self-hosted R executable for each operating system?
>      >      -   OSX
>      >      -   Linux
>      >      -   Windows
>      >
>      > ===== The long version =====
>      >
>      > ----- The Goal -----
>      >
>      > Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
>      >
>      > ----- The Impetus -----
>      >
>      > It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
>      >
>      > We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
>      >
>      > It should be as simple as downloading an application and running it.
>      >
>      > ----- The Current Progress -----
>      >
>      > I have a repo here that is an electron application
>      >
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
>      >
>      > I can bundle these resources without issues
>      >
>      > -   Java
>      > -   Nextflow
>      > -   Our Shiny App
>      >
>      > ----- Process -----
>      > The only missing piece is `R`
>      >
>      > I have a set of environment variables here:
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
>      >
>      > I `source` the env variables and then I run this script here:
>      > `https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e= `
>      >
>      > I then use the downloaded `R` to install dependencies with these scripts:
>      >
>      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
>      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
>      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
>      >
>      > And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
>      >
>      > Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
>      >
>      > ===== The Plea For Guidance =====
>      >
>      > I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
>      >
>      > Any guidance or suggestions are greatly appreciated!
>      >
>      > Warm Regards,
>      >
>      > Logan Knecht
>      >
>      > 	[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
>      > PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  8 01:37:17 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 07 Aug 2020 16:37:17 -0700
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
Message-ID: <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>

While I have not attempted to apply this to Shiny apps on the desktop, layered container technology (e.g. Docker) is being rolled out for desktop app distribution on Linux (snap, flatpak) and Windows (Open Packaging Conventions), with which complex filesystem structures can be managed in isolated runtime environments. The hardest part is working out how the container will interact with the world... which I don't know the details of but it is clearly in the realm of "feasible".

On August 7, 2020 2:23:48 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>I don't think it's feasible to do what you want.  At a very basic
>level, 
>R assumes it has files distributed across a file system (mostly below 
>the R.home() directory).  Faking that in a single standalone executable
>
>may be possible but wouldn't be easy.
>
>If running a server isn't possible, then I'd suggest you work on 
>automating a regular R installation, and put the things you want to run
>
>into scripts that make use of it.  Two steps instead of one.
>
>Duncan Murdoch
>
>
>
>On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
>> Unfortunately, that is not a solution due to the constraints of file
>sizes associated with the run time operations as well as specific
>execution workflows.
>> 
>> I need to make this a packaged distributable and the only blocker for
>it at the moment is not being able to successfully bundle R as a
>standalone binary.
>> 
>> Warm Regards,
>> 
>> Logan Knecht
>> 
>> ?2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com>
>????????:
>> 
>>      Wouldn't it be easier to set up a Shiny host system, and just
>give your
>>      collaborators a URL to the Shiny app running there?
>> 
>>      Duncan Murdoch
>> 
>> 
>>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
>>      > Hello all,
>>      >
>>      > ===== The short version =====
>>      >
>>      > I am trying to build a standalone version for R so that I can
>bundle and package a self-hosted environment for a shiny app. There are
>reasons for this decision, but it will only distract from the
>discussion.
>>      >
>>      > The inspiration for this comes from here:
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
>>      > and here
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
>>      >
>>      > I have tried these solutions, to no avail as I repeatedly
>encounter issues with the process. Some issues have been difficulties
>importing libraries after repeating their steps, others have been
>issues with missing dynamic libraries that aren't available when I
>build from source.
>>      >
>>      > ===== Questions =====
>>      >
>>      > -   How is the R binary at this link created?
>>      >      -   Link:
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
>>      > -   How do I include `libgfortran.5.dylib`
>>      >      -   This distributable, when configured shows a file
>called `libgfortran.5.dylib`
>>      >      -   As of this writing, my solution fails because this is
>missing when I run the self-hosted R
>>      > -   Is there any guidance on how to build a self-hosted R
>executable for each operating system?
>>      >      -   OSX
>>      >      -   Linux
>>      >      -   Windows
>>      >
>>      > ===== The long version =====
>>      >
>>      > ----- The Goal -----
>>      >
>>      > Create a self hosted version of R that runs independent of
>each system so that I can package and build shiny apps to be
>distributed to collaborators in order to evangelize our new statistical
>method.
>>      >
>>      > ----- The Impetus -----
>>      >
>>      > It is too distracting and too much work to get our
>collaborators to configure their environments just to try our statiscal
>methods we have been creating.
>>      >
>>      > We have a shiny app built around the statistical methods to
>simplify the interface for interaction. Now we want to package it for
>easy consumption.
>>      >
>>      > It should be as simple as downloading an application and
>running it.
>>      >
>>      > ----- The Current Progress -----
>>      >
>>      > I have a repo here that is an electron application
>>      >
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
>>      >
>>      > I can bundle these resources without issues
>>      >
>>      > -   Java
>>      > -   Nextflow
>>      > -   Our Shiny App
>>      >
>>      > ----- Process -----
>>      > The only missing piece is `R`
>>      >
>>      > I have a set of environment variables here:
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
>>      >
>>      > I `source` the env variables and then I run this script here:
>>      >
>`https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e=
>`
>>      >
>>      > I then use the downloaded `R` to install dependencies with
>these scripts:
>>      >
>>      > -  
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
>>      > -  
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
>>      > -  
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
>>      >
>>      > And then voil?! It works. Well. It works on my local machine.
>I can run the development build, I can package the build, I can run the
>release after installing it. Everything works.
>>      >
>>      > Except when I bring it over to a separate computer it doesn't
>work because it states that it can't find `libgfortran.5.dylib`. See
>the attached screen shot.
>>      >
>>      > ===== The Plea For Guidance =====
>>      >
>>      > I would love any help to figure out how to achieve this. We
>are very close to somethng tangibly interesting and it's very deflating
>to be blocked because `R` does not have a distributable that can be
>bundled.
>>      >
>>      > Any guidance or suggestions are greatly appreciated!
>>      >
>>      > Warm Regards,
>>      >
>>      > Logan Knecht
>>      >
>>      > 	[[alternative HTML version deleted]]
>>      >
>>      > ______________________________________________
>>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
>>      > PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
>>      > and provide commented, minimal, self-contained, reproducible
>code.
>>      >
>> 
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Sat Aug  8 02:08:12 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 Aug 2020 10:08:12 +1000
Subject: [R] Print and plot a cross Data
In-Reply-To: <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
 <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
 <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>
Message-ID: <CA+8X3fUGsjKo4X+S5BJWRO_MePGiZFwOCHA=SAPT6BH64GyaMg@mail.gmail.com>

Hi Pedro,
I think the error arises in your "if" statement, should be:

if(PERIOD == TRUE)

or more simply:

if(PERIOD)

Jim

On Thu, Aug 6, 2020 at 11:54 PM Pedro p?ramo <percentil101 at gmail.com> wrote:
>
> Hi Jim,
>
> Many thanks for your help, I will try a 2D plot and then pass to 3D.
>
> I am trying something like this:
>
> tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
>
> data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
>
> row_subset<-tus.datos$DATA_TYPE %in% data_types
>
> x<-tus.datos$DATA_TYPE_FM[row_subset]
> y<-tus.datos$OBS_VALUE[row_subset]
>
> PERIOD<-tus.datos$TIME_PERIOD=="01/06/2020"
>
> for (PERIOD="TRUE") {
>
>
> plot(x, y)
>
> }
>
>
> And the error is
>
>  for (PERIOD="TRUE") {
> Error: inesperado '=' in "for (PERIOD="
> >
> >
> > plot(x, y)
> Error: no se puede ubicar un vector de tama?o  1.3 Gb
> >
> > }
> Error: inesperado '}' in "}"
> >
>
>
>
> El jue., 6 ago. 2020 a las 2:24, Jim Lemon (<drjimlemon at gmail.com>) escribi?:
>>
>> Hi Pedro,
>> I'm not exactly sure of what you want, but try this:
>>
>> # I downloaded the CSV file as datayield.csv
>> tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
>> library(scatterplot3d)
>> data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
>> row_subset<-tus.datos$DATA_TYPE %in% data_types
>> scatterplot3d(tus.datos$DATA_TYPE_FM[row_subset],
>>  tus.datos$OBS_VALUE[row_subset],
>>  tus.datos$TIME_PERIOD[row_subset],
>>  color=order(as.numeric(tus.datos$DATA_TYPE[row_subset])))
>> legend(9,8,data_types,pch=1,col=1:7,xpd=TRUE)
>>
>> I used a few tricks to get this to work without being too long a
>> script. The color for PY_7Y is yellow, and this can be changed with a
>> bit of extra code.
>>
>> Jim
>>
>> On Thu, Aug 6, 2020 at 8:40 AM Pedro p?ramo <percentil101 at gmail.com> wrote:
>> >
>> > Hi all,
>> >
>> > I have a csv (extracted from a web) I attach the data:
>> >
>> > I use this code to read the data;
>> >
>> > library("readr")
>> >
>> > tusDatos <- read_csv('~/datayield.csv')
>> >
>> > In this CSV, I want to use three columns:
>> >
>> >  tusDatos$DATA_TYPE_FM,  (will be X axis)
>> > tusDatos$TIME_PERIOD (will be the pivot to search the values)
>> > tusDatos$OBS_VALUE (Y Values)
>> >
>> > In Data_Type_FM I want to plot a graph where only some rows (included in
>> > thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
>> > specific DATE.
>> >
>> > So for each day (time period) I will plot a plot imagine 04/08/2020 (a
>> > value on TIME_PERIOD) for the values
>> >
>> > c(  PY_1Y, PY_2Y,
>> > PY_3Y, PY_4Y,
>> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>> >
>> > In excel for me is "easy" but in R I dont know how to proceed can you give
>> > me some clue to make this king of operations?
>> >
>> > If I wanted to do a 3D PloT would be possible? only also for this limited
>> > values c(  PY_1Y, PY_2Y,
>> > PY_3Y, PY_4Y,
>> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>> >
>> > tusDatos$DATA_TYPE_FM,  (will be X axis)
>> > tusDatos$TIME_PERIOD (Z axis)
>> > tusDatos$OBS_VALUE (Y Values)
>> >
>> > Hope I explained properly and hope you can help and guide.
>> >
>> >
>> >
>> >  datayield.csv
>> > <https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Aug  8 02:30:29 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 Aug 2020 10:30:29 +1000
Subject: [R] Print and plot a cross Data
In-Reply-To: <CA+8X3fUGsjKo4X+S5BJWRO_MePGiZFwOCHA=SAPT6BH64GyaMg@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
 <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
 <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>
 <CA+8X3fUGsjKo4X+S5BJWRO_MePGiZFwOCHA=SAPT6BH64GyaMg@mail.gmail.com>
Message-ID: <CA+8X3fUAdG4Ubm1xPFcSuP7jHLtzQTg23pp2FNaQqom8nMP8eA@mail.gmail.com>

Hi Pedro,
Scratch that last email. I remembered that "tus.datos" was so large
that it was hanging my R session last time. However, this seems to
work:

tus.datos<-read.table("datayield.csv",sep=";",
 header=TRUE,stringsAsFactors=FALSE)
row_subset<-tus.datos$DATA_TYPE_FM %in% data_types &
 tus.datos$TIME_PERIOD == "01/06/2020"
x<-tus.datos$DATA_TYPE_FM[row_subset]
y<-as.numeric(tus.datos$OBS_VALUE[row_subset])
# DATA_TYPE_FM is a character variable
# unless you let it be read as a factor (beware, it may hang your R session)
# and use as.numeric() it will not turn out well.
barplot(y,names.arg=x)

Jim


From kev|neg@n31 @end|ng |rom gm@||@com  Fri Aug  7 22:24:55 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Fri, 7 Aug 2020 15:24:55 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
Message-ID: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>

I posted this question:

I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.

After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.

Thanks.

and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.

Thanks.
	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  8 15:17:42 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 08 Aug 2020 06:17:42 -0700
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
Message-ID: <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>

Compare the sessionInfo outputs for the different environments.

On August 7, 2020 1:24:55 PM PDT, Kevin Egan <kevinegan31 at gmail.com> wrote:
>I posted this question:
>
>I am currently using R , RStudio , and a remote computer (using an R
>script) to run the same code. I start by using set.seed(123) in all
>three versions of the code, then using glmnet to assess a matrix.
>Ultimately, I am having trouble reproducing the results between my
>local and the remote computer's results. I am using R version 4.0.2
>locally, and R version 3.6.0 remote.
>
>After running several tests, I'm wondering if there is a difference
>between the two versions in R which may lead to slightly different
>coefficients. If anyone has any insight I would appreciate it.
>
>Thanks.
>
>and found that there were slight differences between using rnorm with
>R-4.0.2 and R-3.6.0 but did not find any differences for runif between
>both systems. In my original code, I am using rnorm and was wondering
>if this may be the reason I am finding slight differences in
>coefficients for glmnet and lars testing between using my local
>computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my
>code locally on a MacOSX and remote on what I believe is an HPC.
>
>Thanks.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rc_@chw@rtz @end|ng |rom me@com  Sat Aug  8 15:34:21 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Sat, 8 Aug 2020 09:34:21 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
Message-ID: <D95591B3-7B2D-47AD-AB32-FD0A70CFFEF7@me.com>

Hi,

I was initially going to think that the change in the RNG might be the source, however, that change was made in 3.6.0 and would have applied to runif() and sample():

"sample.kind can be "Rounding" or "Rejection", or partial matches to these. The former was the default in versions prior to 3.6.0: it made sample noticeably non-uniform on large populations, and should only be used for reproduction of old results. See PR#17494 for a discussion."

Three other possibilities:

1. Read news() for your local 4.0.2 installation, as there are some changes that were made, including some changes to round() that could be applicable here.

2. Check to see if the version of glmnet is the same on both machines. There have been changes to that package that might be relevant here and you might read the README and NEWS files for the package on CRAN to see if there is any relevant information there.

3. There is always a chance that different hardware and OS versions could lead to issues, especially out to a number of decimal places that could alter results. If you or via an Admin, have the ability to update the remote machine (both R and installed packages), that can help to reduce the number of variables at play here.

Regards,

Marc Schwartz


> On Aug 7, 2020, at 4:24 PM, Kevin Egan <kevinegan31 at gmail.com> wrote:
> 
> I posted this question:
> 
> I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.
> 
> After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.
> 
> Thanks.
> 
> and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.
> 
> Thanks.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  8 16:24:23 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 08 Aug 2020 07:24:23 -0700
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <60A6FED9-D9DD-4EAF-AF04-73080ED17EF4@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>
 <60A6FED9-D9DD-4EAF-AF04-73080ED17EF4@gmail.com>
Message-ID: <45B367BF-7931-41B4-9F47-DF8841695920@dcn.davis.ca.us>

You did not load the corresponding packages in both environments.

Also.. please post plain text format per the Posting Guide mentioned in the footer of every post.

On August 8, 2020 7:15:16 AM PDT, Kevin Egan <kevinegan31 at gmail.com> wrote:
>Local:
>R version 4.0.2 (2020-06-22)
>Platform: x86_64-apple-darwin17.0 (64-bit)
>Running under: macOS Catalina 10.15.6
>
>Matrix products: default
>BLAS:  
>/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
>LAPACK:
>/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>
>locale:
>[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] crayon_1.3.4     dplyr_1.0.0      R6_2.4.1         lifecycle_0.2.0 
>magrittr_1.5     pillar_1.4.3    
>[7] rlang_0.4.7      rstudioapi_0.11  vctrs_0.3.1      generics_0.0.2  
>ellipsis_0.3.0   tools_4.0.2     
>[13] glue_1.4.1       purrr_0.3.4      yaml_2.2.1       compiler_4.0.2 
> pkgconfig_2.0.3  tidyselect_1.1.0
>[19] tibble_3.0.1 
>
>
>Remote:
>> sessionInfo()
>R version 3.6.3 (2020-02-29)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: CentOS Linux 7 (Core)
>
>Matrix products: default
>BLAS/LAPACK:
>/ddn/apps/Cluster-Apps/intel/2019.5/compilers_and_libraries_2019.5.281/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so
>
>locale:
>[1] C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] compiler_3.6.3
>
>> On 8 Aug 2020, at 08:17, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> 
>> Compare the sessionInfo outputs for the different environments.
>> 
>> On August 7, 2020 1:24:55 PM PDT, Kevin Egan <kevinegan31 at gmail.com>
>wrote:
>>> I posted this question:
>>> 
>>> I am currently using R , RStudio , and a remote computer (using an R
>>> script) to run the same code. I start by using set.seed(123) in all
>>> three versions of the code, then using glmnet to assess a matrix.
>>> Ultimately, I am having trouble reproducing the results between my
>>> local and the remote computer's results. I am using R version 4.0.2
>>> locally, and R version 3.6.0 remote.
>>> 
>>> After running several tests, I'm wondering if there is a difference
>>> between the two versions in R which may lead to slightly different
>>> coefficients. If anyone has any insight I would appreciate it.
>>> 
>>> Thanks.
>>> 
>>> and found that there were slight differences between using rnorm
>with
>>> R-4.0.2 and R-3.6.0 but did not find any differences for runif
>between
>>> both systems. In my original code, I am using rnorm and was
>wondering
>>> if this may be the reason I am finding slight differences in
>>> coefficients for glmnet and lars testing between using my local
>>> computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my
>>> code locally on a MacOSX and remote on what I believe is an HPC.
>>> 
>>> Thanks.
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Sun Aug  9 01:05:02 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 9 Aug 2020 11:05:02 +1200
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
Message-ID: <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>

Hi Kevin,

Intuitively, the first step would be to ensure that all versions of R,
and all the R packages, are the same.

However, you mention HPC.
And the glmnet package imports the foreach package, which appears
(after a quick glance) to support multi-core and parallel computing.

If your code uses parallel computing (?), you may need to look at how
random numbers, and related results, are handled...


On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>
> I posted this question:
>
> I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.
>
> After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.
>
> Thanks.
>
> and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.
>
> Thanks.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  9 01:13:19 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 8 Aug 2020 19:13:19 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <D95591B3-7B2D-47AD-AB32-FD0A70CFFEF7@me.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <D95591B3-7B2D-47AD-AB32-FD0A70CFFEF7@me.com>
Message-ID: <b18405d9-abb7-27fe-e649-178abdbfe35f@gmail.com>

On 08/08/2020 9:34 a.m., Marc Schwartz via R-help wrote:
> Hi,
> 
> I was initially going to think that the change in the RNG might be the source, however, that change was made in 3.6.0 and would have applied to runif() and sample():
> 
> "sample.kind can be "Rounding" or "Rejection", or partial matches to these. The former was the default in versions prior to 3.6.0: it made sample noticeably non-uniform on large populations, and should only be used for reproduction of old results. See PR#17494 for a discussion."
> 

That still may be an issue.  If a user saves a workspace in an old 
version and reloads it in a newer version, I believe they get the old 
version of the RNG.

You need to check that the output of RNGkind() matches in all machines 
to know that they're using the same RNGs.

Duncan Murdoch

> Three other possibilities:
> 
> 1. Read news() for your local 4.0.2 installation, as there are some changes that were made, including some changes to round() that could be applicable here.
> 
> 2. Check to see if the version of glmnet is the same on both machines. There have been changes to that package that might be relevant here and you might read the README and NEWS files for the package on CRAN to see if there is any relevant information there.
> 
> 3. There is always a chance that different hardware and OS versions could lead to issues, especially out to a number of decimal places that could alter results. If you or via an Admin, have the ability to update the remote machine (both R and installed packages), that can help to reduce the number of variables at play here.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
>> On Aug 7, 2020, at 4:24 PM, Kevin Egan <kevinegan31 at gmail.com> wrote:
>>
>> I posted this question:
>>
>> I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.
>>
>> After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.
>>
>> Thanks.
>>
>> and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.
>>
>> Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @@e||ck @end|ng |rom gm@||@com  Sun Aug  9 01:18:22 2020
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Sat, 8 Aug 2020 19:18:22 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
Message-ID: <CADKEMqjiN0imSFhBGPztPOEub1TGu+Fg+paQ5kKFtJfi8NMNVg@mail.gmail.com>

Caveat, I have only skimmed this email thread, so please forgive me if I
have missed something.

Are you able to use Renv, packrat, docker, or anaconda? Your compute
environments are very different.
Kindest regards,

Stephen Sefick

On Sat, Aug 8, 2020, 19:05 Abby Spurdle <spurdle.a at gmail.com> wrote:

> Hi Kevin,
>
> Intuitively, the first step would be to ensure that all versions of R,
> and all the R packages, are the same.
>
> However, you mention HPC.
> And the glmnet package imports the foreach package, which appears
> (after a quick glance) to support multi-core and parallel computing.
>
> If your code uses parallel computing (?), you may need to look at how
> random numbers, and related results, are handled...
>
>
> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
> >
> > I posted this question:
> >
> > I am currently using R , RStudio , and a remote computer (using an R
> script) to run the same code. I start by using set.seed(123) in all three
> versions of the code, then using glmnet to assess a matrix. Ultimately, I
> am having trouble reproducing the results between my local and the remote
> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
> remote.
> >
> > After running several tests, I'm wondering if there is a difference
> between the two versions in R which may lead to slightly different
> coefficients. If anyone has any insight I would appreciate it.
> >
> > Thanks.
> >
> > and found that there were slight differences between using rnorm with
> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
> systems. In my original code, I am using rnorm and was wondering if this
> may be the reason I am finding slight differences in coefficients for
> glmnet and lars testing between using my local computer (R-4.0.2) and my
> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
> remote on what I believe is an HPC.
> >
> > Thanks.
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kev|neg@n31 @end|ng |rom gm@||@com  Sat Aug  8 16:15:16 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Sat, 8 Aug 2020 09:15:16 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>
Message-ID: <60A6FED9-D9DD-4EAF-AF04-73080ED17EF4@gmail.com>

Local:
R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] crayon_1.3.4     dplyr_1.0.0      R6_2.4.1         lifecycle_0.2.0  magrittr_1.5     pillar_1.4.3    
 [7] rlang_0.4.7      rstudioapi_0.11  vctrs_0.3.1      generics_0.0.2   ellipsis_0.3.0   tools_4.0.2     
[13] glue_1.4.1       purrr_0.3.4      yaml_2.2.1       compiler_4.0.2   pkgconfig_2.0.3  tidyselect_1.1.0
[19] tibble_3.0.1 


Remote:
> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS/LAPACK: /ddn/apps/Cluster-Apps/intel/2019.5/compilers_and_libraries_2019.5.281/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.6.3

> On 8 Aug 2020, at 08:17, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Compare the sessionInfo outputs for the different environments.
> 
> On August 7, 2020 1:24:55 PM PDT, Kevin Egan <kevinegan31 at gmail.com> wrote:
>> I posted this question:
>> 
>> I am currently using R , RStudio , and a remote computer (using an R
>> script) to run the same code. I start by using set.seed(123) in all
>> three versions of the code, then using glmnet to assess a matrix.
>> Ultimately, I am having trouble reproducing the results between my
>> local and the remote computer's results. I am using R version 4.0.2
>> locally, and R version 3.6.0 remote.
>> 
>> After running several tests, I'm wondering if there is a difference
>> between the two versions in R which may lead to slightly different
>> coefficients. If anyone has any insight I would appreciate it.
>> 
>> Thanks.
>> 
>> and found that there were slight differences between using rnorm with
>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between
>> both systems. In my original code, I am using rnorm and was wondering
>> if this may be the reason I am finding slight differences in
>> coefficients for glmnet and lars testing between using my local
>> computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my
>> code locally on a MacOSX and remote on what I believe is an HPC.
>> 
>> Thanks.
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.


	[[alternative HTML version deleted]]


From |knecht @end|ng |rom |redhutch@org  Fri Aug  7 23:26:58 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Fri, 7 Aug 2020 21:26:58 +0000
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
Message-ID: <3B5EC0C3-1118-44BA-B347-78C0EE08B685@fredhutch.org>

I believe that's what I've been doing already with the links I've provided below.

One of the pieces that escapes me is that there are bundled dynamic libraries like `gfortran` that are missing from the build from source solution I'm pursuing, however they exist in the packaged artifact available from here:
https://cloud.r-project.org/bin/macosx/R-4.0.2.pkg

How does that artifact get created? Does anyone know.

Warm Regards,

Logan

?2020/08/07 ??2:23 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:

    I don't think it's feasible to do what you want.  At a very basic level, 
    R assumes it has files distributed across a file system (mostly below 
    the R.home() directory).  Faking that in a single standalone executable 
    may be possible but wouldn't be easy.

    If running a server isn't possible, then I'd suggest you work on 
    automating a regular R installation, and put the things you want to run 
    into scripts that make use of it.  Two steps instead of one.

    Duncan Murdoch



    On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
    > Unfortunately, that is not a solution due to the constraints of file sizes associated with the run time operations as well as specific execution workflows.
    > 
    > I need to make this a packaged distributable and the only blocker for it at the moment is not being able to successfully bundle R as a standalone binary.
    > 
    > Warm Regards,
    > 
    > Logan Knecht
    > 
    > 2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:
    > 
    >      Wouldn't it be easier to set up a Shiny host system, and just give your
    >      collaborators a URL to the Shiny app running there?
    > 
    >      Duncan Murdoch
    > 
    > 
    >      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
    >      > Hello all,
    >      >
    >      > ===== The short version =====
    >      >
    >      > I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
    >      >
    >      > The inspiration for this comes from here:
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
    >      > and here
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
    >      >
    >      > I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
    >      >
    >      > ===== Questions =====
    >      >
    >      > -   How is the R binary at this link created?
    >      >      -   Link: https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
    >      > -   How do I include `libgfortran.5.dylib`
    >      >      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
    >      >      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
    >      > -   Is there any guidance on how to build a self-hosted R executable for each operating system?
    >      >      -   OSX
    >      >      -   Linux
    >      >      -   Windows
    >      >
    >      > ===== The long version =====
    >      >
    >      > ----- The Goal -----
    >      >
    >      > Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
    >      >
    >      > ----- The Impetus -----
    >      >
    >      > It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
    >      >
    >      > We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
    >      >
    >      > It should be as simple as downloading an application and running it.
    >      >
    >      > ----- The Current Progress -----
    >      >
    >      > I have a repo here that is an electron application
    >      >
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
    >      >
    >      > I can bundle these resources without issues
    >      >
    >      > -   Java
    >      > -   Nextflow
    >      > -   Our Shiny App
    >      >
    >      > ----- Process -----
    >      > The only missing piece is `R`
    >      >
    >      > I have a set of environment variables here:
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
    >      >
    >      > I `source` the env variables and then I run this script here:
    >      > `https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e= `
    >      >
    >      > I then use the downloaded `R` to install dependencies with these scripts:
    >      >
    >      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
    >      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
    >      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
    >      >
    >      > And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
    >      >
    >      > Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
    >      >
    >      > ===== The Plea For Guidance =====
    >      >
    >      > I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
    >      >
    >      > Any guidance or suggestions are greatly appreciated!
    >      >
    >      > Warm Regards,
    >      >
    >      > Logan Knecht
    >      >
    >      > 	[[alternative HTML version deleted]]
    >      >
    >      > ______________________________________________
    >      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
    >      > PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
    >      > and provide commented, minimal, self-contained, reproducible code.
    >      >
    > 
    > 



From kev|neg@n31 @end|ng |rom gm@||@com  Sun Aug  9 14:33:41 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Sun, 9 Aug 2020 07:33:41 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
Message-ID: <CAMKuLyRFVL=G3FRwV-MXk5J3x6F_WcczeEpdL0Am-HwG0ZcGRw@mail.gmail.com>

Hi Abby,

After running a few tests on my local and remote versions of R, this seems
to be the most plausible answer to the problem. I put set.seed(123)
several times within my code and produced the same results but would rather
not have to do that if possible.


On Sat, Aug 8, 2020 at 6:05 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> Hi Kevin,
>
> Intuitively, the first step would be to ensure that all versions of R,
> and all the R packages, are the same.
>
> However, you mention HPC.
> And the glmnet package imports the foreach package, which appears
> (after a quick glance) to support multi-core and parallel computing.
>
> If your code uses parallel computing (?), you may need to look at how
> random numbers, and related results, are handled...
>
>
> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
> >
> > I posted this question:
> >
> > I am currently using R , RStudio , and a remote computer (using an R
> script) to run the same code. I start by using set.seed(123) in all three
> versions of the code, then using glmnet to assess a matrix. Ultimately, I
> am having trouble reproducing the results between my local and the remote
> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
> remote.
> >
> > After running several tests, I'm wondering if there is a difference
> between the two versions in R which may lead to slightly different
> coefficients. If anyone has any insight I would appreciate it.
> >
> > Thanks.
> >
> > and found that there were slight differences between using rnorm with
> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
> systems. In my original code, I am using rnorm and was wondering if this
> may be the reason I am finding slight differences in coefficients for
> glmnet and lars testing between using my local computer (R-4.0.2) and my
> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
> remote on what I believe is an HPC.
> >
> > Thanks.
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@e||ck @end|ng |rom gm@||@com  Sun Aug  9 15:42:38 2020
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Sun, 9 Aug 2020 09:42:38 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <D69C605E-5CA1-4B07-A37E-83144C513B31@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
 <CADKEMqjiN0imSFhBGPztPOEub1TGu+Fg+paQ5kKFtJfi8NMNVg@mail.gmail.com>
 <D69C605E-5CA1-4B07-A37E-83144C513B31@gmail.com>
Message-ID: <CADKEMqhoFgoEK6qRiBkJTsgoTX4sgDBP9MCYi-S7Fhg824ZbOQ@mail.gmail.com>

Hi Kevin,

I think Abby has suggested something similar to what I think the problem is
related to - environment setup.

Some possible solutions:
The renv and packrat packages are a way to version your packages to help
with reproducability. Anaconda might be a solution for the R version and
package version problem, if installed on your hpc. Docker could work as
well (maybe the best option if installed). There are other workarounds, but
I would have to know how your particular hpc/compute environment is set up
to comment further.

Brass tacks:
I think you need to ensure all your package versions (R and add-on
packages) are the same.

Fwiw,

Stephen

On Sun, Aug 9, 2020, 08:26 Kevin Egan <kevinegan31 at gmail.com> wrote:

> Hi Stephen,
>
> I believe I am using Renv, but on my remote computer I am running batch
> files.
>
> Thanks,
>
> Kevin
>
> On 8 Aug 2020, at 18:18, stephen sefick <ssefick at gmail.com> wrote:
>
> Caveat, I have only skimmed this email thread, so please forgive me if I
> have missed something.
>
> Are you able to use Renv, packrat, docker, or anaconda? Your compute
> environments are very different.
> Kindest regards,
>
> Stephen Sefick
>
> On Sat, Aug 8, 2020, 19:05 Abby Spurdle <spurdle.a at gmail.com> wrote:
>
>> Hi Kevin,
>>
>> Intuitively, the first step would be to ensure that all versions of R,
>> and all the R packages, are the same.
>>
>> However, you mention HPC.
>> And the glmnet package imports the foreach package, which appears
>> (after a quick glance) to support multi-core and parallel computing.
>>
>> If your code uses parallel computing (?), you may need to look at how
>> random numbers, and related results, are handled...
>>
>>
>> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>> >
>> > I posted this question:
>> >
>> > I am currently using R , RStudio , and a remote computer (using an R
>> script) to run the same code. I start by using set.seed(123) in all three
>> versions of the code, then using glmnet to assess a matrix. Ultimately, I
>> am having trouble reproducing the results between my local and the remote
>> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
>> remote.
>> >
>> > After running several tests, I'm wondering if there is a difference
>> between the two versions in R which may lead to slightly different
>> coefficients. If anyone has any insight I would appreciate it.
>> >
>> > Thanks.
>> >
>> > and found that there were slight differences between using rnorm with
>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
>> systems. In my original code, I am using rnorm and was wondering if this
>> may be the reason I am finding slight differences in coefficients for
>> glmnet and lars testing between using my local computer (R-4.0.2) and my
>> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
>> remote on what I believe is an HPC.
>> >
>> > Thanks.
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  9 15:47:59 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 9 Aug 2020 09:47:59 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CAMKuLyRFVL=G3FRwV-MXk5J3x6F_WcczeEpdL0Am-HwG0ZcGRw@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
 <CAMKuLyRFVL=G3FRwV-MXk5J3x6F_WcczeEpdL0Am-HwG0ZcGRw@mail.gmail.com>
Message-ID: <41887239-72c9-e0f9-c281-14032c2765b7@gmail.com>

On 09/08/2020 8:33 a.m., Kevin Egan wrote:
> Hi Abby,
> 
> After running a few tests on my local and remote versions of R, this seems
> to be the most plausible answer to the problem. I put set.seed(123)
> several times within my code and produced the same results but would rather
> not have to do that if possible.

You should look at the doRNG package, which addresses exactly this 
problem.  See its vignette, vignette("doRNG", package="doRNG").

Duncan Murdoch
> 
> 
> On Sat, Aug 8, 2020 at 6:05 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
>> Hi Kevin,
>>
>> Intuitively, the first step would be to ensure that all versions of R,
>> and all the R packages, are the same.
>>
>> However, you mention HPC.
>> And the glmnet package imports the foreach package, which appears
>> (after a quick glance) to support multi-core and parallel computing.
>>
>> If your code uses parallel computing (?), you may need to look at how
>> random numbers, and related results, are handled...
>>
>>
>> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>>>
>>> I posted this question:
>>>
>>> I am currently using R , RStudio , and a remote computer (using an R
>> script) to run the same code. I start by using set.seed(123) in all three
>> versions of the code, then using glmnet to assess a matrix. Ultimately, I
>> am having trouble reproducing the results between my local and the remote
>> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
>> remote.
>>>
>>> After running several tests, I'm wondering if there is a difference
>> between the two versions in R which may lead to slightly different
>> coefficients. If anyone has any insight I would appreciate it.
>>>
>>> Thanks.
>>>
>>> and found that there were slight differences between using rnorm with
>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
>> systems. In my original code, I am using rnorm and was wondering if this
>> may be the reason I am finding slight differences in coefficients for
>> glmnet and lars testing between using my local computer (R-4.0.2) and my
>> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
>> remote on what I believe is an HPC.
>>>
>>> Thanks.
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |knecht @end|ng |rom |redhutch@org  Fri Aug  7 23:10:17 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Fri, 7 Aug 2020 21:10:17 +0000
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
Message-ID: <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>

Unfortunately, that is not a solution due to the constraints of file sizes associated with the run time operations as well as specific execution workflows.

I need to make this a packaged distributable and the only blocker for it at the moment is not being able to successfully bundle R as a standalone binary.

Warm Regards,

Logan Knecht

?2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:

    Wouldn't it be easier to set up a Shiny host system, and just give your 
    collaborators a URL to the Shiny app running there?

    Duncan Murdoch


    On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
    > Hello all,
    > 
    > ===== The short version =====
    > 
    > I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
    > 
    > The inspiration for this comes from here:
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e= 
    > and here
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e= 
    > 
    > I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
    > 
    > ===== Questions =====
    > 
    > -   How is the R binary at this link created?
    >      -   Link: https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e= 
    > -   How do I include `libgfortran.5.dylib`
    >      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
    >      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
    > -   Is there any guidance on how to build a self-hosted R executable for each operating system?
    >      -   OSX
    >      -   Linux
    >      -   Windows
    > 
    > ===== The long version =====
    > 
    > ----- The Goal -----
    > 
    > Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
    > 
    > ----- The Impetus -----
    > 
    > It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
    > 
    > We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
    > 
    > It should be as simple as downloading an application and running it.
    > 
    > ----- The Current Progress -----
    > 
    > I have a repo here that is an electron application
    > 
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e= 
    > 
    > I can bundle these resources without issues
    > 
    > -   Java
    > -   Nextflow
    > -   Our Shiny App
    > 
    > ----- Process -----
    > The only missing piece is `R`
    > 
    > I have a set of environment variables here:
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e= 
    > 
    > I `source` the env variables and then I run this script here:
    > `https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e= `
    > 
    > I then use the downloaded `R` to install dependencies with these scripts:
    > 
    > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e= 
    > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e= 
    > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e= 
    > 
    > And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
    > 
    > Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
    > 
    > ===== The Plea For Guidance =====
    > 
    > I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
    > 
    > Any guidance or suggestions are greatly appreciated!
    > 
    > Warm Regards,
    > 
    > Logan Knecht
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e= 
    > PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e= 
    > and provide commented, minimal, self-contained, reproducible code.
    > 



From kev|neg@n31 @end|ng |rom gm@||@com  Sun Aug  9 16:40:02 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Sun, 9 Aug 2020 09:40:02 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CADKEMqhoFgoEK6qRiBkJTsgoTX4sgDBP9MCYi-S7Fhg824ZbOQ@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
 <CADKEMqjiN0imSFhBGPztPOEub1TGu+Fg+paQ5kKFtJfi8NMNVg@mail.gmail.com>
 <D69C605E-5CA1-4B07-A37E-83144C513B31@gmail.com>
 <CADKEMqhoFgoEK6qRiBkJTsgoTX4sgDBP9MCYi-S7Fhg824ZbOQ@mail.gmail.com>
Message-ID: <CAMKuLySjPTR1MqKR319ryhUqJFtLYQiWwvrZm9dMD=EuMdKsXw@mail.gmail.com>

Hi Stephen,

Thanks, I?m now trying to use R 3.6.3 on the HPC, I was able to run a few
tests remote and get reproducible results. The batches have not yet run,
but I?m hoping will give reproducible results when they do.

Thanks,

Kevin

On Sun, Aug 9, 2020 at 08:42 stephen sefick <ssefick at gmail.com> wrote:

> Hi Kevin,
>
> I think Abby has suggested something similar to what I think the problem
> is related to - environment setup.
>
> Some possible solutions:
> The renv and packrat packages are a way to version your packages to help
> with reproducability. Anaconda might be a solution for the R version and
> package version problem, if installed on your hpc. Docker could work as
> well (maybe the best option if installed). There are other workarounds, but
> I would have to know how your particular hpc/compute environment is set up
> to comment further.
>
> Brass tacks:
> I think you need to ensure all your package versions (R and add-on
> packages) are the same.
>
> Fwiw,
>
> Stephen
>
> On Sun, Aug 9, 2020, 08:26 Kevin Egan <kevinegan31 at gmail.com> wrote:
>
>> Hi Stephen,
>>
>> I believe I am using Renv, but on my remote computer I am running batch
>> files.
>>
>> Thanks,
>>
>> Kevin
>>
>> On 8 Aug 2020, at 18:18, stephen sefick <ssefick at gmail.com> wrote:
>>
>> Caveat, I have only skimmed this email thread, so please forgive me if I
>> have missed something.
>>
>> Are you able to use Renv, packrat, docker, or anaconda? Your compute
>> environments are very different.
>> Kindest regards,
>>
>> Stephen Sefick
>>
>> On Sat, Aug 8, 2020, 19:05 Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>>> Hi Kevin,
>>>
>>> Intuitively, the first step would be to ensure that all versions of R,
>>> and all the R packages, are the same.
>>>
>>> However, you mention HPC.
>>> And the glmnet package imports the foreach package, which appears
>>> (after a quick glance) to support multi-core and parallel computing.
>>>
>>> If your code uses parallel computing (?), you may need to look at how
>>> random numbers, and related results, are handled...
>>>
>>>
>>> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>>> >
>>> > I posted this question:
>>> >
>>> > I am currently using R , RStudio , and a remote computer (using an R
>>> script) to run the same code. I start by using set.seed(123) in all three
>>> versions of the code, then using glmnet to assess a matrix. Ultimately, I
>>> am having trouble reproducing the results between my local and the remote
>>> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
>>> remote.
>>> >
>>> > After running several tests, I'm wondering if there is a difference
>>> between the two versions in R which may lead to slightly different
>>> coefficients. If anyone has any insight I would appreciate it.
>>> >
>>> > Thanks.
>>> >
>>> > and found that there were slight differences between using rnorm with
>>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
>>> systems. In my original code, I am using rnorm and was wondering if this
>>> may be the reason I am finding slight differences in coefficients for
>>> glmnet and lars testing between using my local computer (R-4.0.2) and my
>>> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
>>> remote on what I believe is an HPC.
>>> >
>>> > Thanks.
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Aug  9 21:59:07 2020
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 9 Aug 2020 20:59:07 +0100
Subject: [R] Arrange data
In-Reply-To: <63668df7-0823-0a33-3e31-71a794e85b28@sapo.pt>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <de75298f-9ba6-2ed3-5e2b-4095424f9834@sapo.pt>
 <CAO29qn7_qpuOvDodrWUCm+3Js7mXrRhAYa0-kmunEyWZbMMUbA@mail.gmail.com>
 <63668df7-0823-0a33-3e31-71a794e85b28@sapo.pt>
Message-ID: <CAO29qn48LtC505-nqib9DoCt-hYv-PCJtzaAkNPoM_T3tiYgdw@mail.gmail.com>

Dear Rui,

Thank you for your nice help.

Take care and be safe.

Md

On Tue, Aug 4, 2020 at 10:45 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Please keep cc-ing the list R-help is threaded and questions and answers
> might be of help to others in the future.
>
> As for the question, see if the following code does what you want.
> First, create a logical index i of the months between 7 and 3 and use
> that index to subset the original data.frame. Then, a cumsum trick gives
> a vector M defining the data grouping. Group and compute the Value means
> with aggregate. Finally, since each group spans a year border, create a
> more meaningful Years column and put everything together.
>
> df1 <- read.csv("mddat.csv")
>
> i <- with(df1, (Month >= 7 & Month <= 12) | (Month >= 1 & Month <= 3))
> df2 <- df1[i, ]
> M <- cumsum(c(FALSE, diff(as.integer(row.names(df2))) > 1))
>
> agg <- aggregate(Value ~ M, df2, mean)
> Years <- sapply(split(df2$Year, M), function(x){paste(x[1],
> x[length(x)], sep = "-")})
> final <- cbind.data.frame(Years, Value = agg[["Value"]])
>
> head(final)
> #      Years    Value
> #0 1975-1975 87.00000
> #1 1975-1976 89.44444
> #2 1976-1977 85.77778
> #3 1977-1978 81.55556
> #4 1978-1979 71.55556
> #5 1979-1980 75.77778
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> ?s 20:44 de 04/08/20, Md. Moyazzem Hossain escreveu:
> > Dear Rui,
> >
> > Thanks a lot for your help.
> >
> > It is working. Now I am also trying to find the average of values for
> > *July 1975 to March 1976* and record as the value of the year 1975.
> > Moreover, I want to continue it up to the year 2017. You may check the
> > attached file for data (mddat.csv).
> >
> > I use the following function but got error
> > aggregate(Value ~ Year, data = subset(df1, Month >= 7 & Month <= 3), FUN
> > = mean)
> >
> > Please help me again. Thanks in advance.
> >
> > Best Regards,
> > Md
> >
> > On Mon, Aug 3, 2020 at 11:28 PM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     And here is another way, with aggregate.
> >
> >     Make up test data.
> >
> >     set.seed(2020)
> >     df1 <- expand.grid(Year = 2000:2018, Month = 1:12)
> >     df1 <- df1[order(df1$Year),]
> >     df1$Value <- sample(20:30, nrow(df1), TRUE)
> >     head(df1)
> >
> >
> >     #Use subset to keep only the relevant months
> >     aggregate(Value ~ Year, data = subset(df1, Month <= 7), FUN = mean)
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 12:33 de 03/08/2020, Rasmus Liland escreveu:
> >      > On 2020-08-03 21:11 +1000, Jim Lemon wrote:
> >      >> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain
> >     <hossainmm at juniv.edu <mailto:hossainmm at juniv.edu>> wrote:
> >      >>> Hi,
> >      >>>
> >      >>> I have a dataset having monthly
> >      >>> observations (from January to
> >      >>> December) over a period of time like
> >      >>> (2000 to 2018). Now, I am trying to
> >      >>> take an average the value from
> >      >>> January to July of each year.
> >      >>>
> >      >>> The data looks like
> >      >>> Year    Month  Value
> >      >>> 2000    1         25
> >      >>> 2000    2         28
> >      >>> 2000    3         22
> >      >>> ....    ......      .....
> >      >>> 2000    12       26
> >      >>> 2001     1       27
> >      >>> .......         ........
> >      >>> 2018    11       30
> >      >>> 20118   12      29
> >      >>>
> >      >>> Can someone help me in this regard?
> >      >>>
> >      >>> Many thanks in advance.
> >      >> Hi Md,
> >      >> One way is to form a subset of your
> >      >> data, then calculate the means by
> >      >> year:
> >      >>
> >      >> # assume your data is named mddat
> >      >> mddat2<-mddat[mddat$month < 7,]
> >      >> jan2jun<-by(mddat2$value,mddat2$year,mean)
> >      >>
> >      >> Jim
> >      > Hi Md,
> >      >
> >      > you can also define the period in a new
> >      > column, and use aggregate like this:
> >      >
> >      >       Md <- structure(list(
> >      >       Year = c(2000L, 2000L, 2000L,
> >      >       2000L, 2001L, 2018L, 2018L),
> >      >       Month = c(1L, 2L, 3L, 12L, 1L,
> >      >       11L, 12L),
> >      >       Value = c(25L, 28L, 22L, 26L,
> >      >       27L, 30L, 29L)),
> >      >       class = "data.frame",
> >      >       row.names = c(NA, -7L))
> >      >
> >      >       Md[Md$Month %in%
> >      >               1:6,"Period"] <- "first six months of the year"
> >      >       Md[Md$Month %in% 7:12,"Period"] <- "last six months of the
> >     year"
> >      >
> >      >       aggregate(
> >      >         formula=Value~Year+Period,
> >      >         data=Md,
> >      >         FUN=mean)
> >      >
> >      > Rasmus
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >     --
> >     Este e-mail foi verificado em termos de v?rus pelo software
> >     antiv?rus Avast.
> >     https://www.avast.com/antivirus
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Aug  9 21:59:50 2020
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 9 Aug 2020 20:59:50 +0100
Subject: [R] Arrange data
In-Reply-To: <CA+8X3fUvBuPjJR+xkp+mL2KLfg3DqqOhAcEnqdiDVSpZ6LWzhg@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
 <CA+8X3fWF4TBbhqiUErDKKKw-j8nbK8+oEh0kV7+Ow8RiaU6kug@mail.gmail.com>
 <CAO29qn4qjv=i0SGr0QLZSzmpOuW1imhUqeiK4-ivwMj_fk75UQ@mail.gmail.com>
 <CA+8X3fUvBuPjJR+xkp+mL2KLfg3DqqOhAcEnqdiDVSpZ6LWzhg@mail.gmail.com>
Message-ID: <CAO29qn4AC-nq_pueBPhpFqRPhYXG828TMNJS39OBzu7hb1LgrQ@mail.gmail.com>

Dear Jim,

Thanks a lot for your support.

Take care.

Md

On Wed, Aug 5, 2020 at 1:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Md,
> I think the errors are that you forgot to initialize "m", calculated
> the mean outside the loops and forgot the final brace:
>
> m<-rep(0,44)
> for(i in 1975:2017) {
>   for(j in 1:44) {
>    mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
>       mddat$Year == (i+1) & mddat$Month <= 6,]
>    m[j]=mean(mddat2$Value)
>  }
> }
>
> Jim
>
> On Wed, Aug 5, 2020 at 6:04 AM Md. Moyazzem Hossain <hossainmm at juniv.edu>
> wrote:
> >
> > Dear Jim,
> >
> > Thank you very much. You are right. It is good now. However, I want to
> continue it up to the year 2017.
> >
> > I use the following code but got the error
> >
> > for(i in 1975:2017){
> >   for(j in 1:44){
> > mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
> >                 mddat$Year == (i+1) & mddat$Month <= 6,]
> > }
> > m[j]=mean(mddat2$Value)
> >
> > }
> > m
> >
> > Please help me in this regard. Many thanks in advance.
> >
> > Regards,
> > Md
> >
> > On Tue, Aug 4, 2020 at 8:41 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Your problem is in the subset operation. You have asked for a value of
> >> month greater or equal to 7 and less than or equal to 6. You probably
> >> got an error message that told you that the data were of length zero
> >> or something similar. If you check the result of that statement:
> >>
> >> > mddat$month >= 7 & mddat$month <= 6
> >> logical(0)
> >>
> >> In other words, the two logical statements when ANDed cannot produce a
> >> result. A number cannot be greater than or equal to 7 AND less than or
> >> equal to 6. What you want is:
> >>
> >> mddat2<-mddat[mddat$Year == 1975 & mddat$Month >= 7 |
> >>  mddat$Year == 1976 & mddat$Month <= 6,]
> >> mean(mddat2$Value)
> >> [1] 88.91667
> >>
> >> Apart from that, your email client is inserting EOL characters that
> >> cause an error when pasted into R.
> >>
> >> Error: unexpected input in "?"
> >>
> >> Probably due to MS Outlook, this has been happening quite a bit lately.
> >>
> >> Jim
> >>
> >> On Mon, Aug 3, 2020 at 11:30 PM Md. Moyazzem Hossain
> >> <hossainmm at juniv.edu> wrote:
> >> >
> >> > Dear Jim,
> >> >
> >> > Thank you very much. It is working now.
> >> >
> >> > However, I am also trying to find the average of the value from July
> 1975 to June 1976 and recorded as the value for the year 1975 but got an
> error message. I am attaching the data file here. Please check the
> attachment.
> >> >
> >> > mddat=read.csv("F:/mddat.csv", header=TRUE)
> >> > mddat2<-mddat[mddat$Month >=7 & mddat$Month <= 6,]
> >> > jan2jun<-by(mddat2$Value,mddat2$Year,mean)
> >> > jan2jun
> >> >
> >> > Please help me again and many thanks in advance.
> >> >
> >> > Md
> >> >
> >> >
> >> > On Mon, Aug 3, 2020 at 12:33 PM Rasmus Liland <jral at posteo.no> wrote:
> >> >>
> >> >> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
> >> >> > On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <
> hossainmm at juniv.edu> wrote:
> >> >> > >
> >> >> > > Hi,
> >> >> > >
> >> >> > > I have a dataset having monthly
> >> >> > > observations (from January to
> >> >> > > December) over a period of time like
> >> >> > > (2000 to 2018). Now, I am trying to
> >> >> > > take an average the value from
> >> >> > > January to July of each year.
> >> >> > >
> >> >> > > The data looks like
> >> >> > > Year    Month  Value
> >> >> > > 2000    1         25
> >> >> > > 2000    2         28
> >> >> > > 2000    3         22
> >> >> > > ....    ......      .....
> >> >> > > 2000    12       26
> >> >> > > 2001     1       27
> >> >> > > .......         ........
> >> >> > > 2018    11       30
> >> >> > > 20118   12      29
> >> >> > >
> >> >> > > Can someone help me in this regard?
> >> >> > >
> >> >> > > Many thanks in advance.
> >> >> >
> >> >> > Hi Md,
> >> >> > One way is to form a subset of your
> >> >> > data, then calculate the means by
> >> >> > year:
> >> >> >
> >> >> > # assume your data is named mddat
> >> >> > mddat2<-mddat[mddat$month < 7,]
> >> >> > jan2jun<-by(mddat2$value,mddat2$year,mean)
> >> >> >
> >> >> > Jim
> >> >>
> >> >> Hi Md,
> >> >>
> >> >> you can also define the period in a new
> >> >> column, and use aggregate like this:
> >> >>
> >> >>         Md <- structure(list(
> >> >>         Year = c(2000L, 2000L, 2000L,
> >> >>         2000L, 2001L, 2018L, 2018L),
> >> >>         Month = c(1L, 2L, 3L, 12L, 1L,
> >> >>         11L, 12L),
> >> >>         Value = c(25L, 28L, 22L, 26L,
> >> >>         27L, 30L, 29L)),
> >> >>         class = "data.frame",
> >> >>         row.names = c(NA, -7L))
> >> >>
> >> >>         Md[Md$Month %in%
> >> >>                 1:6,"Period"] <- "first six months of the year"
> >> >>         Md[Md$Month %in% 7:12,"Period"] <- "last six months of the
> year"
> >> >>
> >> >>         aggregate(
> >> >>           formula=Value~Year+Period,
> >> >>           data=Md,
> >> >>           FUN=mean)
> >> >>
> >> >> Rasmus
> >> >
> >> >
> >> >
> >
> >
> >
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug 10 05:23:00 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 10 Aug 2020 13:23:00 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB3199D2DBA9ECD5A24F839B93BB470@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
 <CA+8X3fUDzdJ3diRFthS=LzCH6R5wpwaowuBgisYTOETt=vTaQQ@mail.gmail.com>
 <VI1PR0302MB3199E50BAE6DF7AE78178FFCBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fWAexSRCM7mxzv58MTVaQp2rAbeAWtN7Zrd_ffxxXW==g@mail.gmail.com>
 <VI1PR0302MB3199D2DBA9ECD5A24F839B93BB470@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fVHt9MkCzKWvFB3QoeJOxxXkpgTw_omNKXfT1AqqM9QWA@mail.gmail.com>

Hi Ahmet,
An easy way is this:

library(ncdf4)
soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
soil_moist<-ncvar_get(soilm)
smdim<-dim(soil_moist)
# identify NA grid cells
sm_NA_count<-matrix(NA,nrow=smdim[1],ncol=smdim[2])
for(i in 1:smdim[1]) {
 for(j in 1:smdim[2]) {
  sm_NA_count[i,j]<-sum(!is.na(soil_moist[i,j,]))
 }
}

The resulting matrix contains the counts of valid (not NA) values in
each 365 day series in the array. It looks to me as though there are
5914 complete series and the rest are all NA. This does not tell you
why some files (the third dimension) are all NA. Probably the best
guess is that the soil moisture content is not measurable for some
reason. Here is the explanation from NOAA:

Missing Data:

There is no missing data though the ocean has 0's. There is a file
with the percent of the grid that is land. Another file has simply 1
and 0's for land/ocean. Grids where the percent of land is zero are
"missing".

You can get a feel for the geographic coverage like this (white cells
are not NA):

library(maps)
library(plotrix)
color2D.matplot(t(sm_NA_count))

Jim

On Mon, Aug 10, 2020 at 4:09 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
> Hi Jim,
>
>
>
> Could you help me to remove NA values which are water values ?
>
>
>
>
>
> Kimden: Jim Lemon
> G?nderilme: 7 A?ustos 2020 Cuma 22:53
> Kime: ahmet varl?
> Konu: Re: [R] find number of consecutive days in NC files by R
>
>
>
> There are 17848 grid cells in the file I downloaded for 1949. Many of
> them only contain NA values, probably because they are from a
> geographic grid that is covered by water. In the code there is a
> section that prints out a list of the grid cells that contain minimum
> values less than 0.3. Since I don't know which grid cell you are
> using, I had to find one that would produce interpretable results for
> the problem you are trying to solve.
>
> Jim
>
> On Fri, Aug 7, 2020 at 11:03 PM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> > I am greatfull for your helps and ? just want to ask why did you use cell 159,66
> >
>
>


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Aug 10 08:37:33 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 10 Aug 2020 06:37:33 +0000
Subject: [R] find end of monotonic part of vector
In-Reply-To: <5416c4bd-6365-46e0-abeb-9c8f852163f7@sapo.pt>
References: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
 <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>
 <5416c4bd-6365-46e0-abeb-9c8f852163f7@sapo.pt>
Message-ID: <f6230d43aab84b73ae68e165a797cc9d@SRVEXCHCM1302.precheza.cz>

Thank you Rui

The problem is that this was just a part of my data and I have many of such
consecutive chunks. So far I have a solution in mind which I will try. 

Set all values above 900 to NA.
Set all values below 600 (or 650) to NA
Find parts which have at least 4 continuous values (values not having NA
within them).
Find position of all minimum values.

Not sure if this approach will work, though.

Cheers
Petr

> -----Original Message-----
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Friday, August 7, 2020 5:45 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; R-help <r-help at r-project.org>
> Subject: Re: [R] find end of monotonic part of vector
> 
> Hello,
> 
> I should have continued, inline.
> 
> ?s 15:05 de 07/08/20, Rui Barradas escreveu:
> > Hello,
> >
> > Maybe I'm not understanding but looking at this graph
> >
> >
> > i <- diff(kalo.v$vodiv) > 0
> > plot(kalo.v)
> > lines(kalo.v)
> > points(kalo.v$cas[i], kalo.v$vodiv[i], pch = 16, col = "red")
> >
> >
> > it seems you want the point before the first local minimum?
> >
> >
> > min(which(i)) - 1L
> > #[1] 20
> >
> 
> (k <- min(which(i)) - 1L)
> #[1] 20
> 
> kalo.v[k, ]
> #                      cas  vodiv
> #71230 2020-07-27 11:09:00 652.53
> 
> 
> Rui Barradas
> 
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ?s 13:05 de 07/08/20, PIKAL Petr escreveu:
> >> Hallo all
> >>
> >> I have such data
> >>> dput(kalo.v)
> >> structure(list(cas = structure(c(1595847000, 1595847060, 1595847120,
> >> 1595847180, 1595847240, 1595847300, 1595847360, 1595847420,
> >> 1595847480, 1595847540, 1595847600, 1595847660, 1595847720,
> >> 1595847780, 1595847840, 1595847900, 1595847960, 1595848020,
> >> 1595848080, 1595848140, 1595848200, 1595848260, 1595848320,
> >> 1595848380, 1595848440, 1595848500, 1595848560, 1595848620,
> >> 1595848680, 1595848740, 1595848800, 1595848860, 1595848920,
> >> 1595848980, 1595849040, 1595849100, 1595849160, 1595849220,
> >> 1595849280, 1595849340, 1595849400, 1595849460, 1595849520,
> >> 1595849580, 1595849640 ), class = c("POSIXct", "POSIXt"), tzone =
> >> "UTC"), vodiv = c(999.9000244, 999.9000244, 999.9000244, 999.9000244,
> >> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> >> 999.9000244, 999.9000244, 999.9000244, 991.6404419, 925.2166748,
> >> 864.3446045, 812.1702271, 758.9353027, 722.5073242, 684.5323486,
> >> 652.5300293, 82.18816376, 141.1757813, 402.7521667, 999.9000244,
> >> 959.1779175, 967.0949707, 517.1983643, 50, 50, 524.569458,
> >> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> >> 999.9000244, 999.9000244, 977.0491943, 889.9714355, 999.9000244,
> >> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244)),
> >> row.names = 71211:71255, class =
> >> "data.frame")
> >>
> >> and I would like to automatically find endpoint of gradually
> >> decreasing part (here point 20, vodiv = 652.****).
> >>
> >> Usually I use diff but this is just a chunk of bigger data and diff
> >> seems to be difficult to use. I appreciate any hint.
> >>
> >> Best regards.
> >> Petr
> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From percent||101 @end|ng |rom gm@||@com  Fri Aug  7 15:56:43 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Fri, 7 Aug 2020 15:56:43 +0200
Subject: [R] Add a logo on a plot
Message-ID: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>

Hi,

There is a way to add a photo like a free text but images on a plot, (hist,
chart trough ggplot) to add a logo or any PNG .

	[[alternative HTML version deleted]]


From m@||2r@jk@poor @end|ng |rom gm@||@com  Fri Aug  7 18:55:32 2020
From: m@||2r@jk@poor @end|ng |rom gm@||@com (Raj kapoor)
Date: Fri, 7 Aug 2020 22:25:32 +0530
Subject: [R] C stack usage 7970372 is too close to the limit
Message-ID: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>

Hi Team,

I have one production instance in aws, in CentoOs linux environment, i have
5 user to access the instance for using RStudio, In case R-studio working 4
users running good, while we access 5th users its getting error,

First issue : C stack usage 7970372 is too close to the limit

Second Issue :  no stack overflow

Please provide the solution.

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug 10 15:57:08 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 10 Aug 2020 16:57:08 +0300
Subject: [R] Add a logo on a plot
In-Reply-To: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
References: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
Message-ID: <20200810165708.69c92df4@trisector>

On Fri, 7 Aug 2020 15:56:43 +0200
Pedro p?ramo <percentil101 at gmail.com> wrote:

> There is a way to add a photo like a free text but images on a plot,
> (hist, chart trough ggplot) to add a logo or any PNG .

See ?rasterImage and the example in ?png::readPNG [*].

-- 
Best regards,
Ivan

[*] png is a CRAN package, https://cran.r-project.org/package=png


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug 10 16:04:09 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 10 Aug 2020 17:04:09 +0300
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
Message-ID: <20200810170409.36f8bb99@trisector>

On Fri, 7 Aug 2020 22:25:32 +0530
Raj kapoor <mail2rajkapoor at gmail.com> wrote:

> I have one production instance in aws, in CentoOs linux environment,
> i have 5 user to access the instance for using RStudio, In case
> R-studio working 4 users running good, while we access 5th users its
> getting error,

Sorry, R-Studio support is over there: https://support.rstudio.com/

If you think that the issue is with R and not R-Studio, please show us
how this problem can be reproduced (i.e. include the data and the code
we could run ourselves to trigger the issue). Check out the posting
guide [*] and, in particular, this HOWTO [**] on seeking technical help.

-- 
Best regards,
Ivan

> 	[[alternative HTML version deleted]]

P.S. Please post in plain text, not HTML.

[*] https://www.r-project.org/posting-guide.html
The link is appended to every e-mail sent via this list.

[**] http://www.catb.org/~esr/faqs/smart-questions.html


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 10 18:36:49 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 10 Aug 2020 09:36:49 -0700
Subject: [R] Question about PERL lookahead construct in regex's
Message-ID: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>

Folks:

Consider:
> y <- "xx wt"

> grep(" +(?=t)",y, perl = TRUE)
integer(0)
## Unexpected. Lookahead construct does not find "t" after space
## But
> grep(" +(?=.+t)",y, perl = TRUE)
[1] 1
## Expected. Given pattern for **exact** match, lookahead finds it

My concern is:
?regexp says this:
"Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
 *assertions*: they match if an attempt to match the ... forward from the
current position would succeed (or not), but use up no characters in the
string being processed."

But this appears to be imprecise (it confused me, anyway). The usual sense
of "matching" in regex's is "match the pattern somewhere in the string
going forward." But in the perl lookahead construct it apparently must
**exactly** match *everything* in the string that follows.

Questions:
Am I correct about this? If not, what do I misunderstand?
If I am correct, should the regex help be slightly modified to something
like:

"Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
 *assertions*: they match if an attempt to **exactly" match all of ... forward
from the current position would succeed (or not), but use up no characters
in the string being processed."

Thanks.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From john@m@h@rro|d @end|ng |rom gm@||@com  Mon Aug 10 18:51:14 2020
From: john@m@h@rro|d @end|ng |rom gm@||@com (John Harrold)
Date: Mon, 10 Aug 2020 09:51:14 -0700
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
Message-ID: <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>

Hello Raj,

I've gotten this type of error in the past when I've done things like use
while loops that didn't end. Basically, I think this means you're running
out of memory. If you want more users, possibly increase the amount of ram
in your machine.

John

On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor <mail2rajkapoor at gmail.com> wrote:

> Hi Team,
>
> I have one production instance in aws, in CentoOs linux environment, i have
> 5 user to access the instance for using RStudio, In case R-studio working 4
> users running good, while we access 5th users its getting error,
>
> First issue : C stack usage 7970372 is too close to the limit
>
> Second Issue :  no stack overflow
>
> Please provide the solution.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John
:wq

	[[alternative HTML version deleted]]


From m@||2r@jk@poor @end|ng |rom gm@||@com  Mon Aug 10 20:13:05 2020
From: m@||2r@jk@poor @end|ng |rom gm@||@com (Raj kapoor)
Date: Mon, 10 Aug 2020 23:43:05 +0530
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
Message-ID: <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>

Hi John,

I have 10 user in the instance, 9 user is working and access the R studio
app, but while access the 10th user it's getting stack usage limit issues,
then we create the new users its working fine.

On Mon, 10 Aug 2020, 10:21 pm John Harrold, <john.m.harrold at gmail.com>
wrote:

> Hello Raj,
>
> I've gotten this type of error in the past when I've done things like use
> while loops that didn't end. Basically, I think this means you're running
> out of memory. If you want more users, possibly increase the amount of ram
> in your machine.
>
> John
>
> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor <mail2rajkapoor at gmail.com>
> wrote:
>
>> Hi Team,
>>
>> I have one production instance in aws, in CentoOs linux environment, i
>> have
>> 5 user to access the instance for using RStudio, In case R-studio working
>> 4
>> users running good, while we access 5th users its getting error,
>>
>> First issue : C stack usage 7970372 is too close to the limit
>>
>> Second Issue :  no stack overflow
>>
>> Please provide the solution.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> John
> :wq
>

	[[alternative HTML version deleted]]


From m@||2r@jk@poor @end|ng |rom gm@||@com  Mon Aug 10 20:14:22 2020
From: m@||2r@jk@poor @end|ng |rom gm@||@com (Raj kapoor)
Date: Mon, 10 Aug 2020 23:44:22 +0530
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
 <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
Message-ID: <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>

Hi John,

Only the particular users getting error john. Please help me




On Mon, 10 Aug 2020, 11:43 pm Raj kapoor, <mail2rajkapoor at gmail.com> wrote:

> Hi John,
>
> I have 10 user in the instance, 9 user is working and access the R studio
> app, but while access the 10th user it's getting stack usage limit issues,
> then we create the new users its working fine.
>
> On Mon, 10 Aug 2020, 10:21 pm John Harrold, <john.m.harrold at gmail.com>
> wrote:
>
>> Hello Raj,
>>
>> I've gotten this type of error in the past when I've done things like use
>> while loops that didn't end. Basically, I think this means you're running
>> out of memory. If you want more users, possibly increase the amount of ram
>> in your machine.
>>
>> John
>>
>> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor <mail2rajkapoor at gmail.com>
>> wrote:
>>
>>> Hi Team,
>>>
>>> I have one production instance in aws, in CentoOs linux environment, i
>>> have
>>> 5 user to access the instance for using RStudio, In case R-studio
>>> working 4
>>> users running good, while we access 5th users its getting error,
>>>
>>> First issue : C stack usage 7970372 is too close to the limit
>>>
>>> Second Issue :  no stack overflow
>>>
>>> Please provide the solution.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> John
>> :wq
>>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 10 21:05:50 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 10 Aug 2020 12:05:50 -0700
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <C81804B4-27CC-4898-9A37-72031495BFBA@fredhutch.org>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
 <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>
 <C81804B4-27CC-4898-9A37-72031495BFBA@fredhutch.org>
Message-ID: <CA704D54-8FC2-4BD5-85D1-FCD94EA0C6E1@dcn.davis.ca.us>

I specifically said that there are approaches that apply container technology to user software... I generally cannot tell whether software I am running on Ubuntu is a snap container or a native binary. Windows Store offers a similar experience. Your goal of targeting multiple platforms is complicating this discussion though... I don't plan to follow you down that rabbit hole. This forum is about the R language.

On August 10, 2020 10:37:57 AM PDT, "Knecht, Logan" <lknecht at fredhutch.org> wrote:
>I am an expert user for Docker. Unfortunately this is not a use case
>that will work with Docker.
>
>The goal is to provide a self-contained artifact as a solution so that
>no effort needs to be put into the environment configuration.
>
>If Docker was used, the users would need to download docker and figure
>out how to run the docker image I build.
>
>That is a solution, but it does not fit the deliverable requirements
>I'm shooting for.
>
>Logan
>
>?2020/08/07 ??4:37 ??"Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>????????:
>
>While I have not attempted to apply this to Shiny apps on the desktop,
>layered container technology (e.g. Docker) is being rolled out for
>desktop app distribution on Linux (snap, flatpak) and Windows (Open
>Packaging Conventions), with which complex filesystem structures can be
>managed in isolated runtime environments. The hardest part is working
>out how the container will interact with the world... which I don't
>know the details of but it is clearly in the realm of "feasible".
>
>On August 7, 2020 2:23:48 PM PDT, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
>    >I don't think it's feasible to do what you want.  At a very basic
>    >level, 
>>R assumes it has files distributed across a file system (mostly below 
>>the R.home() directory).  Faking that in a single standalone
>executable
>    >
>    >may be possible but wouldn't be easy.
>    >
>    >If running a server isn't possible, then I'd suggest you work on 
>>automating a regular R installation, and put the things you want to
>run
>    >
>    >into scripts that make use of it.  Two steps instead of one.
>    >
>    >Duncan Murdoch
>    >
>    >
>    >
>    >On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
>>> Unfortunately, that is not a solution due to the constraints of file
>    >sizes associated with the run time operations as well as specific
>    >execution workflows.
>    >> 
>>> I need to make this a packaged distributable and the only blocker
>for
>    >it at the moment is not being able to successfully bundle R as a
>    >standalone binary.
>    >> 
>    >> Warm Regards,
>    >> 
>    >> Logan Knecht
>    >> 
>    >> 2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com>
>    >????????:
>    >> 
>  >>      Wouldn't it be easier to set up a Shiny host system, and just
>    >give your
>    >>      collaborators a URL to the Shiny app running there?
>    >> 
>    >>      Duncan Murdoch
>    >> 
>    >> 
>    >>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
>    >>      > Hello all,
>    >>      >
>    >>      > ===== The short version =====
>    >>      >
>>>      > I am trying to build a standalone version for R so that I can
>>bundle and package a self-hosted environment for a shiny app. There
>are
>    >reasons for this decision, but it will only distract from the
>    >discussion.
>    >>      >
>    >>      > The inspiration for this comes from here:
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
>    >>      > and here
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
>    >>      >
>    >>      > I have tried these solutions, to no avail as I repeatedly
> >encounter issues with the process. Some issues have been difficulties
>    >importing libraries after repeating their steps, others have been
>    >issues with missing dynamic libraries that aren't available when I
>    >build from source.
>    >>      >
>    >>      > ===== Questions =====
>    >>      >
>    >>      > -   How is the R binary at this link created?
>    >>      >      -   Link:
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
>    >>      > -   How do I include `libgfortran.5.dylib`
>    >>      >      -   This distributable, when configured shows a file
>    >called `libgfortran.5.dylib`
>>>      >      -   As of this writing, my solution fails because this
>is
>    >missing when I run the self-hosted R
>    >>      > -   Is there any guidance on how to build a self-hosted R
>    >executable for each operating system?
>    >>      >      -   OSX
>    >>      >      -   Linux
>    >>      >      -   Windows
>    >>      >
>    >>      > ===== The long version =====
>    >>      >
>    >>      > ----- The Goal -----
>    >>      >
>   >>      > Create a self hosted version of R that runs independent of
>    >each system so that I can package and build shiny apps to be
>>distributed to collaborators in order to evangelize our new
>statistical
>    >method.
>    >>      >
>    >>      > ----- The Impetus -----
>    >>      >
>    >>      > It is too distracting and too much work to get our
>>collaborators to configure their environments just to try our
>statiscal
>    >methods we have been creating.
>    >>      >
>  >>      > We have a shiny app built around the statistical methods to
> >simplify the interface for interaction. Now we want to package it for
>    >easy consumption.
>    >>      >
>    >>      > It should be as simple as downloading an application and
>    >running it.
>    >>      >
>    >>      > ----- The Current Progress -----
>    >>      >
>    >>      > I have a repo here that is an electron application
>    >>      >
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
>    >>      >
>    >>      > I can bundle these resources without issues
>    >>      >
>    >>      > -   Java
>    >>      > -   Nextflow
>    >>      > -   Our Shiny App
>    >>      >
>    >>      > ----- Process -----
>    >>      > The only missing piece is `R`
>    >>      >
>    >>      > I have a set of environment variables here:
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
>    >>      >
>>>      > I `source` the env variables and then I run this script here:
>    >>      >
>>`https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e=
>    >`
>    >>      >
>   >>      > I then use the downloaded `R` to install dependencies with
>    >these scripts:
>    >>      >
>    >>      > -  
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
>    >>      > -  
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
>    >>      > -  
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
>    >>      >
>>>      > And then voil?! It works. Well. It works on my local machine.
>>I can run the development build, I can package the build, I can run
>the
>    >release after installing it. Everything works.
>    >>      >
>>>      > Except when I bring it over to a separate computer it doesn't
>  >work because it states that it can't find `libgfortran.5.dylib`. See
>    >the attached screen shot.
>    >>      >
>    >>      > ===== The Plea For Guidance =====
>    >>      >
>  >>      > I would love any help to figure out how to achieve this. We
>>are very close to somethng tangibly interesting and it's very
>deflating
>   >to be blocked because `R` does not have a distributable that can be
>    >bundled.
>    >>      >
>    >>      > Any guidance or suggestions are greatly appreciated!
>    >>      >
>    >>      > Warm Regards,
>    >>      >
>    >>      > Logan Knecht
>    >>      >
>    >>      > 	[[alternative HTML version deleted]]
>    >>      >
>    >>      > ______________________________________________
>>>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>    >see
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
>    >>      > PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
> >>      > and provide commented, minimal, self-contained, reproducible
>    >code.
>    >>      >
>    >> 
>    >>
>    >
>    >______________________________________________
>    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=Edz5G4Mxqrv8jUU1i-etY2hmLRGE6fTtUsuO1meaE80&e=
>
>    >PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=wT-y_1LicEh73lA1bSAIHIhxzmmQR1otfvU_-ddVnw4&e=
>
>    >and provide commented, minimal, self-contained, reproducible code.
>
>    -- 
>    Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 10 21:08:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 10 Aug 2020 12:08:26 -0700
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
 <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
 <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>
Message-ID: <B9F37CC1-8716-4E41-92AD-72962303978A@dcn.davis.ca.us>

Please take this discussion elsewhere... it is off-topic here. Ivan offered options earlier in this regard.

On August 10, 2020 11:14:22 AM PDT, Raj kapoor <mail2rajkapoor at gmail.com> wrote:
>Hi John,
>
>Only the particular users getting error john. Please help me
>
>
>
>
>On Mon, 10 Aug 2020, 11:43 pm Raj kapoor, <mail2rajkapoor at gmail.com>
>wrote:
>
>> Hi John,
>>
>> I have 10 user in the instance, 9 user is working and access the R
>studio
>> app, but while access the 10th user it's getting stack usage limit
>issues,
>> then we create the new users its working fine.
>>
>> On Mon, 10 Aug 2020, 10:21 pm John Harrold,
><john.m.harrold at gmail.com>
>> wrote:
>>
>>> Hello Raj,
>>>
>>> I've gotten this type of error in the past when I've done things
>like use
>>> while loops that didn't end. Basically, I think this means you're
>running
>>> out of memory. If you want more users, possibly increase the amount
>of ram
>>> in your machine.
>>>
>>> John
>>>
>>> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor
><mail2rajkapoor at gmail.com>
>>> wrote:
>>>
>>>> Hi Team,
>>>>
>>>> I have one production instance in aws, in CentoOs linux
>environment, i
>>>> have
>>>> 5 user to access the instance for using RStudio, In case R-studio
>>>> working 4
>>>> users running good, while we access 5th users its getting error,
>>>>
>>>> First issue : C stack usage 7970372 is too close to the limit
>>>>
>>>> Second Issue :  no stack overflow
>>>>
>>>> Please provide the solution.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> John
>>> :wq
>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From roy@mende|@@ohn @end|ng |rom no@@@gov  Mon Aug 10 22:08:30 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 10 Aug 2020 13:08:30 -0700
Subject: [R] optim with upper and lower bounds
Message-ID: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>

I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.

Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.

Thanks,

-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From pd@|gd @end|ng |rom gm@||@com  Tue Aug 11 09:48:46 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 11 Aug 2020 09:48:46 +0200
Subject: [R] optim with upper and lower bounds
In-Reply-To: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
References: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
Message-ID: <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>

This stuff is of course dependent on exactly which optimization problem you have, but optimx::optimr is often a very good drop-in replacement for optim, especially when bounds are involved (e.g., optim has an awkward habit of attempting evaluations outside the domain when numerical derivatives are needed).

You might want to look at the last examples in ?stats4::mle (in R 4.x.x)

-pd

> On 10 Aug 2020, at 22:08 , Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
> 
> I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.
> 
> Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.
> 
> Thanks,
> 
> -Roy
> 
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From |knecht @end|ng |rom |redhutch@org  Mon Aug 10 19:37:57 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Mon, 10 Aug 2020 17:37:57 +0000
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
 <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>
Message-ID: <C81804B4-27CC-4898-9A37-72031495BFBA@fredhutch.org>

I am an expert user for Docker. Unfortunately this is not a use case that will work with Docker.

The goal is to provide a self-contained artifact as a solution so that no effort needs to be put into the environment configuration.

If Docker was used, the users would need to download docker and figure out how to run the docker image I build.

That is a solution, but it does not fit the deliverable requirements I'm shooting for.

Logan

?2020/08/07 ??4:37 ??"Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> ????????:

    While I have not attempted to apply this to Shiny apps on the desktop, layered container technology (e.g. Docker) is being rolled out for desktop app distribution on Linux (snap, flatpak) and Windows (Open Packaging Conventions), with which complex filesystem structures can be managed in isolated runtime environments. The hardest part is working out how the container will interact with the world... which I don't know the details of but it is clearly in the realm of "feasible".

    On August 7, 2020 2:23:48 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
    >I don't think it's feasible to do what you want.  At a very basic
    >level, 
    >R assumes it has files distributed across a file system (mostly below 
    >the R.home() directory).  Faking that in a single standalone executable
    >
    >may be possible but wouldn't be easy.
    >
    >If running a server isn't possible, then I'd suggest you work on 
    >automating a regular R installation, and put the things you want to run
    >
    >into scripts that make use of it.  Two steps instead of one.
    >
    >Duncan Murdoch
    >
    >
    >
    >On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
    >> Unfortunately, that is not a solution due to the constraints of file
    >sizes associated with the run time operations as well as specific
    >execution workflows.
    >> 
    >> I need to make this a packaged distributable and the only blocker for
    >it at the moment is not being able to successfully bundle R as a
    >standalone binary.
    >> 
    >> Warm Regards,
    >> 
    >> Logan Knecht
    >> 
    >> 2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com>
    >????????:
    >> 
    >>      Wouldn't it be easier to set up a Shiny host system, and just
    >give your
    >>      collaborators a URL to the Shiny app running there?
    >> 
    >>      Duncan Murdoch
    >> 
    >> 
    >>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
    >>      > Hello all,
    >>      >
    >>      > ===== The short version =====
    >>      >
    >>      > I am trying to build a standalone version for R so that I can
    >bundle and package a self-hosted environment for a shiny app. There are
    >reasons for this decision, but it will only distract from the
    >discussion.
    >>      >
    >>      > The inspiration for this comes from here:
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
    >>      > and here
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
    >>      >
    >>      > I have tried these solutions, to no avail as I repeatedly
    >encounter issues with the process. Some issues have been difficulties
    >importing libraries after repeating their steps, others have been
    >issues with missing dynamic libraries that aren't available when I
    >build from source.
    >>      >
    >>      > ===== Questions =====
    >>      >
    >>      > -   How is the R binary at this link created?
    >>      >      -   Link:
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
    >>      > -   How do I include `libgfortran.5.dylib`
    >>      >      -   This distributable, when configured shows a file
    >called `libgfortran.5.dylib`
    >>      >      -   As of this writing, my solution fails because this is
    >missing when I run the self-hosted R
    >>      > -   Is there any guidance on how to build a self-hosted R
    >executable for each operating system?
    >>      >      -   OSX
    >>      >      -   Linux
    >>      >      -   Windows
    >>      >
    >>      > ===== The long version =====
    >>      >
    >>      > ----- The Goal -----
    >>      >
    >>      > Create a self hosted version of R that runs independent of
    >each system so that I can package and build shiny apps to be
    >distributed to collaborators in order to evangelize our new statistical
    >method.
    >>      >
    >>      > ----- The Impetus -----
    >>      >
    >>      > It is too distracting and too much work to get our
    >collaborators to configure their environments just to try our statiscal
    >methods we have been creating.
    >>      >
    >>      > We have a shiny app built around the statistical methods to
    >simplify the interface for interaction. Now we want to package it for
    >easy consumption.
    >>      >
    >>      > It should be as simple as downloading an application and
    >running it.
    >>      >
    >>      > ----- The Current Progress -----
    >>      >
    >>      > I have a repo here that is an electron application
    >>      >
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
    >>      >
    >>      > I can bundle these resources without issues
    >>      >
    >>      > -   Java
    >>      > -   Nextflow
    >>      > -   Our Shiny App
    >>      >
    >>      > ----- Process -----
    >>      > The only missing piece is `R`
    >>      >
    >>      > I have a set of environment variables here:
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
    >>      >
    >>      > I `source` the env variables and then I run this script here:
    >>      >
    >`https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e=
    >`
    >>      >
    >>      > I then use the downloaded `R` to install dependencies with
    >these scripts:
    >>      >
    >>      > -  
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
    >>      > -  
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
    >>      > -  
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
    >>      >
    >>      > And then voil?! It works. Well. It works on my local machine.
    >I can run the development build, I can package the build, I can run the
    >release after installing it. Everything works.
    >>      >
    >>      > Except when I bring it over to a separate computer it doesn't
    >work because it states that it can't find `libgfortran.5.dylib`. See
    >the attached screen shot.
    >>      >
    >>      > ===== The Plea For Guidance =====
    >>      >
    >>      > I would love any help to figure out how to achieve this. We
    >are very close to somethng tangibly interesting and it's very deflating
    >to be blocked because `R` does not have a distributable that can be
    >bundled.
    >>      >
    >>      > Any guidance or suggestions are greatly appreciated!
    >>      >
    >>      > Warm Regards,
    >>      >
    >>      > Logan Knecht
    >>      >
    >>      > 	[[alternative HTML version deleted]]
    >>      >
    >>      > ______________________________________________
    >>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
    >see
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
    >>      > PLEASE do read the posting guide
    >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
    >>      > and provide commented, minimal, self-contained, reproducible
    >code.
    >>      >
    >> 
    >>
    >
    >______________________________________________
    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=Edz5G4Mxqrv8jUU1i-etY2hmLRGE6fTtUsuO1meaE80&e= 
    >PLEASE do read the posting guide
    >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=wT-y_1LicEh73lA1bSAIHIhxzmmQR1otfvU_-ddVnw4&e= 
    >and provide commented, minimal, self-contained, reproducible code.

    -- 
    Sent from my phone. Please excuse my brevity.


From @zwj|08 @end|ng |rom gm@||@com  Tue Aug 11 10:59:05 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jeff King)
Date: Tue, 11 Aug 2020 16:59:05 +0800
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <B9F37CC1-8716-4E41-92AD-72962303978A@dcn.davis.ca.us>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
 <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
 <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>
 <B9F37CC1-8716-4E41-92AD-72962303978A@dcn.davis.ca.us>
Message-ID: <CAGiFhPO4EiSp6+NtEg5bY0=CvzRdCMLAeb-ku_h=xbHEcjZgAg@mail.gmail.com>

Hello Raj,

Please include a reproducible example. If you only give a generic error
message, the best solution we can offer is to reboot your server and try it
again.

Anyway, from the information you gave, it seems like you should ask this
question in the Rstudio community(I assume you are running their production
on the server). This is R's community, you are welcome to ask but it is
less likely that you can get an expert to answer this type of question.

Best,
Jiefei

On Tue, Aug 11, 2020 at 3:08 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please take this discussion elsewhere... it is off-topic here. Ivan
> offered options earlier in this regard.
>
> On August 10, 2020 11:14:22 AM PDT, Raj kapoor <mail2rajkapoor at gmail.com>
> wrote:
> >Hi John,
> >
> >Only the particular users getting error john. Please help me
> >
> >
> >
> >
> >On Mon, 10 Aug 2020, 11:43 pm Raj kapoor, <mail2rajkapoor at gmail.com>
> >wrote:
> >
> >> Hi John,
> >>
> >> I have 10 user in the instance, 9 user is working and access the R
> >studio
> >> app, but while access the 10th user it's getting stack usage limit
> >issues,
> >> then we create the new users its working fine.
> >>
> >> On Mon, 10 Aug 2020, 10:21 pm John Harrold,
> ><john.m.harrold at gmail.com>
> >> wrote:
> >>
> >>> Hello Raj,
> >>>
> >>> I've gotten this type of error in the past when I've done things
> >like use
> >>> while loops that didn't end. Basically, I think this means you're
> >running
> >>> out of memory. If you want more users, possibly increase the amount
> >of ram
> >>> in your machine.
> >>>
> >>> John
> >>>
> >>> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor
> ><mail2rajkapoor at gmail.com>
> >>> wrote:
> >>>
> >>>> Hi Team,
> >>>>
> >>>> I have one production instance in aws, in CentoOs linux
> >environment, i
> >>>> have
> >>>> 5 user to access the instance for using RStudio, In case R-studio
> >>>> working 4
> >>>> users running good, while we access 5th users its getting error,
> >>>>
> >>>> First issue : C stack usage 7970372 is too close to the limit
> >>>>
> >>>> Second Issue :  no stack overflow
> >>>>
> >>>> Please provide the solution.
> >>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>> --
> >>> John
> >>> :wq
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d||eepkunj@@| @end|ng |rom gm@||@com  Tue Aug 11 14:21:20 2020
From: d||eepkunj@@| @end|ng |rom gm@||@com (Dileepkumar R)
Date: Tue, 11 Aug 2020 17:51:20 +0530
Subject: [R] Trend value from smoothing spline trend fit
Message-ID: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>

Dear All,

I am trying to estimate the non -linear trend value from smooth spline
trend fit (using the generalized additive model (GAM)).

I want to estimate the trend value from a temperature dataset (spatial
averaged annual meantime from 1906 to 2005) as given in the Box 2.2, Table
1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
Report 5 chapter 2
<https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf>,
page number 21-22 )

I do not understand how they estimate the single value trend with 95%
confidence interval from a time-series data as given in the Box 2.2, Figure
1.  Is there any easy way to extract the trend value using mgcv library of
R.?

Google Doc Link:
https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing

Thank you all in advance

Dileepkumar R

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Tue Aug 11 15:24:37 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 11 Aug 2020 09:24:37 -0400
Subject: [R] optim with upper and lower bounds
In-Reply-To: <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>
References: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
 <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>
Message-ID: <b63018f6-54de-afe6-73da-e4e3a96fcc25@gmail.com>

Thanks to Peter for noting that the numerical derivative part of code doesn't check bounds in optim().
I tried to put some checks into Rvmmin and Rcgmin in optimx package (they were separate packages before, and
still on CRAN), but I'm far from capturing all the places where numerical derivative steps can go outside bounds.

And if you have a "production" problem where you are going to run a given optimization over a lot of cases, I'd
strongly suggest that you write your own derivative code, even if it is a numerical approximation. In the case of
a specialized derivative code e.g., part analytic, part numeric, with bounds checking, I'll be willing
to kibbitz, but suggest off-list until something is working, in which case it is probably at least worth
a vignette, as this sort of situation seems to pop up at least once a year and a good example would really
be helpful to guide the process. I'm reluctant to prepare an artificial example because, well, it will be
artificial and not capture the sort of details that have to be addressed.

Best, JN


On 2020-08-11 3:48 a.m., peter dalgaard wrote:
> This stuff is of course dependent on exactly which optimization problem you have, but optimx::optimr is often a very good drop-in replacement for optim, especially when bounds are involved (e.g., optim has an awkward habit of attempting evaluations outside the domain when numerical derivatives are needed).
> 
> You might want to look at the last examples in ?stats4::mle (in R 4.x.x)
> 
> -pd
> 
>> On 10 Aug 2020, at 22:08 , Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
>>
>> I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.
>>
>> Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.
>>
>> Thanks,
>>
>> -Roy
>>
>>
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected" 
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From roy@mende|@@ohn @end|ng |rom no@@@gov  Tue Aug 11 16:06:44 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 11 Aug 2020 07:06:44 -0700
Subject: [R] optim with upper and lower bounds
In-Reply-To: <b63018f6-54de-afe6-73da-e4e3a96fcc25@gmail.com>
References: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
 <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>
 <b63018f6-54de-afe6-73da-e4e3a96fcc25@gmail.com>
Message-ID: <4136B92F-AB3F-4560-88C0-900389A4CB73@noaa.gov>

Thanks to all who responded.  Will take me some time to digest it all.

-Roy


> On Aug 11, 2020, at 6:24 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> Thanks to Peter for noting that the numerical derivative part of code doesn't check bounds in optim().
> I tried to put some checks into Rvmmin and Rcgmin in optimx package (they were separate packages before, and
> still on CRAN), but I'm far from capturing all the places where numerical derivative steps can go outside bounds.
> 
> And if you have a "production" problem where you are going to run a given optimization over a lot of cases, I'd
> strongly suggest that you write your own derivative code, even if it is a numerical approximation. In the case of
> a specialized derivative code e.g., part analytic, part numeric, with bounds checking, I'll be willing
> to kibbitz, but suggest off-list until something is working, in which case it is probably at least worth
> a vignette, as this sort of situation seems to pop up at least once a year and a good example would really
> be helpful to guide the process. I'm reluctant to prepare an artificial example because, well, it will be
> artificial and not capture the sort of details that have to be addressed.
> 
> Best, JN
> 
> 
> On 2020-08-11 3:48 a.m., peter dalgaard wrote:
>> This stuff is of course dependent on exactly which optimization problem you have, but optimx::optimr is often a very good drop-in replacement for optim, especially when bounds are involved (e.g., optim has an awkward habit of attempting evaluations outside the domain when numerical derivatives are needed).
>> 
>> You might want to look at the last examples in ?stats4::mle (in R 4.x.x)
>> 
>> -pd
>> 
>>> On 10 Aug 2020, at 22:08 , Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
>>> 
>>> I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.
>>> 
>>> Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.
>>> 
>>> Thanks,
>>> 
>>> -Roy
>>> 
>>> 
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new street address***
>>> 110 McAllister Way
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>>> 
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected" 
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 11 16:31:46 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Aug 2020 07:31:46 -0700
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
Message-ID: <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>

Caveat: Did not look at any of your links.

However, the usual answer for this sort of question is ?predict.gam  (in
general, predict.whatevermethod)
Have you consulted the man page? If this is not what you want, you may need
to explain more carefully.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 11, 2020 at 5:21 AM Dileepkumar R <dileepkunjaai at gmail.com>
wrote:

> Dear All,
>
> I am trying to estimate the non -linear trend value from smooth spline
> trend fit (using the generalized additive model (GAM)).
>
> I want to estimate the trend value from a temperature dataset (spatial
> averaged annual meantime from 1906 to 2005) as given in the Box 2.2, Table
> 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
> Report 5 chapter 2
> <
> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
> >,
> page number 21-22 )
>
> I do not understand how they estimate the single value trend with 95%
> confidence interval from a time-series data as given in the Box 2.2, Figure
> 1.  Is there any easy way to extract the trend value using mgcv library of
> R.?
>
> Google Doc Link:
>
> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
>
> Thank you all in advance
>
> Dileepkumar R
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v|kr@m@byreddy @end|ng |rom gm@||@com  Mon Aug 10 18:44:05 2020
From: v|kr@m@byreddy @end|ng |rom gm@||@com (Vikram Reddy)
Date: Mon, 10 Aug 2020 10:44:05 -0600
Subject: [R] =?utf-8?q?How_to_auto_generate_=E2=80=9Canchor_links_?=
	=?utf-8?q?=E2=80=9C_and_directory_path_to_text_search_function?=
In-Reply-To: <6049da82b00843319ddd14ae7f74c606@utah.edu>
References: <6049da82b00843319ddd14ae7f74c606@utah.edu>
Message-ID: <CAH+2LYoq=q4xC0fgE7ZLsy=9PnDYGnmyQvVTiKDTZeS7ZWvR2Q@mail.gmail.com>

I have a tokenized txt document with 'div' tags and 'id' to it :




    library(quanteda)


    library(htmltools)


    library(tidyverse)




    text <- <div id="4">But how do you do?</div>


            <div id="5">I see I have frightened you?sit... ?</div>


            <div id="6">It was in July, 1805, and the speaker..</div>


            <div id="7">With these words she greeted Prince Vas?li
Kur?gin...</div>


            <div id="8">Anna P?vlovna had had a cough for some days...</div>


            <div id="9">She was, as she said, suffering from la
grippe....</div>


            <div id="10">Petersburg, used only by the elite.</div>


            <div id="11">All her invitations without exception, written in
French...</div>


            <div id="12">?If you have nothing better to do, Count (or
Prince).. </div>


            <div id="13">?Heavens!</div>


            <div id="14">what a virulent attack!?</div>





             ''''


            <div id="2107">It was plain that this ?well??</div>







I need to auto generate this output to finish it up



    <a href="C:\Users\John\Desktop\final_tokens.html#div number"> text-
sentence </a>



Ex- When I search for the word 'good'





    <a href="C:\Users\John\Desktop\final_tokens.html#49"> Our good and
wonderful sovereign has to </a>


    <a href="C:\Users\John\Desktop\final_tokens.html#73">He is one of the
the good ones.</a>


    <a href="C:\Users\John\Desktop\final_tokens.html#138">She is rich and
of good family..</a>



the div id number should go beside # as show above.



Previously i used



    make_sentences <- function(word) {


                      grep(word,text,value= TRUE)}



above grep  worked fine with plain text before but with lot of regex I need
to modify it ,to get the anchor links directory path and div number to. is
there any solution to this maybe ?

	[[alternative HTML version deleted]]


From d||eepkunj@@| @end|ng |rom gm@||@com  Tue Aug 11 19:41:15 2020
From: d||eepkunj@@| @end|ng |rom gm@||@com (Dileepkumar R)
Date: Tue, 11 Aug 2020 23:11:15 +0530
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
 <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>
Message-ID: <CALTF6snGv9uAz_H+fYGcrsvVdisB8VC4ew6_73xmaozvac19zQ@mail.gmail.com>

Thank you for your reply.

Yes, we can get the curve fit values on the line (as the length of input
data frame) from predict.gam() function.  But I wish to get the trend value
(in Trends in ?C per decade or ?C per year) as given in the Box 2.2, Table
1.  But I couldn't find any option in GAM method.

Actually on of the reviewer of my paper suggested me to estimate the
non-linear trend as given in this Box 2.2, Table 1 and Figure 1.



Dileepkumar R



On Tue, Aug 11, 2020 at 8:01 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Caveat: Did not look at any of your links.
>
> However, the usual answer for this sort of question is ?predict.gam  (in
> general, predict.whatevermethod)
> Have you consulted the man page? If this is not what you want, you may
> need to explain more carefully.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Aug 11, 2020 at 5:21 AM Dileepkumar R <dileepkunjaai at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I am trying to estimate the non -linear trend value from smooth spline
>> trend fit (using the generalized additive model (GAM)).
>>
>> I want to estimate the trend value from a temperature dataset (spatial
>> averaged annual meantime from 1906 to 2005) as given in the Box 2.2, Table
>> 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
>> Report 5 chapter 2
>> <
>> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
>> >,
>> page number 21-22 )
>>
>> I do not understand how they estimate the single value trend with 95%
>> confidence interval from a time-series data as given in the Box 2.2,
>> Figure
>> 1.  Is there any easy way to extract the trend value using mgcv library of
>> R.?
>>
>> Google Doc Link:
>>
>> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
>>
>> Thank you all in advance
>>
>> Dileepkumar R
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 11 19:47:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Aug 2020 10:47:10 -0700
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <CALTF6snGv9uAz_H+fYGcrsvVdisB8VC4ew6_73xmaozvac19zQ@mail.gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
 <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>
 <CALTF6snGv9uAz_H+fYGcrsvVdisB8VC4ew6_73xmaozvac19zQ@mail.gmail.com>
Message-ID: <CAGxFJbQ4CXpfhGaWMpZ=kOdr5Q9Xd1wNWh54YoXsW0Xyfi2Rmg@mail.gmail.com>

??

Change per year = (estimated end value - estimated begin value)/## years

Am I missing something subtle here?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 11, 2020 at 10:41 AM Dileepkumar R <dileepkunjaai at gmail.com>
wrote:

> Thank you for your reply.
>
> Yes, we can get the curve fit values on the line (as the length of input
> data frame) from predict.gam() function.  But I wish to get the trend value
> (in Trends in ?C per decade or ?C per year) as given in the Box 2.2, Table
> 1.  But I couldn't find any option in GAM method.
>
> Actually on of the reviewer of my paper suggested me to estimate the
> non-linear trend as given in this Box 2.2, Table 1 and Figure 1.
>
>
>
> Dileepkumar R
>
>
>
> On Tue, Aug 11, 2020 at 8:01 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Caveat: Did not look at any of your links.
>>
>> However, the usual answer for this sort of question is ?predict.gam  (in
>> general, predict.whatevermethod)
>> Have you consulted the man page? If this is not what you want, you may
>> need to explain more carefully.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Aug 11, 2020 at 5:21 AM Dileepkumar R <dileepkunjaai at gmail.com>
>> wrote:
>>
>>> Dear All,
>>>
>>> I am trying to estimate the non -linear trend value from smooth spline
>>> trend fit (using the generalized additive model (GAM)).
>>>
>>> I want to estimate the trend value from a temperature dataset (spatial
>>> averaged annual meantime from 1906 to 2005) as given in the Box 2.2,
>>> Table
>>> 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
>>> Report 5 chapter 2
>>> <
>>> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
>>> >,
>>> page number 21-22 )
>>>
>>> I do not understand how they estimate the single value trend with 95%
>>> confidence interval from a time-series data as given in the Box 2.2,
>>> Figure
>>> 1.  Is there any easy way to extract the trend value using mgcv library
>>> of
>>> R.?
>>>
>>> Google Doc Link:
>>>
>>> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
>>>
>>> Thank you all in advance
>>>
>>> Dileepkumar R
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From v|vek@utr@ @end|ng |rom gm@||@com  Tue Aug 11 19:50:34 2020
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Tue, 11 Aug 2020 19:50:34 +0200
Subject: [R] Interactive paint corrections on a raster image
Message-ID: <CAHLp6SCddgTsBhVnzaWF-aWm8wYxACPotW6vQnavRaDivUkuzA@mail.gmail.com>

Hi,

I have tried to develop a simple method of correcting some artefacts in an
image with R. Before proceeding further with image analysis.

An example of my attempt:

library(imager)

im <- load.example('coins')

imr <- as.raster(im)

plot(imr)

sel <- locator(n=1)

sel

x1 <- floor(sel$x)

x2 <- x1+10

y1 <- floor(sel$y)

y2 <- y1+10

imr[y1:y2,x1:x2] <- "#FFFFFF"

# I want this correction to be immediately visible without the need for
replotting

imr2 <- imr

plot(imr2)


This works. But I want to improve it to be more flexible inmaking
interactive corrections.
The improvements that I am thinking of are:

1.       Instead of a rectangular area, I want a circular one. And I want
the painting to be visible directly without the need for replotting. I
would like to be able to enlarge slowly the area where I need to do the
corrections (with multiple small corrections to cover an irregular area).
This may require other techniques. For example, with shiny. I know almost
nothing about it. Would appreciate some tips to get started.

2. I am having trouble with specification of colour in the hexadecimal
mode. How can I convert a grayscale image to a numerical mode? I would like
to be able to have corrections made with the intensity in a certain range.
How do I access the colour values at specific locations? I did not succeed
with the getValues function (in a different image).

> getValues(imi3,nrows=seq(917,1017,1),ncols=seq(1119,1219,1))

Error in (function (classes, fdef, mtable)  :

  unable to find an inherited method for function ?getValues? for signature
?"raster", "missing", "numeric"?

I would like to know my mistake here .

I will appreciate all help that I can get.

Thanking you,

Vivek

	[[alternative HTML version deleted]]


From 538280 @end|ng |rom gm@||@com  Tue Aug 11 21:14:04 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 11 Aug 2020 13:14:04 -0600
Subject: [R] Add a logo on a plot
In-Reply-To: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
References: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
Message-ID: <CAFEqCdw4G=Fg49D6rX19ZVz0m6MvKieyGanVSaxyXY8-H3X2Pw@mail.gmail.com>

One option is to use the my.symbols and ms.image functions from the
TeachingDemos package.  There is an example under ?ms.image.


On Mon, Aug 10, 2020 at 7:43 AM Pedro p?ramo <percentil101 at gmail.com> wrote:
>
> Hi,
>
> There is a way to add a photo like a free text but images on a plot, (hist,
> chart trough ggplot) to add a logo or any PNG .
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From 538280 @end|ng |rom gm@||@com  Tue Aug 11 21:23:21 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 11 Aug 2020 13:23:21 -0600
Subject: [R] Question about PERL lookahead construct in regex's
In-Reply-To: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
References: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
Message-ID: <CAFEqCdyRN95w7GraKusBPdR+fqqqwg4oYvBJtvWN==FR4xcS6g@mail.gmail.com>

I think that the current documentation is correct, but that does not
mean that it cannot be improved.

The key phrase for me is "from the current position"  which says to me
that the match needs to happen right there, not just somewhere in the
rest of the string.

If you used the expression " +t" then you would expect it to only
match if the t was immediately after the last space, not somewhere in
the string after the last space, it is the same with the look-ahead.

On Mon, Aug 10, 2020 at 10:37 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Folks:
>
> Consider:
> > y <- "xx wt"
>
> > grep(" +(?=t)",y, perl = TRUE)
> integer(0)
> ## Unexpected. Lookahead construct does not find "t" after space
> ## But
> > grep(" +(?=.+t)",y, perl = TRUE)
> [1] 1
> ## Expected. Given pattern for **exact** match, lookahead finds it
>
> My concern is:
> ?regexp says this:
> "Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
>  *assertions*: they match if an attempt to match the ... forward from the
> current position would succeed (or not), but use up no characters in the
> string being processed."
>
> But this appears to be imprecise (it confused me, anyway). The usual sense
> of "matching" in regex's is "match the pattern somewhere in the string
> going forward." But in the perl lookahead construct it apparently must
> **exactly** match *everything* in the string that follows.
>
> Questions:
> Am I correct about this? If not, what do I misunderstand?
> If I am correct, should the regex help be slightly modified to something
> like:
>
> "Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
>  *assertions*: they match if an attempt to **exactly" match all of ... forward
> from the current position would succeed (or not), but use up no characters
> in the string being processed."
>
> Thanks.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From r@m|ro @end|ng |rom prec|@|onb|o@@@@y@com  Tue Aug 11 21:35:49 2020
From: r@m|ro @end|ng |rom prec|@|onb|o@@@@y@com (Ramiro Barrantes)
Date: Tue, 11 Aug 2020 19:35:49 +0000
Subject: [R] Huge speed performance difference when using non-trivial fixed
 effects in NLMER vs NLME
Message-ID: <50350c703cfe44a7b328dba48601f99c@precisionbioassay.com>

Following Ben Bolker's methodology (described here https://rpubs.com/bbolker/3423) I incorporated non-trivial fixed effects in NLMER for a four-parameter logistic.   I placed a reproducible example here: https://rpubs.com/ramirob/648103


To summarize the question, if we have a dataset with individuals in groups where we have group-specific fixed effects, NLME's performance remains the same:

## [1] "NLME Time Required for data2Groups: 0.0458040237426758"

fit3Groups <- fitNLME(data3Groups,initialValues3Groups)

## [1] "NLME Time Required for data3Groups: 0.0375699996948242"

fit4Groups <- fitNLME(data4Groups,initialValues4Groups)

## [1] "NLME Time Required for data4Groups: 0.0526559352874756"

fit5Groups <- fitNLME(data5Groups,initialValues5Groups)

## [1] "NLME Time Required for data5Groups: 0.0502560138702393"


But when we do the analogous thing in NLMER, the performance increases with increasing number of groups:


## [1] "Time required for the data2Groups: 0.404773950576782"

fitNlmer3Groups <- fitNlmer(data3Groups, initialValues3Groups)

## [1] "Time required for the data3Groups: 0.579570055007935"

fitNlmer4Groups <- fitNlmer(data4Groups, initialValues4Groups)

## [1] "Time required for the data4Groups: 0.957509994506836"

fitNlmer5Groups <- fitNlmer(data5Groups, initialValues5Groups)

## [1] "Time required for the data5Groups: 1.68412184715271"


In addition, NLMER is much slower in general.  This is just a short example, but for more complicated cases the differences in performance are huge (minutes vs seconds).


Is NLMER "worth the wait" (e.g. less fragile, better convergence, etc) when trying to do non-trivial fixed effects? Is there a better methodology than the one described by Ben Bolker back in 2013?


Any insight appreciated.  Again, you can see a reproducible example here https://rpubs.com/ramirob/648103

Thank you!




	[[alternative HTML version deleted]]


From d||eepkunj@@| @end|ng |rom gm@||@com  Tue Aug 11 22:49:29 2020
From: d||eepkunj@@| @end|ng |rom gm@||@com (Dileepkumar R)
Date: Wed, 12 Aug 2020 02:19:29 +0530
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <823E171D-0931-4A12-8B60-9943CD32DF1C@gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
 <823E171D-0931-4A12-8B60-9943CD32DF1C@gmail.com>
Message-ID: <CALTF6smZwUYu8TgjEcERsJycucqBSuVg1ONnugSFG_JzhL4bLg@mail.gmail.com>

Dear Bert Gunter and Mathew Guilfoyle,

Thanks for the reply.

I also agree with you. But that is the actual slope of the straight line
connecting from the first estimated value to last estimated value ( like
dy/dx slope). I tried in that way also, but I couldn't replicate the
results as given in that  Box 2.2, Table 1 and Figure 1.  I can replicate
the line plot as in Box 2.2,  Figure 1 (a) (to verify my input data is the
same as in Figure 1 (a)).

You can see my plot here:
https://drive.google.com/file/d/14WDFFW5J69WvxnhbfdcOZKvGRk6HUWVn/view?usp=sharing


I have attached my code and data (as NetCDF file) along with this mail.

input Data (only 32Kb) :
https://drive.google.com/file/d/1Wt5sjVhWmjhRWOfdc6elUzwOvifRk-OI/view?usp=sharing

code:
https://drive.google.com/file/d/1r5mg1vcNmDCIf19jnMUAFEiLNOLKQiKq/view?usp=sharing

output figure:
https://drive.google.com/file/d/1bEXWCB-H5doVKXO8i_FLO7KZMW3qc9Cw/view?usp=sharing

Sincerely,

Dileepkumar R



On Tue, Aug 11, 2020 at 11:41 PM Mathew Guilfoyle <mrguilfoyle at gmail.com>
wrote:

> Looking at the report (specifically the legend for the table) I think all
> they have done is take the difference between fitted temperatures (given by
> linear regression or the GAM) at the start and end of each period (e.g. in
> 1901 and 2012), and then calculate the average change per year.
>
> In a way it ?linearises? the spline trend but I don?t think it?s really
> valid.  It just highlights how poorly a (simple) linear regression can fit
> a very non-linear trend.
>
> > On 11 Aug 2020, at 13:21, Dileepkumar R <dileepkunjaai at gmail.com> wrote:
> >
> > ?Dear All,
> >
> > I am trying to estimate the non -linear trend value from smooth spline
> > trend fit (using the generalized additive model (GAM)).
> >
> > I want to estimate the trend value from a temperature dataset (spatial
> > averaged annual meantime from 1906 to 2005) as given in the Box 2.2,
> Table
> > 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
> > Report 5 chapter 2
> > <
> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
> >,
> > page number 21-22 )
> >
> > I do not understand how they estimate the single value trend with 95%
> > confidence interval from a time-series data as given in the Box 2.2,
> Figure
> > 1.  Is there any easy way to extract the trend value using mgcv library
> of
> > R.?
> >
> > Google Doc Link:
> >
> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
> >
> > Thank you all in advance
> >
> > Dileepkumar R
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 12 01:42:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Aug 2020 16:42:21 -0700
Subject: [R] 
 Huge speed performance difference when using non-trivial fixed
 effects in NLMER vs NLME
In-Reply-To: <50350c703cfe44a7b328dba48601f99c@precisionbioassay.com>
References: <50350c703cfe44a7b328dba48601f99c@precisionbioassay.com>
Message-ID: <CAGxFJbQTex-9ibWOkXeGKBWObdZrNRSS6QgywA1+mKmQCvVhnA@mail.gmail.com>

This should be posted on the r-sig-mixed-models list rather than here. The
interest and expertise you seek is more likely to be found there.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 11, 2020 at 12:39 PM Ramiro Barrantes <
ramiro at precisionbioassay.com> wrote:

> Following Ben Bolker's methodology (described here
> https://rpubs.com/bbolker/3423) I incorporated non-trivial fixed effects
> in NLMER for a four-parameter logistic.   I placed a reproducible example
> here: https://rpubs.com/ramirob/648103
>
>
> To summarize the question, if we have a dataset with individuals in groups
> where we have group-specific fixed effects, NLME's performance remains the
> same:
>
> ## [1] "NLME Time Required for data2Groups: 0.0458040237426758"
>
> fit3Groups <- fitNLME(data3Groups,initialValues3Groups)
>
> ## [1] "NLME Time Required for data3Groups: 0.0375699996948242"
>
> fit4Groups <- fitNLME(data4Groups,initialValues4Groups)
>
> ## [1] "NLME Time Required for data4Groups: 0.0526559352874756"
>
> fit5Groups <- fitNLME(data5Groups,initialValues5Groups)
>
> ## [1] "NLME Time Required for data5Groups: 0.0502560138702393"
>
>
> But when we do the analogous thing in NLMER, the performance increases
> with increasing number of groups:
>
>
> ## [1] "Time required for the data2Groups: 0.404773950576782"
>
> fitNlmer3Groups <- fitNlmer(data3Groups, initialValues3Groups)
>
> ## [1] "Time required for the data3Groups: 0.579570055007935"
>
> fitNlmer4Groups <- fitNlmer(data4Groups, initialValues4Groups)
>
> ## [1] "Time required for the data4Groups: 0.957509994506836"
>
> fitNlmer5Groups <- fitNlmer(data5Groups, initialValues5Groups)
>
> ## [1] "Time required for the data5Groups: 1.68412184715271"
>
>
> In addition, NLMER is much slower in general.  This is just a short
> example, but for more complicated cases the differences in performance are
> huge (minutes vs seconds).
>
>
> Is NLMER "worth the wait" (e.g. less fragile, better convergence, etc)
> when trying to do non-trivial fixed effects? Is there a better methodology
> than the one described by Ben Bolker back in 2013?
>
>
> Any insight appreciated.  Again, you can see a reproducible example here
> https://rpubs.com/ramirob/648103
>
> Thank you!
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From percent||101 @end|ng |rom gm@||@com  Tue Aug 11 17:34:31 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Tue, 11 Aug 2020 17:34:31 +0200
Subject: [R] write csv of a structure
Message-ID: <CAB-TgNvuGG+aHyRFh3hfAVyreg4XrdAQCZM=bwK_cq3xdMMjXw@mail.gmail.com>

Hi all,

I want to "save" export in a csv or plain text format the results of my
calculations

I use cbind and I obtain what I call "resultprob" if I put deput it shows
me this

dput(resultprob)
structure(c(88.6572680743221, 7250.7), .Dim = 1:2)

> str(resultprob)
 num [1, 1:2] 88.7 7250.7

I use

write_csv(resultprob, file = "resultprob.csv", sep=",")

But this error appears:

Error in write_csv(resultprob, file = "resultprob.csv", sep = ",") :
  unused arguments (file = "resultprob.csv", sep = ",")

What will be happening?

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Aug 12 09:58:45 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 12 Aug 2020 10:58:45 +0300
Subject: [R] write csv of a structure
In-Reply-To: <CAB-TgNvuGG+aHyRFh3hfAVyreg4XrdAQCZM=bwK_cq3xdMMjXw@mail.gmail.com>
References: <CAB-TgNvuGG+aHyRFh3hfAVyreg4XrdAQCZM=bwK_cq3xdMMjXw@mail.gmail.com>
Message-ID: <20200812105845.37d50a28@Tarkus>

On Tue, 11 Aug 2020 17:34:31 +0200
Pedro p?ramo <percentil101 at gmail.com> wrote:

> Error in write_csv(resultprob, file = "resultprob.csv", sep = ",") :
>   unused arguments (file = "resultprob.csv", sep = ",")

There is utils::write.csv and there is readr::write_csv. Judging by the
parameters you pass, you seem to want to call the former, not the
latter.

Hint: use help() to find out the correct arguments of a function if R
tells you that there was a mistake.

-- 
Best regards,
Ivan


From p@r|@@@g@njeh @end|ng |rom med@un|-goett|ngen@de  Wed Aug 12 11:11:46 2020
From: p@r|@@@g@njeh @end|ng |rom med@un|-goett|ngen@de (Ganjeh, Parisa)
Date: Wed, 12 Aug 2020 09:11:46 +0000
Subject: [R] Calculating effectsize or standarized coefficents for gls
 models in R
Message-ID: <22E1A8776829374C9D4E04A0C7A18FF046214F6F@umg-exc-4.ads.local.med.uni-goettingen.de>

Hi,

I am new in R and I would appreciate if you guide me how I can estimate effect size or standardized coefficients for a gls model (generalized least square) in R. if I can find the way for estimating standardized coefficients is better, because I used effect size package for other models (glm) in my study and got a standardized coefficients as effect size. Unfortunately this package could not give a standardized coefficients or another effect size estimator for gls model. As far as I have searched I could not find a formula in R for calculating effect size or standardized coefficients for my gls model.
My model :
Model1<-gls(Ehyp1~Sex1+SESc1+Ebmi1+Age1+PA1,weights=varIdent(form =~1|PA1), data =X6_17_years_Wave1, na.action = na.exclude)
PA1 is  independent variable and categorical and has 3 levels.
Sex1+SESc1+Ebmi1+Age1: consider as covariates
Sex1 is nominal and has 2 groups (girl and boy).
It is the result of R for my gls model:
Generalized least squares fit by REML
  Model: Ehyp1 ~ Sex1 + SESc1 + Ebmi1 + Age1 + PA1
  Data: X6_17_years_Wave1
       AIC      BIC    logLik
  27156.95 27224.53 -13568.48

Variance function:
Structure: Different standard deviations per stratum
Formula: ~1 | PA1
Parameter estimates:
        3         1         2
1.0000000 0.9268285 0.9310299

Coefficients:
                Value  Std.Error    t-value p-value
(Intercept)  5.957760 0.19569967  30.443382  0.0000
Sex12       -0.832327 0.05159467 -16.132034  0.0000
SESc1       -0.099512 0.00727373 -13.681054  0.0000
Ebmi1        0.021064 0.00837363   2.515553  0.0119
Age1        -0.134280 0.00983979 -13.646654  0.0000
PA12        -0.192089 0.06553337  -2.931163  0.0034
PA13        -0.137575 0.07748981  -1.775395  0.0759

Correlation:
      (Intr) Sex12  SESc1  Ebmi1  Age1   PA12
Sex12 -0.203
SESc1 -0.572 -0.017
Ebmi1 -0.578  0.053  0.145
Age1  -0.230  0.001 -0.001 -0.504
PA12  -0.267  0.116 -0.089  0.005  0.086
PA13  -0.339  0.138 -0.038  0.028  0.179  0.621

Standardized residuals:
        Min          Q1         Med          Q3         Max
-2.34330971 -0.76897681 -0.07360691  0.62658220  3.13138556

Residual standard error: 2.146151
Degrees of freedom: 6363 total; 6356 residual


	[[alternative HTML version deleted]]


From |re|ey@ @end|ng |rom gm@||@com  Wed Aug 12 13:44:10 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Wed, 12 Aug 2020 13:44:10 +0200
Subject: [R] add trailing dates with rbind
Message-ID: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>

I am having a hell of a time, this must surely be simple to solve?.

Basically I want to add trailing dates to datasets with differing starting dates so that across datasets I have the same starting date.

# make dataset with the same starting date
start_date = as.Date("2020-03-01")
d_start_date = min(agg_d_h$Group.date)

diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days")) 

for(i in 1:diff_in_days) {
  next_date  = start_date+i
  app_d <- rbind(agg_d_h, c(next_date, 0) )
}

gives:
Error in as.Date.numeric(value) : 'origin' must be supplied

Thank you for your time to help me!

Frederik Feys


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 12 14:10:28 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 12 Aug 2020 15:10:28 +0300
Subject: [R] add trailing dates with rbind
In-Reply-To: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
Message-ID: <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>

Hi Frederik,
(short answer) modify the assignment statement to
    agg_d_h <- rbind( agg_d_h, data.frame(Group.date=next_date,x=0) )

    Note: replace x=0 by your-variable-name=0
    Note: left-hand-side of the assignment statement should be agg_d_h

(longer answer) Your approach is far from the best way to do this task, for
a variety of reasons.
If you think that in the future you will be working a lot with daily time
series and need to perform similar tasks, I would strongly recommend
learning the xts data structure in the xts package.
If you have several time series with different date ranges, and all of them
are xts objects, you can merge them with 'joins' (left joins, right joins,
full joins). xts will automatically handle alignment
and preserving dates, etc.

HTH,
Eric




On Wed, Aug 12, 2020 at 2:44 PM Frederik Feys <frefeys at gmail.com> wrote:

> I am having a hell of a time, this must surely be simple to solve?.
>
> Basically I want to add trailing dates to datasets with differing starting
> dates so that across datasets I have the same starting date.
>
> # make dataset with the same starting date
> start_date = as.Date("2020-03-01")
> d_start_date = min(agg_d_h$Group.date)
>
> diff_in_days = as.numeric(difftime(d_start_date, start_date, units =
> "days"))
>
> for(i in 1:diff_in_days) {
>   next_date  = start_date+i
>   app_d <- rbind(agg_d_h, c(next_date, 0) )
> }
>
> gives:
> Error in as.Date.numeric(value) : 'origin' must be supplied
>
> Thank you for your time to help me!
>
> Frederik Feys
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |re|ey@ @end|ng |rom gm@||@com  Wed Aug 12 15:07:53 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Wed, 12 Aug 2020 15:07:53 +0200
Subject: [R] add trailing dates with rbind
In-Reply-To: <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
 <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>
Message-ID: <36E06F41-BDE1-4D71-AD3C-F65AF363C9C7@gmail.com>

Thank you so much Eric! Wonderful to have an R community helping out so quickly! 

> Op 12 aug. 2020, om 14:10 heeft Eric Berger <ericjberger at gmail.com> het volgende geschreven:
> 
> Hi Frederik,
> (short answer) modify the assignment statement to
>     agg_d_h <- rbind( agg_d_h, data.frame(Group.date=next_date,x=0) )
> 
>     Note: replace x=0 by your-variable-name=0
>     Note: left-hand-side of the assignment statement should be agg_d_h
> 
> (longer answer) Your approach is far from the best way to do this task, for a variety of reasons.
> If you think that in the future you will be working a lot with daily time series and need to perform similar tasks, I would strongly recommend learning the xts data structure in the xts package.
> If you have several time series with different date ranges, and all of them are xts objects, you can merge them with 'joins' (left joins, right joins, full joins). xts will automatically handle alignment
> and preserving dates, etc. 
> 
> HTH,
> Eric
> 
> 
>   
> 
> On Wed, Aug 12, 2020 at 2:44 PM Frederik Feys <frefeys at gmail.com <mailto:frefeys at gmail.com>> wrote:
> I am having a hell of a time, this must surely be simple to solve?.
> 
> Basically I want to add trailing dates to datasets with differing starting dates so that across datasets I have the same starting date.
> 
> # make dataset with the same starting date
> start_date = as.Date("2020-03-01")
> d_start_date = min(agg_d_h$Group.date)
> 
> diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days")) 
> 
> for(i in 1:diff_in_days) {
>   next_date  = start_date+i
>   app_d <- rbind(agg_d_h, c(next_date, 0) )
> }
> 
> gives:
> Error in as.Date.numeric(value) : 'origin' must be supplied
> 
> Thank you for your time to help me!
> 
> Frederik Feys
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @te|@nML @end|ng |rom co||oc@t|on@@de  Wed Aug 12 15:35:20 2020
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stefan Evert)
Date: Wed, 12 Aug 2020 15:35:20 +0200
Subject: [R] Question about PERL lookahead construct in regex's
In-Reply-To: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
References: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
Message-ID: <D8791839-84CA-4846-A96B-9FCBDD538EC5@collocations.de>


> On 10 Aug 2020, at 18:36, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> But this appears to be imprecise (it confused me, anyway). The usual sense
> of "matching" in regex's is "match the pattern somewhere in the string
> going forward." But in the perl lookahead construct it apparently must
> **exactly** match *everything* in the string that follows.
> 
> Questions:
> Am I correct about this? If not, what do I misunderstand?

I think you're confused about the terminology.  To _match_ a regular expression is to find a substring described by the regexp at a given starting point; what you have in mind is to _search_ a string for matches of a regular expression.

Python uses this terminology in its regexp matching functions, and from what you cited in the documentation so do Perl and PCRE in their docs.

Best,
Stefan

From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Wed Aug 12 15:42:09 2020
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Wed, 12 Aug 2020 08:42:09 -0500
Subject: [R] add trailing dates with rbind
In-Reply-To: <36E06F41-BDE1-4D71-AD3C-F65AF363C9C7@gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
 <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>
 <36E06F41-BDE1-4D71-AD3C-F65AF363C9C7@gmail.com>
Message-ID: <CAPPM_gSNgxX904HBN_dN=wna+QQ3OV+P5n4V7aqnXcBQYFEFyw@mail.gmail.com>

Eric,

Thanks for the recommendation for xts!

Frederik,

Please direct future questions about xts to R-SIG-Finance, or
Stackoverflow.  I (and other users) are more likely to see your
questions there than here on R-help.

Best,
Josh

On Wed, Aug 12, 2020 at 8:08 AM Frederik Feys <frefeys at gmail.com> wrote:
>
> Thank you so much Eric! Wonderful to have an R community helping out so quickly!
>
> > Op 12 aug. 2020, om 14:10 heeft Eric Berger <ericjberger at gmail.com> het volgende geschreven:
> >
> > Hi Frederik,
> > (short answer) modify the assignment statement to
> >     agg_d_h <- rbind( agg_d_h, data.frame(Group.date=next_date,x=0) )
> >
> >     Note: replace x=0 by your-variable-name=0
> >     Note: left-hand-side of the assignment statement should be agg_d_h
> >
> > (longer answer) Your approach is far from the best way to do this task, for a variety of reasons.
> > If you think that in the future you will be working a lot with daily time series and need to perform similar tasks, I would strongly recommend learning the xts data structure in the xts package.
> > If you have several time series with different date ranges, and all of them are xts objects, you can merge them with 'joins' (left joins, right joins, full joins). xts will automatically handle alignment
> > and preserving dates, etc.
> >
> > HTH,
> > Eric
> >
> >
> >
> >
> > On Wed, Aug 12, 2020 at 2:44 PM Frederik Feys <frefeys at gmail.com <mailto:frefeys at gmail.com>> wrote:
> > I am having a hell of a time, this must surely be simple to solve?.
> >
> > Basically I want to add trailing dates to datasets with differing starting dates so that across datasets I have the same starting date.
> >
> > # make dataset with the same starting date
> > start_date = as.Date("2020-03-01")
> > d_start_date = min(agg_d_h$Group.date)
> >
> > diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days"))
> >
> > for(i in 1:diff_in_days) {
> >   next_date  = start_date+i
> >   app_d <- rbind(agg_d_h, c(next_date, 0) )
> > }
> >
> > gives:
> > Error in as.Date.numeric(value) : 'origin' must be supplied
> >
> > Thank you for your time to help me!
> >
> > Frederik Feys
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 12 16:41:43 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Aug 2020 07:41:43 -0700
Subject: [R] Question about PERL lookahead construct in regex's
In-Reply-To: <D8791839-84CA-4846-A96B-9FCBDD538EC5@collocations.de>
References: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
 <D8791839-84CA-4846-A96B-9FCBDD538EC5@collocations.de>
Message-ID: <CAGxFJbQsTResp06QaTmbQMvqDug0dR_xOaJgWLC8TEEEyrVpMQ@mail.gmail.com>

Thank you.
That indeed dispels my brain fog!

Best,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 12, 2020 at 6:35 AM Stefan Evert <stefanML at collocations.de>
wrote:

>
> > On 10 Aug 2020, at 18:36, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > But this appears to be imprecise (it confused me, anyway). The usual
> sense
> > of "matching" in regex's is "match the pattern somewhere in the string
> > going forward." But in the perl lookahead construct it apparently must
> > **exactly** match *everything* in the string that follows.
> >
> > Questions:
> > Am I correct about this? If not, what do I misunderstand?
>
> I think you're confused about the terminology.  To _match_ a regular
> expression is to find a substring described by the regexp at a given
> starting point; what you have in mind is to _search_ a string for matches
> of a regular expression.
>
> Python uses this terminology in its regexp matching functions, and from
> what you cited in the documentation so do Perl and PCRE in their docs.
>
> Best,
> Stefan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@mo|n@r @end|ng |rom @bcg|ob@|@net  Wed Aug 12 16:56:53 2020
From: @@mo|n@r @end|ng |rom @bcg|ob@|@net (Stephen P. Molnar)
Date: Wed, 12 Aug 2020 10:56:53 -0400
Subject: [R] Date Conversion Problem
References: <5F340335.6020201.ref@sbcglobal.net>
Message-ID: <5F340335.6020201@sbcglobal.net>

i have written an R script which allow me to plot the number of Covid-10 
cases reported by he state of Ohio. In that se t of data the date format 
is in the form yyyy-mm-dd.

My script uses:

datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1 week")
            .
            .
            .
       + scale_x_date(breaks=datebreaks)
       + theme(axis.text.x = element_text(angle=30, hjust=1))

to plot the data.

The COVID Tracking Project publishes considerably more data than does 
the state of Ohio. However, The project supplies daily statistics using 
the date format YYYYMMDD.I have done some searching, but I can't seem to 
find a solution (that I can understand).

How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?

Thanks is advanced.

-- 
Stephen P. Molnar, Ph.D.
www.molecular-modeling.net
614.312.7528 (c)
Skype:  smolnar1


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 12 17:01:19 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 12 Aug 2020 18:01:19 +0300
Subject: [R] Date Conversion Problem
In-Reply-To: <5F340335.6020201@sbcglobal.net>
References: <5F340335.6020201.ref@sbcglobal.net>
 <5F340335.6020201@sbcglobal.net>
Message-ID: <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>

library(lubridate)
a <- "20200403"
lubridate::ymd(a)
# 2020-04-03

HTH,
Eric


On Wed, Aug 12, 2020 at 5:57 PM Stephen P. Molnar <s.molnar at sbcglobal.net>
wrote:

> i have written an R script which allow me to plot the number of Covid-10
> cases reported by he state of Ohio. In that se t of data the date format
> is in the form yyyy-mm-dd.
>
> My script uses:
>
> datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1
> week")
>             .
>             .
>             .
>        + scale_x_date(breaks=datebreaks)
>        + theme(axis.text.x = element_text(angle=30, hjust=1))
>
> to plot the data.
>
> The COVID Tracking Project publishes considerably more data than does
> the state of Ohio. However, The project supplies daily statistics using
> the date format YYYYMMDD.I have done some searching, but I can't seem to
> find a solution (that I can understand).
>
> How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?
>
> Thanks is advanced.
>
> --
> Stephen P. Molnar, Ph.D.
> www.molecular-modeling.net
> 614.312.7528 (c)
> Skype:  smolnar1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 12 17:18:17 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Aug 2020 08:18:17 -0700
Subject: [R] Date Conversion Problem
In-Reply-To: <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>
References: <5F340335.6020201.ref@sbcglobal.net>
 <5F340335.6020201@sbcglobal.net>
 <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>
Message-ID: <CAGxFJbQazqumrPe9+pCndYgESNbHsnJsdDEEVFsEoiMs4LU5Fw@mail.gmail.com>

Extra packages are not needed.

My question is: why change the character representation at all?  See the
format argument of ?as.Date.

> as.Date("20010102",format="%Y%m%d")
[1] "2001-01-02" ## the default format for the print method for Date objects


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 12, 2020 at 8:07 AM Eric Berger <ericjberger at gmail.com> wrote:

> library(lubridate)
> a <- "20200403"
> lubridate::ymd(a)
> # 2020-04-03
>
> HTH,
> Eric
>
>
> On Wed, Aug 12, 2020 at 5:57 PM Stephen P. Molnar <s.molnar at sbcglobal.net>
> wrote:
>
> > i have written an R script which allow me to plot the number of Covid-10
> > cases reported by he state of Ohio. In that se t of data the date format
> > is in the form yyyy-mm-dd.
> >
> > My script uses:
> >
> > datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1
> > week")
> >             .
> >             .
> >             .
> >        + scale_x_date(breaks=datebreaks)
> >        + theme(axis.text.x = element_text(angle=30, hjust=1))
> >
> > to plot the data.
> >
> > The COVID Tracking Project publishes considerably more data than does
> > the state of Ohio. However, The project supplies daily statistics using
> > the date format YYYYMMDD.I have done some searching, but I can't seem to
> > find a solution (that I can understand).
> >
> > How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?
> >
> > Thanks is advanced.
> >
> > --
> > Stephen P. Molnar, Ph.D.
> > www.molecular-modeling.net
> > 614.312.7528 (c)
> > Skype:  smolnar1
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 12 17:22:16 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 12 Aug 2020 18:22:16 +0300
Subject: [R] Date Conversion Problem
In-Reply-To: <CAGxFJbQazqumrPe9+pCndYgESNbHsnJsdDEEVFsEoiMs4LU5Fw@mail.gmail.com>
References: <5F340335.6020201.ref@sbcglobal.net>
 <5F340335.6020201@sbcglobal.net>
 <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>
 <CAGxFJbQazqumrPe9+pCndYgESNbHsnJsdDEEVFsEoiMs4LU5Fw@mail.gmail.com>
Message-ID: <CAGgJW76ka7A-2NYCuQsJTkgSAZOGPWV9CnhoGzDgZ-VMLkXMvg@mail.gmail.com>

nice

On Wed, Aug 12, 2020 at 6:18 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Extra packages are not needed.
>
> My question is: why change the character representation at all?  See the
> format argument of ?as.Date.
>
> > as.Date("20010102",format="%Y%m%d")
> [1] "2001-01-02" ## the default format for the print method for Date
> objects
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Aug 12, 2020 at 8:07 AM Eric Berger <ericjberger at gmail.com> wrote:
>
>> library(lubridate)
>> a <- "20200403"
>> lubridate::ymd(a)
>> # 2020-04-03
>>
>> HTH,
>> Eric
>>
>>
>> On Wed, Aug 12, 2020 at 5:57 PM Stephen P. Molnar <s.molnar at sbcglobal.net
>> >
>> wrote:
>>
>> > i have written an R script which allow me to plot the number of Covid-10
>> > cases reported by he state of Ohio. In that se t of data the date format
>> > is in the form yyyy-mm-dd.
>> >
>> > My script uses:
>> >
>> > datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1
>> > week")
>> >             .
>> >             .
>> >             .
>> >        + scale_x_date(breaks=datebreaks)
>> >        + theme(axis.text.x = element_text(angle=30, hjust=1))
>> >
>> > to plot the data.
>> >
>> > The COVID Tracking Project publishes considerably more data than does
>> > the state of Ohio. However, The project supplies daily statistics using
>> > the date format YYYYMMDD.I have done some searching, but I can't seem to
>> > find a solution (that I can understand).
>> >
>> > How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?
>> >
>> > Thanks is advanced.
>> >
>> > --
>> > Stephen P. Molnar, Ph.D.
>> > www.molecular-modeling.net
>> > 614.312.7528 (c)
>> > Skype:  smolnar1
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Aug 12 14:08:48 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 12 Aug 2020 12:08:48 +0000
Subject: [R] add trailing dates with rbind
In-Reply-To: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
Message-ID: <d9a412a8750d42be821e673b347f450e@SRVEXCHCM1302.precheza.cz>

Hi

I am not sure if I understand correctly. You want to change starting days to some common value?

It seems to me that you actually want start at zero date and continue in each dataset regardless of actual starting date. If it is the case, I would use day numbers like in these examples

> x <- seq(as.Date("2020-03-01"), by=1,length.out=20)
> x-x[1]
Time differences in days
 [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
> y <- seq(as.Date("2020-03-01"), by=2,length.out=10)
> y-y[1]
Time differences in days
 [1]  0  2  4  6  8 10 12 14 16 18
> z <- seq(as.Date("2019-03-01"), by=2,length.out=50)
> z -z[1]
Time differences in days
 [1]  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48
[26] 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98
>

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Frederik Feys
> Sent: Wednesday, August 12, 2020 1:44 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] add trailing dates with rbind
> 
> I am having a hell of a time, this must surely be simple to solve?.
> 
> Basically I want to add trailing dates to datasets with differing starting dates
> so that across datasets I have the same starting date.
> 
> # make dataset with the same starting date
> start_date = as.Date("2020-03-01")
> d_start_date = min(agg_d_h$Group.date)
> 
> diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days"))
> 
> for(i in 1:diff_in_days) {
>   next_date  = start_date+i
>   app_d <- rbind(agg_d_h, c(next_date, 0) )
> }
> 
> gives:
> Error in as.Date.numeric(value) : 'origin' must be supplied
> 
> Thank you for your time to help me!
> 
> Frederik Feys
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @bdou|@ye@@r @end|ng |rom gm@||@com  Wed Aug 12 14:27:39 2020
From: @bdou|@ye@@r @end|ng |rom gm@||@com (Abdoulaye Sarr)
Date: Wed, 12 Aug 2020 12:27:39 +0000
Subject: [R] date conversion problem
Message-ID: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>

I have dataset with time sine 1800-01-01 and extracted data from 1981 to
2019 and used these lines for the data conversion:
> time_d <- as.Date(time, format="%j", origin=as.Date("1800-01-01"))
> time_years <- format(time_d, "%Y")
> time_months <- format(time_d, "%m")
> time_year_months <- format(time_d, "%Y-%m")
> head(time_d)
[1] "6095-12-22" "6096-01-15" "6096-02-08" "6096-03-03" "6096-03-27"
"6096-04-20"

As you see these gregorian dates are unrealistic and wonder what I am doing
wrong?
The time from the raw file in Jd are like this:

> time
   [1] 1569072 1569096 1569120 1569144 1569168 1569192 1569216 1569240etc.

Hope hint and/or suggestion to solve this.

Best regards

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug 13 10:37:51 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 13 Aug 2020 18:37:51 +1000
Subject: [R] date conversion problem
In-Reply-To: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>
References: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>
Message-ID: <CA+8X3fU6wH=t9SoYrMvJN0MOYK1eTPR--bSLYs=CnbnUepvYHw@mail.gmail.com>

Hi Abdoulaye,
It looks to me as though your offsets are in hours, not days. You can
get a rough date like this:

time<-c(1569072,1569096,1569120,1569144,
 1569168,1569192,1569216,1569240)
time_d<-as.Date("1800-01-01")+time/24
time_d
[1] "1979-01-01" "1979-01-02" "1979-01-03" "1979-01-04" "1979-01-05"
[6] "1979-01-06" "1979-01-07" "1979-01-08"

Jim

On Thu, Aug 13, 2020 at 6:10 PM Abdoulaye Sarr <abdoulayesar at gmail.com> wrote:
>
> I have dataset with time sine 1800-01-01 and extracted data from 1981 to
> 2019 and used these lines for the data conversion:
> > time_d <- as.Date(time, format="%j", origin=as.Date("1800-01-01"))
> > time_years <- format(time_d, "%Y")
> > time_months <- format(time_d, "%m")
> > time_year_months <- format(time_d, "%Y-%m")
> > head(time_d)
> [1] "6095-12-22" "6096-01-15" "6096-02-08" "6096-03-03" "6096-03-27"
> "6096-04-20"
>
> As you see these gregorian dates are unrealistic and wonder what I am doing
> wrong?
> The time from the raw file in Jd are like this:
>
> > time
>    [1] 1569072 1569096 1569120 1569144 1569168 1569192 1569216 1569240etc.
>
> Hope hint and/or suggestion to solve this.
>
> Best regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m|@ojpm @end|ng |rom gm@||@com  Thu Aug 13 11:05:01 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 13 Aug 2020 17:05:01 +0800
Subject: [R] stacked bar on single-color printing
Message-ID: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>

Hi,

   I would like to create percentage stacked bar with graphics package
(e.g., ggplot2) and print it in white/black. The regular option is to use
different color on the bar. Is there any way to use different background on
a bar so that we can tell on a black/white printing? For example, let my
green correspond to ***, while my red correspond to ....

   Thanks,

J

	[[alternative HTML version deleted]]


From pr@@@ddn79 @end|ng |rom gm@||@com  Wed Aug 12 12:50:25 2020
From: pr@@@ddn79 @end|ng |rom gm@||@com (Prasad DN)
Date: Wed, 12 Aug 2020 16:20:25 +0530
Subject: [R] Binomial PCA Using pcr()
Message-ID: <CAN+jWPpZNCMrn=VFSPax3U3LmAzYKaWb2HZsTt97oYWgcQHPLA@mail.gmail.com>

Hi All,

i am very new to R and need guidance.

Need help in doing process capability Analysis for my data set (6 months of
data) given in below format:

Date   |   Opportunities  |  Defectives | DefectivesInPercent

I searched and found that pcr() from QualityTools package can be used for
this purpose.  The USL is 2% defectives.

MyData = read.csv(file.choose())   #select  CSV file that has data in above
mentioned format.
x <- MyData$DefectivesInPercent

pcr(x, distribution = "negative-binomial", usl=0.02)

I get error message as:
Error in pcr(x, distribution = "negative-binomial", usl = 0.02) :
  y distribution could not be found!

Please advise, how to proceed?

Regards,
Prasad DN

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 13 12:31:19 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 13 Aug 2020 11:31:19 +0100
Subject: [R] stacked bar on single-color printing
In-Reply-To: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
Message-ID: <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>

Hello,

Without sample data and the code you've tried it's difficult to say but 
are you looking for something like this?


set.seed(2020)
df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
df1 <- df1[sample(nrow(df1), 100, TRUE), ]

library(ggplot2)

tbl <- as.data.frame(table(df1))

ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
   geom_col() +
   scale_color_manual(values = c("black", "black")) +
   scale_fill_manual(values = c("white", "gray70")) +
   theme_bw()


Hope this helps,

Rui Barradas

?s 10:05 de 13/08/20, John escreveu:
> Hi,
> 
>     I would like to create percentage stacked bar with graphics package
> (e.g., ggplot2) and print it in white/black. The regular option is to use
> different color on the bar. Is there any way to use different background on
> a bar so that we can tell on a black/white printing? For example, let my
> green correspond to ***, while my red correspond to ....
> 
>     Thanks,
> 
> J
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From n|co|@ @end|ng |rom g@mb@ro@co@uk  Thu Aug 13 11:03:16 2020
From: n|co|@ @end|ng |rom g@mb@ro@co@uk (Nicola Gambaro)
Date: Thu, 13 Aug 2020 11:03:16 +0200
Subject: [R] Error with sf ordinary kriging after creating grid
Message-ID: <43C4A697-1F13-4BAB-8A0E-F1DB7E1E886E@gambaro.co.uk>

I want to perform ordinary kriging of temperature (UTCI) data in Nigeria with sf and gstat packages. However, after fitting the variogram model and creating a grid for the region, the krige function returns this error:

Error in (function (classes, fdef, mtable)  : 
  unable to find an inherited method for function ?krige? for signature ?"formula", "sfc_POINT"?
What am I doing wrong? Here is my code:

library(gstat)
library(sf)  
sf_data <- st_as_sf(x = data, coords = c("longitude", "latitude"), crs = 4326)

#VARIOGRAM  
vgm_utci <- variogram(UTCI~1, sf_data)
utci_fit <- fit.variogram(vgm_utci, vgm("Mat"), fit.kappa = TRUE)
   
#CREATE GRID
nigeria <- read_sf("./Igismap/Nigeria_Boundary.shp")
nigeria <- nigeria$geometry
nigeria.grid <- nigeria %>% 
              st_make_grid(cellsize = 0.1, what = "centers") %>%
              st_intersection(nigeria)
            
#UTCI ORDINARY KRIGING
utci_krig <- krige(formula = sf_data$UTCI ~ 1, nigeria.grid, model = utci_fit)
When plotted, the grid and the variogram model look fine. I have attached data and shapefile. Thank you so much in advance,

Nicola

From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug 13 14:20:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Aug 2020 05:20:26 -0700
Subject: [R] Error with sf ordinary kriging after creating grid
In-Reply-To: <43C4A697-1F13-4BAB-8A0E-F1DB7E1E886E@gambaro.co.uk>
References: <43C4A697-1F13-4BAB-8A0E-F1DB7E1E886E@gambaro.co.uk>
Message-ID: <CAGxFJbSyTPGe=pYSkh1UTpvMgUs601zMKDvoswy_nnCyj4MXow@mail.gmail.com>

You should post on r-sig-geo, not here. The specific expertise you seek is
much more likely to be found there.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 13, 2020 at 4:09 AM Nicola Gambaro <nicola at gambaro.co.uk> wrote:

> I want to perform ordinary kriging of temperature (UTCI) data in Nigeria
> with sf and gstat packages. However, after fitting the variogram model and
> creating a grid for the region, the krige function returns this error:
>
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?krige? for signature
> ?"formula", "sfc_POINT"?
> What am I doing wrong? Here is my code:
>
> library(gstat)
> library(sf)
> sf_data <- st_as_sf(x = data, coords = c("longitude", "latitude"), crs =
> 4326)
>
> #VARIOGRAM
> vgm_utci <- variogram(UTCI~1, sf_data)
> utci_fit <- fit.variogram(vgm_utci, vgm("Mat"), fit.kappa = TRUE)
>
> #CREATE GRID
> nigeria <- read_sf("./Igismap/Nigeria_Boundary.shp")
> nigeria <- nigeria$geometry
> nigeria.grid <- nigeria %>%
>               st_make_grid(cellsize = 0.1, what = "centers") %>%
>               st_intersection(nigeria)
>
> #UTCI ORDINARY KRIGING
> utci_krig <- krige(formula = sf_data$UTCI ~ 1, nigeria.grid, model =
> utci_fit)
> When plotted, the grid and the variogram model look fine. I have attached
> data and shapefile. Thank you so much in advance,
>
> Nicola
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Thu Aug 13 15:27:23 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 13 Aug 2020 21:27:23 +0800
Subject: [R] stacked bar on single-color printing
In-Reply-To: <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
 <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
Message-ID: <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>

Thanks Rui. That's very close to what I am looking for. You use gray scales
for different categories. That would be a great idea. Could we use pattern
fill?
Rui Barradas <ruipbarradas at sapo.pt> ? 2020?8?13? ?? ??6:31???

> Hello,
>
> Without sample data and the code you've tried it's difficult to say but
> are you looking for something like this?
>
>
> set.seed(2020)
> df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
> df1 <- df1[sample(nrow(df1), 100, TRUE), ]
>
> library(ggplot2)
>
> tbl <- as.data.frame(table(df1))
>
> ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
>    geom_col() +
>    scale_color_manual(values = c("black", "black")) +
>    scale_fill_manual(values = c("white", "gray70")) +
>    theme_bw()
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 10:05 de 13/08/20, John escreveu:
> > Hi,
> >
> >     I would like to create percentage stacked bar with graphics package
> > (e.g., ggplot2) and print it in white/black. The regular option is to use
> > different color on the bar. Is there any way to use different background
> on
> > a bar so that we can tell on a black/white printing? For example, let my
> > green correspond to ***, while my red correspond to ....
> >
> >     Thanks,
> >
> > J
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @bdou|@ye@@r @end|ng |rom gm@||@com  Thu Aug 13 12:35:09 2020
From: @bdou|@ye@@r @end|ng |rom gm@||@com (Abdoulaye Sarr)
Date: Thu, 13 Aug 2020 10:35:09 +0000
Subject: [R] date conversion problem
In-Reply-To: <CA+8X3fU6wH=t9SoYrMvJN0MOYK1eTPR--bSLYs=CnbnUepvYHw@mail.gmail.com>
References: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>
 <CA+8X3fU6wH=t9SoYrMvJN0MOYK1eTPR--bSLYs=CnbnUepvYHw@mail.gmail.com>
Message-ID: <CAN=6O0+jP1UWiTJFZmjdB45eypUuovGQL8m0ObeQ=d8uk_quHA@mail.gmail.com>

Hi Jim,

Thanks for the hint, that makes sense and I'll arrange accordingly.
Best regards,
Abdoulaye

On Thu, Aug 13, 2020 at 8:38 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Abdoulaye,
> It looks to me as though your offsets are in hours, not days. You can
> get a rough date like this:
>
> time<-c(1569072,1569096,1569120,1569144,
>  1569168,1569192,1569216,1569240)
> time_d<-as.Date("1800-01-01")+time/24
> time_d
> [1] "1979-01-01" "1979-01-02" "1979-01-03" "1979-01-04" "1979-01-05"
> [6] "1979-01-06" "1979-01-07" "1979-01-08"
>
> Jim
>
> On Thu, Aug 13, 2020 at 6:10 PM Abdoulaye Sarr <abdoulayesar at gmail.com>
> wrote:
> >
> > I have dataset with time sine 1800-01-01 and extracted data from 1981 to
> > 2019 and used these lines for the data conversion:
> > > time_d <- as.Date(time, format="%j", origin=as.Date("1800-01-01"))
> > > time_years <- format(time_d, "%Y")
> > > time_months <- format(time_d, "%m")
> > > time_year_months <- format(time_d, "%Y-%m")
> > > head(time_d)
> > [1] "6095-12-22" "6096-01-15" "6096-02-08" "6096-03-03" "6096-03-27"
> > "6096-04-20"
> >
> > As you see these gregorian dates are unrealistic and wonder what I am
> doing
> > wrong?
> > The time from the raw file in Jd are like this:
> >
> > > time
> >    [1] 1569072 1569096 1569120 1569144 1569168 1569192 1569216
> 1569240etc.
> >
> > Hope hint and/or suggestion to solve this.
> >
> > Best regards
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 13 15:48:57 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 13 Aug 2020 14:48:57 +0100
Subject: [R] stacked bar on single-color printing
In-Reply-To: <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
 <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
 <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
Message-ID: <07ebe6a0-ce45-5f1b-7daf-e1c3388356d8@sapo.pt>

Hello,

In base graphics function barplot has arguments angle and density, see 
the help page ?barplot. As an example, with the same data (note that the 
argument density is recycled, 2 values, one per stacked bar times the 
number of unique X vakues):


barplot(Freq ~ Y + X, tbl, density = c(10, 0))


Hope this helps,

Rui Barradas

?s 14:27 de 13/08/20, John escreveu:
> Thanks Rui. That's very close to what I am looking for. You use gray 
> scales for different categories. That would be a great idea. Could we 
> use pattern fill?
> Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> ? 
> 2020?8?13? ?? ??6:31???
> 
>     Hello,
> 
>     Without sample data and the code you've tried it's difficult to say but
>     are you looking for something like this?
> 
> 
>     set.seed(2020)
>     df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
>     df1 <- df1[sample(nrow(df1), 100, TRUE), ]
> 
>     library(ggplot2)
> 
>     tbl <- as.data.frame(table(df1))
> 
>     ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
>      ? ?geom_col() +
>      ? ?scale_color_manual(values = c("black", "black")) +
>      ? ?scale_fill_manual(values = c("white", "gray70")) +
>      ? ?theme_bw()
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 10:05 de 13/08/20, John escreveu:
>      > Hi,
>      >
>      >? ? ?I would like to create percentage stacked bar with graphics
>     package
>      > (e.g., ggplot2) and print it in white/black. The regular option
>     is to use
>      > different color on the bar. Is there any way to use different
>     background on
>      > a bar so that we can tell on a black/white printing? For example,
>     let my
>      > green correspond to ***, while my red correspond to ....
>      >
>      >? ? ?Thanks,
>      >
>      > J
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From 538280 @end|ng |rom gm@||@com  Thu Aug 13 16:37:42 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 13 Aug 2020 08:37:42 -0600
Subject: [R] stacked bar on single-color printing
In-Reply-To: <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
 <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
 <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
Message-ID: <CAFEqCdw=-iOJre0CQ4U5J1ZT7=zTUduMbZbsJud4S0FxtKMJwA@mail.gmail.com>

While it is possible to fill bars with patterns, it is not
recommended.  Fill patterns can lead to what is called the Moire
effect and other optical illusions.  Depending on the fill patterns
and how they relate to each other this can cause an illusion of
movement within the plot, straight lines appearing curved, and
distorting of lengths/positions.  Fill patterns (through the
illusions) can subtly move the observer's eye away from the important
parts of a graph and make it hard to focus on the parts of the graph
that are most important.  Google for phrases "Moire effect graphs" and
"optical illusion diagonal lines" for some examples.

Perhaps a dot chart (using symbols instead of colors/greyscale/fill
patterns) would be a better option than a bar chart for your case.

On Thu, Aug 13, 2020 at 7:21 AM John <miaojpm at gmail.com> wrote:
>
> Thanks Rui. That's very close to what I am looking for. You use gray scales
> for different categories. That would be a great idea. Could we use pattern
> fill?
> Rui Barradas <ruipbarradas at sapo.pt> ? 2020?8?13? ?? ??6:31???
>
> > Hello,
> >
> > Without sample data and the code you've tried it's difficult to say but
> > are you looking for something like this?
> >
> >
> > set.seed(2020)
> > df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
> > df1 <- df1[sample(nrow(df1), 100, TRUE), ]
> >
> > library(ggplot2)
> >
> > tbl <- as.data.frame(table(df1))
> >
> > ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
> >    geom_col() +
> >    scale_color_manual(values = c("black", "black")) +
> >    scale_fill_manual(values = c("white", "gray70")) +
> >    theme_bw()
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 10:05 de 13/08/20, John escreveu:
> > > Hi,
> > >
> > >     I would like to create percentage stacked bar with graphics package
> > > (e.g., ggplot2) and print it in white/black. The regular option is to use
> > > different color on the bar. Is there any way to use different background
> > on
> > > a bar so that we can tell on a black/white printing? For example, let my
> > > green correspond to ***, while my red correspond to ....
> > >
> > >     Thanks,
> > >
> > > J
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From e|en@@|v@nov@ @end|ng |rom hu-ber||n@de  Thu Aug 13 08:00:10 2020
From: e|en@@|v@nov@ @end|ng |rom hu-ber||n@de (Elena Ivanova)
Date: Thu, 13 Aug 2020 09:00:10 +0300
Subject: [R] R 3.6.1 for MAC
Message-ID: <BDD153B8-1A34-41BC-AAF6-B6AF81297F19@hu-berlin.de>

Dear Sir/Madame, 
Could you please let me know where to find the Version 3.6.1 for MAC since I have a package only working with this version

Unfortunately I can not find it here

https://cran.r-project.org/bin/macosx/




Elena Ivanova
PhD Student
elena.ivanova at hu-berlin.de




	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Aug 13 16:58:20 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 13 Aug 2020 17:58:20 +0300
Subject: [R] R 3.6.1 for MAC
In-Reply-To: <BDD153B8-1A34-41BC-AAF6-B6AF81297F19@hu-berlin.de>
References: <BDD153B8-1A34-41BC-AAF6-B6AF81297F19@hu-berlin.de>
Message-ID: <20200813175820.2124d534@trisector>

Dear Elena,

On Thu, 13 Aug 2020 09:00:10 +0300
Elena Ivanova <elena.ivanova at hu-berlin.de> wrote:

> Could you please let me know where to find the Version 3.6.1 for MAC
> since I have a package only working with this version

Short answer: perhaps
https://cran.r-project.org/bin/macosx/el-capitan/base/R-3.6.1.pkg would
work?

R-Help is about R programming, not installation of R on macOS, so if the
link above does not help you, please ask in the R-SIG-Mac mailing list:
https://stat.ethz.ch/mailman/listinfo/r-sig-mac

-- 
Best regards,
Ivan


From herd_dog @end|ng |rom cox@net  Thu Aug 13 17:59:22 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Thu, 13 Aug 2020 08:59:22 -0700
Subject: [R] rNOMAD package
Message-ID: <C9788A2AE06D48D9A943102C9F1F6AE4@OWNERPC>

Daniel Bowman wrote a wonderful package to access National Weather Service data with R.

Unfortunately I stuck trying to download archived Rapid Update Forecasts (RAP) going back into 2016.  I have been poking around on the Internet for days but keep getting recycled to three or four websites that assume a certain level of background knowledge that I don?t have.  It has something to do with OPenDAP (Data Access Protocol) which is a piece of software to grab data over the Internet.

Can someone give me some direction?

Thanks,
Philip
	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Thu Aug 13 18:23:20 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 13 Aug 2020 09:23:20 -0700
Subject: [R] rNOMAD package
In-Reply-To: <C9788A2AE06D48D9A943102C9F1F6AE4@OWNERPC>
References: <C9788A2AE06D48D9A943102C9F1F6AE4@OWNERPC>
Message-ID: <C4807CC7-FC68-4D22-BE6C-A27677B1B33A@noaa.gov>


Hi Philip:

Both 'ncdf4' and 'Rnetcdf' should be able to download data using OPeNDAP.  That the package is using OPeNDAP is transparent to the user,  other than the fact that the "file" is an URL.  Extracts are just like reading a netCDF file using these packages,  so you may have to spend some time learning how to do that.

It is possible that 'tidnyNC' can also do OPeNDAP,  I am just not certain that.

-Roy

> On Aug 13, 2020, at 8:59 AM, Philip <herd_dog at cox.net> wrote:
> 
> Daniel Bowman wrote a wonderful package to access National Weather Service data with R.
> 
> Unfortunately I stuck trying to download archived Rapid Update Forecasts (RAP) going back into 2016.  I have been poking around on the Internet for days but keep getting recycled to three or four websites that assume a certain level of background knowledge that I don?t have.  It has something to do with OPenDAP (Data Access Protocol) which is a piece of software to grab data over the Internet.
> 
> Can someone give me some direction?
> 
> Thanks,
> Philip
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From jgreenberg @end|ng |rom unr@edu  Thu Aug 13 20:58:25 2020
From: jgreenberg @end|ng |rom unr@edu (Jonathan Greenberg)
Date: Thu, 13 Aug 2020 11:58:25 -0700
Subject: [R] Best settings for RStudio video recording?
Message-ID: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>

Folks:

I was wondering if you all would suggest some helpful RStudio
configurations that make recording a session via e.g. zoom the most useful
for students doing remote learning.  Thoughts?

--j

-- 
Jonathan A. Greenberg, PhD
Randall Endowed Professor and Associate Professor of Remote Sensing
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Natural Resources & Environmental Science
University of Nevada, Reno
1664 N Virginia St MS/0186
Reno, NV 89557
Phone: 415-763-5476
https://www.gearslab.org/

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 14 00:15:31 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Aug 2020 15:15:31 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
Message-ID: <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>

Way off topic. Ask at RStudio. This is **R-Help** -- help on R
programming.  RStudio is a private company.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg <jgreenberg at unr.edu>
wrote:

> Folks:
>
> I was wondering if you all would suggest some helpful RStudio
> configurations that make recording a session via e.g. zoom the most useful
> for students doing remote learning.  Thoughts?
>
> --j
>
> --
> Jonathan A. Greenberg, PhD
> Randall Endowed Professor and Associate Professor of Remote Sensing
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Natural Resources & Environmental Science
> University of Nevada, Reno
> 1664 N Virginia St MS/0186
> Reno, NV 89557
> Phone: 415-763-5476
> https://www.gearslab.org/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Fri Aug 14 00:47:30 2020
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Thu, 13 Aug 2020 22:47:30 +0000
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
Message-ID: <BL0PR04MB6609D91356C1E80EED4E998AF9430@BL0PR04MB6609.namprd04.prod.outlook.com>

Excellent question! I think most R courses use RStudio, so it is completely appropriate to ask about how to help people learn R using RStudio.

I don't have a lot experience with virtual teaching, and very limited experience with anything other than short-term workshops.

I think that there is tremendous value, during the 'in person' portion of a course, in doing interactive and even 'ad hoc' analysis, perhaps especially handling the off-the-wall questions that participants might raise (when I have to struggle to figure out what the R answer is, and then convey to the attendees my thinking process), and making all kinds of mistakes, including simple typos (requiring me to explain what the error message means, and how I diagnosed the problem and arrived at a solution that was other than a pull-it-out-of-the-hat miracle).

With this in mind, I try to increase the prominence of the console portion of the RStudio interface. I place it at the top left of the screen (this might be a remnant of in-person presentations, where the heads of people in front often block the view of the lines where code is being enter; this is obviously not relevant in a virtual context). Usually I keep the script portion of the display visible at the bottom left, with only a few lines showing, as a kind of cheat sheet for me, rather than for the students to 'follow along').

I use a large font, which I think helps in both virtual and physical sessions in part because it limits the amount of information on the screen, causing me to slow my presentation enough that the students can absorb what I am saying. Perhaps as a consequence of the limited screen real-estate, students often ask 'to see the last command' so I now include in the right panel the 'History' tab. The division is asymmetric, so the console continues to take up the majority of screen real estate.

The end result of a sequence of operations is often a pretty picture, but since this is only the end result and not the meat of the learning experience I tend to keep the plot window (lower right) relatively small, and try to remember to expand things at the time when the end result is in sight (so to speak;)).

I hope others with more direct experience are not dissuaded by Bert's opinions, and offer up their own experiences or resource recommendations.

Martin Morgan

?On 8/13/20, 6:05 PM, "R-help on behalf of Jonathan Greenberg" <r-help-bounces at r-project.org on behalf of jgreenberg at unr.edu> wrote:

    Folks:

    I was wondering if you all would suggest some helpful RStudio
    configurations that make recording a session via e.g. zoom the most useful
    for students doing remote learning.  Thoughts?

    --j

    -- 
    Jonathan A. Greenberg, PhD
    Randall Endowed Professor and Associate Professor of Remote Sensing
    Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
    Natural Resources & Environmental Science
    University of Nevada, Reno
    1664 N Virginia St MS/0186
    Reno, NV 89557
    Phone: 415-763-5476
    https://www.gearslab.org/

    	[[alternative HTML version deleted]]

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 14 02:11:17 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Aug 2020 17:11:17 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
Message-ID: <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>

The jab about a "private company" detracted from your point. It is a public benefit corporation, but either way they produce open source software that is frequently used to introduce people to R, and the company management structure is irrelevant.

While I would have preferred to see a question that was open to any presentation format, forbidding discussion of how to teach R just because the query happens to limit itself to RStudio seems excessively narrow to me.

I have been frustrated by the fact that there is no r-sig-windows, since I find myself uncomfortably discussing OS-specific issues on R-help for which there is no better place to forward them. Using the multi-OS RStudio for teaching R seems rather less off-topic than that.

On August 13, 2020 3:15:31 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Way off topic. Ask at RStudio. This is **R-Help** -- help on R
>programming.  RStudio is a private company.
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg <jgreenberg at unr.edu>
>wrote:
>
>> Folks:
>>
>> I was wondering if you all would suggest some helpful RStudio
>> configurations that make recording a session via e.g. zoom the most
>useful
>> for students doing remote learning.  Thoughts?
>>
>> --j
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Randall Endowed Professor and Associate Professor of Remote Sensing
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Natural Resources & Environmental Science
>> University of Nevada, Reno
>> 1664 N Virginia St MS/0186
>> Reno, NV 89557
>> Phone: 415-763-5476
>> https://www.gearslab.org/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 14 02:22:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Aug 2020 17:22:21 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
Message-ID: <CAGxFJbR50pJbfJDk1tv_gQ5Hxbw1LE0ujFNhteCzKGg_O-k70w@mail.gmail.com>

Well then:
"Using the multi-OS RStudio for teaching R seems rather less off-topic than
that."

If the query is about teaching r, wouldn't R-Sig-teaching be the right
place to post?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 13, 2020 at 5:11 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The jab about a "private company" detracted from your point. It is a
> public benefit corporation, but either way they produce open source
> software that is frequently used to introduce people to R, and the company
> management structure is irrelevant.
>
> While I would have preferred to see a question that was open to any
> presentation format, forbidding discussion of how to teach R just because
> the query happens to limit itself to RStudio seems excessively narrow to me.
>
> I have been frustrated by the fact that there is no r-sig-windows, since I
> find myself uncomfortably discussing OS-specific issues on R-help for which
> there is no better place to forward them. Using the multi-OS RStudio for
> teaching R seems rather less off-topic than that.
>
> On August 13, 2020 3:15:31 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >Way off topic. Ask at RStudio. This is **R-Help** -- help on R
> >programming.  RStudio is a private company.
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg <jgreenberg at unr.edu>
> >wrote:
> >
> >> Folks:
> >>
> >> I was wondering if you all would suggest some helpful RStudio
> >> configurations that make recording a session via e.g. zoom the most
> >useful
> >> for students doing remote learning.  Thoughts?
> >>
> >> --j
> >>
> >> --
> >> Jonathan A. Greenberg, PhD
> >> Randall Endowed Professor and Associate Professor of Remote Sensing
> >> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> >> Natural Resources & Environmental Science
> >> University of Nevada, Reno
> >> 1664 N Virginia St MS/0186
> >> Reno, NV 89557
> >> Phone: 415-763-5476
> >> https://www.gearslab.org/
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 14 09:50:24 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 14 Aug 2020 00:50:24 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CAGxFJbR50pJbfJDk1tv_gQ5Hxbw1LE0ujFNhteCzKGg_O-k70w@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAGxFJbR50pJbfJDk1tv_gQ5Hxbw1LE0ujFNhteCzKGg_O-k70w@mail.gmail.com>
Message-ID: <238EEAB6-8BB7-4669-B06F-227512D58197@dcn.davis.ca.us>

perhaps. I wasn't aware of it. Given the level of traffic there it looks like I am not alone.

On August 13, 2020 5:22:21 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Well then:
>"Using the multi-OS RStudio for teaching R seems rather less off-topic
>than
>that."
>
>If the query is about teaching r, wouldn't R-Sig-teaching be the right
>place to post?
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Aug 13, 2020 at 5:11 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> The jab about a "private company" detracted from your point. It is a
>> public benefit corporation, but either way they produce open source
>> software that is frequently used to introduce people to R, and the
>company
>> management structure is irrelevant.
>>
>> While I would have preferred to see a question that was open to any
>> presentation format, forbidding discussion of how to teach R just
>because
>> the query happens to limit itself to RStudio seems excessively narrow
>to me.
>>
>> I have been frustrated by the fact that there is no r-sig-windows,
>since I
>> find myself uncomfortably discussing OS-specific issues on R-help for
>which
>> there is no better place to forward them. Using the multi-OS RStudio
>for
>> teaching R seems rather less off-topic than that.
>>
>> On August 13, 2020 3:15:31 PM PDT, Bert Gunter
><bgunter.4567 at gmail.com>
>> wrote:
>> >Way off topic. Ask at RStudio. This is **R-Help** -- help on R
>> >programming.  RStudio is a private company.
>> >
>> >Bert Gunter
>> >
>> >"The trouble with having an open mind is that people keep coming
>along
>> >and
>> >sticking things into it."
>> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> >On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg
><jgreenberg at unr.edu>
>> >wrote:
>> >
>> >> Folks:
>> >>
>> >> I was wondering if you all would suggest some helpful RStudio
>> >> configurations that make recording a session via e.g. zoom the
>most
>> >useful
>> >> for students doing remote learning.  Thoughts?
>> >>
>> >> --j
>> >>
>> >> --
>> >> Jonathan A. Greenberg, PhD
>> >> Randall Endowed Professor and Associate Professor of Remote
>Sensing
>> >> Global Environmental Analysis and Remote Sensing (GEARS)
>Laboratory
>> >> Natural Resources & Environmental Science
>> >> University of Nevada, Reno
>> >> 1664 N Virginia St MS/0186
>> >> Reno, NV 89557
>> >> Phone: 415-763-5476
>> >> https://www.gearslab.org/
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

-- 
Sent from my phone. Please excuse my brevity.


From pd@|gd @end|ng |rom gm@||@com  Fri Aug 14 10:23:18 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 14 Aug 2020 10:23:18 +0200
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <238EEAB6-8BB7-4669-B06F-227512D58197@dcn.davis.ca.us>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAGxFJbR50pJbfJDk1tv_gQ5Hxbw1LE0ujFNhteCzKGg_O-k70w@mail.gmail.com>
 <238EEAB6-8BB7-4669-B06F-227512D58197@dcn.davis.ca.us>
Message-ID: <1F44401A-4C8A-4459-A37F-EB4325BA1514@gmail.com>



> On 14 Aug 2020, at 09:50 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> perhaps. I wasn't aware of it. Given the level of traffic there it looks like I am not alone.
> 
> On August 13, 2020 5:22:21 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Well then:
>> "Using the multi-OS RStudio for teaching R seems rather less off-topic
>> than
>> that."
>> 
>> If the query is about teaching r, wouldn't R-Sig-teaching be the right
>> place to post?
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Aug 13, 2020 at 5:11 PM Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us>
>> wrote:
>> 
>>> The jab about a "private company" detracted from your point. It is a
>>> public benefit corporation, but either way they produce open source
>>> software that is frequently used to introduce people to R, and the
>> company
>>> management structure is irrelevant.
>>> 
>>> While I would have preferred to see a question that was open to any
>>> presentation format, forbidding discussion of how to teach R just
>> because
>>> the query happens to limit itself to RStudio seems excessively narrow
>> to me.
>>> 
>>> I have been frustrated by the fact that there is no r-sig-windows,
>> since I
>>> find myself uncomfortably discussing OS-specific issues on R-help for
>> which
>>> there is no better place to forward them. Using the multi-OS RStudio
>> for
>>> teaching R seems rather less off-topic than that.
>>> 
>>> On August 13, 2020 3:15:31 PM PDT, Bert Gunter
>> <bgunter.4567 at gmail.com>
>>> wrote:
>>>> Way off topic. Ask at RStudio. This is **R-Help** -- help on R
>>>> programming.  RStudio is a private company.
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming
>> along
>>>> and
>>>> sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>> On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg
>> <jgreenberg at unr.edu>
>>>> wrote:
>>>> 
>>>>> Folks:
>>>>> 
>>>>> I was wondering if you all would suggest some helpful RStudio
>>>>> configurations that make recording a session via e.g. zoom the
>> most
>>>> useful
>>>>> for students doing remote learning.  Thoughts?
>>>>> 
>>>>> --j
>>>>> 
>>>>> --
>>>>> Jonathan A. Greenberg, PhD
>>>>> Randall Endowed Professor and Associate Professor of Remote
>> Sensing
>>>>> Global Environmental Analysis and Remote Sensing (GEARS)
>> Laboratory
>>>>> Natural Resources & Environmental Science
>>>>> University of Nevada, Reno
>>>>> 1664 N Virginia St MS/0186
>>>>> Reno, NV 89557
>>>>> Phone: 415-763-5476
>>>>> https://www.gearslab.org/
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@|gd @end|ng |rom gm@||@com  Fri Aug 14 10:29:46 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 14 Aug 2020 10:29:46 +0200
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
Message-ID: <7610B2DE-9315-44F3-8B8E-D638C3F7DFD9@gmail.com>

[Sorry about the misfire a second ago...]

As others have said, for deeper questions, try RStudio's own lists or R-sig-teaching.

However, FWIW, I seem to have gotten away with just using a separate virtual desktop with my usual work setup, and then switch to it when necessary. This was for Panopto video recordings, but Zoom et al. should be much the same. Compared to physical lecturing it is actually somewhat easier, because you don't need to worry so much about projector shortcomings, readability from the back row, etc.

-pd

> On 13 Aug 2020, at 20:58 , Jonathan Greenberg <jgreenberg at unr.edu> wrote:
> 
> Folks:
> 
> I was wondering if you all would suggest some helpful RStudio
> configurations that make recording a session via e.g. zoom the most useful
> for students doing remote learning.  Thoughts?
> 
> --j
> 
> -- 
> Jonathan A. Greenberg, PhD
> Randall Endowed Professor and Associate Professor of Remote Sensing
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Natural Resources & Environmental Science
> University of Nevada, Reno
> 1664 N Virginia St MS/0186
> Reno, NV 89557
> Phone: 415-763-5476
> https://www.gearslab.org/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j|ox @end|ng |rom mcm@@ter@c@  Fri Aug 14 19:54:25 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 14 Aug 2020 13:54:25 -0400
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <29724_1597394136_07E8Zad3023785_7610B2DE-9315-44F3-8B8E-D638C3F7DFD9@gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <29724_1597394136_07E8Zad3023785_7610B2DE-9315-44F3-8B8E-D638C3F7DFD9@gmail.com>
Message-ID: <051b7eab-9607-10ee-2aaa-dbbf8efabc01@mcmaster.ca>

Hi,

I had occasion last month to teach a two-week, two-hour-per-day lecture 
series on R via Zoom for the ICPSR Summer Program -- the website for the 
lectures is at 
<https://socialsciences.mcmaster.ca/jfox/Courses/R/ICPSR/index.html>.

I used RStudio and mostly displayed my desktop via one monitor in a 
two-monitor setup. That allowed me to show the website (or Canvas site) 
for the lectures, PDF slides, or the RStudio window, and to have the 
other monitor free to control the Zoom session. Most of the time, 
perhaps 1.5 hours per session, I displayed the RStudio window.

To set the size of the fonts in RStudio, I tested in a dummy Zoom 
session that I viewed on a small laptop prior to the start of the 
lecture series.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-08-14 4:29 a.m., peter dalgaard wrote:
> [Sorry about the misfire a second ago...]
> 
> As others have said, for deeper questions, try RStudio's own lists or R-sig-teaching.
> 
> However, FWIW, I seem to have gotten away with just using a separate virtual desktop with my usual work setup, and then switch to it when necessary. This was for Panopto video recordings, but Zoom et al. should be much the same. Compared to physical lecturing it is actually somewhat easier, because you don't need to worry so much about projector shortcomings, readability from the back row, etc.
> 
> -pd
> 
>> On 13 Aug 2020, at 20:58 , Jonathan Greenberg <jgreenberg at unr.edu> wrote:
>>
>> Folks:
>>
>> I was wondering if you all would suggest some helpful RStudio
>> configurations that make recording a session via e.g. zoom the most useful
>> for students doing remote learning.  Thoughts?
>>
>> --j
>>
>> -- 
>> Jonathan A. Greenberg, PhD
>> Randall Endowed Professor and Associate Professor of Remote Sensing
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Natural Resources & Environmental Science
>> University of Nevada, Reno
>> 1664 N Virginia St MS/0186
>> Reno, NV 89557
>> Phone: 415-763-5476
>> https://www.gearslab.org/
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From herd_dog @end|ng |rom cox@net  Fri Aug 14 22:58:01 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Fri, 14 Aug 2020 13:58:01 -0700
Subject: [R] Hot Air Balloon Weather Briefings
Message-ID: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>

I?m trying to compare National Weather Service Rapid Update Forecast (RAP) data to GPS breadcrumbs collected by a really clever Apple Phone Ap that lays down longitude, latitude, altitude, compass direction, and speed every six seconds.   Below is a small subset of the GPS data from another flight.  

I want to delete the rows where the balloon does not move (Speed column) for a full minute assuming that it is sitting on the ground ? beginning of the flight, changing passengers, or waiting for the chase crew at the end of the flight.  for example, I want to eliminate the data for minute 30 but keep the data for minute 31 because the balloon starts to move again at second 17.  Any suggestions?  I?ve tried putzing around with multiple lags without success.

      Minute Second Speed 
      29 47 0 
      29 53 0 
      29 59 0 
      30 5 0 
      30 11 0 
      30 17 0 
      30 23 0 
      30 29 0 
      30 35 0 
      30 41 0 
      30 47 0 
      30 53 0 
      30 59 0 
      31 5 0 
      31 11 0 
      31 17 0.402649 
      31 23 0.671081 
      31 29 1.588225 
      31 35 2.438261 
      31 41 2.706693 
      31 47 2.930386 
      31 53 3.310666 
      31 59 3.198819 
      32 5 3.422512 


It would be even better if I could delete the rows where there were ten consecutive zero speed entries such as from minute 30 second 17 to minute 31 second 11.

Thanks,
Philip Heinrich
	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug 14 23:24:49 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 15 Aug 2020 07:24:49 +1000
Subject: [R] Hot Air Balloon Weather Briefings
In-Reply-To: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
References: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
Message-ID: <CA+8X3fUG39u0kFBTpYbprL-H9oaQkjWwDDEHJgXdcQXK4JEx1w@mail.gmail.com>

Hi Philip,
Not very elegant, but:

phdf<-read.table(text="Minute Second Speed
 29 47 0
 29 53 0
 29 59 0
 30 5 0
 30 11 0
 30 17 0
 30 23 0
 30 29 0
 30 35 0
 30 41 0
 30 47 0
 30 53 0
 30 59 0
 31 5 0
 31 11 0
 31 17 0.402649
 31 23 0.671081
 31 29 1.588225
 31 35 2.438261
 31 41 2.706693
 31 47 2.930386
 31 53 3.310666
 31 59 3.198819
 32 5 3.422512",
 header=TRUE,stringsAsFactors=FALSE)
keep<-rep(TRUE,length(phdf$Speed))
for(mini in unique(phdf$Minute))
 if(all(phdf$Speed[phdf$Minute == mini] == 0))
  keep[phdf$Minute == mini]<-FALSE
phdf<-phdf[keep,]

Jim

On Sat, Aug 15, 2020 at 6:59 AM Philip <herd_dog at cox.net> wrote:
>
> I?m trying to compare National Weather Service Rapid Update Forecast (RAP) data to GPS breadcrumbs collected by a really clever Apple Phone Ap that lays down longitude, latitude, altitude, compass direction, and speed every six seconds.   Below is a small subset of the GPS data from another flight.
>
> I want to delete the rows where the balloon does not move (Speed column) for a full minute assuming that it is sitting on the ground ? beginning of the flight, changing passengers, or waiting for the chase crew at the end of the flight.  for example, I want to eliminate the data for minute 30 but keep the data for minute 31 because the balloon starts to move again at second 17.  Any suggestions?  I?ve tried putzing around with multiple lags without success.
>
>       Minute Second Speed
>       29 47 0
>       29 53 0
>       29 59 0
>       30 5 0
>       30 11 0
>       30 17 0
>       30 23 0
>       30 29 0
>       30 35 0
>       30 41 0
>       30 47 0
>       30 53 0
>       30 59 0
>       31 5 0
>       31 11 0
>       31 17 0.402649
>       31 23 0.671081
>       31 29 1.588225
>       31 35 2.438261
>       31 41 2.706693
>       31 47 2.930386
>       31 53 3.310666
>       31 59 3.198819
>       32 5 3.422512
>
>
> It would be even better if I could delete the rows where there were ten consecutive zero speed entries such as from minute 30 second 17 to minute 31 second 11.
>
> Thanks,
> Philip Heinrich
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 14 23:43:20 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 14 Aug 2020 14:43:20 -0700
Subject: [R] Hot Air Balloon Weather Briefings
In-Reply-To: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
References: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
Message-ID: <CAGxFJbSjhApQxWQLoGdcXJ1RPiEnzRuO-=MwOwMj5Y6Pg3c7cQ@mail.gmail.com>

Well which is it?:
"I want to eliminate the data for minute 30 but keep the data for minute 31
because the balloon starts to move again at second 17. "
or
"It would be even better if I could delete the rows where there were ten
consecutive zero speed entries such as from minute 30 second 17 to minute
31 second 11."

If you want to delete say data with >= 10 consecutive 0's, ?rle is your
friend:

rle(phdf$Speed)
Run Length Encoding
  lengths: int [1:10] 15 1 1 1 1 1 1 1 1 1
  values : num [1:10] 0 0.402649 0.671081 1.588225 2.438261 2.706693
2.930386 3.310666 3.198819 3.422512

e.g.
> z <- rle(phdf$Speed)$lengths
## which gives:
> z
 [1] 15  1  1  1  1  1  1  1  1  1
> rep(z>9,z)
 [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[11]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
[21] FALSE FALSE FALSE FALSE

##Thus:
> phdf[ rep(z<10, z), ]
   Minute Second    Speed
16     31     17 0.402649
17     31     23 0.671081
18     31     29 1.588225
19     31     35 2.438261
20     31     41 2.706693
21     31     47 2.930386
22     31     53 3.310666
23     31     59 3.198819
24     32      5 3.422512

But of course, this probably isn't what you meant. So further clarification
is needed.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 14, 2020 at 1:59 PM Philip <herd_dog at cox.net> wrote:

> I?m trying to compare National Weather Service Rapid Update Forecast (RAP)
> data to GPS breadcrumbs collected by a really clever Apple Phone Ap that
> lays down longitude, latitude, altitude, compass direction, and speed every
> six seconds.   Below is a small subset of the GPS data from another
> flight.
>
> I want to delete the rows where the balloon does not move (Speed column)
> for a full minute assuming that it is sitting on the ground ? beginning of
> the flight, changing passengers, or waiting for the chase crew at the end
> of the flight.  for example, I want to eliminate the data for minute 30 but
> keep the data for minute 31 because the balloon starts to move again at
> second 17.  Any suggestions?  I?ve tried putzing around with multiple lags
> without success.
>
>       Minute Second Speed
>       29 47 0
>       29 53 0
>       29 59 0
>       30 5 0
>       30 11 0
>       30 17 0
>       30 23 0
>       30 29 0
>       30 35 0
>       30 41 0
>       30 47 0
>       30 53 0
>       30 59 0
>       31 5 0
>       31 11 0
>       31 17 0.402649
>       31 23 0.671081
>       31 29 1.588225
>       31 35 2.438261
>       31 41 2.706693
>       31 47 2.930386
>       31 53 3.310666
>       31 59 3.198819
>       32 5 3.422512
>
>
> It would be even better if I could delete the rows where there were ten
> consecutive zero speed entries such as from minute 30 second 17 to minute
> 31 second 11.
>
> Thanks,
> Philip Heinrich
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Sat Aug 15 00:21:35 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 15 Aug 2020 00:21:35 +0200
Subject: [R] Hot Air Balloon Weather Briefings
In-Reply-To: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
References: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
Message-ID: <20200814222135.GB707081@posteo.no>

On 2020-08-14 13:58 -0700, Philip wrote:
| I?m trying to compare National Weather 
| Service Rapid Update Forecast (RAP) 
| data to GPS breadcrumbs collected by a 
| really clever Apple Phone Ap that lays 
| down longitude, latitude, altitude, 
| compass direction, and speed every six 
| seconds.   Below is a small subset of 
| the GPS data from another flight.  
| 
| I want to delete the rows where the 
| balloon does not move (Speed column) 
| for a full minute assuming that it is 
| sitting on the ground ? beginning of 
| the flight, changing passengers, or 
| waiting for the chase crew at the end 
| of the flight.  for example, I want to 
| eliminate the data for minute 30 but 
| keep the data for minute 31 because 
| the balloon starts to move again at 
| second 17.  Any suggestions?  I?ve 
| tried putzing around with multiple 
| lags without success.
| 
| 	Minute Second Speed 
| 	[...]
| 
| It would be even better if I could 
| delete the rows where there were ten 
| consecutive zero speed entries such as 
| from minute 30 second 17 to minute 31 
| second 11.

Dear Philip,

first I though about solving this using 
some combination of unique, duplicated, 
table ... then I saw Jim's reply, and 
rewrote it a little:

	rap <-
	structure(list(Minute = c(29L, 29L, 29L,
	30L, 30L, 30L, 30L, 30L, 30L, 30L, 30L, 
	30L, 30L, 31L, 31L, 31L, 31L, 31L, 31L, 
	31L, 31L, 31L, 31L, 31L, 31L, 31L, 31L, 
	31L, 31L, 31L, 31L, 31L, 31L, 31L, 31L, 
	31L, 31L, 31L, 31L, 31L, 31L, 32L), 
	Second = c(47L, 53L, 59L, 5L, 11L, 17L, 
	23L, 29L, 35L, 41L, 47L, 53L, 59L, 5L, 
	11L, 17L, 23L, 29L, 35L, 41L, 43L, 43L, 
	43L, 43L, 43L, 43L, 43L, 43L, 43L, 43L, 
	43L, 43L, 47L, 53L, 54L, 54L, 54L, 54L, 
	54L, 54L, 59L, 5L), 
	Speed = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
	0, 0, 0, 0, 0, 0.402649, 0.671081, 
	1.588225, 2.438261, 2.706693, 0, 0, 0, 
	0, 0, 0, 0, 0, 0, 0, 0, 0, 2.930386, 
	3.310666, 0, 0, 0, 0, 0, 0, 3.198819, 
	3.422512)), class = "data.frame", 
	row.names = c(NA, -42L))
	
	minis <- unique(rap$Minute)
	FUN <- function(mini, rap) {
	  all(rap$Speed[rap$Minute==mini]==0) }
	keep <- rap$Minute %in%
	  minis[!simplify2array(
	    parallel::mclapply(minis, FUN, rap))]
	rap[keep,]

As to Bert's reply, I am a loss as how 
to use the lengths list in 
rle(rap$Speed) for this ...

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200815/b24cec39/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Sat Aug 15 01:35:15 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 15 Aug 2020 01:35:15 +0200
Subject: [R] Hot Air Balloon Weather Briefings
In-Reply-To: <CAGxFJbRXkSF24rMZaxRN=SaVcCGM2OXyjg5gvVS8A7CBMH3zyg@mail.gmail.com>
References: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
 <20200814222135.GB707081@posteo.no>
 <CAGxFJbRXkSF24rMZaxRN=SaVcCGM2OXyjg5gvVS8A7CBMH3zyg@mail.gmail.com>
Message-ID: <20200814233515.GA750378@posteo.no>

On 2020-08-14 15:56 -0700, Bert Gunter wrote:
| On Fri, Aug 14, 2020 at 3:21 PM Rasmus Liland wrote:
| |
| | As to Bert's reply, I am a loss as 
| | how to use the lengths list in 
| | rle(rap$Speed) for this ...
| 
| I showed how in my message for one 
| interpretation of the query. I would 
| need further clarification for other 
| interpretations, but note that in my 
| reply,   rep(z|9, z)  gives a logical 
| vector in which all rows in which a 
| speed of 0 appears in a run of 10 or 
| greater (as no other speed would be 
| replicated) is TRUE, FALSE otherwise.  
| ( z = $lengths).  I would agree that 
| whether this is a good starting point 
| for other interpretations remains to 
| be seen.

Yes, the time cols might be omitted to 
complete this.

	z <- rle(rap$Speed)$lengths
	rap[rep(x=z<10, times=z),]

This is not bad.

/Rasmus

P.S. Adding this back to the list (this 
ends up in a searchable archive, and so 
on and so fourth). 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200815/bbbfbc2e/attachment.sig>

From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Aug 15 06:33:57 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 15 Aug 2020 16:33:57 +1200
Subject: [R] Testing.
Message-ID: <20200815163357.21069df4@rolf-Latitude-E7470>


My apologies for the noise.  Please ignore this message.
I am just trying to test out message filters in a new mail client that
I am learning to use.

Again, sorry for the noise.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @o||m@n|m@n| @end|ng |rom y@hoo@de  Sat Aug 15 00:08:35 2020
From: @o||m@n|m@n| @end|ng |rom y@hoo@de (Mani Solimani)
Date: Fri, 14 Aug 2020 22:08:35 +0000 (UTC)
Subject: [R] Shiny debug mode- reort a bug R version 4.0.2
References: <86344151.2613828.1597442915966.ref@mail.yahoo.com>
Message-ID: <86344151.2613828.1597442915966@mail.yahoo.com>


DearR-help Community,

?

since Iupdated the R V.3:6 to R.V4.0.2 I have the following problem:
It might be the problem of R, if the same pack worksunder V.3.6 and suddenly not in V.4.0.2.
- Session info ----------------------------------------------------------------------------------------------------------------------
setting? value????????????????????? ?
?version? R version 4.0.2 (2020-06-22)
os?????? Windows 10 x64???????????? ?
?system?? x86_64, mingw32??????????? ?
?ui?????? RStudio??????????????????? ?
?language (EN)?????????????????????? ?
?collate? German_Germany.1252??????? ?
?ctype??? German_Germany.1252??????? ?
?tz?????? Europe/Berlin????????????? ?
?date???? 2020-08-13???????????????? ?
?
- Packages --------------------------------------------------------------------------------------------------------------------------
package???? * version date?????? lib source?????? ?
?assertthat??? 0.2.1?? 2019-03-21 [1] CRAN (R 4.0.2)
base64enc???? 0.1-3?? 2015-07-28 [1] CRAN (R 4.0.0)
cli?????????? 2.0.2?? 2020-02-28 [1] CRAN (R 4.0.2)
crayon??????? 1.3.4?? 2017-09-16 [1] CRAN (R 4.0.2)
fansi???????? 0.4.1?? 2020-01-08 [1] CRAN (R 4.0.2)
glue????????? 1.4.1?? 2020-05-13 [1] CRAN (R 4.0.2)
jsonlite????? 1.7.0?? 2020-06-25 [1] CRAN (R 4.0.2)
lattice?????? 0.20-41 2020-04-02 [1] CRAN (R 4.0.2)
magrittr????? 1.5???? 2014-11-22 [1] CRAN (R 4.0.2)
Matrix??????? 1.2-18? 2019-11-27 [1] CRAN (R 4.0.2)
rappdirs????? 0.3.1?? 2016-03-28 [1] CRAN (R 4.0.2)
Rcpp????????? 1.0.5?? 2020-07-06 [1] CRAN (R 4.0.2)
reticulate? * 1.16??? 2020-05-27 [1] CRAN (R 4.0.2)
rstudioapi??? 0.11??? 2020-02-07 [1] CRAN (R 4.0.2)
sessioninfo?? 1.1.1?? 2018-11-05 [1] CRAN (R 4.0.2)
tensorflow? * 2.2.0?? 2020-05-11 [1] CRAN (R 4.0.2)
tfruns??????? 1.4???? 2018-08-25 [1] CRAN (R 4.0.2)
whisker?????? 0.4???? 2019-08-28 [1] CRAN (R 4.0.2)
withr???????? 2.2.0?? 2020-04-20 [1] CRAN (R 4.0.2)



If I create an app in RStudio,? and then change into debug mode with "browser()", my R aborts.



I cannot see why? The problem did not exist as I usedR V3.6 3 days ago. For instance, as you can see in the following, my collougeuses still R V3.6 and the debug mode works well.

[[elided Yahoo spam]]

Thanks a lot

Cheers 
Mani









	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug 15 18:49:27 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 15 Aug 2020 09:49:27 -0700
Subject: [R] Shiny debug mode- reort a bug R version 4.0.2
In-Reply-To: <86344151.2613828.1597442915966@mail.yahoo.com>
References: <86344151.2613828.1597442915966.ref@mail.yahoo.com>
 <86344151.2613828.1597442915966@mail.yahoo.com>
Message-ID: <D1A3DB3A-AA1C-47CD-BE01-A2CA83D68F2F@dcn.davis.ca.us>

If you can provide a reproducible example that does not require RStudio to trigger the error then someone here might try to dig into this. But technically this mailing list is about the R language, not editors or contributed packages, so maybe not. RStudio injects various "helper" functions into R when it loads R that are most likely the source of this (mis-)behavior. Asking at the RStudio support forum seems more likely to get a useful answer sooner.

On August 14, 2020 3:08:35 PM PDT, Mani Solimani via R-help <r-help at r-project.org> wrote:
>
>DearR-help Community,
>
>?
>
>since Iupdated the R V.3:6 to R.V4.0.2 I have the following problem:
>It might be the problem of R, if the same pack worksunder V.3.6 and
>suddenly not in V.4.0.2.
>- Session info
>----------------------------------------------------------------------------------------------------------------------
>setting? value????????????????????? ?
>?version? R version 4.0.2 (2020-06-22)
>os?????? Windows 10 x64???????????? ?
>?system?? x86_64, mingw32??????????? ?
>?ui?????? RStudio??????????????????? ?
>?language (EN)?????????????????????? ?
>?collate? German_Germany.1252??????? ?
>?ctype??? German_Germany.1252??????? ?
>?tz?????? Europe/Berlin????????????? ?
>?date???? 2020-08-13???????????????? ?
>?
>- Packages
>--------------------------------------------------------------------------------------------------------------------------
>package???? * version date?????? lib source?????? ?
>?assertthat??? 0.2.1?? 2019-03-21 [1] CRAN (R 4.0.2)
>base64enc???? 0.1-3?? 2015-07-28 [1] CRAN (R 4.0.0)
>cli?????????? 2.0.2?? 2020-02-28 [1] CRAN (R 4.0.2)
>crayon??????? 1.3.4?? 2017-09-16 [1] CRAN (R 4.0.2)
>fansi???????? 0.4.1?? 2020-01-08 [1] CRAN (R 4.0.2)
>glue????????? 1.4.1?? 2020-05-13 [1] CRAN (R 4.0.2)
>jsonlite????? 1.7.0?? 2020-06-25 [1] CRAN (R 4.0.2)
>lattice?????? 0.20-41 2020-04-02 [1] CRAN (R 4.0.2)
>magrittr????? 1.5???? 2014-11-22 [1] CRAN (R 4.0.2)
>Matrix??????? 1.2-18? 2019-11-27 [1] CRAN (R 4.0.2)
>rappdirs????? 0.3.1?? 2016-03-28 [1] CRAN (R 4.0.2)
>Rcpp????????? 1.0.5?? 2020-07-06 [1] CRAN (R 4.0.2)
>reticulate? * 1.16??? 2020-05-27 [1] CRAN (R 4.0.2)
>rstudioapi??? 0.11??? 2020-02-07 [1] CRAN (R 4.0.2)
>sessioninfo?? 1.1.1?? 2018-11-05 [1] CRAN (R 4.0.2)
>tensorflow? * 2.2.0?? 2020-05-11 [1] CRAN (R 4.0.2)
>tfruns??????? 1.4???? 2018-08-25 [1] CRAN (R 4.0.2)
>whisker?????? 0.4???? 2019-08-28 [1] CRAN (R 4.0.2)
>withr???????? 2.2.0?? 2020-04-20 [1] CRAN (R 4.0.2)
>
>
>
>If I create an app in RStudio,? and then change into debug mode with
>"browser()", my R aborts.
>
>
>
>I cannot see why? The problem did not exist as I usedR V3.6 3 days ago.
>For instance, as you can see in the following, my collougeuses still R
>V3.6 and the debug mode works well.
>
>[[elided Yahoo spam]]
>
>Thanks a lot
>
>Cheers 
>Mani
>
>
>
>
>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From herd_dog @end|ng |rom cox@net  Sat Aug 15 23:25:08 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Sat, 15 Aug 2020 14:25:08 -0700
Subject: [R] Hot Air Balloon Weather Briefings
In-Reply-To: <CAGxFJbSjhApQxWQLoGdcXJ1RPiEnzRuO-=MwOwMj5Y6Pg3c7cQ@mail.gmail.com>
References: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
 <CAGxFJbSjhApQxWQLoGdcXJ1RPiEnzRuO-=MwOwMj5Y6Pg3c7cQ@mail.gmail.com>
Message-ID: <95D3923EE4184CF28C4F260E4F5A791C@OWNERPC>

Your suggestion worked like a charm.  Thank you

rle <- rle(TF$Speed)$lengths #Counts number of repetitions
phdf$rle <- rep(rle>9,rle) #TRUE is ten or more zeros.  FALSE if less than 10
phdf2 <- TF[rep(rle<10,rle),] #Move rows that are FALSE to new data file

From: Bert Gunter 
Sent: Friday, August 14, 2020 2:43 PM
To: Philip 
Cc: r-help 
Subject: Re: [R] Hot Air Balloon Weather Briefings

Well which is it?:
"I want to eliminate the data for minute 30 but keep the data for minute 31 because the balloon starts to move again at second 17. "
or
"It would be even better if I could delete the rows where there were ten consecutive zero speed entries such as from minute 30 second 17 to minute 31 second 11."

If you want to delete say data with >= 10 consecutive 0's, ?rle is your friend:

rle(phdf$Speed)
Run Length Encoding
  lengths: int [1:10] 15 1 1 1 1 1 1 1 1 1
  values : num [1:10] 0 0.402649 0.671081 1.588225 2.438261 2.706693 2.930386 3.310666 3.198819 3.422512

e.g.

> z <- rle(phdf$Speed)$lengths
## which gives:

> z
[1] 15  1  1  1  1  1  1  1  1  1
> rep(z>9,z)
[1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[11]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
[21] FALSE FALSE FALSE FALSE

##Thus:

> phdf[ rep(z<10, z), ]
   Minute Second    Speed
16     31     17 0.402649
17     31     23 0.671081
18     31     29 1.588225
19     31     35 2.438261
20     31     41 2.706693
21     31     47 2.930386
22     31     53 3.310666
23     31     59 3.198819
24     32      5 3.422512

But of course, this probably isn't what you meant. So further clarification is needed.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



On Fri, Aug 14, 2020 at 1:59 PM Philip <herd_dog at cox.net> wrote:

  I?m trying to compare National Weather Service Rapid Update Forecast (RAP) data to GPS breadcrumbs collected by a really clever Apple Phone Ap that lays down longitude, latitude, altitude, compass direction, and speed every six seconds.   Below is a small subset of the GPS data from another flight.  

  I want to delete the rows where the balloon does not move (Speed column) for a full minute assuming that it is sitting on the ground ? beginning of the flight, changing passengers, or waiting for the chase crew at the end of the flight.  for example, I want to eliminate the data for minute 30 but keep the data for minute 31 because the balloon starts to move again at second 17.  Any suggestions?  I?ve tried putzing around with multiple lags without success.

        Minute Second Speed 
        29 47 0 
        29 53 0 
        29 59 0 
        30 5 0 
        30 11 0 
        30 17 0 
        30 23 0 
        30 29 0 
        30 35 0 
        30 41 0 
        30 47 0 
        30 53 0 
        30 59 0 
        31 5 0 
        31 11 0 
        31 17 0.402649 
        31 23 0.671081 
        31 29 1.588225 
        31 35 2.438261 
        31 41 2.706693 
        31 47 2.930386 
        31 53 3.310666 
        31 59 3.198819 
        32 5 3.422512 


  It would be even better if I could delete the rows where there were ten consecutive zero speed entries such as from minute 30 second 17 to minute 31 second 11.

  Thanks,
  Philip Heinrich
          [[alternative HTML version deleted]]

  ______________________________________________
  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
  https://stat.ethz.ch/mailman/listinfo/r-help
  PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
  and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sun Aug 16 06:10:34 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 16 Aug 2020 16:10:34 +1200
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
Message-ID: <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>

On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>  It is a public benefit corporation

Seriously?

On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>  used to introduce people to R

Correction, it introduces people to a modified version of R.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug 16 07:32:25 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 15 Aug 2020 22:32:25 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
Message-ID: <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>

a) Read about it yourself. It is a legal definition.

b) Don't "correct" me with misinformation you are clearly inventing. RStudio the software does not "introduce people to a modified version of R." Each user has to opt in to that "modified" experience by explicitly installing each of the the many CRAN packages that various employees of RStudio have created and all of which can (to my knowledge) be used without installing the RStudio IDE at all. Yes, a bunch of them can be grabbed at once by installing the tidyverse package, but that is also a choice made by users and by instructors struggling to deal with students who have a hard time with Excel much less functional programming. But RStudio is an R IDE.

There are a lot of packages sponsored by RStudio that I find redundant and slow, but portraying the RStudio company or the IDE as inherently "not R" just because newbies like the IDE and the packages they sponsor, and who end up confusing R with RStudio even though they have to install both, is small-minded and biased.

On August 15, 2020 9:10:34 PM PDT, Abby Spurdle <spurdle.a at gmail.com> wrote:
>On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>  It is a public benefit corporation
>
>Seriously?
>
>On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>  used to introduce people to R
>
>Correction, it introduces people to a modified version of R.

-- 
Sent from my phone. Please excuse my brevity.


From |r@|nj @end|ng |rom gm@||@com  Sun Aug 16 20:20:34 2020
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Sun, 16 Aug 2020 19:20:34 +0100
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
Message-ID: <CAHrK514bb_tuy++EP=vx+1BKG6NG-bZXnBFkD_2qD1Yuhke11Q@mail.gmail.com>

On Sun 16 Aug 2020 at 06:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> a) Read about it yourself. It is a legal definition.
>
> b) Don't "correct" me with misinformation you are clearly inventing.
> RStudio the software does not "introduce people to a modified version of
> R." Each user has to opt in to that "modified" experience by explicitly
> installing each of the the many CRAN packages that various employees of
> RStudio have created and all of which can (to my knowledge) be used without
> installing the RStudio IDE at all. Yes, a bunch of them can be grabbed at
> once by installing the tidyverse package, but that is also a choice made by
> users and by instructors struggling to deal with students who have a hard
> time with Excel much less functional programming. But RStudio is an R IDE.
>
> There are a lot of packages sponsored by RStudio that I find redundant and
> slow, but portraying the RStudio company or the IDE as inherently "not R"
> just because newbies like the IDE and the packages they sponsor, and who
> end up confusing R with RStudio even though they have to install both, is
> small-minded and biased


To clarify:  If you use RStudio and do not install any of the RStudio
packages, R in RStudio is the same R as if you were running it from the
command line.  I would think that many users find command completion,
access to help files, project management Etc. useful. Nobody is asking
anyone to install the RStudio packages.  I do sometimes but not always and
have found them useful. Jeff is 100% correct.


>  On August 15, 2020 9:10:34 PM PDT, Abby Spurdle <spurdle.a at gmail.com>
> wrote:
> >On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us> wrote:
> >>  It is a public benefit corporation
> >
> >Seriously?
> >
> >On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us> wrote:
> >>  used to introduce people to R
> >
> >Correction, it introduces people to a modified version of R.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

	[[alternative HTML version deleted]]


From j@whct @end|ng |rom gm@||@com  Sun Aug 16 23:53:23 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Sun, 16 Aug 2020 16:53:23 -0500
Subject: [R] Plot math symbol with string and number
Message-ID: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>

Dear Helpers,

I would like to make plots with titles for different data sets and
different parameters. So a useful title should combine data name
and parameter for clarity. The following is a simplified code example with
two plots. The first title doesn't show sigma as a math symbol, while the
second one doesn't contain the s value as a numeric value - I could
manually change the s value, but when there are many different s values,
this is not a good solution. Thanks!

s <- 1
y <- rnorm(100)
plot(y, main=paste("data", "sigma=", s))
plot(y, main=expression(paste("data", sigma,"=", s)))

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 17 00:18:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 16 Aug 2020 15:18:04 -0700
Subject: [R] Plot math symbol with string and number
In-Reply-To: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
Message-ID: <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>

?plotmath

On Sun, Aug 16, 2020, 14:53 John Smith <jswhct at gmail.com> wrote:

> Dear Helpers,
>
> I would like to make plots with titles for different data sets and
> different parameters. So a useful title should combine data name
> and parameter for clarity. The following is a simplified code example with
> two plots. The first title doesn't show sigma as a math symbol, while the
> second one doesn't contain the s value as a numeric value - I could
> manually change the s value, but when there are many different s values,
> this is not a good solution. Thanks!
>
> s <- 1
> y <- rnorm(100)
> plot(y, main=paste("data", "sigma=", s))
> plot(y, main=expression(paste("data", sigma,"=", s)))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Aug 17 00:39:33 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 17 Aug 2020 10:39:33 +1200
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
Message-ID: <CAB8pepwK9APPKVmwTAGgR-vz5LjHSXy_qK4i0=OZp604gDc3hA@mail.gmail.com>

> a) Read about it yourself. It is a legal definition.

Not quite.
Your statement implies some sort of universalism, which is unrealistic.
Legal definitions vary from one legal system to the next.

I'm not an expert in US company/corporate law.
But as I understand it, the applicable laws vary from state to state.

It's unlikely that you or most readers will interpret the original
statement in a strict legal sense.
But rather, the term is used to imply something.

If the criteria is:
Sacrificing prophets (not just theirs, but their *holding/sibling
companies too*), for some public benefit(s)...

...then I would like to see evidence of this.

> b) Don't "correct" me with misinformation you are clearly inventing. RStudio the software does not "introduce people to a modified version of R."

Read this post:
https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html

My information is accurate, and RStudio does modify R, unless of
course something has changed...


From drj|m|emon @end|ng |rom gm@||@com  Sun Aug 16 00:41:15 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 16 Aug 2020 08:41:15 +1000
Subject: [R] Hot Air Balloon Weather Briefings
In-Reply-To: <BF6CE6BC13F845C5B2AE8C90464D2527@OWNERPC>
References: <E62A77F24CBD468E842A2735E4A641E7@OWNERPC>
 <CA+8X3fUG39u0kFBTpYbprL-H9oaQkjWwDDEHJgXdcQXK4JEx1w@mail.gmail.com>
 <BF6CE6BC13F845C5B2AE8C90464D2527@OWNERPC>
Message-ID: <CA+8X3fV+a3Tm9tDbqoMZR8e3J6cxgkw=Ew7XnOCa8r2=wuomaQ-7322@mail.gmail.com>


Hi Philip,
My fault for assuming that what worked for the sample data would work
for the entire data set. If you run the following code:

# read the file into a data frame
phdf<-read.csv("phdf.csv",stringsAsFactors=FALSE)
print(dim(phdf))
# create a logical variable for the subsetting step
keep<-rep(TRUE,length(phdf$Speed))
# this follows the conventional for(i in ...) syntax
# mini (minute index) is the name of the variable
# that is assigned the successive values of the
# unique values in the Minute column of phdf
# here I was lazy and only dealt with the sample data
# what I should have done was to create a column
# with minute values that don't repeat
phdf$hourmin<-phdf$Hour.Z * 60 + phdf$Minute
for(mini in unique(phdf$hourmin)) {
 # mark all minutes that are all zeros for deletion
 if(all(phdf$Speed[phdf$hourmin == mini] == 0))
  keep[phdf$hourmin == mini]<-FALSE
 # but now there is another condition
 # that I didn't notice (more laziness)
 # drop minutes containing ten consecutive zeros
 # I'll use a cheap trick for this
 # if the length of the run length encoding (rle)
 # of the Speed == 0 condition is less than three,
 # then there can't be a broken run of zeros
 if(length(rle(phdf$Speed[phdf$hourmin == mini])$length)<3)
  keep[phdf$hourmin == mini]<-FALSE
}
# now drop any rows for which has marked FALSE (note all caps!)
phdf<-phdf[keep,]
print(dim(phdf))

You will see that it has removed 67 rows. This is the same as if I had
only applied the first "all zeros"  condition, for there were no
unique minutes with 11 observations that contained a single non-zero
speed value. I can see that you are getting short runs of zero speeds
near the end. I assume that this is due to the balloon slowly bumping
along the ground. Often just looking at the data can suggest solutions
to problems like this.

Coincidentally I am about to email an old friend of mine whose sons
have dabbled in sending balloons high into the air and I will let them
know that they are not alone in performing this unusual practice. If I
haven't answered all your questions, feel free to let me know.

Jim

On Sun, Aug 16, 2020 at 4:39 AM Philip <herd_dog at cox.net> wrote:
>
> Thanks for getting back to me so quickly.
>
> I can get your code to run without errors but I'm not sure what it
> accomplishes since I still get 813 rows of data and 11 variables.  The
> entire file for a January flight is attached.  Also attached is a .jpg of a
> flight from a couple of years ago where my wife putzed back and forth across
> a road for over an hour by going up or down to catch different winds.  Stuff
> like this is one of the charms of the sport for those of us who are easily
> amused.
>
> keep <- rep(TRUE,length(phdf$Speed))             #813 repetitions of TRUE
> for(mini in unique(phdf$Minute))
>   if(all(phdf$Speed[phdf$Minute==mini]==0))
>   keep[phdf$Minute==mini]<-False                     #813 repetitions of
> TRUE in the keep data file.
>
> #Don't understand the assignment (<-) to FALSE
> phdf <- phdf[keep,] #Still have 813 rows of data.
>
> As you may know, we lay out the balloon and then blow cold air into the
> envelope with a gas powered fan.  When it is packed we "go hot".  Just
> before we turn on the pilot light and hit the burner we will turn on the
> tracking software which results in several minutes of no movement at the
> beginning of the flight.  This is what is happening between rows 2 and 70 of
> the attached spreadsheet.  You will also notice that the balloon slowly
> accelerates between rows 71 and 79 p to about 3.4 MPH just after liftoff.
> The no movement is what I want to eliminate.
>
> Can you let me know what I am missing.
>
> Two more thing.  I really not sure about the:
>
>     for(mini in unique(phdf$Minute))
>
> .....line of code.  I understand the unique function but not the "mini
> in..." part.  Is mini a function or just a label?   I understand stuff like:
>
>     for(i in 1:5) print(1:i)
>
> .....from the R base documentation but not real sure how it fits in here.
>
> And finally, I'm retired,  So I have plenty of time and determined to learn
> R.  But I keep running into things like the "mini in unique" command.  I
> have read four or five books and watched or read dozens of tutorials but
> there always seems to be another layer that alludes me.  Any suggestions?
>
> Philip


From roy@mende|@@ohn @end|ng |rom no@@@gov  Mon Aug 17 01:47:48 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Sun, 16 Aug 2020 16:47:48 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CAB8pepwK9APPKVmwTAGgR-vz5LjHSXy_qK4i0=OZp604gDc3hA@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAB8pepwK9APPKVmwTAGgR-vz5LjHSXy_qK4i0=OZp604gDc3hA@mail.gmail.com>
Message-ID: <E98B33C1-F289-4B29-91E9-B1761FF99966@noaa.gov>

May I suggest that this discussion is best left for another time and place.  Some people have very strong opinions about RStudio vis a vis R,  it has been discussed here before, shedding mostly heat and not a lot of light  (nor do I think anyone had their mind changed),  and worse the discussions have tended to move over to twitter,  where twitter mobs have gone after people whose views on this subject  didn't agree with theirs,  to the extent of digging up any transgression that person  ever committed and claiming that discredited anything they said about R and RStudio, rather than dealing with points made.    I have seen people who I have reason to believe are well-meaning,  decent people trying to improve R,  be tarred and feathered on this subject  (and this is on both sides of the discussion),   I can't believe that this helps improve R,  nor does it help anyone use R,  which is the main point of this mail-list.

Thanks,

-Roy
 
PS - Or we can start a discussion on the best editor to use - that should be good for a few flames!   :-)

> On Aug 16, 2020, at 3:39 PM, Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
>> a) Read about it yourself. It is a legal definition.
> 
> Not quite.
> Your statement implies some sort of universalism, which is unrealistic.
> Legal definitions vary from one legal system to the next.
> 
> I'm not an expert in US company/corporate law.
> But as I understand it, the applicable laws vary from state to state.
> 
> It's unlikely that you or most readers will interpret the original
> statement in a strict legal sense.
> But rather, the term is used to imply something.
> 
> If the criteria is:
> Sacrificing prophets (not just theirs, but their *holding/sibling
> companies too*), for some public benefit(s)...
> 
> ...then I would like to see evidence of this.
> 
>> b) Don't "correct" me with misinformation you are clearly inventing. RStudio the software does not "introduce people to a modified version of R."
> 
> Read this post:
> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
> 
> My information is accurate, and RStudio does modify R, unless of
> course something has changed...
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Aug 17 02:02:03 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 17 Aug 2020 00:02:03 +0000
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <E98B33C1-F289-4B29-91E9-B1761FF99966@noaa.gov>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAB8pepwK9APPKVmwTAGgR-vz5LjHSXy_qK4i0=OZp604gDc3hA@mail.gmail.com>
 <E98B33C1-F289-4B29-91E9-B1761FF99966@noaa.gov>
Message-ID: <B8D5A713-2E14-445F-957D-F21C91EB37AA@utoronto.ca>

I totally agree with Roy, thank you.

I hope that we can get the discussion back on OP's question (which is timely and very important, and actually not specific to the IDE).

The problem is that our possibilities to test user experience are usually limited. AFAIK students could be participating via their mobile phone... I want to be able to type code, have them read along, open help-pages, discuss the help pages, and plot things.

Zoom appears to send out 720p video. That is 1280 x 720 px. If I set my monitor from which I screen-share my R session to 1280px wide, does this mean I will be doing the best I can to reduce anti-aliasing artefacts and improve legibility? Or does it even matter?


Cheers,
Boris





> On 2020-08-17, at 09:47, Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
> 
> May I suggest that this discussion is best left for another time and place.  Some people have very strong opinions about RStudio vis a vis R,  it has been discussed here before, shedding mostly heat and not a lot of light  (nor do I think anyone had their mind changed),  and worse the discussions have tended to move over to twitter,  where twitter mobs have gone after people whose views on this subject  didn't agree with theirs,  to the extent of digging up any transgression that person  ever committed and claiming that discredited anything they said about R and RStudio, rather than dealing with points made.    I have seen people who I have reason to believe are well-meaning,  decent people trying to improve R,  be tarred and feathered on this subject  (and this is on both sides of the discussion),   I can't believe that this helps improve R,  nor does it help anyone use R,  which is the main point of this mail-list.
> 
> Thanks,
> 
> -Roy
> 
> PS - Or we can start a discussion on the best editor to use - that should be good for a few flames!   :-)
> 
>> On Aug 16, 2020, at 3:39 PM, Abby Spurdle <spurdle.a at gmail.com> wrote:
>> 
>>> a) Read about it yourself. It is a legal definition.
>> 
>> Not quite.
>> Your statement implies some sort of universalism, which is unrealistic.
>> Legal definitions vary from one legal system to the next.
>> 
>> I'm not an expert in US company/corporate law.
>> But as I understand it, the applicable laws vary from state to state.
>> 
>> It's unlikely that you or most readers will interpret the original
>> statement in a strict legal sense.
>> But rather, the term is used to imply something.
>> 
>> If the criteria is:
>> Sacrificing prophets (not just theirs, but their *holding/sibling
>> companies too*), for some public benefit(s)...
>> 
>> ...then I would like to see evidence of this.
>> 
>>> b) Don't "correct" me with misinformation you are clearly inventing. RStudio the software does not "introduce people to a modified version of R."
>> 
>> Read this post:
>> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
>> 
>> My information is accurate, and RStudio does modify R, unless of
>> course something has changed...
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 17 02:03:59 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 16 Aug 2020 17:03:59 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CAB8pepwK9APPKVmwTAGgR-vz5LjHSXy_qK4i0=OZp604gDc3hA@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAB8pepwK9APPKVmwTAGgR-vz5LjHSXy_qK4i0=OZp604gDc3hA@mail.gmail.com>
Message-ID: <CAGxFJbQ6N8mX3mu8N9_etA3Wv-DaSz+_NU9saemxO-NALXyq+A@mail.gmail.com>

Completely agree with Roy M. and do not wish to express any opinion, but
this typo was too precious to ignore:

"If the criteria is:
Sacrificing prophets (not just theirs, but their *holding/sibling
companies too*), for some public benefit(s)..."

Oh gosh, I hope no prophets are sacrificed ... though I can think of some
financial and political pundits who may deserve that fate ?
Still, let's keep it to chickens or the occasional goat... (with apologies
to any vegans out there).**

Bert Gunter

** and yes feel free to beat me up for this! **


On Sun, Aug 16, 2020 at 3:40 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> > a) Read about it yourself. It is a legal definition.
>
> Not quite.
> Your statement implies some sort of universalism, which is unrealistic.
> Legal definitions vary from one legal system to the next.
>
> I'm not an expert in US company/corporate law.
> But as I understand it, the applicable laws vary from state to state.
>
> It's unlikely that you or most readers will interpret the original
> statement in a strict legal sense.
> But rather, the term is used to imply something.
>
> If the criteria is:
> Sacrificing prophets (not just theirs, but their *holding/sibling
> companies too*), for some public benefit(s)...
>
> ...then I would like to see evidence of this.
>
> > b) Don't "correct" me with misinformation you are clearly inventing.
> RStudio the software does not "introduce people to a modified version of R."
>
> Read this post:
> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
>
> My information is accurate, and RStudio does modify R, unless of
> course something has changed...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 17 02:10:19 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 16 Aug 2020 17:10:19 -0700
Subject: [R] Plot math symbol with string and number
In-Reply-To: <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
Message-ID: <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>

Specifically, see the "how to combine "math" and numeric variables" in the
Examples therein.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Aug 16, 2020 at 3:18 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ?plotmath
>
> On Sun, Aug 16, 2020, 14:53 John Smith <jswhct at gmail.com> wrote:
>
>> Dear Helpers,
>>
>> I would like to make plots with titles for different data sets and
>> different parameters. So a useful title should combine data name
>> and parameter for clarity. The following is a simplified code example with
>> two plots. The first title doesn't show sigma as a math symbol, while the
>> second one doesn't contain the s value as a numeric value - I could
>> manually change the s value, but when there are many different s values,
>> this is not a good solution. Thanks!
>>
>> s <- 1
>> y <- rnorm(100)
>> plot(y, main=paste("data", "sigma=", s))
>> plot(y, main=expression(paste("data", sigma,"=", s)))
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Mon Aug 17 04:13:43 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 17 Aug 2020 04:13:43 +0200
Subject: [R] Plot math symbol with string and number
In-Reply-To: <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
Message-ID: <20200817021343.GB35031@posteo.no>

On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
| On Sun, Aug 16, 2020, 14:53 John wrote:
| | 
| | I would like to make plots with 
| | titles for different data sets and 
| | different parameters. The first 
| | title doesn't show sigma as a math 
| | symbol, while the second one 
| | doesn't contain the s value as a 
| | numeric value
| |
| | s <- 1
| | y <- rnorm(100)
| | plot(y, main=paste("data", "sigma=", s))
| | plot(y, main=expression(paste("data", sigma,"=", s)))
|
| ?plotmath

Dear John, read ?plotmath, it is good, I 
was not aware of its existence; then 
backquote s like so:

	plot(y, main=bquote(paste(
	  "data" ~~ widehat(aleph) 
	  %notin% .(s)^.(s))))

V

r


From @@mo|n@r @end|ng |rom @bcg|ob@|@net  Mon Aug 17 03:00:58 2020
From: @@mo|n@r @end|ng |rom @bcg|ob@|@net (Stephen P. Molnar)
Date: Sun, 16 Aug 2020 21:00:58 -0400
Subject: [R] Ggplot2 Line Problem
References: <5F39D6CA.7000602.ref@sbcglobal.net>
Message-ID: <5F39D6CA.7000602@sbcglobal.net>

I have cobbled together a short script to plot Covid-19 data.

setwd("~/Apps/Models/1-CoronaVirus")

library(tidyverse)
library(lubridate)

datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
datO[ ,1] <- ymd(datO[ ,1])

dfO <- tibble::as_tibble(data.frame(datO[ ,"date"],datO[ 
,"positive"],datO[ ,"negative"],datO[ ,"total"]))

dfO %>%
   ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
   geom_point(color = 'red', size = 0.025)+
   geom_point(y = datO[ ,"negative"], color = 'blue', size = 0.025)+
   geom_point(y = datO[ ,"total"], color = "green", size = 0.025)+
   theme(axis.text.x = element_text(angle=30, hjust=1))+
   theme_bw()+
   scale_y_continuous(limits = c(0,1750000))+
   labs(x = "Date", y = "Number of Tests")+
   ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
   theme(plot.title = element_text(hjust = 0.5))+
   scale_fill_discrete(name = "Test", labels = c("Positive", "Negative", 
"Total"))

Here is the plot:




but, if I want lines rather that the code (the aspplicable plines) uis:

ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
   geom_line(linetype = "solid",color = 'red')+
   geom_line(linetype = "dotdash",y = datO[ ,"negative"], color = 'blue')+
   geom_line(linetype = "twodash",y = datO[ ,"total"], color = "green")+




Now two of the plots are reversed. Google has not been a friend in 
finding a solution.

Help will be much appreciated.

Thanks in advance

-- 
Stephen P. Molnar, Ph.D.
www.molecular-modeling.net
614.312.7528 (c)
Skype:  smolnar1


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 17 04:04:44 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 16 Aug 2020 19:04:44 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <B8D5A713-2E14-445F-957D-F21C91EB37AA@utoronto.ca>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAB8pepwK9APPKVmwTAGgR-vz5LjHSXy_qK4i0=OZp604gDc3hA@mail.gmail.com>
 <E98B33C1-F289-4B29-91E9-B1761FF99966@noaa.gov>
 <B8D5A713-2E14-445F-957D-F21C91EB37AA@utoronto.ca>
Message-ID: <ACB5BD45-9983-4910-AE90-080A97C72D48@dcn.davis.ca.us>

In my experience pixel count is only indirectly related to legibility on a small screen, since they may have very high pixel count yet still be poorly readable with "normal" programming font sizes. If you really want to support that then increase font size. Slide presentations have similar design principles.

If you really want the multi-pane experience then I would advocate for not assuming the phones will be usable, but you can try the medium font everywhere approach and hope for the best.

On August 16, 2020 5:02:03 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>I totally agree with Roy, thank you.
>
>I hope that we can get the discussion back on OP's question (which is
>timely and very important, and actually not specific to the IDE).
>
>The problem is that our possibilities to test user experience are
>usually limited. AFAIK students could be participating via their mobile
>phone... I want to be able to type code, have them read along, open
>help-pages, discuss the help pages, and plot things.
>
>Zoom appears to send out 720p video. That is 1280 x 720 px. If I set my
>monitor from which I screen-share my R session to 1280px wide, does
>this mean I will be doing the best I can to reduce anti-aliasing
>artefacts and improve legibility? Or does it even matter?
>
>
>Cheers,
>Boris
>
>
>
>
>
>> On 2020-08-17, at 09:47, Roy Mendelssohn - NOAA Federal via R-help
><r-help at r-project.org> wrote:
>> 
>> May I suggest that this discussion is best left for another time and
>place.  Some people have very strong opinions about RStudio vis a vis
>R,  it has been discussed here before, shedding mostly heat and not a
>lot of light  (nor do I think anyone had their mind changed),  and
>worse the discussions have tended to move over to twitter,  where
>twitter mobs have gone after people whose views on this subject  didn't
>agree with theirs,  to the extent of digging up any transgression that
>person  ever committed and claiming that discredited anything they said
>about R and RStudio, rather than dealing with points made.    I have
>seen people who I have reason to believe are well-meaning,  decent
>people trying to improve R,  be tarred and feathered on this subject 
>(and this is on both sides of the discussion),   I can't believe that
>this helps improve R,  nor does it help anyone use R,  which is the
>main point of this mail-list.
>> 
>> Thanks,
>> 
>> -Roy
>> 
>> PS - Or we can start a discussion on the best editor to use - that
>should be good for a few flames!   :-)
>> 
>>> On Aug 16, 2020, at 3:39 PM, Abby Spurdle <spurdle.a at gmail.com>
>wrote:
>>> 
>>>> a) Read about it yourself. It is a legal definition.
>>> 
>>> Not quite.
>>> Your statement implies some sort of universalism, which is
>unrealistic.
>>> Legal definitions vary from one legal system to the next.
>>> 
>>> I'm not an expert in US company/corporate law.
>>> But as I understand it, the applicable laws vary from state to
>state.
>>> 
>>> It's unlikely that you or most readers will interpret the original
>>> statement in a strict legal sense.
>>> But rather, the term is used to imply something.
>>> 
>>> If the criteria is:
>>> Sacrificing prophets (not just theirs, but their *holding/sibling
>>> companies too*), for some public benefit(s)...
>>> 
>>> ...then I would like to see evidence of this.
>>> 
>>>> b) Don't "correct" me with misinformation you are clearly
>inventing. RStudio the software does not "introduce people to a
>modified version of R."
>>> 
>>> Read this post:
>>> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
>>> 
>>> My information is accurate, and RStudio does modify R, unless of
>>> course something has changed...
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S.
>Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected" 
>> "the arc of the moral universe is long, but it bends toward justice"
>-MLK Jr.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug 17 07:49:23 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 17 Aug 2020 06:49:23 +0100
Subject: [R] Ggplot2 Line Problem
In-Reply-To: <5F39D6CA.7000602@sbcglobal.net>
References: <5F39D6CA.7000602.ref@sbcglobal.net>
 <5F39D6CA.7000602@sbcglobal.net>
Message-ID: <2779b4a7-bcdb-f578-9123-89c1a4d85c33@sapo.pt>

Hello,

This type of problem is almost always a data reshaping problem.
ggplot graphics work better if the data is in the long format and you 
have 3 columns for counts, one column for each category. If you reformat 
from the current wide format to the long format you will have a date 
vector, a categorical variable and a counts variable.

In the code below just change geom_point to geom_line and the problem is 
solved.


library(tidyverse)
library(lubridate)

datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
datO[ ,1] <- ymd(datO[ ,1])

dfO <- tibble::as_tibble(data.frame(date = datO[ ,"date"],
                                     positive = datO[ ,"positive"],
                                     negative = datO[ ,"negative"],
                                     total = datO[ ,"total"]))

dfO %>%
   pivot_longer(
     cols = -date,
     names_to = "cases",
     values_to = "count"
   ) %>%
   mutate(cases = factor(cases, levels = c("positive", "negative", 
"total"))) %>%
   ggplot(aes(date, count, color = cases)) +
   geom_point() +
   scale_color_manual(name = "Test",
                      labels = c("Positive", "Negative", "Total"),
                      values = c("red", "blue", "green")) +
   ylim(0, 1750000) +
   labs(x = "Date", y = "Number of Tests")+
   ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
   theme_bw() +
   theme(axis.text.x = element_text(angle = 30, hjust = 1),
         plot.title = element_text(hjust = 0.5))



Hope this helps,

Rui Barradas


?s 02:00 de 17/08/20, Stephen P. Molnar escreveu:
> I have cobbled together a short script to plot Covid-19 data.
> 
> setwd("~/Apps/Models/1-CoronaVirus")
> 
> library(tidyverse)
> library(lubridate)
> 
> datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
> datO[ ,1] <- ymd(datO[ ,1])
> 
> dfO <- tibble::as_tibble(data.frame(datO[ ,"date"],datO[ 
> ,"positive"],datO[ ,"negative"],datO[ ,"total"]))
> 
> dfO %>%
>  ? ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
>  ? geom_point(color = 'red', size = 0.025)+
>  ? geom_point(y = datO[ ,"negative"], color = 'blue', size = 0.025)+
>  ? geom_point(y = datO[ ,"total"], color = "green", size = 0.025)+
>  ? theme(axis.text.x = element_text(angle=30, hjust=1))+
>  ? theme_bw()+
>  ? scale_y_continuous(limits = c(0,1750000))+
>  ? labs(x = "Date", y = "Number of Tests")+
>  ? ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
>  ? theme(plot.title = element_text(hjust = 0.5))+
>  ? scale_fill_discrete(name = "Test", labels = c("Positive", "Negative", 
> "Total"))
> 
> Here is the plot:
> 
> 
> 
> 
> but, if I want lines rather that the code (the aspplicable plines) uis:
> 
> ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
>  ? geom_line(linetype = "solid",color = 'red')+
>  ? geom_line(linetype = "dotdash",y = datO[ ,"negative"], color = 'blue')+
>  ? geom_line(linetype = "twodash",y = datO[ ,"total"], color = "green")+
> 
> 
> 
> 
> Now two of the plots are reversed. Google has not been a friend in 
> finding a solution.
> 
> Help will be much appreciated.
> 
> Thanks in advance
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug 17 07:56:42 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 17 Aug 2020 06:56:42 +0100
Subject: [R] Ggplot2 Line Problem
In-Reply-To: <2779b4a7-bcdb-f578-9123-89c1a4d85c33@sapo.pt>
References: <5F39D6CA.7000602.ref@sbcglobal.net>
 <5F39D6CA.7000602@sbcglobal.net>
 <2779b4a7-bcdb-f578-9123-89c1a4d85c33@sapo.pt>
Message-ID: <8ffe2875-d70a-9b4a-7ee7-343be936bd5a@sapo.pt>

Hello,

Sorry, I forgot you also want the line type changed.
Remove color and linetype from the initial call to ggplot and include 
aes(color = cases, linetype = cases) in geom_line. Then add a layer 
scale_linetype_manual with the same name and labels to merge it with the 
color legend.



dfO %>%
   pivot_longer(
     cols = -date,
     names_to = "cases",
     values_to = "count"
   ) %>%
   mutate(cases = factor(cases, levels = c("positive", "negative", 
"total"))) %>%
   ggplot(aes(date, count)) +
   #geom_point() +
   geom_line(aes(color = cases, linetype = cases)) +
   scale_color_manual(name = "Test",
                      labels = c("Positive", "Negative", "Total"),
                      values = c("red", "blue", "green")) +
   scale_linetype_manual(name = "Test",
                         labels = c("Positive", "Negative", "Total"),
                         values = c("solid", "dotdash", "twodash")) +
   ylim(0, 1750000) +
   labs(x = "Date", y = "Number of Tests")+
   ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
   theme_bw() +
   theme(axis.text.x = element_text(angle = 30, hjust = 1),
         plot.title = element_text(hjust = 0.5))


Hope this helps,

Rui Barradas

?s 06:49 de 17/08/20, Rui Barradas escreveu:
> Hello,
> 
> This type of problem is almost always a data reshaping problem.
> ggplot graphics work better if the data is in the long format and you 
> have 3 columns for counts, one column for each category. If you reformat 
> from the current wide format to the long format you will have a date 
> vector, a categorical variable and a counts variable.
> 
> In the code below just change geom_point to geom_line and the problem is 
> solved.
> 
> 
> library(tidyverse)
> library(lubridate)
> 
> datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
> datO[ ,1] <- ymd(datO[ ,1])
> 
> dfO <- tibble::as_tibble(data.frame(date = datO[ ,"date"],
>  ??????????????????????????????????? positive = datO[ ,"positive"],
>  ??????????????????????????????????? negative = datO[ ,"negative"],
>  ??????????????????????????????????? total = datO[ ,"total"]))
> 
> dfO %>%
>  ? pivot_longer(
>  ??? cols = -date,
>  ??? names_to = "cases",
>  ??? values_to = "count"
>  ? ) %>%
>  ? mutate(cases = factor(cases, levels = c("positive", "negative", 
> "total"))) %>%
>  ? ggplot(aes(date, count, color = cases)) +
>  ? geom_point() +
>  ? scale_color_manual(name = "Test",
>  ???????????????????? labels = c("Positive", "Negative", "Total"),
>  ???????????????????? values = c("red", "blue", "green")) +
>  ? ylim(0, 1750000) +
>  ? labs(x = "Date", y = "Number of Tests")+
>  ? ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
>  ? theme_bw() +
>  ? theme(axis.text.x = element_text(angle = 30, hjust = 1),
>  ??????? plot.title = element_text(hjust = 0.5))
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 02:00 de 17/08/20, Stephen P. Molnar escreveu:
>> I have cobbled together a short script to plot Covid-19 data.
>>
>> setwd("~/Apps/Models/1-CoronaVirus")
>>
>> library(tidyverse)
>> library(lubridate)
>>
>> datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
>> datO[ ,1] <- ymd(datO[ ,1])
>>
>> dfO <- tibble::as_tibble(data.frame(datO[ ,"date"],datO[ 
>> ,"positive"],datO[ ,"negative"],datO[ ,"total"]))
>>
>> dfO %>%
>> ?? ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
>> ?? geom_point(color = 'red', size = 0.025)+
>> ?? geom_point(y = datO[ ,"negative"], color = 'blue', size = 0.025)+
>> ?? geom_point(y = datO[ ,"total"], color = "green", size = 0.025)+
>> ?? theme(axis.text.x = element_text(angle=30, hjust=1))+
>> ?? theme_bw()+
>> ?? scale_y_continuous(limits = c(0,1750000))+
>> ?? labs(x = "Date", y = "Number of Tests")+
>> ?? ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
>> ?? theme(plot.title = element_text(hjust = 0.5))+
>> ?? scale_fill_discrete(name = "Test", labels = c("Positive", 
>> "Negative", "Total"))
>>
>> Here is the plot:
>>
>>
>>
>>
>> but, if I want lines rather that the code (the aspplicable plines) uis:
>>
>> ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
>> ?? geom_line(linetype = "solid",color = 'red')+
>> ?? geom_line(linetype = "dotdash",y = datO[ ,"negative"], color = 
>> 'blue')+
>> ?? geom_line(linetype = "twodash",y = datO[ ,"total"], color = "green")+
>>
>>
>>
>>
>> Now two of the plots are reversed. Google has not been a friend in 
>> finding a solution.
>>
>> Help will be much appreciated.
>>
>> Thanks in advance
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m|@ojpm @end|ng |rom gm@||@com  Mon Aug 17 09:41:06 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Mon, 17 Aug 2020 15:41:06 +0800
Subject: [R] Reorganize the data (dplyr or other packages?)
Message-ID: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>

Is there any quick way (dplyr?) to arrange the data
 date          down       uc       up
2019M08   0.01709827 0.2653882 0.7175136
2019M09   0.02094724 0.2265797 0.7524731
2019M10   0.01750911 0.2450030 0.7374879

to
 date          direction  percentage
2019M08   down 0.01709827
2019M09   down 0.02094724
2019M10   down 0.01750911
2019M08   uc 0.2653882
2019M09   uc 0.2265797
2019M10   uc 0.2450030
2019M08   up  0.7175136
2019M09   up 0.7524731
2019M10   up 0.7374879

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Aug 17 09:49:02 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 17 Aug 2020 09:49:02 +0200
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
Message-ID: <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>

You are looking for tidyr::pivot_longer()

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 17 aug. 2020 om 09:35 schreef John <miaojpm at gmail.com>:

> Is there any quick way (dplyr?) to arrange the data
>  date          down       uc       up
> 2019M08   0.01709827 0.2653882 0.7175136
> 2019M09   0.02094724 0.2265797 0.7524731
> 2019M10   0.01750911 0.2450030 0.7374879
>
> to
>  date          direction  percentage
> 2019M08   down 0.01709827
> 2019M09   down 0.02094724
> 2019M10   down 0.01750911
> 2019M08   uc 0.2653882
> 2019M09   uc 0.2265797
> 2019M10   uc 0.2450030
> 2019M08   up  0.7175136
> 2019M09   up 0.7524731
> 2019M10   up 0.7374879
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Aug 17 09:52:27 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 17 Aug 2020 10:52:27 +0300
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
Message-ID: <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>

Alternatively, melt() from the reshape2 package.

library(reshape2)
melt(x,id.vars="date",measure.vars=c("down","uc","up"),variable.name
="direction",value.name="percentage")

HTH,
Eric


On Mon, Aug 17, 2020 at 10:49 AM Thierry Onkelinx via R-help <
r-help at r-project.org> wrote:

> You are looking for tidyr::pivot_longer()
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 17 aug. 2020 om 09:35 schreef John <miaojpm at gmail.com>:
>
> > Is there any quick way (dplyr?) to arrange the data
> >  date          down       uc       up
> > 2019M08   0.01709827 0.2653882 0.7175136
> > 2019M09   0.02094724 0.2265797 0.7524731
> > 2019M10   0.01750911 0.2450030 0.7374879
> >
> > to
> >  date          direction  percentage
> > 2019M08   down 0.01709827
> > 2019M09   down 0.02094724
> > 2019M10   down 0.01750911
> > 2019M08   uc 0.2653882
> > 2019M09   uc 0.2265797
> > 2019M10   uc 0.2450030
> > 2019M08   up  0.7175136
> > 2019M09   up 0.7524731
> > 2019M10   up 0.7374879
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Aug 17 10:23:37 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 17 Aug 2020 10:23:37 +0200
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
Message-ID: <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>

Yes. However reshape2 is a retired package. The author recommends to use
his new package tidyr.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 17 aug. 2020 om 09:52 schreef Eric Berger <ericjberger at gmail.com>:

> Alternatively, melt() from the reshape2 package.
>
> library(reshape2)
> melt(x,id.vars="date",measure.vars=c("down","uc","up"),variable.name
> ="direction",value.name="percentage")
>
> HTH,
> Eric
>
>
> On Mon, Aug 17, 2020 at 10:49 AM Thierry Onkelinx via R-help <
> r-help at r-project.org> wrote:
>
>> You are looking for tidyr::pivot_longer()
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 17 aug. 2020 om 09:35 schreef John <miaojpm at gmail.com>:
>>
>> > Is there any quick way (dplyr?) to arrange the data
>> >  date          down       uc       up
>> > 2019M08   0.01709827 0.2653882 0.7175136
>> > 2019M09   0.02094724 0.2265797 0.7524731
>> > 2019M10   0.01750911 0.2450030 0.7374879
>> >
>> > to
>> >  date          direction  percentage
>> > 2019M08   down 0.01709827
>> > 2019M09   down 0.02094724
>> > 2019M10   down 0.01750911
>> > 2019M08   uc 0.2653882
>> > 2019M09   uc 0.2265797
>> > 2019M10   uc 0.2450030
>> > 2019M08   up  0.7175136
>> > 2019M09   up 0.7524731
>> > 2019M10   up 0.7374879
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Mon Aug 17 10:54:03 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Mon, 17 Aug 2020 16:54:03 +0800
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
 <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
Message-ID: <CABcx46A9WB9SxzFQA98bmbbgR-i4wSbLK+7f9+i-YoqTfJ9M6w@mail.gmail.com>

Thanks!

Thierry Onkelinx <thierry.onkelinx at inbo.be> ? 2020?8?17? ?? ??4:23???

> Yes. However reshape2 is a retired package. The author recommends to use
> his new package tidyr.
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 17 aug. 2020 om 09:52 schreef Eric Berger <ericjberger at gmail.com>:
>
>> Alternatively, melt() from the reshape2 package.
>>
>> library(reshape2)
>> melt(x,id.vars="date",measure.vars=c("down","uc","up"),variable.name
>> ="direction",value.name="percentage")
>>
>> HTH,
>> Eric
>>
>>
>> On Mon, Aug 17, 2020 at 10:49 AM Thierry Onkelinx via R-help <
>> r-help at r-project.org> wrote:
>>
>>> You are looking for tidyr::pivot_longer()
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND
>>> FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 17 aug. 2020 om 09:35 schreef John <miaojpm at gmail.com>:
>>>
>>> > Is there any quick way (dplyr?) to arrange the data
>>> >  date          down       uc       up
>>> > 2019M08   0.01709827 0.2653882 0.7175136
>>> > 2019M09   0.02094724 0.2265797 0.7524731
>>> > 2019M10   0.01750911 0.2450030 0.7374879
>>> >
>>> > to
>>> >  date          direction  percentage
>>> > 2019M08   down 0.01709827
>>> > 2019M09   down 0.02094724
>>> > 2019M10   down 0.01750911
>>> > 2019M08   uc 0.2653882
>>> > 2019M09   uc 0.2265797
>>> > 2019M10   uc 0.2450030
>>> > 2019M08   up  0.7175136
>>> > 2019M09   up 0.7524731
>>> > 2019M10   up 0.7374879
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Aug 17 10:52:56 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 17 Aug 2020 11:52:56 +0300
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
 <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
Message-ID: <CAGgJW76q69pxpHyBfkoCWBPNL1fjwmN2G5b0YwAPxsDUXn7DtQ@mail.gmail.com>

Thanks for this information Thierry. I was not aware.
The author of the packages is Hadley Wickham. He writes on Github that he
does plan to make changes necessary to keep the package available on CRAN.



On Mon, Aug 17, 2020 at 11:23 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Yes. However reshape2 is a retired package. The author recommends to use
> his new package tidyr.
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 17 aug. 2020 om 09:52 schreef Eric Berger <ericjberger at gmail.com>:
>
>> Alternatively, melt() from the reshape2 package.
>>
>> library(reshape2)
>> melt(x,id.vars="date",measure.vars=c("down","uc","up"),variable.name
>> ="direction",value.name="percentage")
>>
>> HTH,
>> Eric
>>
>>
>> On Mon, Aug 17, 2020 at 10:49 AM Thierry Onkelinx via R-help <
>> r-help at r-project.org> wrote:
>>
>>> You are looking for tidyr::pivot_longer()
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND
>>> FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 17 aug. 2020 om 09:35 schreef John <miaojpm at gmail.com>:
>>>
>>> > Is there any quick way (dplyr?) to arrange the data
>>> >  date          down       uc       up
>>> > 2019M08   0.01709827 0.2653882 0.7175136
>>> > 2019M09   0.02094724 0.2265797 0.7524731
>>> > 2019M10   0.01750911 0.2450030 0.7374879
>>> >
>>> > to
>>> >  date          direction  percentage
>>> > 2019M08   down 0.01709827
>>> > 2019M09   down 0.02094724
>>> > 2019M10   down 0.01750911
>>> > 2019M08   uc 0.2653882
>>> > 2019M09   uc 0.2265797
>>> > 2019M10   uc 0.2450030
>>> > 2019M08   up  0.7175136
>>> > 2019M09   up 0.7524731
>>> > 2019M10   up 0.7374879
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From @|dot|@23 @end|ng |rom buckeyem@||@o@u@edu  Mon Aug 17 03:37:32 2020
From: @|dot|@23 @end|ng |rom buckeyem@||@o@u@edu (Sidoti, Salvatore A.)
Date: Mon, 17 Aug 2020 01:37:32 +0000
Subject: [R] Data With Ordinal Responses: Calculate ICC & Assessing Model Fit
Message-ID: <DM5PR0101MB30822AB381E6AB6CFCC4F64FAB5F0@DM5PR0101MB3082.prod.exchangelabs.com>

To begin with, I'm not a fan of cross-posting. However, I posted my question on Stack Exchange more than two weeks ago, but I have yet to receive a sufficient answer:

https://stats.stackexchange.com/questions/479600/data-with-ordinal-responses-calculate-icc-assessing-model-fit
 
Here's what I've learned since then (hopefully):
 
1) ICC of a CLMM:
Computed like this:
(variance of the random effect) / (variance of the random effect + 1)
If this is correct, I would love to see a reference/citation for it.
 
2) 95% Confidence Interval for the ICC from a CLMM Model
To my current understanding, a confidence interval for an ICC is only obtainable via simulation. I've conducted simulations with GLMM model objects ('lme4' package) and the bootMer() function. Unfortunately, bootMer() will not accept a CLMM model ('ordinal' package).
 
3) Model Fit of a CLMM
Assuming that the model converges without incident, the model summary includes a condition number of the Hessian ('cond.H'). This value should be below 10^4 for a "good fit". This is straightforward enough. However, I am not as sure about the value for 'max.grad', which needs to be "well below 1". The question is, to what magnitude should max.grad < 1 for a decent model fit? My reference is linked below (Christensen, 2019), but it does not elaborate further on this point:
 
https://documentcloud.adobe.com/link/track?uri=urn:aaid:scds:US:b6a61fe2-b851-49ce-b8b1-cd760d290636
 
3) Effect Size of a CLMM
The random variable's effect is determined by a comparison between the full model to a model with only the fixed effects via the anova() function. I found this information on the 'rcompanion' package website:
 
https://rcompanion.org/handbook/G_12.html
 
The output of this particular anova() will include a value named 'LR.stat', the likelihood ratio statistic. The LR.stat is twice the difference of each log-likelihood (absolute value) of the respective models. Is LR.stat the mixed-model version of an "effect size"? If so, how does one determine if the effect is small, large, in-between, etc?

Cheers,
Sal

Salvatore A. Sidoti
PhD Candidate
Behavioral Ecology
The Ohio State University


From m|@ojpm @end|ng |rom gm@||@com  Mon Aug 17 10:57:59 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Mon, 17 Aug 2020 16:57:59 +0800
Subject: [R] Error message from "patternbar_s"
Message-ID: <CABcx46AVgmkigmwfuGc_Gsj+Xrh5iOm_YWGitbMBkyUJAFvQ4Q@mail.gmail.com>

Hi ,

   I got warning message from the following code and the graph did not show
as expected; I don't have the date on the x-axis and I do not have legend.
Graph is attached.
   How can I fix it?
******
x<-df_c_m$date
y<-df_c_m$percentage
group <- df_c_m$direction
patternbar_s(df_c_m, x,y, group, xlab='', ylab='%', label.size=3,
pattern.type=c( 'hlines', 'vlines','bricks'), pattern.line.size=c(5, 5,
5),frame.size=1,
             #,background.color=c('grey', 'chartreuse3',  'bisque')
             pixel=16, density=c(18, 72, 54),frame.color='black',
             legend.type='h', legend.h=12, legend.y.pos=0.49,
legend.pixel=6, legend.w=0.275, legend.x.pos=1.05,
             legend.label=c("up", "uc", "dn" ),
 bar.width=0.8)+scale_y_continuous(limits = c(0, 100))+ggtitle('')
******

> df_c_m
      date direction percentage
1  2019M08       up1  71.751356
2  2019M09       up1  75.247309
3  2019M10       up1  73.748786
4  2019M11       up1  72.412511
5  2019M12       up1  72.391628
6  2020M01       up1  73.431773
7  2020M02       up1  72.093799
8  2020M03       up1  65.852532
9  2020M04       up1  53.943831
10 2020M05       up1  49.841939
11 2020M06       up1  64.906832
12 2020M07       up1  64.419087
13 2019M08       uc1  26.538817
14 2019M09       uc1  22.657967
15 2019M10       uc1  24.500303
16 2019M11       uc1  25.870263
17 2019M12       uc1  25.969088
18 2020M01       uc1  25.248130
19 2020M02       uc1  25.272400
20 2020M03       uc1  27.652675
21 2020M04       uc1  33.452643
22 2020M05       uc1  41.622761
23 2020M06       uc1  31.469979
24 2020M07       uc1  32.572614
25 2019M08       dn1   1.709827
26 2019M09       dn1   2.094724
27 2019M10       dn1   1.750911
28 2019M11       dn1   1.717225
29 2019M12       dn1   1.639284
30 2020M01       dn1   1.320097
31 2020M02       dn1   2.633801
32 2020M03       dn1   6.494793
33 2020M04       dn1  12.603527
34 2020M05       dn1   8.535300
35 2020M06       dn1   3.623188
36 2020M07       dn1   3.008299
> x
 [1] "2019M08" "2019M09" "2019M10" "2019M11" "2019M12" "2020M01" "2020M02"
 [8] "2020M03" "2020M04" "2020M05" "2020M06" "2020M07" "2019M08" "2019M09"
[15] "2019M10" "2019M11" "2019M12" "2020M01" "2020M02" "2020M03" "2020M04"
[22] "2020M05" "2020M06" "2020M07" "2019M08" "2019M09" "2019M10" "2019M11"
[29] "2019M12" "2020M01" "2020M02" "2020M03" "2020M04" "2020M05" "2020M06"
[36] "2020M07"
> y
 [1] 71.751356 75.247309 73.748786 72.412511 72.391628 73.431773 72.093799
 [8] 65.852532 53.943831 49.841939 64.906832 64.419087 26.538817 22.657967
[15] 24.500303 25.870263 25.969088 25.248130 25.272400 27.652675 33.452643
[22] 41.622761 31.469979 32.572614  1.709827  2.094724  1.750911  1.717225
[29]  1.639284  1.320097  2.633801  6.494793 12.603527  8.535300  3.623188
[36]  3.008299
> group
 [1] up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 uc1 uc1 uc1 uc1 uc1
uc1 uc1
[20] uc1 uc1 uc1 uc1 uc1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1
Levels: up1 uc1 dn1

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot_pattern.pdf
Type: application/pdf
Size: 183476 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200817/3e0bee55/attachment.pdf>

From @@mo|n@r @end|ng |rom @bcg|ob@|@net  Mon Aug 17 13:42:19 2020
From: @@mo|n@r @end|ng |rom @bcg|ob@|@net (Stephen P. Molnar)
Date: Mon, 17 Aug 2020 07:42:19 -0400
Subject: [R] Ggplot2 Line Problem
In-Reply-To: <2779b4a7-bcdb-f578-9123-89c1a4d85c33@sapo.pt>
References: <5F39D6CA.7000602.ref@sbcglobal.net>
 <5F39D6CA.7000602@sbcglobal.net>
 <2779b4a7-bcdb-f578-9123-89c1a4d85c33@sapo.pt>
Message-ID: <5F3A6D1B.304@sbcglobal.net>

Many thanks. That solved the problem.

On 08/17/2020 01:49 AM, Rui Barradas wrote:
> Hello,
>
> This type of problem is almost always a data reshaping problem.
> ggplot graphics work better if the data is in the long format and you 
> have 3 columns for counts, one column for each category. If you 
> reformat from the current wide format to the long format you will have 
> a date vector, a categorical variable and a counts variable.
>
> In the code below just change geom_point to geom_line and the problem 
> is solved.
>
>
> library(tidyverse)
> library(lubridate)
>
> datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
> datO[ ,1] <- ymd(datO[ ,1])
>
> dfO <- tibble::as_tibble(data.frame(date = datO[ ,"date"],
>                                     positive = datO[ ,"positive"],
>                                     negative = datO[ ,"negative"],
>                                     total = datO[ ,"total"]))
>
> dfO %>%
>   pivot_longer(
>     cols = -date,
>     names_to = "cases",
>     values_to = "count"
>   ) %>%
>   mutate(cases = factor(cases, levels = c("positive", "negative", 
> "total"))) %>%
>   ggplot(aes(date, count, color = cases)) +
>   geom_point() +
>   scale_color_manual(name = "Test",
>                      labels = c("Positive", "Negative", "Total"),
>                      values = c("red", "blue", "green")) +
>   ylim(0, 1750000) +
>   labs(x = "Date", y = "Number of Tests")+
>   ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
>   theme_bw() +
>   theme(axis.text.x = element_text(angle = 30, hjust = 1),
>         plot.title = element_text(hjust = 0.5))
>
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ??s 02:00 de 17/08/20, Stephen P. Molnar escreveu:
>> I have cobbled together a short script to plot Covid-19 data.
>>
>> setwd("~/Apps/Models/1-CoronaVirus")
>>
>> library(tidyverse)
>> library(lubridate)
>>
>> datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
>> datO[ ,1] <- ymd(datO[ ,1])
>>
>> dfO <- tibble::as_tibble(data.frame(datO[ ,"date"],datO[ 
>> ,"positive"],datO[ ,"negative"],datO[ ,"total"]))
>>
>> dfO %>%
>>    ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
>>    geom_point(color = 'red', size = 0.025)+
>>    geom_point(y = datO[ ,"negative"], color = 'blue', size = 0.025)+
>>    geom_point(y = datO[ ,"total"], color = "green", size = 0.025)+
>>    theme(axis.text.x = element_text(angle=30, hjust=1))+
>>    theme_bw()+
>>    scale_y_continuous(limits = c(0,1750000))+
>>    labs(x = "Date", y = "Number of Tests")+
>>    ggtitle("COVID-19 Tests in Ohio \n (8/15/20)")+
>>    theme(plot.title = element_text(hjust = 0.5))+
>>    scale_fill_discrete(name = "Test", labels = c("Positive", 
>> "Negative", "Total"))
>>
>> Here is the plot:
>>
>>
>>
>>
>> but, if I want lines rather that the code (the aspplicable plines) uis:
>>
>> ggplot(aes(x = datO[ ,"date"],y = datO[ ,"positive"]))+
>>    geom_line(linetype = "solid",color = 'red')+
>>    geom_line(linetype = "dotdash",y = datO[ ,"negative"], color = 
>> 'blue')+
>>    geom_line(linetype = "twodash",y = datO[ ,"total"], color = "green")+
>>
>>
>>
>>
>> Now two of the plots are reversed. Google has not been a friend in 
>> finding a solution.
>>
>> Help will be much appreciated.
>>
>> Thanks in advance
>>
>

-- 
Stephen P. Molnar, Ph.D.
www.molecular-modeling.net
614.312.7528 (c)
Skype:  smolnar1


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Aug 17 13:54:25 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 17 Aug 2020 13:54:25 +0200
Subject: [R] install.packages() R vs RStudio
Message-ID: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>

Dear useRs,

Following the recent activity on the list, I have been made aware of
this discussion:
https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html

I used to install all packages in R, but for simplicity (I use RStudio
for all purposes), I now do it in RStudio. Now I am left wondering
whether I should continue installing packages directly from RStudio or
whether I should revert to using R.

My goal is not to flare a debate over whether RStudio is better or worse
than R, but rather simply to understand whether there are differences
and potential issues (that could lead to problems in code) about
installing packages through RStudio.

In general, it would be nice to have a list of the differences in
behavior between R and RStudio, but I believe this should come from the
RStudio side of things.

Thank you all for the insights.
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From h@w|ckh@m @end|ng |rom gm@||@com  Mon Aug 17 14:46:19 2020
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Mon, 17 Aug 2020 07:46:19 -0500
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CAGgJW76q69pxpHyBfkoCWBPNL1fjwmN2G5b0YwAPxsDUXn7DtQ@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
 <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
 <CAGgJW76q69pxpHyBfkoCWBPNL1fjwmN2G5b0YwAPxsDUXn7DtQ@mail.gmail.com>
Message-ID: <CABdHhvEqtL7J1qLXRUjd-P9nf2bFzYZJvKah=MwyKt7SGWq3ZA@mail.gmail.com>

We previously used the term retired to suggest that the package is
taking it easy and relaxing, but isn't dead. This causes a lot of
confusion so we now call this state "superseded" ? we'll continue to
keep reshape2 (and reshape!) on CRAN, but they won't receive any new
features, and we believe that there are now better approaches to
solving the same problem.

Hadley

On Mon, Aug 17, 2020 at 3:58 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Thanks for this information Thierry. I was not aware.
> The author of the packages is Hadley Wickham. He writes on Github that he
> does plan to make changes necessary to keep the package available on CRAN.
>
>
>
> On Mon, Aug 17, 2020 at 11:23 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> > Yes. However reshape2 is a retired package. The author recommends to use
> > his new package tidyr.
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be
> >
> >
> > ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of data.
> > ~ John Tukey
> >
> > ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op ma 17 aug. 2020 om 09:52 schreef Eric Berger <ericjberger at gmail.com>:
> >
> >> Alternatively, melt() from the reshape2 package.
> >>
> >> library(reshape2)
> >> melt(x,id.vars="date",measure.vars=c("down","uc","up"),variable.name
> >> ="direction",value.name="percentage")
> >>
> >> HTH,
> >> Eric
> >>
> >>
> >> On Mon, Aug 17, 2020 at 10:49 AM Thierry Onkelinx via R-help <
> >> r-help at r-project.org> wrote:
> >>
> >>> You are looking for tidyr::pivot_longer()
> >>>
> >>> Best regards,
> >>>
> >>> ir. Thierry Onkelinx
> >>> Statisticus / Statistician
> >>>
> >>> Vlaamse Overheid / Government of Flanders
> >>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> >>> AND
> >>> FOREST
> >>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >>> thierry.onkelinx at inbo.be
> >>> Havenlaan 88 bus 73, 1000 Brussel
> >>> www.inbo.be
> >>>
> >>>
> >>> ///////////////////////////////////////////////////////////////////////////////////////////
> >>> To call in the statistician after the experiment is done may be no more
> >>> than asking him to perform a post-mortem examination: he may be able to
> >>> say
> >>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>> The plural of anecdote is not data. ~ Roger Brinner
> >>> The combination of some data and an aching desire for an answer does not
> >>> ensure that a reasonable answer can be extracted from a given body of
> >>> data.
> >>> ~ John Tukey
> >>>
> >>> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>
> >>> <https://www.inbo.be>
> >>>
> >>>
> >>> Op ma 17 aug. 2020 om 09:35 schreef John <miaojpm at gmail.com>:
> >>>
> >>> > Is there any quick way (dplyr?) to arrange the data
> >>> >  date          down       uc       up
> >>> > 2019M08   0.01709827 0.2653882 0.7175136
> >>> > 2019M09   0.02094724 0.2265797 0.7524731
> >>> > 2019M10   0.01750911 0.2450030 0.7374879
> >>> >
> >>> > to
> >>> >  date          direction  percentage
> >>> > 2019M08   down 0.01709827
> >>> > 2019M09   down 0.02094724
> >>> > 2019M10   down 0.01750911
> >>> > 2019M08   uc 0.2653882
> >>> > 2019M09   uc 0.2265797
> >>> > 2019M10   uc 0.2450030
> >>> > 2019M08   up  0.7175136
> >>> > 2019M09   up 0.7524731
> >>> > 2019M10   up 0.7374879
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide
> >>> > http://www.R-project.org/posting-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>> >
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 17 15:03:34 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 17 Aug 2020 09:03:34 -0400
Subject: [R] install.packages() R vs RStudio
In-Reply-To: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>
References: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>
Message-ID: <0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>

On 17/08/2020 7:54 a.m., Ivan Calandra wrote:
> Dear useRs,
> 
> Following the recent activity on the list, I have been made aware of
> this discussion:
> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
> 
> I used to install all packages in R, but for simplicity (I use RStudio
> for all purposes), I now do it in RStudio. Now I am left wondering
> whether I should continue installing packages directly from RStudio or
> whether I should revert to using R.
> 
> My goal is not to flare a debate over whether RStudio is better or worse
> than R, but rather simply to understand whether there are differences
> and potential issues (that could lead to problems in code) about
> installing packages through RStudio.
> 
> In general, it would be nice to have a list of the differences in
> behavior between R and RStudio, but I believe this should come from the
> RStudio side of things.
> 
> Thank you all for the insights.
> Ivan
> 

To see the install.packages function that RStudio installs, just type 
its name:

 > install.packages
function (...)
.rs.callAs(name, hook, original, ...)
<environment: 0x7fe7dc5b65b0>

You can debug it to see the other variables:

 > debug(install.packages)
 > install.packages("abind")
debugging in: install.packages("abind")
debug: .rs.callAs(name, hook, original, ...)
Browse[2]> name
[1] "install.packages"
Browse[2]> hook
function (original, pkgs, lib, repos = getOption("repos"), ...)
{
     if (missing(pkgs))
         return(utils::install.packages())
     if (!.Call("rs_canInstallPackages", PACKAGE = "(embedding)")) {
         stop("Package installation is disabled in this version of 
RStudio",
             call. = FALSE)
     }
     packratMode <- !is.na(Sys.getenv("R_PACKRAT_MODE", unset = NA))
     if (!is.null(repos) && !packratMode && 
.rs.loadedPackageUpdates(pkgs)) {
         installCmd <- NULL
         for (i in seq_along(sys.calls())) {
             if (identical(deparse(sys.call(i)[[1]]), "install.packages")) {
                 installCmd <- gsub("\\s+", " ", 
paste(deparse(sys.call(i)),
                   collapse = " "))
                 break
             }
         }
         .rs.enqueLoadedPackageUpdates(installCmd)
         stop("Updating loaded packages")
     }
     .rs.addRToolsToPath()
     on.exit({
         .rs.updatePackageEvents()
         .Call("rs_packageLibraryMutated", PACKAGE = "(embedding)")
         .rs.restorePreviousPath()
     })
     original(pkgs, lib, repos, ...)
}
<environment: 0x7fe7db925588>

The .rs.callAs function just substitutes the call to "hook" for the call 
to the original install.packages.  So you can see that they do the 
following:
  - they allow a way to disable installing packages,
  - they support "packrat" (a system for installing particular versions 
of packages, see https://github.com/rstudio/packrat),
  - they add RTools to the path (presumably only on Windows)
  - they call the original function, and at the end update internal 
variables so they can show the library in the Packages pane.

So there is no reason not to do it in R.

By the way, saying that this is a "modified version of R" is like saying 
every single user who defines a variable creates a modified version of 
R.  If you type "x" in the plain R console, you see "Error: object 'x' 
not found".  If you "modify" R by assigning a value to x, you'll see 
something different.  Very scary!

Duncan Murdoch


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Aug 17 15:16:32 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 17 Aug 2020 15:16:32 +0200
Subject: [R] install.packages() R vs RStudio
In-Reply-To: <0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>
References: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>
 <0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>
Message-ID: <96719d80-f479-969b-dd00-58346e747561@rgzm.de>

Thank you Duncan for the very detailed and clear answer!

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 17/08/2020 15:03, Duncan Murdoch wrote:
> On 17/08/2020 7:54 a.m., Ivan Calandra wrote:
>> Dear useRs,
>>
>> Following the recent activity on the list, I have been made aware of
>> this discussion:
>> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
>>
>> I used to install all packages in R, but for simplicity (I use RStudio
>> for all purposes), I now do it in RStudio. Now I am left wondering
>> whether I should continue installing packages directly from RStudio or
>> whether I should revert to using R.
>>
>> My goal is not to flare a debate over whether RStudio is better or worse
>> than R, but rather simply to understand whether there are differences
>> and potential issues (that could lead to problems in code) about
>> installing packages through RStudio.
>>
>> In general, it would be nice to have a list of the differences in
>> behavior between R and RStudio, but I believe this should come from the
>> RStudio side of things.
>>
>> Thank you all for the insights.
>> Ivan
>>
>
> To see the install.packages function that RStudio installs, just type
> its name:
>
> > install.packages
> function (...)
> .rs.callAs(name, hook, original, ...)
> <environment: 0x7fe7dc5b65b0>
>
> You can debug it to see the other variables:
>
> > debug(install.packages)
> > install.packages("abind")
> debugging in: install.packages("abind")
> debug: .rs.callAs(name, hook, original, ...)
> Browse[2]> name
> [1] "install.packages"
> Browse[2]> hook
> function (original, pkgs, lib, repos = getOption("repos"), ...)
> {
> ??? if (missing(pkgs))
> ??????? return(utils::install.packages())
> ??? if (!.Call("rs_canInstallPackages", PACKAGE = "(embedding)")) {
> ??????? stop("Package installation is disabled in this version of
> RStudio",
> ??????????? call. = FALSE)
> ??? }
> ??? packratMode <- !is.na(Sys.getenv("R_PACKRAT_MODE", unset = NA))
> ??? if (!is.null(repos) && !packratMode &&
> .rs.loadedPackageUpdates(pkgs)) {
> ??????? installCmd <- NULL
> ??????? for (i in seq_along(sys.calls())) {
> ??????????? if (identical(deparse(sys.call(i)[[1]]),
> "install.packages")) {
> ??????????????? installCmd <- gsub("\\s+", " ",
> paste(deparse(sys.call(i)),
> ????????????????? collapse = " "))
> ??????????????? break
> ??????????? }
> ??????? }
> ??????? .rs.enqueLoadedPackageUpdates(installCmd)
> ??????? stop("Updating loaded packages")
> ??? }
> ??? .rs.addRToolsToPath()
> ??? on.exit({
> ??????? .rs.updatePackageEvents()
> ??????? .Call("rs_packageLibraryMutated", PACKAGE = "(embedding)")
> ??????? .rs.restorePreviousPath()
> ??? })
> ??? original(pkgs, lib, repos, ...)
> }
> <environment: 0x7fe7db925588>
>
> The .rs.callAs function just substitutes the call to "hook" for the
> call to the original install.packages.? So you can see that they do
> the following:
> ?- they allow a way to disable installing packages,
> ?- they support "packrat" (a system for installing particular versions
> of packages, see https://github.com/rstudio/packrat),
> ?- they add RTools to the path (presumably only on Windows)
> ?- they call the original function, and at the end update internal
> variables so they can show the library in the Packages pane.
>
> So there is no reason not to do it in R.
>
> By the way, saying that this is a "modified version of R" is like
> saying every single user who defines a variable creates a modified
> version of R.? If you type "x" in the plain R console, you see "Error:
> object 'x' not found".? If you "modify" R by assigning a value to x,
> you'll see something different.? Very scary!
>
> Duncan Murdoch
>
>


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Aug 17 15:20:35 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 17 Aug 2020 15:20:35 +0200
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CAHrK514bb_tuy++EP=vx+1BKG6NG-bZXnBFkD_2qD1Yuhke11Q@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAHrK514bb_tuy++EP=vx+1BKG6NG-bZXnBFkD_2qD1Yuhke11Q@mail.gmail.com>
Message-ID: <7ab12d01-7e1e-62e7-6978-9c4935ae2349@rgzm.de>

I don't want to relight the fire, but I was wondering about that
statement from John C Frain:
"If you use RStudio and do not install any of the RStudio packages".

I guess you mean that some packages are bundled with RStudio. I had
never noticed any optional packages during the installation of
RStudio... Is there a way to identify (and delete, if wished) these
packages?
Or have I misunderstood?

Thank you!
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 16/08/2020 20:20, John C Frain wrote:
> On Sun 16 Aug 2020 at 06:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> a) Read about it yourself. It is a legal definition.
>>
>> b) Don't "correct" me with misinformation you are clearly inventing.
>> RStudio the software does not "introduce people to a modified version of
>> R." Each user has to opt in to that "modified" experience by explicitly
>> installing each of the the many CRAN packages that various employees of
>> RStudio have created and all of which can (to my knowledge) be used without
>> installing the RStudio IDE at all. Yes, a bunch of them can be grabbed at
>> once by installing the tidyverse package, but that is also a choice made by
>> users and by instructors struggling to deal with students who have a hard
>> time with Excel much less functional programming. But RStudio is an R IDE.
>>
>> There are a lot of packages sponsored by RStudio that I find redundant and
>> slow, but portraying the RStudio company or the IDE as inherently "not R"
>> just because newbies like the IDE and the packages they sponsor, and who
>> end up confusing R with RStudio even though they have to install both, is
>> small-minded and biased
>
> To clarify:  If you use RStudio and do not install any of the RStudio
> packages, R in RStudio is the same R as if you were running it from the
> command line.  I would think that many users find command completion,
> access to help files, project management Etc. useful. Nobody is asking
> anyone to install the RStudio packages.  I do sometimes but not always and
> have found them useful. Jeff is 100% correct.
>
>
>>  On August 15, 2020 9:10:34 PM PDT, Abby Spurdle <spurdle.a at gmail.com>
>> wrote:
>>> On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>  It is a public benefit corporation
>>> Seriously?
>>>
>>> On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>  used to introduce people to R
>>> Correction, it introduces people to a modified version of R.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From j|ox @end|ng |rom mcm@@ter@c@  Mon Aug 17 16:02:22 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 17 Aug 2020 10:02:22 -0400
Subject: [R] install.packages() R vs RStudio
In-Reply-To: <15328_1597669436_07HD3tE6028766_0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>
References: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>
 <15328_1597669436_07HD3tE6028766_0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>
Message-ID: <62db62e7-72bd-ee67-1643-a26cd540d7c7@mcmaster.ca>

Dear Duncan,

On 2020-08-17 9:03 a.m., Duncan Murdoch wrote:
> On 17/08/2020 7:54 a.m., Ivan Calandra wrote:
>> Dear useRs,
>>
>> Following the recent activity on the list, I have been made aware of
>> this discussion:
>> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
>>
>> I used to install all packages in R, but for simplicity (I use RStudio
>> for all purposes), I now do it in RStudio. Now I am left wondering
>> whether I should continue installing packages directly from RStudio or
>> whether I should revert to using R.
>>
>> My goal is not to flare a debate over whether RStudio is better or worse
>> than R, but rather simply to understand whether there are differences
>> and potential issues (that could lead to problems in code) about
>> installing packages through RStudio.
>>
>> In general, it would be nice to have a list of the differences in
>> behavior between R and RStudio, but I believe this should come from the
>> RStudio side of things.
>>
>> Thank you all for the insights.
>> Ivan
>>
> 
> To see the install.packages function that RStudio installs, just type 
> its name:
> 
>  > install.packages
> function (...)
> .rs.callAs(name, hook, original, ...)
> <environment: 0x7fe7dc5b65b0>
> 
> You can debug it to see the other variables:
> 
>  > debug(install.packages)
>  > install.packages("abind")
> debugging in: install.packages("abind")
> debug: .rs.callAs(name, hook, original, ...)
> Browse[2]> name
> [1] "install.packages"
> Browse[2]> hook
> function (original, pkgs, lib, repos = getOption("repos"), ...)
> {
>  ??? if (missing(pkgs))
>  ??????? return(utils::install.packages())
>  ??? if (!.Call("rs_canInstallPackages", PACKAGE = "(embedding)")) {
>  ??????? stop("Package installation is disabled in this version of 
> RStudio",
>  ??????????? call. = FALSE)
>  ??? }
>  ??? packratMode <- !is.na(Sys.getenv("R_PACKRAT_MODE", unset = NA))
>  ??? if (!is.null(repos) && !packratMode && 
> .rs.loadedPackageUpdates(pkgs)) {
>  ??????? installCmd <- NULL
>  ??????? for (i in seq_along(sys.calls())) {
>  ??????????? if (identical(deparse(sys.call(i)[[1]]), 
> "install.packages")) {
>  ??????????????? installCmd <- gsub("\\s+", " ", 
> paste(deparse(sys.call(i)),
>  ????????????????? collapse = " "))
>  ??????????????? break
>  ??????????? }
>  ??????? }
>  ??????? .rs.enqueLoadedPackageUpdates(installCmd)
>  ??????? stop("Updating loaded packages")
>  ??? }
>  ??? .rs.addRToolsToPath()
>  ??? on.exit({
>  ??????? .rs.updatePackageEvents()
>  ??????? .Call("rs_packageLibraryMutated", PACKAGE = "(embedding)")
>  ??????? .rs.restorePreviousPath()
>  ??? })
>  ??? original(pkgs, lib, repos, ...)
> }
> <environment: 0x7fe7db925588>
> 
> The .rs.callAs function just substitutes the call to "hook" for the call 
> to the original install.packages.? So you can see that they do the 
> following:
>  ?- they allow a way to disable installing packages,
>  ?- they support "packrat" (a system for installing particular versions 
> of packages, see https://github.com/rstudio/packrat),
>  ?- they add RTools to the path (presumably only on Windows)
>  ?- they call the original function, and at the end update internal 
> variables so they can show the library in the Packages pane.
> 
> So there is no reason not to do it in R.
> 
> By the way, saying that this is a "modified version of R" is like saying 
> every single user who defines a variable creates a modified version of 
> R.? If you type "x" in the plain R console, you see "Error: object 'x' 
> not found".? If you "modify" R by assigning a value to x, you'll see 
> something different.? Very scary!

I can't recall ever disagreeing with something you said on the R-help, 
but this seems to me to be off-base. While what you say is technically 
correct, silently masking a standard R function, in this case, I 
believe, by messing with the namespace of the utils package, seems 
inadvisable to me.

As has been noted, cryptic problems have arisen with install.packages() 
in RStudio -- BTW, I use it regularly and haven't personally experienced 
any issues. One could concoct truly scary examples, such as redefining 
isTRUE().

Best,
  John

> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@whct @end|ng |rom gm@||@com  Mon Aug 17 16:23:58 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Mon, 17 Aug 2020 09:23:58 -0500
Subject: [R] Plot math symbol with string and number
In-Reply-To: <20200817021343.GB35031@posteo.no>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
Message-ID: <CAFyG=WP4A53UF5x5Kyav_TP8WrJd4exYe8QwK9dYvLiCKvcO_A@mail.gmail.com>

Thanks to Dunkan, Rasmus and Bert. Will keep the very useful tips. Best!

On Sun, Aug 16, 2020 at 9:13 PM Rasmus Liland <jral at posteo.no> wrote:

> On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
> | On Sun, Aug 16, 2020, 14:53 John wrote:
> | |
> | | I would like to make plots with
> | | titles for different data sets and
> | | different parameters. The first
> | | title doesn't show sigma as a math
> | | symbol, while the second one
> | | doesn't contain the s value as a
> | | numeric value
> | |
> | | s <- 1
> | | y <- rnorm(100)
> | | plot(y, main=paste("data", "sigma=", s))
> | | plot(y, main=expression(paste("data", sigma,"=", s)))
> |
> | ?plotmath
>
> Dear John, read ?plotmath, it is good, I
> was not aware of its existence; then
> backquote s like so:
>
>         plot(y, main=bquote(paste(
>           "data" ~~ widehat(aleph)
>           %notin% .(s)^.(s))))
>
> V
>
> r
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 17 16:39:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 Aug 2020 07:39:54 -0700
Subject: [R] 
 Data With Ordinal Responses: Calculate ICC & Assessing Model Fit
In-Reply-To: <DM5PR0101MB30822AB381E6AB6CFCC4F64FAB5F0@DM5PR0101MB3082.prod.exchangelabs.com>
References: <DM5PR0101MB30822AB381E6AB6CFCC4F64FAB5F0@DM5PR0101MB3082.prod.exchangelabs.com>
Message-ID: <CAGxFJbQTzvA0Nw-9bf=L2=jPRszdo0UD46UCpqxpApk6E7Efjg@mail.gmail.com>

I believe you should post on r-sig-mixed-models, not here. You are more
likely to find the interest and expertise you seek there.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 17, 2020 at 3:28 AM Sidoti, Salvatore A. <
sidoti.23 at buckeyemail.osu.edu> wrote:

> To begin with, I'm not a fan of cross-posting. However, I posted my
> question on Stack Exchange more than two weeks ago, but I have yet to
> receive a sufficient answer:
>
>
> https://stats.stackexchange.com/questions/479600/data-with-ordinal-responses-calculate-icc-assessing-model-fit
>
> Here's what I've learned since then (hopefully):
>
> 1) ICC of a CLMM:
> Computed like this:
> (variance of the random effect) / (variance of the random effect + 1)
> If this is correct, I would love to see a reference/citation for it.
>
> 2) 95% Confidence Interval for the ICC from a CLMM Model
> To my current understanding, a confidence interval for an ICC is only
> obtainable via simulation. I've conducted simulations with GLMM model
> objects ('lme4' package) and the bootMer() function. Unfortunately,
> bootMer() will not accept a CLMM model ('ordinal' package).
>
> 3) Model Fit of a CLMM
> Assuming that the model converges without incident, the model summary
> includes a condition number of the Hessian ('cond.H'). This value should be
> below 10^4 for a "good fit". This is straightforward enough. However, I am
> not as sure about the value for 'max.grad', which needs to be "well below
> 1". The question is, to what magnitude should max.grad < 1 for a decent
> model fit? My reference is linked below (Christensen, 2019), but it does
> not elaborate further on this point:
>
>
> https://documentcloud.adobe.com/link/track?uri=urn:aaid:scds:US:b6a61fe2-b851-49ce-b8b1-cd760d290636
>
> 3) Effect Size of a CLMM
> The random variable's effect is determined by a comparison between the
> full model to a model with only the fixed effects via the anova() function.
> I found this information on the 'rcompanion' package website:
>
> https://rcompanion.org/handbook/G_12.html
>
> The output of this particular anova() will include a value named
> 'LR.stat', the likelihood ratio statistic. The LR.stat is twice the
> difference of each log-likelihood (absolute value) of the respective
> models. Is LR.stat the mixed-model version of an "effect size"? If so, how
> does one determine if the effect is small, large, in-between, etc?
>
> Cheers,
> Sal
>
> Salvatore A. Sidoti
> PhD Candidate
> Behavioral Ecology
> The Ohio State University
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Mon Aug 17 18:53:36 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 17 Aug 2020 18:53:36 +0200
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CABdHhvEqtL7J1qLXRUjd-P9nf2bFzYZJvKah=MwyKt7SGWq3ZA@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
 <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
 <CAGgJW76q69pxpHyBfkoCWBPNL1fjwmN2G5b0YwAPxsDUXn7DtQ@mail.gmail.com>
 <CABdHhvEqtL7J1qLXRUjd-P9nf2bFzYZJvKah=MwyKt7SGWq3ZA@mail.gmail.com>
Message-ID: <20200817165336.GF35031@posteo.no>

Dear John,

Op ma 17 aug. 2020 om 09:52 schreef Eric Berger:
| On Mon, Aug 17, 2020 at 10:49 AM Thierry Onkelinx wrote:
| |
| | You are looking for tidyr::pivot_longer()
|
| Alternatively, melt() from the reshape2 package.
|
| library(reshape2)
| melt(x,id.vars="date",measure.vars=c("down","uc","up"),variable.name
| ="direction",value.name="percentage")

Also, stack is also possible to use:

	tab <- structure(list(
	date = c("2019M08", "2019M09", "2019M10"),
	down = c(0.01709827, 0.02094724, 0.01750911),
	uc = c(0.2653882, 0.2265797, 0.245003),
	up = c(0.7175136, 0.7524731, 0.7374879)),
	class = "data.frame", row.names = c(NA, -3L))
	
	out <- utils::stack(x=tab, select=-date)
	colnames(out) <- c("percentage", "direction")
	out$date <- tab$date
	out <- out[,sort(colnames(out))]
	
	out

yields

	     date direction percentage
	1 2019M08      down 0.01709827
	2 2019M09      down 0.02094724
	3 2019M10      down 0.01750911
	4 2019M08        uc 0.26538820
	5 2019M09        uc 0.22657970
	6 2019M10        uc 0.24500300
	7 2019M08        up 0.71751360
	8 2019M09        up 0.75247310
	9 2019M10        up 0.73748790

On 2020-08-17 07:46 -0500, Hadley Wickham wrote:
| On Mon, Aug 17, 2020 at 11:23 AM Thierry Onkelinx wrote:
| |
| | reshape2 is a retired package. The 
| | author recommends to use his new 
| | package tidyr.
| 
| We previously used the term retired to 
| suggest that the package is taking it 
| easy and relaxing, but isn't dead. 

Haha :)

| This causes a lot of confusion so we 
| now call this state "superseded" ? 
| we'll continue to keep reshape2 (and 
| reshape!) on CRAN

Good!

| but they won't receive any new 
| features, and we believe that there 
| are now better approaches to solving 
| the same problem.

Is tidyr::pivot_longer this better 
solution?  It is an easier to understand 
version of the now retired and confusing 
(for me) tidyr::gather which at least 
reigned back in 2018 (was that any good 
compared to reshape?).

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200817/5cd7435c/attachment.sig>

From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 17 19:09:58 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 Aug 2020 10:09:58 -0700
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <20200817165336.GF35031@posteo.no>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
 <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
 <CAGgJW76q69pxpHyBfkoCWBPNL1fjwmN2G5b0YwAPxsDUXn7DtQ@mail.gmail.com>
 <CABdHhvEqtL7J1qLXRUjd-P9nf2bFzYZJvKah=MwyKt7SGWq3ZA@mail.gmail.com>
 <20200817165336.GF35031@posteo.no>
Message-ID: <CAGxFJbSayXBurF5Szhh0gomKAwC42snQaQ+JoyFKOveCiH7Frw@mail.gmail.com>

Well, not that there is anything "wrong" with previous suggestions, but it
is pretty straightforward just with base R functionality:

> nm <- names(tab)[2:4]
> with(tab, data.frame(date = rep(date, length(nm)),
+                     direction = rep(nm, e = 3),
+                     percentage = do.call(c, tab[, nm]))
+     )
         date direction percentage
down1 2019M08      down 0.01709827
down2 2019M09      down 0.02094724
down3 2019M10      down 0.01750911
uc1   2019M08        uc 0.26538820
uc2   2019M09        uc 0.22657970
uc3   2019M10        uc 0.24500300
up1   2019M08        up 0.71751360
up2   2019M09        up 0.75247310
up3   2019M10        up 0.73748790


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 17, 2020 at 9:53 AM Rasmus Liland <jral at posteo.no> wrote:

> Dear John,
>
> Op ma 17 aug. 2020 om 09:52 schreef Eric Berger:
> | On Mon, Aug 17, 2020 at 10:49 AM Thierry Onkelinx wrote:
> | |
> | | You are looking for tidyr::pivot_longer()
> |
> | Alternatively, melt() from the reshape2 package.
> |
> | library(reshape2)
> | melt(x,id.vars="date",measure.vars=c("down","uc","up"),variable.name
> | ="direction",value.name="percentage")
>
> Also, stack is also possible to use:
>
>         tab <- structure(list(
>         date = c("2019M08", "2019M09", "2019M10"),
>         down = c(0.01709827, 0.02094724, 0.01750911),
>         uc = c(0.2653882, 0.2265797, 0.245003),
>         up = c(0.7175136, 0.7524731, 0.7374879)),
>         class = "data.frame", row.names = c(NA, -3L))
>
>         out <- utils::stack(x=tab, select=-date)
>         colnames(out) <- c("percentage", "direction")
>         out$date <- tab$date
>         out <- out[,sort(colnames(out))]
>
>         out
>
> yields
>
>              date direction percentage
>         1 2019M08      down 0.01709827
>         2 2019M09      down 0.02094724
>         3 2019M10      down 0.01750911
>         4 2019M08        uc 0.26538820
>         5 2019M09        uc 0.22657970
>         6 2019M10        uc 0.24500300
>         7 2019M08        up 0.71751360
>         8 2019M09        up 0.75247310
>         9 2019M10        up 0.73748790
>
> On 2020-08-17 07:46 -0500, Hadley Wickham wrote:
> | On Mon, Aug 17, 2020 at 11:23 AM Thierry Onkelinx wrote:
> | |
> | | reshape2 is a retired package. The
> | | author recommends to use his new
> | | package tidyr.
> |
> | We previously used the term retired to
> | suggest that the package is taking it
> | easy and relaxing, but isn't dead.
>
> Haha :)
>
> | This causes a lot of confusion so we
> | now call this state "superseded" ?
> | we'll continue to keep reshape2 (and
> | reshape!) on CRAN
>
> Good!
>
> | but they won't receive any new
> | features, and we believe that there
> | are now better approaches to solving
> | the same problem.
>
> Is tidyr::pivot_longer this better
> solution?  It is an easier to understand
> version of the now retired and confusing
> (for me) tidyr::gather which at least
> reigned back in 2018 (was that any good
> compared to reshape?).
>
> Best,
> Rasmus
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@v|d@@teven@ @end|ng |rom u@u@edu  Mon Aug 17 19:26:02 2020
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David K Stevens)
Date: Mon, 17 Aug 2020 11:26:02 -0600
Subject: [R] [EXT] Re:  Plot math symbol with string and number
In-Reply-To: <CAFyG=WP4A53UF5x5Kyav_TP8WrJd4exYe8QwK9dYvLiCKvcO_A@mail.gmail.com>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
 <CAFyG=WP4A53UF5x5Kyav_TP8WrJd4exYe8QwK9dYvLiCKvcO_A@mail.gmail.com>
Message-ID: <7bd6957d-5310-c27c-3e42-8b77c8cd2511@usu.edu>

John - one more approach

plot(y,main=parse(text=paste0('data ~~ sigma == ',s)))

Good luck

David Stevens

On 8/17/2020 8:23 AM, John Smith wrote:
> Thanks to Dunkan, Rasmus and Bert. Will keep the very useful tips. Best!
>
> On Sun, Aug 16, 2020 at 9:13 PM Rasmus Liland <jral at posteo.no> wrote:
>
>> On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
>> | On Sun, Aug 16, 2020, 14:53 John wrote:
>> | |
>> | | I would like to make plots with
>> | | titles for different data sets and
>> | | different parameters. The first
>> | | title doesn't show sigma as a math
>> | | symbol, while the second one
>> | | doesn't contain the s value as a
>> | | numeric value
>> | |
>> | | s <- 1
>> | | y <- rnorm(100)
>> | | plot(y, main=paste("data", "sigma=", s))
>> | | plot(y, main=expression(paste("data", sigma,"=", s)))
>> |
>> | ?plotmath
>>
>> Dear John, read ?plotmath, it is good, I
>> was not aware of its existence; then
>> backquote s like so:
>>
>>          plot(y, main=bquote(paste(
>>            "data" ~~ widehat(aleph)
>>            %notin% .(s)^.(s))))
>>
>> V
>>
>> r
>>
>          [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> CAUTION: This email originated from outside of USU. If this appears to be a USU employee, beware of impersonators. Do not click links, reply, download images, or open attachments unless you verify the sender?s identity and know the content is safe.
>
-- 
David K Stevens, P.E., Ph.D.
Professor, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Aug 17 20:28:00 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 17 Aug 2020 18:28:00 +0000 (UTC)
Subject: [R] confidence intervals for the difference between group means
In-Reply-To: <49a5936b-47e3-1b19-0398-893c4a8b8c5e@stamats.de>
References: <287735883.448015.1596550086626.ref@mail.yahoo.com>
 <287735883.448015.1596550086626@mail.yahoo.com>
 <49a5936b-47e3-1b19-0398-893c4a8b8c5e@stamats.de>
Message-ID: <123931007.3920106.1597688880675@mail.yahoo.com>

Dear Matthias,

Many thanks for your response.

Best,
SV


Le mardi 4 ao?t 2020 ? 16:22:41 UTC+2, Prof. Dr. Matthias Kohl <matthias.kohl at stamats.de> a ?crit : 





you could try:

library(MKinfer)
meanDiffCI(a, b, boot = TRUE)

Best
Matthias

Am 04.08.20 um 16:08 schrieb varin sacha via R-help:
> Dear R-experts,
> 
> Using the bootES package I can easily calculate the bootstrap confidence intervals of the means like in the toy example here below. Now, I am looking for the confidence intervals for the difference between group means. In my case, the point estimate of the mean difference is 64.4. I am looking at the 95% confidence intervals around this point estimate (64.4).
> 
> Many thanks for your response.
> 
> ############
> library(bootES)
> a<-c(523,435,478,567,654)
> b<-c(423,523,421,467,501)
> bootES(a)
> bootES(b)

> ############
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Prof. Dr. Matthias Kohl
www.stamats.de

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 17 20:50:07 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 17 Aug 2020 14:50:07 -0400
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <7ab12d01-7e1e-62e7-6978-9c4935ae2349@rgzm.de>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAHrK514bb_tuy++EP=vx+1BKG6NG-bZXnBFkD_2qD1Yuhke11Q@mail.gmail.com>
 <7ab12d01-7e1e-62e7-6978-9c4935ae2349@rgzm.de>
Message-ID: <f2524649-8ef0-5b82-9914-ceea87f6696a@gmail.com>

On 17/08/2020 9:20 a.m., Ivan Calandra wrote:
> I don't want to relight the fire, but I was wondering about that
> statement from John C Frain:
> "If you use RStudio and do not install any of the RStudio packages".
> 
> I guess you mean that some packages are bundled with RStudio. I had
> never noticed any optional packages during the installation of
> RStudio... Is there a way to identify (and delete, if wished) these
> packages?
> Or have I misunderstood?

When you are running RStudio, your search list will include 
"tools:rstudio".  It's not exactly a package, it's an environment 
containing functions used by the RStudio front end.  You can delete it 
and R will still work fine, but I'd expect some parts of the GUI to stop 
working.

Some RStudio actions (e.g. clicking the "knit" button) will prompt you 
to install packages if they are not found.  I don't think any of them 
are "bundled" with RStudio, but I might be wrong about that.

RStudio definitely installs Pandoc and maybe some other packages. 
(These aren't R packages, they are packages in a more general sense.) 
Certainly you should be able to delete Pandoc if you have permissions to 
install it; that may break RMarkdown if you don't have another copy 
somewhere.)

To identify what R packages got installed, just run 
"installed.packages()" before and after installing RStudio, and look for 
differences.

Duncan Murdoch


> 
> Thank you!
> Ivan
> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> On 16/08/2020 20:20, John C Frain wrote:
>> On Sun 16 Aug 2020 at 06:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>>> a) Read about it yourself. It is a legal definition.
>>>
>>> b) Don't "correct" me with misinformation you are clearly inventing.
>>> RStudio the software does not "introduce people to a modified version of
>>> R." Each user has to opt in to that "modified" experience by explicitly
>>> installing each of the the many CRAN packages that various employees of
>>> RStudio have created and all of which can (to my knowledge) be used without
>>> installing the RStudio IDE at all. Yes, a bunch of them can be grabbed at
>>> once by installing the tidyverse package, but that is also a choice made by
>>> users and by instructors struggling to deal with students who have a hard
>>> time with Excel much less functional programming. But RStudio is an R IDE.
>>>
>>> There are a lot of packages sponsored by RStudio that I find redundant and
>>> slow, but portraying the RStudio company or the IDE as inherently "not R"
>>> just because newbies like the IDE and the packages they sponsor, and who
>>> end up confusing R with RStudio even though they have to install both, is
>>> small-minded and biased
>>
>> To clarify:  If you use RStudio and do not install any of the RStudio
>> packages, R in RStudio is the same R as if you were running it from the
>> command line.  I would think that many users find command completion,
>> access to help files, project management Etc. useful. Nobody is asking
>> anyone to install the RStudio packages.  I do sometimes but not always and
>> have found them useful. Jeff is 100% correct.
>>
>>
>>>   On August 15, 2020 9:10:34 PM PDT, Abby Spurdle <spurdle.a at gmail.com>
>>> wrote:
>>>> On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>   It is a public benefit corporation
>>>> Seriously?
>>>>
>>>> On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>   used to introduce people to R
>>>> Correction, it introduces people to a modified version of R.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jr@| @end|ng |rom po@teo@no  Mon Aug 17 21:09:17 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 17 Aug 2020 21:09:17 +0200
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <CAGxFJbSayXBurF5Szhh0gomKAwC42snQaQ+JoyFKOveCiH7Frw@mail.gmail.com>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
 <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
 <CAGgJW76q69pxpHyBfkoCWBPNL1fjwmN2G5b0YwAPxsDUXn7DtQ@mail.gmail.com>
 <CABdHhvEqtL7J1qLXRUjd-P9nf2bFzYZJvKah=MwyKt7SGWq3ZA@mail.gmail.com>
 <20200817165336.GF35031@posteo.no>
 <CAGxFJbSayXBurF5Szhh0gomKAwC42snQaQ+JoyFKOveCiH7Frw@mail.gmail.com>
Message-ID: <20200817190917.GG35031@posteo.no>

On 2020-08-17 10:09 -0700, Bert Gunter wrote:
| On Mon, Aug 17, 2020 at 9:53 AM Rasmus Liland wrote:
| |
| | Also, stack is also possible to use:
| |
| | 	tab <- structure(list(
| | 	date = c("2019M08", "2019M09", "2019M10"),
| | 	down = c(0.01709827, 0.02094724, 0.01750911),
| | 	uc = c(0.2653882, 0.2265797, 0.245003),
| | 	up = c(0.7175136, 0.7524731, 0.7374879)),
| | 	class = "data.frame", row.names = c(NA, -3L))
| |
| | 	out <- utils::stack(x=tab, select=-date)
| | 	colnames(out) <- c("percentage", "direction")
| | 	out$date <- tab$date
| | 	out <- out[,sort(colnames(out))]
| 
| Well, not that there is anything 
| "wrong" with previous suggestions, but 
| it is pretty straightforward just with 
| base R functionality:
| 
| > nm <- names(tab)[2:4]
| > with(tab, data.frame(date = rep(date, length(nm)),
| +                      direction = rep(nm, e = 3),
| +                      percentage = do.call(c, tab[, nm]))
| +      )

This is good :)  You can also use unlist 
directly instead of do.call(c, ...)

	nm <- names(tab)[2:4]
	data.frame(
	  date=tab$date,
	  direction=rep(nm, each=length(nm)),
	  percentage=unlist(tab[,nm]))

V

r

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200817/183d666d/attachment.sig>

From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Aug 17 21:15:58 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 17 Aug 2020 15:15:58 -0400
Subject: [R] install.packages() R vs RStudio
In-Reply-To: <62db62e7-72bd-ee67-1643-a26cd540d7c7@mcmaster.ca>
References: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>
 <15328_1597669436_07HD3tE6028766_0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>
 <62db62e7-72bd-ee67-1643-a26cd540d7c7@mcmaster.ca>
Message-ID: <0a56da0f-c37f-1db2-5377-70a9a1ff3cf6@gmail.com>

Hi John.

I suspect most good front ends do similar things.  For example, on 
MacOS, R.app messes up "history()".  I've never used ESS, but I imagine 
one could find examples where it acts differently than base R:  isn't 
that the point?

One hopes all differences are improvements, but sometimes they're not. 
If the modifications cause trouble (e.g. the ones you and I have never 
experienced with install.packages() in RStudio, or the one I experience 
every now and then with history() in R.app), then that may be a bug in 
the front-end.  It should be reported to the authors.

R is designed to be flexible, and to let people change its behaviour. 
Using that flexibility is what all users should do.  Improving the user 
experience is what front-end writers should do.  I don't find it 
inadvisable at all.  If it's the "silent" part that you object to, I 
think that's a matter of taste.  Personally, I've stopped reading the 
messages like

"Attaching package: ?zoo?

The following objects are masked from ?package:base?:

     as.Date, as.Date.numeric"

so they may as well be silent.

Duncan Murdoch


On 17/08/2020 10:02 a.m., John Fox wrote:
> Dear Duncan,
> 
> On 2020-08-17 9:03 a.m., Duncan Murdoch wrote:
>> On 17/08/2020 7:54 a.m., Ivan Calandra wrote:
>>> Dear useRs,
>>>
>>> Following the recent activity on the list, I have been made aware of
>>> this discussion:
>>> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
>>>
>>> I used to install all packages in R, but for simplicity (I use RStudio
>>> for all purposes), I now do it in RStudio. Now I am left wondering
>>> whether I should continue installing packages directly from RStudio or
>>> whether I should revert to using R.
>>>
>>> My goal is not to flare a debate over whether RStudio is better or worse
>>> than R, but rather simply to understand whether there are differences
>>> and potential issues (that could lead to problems in code) about
>>> installing packages through RStudio.
>>>
>>> In general, it would be nice to have a list of the differences in
>>> behavior between R and RStudio, but I believe this should come from the
>>> RStudio side of things.
>>>
>>> Thank you all for the insights.
>>> Ivan
>>>
>>
>> To see the install.packages function that RStudio installs, just type
>> its name:
>>
>>   > install.packages
>> function (...)
>> .rs.callAs(name, hook, original, ...)
>> <environment: 0x7fe7dc5b65b0>
>>
>> You can debug it to see the other variables:
>>
>>   > debug(install.packages)
>>   > install.packages("abind")
>> debugging in: install.packages("abind")
>> debug: .rs.callAs(name, hook, original, ...)
>> Browse[2]> name
>> [1] "install.packages"
>> Browse[2]> hook
>> function (original, pkgs, lib, repos = getOption("repos"), ...)
>> {
>>   ??? if (missing(pkgs))
>>   ??????? return(utils::install.packages())
>>   ??? if (!.Call("rs_canInstallPackages", PACKAGE = "(embedding)")) {
>>   ??????? stop("Package installation is disabled in this version of
>> RStudio",
>>   ??????????? call. = FALSE)
>>   ??? }
>>   ??? packratMode <- !is.na(Sys.getenv("R_PACKRAT_MODE", unset = NA))
>>   ??? if (!is.null(repos) && !packratMode &&
>> .rs.loadedPackageUpdates(pkgs)) {
>>   ??????? installCmd <- NULL
>>   ??????? for (i in seq_along(sys.calls())) {
>>   ??????????? if (identical(deparse(sys.call(i)[[1]]),
>> "install.packages")) {
>>   ??????????????? installCmd <- gsub("\\s+", " ",
>> paste(deparse(sys.call(i)),
>>   ????????????????? collapse = " "))
>>   ??????????????? break
>>   ??????????? }
>>   ??????? }
>>   ??????? .rs.enqueLoadedPackageUpdates(installCmd)
>>   ??????? stop("Updating loaded packages")
>>   ??? }
>>   ??? .rs.addRToolsToPath()
>>   ??? on.exit({
>>   ??????? .rs.updatePackageEvents()
>>   ??????? .Call("rs_packageLibraryMutated", PACKAGE = "(embedding)")
>>   ??????? .rs.restorePreviousPath()
>>   ??? })
>>   ??? original(pkgs, lib, repos, ...)
>> }
>> <environment: 0x7fe7db925588>
>>
>> The .rs.callAs function just substitutes the call to "hook" for the call
>> to the original install.packages.? So you can see that they do the
>> following:
>>   ?- they allow a way to disable installing packages,
>>   ?- they support "packrat" (a system for installing particular versions
>> of packages, see https://github.com/rstudio/packrat),
>>   ?- they add RTools to the path (presumably only on Windows)
>>   ?- they call the original function, and at the end update internal
>> variables so they can show the library in the Packages pane.
>>
>> So there is no reason not to do it in R.
>>
>> By the way, saying that this is a "modified version of R" is like saying
>> every single user who defines a variable creates a modified version of
>> R.? If you type "x" in the plain R console, you see "Error: object 'x'
>> not found".? If you "modify" R by assigning a value to x, you'll see
>> something different.? Very scary!
> 
> I can't recall ever disagreeing with something you said on the R-help,
> but this seems to me to be off-base. While what you say is technically
> correct, silently masking a standard R function, in this case, I
> believe, by messing with the namespace of the utils package, seems
> inadvisable to me.
> 
> As has been noted, cryptic problems have arisen with install.packages()
> in RStudio -- BTW, I use it regularly and haven't personally experienced
> any issues. One could concoct truly scary examples, such as redefining
> isTRUE().
> 
> Best,
>    John
> 
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From h@w|ckh@m @end|ng |rom gm@||@com  Mon Aug 17 21:25:49 2020
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Mon, 17 Aug 2020 14:25:49 -0500
Subject: [R] Reorganize the data (dplyr or other packages?)
In-Reply-To: <20200817165336.GF35031@posteo.no>
References: <CABcx46DXbFihMfp=N1M8EVb++NzhOPV-TDnnER2R2hActnsRug@mail.gmail.com>
 <CAJuCY5y1jJA81NAokKV25fcmoDxyZxSCwY6943s30Gze6aXcAg@mail.gmail.com>
 <CAGgJW75J5OWUOXhA0mY_Oku_13qhP--FaqgBnsgR7kQFUn4ecA@mail.gmail.com>
 <CAJuCY5x1QjwKWPMiC5wOKHJDMXZDqw1UqqpV3--9QQxXSLvCXA@mail.gmail.com>
 <CAGgJW76q69pxpHyBfkoCWBPNL1fjwmN2G5b0YwAPxsDUXn7DtQ@mail.gmail.com>
 <CABdHhvEqtL7J1qLXRUjd-P9nf2bFzYZJvKah=MwyKt7SGWq3ZA@mail.gmail.com>
 <20200817165336.GF35031@posteo.no>
Message-ID: <CABdHhvFK0ZSD_pyWOzFrAF6aK+M73+QC_+8oHFYcDF5MFeDmGQ@mail.gmail.com>

> | but they won't receive any new
> | features, and we believe that there
> | are now better approaches to solving
> | the same problem.
>
> Is tidyr::pivot_longer this better
> solution?  It is an easier to understand
> version of the now retired and confusing
> (for me) tidyr::gather which at least
> reigned back in 2018 (was that any good
> compared to reshape?).

Yes, and hopefully :)

    library(tidyr)

    tab <- structure(list(
    date = c("2019M08", "2019M09", "2019M10"),
    down = c(0.01709827, 0.02094724, 0.01750911),
    uc = c(0.2653882, 0.2265797, 0.245003),
    up = c(0.7175136, 0.7524731, 0.7374879)),
    class = "data.frame", row.names = c(NA, -3L))

    tab %>% pivot_longer(
      down:up,
      names_to = "direction",
      values_to = "percentage"
    )
    #> # A tibble: 9 x 3
    #>   date    direction percentage
    #>   <chr>   <chr>          <dbl>
    #> 1 2019M08 down          0.0171
    #> 2 2019M08 uc            0.265
    #> 3 2019M08 up            0.718
    #> 4 2019M09 down          0.0209
    #> 5 2019M09 uc            0.227
    #> 6 2019M09 up            0.752
    #> 7 2019M10 down          0.0175
    #> 8 2019M10 uc            0.245
    #> 9 2019M10 up            0.737

<sup>Created on 2020-08-17 by the [reprex
package](https://reprex.tidyverse.org) (v0.3.0)</sup>



-- 
http://hadley.nz


From j|ox @end|ng |rom mcm@@ter@c@  Mon Aug 17 21:33:42 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 17 Aug 2020 15:33:42 -0400
Subject: [R] install.packages() R vs RStudio
In-Reply-To: <28439_1597691978_07HJJaJO023590_0a56da0f-c37f-1db2-5377-70a9a1ff3cf6@gmail.com>
References: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>
 <15328_1597669436_07HD3tE6028766_0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>
 <62db62e7-72bd-ee67-1643-a26cd540d7c7@mcmaster.ca>
 <28439_1597691978_07HJJaJO023590_0a56da0f-c37f-1db2-5377-70a9a1ff3cf6@gmail.com>
Message-ID: <08ad1b66-2ccb-337e-1d1a-2d66d24c0c81@mcmaster.ca>

Hi Duncan,

What you say is entirely sensible.

Yes, it's primarily the silent part that seems problematic to me. 
Messages about masking are uninteresting until one encounters a problem, 
and then they may provide an important clue to the source of the problem.

As to this specific case: It's not clear to me why it's necessary or 
even desirable for RStudio to mask utils::install.packages(). After all 
RStudio provides an alternative route to package installation via the 
Packages tab, and it wouldn't have been hard to name the function 
something different from install.packages() to provide additional 
functionality via direct commands.

Best,
  John

On 2020-08-17 3:15 p.m., Duncan Murdoch wrote:
> Hi John.
> 
> I suspect most good front ends do similar things.? For example, on 
> MacOS, R.app messes up "history()".? I've never used ESS, but I imagine 
> one could find examples where it acts differently than base R:? isn't 
> that the point?
> 
> One hopes all differences are improvements, but sometimes they're not. 
> If the modifications cause trouble (e.g. the ones you and I have never 
> experienced with install.packages() in RStudio, or the one I experience 
> every now and then with history() in R.app), then that may be a bug in 
> the front-end.? It should be reported to the authors.
> 
> R is designed to be flexible, and to let people change its behaviour. 
> Using that flexibility is what all users should do.? Improving the user 
> experience is what front-end writers should do.? I don't find it 
> inadvisable at all.? If it's the "silent" part that you object to, I 
> think that's a matter of taste.? Personally, I've stopped reading the 
> messages like
> 
> "Attaching package: ?zoo?
> 
> The following objects are masked from ?package:base?:
> 
>  ??? as.Date, as.Date.numeric"
> 
> so they may as well be silent.
> 
> Duncan Murdoch
> 
> 
> On 17/08/2020 10:02 a.m., John Fox wrote:
>> Dear Duncan,
>>
>> On 2020-08-17 9:03 a.m., Duncan Murdoch wrote:
>>> On 17/08/2020 7:54 a.m., Ivan Calandra wrote:
>>>> Dear useRs,
>>>>
>>>> Following the recent activity on the list, I have been made aware of
>>>> this discussion:
>>>> https://stat.ethz.ch/pipermail/r-help/2020-May/466788.html
>>>>
>>>> I used to install all packages in R, but for simplicity (I use RStudio
>>>> for all purposes), I now do it in RStudio. Now I am left wondering
>>>> whether I should continue installing packages directly from RStudio or
>>>> whether I should revert to using R.
>>>>
>>>> My goal is not to flare a debate over whether RStudio is better or 
>>>> worse
>>>> than R, but rather simply to understand whether there are differences
>>>> and potential issues (that could lead to problems in code) about
>>>> installing packages through RStudio.
>>>>
>>>> In general, it would be nice to have a list of the differences in
>>>> behavior between R and RStudio, but I believe this should come from the
>>>> RStudio side of things.
>>>>
>>>> Thank you all for the insights.
>>>> Ivan
>>>>
>>>
>>> To see the install.packages function that RStudio installs, just type
>>> its name:
>>>
>>> ? > install.packages
>>> function (...)
>>> .rs.callAs(name, hook, original, ...)
>>> <environment: 0x7fe7dc5b65b0>
>>>
>>> You can debug it to see the other variables:
>>>
>>> ? > debug(install.packages)
>>> ? > install.packages("abind")
>>> debugging in: install.packages("abind")
>>> debug: .rs.callAs(name, hook, original, ...)
>>> Browse[2]> name
>>> [1] "install.packages"
>>> Browse[2]> hook
>>> function (original, pkgs, lib, repos = getOption("repos"), ...)
>>> {
>>> ? ??? if (missing(pkgs))
>>> ? ??????? return(utils::install.packages())
>>> ? ??? if (!.Call("rs_canInstallPackages", PACKAGE = "(embedding)")) {
>>> ? ??????? stop("Package installation is disabled in this version of
>>> RStudio",
>>> ? ??????????? call. = FALSE)
>>> ? ??? }
>>> ? ??? packratMode <- !is.na(Sys.getenv("R_PACKRAT_MODE", unset = NA))
>>> ? ??? if (!is.null(repos) && !packratMode &&
>>> .rs.loadedPackageUpdates(pkgs)) {
>>> ? ??????? installCmd <- NULL
>>> ? ??????? for (i in seq_along(sys.calls())) {
>>> ? ??????????? if (identical(deparse(sys.call(i)[[1]]),
>>> "install.packages")) {
>>> ? ??????????????? installCmd <- gsub("\\s+", " ",
>>> paste(deparse(sys.call(i)),
>>> ? ????????????????? collapse = " "))
>>> ? ??????????????? break
>>> ? ??????????? }
>>> ? ??????? }
>>> ? ??????? .rs.enqueLoadedPackageUpdates(installCmd)
>>> ? ??????? stop("Updating loaded packages")
>>> ? ??? }
>>> ? ??? .rs.addRToolsToPath()
>>> ? ??? on.exit({
>>> ? ??????? .rs.updatePackageEvents()
>>> ? ??????? .Call("rs_packageLibraryMutated", PACKAGE = "(embedding)")
>>> ? ??????? .rs.restorePreviousPath()
>>> ? ??? })
>>> ? ??? original(pkgs, lib, repos, ...)
>>> }
>>> <environment: 0x7fe7db925588>
>>>
>>> The .rs.callAs function just substitutes the call to "hook" for the call
>>> to the original install.packages.? So you can see that they do the
>>> following:
>>> ? ?- they allow a way to disable installing packages,
>>> ? ?- they support "packrat" (a system for installing particular versions
>>> of packages, see https://github.com/rstudio/packrat),
>>> ? ?- they add RTools to the path (presumably only on Windows)
>>> ? ?- they call the original function, and at the end update internal
>>> variables so they can show the library in the Packages pane.
>>>
>>> So there is no reason not to do it in R.
>>>
>>> By the way, saying that this is a "modified version of R" is like saying
>>> every single user who defines a variable creates a modified version of
>>> R.? If you type "x" in the plain R console, you see "Error: object 'x'
>>> not found".? If you "modify" R by assigning a value to x, you'll see
>>> something different.? Very scary!
>>
>> I can't recall ever disagreeing with something you said on the R-help,
>> but this seems to me to be off-base. While what you say is technically
>> correct, silently masking a standard R function, in this case, I
>> believe, by messing with the namespace of the utils package, seems
>> inadvisable to me.
>>
>> As has been noted, cryptic problems have arisen with install.packages()
>> in RStudio -- BTW, I use it regularly and haven't personally experienced
>> any issues. One could concoct truly scary examples, such as redefining
>> isTRUE().
>>
>> Best,
>> ?? John
>>
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@whct @end|ng |rom gm@||@com  Mon Aug 17 21:59:26 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Mon, 17 Aug 2020 14:59:26 -0500
Subject: [R] [EXT] Re: Plot math symbol with string and number
In-Reply-To: <7bd6957d-5310-c27c-3e42-8b77c8cd2511@usu.edu>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
 <CAFyG=WP4A53UF5x5Kyav_TP8WrJd4exYe8QwK9dYvLiCKvcO_A@mail.gmail.com>
 <7bd6957d-5310-c27c-3e42-8b77c8cd2511@usu.edu>
Message-ID: <CAFyG=WMCjQqnsraHOs2m2Au_xvkEA+D0oMoMzSow+ZBMKi6LwQ@mail.gmail.com>

Thanks David for a quite interesting suggestion: Indeed I didn't know
paste0! Best!

On Mon, Aug 17, 2020 at 12:26 PM David K Stevens <david.stevens at usu.edu>
wrote:

> John - one more approach
>
> plot(y,main=parse(text=paste0('data ~~ sigma == ',s)))
>
> Good luck
>
> David Stevens
>
> On 8/17/2020 8:23 AM, John Smith wrote:
> > Thanks to Dunkan, Rasmus and Bert. Will keep the very useful tips. Best!
> >
> > On Sun, Aug 16, 2020 at 9:13 PM Rasmus Liland <jral at posteo.no> wrote:
> >
> >> On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
> >> | On Sun, Aug 16, 2020, 14:53 John wrote:
> >> | |
> >> | | I would like to make plots with
> >> | | titles for different data sets and
> >> | | different parameters. The first
> >> | | title doesn't show sigma as a math
> >> | | symbol, while the second one
> >> | | doesn't contain the s value as a
> >> | | numeric value
> >> | |
> >> | | s <- 1
> >> | | y <- rnorm(100)
> >> | | plot(y, main=paste("data", "sigma=", s))
> >> | | plot(y, main=expression(paste("data", sigma,"=", s)))
> >> |
> >> | ?plotmath
> >>
> >> Dear John, read ?plotmath, it is good, I
> >> was not aware of its existence; then
> >> backquote s like so:
> >>
> >>          plot(y, main=bquote(paste(
> >>            "data" ~~ widehat(aleph)
> >>            %notin% .(s)^.(s))))
> >>
> >> V
> >>
> >> r
> >>
> >          [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > CAUTION: This email originated from outside of USU. If this appears to
> be a USU employee, beware of impersonators. Do not click links, reply,
> download images, or open attachments unless you verify the sender?s
> identity and know the content is safe.
> >
> --
> David K Stevens, P.E., Ph.D.
> Professor, Environmental Engineering
> Civil and Environmental Engineering
> Utah Water Research Laboratory
> 8200 Old Main Hill
> Logan, UT  84322-8200
> 435 797 3229 - voice
> 435 797 1363 - fax
> david.stevens at usu.edu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From cpoiw@rt m@iii@g oii chemo@org@uk  Mon Aug 17 23:14:51 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Mon, 17 Aug 2020 22:14:51 +0100
Subject: [R] Plot math symbol with string and number
In-Reply-To: <20200817021343.GB35031@posteo.no>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
Message-ID: <cc4ad7344f9b88d3fa4d7024480cc89b@chemo.org.uk>

On 2020-08-17 03:13, Rasmus Liland wrote:
> On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
> | On Sun, Aug 16, 2020, 14:53 John wrote:
> | |
> | | I would like to make plots with
> | | titles for different data sets and
> | | different parameters. The first
> | | title doesn't show sigma as a math
> | | symbol, while the second one
> | | doesn't contain the s value as a
> | | numeric value
> | |
> | | s <- 1
> | | y <- rnorm(100)
> | | plot(y, main=paste("data", "sigma=", s))
> | | plot(y, main=expression(paste("data", sigma,"=", s)))
> |
> | ?plotmath
> 
> Dear John, read ?plotmath, it is good, I
> was not aware of its existence; then
> backquote s like so:
> 
> 

Plotmath seems to be the right way to do it.  But without reading 
plotmath I'd have gone with this:

plot(y, main=paste("data", "\u03C3=", s))


From jr@| @end|ng |rom po@teo@no  Mon Aug 17 23:40:46 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 17 Aug 2020 23:40:46 +0200
Subject: [R] Plot math symbol with string and number
In-Reply-To: <cc4ad7344f9b88d3fa4d7024480cc89b@chemo.org.uk>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
 <cc4ad7344f9b88d3fa4d7024480cc89b@chemo.org.uk>
Message-ID: <20200817214046.GH35031@posteo.no>

On 2020-08-17 22:14 +0100, cpolwart at chemo.org.uk wrote:
| On 2020-08-17 03:13, Rasmus Liland wrote:
| | On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
| | |
| | | ?plotmath
| | 
| | Dear John, read ?plotmath, it is 
| | good, I was not aware of its 
| | existence; then backquote s like 
| | so:
| 
| Plotmath seems to be the right way to 
| do it.  But without reading plotmath 
| I'd have gone with this:
| 
| plot(y, main=paste("data", "\u03C3=", s))

Good; for me copying the sigma unicode 
character into that line works too:

	plot(y, main=paste("data?=", s))

How curious 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200817/96989127/attachment.sig>

From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 17 23:54:27 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 17 Aug 2020 14:54:27 -0700
Subject: [R] Plot math symbol with string and number
In-Reply-To: <cc4ad7344f9b88d3fa4d7024480cc89b@chemo.org.uk>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
 <cc4ad7344f9b88d3fa4d7024480cc89b@chemo.org.uk>
Message-ID: <CAGxFJbR8H0tVhtXhu=O04kEdcPyY=uOa7BfHWi43_=v1wsqW2w@mail.gmail.com>

"Plotmath seems to be the right way to do it. "

Not sure I agree with that. Paul Murrell put together plotmath around 2000
prior to the widescale development and adoption of the unicode standard
(corrections/modifications welcome!).  So at the time, there really was no
other way to handle this for most OS'es. With UTF8 now being generally
supported for Unicode, plotmath constructions may not be needed for simple
symbol labeling, as here. Of course for more complex symbolism (fractions,
integrals, ...) it will be. ?plotmath talks about this and has links to
further issues and options, btw.

In other words, unicode may indeed be better than my suggestion of plotmath
here.

I would welcome comments from others who are more knowledgeable about this
than I am.

Bert

On Mon, Aug 17, 2020 at 2:14 PM <cpolwart at chemo.org.uk> wrote:

> On 2020-08-17 03:13, Rasmus Liland wrote:
> > On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
> > | On Sun, Aug 16, 2020, 14:53 John wrote:
> > | |
> > | | I would like to make plots with
> > | | titles for different data sets and
> > | | different parameters. The first
> > | | title doesn't show sigma as a math
> > | | symbol, while the second one
> > | | doesn't contain the s value as a
> > | | numeric value
> > | |
> > | | s <- 1
> > | | y <- rnorm(100)
> > | | plot(y, main=paste("data", "sigma=", s))
> > | | plot(y, main=expression(paste("data", sigma,"=", s)))
> > |
> > | ?plotmath
> >
> > Dear John, read ?plotmath, it is good, I
> > was not aware of its existence; then
> > backquote s like so:
> >
> >
>
> Plotmath seems to be the right way to do it.  But without reading
> plotmath I'd have gone with this:
>
> plot(y, main=paste("data", "\u03C3=", s))
>
>
>
>

	[[alternative HTML version deleted]]


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Aug 18 01:02:37 2020
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Tue, 18 Aug 2020 11:02:37 +1200
Subject: [R] Plot math symbol with string and number
In-Reply-To: <CAGxFJbR8H0tVhtXhu=O04kEdcPyY=uOa7BfHWi43_=v1wsqW2w@mail.gmail.com>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
 <cc4ad7344f9b88d3fa4d7024480cc89b@chemo.org.uk>
 <CAGxFJbR8H0tVhtXhu=O04kEdcPyY=uOa7BfHWi43_=v1wsqW2w@mail.gmail.com>
Message-ID: <e5673051-823f-2411-1e1b-1c78d8c355df@stat.auckland.ac.nz>


I think that comment is fair *on graphics devices that can handle unicode*.

So that is true for Cairo-based graphics devices, but not for the pdf() 
or postscript() devices, for example.

Paul

On 18/08/20 9:54 am, Bert Gunter wrote:
> "Plotmath seems to be the right way to do it."
> 
> Not sure I agree with that. Paul Murrell put together plotmath around 2000
> prior to the widescale development and adoption of the unicode standard
> (corrections/modifications welcome!).  So at the time, there really was no
> other way to handle this for most OS'es. With UTF8 now being generally
> supported for Unicode, plotmath constructions may not be needed for simple
> symbol labeling, as here. Of course for more complex symbolism (fractions,
> integrals, ...) it will be. ?plotmath talks about this and has links to
> further issues and options, btw.
> 
> In other words, unicode may indeed be better than my suggestion of plotmath
> here.
> 
> I would welcome comments from others who are more knowledgeable about this
> than I am.
> 
> Bert
> 
> On Mon, Aug 17, 2020 at 2:14 PM <cpolwart at chemo.org.uk> wrote:
> 
>> On 2020-08-17 03:13, Rasmus Liland wrote:
>>> On Sun, Aug 16, 2020 at 3:18 PM Bert wrote:
>>> | On Sun, Aug 16, 2020, 14:53 John wrote:
>>> | |
>>> | | I would like to make plots with
>>> | | titles for different data sets and
>>> | | different parameters. The first
>>> | | title doesn't show sigma as a math
>>> | | symbol, while the second one
>>> | | doesn't contain the s value as a
>>> | | numeric value
>>> | |
>>> | | s <- 1
>>> | | y <- rnorm(100)
>>> | | plot(y, main=paste("data", "sigma=", s))
>>> | | plot(y, main=expression(paste("data", sigma,"=", s)))
>>> |
>>> | ?plotmath
>>>
>>> Dear John, read ?plotmath, it is good, I
>>> was not aware of its existence; then
>>> backquote s like so:
>>>
>>>
>>
>> Plotmath seems to be the right way to do it.  But without reading
>> plotmath I'd have gone with this:
>>
>> plot(y, main=paste("data", "\u03C3=", s))
>>
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://apc01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7C3624d54caaf64787734308d842f83677%7Cd1b36e950d5042e9958fb63fa906beaa%7C0%7C0%7C637332981200092221&amp;sdata=U7ywrEh7Z3XV84pkxXfzUJTYU8BEZ995Np5xo3%2Fbn9g%3D&amp;reserved=0
> PLEASE do read the posting guide https://apc01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7C3624d54caaf64787734308d842f83677%7Cd1b36e950d5042e9958fb63fa906beaa%7C0%7C0%7C637332981200092221&amp;sdata=7VBd7dQFox%2BCEUEKgJZk6TU6cwmDS7tnAcGok9UH1WQ%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From @purd|e@@ @end|ng |rom gm@||@com  Tue Aug 18 04:08:17 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 18 Aug 2020 14:08:17 +1200
Subject: [R] install.packages() R vs RStudio
In-Reply-To: <0a56da0f-c37f-1db2-5377-70a9a1ff3cf6@gmail.com>
References: <0ce03dd4-e6af-4443-e8e3-63d5fb777395@rgzm.de>
 <15328_1597669436_07HD3tE6028766_0f3b245f-b3d7-08c2-6ec7-fabbcf4bedf6@gmail.com>
 <62db62e7-72bd-ee67-1643-a26cd540d7c7@mcmaster.ca>
 <0a56da0f-c37f-1db2-5377-70a9a1ff3cf6@gmail.com>
Message-ID: <CAB8pepwd_zNLxAceguDyR21D9K=n5M1sUjzv827qyp6ZMtffww@mail.gmail.com>

Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> R is designed to be flexible, and to let people change its behaviour.
> Using that flexibility is what all users should do.  Improving the user
> experience is what front-end writers should do.  I don't find it
> inadvisable at all.

Well, that's a big whopping U-turn.

Abby Spurdle wrote:
> There's a work around.
> You can redefine the print function, using something like:
> print = function (...) base::print (...)

Duncan Murdoch replied:
> That's a really, really bad idea.  If there are two generics named the
> same, how are your users going to know which one they are getting when
> they just say print(myobj)?

https://stat.ethz.ch/pipermail/r-devel/2018-August/076581.html

I can't see how redefining a generic function is any different from
redefining a package installation function.
And can't help but suspect, you're making an exception for RStudio...


From m|@ojpm @end|ng |rom gm@||@com  Tue Aug 18 08:06:26 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 18 Aug 2020 14:06:26 +0800
Subject: [R] Error message from "patternbar_s"
In-Reply-To: <de124954f9e3485abf1fa5e441a2e014@SRVEXCHCM1302.precheza.cz>
References: <CABcx46AVgmkigmwfuGc_Gsj+Xrh5iOm_YWGitbMBkyUJAFvQ4Q@mail.gmail.com>
 <de124954f9e3485abf1fa5e441a2e014@SRVEXCHCM1302.precheza.cz>
Message-ID: <CABcx46CKcCTo_9QWHknnv19LxRhk4psUzuk+mRQ0nZ=d3GA3LA@mail.gmail.com>

Thanks!!

PIKAL Petr <petr.pikal at precheza.cz> ? 2020?8?17? ?? ??8:17???

> Hi
>
> You probably do not have date in your data. Or date in R sense. What
> str(df_c_m) tells you about your date. I believe date is factor or
> character
> variable, which need to be converted do Date variable by appropriate way -
> e.g. strptime or as.Date.
>
> BTW, "dput" result is useful for exchanging data without losing structure.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of John
> > Sent: Monday, August 17, 2020 10:58 AM
> > To: r-help <r-help at r-project.org>
> > Subject: [R] Error message from "patternbar_s"
> >
> > Hi ,
> >
> >    I got warning message from the following code and the graph did not
> show
> > as expected; I don't have the date on the x-axis and I do not have
> legend.
> > Graph is attached.
> >    How can I fix it?
> > ******
> > x<-df_c_m$date
> > y<-df_c_m$percentage
> > group <- df_c_m$direction
> > patternbar_s(df_c_m, x,y, group, xlab='', ylab='%', label.size=3,
> > pattern.type=c(
> > 'hlines', 'vlines','bricks'), pattern.line.size=c(5, 5, 5),frame.size=1,
> >              #,background.color=c('grey', 'chartreuse3',  'bisque')
> >              pixel=16, density=c(18, 72, 54),frame.color='black',
> >              legend.type='h', legend.h=12, legend.y.pos=0.49,
> > legend.pixel=6,
> > legend.w=0.275, legend.x.pos=1.05,
> >              legend.label=c("up", "uc", "dn" ),
> > bar.width=0.8)+scale_y_continuous(limits = c(0, 100))+ggtitle('')
> > ******
> >
> > > df_c_m
> >       date direction percentage
> > 1  2019M08       up1  71.751356
> > 2  2019M09       up1  75.247309
> > 3  2019M10       up1  73.748786
> > 4  2019M11       up1  72.412511
> > 5  2019M12       up1  72.391628
> > 6  2020M01       up1  73.431773
> > 7  2020M02       up1  72.093799
> > 8  2020M03       up1  65.852532
> > 9  2020M04       up1  53.943831
> > 10 2020M05       up1  49.841939
> > 11 2020M06       up1  64.906832
> > 12 2020M07       up1  64.419087
> > 13 2019M08       uc1  26.538817
> > 14 2019M09       uc1  22.657967
> > 15 2019M10       uc1  24.500303
> > 16 2019M11       uc1  25.870263
> > 17 2019M12       uc1  25.969088
> > 18 2020M01       uc1  25.248130
> > 19 2020M02       uc1  25.272400
> > 20 2020M03       uc1  27.652675
> > 21 2020M04       uc1  33.452643
> > 22 2020M05       uc1  41.622761
> > 23 2020M06       uc1  31.469979
> > 24 2020M07       uc1  32.572614
> > 25 2019M08       dn1   1.709827
> > 26 2019M09       dn1   2.094724
> > 27 2019M10       dn1   1.750911
> > 28 2019M11       dn1   1.717225
> > 29 2019M12       dn1   1.639284
> > 30 2020M01       dn1   1.320097
> > 31 2020M02       dn1   2.633801
> > 32 2020M03       dn1   6.494793
> > 33 2020M04       dn1  12.603527
> > 34 2020M05       dn1   8.535300
> > 35 2020M06       dn1   3.623188
> > 36 2020M07       dn1   3.008299
> > > x
> >  [1] "2019M08" "2019M09" "2019M10" "2019M11" "2019M12" "2020M01"
> > "2020M02"
> >  [8] "2020M03" "2020M04" "2020M05" "2020M06" "2020M07" "2019M08"
> > "2019M09"
> > [15] "2019M10" "2019M11" "2019M12" "2020M01" "2020M02" "2020M03"
> > "2020M04"
> > [22] "2020M05" "2020M06" "2020M07" "2019M08" "2019M09" "2019M10"
> > "2019M11"
> > [29] "2019M12" "2020M01" "2020M02" "2020M03" "2020M04" "2020M05"
> > "2020M06"
> > [36] "2020M07"
> > > y
> >  [1] 71.751356 75.247309 73.748786 72.412511 72.391628 73.431773
> > 72.093799  [8] 65.852532 53.943831 49.841939 64.906832 64.419087
> > 26.538817 22.657967 [15] 24.500303 25.870263 25.969088 25.248130
> > 25.272400 27.652675 33.452643 [22] 41.622761 31.469979 32.572614
> > 1.709827  2.094724  1.750911  1.717225 [29]  1.639284  1.320097  2.633801
> > 6.494793 12.603527  8.535300  3.623188 [36]  3.008299
> > > group
> >  [1] up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 uc1 uc1 uc1 uc1 uc1
> > uc1 uc1
> > [20] uc1 uc1 uc1 uc1 uc1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1
> > Levels: up1 uc1 dn1
>

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Tue Aug 18 08:51:59 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 18 Aug 2020 14:51:59 +0800
Subject: [R] "patternbar_s" : show legend and other issues
Message-ID: <CABcx46Dmukf+J_Ydmv3tKF0mFC3XwktyZAQMmnZZES8PJweRhg@mail.gmail.com>

Hi

   Thanks for help from people on this forum. My graph (made with
patternbar_s) is attached.

(1) How should I place my legend under the graph? I have "
,legend.position="bottom"" in my theme, but it does not seem to work.
(2) How may I rotate the y label ("%")?

*****
Code:
*****
x<- factor(df_c_m$date)
df_c_m[,"date"]<-x
y<-df_c_m$percentage
group <- df_c_m$direction
patternbar_s(df_c_m, x,y, group, xlab='', ylab='%', label.size=3,
pattern.type=c( 'hlines','nwlines', 'crosshatch'), pattern.line.size=c(5,
5, 5),frame.size=0.2,
             pixel=16, density=c(18, 30, 50),frame.color='black',
              legend.label=c("up", "uc", "dn" ),
             bar.width=0.8)+scale_y_continuous(limits = c(0,
100.2))+ggtitle('')+ theme(axis.text.x = element_text(angle = 90),
aspect.ratio= 0.4 ,legend.position="bottom")
*****
data
*****
> dput(df_c_m)
structure(list(date = structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L,
8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L), .Label =
c("2019M08",
"2019M09", "2019M10", "2019M11", "2019M12", "2020M01", "2020M02",
"2020M03", "2020M04", "2020M05", "2020M06", "2020M07"), class = "factor"),
    direction = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("up1",
    "uc1", "dn1"), class = "factor"), percentage = c(71.7513561370186,
    75.2473091137506, 73.7487862435345, 72.4125114725349, 72.3916275654038,
    73.4317730346588, 72.0937990292721, 65.8525321274626, 53.9438308698102,
    49.8419388830348, 64.9068322981366, 64.4190871369295, 26.5388171383608,
    22.6579666815841, 24.5003031345886, 25.8702634409608, 25.9690881672084,
    25.2481298705291, 25.2724001268317, 27.6526752244884, 33.4526425872838,
    41.622760800843, 31.4699792960663, 32.5726141078838, 1.70982672462062,
    2.09472420466537, 1.75091062187687, 1.71722508650425, 1.63928426738778,
    1.32009709481208, 2.63380084389626, 6.49479264804901, 12.603526542906,
    8.53530031612223, 3.6231884057971, 3.00829875518672)), row.names =
c(NA,
-36L), class = "data.frame")

From c@|@ndr@ @end|ng |rom rgzm@de  Tue Aug 18 08:47:03 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 18 Aug 2020 08:47:03 +0200
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <f2524649-8ef0-5b82-9914-ceea87f6696a@gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAHrK514bb_tuy++EP=vx+1BKG6NG-bZXnBFkD_2qD1Yuhke11Q@mail.gmail.com>
 <7ab12d01-7e1e-62e7-6978-9c4935ae2349@rgzm.de>
 <f2524649-8ef0-5b82-9914-ceea87f6696a@gmail.com>
Message-ID: <7d32342b-f88f-db01-d4a4-f1062cb6c67e@rgzm.de>

Thank you again Duncan for the details.

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 17/08/2020 20:50, Duncan Murdoch wrote:
> On 17/08/2020 9:20 a.m., Ivan Calandra wrote:
>> I don't want to relight the fire, but I was wondering about that
>> statement from John C Frain:
>> "If you use RStudio and do not install any of the RStudio packages".
>>
>> I guess you mean that some packages are bundled with RStudio. I had
>> never noticed any optional packages during the installation of
>> RStudio... Is there a way to identify (and delete, if wished) these
>> packages?
>> Or have I misunderstood?
>
> When you are running RStudio, your search list will include
> "tools:rstudio".? It's not exactly a package, it's an environment
> containing functions used by the RStudio front end.? You can delete it
> and R will still work fine, but I'd expect some parts of the GUI to
> stop working.
>
> Some RStudio actions (e.g. clicking the "knit" button) will prompt you
> to install packages if they are not found.? I don't think any of them
> are "bundled" with RStudio, but I might be wrong about that.
>
> RStudio definitely installs Pandoc and maybe some other packages.
> (These aren't R packages, they are packages in a more general sense.)
> Certainly you should be able to delete Pandoc if you have permissions
> to install it; that may break RMarkdown if you don't have another copy
> somewhere.)
>
> To identify what R packages got installed, just run
> "installed.packages()" before and after installing RStudio, and look
> for differences.
>
> Duncan Murdoch
>
>
>>
>> Thank you!
>> Ivan
>>
>> -- 
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 16/08/2020 20:20, John C Frain wrote:
>>> On Sun 16 Aug 2020 at 06:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>>> a) Read about it yourself. It is a legal definition.
>>>>
>>>> b) Don't "correct" me with misinformation you are clearly inventing.
>>>> RStudio the software does not "introduce people to a modified
>>>> version of
>>>> R." Each user has to opt in to that "modified" experience by
>>>> explicitly
>>>> installing each of the the many CRAN packages that various
>>>> employees of
>>>> RStudio have created and all of which can (to my knowledge) be used
>>>> without
>>>> installing the RStudio IDE at all. Yes, a bunch of them can be
>>>> grabbed at
>>>> once by installing the tidyverse package, but that is also a choice
>>>> made by
>>>> users and by instructors struggling to deal with students who have
>>>> a hard
>>>> time with Excel much less functional programming. But RStudio is an
>>>> R IDE.
>>>>
>>>> There are a lot of packages sponsored by RStudio that I find
>>>> redundant and
>>>> slow, but portraying the RStudio company or the IDE as inherently
>>>> "not R"
>>>> just because newbies like the IDE and the packages they sponsor,
>>>> and who
>>>> end up confusing R with RStudio even though they have to install
>>>> both, is
>>>> small-minded and biased
>>>
>>> To clarify:? If you use RStudio and do not install any of the RStudio
>>> packages, R in RStudio is the same R as if you were running it from the
>>> command line.? I would think that many users find command completion,
>>> access to help files, project management Etc. useful. Nobody is asking
>>> anyone to install the RStudio packages.? I do sometimes but not
>>> always and
>>> have found them useful. Jeff is 100% correct.
>>>
>>>
>>>> ? On August 15, 2020 9:10:34 PM PDT, Abby Spurdle
>>>> <spurdle.a at gmail.com>
>>>> wrote:
>>>>> On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>> ? It is a public benefit corporation
>>>>> Seriously?
>>>>>
>>>>> On Fri, Aug 14, 2020 at 12:11 PM Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>> ? used to introduce people to R
>>>>> Correction, it introduces people to a modified version of R.
>>>> -- 
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Aug 17 14:17:33 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 17 Aug 2020 12:17:33 +0000
Subject: [R] Error message from "patternbar_s"
In-Reply-To: <CABcx46AVgmkigmwfuGc_Gsj+Xrh5iOm_YWGitbMBkyUJAFvQ4Q@mail.gmail.com>
References: <CABcx46AVgmkigmwfuGc_Gsj+Xrh5iOm_YWGitbMBkyUJAFvQ4Q@mail.gmail.com>
Message-ID: <de124954f9e3485abf1fa5e441a2e014@SRVEXCHCM1302.precheza.cz>

Hi

You probably do not have date in your data. Or date in R sense. What 
str(df_c_m) tells you about your date. I believe date is factor or character 
variable, which need to be converted do Date variable by appropriate way - 
e.g. strptime or as.Date.

BTW, "dput" result is useful for exchanging data without losing structure.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of John
> Sent: Monday, August 17, 2020 10:58 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] Error message from "patternbar_s"
>
> Hi ,
>
>    I got warning message from the following code and the graph did not show
> as expected; I don't have the date on the x-axis and I do not have legend.
> Graph is attached.
>    How can I fix it?
> ******
> x<-df_c_m$date
> y<-df_c_m$percentage
> group <- df_c_m$direction
> patternbar_s(df_c_m, x,y, group, xlab='', ylab='%', label.size=3, 
> pattern.type=c(
> 'hlines', 'vlines','bricks'), pattern.line.size=c(5, 5, 5),frame.size=1,
>              #,background.color=c('grey', 'chartreuse3',  'bisque')
>              pixel=16, density=c(18, 72, 54),frame.color='black',
>              legend.type='h', legend.h=12, legend.y.pos=0.49, 
> legend.pixel=6,
> legend.w=0.275, legend.x.pos=1.05,
>              legend.label=c("up", "uc", "dn" ),
> bar.width=0.8)+scale_y_continuous(limits = c(0, 100))+ggtitle('')
> ******
>
> > df_c_m
>       date direction percentage
> 1  2019M08       up1  71.751356
> 2  2019M09       up1  75.247309
> 3  2019M10       up1  73.748786
> 4  2019M11       up1  72.412511
> 5  2019M12       up1  72.391628
> 6  2020M01       up1  73.431773
> 7  2020M02       up1  72.093799
> 8  2020M03       up1  65.852532
> 9  2020M04       up1  53.943831
> 10 2020M05       up1  49.841939
> 11 2020M06       up1  64.906832
> 12 2020M07       up1  64.419087
> 13 2019M08       uc1  26.538817
> 14 2019M09       uc1  22.657967
> 15 2019M10       uc1  24.500303
> 16 2019M11       uc1  25.870263
> 17 2019M12       uc1  25.969088
> 18 2020M01       uc1  25.248130
> 19 2020M02       uc1  25.272400
> 20 2020M03       uc1  27.652675
> 21 2020M04       uc1  33.452643
> 22 2020M05       uc1  41.622761
> 23 2020M06       uc1  31.469979
> 24 2020M07       uc1  32.572614
> 25 2019M08       dn1   1.709827
> 26 2019M09       dn1   2.094724
> 27 2019M10       dn1   1.750911
> 28 2019M11       dn1   1.717225
> 29 2019M12       dn1   1.639284
> 30 2020M01       dn1   1.320097
> 31 2020M02       dn1   2.633801
> 32 2020M03       dn1   6.494793
> 33 2020M04       dn1  12.603527
> 34 2020M05       dn1   8.535300
> 35 2020M06       dn1   3.623188
> 36 2020M07       dn1   3.008299
> > x
>  [1] "2019M08" "2019M09" "2019M10" "2019M11" "2019M12" "2020M01"
> "2020M02"
>  [8] "2020M03" "2020M04" "2020M05" "2020M06" "2020M07" "2019M08"
> "2019M09"
> [15] "2019M10" "2019M11" "2019M12" "2020M01" "2020M02" "2020M03"
> "2020M04"
> [22] "2020M05" "2020M06" "2020M07" "2019M08" "2019M09" "2019M10"
> "2019M11"
> [29] "2019M12" "2020M01" "2020M02" "2020M03" "2020M04" "2020M05"
> "2020M06"
> [36] "2020M07"
> > y
>  [1] 71.751356 75.247309 73.748786 72.412511 72.391628 73.431773
> 72.093799  [8] 65.852532 53.943831 49.841939 64.906832 64.419087
> 26.538817 22.657967 [15] 24.500303 25.870263 25.969088 25.248130
> 25.272400 27.652675 33.452643 [22] 41.622761 31.469979 32.572614
> 1.709827  2.094724  1.750911  1.717225 [29]  1.639284  1.320097  2.633801
> 6.494793 12.603527  8.535300  3.623188 [36]  3.008299
> > group
>  [1] up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 up1 uc1 uc1 uc1 uc1 uc1
> uc1 uc1
> [20] uc1 uc1 uc1 uc1 uc1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1 dn1
> Levels: up1 uc1 dn1

From m|@ojpm @end|ng |rom gm@||@com  Tue Aug 18 08:31:30 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 18 Aug 2020 14:31:30 +0800
Subject: [R] "patternbar_s" : show legend and other issues
Message-ID: <CABcx46Ce3DDwjjNYFR69DAZeV39ELuvajUyPkPEZO6Ans2XuSg@mail.gmail.com>

Hi

   Thanks for help from people on this forum. My graph (made with
patternbar_s) is attached.

(1) How should I place my legend under the graph? I have "
,legend.position="bottom"" in my theme, but it does not seem to work.
(2) How may I rotate the y label ("%")?

*****
Code:
*****
x<- factor(df_c_m$date)
df_c_m[,"date"]<-x
y<-df_c_m$percentage
group <- df_c_m$direction
patternbar_s(df_c_m, x,y, group, xlab='', ylab='%', label.size=3,
pattern.type=c( 'hlines','nwlines', 'crosshatch'), pattern.line.size=c(5,
5, 5),frame.size=0.2,
             pixel=16, density=c(18, 30, 50),frame.color='black',
              legend.label=c("up", "uc", "dn" ),
             bar.width=0.8)+scale_y_continuous(limits = c(0,
100.2))+ggtitle('')+ theme(axis.text.x = element_text(angle = 90),
aspect.ratio= 0.4 ,legend.position="bottom")
*****
data: attached

-------------- next part --------------
A non-text attachment was scrubbed...
Name: temp200818.pdf
Type: application/pdf
Size: 214674 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200818/42c5ce52/attachment.pdf>

From d@tr7320 @end|ng |rom un|@@ydney@edu@@u  Tue Aug 18 09:00:09 2020
From: d@tr7320 @end|ng |rom un|@@ydney@edu@@u (Dario Strbenac)
Date: Tue, 18 Aug 2020 07:00:09 +0000
Subject: [R] Calculating Minimum Absolute Difference of Two Numeric Vectors
Message-ID: <SYBPR01MB4761B22C41F590A4C35D94F5CD5C0@SYBPR01MB4761.ausprd01.prod.outlook.com>

Good day,

What is a fast and efficient way to calculate the minimum absolute difference between two vectors of numbers? The two vectors have unequal length. I would also like to know the index of the first vector and the second vector which results in the minimum absolute difference. For example:

x <- rpois(500, 100)
y <- rpois(300, 30)

Is there a much faster way than a nested for loop without resorting to Rcpp?

--------------------------------------
Dario Strbenac
University of Sydney
Camperdown NSW 2050
Australia


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Aug 18 10:35:03 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 18 Aug 2020 01:35:03 -0700
Subject: [R] 
 Calculating Minimum Absolute Difference of Two Numeric Vectors
In-Reply-To: <SYBPR01MB4761B22C41F590A4C35D94F5CD5C0@SYBPR01MB4761.ausprd01.prod.outlook.com>
References: <SYBPR01MB4761B22C41F590A4C35D94F5CD5C0@SYBPR01MB4761.ausprd01.prod.outlook.com>
Message-ID: <A8956A8B-3708-47B7-8852-1695D5D75213@dcn.davis.ca.us>

This looks more like a code challenge than a real problem, but anyway Rcpp seems unnecessary.

x <- (2:5)^2/3
y <- (1:6)+0.1
ad <- function( a, b ) {
  abs( a - b )
}
M <- outer( x, y, FUN=ad )
which( M==min(M), arr.ind = TRUE )

On August 18, 2020 12:00:09 AM PDT, Dario Strbenac <dstr7320 at uni.sydney.edu.au> wrote:
>Good day,
>
>What is a fast and efficient way to calculate the minimum absolute
>difference between two vectors of numbers? The two vectors have unequal
>length. I would also like to know the index of the first vector and the
>second vector which results in the minimum absolute difference. For
>example:
>
>x <- rpois(500, 100)
>y <- rpois(300, 30)
>
>Is there a much faster way than a nested for loop without resorting to
>Rcpp?
>
>--------------------------------------
>Dario Strbenac
>University of Sydney
>Camperdown NSW 2050
>Australia
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Tue Aug 18 10:35:07 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 18 Aug 2020 10:35:07 +0200
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <f2524649-8ef0-5b82-9914-ceea87f6696a@gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
 <CAB8pepxhwB3MK1Esh0Nkbo3z8zFAQ0=DY6o0vS4tXQt4D3yL8w@mail.gmail.com>
 <1304BB53-9CDB-4106-9909-04DA62DC7602@dcn.davis.ca.us>
 <CAHrK514bb_tuy++EP=vx+1BKG6NG-bZXnBFkD_2qD1Yuhke11Q@mail.gmail.com>
 <7ab12d01-7e1e-62e7-6978-9c4935ae2349@rgzm.de>
 <f2524649-8ef0-5b82-9914-ceea87f6696a@gmail.com>
Message-ID: <20200818083507.GI35031@posteo.no>

On 2020-08-17 14:50 -0400, Duncan Murdoch wrote:
| 
| Certainly you should be able to delete 
| Pandoc if you have permissions to 
| install it; that may break RMarkdown 
| if you don't have another copy 
| somewhere.)

I use Rmarkdown outside of Rstudio, just 
with rmarkdown::render in an Rscript run 
with entr[1].  On ArchLinux I at least 
need pandoc-citeproc[2] which needs a 
bunch of other Haskell packages.

[1] http://eradman.com/entrproject
[2] https://hackage.haskell.org/package/pandoc-citeproc

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200818/386ffc46/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Tue Aug 18 10:57:13 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 18 Aug 2020 10:57:13 +0200
Subject: [R] Plot math symbol with string and number
In-Reply-To: <e5673051-823f-2411-1e1b-1c78d8c355df@stat.auckland.ac.nz>
References: <CAFyG=WMJhmz-FjAnVh3B5Pe4EqM4Na9JDLJNx53Y3QcX5Ecm=w@mail.gmail.com>
 <CAGxFJbQfv41iycMeY67k6Wq7DZyubKiQyZCg0qbSbUVefs_jQg@mail.gmail.com>
 <CAGxFJbSpzQsNKfyTiTiiYd+V0u6dXrttiVB7K_R0AyCrMSu22Q@mail.gmail.com>
 <20200817021343.GB35031@posteo.no>
 <cc4ad7344f9b88d3fa4d7024480cc89b@chemo.org.uk>
 <CAGxFJbR8H0tVhtXhu=O04kEdcPyY=uOa7BfHWi43_=v1wsqW2w@mail.gmail.com>
 <e5673051-823f-2411-1e1b-1c78d8c355df@stat.auckland.ac.nz>
Message-ID: <20200818085713.GJ35031@posteo.no>

On 2020-08-18 11:02 +1200, Paul Murrell wrote:
| On 18/08/20 9:54 am, Bert Gunter wrote:
| | On Mon, Aug 17, 2020 at 2:14 PM <cpolwart at chemo.org.uk> wrote:
| | | 
| | | Plotmath seems to be the right way 
| | | to do it.  But without reading 
| | | plotmath I'd have gone with this:
| | | 
| | | plot(y, main=paste("data", "\u03C3=", s))
| | 
| | "Plotmath seems to be the right way 
| | to do it."
| | 
| | Not sure I agree with that. Paul 
| | Murrell put together plotmath around 
| | 2000 prior to the widescale 
| | development and adoption of the 
| | unicode standard 
| | (corrections/modifications 
| | welcome!).  So at the time, there 
| | really was no other way to handle 
| | this for most OS'es. With UTF8 now 
| | being generally supported for 
| | Unicode, plotmath constructions may 
| | not be needed for simple symbol 
| | labeling, as here. Of course for 
| | more complex symbolism (fractions, 
| | integrals, ...) it will be. 
| | ?plotmath talks about this and has 
| | links to further issues and options, 
| | btw.
| | 
| | In other words, unicode may indeed 
| | be better than my suggestion of 
| | plotmath here.
| 
| I think that comment is fair *on 
| graphics devices that can handle 
| unicode*.
| 
| So that is true for Cairo-based 
| graphics devices, but not for the 
| pdf() or postscript() devices, for 
| example.

Eventhough I'm a heavy user of pdf(), I 
didn't notice at first that the sigma 
gets converted to two dots with the 
error messages

	Warning messages:
	1: In title(...) :
	  conversion failure on 'data ?= 1' in 'mbcsToSbcs': dot substituted for <cf>
	2: In title(...) :
	  conversion failure on 'data ?= 1' in 'mbcsToSbcs': dot substituted for <83>
	3: In title(...) :
	  conversion failure on 'data ?= 1' in 'mbcsToSbcs': dot substituted for <cf>
	4: In title(...) :
	  conversion failure on 'data ?= 1' in 'mbcsToSbcs': dot substituted for <83>

like if it was a Han character (most 
likely three dots in that case), I just 
ran with cpolwart's suggestion in 
whatever is the default on the R 
console, probably that Cairo thing.  
png() works ofc. 

V

r

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200818/fc34fe32/attachment.sig>

From yjt7660 @end|ng |rom gm@||@com  Tue Aug 18 15:59:01 2020
From: yjt7660 @end|ng |rom gm@||@com (Joon-Taek Yoo)
Date: Tue, 18 Aug 2020 22:59:01 +0900
Subject: [R] an error message in getNOAA.bathy function
Message-ID: <CAPFqpxEA_mY5Be8P4iU=80dRKH5R3JDcpoPXnCv2_HvWGtMg1A@mail.gmail.com>

Dear Helpers,
I am trying to draw a map of East Asia using the getNOAA.bathy ()
function(package marmap) in R. I'v got a following error message.

> dat <- getNOAA.bathy(110, 160, 20, 60, res=4, keep=T)
Querying NOAA database ...
This may take seconds to minutes, depending on grid size
Error in .local(.Object, ...) :
  schannel: next InitializeSecurityContext failed: SEC_E_ILLEGAL_MESSAGE
(0x80090326) - This error usually occurs when a fatal SSL/TLS alert is
received (e.g. handshake failed).

I appreciate any hint. Please could you help me.

Thank you very much.
Yoo

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 18 16:17:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 18 Aug 2020 07:17:09 -0700
Subject: [R] an error message in getNOAA.bathy function
In-Reply-To: <CAPFqpxEA_mY5Be8P4iU=80dRKH5R3JDcpoPXnCv2_HvWGtMg1A@mail.gmail.com>
References: <CAPFqpxEA_mY5Be8P4iU=80dRKH5R3JDcpoPXnCv2_HvWGtMg1A@mail.gmail.com>
Message-ID: <CAGxFJbR5UQY-nOo1n5_Bm1n3+5DBYK_wbnR89eG4MA1OqtPWmg@mail.gmail.com>

I think you are more likely to get a helpful reply on the R-sig-geo list
rather than here.

If all else fails, try contacting the maintainer ( ?maintainer) .

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 18, 2020 at 6:59 AM Joon-Taek Yoo <yjt7660 at gmail.com> wrote:

> Dear Helpers,
> I am trying to draw a map of East Asia using the getNOAA.bathy ()
> function(package marmap) in R. I'v got a following error message.
>
> > dat <- getNOAA.bathy(110, 160, 20, 60, res=4, keep=T)
> Querying NOAA database ...
> This may take seconds to minutes, depending on grid size
> Error in .local(.Object, ...) :
>   schannel: next InitializeSecurityContext failed: SEC_E_ILLEGAL_MESSAGE
> (0x80090326) - This error usually occurs when a fatal SSL/TLS alert is
> received (e.g. handshake failed).
>
> I appreciate any hint. Please could you help me.
>
> Thank you very much.
> Yoo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Tue Aug 18 16:36:37 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 18 Aug 2020 16:36:37 +0200
Subject: [R] an error message in getNOAA.bathy function
In-Reply-To: <CAPFqpxEA_mY5Be8P4iU=80dRKH5R3JDcpoPXnCv2_HvWGtMg1A@mail.gmail.com>
References: <CAPFqpxEA_mY5Be8P4iU=80dRKH5R3JDcpoPXnCv2_HvWGtMg1A@mail.gmail.com>
Message-ID: <20200818143637.GK35031@posteo.no>

On 2020-08-18 22:59 +0900, Joon-Taek Yoo wrote:
| Dear Helpers,
| I am trying to draw a map of East Asia 
| using the getNOAA.bathy () 
| function(package marmap) in R. I'v got 
| a following error message.
| 
| > dat <- getNOAA.bathy(110, 160, 20, 60, res=4, keep=T)
| Querying NOAA database ...
| This may take seconds to minutes, depending on grid size
| Error in .local(.Object, ...) :
|   schannel: next InitializeSecurityContext failed: SEC_E_ILLEGAL_MESSAGE
| (0x80090326) - This error usually occurs when a fatal SSL/TLS alert is
| received (e.g. handshake failed).
| 
| I appreciate any hint. Please could 
| you help me.

Dear Joon-Taek,

perhaps ?turning off? SSL helps, by 
setting these options:

	options("ssl_verifyhost"=0, "ssl_verifypeer"=0)

I get another error (with SSL turned 
on):

	> dat <- marmap::getNOAA.bathy(110, 160, 20, 60, res=4, keep=T)
	Registered S3 methods overwritten by 'adehabitatMA':
	  method                       from
	  print.SpatialPixelsDataFrame sp
	  print.SpatialPixels          sp
	Querying NOAA database ...
	This may take seconds to minutes, depending on grid size
	Error in if (ncol(x) == 3 & !exists("bathy", inherits = FALSE)) { :
	  argument is of length zero

How do I even know what x is there, or 
if "bathy" exists ...

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200818/5dfdda32/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Tue Aug 18 18:01:35 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 18 Aug 2020 18:01:35 +0200
Subject: [R] an error message in getNOAA.bathy function
In-Reply-To: <20200818143637.GK35031@posteo.no>
References: <CAPFqpxEA_mY5Be8P4iU=80dRKH5R3JDcpoPXnCv2_HvWGtMg1A@mail.gmail.com>
 <20200818143637.GK35031@posteo.no>
Message-ID: <20200818160135.GL35031@posteo.no>

On 2020-08-18 16:36 +0200, Rasmus Liland wrote:
> On 2020-08-18 22:59 +0900, Joon-Taek Yoo wrote:
> | Dear Helpers,
> | I am trying to draw a map of East Asia 
> | using the getNOAA.bathy () 
> | function(package marmap) in R. I'v got 
> | a following error message.
> | 
> | > dat <- getNOAA.bathy(110, 160, 20, 60, res=4, keep=T)
> | Querying NOAA database ...
> | This may take seconds to minutes, depending on grid size
> | Error in .local(.Object, ...) :
> |   schannel: next InitializeSecurityContext failed: SEC_E_ILLEGAL_MESSAGE
> | (0x80090326) - This error usually occurs when a fatal SSL/TLS alert is
> | received (e.g. handshake failed).
> | 
> | I appreciate any hint. Please could 
> | you help me.
> 
> Dear Joon-Taek,
> 
> perhaps ?turning off? SSL helps, by 
> setting these options:
> 
> 	options("ssl_verifyhost"=0, "ssl_verifypeer"=0)
> 
> I get another error (with SSL turned 
> on):
> 
> 	> dat <- marmap::getNOAA.bathy(110, 160, 20, 60, res=4, keep=T)
> 	Registered S3 methods overwritten by 'adehabitatMA':
> 	  method                       from
> 	  print.SpatialPixelsDataFrame sp
> 	  print.SpatialPixels          sp
> 	Querying NOAA database ...
> 	This may take seconds to minutes, depending on grid size
> 	Error in if (ncol(x) == 3 & !exists("bathy", inherits = FALSE)) { :
> 	  argument is of length zero
> 
> How do I even know what x is there, or 
> if "bathy" exists ...

Also, check out my old email from back 
in March[1] about mapping the Gulf 
Cooperation Council countries using 
ggplot.  You need the packages rgeos, 
rnaturalearth, sf; which needs the 
backend programs udunits[2], gdal[3], 
perhaps others.

Here is an example map of a wider region 
of East-Asia also showing Laos.

	world <- rnaturalearth::ne_countries(
	  scale = "medium",
	  returnclass = "sf")
	grp1 <- c("China", "Japan", "Korea", 
	  "Dem. Rep. Korea", "Taiwan", "Mongolia",
	  "Hong Kong", "Macao", "Russia")
	world$EA <- rep(NA, length(world$name))
	idx <- world$name %in% grp1
	world$GCC[idx] <- world$name[idx]
	world$CountryGroup <- 
	  rep(NA, length(world$name))
	world$CountryGroup[world$name
	  %in% grp1] <- "East-Asia"
	world <- 
	  cbind(world, 
	    sf::st_coordinates(
	      sf::st_centroid(world$geometry)))
	world$name[idx]
	
	# file <- "/tmp/ea.pdf"
	# res <- 1.2
	# width <- 7*res
	# height <- 5*res
	# pdf(file=file, width=width, height=height)
	
	file <- "/tmp/ea.png"
	res <- 100
	width <- 500
	height <- 500
	png(file=file, width=width,
	    height=height, res=res)
	
	ggplot2::ggplot(data = world) +
	  ggplot2::theme_bw() +
	  ggplot2::geom_sf() +
	  ggplot2::geom_sf(
	    fill = NA, color = gray(.5)) +
	  ggplot2::geom_sf(ggplot2::aes(
	    fill=CountryGroup)) +
	  ggrepel::geom_text_repel(
	    mapping=ggplot2::aes(
	      x=X, y=Y, label=GCC),
	    color="blue") +
	ggplot2::coord_sf(
	  xlim = c(100, 160),
	  ylim = c(10, 60),
	  expand = FALSE) +
	ggplot2::xlab("Longitude") +
	ggplot2::ylab("Latitude") +
	  ggplot2::ggtitle("East-Asia")
	
	dev.off()

Best,
Rasmus

[1] https://stat.ethz.ch/pipermail/r-help/2020-March/466155.html
[2] http://www.unidata.ucar.edu/software/udunits/
[3] http://www.gdal.org/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ea.png
Type: image/png
Size: 52931 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200818/b5a1bec1/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200818/b5a1bec1/attachment.sig>

From petr@p|k@| @end|ng |rom prechez@@cz  Tue Aug 18 10:37:50 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 18 Aug 2020 08:37:50 +0000
Subject: [R] "patternbar_s" : show legend and other issues
In-Reply-To: <CABcx46Ce3DDwjjNYFR69DAZeV39ELuvajUyPkPEZO6Ans2XuSg@mail.gmail.com>
References: <CABcx46Ce3DDwjjNYFR69DAZeV39ELuvajUyPkPEZO6Ans2XuSg@mail.gmail.com>
Message-ID: <129403c0dab6400cbfdd99d8ba7f0370@SRVEXCHCM1302.precheza.cz>

Hi

Probably patternbar handles legend position in nonstandard way so 
lebend.position does not work as expected.

Rotating % is done by axis.title.y ...
theme(axis.text.x = element_text(angle = 90),
axis.title.y = element_text(angle=0),
aspect.ratio= 0.4)

Legend has to be placed probably by legend.y.pos and legend.x.pos.

patternbar_s(df_c_m, x,y, group, xlab='', ylab='%', label.size=3,
pattern.type=c( 'hlines','nwlines', 'crosshatch'),
pattern.line.size=c(5, 5, 5),frame.size=0.2,
pixel=16, density=c(18, 30, 50),frame.color='black',
legend.label=c("up", "uc", "dn" ), bar.width=0.8,
legend.y.pos = .49, legend.x.pos = 1.1) +
scale_y_continuous(limits = c(0, 150.2))

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of John
> Sent: Tuesday, August 18, 2020 8:32 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] "patternbar_s" : show legend and other issues
>
> Hi
>
>    Thanks for help from people on this forum. My graph (made with
> patternbar_s) is attached.
>
> (1) How should I place my legend under the graph? I have "
> ,legend.position="bottom"" in my theme, but it does not seem to work.
> (2) How may I rotate the y label ("%")?
>
> *****
> Code:
> *****
> x<- factor(df_c_m$date)
> df_c_m[,"date"]<-x
> y<-df_c_m$percentage
> group <- df_c_m$direction
> patternbar_s(df_c_m, x,y, group, xlab='', ylab='%', label.size=3, 
> pattern.type=c(
> 'hlines','nwlines', 'crosshatch'), pattern.line.size=c(5, 5, 
> 5),frame.size=0.2,
>              pixel=16, density=c(18, 30, 50),frame.color='black',
>               legend.label=c("up", "uc", "dn" ),
>              bar.width=0.8)+scale_y_continuous(limits = c(0, 
> 100.2))+ggtitle('')+
> theme(axis.text.x = element_text(angle = 90), aspect.ratio= 0.4
> ,legend.position="bottom")
> *****
> data: attached

From petr@p|k@| @end|ng |rom prechez@@cz  Tue Aug 18 11:00:07 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 18 Aug 2020 09:00:07 +0000
Subject: [R] 
 Calculating Minimum Absolute Difference of Two Numeric Vectors
In-Reply-To: <SYBPR01MB4761B22C41F590A4C35D94F5CD5C0@SYBPR01MB4761.ausprd01.prod.outlook.com>
References: <SYBPR01MB4761B22C41F590A4C35D94F5CD5C0@SYBPR01MB4761.ausprd01.prod.outlook.com>
Message-ID: <a3d5dcd2aa294aefafea177baa5d0c1d@SRVEXCHCM1302.precheza.cz>

Hi

maybe

min(abs(outer(x,y, "-")))

If you want indices 

mm <- min(abs(outer(x,y, "-")))
which(abs(outer(x,y, "-"))== mm, arr.ind=TRUE)

And in original vectors

x[which(abs(outer(x,y, "-"))== mm, arr.ind=TRUE)[1]]
y[which(abs(outer(x,y, "-"))== mm, arr.ind=TRUE)[2]]

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dario Strbenac
> Sent: Tuesday, August 18, 2020 9:00 AM
> To: r-help at r-project.org
> Subject: [R] Calculating Minimum Absolute Difference of Two Numeric
Vectors
> 
> Good day,
> 
> What is a fast and efficient way to calculate the minimum absolute
difference
> between two vectors of numbers? The two vectors have unequal length. I
> would also like to know the index of the first vector and the second
vector
> which results in the minimum absolute difference. For example:
> 
> x <- rpois(500, 100)
> y <- rpois(300, 30)
> 
> Is there a much faster way than a nested for loop without resorting to
Rcpp?
> 
> --------------------------------------
> Dario Strbenac
> University of Sydney
> Camperdown NSW 2050
> Australia
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @@mo|n@r @end|ng |rom @bcg|ob@|@net  Tue Aug 18 17:35:11 2020
From: @@mo|n@r @end|ng |rom @bcg|ob@|@net (Stephen P. Molnar)
Date: Tue, 18 Aug 2020 11:35:11 -0400
Subject: [R] R Script Modification Questions
References: <5F3BF52F.7050908.ref@sbcglobal.net>
Message-ID: <5F3BF52F.7050908@sbcglobal.net>

Thanks to the kind folks on this list, this is an elegant replacement 
for the clumsy R script that I that I wrote.




However, I do have a few changes that I would like to make. The problem 
is that while I know how to make changes in Python, I am still bumbling 
around in R Code.

The day-to-day changes in the data are in the cvs file downloaded in 
line 11 of the code.

What I would like to do is use linetype, rather than color, in line 27.

The date in the title of the plot , line 33, is the max value of the 
date in in line 14 and I would like to use that rather than edit the 
Script every time the date changes.

I'd appreciate assistance in making these changes.

Thanks in advance,.

-- 
Stephen P. Molnar, Ph.D.
www.molecular-modeling.net
614.312.7528 (c)
Skype:  smolnar1


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 18 20:09:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 18 Aug 2020 11:09:33 -0700
Subject: [R] R Script Modification Questions
In-Reply-To: <5F3BF52F.7050908@sbcglobal.net>
References: <5F3BF52F.7050908.ref@sbcglobal.net>
 <5F3BF52F.7050908@sbcglobal.net>
Message-ID: <CAGxFJbR+e-bLakoo3K6SHF_PRTHma-hZ6Vpqh5rO6Bs+Y1_9Jg@mail.gmail.com>

1. Generally you should make your posts self-contained -- I see no line
14's or 33's or whatever. Note that you did not continue the old thread
either. I have no desire to go poking around in previous threads (others
certainly may!).

2. Re: max of dates.

 max(as.Date(c("1976-04-07","1982-02-22")))
[1] "1982-02-22"

You seem to be asking basic questions that indicate a need to spend some
time with R tutorials, in this case S3 methods and dates. See ?"date-time"
for a terse but dense explanation; numerous web tutorials are available
that are more suitable for most of us learning new R or R package features.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 18, 2020 at 10:10 AM Stephen P. Molnar <s.molnar at sbcglobal.net>
wrote:

> Thanks to the kind folks on this list, this is an elegant replacement
> for the clumsy R script that I that I wrote.
>
>
>
>
> However, I do have a few changes that I would like to make. The problem
> is that while I know how to make changes in Python, I am still bumbling
> around in R Code.
>
> The day-to-day changes in the data are in the cvs file downloaded in
> line 11 of the code.
>
> What I would like to do is use linetype, rather than color, in line 27.
>
> The date in the title of the plot , line 33, is the max value of the
> date in in line 14 and I would like to use that rather than edit the
> Script every time the date changes.
>
> I'd appreciate assistance in making these changes.
>
> Thanks in advance,.
>
> --
> Stephen P. Molnar, Ph.D.
> www.molecular-modeling.net
> 614.312.7528 (c)
> Skype:  smolnar1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Wed Aug 19 02:48:28 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 19 Aug 2020 02:48:28 +0200
Subject: [R] R Script Modification Questions
In-Reply-To: <CAGxFJbR+e-bLakoo3K6SHF_PRTHma-hZ6Vpqh5rO6Bs+Y1_9Jg@mail.gmail.com>
References: <5F3BF52F.7050908.ref@sbcglobal.net>
 <5F3BF52F.7050908@sbcglobal.net>
 <CAGxFJbR+e-bLakoo3K6SHF_PRTHma-hZ6Vpqh5rO6Bs+Y1_9Jg@mail.gmail.com>
Message-ID: <20200819004828.GA302363@posteo.no>

Dear Stephen,  I reply you inline:

On 2020-08-18 11:09 -0700, Bert Gunter wrote:
| On Tue, Aug 18, 2020 at 10:10 AM Stephen P. Molnar <s.molnar at sbcglobal.net> wrote:
| | 
| | Thanks to the kind folks on this 
| | list, this is an elegant replacement 
| | for the clumsy R script that I that 
| | I wrote.
| |
| |
| |
| |
| 
| 1. Generally you should make your 
|    posts self-contained -- I see no 
|    line 14's or 33's or whatever. Note 
|    that you did not continue the old 
|    thread either. I have no desire to 
|    go poking around in previous 
|    threads (others certainly may!).

There were a bunch of blank lines in 
this area.  Maybe you put your script 
here in a picture or something which 
disappeared somewhere in the guts of the 
stat.ethz.ch mailfilter.

| | However, I do have a few changes 
| | that I would like to make. The 
| | problem is that while I know how to 
| | make changes in Python, I am still 
| | bumbling around in R Code.

I came from python to R some years ago, 
and it is easier I think, if you spend 
some time on it.

| | The day-to-day changes in the data 
| | are in the cvs file downloaded in 
| | line 11 of the code.

Good, now provide line 11.  

| | What I would like to do is use 
| | linetype, rather than color, in line 
| | 27.

You can specify linetype as an argument 
to ggplot2::aes instead of color.  
Perhaps try this, if it is what you did.  
This should also be easy in normal plot, 
see ?par.

| | The date in the title of the plot , 
| | line 33, is the max value of the 
| | date in in line 14 and I would like 
| | to use that rather than edit the 
| | Script every time the date changes.
| 
| 2. Re: max of dates.
| 
|  max(as.Date(c("1976-04-07","1982-02-22")))
| [1] "1982-02-22"
| 
| You seem to be asking basic questions 
| that indicate a need to spend some 
| time with R tutorials, in this case S3 
| methods and dates. See ?"date-time" 
| for a terse but dense explanation; 
| numerous web tutorials are available 
| that are more suitable for most of us 
| learning new R or R package features.

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200819/1d15f330/attachment.sig>

From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 19 04:57:31 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 19 Aug 2020 12:57:31 +1000
Subject: [R] R Script Modification Questions
In-Reply-To: <5F3C8C70.4020901@sbcglobal.net>
References: <5F3BF52F.7050908.ref@sbcglobal.net>
 <5F3BF52F.7050908@sbcglobal.net>
 <CA+8X3fUSOY3a1bEELpqVBwK5cLGCW6Z+OGRfi_+GZ+MXj6zh6A@mail.gmail.com>
 <5F3C8C70.4020901@sbcglobal.net>
Message-ID: <CA+8X3fWoYKDXj26WAhViENyM23ZWYUx4o6HMgdBUqAPhg7u2hQ@mail.gmail.com>

Okay, I can't help much with the ggplot stuff so forget the "lty="
argument for that is base graphics. However, you may get away with

ggtitle(paste0("COVID-19 Tests in Ohio \n(",date[length(date]),")"))+

I don't know whether the tidy* stuff handles indexing in the same way as base R.

Jim

On Wed, Aug 19, 2020 at 12:20 PM Stephen P. Molnar
<s.molnar at sbcglobal.net> wrote:
>
> Jim
>
> Thanks for your note.
>
> This is what didn't make it through:
>
> library(tidyverse)
> library(lubridate)
>
> datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
> <- line 14
> datO[ ,1] <- ymd(datO[ ,1])
>
> dfO <- tibble::as_tibble(data.frame(date = datO[ ,"date"],
>                                      positive = datO[ ,"positive"],
>                                      negative = datO[ ,"negative"],
>                                      total = datO[ ,"total"]))
>
> dfO %>%
>    pivot_longer(
>      cols = -date,
>      names_to = "cases",
>      values_to = "count"
>    ) %>%
>    mutate(cases = factor(cases, levels = c("positive", "negative",
> "total"))) %>%
>    ggplot(aes(date, count, color = cases)) +
>    geom_line() +
>    scale_color_manual(name = "Test",
>                       labels = c("Positive", "Negative", "Total"),
>                       values = c("red", "blue", "green")) +
>    ylim(0, 2000000) +
>    labs(x = "Date", y = "Number of Tests")+
>    ggtitle("COVID-19 Tests in Ohio \n (8/17/20)")+   <- line 33
>    theme_bw() +
>    theme(axis.text.x = element_text(angle = 30, hjust = 1),
>          plot.title = element_text(hjust = 0.5))
>
>              Steve
>
> On 08/18/2020 07:55 PM, Jim Lemon wrote:
> > Hi Stephen,
> > I think something went amiss with your email as there are a few blank
> > lines where I think you meant to paste a code fragment. Line type is
> > specified by the "lty" argument and to stick things together for your
> > plot title, you may want something like this:
> >
> > ..
> > main<-paste("My plot title for",dates[length(dates)]).
> > ..
> >
> > Jim
> >
> > On Wed, Aug 19, 2020 at 3:09 AM Stephen P. Molnar
> > <s.molnar at sbcglobal.net> wrote:
> >> Thanks to the kind folks on this list, this is an elegant replacement
> >> for the clumsy R script that I that I wrote.
> >>
> >>
> >>
> >>
> >> However, I do have a few changes that I would like to make. The problem
> >> is that while I know how to make changes in Python, I am still bumbling
> >> around in R Code.
> >>
> >> The day-to-day changes in the data are in the cvs file downloaded in
> >> line 11 of the code.
> >>
> >> What I would like to do is use linetype, rather than color, in line 27.
> >>
> >> The date in the title of the plot , line 33, is the max value of the
> >> date in in line 14 and I would like to use that rather than edit the
> >> Script every time the date changes.
> >>
> >> I'd appreciate assistance in making these changes.
> >>
> >> Thanks in advance,.
> >>
> >> --
> >> Stephen P. Molnar, Ph.D.
> >> www.molecular-modeling.net
> >> 614.312.7528 (c)
> >> Skype:  smolnar1
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Stephen P. Molnar, Ph.D.
> www.molecular-modeling.net
> 614.312.7528 (c)
> Skype:  smolnar1
>


From U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de  Wed Aug 19 10:52:57 2020
From: U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de (Ulrik Stervbo)
Date: Wed, 19 Aug 2020 10:52:57 +0200
Subject: [R] Binomial PCA Using pcr()
In-Reply-To: <CAN+jWPpZNCMrn=VFSPax3U3LmAzYKaWb2HZsTt97oYWgcQHPLA@mail.gmail.com>
References: <CAN+jWPpZNCMrn=VFSPax3U3LmAzYKaWb2HZsTt97oYWgcQHPLA@mail.gmail.com>
Message-ID: <bdc198210524e6b23a2c338ce7457bd5@ruhr-uni-bochum.de>

Hi Prasad,

I think this might be a problem with the package, and you can try to 
contact the package author.

The error seem to arise because the pcr() cannot find the 
'negative-binomial' distribution

```
library(qualityTools)
x <- rnbinom(500, mu = 4, size = 100)
pcr(x, distribution = "negative-binomial")
```

When I look in the code of pcr(), there is some testing against the 
words 'negative binomial' (note the missing -), although the 
documentation clearly lists 'negative-binomial' as a possible 
distribution.

Unfortunately changing 'negative-binomial' to 'negative binomial' does 
not help, as

```
pcr(x, distribution = "negative binomial")
```

throws the error "object '.confintnbinom' not found" and a lot of 
warnings.

Best,
Ulrik


On 2020-08-12 12:50, Prasad DN wrote:
> Hi All,
> 
> i am very new to R and need guidance.
> 
> Need help in doing process capability Analysis for my data set (6 
> months of
> data) given in below format:
> 
> Date   |   Opportunities  |  Defectives | DefectivesInPercent
> 
> I searched and found that pcr() from QualityTools package can be used 
> for
> this purpose.  The USL is 2% defectives.
> 
> MyData = read.csv(file.choose())   #select  CSV file that has data in 
> above
> mentioned format.
> x <- MyData$DefectivesInPercent
> 
> pcr(x, distribution = "negative-binomial", usl=0.02)
> 
> I get error message as:
> Error in pcr(x, distribution = "negative-binomial", usl = 0.02) :
>   y distribution could not be found!
> 
> Please advise, how to proceed?
> 
> Regards,
> Prasad DN
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @c|@bo|@zz@ @end|ng |rom gm@||@com  Wed Aug 19 11:17:17 2020
From: @c|@bo|@zz@ @end|ng |rom gm@||@com (Valerio Leone Sciabolazza)
Date: Wed, 19 Aug 2020 11:17:17 +0200
Subject: [R] Change how minpack.lm:::summary.nls.lm calculates degrees of
 freedom
Message-ID: <CABZtLWx-Tn=OLiCxxOJ4JS8vO0cNN2MP8e3zu5tz7qK6apNrsg@mail.gmail.com>

Dear R users,
I want to modify how the degrees of freedom are calculated from the
summary function of the package minpack.lm

My first thought was to replicate how minpack.lm:::summary.nls.lm
works, and modify the line of the code that is relevant for my task.
However, for some reason I am not able to use the code contained in
this function to perform this operation.

Here is a reproducible example.

First, I run a NLLS regression using minpack.lm::nls.lm

# From example 1 of the help page of ?minpack.lm::nls.lm
library(minpack.lm)
x <- seq(0,5,length=100)
getPred <- function(parS, xx) parS$a * exp(xx * parS$b) + parS$c
pp <- list(a=9,b=-1, c=6)
simDNoisy <- getPred(pp,x) + rnorm(length(x),sd=.1)
residFun <- function(p, observed, xx) observed - getPred(p,xx)
parStart <- list(a=3,b=-.001, c=1)
nls.out <- nls.lm(par=parStart, fn = residFun, observed = simDNoisy,
xx = x, control = nls.lm.control(nprint=1))
summary(nls.out)

Now, by running minpack.lm:::summary.nls.lm in the console, I get the following
> minpack.lm:::summary.nls.lm
function (object, ...)
{
    param <- coef(object)
    pnames <- names(param)
    ibb <- chol(object$hessian)
    ih <- chol2inv(ibb)
    p <- length(param)
    rdf <- length(object$fvec) - p
    resvar <- deviance(object)/rdf
    se <- sqrt(diag(ih) * resvar)
    names(se) <- pnames
    tval <- param/se
    param <- cbind(param, se, tval, 2 * pt(abs(tval), rdf, lower.tail = FALSE))
    dimnames(param) <- list(pnames, c("Estimate", "Std. Error",
        "t value", "Pr(>|t|)"))
    ans <- list(residuals = object$fvec, sigma = sqrt(object$deviance/rdf),
        df = c(p, rdf), cov.unscaled = ih, info = object$info,
        niter = object$niter, stopmess = object$message, coefficients = param)
    class(ans) <- "summary.nls.lm"
    ans
}

Specifically, my task requires to modify the object p of this
function, say I want to set p <- 2.

To this purpose, I replicate what the summary function does using my
object (nls.out), however an error is returned at line three:
> param <- coef(nls.out)
> pnames <- names(param)
> ibb <- chol(nls.out$hessian)
Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),  :
  'data' must be of a vector type, was 'NULL'

The reason of the error is that there is no nls.out$hessian in nls.out.

I guess that I am missing something about how summary functions work,
and this is the reason why I cannot use the code from
minpack.lm:::summary.nls.lm outside the minpack.lm environment.

Does anyone have any hints on how to proceed? Any other way of dealing
with this issue will be equally appreciated.

Thank you,
Valerio


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 19 11:35:33 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 19 Aug 2020 12:35:33 +0300
Subject: [R] 
 Change how minpack.lm:::summary.nls.lm calculates degrees of freedom
In-Reply-To: <CABZtLWx-Tn=OLiCxxOJ4JS8vO0cNN2MP8e3zu5tz7qK6apNrsg@mail.gmail.com>
References: <CABZtLWx-Tn=OLiCxxOJ4JS8vO0cNN2MP8e3zu5tz7qK6apNrsg@mail.gmail.com>
Message-ID: <CAGgJW76XKBkO8tNQK3Ds02-akrknn8NDvGk-QnvsOO=a4n8yVA@mail.gmail.com>

Hi Valerio,
I did a copy-paste on your reproducible example and I had no problem with
chol(nls.out$hessian).
In addition to summary() you can look at str() to display the structure of
any R object.

> str(nls.out)

List of 9
 $ par     :List of 3
  ..$ a: num 8.99
  ..$ b: num -1.01
  ..$ c: num 6.02
 $ hessian : num [1:3, 1:3] 10.3 43.2 19.9 43.2 382.2 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:3] "a" "b" "c"
  .. ..$ : chr [1:3] "a" "b" "c"
 $ fvec    : num [1:100] 0.0232 -0.105 -0.1332 0.0388 0.1482 ...
 $ info    : int 1
 $ message : chr "Relative error in the sum of squares is at most `ftol'."
 $ diag    :List of 3
  ..$ a: num 9.98
  ..$ b: num 88.6
  ..$ c: num 10
 $ niter   : int 8
 $ rsstrace: num [1:9] 1966.2 327.2 104.8 53.9 33.2 ...
 $ deviance: num 1.06
 - attr(*, "class")= chr "nls.lm"

Also
> nls.out$hessian
         a         b         c
a 10.26361  43.17086  19.89616
b 43.17086 382.17773 166.43747
c 19.89616 166.43747 100.00000

HTH,
Eric



On Wed, Aug 19, 2020 at 12:17 PM Valerio Leone Sciabolazza <
sciabolazza at gmail.com> wrote:

> Dear R users,
> I want to modify how the degrees of freedom are calculated from the
> summary function of the package minpack.lm
>
> My first thought was to replicate how minpack.lm:::summary.nls.lm
> works, and modify the line of the code that is relevant for my task.
> However, for some reason I am not able to use the code contained in
> this function to perform this operation.
>
> Here is a reproducible example.
>
> First, I run a NLLS regression using minpack.lm::nls.lm
>
> # From example 1 of the help page of ?minpack.lm::nls.lm
> library(minpack.lm)
> x <- seq(0,5,length=100)
> getPred <- function(parS, xx) parS$a * exp(xx * parS$b) + parS$c
> pp <- list(a=9,b=-1, c=6)
> simDNoisy <- getPred(pp,x) + rnorm(length(x),sd=.1)
> residFun <- function(p, observed, xx) observed - getPred(p,xx)
> parStart <- list(a=3,b=-.001, c=1)
> nls.out <- nls.lm(par=parStart, fn = residFun, observed = simDNoisy,
> xx = x, control = nls.lm.control(nprint=1))
> summary(nls.out)
>
> Now, by running minpack.lm:::summary.nls.lm in the console, I get the
> following
> > minpack.lm:::summary.nls.lm
> function (object, ...)
> {
>     param <- coef(object)
>     pnames <- names(param)
>     ibb <- chol(object$hessian)
>     ih <- chol2inv(ibb)
>     p <- length(param)
>     rdf <- length(object$fvec) - p
>     resvar <- deviance(object)/rdf
>     se <- sqrt(diag(ih) * resvar)
>     names(se) <- pnames
>     tval <- param/se
>     param <- cbind(param, se, tval, 2 * pt(abs(tval), rdf, lower.tail =
> FALSE))
>     dimnames(param) <- list(pnames, c("Estimate", "Std. Error",
>         "t value", "Pr(>|t|)"))
>     ans <- list(residuals = object$fvec, sigma = sqrt(object$deviance/rdf),
>         df = c(p, rdf), cov.unscaled = ih, info = object$info,
>         niter = object$niter, stopmess = object$message, coefficients =
> param)
>     class(ans) <- "summary.nls.lm"
>     ans
> }
>
> Specifically, my task requires to modify the object p of this
> function, say I want to set p <- 2.
>
> To this purpose, I replicate what the summary function does using my
> object (nls.out), however an error is returned at line three:
> > param <- coef(nls.out)
> > pnames <- names(param)
> > ibb <- chol(nls.out$hessian)
> Error in array(x, c(length(x), 1L), if (!is.null(names(x)))
> list(names(x),  :
>   'data' must be of a vector type, was 'NULL'
>
> The reason of the error is that there is no nls.out$hessian in nls.out.
>
> I guess that I am missing something about how summary functions work,
> and this is the reason why I cannot use the code from
> minpack.lm:::summary.nls.lm outside the minpack.lm environment.
>
> Does anyone have any hints on how to proceed? Any other way of dealing
> with this issue will be equally appreciated.
>
> Thank you,
> Valerio
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @c|@bo|@zz@ @end|ng |rom gm@||@com  Wed Aug 19 11:53:13 2020
From: @c|@bo|@zz@ @end|ng |rom gm@||@com (Valerio Leone Sciabolazza)
Date: Wed, 19 Aug 2020 11:53:13 +0200
Subject: [R] 
 Change how minpack.lm:::summary.nls.lm calculates degrees of freedom
In-Reply-To: <CAGgJW76XKBkO8tNQK3Ds02-akrknn8NDvGk-QnvsOO=a4n8yVA@mail.gmail.com>
References: <CABZtLWx-Tn=OLiCxxOJ4JS8vO0cNN2MP8e3zu5tz7qK6apNrsg@mail.gmail.com>
 <CAGgJW76XKBkO8tNQK3Ds02-akrknn8NDvGk-QnvsOO=a4n8yVA@mail.gmail.com>
Message-ID: <CABZtLWwm+Pw19OJ5RzBvgqEOw1mr9z1tGE7Y6u0KDB=zKwEXQA@mail.gmail.com>

Eric,
you are right! If I run the code on a different instance, it works.
There must be something in my old R environment that messed this up.
Thank you very much for checking this out.
Best,
Valerio

On Wed, Aug 19, 2020 at 11:36 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> Hi Valerio,
> I did a copy-paste on your reproducible example and I had no problem with chol(nls.out$hessian).
> In addition to summary() you can look at str() to display the structure of any R object.
>
> > str(nls.out)
>
> List of 9
>  $ par     :List of 3
>   ..$ a: num 8.99
>   ..$ b: num -1.01
>   ..$ c: num 6.02
>  $ hessian : num [1:3, 1:3] 10.3 43.2 19.9 43.2 382.2 ...
>   ..- attr(*, "dimnames")=List of 2
>   .. ..$ : chr [1:3] "a" "b" "c"
>   .. ..$ : chr [1:3] "a" "b" "c"
>  $ fvec    : num [1:100] 0.0232 -0.105 -0.1332 0.0388 0.1482 ...
>  $ info    : int 1
>  $ message : chr "Relative error in the sum of squares is at most `ftol'."
>  $ diag    :List of 3
>   ..$ a: num 9.98
>   ..$ b: num 88.6
>   ..$ c: num 10
>  $ niter   : int 8
>  $ rsstrace: num [1:9] 1966.2 327.2 104.8 53.9 33.2 ...
>  $ deviance: num 1.06
>  - attr(*, "class")= chr "nls.lm"
>
> Also
> > nls.out$hessian
>          a         b         c
> a 10.26361  43.17086  19.89616
> b 43.17086 382.17773 166.43747
> c 19.89616 166.43747 100.00000
>
> HTH,
> Eric
>
>
>
> On Wed, Aug 19, 2020 at 12:17 PM Valerio Leone Sciabolazza <sciabolazza at gmail.com> wrote:
>>
>> Dear R users,
>> I want to modify how the degrees of freedom are calculated from the
>> summary function of the package minpack.lm
>>
>> My first thought was to replicate how minpack.lm:::summary.nls.lm
>> works, and modify the line of the code that is relevant for my task.
>> However, for some reason I am not able to use the code contained in
>> this function to perform this operation.
>>
>> Here is a reproducible example.
>>
>> First, I run a NLLS regression using minpack.lm::nls.lm
>>
>> # From example 1 of the help page of ?minpack.lm::nls.lm
>> library(minpack.lm)
>> x <- seq(0,5,length=100)
>> getPred <- function(parS, xx) parS$a * exp(xx * parS$b) + parS$c
>> pp <- list(a=9,b=-1, c=6)
>> simDNoisy <- getPred(pp,x) + rnorm(length(x),sd=.1)
>> residFun <- function(p, observed, xx) observed - getPred(p,xx)
>> parStart <- list(a=3,b=-.001, c=1)
>> nls.out <- nls.lm(par=parStart, fn = residFun, observed = simDNoisy,
>> xx = x, control = nls.lm.control(nprint=1))
>> summary(nls.out)
>>
>> Now, by running minpack.lm:::summary.nls.lm in the console, I get the following
>> > minpack.lm:::summary.nls.lm
>> function (object, ...)
>> {
>>     param <- coef(object)
>>     pnames <- names(param)
>>     ibb <- chol(object$hessian)
>>     ih <- chol2inv(ibb)
>>     p <- length(param)
>>     rdf <- length(object$fvec) - p
>>     resvar <- deviance(object)/rdf
>>     se <- sqrt(diag(ih) * resvar)
>>     names(se) <- pnames
>>     tval <- param/se
>>     param <- cbind(param, se, tval, 2 * pt(abs(tval), rdf, lower.tail = FALSE))
>>     dimnames(param) <- list(pnames, c("Estimate", "Std. Error",
>>         "t value", "Pr(>|t|)"))
>>     ans <- list(residuals = object$fvec, sigma = sqrt(object$deviance/rdf),
>>         df = c(p, rdf), cov.unscaled = ih, info = object$info,
>>         niter = object$niter, stopmess = object$message, coefficients = param)
>>     class(ans) <- "summary.nls.lm"
>>     ans
>> }
>>
>> Specifically, my task requires to modify the object p of this
>> function, say I want to set p <- 2.
>>
>> To this purpose, I replicate what the summary function does using my
>> object (nls.out), however an error is returned at line three:
>> > param <- coef(nls.out)
>> > pnames <- names(param)
>> > ibb <- chol(nls.out$hessian)
>> Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),  :
>>   'data' must be of a vector type, was 'NULL'
>>
>> The reason of the error is that there is no nls.out$hessian in nls.out.
>>
>> I guess that I am missing something about how summary functions work,
>> and this is the reason why I cannot use the code from
>> minpack.lm:::summary.nls.lm outside the minpack.lm environment.
>>
>> Does anyone have any hints on how to proceed? Any other way of dealing
>> with this issue will be equally appreciated.
>>
>> Thank you,
>> Valerio
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Wed Aug 19 16:42:59 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 19 Aug 2020 16:42:59 +0200
Subject: [R] R Script Modification Questions
In-Reply-To: <CA+8X3fWoYKDXj26WAhViENyM23ZWYUx4o6HMgdBUqAPhg7u2hQ@mail.gmail.com>
References: <5F3BF52F.7050908.ref@sbcglobal.net>
 <5F3BF52F.7050908@sbcglobal.net>
 <CA+8X3fUSOY3a1bEELpqVBwK5cLGCW6Z+OGRfi_+GZ+MXj6zh6A@mail.gmail.com>
 <5F3C8C70.4020901@sbcglobal.net>
 <CA+8X3fWoYKDXj26WAhViENyM23ZWYUx4o6HMgdBUqAPhg7u2hQ@mail.gmail.com>
Message-ID: <20200819144259.GA1532@posteo.no>

Dear Stephen,

I answer inline:

On 2020-08-19 12:57 +1000, Jim Lemon wrote:
| On Wed, Aug 19, 2020 at 3:09 AM Stephen P. Molnar <s.molnar at sbcglobal.net> wrote:
| |
| | What I would like to do is use 
| | linetype, rather than color, in line 
| | 27.

You need to specify linetype instead of 
color in ggplot::aes, like so

	ggplot2::aes(
	  x=date,
	  y=count,
	  linetype=cases)

and change 
scale_color_manual to 
scale_linetype_manual and its values 
like so

	  ggplot2::scale_linetype_manual(
	    name = "Test",
	    labels = levels,
	    values =
	      c("dotted",
	        "dashed",
	        "solid"))

| | The date in the title of the plot , 
| | line 33, is the max value of the 
| | date in in line 14 and I would like 
| | to use that rather than edit the 
| | Script every time the date changes.
| 
| Okay, I can't help much with the 
| ggplot stuff so forget the "lty=" 
| argument for that is base graphics. 
| However, you may get away with
| 
| ggtitle(paste0("COVID-19 Tests in Ohio \n(",date[length(date]),")"))+
| 
| I don't know whether the tidy* stuff 
| handles indexing in the same way as 
| base R.

I added a format, which converts it to 
the date format you mentioned (but with 
a zero in the month part ...):

	  ggplot2::ggtitle(
	    paste0("COVID-19 Tests in Ohio \n(",
	           format(max(dfO$date), "%m/%d/%y"), ")")) +

Here is the whole script:

	datO <- read.csv("https://api.covidtracking.com/v1/states/oh/daily.csv")
	
	cases <- c("positive", "negative", "total")
	levels <- paste0(
	  toupper(substr(cases, 1, 1)),
	  substr(cases, 2, nchar(cases)))
	
	dfO <- data.frame(
	  date=
	    rep(
	      x=lubridate::ymd(datO$date),
	      each=length(cases)),
	  cases=levels,
	  count=as.vector(t(datO[,cases])))
	dfO$cases <- factor(dfO$cases, levels=levels)
	
	file <- "/tmp/stephen.pdf"
	res <- .5
	width <- 9*res
	height <- 5*res
	pdf(file=file, width=width, height=height)
	
	mapping <- ggplot2::aes(
	  x=date,
	  y=count,
	  linetype=cases)
	
	p <- 
	  ggplot2::ggplot(
	    data=dfO,
	    mapping=mapping) +
	  ggplot2::geom_line() +
	  ggplot2::scale_linetype_manual(
	    name = "Test",
	    labels = levels,
	    values =
	      c("dotted",
	        "dashed",
	        "solid")) +
	  ggplot2::ylim(0, 2e6) +
	  ggplot2::labs(
	    x = "Date",
	    y = "Number of Tests") +
	  ggplot2::ggtitle(
	    paste0("COVID-19 Tests in Ohio \n(",
	           format(max(dfO$date), "%m/%d/%y"), ")")) +
	  ggplot2::theme_bw() +
	  ggplot2::theme(
	    axis.text.x = 
	      ggplot2::element_text(
	        angle = 30, 
	        hjust = 1),
	    plot.title = 
	      ggplot2::element_text(
	        hjust = 0.5))
	
	p
	
	dev.off()

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200819/efc72779/attachment.sig>

From c@|@ndr@ @end|ng |rom rgzm@de  Wed Aug 19 16:46:05 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 19 Aug 2020 16:46:05 +0200
Subject: [R] & and |
Message-ID: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>

Dear useRs,

I feel really stupid, but I cannot understand why "&" doesn't work as I
expect, while "|" does.

I have the following vector:
mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
"SSFA-ConfoMap_Lithics_NMPfilled.csv",?
"SSFA-ConfoMap_Sheeps_NMPfilled.csv", "SSFA-Toothfrax_GuineaPigs.xlsx",
"SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
and I want to find the values that include both "ConfoMap" and "GuineaPigs".

If I do:
grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
it returns an empty vector, character(0).

But if I do:
grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
it returns all the elements that include either "ConfoMap" or
"GuineaPigs", as I would expect.

So what is wrong with my "&" construct? How can I return the elements
that include both parts?

Thank you for your help!
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From c@|@ndr@ @end|ng |rom rgzm@de  Wed Aug 19 16:56:32 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 19 Aug 2020 16:56:32 +0200
Subject: [R] combine filter() and select()
Message-ID: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>

Dear useRs,

I'm new to the tidyverse world and I need some help on basic things.

I have the following tibble:
mytbl <- structure(list(files = c("a", "b", "c", "d", "e", "f"), prop =
1:6), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"))

I want to subset the rows with "a" in the column "files", and keep only
that column.

So I did:
myfile <- mytbl %>%
? filter(grepl("a", files)) %>%
? select(files)

It works, but I believe there must be an easier way to combine filter()
and select(), right?

Thank you!
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 19 17:07:07 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 19 Aug 2020 08:07:07 -0700
Subject: [R] & and |
In-Reply-To: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
Message-ID: <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>

"&" is not a regex metacharacter.
See ?regexp

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de> wrote:

> Dear useRs,
>
> I feel really stupid, but I cannot understand why "&" doesn't work as I
> expect, while "|" does.
>
> I have the following vector:
> mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
> "SSFA-ConfoMap_Lithics_NMPfilled.csv",
> "SSFA-ConfoMap_Sheeps_NMPfilled.csv", "SSFA-Toothfrax_GuineaPigs.xlsx",
> "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
> and I want to find the values that include both "ConfoMap" and
> "GuineaPigs".
>
> If I do:
> grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> it returns an empty vector, character(0).
>
> But if I do:
> grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
> it returns all the elements that include either "ConfoMap" or
> "GuineaPigs", as I would expect.
>
> So what is wrong with my "&" construct? How can I return the elements
> that include both parts?
>
> Thank you for your help!
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 19 17:17:34 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 19 Aug 2020 18:17:34 +0300
Subject: [R] & and |
In-Reply-To: <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
Message-ID: <CAGgJW75CrK5NL6sbH+-3xyXdqpnvtORgpnEtDp5rZXpxvccoKg@mail.gmail.com>

mydata[ intersect( grep("ConfoMap", mydata), grep("GuineaPigs", mydata)  ) ]



On Wed, Aug 19, 2020 at 6:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> "&" is not a regex metacharacter.
> See ?regexp
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
> > Dear useRs,
> >
> > I feel really stupid, but I cannot understand why "&" doesn't work as I
> > expect, while "|" does.
> >
> > I have the following vector:
> > mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
> > "SSFA-ConfoMap_Lithics_NMPfilled.csv",
> > "SSFA-ConfoMap_Sheeps_NMPfilled.csv", "SSFA-Toothfrax_GuineaPigs.xlsx",
> > "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
> > and I want to find the values that include both "ConfoMap" and
> > "GuineaPigs".
> >
> > If I do:
> > grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> > it returns an empty vector, character(0).
> >
> > But if I do:
> > grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
> > it returns all the elements that include either "ConfoMap" or
> > "GuineaPigs", as I would expect.
> >
> > So what is wrong with my "&" construct? How can I return the elements
> > that include both parts?
> >
> > Thank you for your help!
> > Ivan
> >
> > --
> > Dr. Ivan Calandra
> > TraCEr, laboratory for Traceology and Controlled Experiments
> > MONREPOS Archaeological Research Centre and
> > Museum for Human Behavioural Evolution
> > Schloss Monrepos
> > 56567 Neuwied, Germany
> > +49 (0) 2631 9772-243
> > https://www.researchgate.net/profile/Ivan_Calandra
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Wed Aug 19 17:18:18 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 19 Aug 2020 17:18:18 +0200
Subject: [R] & and |
In-Reply-To: <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
Message-ID: <2a6804b6-91a8-3a12-2566-2c37668a2797@rgzm.de>

Thank you Bert for the pointer.

So I guess the solution is:
grep("ConfoMap.+GuineaPigs", mydata, value=TRUE)

This is not the case here, but what if "GuineaPigs" comes before
"ConfoMap"?
Of course I could do two "grep()" calls, but if there a better solution?

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 19/08/2020 17:07, Bert Gunter wrote:
> "&" is not a regex metacharacter.
> See ?regexp
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de
> <mailto:calandra at rgzm.de>> wrote:
>
>     Dear useRs,
>
>     I feel really stupid, but I cannot understand why "&" doesn't work
>     as I
>     expect, while "|" does.
>
>     I have the following vector:
>     mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
>     "SSFA-ConfoMap_Lithics_NMPfilled.csv",?
>     "SSFA-ConfoMap_Sheeps_NMPfilled.csv",
>     "SSFA-Toothfrax_GuineaPigs.xlsx",
>     "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
>     and I want to find the values that include both "ConfoMap" and
>     "GuineaPigs".
>
>     If I do:
>     grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
>     it returns an empty vector, character(0).
>
>     But if I do:
>     grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
>     it returns all the elements that include either "ConfoMap" or
>     "GuineaPigs", as I would expect.
>
>     So what is wrong with my "&" construct? How can I return the elements
>     that include both parts?
>
>     Thank you for your help!
>     Ivan
>
>     -- 
>     Dr. Ivan Calandra
>     TraCEr, laboratory for Traceology and Controlled Experiments
>     MONREPOS Archaeological Research Centre and
>     Museum for Human Behavioural Evolution
>     Schloss Monrepos
>     56567 Neuwied, Germany
>     +49 (0) 2631 9772-243
>     https://www.researchgate.net/profile/Ivan_Calandra
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From c@|@ndr@ @end|ng |rom rgzm@de  Wed Aug 19 17:20:38 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 19 Aug 2020 17:20:38 +0200
Subject: [R] & and |
In-Reply-To: <CAGgJW75CrK5NL6sbH+-3xyXdqpnvtORgpnEtDp5rZXpxvccoKg@mail.gmail.com>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
 <CAGgJW75CrK5NL6sbH+-3xyXdqpnvtORgpnEtDp5rZXpxvccoKg@mail.gmail.com>
Message-ID: <2eb83007-a0ce-7ad8-f4f4-45ec90a8c4c0@rgzm.de>

Thank you Eric, I didn't think about intersect().

Now I'm trying to do that in tidyverse with pipes, and I think that's
too much for me for now!

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 19/08/2020 17:17, Eric Berger wrote:
> mydata[ intersect( grep("ConfoMap", mydata), grep("GuineaPigs",
> mydata) ?) ]
>
>
>
> On Wed, Aug 19, 2020 at 6:13 PM Bert Gunter <bgunter.4567 at gmail.com
> <mailto:bgunter.4567 at gmail.com>> wrote:
>
>     "&" is not a regex metacharacter.
>     See ?regexp
>
>     Bert Gunter
>
>     "The trouble with having an open mind is that people keep coming
>     along and
>     sticking things into it."
>     -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>     On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de
>     <mailto:calandra at rgzm.de>> wrote:
>
>     > Dear useRs,
>     >
>     > I feel really stupid, but I cannot understand why "&" doesn't
>     work as I
>     > expect, while "|" does.
>     >
>     > I have the following vector:
>     > mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
>     > "SSFA-ConfoMap_Lithics_NMPfilled.csv",
>     > "SSFA-ConfoMap_Sheeps_NMPfilled.csv",
>     "SSFA-Toothfrax_GuineaPigs.xlsx",
>     > "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
>     > and I want to find the values that include both "ConfoMap" and
>     > "GuineaPigs".
>     >
>     > If I do:
>     > grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
>     > it returns an empty vector, character(0).
>     >
>     > But if I do:
>     > grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
>     > it returns all the elements that include either "ConfoMap" or
>     > "GuineaPigs", as I would expect.
>     >
>     > So what is wrong with my "&" construct? How can I return the
>     elements
>     > that include both parts?
>     >
>     > Thank you for your help!
>     > Ivan
>     >
>     > --
>     > Dr. Ivan Calandra
>     > TraCEr, laboratory for Traceology and Controlled Experiments
>     > MONREPOS Archaeological Research Centre and
>     > Museum for Human Behavioural Evolution
>     > Schloss Monrepos
>     > 56567 Neuwied, Germany
>     > +49 (0) 2631 9772-243
>     > https://www.researchgate.net/profile/Ivan_Calandra
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 19 17:31:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 19 Aug 2020 08:31:09 -0700
Subject: [R] & and |
In-Reply-To: <2a6804b6-91a8-3a12-2566-2c37668a2797@rgzm.de>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
 <2a6804b6-91a8-3a12-2566-2c37668a2797@rgzm.de>
Message-ID: <CAGxFJbROvcYcgndkGjsdEQMEyXThpYgMxmOqseY3X38d-pDzmg@mail.gmail.com>

Well... wouldn't it be:

rep("(ConfoMap.*GuineaPigs)|(GuineaPigs.*ConfoMap)", mydata, value=TRUE)

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 19, 2020 at 8:23 AM Ivan Calandra <calandra at rgzm.de> wrote:

> Thank you Bert for the pointer.
>
> So I guess the solution is:
> grep("ConfoMap.+GuineaPigs", mydata, value=TRUE)
>
> This is not the case here, but what if "GuineaPigs" comes before
> "ConfoMap"?
> Of course I could do two "grep()" calls, but if there a better solution?
>
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 19/08/2020 17:07, Bert Gunter wrote:
> > "&" is not a regex metacharacter.
> > See ?regexp
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de
> > <mailto:calandra at rgzm.de>> wrote:
> >
> >     Dear useRs,
> >
> >     I feel really stupid, but I cannot understand why "&" doesn't work
> >     as I
> >     expect, while "|" does.
> >
> >     I have the following vector:
> >     mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
> >     "SSFA-ConfoMap_Lithics_NMPfilled.csv",
> >     "SSFA-ConfoMap_Sheeps_NMPfilled.csv",
> >     "SSFA-Toothfrax_GuineaPigs.xlsx",
> >     "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
> >     and I want to find the values that include both "ConfoMap" and
> >     "GuineaPigs".
> >
> >     If I do:
> >     grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> >     it returns an empty vector, character(0).
> >
> >     But if I do:
> >     grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
> >     it returns all the elements that include either "ConfoMap" or
> >     "GuineaPigs", as I would expect.
> >
> >     So what is wrong with my "&" construct? How can I return the elements
> >     that include both parts?
> >
> >     Thank you for your help!
> >     Ivan
> >
> >     --
> >     Dr. Ivan Calandra
> >     TraCEr, laboratory for Traceology and Controlled Experiments
> >     MONREPOS Archaeological Research Centre and
> >     Museum for Human Behavioural Evolution
> >     Schloss Monrepos
> >     56567 Neuwied, Germany
> >     +49 (0) 2631 9772-243
> >     https://www.researchgate.net/profile/Ivan_Calandra
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Wed Aug 19 17:34:03 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 19 Aug 2020 17:34:03 +0200
Subject: [R] & and |
In-Reply-To: <CAGxFJbROvcYcgndkGjsdEQMEyXThpYgMxmOqseY3X38d-pDzmg@mail.gmail.com>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
 <2a6804b6-91a8-3a12-2566-2c37668a2797@rgzm.de>
 <CAGxFJbROvcYcgndkGjsdEQMEyXThpYgMxmOqseY3X38d-pDzmg@mail.gmail.com>
Message-ID: <839ddce8-93a6-5576-e548-2d95ddec7f5e@rgzm.de>

Indeed!
I was just hoping that there would be a shorter way... intersect() is a
nice alternative too. Maybe I can make it work with pipes so that I
don't have to repeat "mydata" but that's another story.

Thank you for the help!
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 19/08/2020 17:31, Bert Gunter wrote:
> Well... wouldn't it be:
>
> rep("(ConfoMap.*GuineaPigs)|(GuineaPigs.*ConfoMap)", mydata, value=TRUE)
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Aug 19, 2020 at 8:23 AM Ivan Calandra <calandra at rgzm.de
> <mailto:calandra at rgzm.de>> wrote:
>
>     Thank you Bert for the pointer.
>
>     So I guess the solution is:
>     grep("ConfoMap.+GuineaPigs", mydata, value=TRUE)
>
>     This is not the case here, but what if "GuineaPigs" comes before
>     "ConfoMap"?
>     Of course I could do two "grep()" calls, but if there a better
>     solution?
>
>     Ivan
>
>     --
>     Dr. Ivan Calandra
>     TraCEr, laboratory for Traceology and Controlled Experiments
>     MONREPOS Archaeological Research Centre and
>     Museum for Human Behavioural Evolution
>     Schloss Monrepos
>     56567 Neuwied, Germany
>     +49 (0) 2631 9772-243
>     https://www.researchgate.net/profile/Ivan_Calandra
>
>     On 19/08/2020 17:07, Bert Gunter wrote:
>     > "&" is not a regex metacharacter.
>     > See ?regexp
>     >
>     > Bert Gunter
>     >
>     > "The trouble with having an open mind is that people keep coming
>     along
>     > and sticking things into it."
>     > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>     >
>     >
>     > On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de
>     <mailto:calandra at rgzm.de>
>     > <mailto:calandra at rgzm.de <mailto:calandra at rgzm.de>>> wrote:
>     >
>     >? ? ?Dear useRs,
>     >
>     >? ? ?I feel really stupid, but I cannot understand why "&"
>     doesn't work
>     >? ? ?as I
>     >? ? ?expect, while "|" does.
>     >
>     >? ? ?I have the following vector:
>     >? ? ?mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
>     >? ? ?"SSFA-ConfoMap_Lithics_NMPfilled.csv",?
>     >? ? ?"SSFA-ConfoMap_Sheeps_NMPfilled.csv",
>     >? ? ?"SSFA-Toothfrax_GuineaPigs.xlsx",
>     >? ? ?"SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
>     >? ? ?and I want to find the values that include both "ConfoMap" and
>     >? ? ?"GuineaPigs".
>     >
>     >? ? ?If I do:
>     >? ? ?grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
>     >? ? ?it returns an empty vector, character(0).
>     >
>     >? ? ?But if I do:
>     >? ? ?grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
>     >? ? ?it returns all the elements that include either "ConfoMap" or
>     >? ? ?"GuineaPigs", as I would expect.
>     >
>     >? ? ?So what is wrong with my "&" construct? How can I return the
>     elements
>     >? ? ?that include both parts?
>     >
>     >? ? ?Thank you for your help!
>     >? ? ?Ivan
>     >
>     >? ? ?--
>     >? ? ?Dr. Ivan Calandra
>     >? ? ?TraCEr, laboratory for Traceology and Controlled Experiments
>     >? ? ?MONREPOS Archaeological Research Centre and
>     >? ? ?Museum for Human Behavioural Evolution
>     >? ? ?Schloss Monrepos
>     >? ? ?56567 Neuwied, Germany
>     >? ? ?+49 (0) 2631 9772-243
>     >? ? ?https://www.researchgate.net/profile/Ivan_Calandra
>     >
>     >? ? ?______________________________________________
>     >? ? ?R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>     mailing list --
>     >? ? ?To UNSUBSCRIBE and more, see
>     >? ? ?https://stat.ethz.ch/mailman/listinfo/r-help
>     >? ? ?PLEASE do read the posting guide
>     >? ? ?http://www.R-project.org/posting-guide.html
>     >? ? ?and provide commented, minimal, self-contained, reproducible
>     code.
>     >
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Aug 19 17:44:10 2020
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 19 Aug 2020 08:44:10 -0700
Subject: [R] & and |
In-Reply-To: <2eb83007-a0ce-7ad8-f4f4-45ec90a8c4c0@rgzm.de>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
 <CAGgJW75CrK5NL6sbH+-3xyXdqpnvtORgpnEtDp5rZXpxvccoKg@mail.gmail.com>
 <2eb83007-a0ce-7ad8-f4f4-45ec90a8c4c0@rgzm.de>
Message-ID: <CAFDcVCRJ5s8nkb0ZJ7xMeOEpA2idf-wWk4Whc6yfFWMd7JCWHQ@mail.gmail.com>

A version of Eric's answer is to use grepl(), which returns a logical vector:

mydata[grepl("ConfoMap", mydata) & grepl("GuineaPigs", mydata)]

with the OR analogue:

mydata[grepl("ConfoMap", mydata) | grepl("GuineaPigs", mydata)]

/Henrik

On Wed, Aug 19, 2020 at 8:24 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
> Thank you Eric, I didn't think about intersect().
>
> Now I'm trying to do that in tidyverse with pipes, and I think that's
> too much for me for now!
>
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 19/08/2020 17:17, Eric Berger wrote:
> > mydata[ intersect( grep("ConfoMap", mydata), grep("GuineaPigs",
> > mydata)  ) ]
> >
> >
> >
> > On Wed, Aug 19, 2020 at 6:13 PM Bert Gunter <bgunter.4567 at gmail.com
> > <mailto:bgunter.4567 at gmail.com>> wrote:
> >
> >     "&" is not a regex metacharacter.
> >     See ?regexp
> >
> >     Bert Gunter
> >
> >     "The trouble with having an open mind is that people keep coming
> >     along and
> >     sticking things into it."
> >     -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >     On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de
> >     <mailto:calandra at rgzm.de>> wrote:
> >
> >     > Dear useRs,
> >     >
> >     > I feel really stupid, but I cannot understand why "&" doesn't
> >     work as I
> >     > expect, while "|" does.
> >     >
> >     > I have the following vector:
> >     > mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
> >     > "SSFA-ConfoMap_Lithics_NMPfilled.csv",
> >     > "SSFA-ConfoMap_Sheeps_NMPfilled.csv",
> >     "SSFA-Toothfrax_GuineaPigs.xlsx",
> >     > "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
> >     > and I want to find the values that include both "ConfoMap" and
> >     > "GuineaPigs".
> >     >
> >     > If I do:
> >     > grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> >     > it returns an empty vector, character(0).
> >     >
> >     > But if I do:
> >     > grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
> >     > it returns all the elements that include either "ConfoMap" or
> >     > "GuineaPigs", as I would expect.
> >     >
> >     > So what is wrong with my "&" construct? How can I return the
> >     elements
> >     > that include both parts?
> >     >
> >     > Thank you for your help!
> >     > Ivan
> >     >
> >     > --
> >     > Dr. Ivan Calandra
> >     > TraCEr, laboratory for Traceology and Controlled Experiments
> >     > MONREPOS Archaeological Research Centre and
> >     > Museum for Human Behavioural Evolution
> >     > Schloss Monrepos
> >     > 56567 Neuwied, Germany
> >     > +49 (0) 2631 9772-243
> >     > https://www.researchgate.net/profile/Ivan_Calandra
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide
> >     > http://www.R-project.org/posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >     >
> >
> >             [[alternative HTML version deleted]]
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdun|@p @end|ng |rom t|bco@com  Wed Aug 19 18:33:21 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 19 Aug 2020 09:33:21 -0700
Subject: [R] & and |
In-Reply-To: <839ddce8-93a6-5576-e548-2d95ddec7f5e@rgzm.de>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
 <2a6804b6-91a8-3a12-2566-2c37668a2797@rgzm.de>
 <CAGxFJbROvcYcgndkGjsdEQMEyXThpYgMxmOqseY3X38d-pDzmg@mail.gmail.com>
 <839ddce8-93a6-5576-e548-2d95ddec7f5e@rgzm.de>
Message-ID: <CAF8bMcZh-yyxDWDGQscEbSOw+HnPp2RoaFi9-JYiOiTcaZhUdQ@mail.gmail.com>

Instead of intersect you could use grepl(pattern1,x) &
grepl(pattern2,x).  Use which() on the result if you must have
integers, but the logicals that grepl() produces are often easier to
use as subscripts.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Aug 19, 2020 at 8:54 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
> Indeed!
> I was just hoping that there would be a shorter way... intersect() is a
> nice alternative too. Maybe I can make it work with pipes so that I
> don't have to repeat "mydata" but that's another story.
>
> Thank you for the help!
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 19/08/2020 17:31, Bert Gunter wrote:
> > Well... wouldn't it be:
> >
> > rep("(ConfoMap.*GuineaPigs)|(GuineaPigs.*ConfoMap)", mydata, value=TRUE)
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Wed, Aug 19, 2020 at 8:23 AM Ivan Calandra <calandra at rgzm.de
> > <mailto:calandra at rgzm.de>> wrote:
> >
> >     Thank you Bert for the pointer.
> >
> >     So I guess the solution is:
> >     grep("ConfoMap.+GuineaPigs", mydata, value=TRUE)
> >
> >     This is not the case here, but what if "GuineaPigs" comes before
> >     "ConfoMap"?
> >     Of course I could do two "grep()" calls, but if there a better
> >     solution?
> >
> >     Ivan
> >
> >     --
> >     Dr. Ivan Calandra
> >     TraCEr, laboratory for Traceology and Controlled Experiments
> >     MONREPOS Archaeological Research Centre and
> >     Museum for Human Behavioural Evolution
> >     Schloss Monrepos
> >     56567 Neuwied, Germany
> >     +49 (0) 2631 9772-243
> >     https://www.researchgate.net/profile/Ivan_Calandra
> >
> >     On 19/08/2020 17:07, Bert Gunter wrote:
> >     > "&" is not a regex metacharacter.
> >     > See ?regexp
> >     >
> >     > Bert Gunter
> >     >
> >     > "The trouble with having an open mind is that people keep coming
> >     along
> >     > and sticking things into it."
> >     > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >     >
> >     >
> >     > On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de
> >     <mailto:calandra at rgzm.de>
> >     > <mailto:calandra at rgzm.de <mailto:calandra at rgzm.de>>> wrote:
> >     >
> >     >     Dear useRs,
> >     >
> >     >     I feel really stupid, but I cannot understand why "&"
> >     doesn't work
> >     >     as I
> >     >     expect, while "|" does.
> >     >
> >     >     I have the following vector:
> >     >     mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
> >     >     "SSFA-ConfoMap_Lithics_NMPfilled.csv",
> >     >     "SSFA-ConfoMap_Sheeps_NMPfilled.csv",
> >     >     "SSFA-Toothfrax_GuineaPigs.xlsx",
> >     >     "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
> >     >     and I want to find the values that include both "ConfoMap" and
> >     >     "GuineaPigs".
> >     >
> >     >     If I do:
> >     >     grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> >     >     it returns an empty vector, character(0).
> >     >
> >     >     But if I do:
> >     >     grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
> >     >     it returns all the elements that include either "ConfoMap" or
> >     >     "GuineaPigs", as I would expect.
> >     >
> >     >     So what is wrong with my "&" construct? How can I return the
> >     elements
> >     >     that include both parts?
> >     >
> >     >     Thank you for your help!
> >     >     Ivan
> >     >
> >     >     --
> >     >     Dr. Ivan Calandra
> >     >     TraCEr, laboratory for Traceology and Controlled Experiments
> >     >     MONREPOS Archaeological Research Centre and
> >     >     Museum for Human Behavioural Evolution
> >     >     Schloss Monrepos
> >     >     56567 Neuwied, Germany
> >     >     +49 (0) 2631 9772-243
> >     >     https://www.researchgate.net/profile/Ivan_Calandra
> >     >
> >     >     ______________________________________________
> >     >     R-help at r-project.org <mailto:R-help at r-project.org>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
> >     mailing list --
> >     >     To UNSUBSCRIBE and more, see
> >     >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     >     PLEASE do read the posting guide
> >     >     http://www.R-project.org/posting-guide.html
> >     >     and provide commented, minimal, self-contained, reproducible
> >     code.
> >     >
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@ho|d @end|ng |rom p@yctc@org  Wed Aug 19 19:21:57 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Wed, 19 Aug 2020 18:21:57 +0100 (BST)
Subject: [R] combine filter() and select()
In-Reply-To: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
References: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
Message-ID: <1665597756.3818393.1597857717037.JavaMail.zimbra@psyctc.org>

Inline

----- Original Message -----
> From: "Ivan Calandra" <calandra at rgzm.de>
> To: "R-help" <r-help at r-project.org>
> Sent: Wednesday, 19 August, 2020 16:56:32
> Subject: [R] combine filter() and select()

> Dear useRs,
> 
> I'm new to the tidyverse world and I need some help on basic things.
> 
> I have the following tibble:
> mytbl <- structure(list(files = c("a", "b", "c", "d", "e", "f"), prop =
> 1:6), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"))
> 
> I want to subset the rows with "a" in the column "files", and keep only
> that column.
> 
> So I did:
> myfile <- mytbl %>%
>? filter(grepl("a", files)) %>%
>? select(files)
> 
> It works, but I believe there must be an easier way to combine filter()
> and select(), right?

I would write 

mytbl %>%
  filter(grepl("a", files)) %>%
  select(files) -> myfile

as I like to keep a sort of "top to bottom and left to right" flow when writing in the tidyverse dialect of R but that's really not important.

Apart from that I think what you've done is "proper tidyverse". To me another difference between the dialects is that classical R often seems to put value on, and make it easy, to do things with incredible few characters.  I think the people who are brilliant at that sort of coding, and there are many on this list, that sort of coding is also easy to read.  I know that Chinese is easy to read if you grew up on it but to a bear of little brain like me, the much more verbose style of tidyverse repays typing time with readability when I come back to my code and, though I have little experience of this yet, when I read other poeple's code.

What did you think wasn't "easy" about what you wrote?

Very best (all),

Chris

> 
> Thank you!
> Ivan
> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug 19 19:27:31 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 19 Aug 2020 10:27:31 -0700
Subject: [R] combine filter() and select()
In-Reply-To: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
References: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
Message-ID: <F2B9A144-F301-40E8-A050-C8B45D062883@dcn.davis.ca.us>

The whole point of dplyr primitives is to support data frames... that is, lists of columns. When you pare your data frame down to one column you are almost certainly using the wrong tool for the job.

So, sure, your code works... and it even does what you wanted in the dplyr style, but what a pointless exercise.

grep( "a", mytbl$file, value=TRUE )

On August 19, 2020 7:56:32 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Dear useRs,
>
>I'm new to the tidyverse world and I need some help on basic things.
>
>I have the following tibble:
>mytbl <- structure(list(files = c("a", "b", "c", "d", "e", "f"), prop =
>1:6), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"))
>
>I want to subset the rows with "a" in the column "files", and keep only
>that column.
>
>So I did:
>myfile <- mytbl %>%
>? filter(grepl("a", files)) %>%
>? select(files)
>
>It works, but I believe there must be an easier way to combine filter()
>and select(), right?
>
>Thank you!
>Ivan

-- 
Sent from my phone. Please excuse my brevity.


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Aug 19 23:27:10 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 19 Aug 2020 16:27:10 -0500
Subject: [R] Trouble getting labels for bars in Pareto Chart
Message-ID: <CAMOcQfPFc3iufn1UjSgrb9vj8O05QS06FZPbwXH3QfV-88Z5ow@mail.gmail.com>

Dear friends,

Hope you are doing well. I am currently using R version 3.6.2. I installed
and loaded package qcc by Mr. Luca Scrucca.

This is the structure of my data:

str(dataset2)
'data.frame':   140 obs. of  2 variables:
 $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
106 65 17 ...
 $ Points: num  55 43 24 21 20 20 18 17 16 16 ...



I tried using the function pareto.chart from the qcc package, but the names
of the columns in the pareto chart are some codes that do not match the
school names in the School column of dataset2.

The graph is generated without any issues, it's just that I want the bars
to have the school labels, how can I accomplish this?

Below is the dput() of my dataset.

dput(dataset2)
structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
"Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
"Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
"Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
"Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
"Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
"Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
"Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
"Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
"David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
"El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
"El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
"Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
"Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
Espinar",
"Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
"La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
"Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
"Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
"Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
"Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
"Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
"Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
"Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
"Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
"R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
"Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
"San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
Porres",
"Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
"Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
"Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
), class = "data.frame")

Best regards,

Paul

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Thu Aug 20 00:32:59 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 20 Aug 2020 00:32:59 +0200
Subject: [R] & and |
In-Reply-To: <CAF8bMcZh-yyxDWDGQscEbSOw+HnPp2RoaFi9-JYiOiTcaZhUdQ@mail.gmail.com>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CAGxFJbQEnuQZrLvwoRcV0wA4Z7N6E0_JmRbNU80R7EdcFHkt5w@mail.gmail.com>
 <2a6804b6-91a8-3a12-2566-2c37668a2797@rgzm.de>
 <CAGxFJbROvcYcgndkGjsdEQMEyXThpYgMxmOqseY3X38d-pDzmg@mail.gmail.com>
 <839ddce8-93a6-5576-e548-2d95ddec7f5e@rgzm.de>
 <CAF8bMcZh-yyxDWDGQscEbSOw+HnPp2RoaFi9-JYiOiTcaZhUdQ@mail.gmail.com>
Message-ID: <20200819223259.GB1532@posteo.no>

On Wed, Aug 19, 2020 at 7:53 AM Ivan Calandra <calandra at rgzm.de> wrote:
| 
| I have the following vector:
| 	mydata <- 
| 	c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv", 
| 	"SSFA-ConfoMap_Lithics_NMPfilled.csv", 
| 	"SSFA-ConfoMap_Sheeps_NMPfilled.csv", 
| 	"SSFA-Toothfrax_GuineaPigs.xlsx", 
| 	"SSFA-Toothfrax_Lithics.xlsx", 
| 	"SSFA-Toothfrax_Sheeps.xlsx")
| and I want to find the values that 
| include both "ConfoMap" and 
| "GuineaPigs".

Dear Ivan,

I also found this[1], so this line 
returns 1 like many of these other 
suggestions:

	grep("(.*ConfoMap)(.*GuineaPigs)", mydata)

Best,
Rasmus

[1] https://stackoverflow.com/questions/13187414/r-grep-is-there-an-and-operator

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200820/41072300/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Thu Aug 20 01:08:39 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 20 Aug 2020 01:08:39 +0200
Subject: [R] Trouble getting labels for bars in Pareto Chart
In-Reply-To: <CAMOcQfPFc3iufn1UjSgrb9vj8O05QS06FZPbwXH3QfV-88Z5ow@mail.gmail.com>
References: <CAMOcQfPFc3iufn1UjSgrb9vj8O05QS06FZPbwXH3QfV-88Z5ow@mail.gmail.com>
Message-ID: <20200819230839.GA24776@posteo.no>

Dear Paul,  I answer inline:

On 2020-08-19 16:27 -0500, Paul Bernal wrote:
| 
| I tried using the function 
| pareto.chart from the qcc package, but 
| the names of the columns in the pareto 
| chart are some codes 

What codes?  Can you please elaborate on 
this?

| that do not match the school names in 
| the School column of dataset2.

Does this mean there exists a third 
hidden vector not included in dataset2 
which conflicts with dataset2$School?

| The graph is generated without any 
| issues, 

Good!

| it's just that I want the bars 
| to have the school labels, how can I 
| accomplish this?

So as ?qcc::pareto.chart states, 
qcc::pareto.chart needs a vector of 
values, data, and names(data) can be 
used to label the bars, there are also 
some examples at the bottom.

Just doing this makes the labels show 
up. 

	points <- dataset2$Points
	names(points) <- dataset2$School
	qcc::pareto.chart(points,
	  main="Pareto Chart for School Points")

Was this what you were looking to do?

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200820/2e6a7408/attachment.sig>

From drj|m|emon @end|ng |rom gm@||@com  Thu Aug 20 01:13:54 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 20 Aug 2020 09:13:54 +1000
Subject: [R] Trouble getting labels for bars in Pareto Chart
In-Reply-To: <CAMOcQfPFc3iufn1UjSgrb9vj8O05QS06FZPbwXH3QfV-88Z5ow@mail.gmail.com>
References: <CAMOcQfPFc3iufn1UjSgrb9vj8O05QS06FZPbwXH3QfV-88Z5ow@mail.gmail.com>
Message-ID: <CA+8X3fVYQywyf09zjOtkA3ry3z9rXRw6iuxxn79y6t1ouTSpTw@mail.gmail.com>

Hi Paul,
I ran this:

library(qcc)
pareto.chart(dataset2$Points)

and like you, got the chart. As you have 140 long labels, I thought at
first it might be the function trying to abbreviate some of them and
actually displaying about 1 in 5. Looking at the code for the
function, this is not the case. You can get the labels (sort of) by
specifying a very wide graphic device and setting the names of the
input vector to dataset2$School:

dpoints<-dataset2$Points
pdf("qcc_dataset2.pdf",width=20,height=5)
names(dpoints)<-dataset2$School
pareto.chart(dpoints)
dev.off()

The attached image shows what I mean.

Jim

On Thu, Aug 20, 2020 at 7:27 AM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
> Dear friends,
>
> Hope you are doing well. I am currently using R version 3.6.2. I installed
> and loaded package qcc by Mr. Luca Scrucca.
>
> This is the structure of my data:
>
> str(dataset2)
> 'data.frame':   140 obs. of  2 variables:
>  $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
> 106 65 17 ...
>  $ Points: num  55 43 24 21 20 20 18 17 16 16 ...
>
>
>
> I tried using the function pareto.chart from the qcc package, but the names
> of the columns in the pareto chart are some codes that do not match the
> school names in the School column of dataset2.
>
> The graph is generated without any issues, it's just that I want the bars
> to have the school labels, how can I accomplish this?
>
> Below is the dput() of my dataset.
>
> dput(dataset2)
> structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
> 116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
> 114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
> 14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
> 95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
> 125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
> 80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
> 5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
> 32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
> 99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
> 134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
> 69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
> 91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
> "Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
> "Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
> "Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
> "Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
> "Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
> "Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
> "Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
> "Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
> "David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
> "El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
> "El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
> "Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
> "Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
> Espinar",
> "Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
> "La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
> "Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
> "Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
> "Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
> "Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
> "Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
> "Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
> "Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
> "Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
> "R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
> "Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
> "San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
> Porres",
> "Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
> "Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
> "Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
> ), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
> 17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
> 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
> 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
> ), class = "data.frame")
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: qcc_dataset2.pdf
Type: application/pdf
Size: 9274 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200820/ccdb61f2/attachment.pdf>

From r@oknz @end|ng |rom gm@||@com  Thu Aug 20 03:28:15 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 20 Aug 2020 13:28:15 +1200
Subject: [R] & and |
In-Reply-To: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
Message-ID: <CABcYAdJo6GskigEuAx+LRkQY87wk8bDL7OL2i2dx3xrXL4vDEQ@mail.gmail.com>

There are & and | operators in the R language.
There is an | operator in regular expressions.
There is NOT any & operator in regular expressions.
grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
looks for elements of mydata containing the literal
string 'ConfoMap&GuineaPigs'.

> foo <- c("a","b","cab","back")
> foo[grepl("a",foo) & grepl("b",foo)]
[1] "cab"  "back"

grepl returns a TRUE/FALSE vector.

On Thu, 20 Aug 2020 at 02:53, Ivan Calandra <calandra at rgzm.de> wrote:

> Dear useRs,
>
> I feel really stupid, but I cannot understand why "&" doesn't work as I
> expect, while "|" does.
>
> I have the following vector:
> mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
> "SSFA-ConfoMap_Lithics_NMPfilled.csv",
> "SSFA-ConfoMap_Sheeps_NMPfilled.csv", "SSFA-Toothfrax_GuineaPigs.xlsx",
> "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
> and I want to find the values that include both "ConfoMap" and
> "GuineaPigs".
>
> If I do:
> grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> it returns an empty vector, character(0).
>
> But if I do:
> grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
> it returns all the elements that include either "ConfoMap" or
> "GuineaPigs", as I would expect.
>
> So what is wrong with my "&" construct? How can I return the elements
> that include both parts?
>
> Thank you for your help!
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Aug 20 08:38:04 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 20 Aug 2020 08:38:04 +0200
Subject: [R] & and |
In-Reply-To: <CABcYAdJo6GskigEuAx+LRkQY87wk8bDL7OL2i2dx3xrXL4vDEQ@mail.gmail.com>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CABcYAdJo6GskigEuAx+LRkQY87wk8bDL7OL2i2dx3xrXL4vDEQ@mail.gmail.com>
Message-ID: <33ee61ee-9d45-3a14-5eb0-107b1dc37653@rgzm.de>

Thank you all for all the very helpful answers!

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 20/08/2020 3:28, Richard O'Keefe wrote:
> There are & and | operators in the R language.
> There is an | operator in regular expressions.
> There is NOT any & operator in regular expressions.
> grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> looks for elements of mydata containing the literal
> string 'ConfoMap&GuineaPigs'.
>
> > foo <- c("a","b","cab","back")
> > foo[grepl("a",foo) & grepl("b",foo)]
> [1] "cab" ?"back"
>
> grepl returns a TRUE/FALSE vector.
>
> On Thu, 20 Aug 2020 at 02:53, Ivan Calandra <calandra at rgzm.de
> <mailto:calandra at rgzm.de>> wrote:
>
>     Dear useRs,
>
>     I feel really stupid, but I cannot understand why "&" doesn't work
>     as I
>     expect, while "|" does.
>
>     I have the following vector:
>     mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
>     "SSFA-ConfoMap_Lithics_NMPfilled.csv",?
>     "SSFA-ConfoMap_Sheeps_NMPfilled.csv",
>     "SSFA-Toothfrax_GuineaPigs.xlsx",
>     "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
>     and I want to find the values that include both "ConfoMap" and
>     "GuineaPigs".
>
>     If I do:
>     grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
>     it returns an empty vector, character(0).
>
>     But if I do:
>     grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
>     it returns all the elements that include either "ConfoMap" or
>     "GuineaPigs", as I would expect.
>
>     So what is wrong with my "&" construct? How can I return the elements
>     that include both parts?
>
>     Thank you for your help!
>     Ivan
>
>     -- 
>     Dr. Ivan Calandra
>     TraCEr, laboratory for Traceology and Controlled Experiments
>     MONREPOS Archaeological Research Centre and
>     Museum for Human Behavioural Evolution
>     Schloss Monrepos
>     56567 Neuwied, Germany
>     +49 (0) 2631 9772-243
>     https://www.researchgate.net/profile/Ivan_Calandra
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Aug 20 08:40:31 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 20 Aug 2020 08:40:31 +0200
Subject: [R] combine filter() and select()
In-Reply-To: <1665597756.3818393.1597857717037.JavaMail.zimbra@psyctc.org>
References: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
 <1665597756.3818393.1597857717037.JavaMail.zimbra@psyctc.org>
Message-ID: <8b46ccc8-05a6-e829-bb1d-552b972644b0@rgzm.de>

Dear Chris,

I didn't think about having the assignment at the end as you showed; it
indeed fits the pipe workflow better.

By "easy", I actually meant shorter. As you said, in base R, I usually
do that in 1 line, so I was hoping to do the same in tidyverse. But I'm
glad to hear that I'm using tidyverse the proper way :)

Best regards,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 19/08/2020 19:21, Chris Evans wrote:
> Inline
>
> ----- Original Message -----
>> From: "Ivan Calandra" <calandra at rgzm.de>
>> To: "R-help" <r-help at r-project.org>
>> Sent: Wednesday, 19 August, 2020 16:56:32
>> Subject: [R] combine filter() and select()
>> Dear useRs,
>>
>> I'm new to the tidyverse world and I need some help on basic things.
>>
>> I have the following tibble:
>> mytbl <- structure(list(files = c("a", "b", "c", "d", "e", "f"), prop =
>> 1:6), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"))
>>
>> I want to subset the rows with "a" in the column "files", and keep only
>> that column.
>>
>> So I did:
>> myfile <- mytbl %>%
>> ? filter(grepl("a", files)) %>%
>> ? select(files)
>>
>> It works, but I believe there must be an easier way to combine filter()
>> and select(), right?
> I would write 
>
> mytbl %>%
>   filter(grepl("a", files)) %>%
>   select(files) -> myfile
>
> as I like to keep a sort of "top to bottom and left to right" flow when writing in the tidyverse dialect of R but that's really not important.
>
> Apart from that I think what you've done is "proper tidyverse". To me another difference between the dialects is that classical R often seems to put value on, and make it easy, to do things with incredible few characters.  I think the people who are brilliant at that sort of coding, and there are many on this list, that sort of coding is also easy to read.  I know that Chinese is easy to read if you grew up on it but to a bear of little brain like me, the much more verbose style of tidyverse repays typing time with readability when I come back to my code and, though I have little experience of this yet, when I read other poeple's code.
>
> What did you think wasn't "easy" about what you wrote?
>
> Very best (all),
>
> Chris
>
>> Thank you!
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Aug 20 08:46:45 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 20 Aug 2020 08:46:45 +0200
Subject: [R] combine filter() and select()
In-Reply-To: <F2B9A144-F301-40E8-A050-C8B45D062883@dcn.davis.ca.us>
References: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
 <F2B9A144-F301-40E8-A050-C8B45D062883@dcn.davis.ca.us>
Message-ID: <29eaaeb1-8e71-8c46-52ec-8535c92cb7ef@rgzm.de>

Hi Jeff,

The code you show is exactly what I usually do, in base R; but I wanted
to play with tidyverse to learn it (and also understand when it makes
sense and when it doesn't).

And yes, of course, in the example I gave, I end up with a 1-cell
tibble, which could be better extracted as a length-1 vector. But my
real goal is not to end up with a single value or even a single column.
I just thought that simplifying my example was the best approach to ask
for advice.

But thank you for letting me know that what I'm doing is pointless!

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 19/08/2020 19:27, Jeff Newmiller wrote:
> The whole point of dplyr primitives is to support data frames... that is, lists of columns. When you pare your data frame down to one column you are almost certainly using the wrong tool for the job.
>
> So, sure, your code works... and it even does what you wanted in the dplyr style, but what a pointless exercise.
>
> grep( "a", mytbl$file, value=TRUE )
>
> On August 19, 2020 7:56:32 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Dear useRs,
>>
>> I'm new to the tidyverse world and I need some help on basic things.
>>
>> I have the following tibble:
>> mytbl <- structure(list(files = c("a", "b", "c", "d", "e", "f"), prop =
>> 1:6), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"))
>>
>> I want to subset the rows with "a" in the column "files", and keep only
>> that column.
>>
>> So I did:
>> myfile <- mytbl %>%
>> ? filter(grepl("a", files)) %>%
>> ? select(files)
>>
>> It works, but I believe there must be an easier way to combine filter()
>> and select(), right?
>>
>> Thank you!
>> Ivan


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Aug 20 10:41:13 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 20 Aug 2020 10:41:13 +0200
Subject: [R] select() columns using their positions
Message-ID: <5c41a824-95be-8480-dc1e-9d35c316d360@rgzm.de>

Dear useRs,

I'm still trying to learn tidyverse syntax.

I would like to select() columns based on their positions/indices, but I
cannot find a way to do that (I've seen a lot about doing that for rows,
but I could not find anything for columns). I thought it would be
obvious, but I cannot find it.

Basically, I am looking for something like:
mydata %>%
? select( vector_of_indices )
I know that the pipe is useless here, but there are more steps in my
real code.

The helper num_range() works only when headers contains the positions
(e.g. "x1, x2...").

Of course, it's easy using "[", but I expected it would be possible with
select() as well; it would make the code more readable than:
mydata %>%
? .[ vector_of_indices ]

Thank you for your help.
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Aug 20 11:03:47 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 20 Aug 2020 02:03:47 -0700
Subject: [R] select() columns using their positions
In-Reply-To: <5c41a824-95be-8480-dc1e-9d35c316d360@rgzm.de>
References: <5c41a824-95be-8480-dc1e-9d35c316d360@rgzm.de>
Message-ID: <42CC184F-A8B1-4B04-B227-8440533D92E8@dcn.davis.ca.us>

Did you try it?

mydata %>%
? select( c( 1, 2, 4 ) )

On August 20, 2020 1:41:13 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Dear useRs,
>
>I'm still trying to learn tidyverse syntax.
>
>I would like to select() columns based on their positions/indices, but
>I
>cannot find a way to do that (I've seen a lot about doing that for
>rows,
>but I could not find anything for columns). I thought it would be
>obvious, but I cannot find it.
>
>Basically, I am looking for something like:
>mydata %>%
>? select( vector_of_indices )
>I know that the pipe is useless here, but there are more steps in my
>real code.
>
>The helper num_range() works only when headers contains the positions
>(e.g. "x1, x2...").
>
>Of course, it's easy using "[", but I expected it would be possible
>with
>select() as well; it would make the code more readable than:
>mydata %>%
>? .[ vector_of_indices ]
>
>Thank you for your help.
>Ivan

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Aug 20 11:05:48 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 20 Aug 2020 11:05:48 +0200
Subject: [R] select() columns using their positions
In-Reply-To: <42CC184F-A8B1-4B04-B227-8440533D92E8@dcn.davis.ca.us>
References: <5c41a824-95be-8480-dc1e-9d35c316d360@rgzm.de>
 <42CC184F-A8B1-4B04-B227-8440533D92E8@dcn.davis.ca.us>
Message-ID: <56a4b63b-2811-6fd4-b8d1-9feee902da8d@rgzm.de>

OK, my bad... I'm sure I had tried it and it didn't work, but I guess
the error was somewhere else...

Thank you!
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 20/08/2020 11:03, Jeff Newmiller wrote:
> Did you try it?
>
> mydata %>%
> ? select( c( 1, 2, 4 ) )
>
> On August 20, 2020 1:41:13 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Dear useRs,
>>
>> I'm still trying to learn tidyverse syntax.
>>
>> I would like to select() columns based on their positions/indices, but
>> I
>> cannot find a way to do that (I've seen a lot about doing that for
>> rows,
>> but I could not find anything for columns). I thought it would be
>> obvious, but I cannot find it.
>>
>> Basically, I am looking for something like:
>> mydata %>%
>> ? select( vector_of_indices )
>> I know that the pipe is useless here, but there are more steps in my
>> real code.
>>
>> The helper num_range() works only when headers contains the positions
>> (e.g. "x1, x2...").
>>
>> Of course, it's easy using "[", but I expected it would be possible
>> with
>> select() as well; it would make the code more readable than:
>> mydata %>%
>> ? .[ vector_of_indices ]
>>
>> Thank you for your help.
>> Ivan


From nz@h@@m @end|ng |rom gm@||@com  Thu Aug 20 09:42:41 2020
From: nz@h@@m @end|ng |rom gm@||@com (Shaami)
Date: Thu, 20 Aug 2020 12:42:41 +0500
Subject: [R] how to prove sum of probabilities to be one in R?
Message-ID: <CAGR+MS5nfrmsRqSsH1QUe2sZHw2X5ZtytqTeD5ZCMkS9yM4FFg@mail.gmail.com>

Hi Dear

I am facing a floating-point problem related to the sum of probabilities.
It is really difficult to prove that sum of probabilities is 1 because of
some minor differences. The MWE is as follows.

> p1=0.99999999
> p2=0.00000000003> p1+p2==1[1] FALSE

The sum of probabilities is approximately 1. The difference from 1 is
1-p1-p2 =  9.97e-09, that is very small. I need to apply the sum of
probabilities conditions in my many functions. But execution is halted
because of floating point.

Could anyone please guide about that?

Thank you

Regards

Shaami

	[[alternative HTML version deleted]]


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Thu Aug 20 12:46:33 2020
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Thu, 20 Aug 2020 10:46:33 +0000
Subject: [R] combine filter() and select()
In-Reply-To: <29eaaeb1-8e71-8c46-52ec-8535c92cb7ef@rgzm.de>
References: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
 <F2B9A144-F301-40E8-A050-C8B45D062883@dcn.davis.ca.us>
 <29eaaeb1-8e71-8c46-52ec-8535c92cb7ef@rgzm.de>
Message-ID: <BL0PR04MB660925DB8F6DF857A32606DBF95A0@BL0PR04MB6609.namprd04.prod.outlook.com>

A kind of hybrid answer is to use base::subset(), which supports non-standard evaluation (it searches for unquoted symbols like 'files' in the code line below in the object that is its first argument; %>% puts 'mytbl' in that first position) and row (filter) and column (select) subsets

> mytbl %>% subset(files %in% "a", files)
# A tibble: 1 x 1
  files
  <chr>
1 a

Or subset(grepl("a", files), files) if that was what you meant.

One important idea that the tidyverse implements is, in my opinion, 'endomorphism' -- you get back the same type of object as you put in -- so I wouldn't use a base R idiom that returned a vector unless that were somehow essential for the next step in the analysis. 

There is value in having separate functions for filter() and select(), and probably there are edge cases where filter(), select(), and subset() behave differently, but for what it's worth subset() can be used to perform these operations individually

> mytbl %>% subset(, files)
# A tibble: 6 x 1
  files
  <chr>
1 a
2 b
3 c
4 d
5 e
6 f
> mytbl %>% subset(grepl("a", files), )
# A tibble: 1 x 2
  files  prop
  <chr> <int>
1 a         1

Martin Morgan

?On 8/20/20, 2:48 AM, "R-help on behalf of Ivan Calandra" <r-help-bounces at r-project.org on behalf of calandra at rgzm.de> wrote:

    Hi Jeff,

    The code you show is exactly what I usually do, in base R; but I wanted
    to play with tidyverse to learn it (and also understand when it makes
    sense and when it doesn't).

    And yes, of course, in the example I gave, I end up with a 1-cell
    tibble, which could be better extracted as a length-1 vector. But my
    real goal is not to end up with a single value or even a single column.
    I just thought that simplifying my example was the best approach to ask
    for advice.

    But thank you for letting me know that what I'm doing is pointless!

    Ivan

    --
    Dr. Ivan Calandra
    TraCEr, laboratory for Traceology and Controlled Experiments
    MONREPOS Archaeological Research Centre and
    Museum for Human Behavioural Evolution
    Schloss Monrepos
    56567 Neuwied, Germany
    +49 (0) 2631 9772-243
    https://www.researchgate.net/profile/Ivan_Calandra

    On 19/08/2020 19:27, Jeff Newmiller wrote:
    > The whole point of dplyr primitives is to support data frames... that is, lists of columns. When you pare your data frame down to one column you are almost certainly using the wrong tool for the job.
    >
    > So, sure, your code works... and it even does what you wanted in the dplyr style, but what a pointless exercise.
    >
    > grep( "a", mytbl$file, value=TRUE )
    >
    > On August 19, 2020 7:56:32 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
    >> Dear useRs,
    >>
    >> I'm new to the tidyverse world and I need some help on basic things.
    >>
    >> I have the following tibble:
    >> mytbl <- structure(list(files = c("a", "b", "c", "d", "e", "f"), prop =
    >> 1:6), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"))
    >>
    >> I want to subset the rows with "a" in the column "files", and keep only
    >> that column.
    >>
    >> So I did:
    >> myfile <- mytbl %>%
    >>   filter(grepl("a", files)) %>%
    >>   select(files)
    >>
    >> It works, but I believe there must be an easier way to combine filter()
    >> and select(), right?
    >>
    >> Thank you!
    >> Ivan

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.

From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Aug 20 13:07:24 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 20 Aug 2020 07:07:24 -0400
Subject: [R] how to prove sum of probabilities to be one in R?
In-Reply-To: <CAGR+MS5nfrmsRqSsH1QUe2sZHw2X5ZtytqTeD5ZCMkS9yM4FFg@mail.gmail.com>
References: <CAGR+MS5nfrmsRqSsH1QUe2sZHw2X5ZtytqTeD5ZCMkS9yM4FFg@mail.gmail.com>
Message-ID: <03c53f05-3e2c-5b83-87a9-fbd91a36ba66@gmail.com>

On 20/08/2020 3:42 a.m., Shaami wrote:
 > Hi Dear
 >
 > I am facing a floating-point problem related to the sum of probabilities.
 > It is really difficult to prove that sum of probabilities is 1 because of
 > some minor differences. The MWE is as follows.
 >
 >> p1=0.99999999
 >> p2=0.00000000003> p1+p2==1[1] FALSE
 >
 > The sum of probabilities is approximately 1. The difference from 1 is
 > 1-p1-p2 =  9.97e-09, that is very small. I need to apply the sum of
 > probabilities conditions in my many functions. But execution is halted
 > because of floating point.
 >
 > Could anyone please guide about that?
Use the approximate test

isTRUE(all.equal(p1+p2, 1))

If the default tolerance of sqrt(.Machine$double.eps) (about 1.5e-8) is 
wrong, change it:

isTRUE(all.equal(p1+p2, 1, tolerance = 0.1))

This says anything between 0.9 and 1.1 is equal to 1.

Duncan Murdoch


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 20 13:14:56 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 20 Aug 2020 12:14:56 +0100
Subject: [R] select() columns using their positions
In-Reply-To: <56a4b63b-2811-6fd4-b8d1-9feee902da8d@rgzm.de>
References: <5c41a824-95be-8480-dc1e-9d35c316d360@rgzm.de>
 <42CC184F-A8B1-4B04-B227-8440533D92E8@dcn.davis.ca.us>
 <56a4b63b-2811-6fd4-b8d1-9feee902da8d@rgzm.de>
Message-ID: <2812c8db-5f92-94d3-ce0c-8984affd2302@sapo.pt>

Hello,

It is also possible to select by vectors of indices (as opposed to a 
vector):
top_n is just to not clutter the display.


library(dplyr)

data(iris)

iris %>% select(1, 3, 4) %>% top_n(5)
iris %>% select(c(1, 3), 4) %>% top_n(5)


Hope this helps,

Rui Barradas


?s 10:05 de 20/08/20, Ivan Calandra escreveu:
> OK, my bad... I'm sure I had tried it and it didn't work, but I guess
> the error was somewhere else...
> 
> Thank you!
> Ivan
> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> On 20/08/2020 11:03, Jeff Newmiller wrote:
>> Did you try it?
>>
>> mydata %>%
>>  ? select( c( 1, 2, 4 ) )
>>
>> On August 20, 2020 1:41:13 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>>> Dear useRs,
>>>
>>> I'm still trying to learn tidyverse syntax.
>>>
>>> I would like to select() columns based on their positions/indices, but
>>> I
>>> cannot find a way to do that (I've seen a lot about doing that for
>>> rows,
>>> but I could not find anything for columns). I thought it would be
>>> obvious, but I cannot find it.
>>>
>>> Basically, I am looking for something like:
>>> mydata %>%
>>>  ? select( vector_of_indices )
>>> I know that the pipe is useless here, but there are more steps in my
>>> real code.
>>>
>>> The helper num_range() works only when headers contains the positions
>>> (e.g. "x1, x2...").
>>>
>>> Of course, it's easy using "[", but I expected it would be possible
>>> with
>>> select() as well; it would make the code more readable than:
>>> mydata %>%
>>>  ? .[ vector_of_indices ]
>>>
>>> Thank you for your help.
>>> Ivan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tom @end|ng |rom d|@no|go@com  Wed Aug 12 17:50:52 2020
From: tom @end|ng |rom d|@no|go@com (Thomas Farrar)
Date: Wed, 12 Aug 2020 17:50:52 +0200
Subject: [R] [R-pkgs] skedastic: Heteroskedasticity Diagnostics for Linear
 Regression Models
Message-ID: <CAG25rBKCrMex3yp8yd-QRyXj_3D79m1tY73jNj8y6H7rwObrnA@mail.gmail.com>

Dear All,

Allow me to re-introduce the skedastic package (version 1.0.0) which now
implements more than 20 different heteroskedasticity tests for the linear
regression model, as well as a graphical diagnostic tool and some helper
functions with broader applications (e.g., computing probability
distributions of certain nonparametric statistics, computing two-sided
p-values from asymmetric distributions using three different methods, and
computing cumulative probabilities for ratios of quadratic forms in normal
random vectors).

All of the included heteroskedasticity tests are taken from
statistics/econometrics literature but many of them have never (to my
knowledge) been made available in statistical software until now.

The new version of the package also incorporates unit tests via testthat
and is thus more robust against code breaks.

CRAN page: https://cran.r-project.org/package=skedastic
Github page: https://github.com/tjfarrar/skedastic

Sincerely,
Thomas

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From h@w|ckh@m @end|ng |rom gm@||@com  Thu Aug 20 18:52:44 2020
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Thu, 20 Aug 2020 11:52:44 -0500
Subject: [R] combine filter() and select()
In-Reply-To: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
References: <cd5f4344-b9b9-3135-8fc5-8a235084804f@rgzm.de>
Message-ID: <CABdHhvG8ERjPPaupUeZG=ZhvavEHU7Na8mj_o+CmNzJ-qUaCug@mail.gmail.com>

On Wed, Aug 19, 2020 at 10:03 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
> Dear useRs,
>
> I'm new to the tidyverse world and I need some help on basic things.
>
> I have the following tibble:
> mytbl <- structure(list(files = c("a", "b", "c", "d", "e", "f"), prop =
> 1:6), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"))
>
> I want to subset the rows with "a" in the column "files", and keep only
> that column.
>
> So I did:
> myfile <- mytbl %>%
>   filter(grepl("a", files)) %>%
>   select(files)
>
> It works, but I believe there must be an easier way to combine filter()
> and select(), right?

Not in the tidyverse. As others have mentioned, both [ and subset() in
base R allow you to simultaneously subset rows and columns, but
there's no single verb in the tidyverse that does both. This is
somewhat informed by the observation that in data frames, unlike
matrices, rows and columns are not exchangeable, and you typically
want to express subsetting in rather different ways.

Hadley

-- 
http://hadley.nz


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 21 00:37:43 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 20 Aug 2020 15:37:43 -0700
Subject: [R] & and |
In-Reply-To: <33ee61ee-9d45-3a14-5eb0-107b1dc37653@rgzm.de>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CABcYAdJo6GskigEuAx+LRkQY87wk8bDL7OL2i2dx3xrXL4vDEQ@mail.gmail.com>
 <33ee61ee-9d45-3a14-5eb0-107b1dc37653@rgzm.de>
Message-ID: <CAGxFJbScRUmTtrCkDy3oMLG34OhKAH6eb-3MRtn6tPZYP5NcEQ@mail.gmail.com>

The single grep regex solutions offered to Ivan's problem were fine, but do
not readily generalize to the conjunction of multiple (>2, say) regex
patterns that can appear anywhere in a string and in any order. However,
note that this can easily be done using the Perl zero width lookahead
construction,  "(?=...)" .
e.g.
> test <- test <- c("xyCz",
"xAyCz","xAyBzC","xCByAz","xACyB","BAyyC","CBxBAy")

## to search for strings contain "A", "B", & "C" in any order
> grep("(?=.*A)(?=.*B)(?=.*C)", test, perl = TRUE)
[1] 3 4 5 6 7

Note that this matches on one or multiple instances of the patterns. If one
wants only exactly one instance of each conjunct,  then something like this
should do:

> lookfor <- c("A","B","C")
> notme <- paste0("[^",lookfor,"]*")
> z <- paste0("(?=", notme, lookfor, notme, "$)",collapse = "")
> grep(z, test, perl = TRUE)
[1] 3 4 5 6

Cheers,
Bert




On Wed, Aug 19, 2020 at 11:38 PM Ivan Calandra <calandra at rgzm.de> wrote:

> Thank you all for all the very helpful answers!
>
> Best,
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 20/08/2020 3:28, Richard O'Keefe wrote:
> > There are & and | operators in the R language.
> > There is an | operator in regular expressions.
> > There is NOT any & operator in regular expressions.
> > grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> > looks for elements of mydata containing the literal
> > string 'ConfoMap&GuineaPigs'.
> >
> > > foo <- c("a","b","cab","back")
> > > foo[grepl("a",foo) & grepl("b",foo)]
> > [1] "cab"  "back"
> >
> > grepl returns a TRUE/FALSE vector.
> >
> > On Thu, 20 Aug 2020 at 02:53, Ivan Calandra <calandra at rgzm.de
> > <mailto:calandra at rgzm.de>> wrote:
> >
> >     Dear useRs,
> >
> >     I feel really stupid, but I cannot understand why "&" doesn't work
> >     as I
> >     expect, while "|" does.
> >
> >     I have the following vector:
> >     mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
> >     "SSFA-ConfoMap_Lithics_NMPfilled.csv",
> >     "SSFA-ConfoMap_Sheeps_NMPfilled.csv",
> >     "SSFA-Toothfrax_GuineaPigs.xlsx",
> >     "SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
> >     and I want to find the values that include both "ConfoMap" and
> >     "GuineaPigs".
> >
> >     If I do:
> >     grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
> >     it returns an empty vector, character(0).
> >
> >     But if I do:
> >     grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
> >     it returns all the elements that include either "ConfoMap" or
> >     "GuineaPigs", as I would expect.
> >
> >     So what is wrong with my "&" construct? How can I return the elements
> >     that include both parts?
> >
> >     Thank you for your help!
> >     Ivan
> >
> >     --
> >     Dr. Ivan Calandra
> >     TraCEr, laboratory for Traceology and Controlled Experiments
> >     MONREPOS Archaeological Research Centre and
> >     Museum for Human Behavioural Evolution
> >     Schloss Monrepos
> >     56567 Neuwied, Germany
> >     +49 (0) 2631 9772-243
> >     https://www.researchgate.net/profile/Ivan_Calandra
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@p@rk4 @end|ng |rom u|c@edu  Fri Aug 21 03:06:16 2020
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Fri, 21 Aug 2020 01:06:16 +0000
Subject: [R] Rotation Forest Error Message
Message-ID: <DM5PR13MB1161006F7A448E310BE01244FA5B0@DM5PR13MB1161.namprd13.prod.outlook.com>

Hi R Helpers,

I wanted to try the rotationForest package.

I pointed it at my data set and got the error message "Error in if (K >= ncol(x)) stop("K should not be greater than or equal to the number of columns in x") :
  argument is of length zero'.

My dataset has 3688 obs. of  111 variables.

Would a quick adjustment to the default value of K resolve this?

If anybody with more experience with the package than me has a general suggestion I would appreciate it.

--John Spaarks


	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Fri Aug 21 06:16:58 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 21 Aug 2020 16:16:58 +1200
Subject: [R] Rotation Forest Error Message
In-Reply-To: <DM5PR13MB1161006F7A448E310BE01244FA5B0@DM5PR13MB1161.namprd13.prod.outlook.com>
References: <DM5PR13MB1161006F7A448E310BE01244FA5B0@DM5PR13MB1161.namprd13.prod.outlook.com>
Message-ID: <CAB8pepz0E6QhtnZ2fuYn9c7_hq1Vp3SHZseBCCKpmojENcfuvA@mail.gmail.com>

Note that I'm not familiar with this package or the method.
Also note that you haven't told anyone what function you're using, or
what your call was.

I'm assuming that you're using the rotationForest() function.
According to its help page, the default is:

    K = round(ncol(x)/3, 0)

There's no reason why the default K value should be higher than the
number of columns, unless:
(1) There's a bug with the package; or
(2) There's a problem with your input.

I note that the package is only version 0.1.3, so a bug is not out of
the question.
Also, I'm a little surprised the author didn't use integer division:

    K = ncol (x) %/% 3

You could just set K to the above value, and see what happens...


On Fri, Aug 21, 2020 at 1:06 PM Sparks, John <jspark4 at uic.edu> wrote:
>
> Hi R Helpers,
>
> I wanted to try the rotationForest package.
>
> I pointed it at my data set and got the error message "Error in if (K >= ncol(x)) stop("K should not be greater than or equal to the number of columns in x") :
>   argument is of length zero'.
>
> My dataset has 3688 obs. of  111 variables.
>
> Would a quick adjustment to the default value of K resolve this?
>
> If anybody with more experience with the package than me has a general suggestion I would appreciate it.
>
> --John Spaarks
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Fri Aug 21 06:22:02 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 21 Aug 2020 16:22:02 +1200
Subject: [R] Rotation Forest Error Message
In-Reply-To: <CAB8pepz0E6QhtnZ2fuYn9c7_hq1Vp3SHZseBCCKpmojENcfuvA@mail.gmail.com>
References: <DM5PR13MB1161006F7A448E310BE01244FA5B0@DM5PR13MB1161.namprd13.prod.outlook.com>
 <CAB8pepz0E6QhtnZ2fuYn9c7_hq1Vp3SHZseBCCKpmojENcfuvA@mail.gmail.com>
Message-ID: <CAB8pepy-wgbDwc=8avAMWysZPJFNnP1x1ne3Na1O+oPYLw-vaA@mail.gmail.com>

Just re-read your question and realized I misread the error message.
The argument is of zero length.

But the conclusion is the same, either a bug in the package, or a
problem with your input.


On Fri, Aug 21, 2020 at 4:16 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Note that I'm not familiar with this package or the method.
> Also note that you haven't told anyone what function you're using, or
> what your call was.
>
> I'm assuming that you're using the rotationForest() function.
> According to its help page, the default is:
>
>     K = round(ncol(x)/3, 0)
>
> There's no reason why the default K value should be higher than the
> number of columns, unless:
> (1) There's a bug with the package; or
> (2) There's a problem with your input.
>
> I note that the package is only version 0.1.3, so a bug is not out of
> the question.
> Also, I'm a little surprised the author didn't use integer division:
>
>     K = ncol (x) %/% 3
>
> You could just set K to the above value, and see what happens...
>
>
> On Fri, Aug 21, 2020 at 1:06 PM Sparks, John <jspark4 at uic.edu> wrote:
> >
> > Hi R Helpers,
> >
> > I wanted to try the rotationForest package.
> >
> > I pointed it at my data set and got the error message "Error in if (K >= ncol(x)) stop("K should not be greater than or equal to the number of columns in x") :
> >   argument is of length zero'.
> >
> > My dataset has 3688 obs. of  111 variables.
> >
> > Would a quick adjustment to the default value of K resolve this?
> >
> > If anybody with more experience with the package than me has a general suggestion I would appreciate it.
> >
> > --John Spaarks
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From c@|@ndr@ @end|ng |rom rgzm@de  Fri Aug 21 08:50:29 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Fri, 21 Aug 2020 08:50:29 +0200
Subject: [R] & and |
In-Reply-To: <CAGxFJbScRUmTtrCkDy3oMLG34OhKAH6eb-3MRtn6tPZYP5NcEQ@mail.gmail.com>
References: <2c71618c-8c4b-a547-8642-66f2038f459f@rgzm.de>
 <CABcYAdJo6GskigEuAx+LRkQY87wk8bDL7OL2i2dx3xrXL4vDEQ@mail.gmail.com>
 <33ee61ee-9d45-3a14-5eb0-107b1dc37653@rgzm.de>
 <CAGxFJbScRUmTtrCkDy3oMLG34OhKAH6eb-3MRtn6tPZYP5NcEQ@mail.gmail.com>
Message-ID: <33a5db80-a65c-8b1b-59db-faa0b6f191eb@rgzm.de>

Thank you Bert, this is wonderful!

Best wishes,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 21/08/2020 0:37, Bert Gunter wrote:
> The single grep regex solutions offered to Ivan's problem were fine,
> but do not readily generalize to the conjunction of multiple (>2, say)
> regex patterns that can appear anywhere in a string and in any order.
> However, note that this can easily be done using the Perl zero width
> lookahead construction,? "(?=...)" .
> e.g.
> > test <- test <- c("xyCz",
> "xAyCz","xAyBzC","xCByAz","xACyB","BAyyC","CBxBAy")
>
> ## to search for strings contain "A", "B", & "C" in any order
> > grep("(?=.*A)(?=.*B)(?=.*C)", test, perl = TRUE)
> [1] 3 4 5 6 7
>
> Note that this matches on one or multiple instances of the patterns.
> If one wants only exactly one instance of each conjunct,? then
> something like this should do:
>
> > lookfor <- c("A","B","C")
> > notme <- paste0("[^",lookfor,"]*")
> > z <- paste0("(?=", notme, lookfor, notme, "$)",collapse = "")
> > grep(z, test, perl = TRUE)
> [1] 3 4 5 6
>
> Cheers,
> Bert
>
>
>
>
> On Wed, Aug 19, 2020 at 11:38 PM Ivan Calandra <calandra at rgzm.de
> <mailto:calandra at rgzm.de>> wrote:
>
>     Thank you all for all the very helpful answers!
>
>     Best,
>     Ivan
>
>     --
>     Dr. Ivan Calandra
>     TraCEr, laboratory for Traceology and Controlled Experiments
>     MONREPOS Archaeological Research Centre and
>     Museum for Human Behavioural Evolution
>     Schloss Monrepos
>     56567 Neuwied, Germany
>     +49 (0) 2631 9772-243
>     https://www.researchgate.net/profile/Ivan_Calandra
>
>     On 20/08/2020 3:28, Richard O'Keefe wrote:
>     > There are & and | operators in the R language.
>     > There is an | operator in regular expressions.
>     > There is NOT any & operator in regular expressions.
>     > grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
>     > looks for elements of mydata containing the literal
>     > string 'ConfoMap&GuineaPigs'.
>     >
>     > > foo <- c("a","b","cab","back")
>     > > foo[grepl("a",foo) & grepl("b",foo)]
>     > [1] "cab" ?"back"
>     >
>     > grepl returns a TRUE/FALSE vector.
>     >
>     > On Thu, 20 Aug 2020 at 02:53, Ivan Calandra <calandra at rgzm.de
>     <mailto:calandra at rgzm.de>
>     > <mailto:calandra at rgzm.de <mailto:calandra at rgzm.de>>> wrote:
>     >
>     >? ? ?Dear useRs,
>     >
>     >? ? ?I feel really stupid, but I cannot understand why "&"
>     doesn't work
>     >? ? ?as I
>     >? ? ?expect, while "|" does.
>     >
>     >? ? ?I have the following vector:
>     >? ? ?mydata <- c("SSFA-ConfoMap_GuineaPigs_NMPfilled.csv",
>     >? ? ?"SSFA-ConfoMap_Lithics_NMPfilled.csv",?
>     >? ? ?"SSFA-ConfoMap_Sheeps_NMPfilled.csv",
>     >? ? ?"SSFA-Toothfrax_GuineaPigs.xlsx",
>     >? ? ?"SSFA-Toothfrax_Lithics.xlsx", "SSFA-Toothfrax_Sheeps.xlsx")
>     >? ? ?and I want to find the values that include both "ConfoMap" and
>     >? ? ?"GuineaPigs".
>     >
>     >? ? ?If I do:
>     >? ? ?grep("ConfoMap&GuineaPigs", mydata, value=TRUE)
>     >? ? ?it returns an empty vector, character(0).
>     >
>     >? ? ?But if I do:
>     >? ? ?grep("ConfoMap|GuineaPigs", mydata, value=TRUE)
>     >? ? ?it returns all the elements that include either "ConfoMap" or
>     >? ? ?"GuineaPigs", as I would expect.
>     >
>     >? ? ?So what is wrong with my "&" construct? How can I return the
>     elements
>     >? ? ?that include both parts?
>     >
>     >? ? ?Thank you for your help!
>     >? ? ?Ivan
>     >
>     >? ? ?--
>     >? ? ?Dr. Ivan Calandra
>     >? ? ?TraCEr, laboratory for Traceology and Controlled Experiments
>     >? ? ?MONREPOS Archaeological Research Centre and
>     >? ? ?Museum for Human Behavioural Evolution
>     >? ? ?Schloss Monrepos
>     >? ? ?56567 Neuwied, Germany
>     >? ? ?+49 (0) 2631 9772-243
>     >? ? ?https://www.researchgate.net/profile/Ivan_Calandra
>     >
>     >? ? ?______________________________________________
>     >? ? ?R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>     mailing list --
>     >? ? ?To UNSUBSCRIBE and more, see
>     >? ? ?https://stat.ethz.ch/mailman/listinfo/r-help
>     >? ? ?PLEASE do read the posting guide
>     >? ? ?http://www.R-project.org/posting-guide.html
>     >? ? ?and provide commented, minimal, self-contained, reproducible
>     code.
>     >
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From jr@| @end|ng |rom po@teo@no  Fri Aug 21 10:18:11 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 21 Aug 2020 10:18:11 +0200
Subject: [R] Rotation Forest Error Message
In-Reply-To: <CAB8pepy-wgbDwc=8avAMWysZPJFNnP1x1ne3Na1O+oPYLw-vaA@mail.gmail.com>
References: <DM5PR13MB1161006F7A448E310BE01244FA5B0@DM5PR13MB1161.namprd13.prod.outlook.com>
 <CAB8pepz0E6QhtnZ2fuYn9c7_hq1Vp3SHZseBCCKpmojENcfuvA@mail.gmail.com>
 <CAB8pepy-wgbDwc=8avAMWysZPJFNnP1x1ne3Na1O+oPYLw-vaA@mail.gmail.com>
Message-ID: <20200821081811.GA68582@posteo.no>

On 2020-08-21 16:22 +1200, Abby Spurdle wrote:
| On Fri, Aug 21, 2020 at 4:16 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
| | On Fri, Aug 21, 2020 at 1:06 PM Sparks, John <jspark4 at uic.edu> wrote:
| | |
| | | Hi R Helpers,
| | |
| | | I wanted to try the rotationForest 
| | | package.
| | |
| | | I pointed it at my data set and 
| | | got the error message "Error in if 
| | | (K >= ncol(x)) stop("K should not 
| | | be greater than or equal to the 
| | | number of columns in x") :
| | |   argument is of length zero'.
| | |
| | | My dataset has 3688 obs. of  111 variables.
| | |
| | | Would a quick adjustment to the 
| | | default value of K resolve this?
| | |
| | | If anybody with more experience 
| | | with the package than me has a 
| | | general suggestion I would 
| | | appreciate it.
| |
| | Note that I'm not familiar with this 
| | package or the method.  Also note 
| | that you haven't told anyone what 
| | function you're using, or what your 
| | call was.
| |
| | I'm assuming that you're using the 
| | rotationForest() function.  
| | According to its help page, the 
| | default is:
| |
| |     K = round(ncol(x)/3, 0)
| |
| | There's no reason why the default K 
| | value should be higher than the 
| | number of columns, unless:
| | (1) There's a bug with the package; or
| | (2) There's a problem with your input.
| |
| | I note that the package is only 
| | version 0.1.3, so a bug is not out 
| | of the question.  Also, I'm a little 
| | surprised the author didn't use 
| | integer division:
| |
| |     K = ncol(x) %/% 3
| |
| | You could just set K to the above 
| | value, and see what happens...
| 
| Just re-read your question and 
| realized I misread the error message.  
| The argument is of zero length.
| 
| But the conclusion is the same, either 
| a bug in the package, or a problem 
| with your input.

Dear John,

check to see if your columns only has 
numbers in them like the *de jure* iris 
dataset used in the example in 
?rotationForest::rotationForest.

	idx <- 1:100
	idx.new <- which(!(1:nrow(iris) %in% idx))
	y <- as.factor(ifelse(iris$Species[idx]=="setosa", 0, 1))
	x <- iris[idx, -5]
	newdata <- iris[idx.new, -5]
	K <- ncol(x) %/% 3
	L <- 100
	rF <-
	  rotationForest::rotationForest(
	    x=x,
	    y=y,
	    K=K,
	    L=L)
	predict(object=rF, newdata=newdata)

Best,
Rasmus


From m|ke9 @end|ng |rom po@teo@n|  Thu Aug 20 19:55:01 2020
From: m|ke9 @end|ng |rom po@teo@n| (Mike)
Date: Thu, 20 Aug 2020 19:55:01 +0200
Subject: [R] plot.window: need finite 'ylim' values
Message-ID: <20200820175501.GC5734@local>

Dear R users,

I have already asked this in r-sig-finance (not getting a solution)
but it seems to be plot-related anyway.

I like to plot several financial charts to files with an identical
layout according to "indicators" so the charts can be browsed
quickly.

quantmod::chart_Series is a function to plot a financially-related
chart in the upper part and zero or more indicators below. Normally
these indicators would be assigned defined values at least in some
part of the subset/window to be plotted, which is fine for plot. But
if all observations are NA chart_Series throws

Error in plot.window(c(1, 31), c(NaN, NaN)) : need finite 'ylim' values

While this outcome for plot/plot.window may be intended for most
applications it is undesirable here. Getting a blank subwindow here is
intended if the indicator is completely NA (at least in the subset to
be plotted).

This post
https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/015000.html
suggests to generate the plot object with chart_Series and then to
explicitly set x$Env$ylim[[4]] before plotting - without success.

Can I tell plot/plot.window to ignore such errors and simply generate
an empty region instead?

Thanks
Mike


My minimal reproducible:

library(quantmod)

my_plot_function <- function () {
  data (sample_matrix)
  sample.xts <- as.xts (sample_matrix[1:50,'Close'], dateFormat="POSIXct")
  sample.xts <- cbind (sample.xts, NA)
  sample.xts[50,2] <- 0
  colnames (sample.xts) <- c('Close', 'Indicator')

  # Indicator
  ta <- list ("add_TA(sample.xts[,2])")

  # In the range to be plotted ta is completely NA 
  subset <- '2007-01-10::2007-01-30'

  plot (chart_Series (sample.xts[,1], subset=subset, TA=ta))
}

my_plot_function ()


From no@p@m @end|ng |rom ||@@e@NA  Fri Aug 21 09:03:38 2020
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Fri, 21 Aug 2020 09:03:38 +0200
Subject: [R] filter() question
Message-ID: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>

Hi,

I have a small test sample with lab reports (PAP smears) from a number
of different providers.  These have Collection Dates and the relevant 
columns glimpse() something like this:

$ Provider       <chr> "Dr C", "Dr D", "Dr C", "Dr D"
$ CollectionDate <chr> "2016-11-03", "2016-11-02", "2016-11-03", "2016-11-03"


I am looking to find (filter) the reports which were collected in the
time period common to all providers?

Something like 

	 the largest First Common CollectionDate 
and 
	 the smallest Last Common CollectionDate

How would I do that? 

I can of course do this "manually", ie collect all Providers and their 
first and last Collection dates and then find the Common First and Last 
one, but wonder if there is an elegant way of doing this :-)-O



greetings, el

-- 
If you want to email me, replace nospam with el

Dr. Eberhard W. Lisse   \         /       Obstetrician & Gynaecologist
el at lisse.NA             / *      |  Telephone: +264 81 124 6733 (cell)
PO Box 8421 Bachbrecht  \      /  If this email is signed with GPG/PGP
10007, Namibia           ;____/ Sect 20 of Act No. 4 of 2019 may apply


From jr@| @end|ng |rom po@teo@no  Fri Aug 21 11:34:18 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 21 Aug 2020 11:34:18 +0200
Subject: [R] filter() question
In-Reply-To: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>
References: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>
Message-ID: <20200821093418.GB68582@posteo.no>

On 2020-08-21 09:03 +0200, Dr Eberhard Lisse wrote:
> Hi,
> 
> I have a small test sample with lab 
> reports (PAP smears) from a number of 
> different providers.  These have 
> Collection Dates and the relevant 
> columns glimpse() something like 
> this:
> 
> $ Provider       <chr> "Dr C", "Dr D", "Dr C", "Dr D"
> $ CollectionDate <chr> "2016-11-03", "2016-11-02", "2016-11-03", "2016-11-03"
> 
> I am looking to find (filter) the 
> reports which were collected in the 
> time period common to all providers?
> 
> Something like 
> 
> 	 the largest First Common CollectionDate 
> and 
> 	 the smallest Last Common CollectionDate
> 
> How would I do that? 
> 
> I can of course do this "manually", ie 
> collect all Providers and their first 
> and last Collection dates and then 
> find the Common First and Last one, 
> but wonder if there is an elegant way 
> of doing this :-)-O

Dear Eberhard,

Is each report in a csv file with those 
two columns, and you want to unify them 
into a dataframe with CollectionDate 
along the rows, and other details for 
each provider along the columns?  This 
can be done with various apply calls and 
reshape.  Can you please subset some 
more example data here using dput.  It 
makes it so much easier.

/Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200821/c8448814/attachment.sig>

From er|cjberger @end|ng |rom gm@||@com  Fri Aug 21 11:41:26 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 21 Aug 2020 12:41:26 +0300
Subject: [R] filter() question
In-Reply-To: <20200821093418.GB68582@posteo.no>
References: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>
 <20200821093418.GB68582@posteo.no>
Message-ID: <CAGgJW76YA6mfK0LdwK7YSu6E47BVHnV_ODg=86coPCuS39A_Bw@mail.gmail.com>

Hi Eberhard,
Here is one possibility using dplyr.

library(dplyr)
set.seed(3)

## set up some fake data
dtV <- as.Date("2020-08-01") + 0:4
x <- sample(dtV,20,repl=TRUE)
provider <- sample(LETTERS[1:3],20,repl=TRUE)
lDf <- data.frame(Provider=provider,CollectionDate=x,stringsAsFactors=FALSE)

## get min/max date for each provider
a <- lDf %>% dplyr::group_by( Provider ) %>%
  dplyr::mutate( minDt=min(CollectionDate), maxDt=max(CollectionDate)) %>%
  dplyr::summarize( u = min(minDt), v = max(maxDt) )

## get the common interval
c(max(a$u), min(a$v))

# [1] "2020-08-02" "2020-08-04"

HTH,
Eric


On Fri, Aug 21, 2020 at 12:34 PM Rasmus Liland <jral at posteo.no> wrote:

> On 2020-08-21 09:03 +0200, Dr Eberhard Lisse wrote:
> > Hi,
> >
> > I have a small test sample with lab
> > reports (PAP smears) from a number of
> > different providers.  These have
> > Collection Dates and the relevant
> > columns glimpse() something like
> > this:
> >
> > $ Provider       <chr> "Dr C", "Dr D", "Dr C", "Dr D"
> > $ CollectionDate <chr> "2016-11-03", "2016-11-02", "2016-11-03",
> "2016-11-03"
> >
> > I am looking to find (filter) the
> > reports which were collected in the
> > time period common to all providers?
> >
> > Something like
> >
> >        the largest First Common CollectionDate
> > and
> >        the smallest Last Common CollectionDate
> >
> > How would I do that?
> >
> > I can of course do this "manually", ie
> > collect all Providers and their first
> > and last Collection dates and then
> > find the Common First and Last one,
> > but wonder if there is an elegant way
> > of doing this :-)-O
>
> Dear Eberhard,
>
> Is each report in a csv file with those
> two columns, and you want to unify them
> into a dataframe with CollectionDate
> along the rows, and other details for
> each provider along the columns?  This
> can be done with various apply calls and
> reshape.  Can you please subset some
> more example data here using dput.  It
> makes it so much easier.
>
> /Rasmus
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug 21 12:33:08 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 21 Aug 2020 20:33:08 +1000
Subject: [R] plot.window: need finite 'ylim' values
In-Reply-To: <20200820175501.GC5734@local>
References: <20200820175501.GC5734@local>
Message-ID: <CA+8X3fUvsqtpQ9E8i-iGzbLr_K+oybRFT9dp3uMD-oRN=y4nPQ@mail.gmail.com>

Hi Mike,
Try this:

plot (chart_Series (sample.xts[,1], subset=subset, TA=ta),
 type="n",ylim=c(minimum,maximum))

where minimum and maximum are the extremes of the plot if there were
any valid values.

Jim

On Fri, Aug 21, 2020 at 6:32 PM Mike <mike9 at posteo.nl> wrote:
>
> Dear R users,
>
> I have already asked this in r-sig-finance (not getting a solution)
> but it seems to be plot-related anyway.
>
> I like to plot several financial charts to files with an identical
> layout according to "indicators" so the charts can be browsed
> quickly.
>
> quantmod::chart_Series is a function to plot a financially-related
> chart in the upper part and zero or more indicators below. Normally
> these indicators would be assigned defined values at least in some
> part of the subset/window to be plotted, which is fine for plot. But
> if all observations are NA chart_Series throws
>
> Error in plot.window(c(1, 31), c(NaN, NaN)) : need finite 'ylim' values
>
> While this outcome for plot/plot.window may be intended for most
> applications it is undesirable here. Getting a blank subwindow here is
> intended if the indicator is completely NA (at least in the subset to
> be plotted).
>
> This post
> https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/015000.html
> suggests to generate the plot object with chart_Series and then to
> explicitly set x$Env$ylim[[4]] before plotting - without success.
>
> Can I tell plot/plot.window to ignore such errors and simply generate
> an empty region instead?
>
> Thanks
> Mike
>
>
> My minimal reproducible:
>
> library(quantmod)
>
> my_plot_function <- function () {
>   data (sample_matrix)
>   sample.xts <- as.xts (sample_matrix[1:50,'Close'], dateFormat="POSIXct")
>   sample.xts <- cbind (sample.xts, NA)
>   sample.xts[50,2] <- 0
>   colnames (sample.xts) <- c('Close', 'Indicator')
>
>   # Indicator
>   ta <- list ("add_TA(sample.xts[,2])")
>
>   # In the range to be plotted ta is completely NA
>   subset <- '2007-01-10::2007-01-30'
>
>   plot (chart_Series (sample.xts[,1], subset=subset, TA=ta))
> }
>
> my_plot_function ()
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From no@p@m @end|ng |rom ||@@e@NA  Fri Aug 21 13:45:48 2020
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Fri, 21 Aug 2020 13:45:48 +0200
Subject: [R] filter() question
In-Reply-To: <CAGgJW76YA6mfK0LdwK7YSu6E47BVHnV_ODg=86coPCuS39A_Bw@mail.gmail.com>
References: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>
 <20200821093418.GB68582@posteo.no>
 <CAGgJW76YA6mfK0LdwK7YSu6E47BVHnV_ODg=86coPCuS39A_Bw@mail.gmail.com>
Message-ID: <2a3500a0-5862-3288-3b92-932dcbb20083@lisse.NA>

Eric, Rasmus,

thank you very much,

	 ALLPAP  %>%
		 group_by(Provider) %>%
		 mutate( minDt=min(CollectionDate),
			 maxDt=max(CollectionDate)) %>%
		 summarize( minDt = min(minDt),
			 maxDt = max(maxDt), .groups="keep" ) %>%
		 ungroup() %>%
		 mutate(MAX_MIN_DATE = max(minDt),
			 MIN_MAX_DATE = min(maxDt)) %>%
		 distinct(MAX_MIN_DATE, MIN_MAX_DATE)

gives me

	 # A tibble: 1 x 2
		MAX_MIN_DATE MIN_MAX_DATE
		<chr>        <chr>       
	 1 2010-02-05   2019-08-30  

which is correct, and what I wanted.

This is so cool :-)-O

el

On 21/08/2020 11:41, Eric Berger wrote:
> Hi Eberhard,
> Here is one possibility using dplyr. 
[...]
> 
> HTH,
> Eric
> 
> 
> On Fri, Aug 21, 2020 at 12:34 PM Rasmus Liland <jral at posteo.no> wrote:
>> On 2020-08-21 09:03 +0200, Dr Eberhard Lisse wrote:
[...]
>> 
>> Dear Eberhard,
>> 
>> Is each report in a csv file with those two columns, and you want to
>> unify them into a dataframe with CollectionDate along the rows, and
>> other details for each provider along the columns?  This can be done
>> with various apply calls and reshape.  Can you please subset some
>> more example data here using dput.  It makes it so much easier.
>> 
>> /Rasmus
[...]
-- 
Dr. Eberhard W. Lisse   \         /       Obstetrician & Gynaecologist 
el at lisse.NA             / *      |  Telephone: +264 81 124 6733 (cell)
PO Box 8421 Bachbrecht  \      /  If this email is signed with GPG/PGP
10007, Namibia           ;____/ Sect 20 of Act No. 4 of 2019 may apply

-- 
If you want to email me, replace nospam with el


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 21 14:45:11 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 21 Aug 2020 05:45:11 -0700
Subject: [R] filter() question
In-Reply-To: <CAGgJW76YA6mfK0LdwK7YSu6E47BVHnV_ODg=86coPCuS39A_Bw@mail.gmail.com>
References: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>
 <20200821093418.GB68582@posteo.no>
 <CAGgJW76YA6mfK0LdwK7YSu6E47BVHnV_ODg=86coPCuS39A_Bw@mail.gmail.com>
Message-ID: <A1340FFF-0E4F-4EA2-A867-72B95BC44384@dcn.davis.ca.us>

Using mutate followed by summarise in this case is completely unnecessary.

a <- (   lDf
     %>% dplyr::group_by( Provider )
     %>% dplyr::summarise( u = min( CollectionDate )
                         ,, v = max( CollectionDate )
                         )
     )

On August 21, 2020 2:41:26 AM PDT, Eric Berger <ericjberger at gmail.com> wrote:
>Hi Eberhard,
>Here is one possibility using dplyr.
>
>library(dplyr)
>set.seed(3)
>
>## set up some fake data
>dtV <- as.Date("2020-08-01") + 0:4
>x <- sample(dtV,20,repl=TRUE)
>provider <- sample(LETTERS[1:3],20,repl=TRUE)
>lDf <-
>data.frame(Provider=provider,CollectionDate=x,stringsAsFactors=FALSE)
>
>## get min/max date for each provider
>a <- lDf %>% dplyr::group_by( Provider ) %>%
>dplyr::mutate( minDt=min(CollectionDate), maxDt=max(CollectionDate))
>%>%
>  dplyr::summarize( u = min(minDt), v = max(maxDt) )
>
>## get the common interval
>c(max(a$u), min(a$v))
>
># [1] "2020-08-02" "2020-08-04"
>
>HTH,
>Eric
>
>
>On Fri, Aug 21, 2020 at 12:34 PM Rasmus Liland <jral at posteo.no> wrote:
>
>> On 2020-08-21 09:03 +0200, Dr Eberhard Lisse wrote:
>> > Hi,
>> >
>> > I have a small test sample with lab
>> > reports (PAP smears) from a number of
>> > different providers.  These have
>> > Collection Dates and the relevant
>> > columns glimpse() something like
>> > this:
>> >
>> > $ Provider       <chr> "Dr C", "Dr D", "Dr C", "Dr D"
>> > $ CollectionDate <chr> "2016-11-03", "2016-11-02", "2016-11-03",
>> "2016-11-03"
>> >
>> > I am looking to find (filter) the
>> > reports which were collected in the
>> > time period common to all providers?
>> >
>> > Something like
>> >
>> >        the largest First Common CollectionDate
>> > and
>> >        the smallest Last Common CollectionDate
>> >
>> > How would I do that?
>> >
>> > I can of course do this "manually", ie
>> > collect all Providers and their first
>> > and last Collection dates and then
>> > find the Common First and Last one,
>> > but wonder if there is an elegant way
>> > of doing this :-)-O
>>
>> Dear Eberhard,
>>
>> Is each report in a csv file with those
>> two columns, and you want to unify them
>> into a dataframe with CollectionDate
>> along the rows, and other details for
>> each provider along the columns?  This
>> can be done with various apply calls and
>> reshape.  Can you please subset some
>> more example data here using dput.  It
>> makes it so much easier.
>>
>> /Rasmus
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Fri Aug 21 16:15:22 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 21 Aug 2020 16:15:22 +0200
Subject: [R] filter() question
In-Reply-To: <2a3500a0-5862-3288-3b92-932dcbb20083@lisse.NA>
References: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>
 <20200821093418.GB68582@posteo.no>
 <CAGgJW76YA6mfK0LdwK7YSu6E47BVHnV_ODg=86coPCuS39A_Bw@mail.gmail.com>
 <2a3500a0-5862-3288-3b92-932dcbb20083@lisse.NA>
Message-ID: <20200821141522.GC68582@posteo.no>

On 2020-08-21 13:45 +0200, Dr Eberhard Lisse wrote:
| 
| Eric, Rasmus,
| 
| thank you very much,
| 
| 	 ALLPAP  %>%
| 		 group_by(Provider) %>%
| 		 mutate( minDt=min(CollectionDate),
| 			 maxDt=max(CollectionDate)) %>%
| 		 summarize( minDt = min(minDt),
| 			 maxDt = max(maxDt), .groups="keep" ) %>%
| 		 ungroup() %>%
| 		 mutate(MAX_MIN_DATE = max(minDt),
| 			 MIN_MAX_DATE = min(maxDt)) %>%
| 		 distinct(MAX_MIN_DATE, MIN_MAX_DATE)
| 
| gives me
| 
| 	 # A tibble: 1 x 2
| 		MAX_MIN_DATE MIN_MAX_DATE
| 		<chr>        <chr>       
| 	 1 2010-02-05   2019-08-30  
| 
| which is correct, and what I wanted.
| 
| This is so cool :-)-O

Dear Eberhard,

handling Dates is a bit tricky in normal 
R, but as long as they are characters, 
like in your example there, everything 
is fine.  So I made this example based 
on Eric's example:

	set.seed(3)
	size <- 20
	x <- as.Date("2016-11-03") + 
	  sample(
	    0:30, 
	    size, 
	    repl=TRUE)
	provider <- paste("Dr", 
	  sample(
	    LETTERS[1:3],
	    size,
	    repl=TRUE))
	lDf <- data.frame(
	  Provider=provider,
	  CollectionDate=x,
	  stringsAsFactors=FALSE)
	
	Provider <- sort(unique(lDf$Provider))
	a <- t(sapply(Provider, function(provider, lDf) {
	    cd <- lDf[
	      lDf$Provider==provider,
	      "CollectionDate"]
	    c("Provider"=provider,
	      as.character(c(
	        "u"=min(cd),
	        "v"=max(cd))))
	  }, lDf=lDf))
	a

which yields

	     Provider u            v
	Dr A "Dr A"   "2016-11-06" "2016-12-01"
	Dr B "Dr B"   "2016-11-07" "2016-12-03"
	Dr C "Dr C"   "2016-11-04" "2016-11-12"

Before I did that, I thought about doing 
something with reshape2, but I could not 
come up with something good.

If you want to work with tibbles in that 
tidyverse thing, which probably can more 
easily work with Dates, rbinding tibbles 
together apparently works:

	a <- lapply(Provider, function(provider, lDf) {
	    cd <- lDf[
	      lDf$Provider==provider,
	      "CollectionDate"]
	    dplyr::tibble(
	      "Provider"=provider,
	      "u"=min(cd),
	      "v"=max(cd))
	  }, lDf=lDf)
	a <- do.call(rbind, a)
	a

which yields

	# A tibble: 3 x 3
	  Provider u          v
	  <chr>    <date>     <date>
	1 Dr A     2016-11-06 2016-12-01
	2 Dr B     2016-11-07 2016-12-03
	3 Dr C     2016-11-04 2016-11-12

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200821/189ef2f6/attachment.sig>

From j@p@rk4 @end|ng |rom u|c@edu  Fri Aug 21 20:08:39 2020
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Fri, 21 Aug 2020 18:08:39 +0000
Subject: [R] Rotation Forest Error Message
In-Reply-To: <20200821081811.GA68582@posteo.no>
References: <DM5PR13MB1161006F7A448E310BE01244FA5B0@DM5PR13MB1161.namprd13.prod.outlook.com>
 <CAB8pepz0E6QhtnZ2fuYn9c7_hq1Vp3SHZseBCCKpmojENcfuvA@mail.gmail.com>
 <CAB8pepy-wgbDwc=8avAMWysZPJFNnP1x1ne3Na1O+oPYLw-vaA@mail.gmail.com>,
 <20200821081811.GA68582@posteo.no>
Message-ID: <DM5PR13MB1161524E4736CB8305745A87FA5B0@DM5PR13MB1161.namprd13.prod.outlook.com>

Thanks Abby and Rasumus.

I like to leave the solution on this list for the next potential person.

I had failed to realize that this package doesn't use one of the formula forms.  So my call of


RotFor2000<-rotationForest(up~.,data=modeldata)

is what caused the error.

After converting to the appropriate form


x<-subset(modeldata,select=-c(up))
y<-modeldata$up
tic()
RotFor2000<-rotationForest(x,y)
toc()

It ran just fine.

Thanks again.
--John Sparks







________________________________
From: Rasmus Liland <jral at posteo.no>
Sent: Friday, August 21, 2020 3:18 AM
To: Abby Spurdle <spurdle.a at gmail.com>
Cc: Sparks, John <jspark4 at uic.edu>; R-help <r-help at r-project.org>
Subject: Re: [R] Rotation Forest Error Message

On 2020-08-21 16:22 +1200, Abby Spurdle wrote:
| On Fri, Aug 21, 2020 at 4:16 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
| | On Fri, Aug 21, 2020 at 1:06 PM Sparks, John <jspark4 at uic.edu> wrote:
| | |
| | | Hi R Helpers,
| | |
| | | I wanted to try the rotationForest
| | | package.
| | |
| | | I pointed it at my data set and
| | | got the error message "Error in if
| | | (K >= ncol(x)) stop("K should not
| | | be greater than or equal to the
| | | number of columns in x") :
| | |   argument is of length zero'.
| | |
| | | My dataset has 3688 obs. of  111 variables.
| | |
| | | Would a quick adjustment to the
| | | default value of K resolve this?
| | |
| | | If anybody with more experience
| | | with the package than me has a
| | | general suggestion I would
| | | appreciate it.
| |
| | Note that I'm not familiar with this
| | package or the method.  Also note
| | that you haven't told anyone what
| | function you're using, or what your
| | call was.
| |
| | I'm assuming that you're using the
| | rotationForest() function.
| | According to its help page, the
| | default is:
| |
| |     K = round(ncol(x)/3, 0)
| |
| | There's no reason why the default K
| | value should be higher than the
| | number of columns, unless:
| | (1) There's a bug with the package; or
| | (2) There's a problem with your input.
| |
| | I note that the package is only
| | version 0.1.3, so a bug is not out
| | of the question.  Also, I'm a little
| | surprised the author didn't use
| | integer division:
| |
| |     K = ncol(x) %/% 3
| |
| | You could just set K to the above
| | value, and see what happens...
|
| Just re-read your question and
| realized I misread the error message.
| The argument is of zero length.
|
| But the conclusion is the same, either
| a bug in the package, or a problem
| with your input.

Dear John,

check to see if your columns only has
numbers in them like the *de jure* iris
dataset used in the example in
?rotationForest::rotationForest.

        idx <- 1:100
        idx.new <- which(!(1:nrow(iris) %in% idx))
        y <- as.factor(ifelse(iris$Species[idx]=="setosa", 0, 1))
        x <- iris[idx, -5]
        newdata <- iris[idx.new, -5]
        K <- ncol(x) %/% 3
        L <- 100
        rF <-
          rotationForest::rotationForest(
            x=x,
            y=y,
            K=K,
            L=L)
        predict(object=rF, newdata=newdata)

Best,
Rasmus

	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Sat Aug 22 01:12:12 2020
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Sat, 22 Aug 2020 01:12:12 +0200
Subject: [R] filter() question
In-Reply-To: <20200821141522.GC68582@posteo.no>
References: <b00495ba-0cf8-edc9-d466-cbe9b01ab69b@lisse.NA>
 <20200821093418.GB68582@posteo.no>
 <CAGgJW76YA6mfK0LdwK7YSu6E47BVHnV_ODg=86coPCuS39A_Bw@mail.gmail.com>
 <2a3500a0-5862-3288-3b92-932dcbb20083@lisse.NA>
 <20200821141522.GC68582@posteo.no>
Message-ID: <248c82ba-c45d-d43f-ed19-f05b9f5cf3b1@lisse.NA>

Rasmus,

thank you,

I am an elderly Gynecologist, dabbling a little, ie exactly the
clientele for which the tidyverse "thingy" was developed :-)-O. 

In addition I like readable code so I later understand what I was trying
to do :-)-O

el


On 2020-08-21 16:15 , Rasmus Liland wrote:
> On 2020-08-21 13:45 +0200, Dr Eberhard Lisse wrote:
[...]
> If you want to work with tibbles in that tidyverse thing, which
> probably can more easily work with Dates, rbinding tibbles together
> apparently works:
[...]

-- 
If you want to email me, replace nospam with el



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200822/142fe916/attachment.sig>

From |n|ojomy @end|ng |rom gm@||@com  Sat Aug 22 04:47:24 2020
From: |n|ojomy @end|ng |rom gm@||@com (Jomy Jose)
Date: Sat, 22 Aug 2020 08:17:24 +0530
Subject: [R] Export R outputs to SAS dataset
Message-ID: <CADGufDFon0OTOyW+EK9AyROqmdVyJHcGcBRY=PNScftOxkc6bQ@mail.gmail.com>

Hi
I was able to run R code via PROC IML in SAS,so is there any way to export
the generated outputs to SAS datasets since the R outputs don't follow data
frame structure.

Thanks in advance
Jose

	[[alternative HTML version deleted]]


From tg@77m @end|ng |rom y@hoo@com  Sat Aug 22 06:25:28 2020
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Fri, 21 Aug 2020 21:25:28 -0700
Subject: [R] readxl question
References: <00df01d6783c$442f26c0$cc8d7440$.ref@yahoo.com>
Message-ID: <00df01d6783c$442f26c0$cc8d7440$@yahoo.com>

Colleagues,

 

I have 250 Excel files in a directory. Each of those files has the same
layout. The problem is that the data in each Excel data is not in
rectangular form. I've been using readxl to extract the data which I need.
Each of my metrics are stored in a particular cell. For each metric, I
create text files which stores my metrics.

 

library(plyr)

library(readxl)

 

files <- list.files(pattern="*.xls", full.names = FALSE)

 

# Extract Work Order

WO <- lapply(files, read_excel, sheet="Sheet1", range=("B9")) WO_list <-
as.data.frame(WO) trans_WO <- t(WO_list) write.table(trans_WO ,"WO.txt")

 

# Extract bubble 14_1

BUBBLE_14_1 <- lapply(files, read_excel, sheet="Sheet1", range=("c46"))
BUBBLE_14_1_list <- as.data.frame(BUBBLE_14_1)

trans_BUBBLE_14_1 <- t(BUBBLE_14_1_list)

 

write.table(trans_BUBBLE_14_1,"BUBBLE_14_1.txt")

 

 

# Extract bubble 14_2

BUBBLE_14_2 <- lapply(files, read_excel, sheet="Sheet1", range=("c62"))
BUBBLE_14_2_list <- as.data.frame(BUBBLE_14_2)

trans_BUBBLE_14_2 <- t(BUBBLE_14_2_list)

write.table(trans_BUBBLE_14_2,"BUBBLE_14_2.txt")

 

After the text files have been created, I cut and paste the contents of each
text file to Excel.

This has worked fine if the number of cells I am extracting from a file is
small.

If the number gets larger, this method is inefficient.

 

Any advice on how to do this would be appreciated.

 

All the best,

 

Thomas Subia


	[[alternative HTML version deleted]]


From tg@77m @end|ng |rom y@hoo@com  Sat Aug 22 06:30:11 2020
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Fri, 21 Aug 2020 21:30:11 -0700
Subject: [R] readxl question
References: <00ec01d6783c$ecbb3130$c6319390$.ref@yahoo.com>
Message-ID: <00ec01d6783c$ecbb3130$c6319390$@yahoo.com>

Colleagues,

 

I have 250 Excel files in a directory. Each of those files has the same
layout. The problem is that the data in each Excel data is not in
rectangular form. I've been using readxl to extract the data which I need.
Each of my metrics are stored in a particular cell. For each metric, I
create text files which stores my metrics.

 

library(plyr)

library(readxl)

 

files <- list.files(pattern="*.xls", full.names = FALSE)

 

# Extract Work Order

WO <- lapply(files, read_excel, sheet="Sheet1", range=("B9")) WO_list <-
as.data.frame(WO)

trans_WO <- t(WO_list)

 

write.table(trans_WO ,"WO.txt")

 

# Extract bubble 14_1

BUBBLE_14_1 <- lapply(files, read_excel, sheet="Sheet1", range=("c46"))
BUBBLE_14_1_list <- as.data.frame(BUBBLE_14_1)

trans_BUBBLE_14_1 <- t(BUBBLE_14_1_list)

 

write.table(trans_BUBBLE_14_1,"BUBBLE_14_1.txt")

 

 

# Extract bubble 14_2

BUBBLE_14_2 <- lapply(files, read_excel, sheet="Sheet1", range=("c62"))
BUBBLE_14_2_list <- as.data.frame(BUBBLE_14_2)

trans_BUBBLE_14_2 <- t(BUBBLE_14_2_list)

write.table(trans_BUBBLE_14_2,"BUBBLE_14_2.txt")

 

After the text files have been created, I cut and paste each column of data
to Excel.

This has worked fine if the number of cells I am extracting from a file is
small.

If the number gets larger, this method is inefficient.

 

Any advice on how to do this would be appreciated.

 

All the best,

 

Thomas Subia


	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Aug 22 11:10:17 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 22 Aug 2020 09:10:17 +0000 (UTC)
Subject: [R] R^2, AICc, bootstrap CIs for Orthogonal regression
References: <470137693.6745414.1598087417038.ref@mail.yahoo.com>
Message-ID: <470137693.6745414.1598087417038@mail.yahoo.com>

Dear R-experts,

I have fitted an orthogonal regression and have some difficulties to get the adjusted R^2 and R^2, the AICc, the coefficients and R^2 bootstrap confidence intervals. Here below my R codes.
Many thanks for your precious help.

########################
y=c(231,212,112,143,154,165,134,115,167,154,134,123,145,167,169,123,132,143,123,165)
x1=c(9,4,5,3,2,1,2,3,4,5,3,6,8,11,2,1,4,3,2,6)
x2=c(9.8,4.2,1.4,2.3,4.3,5.4,2.4,1.1,1.3,6.4,7.5,4.5,2.2,3.3,3.7,3.4,2.1,4.5,3.3,2.2)

####Fit orthogonal regression
install.packages("pracma")
library(pracma)
a=matrix(c(x1,x2),ncol=2)
fit1=odregress(a,y)
fit1 

####R.squared
fit1[["r.squared"]]
fit1[["adj.r.squared"]]

####AICc
install.packages("AICcmodavg")
library(AICcmodavg)
AICc(fit1)

####Bootstrap CIs (coefficients and R^2)
install.packages("boot")
library(boot)
# function to obtain regression...
bs <- function(formula, data, indices) {
??d <- data[indices,] # allows boot to select sample
??fit <- odregress(formula, data=d)
??return(coef(fit))
}
# bootstrapping with 1000 replications
results <- boot(data=Dataset, statistic=bs,
?? R=1000)
########################


From wh@rr|@1 @end|ng |rom protonm@||@com  Fri Aug 21 22:25:06 2020
From: wh@rr|@1 @end|ng |rom protonm@||@com (Wayne Harris)
Date: Fri, 21 Aug 2020 17:25:06 -0300
Subject: [R] on the growth of standard error
Message-ID: <86mu2neogt.fsf-8018@protonmail.com>


I'm intested in understanding why the standard error grows with respect
to the square root of the sample size.  For instance, using an honest
coin and flipping it L times, the expected number of HEADS is half and
we may define the error (relative to the expected number) to be

  e = H - L/2,

where H is the number of heads that we really obtained.  The absolute
value of e grows as L grows, but by how much?  It seems statistical
theory claims it grow by an order of the square root of L.

To try to make things clearer to me, I decided to play a game.  Players
A, B compete to see who gets closer to the error in the number of HEADS
in random samples selected by of an honest coin.  Both players know the
error should follow some square root of L, but B guesses 1/3 sqrt(L)
while A guesses 1/2 sqrt(L) and it seems A is usually better.

It seems statistical theory says the constant should be the standard
deviation of the phenomenon.  I may not have the proper terminology
here.  The standard deviation for the phenomenon of flipping an honest
coin can be taken to be sqrt[((-1/2)^2 + (1/2)^2)/2] = 1/2 by defining
that TAILS are zero and HEADS are one.  (So that's why A is doing
better.)

The standard deviation giving the best constant seems clear because
errors are normally distributed and that is intuitive.  So the standard
deviation gives a measure of how samples might vary, so we can use it to
estimate how far a guess will be from the expected value.  

But standard deviation is only one measure.  I could use the absolute
deviation too, couldn't I?  The absolute deviation of an honest coin
turns out to be 1/2 too, so by luck that's the same answer.  Maybe I'd
need a different example to inspect a particular case of which measure
would turn out to be better.

Anyhow, it's not clear to me why standard deviation is really the best
guess (if it is that at all) for the constant and it's even less clear
to me why error grows with respect to the square root of the number of
coin flips, that is, of the sample size.

I would like to have an intuitive understanding of this, but if that's
too hard, I would at least like to see some mathematical argument on an
interesting book, which you might point me out to.

Thank you!

PS. Is this off-topic?  I'm not aware of any newsgroup on statistics at
the moment.  Please point me to the adequate place if that's applicable?


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug 22 16:26:31 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 22 Aug 2020 07:26:31 -0700
Subject: [R] on the growth of standard error
In-Reply-To: <86mu2neogt.fsf-8018@protonmail.com>
References: <86mu2neogt.fsf-8018@protonmail.com>
Message-ID: <CF000F6F-6A7A-46F0-9B13-31CCC2DFB042@dcn.davis.ca.us>

stats.stackexchange.com

On August 21, 2020 1:25:06 PM PDT, Wayne Harris via R-help <r-help at r-project.org> wrote:
>
>I'm intested in understanding why the standard error grows with respect
>to the square root of the sample size.  For instance, using an honest
>coin and flipping it L times, the expected number of HEADS is half and
>we may define the error (relative to the expected number) to be
>
>  e = H - L/2,
>
>where H is the number of heads that we really obtained.  The absolute
>value of e grows as L grows, but by how much?  It seems statistical
>theory claims it grow by an order of the square root of L.
>
>To try to make things clearer to me, I decided to play a game.  Players
>A, B compete to see who gets closer to the error in the number of HEADS
>in random samples selected by of an honest coin.  Both players know the
>error should follow some square root of L, but B guesses 1/3 sqrt(L)
>while A guesses 1/2 sqrt(L) and it seems A is usually better.
>
>It seems statistical theory says the constant should be the standard
>deviation of the phenomenon.  I may not have the proper terminology
>here.  The standard deviation for the phenomenon of flipping an honest
>coin can be taken to be sqrt[((-1/2)^2 + (1/2)^2)/2] = 1/2 by defining
>that TAILS are zero and HEADS are one.  (So that's why A is doing
>better.)
>
>The standard deviation giving the best constant seems clear because
>errors are normally distributed and that is intuitive.  So the standard
>deviation gives a measure of how samples might vary, so we can use it
>to
>estimate how far a guess will be from the expected value.  
>
>But standard deviation is only one measure.  I could use the absolute
>deviation too, couldn't I?  The absolute deviation of an honest coin
>turns out to be 1/2 too, so by luck that's the same answer.  Maybe I'd
>need a different example to inspect a particular case of which measure
>would turn out to be better.
>
>Anyhow, it's not clear to me why standard deviation is really the best
>guess (if it is that at all) for the constant and it's even less clear
>to me why error grows with respect to the square root of the number of
>coin flips, that is, of the sample size.
>
>I would like to have an intuitive understanding of this, but if that's
>too hard, I would at least like to see some mathematical argument on an
>interesting book, which you might point me out to.
>
>Thank you!
>
>PS. Is this off-topic?  I'm not aware of any newsgroup on statistics at
>the moment.  Please point me to the adequate place if that's
>applicable?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug 22 16:46:53 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 22 Aug 2020 07:46:53 -0700
Subject: [R] on the growth of standard error
In-Reply-To: <86mu2neogt.fsf-8018@protonmail.com>
References: <86mu2neogt.fsf-8018@protonmail.com>
Message-ID: <CAGxFJbS55LLpQ1tw=wrNCcERosJ81ux3wbUiCyy387oqQg0Ccw@mail.gmail.com>

+ (in addition to Jeff's link)
https://en.wikipedia.org/wiki/Binomial_distribution

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 22, 2020 at 6:50 AM Wayne Harris via R-help <
r-help at r-project.org> wrote:

>
> I'm intested in understanding why the standard error grows with respect
> to the square root of the sample size.  For instance, using an honest
> coin and flipping it L times, the expected number of HEADS is half and
> we may define the error (relative to the expected number) to be
>
>   e = H - L/2,
>
> where H is the number of heads that we really obtained.  The absolute
> value of e grows as L grows, but by how much?  It seems statistical
> theory claims it grow by an order of the square root of L.
>
> To try to make things clearer to me, I decided to play a game.  Players
> A, B compete to see who gets closer to the error in the number of HEADS
> in random samples selected by of an honest coin.  Both players know the
> error should follow some square root of L, but B guesses 1/3 sqrt(L)
> while A guesses 1/2 sqrt(L) and it seems A is usually better.
>
> It seems statistical theory says the constant should be the standard
> deviation of the phenomenon.  I may not have the proper terminology
> here.  The standard deviation for the phenomenon of flipping an honest
> coin can be taken to be sqrt[((-1/2)^2 + (1/2)^2)/2] = 1/2 by defining
> that TAILS are zero and HEADS are one.  (So that's why A is doing
> better.)
>
> The standard deviation giving the best constant seems clear because
> errors are normally distributed and that is intuitive.  So the standard
> deviation gives a measure of how samples might vary, so we can use it to
> estimate how far a guess will be from the expected value.
>
> But standard deviation is only one measure.  I could use the absolute
> deviation too, couldn't I?  The absolute deviation of an honest coin
> turns out to be 1/2 too, so by luck that's the same answer.  Maybe I'd
> need a different example to inspect a particular case of which measure
> would turn out to be better.
>
> Anyhow, it's not clear to me why standard deviation is really the best
> guess (if it is that at all) for the constant and it's even less clear
> to me why error grows with respect to the square root of the number of
> coin flips, that is, of the sample size.
>
> I would like to have an intuitive understanding of this, but if that's
> too hard, I would at least like to see some mathematical argument on an
> interesting book, which you might point me out to.
>
> Thank you!
>
> PS. Is this off-topic?  I'm not aware of any newsgroup on statistics at
> the moment.  Please point me to the adequate place if that's applicable?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||rpo2 @end|ng |rom ||n|@gov  Fri Aug 21 19:52:18 2020
From: ||rpo2 @end|ng |rom ||n|@gov (Firpo, Mike)
Date: Fri, 21 Aug 2020 17:52:18 +0000
Subject: [R] System Requirements
Message-ID: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>

Hello,

  Reading the FAQ, I'm confused about whether R 4.0.2 is tested on Windows 7.  I found the following:

> 2.24 Does R run under Windows Vista/7/8/Server 2008?
>
> It does. ...

> 2.2 How do I install R for Windows?
>
> Current binary versions of R are known to run on Windows 7 or later, including on 64-bit versions: See Can I use R on 64-bit Windows?. Windows > XP is no longer supported.
>
> We only test on versions of Windows currently supported by Microsoft, mainly 64-bit Windows 7, Windows Server 2008 and Windows 10. ...

  There is no indication what date these questions and answers were posted.  If it's true that R is only tested on supported versions of Windows, that would exclude Vista and Windows 7.

  The download site doesn't mention operating system requirements.  Does 4.0.2 work on Windows 7?

Thank you,

Mike

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Aug 22 17:50:53 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sat, 22 Aug 2020 11:50:53 -0400
Subject: [R] System Requirements
In-Reply-To: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
References: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
Message-ID: <CAJc=yOEs3_rxpK-o5W8dqpafa1PF3DN6ehRJSRofOuHr9Z0YoQ@mail.gmail.com>

Try it and see?

On Sat, Aug 22, 2020 at 11:44 AM Firpo, Mike via R-help <
r-help at r-project.org> wrote:

> Hello,
>
>   Reading the FAQ, I'm confused about whether R 4.0.2 is tested on Windows
> 7.  I found the following:
>
> > 2.24 Does R run under Windows Vista/7/8/Server 2008?
> >
> > It does. ...
>
> > 2.2 How do I install R for Windows?
> >
> > Current binary versions of R are known to run on Windows 7 or later,
> including on 64-bit versions: See Can I use R on 64-bit Windows?. Windows >
> XP is no longer supported.
> >
> > We only test on versions of Windows currently supported by Microsoft,
> mainly 64-bit Windows 7, Windows Server 2008 and Windows 10. ...
>
>   There is no indication what date these questions and answers were
> posted.  If it's true that R is only tested on supported versions of
> Windows, that would exclude Vista and Windows 7.
>
>   The download site doesn't mention operating system requirements.  Does
> 4.0.2 work on Windows 7?
>
> Thank you,
>
> Mike
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Sat Aug 22 18:05:08 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 22 Aug 2020 18:05:08 +0200
Subject: [R] Export R outputs to SAS dataset
In-Reply-To: <CADGufDFon0OTOyW+EK9AyROqmdVyJHcGcBRY=PNScftOxkc6bQ@mail.gmail.com>
References: <CADGufDFon0OTOyW+EK9AyROqmdVyJHcGcBRY=PNScftOxkc6bQ@mail.gmail.com>
Message-ID: <20200822160508.GA139810@posteo.no>

On 2020-08-22 08:17 +0530, Jomy Jose wrote:
| Hi
| I was able to run R code via PROC IML 
| in SAS,so is there any way to export 
| the generated outputs to SAS datasets 
| since the R outputs don't follow data 
| frame structure.

Dear Jomy,

But perhaps you can take the outputs in 
SAS and work on them inside from there?

To export a data frame from R to SAS via 
a file[1], you can use 

	foreign::write.foreign(..., package="SAS")

But I have not tried it.

I have used foreign::read.spss before, 
hehe :-)  

I know R is also possible to call from 
Julia, and the df appearing in Julia, 
this sounds like it should be possible 
SAS too[2], yes?

Best,
Rasmus

[1] https://www.statmethods.net/input/exportingdata.html
[2] https://documentation.sas.com/?docsetId=imlug&docsetTarget=imlug_r_sect012.htm&docsetVersion=15.1&locale=en

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200822/746d64d2/attachment.sig>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug 22 18:07:06 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 22 Aug 2020 17:07:06 +0100
Subject: [R] System Requirements
In-Reply-To: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
References: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
Message-ID: <45d239b7-921b-80f9-73e0-386f6dff3dc2@sapo.pt>

Hello,

Yes, R 4.0.2 works on Windows 7. As for Vista, I don't know, never tried.

Hope this helps,

Rui Barradas

?s 18:52 de 21/08/20, Firpo, Mike via R-help escreveu:
> Hello,
> 
>    Reading the FAQ, I'm confused about whether R 4.0.2 is tested on Windows 7.  I found the following:
> 
>> 2.24 Does R run under Windows Vista/7/8/Server 2008?
>>
>> It does. ...
> 
>> 2.2 How do I install R for Windows?
>>
>> Current binary versions of R are known to run on Windows 7 or later, including on 64-bit versions: See Can I use R on 64-bit Windows?. Windows > XP is no longer supported.
>>
>> We only test on versions of Windows currently supported by Microsoft, mainly 64-bit Windows 7, Windows Server 2008 and Windows 10. ...
> 
>    There is no indication what date these questions and answers were posted.  If it's true that R is only tested on supported versions of Windows, that would exclude Vista and Windows 7.
> 
>    The download site doesn't mention operating system requirements.  Does 4.0.2 work on Windows 7?
> 
> Thank you,
> 
> Mike
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Aug 22 18:51:41 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 22 Aug 2020 12:51:41 -0400
Subject: [R] System Requirements
In-Reply-To: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
References: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
Message-ID: <27af75e5-74d4-9f1f-028a-8e1e3ec75aea@gmail.com>

I don't know the answer to your main question, but if you're interested 
in knowing when that was written, you can see here

https://github.com/wch/r-source/blame/trunk/doc/manual/R-FAQ.texi

for the main FAQ, and here:

https://github.com/wch/r-source/blame/trunk/doc/manual/rw-FAQ.texi

for the Windows FAQ.  The particular entries you were asking about were 
in the Windows FAQ and most recently updated 5 years ago (2.24) or 4 
months ago (2.2).  So there's a good chance that 2.2 is still valid, 
though like any documentation, it can get out of date without anyone 
noticing.  If you do find that R fails to run on Windows 7, you should 
like R Core know.

Duncan Murdoch



On 21/08/2020 1:52 p.m., Firpo, Mike via R-help wrote:
> Hello,
> 
>    Reading the FAQ, I'm confused about whether R 4.0.2 is tested on Windows 7.  I found the following:
> 
>> 2.24 Does R run under Windows Vista/7/8/Server 2008?
>>
>> It does. ...
> 
>> 2.2 How do I install R for Windows?
>>
>> Current binary versions of R are known to run on Windows 7 or later, including on 64-bit versions: See Can I use R on 64-bit Windows?. Windows > XP is no longer supported.
>>
>> We only test on versions of Windows currently supported by Microsoft, mainly 64-bit Windows 7, Windows Server 2008 and Windows 10. ...
> 
>    There is no indication what date these questions and answers were posted.  If it's true that R is only tested on supported versions of Windows, that would exclude Vista and Windows 7.
> 
>    The download site doesn't mention operating system requirements.  Does 4.0.2 work on Windows 7?
> 
> Thank you,
> 
> Mike
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jr@| @end|ng |rom po@teo@no  Sat Aug 22 18:56:55 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 22 Aug 2020 18:56:55 +0200
Subject: [R] System Requirements
In-Reply-To: <CAJc=yOEs3_rxpK-o5W8dqpafa1PF3DN6ehRJSRofOuHr9Z0YoQ@mail.gmail.com>
References: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
 <CAJc=yOEs3_rxpK-o5W8dqpafa1PF3DN6ehRJSRofOuHr9Z0YoQ@mail.gmail.com>
Message-ID: <20200822165655.GB139810@posteo.no>

Dear Mike,

On 2020-08-22 11:50 -0400, Patrick (Malone Quantitative) wrote:
| On Sat, Aug 22, 2020 at 11:44 AM Firpo, Mike wrote:
| | 
| | Hello,
| |
| | Reading the FAQ, I'm confused about 
| | whether R 4.0.2 is tested on Windows 
| | 7.  I found the following:
| |
| | | 2.24 Does R run under Windows 
| | |   Vista/7/8/Server 2008?
| | |
| | | It does. ...
| | | 
| | | 2.2 How do I install R for Windows?
| | |
| | | Current binary versions of R are 
| | | known to run on Windows 7 or 
| | | later, including on 64-bit 
| | | versions: See Can I use R on 
| | | 64-bit Windows?. Windows XP is 
| | | no longer supported.
| | |
| | | We only test on versions of 
| | | Windows currently supported by 
| | | Microsoft, mainly 64-bit Windows 
| | | 7, Windows Server 2008 and Windows 
| | | 10. ...
| |
| | There is no indication what date 
| | these questions and answers were 
| | posted.  

You have to dig around like a dog in SVN 
or on github.  I found in 
doc/manual/Makefile.in that rw-FAQ.html 
comes from rw-FAQ.texi; the 3.6.0 
version is in qinwang's account[1], 
selecting blame for line 623 and 150 
shows[2][3] that this was written around 
ten years ago by ripley.

Maybe you can get a SVN viewer for 
Windows and pull trunk[4] to look 
around.

| | If it's true that R is only 
| | tested on supported versions of 
| | Windows, that would exclude Vista 
| | and Windows 7.
| |
| | The download site doesn't mention 
| | operating system requirements.  Does 
| | 4.0.2 work on Windows 7?
| 
| Try it and see?

This table[5] says Windows XP was the 
latest deprecated version.

Maybe look into running something like 
Linux Mint?

Best,
Rasmus

[1] https://github.com/qinwang/R/blob/master/doc/manual/rw-FAQ.texi#L623 
[2] https://github.com/qinwang/R/commit/5b8d4d50aa8ac7989dec5d3c571c89c1dd6d6466
[3] https://github.com/qinwang/R/commit/dc8e21174441426237c6af1dff697784eac8d7c1
[4] https://svn.r-project.org/R/trunk/
[5] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200822/6cc0811d/attachment.sig>

From djnord|und @end|ng |rom gm@||@com  Sat Aug 22 23:14:26 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Sat, 22 Aug 2020 14:14:26 -0700
Subject: [R] Export R outputs to SAS dataset
In-Reply-To: <20200822160508.GA139810@posteo.no>
References: <CADGufDFon0OTOyW+EK9AyROqmdVyJHcGcBRY=PNScftOxkc6bQ@mail.gmail.com>
 <20200822160508.GA139810@posteo.no>
Message-ID: <cc08de02-43cc-d17c-c422-6863b2b4f1bc@gmail.com>

On 8/22/2020 9:05 AM, Rasmus Liland wrote:
> On 2020-08-22 08:17 +0530, Jomy Jose wrote:
> | Hi
> | I was able to run R code via PROC IML
> | in SAS,so is there any way to export
> | the generated outputs to SAS datasets
> | since the R outputs don't follow data
> | frame structure.
>
> Dear Jomy,
>
> But perhaps you can take the outputs in
> SAS and work on them inside from there?
>
> To export a data frame from R to SAS via
> a file[1], you can use
>
> 	foreign::write.foreign(..., package="SAS")
>
> But I have not tried it.
>
> I have used foreign::read.spss before,
> hehe :-)
>
> I know R is also possible to call from
> Julia, and the df appearing in Julia,
> this sounds like it should be possible
> SAS too[2], yes?
>
> Best,
> Rasmus
>
> [1] https://www.statmethods.net/input/exportingdata.html
> [2] https://documentation.sas.com/?docsetId=imlug&docsetTarget=imlug_r_sect012.htm&docsetVersion=15.1&locale=en
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Can you give a reproducible example of the R-code you are running and 
the R "output" you want to get back in SAS?? It is difficult from way 
over here to know if you are wanting numerical results like means or 
regression coefficients ... or if you just want printed output in your 
SAS log or listing.

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From @purd|e@@ @end|ng |rom gm@||@com  Sun Aug 23 01:52:17 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 23 Aug 2020 11:52:17 +1200
Subject: [R] on the growth of standard error
In-Reply-To: <86mu2neogt.fsf-8018@protonmail.com>
References: <86mu2neogt.fsf-8018@protonmail.com>
Message-ID: <CAB8pepzvvpvwu15=6cOQSyAUKUEhapYsnHAt2AGPage6Zx9dKQ@mail.gmail.com>

> The absolute
> value of e grows as L grows, but by how much?  It seems statistical
> theory claims it grow by an order of the square root of L.

Assuming you want the standard deviation for the number of successes,
given p=0.5:

#exact
0.5 * sqrt (n)

#numerical approximation
sd (rbinom (1e6, n, 0.5) )

Note that variance should be linear in n.


From m@rc_grt @end|ng |rom y@hoo@|r  Sun Aug 23 11:19:45 2020
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Sun, 23 Aug 2020 11:19:45 +0200
Subject: [R] Error in optim with method L-BFGS-B when hessian is TRUE
References: <2bcc5167-7d0d-c5fc-a1d5-f8f75c47c3b3.ref@yahoo.fr>
Message-ID: <2bcc5167-7d0d-c5fc-a1d5-f8f75c47c3b3@yahoo.fr>

Dear members,

I fought for several days against an error I was getting with optim in 
L-BFGS-B. The error was produced because some parameters were outside 
the limits defined by upper and lower.
After investigation, the error is not produced during the optimization 
itself but during the calculation of the Hessian matrix which does not 
take into account the upper and lower bounds.
It would be nice if this was stated in the optim help within the 
L-BFGS-B method section.

Marc Girondot


From m@rc_grt @end|ng |rom y@hoo@|r  Sun Aug 23 11:27:38 2020
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Sun, 23 Aug 2020 11:27:38 +0200
Subject: [R] Error in optim with method L-BFGS-B when hessian is TRUE
In-Reply-To: <2bcc5167-7d0d-c5fc-a1d5-f8f75c47c3b3@yahoo.fr>
References: <2bcc5167-7d0d-c5fc-a1d5-f8f75c47c3b3.ref@yahoo.fr>
 <2bcc5167-7d0d-c5fc-a1d5-f8f75c47c3b3@yahoo.fr>
Message-ID: <25b79b4a-ebf2-145c-ea82-786196e81091@yahoo.fr>

Sorry... it is already stated in the help, at the hessian section:

hessian
Only if argument hessian is true. A symmetric matrix giving an estimate 
of the Hessian at the solution found. Note that this is the Hessian of 
the unconstrained problem even if the box constraints are active.

So no problem...

Marc

Le 23/08/2020 ?? 11:19, Marc Girondot via R-help a ??crit??:
> Dear members,
>
> I fought for several days against an error I was getting with optim in 
> L-BFGS-B. The error was produced because some parameters were outside 
> the limits defined by upper and lower.
> After investigation, the error is not produced during the optimization 
> itself but during the calculation of the Hessian matrix which does not 
> take into account the upper and lower bounds.
> It would be nice if this was stated in the optim help within the 
> L-BFGS-B method section.
>
> Marc Girondot
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |n|ojomy @end|ng |rom gm@||@com  Sun Aug 23 15:46:00 2020
From: |n|ojomy @end|ng |rom gm@||@com (Jomy Jose)
Date: Sun, 23 Aug 2020 19:16:00 +0530
Subject: [R] Export R outputs to SAS dataset
In-Reply-To: <cc08de02-43cc-d17c-c422-6863b2b4f1bc@gmail.com>
References: <CADGufDFon0OTOyW+EK9AyROqmdVyJHcGcBRY=PNScftOxkc6bQ@mail.gmail.com>
 <20200822160508.GA139810@posteo.no>
 <cc08de02-43cc-d17c-c422-6863b2b4f1bc@gmail.com>
Message-ID: <CADGufDE5+mjxro54B73X5i_OYXEH9QQT7eTN2pPe1=tUTbegAw@mail.gmail.com>

 Hi Daniel

Thanks,please find the code and output

 #--------R libraries---------
      library(tidyverse)
      library(MF)


MFSubj(lesion ~ group, calflung)
HLBoot(lesion ~ group,  calflung, compare = c("con", "vac"), b = 100,
          B = 100, alpha = 0.05, hpd = TRUE, bca = FALSE,
          return.boot = FALSE, trace.it = FALSE, seed = NULL)


10000 bootstrap samples
95% confidence intervals
Comparing vac to con


Mitigated Fraction

                observed median  lower  upper
Equal Tailed        0.44 0.4464 0.1360 0.7024
Highest Density     0.44 0.4464 0.1456 0.7088


Hodges-Lehmann

                observed   median     lower    upper
Equal Tailed    -0.07335 -0.07125 -0.170425 -0.01480
Highest Density -0.07335 -0.07125 -0.156350 -0.00975


Quartile Differences (quartiles of vac - quartiles of con)

     observed    median    lower     upper
Q25 -0.041500 -0.041300 -0.10340 -0.000905
Q50 -0.112525 -0.111175 -0.28115  0.019350
Q75 -0.168000 -0.170425 -0.38650  0.030000


Quartiles of con
    observed   median   lower   upper
Q25 0.054000 0.054000 0.01525 0.11275
Q50 0.139275 0.139275 0.06140 0.31000
Q75 0.315000 0.315000 0.17300 0.45250


Quartiles of vac
    observed  median   lower    upper
Q25  0.01250 0.01250 0.00125 0.026000
Q50  0.02675 0.02675 0.01665 0.144575
Q75  0.14700 0.14700 0.02810 0.292000


Best
Jose

On Sun, Aug 23, 2020 at 2:44 AM Daniel Nordlund <djnordlund at gmail.com>
wrote:

> On 8/22/2020 9:05 AM, Rasmus Liland wrote:
> > On 2020-08-22 08:17 +0530, Jomy Jose wrote:
> > | Hi
> > | I was able to run R code via PROC IML
> > | in SAS,so is there any way to export
> > | the generated outputs to SAS datasets
> > | since the R outputs don't follow data
> > | frame structure.
> >
> > Dear Jomy,
> >
> > But perhaps you can take the outputs in
> > SAS and work on them inside from there?
> >
> > To export a data frame from R to SAS via
> > a file[1], you can use
> >
> >       foreign::write.foreign(..., package="SAS")
> >
> > But I have not tried it.
> >
> > I have used foreign::read.spss before,
> > hehe :-)
> >
> > I know R is also possible to call from
> > Julia, and the df appearing in Julia,
> > this sounds like it should be possible
> > SAS too[2], yes?
> >
> > Best,
> > Rasmus
> >
> > [1] https://www.statmethods.net/input/exportingdata.html
> > [2]
> https://documentation.sas.com/?docsetId=imlug&docsetTarget=imlug_r_sect012.htm&docsetVersion=15.1&locale=en
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Can you give a reproducible example of the R-code you are running and
> the R "output" you want to get back in SAS?  It is difficult from way
> over here to know if you are wanting numerical results like means or
> regression coefficients ... or if you just want printed output in your
> SAS log or listing.
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>
>

	[[alternative HTML version deleted]]


From m|ke9 @end|ng |rom po@teo@n|  Sun Aug 23 16:59:53 2020
From: m|ke9 @end|ng |rom po@teo@n| (Mike)
Date: Sun, 23 Aug 2020 16:59:53 +0200
Subject: [R] plot.window: need finite 'ylim' values
In-Reply-To: <CA+8X3fUvsqtpQ9E8i-iGzbLr_K+oybRFT9dp3uMD-oRN=y4nPQ@mail.gmail.com>
References: <20200820175501.GC5734@local>
 <CA+8X3fUvsqtpQ9E8i-iGzbLr_K+oybRFT9dp3uMD-oRN=y4nPQ@mail.gmail.com>
Message-ID: <20200823145953.GE5734@local>

Hi Jim,

on 21.08. you wrote:

> Try this:
> 
> plot (chart_Series (sample.xts[,1], subset=subset, TA=ta),
>  type="n",ylim=c(minimum,maximum))
> 
> where minimum and maximum are the extremes of the plot if there were
> any valid values.

I've set
minimum <- 0
maximum <- 1

The error persists.

But besides that, passing 'type="n"' to plot would only make sense
when called once an I know there are only NAs to plot. Since I want to
generate many charts in a loop I would have to check for plotable data
first to decide if 'type="n"' should be passed.

As a workaround for now I do something similar. I check if the range
to be plotted is completely NA. If so I manipulate one of those
observations (which can only be 0, 1 or NA) to an "illegal" value of
0.5.

Mike


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Aug 23 19:19:33 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 23 Aug 2020 10:19:33 -0700
Subject: [R] plot.window: need finite 'ylim' values
In-Reply-To: <20200820175501.GC5734@local>
References: <20200820175501.GC5734@local>
Message-ID: <0EE2FD2C-DA6F-483C-8539-7848265DEF4A@comcast.net>

You are using a function whose help page says it is "highly experimental". In such cases it is probably better to contact the package maintainer with a feature request. The DESCRIPTION file says contact should be through one of 

http://www.quantmod.com 
https://github.com/joshuaulrich/quantmod



-- 
David.
> On Aug 20, 2020, at 10:55 AM, Mike <mike9 at posteo.nl> wrote:
> 
> Dear R users,
> 
> I have already asked this in r-sig-finance (not getting a solution)
> but it seems to be plot-related anyway.
> 
> I like to plot several financial charts to files with an identical
> layout according to "indicators" so the charts can be browsed
> quickly.
> 
> quantmod::chart_Series is a function to plot a financially-related
> chart in the upper part and zero or more indicators below. Normally
> these indicators would be assigned defined values at least in some
> part of the subset/window to be plotted, which is fine for plot. But
> if all observations are NA chart_Series throws
> 
> Error in plot.window(c(1, 31), c(NaN, NaN)) : need finite 'ylim' values
> 
> While this outcome for plot/plot.window may be intended for most
> applications it is undesirable here. Getting a blank subwindow here is
> intended if the indicator is completely NA (at least in the subset to
> be plotted).
> 
> This post
> https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/015000.html
> suggests to generate the plot object with chart_Series and then to
> explicitly set x$Env$ylim[[4]] before plotting - without success.
> 
> Can I tell plot/plot.window to ignore such errors and simply generate
> an empty region instead?
> 
> Thanks
> Mike
> 
> 
> My minimal reproducible:
> 
> library(quantmod)
> 
> my_plot_function <- function () {
>  data (sample_matrix)
>  sample.xts <- as.xts (sample_matrix[1:50,'Close'], dateFormat="POSIXct")
>  sample.xts <- cbind (sample.xts, NA)
>  sample.xts[50,2] <- 0
>  colnames (sample.xts) <- c('Close', 'Indicator')
> 
>  # Indicator
>  ta <- list ("add_TA(sample.xts[,2])")
> 
>  # In the range to be plotted ta is completely NA 
>  subset <- '2007-01-10::2007-01-30'
> 
>  plot (chart_Series (sample.xts[,1], subset=subset, TA=ta))
> }
> 
> my_plot_function ()
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sun Aug 23 23:40:42 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 24 Aug 2020 07:40:42 +1000
Subject: [R] plot.window: need finite 'ylim' values
In-Reply-To: <20200823145953.GE5734@local>
References: <20200820175501.GC5734@local>
 <CA+8X3fUvsqtpQ9E8i-iGzbLr_K+oybRFT9dp3uMD-oRN=y4nPQ@mail.gmail.com>
 <20200823145953.GE5734@local>
Message-ID: <CA+8X3fVQfiXH8TN=2nmagvmopBgWqkKOW_w=tQkNPaXXCf=38w@mail.gmail.com>

Hi Mike,
This looks to me as though the error is not being generated by plot,
but by a method specific to the package, maybe something with a name
like plot.chart_Series, that is barfing on a vector of NA values.

Jim

On Mon, Aug 24, 2020 at 1:01 AM Mike <mike9 at posteo.nl> wrote:
>
> Hi Jim,
>
> on 21.08. you wrote:
>
> > Try this:
> >
> > plot (chart_Series (sample.xts[,1], subset=subset, TA=ta),
> >  type="n",ylim=c(minimum,maximum))
> >
> > where minimum and maximum are the extremes of the plot if there were
> > any valid values.
>
> I've set
> minimum <- 0
> maximum <- 1
>
> The error persists.
>
> But besides that, passing 'type="n"' to plot would only make sense
> when called once an I know there are only NAs to plot. Since I want to
> generate many charts in a loop I would have to check for plotable data
> first to decide if 'type="n"' should be passed.
>
> As a workaround for now I do something similar. I check if the range
> to be plotted is completely NA. If so I manipulate one of those
> observations (which can only be 0, 1 or NA) to an "illegal" value of
> 0.5.
>
> Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @pr||ett|ngton @end|ng |rom gm@||@com  Mon Aug 24 05:12:06 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Mon, 24 Aug 2020 15:12:06 +1200
Subject: [R] ggplot 3-color gradient scales
Message-ID: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>

Currently I am using these settings in ggplot to make a gradient from red
to blue.

geom_point( aes(x, y, color=z) ) +
scale_colour_gradient(low = "red",high = "blue") +

z is a ratio, and currently I am able to identify which have high and low
values, but I'd really like to be able to distinguish which are >1, <1, or
close to 1 by color.  It would be great if I could set a middle color in
this gradient (eg. green) that is set the the value of 1, even if that is
not the exact midpoint between my highest and lowest values.  Is there a
way to do this in R?

Thank you,
April

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 24 05:43:22 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 23 Aug 2020 20:43:22 -0700
Subject: [R] ggplot 3-color gradient scales
In-Reply-To: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>
References: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>
Message-ID: <D26692DF-3203-4BDB-88ED-8E444417AA3B@dcn.davis.ca.us>

Check out scale_colour_gradient2()

On August 23, 2020 8:12:06 PM PDT, April Ettington <aprilettington at gmail.com> wrote:
>Currently I am using these settings in ggplot to make a gradient from
>red
>to blue.
>
>geom_point( aes(x, y, color=z) ) +
>scale_colour_gradient(low = "red",high = "blue") +
>
>z is a ratio, and currently I am able to identify which have high and
>low
>values, but I'd really like to be able to distinguish which are >1, <1,
>or
>close to 1 by color.  It would be great if I could set a middle color
>in
>this gradient (eg. green) that is set the the value of 1, even if that
>is
>not the exact midpoint between my highest and lowest values.  Is there
>a
>way to do this in R?
>
>Thank you,
>April
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug 24 07:33:44 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 24 Aug 2020 06:33:44 +0100
Subject: [R] ggplot 3-color gradient scales
In-Reply-To: <D26692DF-3203-4BDB-88ED-8E444417AA3B@dcn.davis.ca.us>
References: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>
 <D26692DF-3203-4BDB-88ED-8E444417AA3B@dcn.davis.ca.us>
Message-ID: <60c66c30-7655-af43-fe34-b2a30f590a83@sapo.pt>

Hello,

Note that the midpoint argument can make a big difference. In the code 
below try commenting out the line where the default is changed.


f <- function(x){
   (x - min(x))/(max(x) - min(x))
}

library(ggplot2)

df1 <- iris[3:5]
names(df1)[1:2] <- c("x", "y")
df1$z <- ave(df1$y, df1$Species, FUN = f)

ggplot(df1) +
   geom_point( aes(x, y, color = z) ) +
   scale_color_gradient2(low = "red",
                         mid = "yellow",
                         high = "blue",
                         midpoint = 0.5
                         )

Hope this helps,

Rui Barradas


?s 04:43 de 24/08/20, Jeff Newmiller escreveu:
> Check out scale_colour_gradient2()
> 
> On August 23, 2020 8:12:06 PM PDT, April Ettington <aprilettington at gmail.com> wrote:
>> Currently I am using these settings in ggplot to make a gradient from
>> red
>> to blue.
>>
>> geom_point( aes(x, y, color=z) ) +
>> scale_colour_gradient(low = "red",high = "blue") +
>>
>> z is a ratio, and currently I am able to identify which have high and
>> low
>> values, but I'd really like to be able to distinguish which are >1, <1,
>> or
>> close to 1 by color.  It would be great if I could set a middle color
>> in
>> this gradient (eg. green) that is set the the value of 1, even if that
>> is
>> not the exact midpoint between my highest and lowest values.  Is there
>> a
>> way to do this in R?
>>
>> Thank you,
>> April
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From @pr||ett|ngton @end|ng |rom gm@||@com  Mon Aug 24 08:28:49 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Mon, 24 Aug 2020 18:28:49 +1200
Subject: [R] ggplot 3-color gradient scales
In-Reply-To: <60c66c30-7655-af43-fe34-b2a30f590a83@sapo.pt>
References: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>
 <D26692DF-3203-4BDB-88ED-8E444417AA3B@dcn.davis.ca.us>
 <60c66c30-7655-af43-fe34-b2a30f590a83@sapo.pt>
Message-ID: <CAE9tUWeWyMvwJxBXrWtwAeY8NN+uQRK8kPReGMSWfBZ9B2VTtA@mail.gmail.com>

Thank you so much!


On Mon, Aug 24, 2020 at 5:33 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Note that the midpoint argument can make a big difference. In the code
> below try commenting out the line where the default is changed.
>
>
> f <- function(x){
>    (x - min(x))/(max(x) - min(x))
> }
>
> library(ggplot2)
>
> df1 <- iris[3:5]
> names(df1)[1:2] <- c("x", "y")
> df1$z <- ave(df1$y, df1$Species, FUN = f)
>
> ggplot(df1) +
>    geom_point( aes(x, y, color = z) ) +
>    scale_color_gradient2(low = "red",
>                          mid = "yellow",
>                          high = "blue",
>                          midpoint = 0.5
>                          )
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 04:43 de 24/08/20, Jeff Newmiller escreveu:
> > Check out scale_colour_gradient2()
> >
> > On August 23, 2020 8:12:06 PM PDT, April Ettington <
> aprilettington at gmail.com> wrote:
> >> Currently I am using these settings in ggplot to make a gradient from
> >> red
> >> to blue.
> >>
> >> geom_point( aes(x, y, color=z) ) +
> >> scale_colour_gradient(low = "red",high = "blue") +
> >>
> >> z is a ratio, and currently I am able to identify which have high and
> >> low
> >> values, but I'd really like to be able to distinguish which are >1, <1,
> >> or
> >> close to 1 by color.  It would be great if I could set a middle color
> >> in
> >> this gradient (eg. green) that is set the the value of 1, even if that
> >> is
> >> not the exact midpoint between my highest and lowest values.  Is there
> >> a
> >> way to do this in R?
> >>
> >> Thank you,
> >> April
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From |uy@g@rc|@ @end|ng |rom gm@||@com  Mon Aug 24 01:04:20 2020
From: |uy@g@rc|@ @end|ng |rom gm@||@com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Sun, 23 Aug 2020 20:04:20 -0300
Subject: [R] Help on plot from transition matrix
Message-ID: <CANxP2S7FS0cHy0fm6Z3O0WOtUptZ3W7+sU35RYmXpN=-3DsSzw@mail.gmail.com>

I am wanting to make a flow diagram like the one attached as an example for
the given dataset.

The idea is to plot a flow diagramm using the probabilities given by a
transition matrix like the displayed in the example below. I have found
some tools like DiagrammeR which might work for this purpose, but it works
by introducing values manually. I wanted to know if there exists any
package able to plot automatically the flow diagram, given the transition
probabilities.

Thanks in advance.

#######

library(TraMineR)

h2a=c("Q-X-Q-Y-W-Z-P")

h3a=c("Q-X-Q-Y-W-Z-P-Q-M-P-Q-A")

h4a=c("Q-X-Q-X-Q-X-Q-Y-W-Z-C-B-Q-M-B-Q-A")

h6a=c("Q-X-Q-X-Q-Y-W-Z-P-Q-P-Q-M-Q-A")

h7a=c("Q-Y-W-Z-P-Q-B-Q-M-A")

h8a=c("Q-Y-W-Z-P-B-Q-M-Q-A")

h9a=c("Q-X-Q-W-Z-B-Q-A")

h10a=c("Q-Y-W-Z-Q-A")

h11a=c("Q-Y-W-Z-B-Q-P-B-Q-M-A")

h12a=c("Q-W-Z-B-P-Q-A")

h13a=c("Q-X-Q-Y-W-Z-P-Q-A")

h14a=c("Q-X-B-X-Q-X-B-Q-X-Q-X-Q-Y-W-Z-B-P-B-Q-A")

h15a=c("Q-X-Y-W-Z-B-P-Q-B-Q-A")

h16a=c("Q-X-Q-B-Q-X-B-X-Q-Y-W-Z-P-B-Q-A")

h17a=c("Q-X-Q-X-B-X-Q-W-Z-P-B-P-Q-A")

h18a=c("Q-Y-W-Z-B-P-Q-B-Q-P-Q-M-B-P-A")

h19a=c("Q-W-Z-B-P-Q-P-Q-M-Q-A")

a=c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a)

a

library(TraMineR)

i1=seqdef(c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a))

seqtrate(i1)

From drj|m|emon @end|ng |rom gm@||@com  Mon Aug 24 10:47:00 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 24 Aug 2020 18:47:00 +1000
Subject: [R] Help on plot from transition matrix
In-Reply-To: <CANxP2S7FS0cHy0fm6Z3O0WOtUptZ3W7+sU35RYmXpN=-3DsSzw@mail.gmail.com>
References: <CANxP2S7FS0cHy0fm6Z3O0WOtUptZ3W7+sU35RYmXpN=-3DsSzw@mail.gmail.com>
Message-ID: <CA+8X3fUsN6EkeK_ZDkeHVh2qwkD+T50B58Jmo=WQyAA_kB=3Rw@mail.gmail.com>

Hi Luis,
As so often happens, the image didn't make it. Try PNG or PDF format.
Without seeing what you want, it's only guessing.

Jim

On Mon, Aug 24, 2020 at 6:34 PM Luis Fernando Garc?a
<luysgarcia at gmail.com> wrote:
>
> I am wanting to make a flow diagram like the one attached as an example for
> the given dataset.
>
> The idea is to plot a flow diagramm using the probabilities given by a
> transition matrix like the displayed in the example below. I have found
> some tools like DiagrammeR which might work for this purpose, but it works
> by introducing values manually. I wanted to know if there exists any
> package able to plot automatically the flow diagram, given the transition
> probabilities.
>
> Thanks in advance.
>
> #######
>
> library(TraMineR)
>
> h2a=c("Q-X-Q-Y-W-Z-P")
>
> h3a=c("Q-X-Q-Y-W-Z-P-Q-M-P-Q-A")
>
> h4a=c("Q-X-Q-X-Q-X-Q-Y-W-Z-C-B-Q-M-B-Q-A")
>
> h6a=c("Q-X-Q-X-Q-Y-W-Z-P-Q-P-Q-M-Q-A")
>
> h7a=c("Q-Y-W-Z-P-Q-B-Q-M-A")
>
> h8a=c("Q-Y-W-Z-P-B-Q-M-Q-A")
>
> h9a=c("Q-X-Q-W-Z-B-Q-A")
>
> h10a=c("Q-Y-W-Z-Q-A")
>
> h11a=c("Q-Y-W-Z-B-Q-P-B-Q-M-A")
>
> h12a=c("Q-W-Z-B-P-Q-A")
>
> h13a=c("Q-X-Q-Y-W-Z-P-Q-A")
>
> h14a=c("Q-X-B-X-Q-X-B-Q-X-Q-X-Q-Y-W-Z-B-P-B-Q-A")
>
> h15a=c("Q-X-Y-W-Z-B-P-Q-B-Q-A")
>
> h16a=c("Q-X-Q-B-Q-X-B-X-Q-Y-W-Z-P-B-Q-A")
>
> h17a=c("Q-X-Q-X-B-X-Q-W-Z-P-B-P-Q-A")
>
> h18a=c("Q-Y-W-Z-B-P-Q-B-Q-P-Q-M-B-P-A")
>
> h19a=c("Q-W-Z-B-P-Q-P-Q-M-Q-A")
>
> a=c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a)
>
> a
>
> library(TraMineR)
>
> i1=seqdef(c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a))
>
> seqtrate(i1)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From herd_dog @end|ng |rom cox@net  Mon Aug 24 17:19:36 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Mon, 24 Aug 2020 08:19:36 -0700
Subject: [R] rNOMADS package
Message-ID: <6FAF005B791B4ED090E75F1B9513C106@OWNERPC>

I am struggling to install a fix for the rNOMADS package which reads National Weather Service data.  I copied the fix (rNOMADS_2.5.0.tar.gz) from an email to a local drive and then tried to install it with the command below.  I also tried installing it without the .tar.gz extension and without the _2.5.0 extension but I get the same error message.  The author, Daniel Bowman, emailed me that the fix should work for R version 4.0 or better.

Do I need to untar it?

install.packages("C://Documents/Ballooning/WeatherBriefing/rNOMADS_2.5.0.tar.gz")

Installing package into ?C:/Users/Owner/Documents/R/win-library/4.0?
(as ?lib? is unspecified)
Warning in install.packages :
  package ?C://Documents/Ballooning/WeatherBriefing/rNOMADS_2.5.0.tar.gz? is not available (for R version 4.0.2)
	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Mon Aug 24 17:26:50 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Mon, 24 Aug 2020 11:26:50 -0400
Subject: [R] [External]  rNOMADS package
In-Reply-To: <6FAF005B791B4ED090E75F1B9513C106@OWNERPC>
References: <6FAF005B791B4ED090E75F1B9513C106@OWNERPC>
Message-ID: <CAGx1TMAjWSH2N_utBg4bxG6i3+zN8OY2h8gjvBUUXoKWq8mLWA@mail.gmail.com>

incorrect double slash c://
use single slash c:/

On Mon, Aug 24, 2020 at 11:21 Philip <herd_dog at cox.net> wrote:

> I am struggling to install a fix for the rNOMADS package which reads
> National Weather Service data.  I copied the fix (rNOMADS_2.5.0.tar.gz)
> from an email to a local drive and then tried to install it with the
> command below.  I also tried installing it without the .tar.gz extension
> and without the _2.5.0 extension but I get the same error message.  The
> author, Daniel Bowman, emailed me that the fix should work for R version
> 4.0 or better.
>
>
>
> Do I need to untar it?
>
>
>
>
> install.packages("C://Documents/Ballooning/WeatherBriefing/rNOMADS_2.5.0.tar.gz")
>
>
>
> Installing package into ?C:/Users/Owner/Documents/R/win-library/4.0?
>
> (as ?lib? is unspecified)
>
> Warning in install.packages :
>
>   package ?C://Documents/Ballooning/WeatherBriefing/rNOMADS_2.5.0.tar.gz?
> is not available (for R version 4.0.2)
>
>         [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Mon Aug 24 17:37:54 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 24 Aug 2020 08:37:54 -0700
Subject: [R] [External] rNOMADS package
In-Reply-To: <CAGx1TMAjWSH2N_utBg4bxG6i3+zN8OY2h8gjvBUUXoKWq8mLWA@mail.gmail.com>
References: <6FAF005B791B4ED090E75F1B9513C106@OWNERPC>
 <CAGx1TMAjWSH2N_utBg4bxG6i3+zN8OY2h8gjvBUUXoKWq8mLWA@mail.gmail.com>
Message-ID: <CAF8bMcZH_6guDWngMmJSv8VHs_qFrfeACYGSEbzS0vjuWux9qQ@mail.gmail.com>

Add the arguments type="source" and repos=NULL to your call to
install.packages().  repos=NULL means that this is a local file, not
something to download from a repository.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 24, 2020 at 8:31 AM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> incorrect double slash c://
> use single slash c:/
>
> On Mon, Aug 24, 2020 at 11:21 Philip <herd_dog at cox.net> wrote:
>
> > I am struggling to install a fix for the rNOMADS package which reads
> > National Weather Service data.  I copied the fix (rNOMADS_2.5.0.tar.gz)
> > from an email to a local drive and then tried to install it with the
> > command below.  I also tried installing it without the .tar.gz extension
> > and without the _2.5.0 extension but I get the same error message.  The
> > author, Daniel Bowman, emailed me that the fix should work for R version
> > 4.0 or better.
> >
> >
> >
> > Do I need to untar it?
> >
> >
> >
> >
> > install.packages("C://Documents/Ballooning/WeatherBriefing/rNOMADS_2.5.0.tar.gz")
> >
> >
> >
> > Installing package into ?C:/Users/Owner/Documents/R/win-library/4.0?
> >
> > (as ?lib? is unspecified)
> >
> > Warning in install.packages :
> >
> >   package ?C://Documents/Ballooning/WeatherBriefing/rNOMADS_2.5.0.tar.gz?
> > is not available (for R version 4.0.2)
> >
> >         [[alternative HTML version deleted]]
> >
> >
> >
> > ______________________________________________
> >
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> > https://stat.ethz.ch/mailman/listinfo/r-help
> >
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From junxu@r @end|ng |rom gm@||@com  Mon Aug 24 17:58:28 2020
From: junxu@r @end|ng |rom gm@||@com (Xu Jun)
Date: Mon, 24 Aug 2020 11:58:28 -0400
Subject: [R] Classification Tree Prediction Error
Message-ID: <CADe_g+Uicy+QuBBd984BBhf_LuSMHuDH7A-KxxFQQ_rXkjRRWg@mail.gmail.com>

Dear all R experts,

I have a question about using cross-validation to assess results estimated
from a classification tree model. I annotated what each line does in the R
code chunk below. Basically, I split the data, named usedta, into 70% vs.
30%, with the training set having 70% and the test set 30% of the original
cases. After splitting the data, I first run a classification tree off the
training set, and then use the results for cross-validation using the test
set. It turns out that if I don't have any predictors and make predictions
by simply betting on the majority class of the zero-one coding of the
binary response variable, I can do better than what the results from the
classification tree would deliver in the test set. What would this imply
and what would cause this problem? Does it mean that classification tree is
not an appropriate method for my data; or, it's because I have too few
variables? Thanks a lot!

Jun Xu, PhD
Professor
Department of Sociology
Ball State University
Muncie, IN 47306
USA

Using the estimates, I get the following prediction rate (correct
prediction) using the test set. Or we can say the misclassification error
rate is 1-0.837 = 0.163

> (tab[1,1] + tab[2,2]) / sum(tab)[1] 0.837


Without any predictors, I can get the following rate by betting on the
majority class every time, again using data from the test set. In this
case, the misclassification error rate is 1-0.85 = 0.15

> table(h2.test)h2.test
1poorHlth 0goodHlth
      101       575 > 571/(571+101)[1] 0.85



R Code Chunk

# set the seed for random number generator for replication
set.seed(47306)
# have the 7/3 split with 70% of the cases allotted to the training set
# AND create the training set identifier
class.train = sample(1:nrow(usedta), nrow(usedta)*0.7)
# create the test set indicator
class.test = (-class.train)
# create a vector for the binary response variable from the test set
# for future cross-tabulation.
h2.test <- usedta$h2[class.test]
# count the train set cases
Ntrain = length(usedta$h2[class.train])
# run the classification tree model using the training set
# h2 is the binary response and other variables are predictors
tree.h2 <- tree(h2 ~ age + educ + female + white + married + happy,
                data = usedta, subset = class.train,
                control = tree.control(nobs=Ntrain, mindev=0.003))
# summary results
summary(tree.h2)
# make predictions of h2 using the test set
tree.h2.pred <- predict(tree.h2, usedta[class.test,], type="class")
# cross tab the predictions using the test set
table(tree.h2.pred, h2.test)
tab = table(tree.h2.pred, h2.test)
# calculate the ratio for the correctly predicted in the test set
(tab[1,1] + tab[2,2]) / sum(tab)
# calculate the ratio for the correctly predicted using the naive approach
# by betting on the majority category.
table(h2.test)[2]/sum(tab)

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 24 19:01:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 24 Aug 2020 10:01:10 -0700
Subject: [R] Classification Tree Prediction Error
In-Reply-To: <CADe_g+Uicy+QuBBd984BBhf_LuSMHuDH7A-KxxFQQ_rXkjRRWg@mail.gmail.com>
References: <CADe_g+Uicy+QuBBd984BBhf_LuSMHuDH7A-KxxFQQ_rXkjRRWg@mail.gmail.com>
Message-ID: <CAGxFJbRE9eHydcvvdyk8fhPF2ORo-5ihXVFhRWs-bPeic9f+Gg@mail.gmail.com>

Purely statistical questions -- as opposed to R programming queries -- are
generally off topic here.
Here is where they are on topic:  https://stats.stackexchange.com/

Suggestion: when you post, do include the package name where you get tree()
from, as there might be
more than one with this function.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 24, 2020 at 8:58 AM Xu Jun <junxu.r at gmail.com> wrote:

> Dear all R experts,
>
> I have a question about using cross-validation to assess results estimated
> from a classification tree model. I annotated what each line does in the R
> code chunk below. Basically, I split the data, named usedta, into 70% vs.
> 30%, with the training set having 70% and the test set 30% of the original
> cases. After splitting the data, I first run a classification tree off the
> training set, and then use the results for cross-validation using the test
> set. It turns out that if I don't have any predictors and make predictions
> by simply betting on the majority class of the zero-one coding of the
> binary response variable, I can do better than what the results from the
> classification tree would deliver in the test set. What would this imply
> and what would cause this problem? Does it mean that classification tree is
> not an appropriate method for my data; or, it's because I have too few
> variables? Thanks a lot!
>
> Jun Xu, PhD
> Professor
> Department of Sociology
> Ball State University
> Muncie, IN 47306
> USA
>
> Using the estimates, I get the following prediction rate (correct
> prediction) using the test set. Or we can say the misclassification error
> rate is 1-0.837 = 0.163
>
> > (tab[1,1] + tab[2,2]) / sum(tab)[1] 0.837
>
>
> Without any predictors, I can get the following rate by betting on the
> majority class every time, again using data from the test set. In this
> case, the misclassification error rate is 1-0.85 = 0.15
>
> > table(h2.test)h2.test
> 1poorHlth 0goodHlth
>       101       575 > 571/(571+101)[1] 0.85
>
>
>
> R Code Chunk
>
> # set the seed for random number generator for replication
> set.seed(47306)
> # have the 7/3 split with 70% of the cases allotted to the training set
> # AND create the training set identifier
> class.train = sample(1:nrow(usedta), nrow(usedta)*0.7)
> # create the test set indicator
> class.test = (-class.train)
> # create a vector for the binary response variable from the test set
> # for future cross-tabulation.
> h2.test <- usedta$h2[class.test]
> # count the train set cases
> Ntrain = length(usedta$h2[class.train])
> # run the classification tree model using the training set
> # h2 is the binary response and other variables are predictors
> tree.h2 <- tree(h2 ~ age + educ + female + white + married + happy,
>                 data = usedta, subset = class.train,
>                 control = tree.control(nobs=Ntrain, mindev=0.003))
> # summary results
> summary(tree.h2)
> # make predictions of h2 using the test set
> tree.h2.pred <- predict(tree.h2, usedta[class.test,], type="class")
> # cross tab the predictions using the test set
> table(tree.h2.pred, h2.test)
> tab = table(tree.h2.pred, h2.test)
> # calculate the ratio for the correctly predicted in the test set
> (tab[1,1] + tab[2,2]) / sum(tab)
> # calculate the ratio for the correctly predicted using the naive approach
> # by betting on the majority category.
> table(h2.test)[2]/sum(tab)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From djnord|und @end|ng |rom gm@||@com  Tue Aug 25 00:56:47 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Mon, 24 Aug 2020 15:56:47 -0700
Subject: [R] Export R outputs to SAS dataset
In-Reply-To: <CADGufDE5+mjxro54B73X5i_OYXEH9QQT7eTN2pPe1=tUTbegAw@mail.gmail.com>
References: <CADGufDFon0OTOyW+EK9AyROqmdVyJHcGcBRY=PNScftOxkc6bQ@mail.gmail.com>
 <20200822160508.GA139810@posteo.no>
 <cc08de02-43cc-d17c-c422-6863b2b4f1bc@gmail.com>
 <CADGufDE5+mjxro54B73X5i_OYXEH9QQT7eTN2pPe1=tUTbegAw@mail.gmail.com>
Message-ID: <b53ba279-a994-d456-e001-5ec9f78ba03d@gmail.com>

It is still not clear to me (1) if you just want the printed output in 
your SAS list file, or (2) if you want the actual numerical results 
returned to SAS so that you can do more manipulation with the numbers.

If (1) you can precede your R code with sink() to output to your SAS 
list file

 ?#--------R libraries---------
sink('path/to/your/listfile.lst', append=TRUE)
 ?library(tidyverse)
 ?library(MF)

MFSubj(lesion ~ group, calflung)
HLBoot(lesion ~ group, ?calflung, compare = c("con", "vac"), b = 100,
 ? ? ? ? ? B = 100, alpha = 0.05, hpd = TRUE, bca = FALSE,
 ? ? ? ? ? return.boot = FALSE, trace.it <http://trace.it> = FALSE, seed 
= NULL)

You will probably need to redirect your SAS list file to the same location
 ?? PROC PRINTTO file='path/to/your/listfile.lst' new;


If (2), then you need to store the output from you function into 
variables that you can examine to see what you may want to import into 
SAS.? So, something like this in R

mfsubj <- MFSubj(lesion ~ group, calflung)
hlboot <- HLBoot(lesion ~ group,? calflung, compare = c("con", "vac"), b 
= 100,
 ????????? B = 100, alpha = 0.05, hpd = TRUE, bca = FALSE,
 ????????? return.boot = FALSE, trace.it = FALSE, seed = NULL)
str(mfsubj)
str(hlboot)

After examining the output, you will know what variables/dataframes you 
want to import and you can use the functions provided by PROC IML for 
that purpose.? You will need to read the SAS documentation to understand 
how to do that.

This is becoming off topic for R-Help, so let me end with suggesting you 
pursue this question either on SAScommunity or the SAS-L listserve.? You 
might also want to look into SAS Viya for running your R code. If you 
want to continue this off-list, I can try to help you more, but I will 
need to better understand what it is that you want to get back into SAS.

Dan


On 8/23/2020 6:46 AM, Jomy Jose wrote:
> ?Hi Daniel
>
> Thanks,please find the code and output
>
> ?#--------R libraries---------
> ? ? ? library(tidyverse)
> ? ? ? library(MF)
>
>
> MFSubj(lesion ~ group, calflung)
> HLBoot(lesion ~ group, ?calflung, compare = c("con", "vac"), b = 100,
> ? ? ? ? ? B = 100, alpha = 0.05, hpd = TRUE, bca = FALSE,
> ? ? ? ? ? return.boot = FALSE, trace.it <http://trace.it> = FALSE, 
> seed = NULL)
>
>
> 10000 bootstrap samples
> 95% confidence intervals
> Comparing vac to con
>
>
> Mitigated Fraction
>
> ? ? ? ? ? ? ? ? observed median ?lower ?upper
> Equal Tailed ? ? ? ?0.44 0.4464 0.1360 0.7024
> Highest Density ? ? 0.44 0.4464 0.1456 0.7088
>
>
> Hodges-Lehmann
>
> ? ? ? ? ? ? ? ? observed ? median ? ? lower ? ?upper
> Equal Tailed ? ?-0.07335 -0.07125 -0.170425 -0.01480
> Highest Density -0.07335 -0.07125 -0.156350 -0.00975
>
>
> Quartile Differences (quartiles of vac - quartiles of con)
>
> ? ? ?observed ? ?median ? ?lower ? ? upper
> Q25 -0.041500 -0.041300 -0.10340 -0.000905
> Q50 -0.112525 -0.111175 -0.28115 ?0.019350
> Q75 -0.168000 -0.170425 -0.38650 ?0.030000
>
>
> Quartiles of con
> ? ? observed ? median ? lower ? upper
> Q25 0.054000 0.054000 0.01525 0.11275
> Q50 0.139275 0.139275 0.06140 0.31000
> Q75 0.315000 0.315000 0.17300 0.45250
>
>
> Quartiles of vac
> ? ? observed ?median ? lower ? ?upper
> Q25 ?0.01250 0.01250 0.00125 0.026000
> Q50 ?0.02675 0.02675 0.01665 0.144575
> Q75 ?0.14700 0.14700 0.02810 0.292000
>
>
> Best
> Jose
>
> On Sun, Aug 23, 2020 at 2:44 AM Daniel Nordlund <djnordlund at gmail.com 
> <mailto:djnordlund at gmail.com>> wrote:
>
>     On 8/22/2020 9:05 AM, Rasmus Liland wrote:
>     > On 2020-08-22 08:17 +0530, Jomy Jose wrote:
>     > | Hi
>     > | I was able to run R code via PROC IML
>     > | in SAS,so is there any way to export
>     > | the generated outputs to SAS datasets
>     > | since the R outputs don't follow data
>     > | frame structure.
>     >
>     > Dear Jomy,
>     >
>     > But perhaps you can take the outputs in
>     > SAS and work on them inside from there?
>     >
>     > To export a data frame from R to SAS via
>     > a file[1], you can use
>     >
>     >? ? ? ?foreign::write.foreign(..., package="SAS")
>     >
>     > But I have not tried it.
>     >
>     > I have used foreign::read.spss before,
>     > hehe :-)
>     >
>     > I know R is also possible to call from
>     > Julia, and the df appearing in Julia,
>     > this sounds like it should be possible
>     > SAS too[2], yes?
>     >
>     > Best,
>     > Rasmus
>     >
>     > [1] https://www.statmethods.net/input/exportingdata.html
>     <https://www.statmethods.net/input/exportingdata.html>
>     > [2]
>     https://documentation.sas.com/?docsetId=imlug&docsetTarget=imlug_r_sect012.htm&docsetVersion=15.1&locale=en
>     <https://documentation.sas.com/?docsetId=imlug&docsetTarget=imlug_r_sect012.htm&docsetVersion=15.1&locale=en>
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     Can you give a reproducible example of the R-code you are running and
>     the R "output" you want to get back in SAS?? It is difficult from way
>     over here to know if you are wanting numerical results like means or
>     regression coefficients ... or if you just want printed output in
>     your
>     SAS log or listing.
>
>     Dan
>
>     -- 
>     Daniel Nordlund
>     Port Townsend, WA? USA
>

-- 
Daniel Nordlund
Port Townsend, WA  USA


From @ndrew@h@||ord @end|ng |rom gm@||@com  Tue Aug 25 07:05:13 2020
From: @ndrew@h@||ord @end|ng |rom gm@||@com (Andrew Halford)
Date: Tue, 25 Aug 2020 16:05:13 +1100
Subject: [R] incompatible dimensions error
Message-ID: <CAJrFtqKi5Z=N-81hpkr0m9PV-EF7dtxAp2DLVEOhpBdzAqT5tA@mail.gmail.com>

Hi Listers

Using mvpart to run a MV regression tree with PCA= TRUE to get a PCA
plotted with sites coloured according to the tree output.

Unfortunately it wont produce the PCA, instead giving the error message..

Error in cor(xall, xx[order(tree$where), ]) : incompatible dimensions.

However, when I run a PCA on the data using the rda command I have no
problems producing a PCA.

data is attached as a text file

my code is thus...
fish05.hel <- decostand(fish05,"hellinger")
fish05.mrt <-
mvpart(data.matrix(fish05.hel)~.,env,margin=0.08,cp=0,rsq=TRUE,xv="pick",xval=nrow(fish05),xvmult=100,which=4,pca=TRUE)

The tree is produced no problem but it wont produce a PCA.

I am just keen to understand what this error means as I dont see anything
unusual about the dataset used, notwithstanding the data is rather messy.

Andy





-- 
Andrew Halford Ph.D
Senior Coastal Fisheries Scientist
Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
New Caledonia | Noum?a, Nouvelle-Cal?donie

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: fish05.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200825/5a37d362/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: env.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200825/5a37d362/attachment-0001.txt>

From @zwj|08 @end|ng |rom gm@||@com  Tue Aug 25 10:36:09 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jeff King)
Date: Tue, 25 Aug 2020 16:36:09 +0800
Subject: [R] incompatible dimensions error
In-Reply-To: <CAJrFtqKi5Z=N-81hpkr0m9PV-EF7dtxAp2DLVEOhpBdzAqT5tA@mail.gmail.com>
References: <CAJrFtqKi5Z=N-81hpkr0m9PV-EF7dtxAp2DLVEOhpBdzAqT5tA@mail.gmail.com>
Message-ID: <CAGiFhPPF4+-26Mc3-Zv=fYPstgJcMXiPb_R7R8C3in57bYx80w@mail.gmail.com>

Hi,

It seems like the package "mvpart" is quite outdated and not available for
the current R release. Since PCA is a very common need I'll suggest finding
a replacement for it so that the error will either go away, or it is easier
for us to reproduce it.

Best,
Jiefei

On Tue, Aug 25, 2020 at 1:06 PM Andrew Halford <andrew.halford at gmail.com>
wrote:

> Hi Listers
>
> Using mvpart to run a MV regression tree with PCA= TRUE to get a PCA
> plotted with sites coloured according to the tree output.
>
> Unfortunately it wont produce the PCA, instead giving the error message..
>
> Error in cor(xall, xx[order(tree$where), ]) : incompatible dimensions.
>
> However, when I run a PCA on the data using the rda command I have no
> problems producing a PCA.
>
> data is attached as a text file
>
> my code is thus...
> fish05.hel <- decostand(fish05,"hellinger")
> fish05.mrt <-
>
> mvpart(data.matrix(fish05.hel)~.,env,margin=0.08,cp=0,rsq=TRUE,xv="pick",xval=nrow(fish05),xvmult=100,which=4,pca=TRUE)
>
> The tree is produced no problem but it wont produce a PCA.
>
> I am just keen to understand what this error means as I dont see anything
> unusual about the dataset used, notwithstanding the data is rather messy.
>
> Andy
>
>
>
>
>
> --
> Andrew Halford Ph.D
> Senior Coastal Fisheries Scientist
> Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
> New Caledonia | Noum?a, Nouvelle-Cal?donie
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pr||ett|ngton @end|ng |rom gm@||@com  Tue Aug 25 11:38:42 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Tue, 25 Aug 2020 21:38:42 +1200
Subject: [R] ggplot 3-color gradient scales
In-Reply-To: <CAE9tUWeWyMvwJxBXrWtwAeY8NN+uQRK8kPReGMSWfBZ9B2VTtA@mail.gmail.com>
References: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>
 <D26692DF-3203-4BDB-88ED-8E444417AA3B@dcn.davis.ca.us>
 <60c66c30-7655-af43-fe34-b2a30f590a83@sapo.pt>
 <CAE9tUWeWyMvwJxBXrWtwAeY8NN+uQRK8kPReGMSWfBZ9B2VTtA@mail.gmail.com>
Message-ID: <CAE9tUWfD8Dg-13x-wb53q0n+BZBai+5N4_jLNedCQXJa0-dQrw@mail.gmail.com>

Is there a way to set it to 3 color categories instead of a gradient?  Like
if the color is based on the numbers in a dataframe column, can I make it
so anything >1.2 is red, <0.8 is blue, and anything in the middle is green?


On Mon, Aug 24, 2020 at 6:28 PM April Ettington <aprilettington at gmail.com>
wrote:

> Thank you so much!
>
>
> On Mon, Aug 24, 2020 at 5:33 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Note that the midpoint argument can make a big difference. In the code
>> below try commenting out the line where the default is changed.
>>
>>
>> f <- function(x){
>>    (x - min(x))/(max(x) - min(x))
>> }
>>
>> library(ggplot2)
>>
>> df1 <- iris[3:5]
>> names(df1)[1:2] <- c("x", "y")
>> df1$z <- ave(df1$y, df1$Species, FUN = f)
>>
>> ggplot(df1) +
>>    geom_point( aes(x, y, color = z) ) +
>>    scale_color_gradient2(low = "red",
>>                          mid = "yellow",
>>                          high = "blue",
>>                          midpoint = 0.5
>>                          )
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> ?s 04:43 de 24/08/20, Jeff Newmiller escreveu:
>> > Check out scale_colour_gradient2()
>> >
>> > On August 23, 2020 8:12:06 PM PDT, April Ettington <
>> aprilettington at gmail.com> wrote:
>> >> Currently I am using these settings in ggplot to make a gradient from
>> >> red
>> >> to blue.
>> >>
>> >> geom_point( aes(x, y, color=z) ) +
>> >> scale_colour_gradient(low = "red",high = "blue") +
>> >>
>> >> z is a ratio, and currently I am able to identify which have high and
>> >> low
>> >> values, but I'd really like to be able to distinguish which are >1, <1,
>> >> or
>> >> close to 1 by color.  It would be great if I could set a middle color
>> >> in
>> >> this gradient (eg. green) that is set the the value of 1, even if that
>> >> is
>> >> not the exact midpoint between my highest and lowest values.  Is there
>> >> a
>> >> way to do this in R?
>> >>
>> >> Thank you,
>> >> April
>> >>
>> >>      [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Aug 25 12:49:39 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 25 Aug 2020 10:49:39 +0000
Subject: [R] ggplot 3-color gradient scales
In-Reply-To: <CAE9tUWfD8Dg-13x-wb53q0n+BZBai+5N4_jLNedCQXJa0-dQrw@mail.gmail.com>
References: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>
 <D26692DF-3203-4BDB-88ED-8E444417AA3B@dcn.davis.ca.us>
 <60c66c30-7655-af43-fe34-b2a30f590a83@sapo.pt>
 <CAE9tUWeWyMvwJxBXrWtwAeY8NN+uQRK8kPReGMSWfBZ9B2VTtA@mail.gmail.com>
 <CAE9tUWfD8Dg-13x-wb53q0n+BZBai+5N4_jLNedCQXJa0-dQrw@mail.gmail.com>
Message-ID: <8a2cacab6ee7453e827394e54e588191@SRVEXCHCM1302.precheza.cz>

Hi

Maybe scale_colour_manual?

Cheers
Petr
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of April Ettington
> Sent: Tuesday, August 25, 2020 11:39 AM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: r-help at r-project.org
> Subject: Re: [R] ggplot 3-color gradient scales
> 
> Is there a way to set it to 3 color categories instead of a gradient?  Like if the
> color is based on the numbers in a dataframe column, can I make it so
> anything >1.2 is red, <0.8 is blue, and anything in the middle is green?
> 
> 
> On Mon, Aug 24, 2020 at 6:28 PM April Ettington <aprilettington at gmail.com>
> wrote:
> 
> > Thank you so much!
> >
> >
> > On Mon, Aug 24, 2020 at 5:33 PM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> >> Hello,
> >>
> >> Note that the midpoint argument can make a big difference. In the
> >> code below try commenting out the line where the default is changed.
> >>
> >>
> >> f <- function(x){
> >>    (x - min(x))/(max(x) - min(x))
> >> }
> >>
> >> library(ggplot2)
> >>
> >> df1 <- iris[3:5]
> >> names(df1)[1:2] <- c("x", "y")
> >> df1$z <- ave(df1$y, df1$Species, FUN = f)
> >>
> >> ggplot(df1) +
> >>    geom_point( aes(x, y, color = z) ) +
> >>    scale_color_gradient2(low = "red",
> >>                          mid = "yellow",
> >>                          high = "blue",
> >>                          midpoint = 0.5
> >>                          )
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >> ?s 04:43 de 24/08/20, Jeff Newmiller escreveu:
> >> > Check out scale_colour_gradient2()
> >> >
> >> > On August 23, 2020 8:12:06 PM PDT, April Ettington <
> >> aprilettington at gmail.com> wrote:
> >> >> Currently I am using these settings in ggplot to make a gradient
> >> >> from red to blue.
> >> >>
> >> >> geom_point( aes(x, y, color=z) ) + scale_colour_gradient(low =
> >> >> "red",high = "blue") +
> >> >>
> >> >> z is a ratio, and currently I am able to identify which have high
> >> >> and low values, but I'd really like to be able to distinguish
> >> >> which are >1, <1, or close to 1 by color.  It would be great if I
> >> >> could set a middle color in this gradient (eg. green) that is set
> >> >> the the value of 1, even if that is not the exact midpoint between
> >> >> my highest and lowest values.  Is there a way to do this in R?
> >> >>
> >> >> Thank you,
> >> >> April
> >> >>
> >> >>      [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug 25 13:01:46 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 25 Aug 2020 12:01:46 +0100
Subject: [R] ggplot 3-color gradient scales
In-Reply-To: <CAE9tUWfD8Dg-13x-wb53q0n+BZBai+5N4_jLNedCQXJa0-dQrw@mail.gmail.com>
References: <CAE9tUWeL37oSTxB2GJuozEhSoFe0tbe23GXk=3EEgSGNqX=-Kg@mail.gmail.com>
 <D26692DF-3203-4BDB-88ED-8E444417AA3B@dcn.davis.ca.us>
 <60c66c30-7655-af43-fe34-b2a30f590a83@sapo.pt>
 <CAE9tUWeWyMvwJxBXrWtwAeY8NN+uQRK8kPReGMSWfBZ9B2VTtA@mail.gmail.com>
 <CAE9tUWfD8Dg-13x-wb53q0n+BZBai+5N4_jLNedCQXJa0-dQrw@mail.gmail.com>
Message-ID: <b280643f-8adf-7ca7-2232-d172bae5cea2@sapo.pt>

Hello,

If you want a predetermined number of colors, discretise the data and 
use scale_color_manual. In the code below I first compute another vector 
z, with a different range, 0 to 2. (In my first mail it was 0 to 1.)

g <- function(x, a = 0, b = 1){
   (b - a)*(x - min(x))/(max(x) - min(x)) + a
}

library(ggplot2)

df1 <- iris[3:5]
names(df1)[1:2] <- c("x", "y")
df1$z <- ave(df1$y, df1$Species, FUN = function(x) g(x, a = 0, b = 2))


Now is the step that solves the problem, to bin the vector. Other 
options could include findInterval. Then the two plot instructions are 
equivalent.

df1$z <- cut(df1$z,
              breaks = c(-Inf, 0.8, 1.2, Inf),
              labels = c("Small", "Medium", "Large"))


ggplot(df1) +
   geom_point( aes(x, y, color = z) ) +
   scale_color_manual(values = c("red", "green", "blue"))

ggplot(df1) +
   geom_point( aes(x, y, color = z) ) +
   scale_color_manual(breaks = c("Small", "Medium", "Large"),
                      values = c("Small" = "red", "Medium" = "green", 
"Large" = "blue"))


Hope this helps,

Rui Barradas


?s 10:38 de 25/08/20, April Ettington escreveu:
> Is there a way to set it to 3 color categories instead of a gradient?  
> Like if the color is based on the numbers in a dataframe column, can I 
> make it so anything >1.2 is red, <0.8 is blue, and anything in the 
> middle is green?
> 
> 
> On Mon, Aug 24, 2020 at 6:28 PM April Ettington 
> <aprilettington at gmail.com <mailto:aprilettington at gmail.com>> wrote:
> 
>     Thank you so much!
> 
> 
>     On Mon, Aug 24, 2020 at 5:33 PM Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>         Hello,
> 
>         Note that the midpoint argument can make a big difference. In
>         the code
>         below try commenting out the line where the default is changed.
> 
> 
>         f <- function(x){
>          ? ?(x - min(x))/(max(x) - min(x))
>         }
> 
>         library(ggplot2)
> 
>         df1 <- iris[3:5]
>         names(df1)[1:2] <- c("x", "y")
>         df1$z <- ave(df1$y, df1$Species, FUN = f)
> 
>         ggplot(df1) +
>          ? ?geom_point( aes(x, y, color = z) ) +
>          ? ?scale_color_gradient2(low = "red",
>          ? ? ? ? ? ? ? ? ? ? ? ? ?mid = "yellow",
>          ? ? ? ? ? ? ? ? ? ? ? ? ?high = "blue",
>          ? ? ? ? ? ? ? ? ? ? ? ? ?midpoint = 0.5
>          ? ? ? ? ? ? ? ? ? ? ? ? ?)
> 
>         Hope this helps,
> 
>         Rui Barradas
> 
> 
>         ?s 04:43 de 24/08/20, Jeff Newmiller escreveu:
>          > Check out scale_colour_gradient2()
>          >
>          > On August 23, 2020 8:12:06 PM PDT, April Ettington
>         <aprilettington at gmail.com <mailto:aprilettington at gmail.com>> wrote:
>          >> Currently I am using these settings in ggplot to make a
>         gradient from
>          >> red
>          >> to blue.
>          >>
>          >> geom_point( aes(x, y, color=z) ) +
>          >> scale_colour_gradient(low = "red",high = "blue") +
>          >>
>          >> z is a ratio, and currently I am able to identify which have
>         high and
>          >> low
>          >> values, but I'd really like to be able to distinguish which
>         are >1, <1,
>          >> or
>          >> close to 1 by color.? It would be great if I could set a
>         middle color
>          >> in
>          >> this gradient (eg. green) that is set the the value of 1,
>         even if that
>          >> is
>          >> not the exact midpoint between my highest and lowest
>         values.? Is there
>          >> a
>          >> way to do this in R?
>          >>
>          >> Thank you,
>          >> April
>          >>
>          >>? ? ? [[alternative HTML version deleted]]
>          >>
>          >> ______________________________________________
>          >> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>          >> https://stat.ethz.ch/mailman/listinfo/r-help
>          >> PLEASE do read the posting guide
>          >> http://www.R-project.org/posting-guide.html
>          >> and provide commented, minimal, self-contained, reproducible
>         code.
>          >
>


From m|ke9 @end|ng |rom po@teo@n|  Tue Aug 25 14:26:43 2020
From: m|ke9 @end|ng |rom po@teo@n| (Mike)
Date: Tue, 25 Aug 2020 14:26:43 +0200
Subject: [R] which.min, equal values and fractions
Message-ID: <20200825122643.GA4321@local>

Hi,

According to ?which.min it returns the "index of the (first)
minimum". So I would expect it to also return the first minimum when
providing two identical extrema. But my minimal reproducible doesn't
do so:

data1a <- c(3.2,4.2)
data1b <- c(3.1,4.1)

data2a <- c(0.2,1.2)
data2b <- c(4.2,5.2)

data3aa <- data1a - data2a
data3ba <- data1b - data2a
data3ab <- data1a - data2b
data3bb <- data1b - data2b

print (data3aa)
print (which.min (data3aa))
print (which.max (data3aa))

print (data3ba)
print (which.min (data3ba))
print (which.max (data3ba))

print (data3ab)
print (which.min (data3ab))
print (which.max (data3ab))

print (data3bb)
print (which.min (data3bb))
print (which.max (data3bb))

results in:

[1] 3 3
[1] 1
[1] 1
[1] 2.9 2.9
[1] 2
[1] 1
[1] -1 -1
[1] 1
[1] 1
[1] -1.1 -1.1
[1] 2
[1] 1

First of all which.max works as expected by always returning 1.

But which.min only does so if the values don't contain fractions.
And I get

> identical (data3ba, c(2.9,2.9))
[1] FALSE

Why is which.min not always returning 1 but which.max does?

Mike


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Aug 25 14:39:46 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 25 Aug 2020 15:39:46 +0300
Subject: [R] which.min, equal values and fractions
In-Reply-To: <20200825122643.GA4321@local>
References: <20200825122643.GA4321@local>
Message-ID: <20200825153946.1e6ed8ff@trisector>

On Tue, 25 Aug 2020 14:26:43 +0200
Mike <mike9 at posteo.nl> wrote:

> But which.min only does so if the values don't contain fractions.
> And I get
> 
> > identical (data3ba, c(2.9,2.9))  
> [1] FALSE
> 
> Why is which.min not always returning 1 but which.max does?

It's the unfortunate consequence of the way floating point numbers
work:

data3ba - 2.9
# [1]  0.000000e+00 -4.440892e-16

See R FAQ 7.31:
https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

-- 
Best regards,
Ivan


From junxu@r @end|ng |rom gm@||@com  Tue Aug 25 16:18:21 2020
From: junxu@r @end|ng |rom gm@||@com (Xu Jun)
Date: Tue, 25 Aug 2020 10:18:21 -0400
Subject: [R] Classification Tree Prediction Error
In-Reply-To: <CAGxFJbRE9eHydcvvdyk8fhPF2ORo-5ihXVFhRWs-bPeic9f+Gg@mail.gmail.com>
References: <CADe_g+Uicy+QuBBd984BBhf_LuSMHuDH7A-KxxFQQ_rXkjRRWg@mail.gmail.com>
 <CAGxFJbRE9eHydcvvdyk8fhPF2ORo-5ihXVFhRWs-bPeic9f+Gg@mail.gmail.com>
Message-ID: <CADe_g+WztX47N=OudnpG6Gt8M4cKUW4uutmF=0iOVLwYF3ygcA@mail.gmail.com>

Thank you for your comment! This tree function is from the tree package.
Although it might be a pure statistical question, it could be related to
how the tree function is used. I will explore the site that you suggested.
But if there is anyone who can figure it out off the top of their head, I'd
very much appreciate it.

Jun

On Mon, Aug 24, 2020 at 1:01 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Purely statistical questions -- as opposed to R programming queries -- are
> generally off topic here.
> Here is where they are on topic:  https://stats.stackexchange.com/
>
> Suggestion: when you post, do include the package name where you get
> tree() from, as there might be
> more than one with this function.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Aug 24, 2020 at 8:58 AM Xu Jun <junxu.r at gmail.com> wrote:
>
>> Dear all R experts,
>>
>> I have a question about using cross-validation to assess results estimated
>> from a classification tree model. I annotated what each line does in the R
>> code chunk below. Basically, I split the data, named usedta, into 70% vs.
>> 30%, with the training set having 70% and the test set 30% of the original
>> cases. After splitting the data, I first run a classification tree off the
>> training set, and then use the results for cross-validation using the test
>> set. It turns out that if I don't have any predictors and make predictions
>> by simply betting on the majority class of the zero-one coding of the
>> binary response variable, I can do better than what the results from the
>> classification tree would deliver in the test set. What would this imply
>> and what would cause this problem? Does it mean that classification tree
>> is
>> not an appropriate method for my data; or, it's because I have too few
>> variables? Thanks a lot!
>>
>> Jun Xu, PhD
>> Professor
>> Department of Sociology
>> Ball State University
>> Muncie, IN 47306
>> USA
>>
>> Using the estimates, I get the following prediction rate (correct
>> prediction) using the test set. Or we can say the misclassification error
>> rate is 1-0.837 = 0.163
>>
>> > (tab[1,1] + tab[2,2]) / sum(tab)[1] 0.837
>>
>>
>> Without any predictors, I can get the following rate by betting on the
>> majority class every time, again using data from the test set. In this
>> case, the misclassification error rate is 1-0.85 = 0.15
>>
>> > table(h2.test)h2.test
>> 1poorHlth 0goodHlth
>>       101       575 > 571/(571+101)[1] 0.85
>>
>>
>>
>> R Code Chunk
>>
>> # set the seed for random number generator for replication
>> set.seed(47306)
>> # have the 7/3 split with 70% of the cases allotted to the training set
>> # AND create the training set identifier
>> class.train = sample(1:nrow(usedta), nrow(usedta)*0.7)
>> # create the test set indicator
>> class.test = (-class.train)
>> # create a vector for the binary response variable from the test set
>> # for future cross-tabulation.
>> h2.test <- usedta$h2[class.test]
>> # count the train set cases
>> Ntrain = length(usedta$h2[class.train])
>> # run the classification tree model using the training set
>> # h2 is the binary response and other variables are predictors
>> tree.h2 <- tree(h2 ~ age + educ + female + white + married + happy,
>>                 data = usedta, subset = class.train,
>>                 control = tree.control(nobs=Ntrain, mindev=0.003))
>> # summary results
>> summary(tree.h2)
>> # make predictions of h2 using the test set
>> tree.h2.pred <- predict(tree.h2, usedta[class.test,], type="class")
>> # cross tab the predictions using the test set
>> table(tree.h2.pred, h2.test)
>> tab = table(tree.h2.pred, h2.test)
>> # calculate the ratio for the correctly predicted in the test set
>> (tab[1,1] + tab[2,2]) / sum(tab)
>> # calculate the ratio for the correctly predicted using the naive approach
>> # by betting on the majority category.
>> table(h2.test)[2]/sum(tab)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From j@whct @end|ng |rom gm@||@com  Tue Aug 25 17:09:33 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Tue, 25 Aug 2020 10:09:33 -0500
Subject: [R] Classification Tree Prediction Error
In-Reply-To: <CADe_g+WztX47N=OudnpG6Gt8M4cKUW4uutmF=0iOVLwYF3ygcA@mail.gmail.com>
References: <CADe_g+Uicy+QuBBd984BBhf_LuSMHuDH7A-KxxFQQ_rXkjRRWg@mail.gmail.com>
 <CAGxFJbRE9eHydcvvdyk8fhPF2ORo-5ihXVFhRWs-bPeic9f+Gg@mail.gmail.com>
 <CADe_g+WztX47N=OudnpG6Gt8M4cKUW4uutmF=0iOVLwYF3ygcA@mail.gmail.com>
Message-ID: <CAFyG=WN5jo9bwmTiyAcecupNodvC3EXkCHbug5CnXEH=51EsBw@mail.gmail.com>

As Bert advised correctly, this is not an R programming question. There is
some misunderstanding on how training//test data work together
in predictions. Suppose your test data has only one class. Therefore, you can
get the following rate by betting on the majority class every time, again
using data from the test set. In this case, the misclassification rate is
0! Of course no classification algorithm can beat that prediction for which
you already utilize the truth in the test data. In conclusion, the tree
model you provided has accuracy 0.837, which is very close to 0.85. I would
not complain.

On Tue, Aug 25, 2020 at 9:19 AM Xu Jun <junxu.r at gmail.com> wrote:

> Thank you for your comment! This tree function is from the tree package.
> Although it might be a pure statistical question, it could be related to
> how the tree function is used. I will explore the site that you suggested.
> But if there is anyone who can figure it out off the top of their head, I'd
> very much appreciate it.
>
> Jun
>
> On Mon, Aug 24, 2020 at 1:01 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
> > Purely statistical questions -- as opposed to R programming queries --
> are
> > generally off topic here.
> > Here is where they are on topic:  https://stats.stackexchange.com/
> >
> > Suggestion: when you post, do include the package name where you get
> > tree() from, as there might be
> > more than one with this function.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Mon, Aug 24, 2020 at 8:58 AM Xu Jun <junxu.r at gmail.com> wrote:
> >
> >> Dear all R experts,
> >>
> >> I have a question about using cross-validation to assess results
> estimated
> >> from a classification tree model. I annotated what each line does in
> the R
> >> code chunk below. Basically, I split the data, named usedta, into 70%
> vs.
> >> 30%, with the training set having 70% and the test set 30% of the
> original
> >> cases. After splitting the data, I first run a classification tree off
> the
> >> training set, and then use the results for cross-validation using the
> test
> >> set. It turns out that if I don't have any predictors and make
> predictions
> >> by simply betting on the majority class of the zero-one coding of the
> >> binary response variable, I can do better than what the results from the
> >> classification tree would deliver in the test set. What would this imply
> >> and what would cause this problem? Does it mean that classification tree
> >> is
> >> not an appropriate method for my data; or, it's because I have too few
> >> variables? Thanks a lot!
> >>
> >> Jun Xu, PhD
> >> Professor
> >> Department of Sociology
> >> Ball State University
> >> Muncie, IN 47306
> >> USA
> >>
> >> Using the estimates, I get the following prediction rate (correct
> >> prediction) using the test set. Or we can say the misclassification
> error
> >> rate is 1-0.837 = 0.163
> >>
> >> > (tab[1,1] + tab[2,2]) / sum(tab)[1] 0.837
> >>
> >>
> >> Without any predictors, I can get the following rate by betting on the
> >> majority class every time, again using data from the test set. In this
> >> case, the misclassification error rate is 1-0.85 = 0.15
> >>
> >> > table(h2.test)h2.test
> >> 1poorHlth 0goodHlth
> >>       101       575 > 571/(571+101)[1] 0.85
> >>
> >>
> >>
> >> R Code Chunk
> >>
> >> # set the seed for random number generator for replication
> >> set.seed(47306)
> >> # have the 7/3 split with 70% of the cases allotted to the training set
> >> # AND create the training set identifier
> >> class.train = sample(1:nrow(usedta), nrow(usedta)*0.7)
> >> # create the test set indicator
> >> class.test = (-class.train)
> >> # create a vector for the binary response variable from the test set
> >> # for future cross-tabulation.
> >> h2.test <- usedta$h2[class.test]
> >> # count the train set cases
> >> Ntrain = length(usedta$h2[class.train])
> >> # run the classification tree model using the training set
> >> # h2 is the binary response and other variables are predictors
> >> tree.h2 <- tree(h2 ~ age + educ + female + white + married + happy,
> >>                 data = usedta, subset = class.train,
> >>                 control = tree.control(nobs=Ntrain, mindev=0.003))
> >> # summary results
> >> summary(tree.h2)
> >> # make predictions of h2 using the test set
> >> tree.h2.pred <- predict(tree.h2, usedta[class.test,], type="class")
> >> # cross tab the predictions using the test set
> >> table(tree.h2.pred, h2.test)
> >> tab = table(tree.h2.pred, h2.test)
> >> # calculate the ratio for the correctly predicted in the test set
> >> (tab[1,1] + tab[2,2]) / sum(tab)
> >> # calculate the ratio for the correctly predicted using the naive
> approach
> >> # by betting on the majority category.
> >> table(h2.test)[2]/sum(tab)
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@whct @end|ng |rom gm@||@com  Tue Aug 25 17:33:30 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Tue, 25 Aug 2020 10:33:30 -0500
Subject: [R] How to obtain individual log-likelihood value from glm?
Message-ID: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>

Dear R-help,

The function logLik can be used to obtain the maximum log-likelihood value
from a glm object. This is an aggregated value, a summation of individual
log-likelihood values. How do I obtain individual values? In the following
example, I would expect 9 numbers since the response has length 9. I could
write a function to compute the values, but there are lots of
family members in glm, and I am trying not to reinvent wheels. Thanks!

counts <- c(18,17,15,20,10,20,25,13,12)
     outcome <- gl(3,1,9)
     treatment <- gl(3,3)
     data.frame(treatment, outcome, counts) # showing data
     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
     (ll <- logLik(glm.D93))

	[[alternative HTML version deleted]]


From b|@hop_peterj @end|ng |rom hotm@||@com  Mon Aug 24 12:27:41 2020
From: b|@hop_peterj @end|ng |rom hotm@||@com (Peter Bishop)
Date: Mon, 24 Aug 2020 10:27:41 +0000
Subject: [R] Matching backslash in a table's column using R language
Message-ID: <ME2PR01MB3857E156F9173873A3EDD86D83560@ME2PR01MB3857.ausprd01.prod.outlook.com>

In SQL, I'm using R as a way to filter data based on:
    - 20 characters in the range <space> to <tilde>
    - excluding <quote>, <apostrophe>, <comma>, <question mark>, <backslash>, <backtick>

Given a SQL column containing the data:

    code
    ----
    A\BCDEFG

and the T-SQL script:

    EXEC [sys].[sp_execute_external_script]
            @language=N'R',
            @script=N'
    pattern1 = "^[\x20-\x7e]{1,20}$"
    pattern2 = "[\x22\x27\x2c\x3f\x5c\x60]"

    outData <- subset(inData, grepl(pattern1, code, perl=TRUE) & !grepl(pattern2, code, perl=TRUE))',
            @input_data_1 = N'SELECT [code] FROM [dbo].[products]',
            @input_data_1_name = N'inData',
            @output_data_1_name = N'outData'
    WITH
            RESULT SETS (AS OBJECT [dbo].[products]);
    GO

why does the row detailed above get returned? I know that backslash is a special character but not in the SQL table. Consequently, the T-SQL code:

    SELECT ASCII(SUBSTRING([value], 2, 1)) FROM [table]

returns 92 (the ASCII code for <backslash>) which shows that this is being recognised as a backslash character and not as an escape indicator for the following "B".

Can anyone advise how I can filter out the <backslash> in the way that the other identified characters are being successfully filtered? As the data is being retrieved from a table, I can?t ask the data provider to use ?\\? instead of ?\? as that will be invalid for other uses.

Thanks.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 25 18:29:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 25 Aug 2020 09:29:33 -0700
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
Message-ID: <CAGxFJbTz_cjEmQeeoLXi6aSiz=V-qKRVHuftJyeU-6GXBOXVgQ@mail.gmail.com>

If you look at

stats:::logLik.glm  #3 ":" because it's unexported, as is true of most
methods

it should be obvious.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 25, 2020 at 8:34 AM John Smith <jswhct at gmail.com> wrote:

> Dear R-help,
>
> The function logLik can be used to obtain the maximum log-likelihood value
> from a glm object. This is an aggregated value, a summation of individual
> log-likelihood values. How do I obtain individual values? In the following
> example, I would expect 9 numbers since the response has length 9. I could
> write a function to compute the values, but there are lots of
> family members in glm, and I am trying not to reinvent wheels. Thanks!
>
> counts <- c(18,17,15,20,10,20,25,13,12)
>      outcome <- gl(3,1,9)
>      treatment <- gl(3,3)
>      data.frame(treatment, outcome, counts) # showing data
>      glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>      (ll <- logLik(glm.D93))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Tue Aug 25 18:40:17 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 25 Aug 2020 18:40:17 +0200
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
Message-ID: <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>

If you don't worry too much about an additive constant, then half the negative squared deviance residuals should do. (Not quite sure how weights factor in. Looks like they are accounted for.)

-pd

> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
> 
> Dear R-help,
> 
> The function logLik can be used to obtain the maximum log-likelihood value
> from a glm object. This is an aggregated value, a summation of individual
> log-likelihood values. How do I obtain individual values? In the following
> example, I would expect 9 numbers since the response has length 9. I could
> write a function to compute the values, but there are lots of
> family members in glm, and I am trying not to reinvent wheels. Thanks!
> 
> counts <- c(18,17,15,20,10,20,25,13,12)
>     outcome <- gl(3,1,9)
>     treatment <- gl(3,3)
>     data.frame(treatment, outcome, counts) # showing data
>     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>     (ll <- logLik(glm.D93))
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 25 20:26:08 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 25 Aug 2020 11:26:08 -0700
Subject: [R] Matching backslash in a table's column using R language
In-Reply-To: <ME2PR01MB3857E156F9173873A3EDD86D83560@ME2PR01MB3857.ausprd01.prod.outlook.com>
References: <ME2PR01MB3857E156F9173873A3EDD86D83560@ME2PR01MB3857.ausprd01.prod.outlook.com>
Message-ID: <CAGxFJbTvCAMGa_XSTbmXd1VORuZO3rUw3D25THyEgWF2-s_RgQ@mail.gmail.com>

1. I am far from an expert on such matters
2. It is unclear to me what your input is -- I assume a file.

The problem, as you indicate, is that R's parser sees "\B" as an incorrect
escape character, so, for example:
> cat("\B")
Error: '\B' is an unrecognized escape in character string starting ""\B"

In any case, I think you should look at ?scan. Here is an example where I
scan from the keyboard first and then remove the "\". You may have to scan
from a file to do this.

> z <-scan(file = "", what = "character")
1: A\BCDEFG
2:     #CR terminates input
Read 1 item

> cat(z)
A\BCDEFG

> nchar(z)
[1] 8  ## scan read in the "\" as a single character from the console.

> sub("\\\\","",z)  ## Yes, 4 backslashes
[1] "ABCDEFG"

There may be better ways to do this, but as I said, I'm no expert.

BTW, in posting here, please post in *plain text,* as the server can mangle
html.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 25, 2020 at 9:02 AM Peter Bishop <bishop_peterj at hotmail.com>
wrote:

> In SQL, I'm using R as a way to filter data based on:
>     - 20 characters in the range <space> to <tilde>
>     - excluding <quote>, <apostrophe>, <comma>, <question mark>,
> <backslash>, <backtick>
>
> Given a SQL column containing the data:
>
>     code
>     ----
>     A\BCDEFG
>
> and the T-SQL script:
>
>     EXEC [sys].[sp_execute_external_script]
>             @language=N'R',
>             @script=N'
>     pattern1 = "^[\x20-\x7e]{1,20}$"
>     pattern2 = "[\x22\x27\x2c\x3f\x5c\x60]"
>
>     outData <- subset(inData, grepl(pattern1, code, perl=TRUE) &
> !grepl(pattern2, code, perl=TRUE))',
>             @input_data_1 = N'SELECT [code] FROM [dbo].[products]',
>             @input_data_1_name = N'inData',
>             @output_data_1_name = N'outData'
>     WITH
>             RESULT SETS (AS OBJECT [dbo].[products]);
>     GO
>
> why does the row detailed above get returned? I know that backslash is a
> special character but not in the SQL table. Consequently, the T-SQL code:
>
>     SELECT ASCII(SUBSTRING([value], 2, 1)) FROM [table]
>
> returns 92 (the ASCII code for <backslash>) which shows that this is being
> recognised as a backslash character and not as an escape indicator for the
> following "B".
>
> Can anyone advise how I can filter out the <backslash> in the way that the
> other identified characters are being successfully filtered? As the data is
> being retrieved from a table, I can?t ask the data provider to use ?\\?
> instead of ?\? as that will be invalid for other uses.
>
> Thanks.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From b|@hop_peterj @end|ng |rom hotm@||@com  Tue Aug 25 21:16:35 2020
From: b|@hop_peterj @end|ng |rom hotm@||@com (Peter Bishop)
Date: Tue, 25 Aug 2020 19:16:35 +0000
Subject: [R] Matching backslash in a table's column using R language
In-Reply-To: <CAGxFJbTvCAMGa_XSTbmXd1VORuZO3rUw3D25THyEgWF2-s_RgQ@mail.gmail.com>
References: <ME2PR01MB3857E156F9173873A3EDD86D83560@ME2PR01MB3857.ausprd01.prod.outlook.com>,
 <CAGxFJbTvCAMGa_XSTbmXd1VORuZO3rUw3D25THyEgWF2-s_RgQ@mail.gmail.com>
Message-ID: <ME2PR01MB385722776B2806EDA31306F783570@ME2PR01MB3857.ausprd01.prod.outlook.com>

The feed is coming from a SQL table and this is using the embedded support for R which comes with SQL 2016. The source is therefore a SELECT statement.


As an aside, I found a workaround by changing the pattern from:


"[\x22\x27\x2c\x3f\x5c\x60]"


to:


"[\x22\x27\x2c\x3f\x5c\x5c\x60]"


This seems to be escaping the backslash in the R script rather than in the data - which confuses me.

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Wednesday, 26 August 2020 4:26 AM
To: Peter Bishop <bishop_peterj at hotmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Matching backslash in a table's column using R language

1. I am far from an expert on such matters
2. It is unclear to me what your input is -- I assume a file.

The problem, as you indicate, is that R's parser sees "\B" as an incorrect escape character, so, for example:
> cat("\B")
Error: '\B' is an unrecognized escape in character string starting ""\B"

In any case, I think you should look at ?scan. Here is an example where I scan from the keyboard first and then remove the "\". You may have to scan from a file to do this.

> z <-scan(file = "", what = "character")
1: A\BCDEFG
2:     #CR terminates input
Read 1 item

> cat(z)
A\BCDEFG

> nchar(z)
[1] 8  ## scan read in the "\" as a single character from the console.

> sub("\\\\","",z)  ## Yes, 4 backslashes
[1] "ABCDEFG"

There may be better ways to do this, but as I said, I'm no expert.

BTW, in posting here, please post in *plain text,* as the server can mangle html.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 25, 2020 at 9:02 AM Peter Bishop <bishop_peterj at hotmail.com<mailto:bishop_peterj at hotmail.com>> wrote:
In SQL, I'm using R as a way to filter data based on:
    - 20 characters in the range <space> to <tilde>
    - excluding <quote>, <apostrophe>, <comma>, <question mark>, <backslash>, <backtick>

Given a SQL column containing the data:

    code
    ----
    A\BCDEFG

and the T-SQL script:

    EXEC [sys].[sp_execute_external_script]
            @language=N'R',
            @script=N'
    pattern1 = "^[\x20-\x7e]{1,20}$"
    pattern2 = "[\x22\x27\x2c\x3f\x5c\x60]"

    outData <- subset(inData, grepl(pattern1, code, perl=TRUE) & !grepl(pattern2, code, perl=TRUE))',
            @input_data_1 = N'SELECT [code] FROM [dbo].[products]',
            @input_data_1_name = N'inData',
            @output_data_1_name = N'outData'
    WITH
            RESULT SETS (AS OBJECT [dbo].[products]);
    GO

why does the row detailed above get returned? I know that backslash is a special character but not in the SQL table. Consequently, the T-SQL code:

    SELECT ASCII(SUBSTRING([value], 2, 1)) FROM [table]

returns 92 (the ASCII code for <backslash>) which shows that this is being recognised as a backslash character and not as an escape indicator for the following "B".

Can anyone advise how I can filter out the <backslash> in the way that the other identified characters are being successfully filtered? As the data is being retrieved from a table, I can?t ask the data provider to use ?\\? instead of ?\? as that will be invalid for other uses.

Thanks.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=02%7C01%7C%7C21350c4700bf48cb035008d849245d6c%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339767813946809&sdata=v79GeIK6IXhKuF4q0qJ3uopMdJeYzKKvdi5a4NqgdeM%3D&reserved=0>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://nam05.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=02%7C01%7C%7C21350c4700bf48cb035008d849245d6c%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339767813956802&sdata=iKgAGe23wPBrIK4iI3q0Vqk19q%2B%2FgSgiRUV858XOU3A%3D&reserved=0>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Aug 25 21:53:16 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 25 Aug 2020 12:53:16 -0700
Subject: [R] Matching backslash in a table's column using R language
In-Reply-To: <ME2PR01MB385722776B2806EDA31306F783570@ME2PR01MB3857.ausprd01.prod.outlook.com>
References: <ME2PR01MB3857E156F9173873A3EDD86D83560@ME2PR01MB3857.ausprd01.prod.outlook.com>,
 <CAGxFJbTvCAMGa_XSTbmXd1VORuZO3rUw3D25THyEgWF2-s_RgQ@mail.gmail.com>
 <ME2PR01MB385722776B2806EDA31306F783570@ME2PR01MB3857.ausprd01.prod.outlook.com>
Message-ID: <39507455-ECE8-4826-95DF-220C33E17A82@dcn.davis.ca.us>

In my opinion, using hexadecimal ASCII is much more obscure than simply using the escape character properly... that is, you are doing no-one any favors by using them. But to attain clarity here, you need to envision what the various software layers are doing.

In your case, SQLServer may not utilize escape character, but it is passing your R code to the R interpreter, which does use the escape character to convert source code into strings in memory, which are then passed into the regex parser, which is the final layer that also handles the same escape character. 

What may be confusing you is the distinction between what is in memory that the regex parser sees:

["',?\\`]

and what the R string literal looks like that you should type to get this string into memory:

"[\"',?\\\\`]"

When you pass the latter literal to the cat() function, it will show you the former version. When you have the literal stored in memory, you can use the print() function to see what you have to type as a literal string to get the in-memory version. I use this trick (cat) to help me zero in on what is actually getting passed to the regex engine when I have difficulty envisioning what is going on.

The regex engine needs that doubled backslash to recognize that _it_ should not give special treatment to the \ there, and should look for it in the input data.

On August 25, 2020 12:16:35 PM PDT, Peter Bishop <bishop_peterj at hotmail.com> wrote:
>The feed is coming from a SQL table and this is using the embedded
>support for R which comes with SQL 2016. The source is therefore a
>SELECT statement.
>
>
>As an aside, I found a workaround by changing the pattern from:
>
>
>"[\x22\x27\x2c\x3f\x5c\x60]"
>
>
>to:
>
>
>"[\x22\x27\x2c\x3f\x5c\x5c\x60]"
>
>
>This seems to be escaping the backslash in the R script rather than in
>the data - which confuses me.
>
>________________________________
>From: Bert Gunter <bgunter.4567 at gmail.com>
>Sent: Wednesday, 26 August 2020 4:26 AM
>To: Peter Bishop <bishop_peterj at hotmail.com>
>Cc: r-help at r-project.org <r-help at r-project.org>
>Subject: Re: [R] Matching backslash in a table's column using R
>language
>
>1. I am far from an expert on such matters
>2. It is unclear to me what your input is -- I assume a file.
>
>The problem, as you indicate, is that R's parser sees "\B" as an
>incorrect escape character, so, for example:
>> cat("\B")
>Error: '\B' is an unrecognized escape in character string starting
>""\B"
>
>In any case, I think you should look at ?scan. Here is an example where
>I scan from the keyboard first and then remove the "\". You may have to
>scan from a file to do this.
>
>> z <-scan(file = "", what = "character")
>1: A\BCDEFG
>2:     #CR terminates input
>Read 1 item
>
>> cat(z)
>A\BCDEFG
>
>> nchar(z)
>[1] 8  ## scan read in the "\" as a single character from the console.
>
>> sub("\\\\","",z)  ## Yes, 4 backslashes
>[1] "ABCDEFG"
>
>There may be better ways to do this, but as I said, I'm no expert.
>
>BTW, in posting here, please post in *plain text,* as the server can
>mangle html.
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Tue, Aug 25, 2020 at 9:02 AM Peter Bishop
><bishop_peterj at hotmail.com<mailto:bishop_peterj at hotmail.com>> wrote:
>In SQL, I'm using R as a way to filter data based on:
>    - 20 characters in the range <space> to <tilde>
>- excluding <quote>, <apostrophe>, <comma>, <question mark>,
><backslash>, <backtick>
>
>Given a SQL column containing the data:
>
>    code
>    ----
>    A\BCDEFG
>
>and the T-SQL script:
>
>    EXEC [sys].[sp_execute_external_script]
>            @language=N'R',
>            @script=N'
>    pattern1 = "^[\x20-\x7e]{1,20}$"
>    pattern2 = "[\x22\x27\x2c\x3f\x5c\x60]"
>
>outData <- subset(inData, grepl(pattern1, code, perl=TRUE) &
>!grepl(pattern2, code, perl=TRUE))',
>            @input_data_1 = N'SELECT [code] FROM [dbo].[products]',
>            @input_data_1_name = N'inData',
>            @output_data_1_name = N'outData'
>    WITH
>            RESULT SETS (AS OBJECT [dbo].[products]);
>    GO
>
>why does the row detailed above get returned? I know that backslash is
>a special character but not in the SQL table. Consequently, the T-SQL
>code:
>
>    SELECT ASCII(SUBSTRING([value], 2, 1)) FROM [table]
>
>returns 92 (the ASCII code for <backslash>) which shows that this is
>being recognised as a backslash character and not as an escape
>indicator for the following "B".
>
>Can anyone advise how I can filter out the <backslash> in the way that
>the other identified characters are being successfully filtered? As the
>data is being retrieved from a table, I can?t ask the data provider to
>use ?\\? instead of ?\? as that will be invalid for other uses.
>
>Thanks.
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=02%7C01%7C%7C21350c4700bf48cb035008d849245d6c%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339767813946809&sdata=v79GeIK6IXhKuF4q0qJ3uopMdJeYzKKvdi5a4NqgdeM%3D&reserved=0>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<https://nam05.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&data=02%7C01%7C%7C21350c4700bf48cb035008d849245d6c%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339767813956802&sdata=iKgAGe23wPBrIK4iI3q0Vqk19q%2B%2FgSgiRUV858XOU3A%3D&reserved=0>
>and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From b|@hop_peterj @end|ng |rom hotm@||@com  Tue Aug 25 22:19:50 2020
From: b|@hop_peterj @end|ng |rom hotm@||@com (Peter Bishop)
Date: Tue, 25 Aug 2020 20:19:50 +0000
Subject: [R] Matching backslash in a table's column using R language
In-Reply-To: <39507455-ECE8-4826-95DF-220C33E17A82@dcn.davis.ca.us>
References: <ME2PR01MB3857E156F9173873A3EDD86D83560@ME2PR01MB3857.ausprd01.prod.outlook.com>,
 <CAGxFJbTvCAMGa_XSTbmXd1VORuZO3rUw3D25THyEgWF2-s_RgQ@mail.gmail.com>
 <ME2PR01MB385722776B2806EDA31306F783570@ME2PR01MB3857.ausprd01.prod.outlook.com>,
 <39507455-ECE8-4826-95DF-220C33E17A82@dcn.davis.ca.us>
Message-ID: <ME1PR01MB1714062EE55017DE670F8C2A83570@ME1PR01MB1714.ausprd01.prod.outlook.com>

To be honest, I've only used the hex values as that was the format in which the patterns were passed to me. 

However from your explanation, I now understand what's going on. I didn't appreciate that the characters were passed to another layer and not seeing the hex code as the raw backslash. 

Many thanks for the explanation. 

> On 25 Aug 2020, at 20:53, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> ?In my opinion, using hexadecimal ASCII is much more obscure than simply using the escape character properly... that is, you are doing no-one any favors by using them. But to attain clarity here, you need to envision what the various software layers are doing.
> 
> In your case, SQLServer may not utilize escape character, but it is passing your R code to the R interpreter, which does use the escape character to convert source code into strings in memory, which are then passed into the regex parser, which is the final layer that also handles the same escape character. 
> 
> What may be confusing you is the distinction between what is in memory that the regex parser sees:
> 
> ["',?\\`]
> 
> and what the R string literal looks like that you should type to get this string into memory:
> 
> "[\"',?\\\\`]"
> 
> When you pass the latter literal to the cat() function, it will show you the former version. When you have the literal stored in memory, you can use the print() function to see what you have to type as a literal string to get the in-memory version. I use this trick (cat) to help me zero in on what is actually getting passed to the regex engine when I have difficulty envisioning what is going on.
> 
> The regex engine needs that doubled backslash to recognize that _it_ should not give special treatment to the \ there, and should look for it in the input data.
> 
>> On August 25, 2020 12:16:35 PM PDT, Peter Bishop <bishop_peterj at hotmail.com> wrote:
>> The feed is coming from a SQL table and this is using the embedded
>> support for R which comes with SQL 2016. The source is therefore a
>> SELECT statement.
>> 
>> 
>> As an aside, I found a workaround by changing the pattern from:
>> 
>> 
>> "[\x22\x27\x2c\x3f\x5c\x60]"
>> 
>> 
>> to:
>> 
>> 
>> "[\x22\x27\x2c\x3f\x5c\x5c\x60]"
>> 
>> 
>> This seems to be escaping the backslash in the R script rather than in
>> the data - which confuses me.
>> 
>> ________________________________
>> From: Bert Gunter <bgunter.4567 at gmail.com>
>> Sent: Wednesday, 26 August 2020 4:26 AM
>> To: Peter Bishop <bishop_peterj at hotmail.com>
>> Cc: r-help at r-project.org <r-help at r-project.org>
>> Subject: Re: [R] Matching backslash in a table's column using R
>> language
>> 
>> 1. I am far from an expert on such matters
>> 2. It is unclear to me what your input is -- I assume a file.
>> 
>> The problem, as you indicate, is that R's parser sees "\B" as an
>> incorrect escape character, so, for example:
>>> cat("\B")
>> Error: '\B' is an unrecognized escape in character string starting
>> ""\B"
>> 
>> In any case, I think you should look at ?scan. Here is an example where
>> I scan from the keyboard first and then remove the "\". You may have to
>> scan from a file to do this.
>> 
>>> z <-scan(file = "", what = "character")
>> 1: A\BCDEFG
>> 2:     #CR terminates input
>> Read 1 item
>> 
>>> cat(z)
>> A\BCDEFG
>> 
>>> nchar(z)
>> [1] 8  ## scan read in the "\" as a single character from the console.
>> 
>>> sub("\\\\","",z)  ## Yes, 4 backslashes
>> [1] "ABCDEFG"
>> 
>> There may be better ways to do this, but as I said, I'm no expert.
>> 
>> BTW, in posting here, please post in *plain text,* as the server can
>> mangle html.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Tue, Aug 25, 2020 at 9:02 AM Peter Bishop
>> <bishop_peterj at hotmail.com<mailto:bishop_peterj at hotmail.com>> wrote:
>> In SQL, I'm using R as a way to filter data based on:
>>   - 20 characters in the range <space> to <tilde>
>> - excluding <quote>, <apostrophe>, <comma>, <question mark>,
>> <backslash>, <backtick>
>> 
>> Given a SQL column containing the data:
>> 
>>   code
>>   ----
>>   A\BCDEFG
>> 
>> and the T-SQL script:
>> 
>>   EXEC [sys].[sp_execute_external_script]
>>           @language=N'R',
>>           @script=N'
>>   pattern1 = "^[\x20-\x7e]{1,20}$"
>>   pattern2 = "[\x22\x27\x2c\x3f\x5c\x60]"
>> 
>> outData <- subset(inData, grepl(pattern1, code, perl=TRUE) &
>> !grepl(pattern2, code, perl=TRUE))',
>>           @input_data_1 = N'SELECT [code] FROM [dbo].[products]',
>>           @input_data_1_name = N'inData',
>>           @output_data_1_name = N'outData'
>>   WITH
>>           RESULT SETS (AS OBJECT [dbo].[products]);
>>   GO
>> 
>> why does the row detailed above get returned? I know that backslash is
>> a special character but not in the SQL table. Consequently, the T-SQL
>> code:
>> 
>>   SELECT ASCII(SUBSTRING([value], 2, 1)) FROM [table]
>> 
>> returns 92 (the ASCII code for <backslash>) which shows that this is
>> being recognised as a backslash character and not as an escape
>> indicator for the following "B".
>> 
>> Can anyone advise how I can filter out the <backslash> in the way that
>> the other identified characters are being successfully filtered? As the
>> data is being retrieved from a table, I can?t ask the data provider to
>> use ?\\? instead of ?\? as that will be invalid for other uses.
>> 
>> Thanks.
>> 
>>       [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7C61b6372acf8c4d215faa08d8493093e1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339820268206663&amp;sdata=9t4wAFzYNfo%2B%2BITjORuSPUVNDtcSHm5hJN8yYGnEUnU%3D&amp;reserved=0<https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7C61b6372acf8c4d215faa08d8493093e1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339820268206663&amp;sdata=9t4wAFzYNfo%2B%2BITjORuSPUVNDtcSHm5hJN8yYGnEUnU%3D&amp;reserved=0>
>> PLEASE do read the posting guide
>> https://eur04.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7C61b6372acf8c4d215faa08d8493093e1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339820268206663&amp;sdata=UVGq0iXkHMdLFC2oL1l5WG730HW1fvEJPDFaiHS3a98%3D&amp;reserved=0<https://eur04.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7C61b6372acf8c4d215faa08d8493093e1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339820268206663&amp;sdata=UVGq0iXkHMdLFC2oL1l5WG730HW1fvEJPDFaiHS3a98%3D&amp;reserved=0>
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>    [[alternative HTML version deleted]]
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://eur04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7C61b6372acf8c4d215faa08d8493093e1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339820268206663&amp;sdata=9t4wAFzYNfo%2B%2BITjORuSPUVNDtcSHm5hJN8yYGnEUnU%3D&amp;reserved=0
> PLEASE do read the posting guide https://eur04.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7C61b6372acf8c4d215faa08d8493093e1%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637339820268206663&amp;sdata=UVGq0iXkHMdLFC2oL1l5WG730HW1fvEJPDFaiHS3a98%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.

From dz|147 @end|ng |rom p@u@edu  Mon Aug 24 12:52:07 2020
From: dz|147 @end|ng |rom p@u@edu (Lee, Deborah)
Date: Mon, 24 Aug 2020 10:52:07 +0000
Subject: [R] paran package - error message
Message-ID: <MN2PR02MB62549910CF8E20AE631965C996560@MN2PR02MB6254.namprd02.prod.outlook.com>

I am trying to using the "paran" package in R for Horn's parallel analysis. According to the "paran" manual, the highlighted yellow ought to be a numerical matrix or data frame. It looks like this should be the file name. Is there something that I need to do

install.packages("paran")
library(paran)

IS<- read.table ("C:/Users/Deborah Lee/Documents/R/IS.csv")
paran(IS, cfa=TRUE, graph=TRUE, color=TRUE, col=c("black", "red", "blue"))

When I run the code above, I get the error message below.
in cor(x) : 'x' must be numeric

How do I set up my data (csv) file itself to make this a numerical matrix? (FYI: row 1 for headers for variables names).

Thank you for your help.


Deborah D. Lee, PhD
Associate Director of Student Affairs Research and Assessment
The Pennsylvania State University

105 White Building
University Park, PA 16802
(814) 863-9609


	[[alternative HTML version deleted]]


From j@merk|e|n @end|ng |rom y@hoo@de  Mon Aug 24 15:06:57 2020
From: j@merk|e|n @end|ng |rom y@hoo@de (=?UTF-8?Q?Ja_M=C3=BCller?=)
Date: Mon, 24 Aug 2020 13:06:57 +0000 (UTC)
Subject: [R] How to write an interface function for bootstrapping with
 clusterboot() in R?
References: <1104337129.7894200.1598274417372.ref@mail.yahoo.com>
Message-ID: <1104337129.7894200.1598274417372@mail.yahoo.com>

Dear all,
I am trying to write an interface function (CBI function) in order to use the bootstrapping function clusterboot() together with the clustering algorithm kmodes(). See here:

https://www.rdocumentation.org/packages/fpc/versions/2.2-7/topics/clusterboot
kmodes function | R Documentation
Has anyone already written interface functions for clusterboot() and can assist me or send me some example code for other interface functions for clusterboot()?

Please find my code below:   
   - I use the built-in dataset USArrests for the purpose of this minimal reproducible code only, which yields the same error message as when I use my actual data set.
   - mykmodesCBI = The name of the interface function I wish to create.
   - kmodes_boot10 = The result of the clusterboot() function using the interface function mykmodesCBI
   - I am getting the error message 'Error in matrix(0, nrow = c1$nc, ncol = B) :non-numeric matrix extent'
I have not found any assistance online so far, this is why I now turn to the R-help mailing list. Thank you in advance, any help is much appreciated!Julia

#--------------------------------------------------------------beginning of code snippet------------------------------------------------------------------------
library("fpc")
library("cluster")

data(USArrests)
mydata_example <- USArrests %>%
  na.omit() %>%          
  scale()

mykmodesCBI <- function(data, k) {
  result = kmodes(data, modes=k, iter.max = 50, weighted = FALSE ); 
  nc = n_distinct( kmodes(data, modes=k, iter.max = 50, weighted = FALSE )$cluster ) ; 
  clusterlist=  list( as.vector(lapply( kmodes(data, modes=1, iter.max = 50, weighted = FALSE )$cluster,function(x) if(x==1) {TRUE} else {FALSE} )),
                      as.vector(lapply( kmodes(data, modes=2, iter.max = 50, weighted = FALSE )$cluster,function(x) if(x==2) {TRUE} else {FALSE} )),
                      as.vector(lapply( kmodes(data, modes=3, iter.max = 50, weighted = FALSE )$cluster,function(x) if(x==3) {TRUE} else {FALSE} )),
                      as.vector(lapply( kmodes(data, modes=4, iter.max = 50, weighted = FALSE )$cluster,function(x) if(x==5) {TRUE} else {FALSE} )),
                      as.vector(lapply( kmodes(data, modes=5, iter.max = 50, weighted = FALSE )$cluster,function(x) if(x==5) {TRUE} else {FALSE} )),
                      as.vector(lapply( kmodes(data, modes=6, iter.max = 50, weighted = FALSE )$cluster,function(x) if(x==6) {TRUE} else {FALSE} ))
                    )
  partition = as.vector(list( kmodes(data, modes=k, iter.max = 50, weighted = FALSE )$cluster )); 
  clustermethod = "kmodes"; 
  return( list( result, nc, clusterlist, partition, clustermethod ) )
}

kmodes_boot10 <- clusterboot(
    data=mydata_example,          
    B = 10,                    
    distances=FALSE,            
    bootmethod = "boot",       
    multipleboot = FALSE, 
    clustermethod = mykmodesCBI, 
    k = 6,   
    seed = 123,           
    datatomatrix=TRUE)               
kmodes_boot10#--------------------------------------------------------------end of code snippet------------------------------------------------------------------------



	[[alternative HTML version deleted]]


From |uy@g@rc|@ @end|ng |rom gm@||@com  Mon Aug 24 18:43:39 2020
From: |uy@g@rc|@ @end|ng |rom gm@||@com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Mon, 24 Aug 2020 13:43:39 -0300
Subject: [R] Help on plot from transition matrix
In-Reply-To: <CA+8X3fUsN6EkeK_ZDkeHVh2qwkD+T50B58Jmo=WQyAA_kB=3Rw@mail.gmail.com>
References: <CANxP2S7FS0cHy0fm6Z3O0WOtUptZ3W7+sU35RYmXpN=-3DsSzw@mail.gmail.com>
 <CA+8X3fUsN6EkeK_ZDkeHVh2qwkD+T50B58Jmo=WQyAA_kB=3Rw@mail.gmail.com>
Message-ID: <CANxP2S4KTdwQD8=JGH2M_TAaMpmorAVGvCk=X096Tm61-vhrZg@mail.gmail.com>

Thanks Jim,

I do not know what happened, I will try the question again.

Best

El lun., 24 ago. 2020 a las 5:47, Jim Lemon (<drjimlemon at gmail.com>)
escribi?:

> Hi Luis,
> As so often happens, the image didn't make it. Try PNG or PDF format.
> Without seeing what you want, it's only guessing.
>
> Jim
>
> On Mon, Aug 24, 2020 at 6:34 PM Luis Fernando Garc?a
> <luysgarcia at gmail.com> wrote:
> >
> > I am wanting to make a flow diagram like the one attached as an example
> for
> > the given dataset.
> >
> > The idea is to plot a flow diagramm using the probabilities given by a
> > transition matrix like the displayed in the example below. I have found
> > some tools like DiagrammeR which might work for this purpose, but it
> works
> > by introducing values manually. I wanted to know if there exists any
> > package able to plot automatically the flow diagram, given the transition
> > probabilities.
> >
> > Thanks in advance.
> >
> > #######
> >
> > library(TraMineR)
> >
> > h2a=c("Q-X-Q-Y-W-Z-P")
> >
> > h3a=c("Q-X-Q-Y-W-Z-P-Q-M-P-Q-A")
> >
> > h4a=c("Q-X-Q-X-Q-X-Q-Y-W-Z-C-B-Q-M-B-Q-A")
> >
> > h6a=c("Q-X-Q-X-Q-Y-W-Z-P-Q-P-Q-M-Q-A")
> >
> > h7a=c("Q-Y-W-Z-P-Q-B-Q-M-A")
> >
> > h8a=c("Q-Y-W-Z-P-B-Q-M-Q-A")
> >
> > h9a=c("Q-X-Q-W-Z-B-Q-A")
> >
> > h10a=c("Q-Y-W-Z-Q-A")
> >
> > h11a=c("Q-Y-W-Z-B-Q-P-B-Q-M-A")
> >
> > h12a=c("Q-W-Z-B-P-Q-A")
> >
> > h13a=c("Q-X-Q-Y-W-Z-P-Q-A")
> >
> > h14a=c("Q-X-B-X-Q-X-B-Q-X-Q-X-Q-Y-W-Z-B-P-B-Q-A")
> >
> > h15a=c("Q-X-Y-W-Z-B-P-Q-B-Q-A")
> >
> > h16a=c("Q-X-Q-B-Q-X-B-X-Q-Y-W-Z-P-B-Q-A")
> >
> > h17a=c("Q-X-Q-X-B-X-Q-W-Z-P-B-P-Q-A")
> >
> > h18a=c("Q-Y-W-Z-B-P-Q-B-Q-P-Q-M-B-P-A")
> >
> > h19a=c("Q-W-Z-B-P-Q-P-Q-M-Q-A")
> >
> >
> a=c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a)
> >
> > a
> >
> > library(TraMineR)
> >
> >
> i1=seqdef(c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a))
> >
> > seqtrate(i1)
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |uy@g@rc|@ @end|ng |rom gm@||@com  Mon Aug 24 18:55:26 2020
From: |uy@g@rc|@ @end|ng |rom gm@||@com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Mon, 24 Aug 2020 13:55:26 -0300
Subject: [R] Help on plot from transition matrix
Message-ID: <CANxP2S5dDeyhHjga7KoD3uzWmyaxA6G0vcHiw0j-gsOTN9gSWA@mail.gmail.com>

Dear all,

 I am wanting to make a flow diagram like the one attached as an example
for the given dataset (
https://drive.google.com/file/d/1CdtcJ5g6bp6jEoY7P6dKxO1mZWLEFZX7/view?usp=sharing
).

The idea is to plot a flow diagram using the probabilities given by a
transition matrix like the displayed in the example below. I have found
some tools like DiagrammeR which might work for this purpose, but it works
by introducing values manually. I wanted to know if there exists any
package able to plot automatically the flow diagram, given the transition
probabilities.

Thanks in advance.

#######

library(TraMineR)

h2a=c("Q-X-Q-Y-W-Z-P")

h3a=c("Q-X-Q-Y-W-Z-P-Q-M-P-Q-A")

h4a=c("Q-X-Q-X-Q-X-Q-Y-W-Z-C-B-Q-M-B-Q-A")

h6a=c("Q-X-Q-X-Q-Y-W-Z-P-Q-P-Q-M-Q-A")

h7a=c("Q-Y-W-Z-P-Q-B-Q-M-A")

h8a=c("Q-Y-W-Z-P-B-Q-M-Q-A")

h9a=c("Q-X-Q-W-Z-B-Q-A")

h10a=c("Q-Y-W-Z-Q-A")

h11a=c("Q-Y-W-Z-B-Q-P-B-Q-M-A")

h12a=c("Q-W-Z-B-P-Q-A")

h13a=c("Q-X-Q-Y-W-Z-P-Q-A")

h14a=c("Q-X-B-X-Q-X-B-Q-X-Q-X-Q-Y-W-Z-B-P-B-Q-A")

h15a=c("Q-X-Y-W-Z-B-P-Q-B-Q-A")

h16a=c("Q-X-Q-B-Q-X-B-X-Q-Y-W-Z-P-B-Q-A")

h17a=c("Q-X-Q-X-B-X-Q-W-Z-P-B-P-Q-A")

h18a=c("Q-Y-W-Z-B-P-Q-B-Q-P-Q-M-B-P-A")

h19a=c("Q-W-Z-B-P-Q-P-Q-M-Q-A")

a=c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a)

a

library(TraMineR)

i1=seqdef(c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a))

seqtrate(i1)

	[[alternative HTML version deleted]]


From ny@rkoer|c5 @end|ng |rom gm@||@com  Tue Aug 25 08:15:33 2020
From: ny@rkoer|c5 @end|ng |rom gm@||@com (Nyarko Eric)
Date: Mon, 24 Aug 2020 23:15:33 -0700
Subject: [R] Error computing mlogit model
Message-ID: <CA+1r2QSXmzSHQo9JXHzYCy8E2tGH6zSh-iwATMfQRrit44bazw@mail.gmail.com>

Hi



Please, I get this error message ?Error in data[theorder, ] : incorrect
number of dimensions? when I run the mlogit model presented below.



Best regards,

Eric





library(mlogit)

library(idefix)

idefix.data *<- *aggregate_design

idefix.data

des *<- *as.matrix(idefix.data[, 3*:*8], ncol = 6)

des

y *<- *idefix.data[, 9]

y



mlogit.data *<- *Datatrans(pkg = "mlogit", des = des, y = y,

n.alts = 2, n.sets = 8, n.resp = 7, bin = TRUE)



gh3aP <- mlogit(y ~ -1 + par.1 +par.2 +par.3 +par.4+ par.5 +par.6, data =
des)

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Aug 26 09:50:22 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 26 Aug 2020 07:50:22 +0000
Subject: [R] readxl question
In-Reply-To: <00df01d6783c$442f26c0$cc8d7440$@yahoo.com>
References: <00df01d6783c$442f26c0$cc8d7440$.ref@yahoo.com>
 <00df01d6783c$442f26c0$cc8d7440$@yahoo.com>
Message-ID: <f6a2cb5ef73b49728d7b668cfbbd7e6b@SRVEXCHCM1302.precheza.cz>

Hi


Are you sure that your command read values from respective cells?

I tried it and got empty data frame with names 
> WO <- lapply(files, read_excel, sheet=1, range=("B3")) 
> as.data.frame(WO)
[1] ano                 TP303               X96                
[4] X0                  X3.7519999999999998 X26.7              
<0 rows> (or 0-length row.names)

To get data, col_names argument should be set to FALSE
WO <- lapply(files, read_excel, sheet=1, range=("B3"), col_names=FALSE)
WO2 <- lapply(files, read_excel, sheet=1, range=("B5"), col_names=FALSE)

After that unlist and one rbind together with t should be enough to give you
one table
WO <- unlist(WO)
WO2 <- unlist(WO2)
result <- t(rbind(WO, WO2))
result
     WO      WO2       
...1 "ano"   "ano"     
...1 "TP303" "261119/2"
...1 "96"    "288"     
...1 "0"     "192"     
...1 "3.752" "25.92094"
...1 "26.7"  "38.6"    
>

And instead txt document you could do

write.table(result, "result.xls", sep = "\t", row.names = F)

And now "result.xls" is directly readable with Excel

Cheers
Petr

>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Thomas Subia via
> R-help
> Sent: Saturday, August 22, 2020 6:25 AM
> To: r-help at r-project.org
> Subject: [R] readxl question
> 
> Colleagues,
> 
> 
> 
> I have 250 Excel files in a directory. Each of those files has the same
layout.
> The problem is that the data in each Excel data is not in rectangular
form. I've
> been using readxl to extract the data which I need.
> Each of my metrics are stored in a particular cell. For each metric, I
create text
> files which stores my metrics.
> 
> 
> 
> library(plyr)
> 
> library(readxl)
> 
> 
> 
> files <- list.files(pattern="*.xls", full.names = FALSE)
> 
> 
> 
> # Extract Work Order
> 
> WO <- lapply(files, read_excel, sheet="Sheet1", range=("B9")) WO_list <-
> as.data.frame(WO) trans_WO <- t(WO_list) write.table(trans_WO ,"WO.txt")
> 
> 
> 
> # Extract bubble 14_1
> 
> BUBBLE_14_1 <- lapply(files, read_excel, sheet="Sheet1", range=("c46"))
> BUBBLE_14_1_list <- as.data.frame(BUBBLE_14_1)
> 
> trans_BUBBLE_14_1 <- t(BUBBLE_14_1_list)
> 
> 
> 
> write.table(trans_BUBBLE_14_1,"BUBBLE_14_1.txt")
> 
> 
> 
> 
> 
> # Extract bubble 14_2
> 
> BUBBLE_14_2 <- lapply(files, read_excel, sheet="Sheet1", range=("c62"))
> BUBBLE_14_2_list <- as.data.frame(BUBBLE_14_2)
> 
> trans_BUBBLE_14_2 <- t(BUBBLE_14_2_list)
> 
> write.table(trans_BUBBLE_14_2,"BUBBLE_14_2.txt")
> 
> 
> 
> After the text files have been created, I cut and paste the contents of
each
> text file to Excel.
> 
> This has worked fine if the number of cells I am extracting from a file is
small.
> 
> If the number gets larger, this method is inefficient.
> 
> 
> 
> Any advice on how to do this would be appreciated.
> 
> 
> 
> All the best,
> 
> 
> 
> Thomas Subia
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From petr@p|k@| @end|ng |rom prechez@@cz  Wed Aug 26 10:00:57 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 26 Aug 2020 08:00:57 +0000
Subject: [R] paran package - error message
In-Reply-To: <MN2PR02MB62549910CF8E20AE631965C996560@MN2PR02MB6254.namprd02.prod.outlook.com>
References: <MN2PR02MB62549910CF8E20AE631965C996560@MN2PR02MB6254.namprd02.prod.outlook.com>
Message-ID: <88a252c28dcd45a39f7d3660433ebad7@SRVEXCHCM1302.precheza.cz>

Hi

IS is data frame so it is not numeric.

try str(IS) to see structure of your data.
maybe just

mat.IS <- as.matrix(IS)

gives you desired result, but it depends on (undisclosed) IS structure

BTW, do not use html formatting, it is useless in this list

BTW2, you should spend at least few minutes to read basic docs, kindly
offered by R-core in doc directory, especially R-intro which gives you quick
info about objects and their properties.

BTW3, your read.table is lacking header and sep and maybe dec specification
so I doubt it reads your data properly.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Lee, Deborah
> Sent: Monday, August 24, 2020 12:52 PM
> To: r-help at r-project.org
> Subject: [R] paran package - error message
> 
> I am trying to using the "paran" package in R for Horn's parallel
analysis.
> According to the "paran" manual, the highlighted yellow ought to be a
> numerical matrix or data frame. It looks like this should be the file
name. Is
> there something that I need to do
> 
> install.packages("paran")
> library(paran)
> 
> IS<- read.table ("C:/Users/Deborah Lee/Documents/R/IS.csv") paran(IS,
> cfa=TRUE, graph=TRUE, color=TRUE, col=c("black", "red", "blue"))
> 
> When I run the code above, I get the error message below.
> in cor(x) : 'x' must be numeric
> 
> How do I set up my data (csv) file itself to make this a numerical matrix?
(FYI:
> row 1 for headers for variables names).
> 
> Thank you for your help.
> 
> 
> Deborah D. Lee, PhD
> Associate Director of Student Affairs Research and Assessment The
> Pennsylvania State University
> 
> 105 White Building
> University Park, PA 16802
> (814) 863-9609
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From dz|147 @end|ng |rom p@u@edu  Wed Aug 26 12:03:13 2020
From: dz|147 @end|ng |rom p@u@edu (Lee, Deborah)
Date: Wed, 26 Aug 2020 10:03:13 +0000
Subject: [R] paran package - error message
In-Reply-To: <88a252c28dcd45a39f7d3660433ebad7@SRVEXCHCM1302.precheza.cz>
References: <MN2PR02MB62549910CF8E20AE631965C996560@MN2PR02MB6254.namprd02.prod.outlook.com>
 <88a252c28dcd45a39f7d3660433ebad7@SRVEXCHCM1302.precheza.cz>
Message-ID: <MN2PR02MB625419B54A5C1CD2BE627DF796540@MN2PR02MB6254.namprd02.prod.outlook.com>

Thank you very much. I appreciate your help! 

Deborah D. Lee, PhD
Associate Director of Student Affairs Research and Assessment
The Pennsylvania State University

105 White?Building
University Park, PA 16802
(814) 863-9609

-----Original Message-----
From: PIKAL Petr <petr.pikal at precheza.cz> 
Sent: Wednesday, August 26, 2020 4:01 AM
To: Lee, Deborah <dzl147 at psu.edu>; r-help at r-project.org
Subject: RE: paran package - error message

Hi

IS is data frame so it is not numeric.

try str(IS) to see structure of your data.
maybe just

mat.IS <- as.matrix(IS)

gives you desired result, but it depends on (undisclosed) IS structure

BTW, do not use html formatting, it is useless in this list

BTW2, you should spend at least few minutes to read basic docs, kindly
offered by R-core in doc directory, especially R-intro which gives you quick
info about objects and their properties.

BTW3, your read.table is lacking header and sep and maybe dec specification
so I doubt it reads your data properly.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Lee, Deborah
> Sent: Monday, August 24, 2020 12:52 PM
> To: r-help at r-project.org
> Subject: [R] paran package - error message
> 
> I am trying to using the "paran" package in R for Horn's parallel
analysis.
> According to the "paran" manual, the highlighted yellow ought to be a
> numerical matrix or data frame. It looks like this should be the file
name. Is
> there something that I need to do
> 
> install.packages("paran")
> library(paran)
> 
> IS<- read.table ("C:/Users/Deborah Lee/Documents/R/IS.csv") paran(IS,
> cfa=TRUE, graph=TRUE, color=TRUE, col=c("black", "red", "blue"))
> 
> When I run the code above, I get the error message below.
> in cor(x) : 'x' must be numeric
> 
> How do I set up my data (csv) file itself to make this a numerical matrix?
(FYI:
> row 1 for headers for variables names).
> 
> Thank you for your help.
> 
> 
> Deborah D. Lee, PhD
> Associate Director of Student Affairs Research and Assessment The
> Pennsylvania State University
> 
> 105 White Building
> University Park, PA 16802
> (814) 863-9609
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 26 12:30:46 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 26 Aug 2020 20:30:46 +1000
Subject: [R] Help on plot from transition matrix
In-Reply-To: <CANxP2S5dDeyhHjga7KoD3uzWmyaxA6G0vcHiw0j-gsOTN9gSWA@mail.gmail.com>
References: <CANxP2S5dDeyhHjga7KoD3uzWmyaxA6G0vcHiw0j-gsOTN9gSWA@mail.gmail.com>
Message-ID: <CA+8X3fUUNbtc4SQHn2FpfKuwqSruY=TBHLe7pLOnZzg51Tic1w@mail.gmail.com>

Hi Luis,
I had a quick look at the "diagram" package, which seems to accept
transition matrices. I don't have it installed, but the help pages are
fairly easy to follow and may do the job for you.

Jim

On Wed, Aug 26, 2020 at 5:50 PM Luis Fernando Garc?a
<luysgarcia at gmail.com> wrote:
>
> Dear all,
>
>  I am wanting to make a flow diagram like the one attached as an example
> for the given dataset (
> https://drive.google.com/file/d/1CdtcJ5g6bp6jEoY7P6dKxO1mZWLEFZX7/view?usp=sharing
> ).
>
> The idea is to plot a flow diagram using the probabilities given by a
> transition matrix like the displayed in the example below. I have found
> some tools like DiagrammeR which might work for this purpose, but it works
> by introducing values manually. I wanted to know if there exists any
> package able to plot automatically the flow diagram, given the transition
> probabilities.
>
> Thanks in advance.
>
> #######
>
> library(TraMineR)
>
> h2a=c("Q-X-Q-Y-W-Z-P")
>
> h3a=c("Q-X-Q-Y-W-Z-P-Q-M-P-Q-A")
>
> h4a=c("Q-X-Q-X-Q-X-Q-Y-W-Z-C-B-Q-M-B-Q-A")
>
> h6a=c("Q-X-Q-X-Q-Y-W-Z-P-Q-P-Q-M-Q-A")
>
> h7a=c("Q-Y-W-Z-P-Q-B-Q-M-A")
>
> h8a=c("Q-Y-W-Z-P-B-Q-M-Q-A")
>
> h9a=c("Q-X-Q-W-Z-B-Q-A")
>
> h10a=c("Q-Y-W-Z-Q-A")
>
> h11a=c("Q-Y-W-Z-B-Q-P-B-Q-M-A")
>
> h12a=c("Q-W-Z-B-P-Q-A")
>
> h13a=c("Q-X-Q-Y-W-Z-P-Q-A")
>
> h14a=c("Q-X-B-X-Q-X-B-Q-X-Q-X-Q-Y-W-Z-B-P-B-Q-A")
>
> h15a=c("Q-X-Y-W-Z-B-P-Q-B-Q-A")
>
> h16a=c("Q-X-Q-B-Q-X-B-X-Q-Y-W-Z-P-B-Q-A")
>
> h17a=c("Q-X-Q-X-B-X-Q-W-Z-P-B-P-Q-A")
>
> h18a=c("Q-Y-W-Z-B-P-Q-B-Q-P-Q-M-B-P-A")
>
> h19a=c("Q-W-Z-B-P-Q-P-Q-M-Q-A")
>
> a=c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a)
>
> a
>
> library(TraMineR)
>
> i1=seqdef(c(h2a,h3a,h4a,h6a,h7a,h8a,h9a,h10a,h11a,h12a,h13a,h14a,h15a,h16a,h17a,h18a,h19a))
>
> seqtrate(i1)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 26 12:43:09 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 26 Aug 2020 20:43:09 +1000
Subject: [R] Error computing mlogit model
In-Reply-To: <CA+1r2QSXmzSHQo9JXHzYCy8E2tGH6zSh-iwATMfQRrit44bazw@mail.gmail.com>
References: <CA+1r2QSXmzSHQo9JXHzYCy8E2tGH6zSh-iwATMfQRrit44bazw@mail.gmail.com>
Message-ID: <CA+8X3fU+XhKQJ32dMGFYyqLzk5Ut07S8EYzLJiRDj2wPS8HtBw@mail.gmail.com>

Hi Eric,
There are a few mysteries in your request. As we don't know what "des"
is, it is difficult to see why it does not have the correct number of
dimensions. It looks like it should be an n x 6 matrix, but is that
what it really is and does the mlogit function expect such a matrix?

JIm

On Wed, Aug 26, 2020 at 6:09 PM Nyarko Eric <nyarkoeric5 at gmail.com> wrote:
>
> Hi
>
>
>
> Please, I get this error message ?Error in data[theorder, ] : incorrect
> number of dimensions? when I run the mlogit model presented below.
>
>
>
> Best regards,
>
> Eric
>
>
>
>
>
> library(mlogit)
>
> library(idefix)
>
> idefix.data *<- *aggregate_design
>
> idefix.data
>
> des *<- *as.matrix(idefix.data[, 3*:*8], ncol = 6)
>
> des
>
> y *<- *idefix.data[, 9]
>
> y
>
>
>
> mlogit.data *<- *Datatrans(pkg = "mlogit", des = des, y = y,
>
> n.alts = 2, n.sets = 8, n.resp = 7, bin = TRUE)
>
>
>
> gh3aP <- mlogit(y ~ -1 + par.1 +par.2 +par.3 +par.4+ par.5 +par.6, data =
> des)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Aug 26 13:06:13 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 26 Aug 2020 12:06:13 +0100
Subject: [R] paran package - error message
In-Reply-To: <88a252c28dcd45a39f7d3660433ebad7@SRVEXCHCM1302.precheza.cz>
References: <MN2PR02MB62549910CF8E20AE631965C996560@MN2PR02MB6254.namprd02.prod.outlook.com>
 <88a252c28dcd45a39f7d3660433ebad7@SRVEXCHCM1302.precheza.cz>
Message-ID: <f456e9ad-047a-0910-69de-e3d9ba803a1c@sapo.pt>

Hello,

Inline.

?s 09:00 de 26/08/20, PIKAL Petr escreveu:
> Hi
> 
> IS is data frame so it is not numeric.
> 
> try str(IS) to see structure of your data.
> maybe just
> 
> mat.IS <- as.matrix(IS)
> 
> gives you desired result, but it depends on (undisclosed) IS structure
> 
> BTW, do not use html formatting, it is useless in this list
> 
> BTW2, you should spend at least few minutes to read basic docs, kindly
> offered by R-core in doc directory, especially R-intro which gives you quick
> info about objects and their properties.
> 
> BTW3, your read.table is lacking header and sep and maybe dec specification
> so I doubt it reads your data properly.

Since the file is a csv file (or at least its extension is) read.csv 
should solve those issues.

To the OP: read.csv is a way to call read.table but deliberately made 
inflexible. It sets some arguments to values other than their defaults, 
including

header = TRUE
sep = ","
fill = TRUE

The default dec = "," is the same. If you are reading files coming from 
countries like mine where the decimal separator is a comma read.csv2 
sets the values sep = ";" and dec = ",".

Read help("read.csv"), the difference from read.table is well explained.


Hope this helps,

Rui Barradas
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Lee, Deborah
>> Sent: Monday, August 24, 2020 12:52 PM
>> To: r-help at r-project.org
>> Subject: [R] paran package - error message
>>
>> I am trying to using the "paran" package in R for Horn's parallel
> analysis.
>> According to the "paran" manual, the highlighted yellow ought to be a
>> numerical matrix or data frame. It looks like this should be the file
> name. Is
>> there something that I need to do
>>
>> install.packages("paran")
>> library(paran)
>>
>> IS<- read.table ("C:/Users/Deborah Lee/Documents/R/IS.csv") paran(IS,
>> cfa=TRUE, graph=TRUE, color=TRUE, col=c("black", "red", "blue"))
>>
>> When I run the code above, I get the error message below.
>> in cor(x) : 'x' must be numeric
>>
>> How do I set up my data (csv) file itself to make this a numerical matrix?
> (FYI:
>> row 1 for headers for variables names).
>>
>> Thank you for your help.
>>
>>
>> Deborah D. Lee, PhD
>> Associate Director of Student Affairs Research and Assessment The
>> Pennsylvania State University
>>
>> 105 White Building
>> University Park, PA 16802
>> (814) 863-9609
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @cupton @end|ng |rom np@@edu  Wed Aug 26 14:43:30 2020
From: @cupton @end|ng |rom np@@edu (Upton, Stephen (Steve) (CIV))
Date: Wed, 26 Aug 2020 12:43:30 +0000
Subject: [R] readxl question
In-Reply-To: <f6a2cb5ef73b49728d7b668cfbbd7e6b@SRVEXCHCM1302.precheza.cz>
References: <00df01d6783c$442f26c0$cc8d7440$.ref@yahoo.com>
 <00df01d6783c$442f26c0$cc8d7440$@yahoo.com>
 <f6a2cb5ef73b49728d7b668cfbbd7e6b@SRVEXCHCM1302.precheza.cz>
Message-ID: <BN8PR13MB270820C7B97253CF59831C4BAD540@BN8PR13MB2708.namprd13.prod.outlook.com>

>From your example, it appears you are reading in the same excel file for
each function to get a value. I would look at creating a function that
extracts what you need from each file all at once, rather than separate
reads.

Stephen C. Upton
SEED (Simulation Experiments & Efficient Designs) Center for Data Farming
SEED Center website:?https://harvest.nps.edu

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Wednesday, August 26, 2020 3:50 AM
To: Thomas Subia <tgs77m at yahoo.com>
Cc: r-help at r-project.org
Subject: Re: [R] readxl question

NPS WARNING: *external sender* verify before acting.


Hi


Are you sure that your command read values from respective cells?

I tried it and got empty data frame with names
> WO <- lapply(files, read_excel, sheet=1, range=("B3"))
> as.data.frame(WO)
[1] ano                 TP303               X96
[4] X0                  X3.7519999999999998 X26.7
<0 rows> (or 0-length row.names)

To get data, col_names argument should be set to FALSE WO <- lapply(files,
read_excel, sheet=1, range=("B3"), col_names=FALSE)
WO2 <- lapply(files, read_excel, sheet=1, range=("B5"), col_names=FALSE)

After that unlist and one rbind together with t should be enough to give you
one table WO <- unlist(WO)
WO2 <- unlist(WO2)
result <- t(rbind(WO, WO2))
result
     WO      WO2
...1 "ano"   "ano"
...1 "TP303" "261119/2"
...1 "96"    "288"
...1 "0"     "192"
...1 "3.752" "25.92094"
...1 "26.7"  "38.6"
>

And instead txt document you could do

write.table(result, "result.xls", sep = "\t", row.names = F)

And now "result.xls" is directly readable with Excel

Cheers
Petr

>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Thomas Subia 
> via R-help
> Sent: Saturday, August 22, 2020 6:25 AM
> To: r-help at r-project.org
> Subject: [R] readxl question
>
> Colleagues,
>
>
>
> I have 250 Excel files in a directory. Each of those files has the 
> same
layout.
> The problem is that the data in each Excel data is not in rectangular
form. I've
> been using readxl to extract the data which I need.
> Each of my metrics are stored in a particular cell. For each metric, I
create text
> files which stores my metrics.
>
>
>
> library(plyr)
>
> library(readxl)
>
>
>
> files <- list.files(pattern="*.xls", full.names = FALSE)
>
>
>
> # Extract Work Order
>
> WO <- lapply(files, read_excel, sheet="Sheet1", range=("B9")) WO_list 
> <-
> as.data.frame(WO) trans_WO <- t(WO_list) write.table(trans_WO 
> ,"WO.txt")
>
>
>
> # Extract bubble 14_1
>
> BUBBLE_14_1 <- lapply(files, read_excel, sheet="Sheet1", 
> range=("c46")) BUBBLE_14_1_list <- as.data.frame(BUBBLE_14_1)
>
> trans_BUBBLE_14_1 <- t(BUBBLE_14_1_list)
>
>
>
> write.table(trans_BUBBLE_14_1,"BUBBLE_14_1.txt")
>
>
>
>
>
> # Extract bubble 14_2
>
> BUBBLE_14_2 <- lapply(files, read_excel, sheet="Sheet1", 
> range=("c62")) BUBBLE_14_2_list <- as.data.frame(BUBBLE_14_2)
>
> trans_BUBBLE_14_2 <- t(BUBBLE_14_2_list)
>
> write.table(trans_BUBBLE_14_2,"BUBBLE_14_2.txt")
>
>
>
> After the text files have been created, I cut and paste the contents 
> of
each
> text file to Excel.
>
> This has worked fine if the number of cells I am extracting from a 
> file is
small.
>
> If the number gets larger, this method is inefficient.
>
>
>
> Any advice on how to do this would be appreciated.
>
>
>
> All the best,
>
>
>
> Thomas Subia
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html and provide commented, minimal, self-contained, 
> reproducible code.

From e@d@@dmehr @end|ng |rom gm@||@com  Wed Aug 26 10:57:36 2020
From: e@d@@dmehr @end|ng |rom gm@||@com (Elham Daadmehr)
Date: Wed, 26 Aug 2020 10:57:36 +0200
Subject: [R] Importing data using Foreign
Message-ID: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>

Hi all,

I have a simple problem. I get stuck in using the imported spss data (.sav)
using "read.spss".
I imported data (z) without any problem. After importing, the first column
doesn't contain any "NA". but when I choose a subset of it (like:
z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in the
first column).

The (.sav) file is the output of Compustat (WRDS).

It is terrible, I can't find the mistake.

Thank you in advance for your help,
Elham

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 26 15:31:22 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 26 Aug 2020 16:31:22 +0300
Subject: [R] Importing data using Foreign
In-Reply-To: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
Message-ID: <CAGgJW74nC4DO5fmujb5gnFib7yLxv1DjBL6T1s4=mQOr_6Xvvw@mail.gmail.com>

Hi Elham,
You are not giving us much to go on here.
Show us the commands that (a) confirm there are no NA's in the first column
of z
and (b) output a row of z that has an NA in the first column.
Here's how one might do this:
(a) sum(is.na(z[,1]))
(b) z[ match(TRUE, z[,8] %in% c("11","12","14")), ]

Eric


On Wed, Aug 26, 2020 at 3:56 PM Elham Daadmehr <e.daadmehr at gmail.com> wrote:

> Hi all,
>
> I have a simple problem. I get stuck in using the imported spss data (.sav)
> using "read.spss".
> I imported data (z) without any problem. After importing, the first column
> doesn't contain any "NA". but when I choose a subset of it (like:
> z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in the
> first column).
>
> The (.sav) file is the output of Compustat (WRDS).
>
> It is terrible, I can't find the mistake.
>
> Thank you in advance for your help,
> Elham
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Aug 26 15:38:29 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 26 Aug 2020 13:38:29 +0000
Subject: [R] readxl question
In-Reply-To: <BN8PR13MB270820C7B97253CF59831C4BAD540@BN8PR13MB2708.namprd13.prod.outlook.com>
References: <00df01d6783c$442f26c0$cc8d7440$.ref@yahoo.com>
 <00df01d6783c$442f26c0$cc8d7440$@yahoo.com>
 <f6a2cb5ef73b49728d7b668cfbbd7e6b@SRVEXCHCM1302.precheza.cz>
 <BN8PR13MB270820C7B97253CF59831C4BAD540@BN8PR13MB2708.namprd13.prod.outlook.com>
Message-ID: <234c3514164b4e9fada3ba2a3ebd5c20@SRVEXCHCM1302.precheza.cz>

Hi

As OP has only about 250 files and in read_excel you cannot specify several
ranges at once, reading those values separately and concatenating them
together in one step seems to be the most efficient way. One probably could
design such function, but time spent on the function performing the task
only once is probably bigger than performing 250*3 reads.

I see inefficiency in writing each column into separate text file and
coppying it back to Excel file.

Cheers
Petr

> -----Original Message-----
> From: Upton, Stephen (Steve) (CIV) <scupton at nps.edu>
> Sent: Wednesday, August 26, 2020 2:44 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; Thomas Subia <tgs77m at yahoo.com>
> Cc: r-help at r-project.org
> Subject: RE: [R] readxl question
> 
> From your example, it appears you are reading in the same excel file for
> each function to get a value. I would look at creating a function that
> extracts what you need from each file all at once, rather than separate
> reads.
> 
> Stephen C. Upton
> SEED (Simulation Experiments & Efficient Designs) Center for Data Farming
> SEED Center website:?https://harvest.nps.edu
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
> Sent: Wednesday, August 26, 2020 3:50 AM
> To: Thomas Subia <tgs77m at yahoo.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] readxl question
> 
> NPS WARNING: *external sender* verify before acting.
> 
> 
> Hi
> 
> 
> Are you sure that your command read values from respective cells?
> 
> I tried it and got empty data frame with names
> > WO <- lapply(files, read_excel, sheet=1, range=("B3"))
> > as.data.frame(WO)
> [1] ano                 TP303               X96
> [4] X0                  X3.7519999999999998 X26.7
> <0 rows> (or 0-length row.names)
> 
> To get data, col_names argument should be set to FALSE WO <- lapply(files,
> read_excel, sheet=1, range=("B3"), col_names=FALSE)
> WO2 <- lapply(files, read_excel, sheet=1, range=("B5"), col_names=FALSE)
> 
> After that unlist and one rbind together with t should be enough to give
you
> one table WO <- unlist(WO)
> WO2 <- unlist(WO2)
> result <- t(rbind(WO, WO2))
> result
>      WO      WO2
> ...1 "ano"   "ano"
> ...1 "TP303" "261119/2"
> ...1 "96"    "288"
> ...1 "0"     "192"
> ...1 "3.752" "25.92094"
> ...1 "26.7"  "38.6"
> >
> 
> And instead txt document you could do
> 
> write.table(result, "result.xls", sep = "\t", row.names = F)
> 
> And now "result.xls" is directly readable with Excel
> 
> Cheers
> Petr
> 
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Thomas Subia
> > via R-help
> > Sent: Saturday, August 22, 2020 6:25 AM
> > To: r-help at r-project.org
> > Subject: [R] readxl question
> >
> > Colleagues,
> >
> >
> >
> > I have 250 Excel files in a directory. Each of those files has the
> > same
> layout.
> > The problem is that the data in each Excel data is not in rectangular
> form. I've
> > been using readxl to extract the data which I need.
> > Each of my metrics are stored in a particular cell. For each metric, I
> create text
> > files which stores my metrics.
> >
> >
> >
> > library(plyr)
> >
> > library(readxl)
> >
> >
> >
> > files <- list.files(pattern="*.xls", full.names = FALSE)
> >
> >
> >
> > # Extract Work Order
> >
> > WO <- lapply(files, read_excel, sheet="Sheet1", range=("B9")) WO_list
> > <-
> > as.data.frame(WO) trans_WO <- t(WO_list) write.table(trans_WO
> > ,"WO.txt")
> >
> >
> >
> > # Extract bubble 14_1
> >
> > BUBBLE_14_1 <- lapply(files, read_excel, sheet="Sheet1",
> > range=("c46")) BUBBLE_14_1_list <- as.data.frame(BUBBLE_14_1)
> >
> > trans_BUBBLE_14_1 <- t(BUBBLE_14_1_list)
> >
> >
> >
> > write.table(trans_BUBBLE_14_1,"BUBBLE_14_1.txt")
> >
> >
> >
> >
> >
> > # Extract bubble 14_2
> >
> > BUBBLE_14_2 <- lapply(files, read_excel, sheet="Sheet1",
> > range=("c62")) BUBBLE_14_2_list <- as.data.frame(BUBBLE_14_2)
> >
> > trans_BUBBLE_14_2 <- t(BUBBLE_14_2_list)
> >
> > write.table(trans_BUBBLE_14_2,"BUBBLE_14_2.txt")
> >
> >
> >
> > After the text files have been created, I cut and paste the contents
> > of
> each
> > text file to Excel.
> >
> > This has worked fine if the number of cells I am extracting from a
> > file is
> small.
> >
> > If the number gets larger, this method is inefficient.
> >
> >
> >
> > Any advice on how to do this would be appreciated.
> >
> >
> >
> > All the best,
> >
> >
> >
> > Thomas Subia
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.

From pd@|gd @end|ng |rom gm@||@com  Wed Aug 26 16:51:00 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 26 Aug 2020 16:51:00 +0200
Subject: [R] Importing data using Foreign
In-Reply-To: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
Message-ID: <721738A2-6ED9-4678-9772-6D1AB2B8674B@gmail.com>

Offhand, I suspect that the NAs are in the 8th column.

> On 26 Aug 2020, at 10:57 , Elham Daadmehr <e.daadmehr at gmail.com> wrote:
> 
> Hi all,
> 
> I have a simple problem. I get stuck in using the imported spss data (.sav)
> using "read.spss".
> I imported data (z) without any problem. After importing, the first column
> doesn't contain any "NA". but when I choose a subset of it (like:
> z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in the
> first column).
> 
> The (.sav) file is the output of Compustat (WRDS).
> 
> It is terrible, I can't find the mistake.
> 
> Thank you in advance for your help,
> Elham
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 26 16:57:59 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 26 Aug 2020 17:57:59 +0300
Subject: [R] Importing data using Foreign
In-Reply-To: <721738A2-6ED9-4678-9772-6D1AB2B8674B@gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
 <721738A2-6ED9-4678-9772-6D1AB2B8674B@gmail.com>
Message-ID: <CAGgJW77Xr=GQNJOfRHM6_OahqZF8oVQGUp-arM_3eDYn52vXsw@mail.gmail.com>

Good point! :-)


On Wed, Aug 26, 2020 at 5:55 PM peter dalgaard <pdalgd at gmail.com> wrote:

> Offhand, I suspect that the NAs are in the 8th column.
>
> > On 26 Aug 2020, at 10:57 , Elham Daadmehr <e.daadmehr at gmail.com> wrote:
> >
> > Hi all,
> >
> > I have a simple problem. I get stuck in using the imported spss data
> (.sav)
> > using "read.spss".
> > I imported data (z) without any problem. After importing, the first
> column
> > doesn't contain any "NA". but when I choose a subset of it (like:
> > z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in the
> > first column).
> >
> > The (.sav) file is the output of Compustat (WRDS).
> >
> > It is terrible, I can't find the mistake.
> >
> > Thank you in advance for your help,
> > Elham
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 26 17:09:39 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 26 Aug 2020 18:09:39 +0300
Subject: [R] Importing data using Foreign
In-Reply-To: <CAL=F3iZc6DK03DvmvjYsOU2Xj8bbDLsGeXQbwip1YetknkQH+A@mail.gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
 <721738A2-6ED9-4678-9772-6D1AB2B8674B@gmail.com>
 <CAGgJW77Xr=GQNJOfRHM6_OahqZF8oVQGUp-arM_3eDYn52vXsw@mail.gmail.com>
 <CAL=F3iZc6DK03DvmvjYsOU2Xj8bbDLsGeXQbwip1YetknkQH+A@mail.gmail.com>
Message-ID: <CAGgJW77j2SODmLVjC_ht2rvcrzOuahVQcByFex2zHkeZ83ZG3w@mail.gmail.com>

c(1:3)[c(1,NA,3)]
[1] 1 NA 3


On Wed, Aug 26, 2020 at 6:06 PM Elham Daadmehr <e.daadmehr at gmail.com> wrote:

> Thanks guys. but I'm a bit confused. the input is the first column (z[,1]
> and z1[,1]).
> How is it possible that a subset of a non-NA vector, contains NA?
>
> On Wed, Aug 26, 2020 at 4:58 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> Good point! :-)
>>
>>
>> On Wed, Aug 26, 2020 at 5:55 PM peter dalgaard <pdalgd at gmail.com> wrote:
>>
>>> Offhand, I suspect that the NAs are in the 8th column.
>>>
>>> > On 26 Aug 2020, at 10:57 , Elham Daadmehr <e.daadmehr at gmail.com>
>>> wrote:
>>> >
>>> > Hi all,
>>> >
>>> > I have a simple problem. I get stuck in using the imported spss data
>>> (.sav)
>>> > using "read.spss".
>>> > I imported data (z) without any problem. After importing, the first
>>> column
>>> > doesn't contain any "NA". but when I choose a subset of it (like:
>>> > z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in
>>> the
>>> > first column).
>>> >
>>> > The (.sav) file is the output of Compustat (WRDS).
>>> >
>>> > It is terrible, I can't find the mistake.
>>> >
>>> > Thank you in advance for your help,
>>> > Elham
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Aug 26 18:03:01 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 26 Aug 2020 18:03:01 +0200
Subject: [R] Importing data using Foreign
In-Reply-To: <CAL=F3iZc6DK03DvmvjYsOU2Xj8bbDLsGeXQbwip1YetknkQH+A@mail.gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
 <721738A2-6ED9-4678-9772-6D1AB2B8674B@gmail.com>
 <CAGgJW77Xr=GQNJOfRHM6_OahqZF8oVQGUp-arM_3eDYn52vXsw@mail.gmail.com>
 <CAL=F3iZc6DK03DvmvjYsOU2Xj8bbDLsGeXQbwip1YetknkQH+A@mail.gmail.com>
Message-ID: <1EBEB6F3-C815-4414-92B0-75463805FC86@gmail.com>

It is because you don't know whether you want it or not. 

It is a bit more obvious with integer indexing, as in color[race]: if race is NA you don't know what color to put in, but the result should be the same length as race. 

With logical indices, the behaviour is a bit annoying, but ultimately follows from the coercion rules: You might think that you could treat NA as FALSE (& the subset() function does just that), but then you'd get the problem that x[NA] would differ from x[as.integer(NA)] because NA is of mode "logical", lowest in the coercion hierarchy.

-pd

> On 26 Aug 2020, at 17:06 , Elham Daadmehr <e.daadmehr at gmail.com> wrote:
> 
> Thanks guys. but I'm a bit confused. the input is the first column (z[,1] and z1[,1]).
> How is it possible that a subset of a non-NA vector, contains NA?
> 
> On Wed, Aug 26, 2020 at 4:58 PM Eric Berger <ericjberger at gmail.com> wrote:
> Good point! :-)
> 
> 
> On Wed, Aug 26, 2020 at 5:55 PM peter dalgaard <pdalgd at gmail.com> wrote:
> Offhand, I suspect that the NAs are in the 8th column.
> 
> > On 26 Aug 2020, at 10:57 , Elham Daadmehr <e.daadmehr at gmail.com> wrote:
> > 
> > Hi all,
> > 
> > I have a simple problem. I get stuck in using the imported spss data (.sav)
> > using "read.spss".
> > I imported data (z) without any problem. After importing, the first column
> > doesn't contain any "NA". but when I choose a subset of it (like:
> > z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in the
> > first column).
> > 
> > The (.sav) file is the output of Compustat (WRDS).
> > 
> > It is terrible, I can't find the mistake.
> > 
> > Thank you in advance for your help,
> > Elham
> > 
> >       [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From e@d@@dmehr @end|ng |rom gm@||@com  Wed Aug 26 16:27:42 2020
From: e@d@@dmehr @end|ng |rom gm@||@com (Elham Daadmehr)
Date: Wed, 26 Aug 2020 16:27:42 +0200
Subject: [R] Importing data using Foreign
In-Reply-To: <CAGgJW74nC4DO5fmujb5gnFib7yLxv1DjBL6T1s4=mQOr_6Xvvw@mail.gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
 <CAGgJW74nC4DO5fmujb5gnFib7yLxv1DjBL6T1s4=mQOr_6Xvvw@mail.gmail.com>
Message-ID: <CAL=F3iZMiuzhvirVPv8MsE3Os5h2PczPKvKdtu+K0anCsV6ZHg@mail.gmail.com>

Thanks for your reply.

You're right, here is what I did:

> library(foreign)

> sz201401=read.spss("/Users/e.daadmehr/Desktop/Term/LastLast/untitled
folder/2014/1.sav", to.data.frame=TRUE)

Warning message:

In read.spss("/Users/e.daadmehr/Desktop/Term/LastLast/untitled
folder/2014/1.sav",  :

  /Users/e.daadmehr/Desktop/Term/LastLast/untitled folder/2014/1.sav:
Compression bias (0) is not the usual value of 100

> z =sz201401

> is.list(z)

[1] TRUE

> z=as.data.frame(z)

> is.data.frame(z)

[1] TRUE

> z=z[,-c(10)]

> sum(is.na(z[,1]))

[1] 0

> z1=z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]

> sum(is.na(z1[,1]))

[1] 399


my file is not compressed.


Thank you in advance,

Elham



On Wed, Aug 26, 2020 at 3:31 PM Eric Berger <ericjberger at gmail.com> wrote:

> Hi Elham,
> You are not giving us much to go on here.
> Show us the commands that (a) confirm there are no NA's in the first
> column of z
> and (b) output a row of z that has an NA in the first column.
> Here's how one might do this:
> (a) sum(is.na(z[,1]))
> (b) z[ match(TRUE, z[,8] %in% c("11","12","14")), ]
>
> Eric
>
>
> On Wed, Aug 26, 2020 at 3:56 PM Elham Daadmehr <e.daadmehr at gmail.com>
> wrote:
>
>> Hi all,
>>
>> I have a simple problem. I get stuck in using the imported spss data
>> (.sav)
>> using "read.spss".
>> I imported data (z) without any problem. After importing, the first column
>> doesn't contain any "NA". but when I choose a subset of it (like:
>> z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in the
>> first column).
>>
>> The (.sav) file is the output of Compustat (WRDS).
>>
>> It is terrible, I can't find the mistake.
>>
>> Thank you in advance for your help,
>> Elham
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From e@d@@dmehr @end|ng |rom gm@||@com  Wed Aug 26 17:06:30 2020
From: e@d@@dmehr @end|ng |rom gm@||@com (Elham Daadmehr)
Date: Wed, 26 Aug 2020 17:06:30 +0200
Subject: [R] Importing data using Foreign
In-Reply-To: <CAGgJW77Xr=GQNJOfRHM6_OahqZF8oVQGUp-arM_3eDYn52vXsw@mail.gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
 <721738A2-6ED9-4678-9772-6D1AB2B8674B@gmail.com>
 <CAGgJW77Xr=GQNJOfRHM6_OahqZF8oVQGUp-arM_3eDYn52vXsw@mail.gmail.com>
Message-ID: <CAL=F3iZc6DK03DvmvjYsOU2Xj8bbDLsGeXQbwip1YetknkQH+A@mail.gmail.com>

Thanks guys. but I'm a bit confused. the input is the first column (z[,1]
and z1[,1]).
How is it possible that a subset of a non-NA vector, contains NA?

On Wed, Aug 26, 2020 at 4:58 PM Eric Berger <ericjberger at gmail.com> wrote:

> Good point! :-)
>
>
> On Wed, Aug 26, 2020 at 5:55 PM peter dalgaard <pdalgd at gmail.com> wrote:
>
>> Offhand, I suspect that the NAs are in the 8th column.
>>
>> > On 26 Aug 2020, at 10:57 , Elham Daadmehr <e.daadmehr at gmail.com> wrote:
>> >
>> > Hi all,
>> >
>> > I have a simple problem. I get stuck in using the imported spss data
>> (.sav)
>> > using "read.spss".
>> > I imported data (z) without any problem. After importing, the first
>> column
>> > doesn't contain any "NA". but when I choose a subset of it (like:
>> > z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in
>> the
>> > first column).
>> >
>> > The (.sav) file is the output of Compustat (WRDS).
>> >
>> > It is terrible, I can't find the mistake.
>> >
>> > Thank you in advance for your help,
>> > Elham
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From e@d@@dmehr @end|ng |rom gm@||@com  Wed Aug 26 18:16:10 2020
From: e@d@@dmehr @end|ng |rom gm@||@com (Elham Daadmehr)
Date: Wed, 26 Aug 2020 18:16:10 +0200
Subject: [R] Importing data using Foreign
In-Reply-To: <1EBEB6F3-C815-4414-92B0-75463805FC86@gmail.com>
References: <CAL=F3iZx9jqVsL4arMHnFx1vD3jHC2wST08gWZnPu60G5Z8abA@mail.gmail.com>
 <721738A2-6ED9-4678-9772-6D1AB2B8674B@gmail.com>
 <CAGgJW77Xr=GQNJOfRHM6_OahqZF8oVQGUp-arM_3eDYn52vXsw@mail.gmail.com>
 <CAL=F3iZc6DK03DvmvjYsOU2Xj8bbDLsGeXQbwip1YetknkQH+A@mail.gmail.com>
 <1EBEB6F3-C815-4414-92B0-75463805FC86@gmail.com>
Message-ID: <CAL=F3iZf-1BcOYUYscMEhKnPwVxuHvE5SPC39SmBOTqyjLkEvw@mail.gmail.com>

Thanks a lot. I?ve got it just now.

On Wed, Aug 26, 2020 at 6:03 PM peter dalgaard <pdalgd at gmail.com> wrote:

> It is because you don't know whether you want it or not.
>
> It is a bit more obvious with integer indexing, as in color[race]: if race
> is NA you don't know what color to put in, but the result should be the
> same length as race.
>
> With logical indices, the behaviour is a bit annoying, but ultimately
> follows from the coercion rules: You might think that you could treat NA as
> FALSE (& the subset() function does just that), but then you'd get the
> problem that x[NA] would differ from x[as.integer(NA)] because NA is of
> mode "logical", lowest in the coercion hierarchy.
>
> -pd
>
> > On 26 Aug 2020, at 17:06 , Elham Daadmehr <e.daadmehr at gmail.com> wrote:
> >
> > Thanks guys. but I'm a bit confused. the input is the first column
> (z[,1] and z1[,1]).
> > How is it possible that a subset of a non-NA vector, contains NA?
> >
> > On Wed, Aug 26, 2020 at 4:58 PM Eric Berger <ericjberger at gmail.com>
> wrote:
> > Good point! :-)
> >
> >
> > On Wed, Aug 26, 2020 at 5:55 PM peter dalgaard <pdalgd at gmail.com> wrote:
> > Offhand, I suspect that the NAs are in the 8th column.
> >
> > > On 26 Aug 2020, at 10:57 , Elham Daadmehr <e.daadmehr at gmail.com>
> wrote:
> > >
> > > Hi all,
> > >
> > > I have a simple problem. I get stuck in using the imported spss data
> (.sav)
> > > using "read.spss".
> > > I imported data (z) without any problem. After importing, the first
> column
> > > doesn't contain any "NA". but when I choose a subset of it (like:
> > > z[z[,8]=="11"|z[,8]=="12"|z[,8]=="14",]), lots of NA appears (even in
> the
> > > first column).
> > >
> > > The (.sav) file is the output of Compustat (WRDS).
> > >
> > > It is terrible, I can't find the mistake.
> > >
> > > Thank you in advance for your help,
> > > Elham
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From d@vidwk@tz m@iii@g oii gm@ii@com  Wed Aug 26 17:16:26 2020
From: d@vidwk@tz m@iii@g oii gm@ii@com (d@vidwk@tz m@iii@g oii gm@ii@com)
Date: Wed, 26 Aug 2020 08:16:26 -0700
Subject: [R] Export R outputs to SAS dataset
In-Reply-To: <b53ba279-a994-d456-e001-5ec9f78ba03d@gmail.com>
References: <CADGufDFon0OTOyW+EK9AyROqmdVyJHcGcBRY=PNScftOxkc6bQ@mail.gmail.com>
 <20200822160508.GA139810@posteo.no>
 <cc08de02-43cc-d17c-c422-6863b2b4f1bc@gmail.com>
 <CADGufDE5+mjxro54B73X5i_OYXEH9QQT7eTN2pPe1=tUTbegAw@mail.gmail.com>
 <b53ba279-a994-d456-e001-5ec9f78ba03d@gmail.com>
Message-ID: <CAL+5cuhJJD8cUSfmGfLL3OivLx2Jgb6HN_QH4MFKgxzsQihPLA@mail.gmail.com>

Daniel,

I have used this package with success:

https://cran.r-project.org/web/packages/SASxport/SASxport.pdf

On Mon, Aug 24, 2020 at 3:57 PM Daniel Nordlund <djnordlund at gmail.com>
wrote:

> It is still not clear to me (1) if you just want the printed output in
> your SAS list file, or (2) if you want the actual numerical results
> returned to SAS so that you can do more manipulation with the numbers.
>
> If (1) you can precede your R code with sink() to output to your SAS
> list file
>
>   #--------R libraries---------
> sink('path/to/your/listfile.lst', append=TRUE)
>   library(tidyverse)
>   library(MF)
>
> MFSubj(lesion ~ group, calflung)
> HLBoot(lesion ~ group,  calflung, compare = c("con", "vac"), b = 100,
>            B = 100, alpha = 0.05, hpd = TRUE, bca = FALSE,
>            return.boot = FALSE, trace.it <http://trace.it> = FALSE, seed
> = NULL)
>
> You will probably need to redirect your SAS list file to the same location
>     PROC PRINTTO file='path/to/your/listfile.lst' new;
>
>
> If (2), then you need to store the output from you function into
> variables that you can examine to see what you may want to import into
> SAS.  So, something like this in R
>
> mfsubj <- MFSubj(lesion ~ group, calflung)
> hlboot <- HLBoot(lesion ~ group,  calflung, compare = c("con", "vac"), b
> = 100,
>            B = 100, alpha = 0.05, hpd = TRUE, bca = FALSE,
>            return.boot = FALSE, trace.it = FALSE, seed = NULL)
> str(mfsubj)
> str(hlboot)
>
> After examining the output, you will know what variables/dataframes you
> want to import and you can use the functions provided by PROC IML for
> that purpose.  You will need to read the SAS documentation to understand
> how to do that.
>
> This is becoming off topic for R-Help, so let me end with suggesting you
> pursue this question either on SAScommunity or the SAS-L listserve.  You
> might also want to look into SAS Viya for running your R code. If you
> want to continue this off-list, I can try to help you more, but I will
> need to better understand what it is that you want to get back into SAS.
>
> Dan
>
>
> On 8/23/2020 6:46 AM, Jomy Jose wrote:
> >  Hi Daniel
> >
> > Thanks,please find the code and output
> >
> >  #--------R libraries---------
> >       library(tidyverse)
> >       library(MF)
> >
> >
> > MFSubj(lesion ~ group, calflung)
> > HLBoot(lesion ~ group,  calflung, compare = c("con", "vac"), b = 100,
> >           B = 100, alpha = 0.05, hpd = TRUE, bca = FALSE,
> >           return.boot = FALSE, trace.it <http://trace.it> = FALSE,
> > seed = NULL)
> >
> >
> > 10000 bootstrap samples
> > 95% confidence intervals
> > Comparing vac to con
> >
> >
> > Mitigated Fraction
> >
> >                 observed median  lower  upper
> > Equal Tailed        0.44 0.4464 0.1360 0.7024
> > Highest Density     0.44 0.4464 0.1456 0.7088
> >
> >
> > Hodges-Lehmann
> >
> >                 observed   median     lower    upper
> > Equal Tailed    -0.07335 -0.07125 -0.170425 -0.01480
> > Highest Density -0.07335 -0.07125 -0.156350 -0.00975
> >
> >
> > Quartile Differences (quartiles of vac - quartiles of con)
> >
> >      observed    median    lower     upper
> > Q25 -0.041500 -0.041300 -0.10340 -0.000905
> > Q50 -0.112525 -0.111175 -0.28115  0.019350
> > Q75 -0.168000 -0.170425 -0.38650  0.030000
> >
> >
> > Quartiles of con
> >     observed   median   lower   upper
> > Q25 0.054000 0.054000 0.01525 0.11275
> > Q50 0.139275 0.139275 0.06140 0.31000
> > Q75 0.315000 0.315000 0.17300 0.45250
> >
> >
> > Quartiles of vac
> >     observed  median   lower    upper
> > Q25  0.01250 0.01250 0.00125 0.026000
> > Q50  0.02675 0.02675 0.01665 0.144575
> > Q75  0.14700 0.14700 0.02810 0.292000
> >
> >
> > Best
> > Jose
> >
> > On Sun, Aug 23, 2020 at 2:44 AM Daniel Nordlund <djnordlund at gmail.com
> > <mailto:djnordlund at gmail.com>> wrote:
> >
> >     On 8/22/2020 9:05 AM, Rasmus Liland wrote:
> >     > On 2020-08-22 08:17 +0530, Jomy Jose wrote:
> >     > | Hi
> >     > | I was able to run R code via PROC IML
> >     > | in SAS,so is there any way to export
> >     > | the generated outputs to SAS datasets
> >     > | since the R outputs don't follow data
> >     > | frame structure.
> >     >
> >     > Dear Jomy,
> >     >
> >     > But perhaps you can take the outputs in
> >     > SAS and work on them inside from there?
> >     >
> >     > To export a data frame from R to SAS via
> >     > a file[1], you can use
> >     >
> >     >       foreign::write.foreign(..., package="SAS")
> >     >
> >     > But I have not tried it.
> >     >
> >     > I have used foreign::read.spss before,
> >     > hehe :-)
> >     >
> >     > I know R is also possible to call from
> >     > Julia, and the df appearing in Julia,
> >     > this sounds like it should be possible
> >     > SAS too[2], yes?
> >     >
> >     > Best,
> >     > Rasmus
> >     >
> >     > [1] https://www.statmethods.net/input/exportingdata.html
> >     <https://www.statmethods.net/input/exportingdata.html>
> >     > [2]
> >
> https://documentation.sas.com/?docsetId=imlug&docsetTarget=imlug_r_sect012.htm&docsetVersion=15.1&locale=en
> >     <
> https://documentation.sas.com/?docsetId=imlug&docsetTarget=imlug_r_sect012.htm&docsetVersion=15.1&locale=en
> >
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     <https://stat.ethz.ch/mailman/listinfo/r-help>
> >     > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     <http://www.R-project.org/posting-guide.html>
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
> >     Can you give a reproducible example of the R-code you are running and
> >     the R "output" you want to get back in SAS?  It is difficult from way
> >     over here to know if you are wanting numerical results like means or
> >     regression coefficients ... or if you just want printed output in
> >     your
> >     SAS log or listing.
> >
> >     Dan
> >
> >     --
> >     Daniel Nordlund
> >     Port Townsend, WA  USA
> >
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug 27 13:56:59 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 27 Aug 2020 13:56:59 +0200
Subject: [R] draw with plotrix
Message-ID: <CAMk+s2Rw2Vd67QqJGr-wacjXP2fYBHD-EP6x3PYf=H8CK7YeUg@mail.gmail.com>

Hello,
I have a dataframe as follows
```
x = c(rep("1000 pmol", 2), rep("100 pmol", 2), rep("10 pmol", 2),
rep("0 pmol", 2))
y = c(2.7642, 2.8192, 2.1976, 2.2816, 1.8929, 1.8883, 1.0051, 0.8561)
z = c(rep("Sample",6), rep("Control", 2))
Q = data.frame(x, y, z, stringsAsFactors = FALSE)
```
I am trying to use plotrix to draw y broke down by x and differentiate
the markers by z, but I get:
```
> brkdn.plot(
+   y, groups=x, obs=z,
+   data=Q, mct="mean", md="std.error",
+   stagger=NA, dispbar=TRUE,
+   type="p", pch=16,
+   main="Measurement",
+   xlab=expression(bold("Amount of probe")),
+   ylab=expression(bold("Optical density"))
+ )
Error in .subset2(x, i, exact = exact) : no such index at level 1

```
and similar with other combinations (`obs = x`...).
What is the correct syntax?
Thank you


-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug 27 14:16:09 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 27 Aug 2020 14:16:09 +0200
Subject: [R] plot factors with dots in R
Message-ID: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>

Hello,
I have a dataframe as follows:
```
x = c("0 pmol", "10 pmol", "100 pmol", "1000 pmol")
y = c(0.9306, 1.8906, 2.2396, 2.7917)
df = data.frame(x, y)

> str(df)
'data.frame': 4 obs. of  2 variables:
 $ x: chr  "0 pmol" "10 pmol" "100 pmol" "1000 pmol"
 $ y: num  0.931 1.891 2.24 2.792
```
I would like to visualize the data with the classic dots (pch=16) but:
```
> plot(df$y ~ df$x)
Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
2: In min(x) : no non-missing arguments to min; returning Inf
3: In max(x) : no non-missing arguments to max; returning -Inf
```
which is right because x is not numeric, so I took the factor:
```
plot(df$y ~ factor(df$x)) # gives bars instead of dots
plot(df$y ~ factor(df$x), pch = 16) # this also
```
I tried to convert directly the dataframe:
```
df$x = lapply(df$x, factor)
> str(df)
'data.frame': 4 obs. of  2 variables:
 $ x:List of 4
  ..$ : Factor w/ 1 level "0 pmol": 1
  ..$ : Factor w/ 1 level "10 pmol": 1
  ..$ : Factor w/ 1 level "100 pmol": 1
  ..$ : Factor w/ 1 level "1000 pmol": 1
 $ y: num  0.931 1.891 2.24 2.792

> plot(r$y ~ r$x, pch = 16)
Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
2: In min(x) : no non-missing arguments to min; returning Inf
3: In max(x) : no non-missing arguments to max; returning -Inf
```
If I try to pass the number of levels:
```
plot(df$y ~ factor(df$x, 1:4), pch = 16) # this draw a boxplot with
all data on level 1

> df$x = lapply(df$x, factor(1:4))
Error in match.fun(FUN) :
  'factor(1:4)' is not a function, character or symbol
```

Since the transformation has given only one level (1), my questions are:
How do I tell R to use a dot instead of a line?
What is the correct way of setting factors?


-- 
Best regards,
Luigi


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Aug 27 14:37:39 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 27 Aug 2020 12:37:39 +0000
Subject: [R] plot factors with dots in R
In-Reply-To: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
References: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
Message-ID: <e46f9458b2174e08adeb02b1f9f854a4@SRVEXCHCM1302.precheza.cz>

Hi.
It is probably somewhere in docs, but factors are actually numerics vith
labels. 

So with your original data frame

df$x <- factor(df$x)
plot(as.numeric(df$x), df$y)

gives you points. You need to set labels to x axis though.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, August 27, 2020 2:16 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] plot factors with dots in R
> 
> Hello,
> I have a dataframe as follows:
> ```
> x = c("0 pmol", "10 pmol", "100 pmol", "1000 pmol")
> y = c(0.9306, 1.8906, 2.2396, 2.7917)
> df = data.frame(x, y)
> 
> > str(df)
> 'data.frame': 4 obs. of  2 variables:
>  $ x: chr  "0 pmol" "10 pmol" "100 pmol" "1000 pmol"
>  $ y: num  0.931 1.891 2.24 2.792
> ```
> I would like to visualize the data with the classic dots (pch=16) but:
> ```
> > plot(df$y ~ df$x)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> which is right because x is not numeric, so I took the factor:
> ```
> plot(df$y ~ factor(df$x)) # gives bars instead of dots
> plot(df$y ~ factor(df$x), pch = 16) # this also
> ```
> I tried to convert directly the dataframe:
> ```
> df$x = lapply(df$x, factor)
> > str(df)
> 'data.frame': 4 obs. of  2 variables:
>  $ x:List of 4
>   ..$ : Factor w/ 1 level "0 pmol": 1
>   ..$ : Factor w/ 1 level "10 pmol": 1
>   ..$ : Factor w/ 1 level "100 pmol": 1
>   ..$ : Factor w/ 1 level "1000 pmol": 1
>  $ y: num  0.931 1.891 2.24 2.792
> 
> > plot(r$y ~ r$x, pch = 16)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> If I try to pass the number of levels:
> ```
> plot(df$y ~ factor(df$x, 1:4), pch = 16) # this draw a boxplot with
> all data on level 1
> 
> > df$x = lapply(df$x, factor(1:4))
> Error in match.fun(FUN) :
>   'factor(1:4)' is not a function, character or symbol
> ```
> 
> Since the transformation has given only one level (1), my questions are:
> How do I tell R to use a dot instead of a line?
> What is the correct way of setting factors?
> 
> 
> --
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drj|m|emon @end|ng |rom gm@||@com  Thu Aug 27 14:43:40 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 27 Aug 2020 22:43:40 +1000
Subject: [R] draw with plotrix
In-Reply-To: <CAMk+s2Rw2Vd67QqJGr-wacjXP2fYBHD-EP6x3PYf=H8CK7YeUg@mail.gmail.com>
References: <CAMk+s2Rw2Vd67QqJGr-wacjXP2fYBHD-EP6x3PYf=H8CK7YeUg@mail.gmail.com>
Message-ID: <CA+8X3fUq1W2+Bu-bqf4uuzCZx46xM19GVwGKDYp5DnCM1pPs=Q@mail.gmail.com>

Hi Luigi,
Try this:

brkdn.plot(y~x+z,data=Q)

Jim

On Thu, Aug 27, 2020 at 9:57 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have a dataframe as follows
> ```
> x = c(rep("1000 pmol", 2), rep("100 pmol", 2), rep("10 pmol", 2),
> rep("0 pmol", 2))
> y = c(2.7642, 2.8192, 2.1976, 2.2816, 1.8929, 1.8883, 1.0051, 0.8561)
> z = c(rep("Sample",6), rep("Control", 2))
> Q = data.frame(x, y, z, stringsAsFactors = FALSE)
> ```
> I am trying to use plotrix to draw y broke down by x and differentiate
> the markers by z, but I get:
> ```
> > brkdn.plot(
> +   y, groups=x, obs=z,
> +   data=Q, mct="mean", md="std.error",
> +   stagger=NA, dispbar=TRUE,
> +   type="p", pch=16,
> +   main="Measurement",
> +   xlab=expression(bold("Amount of probe")),
> +   ylab=expression(bold("Optical density"))
> + )
> Error in .subset2(x, i, exact = exact) : no such index at level 1
>
> ```
> and similar with other combinations (`obs = x`...).
> What is the correct syntax?
> Thank you
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug 27 14:46:02 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 27 Aug 2020 14:46:02 +0200
Subject: [R] plot factors with dots in R
In-Reply-To: <e46f9458b2174e08adeb02b1f9f854a4@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
 <e46f9458b2174e08adeb02b1f9f854a4@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMk+s2STbYqru4sHm6MPzQP568q2szYxG8mJ6p9JUqM6gmgwfQ@mail.gmail.com>

Thank you, better than before...

On Thu, Aug 27, 2020 at 2:37 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi.
> It is probably somewhere in docs, but factors are actually numerics vith
> labels.
>
> So with your original data frame
>
> df$x <- factor(df$x)
> plot(as.numeric(df$x), df$y)
>
> gives you points. You need to set labels to x axis though.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Thursday, August 27, 2020 2:16 PM
> > To: r-help <r-help at r-project.org>
> > Subject: [R] plot factors with dots in R
> >
> > Hello,
> > I have a dataframe as follows:
> > ```
> > x = c("0 pmol", "10 pmol", "100 pmol", "1000 pmol")
> > y = c(0.9306, 1.8906, 2.2396, 2.7917)
> > df = data.frame(x, y)
> >
> > > str(df)
> > 'data.frame': 4 obs. of  2 variables:
> >  $ x: chr  "0 pmol" "10 pmol" "100 pmol" "1000 pmol"
> >  $ y: num  0.931 1.891 2.24 2.792
> > ```
> > I would like to visualize the data with the classic dots (pch=16) but:
> > ```
> > > plot(df$y ~ df$x)
> > Error in plot.window(...) : need finite 'xlim' values
> > In addition: Warning messages:
> > 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> > 2: In min(x) : no non-missing arguments to min; returning Inf
> > 3: In max(x) : no non-missing arguments to max; returning -Inf
> > ```
> > which is right because x is not numeric, so I took the factor:
> > ```
> > plot(df$y ~ factor(df$x)) # gives bars instead of dots
> > plot(df$y ~ factor(df$x), pch = 16) # this also
> > ```
> > I tried to convert directly the dataframe:
> > ```
> > df$x = lapply(df$x, factor)
> > > str(df)
> > 'data.frame': 4 obs. of  2 variables:
> >  $ x:List of 4
> >   ..$ : Factor w/ 1 level "0 pmol": 1
> >   ..$ : Factor w/ 1 level "10 pmol": 1
> >   ..$ : Factor w/ 1 level "100 pmol": 1
> >   ..$ : Factor w/ 1 level "1000 pmol": 1
> >  $ y: num  0.931 1.891 2.24 2.792
> >
> > > plot(r$y ~ r$x, pch = 16)
> > Error in plot.window(...) : need finite 'xlim' values
> > In addition: Warning messages:
> > 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> > 2: In min(x) : no non-missing arguments to min; returning Inf
> > 3: In max(x) : no non-missing arguments to max; returning -Inf
> > ```
> > If I try to pass the number of levels:
> > ```
> > plot(df$y ~ factor(df$x, 1:4), pch = 16) # this draw a boxplot with
> > all data on level 1
> >
> > > df$x = lapply(df$x, factor(1:4))
> > Error in match.fun(FUN) :
> >   'factor(1:4)' is not a function, character or symbol
> > ```
> >
> > Since the transformation has given only one level (1), my questions are:
> > How do I tell R to use a dot instead of a line?
> > What is the correct way of setting factors?
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug 27 14:47:40 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 27 Aug 2020 14:47:40 +0200
Subject: [R] draw with plotrix
In-Reply-To: <CA+8X3fUq1W2+Bu-bqf4uuzCZx46xM19GVwGKDYp5DnCM1pPs=Q@mail.gmail.com>
References: <CAMk+s2Rw2Vd67QqJGr-wacjXP2fYBHD-EP6x3PYf=H8CK7YeUg@mail.gmail.com>
 <CA+8X3fUq1W2+Bu-bqf4uuzCZx46xM19GVwGKDYp5DnCM1pPs=Q@mail.gmail.com>
Message-ID: <CAMk+s2Q1nhh+3Kg2fnSmqURmU43xutFP8dNXNv0Tm8GRWBTqxA@mail.gmail.com>

exactly what I needed!
Thank you so much
Luigi

On Thu, Aug 27, 2020 at 2:43 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> Try this:
>
> brkdn.plot(y~x+z,data=Q)
>
> Jim
>
> On Thu, Aug 27, 2020 at 9:57 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have a dataframe as follows
> > ```
> > x = c(rep("1000 pmol", 2), rep("100 pmol", 2), rep("10 pmol", 2),
> > rep("0 pmol", 2))
> > y = c(2.7642, 2.8192, 2.1976, 2.2816, 1.8929, 1.8883, 1.0051, 0.8561)
> > z = c(rep("Sample",6), rep("Control", 2))
> > Q = data.frame(x, y, z, stringsAsFactors = FALSE)
> > ```
> > I am trying to use plotrix to draw y broke down by x and differentiate
> > the markers by z, but I get:
> > ```
> > > brkdn.plot(
> > +   y, groups=x, obs=z,
> > +   data=Q, mct="mean", md="std.error",
> > +   stagger=NA, dispbar=TRUE,
> > +   type="p", pch=16,
> > +   main="Measurement",
> > +   xlab=expression(bold("Amount of probe")),
> > +   ylab=expression(bold("Optical density"))
> > + )
> > Error in .subset2(x, i, exact = exact) : no such index at level 1
> >
> > ```
> > and similar with other combinations (`obs = x`...).
> > What is the correct syntax?
> > Thank you
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de  Thu Aug 27 17:33:27 2020
From: U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de (Ulrik Stervbo)
Date: Thu, 27 Aug 2020 17:33:27 +0200
Subject: [R] readxl question
In-Reply-To: <234c3514164b4e9fada3ba2a3ebd5c20@SRVEXCHCM1302.precheza.cz>
References: <00df01d6783c$442f26c0$cc8d7440$.ref@yahoo.com>
 <00df01d6783c$442f26c0$cc8d7440$@yahoo.com>
 <f6a2cb5ef73b49728d7b668cfbbd7e6b@SRVEXCHCM1302.precheza.cz>
 <BN8PR13MB270820C7B97253CF59831C4BAD540@BN8PR13MB2708.namprd13.prod.outlook.com>
 <234c3514164b4e9fada3ba2a3ebd5c20@SRVEXCHCM1302.precheza.cz>
Message-ID: <885b5a702a310a2e8483bacb4209679a@ruhr-uni-bochum.de>

Hi Thomas,

I am not familiar with the use of the range argument, but it seems to me 
that the cell value becomes the column name. This might be fine, but you 
might get into trouble if you have repeated cell values since 
as.data.frame() will fix these.

I am also not sure about what you want, but this seems to capture your 
example (reading the same cells in a number of files):

```
library(readxl)

# Create test set
path <- readxl_example("geometry.xls")

read_xls(path) # See the content

example_file1 <- tempfile(fileext = ".xls")
example_file2 <- tempfile(fileext = ".xls")

file.copy(path, example_file1, overwrite = TRUE)
file.copy(path, example_file2, overwrite = TRUE)

# Solve the problem using loops
files <- c(example_file1, example_file2)
ranges <- c("B4", "C5", "D6")

fr <- lapply(ranges, function(cur_range, files){
   x <- lapply(files, read_xls, sheet = 1, range = cur_range)
   t(as.data.frame(x))
}, files = files)

# Loop over fr and save content if needed
```

A couple of variations over the theme, where the cell content is 
accessed after reading the file. This will not work well if the data in 
the excel files does not start at A1, but if you can adjust for this it 
should work just fine

```
# Solution #2

# Read the whole excel file, and access just the column - row
# This will give really unexpected results if the data does not start in 
the
# cell A1 as is the case for geometry.xls. Also, it does not work with 
ranges
# spaning more than a single cell
files <- rep(readxl_example("datasets.xlsx"), 3)
ranges <- c("B4", "C5", "D6")

# Loop over the files to avoid re-reading
fr <- lapply(files, function(cur_file, ranges){
   df <- read_excel(cur_file, sheet = 1)
   x <- lapply(ranges, function(cur_range, df){
     cr <- cellranger::as.cell_addr(cur_range, strict = FALSE)
     df[cr$row, cr$col][[1]]
   }, df = df)
   as.data.frame(setNames(x, ranges))

}, ranges = ranges)

# Solution 3
# Like solution 2 but using purr

library(purrr)

files <- rep(readxl_example("datasets.xlsx"), 3)
ranges <- c("B4", "C5", "D6")

map_dfr(files, function(cur_file, ranges){
   map_dfc(ranges, function(cur_range, df){
     df <- read_excel(cur_file, sheet = 1)
     cr <- cellranger::as.cell_addr(cur_range, strict = FALSE)
     setNames(df[cr$row, cr$col], cur_range)
   }, df = df)

}, ranges = ranges)

# Solution 4
# Like solution 3, but with the addition of the file name and producing 
a single
# data.frame at the end

library(purrr)

path <- readxl_example("datasets.xls")
example_file1 <- tempfile(fileext = "_1.xls")
example_file2 <- tempfile(fileext = "_2.xls")
example_file3 <- tempfile(fileext = "_3.xls")

file.copy(path, example_file1, overwrite = TRUE)
file.copy(path, example_file2, overwrite = TRUE)
file.copy(path, example_file3, overwrite = TRUE)

files <- c(example_file1, example_file2, example_file3)

# Name the file paths with the file names. We can them make use of the 
.id
# argument to map_dfr()
files <- setNames(files, basename(files))
ranges <- c("B4", "C5", "D6")

map_dfr(files, function(cur_file, ranges){
   map_dfc(ranges, function(cur_range, df){
     df <- read_excel(cur_file, sheet = 1)
     cr <- cellranger::as.cell_addr(cur_range, strict = FALSE)
     setNames(df[cr$row, cr$col], cur_range)
   }, df = df)
}, ranges = ranges, .id = "filename")
```

HTH
Ulrik

On 2020-08-26 15:38, PIKAL Petr wrote:
> Hi
> 
> As OP has only about 250 files and in read_excel you cannot specify 
> several
> ranges at once, reading those values separately and concatenating them
> together in one step seems to be the most efficient way. One probably 
> could
> design such function, but time spent on the function performing the 
> task
> only once is probably bigger than performing 250*3 reads.
> 
> I see inefficiency in writing each column into separate text file and
> coppying it back to Excel file.
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: Upton, Stephen (Steve) (CIV) <scupton at nps.edu>
>> Sent: Wednesday, August 26, 2020 2:44 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>; Thomas Subia 
>> <tgs77m at yahoo.com>
>> Cc: r-help at r-project.org
>> Subject: RE: [R] readxl question
>> 
>> From your example, it appears you are reading in the same excel file 
>> for
>> each function to get a value. I would look at creating a function that
>> extracts what you need from each file all at once, rather than 
>> separate
>> reads.
>> 
>> Stephen C. Upton
>> SEED (Simulation Experiments & Efficient Designs) Center for Data 
>> Farming
>> SEED Center website:?https://harvest.nps.edu
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL 
>> Petr
>> Sent: Wednesday, August 26, 2020 3:50 AM
>> To: Thomas Subia <tgs77m at yahoo.com>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] readxl question
>> 
>> NPS WARNING: *external sender* verify before acting.
>> 
>> 
>> Hi
>> 
>> 
>> Are you sure that your command read values from respective cells?
>> 
>> I tried it and got empty data frame with names
>> > WO <- lapply(files, read_excel, sheet=1, range=("B3"))
>> > as.data.frame(WO)
>> [1] ano                 TP303               X96
>> [4] X0                  X3.7519999999999998 X26.7
>> <0 rows> (or 0-length row.names)
>> 
>> To get data, col_names argument should be set to FALSE WO <- 
>> lapply(files,
>> read_excel, sheet=1, range=("B3"), col_names=FALSE)
>> WO2 <- lapply(files, read_excel, sheet=1, range=("B5"), 
>> col_names=FALSE)
>> 
>> After that unlist and one rbind together with t should be enough to 
>> give
> you
>> one table WO <- unlist(WO)
>> WO2 <- unlist(WO2)
>> result <- t(rbind(WO, WO2))
>> result
>>      WO      WO2
>> ...1 "ano"   "ano"
>> ...1 "TP303" "261119/2"
>> ...1 "96"    "288"
>> ...1 "0"     "192"
>> ...1 "3.752" "25.92094"
>> ...1 "26.7"  "38.6"
>> >
>> 
>> And instead txt document you could do
>> 
>> write.table(result, "result.xls", sep = "\t", row.names = F)
>> 
>> And now "result.xls" is directly readable with Excel
>> 
>> Cheers
>> Petr
>> 
>> >
>> > -----Original Message-----
>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Thomas Subia
>> > via R-help
>> > Sent: Saturday, August 22, 2020 6:25 AM
>> > To: r-help at r-project.org
>> > Subject: [R] readxl question
>> >
>> > Colleagues,
>> >
>> >
>> >
>> > I have 250 Excel files in a directory. Each of those files has the
>> > same
>> layout.
>> > The problem is that the data in each Excel data is not in rectangular
>> form. I've
>> > been using readxl to extract the data which I need.
>> > Each of my metrics are stored in a particular cell. For each metric, I
>> create text
>> > files which stores my metrics.
>> >
>> >
>> >
>> > library(plyr)
>> >
>> > library(readxl)
>> >
>> >
>> >
>> > files <- list.files(pattern="*.xls", full.names = FALSE)
>> >
>> >
>> >
>> > # Extract Work Order
>> >
>> > WO <- lapply(files, read_excel, sheet="Sheet1", range=("B9")) WO_list
>> > <-
>> > as.data.frame(WO) trans_WO <- t(WO_list) write.table(trans_WO
>> > ,"WO.txt")
>> >
>> >
>> >
>> > # Extract bubble 14_1
>> >
>> > BUBBLE_14_1 <- lapply(files, read_excel, sheet="Sheet1",
>> > range=("c46")) BUBBLE_14_1_list <- as.data.frame(BUBBLE_14_1)
>> >
>> > trans_BUBBLE_14_1 <- t(BUBBLE_14_1_list)
>> >
>> >
>> >
>> > write.table(trans_BUBBLE_14_1,"BUBBLE_14_1.txt")
>> >
>> >
>> >
>> >
>> >
>> > # Extract bubble 14_2
>> >
>> > BUBBLE_14_2 <- lapply(files, read_excel, sheet="Sheet1",
>> > range=("c62")) BUBBLE_14_2_list <- as.data.frame(BUBBLE_14_2)
>> >
>> > trans_BUBBLE_14_2 <- t(BUBBLE_14_2_list)
>> >
>> > write.table(trans_BUBBLE_14_2,"BUBBLE_14_2.txt")
>> >
>> >
>> >
>> > After the text files have been created, I cut and paste the contents
>> > of
>> each
>> > text file to Excel.
>> >
>> > This has worked fine if the number of cells I am extracting from a
>> > file is
>> small.
>> >
>> > If the number gets larger, this method is inefficient.
>> >
>> >
>> >
>> > Any advice on how to do this would be appreciated.
>> >
>> >
>> >
>> > All the best,
>> >
>> >
>> >
>> > Thomas Subia
>> >
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html and provide commented, minimal, self-contained,
>> > reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de  Thu Aug 27 17:46:50 2020
From: U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de (Ulrik Stervbo)
Date: Thu, 27 Aug 2020 17:46:50 +0200
Subject: [R] readxl question
In-Reply-To: <885b5a702a310a2e8483bacb4209679a@ruhr-uni-bochum.de>
References: <00df01d6783c$442f26c0$cc8d7440$.ref@yahoo.com>
 <00df01d6783c$442f26c0$cc8d7440$@yahoo.com>
 <f6a2cb5ef73b49728d7b668cfbbd7e6b@SRVEXCHCM1302.precheza.cz>
 <BN8PR13MB270820C7B97253CF59831C4BAD540@BN8PR13MB2708.namprd13.prod.outlook.com>
 <234c3514164b4e9fada3ba2a3ebd5c20@SRVEXCHCM1302.precheza.cz>
 <885b5a702a310a2e8483bacb4209679a@ruhr-uni-bochum.de>
Message-ID: <ab3a9c69e293087d9c95be636c190a11@ruhr-uni-bochum.de>

I clearly didn't read well enough. As Petr pointed out, there is also 
the col_names argument.

```
# Solution 4a

map_dfr(files, function(cur_file, ranges){
   map_dfc(ranges, function(cur_range, df){
     read_excel(cur_file, sheet = 1, col_names = cur_range, range = 
cur_range)
   }, df = df)
}, ranges = ranges, .id = "filename")

```

On 2020-08-27 17:33, Ulrik Stervbo via R-help wrote:
> Hi Thomas,
> 
> I am not familiar with the use of the range argument, but it seems to
> me that the cell value becomes the column name. This might be fine,
> but you might get into trouble if you have repeated cell values since
> as.data.frame() will fix these.
> 
> I am also not sure about what you want, but this seems to capture your
> example (reading the same cells in a number of files):
> 
> ```
> library(readxl)
> 
> # Create test set
> path <- readxl_example("geometry.xls")
> 
> read_xls(path) # See the content
> 
> example_file1 <- tempfile(fileext = ".xls")
> example_file2 <- tempfile(fileext = ".xls")
> 
> file.copy(path, example_file1, overwrite = TRUE)
> file.copy(path, example_file2, overwrite = TRUE)
> 
> # Solve the problem using loops
> files <- c(example_file1, example_file2)
> ranges <- c("B4", "C5", "D6")
> 
> fr <- lapply(ranges, function(cur_range, files){
>   x <- lapply(files, read_xls, sheet = 1, range = cur_range)
>   t(as.data.frame(x))
> }, files = files)
> 
> # Loop over fr and save content if needed
> ```
> 
> A couple of variations over the theme, where the cell content is
> accessed after reading the file. This will not work well if the data
> in the excel files does not start at A1, but if you can adjust for
> this it should work just fine
> 
> ```
> # Solution #2
> 
> # Read the whole excel file, and access just the column - row
> # This will give really unexpected results if the data does not start 
> in the
> # cell A1 as is the case for geometry.xls. Also, it does not work with 
> ranges
> # spaning more than a single cell
> files <- rep(readxl_example("datasets.xlsx"), 3)
> ranges <- c("B4", "C5", "D6")
> 
> # Loop over the files to avoid re-reading
> fr <- lapply(files, function(cur_file, ranges){
>   df <- read_excel(cur_file, sheet = 1)
>   x <- lapply(ranges, function(cur_range, df){
>     cr <- cellranger::as.cell_addr(cur_range, strict = FALSE)
>     df[cr$row, cr$col][[1]]
>   }, df = df)
>   as.data.frame(setNames(x, ranges))
> 
> }, ranges = ranges)
> 
> # Solution 3
> # Like solution 2 but using purr
> 
> library(purrr)
> 
> files <- rep(readxl_example("datasets.xlsx"), 3)
> ranges <- c("B4", "C5", "D6")
> 
> map_dfr(files, function(cur_file, ranges){
>   map_dfc(ranges, function(cur_range, df){
>     df <- read_excel(cur_file, sheet = 1)
>     cr <- cellranger::as.cell_addr(cur_range, strict = FALSE)
>     setNames(df[cr$row, cr$col], cur_range)
>   }, df = df)
> 
> }, ranges = ranges)
> 
> # Solution 4
> # Like solution 3, but with the addition of the file name and producing 
> a single
> # data.frame at the end
> 
> library(purrr)
> 
> path <- readxl_example("datasets.xls")
> example_file1 <- tempfile(fileext = "_1.xls")
> example_file2 <- tempfile(fileext = "_2.xls")
> example_file3 <- tempfile(fileext = "_3.xls")
> 
> file.copy(path, example_file1, overwrite = TRUE)
> file.copy(path, example_file2, overwrite = TRUE)
> file.copy(path, example_file3, overwrite = TRUE)
> 
> files <- c(example_file1, example_file2, example_file3)
> 
> # Name the file paths with the file names. We can them make use of the 
> .id
> # argument to map_dfr()
> files <- setNames(files, basename(files))
> ranges <- c("B4", "C5", "D6")
> 
> map_dfr(files, function(cur_file, ranges){
>   map_dfc(ranges, function(cur_range, df){
>     df <- read_excel(cur_file, sheet = 1)
>     cr <- cellranger::as.cell_addr(cur_range, strict = FALSE)
>     setNames(df[cr$row, cr$col], cur_range)
>   }, df = df)
> }, ranges = ranges, .id = "filename")
> ```
> 
> HTH
> Ulrik
> 
> On 2020-08-26 15:38, PIKAL Petr wrote:
>> Hi
>> 
>> As OP has only about 250 files and in read_excel you cannot specify 
>> several
>> ranges at once, reading those values separately and concatenating them
>> together in one step seems to be the most efficient way. One probably 
>> could
>> design such function, but time spent on the function performing the 
>> task
>> only once is probably bigger than performing 250*3 reads.
>> 
>> I see inefficiency in writing each column into separate text file and
>> coppying it back to Excel file.
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: Upton, Stephen (Steve) (CIV) <scupton at nps.edu>
>>> Sent: Wednesday, August 26, 2020 2:44 PM
>>> To: PIKAL Petr <petr.pikal at precheza.cz>; Thomas Subia 
>>> <tgs77m at yahoo.com>
>>> Cc: r-help at r-project.org
>>> Subject: RE: [R] readxl question
>>> 
>>> From your example, it appears you are reading in the same excel file 
>>> for
>>> each function to get a value. I would look at creating a function 
>>> that
>>> extracts what you need from each file all at once, rather than 
>>> separate
>>> reads.
>>> 
>>> Stephen C. Upton
>>> SEED (Simulation Experiments & Efficient Designs) Center for Data 
>>> Farming
>>> SEED Center website:?https://harvest.nps.edu
>>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL 
>>> Petr
>>> Sent: Wednesday, August 26, 2020 3:50 AM
>>> To: Thomas Subia <tgs77m at yahoo.com>
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] readxl question
>>> 
>>> NPS WARNING: *external sender* verify before acting.
>>> 
>>> 
>>> Hi
>>> 
>>> 
>>> Are you sure that your command read values from respective cells?
>>> 
>>> I tried it and got empty data frame with names
>>> > WO <- lapply(files, read_excel, sheet=1, range=("B3"))
>>> > as.data.frame(WO)
>>> [1] ano                 TP303               X96
>>> [4] X0                  X3.7519999999999998 X26.7
>>> <0 rows> (or 0-length row.names)
>>> 
>>> To get data, col_names argument should be set to FALSE WO <- 
>>> lapply(files,
>>> read_excel, sheet=1, range=("B3"), col_names=FALSE)
>>> WO2 <- lapply(files, read_excel, sheet=1, range=("B5"), 
>>> col_names=FALSE)
>>> 
>>> After that unlist and one rbind together with t should be enough to 
>>> give
>> you
>>> one table WO <- unlist(WO)
>>> WO2 <- unlist(WO2)
>>> result <- t(rbind(WO, WO2))
>>> result
>>>      WO      WO2
>>> ...1 "ano"   "ano"
>>> ...1 "TP303" "261119/2"
>>> ...1 "96"    "288"
>>> ...1 "0"     "192"
>>> ...1 "3.752" "25.92094"
>>> ...1 "26.7"  "38.6"
>>> >
>>> 
>>> And instead txt document you could do
>>> 
>>> write.table(result, "result.xls", sep = "\t", row.names = F)
>>> 
>>> And now "result.xls" is directly readable with Excel
>>> 
>>> Cheers
>>> Petr
>>> 
>>> >
>>> > -----Original Message-----
>>> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Thomas Subia
>>> > via R-help
>>> > Sent: Saturday, August 22, 2020 6:25 AM
>>> > To: r-help at r-project.org
>>> > Subject: [R] readxl question
>>> >
>>> > Colleagues,
>>> >
>>> >
>>> >
>>> > I have 250 Excel files in a directory. Each of those files has the
>>> > same
>>> layout.
>>> > The problem is that the data in each Excel data is not in rectangular
>>> form. I've
>>> > been using readxl to extract the data which I need.
>>> > Each of my metrics are stored in a particular cell. For each metric, I
>>> create text
>>> > files which stores my metrics.
>>> >
>>> >
>>> >
>>> > library(plyr)
>>> >
>>> > library(readxl)
>>> >
>>> >
>>> >
>>> > files <- list.files(pattern="*.xls", full.names = FALSE)
>>> >
>>> >
>>> >
>>> > # Extract Work Order
>>> >
>>> > WO <- lapply(files, read_excel, sheet="Sheet1", range=("B9")) WO_list
>>> > <-
>>> > as.data.frame(WO) trans_WO <- t(WO_list) write.table(trans_WO
>>> > ,"WO.txt")
>>> >
>>> >
>>> >
>>> > # Extract bubble 14_1
>>> >
>>> > BUBBLE_14_1 <- lapply(files, read_excel, sheet="Sheet1",
>>> > range=("c46")) BUBBLE_14_1_list <- as.data.frame(BUBBLE_14_1)
>>> >
>>> > trans_BUBBLE_14_1 <- t(BUBBLE_14_1_list)
>>> >
>>> >
>>> >
>>> > write.table(trans_BUBBLE_14_1,"BUBBLE_14_1.txt")
>>> >
>>> >
>>> >
>>> >
>>> >
>>> > # Extract bubble 14_2
>>> >
>>> > BUBBLE_14_2 <- lapply(files, read_excel, sheet="Sheet1",
>>> > range=("c62")) BUBBLE_14_2_list <- as.data.frame(BUBBLE_14_2)
>>> >
>>> > trans_BUBBLE_14_2 <- t(BUBBLE_14_2_list)
>>> >
>>> > write.table(trans_BUBBLE_14_2,"BUBBLE_14_2.txt")
>>> >
>>> >
>>> >
>>> > After the text files have been created, I cut and paste the contents
>>> > of
>>> each
>>> > text file to Excel.
>>> >
>>> > This has worked fine if the number of cells I am extracting from a
>>> > file is
>>> small.
>>> >
>>> > If the number gets larger, this method is inefficient.
>>> >
>>> >
>>> >
>>> > Any advice on how to do this would be appreciated.
>>> >
>>> >
>>> >
>>> > All the best,
>>> >
>>> >
>>> >
>>> > Thomas Subia
>>> >
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>>> > guide.html and provide commented, minimal, self-contained,
>>> > reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 27 18:08:15 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 27 Aug 2020 17:08:15 +0100
Subject: [R] plot factors with dots in R
In-Reply-To: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
References: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
Message-ID: <0c56416b-2608-2bdb-0177-12b0c0183041@sapo.pt>

Hello,

The plots that you say give bars (or my equivalent version below) don't 
give bars, what they give are boxplots with just one value and the 
median Q1 and Q3 are all equal.

plot(y ~ factor(x), df, pch = 16)  # boxplot


Is the following what you are looking for?


plot(y ~ as.integer(factor(x)), df, pch = 16, xlab = "x", xaxt = "n")
axis(1, at = as.integer(factor(df$x)), labels = df$x)


Hope this helps,

Rui Barradas


?s 13:16 de 27/08/20, Luigi Marongiu escreveu:
> Hello,
> I have a dataframe as follows:
> ```
> x = c("0 pmol", "10 pmol", "100 pmol", "1000 pmol")
> y = c(0.9306, 1.8906, 2.2396, 2.7917)
> df = data.frame(x, y)
> 
>> str(df)
> 'data.frame': 4 obs. of  2 variables:
>   $ x: chr  "0 pmol" "10 pmol" "100 pmol" "1000 pmol"
>   $ y: num  0.931 1.891 2.24 2.792
> ```
> I would like to visualize the data with the classic dots (pch=16) but:
> ```
>> plot(df$y ~ df$x)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> which is right because x is not numeric, so I took the factor:
> ```
> plot(df$y ~ factor(df$x)) # gives bars instead of dots
> plot(df$y ~ factor(df$x), pch = 16) # this also
> ```
> I tried to convert directly the dataframe:
> ```
> df$x = lapply(df$x, factor)
>> str(df)
> 'data.frame': 4 obs. of  2 variables:
>   $ x:List of 4
>    ..$ : Factor w/ 1 level "0 pmol": 1
>    ..$ : Factor w/ 1 level "10 pmol": 1
>    ..$ : Factor w/ 1 level "100 pmol": 1
>    ..$ : Factor w/ 1 level "1000 pmol": 1
>   $ y: num  0.931 1.891 2.24 2.792
> 
>> plot(r$y ~ r$x, pch = 16)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> If I try to pass the number of levels:
> ```
> plot(df$y ~ factor(df$x, 1:4), pch = 16) # this draw a boxplot with
> all data on level 1
> 
>> df$x = lapply(df$x, factor(1:4))
> Error in match.fun(FUN) :
>    'factor(1:4)' is not a function, character or symbol
> ```
> 
> Since the transformation has given only one level (1), my questions are:
> How do I tell R to use a dot instead of a line?
> What is the correct way of setting factors?
> 
>


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug 28 02:15:05 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 28 Aug 2020 10:15:05 +1000
Subject: [R] plot factors with dots in R
In-Reply-To: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
References: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
Message-ID: <CA+8X3fXvOuqt6zXXdWPPhLsVnHDczMy_qsfGfXOM7rpy0GkAuQ@mail.gmail.com>

Hi Luigi,
Maybe just:

plot(as.numeric(factor(x,levels=x)),y,xaxt="n",
 main="Concentration by effect",
 xlab="Concentration",ylab="Effect")
axis(1,at=1:4,labels=x)

Jim

On Thu, Aug 27, 2020 at 10:16 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have a dataframe as follows:
> ```
> x = c("0 pmol", "10 pmol", "100 pmol", "1000 pmol")
> y = c(0.9306, 1.8906, 2.2396, 2.7917)
> df = data.frame(x, y)
>
> > str(df)
> 'data.frame': 4 obs. of  2 variables:
>  $ x: chr  "0 pmol" "10 pmol" "100 pmol" "1000 pmol"
>  $ y: num  0.931 1.891 2.24 2.792
> ```
> I would like to visualize the data with the classic dots (pch=16) but:
> ```
> > plot(df$y ~ df$x)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> which is right because x is not numeric, so I took the factor:
> ```
> plot(df$y ~ factor(df$x)) # gives bars instead of dots
> plot(df$y ~ factor(df$x), pch = 16) # this also
> ```
> I tried to convert directly the dataframe:
> ```
> df$x = lapply(df$x, factor)
> > str(df)
> 'data.frame': 4 obs. of  2 variables:
>  $ x:List of 4
>   ..$ : Factor w/ 1 level "0 pmol": 1
>   ..$ : Factor w/ 1 level "10 pmol": 1
>   ..$ : Factor w/ 1 level "100 pmol": 1
>   ..$ : Factor w/ 1 level "1000 pmol": 1
>  $ y: num  0.931 1.891 2.24 2.792
>
> > plot(r$y ~ r$x, pch = 16)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> If I try to pass the number of levels:
> ```
> plot(df$y ~ factor(df$x, 1:4), pch = 16) # this draw a boxplot with
> all data on level 1
>
> > df$x = lapply(df$x, factor(1:4))
> Error in match.fun(FUN) :
>   'factor(1:4)' is not a function, character or symbol
> ```
>
> Since the transformation has given only one level (1), my questions are:
> How do I tell R to use a dot instead of a line?
> What is the correct way of setting factors?
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@whct @end|ng |rom gm@||@com  Fri Aug 28 03:58:31 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Thu, 27 Aug 2020 20:58:31 -0500
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
Message-ID: <CAFyG=WM1ovXC2vJomyEZ4VKQMMYrwYk9aZxjjPJO6cO6pLMt2g@mail.gmail.com>

Thanks Peter for a very promising tip.

On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com> wrote:

> If you don't worry too much about an additive constant, then half the
> negative squared deviance residuals should do. (Not quite sure how weights
> factor in. Looks like they are accounted for.)
>
> -pd
>
> > On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
> >
> > Dear R-help,
> >
> > The function logLik can be used to obtain the maximum log-likelihood
> value
> > from a glm object. This is an aggregated value, a summation of individual
> > log-likelihood values. How do I obtain individual values? In the
> following
> > example, I would expect 9 numbers since the response has length 9. I
> could
> > write a function to compute the values, but there are lots of
> > family members in glm, and I am trying not to reinvent wheels. Thanks!
> >
> > counts <- c(18,17,15,20,10,20,25,13,12)
> >     outcome <- gl(3,1,9)
> >     treatment <- gl(3,3)
> >     data.frame(treatment, outcome, counts) # showing data
> >     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> >     (ll <- logLik(glm.D93))
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Fri Aug 28 09:02:28 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Fri, 28 Aug 2020 12:32:28 +0530
Subject: [R] plot factors with dots in R
In-Reply-To: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
References: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
Message-ID: <CADfFDC5ez=BSAKy0m8LOO0hPa6J_cHxJTOSPg-6rUrZ7PuaHjA@mail.gmail.com>

On Thu, Aug 27, 2020 at 5:46 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have a dataframe as follows:
> ```
> x = c("0 pmol", "10 pmol", "100 pmol", "1000 pmol")
> y = c(0.9306, 1.8906, 2.2396, 2.7917)
> df = data.frame(x, y)
>
> > str(df)
> 'data.frame': 4 obs. of  2 variables:
>  $ x: chr  "0 pmol" "10 pmol" "100 pmol" "1000 pmol"
>  $ y: num  0.931 1.891 2.24 2.792
> ```
> I would like to visualize the data with the classic dots (pch=16) but:

Perhaps this is a good starting point:

with(df, dotchart(y, labels = x, pch = 16))

-Deepayan

> ```
> > plot(df$y ~ df$x)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> which is right because x is not numeric, so I took the factor:
> ```
> plot(df$y ~ factor(df$x)) # gives bars instead of dots
> plot(df$y ~ factor(df$x), pch = 16) # this also
> ```
> I tried to convert directly the dataframe:
> ```
> df$x = lapply(df$x, factor)
> > str(df)
> 'data.frame': 4 obs. of  2 variables:
>  $ x:List of 4
>   ..$ : Factor w/ 1 level "0 pmol": 1
>   ..$ : Factor w/ 1 level "10 pmol": 1
>   ..$ : Factor w/ 1 level "100 pmol": 1
>   ..$ : Factor w/ 1 level "1000 pmol": 1
>  $ y: num  0.931 1.891 2.24 2.792
>
> > plot(r$y ~ r$x, pch = 16)
> Error in plot.window(...) : need finite 'xlim' values
> In addition: Warning messages:
> 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> 2: In min(x) : no non-missing arguments to min; returning Inf
> 3: In max(x) : no non-missing arguments to max; returning -Inf
> ```
> If I try to pass the number of levels:
> ```
> plot(df$y ~ factor(df$x, 1:4), pch = 16) # this draw a boxplot with
> all data on level 1
>
> > df$x = lapply(df$x, factor(1:4))
> Error in match.fun(FUN) :
>   'factor(1:4)' is not a function, character or symbol
> ```
>
> Since the transformation has given only one level (1), my questions are:
> How do I tell R to use a dot instead of a line?
> What is the correct way of setting factors?
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From herd_dog @end|ng |rom cox@net  Fri Aug 28 16:08:13 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Fri, 28 Aug 2020 07:08:13 -0700
Subject: [R] Would Like Some Advise
Message-ID: <1157A76A248944878C040D1FE0AE725C@OWNERPC>

I need a new computer.  have a friend who is convinced that I have an aura about me that just kills electronic devices.

Does anyone out there have an opinion about Windows vs. Linux?  

I?m retired so this is just for my own enjoyment but I?m crunching some large National Weather Service files and will move on to baseball data and a few other things.  I?d like some advise about how much RAM and stuff like that.  I understand there is something called zones of computer memory. Can someone direct me to a good source so I can learn more?   I really don?t understand stuff like this.  Does anyone think I need to upgrade my wifi?

Thanks,
Philip
	[[alternative HTML version deleted]]


From g@@@powe|| @end|ng |rom protonm@||@com  Fri Aug 28 16:45:12 2020
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg)
Date: Fri, 28 Aug 2020 14:45:12 +0000
Subject: [R] Would Like Some Advise
In-Reply-To: <1157A76A248944878C040D1FE0AE725C@OWNERPC>
References: <1157A76A248944878C040D1FE0AE725C@OWNERPC>
Message-ID: <ZIA2z5nbnDqR9Dkv3GQA8ivFNwMfy2JtZj6b9QrEZMuqJBDCs0Lp9gTHlLXefCFoEDiVNnVlmA0ZdvozYgWMi2U-jWc73pDXJIfZt9V9Hgo=@protonmail.com>

Phillip,

The primary differences between Windows and Linux:

Windows attempts to monetize most of what you do on your computer in the same way that Facebook, Google, and other Social Media sites go, but Microsoft goes one step further, and they use the OS to monetize Windows Users. Linux on the other hand, being open source does not. Linux Distributions are free, and there are many to choose from. My recommendation on Distributions would be either PCLINUXOS with the KDE Plasma 5 Desktop interface, or Kubuntu which is Ubuntu with a KDE Desktop (instead of a Gnome, XFCE, Enlightenment, or Cinnamon) Desktop. The KDE Desktop is much more refined compared to the others - IMO. So, in a nutshell - Windows monetizes you thru the OS, Linux does not.

Windows Pros:
-Much greater variety of commercial software available and easier to install
-Familiar interface
-Better for people who want to play games
-Will not lock up as easily if the computer runs out of memory

Windows Cons:
-Less Secure in the sense that more nefarious players target windows
-Cost (not free)
-Microsoft Monetizes users of the OS
-less control of what is installed on the machine (there are commercial apps in Windows that Microsoft makes it hard to remove - like xbox, and crap like that)
-commercial software is typically more polished - like Microsoft Office

Linux Pros:
-Free
-More Secure - fewer nefarious players targeting the OS
-Free software available thru repositories make it easy to install much of what you need to include an office suit that is good (Libre Office, among others)
-Satisfaction in having learned something new - kinda outside the box
-User has MUCH more control
-Just a better experience - IMO

Linux Cons:
-Some hardware is still difficult to get working with Linux, but not much anymore (CAC card readers for instance, or remote scanners, and sometimes printers)
-Linux OS can lock up if a program consumes all of the physical memory... thought it'll usually recover once the application craps out (like R - had this happen many times before I built a new computer with 128GB) 

-Linux is poor at memory management when a swap file becomes necessary (yes, it is true - sorry)


I prefer Linux, but because I have a work computer issued to me that runs Windows - I still use it. If it were not for that, I would not. I run Linux (PCLINUXOS 64 bit with KDE) on all my home computers, but can still dual boot into windows when I need to.

As for R - it runs fine on either.

As for memory - get 128GB, and you won't have to look back and worry... that is if you think there is even a remote possibility that you'll need more than 64 GB - which is likely if you are using R to process weather data.

r/
Gregg
AZ









??????? Original Message ???????
On Friday, August 28, 2020 7:08 AM, Philip <herd_dog at cox.net> wrote:

> I need a new computer. have a friend who is convinced that I have an aura about me that just kills electronic devices.
> 

> Does anyone out there have an opinion about Windows vs. Linux?
> 

> I?m retired so this is just for my own enjoyment but I?m crunching some large National Weather Service files and will move on to baseball data and a few other things. I?d like some advise about how much RAM and stuff like that. I understand there is something called zones of computer memory. Can someone direct me to a good source so I can learn more? I really don?t understand stuff like this. Does anyone think I need to upgrade my wifi?
> 

> Thanks,
> Philip
> [[alternative HTML version deleted]]
> 

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 509 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200828/15c63d86/attachment.sig>

From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Fri Aug 28 16:51:41 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Fri, 28 Aug 2020 14:51:41 +0000
Subject: [R] how to create a sequence to consecutive values
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809EA1CB@ESINO.regionemarche.intra>

Dear R-list users,
this is a simple question, I have not been able to find an efficient solution.
Given a vector with only 0 or 1 values, I need to give a sequence to the consecutive values of 1:

a <- c(0,0,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,0,0)

I should get as result

(0,0,0,1,1,1,1,0,0,0,0,2,2,0,3,3,3,0,0)

I tried with ave, but no way to get it for me.

Thank you for your help
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 28 17:14:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 28 Aug 2020 08:14:04 -0700
Subject: [R] how to create a sequence to consecutive values
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809EA1CB@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809EA1CB@ESINO.regionemarche.intra>
Message-ID: <CAGxFJbSkaNvrV8r86ne-DNQeu5N3Xa2Mp10dYv6G=r-_NK=RCw@mail.gmail.com>

Using ?rle

> z <- rle(a)
> v <- z$values
> v[v==1] <- seq_along(v[v==1]) ## or use cumsum
< rep(v,z$lengths)
 [1] 0 0 0 1 1 1 1 0 0 0 0 2 2 0 3 3 3 0 0

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 28, 2020 at 7:52 AM Stefano Sofia <
stefano.sofia at regione.marche.it> wrote:

> Dear R-list users,
> this is a simple question, I have not been able to find an efficient
> solution.
> Given a vector with only 0 or 1 values, I need to give a sequence to the
> consecutive values of 1:
>
> a <- c(0,0,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,0,0)
>
> I should get as result
>
> (0,0,0,1,1,1,1,0,0,0,0,2,2,0,3,3,3,0,0)
>
> I tried with ave, but no way to get it for me.
>
> Thank you for your help
> Stefano
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Fri Aug 28 17:19:41 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Fri, 28 Aug 2020 15:19:41 +0000
Subject: [R] how to create a sequence to consecutive values
In-Reply-To: <CAGxFJbSkaNvrV8r86ne-DNQeu5N3Xa2Mp10dYv6G=r-_NK=RCw@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F809EA1CB@ESINO.regionemarche.intra>,
 <CAGxFJbSkaNvrV8r86ne-DNQeu5N3Xa2Mp10dYv6G=r-_NK=RCw@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809EA1E2@ESINO.regionemarche.intra>

Thank you!
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------
________________________________
Da: Bert Gunter [bgunter.4567 at gmail.com]
Inviato: venerd? 28 agosto 2020 17.14
A: Stefano Sofia
Cc: r-help mailing list
Oggetto: Re: [R] how to create a sequence to consecutive values

Using ?rle

> z <- rle(a)
> v <- z$values
> v[v==1] <- seq_along(v[v==1]) ## or use cumsum
< rep(v,z$lengths)
 [1] 0 0 0 1 1 1 1 0 0 0 0 2 2 0 3 3 3 0 0

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 28, 2020 at 7:52 AM Stefano Sofia <stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>> wrote:
Dear R-list users,
this is a simple question, I have not been able to find an efficient solution.
Given a vector with only 0 or 1 values, I need to give a sequence to the consecutive values of 1:

a <- c(0,0,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,0,0)

I should get as result

(0,0,0,1,1,1,1,0,0,0,0,2,2,0,3,3,3,0,0)

I tried with ave, but no way to get it for me.

Thank you for your help
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y>
and provide commented, minimal, self-contained, reproducible code.

--
Questo messaggio ? stato analizzato con Libra ESVA ed ? risultato non infetto

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From j@whct @end|ng |rom gm@||@com  Fri Aug 28 17:32:49 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Fri, 28 Aug 2020 10:32:49 -0500
Subject: [R] Passing formula and weights error
Message-ID: <CAFyG=WP1z9NYNOLSe3gbNbE1ye_qHRqTWB3c9yW_FNubC2RcKA@mail.gmail.com>

Dear R-help:

I am writing a function based on glm and would like some variations of
weights. In the code below, I couldn't understand why the second glm
function fails and don't know how to fix it:

Error in eval(extras, data, env) : object 'newweights' not found
 Calls: print ... eval -> <Anonymous> -> model.frame.default -> eval -> eval
 Execution halted

### R code
y <- rnorm(100)
 x <- rnorm(100)
 data <- data.frame(cbind(x, y))
 weights <- rep(1, 100)
 n <- 100
 myglm <- function(formula, data, weights){
     ## this works
     print(glm(formula, data, family=gaussian(), weights))
     ## this is not working
     newweights <- rep(1, n)
     glm(formula, data, family=gaussian(), weights=newweights)
 }
 myglm(y~., data, weights)

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 28 17:48:16 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 28 Aug 2020 08:48:16 -0700
Subject: [R] how to create a sequence to consecutive values
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809EA1E2@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809EA1CB@ESINO.regionemarche.intra>,
 <CAGxFJbSkaNvrV8r86ne-DNQeu5N3Xa2Mp10dYv6G=r-_NK=RCw@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4F809EA1E2@ESINO.regionemarche.intra>
Message-ID: <CC8AB8DB-1842-495C-A7D1-C0C010EC39FA@dcn.davis.ca.us>

cumsum is a bit faster...

a <- c( 0, 0, 0, 1, 1, 1, 1, 0, 0, 0
      , 0, 1, 1, 0, 1, 1, 1, 0
      )

f1 <- function(a) {
  z <- rle(a)
  v <- z$values
  v[v==1] <- seq_along(v[v==1]) ## or use cumsum
  rep(v,z$lengths)
}

f2 <- function(a) {
  v <- cumsum( c( a[1], 1==diff(a) ) )
  v[ 0==a ] <- 0
  v
}

f2(a)

library(microbenchmark)

a2 <- rep( c( 0,0, 1, 1, 1 )
         , 300 )

microbenchmark( res1 <- f1(a2)
              , res2 <- f2(a2)
              )
stopifnot( res1 == res2 )


On August 28, 2020 8:19:41 AM PDT, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
>Thank you!
>Stefano
>
>         (oo)
>--oOO--( )--OOo----------------
>Stefano Sofia PhD
>Civil Protection - Marche Region
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona
>Uff: 071 806 7743
>E-mail: stefano.sofia at regione.marche.it
>---Oo---------oO----------------
>________________________________
>Da: Bert Gunter [bgunter.4567 at gmail.com]
>Inviato: venerd? 28 agosto 2020 17.14
>A: Stefano Sofia
>Cc: r-help mailing list
>Oggetto: Re: [R] how to create a sequence to consecutive values
>
>Using ?rle
>
>> z <- rle(a)
>> v <- z$values
>> v[v==1] <- seq_along(v[v==1]) ## or use cumsum
>< rep(v,z$lengths)
> [1] 0 0 0 1 1 1 1 0 0 0 0 2 2 0 3 3 3 0 0
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Fri, Aug 28, 2020 at 7:52 AM Stefano Sofia
><stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>>
>wrote:
>Dear R-list users,
>this is a simple question, I have not been able to find an efficient
>solution.
>Given a vector with only 0 or 1 values, I need to give a sequence to
>the consecutive values of 1:
>
>a <- c(0,0,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,0,0)
>
>I should get as result
>
>(0,0,0,1,1,1,1,0,0,0,0,2,2,0,3,3,3,0,0)
>
>I tried with ave, but no way to get it for me.
>
>Thank you for your help
>Stefano
>
>         (oo)
>--oOO--( )--OOo----------------
>Stefano Sofia PhD
>Civil Protection - Marche Region
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona
>Uff: 071 806 7743
>E-mail:
>stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>
>---Oo---------oO----------------
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate alla ricezione. I messaggi di posta elettronica per i
>client di Regione Marche possono contenere informazioni confidenziali e
>con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>
>--
>Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>This message was scanned by Libra ESVA and is believed to be clean.
>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y>
>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Questo messaggio ? stato analizzato con Libra ESVA ed ? risultato non
>infetto
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate alla ricezione. I messaggi di posta elettronica per i
>client di Regione Marche possono contenere informazioni confidenziali e
>con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>
>-->
>Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.>
>This message was scanned by Libra ESVA and is believed to be clean.
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 28 18:07:19 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 28 Aug 2020 09:07:19 -0700
Subject: [R] how to create a sequence to consecutive values
In-Reply-To: <CC8AB8DB-1842-495C-A7D1-C0C010EC39FA@dcn.davis.ca.us>
References: <8B435C9568170B469AE31E8891E8CC4F809EA1CB@ESINO.regionemarche.intra>
 <CAGxFJbSkaNvrV8r86ne-DNQeu5N3Xa2Mp10dYv6G=r-_NK=RCw@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4F809EA1E2@ESINO.regionemarche.intra>
 <CC8AB8DB-1842-495C-A7D1-C0C010EC39FA@dcn.davis.ca.us>
Message-ID: <CAGxFJbTmusOvsQDFzkq5T_q9HzY7nR=1O1GkDEu=q35TgY1q7g@mail.gmail.com>

Actually, I prefer Jeff's use of diff() . Hadn't thought of that.

However, note that, unsurprisingly,  NA's mess up both: The rle() method
fails with an error and the diff() method gives the wrong answer.

Cheers,
Bert


On Fri, Aug 28, 2020 at 8:48 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> cumsum is a bit faster...
>
> a <- c( 0, 0, 0, 1, 1, 1, 1, 0, 0, 0
>       , 0, 1, 1, 0, 1, 1, 1, 0
>       )
>
> f1 <- function(a) {
>   z <- rle(a)
>   v <- z$values
>   v[v==1] <- seq_along(v[v==1]) ## or use cumsum
>   rep(v,z$lengths)
> }
>
> f2 <- function(a) {
>   v <- cumsum( c( a[1], 1==diff(a) ) )
>   v[ 0==a ] <- 0
>   v
> }
>
> f2(a)
>
> library(microbenchmark)
>
> a2 <- rep( c( 0,0, 1, 1, 1 )
>          , 300 )
>
> microbenchmark( res1 <- f1(a2)
>               , res2 <- f2(a2)
>               )
> stopifnot( res1 == res2 )
>
>
> On August 28, 2020 8:19:41 AM PDT, Stefano Sofia <
> stefano.sofia at regione.marche.it> wrote:
> >Thank you!
> >Stefano
> >
> >         (oo)
> >--oOO--( )--OOo----------------
> >Stefano Sofia PhD
> >Civil Protection - Marche Region
> >Meteo Section
> >Snow Section
> >Via del Colle Ameno 5
> >60126 Torrette di Ancona, Ancona
> >Uff: 071 806 7743
> >E-mail: stefano.sofia at regione.marche.it
> >---Oo---------oO----------------
> >________________________________
> >Da: Bert Gunter [bgunter.4567 at gmail.com]
> >Inviato: venerd? 28 agosto 2020 17.14
> >A: Stefano Sofia
> >Cc: r-help mailing list
> >Oggetto: Re: [R] how to create a sequence to consecutive values
> >
> >Using ?rle
> >
> >> z <- rle(a)
> >> v <- z$values
> >> v[v==1] <- seq_along(v[v==1]) ## or use cumsum
> >< rep(v,z$lengths)
> > [1] 0 0 0 1 1 1 1 0 0 0 0 2 2 0 3 3 3 0 0
> >
> >Cheers,
> >Bert
> >
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Fri, Aug 28, 2020 at 7:52 AM Stefano Sofia
> ><stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>>
> >wrote:
> >Dear R-list users,
> >this is a simple question, I have not been able to find an efficient
> >solution.
> >Given a vector with only 0 or 1 values, I need to give a sequence to
> >the consecutive values of 1:
> >
> >a <- c(0,0,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,0,0)
> >
> >I should get as result
> >
> >(0,0,0,1,1,1,1,0,0,0,0,2,2,0,3,3,3,0,0)
> >
> >I tried with ave, but no way to get it for me.
> >
> >Thank you for your help
> >Stefano
> >
> >         (oo)
> >--oOO--( )--OOo----------------
> >Stefano Sofia PhD
> >Civil Protection - Marche Region
> >Meteo Section
> >Snow Section
> >Via del Colle Ameno 5
> >60126 Torrette di Ancona, Ancona
> >Uff: 071 806 7743
> >E-mail:
> >stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>
> >---Oo---------oO----------------
> >
> >________________________________
> >
> >AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> >informazioni confidenziali, pertanto ? destinato solo a persone
> >autorizzate alla ricezione. I messaggi di posta elettronica per i
> >client di Regione Marche possono contenere informazioni confidenziali e
> >con privilegi legali. Se non si ? il destinatario specificato, non
> >leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
> >ricevuto questo messaggio per errore, inoltrarlo al mittente ed
> >eliminarlo completamente dal sistema del proprio computer. Ai sensi
> >dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
> >ed urgenza, la risposta al presente messaggio di posta elettronica pu?
> >essere visionata da persone estranee al destinatario.
> >IMPORTANT NOTICE: This e-mail message is intended to be received only
> >by persons entitled to receive the confidential information it may
> >contain. E-mail messages to clients of Regione Marche may contain
> >information that is confidential and legally privileged. Please do not
> >read, copy, forward, or store this message unless you are an intended
> >recipient of it. If you have received this message in error, please
> >forward it to the sender and delete it completely from your computer
> >system.
> >
> >--
> >Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
> >infetto.
> >This message was scanned by Libra ESVA and is believed to be clean.
> >
> >
> >        [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> >UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help<
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> >
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html<
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> >
> >and provide commented, minimal, self-contained, reproducible code.
> >
> >--
> >Questo messaggio ? stato analizzato con Libra ESVA ed ? risultato non
> >infetto
> >
> >________________________________
> >
> >AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> >informazioni confidenziali, pertanto ? destinato solo a persone
> >autorizzate alla ricezione. I messaggi di posta elettronica per i
> >client di Regione Marche possono contenere informazioni confidenziali e
> >con privilegi legali. Se non si ? il destinatario specificato, non
> >leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
> >ricevuto questo messaggio per errore, inoltrarlo al mittente ed
> >eliminarlo completamente dal sistema del proprio computer. Ai sensi
> >dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
> >ed urgenza, la risposta al presente messaggio di posta elettronica pu?
> >essere visionata da persone estranee al destinatario.
> >IMPORTANT NOTICE: This e-mail message is intended to be received only
> >by persons entitled to receive the confidential information it may
> >contain. E-mail messages to clients of Regione Marche may contain
> >information that is confidential and legally privileged. Please do not
> >read, copy, forward, or store this message unless you are an intended
> >recipient of it. If you have received this message in error, please
> >forward it to the sender and delete it completely from your computer
> >system.
> >
> >-->
> >Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
> >infetto.>
> >This message was scanned by Libra ESVA and is believed to be clean.
> >
> >
> >       [[alternative HTML version deleted]]
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 28 18:11:09 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 28 Aug 2020 09:11:09 -0700
Subject: [R] Would Like Some Advise
In-Reply-To: <ZIA2z5nbnDqR9Dkv3GQA8ivFNwMfy2JtZj6b9QrEZMuqJBDCs0Lp9gTHlLXefCFoEDiVNnVlmA0ZdvozYgWMi2U-jWc73pDXJIfZt9V9Hgo=@protonmail.com>
References: <1157A76A248944878C040D1FE0AE725C@OWNERPC>
 <ZIA2z5nbnDqR9Dkv3GQA8ivFNwMfy2JtZj6b9QrEZMuqJBDCs0Lp9gTHlLXefCFoEDiVNnVlmA0ZdvozYgWMi2U-jWc73pDXJIfZt9V9Hgo=@protonmail.com>
Message-ID: <B5D9647C-1441-45C8-AA0F-21FE483806F5@dcn.davis.ca.us>

Linux supports process parallel processing with copy-on-write memory sharing (i.e. forking via mclapply) that makes certain kinds of algorithm parallelization much more memory-efficient. 

On August 28, 2020 7:45:12 AM PDT, Gregg via R-help <r-help at r-project.org> wrote:
>Phillip,
>
>The primary differences between Windows and Linux:
>
>Windows attempts to monetize most of what you do on your computer in
>the same way that Facebook, Google, and other Social Media sites go,
>but Microsoft goes one step further, and they use the OS to monetize
>Windows Users. Linux on the other hand, being open source does not.
>Linux Distributions are free, and there are many to choose from. My
>recommendation on Distributions would be either PCLINUXOS with the KDE
>Plasma 5 Desktop interface, or Kubuntu which is Ubuntu with a KDE
>Desktop (instead of a Gnome, XFCE, Enlightenment, or Cinnamon) Desktop.
>The KDE Desktop is much more refined compared to the others - IMO. So,
>in a nutshell - Windows monetizes you thru the OS, Linux does not.
>
>Windows Pros:
>-Much greater variety of commercial software available and easier to
>install
>-Familiar interface
>-Better for people who want to play games
>-Will not lock up as easily if the computer runs out of memory
>
>Windows Cons:
>-Less Secure in the sense that more nefarious players target windows
>-Cost (not free)
>-Microsoft Monetizes users of the OS
>-less control of what is installed on the machine (there are commercial
>apps in Windows that Microsoft makes it hard to remove - like xbox, and
>crap like that)
>-commercial software is typically more polished - like Microsoft Office
>
>Linux Pros:
>-Free
>-More Secure - fewer nefarious players targeting the OS
>-Free software available thru repositories make it easy to install much
>of what you need to include an office suit that is good (Libre Office,
>among others)
>-Satisfaction in having learned something new - kinda outside the box
>-User has MUCH more control
>-Just a better experience - IMO
>
>Linux Cons:
>-Some hardware is still difficult to get working with Linux, but not
>much anymore (CAC card readers for instance, or remote scanners, and
>sometimes printers)
>-Linux OS can lock up if a program consumes all of the physical
>memory... thought it'll usually recover once the application craps out
>(like R - had this happen many times before I built a new computer with
>128GB) 
>
>-Linux is poor at memory management when a swap file becomes necessary
>(yes, it is true - sorry)
>
>
>I prefer Linux, but because I have a work computer issued to me that
>runs Windows - I still use it. If it were not for that, I would not. I
>run Linux (PCLINUXOS 64 bit with KDE) on all my home computers, but can
>still dual boot into windows when I need to.
>
>As for R - it runs fine on either.
>
>As for memory - get 128GB, and you won't have to look back and worry...
>that is if you think there is even a remote possibility that you'll
>need more than 64 GB - which is likely if you are using R to process
>weather data.
>
>r/
>Gregg
>AZ
>
>
>
>
>
>
>
>
>
>??????? Original Message ???????
>On Friday, August 28, 2020 7:08 AM, Philip <herd_dog at cox.net> wrote:
>
>> I need a new computer. have a friend who is convinced that I have an
>aura about me that just kills electronic devices.
>> 
>
>> Does anyone out there have an opinion about Windows vs. Linux?
>> 
>
>> I?m retired so this is just for my own enjoyment but I?m crunching
>some large National Weather Service files and will move on to baseball
>data and a few other things. I?d like some advise about how much RAM
>and stuff like that. I understand there is something called zones of
>computer memory. Can someone direct me to a good source so I can learn
>more? I really don?t understand stuff like this. Does anyone think I
>need to upgrade my wifi?
>> 
>
>> Thanks,
>> Philip
>> [[alternative HTML version deleted]]
>> 
>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug 28 18:31:40 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 28 Aug 2020 12:31:40 -0400
Subject: [R] Passing formula and weights error
In-Reply-To: <CAFyG=WP1z9NYNOLSe3gbNbE1ye_qHRqTWB3c9yW_FNubC2RcKA@mail.gmail.com>
References: <CAFyG=WP1z9NYNOLSe3gbNbE1ye_qHRqTWB3c9yW_FNubC2RcKA@mail.gmail.com>
Message-ID: <5b4e8a82-2d2c-b654-3710-93af255fc434@gmail.com>

This came up recently in a discussion of lm() on the R-devel list.  I'd 
assume the same issue applies to glm.

The problem is that the argument to weights is evaluated in the same way 
as arguments in the formula:  first in data, then in the environment of 
the formula.  The latter will eventually lead back to the global 
environment, but won't lead to the local evaluation frame in myglm().

The easiest solution is to add newweights to the data argument, but 
there are a few gotchas here.

First, if newweights is already a column in data, you'll mess things up. 
  So be sure to use a name that can't be there.  That's okay in your 
example.

The second problem is that a dot in the formula will cause problems, 
because it will try to include newweights as a predictor variable.  It's 
possible to work around this, but it's probably better to use a more 
complicated solution instead:  modify the formula environment so it 
starts with a small environment holding newweights.  You don't want to 
add newweights directly to environment(formula), because that will have 
side effects outside your function.

This version of your function takes this more complicated approach:

  myglm <- function(formula, data, weights){
      ## this works
      print(glm(formula, data, family=gaussian(), weights))
      env <- new.env(parent = environment(formula))
      env$newweights <- rep(1, n)
      environment(formula) <- env

      glm(formula, data, family=gaussian(), weights=newweights)
  }

Duncan Murdoch


On 28/08/2020 11:32 a.m., John Smith wrote:
> Dear R-help:
> 
> I am writing a function based on glm and would like some variations of
> weights. In the code below, I couldn't understand why the second glm
> function fails and don't know how to fix it:
> 
> Error in eval(extras, data, env) : object 'newweights' not found
>   Calls: print ... eval -> <Anonymous> -> model.frame.default -> eval -> eval
>   Execution halted
> 
> ### R code
> y <- rnorm(100)
>   x <- rnorm(100)
>   data <- data.frame(cbind(x, y))
>   weights <- rep(1, 100)
>   n <- 100
>   myglm <- function(formula, data, weights){
>       ## this works
>       print(glm(formula, data, family=gaussian(), weights))
>       ## this is not working
>       newweights <- rep(1, n)
>       glm(formula, data, family=gaussian(), weights=newweights)
>   }
>   myglm(y~., data, weights)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdun|@p @end|ng |rom t|bco@com  Fri Aug 28 18:38:07 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 28 Aug 2020 09:38:07 -0700
Subject: [R] Passing formula and weights error
In-Reply-To: <CAFyG=WP1z9NYNOLSe3gbNbE1ye_qHRqTWB3c9yW_FNubC2RcKA@mail.gmail.com>
References: <CAFyG=WP1z9NYNOLSe3gbNbE1ye_qHRqTWB3c9yW_FNubC2RcKA@mail.gmail.com>
Message-ID: <CAF8bMcaJJC2DeWZaOVMDfUFQKdskS9SPKi1rezVV0eSgY+hZgg@mail.gmail.com>

Note that neither call to glm in your myglm function really works -
the first one is using the 'weights' object from the global
environment, not the weights argument.  E.g., in the fresh R session,
where I avoid making unneeded assignments and use fixed x and y for
repeatability,

  > n <- 16
  > data <- data.frame(x = log2(1:n), y = 1:n)
  > myglm2 <- function(formula, data, weights)
      {
          glm(formula, data=data, family=gaussian(), weights=weights)
      }
  > myglm2(y~., data=data, weights=1/(1:n))
  Error in model.frame.default(formula = formula, data = data, weights
= weights,  :
    invalid type (closure) for variable '(weights)'

The error arises because glm finds stats::weights, a function, not the
argument called weights.  glm(), lm() and their ilk evaluate their
weights and subset arguments in the environment of the formula.  In
this case environment(y~.) is .GlobalEnv, not the function's
environment.  The following function gives one way to deal with this,
by giving formula a new environment that inherits from its original
environment and contains the extra variables.

  > myglm3 <- function(formula, data, weights)
      {
          envir <- list2env(list(weights=weights), parent=environment(formula))
          environment(formula) <- envir
          glm(formula, data=data, family=gaussian(), weights=weights)
      }
  > myglm3(y~., data=data, weights=1/(1:n))

  Call:  glm(formula = formula, family = gaussian(), data = data,
weights = weights)

  Coefficients:
  (Intercept)            x
     -0.09553      2.93352

  Degrees of Freedom: 15 Total (i.e. Null);  14 Residual
  Null Deviance:      60.28
  Residual Deviance: 7.72         AIC: 70.42

This is the same result you get with a direct call to
  glm(y~., data=data, weights=1/(1:n))

This is a common problem and I don't know if there is a FAQ on it or a
standard function to deal with it.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Aug 28, 2020 at 8:33 AM John Smith <jswhct at gmail.com> wrote:
>
> Dear R-help:
>
> I am writing a function based on glm and would like some variations of
> weights. In the code below, I couldn't understand why the second glm
> function fails and don't know how to fix it:
>
> Error in eval(extras, data, env) : object 'newweights' not found
>  Calls: print ... eval -> <Anonymous> -> model.frame.default -> eval -> eval
>  Execution halted
>
> ### R code
> y <- rnorm(100)
>  x <- rnorm(100)
>  data <- data.frame(cbind(x, y))
>  weights <- rep(1, 100)
>  n <- 100
>  myglm <- function(formula, data, weights){
>      ## this works
>      print(glm(formula, data, family=gaussian(), weights))
>      ## this is not working
>      newweights <- rep(1, n)
>      glm(formula, data, family=gaussian(), weights=newweights)
>  }
>  myglm(y~., data, weights)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@whct @end|ng |rom gm@||@com  Fri Aug 28 20:23:23 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Fri, 28 Aug 2020 13:23:23 -0500
Subject: [R] Passing formula and weights error
In-Reply-To: <CAF8bMcaJJC2DeWZaOVMDfUFQKdskS9SPKi1rezVV0eSgY+hZgg@mail.gmail.com>
References: <CAFyG=WP1z9NYNOLSe3gbNbE1ye_qHRqTWB3c9yW_FNubC2RcKA@mail.gmail.com>
 <CAF8bMcaJJC2DeWZaOVMDfUFQKdskS9SPKi1rezVV0eSgY+hZgg@mail.gmail.com>
Message-ID: <CAFyG=WO2qzqC0rxkaUbFv4Zp8+TP08Bjmc=Ev-rOqwiyMnHAuw@mail.gmail.com>

Thanks to Duncan and Bill for very helpful tips.

On Fri, Aug 28, 2020 at 11:38 AM William Dunlap <wdunlap at tibco.com> wrote:

> Note that neither call to glm in your myglm function really works -
> the first one is using the 'weights' object from the global
> environment, not the weights argument.  E.g., in the fresh R session,
> where I avoid making unneeded assignments and use fixed x and y for
> repeatability,
>
>   > n <- 16
>   > data <- data.frame(x = log2(1:n), y = 1:n)
>   > myglm2 <- function(formula, data, weights)
>       {
>           glm(formula, data=data, family=gaussian(), weights=weights)
>       }
>   > myglm2(y~., data=data, weights=1/(1:n))
>   Error in model.frame.default(formula = formula, data = data, weights
> = weights,  :
>     invalid type (closure) for variable '(weights)'
>
> The error arises because glm finds stats::weights, a function, not the
> argument called weights.  glm(), lm() and their ilk evaluate their
> weights and subset arguments in the environment of the formula.  In
> this case environment(y~.) is .GlobalEnv, not the function's
> environment.  The following function gives one way to deal with this,
> by giving formula a new environment that inherits from its original
> environment and contains the extra variables.
>
>   > myglm3 <- function(formula, data, weights)
>       {
>           envir <- list2env(list(weights=weights),
> parent=environment(formula))
>           environment(formula) <- envir
>           glm(formula, data=data, family=gaussian(), weights=weights)
>       }
>   > myglm3(y~., data=data, weights=1/(1:n))
>
>   Call:  glm(formula = formula, family = gaussian(), data = data,
> weights = weights)
>
>   Coefficients:
>   (Intercept)            x
>      -0.09553      2.93352
>
>   Degrees of Freedom: 15 Total (i.e. Null);  14 Residual
>   Null Deviance:      60.28
>   Residual Deviance: 7.72         AIC: 70.42
>
> This is the same result you get with a direct call to
>   glm(y~., data=data, weights=1/(1:n))
>
> This is a common problem and I don't know if there is a FAQ on it or a
> standard function to deal with it.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Aug 28, 2020 at 8:33 AM John Smith <jswhct at gmail.com> wrote:
> >
> > Dear R-help:
> >
> > I am writing a function based on glm and would like some variations of
> > weights. In the code below, I couldn't understand why the second glm
> > function fails and don't know how to fix it:
> >
> > Error in eval(extras, data, env) : object 'newweights' not found
> >  Calls: print ... eval -> <Anonymous> -> model.frame.default -> eval ->
> eval
> >  Execution halted
> >
> > ### R code
> > y <- rnorm(100)
> >  x <- rnorm(100)
> >  data <- data.frame(cbind(x, y))
> >  weights <- rep(1, 100)
> >  n <- 100
> >  myglm <- function(formula, data, weights){
> >      ## this works
> >      print(glm(formula, data, family=gaussian(), weights))
> >      ## this is not working
> >      newweights <- rep(1, n)
> >      glm(formula, data, family=gaussian(), weights=newweights)
> >  }
> >  myglm(y~., data, weights)
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@whct @end|ng |rom gm@||@com  Sat Aug 29 03:28:12 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Fri, 28 Aug 2020 20:28:12 -0500
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
Message-ID: <CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>

If the weights < 1, then we have different values! See an example below.
How  should I interpret logLik value then?

set.seed(135)
 y <- c(rep(0, 50), rep(1, 50))
 x <- rnorm(100)
 data <- data.frame(cbind(x, y))
 weights <- c(rep(1, 50), rep(2, 50))
 fit <- glm(y~x, data, family=binomial(), weights/10)
 res.dev <- residuals(fit, type="deviance")
 res2 <- -0.5*res.dev^2
 cat("loglikelihood value", logLik(fit), sum(res2), "\n")

On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com> wrote:

> If you don't worry too much about an additive constant, then half the
> negative squared deviance residuals should do. (Not quite sure how weights
> factor in. Looks like they are accounted for.)
>
> -pd
>
> > On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
> >
> > Dear R-help,
> >
> > The function logLik can be used to obtain the maximum log-likelihood
> value
> > from a glm object. This is an aggregated value, a summation of individual
> > log-likelihood values. How do I obtain individual values? In the
> following
> > example, I would expect 9 numbers since the response has length 9. I
> could
> > write a function to compute the values, but there are lots of
> > family members in glm, and I am trying not to reinvent wheels. Thanks!
> >
> > counts <- c(18,17,15,20,10,20,25,13,12)
> >     outcome <- gl(3,1,9)
> >     treatment <- gl(3,3)
> >     data.frame(treatment, outcome, counts) # showing data
> >     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> >     (ll <- logLik(glm.D93))
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From m@rk|eed@2 @end|ng |rom gm@||@com  Sat Aug 29 04:14:39 2020
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Fri, 28 Aug 2020 22:14:39 -0400
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
Message-ID: <CAHz+bWaUugOUOrjKBKTK0AN4V21pgbdR7J=kgtMOCvxT=oGZ-Q@mail.gmail.com>

Hii: It's been a long time but John Fox's "Companion to Appied Regression"
book has the expressions
for the likelihood of the binomial glm. ( and probably the others also ).
Just running logLik is not so useful
because it could be leaving out multiplicative factors. If you can get your
hands on any edition of John's book,
I remember it being quite helpful in terms of providing all of the gory
details and  for understanding GLM's in
general.







On Fri, Aug 28, 2020 at 9:28 PM John Smith <jswhct at gmail.com> wrote:

> If the weights < 1, then we have different values! See an example below.
> How  should I interpret logLik value then?
>
> set.seed(135)
>  y <- c(rep(0, 50), rep(1, 50))
>  x <- rnorm(100)
>  data <- data.frame(cbind(x, y))
>  weights <- c(rep(1, 50), rep(2, 50))
>  fit <- glm(y~x, data, family=binomial(), weights/10)
>  res.dev <- residuals(fit, type="deviance")
>  res2 <- -0.5*res.dev^2
>  cat("loglikelihood value", logLik(fit), sum(res2), "\n")
>
> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com> wrote:
>
> > If you don't worry too much about an additive constant, then half the
> > negative squared deviance residuals should do. (Not quite sure how
> weights
> > factor in. Looks like they are accounted for.)
> >
> > -pd
> >
> > > On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
> > >
> > > Dear R-help,
> > >
> > > The function logLik can be used to obtain the maximum log-likelihood
> > value
> > > from a glm object. This is an aggregated value, a summation of
> individual
> > > log-likelihood values. How do I obtain individual values? In the
> > following
> > > example, I would expect 9 numbers since the response has length 9. I
> > could
> > > write a function to compute the values, but there are lots of
> > > family members in glm, and I am trying not to reinvent wheels. Thanks!
> > >
> > > counts <- c(18,17,15,20,10,20,25,13,12)
> > >     outcome <- gl(3,1,9)
> > >     treatment <- gl(3,3)
> > >     data.frame(treatment, outcome, counts) # showing data
> > >     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> > >     (ll <- logLik(glm.D93))
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug 29 05:51:37 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 28 Aug 2020 23:51:37 -0400
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
Message-ID: <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>

Dear John

I think that you misunderstand the use of the weights argument to glm() 
for a binomial GLM. From ?glm: "For a binomial GLM prior weights are 
used to give the number of trials when the response is the proportion of 
successes." That is, in this case y should be the observed proportion of 
successes (i.e., between 0 and 1) and the weights are integers giving 
the number of trials for each binomial observation.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-08-28 9:28 p.m., John Smith wrote:
> If the weights < 1, then we have different values! See an example below.
> How  should I interpret logLik value then?
> 
> set.seed(135)
>   y <- c(rep(0, 50), rep(1, 50))
>   x <- rnorm(100)
>   data <- data.frame(cbind(x, y))
>   weights <- c(rep(1, 50), rep(2, 50))
>   fit <- glm(y~x, data, family=binomial(), weights/10)
>   res.dev <- residuals(fit, type="deviance")
>   res2 <- -0.5*res.dev^2
>   cat("loglikelihood value", logLik(fit), sum(res2), "\n")
> 
> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> If you don't worry too much about an additive constant, then half the
>> negative squared deviance residuals should do. (Not quite sure how weights
>> factor in. Looks like they are accounted for.)
>>
>> -pd
>>
>>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
>>>
>>> Dear R-help,
>>>
>>> The function logLik can be used to obtain the maximum log-likelihood
>> value
>>> from a glm object. This is an aggregated value, a summation of individual
>>> log-likelihood values. How do I obtain individual values? In the
>> following
>>> example, I would expect 9 numbers since the response has length 9. I
>> could
>>> write a function to compute the values, but there are lots of
>>> family members in glm, and I am trying not to reinvent wheels. Thanks!
>>>
>>> counts <- c(18,17,15,20,10,20,25,13,12)
>>>      outcome <- gl(3,1,9)
>>>      treatment <- gl(3,3)
>>>      data.frame(treatment, outcome, counts) # showing data
>>>      glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>>>      (ll <- logLik(glm.D93))
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j@whct @end|ng |rom gm@||@com  Sat Aug 29 07:30:27 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Sat, 29 Aug 2020 00:30:27 -0500
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
 <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>
Message-ID: <972FD22B-9A75-4854-9005-7B4865D07564@gmail.com>

Thanks Prof. Fox. 

I am curious: what is the model estimated below?

I guess my inquiry seems more complicated than I thought: with y being 0/1, how to fit weighted logistic regression with weights <1, in the sense of weighted least squares? Thanks

> On Aug 28, 2020, at 10:51 PM, John Fox <jfox at mcmaster.ca> wrote:
> 
> Dear John
> 
> I think that you misunderstand the use of the weights argument to glm() for a binomial GLM. From ?glm: "For a binomial GLM prior weights are used to give the number of trials when the response is the proportion of successes." That is, in this case y should be the observed proportion of successes (i.e., between 0 and 1) and the weights are integers giving the number of trials for each binomial observation.
> 
> I hope this helps,
> John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
> 
>> On 2020-08-28 9:28 p.m., John Smith wrote:
>> If the weights < 1, then we have different values! See an example below.
>> How  should I interpret logLik value then?
>> set.seed(135)
>>  y <- c(rep(0, 50), rep(1, 50))
>>  x <- rnorm(100)
>>  data <- data.frame(cbind(x, y))
>>  weights <- c(rep(1, 50), rep(2, 50))
>>  fit <- glm(y~x, data, family=binomial(), weights/10)
>>  res.dev <- residuals(fit, type="deviance")
>>  res2 <- -0.5*res.dev^2
>>  cat("loglikelihood value", logLik(fit), sum(res2), "\n")
>>> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com> wrote:
>>> If you don't worry too much about an additive constant, then half the
>>> negative squared deviance residuals should do. (Not quite sure how weights
>>> factor in. Looks like they are accounted for.)
>>> 
>>> -pd
>>> 
>>>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
>>>> 
>>>> Dear R-help,
>>>> 
>>>> The function logLik can be used to obtain the maximum log-likelihood
>>> value
>>>> from a glm object. This is an aggregated value, a summation of individual
>>>> log-likelihood values. How do I obtain individual values? In the
>>> following
>>>> example, I would expect 9 numbers since the response has length 9. I
>>> could
>>>> write a function to compute the values, but there are lots of
>>>> family members in glm, and I am trying not to reinvent wheels. Thanks!
>>>> 
>>>> counts <- c(18,17,15,20,10,20,25,13,12)
>>>>     outcome <- gl(3,1,9)
>>>>     treatment <- gl(3,3)
>>>>     data.frame(treatment, outcome, counts) # showing data
>>>>     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>>>>     (ll <- logLik(glm.D93))
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>    [[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From |r@edr|c @end|ng |rom @|u@edu  Thu Aug 27 20:14:19 2020
From: |r@edr|c @end|ng |rom @|u@edu (Fraedrich, John)
Date: Thu, 27 Aug 2020 18:14:19 +0000
Subject: [R] PROBLEM: quickly downloading 10,000 articles to sift through
Message-ID: <CY4PR0701MB369878348CB5F237F8108C49C3550@CY4PR0701MB3698.namprd07.prod.outlook.com>



To analyze 10,000+ articles within several journals to determine major theories used, empirical research of models, constructs, and variables, differences in standard definitions by discipline, etc. Is/does R have this in a software package?



Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]


From rene@j@@u@rez @end|ng |rom gm@||@com  Fri Aug 28 16:22:54 2020
From: rene@j@@u@rez @end|ng |rom gm@||@com (Rene J Suarez-Soto)
Date: Fri, 28 Aug 2020 10:22:54 -0400
Subject: [R] Base package being deleted recurrently
Message-ID: <CAKeefvtV8o=JZV2RkB_HiFR3mqYS0ZP4UKCrbSJuEOot7k=fOA@mail.gmail.com>

Hi,

I have a very strange issue. I am currently running R 4.0.2. The files in
my library/base/ are being deleted by some unknown reason. I have had to
install R over 20 times in the last 2 month. I have installed using user
privileges and admin. I have installed it to different directories but the
same issue repeats. I have checked the history of the antivirus program and
it does not seem to be a problem. This is in an enterprise environment but
IT checked an it does not seem to be related to any security processes. Any
ideas? Thanks.

	[[alternative HTML version deleted]]


From duytr@n2310 @end|ng |rom gm@||@com  Fri Aug 28 16:44:35 2020
From: duytr@n2310 @end|ng |rom gm@||@com (Duy Tran)
Date: Fri, 28 Aug 2020 09:44:35 -0500
Subject: [R] Would Like Some Advise
In-Reply-To: <1157A76A248944878C040D1FE0AE725C@OWNERPC>
References: <1157A76A248944878C040D1FE0AE725C@OWNERPC>
Message-ID: <CAONaHRs-2F2H2AJ2adgBJKkDFABuk=N4PRusbY1OmTiqZiO4KA@mail.gmail.com>

I've worked with a 16 Gb laptop of RAM and it's been plenty for me. If you
need to work with larger data, I think you should look into packages like
sparklyr, which is basically dplyr running on a Spark cluster. Hope that
helps !
Duy


On Fri, Aug 28, 2020 at 9:09 AM Philip <herd_dog at cox.net> wrote:

> I need a new computer.  have a friend who is convinced that I have an aura
> about me that just kills electronic devices.
>
> Does anyone out there have an opinion about Windows vs. Linux?
>
> I?m retired so this is just for my own enjoyment but I?m crunching some
> large National Weather Service files and will move on to baseball data and
> a few other things.  I?d like some advise about how much RAM and stuff like
> that.  I understand there is something called zones of computer memory. Can
> someone direct me to a good source so I can learn more?   I really don?t
> understand stuff like this.  Does anyone think I need to upgrade my wifi?
>
> Thanks,
> Philip
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Sat Aug 29 11:31:31 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 29 Aug 2020 11:31:31 +0200
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
Message-ID: <C7BBCF4B-CD92-4E84-BB66-A1AC5395E976@gmail.com>



> On 25 Aug 2020, at 18:40 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> If you don't worry too much about an additive constant, then half the negative squared deviance residuals should do. (Not quite sure how weights factor in. Looks like they are accounted for.)
> 
> -pd
> 
>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
>> 
>> Dear R-help,
>> 
>> The function logLik can be used to obtain the maximum log-likelihood value
>> from a glm object. This is an aggregated value, a summation of individual
>> log-likelihood values. How do I obtain individual values? In the following
>> example, I would expect 9 numbers since the response has length 9. I could
>> write a function to compute the values, but there are lots of
>> family members in glm, and I am trying not to reinvent wheels. Thanks!
>> 
>> counts <- c(18,17,15,20,10,20,25,13,12)
>>    outcome <- gl(3,1,9)
>>    treatment <- gl(3,3)
>>    data.frame(treatment, outcome, counts) # showing data
>>    glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>>    (ll <- logLik(glm.D93))
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@|gd @end|ng |rom gm@||@com  Sat Aug 29 11:38:46 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 29 Aug 2020 11:38:46 +0200
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
Message-ID: <8D564481-C8B1-4DC1-A77D-559B2618CEAF@gmail.com>

Briefly, you shouldn't. One way of seeing it is if you switch the model to y~1, you still get logLik==0.

The root cause is the rounding in binomial()$aic:

> binomial()$aic
function (y, n, mu, wt, dev) 
{
    m <- if (any(n > 1)) 
        n
    else wt
    -2 * sum(ifelse(m > 0, (wt/m), 0) * dbinom(round(m * y), 
        round(m), mu, log = TRUE))
}

which, if wt is small enough ends up calculating dbinom(0, 0, p, log=TRUE) which is zero. 

(Not rounding gives you NaN, because you're trying to fit a model with a non-integer number of observations.)

-pd

> On 29 Aug 2020, at 03:28 , John Smith <jswhct at gmail.com> wrote:
> 
> If the weights < 1, then we have different values! See an example below. How  should I interpret logLik value then?
> 
> set.seed(135)
>  y <- c(rep(0, 50), rep(1, 50))
>  x <- rnorm(100)
>  data <- data.frame(cbind(x, y))
>  weights <- c(rep(1, 50), rep(2, 50))
>  fit <- glm(y~x, data, family=binomial(), weights/10)
>  res.dev <- residuals(fit, type="deviance")
>  res2 <- -0.5*res.dev^2
>  cat("loglikelihood value", logLik(fit), sum(res2), "\n")
> 
> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com> wrote:
> If you don't worry too much about an additive constant, then half the negative squared deviance residuals should do. (Not quite sure how weights factor in. Looks like they are accounted for.)
> 
> -pd
> 
> > On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
> > 
> > Dear R-help,
> > 
> > The function logLik can be used to obtain the maximum log-likelihood value
> > from a glm object. This is an aggregated value, a summation of individual
> > log-likelihood values. How do I obtain individual values? In the following
> > example, I would expect 9 numbers since the response has length 9. I could
> > write a function to compute the values, but there are lots of
> > family members in glm, and I am trying not to reinvent wheels. Thanks!
> > 
> > counts <- c(18,17,15,20,10,20,25,13,12)
> >     outcome <- gl(3,1,9)
> >     treatment <- gl(3,3)
> >     data.frame(treatment, outcome, counts) # showing data
> >     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> >     (ll <- logLik(glm.D93))
> > 
> >       [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j@zh@o @end|ng |rom ye@h@net  Sat Aug 29 15:40:20 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Sat, 29 Aug 2020 21:40:20 +0800
Subject: [R] tempdir() does not respect TMPDIR
Message-ID: <da93cf56-777b-bcb1-4994-b2a28b763abd@yeah.net>

Hi there,

When I started R by double clicking on Rgui icon (I am on Windows), the 
tempdir() returned the tmpdir in the directory I set in .Renviron. If I 
started R by double clicking on a *.RData file, the tempdir() return the 
tmpdir in the directory setting by Windows system. I don't know whether 
it's designed.

 > sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)
...

Best,
Jinsong


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug 29 16:02:36 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 29 Aug 2020 10:02:36 -0400
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <972FD22B-9A75-4854-9005-7B4865D07564@gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
 <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>
 <972FD22B-9A75-4854-9005-7B4865D07564@gmail.com>
Message-ID: <e5646682-62fa-6851-bb11-5cac294bbd53@mcmaster.ca>

Dear John,

On 2020-08-29 1:30 a.m., John Smith wrote:
> Thanks Prof. Fox.
> 
> I am curious: what is the model estimated below?

Nonsense, as Peter explained in a subsequent response to your prior posting.

> 
> I guess my inquiry seems more complicated than I thought: with y being 0/1, how to fit weighted logistic regression with weights <1, in the sense of weighted least squares? Thanks

What sense would that make? WLS is meant to account for non-constant 
error variance in a linear model, but in a binomial GLM, the variance is 
purely a function for the mean.

If you had binomial (rather than binary 0/1) observations (i.e., 
binomial trials exceeding 1), then you could account for overdispersion, 
e.g., by introducing a dispersion parameter via the quasibinomial 
family, but that isn't equivalent to variance weights in a LM, rather to 
the error-variance parameter in a LM.

I guess the question is what are you trying to achieve with the weights?

Best,
  John

> 
>> On Aug 28, 2020, at 10:51 PM, John Fox <jfox at mcmaster.ca> wrote:
>>
>> Dear John
>>
>> I think that you misunderstand the use of the weights argument to glm() for a binomial GLM. From ?glm: "For a binomial GLM prior weights are used to give the number of trials when the response is the proportion of successes." That is, in this case y should be the observed proportion of successes (i.e., between 0 and 1) and the weights are integers giving the number of trials for each binomial observation.
>>
>> I hope this helps,
>> John
>>
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> web: https://socialsciences.mcmaster.ca/jfox/
>>
>>> On 2020-08-28 9:28 p.m., John Smith wrote:
>>> If the weights < 1, then we have different values! See an example below.
>>> How  should I interpret logLik value then?
>>> set.seed(135)
>>>   y <- c(rep(0, 50), rep(1, 50))
>>>   x <- rnorm(100)
>>>   data <- data.frame(cbind(x, y))
>>>   weights <- c(rep(1, 50), rep(2, 50))
>>>   fit <- glm(y~x, data, family=binomial(), weights/10)
>>>   res.dev <- residuals(fit, type="deviance")
>>>   res2 <- -0.5*res.dev^2
>>>   cat("loglikelihood value", logLik(fit), sum(res2), "\n")
>>>> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com> wrote:
>>>> If you don't worry too much about an additive constant, then half the
>>>> negative squared deviance residuals should do. (Not quite sure how weights
>>>> factor in. Looks like they are accounted for.)
>>>>
>>>> -pd
>>>>
>>>>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
>>>>>
>>>>> Dear R-help,
>>>>>
>>>>> The function logLik can be used to obtain the maximum log-likelihood
>>>> value
>>>>> from a glm object. This is an aggregated value, a summation of individual
>>>>> log-likelihood values. How do I obtain individual values? In the
>>>> following
>>>>> example, I would expect 9 numbers since the response has length 9. I
>>>> could
>>>>> write a function to compute the values, but there are lots of
>>>>> family members in glm, and I am trying not to reinvent wheels. Thanks!
>>>>>
>>>>> counts <- c(18,17,15,20,10,20,25,13,12)
>>>>>      outcome <- gl(3,1,9)
>>>>>      treatment <- gl(3,3)
>>>>>      data.frame(treatment, outcome, counts) # showing data
>>>>>      glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>>>>>      (ll <- logLik(glm.D93))
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> --
>>>> Peter Dalgaard, Professor,
>>>> Center for Statistics, Copenhagen Business School
>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>> Phone: (+45)38153501
>>>> Office: A 4.23
>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>     [[alternative HTML version deleted]]
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From pro|jcn@@h @end|ng |rom gm@||@com  Sat Aug 29 17:17:11 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sat, 29 Aug 2020 11:17:11 -0400
Subject: [R] Base package being deleted recurrently
In-Reply-To: <CAKeefvtV8o=JZV2RkB_HiFR3mqYS0ZP4UKCrbSJuEOot7k=fOA@mail.gmail.com>
References: <CAKeefvtV8o=JZV2RkB_HiFR3mqYS0ZP4UKCrbSJuEOot7k=fOA@mail.gmail.com>
Message-ID: <12771195-21f8-b03d-dab7-8ef12331cf2c@gmail.com>

Possibly way off target, but I know some of our U of O teaching
systems boot by reverting to a standard image i.e., you get back
to a vanilla system. That would certainly kill any install.

JN

On 2020-08-28 10:22 a.m., Rene J Suarez-Soto wrote:
> Hi,
> 
> I have a very strange issue. I am currently running R 4.0.2. The files in
> my library/base/ are being deleted by some unknown reason. I have had to
> install R over 20 times in the last 2 month. I have installed using user
> privileges and admin. I have installed it to different directories but the
> same issue repeats. I have checked the history of the antivirus program and
> it does not seem to be a problem. This is in an enterprise environment but
> IT checked an it does not seem to be related to any security processes. Any
> ideas? Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j@whct @end|ng |rom gm@||@com  Sat Aug 29 17:18:38 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Sat, 29 Aug 2020 10:18:38 -0500
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <e5646682-62fa-6851-bb11-5cac294bbd53@mcmaster.ca>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
 <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>
 <972FD22B-9A75-4854-9005-7B4865D07564@gmail.com>
 <e5646682-62fa-6851-bb11-5cac294bbd53@mcmaster.ca>
Message-ID: <CAFyG=WMtjKgn=tiuvrEu8fEZ-oB=MOY1C9sbJYyWjg+RTGqkkw@mail.gmail.com>

Thanks for very insightful thoughts. What I am trying to achieve with the
weights is actually not new, something like
https://stats.stackexchange.com/questions/44776/logistic-regression-with-weighted-instances.
I thought my inquiry was not too strange, and I could utilize some existing
codes. It is just an optimization problem at the end of day, or not? Thanks

On Sat, Aug 29, 2020 at 9:02 AM John Fox <jfox at mcmaster.ca> wrote:

> Dear John,
>
> On 2020-08-29 1:30 a.m., John Smith wrote:
> > Thanks Prof. Fox.
> >
> > I am curious: what is the model estimated below?
>
> Nonsense, as Peter explained in a subsequent response to your prior
> posting.
>
> >
> > I guess my inquiry seems more complicated than I thought: with y being
> 0/1, how to fit weighted logistic regression with weights <1, in the sense
> of weighted least squares? Thanks
>
> What sense would that make? WLS is meant to account for non-constant
> error variance in a linear model, but in a binomial GLM, the variance is
> purely a function for the mean.
>
> If you had binomial (rather than binary 0/1) observations (i.e.,
> binomial trials exceeding 1), then you could account for overdispersion,
> e.g., by introducing a dispersion parameter via the quasibinomial
> family, but that isn't equivalent to variance weights in a LM, rather to
> the error-variance parameter in a LM.
>
> I guess the question is what are you trying to achieve with the weights?
>
> Best,
>   John
>
> >
> >> On Aug 28, 2020, at 10:51 PM, John Fox <jfox at mcmaster.ca> wrote:
> >>
> >> Dear John
> >>
> >> I think that you misunderstand the use of the weights argument to glm()
> for a binomial GLM. From ?glm: "For a binomial GLM prior weights are used
> to give the number of trials when the response is the proportion of
> successes." That is, in this case y should be the observed proportion of
> successes (i.e., between 0 and 1) and the weights are integers giving the
> number of trials for each binomial observation.
> >>
> >> I hope this helps,
> >> John
> >>
> >> John Fox, Professor Emeritus
> >> McMaster University
> >> Hamilton, Ontario, Canada
> >> web: https://socialsciences.mcmaster.ca/jfox/
> >>
> >>> On 2020-08-28 9:28 p.m., John Smith wrote:
> >>> If the weights < 1, then we have different values! See an example
> below.
> >>> How  should I interpret logLik value then?
> >>> set.seed(135)
> >>>   y <- c(rep(0, 50), rep(1, 50))
> >>>   x <- rnorm(100)
> >>>   data <- data.frame(cbind(x, y))
> >>>   weights <- c(rep(1, 50), rep(2, 50))
> >>>   fit <- glm(y~x, data, family=binomial(), weights/10)
> >>>   res.dev <- residuals(fit, type="deviance")
> >>>   res2 <- -0.5*res.dev^2
> >>>   cat("loglikelihood value", logLik(fit), sum(res2), "\n")
> >>>> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com>
> wrote:
> >>>> If you don't worry too much about an additive constant, then half the
> >>>> negative squared deviance residuals should do. (Not quite sure how
> weights
> >>>> factor in. Looks like they are accounted for.)
> >>>>
> >>>> -pd
> >>>>
> >>>>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
> >>>>>
> >>>>> Dear R-help,
> >>>>>
> >>>>> The function logLik can be used to obtain the maximum log-likelihood
> >>>> value
> >>>>> from a glm object. This is an aggregated value, a summation of
> individual
> >>>>> log-likelihood values. How do I obtain individual values? In the
> >>>> following
> >>>>> example, I would expect 9 numbers since the response has length 9. I
> >>>> could
> >>>>> write a function to compute the values, but there are lots of
> >>>>> family members in glm, and I am trying not to reinvent wheels.
> Thanks!
> >>>>>
> >>>>> counts <- c(18,17,15,20,10,20,25,13,12)
> >>>>>      outcome <- gl(3,1,9)
> >>>>>      treatment <- gl(3,3)
> >>>>>      data.frame(treatment, outcome, counts) # showing data
> >>>>>      glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> >>>>>      (ll <- logLik(glm.D93))
> >>>>>
> >>>>>        [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> --
> >>>> Peter Dalgaard, Professor,
> >>>> Center for Statistics, Copenhagen Business School
> >>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >>>> Phone: (+45)38153501
> >>>> Office: A 4.23
> >>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>     [[alternative HTML version deleted]]
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Sat Aug 29 17:34:29 2020
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Sat, 29 Aug 2020 17:34:29 +0200
Subject: [R] serialize does not work as expected
Message-ID: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>

Hi,

if I create a list with

l <- list(1:3, as.numeric(1:3), c(1,2,3))

and applying

lapply(l, 'class')
lapply(l, 'mode')
lapply(l, 'storage.mode')
lapply(l, 'typeof')
identical(l[[2]], l[[3]])

then I would believe that as,numeric(1:3) and c(1,2,3) are identical 
objects. However,

lapply(l, serialize, connection=NULL)

returns different results for each list element :(

Any ideas, why it is like that?

Best Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug 29 17:53:14 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 29 Aug 2020 08:53:14 -0700
Subject: [R] serialize does not work as expected
In-Reply-To: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
References: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
Message-ID: <AF9753DB-119B-4C6F-ADBC-FAEEE2A1A350@dcn.davis.ca.us>

Did you really conclude from looking at class that they were identical?

Numeric mode sometimes makes it hard to distinguish integers from doubles, but they are different.

On August 29, 2020 8:34:29 AM PDT, Sigbert Klinke <sigbert at wiwi.hu-berlin.de> wrote:
>Hi,
>
>if I create a list with
>
>l <- list(1:3, as.numeric(1:3), c(1,2,3))
>
>and applying
>
>lapply(l, 'class')
>lapply(l, 'mode')
>lapply(l, 'storage.mode')
>lapply(l, 'typeof')
>identical(l[[2]], l[[3]])
>
>then I would believe that as,numeric(1:3) and c(1,2,3) are identical 
>objects. However,
>
>lapply(l, serialize, connection=NULL)
>
>returns different results for each list element :(
>
>Any ideas, why it is like that?
>
>Best Sigbert

-- 
Sent from my phone. Please excuse my brevity.


From n4|bz @end|ng |rom t@mp@b@y@rr@com  Sat Aug 29 17:54:16 2020
From: n4|bz @end|ng |rom t@mp@b@y@rr@com (Robert D. Bowers M.A.)
Date: Sat, 29 Aug 2020 11:54:16 -0400
Subject: [R] Would Like Some Advice
In-Reply-To: <mailman.360544.1.1598695201.35979.r-help@r-project.org>
References: <mailman.360544.1.1598695201.35979.r-help@r-project.org>
Message-ID: <f356a443-7417-7b56-76a9-778db00b91e5@tampabay.rr.com>

Besides monitization, Windows has a few other things that infuriate 
me... (1) VERY hard to control updates, (2) "sneaker" updates - things 
installed that people don't want (like trying to force Windows computer 
owners to update - and sometimes wrecking the computer when it does), 
(3) bad updates - suddenly you find features or programs you use all the 
time not working, and you have to find out which update (or combination) 
broke your software and remove them, and worst of all IMO - there used 
to be things you could do with Windows that have been completely stopped 
- configurations and ways of increasing REAL security (not just 
protecting profits) and making the system that much more efficient.? 
When I purchase a computer - I don't want some corporation forcing me to 
fit ITS stereotypes - I want total control over it and I will be the one 
making the final decisions about it (including what I do with it and the 
software I use).? (I should add that I often have to spend hours helping 
my wife with her work computer - W10, because of updates breaking her 
work software or other problems.)

I dumped Windows in 2010 - although I'd been using Linux off and on 
before then.? You see, I was finishing up my Thesis using Office, and no 
matter what I did - Office would scramble the format into what IT 
thought was right (and creating all sorts of "Widows and Orphans" and 
other format errors not matching my school's requirements).? I had to 
export the thesis into text format and load it into OpenOffice - instant 
cure of the headaches.? Also, back in 2007, there was a "security" 
update to Windows media player (I forget the name).? I was using it to 
save a video I'd taken the summer before while camping - of a black bear 
walking through our campsite.? Their software popped up a very nasty 
message that I didn't have the right to a video I HAD TAKEN MYSELF... 
and deleted every copy and version from my computer.? No backups yet... 
total loss.? Microsoft suddenly sent out a new update after I'd lost the 
video and that problem vanished, but we had friends at that time who 
also experienced the same thing (even music one person had written and 
recorded).? I think you can see why I support Linux.

Linux - for the most part, you have total control over what goes in your 
computer - which can be both good and bad (if you're not careful).? I 
myself prefer Ubuntu with the Gnome (old style) desktop - I'm a firm 
believer of "If it's not broken, don't fix it!!!".? The desktop is a 
personal preference thing.? I also very much like stability in my 
computer - so if that is important, avoid the experimental and stick 
with the LTS (Long Term Support) versions. (There are people who are 
always after the "latest and greatest" and they sometimes forget that 
not everyone has the same interests they do!)

Another drawback of Linux... software can lose support (the author gets 
tired of it) - as I've experienced a few times, or "updates" to core 
modules in the OS itself (more of the "if it's not broken don't fix 
it!!!" stuff) that break entire packages because of internal changes.? 
Sometimes programmers forget about backwards compatibility... and that 
not everyone wants "the latest and greatest" at all.? I also firmly 
believe that if equipment does the job to your satisfaction, it is NOT 
'obsolete'.? I don't support throwaway culture.

There is also this problem - many software authors don't think to export 
their program to Linux, or don't want to bother.? Some may even be 
pressured into only doing Windows.? I use Windows 7 (I absolutely HATE 
10) in a virtual machine when I have software that is Windows only 
(often Paid-for software, where nothing else will do the job or where 
the equipment it runs will only work with specific software).? That's 
the only case where I willingly use Windows.

I would finish by saying I use Ubuntu LTS with Gnome because of the wide 
variety of programs I use, besides the usual Word 
Processor/Email/Browser that usually comes with the OS.? I use my 
computer for Amateur Radio, research (document research, but also doing 
things like XRF calibration curves, radiocarbon dating correction, 
optical spectroscopy work, and so on), and rarely for games - plus I do 
like to watch videos and movies now and then. There are specialized 
"flavors" of Linux that might fit one's need better.? Oh, and using 
Linux often requires a bit more knowledge (to really be able to utilize 
it) than Windows - but then, that also depends on the flavor.

BTW - I don't use R like I used to, but have always had good luck with 
it running under Linux.? I don't know how it works under Windows - maybe 
someone can speak to that.

I hope this is helpful!

Bob


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Aug 29 18:13:12 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 29 Aug 2020 12:13:12 -0400
Subject: [R] serialize does not work as expected
In-Reply-To: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
References: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
Message-ID: <9d425b6b-ccc0-d489-c3f2-810d21da8d0d@gmail.com>

On 29/08/2020 11:34 a.m., Sigbert Klinke wrote:
> Hi,
> 
> if I create a list with
> 
> l <- list(1:3, as.numeric(1:3), c(1,2,3))
> 
> and applying
> 
> lapply(l, 'class')
> lapply(l, 'mode')
> lapply(l, 'storage.mode')
> lapply(l, 'typeof')
> identical(l[[2]], l[[3]])
> 
> then I would believe that as,numeric(1:3) and c(1,2,3) are identical
> objects. However,
> 
> lapply(l, serialize, connection=NULL)
> 
> returns different results for each list element :(
> 
> Any ideas, why it is like that?

Objects like 1:3 are stored in a special compact form, where 1:3 takes 
up the same space as 1:1000000.  Apparently as.numeric() knows to work 
with that special form, and produces the numeric version of it.

You can confirm this by looking at the results of

serialize(l[[i]], connection=stdout(), ascii=TRUE)

for each of i=1,2,3:

 > for (i in 1:3) {
+  cat("\nElement", i, "\n")
+  serialize(l[[i]], connection=stdout(), ascii=TRUE)
+ }

Element 1
A
3
262146
197888
5
UTF-8
238
2
1
262153
14
compact_intseq
2
1
262153
4
base
2
13
1
13
254
14
3
3
1
1
254

Element 2
A
3
262146
197888
5
UTF-8
238
2
1
262153
15
compact_realseq
2
1
262153
4
base
2
13
1
14
254
14
3
3
1
1
254

Element 3
A
3
262146
197888
5
UTF-8
14
3
1
2
3

Notice how element 1 is a "compact_intseq" and element 2 is a 
"compact_realseq".

Duncan Murdoch


From henr|k@bengt@@on @end|ng |rom gm@||@com  Sat Aug 29 18:36:31 2020
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sat, 29 Aug 2020 09:36:31 -0700
Subject: [R] tempdir() does not respect TMPDIR
In-Reply-To: <da93cf56-777b-bcb1-4994-b2a28b763abd@yeah.net>
References: <da93cf56-777b-bcb1-4994-b2a28b763abd@yeah.net>
Message-ID: <CAFDcVCRAAxdf0038rWR8cVN8pHD0NdcXHK+u4LtzhTbFYcX8cQ@mail.gmail.com>

It is too late to set TMPDIR in .Renviron.  It is one of the
environment variables that has to be set prior to launching R.  From
help("tempfile", package = "base"):

The environment variables TMPDIR, TMP and TEMP are checked in turn and
the first found which points to a writable directory is used: if none
succeeds ?/tmp? is used. The path should not contain spaces. **Note
that setting any of these environment variables in the R session has
no effect on tempdir(): the per-session temporary directory is created
before the interpreter is started.**

/Henrik

On Sat, Aug 29, 2020 at 6:40 AM Jinsong Zhao <jszhao at yeah.net> wrote:
>
> Hi there,
>
> When I started R by double clicking on Rgui icon (I am on Windows), the
> tempdir() returned the tmpdir in the directory I set in .Renviron. If I
> started R by double clicking on a *.RData file, the tempdir() return the
> tmpdir in the directory setting by Windows system. I don't know whether
> it's designed.
>
>  > sessionInfo()
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
> ...
>
> Best,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug 29 18:39:20 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 29 Aug 2020 12:39:20 -0400
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <15858_1598714852_07TFRV5H020905_CAFyG=WMtjKgn=tiuvrEu8fEZ-oB=MOY1C9sbJYyWjg+RTGqkkw@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
 <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>
 <972FD22B-9A75-4854-9005-7B4865D07564@gmail.com>
 <e5646682-62fa-6851-bb11-5cac294bbd53@mcmaster.ca>
 <15858_1598714852_07TFRV5H020905_CAFyG=WMtjKgn=tiuvrEu8fEZ-oB=MOY1C9sbJYyWjg+RTGqkkw@mail.gmail.com>
Message-ID: <d9578bfa-685f-0b3a-0e15-143c30e5135b@mcmaster.ca>

Dear John,

On 2020-08-29 11:18 a.m., John Smith wrote:
> Thanks for very insightful thoughts. What I am trying to achieve with the
> weights is actually not new, something like
> https://stats.stackexchange.com/questions/44776/logistic-regression-with-weighted-instances.
> I thought my inquiry was not too strange, and I could utilize some existing
> codes. It is just an optimization problem at the end of day, or not? Thanks

So the object is to fit a regularized (i.e, penalized) logistic 
regression rather than to fit by ML. glm() won't do that.

I took a quick look at the stackexchange link that you provided and the 
document referenced in that link.  The penalty proposed in the document 
is just a multiple of the sum of squared regression coefficients, what 
usually called an L2 penalty in the machine-learning literature.  There 
are existing implementations of regularized logistic regression in R -- 
see the machine learning CRAN taskview 
<https://cran.r-project.org/web/views/MachineLearning.html>. I believe 
that the penalized package will fit a regularized logistic regression 
with an L2 penalty.

As well, unless my quick reading was inaccurate, I think that you, and 
perhaps the stackexchange poster, might have been confused by the 
terminology used in the document: What's referred to as "weights" in the 
document is what statisticians more typically call "regression 
coefficients," and the "bias weight" is the "intercept" or "regression 
constant." Perhaps I'm missing some connection -- I'm not the best 
person to ask about machine learning.

Best,
  John

> 
> On Sat, Aug 29, 2020 at 9:02 AM John Fox <jfox at mcmaster.ca> wrote:
> 
>> Dear John,
>>
>> On 2020-08-29 1:30 a.m., John Smith wrote:
>>> Thanks Prof. Fox.
>>>
>>> I am curious: what is the model estimated below?
>>
>> Nonsense, as Peter explained in a subsequent response to your prior
>> posting.
>>
>>>
>>> I guess my inquiry seems more complicated than I thought: with y being
>> 0/1, how to fit weighted logistic regression with weights <1, in the sense
>> of weighted least squares? Thanks
>>
>> What sense would that make? WLS is meant to account for non-constant
>> error variance in a linear model, but in a binomial GLM, the variance is
>> purely a function for the mean.
>>
>> If you had binomial (rather than binary 0/1) observations (i.e.,
>> binomial trials exceeding 1), then you could account for overdispersion,
>> e.g., by introducing a dispersion parameter via the quasibinomial
>> family, but that isn't equivalent to variance weights in a LM, rather to
>> the error-variance parameter in a LM.
>>
>> I guess the question is what are you trying to achieve with the weights?
>>
>> Best,
>>    John
>>
>>>
>>>> On Aug 28, 2020, at 10:51 PM, John Fox <jfox at mcmaster.ca> wrote:
>>>>
>>>> Dear John
>>>>
>>>> I think that you misunderstand the use of the weights argument to glm()
>> for a binomial GLM. From ?glm: "For a binomial GLM prior weights are used
>> to give the number of trials when the response is the proportion of
>> successes." That is, in this case y should be the observed proportion of
>> successes (i.e., between 0 and 1) and the weights are integers giving the
>> number of trials for each binomial observation.
>>>>
>>>> I hope this helps,
>>>> John
>>>>
>>>> John Fox, Professor Emeritus
>>>> McMaster University
>>>> Hamilton, Ontario, Canada
>>>> web: https://socialsciences.mcmaster.ca/jfox/
>>>>
>>>>> On 2020-08-28 9:28 p.m., John Smith wrote:
>>>>> If the weights < 1, then we have different values! See an example
>> below.
>>>>> How  should I interpret logLik value then?
>>>>> set.seed(135)
>>>>>    y <- c(rep(0, 50), rep(1, 50))
>>>>>    x <- rnorm(100)
>>>>>    data <- data.frame(cbind(x, y))
>>>>>    weights <- c(rep(1, 50), rep(2, 50))
>>>>>    fit <- glm(y~x, data, family=binomial(), weights/10)
>>>>>    res.dev <- residuals(fit, type="deviance")
>>>>>    res2 <- -0.5*res.dev^2
>>>>>    cat("loglikelihood value", logLik(fit), sum(res2), "\n")
>>>>>> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com>
>> wrote:
>>>>>> If you don't worry too much about an additive constant, then half the
>>>>>> negative squared deviance residuals should do. (Not quite sure how
>> weights
>>>>>> factor in. Looks like they are accounted for.)
>>>>>>
>>>>>> -pd
>>>>>>
>>>>>>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
>>>>>>>
>>>>>>> Dear R-help,
>>>>>>>
>>>>>>> The function logLik can be used to obtain the maximum log-likelihood
>>>>>> value
>>>>>>> from a glm object. This is an aggregated value, a summation of
>> individual
>>>>>>> log-likelihood values. How do I obtain individual values? In the
>>>>>> following
>>>>>>> example, I would expect 9 numbers since the response has length 9. I
>>>>>> could
>>>>>>> write a function to compute the values, but there are lots of
>>>>>>> family members in glm, and I am trying not to reinvent wheels.
>> Thanks!
>>>>>>>
>>>>>>> counts <- c(18,17,15,20,10,20,25,13,12)
>>>>>>>       outcome <- gl(3,1,9)
>>>>>>>       treatment <- gl(3,3)
>>>>>>>       data.frame(treatment, outcome, counts) # showing data
>>>>>>>       glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>>>>>>>       (ll <- logLik(glm.D93))
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> --
>>>>>> Peter Dalgaard, Professor,
>>>>>> Center for Statistics, Copenhagen Business School
>>>>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>>>>> Phone: (+45)38153501
>>>>>> Office: A 4.23
>>>>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>      [[alternative HTML version deleted]]
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Sat Aug 29 19:10:02 2020
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Sat, 29 Aug 2020 19:10:02 +0200
Subject: [R] serialize does not work as expected
In-Reply-To: <9d425b6b-ccc0-d489-c3f2-810d21da8d0d@gmail.com>
References: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
 <9d425b6b-ccc0-d489-c3f2-810d21da8d0d@gmail.com>
Message-ID: <39302768-7fbf-8132-e604-0ee88d8cd050@wiwi.hu-berlin.de>

Hi,

is there in R a way to "normalize" a vector from 
compact_intseq/compact_realseq to a "normal" vector?

Sigbert

Am 29.08.20 um 18:13 schrieb Duncan Murdoch:
> Element 1
> A
> 3
> 262146
> 197888
> 5
> UTF-8
> 238
> 2
> 1
> 262153
> 14
> compact_intseq
> 2
> 1
> 262153
> 4
> base
> 2
> 13
> 1
> 13
> 254
> 14
> 3
> 3
> 1
> 1
> 254
> 
> Element 2
> A
> 3
> 262146
> 197888
> 5
> UTF-8
> 238
> 2
> 1
> 262153
> 15
> compact_realseq
> 2
> 1
> 262153
> 4
> base
> 2
> 13
> 1
> 14
> 254
> 14
> 3
> 3
> 1
> 1
> 254
> 
> Element 3
> A
> 3
> 262146
> 197888
> 5
> UTF-8
> 14
> 3
> 1
> 2
> 3


-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From henr|k@bengt@@on @end|ng |rom gm@||@com  Sat Aug 29 19:21:28 2020
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sat, 29 Aug 2020 10:21:28 -0700
Subject: [R] serialize does not work as expected
In-Reply-To: <39302768-7fbf-8132-e604-0ee88d8cd050@wiwi.hu-berlin.de>
References: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
 <9d425b6b-ccc0-d489-c3f2-810d21da8d0d@gmail.com>
 <39302768-7fbf-8132-e604-0ee88d8cd050@wiwi.hu-berlin.de>
Message-ID: <CAFDcVCSsEmWYrmcwNdez0sNC0mo37_kv5iwCTme4Ku82XbsUig@mail.gmail.com>

Does serialize(..., version = 2L) do what you want?

/Henrik

On Sat, Aug 29, 2020 at 10:10 AM Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
>
> Hi,
>
> is there in R a way to "normalize" a vector from
> compact_intseq/compact_realseq to a "normal" vector?
>
> Sigbert
>
> Am 29.08.20 um 18:13 schrieb Duncan Murdoch:
> > Element 1
> > A
> > 3
> > 262146
> > 197888
> > 5
> > UTF-8
> > 238
> > 2
> > 1
> > 262153
> > 14
> > compact_intseq
> > 2
> > 1
> > 262153
> > 4
> > base
> > 2
> > 13
> > 1
> > 13
> > 254
> > 14
> > 3
> > 3
> > 1
> > 1
> > 254
> >
> > Element 2
> > A
> > 3
> > 262146
> > 197888
> > 5
> > UTF-8
> > 238
> > 2
> > 1
> > 262153
> > 15
> > compact_realseq
> > 2
> > 1
> > 262153
> > 4
> > base
> > 2
> > 13
> > 1
> > 14
> > 254
> > 14
> > 3
> > 3
> > 1
> > 1
> > 254
> >
> > Element 3
> > A
> > 3
> > 262146
> > 197888
> > 5
> > UTF-8
> > 14
> > 3
> > 1
> > 2
> > 3
>
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdun|@p @end|ng |rom t|bco@com  Sat Aug 29 19:23:29 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Sat, 29 Aug 2020 10:23:29 -0700
Subject: [R] serialize does not work as expected
In-Reply-To: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
References: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
Message-ID: <CAF8bMcY1h50FhOHbmKKg09tFj=3xYecxWH-ft7E4tB2wMo_-cA@mail.gmail.com>

For some reason l[[2]] is serialized as a 'compact_realseq' and l[3]]
is not.  They both unserialize to the same thing.  On Windows I get:

> lapply(l, function(x)rawToChar(serialize(x, connection=NULL, ascii=TRUE)))
[[1]]
[1] "A\n3\n262146\n197888\n6\nCP1252\n238\n2\n1\n262153\n14\ncompact_intseq\n2\n1\n262153\n4\nbase\n2\n13\n1\n13\n254\n14\n3\n3\n1\n1\n254\n"

[[2]]
[1] "A\n3\n262146\n197888\n6\nCP1252\n238\n2\n1\n262153\n15\ncompact_realseq\n2\n1\n262153\n4\nbase\n2\n13\n1\n14\n254\n14\n3\n3\n1\n1\n254\n"

[[3]]
[1] "A\n3\n262146\n197888\n6\nCP1252\n14\n3\n1\n2\n3\n"

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Aug 29, 2020 at 8:37 AM Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
>
> Hi,
>
> if I create a list with
>
> l <- list(1:3, as.numeric(1:3), c(1,2,3))
>
> and applying
>
> lapply(l, 'class')
> lapply(l, 'mode')
> lapply(l, 'storage.mode')
> lapply(l, 'typeof')
> identical(l[[2]], l[[3]])
>
> then I would believe that as,numeric(1:3) and c(1,2,3) are identical
> objects. However,
>
> lapply(l, serialize, connection=NULL)
>
> returns different results for each list element :(
>
> Any ideas, why it is like that?
>
> Best Sigbert
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@whct @end|ng |rom gm@||@com  Sat Aug 29 19:23:42 2020
From: j@whct @end|ng |rom gm@||@com (John Smith)
Date: Sat, 29 Aug 2020 12:23:42 -0500
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <CAFyG=WMtjKgn=tiuvrEu8fEZ-oB=MOY1C9sbJYyWjg+RTGqkkw@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
 <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>
 <972FD22B-9A75-4854-9005-7B4865D07564@gmail.com>
 <e5646682-62fa-6851-bb11-5cac294bbd53@mcmaster.ca>
 <CAFyG=WMtjKgn=tiuvrEu8fEZ-oB=MOY1C9sbJYyWjg+RTGqkkw@mail.gmail.com>
Message-ID: <CAFyG=WMoH_8Mb2Gt5WjYitDeimhJgtzNe1QXcoYLOeJLaREvrQ@mail.gmail.com>

In the book Modern Applied Statistics with S, 4th edition, 2002, by
Venables and Ripley, there is a function logitreg on page 445, which does
provide the weighted logistic regression I asked, judging by the loss
function. And interesting enough, logitreg provides the same coefficients
as glm in the example I provided earlier, even with weights < 1. Also for
residual deviance, logitreg yields the same number as glm. Unless I
misunderstood something, I am convinced that glm is a valid tool for
weighted logistic regression despite the description on weights and somehow
questionable logLik value in the case of non-integer weights < 1. Perhaps
this is a bold claim: the description of weights can be modified and logLik
can be updated as well.

The stackexchange inquiry I provided is what I feel interesting, not the
link in that post. Sorry for the confusion.

On Sat, Aug 29, 2020 at 10:18 AM John Smith <jswhct at gmail.com> wrote:

> Thanks for very insightful thoughts. What I am trying to achieve with the
> weights is actually not new, something like
> https://stats.stackexchange.com/questions/44776/logistic-regression-with-weighted-instances.
> I thought my inquiry was not too strange, and I could utilize some existing
> codes. It is just an optimization problem at the end of day, or not? Thanks
>
> On Sat, Aug 29, 2020 at 9:02 AM John Fox <jfox at mcmaster.ca> wrote:
>
>> Dear John,
>>
>> On 2020-08-29 1:30 a.m., John Smith wrote:
>> > Thanks Prof. Fox.
>> >
>> > I am curious: what is the model estimated below?
>>
>> Nonsense, as Peter explained in a subsequent response to your prior
>> posting.
>>
>> >
>> > I guess my inquiry seems more complicated than I thought: with y being
>> 0/1, how to fit weighted logistic regression with weights <1, in the sense
>> of weighted least squares? Thanks
>>
>> What sense would that make? WLS is meant to account for non-constant
>> error variance in a linear model, but in a binomial GLM, the variance is
>> purely a function for the mean.
>>
>> If you had binomial (rather than binary 0/1) observations (i.e.,
>> binomial trials exceeding 1), then you could account for overdispersion,
>> e.g., by introducing a dispersion parameter via the quasibinomial
>> family, but that isn't equivalent to variance weights in a LM, rather to
>> the error-variance parameter in a LM.
>>
>> I guess the question is what are you trying to achieve with the weights?
>>
>> Best,
>>   John
>>
>> >
>> >> On Aug 28, 2020, at 10:51 PM, John Fox <jfox at mcmaster.ca> wrote:
>> >>
>> >> Dear John
>> >>
>> >> I think that you misunderstand the use of the weights argument to
>> glm() for a binomial GLM. From ?glm: "For a binomial GLM prior weights are
>> used to give the number of trials when the response is the proportion of
>> successes." That is, in this case y should be the observed proportion of
>> successes (i.e., between 0 and 1) and the weights are integers giving the
>> number of trials for each binomial observation.
>> >>
>> >> I hope this helps,
>> >> John
>> >>
>> >> John Fox, Professor Emeritus
>> >> McMaster University
>> >> Hamilton, Ontario, Canada
>> >> web: https://socialsciences.mcmaster.ca/jfox/
>> >>
>> >>> On 2020-08-28 9:28 p.m., John Smith wrote:
>> >>> If the weights < 1, then we have different values! See an example
>> below.
>> >>> How  should I interpret logLik value then?
>> >>> set.seed(135)
>> >>>   y <- c(rep(0, 50), rep(1, 50))
>> >>>   x <- rnorm(100)
>> >>>   data <- data.frame(cbind(x, y))
>> >>>   weights <- c(rep(1, 50), rep(2, 50))
>> >>>   fit <- glm(y~x, data, family=binomial(), weights/10)
>> >>>   res.dev <- residuals(fit, type="deviance")
>> >>>   res2 <- -0.5*res.dev^2
>> >>>   cat("loglikelihood value", logLik(fit), sum(res2), "\n")
>> >>>> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard <pdalgd at gmail.com>
>> wrote:
>> >>>> If you don't worry too much about an additive constant, then half the
>> >>>> negative squared deviance residuals should do. (Not quite sure how
>> weights
>> >>>> factor in. Looks like they are accounted for.)
>> >>>>
>> >>>> -pd
>> >>>>
>> >>>>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com> wrote:
>> >>>>>
>> >>>>> Dear R-help,
>> >>>>>
>> >>>>> The function logLik can be used to obtain the maximum log-likelihood
>> >>>> value
>> >>>>> from a glm object. This is an aggregated value, a summation of
>> individual
>> >>>>> log-likelihood values. How do I obtain individual values? In the
>> >>>> following
>> >>>>> example, I would expect 9 numbers since the response has length 9. I
>> >>>> could
>> >>>>> write a function to compute the values, but there are lots of
>> >>>>> family members in glm, and I am trying not to reinvent wheels.
>> Thanks!
>> >>>>>
>> >>>>> counts <- c(18,17,15,20,10,20,25,13,12)
>> >>>>>      outcome <- gl(3,1,9)
>> >>>>>      treatment <- gl(3,3)
>> >>>>>      data.frame(treatment, outcome, counts) # showing data
>> >>>>>      glm.D93 <- glm(counts ~ outcome + treatment, family =
>> poisson())
>> >>>>>      (ll <- logLik(glm.D93))
>> >>>>>
>> >>>>>        [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>> --
>> >>>> Peter Dalgaard, Professor,
>> >>>> Center for Statistics, Copenhagen Business School
>> >>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> >>>> Phone: (+45)38153501
>> >>>> Office: A 4.23
>> >>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>     [[alternative HTML version deleted]]
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug 29 20:14:23 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 29 Aug 2020 14:14:23 -0400
Subject: [R] How to obtain individual log-likelihood value from glm?
In-Reply-To: <CAFyG=WMoH_8Mb2Gt5WjYitDeimhJgtzNe1QXcoYLOeJLaREvrQ@mail.gmail.com>
References: <CAFyG=WPbp8XCToME-AMTwM4D3YkLEdENUr_HHWZ6EjHhPwo4Ng@mail.gmail.com>
 <D1D996D0-5BC9-4BAC-9655-EAFBBDA6E9F2@gmail.com>
 <6048_1598664524_07T1Shrm005013_CAFyG=WPFvZDnox3yTG07O__6KzPojpX6HfPkdyn=GSf5h=RrXg@mail.gmail.com>
 <3b6c0844-4aff-49bd-6291-09dee4e4862f@mcmaster.ca>
 <972FD22B-9A75-4854-9005-7B4865D07564@gmail.com>
 <e5646682-62fa-6851-bb11-5cac294bbd53@mcmaster.ca>
 <CAFyG=WMtjKgn=tiuvrEu8fEZ-oB=MOY1C9sbJYyWjg+RTGqkkw@mail.gmail.com>
 <CAFyG=WMoH_8Mb2Gt5WjYitDeimhJgtzNe1QXcoYLOeJLaREvrQ@mail.gmail.com>
Message-ID: <7fc43740-5097-eaa7-614d-618af8762ca1@mcmaster.ca>

Dear John,

If you look at the code for logitreg() in the MASS text, you'll see that 
the casewise components of the log-likelihood are multiplied by the 
corresponding weights. As far as I can see, this only makes sense if the 
weights are binomial trials. Otherwise, while the coefficients 
themselves will be the same as obtained for proportionally similar 
integer weights (e.g., using your weights rather than weights/10), 
quantities such as the maximized log-likelihood, deviance, and 
coefficient standard errors will be uninterpretable.

logitreg() is simply another way to compute the MLE, using a 
general-purpose optimizer rather than than iteratively weighted 
least-squares, which is what glm() uses. That the two functions provide 
the same answer within rounding error is unsurprising -- they're solving 
the same problem. A difference between the two functions is that glm() 
issues a warning about non-integer weights, while logitreg() doesn't. As 
I understand it, the motivation for writing logitreg() is to provide a 
function that could easily be modified, e.g., to impose parameter 
constraints on the solution.

I think that this discussion has gotten unproductive. If you feel that 
proceeding with noninteger weights makes sense, for a reason that I 
don't understand, then you should go ahead.

Best,
  John

On 2020-08-29 1:23 p.m., John Smith wrote:
> In the book Modern Applied Statistics with S, 4th edition, 2002, by 
> Venables and Ripley, there is a function logitreg on page 445, which 
> does provide the weighted logistic regression I asked, judging by the 
> loss function. And interesting enough, logitreg?provides the same 
> coefficients as glm in the example I provided earlier, even with weights 
> < 1. Also for residual?deviance, logitreg?yields the same number as glm. 
> Unless I misunderstood something, I am convinced that glm is a 
> valid?tool for weighted logistic regression despite the description on 
> weights and somehow questionable logLik value in the case of non-integer 
> weights < 1. Perhaps this is a bold claim: the description of weights 
> can be modified and logLik can be updated as well.
> 
> The stackexchange inquiry I provided is what I feel interesting, not the 
> link in that post. Sorry for the confusion.
> 
> On Sat, Aug 29, 2020 at 10:18 AM John Smith <jswhct at gmail.com 
> <mailto:jswhct at gmail.com>> wrote:
> 
>     Thanks for very insightful thoughts. What I am trying?to achieve
>     with the weights is actually not new, something like
>     https://stats.stackexchange.com/questions/44776/logistic-regression-with-weighted-instances.
>     I thought my inquiry was not too strange, and I could utilize some
>     existing codes. It is just an optimization problem at the end of
>     day, or not? Thanks
> 
>     On Sat, Aug 29, 2020 at 9:02 AM John Fox <jfox at mcmaster.ca
>     <mailto:jfox at mcmaster.ca>> wrote:
> 
>         Dear John,
> 
>         On 2020-08-29 1:30 a.m., John Smith wrote:
>          > Thanks Prof. Fox.
>          >
>          > I am curious: what is the model estimated below?
> 
>         Nonsense, as Peter explained in a subsequent response to your
>         prior posting.
> 
>          >
>          > I guess my inquiry seems more complicated than I thought:
>         with y being 0/1, how to fit weighted logistic regression with
>         weights <1, in the sense of weighted least squares? Thanks
> 
>         What sense would that make? WLS is meant to account for
>         non-constant
>         error variance in a linear model, but in a binomial GLM, the
>         variance is
>         purely a function for the mean.
> 
>         If you had binomial (rather than binary 0/1) observations (i.e.,
>         binomial trials exceeding 1), then you could account for
>         overdispersion,
>         e.g., by introducing a dispersion parameter via the quasibinomial
>         family, but that isn't equivalent to variance weights in a LM,
>         rather to
>         the error-variance parameter in a LM.
> 
>         I guess the question is what are you trying to achieve with the
>         weights?
> 
>         Best,
>          ? John
> 
>          >
>          >> On Aug 28, 2020, at 10:51 PM, John Fox <jfox at mcmaster.ca
>         <mailto:jfox at mcmaster.ca>> wrote:
>          >>
>          >> Dear John
>          >>
>          >> I think that you misunderstand the use of the weights
>         argument to glm() for a binomial GLM. From ?glm: "For a binomial
>         GLM prior weights are used to give the number of trials when the
>         response is the proportion of successes." That is, in this case
>         y should be the observed proportion of successes (i.e., between
>         0 and 1) and the weights are integers giving the number of
>         trials for each binomial observation.
>          >>
>          >> I hope this helps,
>          >> John
>          >>
>          >> John Fox, Professor Emeritus
>          >> McMaster University
>          >> Hamilton, Ontario, Canada
>          >> web: https://socialsciences.mcmaster.ca/jfox/
>          >>
>          >>> On 2020-08-28 9:28 p.m., John Smith wrote:
>          >>> If the weights < 1, then we have different values! See an
>         example below.
>          >>> How? should I interpret logLik value then?
>          >>> set.seed(135)
>          >>>? ?y <- c(rep(0, 50), rep(1, 50))
>          >>>? ?x <- rnorm(100)
>          >>>? ?data <- data.frame(cbind(x, y))
>          >>>? ?weights <- c(rep(1, 50), rep(2, 50))
>          >>>? ?fit <- glm(y~x, data, family=binomial(), weights/10)
>          >>> res.dev <http://res.dev> <- residuals(fit, type="deviance")
>          >>>? ?res2 <- -0.5*res.dev <http://res.dev>^2
>          >>>? ?cat("loglikelihood value", logLik(fit), sum(res2), "\n")
>          >>>> On Tue, Aug 25, 2020 at 11:40 AM peter dalgaard
>         <pdalgd at gmail.com <mailto:pdalgd at gmail.com>> wrote:
>          >>>> If you don't worry too much about an additive constant,
>         then half the
>          >>>> negative squared deviance residuals should do. (Not quite
>         sure how weights
>          >>>> factor in. Looks like they are accounted for.)
>          >>>>
>          >>>> -pd
>          >>>>
>          >>>>> On 25 Aug 2020, at 17:33 , John Smith <jswhct at gmail.com
>         <mailto:jswhct at gmail.com>> wrote:
>          >>>>>
>          >>>>> Dear R-help,
>          >>>>>
>          >>>>> The function logLik can be used to obtain the maximum
>         log-likelihood
>          >>>> value
>          >>>>> from a glm object. This is an aggregated value, a
>         summation of individual
>          >>>>> log-likelihood values. How do I obtain individual values?
>         In the
>          >>>> following
>          >>>>> example, I would expect 9 numbers since the response has
>         length 9. I
>          >>>> could
>          >>>>> write a function to compute the values, but there are lots of
>          >>>>> family members in glm, and I am trying not to reinvent
>         wheels. Thanks!
>          >>>>>
>          >>>>> counts <- c(18,17,15,20,10,20,25,13,12)
>          >>>>>? ? ? outcome <- gl(3,1,9)
>          >>>>>? ? ? treatment <- gl(3,3)
>          >>>>>? ? ? data.frame(treatment, outcome, counts) # showing data
>          >>>>>? ? ? glm.D93 <- glm(counts ~ outcome + treatment, family
>         = poisson())
>          >>>>>? ? ? (ll <- logLik(glm.D93))
>          >>>>>
>          >>>>>? ? ? ? [[alternative HTML version deleted]]
>          >>>>>
>          >>>>> ______________________________________________
>          >>>>> R-help at r-project.org <mailto:R-help at r-project.org>
>         mailing list -- To UNSUBSCRIBE and more, see
>          >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>          >>>>> PLEASE do read the posting guide
>          >>>> http://www.R-project.org/posting-guide.html
>          >>>>> and provide commented, minimal, self-contained,
>         reproducible code.
>          >>>>
>          >>>> --
>          >>>> Peter Dalgaard, Professor,
>          >>>> Center for Statistics, Copenhagen Business School
>          >>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>          >>>> Phone: (+45)38153501
>          >>>> Office: A 4.23
>          >>>> Email: pd.mes at cbs.dk <mailto:pd.mes at cbs.dk>? Priv:
>         PDalgd at gmail.com <mailto:PDalgd at gmail.com>
>          >>>>
>          >>>>
>          >>>>
>          >>>>
>          >>>>
>          >>>>
>          >>>>
>          >>>>
>          >>>>
>          >>>>
>          >>>? ? ?[[alternative HTML version deleted]]
>          >>> ______________________________________________
>          >>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>          >>> https://stat.ethz.ch/mailman/listinfo/r-help
>          >>> PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>          >>> and provide commented, minimal, self-contained,
>         reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Aug 29 21:03:45 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 29 Aug 2020 15:03:45 -0400
Subject: [R] serialize does not work as expected
In-Reply-To: <39302768-7fbf-8132-e604-0ee88d8cd050@wiwi.hu-berlin.de>
References: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
 <9d425b6b-ccc0-d489-c3f2-810d21da8d0d@gmail.com>
 <39302768-7fbf-8132-e604-0ee88d8cd050@wiwi.hu-berlin.de>
Message-ID: <74c700de-1db5-6f3d-f917-0b5ff3307e37@gmail.com>

On 29/08/2020 1:10 p.m., Sigbert Klinke wrote:
> Hi,
> 
> is there in R a way to "normalize" a vector from
> compact_intseq/compact_realseq to a "normal" vector?

I don't know if there's a function specifically designed to do that, but 
as Henrik proposed, this works:

  l_normalized <- unserialize(serialize(l, connection=NULL, version=2))

Duncan Murdoch


From b@ye@|@n|og|c@1 @end|ng |rom gm@||@com  Sat Aug 29 21:33:25 2020
From: b@ye@|@n|og|c@1 @end|ng |rom gm@||@com (Jan Galkowski)
Date: Sat, 29 Aug 2020 15:33:25 -0400
Subject: [R] Would Like Some Advise
In-Reply-To: <mailman.360544.1.1598695201.35979.r-help@r-project.org>
References: <mailman.360544.1.1598695201.35979.r-help@r-project.org>
Message-ID: <2b56be39-110d-4b7f-b6f4-1ecaf1864bbe@www.fastmail.com>

Hi Philip,

This ends up being a pretty personal decision, but here's my advice.  

I have used Windows of various flavors, and Linux in a couple of versions.  I have also used four or five Unixen, in addition to Linux. I've never spent a lot of time using a Mac, although in many instances most of my colleagues at companies have.  It's invariably a cubicle-like environment, so when they have problems, you know.   I also have a Chromebook, which is what I am using to write this, and while awaiting the arrival of a new Windows 10 system. 

I have used R heavily on both Windows and Linux. On Linux I used it on my desktop, and I still use it on various large servers, now via RStudio, before from the shell. In the case of the servers, I don't have to maintain them, although I sometimes need to put up with peculiarities of their being maintained by others. (I rarely have sudo access, and sometimes someone has to install something for me, or help me install an R package, because the configuration of libraries on the server isn't quite what R expects.)

My experience with Linux desktops is that they seem fine initially, but then, inevitably, one day you need to upgrade to the next version of Ubuntu or whatever, and, for me, then the hell begins. In the last two times I did it, even with help of co-workers, it was so problematic, that I turned the desktop in, and stopped using the Linux. 

Prior to my last Linux version, I also seemed to need to spend an increasingly large amount of time doing maintanence and moving things around ... I ran out of R library space once and had to move the entire installation elsewhere.  I did, but it took literally 2 days to figured it out. 

Yes, if Linux runs out of physical store -- a moment which isn't always predictable -- R freezes.  Memory is of course an issue with Windows, but it simply does what, in my opinion, any modern system does and pages out to virtual memory, up to some limit of course.  (I always begin my  Windows R workspaces with 16 GB of RAM, and have expanded to 40 GB at times.)  I have just purchased a new Windows 10 system, was going to get 64 GB of RAM, but, for economy, settled on 32 GB. (I'm semi-retired as well.) My practice on the old Windows 7 system (with 16 GB RAM) was that I purchased a 256 GB SSD and put the paging file there.  That's not quite as good as RAM, but it's much better than a mechanical magnetic drive. My new Windows 10 has a 1 TB SSD.  I may move my old 256 GB SSD over to the new just as a side store, but will need to observe system cooling limits.  The new system is an 8 core Intel I7. 

Windows updates are a pain, mostly because they almost always involve a reboot. I *loved* using my Windows 7 past end of support because there were no updates.  I always found Windows Office programs to be incredibly annoying, tolerating them because if you exchange documents with the rest of the world, some appreciable fraction will be Word and Excel spreadsheets.  That said, I got rid of all my official Microsoft Office and moved to Open Office, which is fine. I also primarily use LaTeX and MikTeX for my own documents authored, and often use R to generate tables and other things for including in the LaTeX. 

On the other hand, when using Linux, ultimately YOU are responsible for keeping your libraries and everything else updated. When R updates, and new packages need to be updated, too, the update mechanism for Linux is recompiling from source. You sometimes need to do that for Windows, and Rtools gives you the way, but generally packages are in binary form. This means they are independent of the particular configuration of libraries you have on your system. That's great in my opinion. And easy.  Occasionally you'll find an R package which is source only and for some reason doesn't work with Rtools.  Then you are sometimes out of luck or need to run the source version of the package, if it's supported, which can be slow.  Sometimes, but rarely, source versions aren't supported.  I have also found in server environments that administrators are sometimes sloppy about keeping their gcc and other things updated. So at times I couldn't compile R packages because the admin on the server had an out-of-date gcc which produced a buggy version. 
 
Whether Linux or Windows, I often use multi-core for the Monte Carlo calculations I run, whether bootstraps, random forests, or MCMC.  I have used JAGS quite a lot but I don't believe it supports multi-core (unless something has changed recently).  I use MCMCpack and others. 

The media support for Windows is much better than Linux.  (At least Ubuntu now *has* some.) And it is work to keep Linux meda properly updated.  Still, I don't use Windows Media Player, preferring VLC.

And there are a wealth of programs and software available for Windows.  

No doubt, you need a good anti-virus and a good firewall. (Heck, I have that on my Google Pixel 2, too.)  I'm moving to the McAfee subscription my wife has for other systems in the house. 

Note, while R is my primary computational world, by far, I do run Anaconda Python 3 from time to time.  It can be useful for preparing data for consumption by R, given raw files, many with glitches and mistakes.  But with the data.table package and other packages in R, I'm finding that's less and less true. The biggest headache of Python is that you need to keep its libraries updated.  I also have used Python some times just to access MATPLOTLIB.  I prefer R, though, because, like MATLAB, its numerics are better than Python's NUMPY and SCIPY.

As I said, I don't know Mac at all well.  But I do know that, when Mac released a new version, somehow the colleagues about me would often degenerate into a couple of days of grumbling and meeting with each other about how they got past or around some stumbling point when updating their systems.  Otherwise people seem to like them a lot. 

I think all operating systems are deals with the Devil. It's what you put up with and deal with. 

As you can see, I opted to go the Windows route again, for probably the next 10 years. 

YMMV.

 - Jan

On Sat, Aug 29, 2020, at 06:00, r-help-request at r-project.org wrote:
> From: "Philip" <herd_dog at cox.net>
> To: "r-help" <R-help at r-project.org>
> Subject: [R] Would Like Some Advise
> Message-ID: <1157A76A248944878C040D1FE0AE725C at OWNERPC>
> Content-Type: text/plain; charset="utf-8"
> 
> I need a new computer.  have a friend who is convinced that I have an 
> aura about me that just kills electronic devices.
> 
> Does anyone out there have an opinion about Windows vs. Linux?  
> 
> I?m retired so this is just for my own enjoyment but I?m crunching some 
> large National Weather Service files and will move on to baseball data 
> and a few other things.  I?d like some advise about how much RAM and 
> stuff like that.  I understand there is something called zones of 
> computer memory. Can someone direct me to a good source so I can learn 
> more?   I really don?t understand stuff like this.  Does anyone think I 
> need to upgrade my wifi?
> 
> Thanks,
> Philip


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sat Aug 29 23:15:56 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sat, 29 Aug 2020 21:15:56 +0000
Subject: [R] Solving derivates, getting the minimum of a function,
 and helpful documentation of the deriv function
Message-ID: <MN2PR03MB5167B9D0182701DE85DE967BE2530@MN2PR03MB5167.namprd03.prod.outlook.com>

I am trying to find the minimum of a linear function:

y <- (-0.0263*b) + (0.0010*B^2)

I am having GREAT difficulty with the documentation of the deriv function. I have (after playing for two-hours) been able to get the following to work:

zoop <- deriv(expression((-0.0263*B)+(0.0010*B^2)),"B",func=TRUE)
class(zoop)
zoop(2)

which appears to give me the value of the derivative of my expression w.r.t. B
(I am not certain what the func arugment does, but it appears to be necessary)

Following what one learns in calculus 1, I now need to set the derivative equal to 0 and solve for B. I have no idea how to do this

Can someone point me in the right direction. Additionally can someone suggest documentation for deriv that is easily intelligible to someone who wants to learn how to use the function, rather that documentation that helps one who is already familiar with the function. (I have a need for derivatives that is beyond finding the minimum of a function)

Thank you
John

P.S. Please don?t flame. I spent a good deal of time looking at documentation and searching the internet. There may be something on line, but I clearly am not using the correct search terms.







	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sat Aug 29 23:25:40 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 29 Aug 2020 14:25:40 -0700
Subject: [R] Solving derivates, getting the minimum of a function,
 and helpful documentation of the deriv function
In-Reply-To: <MN2PR03MB5167B9D0182701DE85DE967BE2530@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167B9D0182701DE85DE967BE2530@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <8FF690DD-FB70-45BB-85C5-1B8AE41D53DE@noaa.gov>

Hi John:

Can I ask if this is the specific problem you are after,  or a test for  more general problem?  If the former,  the derivative is

 -0.0263 + 0.002 * B

so the solution for B is:

B = (0263)/0.002

If you are after a more general way fo doing this:

?solve

-Roy

> On Aug 29, 2020, at 2:15 PM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> I am trying to find the minimum of a linear function:
> 
> y <- (-0.0263*b) + (0.0010*B^2)
> 
> I am having GREAT difficulty with the documentation of the deriv function. I have (after playing for two-hours) been able to get the following to work:
> 
> zoop <- deriv(expression((-0.0263*B)+(0.0010*B^2)),"B",func=TRUE)
> class(zoop)
> zoop(2)
> 
> which appears to give me the value of the derivative of my expression w.r.t. B
> (I am not certain what the func arugment does, but it appears to be necessary)
> 
> Following what one learns in calculus 1, I now need to set the derivative equal to 0 and solve for B. I have no idea how to do this
> 
> Can someone point me in the right direction. Additionally can someone suggest documentation for deriv that is easily intelligible to someone who wants to learn how to use the function, rather that documentation that helps one who is already familiar with the function. (I have a need for derivatives that is beyond finding the minimum of a function)
> 
> Thank you
> John
> 
> P.S. Please don?t flame. I spent a good deal of time looking at documentation and searching the internet. There may be something on line, but I clearly am not using the correct search terms.
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From j@zh@o @end|ng |rom ye@h@net  Sun Aug 30 01:30:27 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Sun, 30 Aug 2020 07:30:27 +0800
Subject: [R] tempdir() does not respect TMPDIR
In-Reply-To: <CAFDcVCRAAxdf0038rWR8cVN8pHD0NdcXHK+u4LtzhTbFYcX8cQ@mail.gmail.com>
References: <da93cf56-777b-bcb1-4994-b2a28b763abd@yeah.net>
 <CAFDcVCRAAxdf0038rWR8cVN8pHD0NdcXHK+u4LtzhTbFYcX8cQ@mail.gmail.com>
Message-ID: <f9fe4948-d163-ab5b-7898-0bcdd07685a4@yeah.net>

I read the help page, I don't understand it very well, since I set the 
environmental variable TMPDIR in .Renviron. What confused me is when 
double clicking the *.RData to launch R, the tempdir() does not respect 
the environmental variable TMPDIR, but launch R by double clicking Rgui 
icon does.

Best,
Jinsong

On 2020/8/30 0:36, Henrik Bengtsson wrote:
> It is too late to set TMPDIR in .Renviron.  It is one of the
> environment variables that has to be set prior to launching R.  From
> help("tempfile", package = "base"):
> 
> The environment variables TMPDIR, TMP and TEMP are checked in turn and
> the first found which points to a writable directory is used: if none
> succeeds ?/tmp? is used. The path should not contain spaces. **Note
> that setting any of these environment variables in the R session has
> no effect on tempdir(): the per-session temporary directory is created
> before the interpreter is started.**
> 
> /Henrik
> 
> On Sat, Aug 29, 2020 at 6:40 AM Jinsong Zhao <jszhao at yeah.net> wrote:
>>
>> Hi there,
>>
>> When I started R by double clicking on Rgui icon (I am on Windows), the
>> tempdir() returned the tmpdir in the directory I set in .Renviron. If I
>> started R by double clicking on a *.RData file, the tempdir() return the
>> tmpdir in the directory setting by Windows system. I don't know whether
>> it's designed.
>>
>>   > sessionInfo()
>> R version 4.0.2 (2020-06-22)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 18363)
>> ...
>>
>> Best,
>> Jinsong
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug 30 03:36:42 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 30 Aug 2020 13:36:42 +1200
Subject: [R] Solving derivates, getting the minimum of a function,
 and helpful documentation of the deriv function
In-Reply-To: <MN2PR03MB5167B9D0182701DE85DE967BE2530@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167B9D0182701DE85DE967BE2530@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <20200830133642.188b42ea@rolf-Latitude-E7470>


On Sat, 29 Aug 2020 21:15:56 +0000
"Sorkin, John" <jsorkin at som.umaryland.edu> wrote:

> I am trying to find the minimum of a linear function:

Quadratic function???
 
> y <- (-0.0263*b) + (0.0010*B^2)
> 
> I am having GREAT difficulty with the documentation of the deriv
> function. I have (after playing for two-hours) been able to get the
> following to work:
> 
> zoop <- deriv(expression((-0.0263*B)+(0.0010*B^2)),"B",func=TRUE)
> class(zoop)
> zoop(2)
> 
> which appears to give me the value of the derivative of my expression
> w.r.t. B (I am not certain what the func arugment does, but it
> appears to be necessary)

It causes deriv() to return a *function* rather than an *expression*.
> 
> Following what one learns in calculus 1, I now need to set the
> derivative equal to 0 and solve for B. I have no idea how to do this
> 
> Can someone point me in the right direction. Additionally can someone
> suggest documentation for deriv that is easily intelligible to
> someone who wants to learn how to use the function, rather that
> documentation that helps one who is already familiar with the
> function. (I have a need for derivatives that is beyond finding the
> minimum of a function)
> 
> Thank you
> John
> 
> P.S. Please don?t flame. I spent a good deal of time looking at
> documentation and searching the internet. There may be something on
> line, but I clearly am not using the correct search terms.

Couple of things that you could play around with.

y <- expression(-0.0263*B + 0.0010*B^2)
z <- deriv(y,"B",func=TRUE)
f <- function(x,z){as.vector(attr(z(x),"gradient"))}

(1) uniroot(f,c(5,15),z=z)$root
# 13.15 --- right answer!!! :-)

(2) library(polynom) # You may need to install this package.
    p <- poly.calc(x=1:2,y=f(1:2,z=z))
    polyroot(p)
# 13.15+0i You can get rid of the extraneous imaginary part
# by using Re(polyroot(p))

HTH

cheers,

Rolf

P.S. It's irritating the way that one has to fiddle about in order to
get a function that returns the value of the derivative, rather than the
value of the function being differentiated!

R.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @zwj|08 @end|ng |rom gm@||@com  Sun Aug 30 07:28:55 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jeff King)
Date: Sun, 30 Aug 2020 01:28:55 -0400
Subject: [R] serialize does not work as expected
In-Reply-To: <39302768-7fbf-8132-e604-0ee88d8cd050@wiwi.hu-berlin.de>
References: <526e2d4d-5b31-339c-ed75-e310b87f6b28@wiwi.hu-berlin.de>
 <9d425b6b-ccc0-d489-c3f2-810d21da8d0d@gmail.com>
 <39302768-7fbf-8132-e604-0ee88d8cd050@wiwi.hu-berlin.de>
Message-ID: <CAGiFhPO2XK67-Ttc9zqpo2XorZhyp8TQLPgAEDrzK+WhoqmFag@mail.gmail.com>

compact sequences are actually an ALTREP object. I do not know if there is
any standard way to do it, but here is a trick for what you want.

```
> x <- 1:3
> .Internal(inspect(x))
@0x00000196bed8dd78 13 INTSXP g0c0 [NAM(7)]  1 : 3 (compact)
> x[1] <- x[1]
> .Internal(inspect(x))
@0x00000196bef90b60 13 INTSXP g0c2 [NAM(7)] (len=3, tl=0) 1,2,3
```

Best,
Jiefei

On Sat, Aug 29, 2020 at 1:10 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
wrote:

> Hi,
>
> is there in R a way to "normalize" a vector from
> compact_intseq/compact_realseq to a "normal" vector?
>
> Sigbert
>
> Am 29.08.20 um 18:13 schrieb Duncan Murdoch:
> > Element 1
> > A
> > 3
> > 262146
> > 197888
> > 5
> > UTF-8
> > 238
> > 2
> > 1
> > 262153
> > 14
> > compact_intseq
> > 2
> > 1
> > 262153
> > 4
> > base
> > 2
> > 13
> > 1
> > 13
> > 254
> > 14
> > 3
> > 3
> > 1
> > 1
> > 254
> >
> > Element 2
> > A
> > 3
> > 262146
> > 197888
> > 5
> > UTF-8
> > 238
> > 2
> > 1
> > 262153
> > 15
> > compact_realseq
> > 2
> > 1
> > 262153
> > 4
> > base
> > 2
> > 13
> > 1
> > 14
> > 254
> > 14
> > 3
> > 3
> > 1
> > 1
> > 254
> >
> > Element 3
> > A
> > 3
> > 262146
> > 197888
> > 5
> > UTF-8
> > 14
> > 3
> > 1
> > 2
> > 3
>
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henr|k@bengt@@on @end|ng |rom gm@||@com  Sun Aug 30 21:45:03 2020
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sun, 30 Aug 2020 12:45:03 -0700
Subject: [R] tempdir() does not respect TMPDIR
In-Reply-To: <f9fe4948-d163-ab5b-7898-0bcdd07685a4@yeah.net>
References: <da93cf56-777b-bcb1-4994-b2a28b763abd@yeah.net>
 <CAFDcVCRAAxdf0038rWR8cVN8pHD0NdcXHK+u4LtzhTbFYcX8cQ@mail.gmail.com>
 <f9fe4948-d163-ab5b-7898-0bcdd07685a4@yeah.net>
Message-ID: <CAFDcVCQ1WqatVbEfOS6=vn+2rNiozdr-b=Wbn4x0RwrndrAJQw@mail.gmail.com>

Sorry, I should retract my claim that it's too late to set TMPDIR in
.Renviron.  It does indeed work on Linux and R 4.0.2, e.g.

$ cd
$ mkdir test
$ cd test
$ echo "TMPDIR=$PWD" > ./.Renviron
$ cat ./.Renviron
TMPDIR=/home/hb/test
Rscript --no-init-file -e "tempdir()"
[1] "/home/hb/test/RtmpyH47tc"

Hmm... either this has changed "recently" or I've got it wrong all the
time.  Eitherway, I need to revise the vignette in my 'startup'
package.

Sorry for the misleading comment.

So, back to your comment about it does *not* work, that is,
~/.Renviron is not read, when you double-click on an .RData file.  I
just tried with R 4.0.2 in a Windows 10 VM and I think I can reproduce
what you're describing.

The problem seems to be that when one launches Rgui via
double-clicking .RData, the Rgui will only read ./.Renviron, that is,
the .Renviron file that is located in the same folder as the .RData
file.  It will never load ~/.Renviron (e.g.
C:/Users\alice/Documents/.Renviron) unless the .RData file is in that
folder too.

This looks odd to me but it could be that I made another mistake in my
conclusions above.  I let someone else with a less mushy brain take
over from here.

/Henrik

On Sat, Aug 29, 2020 at 4:31 PM Jinsong Zhao <jszhao at yeah.net> wrote:
>
> I read the help page, I don't understand it very well, since I set the
> environmental variable TMPDIR in .Renviron. What confused me is when
> double clicking the *.RData to launch R, the tempdir() does not respect
> the environmental variable TMPDIR, but launch R by double clicking Rgui
> icon does.
>
> Best,
> Jinsong
>
> On 2020/8/30 0:36, Henrik Bengtsson wrote:
> > It is too late to set TMPDIR in .Renviron.  It is one of the
> > environment variables that has to be set prior to launching R.  From
> > help("tempfile", package = "base"):
> >
> > The environment variables TMPDIR, TMP and TEMP are checked in turn and
> > the first found which points to a writable directory is used: if none
> > succeeds ?/tmp? is used. The path should not contain spaces. **Note
> > that setting any of these environment variables in the R session has
> > no effect on tempdir(): the per-session temporary directory is created
> > before the interpreter is started.**
> >
> > /Henrik
> >
> > On Sat, Aug 29, 2020 at 6:40 AM Jinsong Zhao <jszhao at yeah.net> wrote:
> >>
> >> Hi there,
> >>
> >> When I started R by double clicking on Rgui icon (I am on Windows), the
> >> tempdir() returned the tmpdir in the directory I set in .Renviron. If I
> >> started R by double clicking on a *.RData file, the tempdir() return the
> >> tmpdir in the directory setting by Windows system. I don't know whether
> >> it's designed.
> >>
> >>   > sessionInfo()
> >> R version 4.0.2 (2020-06-22)
> >> Platform: x86_64-w64-mingw32/x64 (64-bit)
> >> Running under: Windows 10 x64 (build 18363)
> >> ...
> >>
> >> Best,
> >> Jinsong
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k@ym|n@ko @end|ng |rom gm@||@com  Sun Aug 30 20:11:02 2020
From: k@ym|n@ko @end|ng |rom gm@||@com (Kyungmin Ko)
Date: Sun, 30 Aug 2020 14:11:02 -0400
Subject: [R] 
 Can I use "mcnemar.test" for 3*3 tables (or is there a bug in
 the command?)
Message-ID: <CAAh8H1ENJ++uv0A6PPU7udtJgAd=-_ZbkG7YOsdQ11ZZub1n4w@mail.gmail.com>

>2) The second one is to produce a 3 by 3 table, with the rows indicating
>what the kids answered to setting 1 of the experiment, and the columns
>indicating the kids answers to setting 2.
>Now the question is:
>was there marginal homogenity? if not, then that is an indicator that the
>general response to the experimental settings was different for the kids.

>1) can I use "mcnemar.test" for 3*3 (or more) tables ?
As Peter Dalgaard and jchavez12 (on Nabble) pointed out,
"mcnemar.test" does McNemar-Bowker test (Bowker's test) which tests
symmetry, not marginal homogeneity.
Marginal homogeneity and symmetry are equivalent in 2x2 matrices but
not for larger tables.
I also was confused because many resources (for example Wikipedia
accessed 2020-08-30) introduce McNemar's test as a test of marginal
homogeneity (which it is only for 2x2 matrices).
The R Reference Manual entry for mcnemar.test states that it tests for symmetry.
The code for mcnemar.test is also consistent with the McNemar-Bowker
test for symmetry.

>Is there a bug in the command?
Since the function does what the manual states it does, I would not
call this a bug.
Although, I would like it if the result of mcnemar.test would print
"McNemar's Chi-squared test of symmetry" rather than just "McNemar's
Chi-squared test."

>Is the one necessarily better then the other? (for example for
>sparser matrices ?)
mcnemar.test often fails for sparse matrices, because symmetric zeros
produce a NaN due to division by zero in the following line of
mcnemar.test code:
STATISTIC <- sum(y[upper.tri(x)]^2/x[upper.tri(x)])
The McNemar-Bowker test uses Chi-squared approximation, which would
not be good for small counts (and sparse matrices).
mcnemar.test does not perform continuity correction for matrices
larger than 2x2.
Is there an exact test for symmetry of matrices larger than 2x2?
I could not find one.

>Is there a bug in the command?
I would not call this a bug.
This behavior of giving "NA" due to a division by zero seems to be
consistent across statistical tests in R.
For example chisq.test(matrix(c(0, 0, 1, 2), nrow = 2) gives NA.

>So which one is "right" ?
You have the option of the McNemar-Bowker test for symmetry
(mcnemar.test), and Stuart-Maxwell test (mh_test).
As an "indicator that the general response to the experimental
settings was different for the kids,"
I would think that if marginal homogeneity is rejected, the two tests
are not equivalent.
I would run mh_test with distribution = "exact" .
The relationship between symmetry and equivalence of two tests is not
as clear to me.
I suppose if the two experimental settings are equivalent and the
distribution of random error for each test are also the same the
resulting matrix would be symmetric?

R 4.0.2 . coin 1.3.1 .


From j@zh@o @end|ng |rom ye@h@net  Mon Aug 31 03:40:56 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Mon, 31 Aug 2020 09:40:56 +0800
Subject: [R] tempdir() does not respect TMPDIR
In-Reply-To: <CAFDcVCQ1WqatVbEfOS6=vn+2rNiozdr-b=Wbn4x0RwrndrAJQw@mail.gmail.com>
References: <da93cf56-777b-bcb1-4994-b2a28b763abd@yeah.net>
 <CAFDcVCRAAxdf0038rWR8cVN8pHD0NdcXHK+u4LtzhTbFYcX8cQ@mail.gmail.com>
 <f9fe4948-d163-ab5b-7898-0bcdd07685a4@yeah.net>
 <CAFDcVCQ1WqatVbEfOS6=vn+2rNiozdr-b=Wbn4x0RwrndrAJQw@mail.gmail.com>
Message-ID: <73cf597d-2b2c-b88b-64a3-0a4c3be8d867@yeah.net>

Thanks a lot for the confirmation and explanation.

On 2020/8/31 3:45, Henrik Bengtsson wrote:
> Sorry, I should retract my claim that it's too late to set TMPDIR in
> .Renviron.  It does indeed work on Linux and R 4.0.2, e.g.
> 
> $ cd
> $ mkdir test
> $ cd test
> $ echo "TMPDIR=$PWD" > ./.Renviron
> $ cat ./.Renviron
> TMPDIR=/home/hb/test
> Rscript --no-init-file -e "tempdir()"
> [1] "/home/hb/test/RtmpyH47tc"
> 
> Hmm... either this has changed "recently" or I've got it wrong all the
> time.  Eitherway, I need to revise the vignette in my 'startup'
> package.

This works just becuase .Renviron is in the same directory R launched. 
It confirmed what you stated that launched Rgui via double-clicking 
.RData. Generally, we put .Renviron in R_USER (on Windows).

> 
> Sorry for the misleading comment.
> 
> So, back to your comment about it does *not* work, that is,
> ~/.Renviron is not read, when you double-click on an .RData file.  I
> just tried with R 4.0.2 in a Windows 10 VM and I think I can reproduce
> what you're describing.
> 
> The problem seems to be that when one launches Rgui via
> double-clicking .RData, the Rgui will only read ./.Renviron, that is,
> the .Renviron file that is located in the same folder as the .RData
> file.  It will never load ~/.Renviron (e.g.
> C:/Users\alice/Documents/.Renviron) unless the .RData file is in that
> folder too.

I should guess to that you said. When I launched R from console (cmd on 
Windows) by command like:

C:\Users\zjs>"c:\Program Files\R\R-4.0.2\bin\R.exe"
or
C:\Users\zjs>"c:\Program Files\R\R-4.0.2\bin\x64\Rgui.exe"

The tempdir() does not return the value I set in .Renviron. It means 
when R launching, it search .Renvrion in the current directory. If it 
does not get the .Renviron, it does not search it in R_USER. Am I right?

So where I set TMPDIR, R would use it whenever it launched? The purpose 
that I tried to set TMPDIR is RStudio may refuse to work when user name 
contained non-latin characters.

Thanks again.

Best,
Jinsong

> 
> This looks odd to me but it could be that I made another mistake in my
> conclusions above.  I let someone else with a less mushy brain take
> over from here.
> 
> /Henrik
> 
> On Sat, Aug 29, 2020 at 4:31 PM Jinsong Zhao <jszhao at yeah.net> wrote:
>>
>> I read the help page, I don't understand it very well, since I set the
>> environmental variable TMPDIR in .Renviron. What confused me is when
>> double clicking the *.RData to launch R, the tempdir() does not respect
>> the environmental variable TMPDIR, but launch R by double clicking Rgui
>> icon does.
>>
>> Best,
>> Jinsong
>>
>> On 2020/8/30 0:36, Henrik Bengtsson wrote:
>>> It is too late to set TMPDIR in .Renviron.  It is one of the
>>> environment variables that has to be set prior to launching R.  From
>>> help("tempfile", package = "base"):
>>>
>>> The environment variables TMPDIR, TMP and TEMP are checked in turn and
>>> the first found which points to a writable directory is used: if none
>>> succeeds ?/tmp? is used. The path should not contain spaces. **Note
>>> that setting any of these environment variables in the R session has
>>> no effect on tempdir(): the per-session temporary directory is created
>>> before the interpreter is started.**
>>>
>>> /Henrik
>>>
>>> On Sat, Aug 29, 2020 at 6:40 AM Jinsong Zhao <jszhao at yeah.net> wrote:
>>>>
>>>> Hi there,
>>>>
>>>> When I started R by double clicking on Rgui icon (I am on Windows), the
>>>> tempdir() returned the tmpdir in the directory I set in .Renviron. If I
>>>> started R by double clicking on a *.RData file, the tempdir() return the
>>>> tmpdir in the directory setting by Windows system. I don't know whether
>>>> it's designed.
>>>>
>>>>    > sessionInfo()
>>>> R version 4.0.2 (2020-06-22)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 10 x64 (build 18363)
>>>> ...
>>>>
>>>> Best,
>>>> Jinsong


From j@zh@o @end|ng |rom ye@h@net  Mon Aug 31 05:06:06 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Mon, 31 Aug 2020 11:06:06 +0800
Subject: [R] tempdir() does not respect TMPDIR
In-Reply-To: <CAFDcVCQ1WqatVbEfOS6=vn+2rNiozdr-b=Wbn4x0RwrndrAJQw@mail.gmail.com>
References: <da93cf56-777b-bcb1-4994-b2a28b763abd@yeah.net>
 <CAFDcVCRAAxdf0038rWR8cVN8pHD0NdcXHK+u4LtzhTbFYcX8cQ@mail.gmail.com>
 <f9fe4948-d163-ab5b-7898-0bcdd07685a4@yeah.net>
 <CAFDcVCQ1WqatVbEfOS6=vn+2rNiozdr-b=Wbn4x0RwrndrAJQw@mail.gmail.com>
Message-ID: <b8c86634-91ec-a0df-b9a9-07dfb3f55aec@yeah.net>

The solution to this question is to set environmental variable R_ENVIRON 
that point to the .Renviron file. I should read the ?Startup more carefully.

Best,
Jinsong

On 2020/8/31 3:45, Henrik Bengtsson wrote:
> Sorry, I should retract my claim that it's too late to set TMPDIR in
> .Renviron.  It does indeed work on Linux and R 4.0.2, e.g.
> 
> $ cd
> $ mkdir test
> $ cd test
> $ echo "TMPDIR=$PWD" > ./.Renviron
> $ cat ./.Renviron
> TMPDIR=/home/hb/test
> Rscript --no-init-file -e "tempdir()"
> [1] "/home/hb/test/RtmpyH47tc"
> 
> Hmm... either this has changed "recently" or I've got it wrong all the
> time.  Eitherway, I need to revise the vignette in my 'startup'
> package.
> 
> Sorry for the misleading comment.
> 
> So, back to your comment about it does *not* work, that is,
> ~/.Renviron is not read, when you double-click on an .RData file.  I
> just tried with R 4.0.2 in a Windows 10 VM and I think I can reproduce
> what you're describing.
> 
> The problem seems to be that when one launches Rgui via
> double-clicking .RData, the Rgui will only read ./.Renviron, that is,
> the .Renviron file that is located in the same folder as the .RData
> file.  It will never load ~/.Renviron (e.g.
> C:/Users\alice/Documents/.Renviron) unless the .RData file is in that
> folder too.
> 
> This looks odd to me but it could be that I made another mistake in my
> conclusions above.  I let someone else with a less mushy brain take
> over from here.
> 
> /Henrik
> 
> On Sat, Aug 29, 2020 at 4:31 PM Jinsong Zhao <jszhao at yeah.net> wrote:
>>
>> I read the help page, I don't understand it very well, since I set the
>> environmental variable TMPDIR in .Renviron. What confused me is when
>> double clicking the *.RData to launch R, the tempdir() does not respect
>> the environmental variable TMPDIR, but launch R by double clicking Rgui
>> icon does.
>>
>> Best,
>> Jinsong
>>
>> On 2020/8/30 0:36, Henrik Bengtsson wrote:
>>> It is too late to set TMPDIR in .Renviron.  It is one of the
>>> environment variables that has to be set prior to launching R.  From
>>> help("tempfile", package = "base"):
>>>
>>> The environment variables TMPDIR, TMP and TEMP are checked in turn and
>>> the first found which points to a writable directory is used: if none
>>> succeeds ?/tmp? is used. The path should not contain spaces. **Note
>>> that setting any of these environment variables in the R session has
>>> no effect on tempdir(): the per-session temporary directory is created
>>> before the interpreter is started.**
>>>
>>> /Henrik
>>>
>>> On Sat, Aug 29, 2020 at 6:40 AM Jinsong Zhao <jszhao at yeah.net> wrote:
>>>>
>>>> Hi there,
>>>>
>>>> When I started R by double clicking on Rgui icon (I am on Windows), the
>>>> tempdir() returned the tmpdir in the directory I set in .Renviron. If I
>>>> started R by double clicking on a *.RData file, the tempdir() return the
>>>> tmpdir in the directory setting by Windows system. I don't know whether
>>>> it's designed.
>>>>
>>>>    > sessionInfo()
>>>> R version 4.0.2 (2020-06-22)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 10 x64 (build 18363)
>>>> ...
>>>>
>>>> Best,
>>>> Jinsong


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Mon Aug 31 05:25:44 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Sun, 30 Aug 2020 20:25:44 -0700
Subject: [R] 
 PROBLEM: quickly downloading 10,000 articles to sift through
In-Reply-To: <CY4PR0701MB369878348CB5F237F8108C49C3550@CY4PR0701MB3698.namprd07.prod.outlook.com>
References: <CY4PR0701MB369878348CB5F237F8108C49C3550@CY4PR0701MB3698.namprd07.prod.outlook.com>
Message-ID: <CAA99HCwPciBRw6eQ6f83TdzRuatTtd=GK3+bZm-kkf+73159SQ@mail.gmail.com>

Hello John, Does this help?

https://cran.r-project.org/web/packages/bibliometrix/vignettes/bibliometrix-vignette.html
https://bibliometrix.org/

Best, Bill.

W. Michels, Ph.D.


On Fri, Aug 28, 2020 at 11:04 PM Fraedrich, John <fraedric at siu.edu> wrote:
>
>
>
> To analyze 10,000+ articles within several journals to determine major theories used, empirical research of models, constructs, and variables, differences in standard definitions by discipline, etc. Is/does R have this in a software package?
>
>
>
> Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Aug 31 08:30:03 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 31 Aug 2020 06:30:03 +0000
Subject: [R] how to create a sequence to consecutive values
In-Reply-To: <CAGxFJbTmusOvsQDFzkq5T_q9HzY7nR=1O1GkDEu=q35TgY1q7g@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F809EA1CB@ESINO.regionemarche.intra>
 <CAGxFJbSkaNvrV8r86ne-DNQeu5N3Xa2Mp10dYv6G=r-_NK=RCw@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4F809EA1E2@ESINO.regionemarche.intra>
 <CC8AB8DB-1842-495C-A7D1-C0C010EC39FA@dcn.davis.ca.us>,
 <CAGxFJbTmusOvsQDFzkq5T_q9HzY7nR=1O1GkDEu=q35TgY1q7g@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809EA76D@ESINO.regionemarche.intra>

Thank you both of you. I am studying these solutions.

Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------
________________________________
Da: Bert Gunter [bgunter.4567 at gmail.com]
Inviato: venerd? 28 agosto 2020 18.07
A: Jeff Newmiller
Cc: Stefano Sofia; r-help mailing list
Oggetto: Re: [R] how to create a sequence to consecutive values

Actually, I prefer Jeff's use of diff() . Hadn't thought of that.

However, note that, unsurprisingly,  NA's mess up both: The rle() method fails with an error and the diff() method gives the wrong answer.

Cheers,
Bert


On Fri, Aug 28, 2020 at 8:48 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us<mailto:jdnewmil at dcn.davis.ca.us>> wrote:
cumsum is a bit faster...

a <- c( 0, 0, 0, 1, 1, 1, 1, 0, 0, 0
      , 0, 1, 1, 0, 1, 1, 1, 0
      )

f1 <- function(a) {
  z <- rle(a)
  v <- z$values
  v[v==1] <- seq_along(v[v==1]) ## or use cumsum
  rep(v,z$lengths)
}

f2 <- function(a) {
  v <- cumsum( c( a[1], 1==diff(a) ) )
  v[ 0==a ] <- 0
  v
}

f2(a)

library(microbenchmark)

a2 <- rep( c( 0,0, 1, 1, 1 )
         , 300 )

microbenchmark( res1 <- f1(a2)
              , res2 <- f2(a2)
              )
stopifnot( res1 == res2 )


On August 28, 2020 8:19:41 AM PDT, Stefano Sofia <stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>> wrote:
>Thank you!
>Stefano
>
>         (oo)
>--oOO--( )--OOo----------------
>Stefano Sofia PhD
>Civil Protection - Marche Region
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona
>Uff: 071 806 7743
>E-mail: stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>
>---Oo---------oO----------------
>________________________________
>Da: Bert Gunter [bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>]
>Inviato: venerd? 28 agosto 2020 17.14
>A: Stefano Sofia
>Cc: r-help mailing list
>Oggetto: Re: [R] how to create a sequence to consecutive values
>
>Using ?rle
>
>> z <- rle(a)
>> v <- z$values
>> v[v==1] <- seq_along(v[v==1]) ## or use cumsum
>< rep(v,z$lengths)
> [1] 0 0 0 1 1 1 1 0 0 0 0 2 2 0 3 3 3 0 0
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Fri, Aug 28, 2020 at 7:52 AM Stefano Sofia
><stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it><mailto:stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>>>
>wrote:
>Dear R-list users,
>this is a simple question, I have not been able to find an efficient
>solution.
>Given a vector with only 0 or 1 values, I need to give a sequence to
>the consecutive values of 1:
>
>a <- c(0,0,0,1,1,1,1,0,0,0,0,1,1,0,1,1,1,0,0)
>
>I should get as result
>
>(0,0,0,1,1,1,1,0,0,0,0,2,2,0,3,3,3,0,0)
>
>I tried with ave, but no way to get it for me.
>
>Thank you for your help
>Stefano
>
>         (oo)
>--oOO--( )--OOo----------------
>Stefano Sofia PhD
>Civil Protection - Marche Region
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona
>Uff: 071 806 7743
>E-mail:
>stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it><mailto:stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>>
>---Oo---------oO----------------
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate alla ricezione. I messaggi di posta elettronica per i
>client di Regione Marche possono contenere informazioni confidenziali e
>con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>
>--
>Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>This message was scanned by Libra ESVA and is believed to be clean.
>
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
>UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y><https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y><https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y>
>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Questo messaggio ? stato analizzato con Libra ESVA ed ? risultato non
>infetto
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate alla ricezione. I messaggi di posta elettronica per i
>client di Regione Marche possono contenere informazioni confidenziali e
>con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>
>-->
>Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.>
>This message was scanned by Libra ESVA and is believed to be clean.
>
>
>       [[alternative HTML version deleted]]

--
Sent from my phone. Please excuse my brevity.

--
Questo messaggio ? stato analizzato con Libra ESVA ed ? risultato non infetto

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Aug 31 12:55:48 2020
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 31 Aug 2020 16:25:48 +0530
Subject: [R] Connection to Oracle DB failing from R
Message-ID: <CA+dpOJnZf5+3Df-_-sydZKoncQNY5bBRK+=nDZj4oyvCfHTuMw@mail.gmail.com>

Hi,

I am trying to establish a connection to a Oracle DB from R and used below
code which is failing every time I try -

> library(RJDBC)
Loading required package: DBI
> jdbcDriver =JDBC("oracle.jdbc.OracleDriver",classPath="ojdbc5.jar")

 *** caught segfault ***
address 0x854961, cause 'memory not mapped'

Traceback:
 1: .jinit(classPath)
 2: JDBC("oracle.jdbc.OracleDriver", classPath = "ojdbc5.jar")

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:


Below is my session info -

> sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:
 /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
LAPACK:
/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] C/UTF-8/C/C/C/C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RJDBC_0.2-8  DBI_1.1.0    rJava_0.9-13

loaded via a namespace (and not attached):
[1] compiler_4.0.2

I downloaded the JAR file from
https://www.oracle.com/database/technologies/jdbcdriver-ucp-downloads.html

Can you please help me to understand why it is failing?

	[[alternative HTML version deleted]]


From tobby @end|ng |rom htu@@t  Mon Aug 31 14:00:17 2020
From: tobby @end|ng |rom htu@@t (Tobias Fellinger)
Date: Mon, 31 Aug 2020 14:00:17 +0200
Subject: [R] Problem running stan interactively
Message-ID: <9590617A-ECAD-42A1-8DD8-17021B45B7A2@htu.at>

Hi,


I try to run a stan model in R 4.0.2 and the session crashes if I run the code interactively (sourcing from an interactive session or from Rstudio) but runs fine if run with Rscript or R -e 'source("rstan_test.R")' . I don't really know where to begin to debug this.

I'm not sure if this is due to the setup on my machine or if this is a bug in either the packaging on Debian, the rstan package or R itself, so I'm posting it here in the most general mailinglist.


For now just running the model in a non-interactive session is a workaround. R and stan code and sessionInfo below.


All the best and thanks in advance, Tobias


==== rstan_test.R ====
library(rstan)


schools_dat <- list(J = 8,

y = c(28, 8, -3, 7, -1, 1, 18, 12),

sigma = c(15, 10, 16, 11, 9, 11, 10, 18))


fit <- stan(file = 'schools.stan', data = schools_dat)


message("done")

====


==== schools.stan ====

// saved as schools.stan

data {

int<lower=0> J; // number of schools

real y[J]; // estimated treatment effects

real<lower=0> sigma[J]; // standard error of effect estimates

}

parameters {

real mu; // population treatment effect

real<lower=0> tau; // standard deviation in treatment effects

vector[J] eta; // unscaled deviation from mu by school

}

transformed parameters {

vector[J] theta = mu + tau * eta; // school treatment effects

}

model {

target += normal_lpdf(eta | 0, 1); // prior log-density

target += normal_lpdf(y | theta, sigma); // log-likelihood

}

====


==== output of sessionInfo ====

$ R -e 'library(rstan); sessionInfo()'


R version 4.0.2 (2020-06-22) -- "Taking Off Again"

Copyright (C) 2020 The R Foundation for Statistical Computing

Platform: x86_64-pc-linux-gnu (64-bit)


R is free software and comes with ABSOLUTELY NO WARRANTY.

You are welcome to redistribute it under certain conditions.

Type 'license()' or 'licence()' for distribution details.


Natural language support but running in an English locale


R is a collaborative project with many contributors.

Type 'contributors()' for more information and

'citation()' on how to cite R or R packages in publications.


Type 'demo()' for some demos, 'help()' for on-line help, or

'help.start()' for an HTML browser interface to help.

Type 'q()' to quit R.


> library(rstan); sessionInfo()

Loading required package: StanHeaders

Loading required package: ggplot2

rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)

For execution on a local, multicore CPU with excess RAM we recommend calling

options(mc.cores = parallel::detectCores()).

To avoid recompilation of unchanged Stan programs, we recommend calling

rstan_options(auto_write = TRUE)

R version 4.0.2 (2020-06-22)

Platform: x86_64-pc-linux-gnu (64-bit)

Running under: Debian GNU/Linux 10 (buster)


Matrix products: default

BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3

LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so


locale:

[1] LC_CTYPE=en_US.utf8 LC_NUMERIC=C

[3] LC_TIME=en_DK.UTF-8 LC_COLLATE=en_US.utf8

[5] LC_MONETARY=en_DK.UTF-8 LC_MESSAGES=en_US.utf8

[7] LC_PAPER=en_DK.UTF-8 LC_NAME=C

[9] LC_ADDRESS=C LC_TELEPHONE=C

[11] LC_MEASUREMENT=en_DK.UTF-8 LC_IDENTIFICATION=C


attached base packages:

[1] stats graphics grDevices utils datasets methods base


other attached packages:

[1] rstan_2.21.2 ggplot2_3.3.2 StanHeaders_2.21.0-6


loaded via a namespace (and not attached):

[1] Rcpp_1.0.5 pillar_1.4.6 compiler_4.0.2 prettyunits_1.1.1

[5] tools_4.0.2 pkgbuild_1.1.0 jsonlite_1.7.0 lifecycle_0.2.0

[9] tibble_3.0.3 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.7

[13] cli_2.0.2 parallel_4.0.2 curl_4.3 loo_2.3.1

[17] gridExtra_2.3 withr_2.2.0 dplyr_1.0.2 generics_0.0.2

[21] vctrs_0.3.4 stats4_4.0.2 grid_4.0.2 tidyselect_1.1.0

[25] glue_1.4.2 inline_0.3.15 R6_2.4.1 processx_3.4.3

[29] fansi_0.4.1 callr_3.4.3 purrr_0.3.4 magrittr_1.5

[33] codetools_0.2-16 scales_1.1.1 ps_1.3.4 ellipsis_0.3.1

[37] matrixStats_0.56.0 assertthat_0.2.1 colorspace_1.4-1 V8_3.2.0

[41] RcppParallel_5.0.2 munsell_0.5.0 crayon_1.3.4

>

>

====

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug 31 14:01:14 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 31 Aug 2020 14:01:14 +0200
Subject: [R] plot factors with dots in R
In-Reply-To: <CADfFDC5ez=BSAKy0m8LOO0hPa6J_cHxJTOSPg-6rUrZ7PuaHjA@mail.gmail.com>
References: <CAMk+s2TjtVZaWJd3QTvKTTOzz5b8Pz8WZXC_6hEUhmFrM8BN0Q@mail.gmail.com>
 <CADfFDC5ez=BSAKy0m8LOO0hPa6J_cHxJTOSPg-6rUrZ7PuaHjA@mail.gmail.com>
Message-ID: <CAMk+s2T9nK2EatpfS+gDVi_vo0PkZCLSu2mh63yrXO6P2pTCww@mail.gmail.com>

Thank you, all solutions work!

On Fri, Aug 28, 2020 at 9:02 AM Deepayan Sarkar
<deepayan.sarkar at gmail.com> wrote:
>
> On Thu, Aug 27, 2020 at 5:46 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have a dataframe as follows:
> > ```
> > x = c("0 pmol", "10 pmol", "100 pmol", "1000 pmol")
> > y = c(0.9306, 1.8906, 2.2396, 2.7917)
> > df = data.frame(x, y)
> >
> > > str(df)
> > 'data.frame': 4 obs. of  2 variables:
> >  $ x: chr  "0 pmol" "10 pmol" "100 pmol" "1000 pmol"
> >  $ y: num  0.931 1.891 2.24 2.792
> > ```
> > I would like to visualize the data with the classic dots (pch=16) but:
>
> Perhaps this is a good starting point:
>
> with(df, dotchart(y, labels = x, pch = 16))
>
> -Deepayan
>
> > ```
> > > plot(df$y ~ df$x)
> > Error in plot.window(...) : need finite 'xlim' values
> > In addition: Warning messages:
> > 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> > 2: In min(x) : no non-missing arguments to min; returning Inf
> > 3: In max(x) : no non-missing arguments to max; returning -Inf
> > ```
> > which is right because x is not numeric, so I took the factor:
> > ```
> > plot(df$y ~ factor(df$x)) # gives bars instead of dots
> > plot(df$y ~ factor(df$x), pch = 16) # this also
> > ```
> > I tried to convert directly the dataframe:
> > ```
> > df$x = lapply(df$x, factor)
> > > str(df)
> > 'data.frame': 4 obs. of  2 variables:
> >  $ x:List of 4
> >   ..$ : Factor w/ 1 level "0 pmol": 1
> >   ..$ : Factor w/ 1 level "10 pmol": 1
> >   ..$ : Factor w/ 1 level "100 pmol": 1
> >   ..$ : Factor w/ 1 level "1000 pmol": 1
> >  $ y: num  0.931 1.891 2.24 2.792
> >
> > > plot(r$y ~ r$x, pch = 16)
> > Error in plot.window(...) : need finite 'xlim' values
> > In addition: Warning messages:
> > 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
> > 2: In min(x) : no non-missing arguments to min; returning Inf
> > 3: In max(x) : no non-missing arguments to max; returning -Inf
> > ```
> > If I try to pass the number of levels:
> > ```
> > plot(df$y ~ factor(df$x, 1:4), pch = 16) # this draw a boxplot with
> > all data on level 1
> >
> > > df$x = lapply(df$x, factor(1:4))
> > Error in match.fun(FUN) :
> >   'factor(1:4)' is not a function, character or symbol
> > ```
> >
> > Since the transformation has given only one level (1), my questions are:
> > How do I tell R to use a dot instead of a line?
> > What is the correct way of setting factors?
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rc_@chw@rtz @end|ng |rom me@com  Mon Aug 31 14:29:12 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 31 Aug 2020 08:29:12 -0400
Subject: [R] Connection to Oracle DB failing from R
In-Reply-To: <CA+dpOJnZf5+3Df-_-sydZKoncQNY5bBRK+=nDZj4oyvCfHTuMw@mail.gmail.com>
References: <CA+dpOJnZf5+3Df-_-sydZKoncQNY5bBRK+=nDZj4oyvCfHTuMw@mail.gmail.com>
Message-ID: <99BBF7BD-F722-47DC-A1D8-742AD0B99232@me.com>

> On Aug 31, 2020, at 6:55 AM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> Hi,
> 
> I am trying to establish a connection to a Oracle DB from R and used below
> code which is failing every time I try -
> 
>> library(RJDBC)
> Loading required package: DBI
>> jdbcDriver =JDBC("oracle.jdbc.OracleDriver",classPath="ojdbc5.jar")
> 
> *** caught segfault ***
> address 0x854961, cause 'memory not mapped'
> 
> Traceback:
> 1: .jinit(classPath)
> 2: JDBC("oracle.jdbc.OracleDriver", classPath = "ojdbc5.jar")
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
> 
> 
> Below is my session info -
> 
>> sessionInfo()
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Catalina 10.15.6
> 
> Matrix products: default
> BLAS:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] C/UTF-8/C/C/C/C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] RJDBC_0.2-8  DBI_1.1.0    rJava_0.9-13
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.0.2
> 
> I downloaded the JAR file from
> https://www.oracle.com/database/technologies/jdbcdriver-ucp-downloads.html
> 
> Can you please help me to understand why it is failing?


Hi,

I am copying Simon here, as he is the package author/maintainer for RJDBC.

Typically, segfault's can indicate some kind of version mismatch in the components that have been installed.

Since there are multiple pieces to this installation, between the packages and the underlying Java installation on your Mac, I would defer to Simon's more intimate knowledge here.

In searching for related issues, I noted some other posts on multiple OSs, and some issues raised on Simon's Github repo for the package.

Also, I am torn between suggesting that this be re-posted to r-sig-db, which is specific to R and database interfaces, and r-sig-mac, which is specific to R on macOS. 

However, I will defer to Simon on how he might prefer to handle follow up discussion on your issue.

Regards,

Marc Schwartz


From wdun|@p @end|ng |rom t|bco@com  Mon Aug 31 16:51:38 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 31 Aug 2020 07:51:38 -0700
Subject: [R] Connection to Oracle DB failing from R
In-Reply-To: <CA+dpOJnZf5+3Df-_-sydZKoncQNY5bBRK+=nDZj4oyvCfHTuMw@mail.gmail.com>
References: <CA+dpOJnZf5+3Df-_-sydZKoncQNY5bBRK+=nDZj4oyvCfHTuMw@mail.gmail.com>
Message-ID: <CAF8bMcYiHGuyEf3bBXed-+sF2QwdqiSLCObWfqPSYgy3FB-RkA@mail.gmail.com>

Which version of java do you have installed?  Oracle's web site says
ojdbc5.jar is for Java 1.5 and ojdbc6.jar is for more recent versions.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Aug 31, 2020 at 3:56 AM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi,
>
> I am trying to establish a connection to a Oracle DB from R and used below
> code which is failing every time I try -
>
> > library(RJDBC)
> Loading required package: DBI
> > jdbcDriver =JDBC("oracle.jdbc.OracleDriver",classPath="ojdbc5.jar")
>
>  *** caught segfault ***
> address 0x854961, cause 'memory not mapped'
>
> Traceback:
>  1: .jinit(classPath)
>  2: JDBC("oracle.jdbc.OracleDriver", classPath = "ojdbc5.jar")
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
>
>
> Below is my session info -
>
> > sessionInfo()
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Catalina 10.15.6
>
> Matrix products: default
> BLAS:
>  /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>
> locale:
> [1] C/UTF-8/C/C/C/C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] RJDBC_0.2-8  DBI_1.1.0    rJava_0.9-13
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.2
>
> I downloaded the JAR file from
> https://www.oracle.com/database/technologies/jdbcdriver-ucp-downloads.html
>
> Can you please help me to understand why it is failing?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Aug 31 17:17:02 2020
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 31 Aug 2020 20:47:02 +0530
Subject: [R] Connection to Oracle DB failing from R
In-Reply-To: <CAF8bMcYiHGuyEf3bBXed-+sF2QwdqiSLCObWfqPSYgy3FB-RkA@mail.gmail.com>
References: <CA+dpOJnZf5+3Df-_-sydZKoncQNY5bBRK+=nDZj4oyvCfHTuMw@mail.gmail.com>
 <CAF8bMcYiHGuyEf3bBXed-+sF2QwdqiSLCObWfqPSYgy3FB-RkA@mail.gmail.com>
Message-ID: <CA+dpOJnvFdBZ_rxhhv6CQ3m2dRzWN=1o5guf3HoE0cNP0VSt=w@mail.gmail.com>

Hi,

The Java version below. Let me know if any other information is
required. Thanks,

java -version
java version "1.8.0_201"
Java(TM) SE Runtime Environment (build 1.8.0_201-b09)
Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)


On Mon, Aug 31, 2020 at 8:21 PM William Dunlap <wdunlap at tibco.com> wrote:
>
> Which version of java do you have installed?  Oracle's web site says
> ojdbc5.jar is for Java 1.5 and ojdbc6.jar is for more recent versions.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Aug 31, 2020 at 3:56 AM Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
> >
> > Hi,
> >
> > I am trying to establish a connection to a Oracle DB from R and used below
> > code which is failing every time I try -
> >
> > > library(RJDBC)
> > Loading required package: DBI
> > > jdbcDriver =JDBC("oracle.jdbc.OracleDriver",classPath="ojdbc5.jar")
> >
> >  *** caught segfault ***
> > address 0x854961, cause 'memory not mapped'
> >
> > Traceback:
> >  1: .jinit(classPath)
> >  2: JDBC("oracle.jdbc.OracleDriver", classPath = "ojdbc5.jar")
> >
> > Possible actions:
> > 1: abort (with core dump, if enabled)
> > 2: normal R exit
> > 3: exit R without saving workspace
> > 4: exit R saving workspace
> > Selection:
> >
> >
> > Below is my session info -
> >
> > > sessionInfo()
> > R version 4.0.2 (2020-06-22)
> > Platform: x86_64-apple-darwin17.0 (64-bit)
> > Running under: macOS Catalina 10.15.6
> >
> > Matrix products: default
> > BLAS:
> >  /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> > LAPACK:
> > /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> >
> > locale:
> > [1] C/UTF-8/C/C/C/C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] RJDBC_0.2-8  DBI_1.1.0    rJava_0.9-13
> >
> > loaded via a namespace (and not attached):
> > [1] compiler_4.0.2
> >
> > I downloaded the JAR file from
> > https://www.oracle.com/database/technologies/jdbcdriver-ucp-downloads.html
> >
> > Can you please help me to understand why it is failing?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Mon Aug 31 17:41:19 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 31 Aug 2020 17:41:19 +0200
Subject: [R] 
 Can I use "mcnemar.test" for 3*3 tables (or is there a bug in
 the command?)
In-Reply-To: <CAAh8H1ENJ++uv0A6PPU7udtJgAd=-_ZbkG7YOsdQ11ZZub1n4w@mail.gmail.com>
References: <CAAh8H1ENJ++uv0A6PPU7udtJgAd=-_ZbkG7YOsdQ11ZZub1n4w@mail.gmail.com>
Message-ID: <9D52FC37-6BB7-41F3-BDF2-E53C3232CD6B@gmail.com>



> On 30 Aug 2020, at 20:11 , Kyungmin Ko <kaymin.ko at gmail.com> wrote:
> 
>> 2) The second one is to produce a 3 by 3 table, with the rows indicating
>> what the kids answered to setting 1 of the experiment, and the columns
>> indicating the kids answers to setting 2.
>> Now the question is:
>> was there marginal homogenity? if not, then that is an indicator that the
>> general response to the experimental settings was different for the kids.
> 
>> 1) can I use "mcnemar.test" for 3*3 (or more) tables ?
> As Peter Dalgaard and jchavez12 (on Nabble) pointed out,

Um, that was on July 19, 2009.....

> "mcnemar.test" does McNemar-Bowker test (Bowker's test) which tests
> symmetry, not marginal homogeneity.
> Marginal homogeneity and symmetry are equivalent in 2x2 matrices but
> not for larger tables.
> I also was confused because many resources (for example Wikipedia
> accessed 2020-08-30) introduce McNemar's test as a test of marginal
> homogeneity (which it is only for 2x2 matrices).
> The R Reference Manual entry for mcnemar.test states that it tests for symmetry.
> The code for mcnemar.test is also consistent with the McNemar-Bowker
> test for symmetry.
> 
>> Is there a bug in the command?
> Since the function does what the manual states it does, I would not
> call this a bug.
> Although, I would like it if the result of mcnemar.test would print
> "McNemar's Chi-squared test of symmetry" rather than just "McNemar's
> Chi-squared test."
> 
>> Is the one necessarily better then the other? (for example for
>> sparser matrices ?)
> mcnemar.test often fails for sparse matrices, because symmetric zeros
> produce a NaN due to division by zero in the following line of
> mcnemar.test code:
> STATISTIC <- sum(y[upper.tri(x)]^2/x[upper.tri(x)])
> The McNemar-Bowker test uses Chi-squared approximation, which would
> not be good for small counts (and sparse matrices).
> mcnemar.test does not perform continuity correction for matrices
> larger than 2x2.
> Is there an exact test for symmetry of matrices larger than 2x2?
> I could not find one.

The exact test for the 2x2 case is isomorphic to a binomial test of the two off-diagonal elements (conditioning on the sum).

The natural way of constructing a test for the k x k case would be based on the Cartesian product of k(k-1)/2 binomials with p=.5, (one for each i,j-combination). This shouldn't be too hard if k is small, but of course it explodes combinatorially as k increases.

-pd

> 
>> Is there a bug in the command?
> I would not call this a bug.
> This behavior of giving "NA" due to a division by zero seems to be
> consistent across statistical tests in R.
> For example chisq.test(matrix(c(0, 0, 1, 2), nrow = 2) gives NA.
> 
>> So which one is "right" ?
> You have the option of the McNemar-Bowker test for symmetry
> (mcnemar.test), and Stuart-Maxwell test (mh_test).
> As an "indicator that the general response to the experimental
> settings was different for the kids,"
> I would think that if marginal homogeneity is rejected, the two tests
> are not equivalent.
> I would run mh_test with distribution = "exact" .
> The relationship between symmetry and equivalence of two tests is not
> as clear to me.
> I suppose if the two experimental settings are equivalent and the
> distribution of random error for each test are also the same the
> resulting matrix would be symmetric?
> 
> R 4.0.2 . coin 1.3.1 .
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ||rpo2 @end|ng |rom ||n|@gov  Mon Aug 31 22:36:34 2020
From: ||rpo2 @end|ng |rom ||n|@gov (Firpo, Mike)
Date: Mon, 31 Aug 2020 20:36:34 +0000
Subject: [R] System Requirements
In-Reply-To: <20200822165655.GB139810@posteo.no>
References: <BYAPR09MB32225E8E9DD4EC982A0651CEF85B0@BYAPR09MB3222.namprd09.prod.outlook.com>
 <CAJc=yOEs3_rxpK-o5W8dqpafa1PF3DN6ehRJSRofOuHr9Z0YoQ@mail.gmail.com>
 <20200822165655.GB139810@posteo.no>
Message-ID: <BYAPR09MB32224A38DCBDDF653C475206F8510@BYAPR09MB3222.namprd09.prod.outlook.com>

Patrick, Rui, Murdoch, and Rasmus,

  Thank you for your responses.  It may not be fair of me to send out that request just before leaving on vacation for a week.  I appreciate you getting back to me.

All the best,

Mike

-----Original Message-----
From: Rasmus Liland <jral at posteo.no> 
Sent: Saturday, August 22, 2020 9:57 AM
To: Patrick (Malone Quantitative) <malone at malonequantitative.com>; Firpo, Mike <firpo2 at llnl.gov>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] System Requirements

Dear Mike,

On 2020-08-22 11:50 -0400, Patrick (Malone Quantitative) wrote:
| On Sat, Aug 22, 2020 at 11:44 AM Firpo, Mike wrote:
| | 
| | Hello,
| |
| | Reading the FAQ, I'm confused about whether R 4.0.2 is tested on 
| | Windows 7.  I found the following:
| |
| | | 2.24 Does R run under Windows 
| | |   Vista/7/8/Server 2008?
| | |
| | | It does. ...
| | | 
| | | 2.2 How do I install R for Windows?
| | |
| | | Current binary versions of R are
| | | known to run on Windows 7 or
| | | later, including on 64-bit
| | | versions: See Can I use R on
| | | 64-bit Windows?. Windows XP is
| | | no longer supported.
| | |
| | | We only test on versions of
| | | Windows currently supported by
| | | Microsoft, mainly 64-bit Windows
| | | 7, Windows Server 2008 and Windows 10. ...
| |
| | There is no indication what date
| | these questions and answers were
| | posted.  

You have to dig around like a dog in SVN or on github.  I found in doc/manual/Makefile.in that rw-FAQ.html comes from rw-FAQ.texi; the 3.6.0 version is in qinwang's account[1], selecting blame for line 623 and 150 shows[2][3] that this was written around ten years ago by ripley.

Maybe you can get a SVN viewer for
Windows and pull trunk[4] to look
around.

| | If it's true that R is only
| | tested on supported versions of
| | Windows, that would exclude Vista
| | and Windows 7.
| |
| | The download site doesn't mention
| | operating system requirements.  Does
| | 4.0.2 work on Windows 7?
| 
| Try it and see?

This table[5] says Windows XP was the
latest deprecated version.

Maybe look into running something like
Linux Mint?

Best,
Rasmus

[1] https://github.com/qinwang/R/blob/master/doc/manual/rw-FAQ.texi#L623
[2] https://github.com/qinwang/R/commit/5b8d4d50aa8ac7989dec5d3c571c89c1dd6d6466
[3] https://github.com/qinwang/R/commit/dc8e21174441426237c6af1dff697784eac8d7c1
[4] https://svn.r-project.org/R/trunk/
[5] https://en.wikipedia.org/wiki/R_(programming_language)#Milestones


